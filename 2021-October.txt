From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Oct  1 08:30:55 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 1 Oct 2021 08:30:55 +0200
Subject: [R] how to combine logic test on vectors in R?
In-Reply-To: <CAGgJW77WETWGALN_t3N8NoXFxMrKo5tsCDXPNWWHEROMw=8yAw@mail.gmail.com>
References: <CAMk+s2TiRXCr1dP1xf6F9fKj7DvGpuMSjrqfpQRBp=N8AAR-xA@mail.gmail.com>
 <CAM_vjunfBsW94i8N3-b+c5WZ19+XZi-tLMACixyTzmpj006Zyw@mail.gmail.com>
 <CAMk+s2R-eLK-b1bcHzSmrJCs7H1N9ynA3n6ckZC9mZYd+DgVOw@mail.gmail.com>
 <CAGxFJbSY2gjSGfmMYVxR5qn8dAyLnH57hDUdKjW_wa++Gj5CtA@mail.gmail.com>
 <CAGgJW77WETWGALN_t3N8NoXFxMrKo5tsCDXPNWWHEROMw=8yAw@mail.gmail.com>
Message-ID: <CAMk+s2RGOm0uCa5ZzgkA0czAyHzL9DTW-U_qR1qu4iw3O40eBg@mail.gmail.com>

Thank you! I have been thinking of using length but it would make the
test more complex. I did not know about all() but it looks like the
tool for the job. Cheers

On Thu, Sep 30, 2021 at 6:24 PM Eric Berger <ericjberger at gmail.com> wrote:
>
> Alternatively you can modify the test as follows:
>
> length(unique(df_b$q)) == 1
>
>
>
> On Thu, Sep 30, 2021 at 7:22 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> I haven't followed this thread closely, but to your question I think
>> maybe this is what you want"
>>
>> > z <- c("","")
>> > all(z == "")
>> [1] TRUE
>> > z <- c("a","")
>> > all(z == "")
>> [1] FALSE
>>
>> If this isn't it, just ignore without reply.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Thu, Sep 30, 2021 at 8:51 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >
>> > Yes, but the && should work within `unique(df_b$q) == ""` because the
>> > test should be: (IF THE DATAFRAME HAS ZERO ROW) OR (ALL THE ELEMENTS
>> > OF $q ARE EMPTY) THEN (PRINT empty).
>> > Can I collapse the TRUE FALSE of `unique(df_b$q) == ""`into a single FALSE?
>> >
>> > On Thu, Sep 30, 2021 at 4:28 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> > >
>> > > Hi,
>> > >
>> > > The OR operator you used is working as expected: || starts from the
>> > > left and evaluates only enough of the options to determine the
>> > > results. The first test is TRUE,  so the result is TRUE. It sounds
>> > > like you might actually want an AND operator, & or &&, which will only
>> > > return TRUE if all elements are TRUE,
>> > >
>> > > More on logical operators:
>> > > https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html
>> > >
>> > > Sarah
>> > >
>> > > On Thu, Sep 30, 2021 at 9:07 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> > > >
>> > > > Hello,
>> > > > I have two data frames, each with three rows:
>> > > > ```
>> > > > df_a <- data.frame(a = letters[1:3], b = LETTERS[1:3], q = c("", "", ""),
>> > > > stringsAsFactors = FALSE)
>> > > > df_b <- data.frame(a = letters[4:6], b = LETTERS[4:6], q = c("", "", "1.5"),
>> > > > stringsAsFactors = FALSE)
>> > > > ```
>> > > > I need to test whether the dataframe has been selected and if there is
>> > > > a value in the q column. I combined in the following test:
>> > > > ```
>> > > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
>> > > > print("empty")
>> > > > }
>> > > > if (nrow(df_b) == 0 || unique(df_b$q) == "") {
>> > > > print("empty")
>> > > > }
>> > > > ```
>> > > > The test for df_a worked as expected:
>> > > > ```
>> > > > > nrow(df_a) == 0
>> > > > [1] FALSE
>> > > > > unique(df_a$q) == ""
>> > > > [1] TRUE
>> > > > > (nrow(df_a) == 0 || unique(df_a$q) == "")
>> > > > [1] TRUE
>> > > > > if (nrow(df_a) == 0 || unique(df_a$q) == "") {
>> > > > + print("empty")
>> > > > + }
>> > > > [1] "empty"
>> > > > ```
>> > > > but the one for df_b did not:
>> > > > ```
>> > > > > nrow(df_b) == 0
>> > > > [1] FALSE
>> > > > > unique(df_b$q) == ""
>> > > > [1]  TRUE FALSE
>> > > > > (nrow(df_b) == 0 || unique(df_b$q) == "")
>> > > > [1] TRUE
>> > > > > unique(df_b$q)
>> > > > [1] ""    "1.5"
>> > > > ```
>> > > > I say that it did not work because unique(df_b$q) IS NOT "", hence
>> > > > `(nrow(df_b) == 0 || unique(df_b$q) == "")` should be FALSE, instead R
>> > > > evaluated the first element of unique(df_b$q) == "", which is TRUE.
>> > > > How can I properly implement a logic test on vectors?
>> > > >  Thank you
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > >
>> > >
>> > > --
>> > > Sarah Goslee (she/her)
>> > > http://www.sarahgoslee.com
>> >
>> >
>> >
>> > --
>> > Best regards,
>> > Luigi
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Oct  1 10:05:04 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 1 Oct 2021 10:05:04 +0200
Subject: [R] How to get a given cut-off in logit regression?
Message-ID: <CAMk+s2RYq+P_kJ64L2PfLPsuS8dm2QC6or5VtSz+nrmKM4nRUQ@mail.gmail.com>

Hello,
I would like to calculate the 95% success rate of a test. I have a
series of dilutions and the proportion of positive results out of 37
attempts for each of them. I would like to find the concentration that
gives 95% success and I used logit regression:
```
df <- data.frame(concentration = c(1, 10, 100, 1000, 10000),
positivity = c(0.86, 1, 1, 1, 1))
model <- glm(positivity~concentration, family="binomial", data=df)
summary(model)
confint(model)
```
When running the model, I get a warning:
```
Warning messages:
1: In eval(family$initialize) : non-integer #successes in a binomial glm!
2: glm.fit: algorithm did not converge
3: glm.fit: fitted probabilities numerically 0 or 1 occurred
```
but I got  something:
```
> summary(model)

Call:
glm(formula = positivity ~ concentration, family = "binomial",
data = df)

Deviance Residuals:
1         2         3         4         5
0.00e+00  4.41e-04  2.00e-08  2.00e-08  2.00e-08

Coefficients:
Estimate Std. Error z value Pr(>|z|)
(Intercept)      0.223    216.154   0.001    0.999
concentration    1.592    216.131   0.007    0.994

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 4.6727e-01  on 4  degrees of freedom
Residual deviance: 1.9445e-07  on 3  degrees of freedom
AIC: 4.3016

Number of Fisher Scoring iterations: 25
```

How can I now find the concentration that gives 95% positivity?

Thanks

-- 
Best regards,
Luigi


From tr|ng @end|ng |rom gvdnet@dk  Fri Oct  1 14:52:45 2021
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Fri, 1 Oct 2021 14:52:45 +0200
Subject: [R] linetype corruption in ggplot2
Message-ID: <ec71d5cf-8c78-7bcf-1e02-aee2ae21d71b@gvdnet.dk>

Dear friends - another simple question: the assignment of linetype seems 
to be corrupted in the code below- I would want the solid line
to be the lowest? and also want the legend to be correct. I guess R 
orders the legend names alphabetically and could handle? that but
cannot unnderstand how the lines apparently are switched.

library(ggplot2)

BB <- cbind(c(1,2,3),c(2,4,6),c(3,6,9))
x <- c(2,3,4)
LT <- c("solid","dashed","dotted")

GG <- ggplot()
for (i in 1:3) {
 ? dd <- data.frame(x,BB=BB[i,],LT=LT[i])
 ? GG <- GG + geom_line(data=dd,aes(x=x,y=BB,linetype=LT),size=1)

}
GG+scale_y_continuous(breaks=seq(1,10))

I'm on Windows, R 4.0.5

All best wishes

Troels


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct  1 15:21:55 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 1 Oct 2021 14:21:55 +0100
Subject: [R] linetype corruption in ggplot2
In-Reply-To: <ec71d5cf-8c78-7bcf-1e02-aee2ae21d71b@gvdnet.dk>
References: <ec71d5cf-8c78-7bcf-1e02-aee2ae21d71b@gvdnet.dk>
Message-ID: <26f6b1da-d04e-7f28-2ab7-06945769eaef@sapo.pt>

Hello,

The problem is in the for loop. Every time through it the data argument 
changes and ggplot only evaluates when printing, not when it's 
constructing the object.

It's not a good idea to construct a ggplot object in a loop.

Why don't you put x and BB in a data.frame, reshape it to long format 
and plot all lines in the same instruction?


df1 <- data.frame(x, BB)
names(df1)[2:4] <- paste0("BB", 1:3)

df1_long <- reshape(
   df1, direction = "long",
   varying = names(df1)[2:4],
   v.names = "BB",
   timevar = "LT"
)
df1_long$LT <- LT[df1_long$LT]

ggplot(df1_long, aes(x, BB, linetype = LT)) +
   geom_line() +
   scale_linetype_manual(values = c(solid = "solid", dashed = "dashed", 
dotted = "dotted"))



Hope this helps,

Rui Barradas

?s 13:52 de 01/10/21, Troels Ring escreveu:
> Dear friends - another simple question: the assignment of linetype seems 
> to be corrupted in the code below- I would want the solid line
> to be the lowest? and also want the legend to be correct. I guess R 
> orders the legend names alphabetically and could handle? that but
> cannot unnderstand how the lines apparently are switched.
> 
> library(ggplot2)
> 
> BB <- cbind(c(1,2,3),c(2,4,6),c(3,6,9))
> x <- c(2,3,4)
> LT <- c("solid","dashed","dotted")
> 
> GG <- ggplot()
> for (i in 1:3) {
>  ? dd <- data.frame(x,BB=BB[i,],LT=LT[i])
>  ? GG <- GG + geom_line(data=dd,aes(x=x,y=BB,linetype=LT),size=1)
> 
> }
> GG+scale_y_continuous(breaks=seq(1,10))
> 
> I'm on Windows, R 4.0.5
> 
> All best wishes
> 
> Troels
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr|ng @end|ng |rom gvdnet@dk  Sat Oct  2 07:28:42 2021
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Sat, 2 Oct 2021 07:28:42 +0200
Subject: [R] linetype corruption in ggplot2
In-Reply-To: <ec71d5cf-8c78-7bcf-1e02-aee2ae21d71b@gvdnet.dk>
References: <ec71d5cf-8c78-7bcf-1e02-aee2ae21d71b@gvdnet.dk>
Message-ID: <4f1e6e43-cd06-8ac7-7d2d-79e5c91f9f16@gvdnet.dk>

Thanks a lot, Rui - this works well - although I still fail to see why a 
loop could not do it although your explanation for the problem is well 
taken!

All best
Troels

Den 01-10-2021 kl. 15:21 skrev Rui Barradas:
> Hello,
>
> The problem is in the for loop. Every time through it the data 
> argument changes and ggplot only evaluates when printing, not when 
> it's constructing the object.
>
> It's not a good idea to construct a ggplot object in a loop.
>
> Why don't you put x and BB in a data.frame, reshape it to long format 
> and plot all lines in the same instruction?
>
>
> df1 <- data.frame(x, BB)
> names(df1)[2:4] <- paste0("BB", 1:3)
>
> df1_long <- reshape(
> ? df1, direction = "long",
> ? varying = names(df1)[2:4],
> ? v.names = "BB",
> ? timevar = "LT"
> )
> df1_long$LT <- LT[df1_long$LT]
>
> ggplot(df1_long, aes(x, BB, linetype = LT)) +
> ? geom_line() +
> ? scale_linetype_manual(values = c(solid = "solid", dashed = "dashed", 
> dotted = "dotted"))
>
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 13:52 de 01/10/21, Troels Ring escreveu:
>> Dear friends - another simple question: the assignment of linetype 
>> seems to be corrupted in the code below- I would want the solid line
>> to be the lowest? and also want the legend to be correct. I guess R 
>> orders the legend names alphabetically and could handle that but
>> cannot unnderstand how the lines apparently are switched.
>>
>> library(ggplot2)
>>
>> BB <- cbind(c(1,2,3),c(2,4,6),c(3,6,9))
>> x <- c(2,3,4)
>> LT <- c("solid","dashed","dotted")
>>
>> GG <- ggplot()
>> for (i in 1:3) {
>> ?? dd <- data.frame(x,BB=BB[i,],LT=LT[i])
>> ?? GG <- GG + geom_line(data=dd,aes(x=x,y=BB,linetype=LT),size=1)
>>
>> }
>> GG+scale_y_continuous(breaks=seq(1,10))
>>
>> I'm on Windows, R 4.0.5
>>
>> All best wishes
>>
>> Troels
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct  2 10:14:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 2 Oct 2021 10:14:02 +0200
Subject: [R] how to predict X given Y using logit regresion in R?
Message-ID: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>

Hello,
I have set a glm model using probit. I would like to use it to predict
X given Y. I have followed this example:
```
f2<-data.frame(age=c(10,20,30),weight=c(100,200,300))
f3<-data.frame(age=c(15,25))
f4<-data.frame(age=18)
mod<-lm(weight~age,data=f2)
> predict(mod,f3)
1
150
> predict(mod,f4)
1
180
```

I have set the following:
```
df <- data.frame(concentration = c(1, 10, 100, 1000, 10000),
positivity = c(0.86, 1, 1, 1, 1))
model <- glm(positivity~concentration,family = binomial(link =
"logit"), data=df)
> e3<-data.frame(concentration=c(11, 101), positivity=c(1, 1))
> predict(model, e3)
1               2
5.645045 46.727573
```
but:
```
> e4<-data.frame(positivity=0.95)
> e4
positivity
1       0.95
> predict(model, e4)
Error in eval(predvars, data, env) : object 'concentration' not found
```
Why did the thing worked for f4 but not e4? How do I get X given Y?
Do I need to find the inverse function of logit (which one?) and apply
this to the regression or is there a simpler method?
Also, is it possible to plot the model to get a smooter line than
`plot(positivity ~ concentration, data = df, log = "x", type="o")`?
Thanks
-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct  2 16:33:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 2 Oct 2021 16:33:32 +0200
Subject: [R] how to predict X given Y using logit regresion in R?
In-Reply-To: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>
References: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>
Message-ID: <CAMk+s2RS4KFZM00fBzzOZFrmOyfve0XJ2KG80WYSOgpDt_Go+Q@mail.gmail.com>

I tried with:
```
library(chemCal)
inverse.predict(model, 0.95)
> inverse.predict(model, 0.95)
$Prediction
[1] 0.4565871

$`Standard Error`
[1] 5.525725e-10

$Confidence
[1] 1.758532e-09

$`Confidence Limits`
[1] 0.4565871 0.4565871
```
but the value 0.457 does not sound good, it should be about 1.7. Could
it be that model is based on glm whereas inverse.predict uses linear
regression?

On Sat, Oct 2, 2021 at 10:14 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have set a glm model using probit. I would like to use it to predict
> X given Y. I have followed this example:
> ```
> f2<-data.frame(age=c(10,20,30),weight=c(100,200,300))
> f3<-data.frame(age=c(15,25))
> f4<-data.frame(age=18)
> mod<-lm(weight~age,data=f2)
> > predict(mod,f3)
> 1
> 150
> > predict(mod,f4)
> 1
> 180
> ```
>
> I have set the following:
> ```
> df <- data.frame(concentration = c(1, 10, 100, 1000, 10000),
> positivity = c(0.86, 1, 1, 1, 1))
> model <- glm(positivity~concentration,family = binomial(link =
> "logit"), data=df)
> > e3<-data.frame(concentration=c(11, 101), positivity=c(1, 1))
> > predict(model, e3)
> 1               2
> 5.645045 46.727573
> ```
> but:
> ```
> > e4<-data.frame(positivity=0.95)
> > e4
> positivity
> 1       0.95
> > predict(model, e4)
> Error in eval(predvars, data, env) : object 'concentration' not found
> ```
> Why did the thing worked for f4 but not e4? How do I get X given Y?
> Do I need to find the inverse function of logit (which one?) and apply
> this to the regression or is there a simpler method?
> Also, is it possible to plot the model to get a smooter line than
> `plot(positivity ~ concentration, data = df, log = "x", type="o")`?
> Thanks
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct  2 22:36:57 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 2 Oct 2021 22:36:57 +0200
Subject: [R] how to predict X given Y using logit regresion in R?
In-Reply-To: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>
References: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>
Message-ID: <CAMk+s2Rm-eJfXP8Qzr2OoPohm1yryvwNA4dDk5tzqJ0mLPdy7Q@mail.gmail.com>

Hello,
I also tried with
```
library(MASS)
> dose.p(model,p=.95)
               Dose       SE
p = 0.95: 1.70912 96.26511
```
which is closer to the expected 1.72 but with a very large error (I
expected 1.10-2.34). Is this regression correct?

On Sat, Oct 2, 2021 at 10:14 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have set a glm model using probit. I would like to use it to predict
> X given Y. I have followed this example:
> ```
> f2<-data.frame(age=c(10,20,30),weight=c(100,200,300))
> f3<-data.frame(age=c(15,25))
> f4<-data.frame(age=18)
> mod<-lm(weight~age,data=f2)
> > predict(mod,f3)
> 1
> 150
> > predict(mod,f4)
> 1
> 180
> ```
>
> I have set the following:
> ```
> df <- data.frame(concentration = c(1, 10, 100, 1000, 10000),
> positivity = c(0.86, 1, 1, 1, 1))
> model <- glm(positivity~concentration,family = binomial(link =
> "logit"), data=df)
> > e3<-data.frame(concentration=c(11, 101), positivity=c(1, 1))
> > predict(model, e3)
> 1               2
> 5.645045 46.727573
> ```
> but:
> ```
> > e4<-data.frame(positivity=0.95)
> > e4
> positivity
> 1       0.95
> > predict(model, e4)
> Error in eval(predvars, data, env) : object 'concentration' not found
> ```
> Why did the thing worked for f4 but not e4? How do I get X given Y?
> Do I need to find the inverse function of logit (which one?) and apply
> this to the regression or is there a simpler method?
> Also, is it possible to plot the model to get a smooter line than
> `plot(positivity ~ concentration, data = df, log = "x", type="o")`?
> Thanks
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct  2 22:48:51 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 2 Oct 2021 22:48:51 +0200
Subject: [R] how to predict X given Y using logit regresion in R?
In-Reply-To: <CAMk+s2RS4KFZM00fBzzOZFrmOyfve0XJ2KG80WYSOgpDt_Go+Q@mail.gmail.com>
References: <CAMk+s2QALE7pbnsgp5=A1omW+CFh6YzoHTcWnzQrnmZJvUzy1w@mail.gmail.com>
 <CAMk+s2RS4KFZM00fBzzOZFrmOyfve0XJ2KG80WYSOgpDt_Go+Q@mail.gmail.com>
Message-ID: <CAMk+s2SrPDtbip4ZPxvTZ0+fjdAgNpu3yUXrw+apYNo_7x8Fxw@mail.gmail.com>

Actually,
I think it worked with chemCal, it was the drawing that was a bit
rough. I sort it with:
```
library(MASS)
lod <- dose.p(model,p=.95)
plot(positivity ~ concentration, data = df, log = "x",
xlab=expression(bold(paste("Concentration (c/", mu, "L)"))),
ylab=expression(bold("Proportion of positivity")))
newdata <- data.frame(concentration=seq(min(df$concentration),
max(df$concentration),by=0.01))
newdata$positivity = predict(model, newdata, type="response")
abline(h=0.95, lty=3)
abline(v=lod, lty=3)
points(positivity ~ concentration, data = newdata, type="l")
text(lod+0.2, 0.87, labels = round(lod, 2), cex = 0.9)
```


Case closed

On Sat, Oct 2, 2021 at 4:33 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> I tried with:
> ```
> library(chemCal)
> inverse.predict(model, 0.95)
> > inverse.predict(model, 0.95)
> $Prediction
> [1] 0.4565871
>
> $`Standard Error`
> [1] 5.525725e-10
>
> $Confidence
> [1] 1.758532e-09
>
> $`Confidence Limits`
> [1] 0.4565871 0.4565871
> ```
> but the value 0.457 does not sound good, it should be about 1.7. Could
> it be that model is based on glm whereas inverse.predict uses linear
> regression?
>
> On Sat, Oct 2, 2021 at 10:14 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have set a glm model using probit. I would like to use it to predict
> > X given Y. I have followed this example:
> > ```
> > f2<-data.frame(age=c(10,20,30),weight=c(100,200,300))
> > f3<-data.frame(age=c(15,25))
> > f4<-data.frame(age=18)
> > mod<-lm(weight~age,data=f2)
> > > predict(mod,f3)
> > 1
> > 150
> > > predict(mod,f4)
> > 1
> > 180
> > ```
> >
> > I have set the following:
> > ```
> > df <- data.frame(concentration = c(1, 10, 100, 1000, 10000),
> > positivity = c(0.86, 1, 1, 1, 1))
> > model <- glm(positivity~concentration,family = binomial(link =
> > "logit"), data=df)
> > > e3<-data.frame(concentration=c(11, 101), positivity=c(1, 1))
> > > predict(model, e3)
> > 1               2
> > 5.645045 46.727573
> > ```
> > but:
> > ```
> > > e4<-data.frame(positivity=0.95)
> > > e4
> > positivity
> > 1       0.95
> > > predict(model, e4)
> > Error in eval(predvars, data, env) : object 'concentration' not found
> > ```
> > Why did the thing worked for f4 but not e4? How do I get X given Y?
> > Do I need to find the inverse function of logit (which one?) and apply
> > this to the regression or is there a simpler method?
> > Also, is it possible to plot the model to get a smooter line than
> > `plot(positivity ~ concentration, data = df, log = "x", type="o")`?
> > Thanks
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 8687 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211002/e5f2b21a/attachment.png>

From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Oct  3 00:00:15 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 3 Oct 2021 01:00:15 +0300
Subject: [R] Descriptive Statistics: useful hacks
Message-ID: <31e14083-b267-0e06-074f-814f34d15c9e@syonic.eu>

Dear R Users,


I have started to compile some useful hacks for the generation of nice 
descriptive statistics. I hope that these functions & hacks are useful 
to the wider R community. I hope that package developers also get some 
inspiration from the code or from these ideas.


I have started to review various packages focused on descriptive 
statistics - although I am still at the very beginning.


### Hacks / Code
- split table headers in 2 rows;
- split results over 2 rows: view.gtsummary(...);
- add abbreviations as footnotes: add.abbrev(...);

The results are exported as a web page (using shiny) and can be printed 
as a pdf documented. See the following pdf example:

https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.Example_1.pdf


### Example
# currently focused on package gtsummary
library(gtsummary)
library(xml2)

mtcars %>%
 ??? # rename2():
 ??? # - see file Tools.Data.R;
 ??? # - behaves in most cases the same as dplyr::rename();
 ??? rename2("HP" = "hp", "Displ" = disp, "Wt (klb)" = "wt", "Rar" = 
drat) %>%
 ??? # as.factor.df():
 ??? # - see file Tools.Data.R;
 ??? # - encode as (ordered) factor;
 ??? as.factor.df("cyl", "Cyl ") %>%
 ??? # the Descriptive Statistics:
 ??? tbl_summary(by = cyl) %>%
 ??? modify_header(update = header) %>%
 ??? add_p() %>%
 ??? add_overall() %>%
 ??? modify_header(update = header0) %>%
 ??? # Hack: split long statistics !!!
 ??? view.gtsummary(view=FALSE, len=8) %>%
 ??? add.abbrev(
 ??? ??? c("Displ", "HP", "Rar", "Wt (klb)" = "Wt"),
 ??? ??? c("Displacement (in^3)", "Gross horsepower", "Rear axle ratio",
 ??? ??? "Weight (1000 lbs)"));


The required functions are on Github:
https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.R 



The functions rename2() & as.factor.df() are only data-helpers and can 
be found also on Github:
https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R


Note:

1.) The function add.abbrev() operates on the generated html-code:

- the functionality is more generic and could be used easily with other 
packages that export web pages as well;

2.) Split statistics: is an ugly hack. I plan to redesign the 
functionality using xml-technologies. But I have already too many 
side-projects.

3.) as.factor.df(): traditionally, one would create derived data-sets or 
add a new column with the variable as factor (as the user may need the 
numeric values for further analysis). But it looked nicer as a single 
block of code.


Sincerely,


Leonard


From bgunter@4567 @end|ng |rom gm@||@com  Sun Oct  3 00:31:33 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 2 Oct 2021 15:31:33 -0700
Subject: [R] Descriptive Statistics: useful hacks
In-Reply-To: <31e14083-b267-0e06-074f-814f34d15c9e@syonic.eu>
References: <31e14083-b267-0e06-074f-814f34d15c9e@syonic.eu>
Message-ID: <CAGxFJbQMGmYa3qKd2a+c0_bQg8nAfyj6EgnHdjNqrqcBhCQYuA@mail.gmail.com>

If you think what you are doing is useful, why do you not put it in a
package?! That is, after all, the whole purpose of packages.

I can only speak for myself, of course, but I doubt that posting long
involved messages with code here is going to have anything like the
utility of providing a package with carefully written and tested code
and documented functionality. If you have suggestions about how to
improve a *particular* package, a better alternative is probably to
contact the package maintainer.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Oct 2, 2021 at 3:00 PM Leonard Mada via R-help
<r-help at r-project.org> wrote:
>
> Dear R Users,
>
>
> I have started to compile some useful hacks for the generation of nice
> descriptive statistics. I hope that these functions & hacks are useful
> to the wider R community. I hope that package developers also get some
> inspiration from the code or from these ideas.
>
>
> I have started to review various packages focused on descriptive
> statistics - although I am still at the very beginning.
>
>
> ### Hacks / Code
> - split table headers in 2 rows;
> - split results over 2 rows: view.gtsummary(...);
> - add abbreviations as footnotes: add.abbrev(...);
>
> The results are exported as a web page (using shiny) and can be printed
> as a pdf documented. See the following pdf example:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.Example_1.pdf
>
>
> ### Example
> # currently focused on package gtsummary
> library(gtsummary)
> library(xml2)
>
> mtcars %>%
>      # rename2():
>      # - see file Tools.Data.R;
>      # - behaves in most cases the same as dplyr::rename();
>      rename2("HP" = "hp", "Displ" = disp, "Wt (klb)" = "wt", "Rar" =
> drat) %>%
>      # as.factor.df():
>      # - see file Tools.Data.R;
>      # - encode as (ordered) factor;
>      as.factor.df("cyl", "Cyl ") %>%
>      # the Descriptive Statistics:
>      tbl_summary(by = cyl) %>%
>      modify_header(update = header) %>%
>      add_p() %>%
>      add_overall() %>%
>      modify_header(update = header0) %>%
>      # Hack: split long statistics !!!
>      view.gtsummary(view=FALSE, len=8) %>%
>      add.abbrev(
>          c("Displ", "HP", "Rar", "Wt (klb)" = "Wt"),
>          c("Displacement (in^3)", "Gross horsepower", "Rear axle ratio",
>          "Weight (1000 lbs)"));
>
>
> The required functions are on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.R
>
>
>
> The functions rename2() & as.factor.df() are only data-helpers and can
> be found also on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R
>
>
> Note:
>
> 1.) The function add.abbrev() operates on the generated html-code:
>
> - the functionality is more generic and could be used easily with other
> packages that export web pages as well;
>
> 2.) Split statistics: is an ugly hack. I plan to redesign the
> functionality using xml-technologies. But I have already too many
> side-projects.
>
> 3.) as.factor.df(): traditionally, one would create derived data-sets or
> add a new column with the variable as factor (as the user may need the
> numeric values for further analysis). But it looked nicer as a single
> block of code.
>
>
> Sincerely,
>
>
> Leonard
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Sun Oct  3 18:40:48 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 3 Oct 2021 18:40:48 +0200
Subject: [R] [Rd] R 4.1.2 scheduled for November 1
Message-ID: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>

(Just a quick heads-up for developers.)
 
Full schedule to be made available soon.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From pd@|gd @end|ng |rom gm@||@com  Sun Oct  3 18:58:08 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 3 Oct 2021 18:58:08 +0200
Subject: [R] [Rd] R 4.1.2 scheduled for November 1
In-Reply-To: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
References: <7BC92570-396C-47AD-A035-6558E1FEEAC0@gmail.com>
Message-ID: <EE1D7D21-430D-4FF8-BEF8-3B46DBD29B7A@gmail.com>

Schedule should appear on developer.r-project.org when it gets updated from SVN.

> On 3 Oct 2021, at 18:40 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> (Just a quick heads-up for developers.)
> 
> Full schedule to be made available soon.
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From pj@|nh@07 @end|ng |rom gm@||@com  Tue Oct  5 14:19:31 2021
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Tue, 5 Oct 2021 08:19:31 -0400
Subject: [R] Need in formatting data for circos plot
Message-ID: <CAGjf1cM_bW+y6LvC=e0yxtHqoG8LXeM6Qf2emry0_qkZRPh_yQ@mail.gmail.com>

Hi All,

I have gene expression data with differential fold change value and the
file looks like as below:
Chrom start_pos end_pos value
14 20482867 20496901 2.713009346
4 123712710 123718202 -2.20797815
13 80883384 80896042 1.646405782
16 48842551 48844461 -1.636002557
17 28399094 28517527 1.033066311
9 31846044 31913462 -1.738549101
1 45311538 45349706 -1.360867536
I wrote a code in R but it is giving error so I need help in trouble
shooting:
library(circlize)
library(gtools)
library(dplyr)
circos.initializeWithIdeogram(species = "mm10")
circos.par("track.height"=0.20)

circos.genomicTrackPlotRegion(data = db_tr,ylim = C(-7, 7), numeric.column
= 4,
                              panel.fun = function(region,value,...) {
                                cond <- value[,1] < 0.0
                                circos.genomicPoints(region[cond,],
value[cond,], pch = ".", cex = 0.1,
                                                     col = "khaki4")
                                circos.genomicPoints(region[!cond,],
value[!cond,], pch = ".", cex = 0.1,
                                                     col = "indianred")
                              })
Error is : Error in C(-7, 7) : object not interpretable as a factor

Please help as I am new to circos plot and tried a lot. The file is also
attached here.

Thanks,
Puja

From petr@p|k@| @end|ng |rom prechez@@cz  Tue Oct  5 15:19:42 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 5 Oct 2021 13:19:42 +0000
Subject: [R] Need in formatting data for circos plot
In-Reply-To: <CAGjf1cM_bW+y6LvC=e0yxtHqoG8LXeM6Qf2emry0_qkZRPh_yQ@mail.gmail.com>
References: <CAGjf1cM_bW+y6LvC=e0yxtHqoG8LXeM6Qf2emry0_qkZRPh_yQ@mail.gmail.com>
Message-ID: <fedaf419791a4b45a9b6e80bb003930c@SRVEXCHCM1302.precheza.cz>

Hm,

Maybe if you change 
> C(-7, 7)
Error in C(-7, 7) : object not interpretable as a factor

to

> c(-7, 7)
[1] -7  7

Cheers
Petr


S pozdravem | Best Regards
RNDr. Petr PIKAL
Vedouc? V?zkumu a v?voje | Research Manager
PRECHEZA a.s.
n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
Tel: +420 581 252 256 | GSM: +420 724 008 364
petr.pikal at precheza.cz | www.precheza.cz
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
partner? PRECHEZA a.s. jsou zve?ejn?ny na:
https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about
processing and protection of business partner's personal data are available
on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
https://www.precheza.cz/01-dovetek/ | This email and any documents attached
to it may be confidential and are subject to the legally binding disclaimer:
https://www.precheza.cz/en/01-disclaimer/

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of pooja sinha
> Sent: Tuesday, October 5, 2021 2:20 PM
> To: r-help mailing list <r-help at r-project.org>
> Subject: [R] Need in formatting data for circos plot
> 
> Hi All,
> 
> I have gene expression data with differential fold change value and the
file
> looks like as below:
> Chrom start_pos end_pos value
> 14 20482867 20496901 2.713009346
> 4 123712710 123718202 -2.20797815
> 13 80883384 80896042 1.646405782
> 16 48842551 48844461 -1.636002557
> 17 28399094 28517527 1.033066311
> 9 31846044 31913462 -1.738549101
> 1 45311538 45349706 -1.360867536
> I wrote a code in R but it is giving error so I need help in trouble
> shooting:
> library(circlize)
> library(gtools)
> library(dplyr)
> circos.initializeWithIdeogram(species = "mm10")
> circos.par("track.height"=0.20)
> 
> circos.genomicTrackPlotRegion(data = db_tr,ylim = C(-7, 7), numeric.column
> = 4,
>                               panel.fun = function(region,value,...) {
>                                 cond <- value[,1] < 0.0
>                                 circos.genomicPoints(region[cond,],
> value[cond,], pch = ".", cex = 0.1,
>                                                      col = "khaki4")
>                                 circos.genomicPoints(region[!cond,],
> value[!cond,], pch = ".", cex = 0.1,
>                                                      col = "indianred")
>                               })
> Error is : Error in C(-7, 7) : object not interpretable as a factor
> 
> Please help as I am new to circos plot and tried a lot. The file is also
attached
> here.
> 
> Thanks,
> Puja
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pj@|nh@07 @end|ng |rom gm@||@com  Tue Oct  5 16:15:01 2021
From: pj@|nh@07 @end|ng |rom gm@||@com (pooja sinha)
Date: Tue, 5 Oct 2021 10:15:01 -0400
Subject: [R] Need in formatting data for circos plot
In-Reply-To: <fedaf419791a4b45a9b6e80bb003930c@SRVEXCHCM1302.precheza.cz>
References: <CAGjf1cM_bW+y6LvC=e0yxtHqoG8LXeM6Qf2emry0_qkZRPh_yQ@mail.gmail.com>
 <fedaf419791a4b45a9b6e80bb003930c@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGjf1cO=dN5PkzE5k7h-nL9eZ9uwD+eqAqc6abt5kxLC0tokog@mail.gmail.com>

Thanks, the code is working now but it is not plotting in the colorwise
manner ie, khaki4 and indian red. Maybe I need to work more. If you have
any clue then please let me know.


Thanks again,
Puja

On Tue, Oct 5, 2021 at 9:19 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hm,
>
> Maybe if you change
> > C(-7, 7)
> Error in C(-7, 7) : object not interpretable as a factor
>
> to
>
> > c(-7, 7)
> [1] -7  7
>
> Cheers
> Petr
>
>
> S pozdravem | Best Regards
> RNDr. Petr PIKAL
> Vedouc? V?zkumu a v?voje | Research Manager
> PRECHEZA a.s.
> n?b?. Dr. Edvarda Bene?e 1170/24 | 750 02 P?erov | Czech Republic
> Tel: +420 581 252 256 | GSM: +420 724 008 364
> petr.pikal at precheza.cz | www.precheza.cz
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about
> processing and protection of business partner's personal data are available
> on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
> a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti:
> https://www.precheza.cz/01-dovetek/ | This email and any documents
> attached
> to it may be confidential and are subject to the legally binding
> disclaimer:
> https://www.precheza.cz/en/01-disclaimer/
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of pooja sinha
> > Sent: Tuesday, October 5, 2021 2:20 PM
> > To: r-help mailing list <r-help at r-project.org>
> > Subject: [R] Need in formatting data for circos plot
> >
> > Hi All,
> >
> > I have gene expression data with differential fold change value and the
> file
> > looks like as below:
> > Chrom start_pos end_pos value
> > 14 20482867 20496901 2.713009346
> > 4 123712710 123718202 -2.20797815
> > 13 80883384 80896042 1.646405782
> > 16 48842551 48844461 -1.636002557
> > 17 28399094 28517527 1.033066311
> > 9 31846044 31913462 -1.738549101
> > 1 45311538 45349706 -1.360867536
> > I wrote a code in R but it is giving error so I need help in trouble
> > shooting:
> > library(circlize)
> > library(gtools)
> > library(dplyr)
> > circos.initializeWithIdeogram(species = "mm10")
> > circos.par("track.height"=0.20)
> >
> > circos.genomicTrackPlotRegion(data = db_tr,ylim = C(-7, 7),
> numeric.column
> > = 4,
> >                               panel.fun = function(region,value,...) {
> >                                 cond <- value[,1] < 0.0
> >                                 circos.genomicPoints(region[cond,],
> > value[cond,], pch = ".", cex = 0.1,
> >                                                      col = "khaki4")
> >                                 circos.genomicPoints(region[!cond,],
> > value[!cond,], pch = ".", cex = 0.1,
> >                                                      col = "indianred")
> >                               })
> > Error is : Error in C(-7, 7) : object not interpretable as a factor
> >
> > Please help as I am new to circos plot and tried a lot. The file is also
> attached
> > here.
> >
> > Thanks,
> > Puja
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @nne@z@ch@z@ch @end|ng |rom gm@||@com  Mon Oct  4 20:02:36 2021
From: @nne@z@ch@z@ch @end|ng |rom gm@||@com (Anne Zach)
Date: Mon, 4 Oct 2021 11:02:36 -0700
Subject: [R] Rename variables starting with digits
Message-ID: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>

Dear R users,

I have a dataframe that contains several variables, among which 105
correspond to scores on certain trials. Unfortunately, when I imported this
dataframe into R, I realised that the variable names corresponding to each
trial begin with digits, which violates R naming conventions.

I am trying to relabel these variables by adding a 'v' as a prefix to each
of them, I'd like to use tidyverse, but I am struggling with this process
of renaming. When I run this chunk of code, no error occurs but my
variables are not renamed. I'm fairly new to R and I can't understand what
I'm doing wrong.

```{r}

behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
starts_with('^\\d'))

```

I appreciate if you can help.

Best,
Anne

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Tue Oct  5 18:21:51 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Tue, 5 Oct 2021 12:21:51 -0400
Subject: [R] Rename variables starting with digits
In-Reply-To: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
Message-ID: <CAPcHnpRhbEuwyX+1=JNvEFHV2M7OBEnmVMEV8V6n40Gp_3hvdQ@mail.gmail.com>

Hello,


I think you have to use 'matches' instead of 'starts_with', I believe
starts_with does not accept a regular expression whereas matches does.

On Tue, Oct 5, 2021 at 12:15 PM Anne Zach <anne.zach.zach at gmail.com> wrote:

> Dear R users,
>
> I have a dataframe that contains several variables, among which 105
> correspond to scores on certain trials. Unfortunately, when I imported this
> dataframe into R, I realised that the variable names corresponding to each
> trial begin with digits, which violates R naming conventions.
>
> I am trying to relabel these variables by adding a 'v' as a prefix to each
> of them, I'd like to use tidyverse, but I am struggling with this process
> of renaming. When I run this chunk of code, no error occurs but my
> variables are not renamed. I'm fairly new to R and I can't understand what
> I'm doing wrong.
>
> ```{r}
>
> behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> starts_with('^\\d'))
>
> ```
>
> I appreciate if you can help.
>
> Best,
> Anne
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Oct  5 18:25:46 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 5 Oct 2021 19:25:46 +0300
Subject: [R] Rename variables starting with digits
In-Reply-To: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
Message-ID: <CAGgJW756u4DTR9X_bMqa7haZJ=vKPqOy8c0BO_WXvhGj7zqz-Q@mail.gmail.com>

Hi Anne,
It would be helpful to include at least part of behavioral_df for people to
understand the issue better.
Please do the following in R and post the output.

dput( head( behavioral_df) )

Also, set your email to plain text as HTML is stripped from emails on this
list.

Best,
Eric




On Tue, Oct 5, 2021 at 7:15 PM Anne Zach <anne.zach.zach at gmail.com> wrote:

> Dear R users,
>
> I have a dataframe that contains several variables, among which 105
> correspond to scores on certain trials. Unfortunately, when I imported this
> dataframe into R, I realised that the variable names corresponding to each
> trial begin with digits, which violates R naming conventions.
>
> I am trying to relabel these variables by adding a 'v' as a prefix to each
> of them, I'd like to use tidyverse, but I am struggling with this process
> of renaming. When I run this chunk of code, no error occurs but my
> variables are not renamed. I'm fairly new to R and I can't understand what
> I'm doing wrong.
>
> ```{r}
>
> behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> starts_with('^\\d'))
>
> ```
>
> I appreciate if you can help.
>
> Best,
> Anne
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Oct  5 19:11:11 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 5 Oct 2021 13:11:11 -0400
Subject: [R] Rename variables starting with digits
In-Reply-To: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
Message-ID: <21104a65-5f3d-f7f2-d953-ce644de2f210@gmail.com>

On 04/10/2021 2:02 p.m., Anne Zach wrote:
> Dear R users,
> 
> I have a dataframe that contains several variables, among which 105
> correspond to scores on certain trials. Unfortunately, when I imported this
> dataframe into R, I realised that the variable names corresponding to each
> trial begin with digits, which violates R naming conventions.
> 
> I am trying to relabel these variables by adding a 'v' as a prefix to each
> of them, I'd like to use tidyverse, but I am struggling with this process
> of renaming. When I run this chunk of code, no error occurs but my
> variables are not renamed. I'm fairly new to R and I can't understand what
> I'm doing wrong.
> 
> ```{r}
> 
> behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> starts_with('^\\d'))
> 
> ```

You should also consider not renaming the columns.  R allows 
non-standard names to be used as long as you quote them somehow.  For 
example,

   behavioral_df[, "50%"]

will get you the column with name "50%", as will

   behavioral_df$`50%`

I suspect most tidyverse functions will be fine with the `50%` style of 
quoting.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Tue Oct  5 19:21:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 5 Oct 2021 10:21:38 -0700
Subject: [R] Rename variables starting with digits
In-Reply-To: <21104a65-5f3d-f7f2-d953-ce644de2f210@gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
 <21104a65-5f3d-f7f2-d953-ce644de2f210@gmail.com>
Message-ID: <CAGxFJbRWMxBUGS_HUmxYJ+ahqyhp7W6PSGwE9N_73=8a5rXMBg@mail.gmail.com>

... and to add to what Eric and Duncan have said, what you have as column
names depends on how the data were imported. e.g.:

> d1 <-data.frame(a = 1:3, `1b` = letters[1:3]) ## check.names has a
default of TRUE
> names(d1)
[1] "a"   "X1b"   ## note the conversion to a syntactically valid name. See
?data.frame and ?make.names for details

> d2 <-data.frame(a = 1:3, `1b` = letters[1:3], check.names = FALSE)
> names(d2)
[1] "a"  "1b"

So what does names(behavioral_df)  give?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Oct 5, 2021 at 10:11 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 04/10/2021 2:02 p.m., Anne Zach wrote:
> > Dear R users,
> >
> > I have a dataframe that contains several variables, among which 105
> > correspond to scores on certain trials. Unfortunately, when I imported
> this
> > dataframe into R, I realised that the variable names corresponding to
> each
> > trial begin with digits, which violates R naming conventions.
> >
> > I am trying to relabel these variables by adding a 'v' as a prefix to
> each
> > of them, I'd like to use tidyverse, but I am struggling with this process
> > of renaming. When I run this chunk of code, no error occurs but my
> > variables are not renamed. I'm fairly new to R and I can't understand
> what
> > I'm doing wrong.
> >
> > ```{r}
> >
> > behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> > starts_with('^\\d'))
> >
> > ```
>
> You should also consider not renaming the columns.  R allows
> non-standard names to be used as long as you quote them somehow.  For
> example,
>
>    behavioral_df[, "50%"]
>
> will get you the column with name "50%", as will
>
>    behavioral_df$`50%`
>
> I suspect most tidyverse functions will be fine with the `50%` style of
> quoting.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Tue Oct  5 20:50:29 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Tue, 5 Oct 2021 21:50:29 +0300
Subject: [R] Descriptive Statistics: useful hacks
In-Reply-To: <31e14083-b267-0e06-074f-814f34d15c9e@syonic.eu>
References: <31e14083-b267-0e06-074f-814f34d15c9e@syonic.eu>
Message-ID: <b4dbe674-1547-125a-66db-3159da8f8d46@syonic.eu>

Dear R users,


I wrote in the meantime a new function:

apply.html(html, XPATH, FUN, ...)


This function applies FUN to the nodes selected using XPATH. However, I 
wonder if there is a possibility to use more simple selectors (e.g. 
jQuery). Although I am not an expert with jQuery, it may be easier for 
end users than XPATH.


Package htmltools does not seem to offer support to import a native html 
file, nor do I see any functions using jQuery selectors. I do not seem 
to find any such packages. I would be glad for any hints.


Many thanks,


Leonard

=======

Latest code is on Github:

https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.R


Notes:

1.) as.html() currently imports only a few types, but it could be easily 
extended to fully generic html;

Note: the export as shiny app may not work with a fully generic html; I 
have not yet explored all the implications!

2.) I am still struggling to understand how to best design the option: 
with.tags = TRUE.

3.) llammas.FUN: Was implemented at great expense and at the last 
minute, but unfortunately is still incomplete and important visual 
styles are missing. Help is welcomed.


On 10/3/2021 1:00 AM, Leonard Mada wrote:
> Dear R Users,
>
>
> I have started to compile some useful hacks for the generation of nice 
> descriptive statistics. I hope that these functions & hacks are useful 
> to the wider R community. I hope that package developers also get some 
> inspiration from the code or from these ideas.
>
>
> I have started to review various packages focused on descriptive 
> statistics - although I am still at the very beginning.
>
>
> ### Hacks / Code
> - split table headers in 2 rows;
> - split results over 2 rows: view.gtsummary(...);
> - add abbreviations as footnotes: add.abbrev(...);
>
> The results are exported as a web page (using shiny) and can be 
> printed as a pdf documented. See the following pdf example:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.Example_1.pdf 
>
>
>
> ### Example
> # currently focused on package gtsummary
> library(gtsummary)
> library(xml2)
>
> mtcars %>%
> ??? # rename2():
> ??? # - see file Tools.Data.R;
> ??? # - behaves in most cases the same as dplyr::rename();
> ??? rename2("HP" = "hp", "Displ" = disp, "Wt (klb)" = "wt", "Rar" = 
> drat) %>%
> ??? # as.factor.df():
> ??? # - see file Tools.Data.R;
> ??? # - encode as (ordered) factor;
> ??? as.factor.df("cyl", "Cyl ") %>%
> ??? # the Descriptive Statistics:
> ??? tbl_summary(by = cyl) %>%
> ??? modify_header(update = header) %>%
> ??? add_p() %>%
> ??? add_overall() %>%
> ??? modify_header(update = header0) %>%
> ??? # Hack: split long statistics !!!
> ??? view.gtsummary(view=FALSE, len=8) %>%
> ??? add.abbrev(
> ??? ??? c("Displ", "HP", "Rar", "Wt (klb)" = "Wt"),
> ??? ??? c("Displacement (in^3)", "Gross horsepower", "Rear axle ratio",
> ??? ??? "Weight (1000 lbs)"));
>
>
> The required functions are on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.DescriptiveStatistics.R 
>
>
>
> The functions rename2() & as.factor.df() are only data-helpers and can 
> be found also on Github:
> https://github.com/discoleo/R/blob/master/Stat/Tools.Data.R
>
>
> Note:
>
> 1.) The function add.abbrev() operates on the generated html-code:
>
> - the functionality is more generic and could be used easily with 
> other packages that export web pages as well;
>
> 2.) Split statistics: is an ugly hack. I plan to redesign the 
> functionality using xml-technologies. But I have already too many 
> side-projects.
>
> 3.) as.factor.df(): traditionally, one would create derived data-sets 
> or add a new column with the variable as factor (as the user may need 
> the numeric values for further analysis). But it looked nicer as a 
> single block of code.
>
>
> Sincerely,
>
>
> Leonard
>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Oct  6 00:12:13 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 6 Oct 2021 09:12:13 +1100
Subject: [R] Rename variables starting with digits
In-Reply-To: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
Message-ID: <CA+8X3fV2DFxug5hr0M=xnKxfFD3y8R2ZUPx68QWa7mKV0Ah-0g@mail.gmail.com>

Hi Anne,
As mentioned above, you may have to do nothing. Here is an example
that might clarify that:

azdat<-read.table(text="subject 1 2 3
1 10 20 30
2 11 22 33",
header=TRUE,stringsAsFactors=FALSE)
azdat
 subject X1 X2 X3
1       1 10 20 30
2       2 11 22 33

As you can see, R simply prepends an "X" to numeric names. If you
really want a "v":

names(azdat)<-gsub("X","v",names(azdat))

Jim
Always happy to help an ANZAC (bad joke)

On Wed, Oct 6, 2021 at 3:15 AM Anne Zach <anne.zach.zach at gmail.com> wrote:
>
> Dear R users,
>
> I have a dataframe that contains several variables, among which 105
> correspond to scores on certain trials. Unfortunately, when I imported this
> dataframe into R, I realised that the variable names corresponding to each
> trial begin with digits, which violates R naming conventions.
>
> I am trying to relabel these variables by adding a 'v' as a prefix to each
> of them, I'd like to use tidyverse, but I am struggling with this process
> of renaming. When I run this chunk of code, no error occurs but my
> variables are not renamed. I'm fairly new to R and I can't understand what
> I'm doing wrong.
>
> ```{r}
>
> behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> starts_with('^\\d'))
>
> ```
>
> I appreciate if you can help.
>
> Best,
> Anne
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thom@@@@ub|@ @end|ng |rom |m|ndu@tr|e@@com  Wed Oct  6 00:20:33 2021
From: thom@@@@ub|@ @end|ng |rom |m|ndu@tr|e@@com (Thomas Subia)
Date: Tue, 5 Oct 2021 22:20:33 +0000
Subject: [R] (no subject)
Message-ID: <MWHPR12MB1790809FDFA7B79A5B019569ECAF9@MWHPR12MB1790.namprd12.prod.outlook.com>

Colleagues,

Some co-workers are wondering about how secure R software is. 
Is there any documentation on this which I can forward to them?


All the best,
Thomas Subia
Quality Engineer


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Oct  6 11:53:03 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 6 Oct 2021 12:53:03 +0300
Subject: [R] (no subject)
In-Reply-To: <MWHPR12MB1790809FDFA7B79A5B019569ECAF9@MWHPR12MB1790.namprd12.prod.outlook.com>
References: <MWHPR12MB1790809FDFA7B79A5B019569ECAF9@MWHPR12MB1790.namprd12.prod.outlook.com>
Message-ID: <20211006125303.2d294a92@Tarkus>

On Tue, 5 Oct 2021 22:20:33 +0000
Thomas Subia <thomas.subia at fmindustries.com> wrote:

> Some co-workers are wondering about how secure R software is.

I'm afraid that this question is too hard to answer without their
threat model. Secure against what, specifically?

> Is there any documentation on this which I can forward to them?

Well, R is a programming language. It's Turing-complete (see halting
problem), will happily run machine code from shared objects (see
dyn.load, .C, .Call), and install.packages() is there to download
third-party code from the Internet. But that's the case with all
programming languages I know that are used for statistics, which aren't
supposed to run untrusted code.

Maybe you're concerned about data input/output instead. Functions are
first-class objects, so it's possible to save and load them from data
files. Not sure if there's a way to run code on data load, but you can
do it on print() (e.g. print.nls(x) calling x$m$getAllPars()), so don't
load()/readRDS() untrusted data files. There are known bugs in the
deserialiser, too: https://bugs.r-project.org/show_bug.cgi?id=16034

Don't know if it's documented anywhere, though. What are your
co-workers concerned about?

-- 
Best regards,
Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct  6 15:56:14 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Oct 2021 06:56:14 -0700
Subject: [R] (no subject)
In-Reply-To: <20211006125303.2d294a92@Tarkus>
References: <MWHPR12MB1790809FDFA7B79A5B019569ECAF9@MWHPR12MB1790.namprd12.prod.outlook.com>
 <20211006125303.2d294a92@Tarkus>
Message-ID: <CAGxFJbQG=MrwZYAHd5XkRCEBq0isrVXRj6FDo44zoNFyPGp5qw@mail.gmail.com>

Perhaps it's R packages and the security policies -- checks for malicious
software, etc. -- of the repositories on which they reside that Thomas
should be concerned with. R, itself, is fine(checksums are provided), but,
as you say, can be programmed to do anything. So R packages can certainly
do damage. For CRAN, at least, I believe it's download at your own risk.
Presumably, virus checking capabilities at the local level could check all
such downloads, as per usual.

Correction and clarification of any of the above welcome of course.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Oct 6, 2021 at 2:53 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Tue, 5 Oct 2021 22:20:33 +0000
> Thomas Subia <thomas.subia at fmindustries.com> wrote:
>
> > Some co-workers are wondering about how secure R software is.
>
> I'm afraid that this question is too hard to answer without their
> threat model. Secure against what, specifically?
>
> > Is there any documentation on this which I can forward to them?
>
> Well, R is a programming language. It's Turing-complete (see halting
> problem), will happily run machine code from shared objects (see
> dyn.load, .C, .Call), and install.packages() is there to download
> third-party code from the Internet. But that's the case with all
> programming languages I know that are used for statistics, which aren't
> supposed to run untrusted code.
>
> Maybe you're concerned about data input/output instead. Functions are
> first-class objects, so it's possible to save and load them from data
> files. Not sure if there's a way to run code on data load, but you can
> do it on print() (e.g. print.nls(x) calling x$m$getAllPars()), so don't
> load()/readRDS() untrusted data files. There are known bugs in the
> deserialiser, too: https://bugs.r-project.org/show_bug.cgi?id=16034
>
> Don't know if it's documented anywhere, though. What are your
> co-workers concerned about?
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Wed Oct  6 18:23:15 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed,  6 Oct 2021 16:23:15 +0000
Subject: [R] RSQLite slowness
Message-ID: <YV3Nc2Be5rl6EzwD@posteo.no>

Dear r-help readers,

why is it so much slower to query an 
sqlite database using RSQlite ?from the 
outside? using param like 

	statement <-
	 "SELECT * FROM gene2refseq
	  LEFT JOIN gene_info ON
	    gene_info.GeneID = gene2refseq.GeneID
	  WHERE gene2refseq.`RNA_nucleotide_accession.version` 
	    LIKE ?"
	db <- "gene_info.sqlite"
	conn <- DBI::dbConnect(RSQLite::SQLite(), db)
	x1 <- DBI::dbGetQuery(conn=conn, 
	  statement=statement, 
	  param=list(H?kan20210914$RNANucleotideAccession))

compared to querying ?from the inside? 
of sqlite, by writing your search terms 
as a table first, and then calling it 

	statement <- 
	 "SELECT * FROM H
	  LEFT JOIN gene2refseq R ON
	    R.`RNA_nucleotide_accession.version` 
	    LIKE '%' || H.RNANucleotideAccession || '%'
	  LEFT JOIN gene_info I ON I.GeneID = R.GeneID"
	DBI::dbWriteTable(conn, "H", H?kan20210914)
	x2 <- DBI::dbGetQuery(conn=conn, statement=statement)
	DBI::dbDisconnect(conn)

On my system (E5-2603 v4), the first 
query took more than an hour, while the 
second took only a few minutes ...  

Do you guys know of any faster (but also 
nice) way to dig around in very large 
tsv files like 
https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2refseq.gz 
and 
https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene_info.gz 
?

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211006/671429f1/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct  6 19:22:25 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Oct 2021 10:22:25 -0700
Subject: [R] RSQLite slowness
In-Reply-To: <YV3Nc2Be5rl6EzwD@posteo.no>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
Message-ID: <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>

Generally, such gene-related questions are better asked on Bioconductor
than here. They also might know of more efficient, purpose built tools for
your efforts there. No guarantees, of course, and you might get a helpful
response here. But if not ...

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Oct 6, 2021 at 9:23 AM Rasmus Liland <jral at posteo.no> wrote:

> Dear r-help readers,
>
> why is it so much slower to query an
> sqlite database using RSQlite ?from the
> outside? using param like
>
>         statement <-
>          "SELECT * FROM gene2refseq
>           LEFT JOIN gene_info ON
>             gene_info.GeneID = gene2refseq.GeneID
>           WHERE gene2refseq.`RNA_nucleotide_accession.version`
>             LIKE ?"
>         db <- "gene_info.sqlite"
>         conn <- DBI::dbConnect(RSQLite::SQLite(), db)
>         x1 <- DBI::dbGetQuery(conn=conn,
>           statement=statement,
>           param=list(H?kan20210914$RNANucleotideAccession))
>
> compared to querying ?from the inside?
> of sqlite, by writing your search terms
> as a table first, and then calling it
>
>         statement <-
>          "SELECT * FROM H
>           LEFT JOIN gene2refseq R ON
>             R.`RNA_nucleotide_accession.version`
>             LIKE '%' || H.RNANucleotideAccession || '%'
>           LEFT JOIN gene_info I ON I.GeneID = R.GeneID"
>         DBI::dbWriteTable(conn, "H", H?kan20210914)
>         x2 <- DBI::dbGetQuery(conn=conn, statement=statement)
>         DBI::dbDisconnect(conn)
>
> On my system (E5-2603 v4), the first
> query took more than an hour, while the
> second took only a few minutes ...
>
> Do you guys know of any faster (but also
> nice) way to dig around in very large
> tsv files like
> https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2refseq.gz
> and
> https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene_info.gz
> ?
>
> Best,
> Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @nne@z@ch@z@ch @end|ng |rom gm@||@com  Wed Oct  6 19:30:49 2021
From: @nne@z@ch@z@ch @end|ng |rom gm@||@com (Anne Zach)
Date: Wed, 6 Oct 2021 10:30:49 -0700
Subject: [R] Rename variables starting with digits
In-Reply-To: <CA+8X3fV2DFxug5hr0M=xnKxfFD3y8R2ZUPx68QWa7mKV0Ah-0g@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
 <CA+8X3fV2DFxug5hr0M=xnKxfFD3y8R2ZUPx68QWa7mKV0Ah-0g@mail.gmail.com>
Message-ID: <CACt1pfo0_XNR+u61_W8_YjSVGAWm+35TxO=rzjXqVat29q=Tgg@mail.gmail.com>

Hello,

Thank you for your help, I really appreciate it, I was able to solve the
problem!

Here is a part of my dataframe (just in case...):

> dput( head( behavioral_df) )

structure(list(ID = c(1, 2, 3, 4, 5, 6), DOB = c("9/53/1959",

"4/8/1953", "2/21/1961", "10/11/1948", "9/4/1962", "8/22/1953"

), startpoint = c(2.33, 2.44, 1.57, 3.1, 2.78, 1.89), endpoint = c(3.5,

4, 2.4, 4.02, 3.98, 2.1), `1_t1_start` = c(1, 1, 1, 1, 1, 1),

    `1_T1` = c(4, 7, 2, 3, 3, 5), `2_T2_start` = c(2.67, 3.3,

    2.45, 2.2, 1.9, 2.6), `2_T2` = c(5, 5, 6, 4, 5, 3), `3_T3_start` =
c(4.76,

    5.1, 3.87, 3.61, 2.83, 3.7), `3_T3` = c(7, 3, 4, 2, 5, 3),

    `4_T4_start` = c(6.09, 6.99, 5.21, 5.19, 5.02, 6.34), `4_T4` = c(4,

    5, 5, 4, 3, 6)), row.names = c(NA, -6L), class = c("tbl_df",
"tbl", "data.frame"))

Also, I checked my options and I have my email set to plain text...

Best,
Anne



On Tue, Oct 5, 2021 at 3:12 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Anne,
> As mentioned above, you may have to do nothing. Here is an example
> that might clarify that:
>
> azdat<-read.table(text="subject 1 2 3
> 1 10 20 30
> 2 11 22 33",
> header=TRUE,stringsAsFactors=FALSE)
> azdat
>  subject X1 X2 X3
> 1       1 10 20 30
> 2       2 11 22 33
>
> As you can see, R simply prepends an "X" to numeric names. If you
> really want a "v":
>
> names(azdat)<-gsub("X","v",names(azdat))
>
> Jim
> Always happy to help an ANZAC (bad joke)
>
> On Wed, Oct 6, 2021 at 3:15 AM Anne Zach <anne.zach.zach at gmail.com> wrote:
> >
> > Dear R users,
> >
> > I have a dataframe that contains several variables, among which 105
> > correspond to scores on certain trials. Unfortunately, when I imported
> this
> > dataframe into R, I realised that the variable names corresponding to
> each
> > trial begin with digits, which violates R naming conventions.
> >
> > I am trying to relabel these variables by adding a 'v' as a prefix to
> each
> > of them, I'd like to use tidyverse, but I am struggling with this process
> > of renaming. When I run this chunk of code, no error occurs but my
> > variables are not renamed. I'm fairly new to R and I can't understand
> what
> > I'm doing wrong.
> >
> > ```{r}
> >
> > behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
> > starts_with('^\\d'))
> >
> > ```
> >
> > I appreciate if you can help.
> >
> > Best,
> > Anne
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From toro @end|ng |rom |ett|@c|@com  Wed Oct  6 20:31:51 2021
From: toro @end|ng |rom |ett|@c|@com (Gabriel Toro)
Date: Wed, 6 Oct 2021 18:31:51 +0000
Subject: [R] Strange behavior of 2-d array within function
Message-ID: <DM6PR16MB3529BA05ABE89FCDCA0755D5AAB09@DM6PR16MB3529.namprd16.prod.outlook.com>

Hi,

I have a function, which defines an array of dimensions 5000 by 60, calculates the values within that array and then returns the array on exit.

I get an error: Error in my_simulated[ir, 1:it] : incorrect number of dimensions

For some strange reason, the array is somehow being changed from
       mode "numeric" and attributes $dim=6000 by 50
       to
       mode "list" and attributes NULL

This change occurs at more or less random iterations within a loop (all within the same function call). I am not explicitly manipulating the mode or attributes of the array after it is created.

I would appreciate any suggestions on what may be causing this problem. I have stared at the code for a long time, run the debugger, etc.

Thanks,

Gabriel

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Wed Oct  6 20:49:55 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed,  6 Oct 2021 18:49:55 +0000
Subject: [R] RSQLite slowness
In-Reply-To: <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
Message-ID: <YV3v0y6SEJdLyrOb@posteo.no>

Thank you Bert, I set up a new thread on 
BioStars [1].  So far, I'm a bit 
unfamilliar with Bioconductor (but will 
hopefully attend a course about it in 
November, which I'm kinda hyped about), 
other than installing and updating R 
packages using BiocManager ....  Did you 
think of something else than 
BioStars.org when saying ?Bioconductor??

The question could be viewed as gene 
related, but I think it is really about 
how can one easier than with sqlite 
handle large tsv files, and why is that 
parser thing so slow ...  I think this 
is more like a core R thing than gene 
related question ...  

[1] https://www.biostars.org/p/9492486/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211006/659983b5/attachment.sig>

From mtmorg@n@b|oc @end|ng |rom gm@||@com  Wed Oct  6 21:02:12 2021
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Wed, 6 Oct 2021 19:02:12 +0000
Subject: [R] RSQLite slowness
In-Reply-To: <YV3v0y6SEJdLyrOb@posteo.no>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
 <YV3v0y6SEJdLyrOb@posteo.no>
Message-ID: <BN8PR04MB6241F386D4924EB76C7A372CF9B09@BN8PR04MB6241.namprd04.prod.outlook.com>

https://support.bioconductor.org and the community slack (sign up at https://bioc-community.herokuapp.com/ ) as well as the general site https://bioconductor.org . Actually your question sounds like a SQLite question ? JOIN a table, versus parameterized query. One could perhaps construct the relevant example at the sqlite command line?

Martin Morgan

On 10/6/21, 2:50 PM, "R-help" <r-help-bounces at r-project.org> wrote:
Thank you Bert, I set up a new thread on
BioStars [1].  So far, I'm a bit
unfamilliar with Bioconductor (but will
hopefully attend a course about it in
November, which I'm kinda hyped about),
other than installing and updating R
packages using BiocManager ....  Did you
think of something else than
BioStars.org when saying ?Bioconductor??

The question could be viewed as gene
related, but I think it is really about
how can one easier than with sqlite
handle large tsv files, and why is that
parser thing so slow ...  I think this
is more like a core R thing than gene
related question ...

[1] https://www.biostars.org/p/9492486/



	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Oct  6 21:11:00 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 06 Oct 2021 12:11:00 -0700
Subject: [R] RSQLite slowness
In-Reply-To: <YV3v0y6SEJdLyrOb@posteo.no>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
 <YV3v0y6SEJdLyrOb@posteo.no>
Message-ID: <08BBFB7E-00CE-41A0-A4F4-7D4DE07C7757@dcn.davis.ca.us>

Since the sqlite package is contributed, it is NOT related to "core R", and is in fact technically off-topic on this list.

FWIW all SQL implementations work better with indexes, but AFAIK the R data frame support does nothing with indexes. This may be related to your question, or not. I am not a regular sqlite user.

As for fast reading of tsv files, I think arrow, readr, and data.table packages all offer high-performance import functions that could be relevant.

On October 6, 2021 11:49:55 AM PDT, Rasmus Liland <jral at posteo.no> wrote:
>Thank you Bert, I set up a new thread on 
>BioStars [1].  So far, I'm a bit 
>unfamilliar with Bioconductor (but will 
>hopefully attend a course about it in 
>November, which I'm kinda hyped about), 
>other than installing and updating R 
>packages using BiocManager ....  Did you 
>think of something else than 
>BioStars.org when saying ?Bioconductor??
>
>The question could be viewed as gene 
>related, but I think it is really about 
>how can one easier than with sqlite 
>handle large tsv files, and why is that 
>parser thing so slow ...  I think this 
>is more like a core R thing than gene 
>related question ...  
>
>[1] https://www.biostars.org/p/9492486/

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Oct  6 21:15:10 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 06 Oct 2021 12:15:10 -0700
Subject: [R] Rename variables starting with digits
In-Reply-To: <CACt1pfo0_XNR+u61_W8_YjSVGAWm+35TxO=rzjXqVat29q=Tgg@mail.gmail.com>
References: <CACt1pfrz-L8d1GXa2uPKaWjQaB+ar2t0V=X33PafGzR-C3osOw@mail.gmail.com>
 <CA+8X3fV2DFxug5hr0M=xnKxfFD3y8R2ZUPx68QWa7mKV0Ah-0g@mail.gmail.com>
 <CACt1pfo0_XNR+u61_W8_YjSVGAWm+35TxO=rzjXqVat29q=Tgg@mail.gmail.com>
Message-ID: <BB42515D-565D-4D72-A94F-1600C89104CE@dcn.davis.ca.us>

>Also, I checked my options and I have my email set to plain text...

The warning inserted by the mailing list at the bottom of your message below

>	[[alternative HTML version deleted]]

indicates that you may still need to understand your mail client better.

On October 6, 2021 10:30:49 AM PDT, Anne Zach <anne.zach.zach at gmail.com> wrote:
>Hello,
>
>Thank you for your help, I really appreciate it, I was able to solve the
>problem!
>
>Here is a part of my dataframe (just in case...):
>
>> dput( head( behavioral_df) )
>
>structure(list(ID = c(1, 2, 3, 4, 5, 6), DOB = c("9/53/1959",
>
>"4/8/1953", "2/21/1961", "10/11/1948", "9/4/1962", "8/22/1953"
>
>), startpoint = c(2.33, 2.44, 1.57, 3.1, 2.78, 1.89), endpoint = c(3.5,
>
>4, 2.4, 4.02, 3.98, 2.1), `1_t1_start` = c(1, 1, 1, 1, 1, 1),
>
>    `1_T1` = c(4, 7, 2, 3, 3, 5), `2_T2_start` = c(2.67, 3.3,
>
>    2.45, 2.2, 1.9, 2.6), `2_T2` = c(5, 5, 6, 4, 5, 3), `3_T3_start` =
>c(4.76,
>
>    5.1, 3.87, 3.61, 2.83, 3.7), `3_T3` = c(7, 3, 4, 2, 5, 3),
>
>    `4_T4_start` = c(6.09, 6.99, 5.21, 5.19, 5.02, 6.34), `4_T4` = c(4,
>
>    5, 5, 4, 3, 6)), row.names = c(NA, -6L), class = c("tbl_df",
>"tbl", "data.frame"))
>
>Also, I checked my options and I have my email set to plain text...
>
>Best,
>Anne
>
>
>
>On Tue, Oct 5, 2021 at 3:12 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Anne,
>> As mentioned above, you may have to do nothing. Here is an example
>> that might clarify that:
>>
>> azdat<-read.table(text="subject 1 2 3
>> 1 10 20 30
>> 2 11 22 33",
>> header=TRUE,stringsAsFactors=FALSE)
>> azdat
>>  subject X1 X2 X3
>> 1       1 10 20 30
>> 2       2 11 22 33
>>
>> As you can see, R simply prepends an "X" to numeric names. If you
>> really want a "v":
>>
>> names(azdat)<-gsub("X","v",names(azdat))
>>
>> Jim
>> Always happy to help an ANZAC (bad joke)
>>
>> On Wed, Oct 6, 2021 at 3:15 AM Anne Zach <anne.zach.zach at gmail.com> wrote:
>> >
>> > Dear R users,
>> >
>> > I have a dataframe that contains several variables, among which 105
>> > correspond to scores on certain trials. Unfortunately, when I imported
>> this
>> > dataframe into R, I realised that the variable names corresponding to
>> each
>> > trial begin with digits, which violates R naming conventions.
>> >
>> > I am trying to relabel these variables by adding a 'v' as a prefix to
>> each
>> > of them, I'd like to use tidyverse, but I am struggling with this process
>> > of renaming. When I run this chunk of code, no error occurs but my
>> > variables are not renamed. I'm fairly new to R and I can't understand
>> what
>> > I'm doing wrong.
>> >
>> > ```{r}
>> >
>> > behavioral_df <- behavioral_df %>% rename_with(.fn =  ~paste0("v"),
>> > starts_with('^\\d'))
>> >
>> > ```
>> >
>> > I appreciate if you can help.
>> >
>> > Best,
>> > Anne
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct  6 21:39:13 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 6 Oct 2021 12:39:13 -0700
Subject: [R] Strange behavior of 2-d array within function
In-Reply-To: <DM6PR16MB3529BA05ABE89FCDCA0755D5AAB09@DM6PR16MB3529.namprd16.prod.outlook.com>
References: <DM6PR16MB3529BA05ABE89FCDCA0755D5AAB09@DM6PR16MB3529.namprd16.prod.outlook.com>
Message-ID: <CAGxFJbTkBHwPieAuaKtUXE3aDKx9eUCSSGLtb+K7D5_GX4biZw@mail.gmail.com>

Likely impossible to answer without seeing your  code.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Oct 6, 2021 at 11:33 AM Gabriel Toro <toro at lettisci.com> wrote:

> Hi,
>
> I have a function, which defines an array of dimensions 5000 by 60,
> calculates the values within that array and then returns the array on exit.
>
> I get an error: Error in my_simulated[ir, 1:it] : incorrect number of
> dimensions
>
> For some strange reason, the array is somehow being changed from
>        mode "numeric" and attributes $dim=6000 by 50
>        to
>        mode "list" and attributes NULL
>
> This change occurs at more or less random iterations within a loop (all
> within the same function call). I am not explicitly manipulating the mode
> or attributes of the array after it is created.
>
> I would appreciate any suggestions on what may be causing this problem. I
> have stared at the code for a long time, run the debugger, etc.
>
> Thanks,
>
> Gabriel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Oct  7 10:36:00 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 7 Oct 2021 08:36:00 +0000
Subject: [R] Strange behavior of 2-d array within function
In-Reply-To: <DM6PR16MB3529BA05ABE89FCDCA0755D5AAB09@DM6PR16MB3529.namprd16.prod.outlook.com>
References: <DM6PR16MB3529BA05ABE89FCDCA0755D5AAB09@DM6PR16MB3529.namprd16.prod.outlook.com>
Message-ID: <ad95dc05551f45e8908eefa60f60754f@SRVEXCHCM1302.precheza.cz>

Hi

I would print/save iteration number to see at what time this occured and
probably traceback() could give you some hint.
Alternatively you could make a function from your code see ?function and use
debug to trace the error.

Without some working example it is impossible to see where is the problem.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Gabriel Toro
> Sent: Wednesday, October 6, 2021 8:32 PM
> To: r-help at r-project.org
> Subject: [R] Strange behavior of 2-d array within function
> 
> Hi,
> 
> I have a function, which defines an array of dimensions 5000 by 60,
calculates
> the values within that array and then returns the array on exit.
> 
> I get an error: Error in my_simulated[ir, 1:it] : incorrect number of
dimensions
> 
> For some strange reason, the array is somehow being changed from
>        mode "numeric" and attributes $dim=6000 by 50
>        to
>        mode "list" and attributes NULL
> 
> This change occurs at more or less random iterations within a loop (all
within
> the same function call). I am not explicitly manipulating the mode or
> attributes of the array after it is created.
> 
> I would appreciate any suggestions on what may be causing this problem. I
> have stared at the code for a long time, run the debugger, etc.
> 
> Thanks,
> 
> Gabriel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From kry|ov@r00t @end|ng |rom gm@||@com  Thu Oct  7 10:58:09 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 7 Oct 2021 11:58:09 +0300
Subject: [R] RSQLite slowness
In-Reply-To: <YV3Nc2Be5rl6EzwD@posteo.no>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
Message-ID: <20211007115809.2e83938e@arachnoid>

On Wed,  6 Oct 2021 16:23:15 +0000
Rasmus Liland <jral at posteo.no> wrote:

> 	 "SELECT * FROM gene2refseq
> 	  LEFT JOIN gene_info ON
> 	    gene_info.GeneID = gene2refseq.GeneID
> 	  WHERE gene2refseq.`RNA_nucleotide_accession.version` 
> 	    LIKE ?"

<...>

> 	x1 <- DBI::dbGetQuery(conn=conn, 
> 	  statement=statement, 
> 	  param=list(H?kan20210914$RNANucleotideAccession))

I think that the problem here is that you pass a vector as a bound
parameter to LIKE, when parameter placeholders usually expect a scalar.
DBI transparently handles this:

>> The elements of the `params` argument do not need to be scalars,
>> vectors of arbitrary length (including length 0) are supported.  For
>> queries, calling dbFetch() binding such parameters returns
>> concatenated results, equivalent to binding and fetching for each
>> set of values and connecting via rbind().

I think this means that DBI runs a SELECT for each value in
H?kan20210914$RNANucleotideAccession, which is understandably slower
than a single query. Unfortunately, it's hard to pass vectors of values
to queries with bound parameters; the SQL engines I know don't have a
syntax for "WHERE param IN (:multi_placeholder:)". SQLite comes with
carray [1], but I don't know whether it's exposed by RSQLite (could be
hard to do in a pointer-safe way), and you're already aware of the
traditional way of doing that: create a temporary table, populate it
and JOIN with the rest of the query.

-- 
Best regards,
Ivan

[1] https://www.sqlite.org/carray.html


From mon|c@p@|@|ovejoy @end|ng |rom gm@||@com  Thu Oct  7 15:44:27 2021
From: mon|c@p@|@|ovejoy @end|ng |rom gm@||@com (Monica Palaseanu-Lovejoy)
Date: Thu, 7 Oct 2021 09:44:27 -0400
Subject: [R] Tidygrraph example not working
Message-ID: <CABnpDg0UJUzF+mCcR5QXr_cj5UgDJuF96UTj-Z75k+jurWakSg@mail.gmail.com>

Hi,

I am trying to learn more about tidygraph, so i am following this blog:
https://www.data-imaginist.com/2017/introducing-tidygraph/

Few months ago the examples in the blog worked very well, but today they do
not.

I just installed R x64 4.1.1, so i should be up and running with the latest
on a Windows machine.

From the blog:

iris_clust <- hclust(dist(iris[1:4]))
iris_tree <- as_tbl_graph(iris_clust)

iris_tree <- iris_tree %>%
    activate(nodes) %>%
    mutate(Species = ifelse(leaf, as.character(iris$Species)[label], NA)) %>%
    activate(edges) %>%
    mutate(to_setose = .N()$Species[to] == 'setosa')
iris_tree#> # A tbl_graph: 299 nodes and 298 edges#> ##> # A rooted
tree#> ##> # Edge Data: 298 x 3 (active)#>    from    to to_setose#>
<int> <int>     <lgl>#> 1     3     1      TRUE#> 2     3     2
TRUE#> 3     7     5      TRUE#> 4     7     6      TRUE#> 5     8
4      TRUE#> 6     8     7        NA#> # ... with 292 more rows#> ##>
# Node Data: 299 x 5#>      height  leaf  label members Species#>
 <dbl> <lgl> <fctr>   <int>   <chr>#> 1 0.0000000  TRUE    108       1
 setosa#> 2 0.0000000  TRUE    131       1  setosa#> 3 0.2645751 FALSE
             2    <NA>#> # ... with 296 more rows
Now from my R session:

library(tidygraph)

Attaching package: ?tidygraph?

The following object is masked from ?package:stats?:

    filter
iris_clust <- hclust(dist(iris[1:4]))
iris_tree <- as_tbl_graph(iris_clust)

iris_tree <- iris_tree %>%
     activate(nodes) %>%
     mutate(Species = ifelse(leaf, as.character(iris$Species)[label], NA)) %>%
     activate(edges) %>%
     mutate(to_setose = .N()$Species[to] == "setosa")
 iris_tree
# A tbl_graph: 299 nodes and 298 edges
#
# A rooted tree
#
# Edge Data: 298 x 3 (active)
   from    to to_setose
  <int> <int> <lgl>
1     3     1 NA
2     3     2 NA
3     7     5 NA
4     7     6 NA
5     8     4 NA
6     8     7 NA
# ... with 292 more rows
#
# Node Data: 299 x 5
  height leaf  label members Species
   <dbl> <lgl> <chr>   <int> <chr>
1  0     TRUE  "108"       1 <NA>
2  0     TRUE  "131"       1 <NA>
3  0.265 FALSE ""          2 <NA>
# ... with 296 more rows

As you see the attributes from the Species column are not added to the
table, and all are NA.

It is not clear to me where i made my mistake. Any help is very much
appreciated.

Thanks,

Monica

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Oct  7 15:47:33 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 7 Oct 2021 13:47:33 +0000
Subject: [R] adding results to plot
In-Reply-To: <b354f020-4f18-d696-74d5-43a787996edf@sapo.pt>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <b354f020-4f18-d696-74d5-43a787996edf@sapo.pt>
Message-ID: <9401ae8901ae4cf9adeed4d122374a91@SRVEXCHCM1302.precheza.cz>

Hallo Rui.

I finally tested your function and it seems to me that it should propagate
to the core R or at least to the stats package.

Although it is a bit overkill for my purpose, its use is straightforward and
simple. I checked it for several *test functions and did not find any
problem.

Thanks and best regards.

Petr

> -----Original Message-----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, September 17, 2021 9:56 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help <r-help at r-project.org>
> Subject: Re: [R] adding results to plot
> 
> Hello,
> 
> *.test functions in base R return a list of class "htest", with its own
> print method.
> The method text.htest for objects of class "htest" below is a hack. I
> adapted the formating part of the code of print.htest to plot text().
> I find it maybe too complicated but it seems to work.
> 
> Warning: Not debugged at all.
> 
> 
> 
> text.htest <- function (ht, x, y = NULL, digits = getOption("digits"),
>                          prefix = "", adj = NULL, ...) {
>    out <- list()
>    i_out <- 1L
>    out[[i_out]] <- paste(strwrap(ht$method, prefix = prefix), sep = "\n")
>    i_out <- i_out + 1L
>    out[[i_out]] <- paste0("data:  ", ht$data.name)
> 
>    stat_line <- NULL
>    i_stat_line <- 0L
>    if (!is.null(ht$statistic)) {
>      i_stat_line <- i_stat_line + 1L
>      stat_line[[i_stat_line]] <- paste(names(ht$statistic), "=",
>                                        format(ht$statistic, digits =
> max(1L, digits - 2L)))
>    }
>    if (!is.null(ht$parameter)) {
>      i_stat_line <- i_stat_line + 1L
>      stat_line[[i_stat_line]] <- paste(names(ht$parameter), "=",
>                                        format(ht$parameter, digits =
> max(1L, digits - 2L)))
>    }
>    if (!is.null(ht$p.value)) {
>      fp <- format.pval(ht$p.value, digits = max(1L, digits - 3L))
>      i_stat_line <- i_stat_line + 1L
>      stat_line[[i_stat_line]] <- paste("p-value",
>                                        if (startsWith(fp, "<")) fp else
> paste("=", fp))
>    }
>    if(!is.null(stat_line)){
>      i_out <- i_out + 1L
>      #out[[i_out]] <- strwrap(paste(stat_line, collapse = ", "))
>      out[[i_out]] <- paste(stat_line, collapse = ", ")
>    }
>    if (!is.null(ht$alternative)) {
>      alt <- NULL
>      i_alt <- 1L
>      alt[[i_alt]] <- "alternative hypothesis: "
>      if (!is.null(ht$null.value)) {
>        if (length(ht$null.value) == 1L) {
>          alt.char <- switch(ht$alternative, two.sided = "not equal to",
>                             less = "less than", greater = "greater than")
>          i_alt <- i_alt + 1L
>          alt[[i_alt]] <- paste0("true ", names(ht$null.value), " is ",
> alt.char,
>                                 " ", ht$null.value)
>        }
>        else {
>          i_alt <- i_alt + 1L
>          alt[[i_alt]] <- paste0(ht$alternative, "\nnull values:\n")
>        }
>      }
>      else {
>        i_alt <- i_alt + 1L
>        alt[[i_alt]] <- ht$alternative
>      }
>      i_out <- i_out + 1L
>      out[[i_out]] <- paste(alt, collapse = " ")
>    }
>    if (!is.null(ht$conf.int)) {
>      i_out <- i_out + 1L
>      out[[i_out]] <- paste0(format(100 * attr(ht$conf.int, "conf.level")),
>                             " percent confidence interval:\n", " ",
>                             paste(format(ht$conf.int[1:2], digits =
> digits), collapse = " "))
>    }
>    if (!is.null(ht$estimate)) {
>      i_out <- i_out + 1L
>      out[[i_out]] <- paste("sample estimates:", round(ht$estimate,
> digits = digits), sep = "\n")
>    }
>    i_out <- i_out + 1L
>    out[[i_out]] <- "\n"
>    names(out)[i_out] <- "sep"
>    out <- do.call(paste, out)
>    if(is.null(adj)) adj <- 0L
>    text(x, y, labels = out, adj = adj, ...)
>    invisible(out)
> }
> 
> 
> res <- shapiro.test(rnorm(100))
> plot(1,1, ylim = c(0, length(res) + 1L))
> text(res, 0.6, length(res) - 1)
> res
> 
> res2 <- t.test(rnorm(100))
> plot(1,1, ylim = c(0, length(res2) + 1L))
> text(res2, 0.6, length(res2) - 1L)
> res2
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> ?s 15:12 de 16/09/21, PIKAL Petr escreveu:
> > Dear all
> >
> > I know I have seen the answer somewhere but I am not able to find it.
> Please
> > help
> >
> >> plot(1,1)
> >> res <- shapiro.test(rnorm(100))
> >> res
> >
> >          Shapiro-Wilk normality test
> >
> > data:  rnorm(100)
> > W = 0.98861, p-value = 0.5544
> >
> > I would like to add whole res object to the plot.
> >
> > I can do it one by one
> >> text(locator(1), res$method)
> >> text(locator(1), as.character(res$p.value))
> > ...
> > But it is quite inconvenient
> >
> > I could find some way in ggplot world but not in plain plot world.
> >
> > Best regards
> > Petr
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >

From jr@| @end|ng |rom po@teo@no  Thu Oct  7 16:27:40 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu,  7 Oct 2021 14:27:40 +0000
Subject: [R] RSQLite slowness
In-Reply-To: <20211007115809.2e83938e@arachnoid>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <20211007115809.2e83938e@arachnoid>
Message-ID: <YV8D3Ibp8bDtd3iR@posteo.no>

Dear Ivan,

Thanks for that explaination!  I think 
it explains the slowness clearly.

It is possible to use carray is in Rust 
[1] so it might be available in R in the 
future(?)  I'll look into rusqlite some 
time at least.

sqlite is supposed to be one of the 
fastest sql implementations.  Realm [2] 
might be faster, but I don't know how to 
use it in R so ...  

I thought someone might suggest Redis, 
but I think it is way slower.  

sqlite with indexes and the traditional 
way of doing that by writing in a 
temporary table might just be it ... 

Best,
Rasmus

[1] https://docs.rs/rusqlite/0.24.2/rusqlite/vtab/array/index.html
[2] https://en.wikipedia.org/wiki/Realm_(database)
[3] https://en.wikipedia.org/wiki/Redis

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211007/481d4bf3/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Thu Oct  7 16:27:29 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu,  7 Oct 2021 14:27:29 +0000
Subject: [R] RSQLite slowness
In-Reply-To: <08BBFB7E-00CE-41A0-A4F4-7D4DE07C7757@dcn.davis.ca.us>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
 <YV3v0y6SEJdLyrOb@posteo.no>
 <08BBFB7E-00CE-41A0-A4F4-7D4DE07C7757@dcn.davis.ca.us>
Message-ID: <YV8D0daIjI1+dYRt@posteo.no>

On 2021-10-06 12:11 -0700, Jeff Newmiller wrote:
> FWIW all SQL implementations work 
> better with indexes

An index seems to be a good way to 
improve sql performance, I'll look into 
it.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211007/866e206c/attachment.sig>

From kev|n@thorpe @end|ng |rom utoronto@c@  Thu Oct  7 16:56:05 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Thu, 7 Oct 2021 14:56:05 +0000
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
 <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
Message-ID: <851E37B0-DF67-422E-9D27-789F8CAE30CC@utoronto.ca>

I thought I would close the loop on this. It was really weird and I don?t understand everything that went on.

First, it was indeed the case that the main library was not writeable so packages were being installed in a user library.

Here is where it gets confusing to me. Both library paths did appear in .libPaths(). I could not figure out where that was being set since there was no user .Rprofile and Rprofile.site was not modified. To start over I got the user to delete the local library and started R as an administrator and forced installation in the main library with the lib argument. However, even with dependencies=TRUE in install.packages() everything was not getting installed. I then had the user start RStudio as an admin and use the install packages from the menu, again specifying the main library and asking for dependencies. When this was done, many additional packages were then installed that were not installed when running the native R application. Eventually, after that, tidyverse loaded (I realize it is a wrapper to load a bunch of other packages). I also had the user install rms (which we use) and again, various bits did not get installed and had to be manually requested (I don?t remember which ones).

Anyway, in the end we got his system functioning. I realize that running as admin to install packages is probably not best practice, but it was the only way I saw to get things working. I _think_ some of the problems were because his home directory is synced with OneDrive and the user library path was to a OneDrive folder.

I am often shocked by the difficulties students have installing packages. They manage to get errors that I have never seen in all my user of using R. On a Win10 box of my own, I installed R and packages with no difficulties so, naturally am surprised when things go this haywire with an installation.

That?s my story. Hope it was entertaining. :-)

Kevin


> On Sep 24, 2021, at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> It is worth checking that the library where things were most recently installed is the first place R looks, i.e. the first entry in .libPaths().  Often R is installed by an administrator, and users can't write to the main library, so when they install packages they go somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't see the new installs.
> 
> Duncan Murdoch
> 
> On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
>> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
>>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>> 
>>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>> 
>>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>> 
>>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>> 
>>>>> library("tidyverse")
>>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>> 
>>>> Here is the sessionInfo()
>>>> 
>>>>> sessionInfo()
>>>> R version 4.1.1 (2021-08-10)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> Running under: Windows 10 x64 (build 19042)
>>>> 
>>>> Matrix products: default
>>>> 
>>>> locale:
>>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=English_Canada.1252
>>>> 
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1
>>>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11
>>>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0
>>>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1
>>>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1
>>>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>>>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>> 
>>> 
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
> 

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael?s Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From jr@| @end|ng |rom po@teo@no  Thu Oct  7 16:27:19 2021
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu,  7 Oct 2021 14:27:19 +0000
Subject: [R] RSQLite slowness
In-Reply-To: <BN8PR04MB6241F386D4924EB76C7A372CF9B09@BN8PR04MB6241.namprd04.prod.outlook.com>
References: <YV3Nc2Be5rl6EzwD@posteo.no>
 <CAGxFJbRT6jPfCKvRuys9Z0ScZqvAO-xB7G9_Lk1aG9504SqfBg@mail.gmail.com>
 <YV3v0y6SEJdLyrOb@posteo.no>
 <BN8PR04MB6241F386D4924EB76C7A372CF9B09@BN8PR04MB6241.namprd04.prod.outlook.com>
Message-ID: <YV8DxwtCEYuBDcbX@posteo.no>

Dear Martin Morgan,

Thanks for all those links!  Yes, my 
question can be characterized like that 
I think, traditional way writing 
a temporary table into the database and 
left JOINing the others vs. 
parameterized query. 

A relevant example would be to first 
create the database from the compressed 
tsv files:

	for i in gene_info gene2refseq; do
	  wget -c https://ftp.ncbi.nlm.nih.gov/gene/DATA/$i.gz
	  gzip -d $i.gz
	  sqlite3 gene_info.sqlite ".mode tabs" ".import $i $i"
	  rm $i; done

then run this R code:

	H <- data.frame(Group = c(1, 1, 2, 2),
	  NM = c("NM_001267695", "NM_001007636",
	         "NM_001003706", "NM_001353612"))
	conn <- DBI::dbConnect(RSQLite::SQLite(), "gene_info.sqlite")
	DBI::dbWriteTable(conn, "H", H, overwrite=T)
	
	statement.1 <-
	 "SELECT * FROM gene2refseq R
	  LEFT JOIN gene_info I ON I.GeneID = R.GeneID
	  WHERE R.`RNA_nucleotide_accession.version`
	    LIKE '%' || ? || '%'"
	time.1 <- proc.time()
	x1 <- DBI::dbGetQuery(
	  conn=conn,
	  statement=statement.1,
	  param=list(H$NM))
	time.1 <- proc.time() - time.1
	
	statement.2 <-
	 "SELECT * FROM H
	  LEFT JOIN gene2refseq R ON
	    R.`RNA_nucleotide_accession.version`
	    LIKE '%' || H.NM || '%'
	  LEFT JOIN gene_info I ON I.GeneID = R.GeneID"
	time.2 <- proc.time()
	x2 <- DBI::dbGetQuery(
	  conn=conn,
	  statement=statement.2)
	time.2 <- proc.time() - time.2
	
	DBI::dbDisconnect(conn)
	
	saveRDS(object=x1, file="ex1_x1.rds", compress="xz")
	saveRDS(object=x2, file="ex1_x2.rds", compress="xz")
	saveRDS(object=list("Time x1"=list(time.1),
	                    "Time x2"=list(time.2)),
	        file="ex1_t.rds", compress="xz")

I got these timings in the ex1_t.rds 
file:

	$`Time x1`
	   user  system elapsed
	571.731 182.006 772.199
	
	$`Time x2`
	   user  system elapsed
	200.068  90.529 295.086

As you can see, statement.1 takes a lot 
longer to process compared to 
statement.2 ...  When I add the rest of 
the 31 search terms, the difference gets 
a lot bigger like I pointed out 
initially, beyond the full hour vs. only 
a few minutes. 

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211007/c25ba4ab/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Oct  7 17:37:17 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 07 Oct 2021 08:37:17 -0700
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <851E37B0-DF67-422E-9D27-789F8CAE30CC@utoronto.ca>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
 <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
 <851E37B0-DF67-422E-9D27-789F8CAE30CC@utoronto.ca>
Message-ID: <D1F37452-AB58-47F2-90A5-4254DB9D2867@dcn.davis.ca.us>

Sad, more like.

fortunes::fortune(337)

You would have done just as well to delete the user library and let R prompt you to re-create it if things were that bad. Note that the default R configuration always looks first in the user library and only falls back to the system library if the desired package is not found in the user library. In most user-administered R installations you are better off acting as though the system library wasn't there.

On October 7, 2021 7:56:05 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>I thought I would close the loop on this. It was really weird and I don?t understand everything that went on.
>
>First, it was indeed the case that the main library was not writeable so packages were being installed in a user library.
>
>Here is where it gets confusing to me. Both library paths did appear in .libPaths(). I could not figure out where that was being set since there was no user .Rprofile and Rprofile.site was not modified. To start over I got the user to delete the local library and started R as an administrator and forced installation in the main library with the lib argument. However, even with dependencies=TRUE in install.packages() everything was not getting installed. I then had the user start RStudio as an admin and use the install packages from the menu, again specifying the main library and asking for dependencies. When this was done, many additional packages were then installed that were not installed when running the native R application. Eventually, after that, tidyverse loaded (I realize it is a wrapper to load a bunch of other packages). I also had the user install rms (which we use) and again, various bits did not get installed and had to be manually requested (I don?t remember which ones).
>
>Anyway, in the end we got his system functioning. I realize that running as admin to install packages is probably not best practice, but it was the only way I saw to get things working. I _think_ some of the problems were because his home directory is synced with OneDrive and the user library path was to a OneDrive folder.
>
>I am often shocked by the difficulties students have installing packages. They manage to get errors that I have never seen in all my user of using R. On a Win10 box of my own, I installed R and packages with no difficulties so, naturally am surprised when things go this haywire with an installation.
>
>That?s my story. Hope it was entertaining. :-)
>
>Kevin
>
>
>> On Sep 24, 2021, at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> It is worth checking that the library where things were most recently installed is the first place R looks, i.e. the first entry in .libPaths().  Often R is installed by an administrator, and users can't write to the main library, so when they install packages they go somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't see the new installs.
>> 
>> Duncan Murdoch
>> 
>> On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
>>> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
>>>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>> 
>>>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>>> 
>>>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>>> 
>>>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>>> 
>>>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>>> 
>>>>>> library("tidyverse")
>>>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>>> 
>>>>> Here is the sessionInfo()
>>>>> 
>>>>>> sessionInfo()
>>>>> R version 4.1.1 (2021-08-10)
>>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>> Running under: Windows 10 x64 (build 19042)
>>>>> 
>>>>> Matrix products: default
>>>>> 
>>>>> locale:
>>>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>>>>> [5] LC_TIME=English_Canada.1252
>>>>> 
>>>>> attached base packages:
>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>> 
>>>>> loaded via a namespace (and not attached):
>>>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1
>>>>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11
>>>>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0
>>>>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1
>>>>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1
>>>>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>>>>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>>> 
>>>> 
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>> 
>

-- 
Sent from my phone. Please excuse my brevity.


From kev|n@thorpe @end|ng |rom utoronto@c@  Thu Oct  7 17:49:34 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Thu, 7 Oct 2021 15:49:34 +0000
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <D1F37452-AB58-47F2-90A5-4254DB9D2867@dcn.davis.ca.us>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
 <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
 <851E37B0-DF67-422E-9D27-789F8CAE30CC@utoronto.ca>
 <D1F37452-AB58-47F2-90A5-4254DB9D2867@dcn.davis.ca.us>
Message-ID: <5D18BAE5-CD54-4D6A-A5BD-1DEBB6115529@utoronto.ca>

Nice fortune.

In retrospect, maybe it would have worked to re-build the user library. Things were acting so strangely to me I opted for the direct, if more dangerous approach. :-)


> On Oct 7, 2021, at 11:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Sad, more like.
> 
> fortunes::fortune(337)
> 
> You would have done just as well to delete the user library and let R prompt you to re-create it if things were that bad. Note that the default R configuration always looks first in the user library and only falls back to the system library if the desired package is not found in the user library. In most user-administered R installations you are better off acting as though the system library wasn't there.
> 
> On October 7, 2021 7:56:05 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>> I thought I would close the loop on this. It was really weird and I don?t understand everything that went on.
>> 
>> First, it was indeed the case that the main library was not writeable so packages were being installed in a user library.
>> 
>> Here is where it gets confusing to me. Both library paths did appear in .libPaths(). I could not figure out where that was being set since there was no user .Rprofile and Rprofile.site was not modified. To start over I got the user to delete the local library and started R as an administrator and forced installation in the main library with the lib argument. However, even with dependencies=TRUE in install.packages() everything was not getting installed. I then had the user start RStudio as an admin and use the install packages from the menu, again specifying the main library and asking for dependencies. When this was done, many additional packages were then installed that were not installed when running the native R application. Eventually, after that, tidyverse loaded (I realize it is a wrapper to load a bunch of other packages). I also had the user install rms (which we use) and again, various bits did not get installed and had to be manually requested (I don?t remember which ones).
>> 
>> Anyway, in the end we got his system functioning. I realize that running as admin to install packages is probably not best practice, but it was the only way I saw to get things working. I _think_ some of the problems were because his home directory is synced with OneDrive and the user library path was to a OneDrive folder.
>> 
>> I am often shocked by the difficulties students have installing packages. They manage to get errors that I have never seen in all my user of using R. On a Win10 box of my own, I installed R and packages with no difficulties so, naturally am surprised when things go this haywire with an installation.
>> 
>> That?s my story. Hope it was entertaining. :-)
>> 
>> Kevin
>> 
>> 
>>> On Sep 24, 2021, at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> 
>>> It is worth checking that the library where things were most recently installed is the first place R looks, i.e. the first entry in .libPaths().  Often R is installed by an administrator, and users can't write to the main library, so when they install packages they go somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't see the new installs.
>>> 
>>> Duncan Murdoch
>>> 
>>> On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
>>>> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
>>>>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>>> 
>>>>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>>>> 
>>>>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>>>> 
>>>>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>>>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>>>> 
>>>>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>>>> 
>>>>>>> library("tidyverse")
>>>>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>>>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>>>> 
>>>>>> Here is the sessionInfo()
>>>>>> 
>>>>>>> sessionInfo()
>>>>>> R version 4.1.1 (2021-08-10)
>>>>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>>> Running under: Windows 10 x64 (build 19042)
>>>>>> 
>>>>>> Matrix products: default
>>>>>> 
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 LC_MONETARY=English_Canada.1252 LC_NUMERIC=C
>>>>>> [5] LC_TIME=English_Canada.1252
>>>>>> 
>>>>>> attached base packages:
>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>> 
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1
>>>>>> [8] jsonlite_1.7.2 lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11
>>>>>> [15] reprex_2.0.1 DBI_1.1.1 haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0
>>>>>> [22] generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 glue_1.4.2 R6_2.5.1
>>>>>> [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1
>>>>>> [36] modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2
>>>>>> [43] utf8_1.2.2 munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>>>> 
>>>>> 
>>>>> -- 
>>>>> Sent from my phone. Please excuse my brevity.
>>> 
>> 
> 
> -- 
> Sent from my phone. Please excuse my brevity.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael?s Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From M|ke@Conk||n @end|ng |rom g|k@com  Thu Oct  7 17:57:30 2021
From: M|ke@Conk||n @end|ng |rom g|k@com (Conklin, Mike (GfK))
Date: Thu, 7 Oct 2021 15:57:30 +0000
Subject: [R] Unusual Error Loading tidyverse
In-Reply-To: <5D18BAE5-CD54-4D6A-A5BD-1DEBB6115529@utoronto.ca>
References: <1BF57FD6-084F-417A-B427-CA605963FD5D@utoronto.ca>
 <8B47DEAA-AE9E-44C5-9F8D-3D73DAD6ADE9@dcn.davis.ca.us>
 <1AE05F6A-672B-4A8C-8F12-90128F95F6DD@utoronto.ca>
 <94303eba-9239-3d62-bf23-d1c19721a6b2@gmail.com>
 <851E37B0-DF67-422E-9D27-789F8CAE30CC@utoronto.ca>
 <D1F37452-AB58-47F2-90A5-4254DB9D2867@dcn.davis.ca.us>
 <5D18BAE5-CD54-4D6A-A5BD-1DEBB6115529@utoronto.ca>
Message-ID: <CWXP123MB4952B029921E0FFBB7AF9FB399B19@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>

My experience is that the combination of OneDrive and R leads to lack of productivity.

--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
M +1 612 567 8287

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kevin Thorpe
Sent: Thursday, October 7, 2021 10:50 AM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: R Help Mailing List <r-help at r-project.org>
Subject: Re: [R] Unusual Error Loading tidyverse



Nice fortune.

In retrospect, maybe it would have worked to re-build the user library. Things were acting so strangely to me I opted for the direct, if more dangerous approach. :-)


> On Oct 7, 2021, at 11:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Sad, more like.
>
> fortunes::fortune(337)
>
> You would have done just as well to delete the user library and let R prompt you to re-create it if things were that bad. Note that the default R configuration always looks first in the user library and only falls back to the system library if the desired package is not found in the user library. In most user-administered R installations you are better off acting as though the system library wasn't there.
>
> On October 7, 2021 7:56:05 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>> I thought I would close the loop on this. It was really weird and I don?t understand everything that went on.
>>
>> First, it was indeed the case that the main library was not writeable so packages were being installed in a user library.
>>
>> Here is where it gets confusing to me. Both library paths did appear in .libPaths(). I could not figure out where that was being set since there was no user .Rprofile and Rprofile.site was not modified. To start over I got the user to delete the local library and started R as an administrator and forced installation in the main library with the lib argument. However, even with dependencies=TRUE in install.packages() everything was not getting installed. I then had the user start RStudio as an admin and use the install packages from the menu, again specifying the main library and asking for dependencies. When this was done, many additional packages were then installed that were not installed when running the native R application. Eventually, after that, tidyverse loaded (I realize it is a wrapper to load a bunch of other packages). I also had the user install rms (which we use) and again, various bits did not get installed and had to be manually requested (I don?t remember which ones).
>>
>> Anyway, in the end we got his system functioning. I realize that running as admin to install packages is probably not best practice, but it was the only way I saw to get things working. I _think_ some of the problems were because his home directory is synced with OneDrive and the user library path was to a OneDrive folder.
>>
>> I am often shocked by the difficulties students have installing packages. They manage to get errors that I have never seen in all my user of using R. On a Win10 box of my own, I installed R and packages with no difficulties so, naturally am surprised when things go this haywire with an installation.
>>
>> That?s my story. Hope it was entertaining. :-)
>>
>> Kevin
>>
>>
>>> On Sep 24, 2021, at 3:26 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>
>>> It is worth checking that the library where things were most recently installed is the first place R looks, i.e. the first entry in .libPaths().  Often R is installed by an administrator, and users can't write to the main library, so when they install packages they go somewhere else.  If "somewhere else" isn't first in .libPaths(), R won't see the new installs.
>>>
>>> Duncan Murdoch
>>>
>>> On 24/09/2021 2:04 p.m., Kevin Thorpe wrote:
>>>> I did try installing xml2 and it appeared to complete. I will ask him to try again and send me the output.
>>>>> On Sep 24, 2021, at 1:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>
>>>>> Seems like they should install the xml2 package before proceeding to load whatever (tidyverse).
>>>>>
>>>>> This kind of "dependency missing" problem tends to be a recurring problem particularly on Windows but in general when some deeply-embedded dependency fails to load or is removed in preparation for upgrading.
>>>>>
>>>>> On September 24, 2021 10:40:41 AM PDT, Kevin Thorpe <kevin.thorpe at utoronto.ca> wrote:
>>>>>> Below is some output from one of my students. I have never seen this error and tried a few things (updating packages for one) but am at a loss to help further. Would appreciate suggestions that I can pass along.
>>>>>>
>>>>>> Here is the error. I tried an install.packages(?xml2?) which appeared to complete but the error persists.
>>>>>>
>>>>>>> library("tidyverse")
>>>>>> Error: package or namespace load failed for ?tidyverse? in library.dynam(lib, package, package.lib):
>>>>>> DLL ?xml2? not found: maybe not installed for this architecture?
>>>>>>
>>>>>> Here is the sessionInfo()
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 4.1.1 (2021-08-10)
>>>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows 
>>>>>> 10 x64 (build 19042)
>>>>>>
>>>>>> Matrix products: default
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_Canada.1252 LC_CTYPE=English_Canada.1252 
>>>>>> LC_MONETARY=English_Canada.1252 LC_NUMERIC=C [5] 
>>>>>> LC_TIME=English_Canada.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] Rcpp_1.0.7 cellranger_1.1.0 pillar_1.6.2 compiler_4.1.1 
>>>>>> dbplyr_2.1.1 forcats_0.5.1 tools_4.1.1 [8] jsonlite_1.7.2 
>>>>>> lubridate_1.7.10 lifecycle_1.0.0 tibble_3.1.4 gtable_0.3.0 
>>>>>> pkgconfig_2.0.3 rlang_0.4.11 [15] reprex_2.0.1 DBI_1.1.1 
>>>>>> haven_2.4.3 withr_2.4.2 dplyr_1.0.7 httr_1.4.2 fs_1.5.0 [22] 
>>>>>> generics_0.1.0 vctrs_0.3.8 hms_1.1.0 grid_4.1.1 tidyselect_1.1.1 
>>>>>> glue_1.4.2 R6_2.5.1 [29] fansi_0.5.0 readxl_1.3.1 tzdb_0.1.2 
>>>>>> tidyr_1.1.3 ggplot2_3.3.5 purrr_0.3.4 readr_2.0.1 [36] 
>>>>>> modelr_0.1.8 magrittr_2.0.1 backports_1.2.1 scales_1.1.1 
>>>>>> ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-2 [43] utf8_1.2.2 
>>>>>> munsell_0.5.0 broom_0.7.9 crayon_1.4.1
>>>>>>
>>>>>
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>
>>
>
> --
> Sent from my phone. Please excuse my brevity.

--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka Shing Knowledge Institute of St. Michael?s Hospital Assistant Professor, Dalla Lana School of Public Health University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Thu Oct  7 18:30:24 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Thu, 7 Oct 2021 19:30:24 +0300
Subject: [R] Extracting Comments from Functions/Packages
Message-ID: <6b279d84-f7e8-8bdd-b70e-f3d08b3d0c5c@syonic.eu>

Dear R Users,


I wrote a minimal parser to extract strings and comments from the 
function definitions.


The string extraction works fine. But there are no comments:

a.) Are the comments stripped from the compiled packages?

b.) Alternatively: Is the deparse() not suited for this task?

b.2.) Is deparse() parsing the function/expression itself?

[see code for extract.str.fun() function below]


### All strings in "base"
extract.str.pkg("base")
# type = 2 for Comments:
extract.str.pkg("base", type=2)
extract.str.pkg("sp", type=2)
extract.str.pkg("NetLogoR", type=2)

The code for the 2 functions (extract.str.pkg & extract.str.fun) and the 
code for the parse.simple() parser are below.


Sincerely,


Leonard

=======

The latest code is on GitHub:

https://github.com/discoleo/R/blob/master/Stat/Tools.Formulas.R


### Code to process functions in packages:
extract.str.fun = function(fn, pkg, type=1, strip=TRUE) {
 ??? fn = as.symbol(fn); pkg = as.symbol(pkg);
 ??? fn = list(substitute(pkg ::: fn));
 ??? # deparse
 ??? s = paste0(do.call(deparse, fn), collapse="");
 ??? npos = parse.simple(s);
 ??? extract.str(s, npos[[type]], strip=strip)
}
extract.str.pkg = function(pkg, type=1, exclude.z = TRUE, strip=TRUE) {
 ??? nms = ls(getNamespace(pkg));
 ??? l = lapply(nms, function(fn) extract.str.fun(fn, pkg, type=type, 
strip=strip));
 ??? if(exclude.z) {
 ??? ??? hasStr = sapply(l, function(s) length(s) >= 1);
 ??? ??? nms = nms[hasStr];
 ??? ??? l = l[hasStr];
 ??? }
 ??? names(l) = nms;
 ??? return(l);
}

### minimal Parser:
# - proof of concept;
# - may be useful to process non-conformant R "code", e.g.:
#?? "{\"abc\" + \"bcd\"} {FUN}"; (still TODO)
# Warning:
# - not thoroughly checked &
#?? may be a little buggy!

parse.simple = function(x, eol="\n") {
 ??? len = nchar(x);
 ??? n.comm = list(integer(0), integer(0));
 ??? n.str? = list(integer(0), integer(0));
 ??? is.hex = function(ch) {
 ??? ??? # Note: only for 1 character!
 ??? ??? return((ch >= "0" && ch <= "9") ||
 ??? ??? ??? (ch >= "A" && ch <= "F") ||
 ??? ??? ??? (ch >= "a" && ch <= "f"));
 ??? }
 ??? npos = 1;
 ??? while(npos <= len) {
 ??? ??? s = substr(x, npos, npos);
 ??? ??? # State: COMMENT
 ??? ??? if(s == "#") {
 ??? ??? ??? n.comm[[1]] = c(n.comm[[1]], npos);
 ??? ??? ??? while(npos < len) {
 ??? ??? ??? ??? npos = npos + 1;
 ??? ??? ??? ??? if(substr(x, npos, npos) == eol) break;
 ??? ??? ??? }
 ??? ??? ??? n.comm[[2]] = c(n.comm[[2]], npos);
 ??? ??? ??? npos = npos + 1; next;
 ??? ??? }
 ??? ??? # State: STRING
 ??? ??? if(s == "\"" || s == "'") {
 ??? ??? ??? n.str[[1]] = c(n.str[[1]], npos);
 ??? ??? ??? while(npos < len) {
 ??? ??? ??? ??? npos = npos + 1;
 ??? ??? ??? ??? se = substr(x, npos, npos);
 ??? ??? ??? ??? if(se == "\\") {
 ??? ??? ??? ??? ??? npos = npos + 1;
 ??? ??? ??? ??? ??? # simple escape vs Unicode:
 ??? ??? ??? ??? ??? if(substr(x, npos, npos) != "u") next;
 ??? ??? ??? ??? ??? len.end = min(len, npos + 4);
 ??? ??? ??? ??? ??? npos = npos + 1;
 ??? ??? ??? ??? ??? isAllHex = TRUE;
 ??? ??? ??? ??? ??? while(npos <= len.end) {
 ??? ??? ??? ??? ??? ??? se = substr(x, npos, npos);
 ??? ??? ??? ??? ??? ??? if( ! is.hex(se)) { isAllHex = FALSE; break; }
 ??? ??? ??? ??? ??? ??? npos = npos + 1;
 ??? ??? ??? ??? ??? }
 ??? ??? ??? ??? ??? if(isAllHex) next;
 ??? ??? ??? ??? }
 ??? ??? ??? ??? if(se == s) break;
 ??? ??? ??? }
 ??? ??? ??? n.str[[2]] = c(n.str[[2]], npos);
 ??? ??? ??? npos = npos + 1; next;
 ??? ??? }
 ??? ??? npos = npos + 1;
 ??? }
 ??? return(list(str = n.str, comm = n.comm));
}


extract.str = function(s, npos, strip=FALSE) {
 ??? if(length(npos[[1]]) == 0) return(character(0));
 ??? strip.FUN = if(strip) {
 ??? ??? ??? function(id) {
 ??? ??? ??? ??? if(npos[[1]][[id]] + 1 < npos[[2]][[id]]) {
 ??? ??? ??? ??? ??? nStart = npos[[1]][[id]] + 1;
 ??? ??? ??? ??? ??? nEnd = npos[[2]][[id]] - 1; # TODO: Error with 
malformed string
 ??? ??? ??? ??? ??? return(substr(s, nStart, nEnd));
 ??? ??? ??? ??? } else {
 ??? ??? ??? ??? ??? return("");
 ??? ??? ??? ??? }
 ??? ??? ??? }
 ??? ??? } else function(id) substr(s, npos[[1]][[id]], npos[[2]][[id]]);
 ??? sapply(seq(length(npos[[1]])), strip.FUN);
}


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Thu Oct  7 18:29:04 2021
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Thu, 7 Oct 2021 16:29:04 +0000
Subject: [R] How to use ifelse without invoking warnings
Message-ID: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>

Hi,
I would like to execute the following vectorized calculation:

  ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )

For example:


> k <- c(-1.2,-0.5, 1.5, 10.4)
> n <- 10
> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
Warning message:
In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> print(ans)
[1] 0.000000000 0.006821826 0.254991551 1.000000000

The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?

Thank you,
Ravi


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Oct  7 19:34:17 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 7 Oct 2021 10:34:17 -0700
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <CAGxFJbRE1GoX=JHFUxBDDmho47ENsceYbgxxwn6J49Xab_CWaQ@mail.gmail.com>

?suppressWarnings

> p <- .05
> k <- c(-1.2,-0.5, 1.5, 10.4)
> n <- 10
>
> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE),
ifelse (k < -1, 0, 1) )
Warning message:
In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>
> suppressWarnings(ans <- ifelse (k >= -1 & k <= n,
pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) ))
## no warnings

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Oct 7, 2021 at 10:21 AM Ravi Varadhan via R-help <
r-help at r-project.org> wrote:

> Hi,
> I would like to execute the following vectorized calculation:
>
>   ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE),
> ifelse (k < -1, 0, 1) )
>
> For example:
>
>
> > k <- c(-1.2,-0.5, 1.5, 10.4)
> > n <- 10
> > ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE),
> ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> > print(ans)
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>
> The answer is correct.  However, I would like to eliminate the annoying
> warnings.  Is there a better way to do this?
>
> Thank you,
> Ravi
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Oct  7 19:34:35 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 7 Oct 2021 13:34:35 -0400
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
References: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <CAM_vjukuPfMZmQQ2X5+0FicRLr8k3cCa_+Ao-8LPxCoRgvFHcw@mail.gmail.com>

If you are positive the warnings don't matter for your application,
you can disable them: see ?options for details of warn.

But that can be dangerous, so be careful!

Sarah

On Thu, Oct 7, 2021 at 1:21 PM Ravi Varadhan via R-help
<r-help at r-project.org> wrote:
>
> Hi,
> I would like to execute the following vectorized calculation:
>
>   ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
>
> For example:
>
>
> > k <- c(-1.2,-0.5, 1.5, 10.4)
> > n <- 10
> > ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> > print(ans)
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>
> The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?
>
> Thank you,
> Ravi
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Oct  7 19:38:34 2021
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 7 Oct 2021 13:38:34 -0400
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <CAGxFJbRE1GoX=JHFUxBDDmho47ENsceYbgxxwn6J49Xab_CWaQ@mail.gmail.com>
References: <MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <CAGxFJbRE1GoX=JHFUxBDDmho47ENsceYbgxxwn6J49Xab_CWaQ@mail.gmail.com>
Message-ID: <CAM_vju=7uB98YDWq9Gm9=F=MUWp7nW8=OQOJ5_C50CG2Y5W=wQ@mail.gmail.com>

Bert's approach is much less risky!

On Thu, Oct 7, 2021 at 1:37 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> ?suppressWarnings
>
> > p <- .05
> > k <- c(-1.2,-0.5, 1.5, 10.4)
> > n <- 10
> >
> > ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE),
> ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> >
> > suppressWarnings(ans <- ifelse (k >= -1 & k <= n,
> pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) ))
> ## no warnings
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Oct 7, 2021 at 10:21 AM Ravi Varadhan via R-help <
> r-help at r-project.org> wrote:
>
> > Hi,
> > I would like to execute the following vectorized calculation:
> >
> >   ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE),
> > ifelse (k < -1, 0, 1) )
> >
> > For example:
> >
> >
> > > k <- c(-1.2,-0.5, 1.5, 10.4)
> > > n <- 10
> > > ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE),
> > ifelse (k < -1, 0, 1) )
> > Warning message:
> > In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> > > print(ans)
> > [1] 0.000000000 0.006821826 0.254991551 1.000000000
> >
> > The answer is correct.  However, I would like to eliminate the annoying
> > warnings.  Is there a better way to do this?
> >
> > Thank you,
> > Ravi
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From j|ox @end|ng |rom mcm@@ter@c@  Thu Oct  7 20:00:51 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 7 Oct 2021 14:00:51 -0400
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>

Dear Ravi,

It's already been suggested that you could disable warnings, but that's 
risky in case there's a warning that you didn't anticipate. Here's a 
different approach:

 > kk <- k[k >= -1 & k <= n]
 > ans <- numeric(length(k))
 > ans[k > n] <- 1
 > ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)
 > ans
[1] 0.000000000 0.006821826 0.254991551 1.000000000

BTW, I don't think that you mentioned that p = 0.3, but that seems 
apparent from the output you showed.

I hope this helps,
  John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
> Hi,
> I would like to execute the following vectorized calculation:
> 
>    ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
> 
> For example:
> 
> 
>> k <- c(-1.2,-0.5, 1.5, 10.4)
>> n <- 10
>> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>> print(ans)
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
> 
> The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?
> 
> Thank you,
> Ravi
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Oct  7 21:26:47 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 07 Oct 2021 21:26:47 +0200
Subject: [R] Extracting Comments from Functions/Packages
In-Reply-To: <6b279d84-f7e8-8bdd-b70e-f3d08b3d0c5c@syonic.eu> (Leonard Mada
 via's message of "Thu, 7 Oct 2021 19:30:24 +0300")
References: <6b279d84-f7e8-8bdd-b70e-f3d08b3d0c5c@syonic.eu>
Message-ID: <87k0iofxfs.fsf@enricoschumann.net>

On Thu, 07 Oct 2021, Leonard Mada via R-help writes:

> Dear R Users,
>
>
> I wrote a minimal parser to extract strings and
> comments from the function definitions.
>
>
> The string extraction works fine. But there are no comments:
>
> a.) Are the comments stripped from the compiled packages?
>
> b.) Alternatively: Is the deparse() not suited for this task?
>
> b.2.) Is deparse() parsing the function/expression itself?
>
> [see code for extract.str.fun() function below]
>
>
> ### All strings in "base"
> extract.str.pkg("base")
> # type = 2 for Comments:
> extract.str.pkg("base", type=2)
> extract.str.pkg("sp", type=2)
> extract.str.pkg("NetLogoR", type=2)
>
> The code for the 2 functions (extract.str.pkg &
> extract.str.fun) and the code for the parse.simple()
> parser are below.
>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
> The latest code is on GitHub:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.Formulas.R
>
>
> ### Code to process functions in packages:
> extract.str.fun = function(fn, pkg, type=1, strip=TRUE) {
> ??? fn = as.symbol(fn); pkg = as.symbol(pkg);
> ??? fn = list(substitute(pkg ::: fn));
> ??? # deparse
> ??? s = paste0(do.call(deparse, fn), collapse="");
> ??? npos = parse.simple(s);
> ??? extract.str(s, npos[[type]], strip=strip)
> }
> extract.str.pkg = function(pkg, type=1, exclude.z = TRUE, strip=TRUE) {
> ??? nms = ls(getNamespace(pkg));
> ??? l = lapply(nms, function(fn) extract.str.fun(fn,
> pkg, type=type, strip=strip));
> ??? if(exclude.z) {
> ??? ??? hasStr = sapply(l, function(s) length(s) >= 1);
> ??? ??? nms = nms[hasStr];
> ??? ??? l = l[hasStr];
> ??? }
> ??? names(l) = nms;
> ??? return(l);
> }
>
> ### minimal Parser:
> # - proof of concept;
> # - may be useful to process non-conformant R "code", e.g.:
> #?? "{\"abc\" + \"bcd\"} {FUN}"; (still TODO)
> # Warning:
> # - not thoroughly checked &
> #?? may be a little buggy!
>
> parse.simple = function(x, eol="\n") {
> ??? len = nchar(x);
> ??? n.comm = list(integer(0), integer(0));
> ??? n.str? = list(integer(0), integer(0));
> ??? is.hex = function(ch) {
> ??? ??? # Note: only for 1 character!
> ??? ??? return((ch >= "0" && ch <= "9") ||
> ??? ??? ??? (ch >= "A" && ch <= "F") ||
> ??? ??? ??? (ch >= "a" && ch <= "f"));
> ??? }
> ??? npos = 1;
> ??? while(npos <= len) {
> ??? ??? s = substr(x, npos, npos);
> ??? ??? # State: COMMENT
> ??? ??? if(s == "#") {
> ??? ??? ??? n.comm[[1]] = c(n.comm[[1]], npos);
> ??? ??? ??? while(npos < len) {
> ??? ??? ??? ??? npos = npos + 1;
> ??? ??? ??? ??? if(substr(x, npos, npos) == eol) break;
> ??? ??? ??? }
> ??? ??? ??? n.comm[[2]] = c(n.comm[[2]], npos);
> ??? ??? ??? npos = npos + 1; next;
> ??? ??? }
> ??? ??? # State: STRING
> ??? ??? if(s == "\"" || s == "'") {
> ??? ??? ??? n.str[[1]] = c(n.str[[1]], npos);
> ??? ??? ??? while(npos < len) {
> ??? ??? ??? ??? npos = npos + 1;
> ??? ??? ??? ??? se = substr(x, npos, npos);
> ??? ??? ??? ??? if(se == "\\") {
> ??? ??? ??? ??? ??? npos = npos + 1;
> ??? ??? ??? ??? ??? # simple escape vs Unicode:
> ??? ??? ??? ??? ??? if(substr(x, npos, npos) != "u") next;
> ??? ??? ??? ??? ??? len.end = min(len, npos + 4);
> ??? ??? ??? ??? ??? npos = npos + 1;
> ??? ??? ??? ??? ??? isAllHex = TRUE;
> ??? ??? ??? ??? ??? while(npos <= len.end) {
> ??? ??? ??? ??? ??? ??? se = substr(x, npos, npos);
> ??? ??? ??? ??? ??? ??? if( ! is.hex(se)) { isAllHex = FALSE; break; }
> ??? ??? ??? ??? ??? ??? npos = npos + 1;
> ??? ??? ??? ??? ??? }
> ??? ??? ??? ??? ??? if(isAllHex) next;
> ??? ??? ??? ??? }
> ??? ??? ??? ??? if(se == s) break;
> ??? ??? ??? }
> ??? ??? ??? n.str[[2]] = c(n.str[[2]], npos);
> ??? ??? ??? npos = npos + 1; next;
> ??? ??? }
> ??? ??? npos = npos + 1;
> ??? }
> ??? return(list(str = n.str, comm = n.comm));
> }
>
>
> extract.str = function(s, npos, strip=FALSE) {
> ??? if(length(npos[[1]]) == 0) return(character(0));
> ??? strip.FUN = if(strip) {
> ??? ??? ??? function(id) {
> ??? ??? ??? ??? if(npos[[1]][[id]] + 1 < npos[[2]][[id]]) {
> ??? ??? ??? ??? ??? nStart = npos[[1]][[id]] + 1;
> ??? ??? ??? ??? ??? nEnd = npos[[2]][[id]] - 1; # TODO:
> Error with malformed string
> ??? ??? ??? ??? ??? return(substr(s, nStart, nEnd));
> ??? ??? ??? ??? } else {
> ??? ??? ??? ??? ??? return("");
> ??? ??? ??? ??? }
> ??? ??? ??? }
> ??? ??? } else function(id) substr(s, npos[[1]][[id]], npos[[2]][[id]]);
> ??? sapply(seq(length(npos[[1]])), strip.FUN);
> }
>

On a.) There is an option "keep.source" that controls
       this behaviour. When you install a package via
       R CMD INSTALL, you can specify the option; see
       R CMD INSTALL --help .

There is also the "remindR" package on CRAN which
(I think) does something similar.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ben@de|v|de @end|ng |rom u|@j@edu@br  Fri Oct  8 00:46:52 2021
From: ben@de|v|de @end|ng |rom u|@j@edu@br (Ben Deivide de Oliveira Batista)
Date: Thu, 7 Oct 2021 19:46:52 -0300
Subject: [R] There is a relationship of the Modify-in-place optimisation of
 a object and the local variable `*tmp*`?
Message-ID: <CAM7vW+PAjzsyQhry=n9oKJwAVvj9cxqJiqppdrM4UbVzxDUdsQ@mail.gmail.com>

Dear R users,

When modify-in-place of objects occurs, is there a local variable called
`*tmp*`, behind the scenes R? Let's look at two examples to understand the
question.

Example 1 (R Language Definition)
--------------------------------------------------

> x <- 1:10
> tracemem(x)
[1] "<000000000798F758>"
> x[3:5] <- 13:15
tracemem[0x000000000798f758 -> 0x0000000008207030]:

The result of this command is as if the following had been executed
`*tmp*` <- x
x <- "[<-"(`*tmp*`, 3:5, value=13:15)
rm(`*tmp*`)

Conclusion: Here copy-on-modify occurs!


Example 2 : Modify-in-place
-----------------------

> x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
> tracemem(x)
[1] "<0000000008BFB818>"
> x[3:5] <- 13:15Conclusion: Here modify-in-place occurs!
For example 2, is there a local variable `*tmp*` for this case? If so,
what would the syntactic representation look like, similar to example 1?



-- 
Ben D?ivide de Oliveira Batista

Prof. Estat?stica (DEFIM/CAP/UFSJ)
P?gina pessoal/profissional: bendeivide.github.io
P?gina Institucional: www.ufsj.edu.br/bendeivide

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct  8 09:15:47 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 8 Oct 2021 08:15:47 +0100
Subject: [R] adding results to plot
In-Reply-To: <9401ae8901ae4cf9adeed4d122374a91@SRVEXCHCM1302.precheza.cz>
References: <0671d8bb61d74f2db55853bf19f32381@SRVEXCHCM1302.precheza.cz>
 <b354f020-4f18-d696-74d5-43a787996edf@sapo.pt>
 <9401ae8901ae4cf9adeed4d122374a91@SRVEXCHCM1302.precheza.cz>
Message-ID: <d36da0a3-1ad4-5d1b-3aac-b4a88a3a80c2@sapo.pt>

Hello,

Thanks for the compliment.

The R Core team, to which we must be very grateful for their great work 
along so many years, is, for good and obvious reasons, known to be 
change resistant and a new method would overload them even more with 
maintenance worries so I guess text.htest won't make it to core R.

(And that would be to open a precedent. Is, for instance, text.lm next?)

If it does make it to base R, which I doubt, then the base R package 
should be package graphics, right?

In the mean time I have found a small bug, near the end of print.htest 
there's


print(x$estimate, digits = digits, ...)


corresponding to my


paste("sample estimates:", round(ht$estimate, digits = digits), sep =  "\n")


The bug is that x$estimate/ht$estimate is a named vector and with paste 
the names attribute is lost. It doesn't plot "mean of x". I will 
probably try to sort this out but make no promises.

Thanks once again,

Rui Barradas

?s 14:47 de 07/10/21, PIKAL Petr escreveu:
> Hallo Rui.
> 
> I finally tested your function and it seems to me that it should propagate
> to the core R or at least to the stats package.
> 
> Although it is a bit overkill for my purpose, its use is straightforward and
> simple. I checked it for several *test functions and did not find any
> problem.
> 
> Thanks and best regards.
> 
> Petr
> 
>> -----Original Message-----
>> From: Rui Barradas <ruipbarradas at sapo.pt>
>> Sent: Friday, September 17, 2021 9:56 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help <r-help at r-project.org>
>> Subject: Re: [R] adding results to plot
>>
>> Hello,
>>
>> *.test functions in base R return a list of class "htest", with its own
>> print method.
>> The method text.htest for objects of class "htest" below is a hack. I
>> adapted the formating part of the code of print.htest to plot text().
>> I find it maybe too complicated but it seems to work.
>>
>> Warning: Not debugged at all.
>>
>>
>>
>> text.htest <- function (ht, x, y = NULL, digits = getOption("digits"),
>>                           prefix = "", adj = NULL, ...) {
>>     out <- list()
>>     i_out <- 1L
>>     out[[i_out]] <- paste(strwrap(ht$method, prefix = prefix), sep = "\n")
>>     i_out <- i_out + 1L
>>     out[[i_out]] <- paste0("data:  ", ht$data.name)
>>
>>     stat_line <- NULL
>>     i_stat_line <- 0L
>>     if (!is.null(ht$statistic)) {
>>       i_stat_line <- i_stat_line + 1L
>>       stat_line[[i_stat_line]] <- paste(names(ht$statistic), "=",
>>                                         format(ht$statistic, digits =
>> max(1L, digits - 2L)))
>>     }
>>     if (!is.null(ht$parameter)) {
>>       i_stat_line <- i_stat_line + 1L
>>       stat_line[[i_stat_line]] <- paste(names(ht$parameter), "=",
>>                                         format(ht$parameter, digits =
>> max(1L, digits - 2L)))
>>     }
>>     if (!is.null(ht$p.value)) {
>>       fp <- format.pval(ht$p.value, digits = max(1L, digits - 3L))
>>       i_stat_line <- i_stat_line + 1L
>>       stat_line[[i_stat_line]] <- paste("p-value",
>>                                         if (startsWith(fp, "<")) fp else
>> paste("=", fp))
>>     }
>>     if(!is.null(stat_line)){
>>       i_out <- i_out + 1L
>>       #out[[i_out]] <- strwrap(paste(stat_line, collapse = ", "))
>>       out[[i_out]] <- paste(stat_line, collapse = ", ")
>>     }
>>     if (!is.null(ht$alternative)) {
>>       alt <- NULL
>>       i_alt <- 1L
>>       alt[[i_alt]] <- "alternative hypothesis: "
>>       if (!is.null(ht$null.value)) {
>>         if (length(ht$null.value) == 1L) {
>>           alt.char <- switch(ht$alternative, two.sided = "not equal to",
>>                              less = "less than", greater = "greater than")
>>           i_alt <- i_alt + 1L
>>           alt[[i_alt]] <- paste0("true ", names(ht$null.value), " is ",
>> alt.char,
>>                                  " ", ht$null.value)
>>         }
>>         else {
>>           i_alt <- i_alt + 1L
>>           alt[[i_alt]] <- paste0(ht$alternative, "\nnull values:\n")
>>         }
>>       }
>>       else {
>>         i_alt <- i_alt + 1L
>>         alt[[i_alt]] <- ht$alternative
>>       }
>>       i_out <- i_out + 1L
>>       out[[i_out]] <- paste(alt, collapse = " ")
>>     }
>>     if (!is.null(ht$conf.int)) {
>>       i_out <- i_out + 1L
>>       out[[i_out]] <- paste0(format(100 * attr(ht$conf.int, "conf.level")),
>>                              " percent confidence interval:\n", " ",
>>                              paste(format(ht$conf.int[1:2], digits =
>> digits), collapse = " "))
>>     }
>>     if (!is.null(ht$estimate)) {
>>       i_out <- i_out + 1L
>>       out[[i_out]] <- paste("sample estimates:", round(ht$estimate,
>> digits = digits), sep = "\n")
>>     }
>>     i_out <- i_out + 1L
>>     out[[i_out]] <- "\n"
>>     names(out)[i_out] <- "sep"
>>     out <- do.call(paste, out)
>>     if(is.null(adj)) adj <- 0L
>>     text(x, y, labels = out, adj = adj, ...)
>>     invisible(out)
>> }
>>
>>
>> res <- shapiro.test(rnorm(100))
>> plot(1,1, ylim = c(0, length(res) + 1L))
>> text(res, 0.6, length(res) - 1)
>> res
>>
>> res2 <- t.test(rnorm(100))
>> plot(1,1, ylim = c(0, length(res2) + 1L))
>> text(res2, 0.6, length(res2) - 1L)
>> res2
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> ?s 15:12 de 16/09/21, PIKAL Petr escreveu:
>>> Dear all
>>>
>>> I know I have seen the answer somewhere but I am not able to find it.
>> Please
>>> help
>>>
>>>> plot(1,1)
>>>> res <- shapiro.test(rnorm(100))
>>>> res
>>>
>>>           Shapiro-Wilk normality test
>>>
>>> data:  rnorm(100)
>>> W = 0.98861, p-value = 0.5544
>>>
>>> I would like to add whole res object to the plot.
>>>
>>> I can do it one by one
>>>> text(locator(1), res$method)
>>>> text(locator(1), as.character(res$p.value))
>>> ...
>>> But it is quite inconvenient
>>>
>>> I could find some way in ggplot world but not in plain plot world.
>>>
>>> Best regards
>>> Petr
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Oct  8 11:58:35 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 8 Oct 2021 05:58:35 -0400
Subject: [R] 
 There is a relationship of the Modify-in-place optimisation of
 a object and the local variable `*tmp*`?
In-Reply-To: <CAM7vW+PAjzsyQhry=n9oKJwAVvj9cxqJiqppdrM4UbVzxDUdsQ@mail.gmail.com>
References: <CAM7vW+PAjzsyQhry=n9oKJwAVvj9cxqJiqppdrM4UbVzxDUdsQ@mail.gmail.com>
Message-ID: <a743b96d-d2cc-d9d7-47cb-342d8a23b84a@gmail.com>

On 07/10/2021 6:46 p.m., Ben Deivide de Oliveira Batista wrote:
> Dear R users,
> 
> When modify-in-place of objects occurs, is there a local variable called
> `*tmp*`, behind the scenes R? Let's look at two examples to understand the
> question.
> 
> Example 1 (R Language Definition)
> --------------------------------------------------
> 
>> x <- 1:10
>> tracemem(x)
> [1] "<000000000798F758>"
>> x[3:5] <- 13:15
> tracemem[0x000000000798f758 -> 0x0000000008207030]:
> 
> The result of this command is as if the following had been executed
> `*tmp*` <- x
> x <- "[<-"(`*tmp*`, 3:5, value=13:15)
> rm(`*tmp*`)
> 
> Conclusion: Here copy-on-modify occurs!
> 
> 
> Example 2 : Modify-in-place
> -----------------------
> 
>> x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
>> tracemem(x)
> [1] "<0000000008BFB818>"
>> x[3:5] <- 13:15Conclusion: Here modify-in-place occurs!
> For example 2, is there a local variable `*tmp*` for this case? If so,
> what would the syntactic representation look like, similar to example 1?

I think there is, and it would be the same as in 1.  The memory 
operations are different because x is different:  in 1, it is stored in 
a compact representation of 1:10, which needs to be expanded to a full 
array of doubles before the entries can be changed.  In 2, it is already 
stored as an array of doubles so this isn't needed.

Duncan Murdoch


From j|ox @end|ng |rom mcm@@ter@c@  Fri Oct  8 17:38:52 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Fri, 8 Oct 2021 11:38:52 -0400
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
 <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <6b011831-5760-3c9a-56db-b0779e2c2638@mcmaster.ca>

Dear Ravi,

On 2021-10-08 8:21 a.m., Ravi Varadhan wrote:
> Thank you to Bert, Sarah, and John. I did consider suppressing warnings, 
> but I felt that there must be a more principled approach.? While John's 
> solution is what I would prefer, I cannot help but wonder why `ifelse' 
> was not constructed to avoid this behavior.

The conditional if () else, which works on an individual logical value, 
uses lazy evaluation and so can avoid the problem you encountered. My 
guess is that implementing lazy evaluation for the vectorized ifelse() 
would incur too high a computational overhead for large arguments.

Best,
  John

> 
> Thanks & Best regards,
> Ravi
> ------------------------------------------------------------------------
> *From:* John Fox <jfox at mcmaster.ca>
> *Sent:* Thursday, October 7, 2021 2:00 PM
> *To:* Ravi Varadhan <ravi.varadhan at jhu.edu>
> *Cc:* R-Help <r-help at r-project.org>
> *Subject:* Re: [R] How to use ifelse without invoking warnings
> 
>  ????? External Email - Use Caution
> 
> 
> 
> Dear Ravi,
> 
> It's already been suggested that you could disable warnings, but that's
> risky in case there's a warning that you didn't anticipate. Here's a
> different approach:
> 
>  ?> kk <- k[k >= -1 & k <= n]
>  ?> ans <- numeric(length(k))
>  ?> ans[k > n] <- 1
>  ?> ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)
>  ?> ans
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
> 
> BTW, I don't think that you mentioned that p = 0.3, but that seems
> apparent from the output you showed.
> 
> I hope this helps,
>  ? John
> 
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: 
> https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7gcEEXhM3qFi7n78ZM%3D&amp;reserved=0 
> <https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7gcEEXhM3qFi7n78ZM%3D&amp;reserved=0>
> 
> On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
>> Hi,
>> I would like to execute the following vectorized calculation:
>>
>>??? ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
>>
>> For example:
>>
>>
>>> k <- c(-1.2,-0.5, 1.5, 10.4)
>>> n <- 10
>>> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
>> Warning message:
>> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>>> print(ans)
>> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>>
>> The answer is correct.? However, I would like to eliminate the annoying warnings.? Is there a better way to do this?
>>
>> Thank you,
>> Ravi
>>
>>
>>?????? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;reserved=0 
> <https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;reserved=0>
>> PLEASE do read the posting guide https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0 
> <https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From Ry@n@Der|ck@on @end|ng |rom v@@gov  Fri Oct  8 19:49:20 2021
From: Ry@n@Der|ck@on @end|ng |rom v@@gov (Derickson, Ryan, VHA NCOD)
Date: Fri, 8 Oct 2021 17:49:20 +0000
Subject: [R] unexpected behavior in apply
Message-ID: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>

Hello, 

I'm seeing unexpected behavior when using apply() compared to a for loop when a character vector is part of the data subjected to the apply statement. Below, I check whether all non-missing values are <= 3. If I include a character column, apply incorrectly returns TRUE for d3. If I only pass the numeric columns to apply, it is correct for d3. If I use a for loop, it is correct. 

> d<-data.frame(d1 = letters[1:3],
+               d2 = c(1,2,3),
+               d3 = c(NA,NA,6))
> 
> d
  d1 d2 d3
1  a  1 NA
2  b  2 NA
3  c  3  6
> 
> # results are incorrect
> apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
   d1    d2    d3 
FALSE  TRUE  TRUE 
> 
> # results are correct
> apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
   d2    d3 
 TRUE FALSE 
> 
> # results are correct
> for(i in names(d)){
+   print(all(d[!is.na(d[,i]),i] <= 3))
+ }
[1] FALSE
[1] TRUE
[1] FALSE


Finally, if I remove the NA values from d3 and include the character column in apply, it is correct.

> d<-data.frame(d1 = letters[1:3],
+               d2 = c(1,2,3),
+               d3 = c(4,5,6))
> 
> d
  d1 d2 d3
1  a  1  4
2  b  2  5
3  c  3  6
> 
> # results are correct
> apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
   d1    d2    d3 
FALSE  TRUE FALSE


Can someone help me understand what's happening?


From @zwj|08 @end|ng |rom gm@||@com  Fri Oct  8 20:03:25 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sat, 9 Oct 2021 02:03:25 +0800
Subject: [R] unexpected behavior in apply
In-Reply-To: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
Message-ID: <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>

Hi,

I guess this can tell you what happens behind the scene


> d<-data.frame(d1 = letters[1:3],
+               d2 = c(1,2,3),
+               d3 = c(NA,NA,6))
> apply(d, 2, FUN=function(x)x)
     d1  d2  d3
[1,] "a" "1" NA
[2,] "b" "2" NA
[3,] "c" "3" " 6"
> "a"<=3
[1] FALSE
> "2"<=3
[1] TRUE
> "6"<=3
[1] FALSE

Note that there is an additional space in the character value " 6",
that's why your comparison fails. I do not understand why but this
might be a bug in R

Best,
Jiefei

On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> I'm seeing unexpected behavior when using apply() compared to a for loop when a character vector is part of the data subjected to the apply statement. Below, I check whether all non-missing values are <= 3. If I include a character column, apply incorrectly returns TRUE for d3. If I only pass the numeric columns to apply, it is correct for d3. If I use a for loop, it is correct.
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(NA,NA,6))
> >
> > d
>   d1 d2 d3
> 1  a  1 NA
> 2  b  2 NA
> 3  c  3  6
> >
> > # results are incorrect
> > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d1    d2    d3
> FALSE  TRUE  TRUE
> >
> > # results are correct
> > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d2    d3
>  TRUE FALSE
> >
> > # results are correct
> > for(i in names(d)){
> +   print(all(d[!is.na(d[,i]),i] <= 3))
> + }
> [1] FALSE
> [1] TRUE
> [1] FALSE
>
>
> Finally, if I remove the NA values from d3 and include the character column in apply, it is correct.
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(4,5,6))
> >
> > d
>   d1 d2 d3
> 1  a  1  4
> 2  b  2  5
> 3  c  3  6
> >
> > # results are correct
> > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d1    d2    d3
> FALSE  TRUE FALSE
>
>
> Can someone help me understand what's happening?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @kw@|mmo @end|ng |rom gm@||@com  Fri Oct  8 20:08:25 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Fri, 8 Oct 2021 14:08:25 -0400
Subject: [R] unexpected behavior in apply
In-Reply-To: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
Message-ID: <CAPcHnpQacRZ5CS00vZmOjnx9yQWPkJzMADBjeTYZQwJZG-q_dw@mail.gmail.com>

Hello,


The issue comes that 'apply' tries to coerce its argument to a matrix. This
means that all your columns will become character class, and the result
will not be what you wanted. I would suggest something more like:


sapply(d, function(x) all(x[!is.na(x)] <= 3))

or

vapply(d, function(x) all(x[!is.na(x)] <= 3), NA)


Also, here is a different method that might look cleaner:


sapply(d, function(x) all(x <= 3, na.rm = TRUE))

vapply(d, function(x) all(x <= 3, na.rm = TRUE), NA)


It's up to you which you choose. I hope this helps!

On Fri, Oct 8, 2021 at 1:50 PM Derickson, Ryan, VHA NCOD via R-help <
r-help at r-project.org> wrote:

> Hello,
>
> I'm seeing unexpected behavior when using apply() compared to a for loop
> when a character vector is part of the data subjected to the apply
> statement. Below, I check whether all non-missing values are <= 3. If I
> include a character column, apply incorrectly returns TRUE for d3. If I
> only pass the numeric columns to apply, it is correct for d3. If I use a
> for loop, it is correct.
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(NA,NA,6))
> >
> > d
>   d1 d2 d3
> 1  a  1 NA
> 2  b  2 NA
> 3  c  3  6
> >
> > # results are incorrect
> > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d1    d2    d3
> FALSE  TRUE  TRUE
> >
> > # results are correct
> > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d2    d3
>  TRUE FALSE
> >
> > # results are correct
> > for(i in names(d)){
> +   print(all(d[!is.na(d[,i]),i] <= 3))
> + }
> [1] FALSE
> [1] TRUE
> [1] FALSE
>
>
> Finally, if I remove the NA values from d3 and include the character
> column in apply, it is correct.
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(4,5,6))
> >
> > d
>   d1 d2 d3
> 1  a  1  4
> 2  b  2  5
> 3  c  3  6
> >
> > # results are correct
> > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d1    d2    d3
> FALSE  TRUE FALSE
>
>
> Can someone help me understand what's happening?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From g@@mo||n@k|1 @end|ng |rom gm@||@com  Fri Oct  8 20:20:30 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Fri, 8 Oct 2021 20:20:30 +0200
Subject: [R] ODP:  unexpected behavior in apply
In-Reply-To: <CAPcHnpQacRZ5CS00vZmOjnx9yQWPkJzMADBjeTYZQwJZG-q_dw@mail.gmail.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAPcHnpQacRZ5CS00vZmOjnx9yQWPkJzMADBjeTYZQwJZG-q_dw@mail.gmail.com>
Message-ID: <CABxpnnm4BzbXb4cWhFo+bv=cORKTDvQABt3CCSno6W8fWrWFZg@mail.gmail.com>

Hi,
but why is there a space before 6? Isn't it the source of the problem?

Best regards,
Grzegorz


pt., 8 pa? 2021 o 20:14 Andrew Simmons <akwsimmo at gmail.com> napisa?(a):
>
> Hello,
>
>
> The issue comes that 'apply' tries to coerce its argument to a matrix. This
> means that all your columns will become character class, and the result
> will not be what you wanted. I would suggest something more like:
>
>
> sapply(d, function(x) all(x[!is.na(x)] <= 3))
>
> or
>
> vapply(d, function(x) all(x[!is.na(x)] <= 3), NA)
>
>
> Also, here is a different method that might look cleaner:
>
>
> sapply(d, function(x) all(x <= 3, na.rm = TRUE))
>
> vapply(d, function(x) all(x <= 3, na.rm = TRUE), NA)
>
>
> It's up to you which you choose. I hope this helps!
>
> On Fri, Oct 8, 2021 at 1:50 PM Derickson, Ryan, VHA NCOD via R-help <
> r-help at r-project.org> wrote:
>
> > Hello,
> >
> > I'm seeing unexpected behavior when using apply() compared to a for loop
> > when a character vector is part of the data subjected to the apply
> > statement. Below, I check whether all non-missing values are <= 3. If I
> > include a character column, apply incorrectly returns TRUE for d3. If I
> > only pass the numeric columns to apply, it is correct for d3. If I use a
> > for loop, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1 NA
> > 2  b  2 NA
> > 3  c  3  6
> > >
> > > # results are incorrect
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE  TRUE
> > >
> > > # results are correct
> > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d2    d3
> >  TRUE FALSE
> > >
> > > # results are correct
> > > for(i in names(d)){
> > +   print(all(d[!is.na(d[,i]),i] <= 3))
> > + }
> > [1] FALSE
> > [1] TRUE
> > [1] FALSE
> >
> >
> > Finally, if I remove the NA values from d3 and include the character
> > column in apply, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(4,5,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1  4
> > 2  b  2  5
> > 3  c  3  6
> > >
> > > # results are correct
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE FALSE
> >
> >
> > Can someone help me understand what's happening?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zwj|08 @end|ng |rom gm@||@com  Fri Oct  8 20:21:35 2021
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Sat, 9 Oct 2021 02:21:35 +0800
Subject: [R] unexpected behavior in apply
In-Reply-To: <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
Message-ID: <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>

Ok, it turns out that this is documented, even though it looks surprising.

First of all, the apply function will try to convert any object with
the dim attribute to a matrix(my intuition agrees with you that there
should be no conversion), so the first step of the apply function is

> as.matrix.data.frame(d)
     d1  d2  d3
[1,] "a" "1" NA
[2,] "b" "2" NA
[3,] "c" "3" " 6"

Since the data frame `d` is a mixture of character and non-character
values, the non-character value will be converted to the character
using the function `format`. However, the problem is that the NA value
will also be formatted to the character

> format(c(NA, 6))
[1] "NA" " 6"

That's where the space comes from. It is purely for making the result
pretty... The character NA will be removed later, but the space is not
stripped. I would say this is not a good design, and it might be worth
not including the NA value in the format function. At the current
stage, I will suggest using the function `lapply` to do what you want.

> lapply(d, FUN=function(x)all(x[!is.na(x)] <= 3))
$d1
[1] FALSE
$d2
[1] TRUE
$d3
[1] FALSE

Everything should work as you expect.

Best,
Jiefei

On Sat, Oct 9, 2021 at 2:03 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
> Hi,
>
> I guess this can tell you what happens behind the scene
>
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(NA,NA,6))
> > apply(d, 2, FUN=function(x)x)
>      d1  d2  d3
> [1,] "a" "1" NA
> [2,] "b" "2" NA
> [3,] "c" "3" " 6"
> > "a"<=3
> [1] FALSE
> > "2"<=3
> [1] TRUE
> > "6"<=3
> [1] FALSE
>
> Note that there is an additional space in the character value " 6",
> that's why your comparison fails. I do not understand why but this
> might be a bug in R
>
> Best,
> Jiefei
>
> On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello,
> >
> > I'm seeing unexpected behavior when using apply() compared to a for loop when a character vector is part of the data subjected to the apply statement. Below, I check whether all non-missing values are <= 3. If I include a character column, apply incorrectly returns TRUE for d3. If I only pass the numeric columns to apply, it is correct for d3. If I use a for loop, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1 NA
> > 2  b  2 NA
> > 3  c  3  6
> > >
> > > # results are incorrect
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE  TRUE
> > >
> > > # results are correct
> > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d2    d3
> >  TRUE FALSE
> > >
> > > # results are correct
> > > for(i in names(d)){
> > +   print(all(d[!is.na(d[,i]),i] <= 3))
> > + }
> > [1] FALSE
> > [1] TRUE
> > [1] FALSE
> >
> >
> > Finally, if I remove the NA values from d3 and include the character column in apply, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(4,5,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1  4
> > 2  b  2  5
> > 3  c  3  6
> > >
> > > # results are correct
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE FALSE
> >
> >
> > Can someone help me understand what's happening?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From Ry@n@Der|ck@on @end|ng |rom v@@gov  Fri Oct  8 20:24:17 2021
From: Ry@n@Der|ck@on @end|ng |rom v@@gov (Derickson, Ryan, VHA NCOD)
Date: Fri, 8 Oct 2021 18:24:17 +0000
Subject: [R] [EXTERNAL] Re:  unexpected behavior in apply
In-Reply-To: <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
 <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
Message-ID: <SA0PR09MB73390E557D67C26608D7CC83F7B29@SA0PR09MB7339.namprd09.prod.outlook.com>

This is interesting and does seem suboptimal. Especially because if I start with a matrix from the beginning, it behaves as expected.

> d<-data.frame(d1 = letters[1:3],
+               d2 = c("1","2","3"),
+               d3 = c(NA,NA,"6"))
> 
> str(d)
'data.frame':	3 obs. of  3 variables:
 $ d1: chr  "a" "b" "c"
 $ d2: chr  "1" "2" "3"
 $ d3: chr  NA NA "6"
> 
> apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
   d1    d2    d3 
FALSE  TRUE FALSE




-----Original Message-----
From: Jiefei Wang <szwjf08 at gmail.com> 
Sent: Friday, October 8, 2021 2:22 PM
To: Derickson, Ryan, VHA NCOD <Ryan.Derickson at va.gov>
Cc: r-help at r-project.org
Subject: [EXTERNAL] Re: [R] unexpected behavior in apply

Ok, it turns out that this is documented, even though it looks surprising.

First of all, the apply function will try to convert any object with the dim attribute to a matrix(my intuition agrees with you that there should be no conversion), so the first step of the apply function is

> as.matrix.data.frame(d)
     d1  d2  d3
[1,] "a" "1" NA
[2,] "b" "2" NA
[3,] "c" "3" " 6"

Since the data frame `d` is a mixture of character and non-character values, the non-character value will be converted to the character using the function `format`. However, the problem is that the NA value will also be formatted to the character

> format(c(NA, 6))
[1] "NA" " 6"

That's where the space comes from. It is purely for making the result pretty... The character NA will be removed later, but the space is not stripped. I would say this is not a good design, and it might be worth not including the NA value in the format function. At the current stage, I will suggest using the function `lapply` to do what you want.

> lapply(d, FUN=function(x)all(x[!is.na(x)] <= 3))
$d1
[1] FALSE
$d2
[1] TRUE
$d3
[1] FALSE

Everything should work as you expect.

Best,
Jiefei

On Sat, Oct 9, 2021 at 2:03 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
>
> Hi,
>
> I guess this can tell you what happens behind the scene
>
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c(1,2,3),
> +               d3 = c(NA,NA,6))
> > apply(d, 2, FUN=function(x)x)
>      d1  d2  d3
> [1,] "a" "1" NA
> [2,] "b" "2" NA
> [3,] "c" "3" " 6"
> > "a"<=3
> [1] FALSE
> > "2"<=3
> [1] TRUE
> > "6"<=3
> [1] FALSE
>
> Note that there is an additional space in the character value " 6", 
> that's why your comparison fails. I do not understand why but this 
> might be a bug in R
>
> Best,
> Jiefei
>
> On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help 
> <r-help at r-project.org> wrote:
> >
> > Hello,
> >
> > I'm seeing unexpected behavior when using apply() compared to a for loop when a character vector is part of the data subjected to the apply statement. Below, I check whether all non-missing values are <= 3. If I include a character column, apply incorrectly returns TRUE for d3. If I only pass the numeric columns to apply, it is correct for d3. If I use a for loop, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1 NA
> > 2  b  2 NA
> > 3  c  3  6
> > >
> > > # results are incorrect
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE  TRUE
> > >
> > > # results are correct
> > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d2    d3
> >  TRUE FALSE
> > >
> > > # results are correct
> > > for(i in names(d)){
> > +   print(all(d[!is.na(d[,i]),i] <= 3)) }
> > [1] FALSE
> > [1] TRUE
> > [1] FALSE
> >
> >
> > Finally, if I remove the NA values from d3 and include the character column in apply, it is correct.
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(4,5,6))
> > >
> > > d
> >   d1 d2 d3
> > 1  a  1  4
> > 2  b  2  5
> > 3  c  3  6
> > >
> > > # results are correct
> > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> >    d1    d2    d3
> > FALSE  TRUE FALSE
> >
> >
> > Can someone help me understand what's happening?
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fst
> > at.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7Cd4c50
> > d8f8da547cbf36108d98a88880c%7Ce95f1b23abaf45ee821db7ab251ab3bf%7C0%7
> > C0%7C637693141284202940%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAi
> > LCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=3KAp
> > Y5pdxAh5BzVZvjyrQKTpqkigQmW8N7pmU7DQGcU%3D&amp;reserved=0
> > PLEASE do read the posting guide 
> > https://gcc02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww
> > .r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7Cd4c50d8f8d
> > a547cbf36108d98a88880c%7Ce95f1b23abaf45ee821db7ab251ab3bf%7C0%7C0%7C
> > 637693141284202940%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQI
> > joiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=mgrquTpZU
> > SQt7cGywiHtaKWrdqAjvaG4gFx9aD7nRlA%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.


From g@@mo||n@k|1 @end|ng |rom gm@||@com  Fri Oct  8 20:51:57 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Fri, 8 Oct 2021 20:51:57 +0200
Subject: [R] [EXTERNAL] Re: unexpected behavior in apply
In-Reply-To: <SA0PR09MB73390E557D67C26608D7CC83F7B29@SA0PR09MB7339.namprd09.prod.outlook.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
 <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
 <SA0PR09MB73390E557D67C26608D7CC83F7B29@SA0PR09MB7339.namprd09.prod.outlook.com>
Message-ID: <CABxpnnmETVnQhjiH4RByvn1o8BkK1k4_V0jZSbH=18q=nvaDrQ@mail.gmail.com>

This will work as well:

d<-data.frame(d1 = letters[1:3],
              d2 = c(1,2,3),
              d3 = c(NA_character_,NA_character_,6))

apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))

d1          d2      d3
FALSE  TRUE FALSE

i.e. when NA changed do NA_character_

pt., 8 pa? 2021 o 20:44 Derickson, Ryan, VHA NCOD via R-help
<r-help at r-project.org> napisa?(a):
>
> This is interesting and does seem suboptimal. Especially because if I start with a matrix from the beginning, it behaves as expected.
>
> > d<-data.frame(d1 = letters[1:3],
> +               d2 = c("1","2","3"),
> +               d3 = c(NA,NA,"6"))
> >
> > str(d)
> 'data.frame':   3 obs. of  3 variables:
>  $ d1: chr  "a" "b" "c"
>  $ d2: chr  "1" "2" "3"
>  $ d3: chr  NA NA "6"
> >
> > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
>    d1    d2    d3
> FALSE  TRUE FALSE
>
>
>
>
> -----Original Message-----
> From: Jiefei Wang <szwjf08 at gmail.com>
> Sent: Friday, October 8, 2021 2:22 PM
> To: Derickson, Ryan, VHA NCOD <Ryan.Derickson at va.gov>
> Cc: r-help at r-project.org
> Subject: [EXTERNAL] Re: [R] unexpected behavior in apply
>
> Ok, it turns out that this is documented, even though it looks surprising.
>
> First of all, the apply function will try to convert any object with the dim attribute to a matrix(my intuition agrees with you that there should be no conversion), so the first step of the apply function is
>
> > as.matrix.data.frame(d)
>      d1  d2  d3
> [1,] "a" "1" NA
> [2,] "b" "2" NA
> [3,] "c" "3" " 6"
>
> Since the data frame `d` is a mixture of character and non-character values, the non-character value will be converted to the character using the function `format`. However, the problem is that the NA value will also be formatted to the character
>
> > format(c(NA, 6))
> [1] "NA" " 6"
>
> That's where the space comes from. It is purely for making the result pretty... The character NA will be removed later, but the space is not stripped. I would say this is not a good design, and it might be worth not including the NA value in the format function. At the current stage, I will suggest using the function `lapply` to do what you want.
>
> > lapply(d, FUN=function(x)all(x[!is.na(x)] <= 3))
> $d1
> [1] FALSE
> $d2
> [1] TRUE
> $d3
> [1] FALSE
>
> Everything should work as you expect.
>
> Best,
> Jiefei
>
> On Sat, Oct 9, 2021 at 2:03 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> > Hi,
> >
> > I guess this can tell you what happens behind the scene
> >
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > > apply(d, 2, FUN=function(x)x)
> >      d1  d2  d3
> > [1,] "a" "1" NA
> > [2,] "b" "2" NA
> > [3,] "c" "3" " 6"
> > > "a"<=3
> > [1] FALSE
> > > "2"<=3
> > [1] TRUE
> > > "6"<=3
> > [1] FALSE
> >
> > Note that there is an additional space in the character value " 6",
> > that's why your comparison fails. I do not understand why but this
> > might be a bug in R
> >
> > Best,
> > Jiefei
> >
> > On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > I'm seeing unexpected behavior when using apply() compared to a for loop when a character vector is part of the data subjected to the apply statement. Below, I check whether all non-missing values are <= 3. If I include a character column, apply incorrectly returns TRUE for d3. If I only pass the numeric columns to apply, it is correct for d3. If I use a for loop, it is correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(NA,NA,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1 NA
> > > 2  b  2 NA
> > > 3  c  3  6
> > > >
> > > > # results are incorrect
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE  TRUE
> > > >
> > > > # results are correct
> > > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d2    d3
> > >  TRUE FALSE
> > > >
> > > > # results are correct
> > > > for(i in names(d)){
> > > +   print(all(d[!is.na(d[,i]),i] <= 3)) }
> > > [1] FALSE
> > > [1] TRUE
> > > [1] FALSE
> > >
> > >
> > > Finally, if I remove the NA values from d3 and include the character column in apply, it is correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(4,5,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1  4
> > > 2  b  2  5
> > > 3  c  3  6
> > > >
> > > > # results are correct
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE FALSE
> > >
> > >
> > > Can someone help me understand what's happening?
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fst
> > > at.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7C%7Cd4c50
> > > d8f8da547cbf36108d98a88880c%7Ce95f1b23abaf45ee821db7ab251ab3bf%7C0%7
> > > C0%7C637693141284202940%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAi
> > > LCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=3KAp
> > > Y5pdxAh5BzVZvjyrQKTpqkigQmW8N7pmU7DQGcU%3D&amp;reserved=0
> > > PLEASE do read the posting guide
> > > https://gcc02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww
> > > .r-project.org%2Fposting-guide.html&amp;data=04%7C01%7C%7Cd4c50d8f8d
> > > a547cbf36108d98a88880c%7Ce95f1b23abaf45ee821db7ab251ab3bf%7C0%7C0%7C
> > > 637693141284202940%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQI
> > > joiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=mgrquTpZU
> > > SQt7cGywiHtaKWrdqAjvaG4gFx9aD7nRlA%3D&amp;reserved=0
> > > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@v|@v@r@dh@n @end|ng |rom jhu@edu  Fri Oct  8 14:21:44 2021
From: r@v|@v@r@dh@n @end|ng |rom jhu@edu (Ravi Varadhan)
Date: Fri, 8 Oct 2021 12:21:44 +0000
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
Message-ID: <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>

Thank you to Bert, Sarah, and John. I did consider suppressing warnings, but I felt that there must be a more principled approach.  While John's solution is what I would prefer, I cannot help but wonder why `ifelse' was not constructed to avoid this behavior.

Thanks & Best regards,
Ravi
________________________________
From: John Fox <jfox at mcmaster.ca>
Sent: Thursday, October 7, 2021 2:00 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: R-Help <r-help at r-project.org>
Subject: Re: [R] How to use ifelse without invoking warnings


      External Email - Use Caution



Dear Ravi,

It's already been suggested that you could disable warnings, but that's
risky in case there's a warning that you didn't anticipate. Here's a
different approach:

 > kk <- k[k >= -1 & k <= n]
 > ans <- numeric(length(k))
 > ans[k > n] <- 1
 > ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)
 > ans
[1] 0.000000000 0.006821826 0.254991551 1.000000000

BTW, I don't think that you mentioned that p = 0.3, but that seems
apparent from the output you showed.

I hope this helps,
  John

--
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7gcEEXhM3qFi7n78ZM%3D&amp;reserved=0

On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
> Hi,
> I would like to execute the following vectorized calculation:
>
>    ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
>
> For example:
>
>
>> k <- c(-1.2,-0.5, 1.5, 10.4)
>> n <- 10
>> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>> print(ans)
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>
> The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?
>
> Thank you,
> Ravi
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Oct  9 00:22:11 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 8 Oct 2021 18:22:11 -0400
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
 <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <00d401d7bc92$f0b79850$d226c8f0$@verizon.net>

Ravi,

I have no idea what motivated the people who made ifelse() but there is no
reason they felt the need to program it to meet your precise need. As others
have noted, it probably was built to handle simple cases well and it expects
to return a result that is the same length as the input. If some of the
processing returns an NA or a NaN then that is what it probably should
return. 

What is the alternative? Return a shorter result? Replace it with a zero?
Fail utterly and abort the program?

YOU as the programmer should make such decisions for a non-routine case.

You can create functions with names like wrapperIf() and wrapperElse() and
do your ifelse like this:

result <- ifelse(condition, wrapperIf(args), wrapperElse(args))

Why the wrappers? If your logic is to replace NaN with 0 or NA or 666 or
Inf, then the code for it would invoke your functionality and if tested to
be a NaN it would replace it as you wish. Yes, it would slow things down a
bit but leave the ifelse() routine fairly simple.

If your goal is to remove those entries, you can do it after by manipulating
"result" above such as not keeping any item that matches 666, or even
without the wrappers, something like:

result <- result[!is.nan(result)]

But, of course, warnings are only suppressed if done right. Clearly you can
very selectively suppress warnings in the wrapper functions above without
also suppressing some other more valid warnings. But if the warning is
coming from ifelse() itself then not ever having it see a NaN would suppress
that.

Do note that the implementation of ifelse() is currently a function, not
some internal call. You can copy that and make your own slightly modified
version if you wish. 

(no R) Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Ravi Varadhan via
R-help
Sent: Friday, October 8, 2021 8:22 AMiu
To: John Fox <jfox at mcmaster.ca>l
Cc: R-Help <r-help at r-project.org>
Subject: Re: [R] How to use ifelse without invoking warnings

Thank you to Bert, Sarah, and John. I did consider suppressing warnings, but
I felt that there must be a more principled approach.  While John's solution
is what I would prefer, I cannot help but wonder why `ifelse' was not
constructed to avoid this behavior.

Thanks & Best regards,
Ravi
________________________________
From: John Fox <jfox at mcmaster.ca>
Sent: Thursday, October 7, 2021 2:00 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: R-Help <r-help at r-project.org>
Subject: Re: [R] How to use ifelse without invoking warnings


      External Email - Use Caution



Dear Ravi,

It's already been suggested that you could disable warnings, but that's
risky in case there's a warning that you didn't anticipate. Here's a
different approach:

 > kk <- k[k >= -1 & k <= n]
 > ans <- numeric(length(k))
 > ans[k > n] <- 1
 > ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)  >
ans [1] 0.000000000 0.006821826 0.254991551 1.000000000

BTW, I don't think that you mentioned that p = 0.3, but that seems apparent
from the output you showed.

I hope this helps,
  John

--
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web:
https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialscie
nces.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd88
2e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C63
7692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzI
iLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7g
cEEXhM3qFi7n78ZM%3D&amp;reserved=0

On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
> Hi,
> I would like to execute the following vectorized calculation:
>
>    ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = 
> FALSE), ifelse (k < -1, 0, 1) )
>
> For example:
>
>
>> k <- c(-1.2,-0.5, 1.5, 10.4)
>> n <- 10
>> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), 
>> ifelse (k < -1, 0, 1) )
> Warning message:
> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>> print(ans)
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>
> The answer is correct.  However, I would like to eliminate the annoying
warnings.  Is there a better way to do this?
>
> Thank you,
> Ravi
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadha
> n%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f8
> 6f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWI
> joiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&a
> mp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;rese
> rved=0 PLEASE do read the posting guide 
> https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r
> -project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40j
> hu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8ae
> df0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC
> 4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sd
> ata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Oct  9 00:45:44 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 08 Oct 2021 15:45:44 -0700
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
 <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <AD74ADED-A9EE-451C-9615-7B9EFE4C320B@dcn.davis.ca.us>

I don't think it is avoidable... ifelse cannot figure out which elements will exist in the second and third arguments until they are evaluated, so it cannot make use of the TRUE/FALSE information until both possible output vectors have been evaluated, which is a performance hit and yields warnings or errors.

You, on the other hand, can figure that out and use input validation to limit which inputs get fed into the warning- or error- producing algorithm and put the results into a final result vector using indexed assignment as Dr Fox suggested.


On October 8, 2021 5:21:44 AM PDT, Ravi Varadhan via R-help <r-help at r-project.org> wrote:
>Thank you to Bert, Sarah, and John. I did consider suppressing warnings, but I felt that there must be a more principled approach.  While John's solution is what I would prefer, I cannot help but wonder why `ifelse' was not constructed to avoid this behavior.
>
>Thanks & Best regards,
>Ravi
>________________________________
>From: John Fox <jfox at mcmaster.ca>
>Sent: Thursday, October 7, 2021 2:00 PM
>To: Ravi Varadhan <ravi.varadhan at jhu.edu>
>Cc: R-Help <r-help at r-project.org>
>Subject: Re: [R] How to use ifelse without invoking warnings
>
>
>      External Email - Use Caution
>
>
>
>Dear Ravi,
>
>It's already been suggested that you could disable warnings, but that's
>risky in case there's a warning that you didn't anticipate. Here's a
>different approach:
>
> > kk <- k[k >= -1 & k <= n]
> > ans <- numeric(length(k))
> > ans[k > n] <- 1
> > ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)
> > ans
>[1] 0.000000000 0.006821826 0.254991551 1.000000000
>
>BTW, I don't think that you mentioned that p = 0.3, but that seems
>apparent from the output you showed.
>
>I hope this helps,
>  John
>
>--
>John Fox, Professor Emeritus
>McMaster University
>Hamilton, Ontario, Canada
>web: https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7gcEEXhM3qFi7n78ZM%3D&amp;reserved=0
>
>On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
>> Hi,
>> I would like to execute the following vectorized calculation:
>>
>>    ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
>>
>> For example:
>>
>>
>>> k <- c(-1.2,-0.5, 1.5, 10.4)
>>> n <- 10
>>> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
>> Warning message:
>> In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
>>> print(ans)
>> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>>
>> The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?
>>
>> Thank you,
>> Ravi
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;reserved=0
>> PLEASE do read the posting guide https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Oct  9 07:02:58 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 9 Oct 2021 10:32:58 +0530
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
References: <8197_1633627307_197HLkf0027632_MW4PR01MB6212AE658D3DDB1A55B38469F2B19@MW4PR01MB6212.prod.exchangelabs.com>
 <6203fea2-3235-531d-891f-01a0ac23bef7@mcmaster.ca>
 <MW4PR01MB621281C95C40AEE978CC2BF9F2B29@MW4PR01MB6212.prod.exchangelabs.com>
Message-ID: <CADfFDC7W323Y4n=M0EDAtv7uF-vzCbEUHkq_gd_aFdVpkYGWyQ@mail.gmail.com>

On Sat, Oct 9, 2021 at 3:00 AM Ravi Varadhan via R-help
<r-help at r-project.org> wrote:
>
> Thank you to Bert, Sarah, and John. I did consider suppressing warnings, but I felt that
> there must be a more principled approach.  While John's solution is what I would prefer,
> I cannot help but wonder why `ifelse' was not constructed to avoid this behavior.

Note that John's approach is mentioned twice in the help page for
ifelse, once in the examples, and once quite early on in the "Warning"
section:

     Sometimes it is better to use a construction such as

       (tmp <- yes; tmp[!test] <- no[!test]; tmp)

     , possibly extended to handle missing values in 'test'.

Best,
-Deepayan

> Thanks & Best regards,
> Ravi
> ________________________________
> From: John Fox <jfox at mcmaster.ca>
> Sent: Thursday, October 7, 2021 2:00 PM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: R-Help <r-help at r-project.org>
> Subject: Re: [R] How to use ifelse without invoking warnings
>
>
>       External Email - Use Caution
>
>
>
> Dear Ravi,
>
> It's already been suggested that you could disable warnings, but that's
> risky in case there's a warning that you didn't anticipate. Here's a
> different approach:
>
>  > kk <- k[k >= -1 & k <= n]
>  > ans <- numeric(length(k))
>  > ans[k > n] <- 1
>  > ans[k >= -1 & k <= n] <- pbeta(p, kk + 1, n - kk, lower.tail=FALSE)
>  > ans
> [1] 0.000000000 0.006821826 0.254991551 1.000000000
>
> BTW, I don't think that you mentioned that p = 0.3, but that seems
> apparent from the output you showed.
>
> I hope this helps,
>   John
>
> --
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fsocialsciences.mcmaster.ca%2Fjfox%2F&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160038474%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=Q33yXm36BwEVKUWO72CWFpSUx7gcEEXhM3qFi7n78ZM%3D&amp;reserved=0
>
> On 2021-10-07 12:29 p.m., Ravi Varadhan via R-help wrote:
> > Hi,
> > I would like to execute the following vectorized calculation:
> >
> >    ans <- ifelse (k >= -1 & k <= n, pbeta(p, k+1, n-k, lower.tail = FALSE), ifelse (k < -1, 0, 1) )
> >
> > For example:
> >
> >
> >> k <- c(-1.2,-0.5, 1.5, 10.4)
> >> n <- 10
> >> ans <- ifelse (k >= -1 & k <= n, pbeta(p,k+1,n-k,lower.tail=FALSE), ifelse (k < -1, 0, 1) )
> > Warning message:
> > In pbeta(p, k + 1, n - k, lower.tail = FALSE) : NaNs produced
> >> print(ans)
> > [1] 0.000000000 0.006821826 0.254991551 1.000000000
> >
> > The answer is correct.  However, I would like to eliminate the annoying warnings.  Is there a better way to do this?
> >
> > Thank you,
> > Ravi
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=FXX%2B4zNT0JHBnDFO5dXBDQ484oQF1EK5%2Fa0dG9P%2F4k4%3D&amp;reserved=0
> > PLEASE do read the posting guide https://nam02.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Cravi.varadhan%40jhu.edu%7Cfd882e7c4f4349db34e108d989bc6a9f%7C9fa4f438b1e6473b803f86f8aedf0dec%7C0%7C0%7C637692265160048428%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000&amp;sdata=ss2ohzJIY6qj0eAexk4yVzTzbjXxK5VZNors0GpsbA0%3D&amp;reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Oct  9 20:26:01 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sat, 9 Oct 2021 21:26:01 +0300
Subject: [R] How to use ifelse without invoking warnings
Message-ID: <55052e24-3337-12e9-09f1-7681d2d77de1@syonic.eu>

Dear Ravi,


I wrote a small replacement for ifelse() which avoids such unnecessary 
evaluations (it bothered me a few times as well - so I decided to try a 
small replacement).


### Example:
x = 1:10
FUN = list();
FUN[[1]] = function(x, y) x*y;
FUN[[2]] = function(x, y) x^2;
FUN[[3]] = function(x, y) x;
# lets run multiple conditions
# eval.by.formula(conditions, FUN.list, ... (arguments for FUN) );
eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, x, x-1)
# Example 2
eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, 2, x)


### Disclaimer:
- NOT properly tested;


The code for the function is below. Maybe someone can experiment with 
the code and improve it further. There are a few issues / open 
questions, like:

1.) Best Name: eval.by.formula, ifelse.formula, ...?

2.) Named arguments: not yet;

3.) Fixed values inside FUN.list

4.) Format of expression for conditions:

expression(cond1, cond2, cond3) vs cond1 ~ cond2 ~ cond3 ???

5.) Code efficiency

- some tests on large data sets & optimizations are warranted;


Sincerely,


Leonard

=======

The latest code is on Github:

https://github.com/discoleo/R/blob/master/Stat/Tools.Formulas.R


eval.by.formula = function(e, FUN.list, ..., default=NA) {
 ?? ?tok = split.formula(e);
 ?? ?if(length(tok) == 0) return();
 ?? ?FUN = FUN.list;
 ?? ?# Argument List
 ?? ?clst = substitute(as.list(...))[-1];
 ?? ?len? = length(clst);
 ?? ?clst.all = lapply(clst, eval);
 ?? ?eval.f = function(idCond) {
 ?? ???? sapply(seq(length(isEval)), function(id) {
 ?? ???? ??? if(isEval[[id]] == FALSE) return(default);
 ?? ???? ??? args.l = lapply(clst.all, function(a) if(length(a) == 1) a 
else a[[id]]);
 ?? ???? ??? do.call(FUN[[idCond]], args.l);
 ?? ???? });
 ?? ?}
 ?? ?# eval 1st condition:
 ?? ?isEval = eval(tok[[1]]);
 ?? ?rez = eval.f(1);
 ?? ?if(length(tok) == 1) return(rez);
 ?? ?# eval remaining conditions
 ?? ?isEvalAll = isEval;
 ?? ?for(id in seq(2, length(tok))) {
 ?? ???? if(tok[[id]] == ".") {
 ?? ???? ??? # Remaining conditions: tok == ".";
 ?? ???? ??? # makes sens only on the last position
 ?? ???? ??? if(id < length(tok)) warning("\".\" is not last!");
 ?? ???? ??? isEval = ! isEvalAll;
 ?? ???? ??? rez[isEval] = eval.f(id)[isEval];
 ?? ???? ??? next;
 ?? ???? }
 ?? ???? isEval = rep(FALSE, length(isEval));
 ?? ???? isEval[ ! isEvalAll] = eval(tok[[id]])[ ! isEvalAll];
 ?? ???? isEvalAll[isEval] = isEval[isEval];
 ?? ???? rez[isEval] = eval.f(id)[isEval];
 ?? ?}
 ?? ?return(rez);
}


# current code uses the formula format:
# cond1 ~ cond 2 ~ cond3

# tokenizes a formula in its parts delimited by "~"
# Note:
# - tokenization is automatic for ",";
# - but call MUST then use FUN(expression(_conditions_), other_args, ...);
split.formula = function(e) {
 ?? ?tok = list();
 ?? ?while(length(e) > 0) {
 ?? ???? if(e[[1]] == "~") {
 ?? ???? ??? if(length(e) == 2) { tok = c(NA, e[[2]], tok); break; }
 ?? ???? ??? tok = c(e[[3]], tok);
 ?? ???? ??? e = e[[2]];
 ?? ???? } else {
 ?? ???? ??? tok = c(e, tok); break;
 ?? ???? }
 ?? ?}
 ?? ?return(tok);
}


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Oct  9 21:35:55 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 9 Oct 2021 15:35:55 -0400
Subject: [R] assumptions about how things are done
References: <029401d7bd44$e10843c0$a318cb40$.ref@verizon.net>
Message-ID: <029401d7bd44$e10843c0$a318cb40$@verizon.net>

This is supposed to be a forum for help so general and philosophical
discussions belong elsewhere, or nowhere.

 

Having said that, I want to make a brief point. Both new and experienced
people make implicit assumptions about the code they use. Often nobody looks
at how the sausage is made. The recent discussion of ifelse() made me take a
look and I was not thrilled.

 

My NA?VE view was that ifelse() was implemented as a sort of loop construct.
I mean if I have a vector of length N and perhaps a few other vectors of the
same length, I might say:

 

result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
result-if-false-using-vectors)

 

So say I want to take a vector of integers from 1 to N and make an output a
second vector where you have either a prime number or NA. If I have a
function called is.prime() that checks a single number and returns
TRUE/FALSE, it might look like this:

 

primed <- ifelse(is.prime(A, A, NA)

 

So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
composite becomes NA and so on.

 

If you wrote the above using loops, it would be to range from index 1 to N
and apply the above. There are many complications as R allows vectors to be
longer or to be repeated as needed.

 

What I found ifelse() as implemented to do, is sort of like this:

 

Make a vector of the right length for the results, initially empty.

 

Make a vector evaluating the condition so it is effectively a Boolean
result.

Calculate which indices are TRUE. Secondarily, calculate another set of
indices that are false.

 

Calculate ALL the THEN conditions and ditto all the ELSE conditions.

 

Now copy into the result all the THEN values indexed by the TRUE above and
than all the ELSE values indicated by the FALSE above.

 

In plain English, make a result from two other results based on picking
either one from menu A or one from menu B.

 

That is not a bad algorithm and in a vectorized language like R, maybe even
quite effective and efficient. It does lots of extra work as by definition
it throws at least half away.

 

I suspect the implementation could be made much faster by making some of it
done internally using a language like C.

 

But now that I know what this implementation did, I might have some qualms
at using it in some situations. The original complaint led to other
observations and needs and perhaps blindly using a supplied function like
ifelse() may not be a decent solution for some needs.

 

I note how I had to reorient my work elsewhere using a group of packages
called the tidyverse when they added a function to allow rowwise
manipulation of the data as compared to an ifelse-like method using all
columns at once. There is room for many approaches and if a function may not
be doing quite what you want, something else may better meet your needs OR
you may want to see if you can copy the existing function and modify it for
your own personal needs.

 

In the case we mentioned, the goal was to avoid printing selected warnings.
Since the function is readable, it can easily be modified in a copy to find
what is causing the warnings and either rewrite a bit to avoid them or start
over with perhaps your own function that tests before doing things and
avoids tripping the condition (generating a NaN) entirely.

 

Like may languages, R is a bit too rich. You can piggyback on the work of
others but with some caution as they did not necessarily have you in mind
with what they created.

 

 


	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sat Oct  9 23:09:11 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 10 Oct 2021 00:09:11 +0300
Subject: [R] How to use ifelse without invoking warnings
In-Reply-To: <55052e24-3337-12e9-09f1-7681d2d77de1@syonic.eu>
References: <55052e24-3337-12e9-09f1-7681d2d77de1@syonic.eu>
Message-ID: <04ed42ba-7ca6-d795-2603-38cca097fb38@syonic.eu>

Dear Ravi,


I have uploaded on GitHub a version which handles also constant values 
instead of functions.


Regarding named arguments: this is actually handled automatically as well:

eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, y=2, x)
# [1]? 1? 4? 9 16 25? 6 14? 8 18 10
eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, x=2, x)
# [1]? 4? 4? 4? 4? 4? 2 14? 2 18? 2
eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., list(FUN[[1]], 0, 1), 
y=2, x)
 ?# [1]? 0? 0? 0? 0? 0? 1 14? 1 18? 1


But it still needs proper testing and maybe optimization: it is possible 
to run sapply on the filtered sequence (but I did not want to break 
anything now).


Sincerely,


Leonard



On 10/9/2021 9:26 PM, Leonard Mada wrote:
> Dear Ravi,
>
>
> I wrote a small replacement for ifelse() which avoids such unnecessary 
> evaluations (it bothered me a few times as well - so I decided to try 
> a small replacement).
>
>
> ### Example:
> x = 1:10
> FUN = list();
> FUN[[1]] = function(x, y) x*y;
> FUN[[2]] = function(x, y) x^2;
> FUN[[3]] = function(x, y) x;
> # lets run multiple conditions
> # eval.by.formula(conditions, FUN.list, ... (arguments for FUN) );
> eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, x, x-1)
> # Example 2
> eval.by.formula((x > 5 & x %% 2) ~ (x <= 5) ~ ., FUN, 2, x)
>
>
> ### Disclaimer:
> - NOT properly tested;
>
>
> The code for the function is below. Maybe someone can experiment with 
> the code and improve it further. There are a few issues / open 
> questions, like:
>
> 1.) Best Name: eval.by.formula, ifelse.formula, ...?
>
> 2.) Named arguments: not yet;
>
> 3.) Fixed values inside FUN.list
>
> 4.) Format of expression for conditions:
>
> expression(cond1, cond2, cond3) vs cond1 ~ cond2 ~ cond3 ???
>
> 5.) Code efficiency
>
> - some tests on large data sets & optimizations are warranted;
>
>
> Sincerely,
>
>
> Leonard
>
> =======
>
> The latest code is on Github:
>
> https://github.com/discoleo/R/blob/master/Stat/Tools.Formulas.R
>
> [...]
>


From drj|m|emon @end|ng |rom gm@||@com  Sat Oct  9 23:34:52 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 10 Oct 2021 08:34:52 +1100
Subject: [R] assumptions about how things are done
In-Reply-To: <029401d7bd44$e10843c0$a318cb40$@verizon.net>
References: <029401d7bd44$e10843c0$a318cb40$.ref@verizon.net>
 <029401d7bd44$e10843c0$a318cb40$@verizon.net>
Message-ID: <CA+8X3fUQvXUx0=cVvNVTv144PQrRHgHgp1iBiXk23R8V+9=71g@mail.gmail.com>

Hi Avi,
Definitely a learning moment. I may consider writing an ifElse() for
my own use and sharing it if anyone wants it.

Jim

On Sun, Oct 10, 2021 at 6:36 AM Avi Gross via R-help
<r-help at r-project.org> wrote:
>
> This is supposed to be a forum for help so general and philosophical
> discussions belong elsewhere, or nowhere.
>
>
>
> Having said that, I want to make a brief point. Both new and experienced
> people make implicit assumptions about the code they use. Often nobody looks
> at how the sausage is made. The recent discussion of ifelse() made me take a
> look and I was not thrilled.
>
>
>
> My NA?VE view was that ifelse() was implemented as a sort of loop construct.
> I mean if I have a vector of length N and perhaps a few other vectors of the
> same length, I might say:
>
>
>
> result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
> result-if-false-using-vectors)
>
>
>
> So say I want to take a vector of integers from 1 to N and make an output a
> second vector where you have either a prime number or NA. If I have a
> function called is.prime() that checks a single number and returns
> TRUE/FALSE, it might look like this:
>
>
>
> primed <- ifelse(is.prime(A, A, NA)
>
>
>
> So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
> composite becomes NA and so on.
>
>
>
> If you wrote the above using loops, it would be to range from index 1 to N
> and apply the above. There are many complications as R allows vectors to be
> longer or to be repeated as needed.
>
>
>
> What I found ifelse() as implemented to do, is sort of like this:
>
>
>
> Make a vector of the right length for the results, initially empty.
>
>
>
> Make a vector evaluating the condition so it is effectively a Boolean
> result.
>
> Calculate which indices are TRUE. Secondarily, calculate another set of
> indices that are false.
>
>
>
> Calculate ALL the THEN conditions and ditto all the ELSE conditions.
>
>
>
> Now copy into the result all the THEN values indexed by the TRUE above and
> than all the ELSE values indicated by the FALSE above.
>
>
>
> In plain English, make a result from two other results based on picking
> either one from menu A or one from menu B.
>
>
>
> That is not a bad algorithm and in a vectorized language like R, maybe even
> quite effective and efficient. It does lots of extra work as by definition
> it throws at least half away.
>
>
>
> I suspect the implementation could be made much faster by making some of it
> done internally using a language like C.
>
>
>
> But now that I know what this implementation did, I might have some qualms
> at using it in some situations. The original complaint led to other
> observations and needs and perhaps blindly using a supplied function like
> ifelse() may not be a decent solution for some needs.
>
>
>
> I note how I had to reorient my work elsewhere using a group of packages
> called the tidyverse when they added a function to allow rowwise
> manipulation of the data as compared to an ifelse-like method using all
> columns at once. There is room for many approaches and if a function may not
> be doing quite what you want, something else may better meet your needs OR
> you may want to see if you can copy the existing function and modify it for
> your own personal needs.
>
>
>
> In the case we mentioned, the goal was to avoid printing selected warnings.
> Since the function is readable, it can easily be modified in a copy to find
> what is causing the warnings and either rewrite a bit to avoid them or start
> over with perhaps your own function that tests before doing things and
> avoids tripping the condition (generating a NaN) entirely.
>
>
>
> Like may languages, R is a bit too rich. You can piggyback on the work of
> others but with some caution as they did not necessarily have you in mind
> with what they created.
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@ywong @end|ng |rom t@mu@edu  Sun Oct 10 04:39:51 2021
From: r@ywong @end|ng |rom t@mu@edu (Raymond Wong)
Date: Sat, 9 Oct 2021 21:39:51 -0500
Subject: [R] 2022 John M. Chambers Software Award
In-Reply-To: <c303bf24-2935-45bd-a2c8-eee89ecc3ae6@Spark>
References: <c303bf24-2935-45bd-a2c8-eee89ecc3ae6@Spark>
Message-ID: <5682efef-3a6f-44bc-9d42-fd8ad4306855@Spark>

Dear R-help listers,

The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery (ACM) presented the ACM Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student.

Please visit?http://asa.stat.uconn.edu?for more information.

Best regards,

Raymond Wong

Awards Chair
ASA Section on Statistical Computing
ASA Section on Statistical Graphics

Associate Professor
Department of Statistics
Texas A&M University




	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sun Oct 10 08:27:27 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 10 Oct 2021 19:27:27 +1300
Subject: [R] assumptions about how things are done
In-Reply-To: <029401d7bd44$e10843c0$a318cb40$@verizon.net>
References: <029401d7bd44$e10843c0$a318cb40$.ref@verizon.net>
 <029401d7bd44$e10843c0$a318cb40$@verizon.net>
Message-ID: <CABcYAdKDerXkaUKTZn58nYRTtN+zSprDGTtRiE=wZ6Mauy+rbQ@mail.gmail.com>

Colour me confused.
if (...) { ... } else { ... }
is a control structure.  It requires the test to evaluate to a single
logical value,
then it evaluates one choice completely and the other not at all.
It is special syntax.

ifelse(..., ..., ...) is not a control structure.  It is not special
syntax.  It is a
normal function call, and it evaluates its arguments and expands them to
a common length just like "+" or, more to the point, just like "&".

So why do we have people expecting a normal function call to do special
control structure magic?

Leaving aside the extending-to-a-common-length part, it's
ifelse <- function (test, true.part, false.part) {
    false.part[test] <- true.part[test]
    false.part
}

Why is it so hard to understand that there is nothing special to
understand here?

On Sun, 10 Oct 2021 at 08:36, Avi Gross via R-help <r-help at r-project.org> wrote:
>
> This is supposed to be a forum for help so general and philosophical
> discussions belong elsewhere, or nowhere.
>
>
>
> Having said that, I want to make a brief point. Both new and experienced
> people make implicit assumptions about the code they use. Often nobody looks
> at how the sausage is made. The recent discussion of ifelse() made me take a
> look and I was not thrilled.
>
>
>
> My NA?VE view was that ifelse() was implemented as a sort of loop construct.
> I mean if I have a vector of length N and perhaps a few other vectors of the
> same length, I might say:
>
>
>
> result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
> result-if-false-using-vectors)
>
>
>
> So say I want to take a vector of integers from 1 to N and make an output a
> second vector where you have either a prime number or NA. If I have a
> function called is.prime() that checks a single number and returns
> TRUE/FALSE, it might look like this:
>
>
>
> primed <- ifelse(is.prime(A, A, NA)
>
>
>
> So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
> composite becomes NA and so on.
>
>
>
> If you wrote the above using loops, it would be to range from index 1 to N
> and apply the above. There are many complications as R allows vectors to be
> longer or to be repeated as needed.
>
>
>
> What I found ifelse() as implemented to do, is sort of like this:
>
>
>
> Make a vector of the right length for the results, initially empty.
>
>
>
> Make a vector evaluating the condition so it is effectively a Boolean
> result.
>
> Calculate which indices are TRUE. Secondarily, calculate another set of
> indices that are false.
>
>
>
> Calculate ALL the THEN conditions and ditto all the ELSE conditions.
>
>
>
> Now copy into the result all the THEN values indexed by the TRUE above and
> than all the ELSE values indicated by the FALSE above.
>
>
>
> In plain English, make a result from two other results based on picking
> either one from menu A or one from menu B.
>
>
>
> That is not a bad algorithm and in a vectorized language like R, maybe even
> quite effective and efficient. It does lots of extra work as by definition
> it throws at least half away.
>
>
>
> I suspect the implementation could be made much faster by making some of it
> done internally using a language like C.
>
>
>
> But now that I know what this implementation did, I might have some qualms
> at using it in some situations. The original complaint led to other
> observations and needs and perhaps blindly using a supplied function like
> ifelse() may not be a decent solution for some needs.
>
>
>
> I note how I had to reorient my work elsewhere using a group of packages
> called the tidyverse when they added a function to allow rowwise
> manipulation of the data as compared to an ifelse-like method using all
> columns at once. There is room for many approaches and if a function may not
> be doing quite what you want, something else may better meet your needs OR
> you may want to see if you can copy the existing function and modify it for
> your own personal needs.
>
>
>
> In the case we mentioned, the goal was to avoid printing selected warnings.
> Since the function is readable, it can easily be modified in a copy to find
> what is causing the warnings and either rewrite a bit to avoid them or start
> over with perhaps your own function that tests before doing things and
> avoids tripping the condition (generating a NaN) entirely.
>
>
>
> Like may languages, R is a bit too rich. You can piggyback on the work of
> others but with some caution as they did not necessarily have you in mind
> with what they created.
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m|n@h@|| @end|ng |rom um|ch@edu  Sun Oct 10 10:18:13 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Sun, 10 Oct 2021 11:18:13 +0300
Subject: [R] assumptions about how things are done
In-Reply-To: <CABcYAdKDerXkaUKTZn58nYRTtN+zSprDGTtRiE=wZ6Mauy+rbQ@mail.gmail.com>
References: <029401d7bd44$e10843c0$a318cb40$.ref@verizon.net>
 <029401d7bd44$e10843c0$a318cb40$@verizon.net>
 <CABcYAdKDerXkaUKTZn58nYRTtN+zSprDGTtRiE=wZ6Mauy+rbQ@mail.gmail.com>
Message-ID: <2933100.1633853893@apollo2.minshall.org>

hi, Richard,

> ifelse(..., ..., ...) is not a control structure.  It is not special
> syntax.  It is a normal function call, and it evaluates its arguments
> and expands them to a common length just like "+" or, more to the
> point, just like "&".
>
> So why do we have people expecting a normal function call to do
> special control structure magic?
>
> Leaving aside the extending-to-a-common-length part, it's
> ifelse <- function (test, true.part, false.part) {
>     false.part[test] <- true.part[test]
>     false.part
> }
>
> Why is it so hard to understand that there is nothing special to
> understand here?

i wonder if possibly because features like non-standard evaluation lead
many of us to conclude there may/should/could be magic at all levels?

cheers, Greg


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Oct 10 10:28:43 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 10 Oct 2021 21:28:43 +1300
Subject: [R] assumptions about how things are done
In-Reply-To: <CABcYAdKDerXkaUKTZn58nYRTtN+zSprDGTtRiE=wZ6Mauy+rbQ@mail.gmail.com>
References: <029401d7bd44$e10843c0$a318cb40$.ref@verizon.net>
 <029401d7bd44$e10843c0$a318cb40$@verizon.net>
 <CABcYAdKDerXkaUKTZn58nYRTtN+zSprDGTtRiE=wZ6Mauy+rbQ@mail.gmail.com>
Message-ID: <20211010212843.5c7691c2@rolf-Latitude-E7470>


On Sun, 10 Oct 2021 19:27:27 +1300
"Richard O'Keefe" <raoknz at gmail.com> wrote:

<SNIP>

> Why is it so hard to understand that there is nothing special to
> understand here?

<SNIP>

Fortune nomination.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Oct 11 11:15:27 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 11 Oct 2021 09:15:27 +0000
Subject: [R] unexpected behavior in apply
In-Reply-To: <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
 <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
Message-ID: <a71107e9441e476db477fe28acfff8d1@SRVEXCHCM1302.precheza.cz>

Hi

it is not surprising at all.

from apply documentation

Arguments
X	
an array, including a matrix.

data.frame is not matrix or array (even if it rather resembles one)

So if you put a cake into oven you cannot expect getting fried potatoes from
it.

For data frames sapply or lapply is preferable as it is designed for lists
and data frame is (again from documentation)

A data frame is a list of variables of the same number of rows with unique
row names, given class "data.frame".

> sapply(d,function(x) all(x[!is.na(x)]<=3))
   d1    d2    d3 
FALSE  TRUE FALSE 

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jiefei Wang
> Sent: Friday, October 8, 2021 8:22 PM
> To: Derickson, Ryan, VHA NCOD <Ryan.Derickson at va.gov>
> Cc: r-help at r-project.org
> Subject: Re: [R] unexpected behavior in apply
> 
> Ok, it turns out that this is documented, even though it looks surprising.
> 
> First of all, the apply function will try to convert any object with the
dim
> attribute to a matrix(my intuition agrees with you that there should be no
> conversion), so the first step of the apply function is
> 
> > as.matrix.data.frame(d)
>      d1  d2  d3
> [1,] "a" "1" NA
> [2,] "b" "2" NA
> [3,] "c" "3" " 6"
> 
> Since the data frame `d` is a mixture of character and non-character
values,
> the non-character value will be converted to the character using the
function
> `format`. However, the problem is that the NA value will also be formatted
to
> the character
> 
> > format(c(NA, 6))
> [1] "NA" " 6"
> 
> That's where the space comes from. It is purely for making the result
pretty...
> The character NA will be removed later, but the space is not stripped. I
would
> say this is not a good design, and it might be worth not including the NA
value
> in the format function. At the current stage, I will suggest using the
function
> `lapply` to do what you want.
> 
> > lapply(d, FUN=function(x)all(x[!is.na(x)] <= 3))
> $d1
> [1] FALSE
> $d2
> [1] TRUE
> $d3
> [1] FALSE
> 
> Everything should work as you expect.
> 
> Best,
> Jiefei
> 
> On Sat, Oct 9, 2021 at 2:03 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> > Hi,
> >
> > I guess this can tell you what happens behind the scene
> >
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > > apply(d, 2, FUN=function(x)x)
> >      d1  d2  d3
> > [1,] "a" "1" NA
> > [2,] "b" "2" NA
> > [3,] "c" "3" " 6"
> > > "a"<=3
> > [1] FALSE
> > > "2"<=3
> > [1] TRUE
> > > "6"<=3
> > [1] FALSE
> >
> > Note that there is an additional space in the character value " 6",
> > that's why your comparison fails. I do not understand why but this
> > might be a bug in R
> >
> > Best,
> > Jiefei
> >
> > On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > I'm seeing unexpected behavior when using apply() compared to a for
> loop when a character vector is part of the data subjected to the apply
> statement. Below, I check whether all non-missing values are <= 3. If I
> include a character column, apply incorrectly returns TRUE for d3. If I
only
> pass the numeric columns to apply, it is correct for d3. If I use a for
loop, it is
> correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(NA,NA,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1 NA
> > > 2  b  2 NA
> > > 3  c  3  6
> > > >
> > > > # results are incorrect
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE  TRUE
> > > >
> > > > # results are correct
> > > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d2    d3
> > >  TRUE FALSE
> > > >
> > > > # results are correct
> > > > for(i in names(d)){
> > > +   print(all(d[!is.na(d[,i]),i] <= 3)) }
> > > [1] FALSE
> > > [1] TRUE
> > > [1] FALSE
> > >
> > >
> > > Finally, if I remove the NA values from d3 and include the character
> column in apply, it is correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(4,5,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1  4
> > > 2  b  2  5
> > > 3  c  3  6
> > > >
> > > > # results are correct
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE FALSE
> > >
> > >
> > > Can someone help me understand what's happening?
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Oct 11 13:46:36 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 11 Oct 2021 13:46:36 +0200
Subject: [R] Missing text in lattice key legend
Message-ID: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>

Hello,
I am drawing some data with lattice using:
```
library(lattice)
COLS = c("gold", "forestgreen", "darkslategray3", "purple")
xyplot(Value ~ Concentration,
       group = Substance, data = inf_avg,
       pch = 16, cex = 1.2, type = "b",
       xlab=expression(bold(paste("Concentration (", mu, "M)"))),
       ylab=expression(bold("Infection rate")),
       col=COLS,
       scales = list(x = list(log = 10, at=c(unique(inf_avg$Concentration))
                              )
                     ),
       key = list(space="top", columns=4, col = "black",
                       points=list(pch=c(16, 16, 16, 16),
                                   col=COLS,
                                   text=list(c("6-PN", "8-PN", "IX", "XN")
                                            )
                                   )
                  ),
       panel = function(x,y) {
         panel.xyplot(x,y)
         errbar()
       }
)
```
It all works but the legend only shows the colored dots, there is no
text. Is it something missing from the syntax?
Thanks

-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Oct 11 14:11:06 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 11 Oct 2021 14:11:06 +0200
Subject: [R] How to add error bars to lattice xyplot
Message-ID: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>

Hello,
I am trying to plot data using lattice. The basic plot works:
```
Substance = rep(c("A", "B", "C", "D"),4)
Concentration = rep(1:4,4),
Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
          92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
          25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
          0.06333333)
df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
14.0874424,
       38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
       0.2498666,  8.4537585, 10.8058456,  0.1096966)
dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)

library(lattice)
COLS = c("gold", "forestgreen", "darkslategray3", "purple")
xyplot(Value ~ Concentration,
       group = Substance, data = df,
       pch = 16, cex = 1.2, type = "b",
       xlab=expression(bold(paste("Concentration (", mu, "M)"))),
       ylab=expression(bold("Infection rate")),
       col=COLS,
       scales = list(x = list(log = 10, at=c(unique(df$Concentration))
       )
       ),
       key = list(space="top", columns=4, col = "black",
                  points=list(pch=c(16, 16, 16, 16),
                              col=COLS,
                              text=list(c("6-PN", "8-PN", "IX", "XN")
                              )
                  )
       )

)
```
but how do I add the error bars?
I tried with
```
xyplot(Value ~ Concentration,
       group = Substance, data = df,
       pch = 16, cex = 1.2, type = "b",
       xlab=expression(bold(paste("Concentration (", mu, "M)"))),
       ylab=expression(bold("Infection rate")),
       col=COLS,
       scales = list(x = list(log = 10, at=c(unique(df$Concentration))
       )
       ),
       key = list(space="top", columns=4, col = "black",
                  points=list(pch=c(16, 16, 16, 16),
                              col=COLS,
                              text=list(c("6-PN", "8-PN", "IX", "XN")
                              )
                  )
       ),
       panel = function (x,y,) {
         panel.segments(x0 = df$Concentration, x1 = df$Concentration,
                        y0 = df$Value - dfsd$Value,
                        y1 = df$Value + dfsd$Value,
                        col = COLS)
       }

)
```
but the bars are plotted outside the graph.
What is the correct syntax? can I use raw data instead of making the
mean and std dev separately?
Thanks

-- 
Best regards,
Luigi


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Mon Oct 11 14:18:54 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Mon, 11 Oct 2021 17:48:54 +0530
Subject: [R] Missing text in lattice key legend
In-Reply-To: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
References: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
Message-ID: <CADfFDC6VQfQZutNsRhSgd64qeGMGAtxxHG3xPfJDLjwAFJu82w@mail.gmail.com>

On Mon, Oct 11, 2021 at 5:17 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I am drawing some data with lattice using:
> ```
> library(lattice)
> COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> xyplot(Value ~ Concentration,
>        group = Substance, data = inf_avg,
>        pch = 16, cex = 1.2, type = "b",
>        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>        ylab=expression(bold("Infection rate")),
>        col=COLS,
>        scales = list(x = list(log = 10, at=c(unique(inf_avg$Concentration))
>                               )
>                      ),
>        key = list(space="top", columns=4, col = "black",
>                        points=list(pch=c(16, 16, 16, 16),
>                                    col=COLS,
>                                    text=list(c("6-PN", "8-PN", "IX", "XN")
>                                             )
>                                    )
>                   ),
>        panel = function(x,y) {
>          panel.xyplot(x,y)
>          errbar()
>        }
> )
> ```
> It all works but the legend only shows the colored dots, there is no
> text. Is it something missing from the syntax?

Your text component is nested inside the points component. I think you
want it outside, e.g.,

xyplot(1 ~ 1,
       key = list(space="top", columns=4, col = "black",
                  points=list(pch=c(16, 16, 16, 16),
                              col=COLS),
                  text=list(c("6-PN", "8-PN", "IX", "XN"))
                  ))

Best,
-Deepayan

> Thanks
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Oct 11 14:38:36 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 11 Oct 2021 14:38:36 +0200
Subject: [R] Missing text in lattice key legend
In-Reply-To: <CADfFDC6VQfQZutNsRhSgd64qeGMGAtxxHG3xPfJDLjwAFJu82w@mail.gmail.com>
References: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
 <CADfFDC6VQfQZutNsRhSgd64qeGMGAtxxHG3xPfJDLjwAFJu82w@mail.gmail.com>
Message-ID: <CAMk+s2R=kUhiCze_LWqhLw6Ee+oH6h_uwgDyTVkkPzTAfsh4VQ@mail.gmail.com>

Awesome, thanks!

On Mon, Oct 11, 2021 at 2:19 PM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Mon, Oct 11, 2021 at 5:17 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I am drawing some data with lattice using:
> > ```
> > library(lattice)
> > COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> > xyplot(Value ~ Concentration,
> >        group = Substance, data = inf_avg,
> >        pch = 16, cex = 1.2, type = "b",
> >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> >        ylab=expression(bold("Infection rate")),
> >        col=COLS,
> >        scales = list(x = list(log = 10, at=c(unique(inf_avg$Concentration))
> >                               )
> >                      ),
> >        key = list(space="top", columns=4, col = "black",
> >                        points=list(pch=c(16, 16, 16, 16),
> >                                    col=COLS,
> >                                    text=list(c("6-PN", "8-PN", "IX", "XN")
> >                                             )
> >                                    )
> >                   ),
> >        panel = function(x,y) {
> >          panel.xyplot(x,y)
> >          errbar()
> >        }
> > )
> > ```
> > It all works but the legend only shows the colored dots, there is no
> > text. Is it something missing from the syntax?
>
> Your text component is nested inside the points component. I think you
> want it outside, e.g.,
>
> xyplot(1 ~ 1,
>        key = list(space="top", columns=4, col = "black",
>                   points=list(pch=c(16, 16, 16, 16),
>                               col=COLS),
>                   text=list(c("6-PN", "8-PN", "IX", "XN"))
>                   ))
>
> Best,
> -Deepayan
>
> > Thanks
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Mon Oct 11 15:55:54 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Mon, 11 Oct 2021 19:25:54 +0530
Subject: [R] How to add error bars to lattice xyplot
In-Reply-To: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>
References: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>
Message-ID: <CADfFDC4bYN4cv87AcddwdFL7Pg2u6bCOZrNHuKB7Y3anisF4Jw@mail.gmail.com>

On Mon, Oct 11, 2021 at 5:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I am trying to plot data using lattice. The basic plot works:
> ```
> Substance = rep(c("A", "B", "C", "D"),4)
> Concentration = rep(1:4,4),
> Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
>           92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
>           25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
>           0.06333333)
> df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
> Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
> 14.0874424,
>        38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
>        0.2498666,  8.4537585, 10.8058456,  0.1096966)
> dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
>
> library(lattice)
> COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> xyplot(Value ~ Concentration,
>        group = Substance, data = df,
>        pch = 16, cex = 1.2, type = "b",
>        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>        ylab=expression(bold("Infection rate")),
>        col=COLS,
>        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>        )
>        ),
>        key = list(space="top", columns=4, col = "black",
>                   points=list(pch=c(16, 16, 16, 16),
>                               col=COLS,
>                               text=list(c("6-PN", "8-PN", "IX", "XN")
>                               )
>                   )
>        )
>
> )
> ```
> but how do I add the error bars?
> I tried with
> ```
> xyplot(Value ~ Concentration,
>        group = Substance, data = df,
>        pch = 16, cex = 1.2, type = "b",
>        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>        ylab=expression(bold("Infection rate")),
>        col=COLS,
>        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>        )
>        ),
>        key = list(space="top", columns=4, col = "black",
>                   points=list(pch=c(16, 16, 16, 16),
>                               col=COLS,
>                               text=list(c("6-PN", "8-PN", "IX", "XN")
>                               )
>                   )
>        ),
>        panel = function (x,y,) {
>          panel.segments(x0 = df$Concentration, x1 = df$Concentration,
>                         y0 = df$Value - dfsd$Value,
>                         y1 = df$Value + dfsd$Value,
>                         col = COLS)
>        }
>
> )
> ```
> but the bars are plotted outside the graph.

You need to apply the log-transformation yourself, e.g.,

         panel.segments(x0 = log10(df$Concentration), x1 =
log10(df$Concentration),

But this is not really a scalable approach. You should check if
Hmisc::xYplot suits your needs:

https://search.r-project.org/CRAN/refmans/Hmisc/html/xYplot.html

Best,
-Deepayan

> What is the correct syntax? can I use raw data instead of making the
> mean and std dev separately?
> Thanks
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Mon Oct 11 16:22:25 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 11 Oct 2021 14:22:25 +0000
Subject: [R] [External]  Missing text in lattice key legend
In-Reply-To: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
References: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
Message-ID: <BL1PR11MB523999CF72669E54D13EE543D2B59@BL1PR11MB5239.namprd11.prod.outlook.com>

looks like a paren outof place.  the text is inside the points. it should be parallel to the points in the calling sequence.

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Luigi Marongiu <marongiu.luigi at gmail.com>
Sent: Monday, October 11, 2021 7:46:36 AM
To: r-help <r-help at r-project.org>
Subject: [External] [R] Missing text in lattice key legend

Hello,
I am drawing some data with lattice using:
```
library(lattice)
COLS = c("gold", "forestgreen", "darkslategray3", "purple")
xyplot(Value ~ Concentration,
       group = Substance, data = inf_avg,
       pch = 16, cex = 1.2, type = "b",
       xlab=expression(bold(paste("Concentration (", mu, "M)"))),
       ylab=expression(bold("Infection rate")),
       col=COLS,
       scales = list(x = list(log = 10, at=c(unique(inf_avg$Concentration))
                              )
                     ),
       key = list(space="top", columns=4, col = "black",
                       points=list(pch=c(16, 16, 16, 16),
                                   col=COLS,
                                   text=list(c("6-PN", "8-PN", "IX", "XN")
                                            )
                                   )
                  ),
       panel = function(x,y) {
         panel.xyplot(x,y)
         errbar()
       }
)
```
It all works but the legend only shows the colored dots, there is no
text. Is it something missing from the syntax?
Thanks

--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7C3f303633d643499924e208d98cacdaef%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637695496888670932%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=98vQNMB7OcS%2B2R73ZMngEeg%2BP6PeP3oCAOUDHxs9SU8%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7C3f303633d643499924e208d98cacdaef%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637695496888670932%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=1yzXmD57qql7UXEKNqdK8Iq1vhfkUYf%2BpX8gvfvD3p0%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From JH@rm@e @end|ng |rom roku@com  Mon Oct 11 17:08:03 2021
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Mon, 11 Oct 2021 15:08:03 +0000
Subject: [R] assumptions about how things are done
Message-ID: <C9330D44-9671-438C-9FC2-5F0CC11C8C32@roku.com>

As noted by Richard O'Keefe, what usually happens in an R function is that any argument is evaluated either in its entirety or not at all. A few functions use substitute or similar trickery, but then expectations should be documented. I can understand that you want something like ifelse(y>x,x/y,z) to run without warning about division by zero, but how would that be implemented in general? Even a subexpression as simple as f(a,b) presents a problem: you want f(a,b)[cond], but you don't know how the function f works. It might be just a vector operation (and then perhaps f(a[cond],b[cond]) is what we want), or it might return a+rev(b). Avi Gross correctly notes that the implementation is not what he wants, but I think that what he wants is possible only in special cases.

Regards,
Jorgen Harmse. 

?

    Message: 2
    Date: Sat, 9 Oct 2021 15:35:55 -0400
    From: "Avi Gross" <avigross at verizon.net>
    To: <r-help at r-project.org>
    Subject: [R] assumptions about how things are done
    Message-ID: <029401d7bd44$e10843c0$a318cb40$@verizon.net>
    Content-Type: text/plain; charset="utf-8"

    This is supposed to be a forum for help so general and philosophical
    discussions belong elsewhere, or nowhere.



    Having said that, I want to make a brief point. Both new and experienced
    people make implicit assumptions about the code they use. Often nobody looks
    at how the sausage is made. The recent discussion of ifelse() made me take a
    look and I was not thrilled.



    My NA?VE view was that ifelse() was implemented as a sort of loop construct.
    I mean if I have a vector of length N and perhaps a few other vectors of the
    same length, I might say:



    result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
    result-if-false-using-vectors)



    So say I want to take a vector of integers from 1 to N and make an output a
    second vector where you have either a prime number or NA. If I have a
    function called is.prime() that checks a single number and returns
    TRUE/FALSE, it might look like this:



    primed <- ifelse(is.prime(A, A, NA)



    So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
    composite becomes NA and so on.



    If you wrote the above using loops, it would be to range from index 1 to N
    and apply the above. There are many complications as R allows vectors to be
    longer or to be repeated as needed.



    What I found ifelse() as implemented to do, is sort of like this:



    Make a vector of the right length for the results, initially empty.



    Make a vector evaluating the condition so it is effectively a Boolean
    result.

    Calculate which indices are TRUE. Secondarily, calculate another set of
    indices that are false.



    Calculate ALL the THEN conditions and ditto all the ELSE conditions.



    Now copy into the result all the THEN values indexed by the TRUE above and
    than all the ELSE values indicated by the FALSE above.



    In plain English, make a result from two other results based on picking
    either one from menu A or one from menu B.



    That is not a bad algorithm and in a vectorized language like R, maybe even
    quite effective and efficient. It does lots of extra work as by definition
    it throws at least half away.



    I suspect the implementation could be made much faster by making some of it
    done internally using a language like C.



    But now that I know what this implementation did, I might have some qualms
    at using it in some situations. The original complaint led to other
    observations and needs and perhaps blindly using a supplied function like
    ifelse() may not be a decent solution for some needs.



    I note how I had to reorient my work elsewhere using a group of packages
    called the tidyverse when they added a function to allow rowwise
    manipulation of the data as compared to an ifelse-like method using all
    columns at once. There is room for many approaches and if a function may not
    be doing quite what you want, something else may better meet your needs OR
    you may want to see if you can copy the existing function and modify it for
    your own personal needs.



    In the case we mentioned, the goal was to avoid printing selected warnings.
    Since the function is readable, it can easily be modified in a copy to find
    what is causing the warnings and either rewrite a bit to avoid them or start
    over with perhaps your own function that tests before doing things and
    avoids tripping the condition (generating a NaN) entirely.



    Like may languages, R is a bit too rich. You can piggyback on the work of
    others but with some caution as they did not necessarily have you in mind
    with what they created.






    	[[alternative HTML version deleted]]





    ------------------------------

    Message: 4
    Date: Sun, 10 Oct 2021 08:34:52 +1100
    From: Jim Lemon <drjimlemon at gmail.com>
    To: Avi Gross <avigross at verizon.net>
    Cc: r-help mailing list <r-help at r-project.org>
    Subject: Re: [R] assumptions about how things are done
    Message-ID:
    	<CA+8X3fUQvXUx0=cVvNVTv144PQrRHgHgp1iBiXk23R8V+9=71g at mail.gmail.com>
    Content-Type: text/plain; charset="utf-8"

    Hi Avi,
    Definitely a learning moment. I may consider writing an ifElse() for
    my own use and sharing it if anyone wants it.

    Jim

    On Sun, Oct 10, 2021 at 6:36 AM Avi Gross via R-help
    <r-help at r-project.org> wrote:
    >
    > This is supposed to be a forum for help so general and philosophical
    > discussions belong elsewhere, or nowhere.
    >
    >
    >
    > Having said that, I want to make a brief point. Both new and experienced
    > people make implicit assumptions about the code they use. Often nobody looks
    > at how the sausage is made. The recent discussion of ifelse() made me take a
    > look and I was not thrilled.
    >
    >
    >
    > My NA?VE view was that ifelse() was implemented as a sort of loop construct.
    > I mean if I have a vector of length N and perhaps a few other vectors of the
    > same length, I might say:
    >
    >
    >
    > result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
    > result-if-false-using-vectors)
    >
    >
    >
    > So say I want to take a vector of integers from 1 to N and make an output a
    > second vector where you have either a prime number or NA. If I have a
    > function called is.prime() that checks a single number and returns
    > TRUE/FALSE, it might look like this:
    >
    >
    >
    > primed <- ifelse(is.prime(A, A, NA)
    >
    >
    >
    > So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
    > composite becomes NA and so on.
    >
    >
    >
    > If you wrote the above using loops, it would be to range from index 1 to N
    > and apply the above. There are many complications as R allows vectors to be
    > longer or to be repeated as needed.
    >
    >
    >
    > What I found ifelse() as implemented to do, is sort of like this:
    >
    >
    >
    > Make a vector of the right length for the results, initially empty.
    >
    >
    >
    > Make a vector evaluating the condition so it is effectively a Boolean
    > result.
    >
    > Calculate which indices are TRUE. Secondarily, calculate another set of
    > indices that are false.
    >
    >
    >
    > Calculate ALL the THEN conditions and ditto all the ELSE conditions.
    >
    >
    >
    > Now copy into the result all the THEN values indexed by the TRUE above and
    > than all the ELSE values indicated by the FALSE above.
    >
    >
    >
    > In plain English, make a result from two other results based on picking
    > either one from menu A or one from menu B.
    >
    >
    >
    > That is not a bad algorithm and in a vectorized language like R, maybe even
    > quite effective and efficient. It does lots of extra work as by definition
    > it throws at least half away.
    >
    >
    >
    > I suspect the implementation could be made much faster by making some of it
    > done internally using a language like C.
    >
    >
    >
    > But now that I know what this implementation did, I might have some qualms
    > at using it in some situations. The original complaint led to other
    > observations and needs and perhaps blindly using a supplied function like
    > ifelse() may not be a decent solution for some needs.
    >
    >
    >
    > I note how I had to reorient my work elsewhere using a group of packages
    > called the tidyverse when they added a function to allow rowwise
    > manipulation of the data as compared to an ifelse-like method using all
    > columns at once. There is room for many approaches and if a function may not
    > be doing quite what you want, something else may better meet your needs OR
    > you may want to see if you can copy the existing function and modify it for
    > your own personal needs.
    >
    >
    >
    > In the case we mentioned, the goal was to avoid printing selected warnings.
    > Since the function is readable, it can easily be modified in a copy to find
    > what is causing the warnings and either rewrite a bit to avoid them or start
    > over with perhaps your own function that tests before doing things and
    > avoids tripping the condition (generating a NaN) entirely.
    >
    >
    >
    > Like may languages, R is a bit too rich. You can piggyback on the work of
    > others but with some caution as they did not necessarily have you in mind
    > with what they created.
    >
    >
    >
    >
    >
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.





From M|ke@Conk||n @end|ng |rom g|k@com  Mon Oct 11 18:24:01 2021
From: M|ke@Conk||n @end|ng |rom g|k@com (Conklin, Mike (GfK))
Date: Mon, 11 Oct 2021 16:24:01 +0000
Subject: [R] How to read from a file within a gzipped file
Message-ID: <CWXP123MB4952F49DC4D769102F4A877899B59@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>


Hi have a large number of zipped files, each containing 3 xml files that I want to read.  I would like to read one of the xml files without having to decompress each zip file first.

If I run gzfile(path2zipped file) I get

A connection with
description "X:/Mkt Science/Projects/ tv/202109.ext/tsa.20210901.xml.zip"
class       "gzfile"
mode        "rb"
text        "text"
opened      "closed"
can read    "yes"
can write   "yes"

Within that zipped file I want to read from

"20210901.socioDemos.a.xml" which is one of 3 xml files within the zip file



Is there a way to return a connection to a single file within a zipped file using gzfile or some other method.



--
W. Michael Conklin
Executive Vice President
Marketing & Data Sciences - North America
GfK
mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
M +1 612 567 8287
www.gfk.com<http://www.gfk.com/>


	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Oct 11 19:01:55 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 11 Oct 2021 20:01:55 +0300
Subject: [R] How to read from a file within a gzipped file
In-Reply-To: <CWXP123MB4952F49DC4D769102F4A877899B59@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>
References: <CWXP123MB4952F49DC4D769102F4A877899B59@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <20211011200155.0b3a6566@Tarkus>

On Mon, 11 Oct 2021 16:24:01 +0000
"Conklin, Mike (GfK) via R-help" <r-help at r-project.org> wrote:

> Is there a way to return a connection to a single file within a
> zipped file using gzfile or some other method.

Sure! Use unz() instead of gzfile().

-- 
Best regards,
Ivan


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 11 19:16:52 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 11 Oct 2021 18:16:52 +0100
Subject: [R] How to read from a file within a gzipped file
In-Reply-To: <CWXP123MB4952F49DC4D769102F4A877899B59@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>
References: <CWXP123MB4952F49DC4D769102F4A877899B59@CWXP123MB4952.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <f4ef7179-e2ee-e694-8c48-74a38877c9a3@sapo.pt>

Hello,

You can create a connection and read from it.

desc <- "X:/Mkt Science/Projects/ tv/202109.ext/tsa.20210901.xml.zip"
fname <- "20210901.socioDemos.a.xml"
zz <- unz(desc, fname)


Now read from zz. Example:


xml <- XML::xmlParse(zz)


Hope this helps,

Rui Barradas

?s 17:24 de 11/10/21, Conklin, Mike (GfK) via R-help escreveu:
> 
> Hi have a large number of zipped files, each containing 3 xml files that I want to read.  I would like to read one of the xml files without having to decompress each zip file first.
> 
> If I run gzfile(path2zipped file) I get
> 
> A connection with
> description "X:/Mkt Science/Projects/ tv/202109.ext/tsa.20210901.xml.zip"
> class       "gzfile"
> mode        "rb"
> text        "text"
> opened      "closed"
> can read    "yes"
> can write   "yes"
> 
> Within that zipped file I want to read from
> 
> "20210901.socioDemos.a.xml" which is one of 3 xml files within the zip file
> 
> 
> 
> Is there a way to return a connection to a single file within a zipped file using gzfile or some other method.
> 
> 
> 
> --
> W. Michael Conklin
> Executive Vice President
> Marketing & Data Sciences - North America
> GfK
> mike.conklin at gfk.com<mailto:mike.conklin at gfk.com>
> M +1 612 567 8287
> www.gfk.com<http://www.gfk.com/>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Oct 11 20:58:08 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 11 Oct 2021 20:58:08 +0200
Subject: [R] [External]  Missing text in lattice key legend
In-Reply-To: <BL1PR11MB523999CF72669E54D13EE543D2B59@BL1PR11MB5239.namprd11.prod.outlook.com>
References: <CAMk+s2SWKE1a8aB2wyTR9q8HQhQVpsBUksWDo2NzTurVywT+ZA@mail.gmail.com>
 <BL1PR11MB523999CF72669E54D13EE543D2B59@BL1PR11MB5239.namprd11.prod.outlook.com>
Message-ID: <CAMk+s2Tv08yYj1aVH78SukjbotQm5yTWGYEP-fZ5EQebXAteMQ@mail.gmail.com>

Yes, that was the case. Now it works! Thanks

On Mon, Oct 11, 2021 at 4:22 PM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> looks like a paren outof place.  the text is inside the points. it should be parallel to the points in the calling sequence.
>
> Get Outlook for iOS
> ________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Luigi Marongiu <marongiu.luigi at gmail.com>
> Sent: Monday, October 11, 2021 7:46:36 AM
> To: r-help <r-help at r-project.org>
> Subject: [External] [R] Missing text in lattice key legend
>
> Hello,
> I am drawing some data with lattice using:
> ```
> library(lattice)
> COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> xyplot(Value ~ Concentration,
>        group = Substance, data = inf_avg,
>        pch = 16, cex = 1.2, type = "b",
>        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>        ylab=expression(bold("Infection rate")),
>        col=COLS,
>        scales = list(x = list(log = 10, at=c(unique(inf_avg$Concentration))
>                               )
>                      ),
>        key = list(space="top", columns=4, col = "black",
>                        points=list(pch=c(16, 16, 16, 16),
>                                    col=COLS,
>                                    text=list(c("6-PN", "8-PN", "IX", "XN")
>                                             )
>                                    )
>                   ),
>        panel = function(x,y) {
>          panel.xyplot(x,y)
>          errbar()
>        }
> )
> ```
> It all works but the legend only shows the colored dots, there is no
> text. Is it something missing from the syntax?
> Thanks
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7C3f303633d643499924e208d98cacdaef%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637695496888670932%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=98vQNMB7OcS%2B2R73ZMngEeg%2BP6PeP3oCAOUDHxs9SU8%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7C3f303633d643499924e208d98cacdaef%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637695496888670932%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=1yzXmD57qql7UXEKNqdK8Iq1vhfkUYf%2BpX8gvfvD3p0%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Oct 11 21:24:13 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 11 Oct 2021 21:24:13 +0200
Subject: [R] How to add error bars to lattice xyplot
In-Reply-To: <CADfFDC4bYN4cv87AcddwdFL7Pg2u6bCOZrNHuKB7Y3anisF4Jw@mail.gmail.com>
References: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>
 <CADfFDC4bYN4cv87AcddwdFL7Pg2u6bCOZrNHuKB7Y3anisF4Jw@mail.gmail.com>
Message-ID: <CAMk+s2Qo6gOzDsbtykvDzxF6hGGo5TSw9VBu8zMhyereJMmvbQ@mail.gmail.com>

Thanks,
now I got the bars (although without notch) but I lost the main plot:
```
xyplot(Value ~ Concentration,
group = Substance, data = df,
pch = 16, cex = 1.2, type = "b",
xlab=expression(bold(paste("Concentration (", mu, "M)"))),
ylab=expression(bold("Infection rate")),
col=COLS,
scales = list(x = list(log = 10, at=c(unique(df$Concentration))
)
),
key = list(space="top", columns=4, col = "black",
points=list(pch=c(16, 16, 16, 16),
col=COLS
),
text=list(c("A", "B", "C", "D")
)
),
panel = function (x,y) {
panel.segments(x0 = log10(df$Concentration),
x1 = log10(df$Concentration),
y0 = df$Value - dfsd$Value,
y1 = df$Value + dfsd$Value,
col = COLS)
}

)
```
I will check xYplot out, I think it is the tool for the job.

On Mon, Oct 11, 2021 at 3:56 PM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Mon, Oct 11, 2021 at 5:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I am trying to plot data using lattice. The basic plot works:
> > ```
> > Substance = rep(c("A", "B", "C", "D"),4)
> > Concentration = rep(1:4,4),
> > Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
> >           92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
> >           25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
> >           0.06333333)
> > df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
> > Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
> > 14.0874424,
> >        38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
> >        0.2498666,  8.4537585, 10.8058456,  0.1096966)
> > dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
> >
> > library(lattice)
> > COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> > xyplot(Value ~ Concentration,
> >        group = Substance, data = df,
> >        pch = 16, cex = 1.2, type = "b",
> >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> >        ylab=expression(bold("Infection rate")),
> >        col=COLS,
> >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> >        )
> >        ),
> >        key = list(space="top", columns=4, col = "black",
> >                   points=list(pch=c(16, 16, 16, 16),
> >                               col=COLS,
> >                               text=list(c("6-PN", "8-PN", "IX", "XN")
> >                               )
> >                   )
> >        )
> >
> > )
> > ```
> > but how do I add the error bars?
> > I tried with
> > ```
> > xyplot(Value ~ Concentration,
> >        group = Substance, data = df,
> >        pch = 16, cex = 1.2, type = "b",
> >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> >        ylab=expression(bold("Infection rate")),
> >        col=COLS,
> >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> >        )
> >        ),
> >        key = list(space="top", columns=4, col = "black",
> >                   points=list(pch=c(16, 16, 16, 16),
> >                               col=COLS,
> >                               text=list(c("6-PN", "8-PN", "IX", "XN")
> >                               )
> >                   )
> >        ),
> >        panel = function (x,y,) {
> >          panel.segments(x0 = df$Concentration, x1 = df$Concentration,
> >                         y0 = df$Value - dfsd$Value,
> >                         y1 = df$Value + dfsd$Value,
> >                         col = COLS)
> >        }
> >
> > )
> > ```
> > but the bars are plotted outside the graph.
>
> You need to apply the log-transformation yourself, e.g.,
>
>          panel.segments(x0 = log10(df$Concentration), x1 =
> log10(df$Concentration),
>
> But this is not really a scalable approach. You should check if
> Hmisc::xYplot suits your needs:
>
> https://search.r-project.org/CRAN/refmans/Hmisc/html/xYplot.html
>
> Best,
> -Deepayan
>
> > What is the correct syntax? can I use raw data instead of making the
> > mean and std dev separately?
> > Thanks
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Oct 11 22:18:36 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 12 Oct 2021 09:18:36 +1300
Subject: [R] unexpected behavior in apply
In-Reply-To: <a71107e9441e476db477fe28acfff8d1@SRVEXCHCM1302.precheza.cz>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
 <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
 <a71107e9441e476db477fe28acfff8d1@SRVEXCHCM1302.precheza.cz>
Message-ID: <20211012091836.46f81efd@rolf-Latitude-E7470>

On Mon, 11 Oct 2021 09:15:27 +0000
PIKAL Petr <petr.pikal at precheza.cz> wrote:

<SNIP>

> 
> data.frame is not matrix or array (even if it rather resembles one)
> 
> So if you put a cake into oven you cannot expect getting fried
> potatoes from it.

<SNIP>

Another fortune nomination!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter@4567 @end|ng |rom gm@||@com  Mon Oct 11 22:28:31 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 11 Oct 2021 13:28:31 -0700
Subject: [R] How to add error bars to lattice xyplot
In-Reply-To: <CAMk+s2Qo6gOzDsbtykvDzxF6hGGo5TSw9VBu8zMhyereJMmvbQ@mail.gmail.com>
References: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>
 <CADfFDC4bYN4cv87AcddwdFL7Pg2u6bCOZrNHuKB7Y3anisF4Jw@mail.gmail.com>
 <CAMk+s2Qo6gOzDsbtykvDzxF6hGGo5TSw9VBu8zMhyereJMmvbQ@mail.gmail.com>
Message-ID: <CAGxFJbSmBR-B8V8c+-LGe4BtALjE=uN9hhd-pTNPAB9AwyD2fA@mail.gmail.com>

Your panel function needs to plot the points! See at ############ below

xyplot(Value ~ Concentration,
       group = Substance, data = df,
       pch = 16, cex = 1.2, type = "b",
       xlab=expression(bold(paste("Concentration (", mu, "M)"))),
       ylab=expression(bold("Infection rate")),
       col=COLS,
       scales = list(x = list(log = 10, at=c(unique(df$Concentration))
       )
       ),
       key = list(space="top", columns=4, col = "black",
                  points=list(pch=c(16, 16, 16, 16),
                              col=COLS
                  ),
                  text=list(c("A", "B", "C", "D")
                  )
       ),
       panel = function (x,y,...) {
          panel.xyplot(x,y, ...)  ###########
          panel.segments(x0 = log10(df$Concentration),
                         x1 = log10(df$Concentration),
                         y0 = df$Value - dfsd$Value,
                         y1 = df$Value + dfsd$Value,
                         col = COLS)
       }



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 11, 2021 at 12:24 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Thanks,
> now I got the bars (although without notch) but I lost the main plot:
> ```
> xyplot(Value ~ Concentration,
> group = Substance, data = df,
> pch = 16, cex = 1.2, type = "b",
> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> ylab=expression(bold("Infection rate")),
> col=COLS,
> scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> )
> ),
> key = list(space="top", columns=4, col = "black",
> points=list(pch=c(16, 16, 16, 16),
> col=COLS
> ),
> text=list(c("A", "B", "C", "D")
> )
> ),
> panel = function (x,y) {
> panel.segments(x0 = log10(df$Concentration),
> x1 = log10(df$Concentration),
> y0 = df$Value - dfsd$Value,
> y1 = df$Value + dfsd$Value,
> col = COLS)
> }
>
> )
> ```
> I will check xYplot out, I think it is the tool for the job.
>
> On Mon, Oct 11, 2021 at 3:56 PM Deepayan Sarkar
> <deepayan.sarkar at gmail.com> wrote:
> >
> > On Mon, Oct 11, 2021 at 5:41 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> > >
> > > Hello,
> > > I am trying to plot data using lattice. The basic plot works:
> > > ```
> > > Substance = rep(c("A", "B", "C", "D"),4)
> > > Concentration = rep(1:4,4),
> > > Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,
> 14.82333333,
> > >           92.37333333, 98.95666667,   1.48333333,   0.64666667,
> 50.66000000,
> > >           25.75333333,   0.69000000, 0.21666667,   7.40666667,
>  6.92000000,
> > >           0.06333333)
> > > df = data.frame(Substance, Concentration, Value, stringsAsFactors =
> FALSE)
> > > Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
> > > 14.0874424,
> > >        38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,
> 0.7218726,
> > >        0.2498666,  8.4537585, 10.8058456,  0.1096966)
> > > dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors =
> FALSE)
> > >
> > > library(lattice)
> > > COLS = c("gold", "forestgreen", "darkslategray3", "purple")
> > > xyplot(Value ~ Concentration,
> > >        group = Substance, data = df,
> > >        pch = 16, cex = 1.2, type = "b",
> > >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> > >        ylab=expression(bold("Infection rate")),
> > >        col=COLS,
> > >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> > >        )
> > >        ),
> > >        key = list(space="top", columns=4, col = "black",
> > >                   points=list(pch=c(16, 16, 16, 16),
> > >                               col=COLS,
> > >                               text=list(c("6-PN", "8-PN", "IX", "XN")
> > >                               )
> > >                   )
> > >        )
> > >
> > > )
> > > ```
> > > but how do I add the error bars?
> > > I tried with
> > > ```
> > > xyplot(Value ~ Concentration,
> > >        group = Substance, data = df,
> > >        pch = 16, cex = 1.2, type = "b",
> > >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> > >        ylab=expression(bold("Infection rate")),
> > >        col=COLS,
> > >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> > >        )
> > >        ),
> > >        key = list(space="top", columns=4, col = "black",
> > >                   points=list(pch=c(16, 16, 16, 16),
> > >                               col=COLS,
> > >                               text=list(c("6-PN", "8-PN", "IX", "XN")
> > >                               )
> > >                   )
> > >        ),
> > >        panel = function (x,y,) {
> > >          panel.segments(x0 = df$Concentration, x1 = df$Concentration,
> > >                         y0 = df$Value - dfsd$Value,
> > >                         y1 = df$Value + dfsd$Value,
> > >                         col = COLS)
> > >        }
> > >
> > > )
> > > ```
> > > but the bars are plotted outside the graph.
> >
> > You need to apply the log-transformation yourself, e.g.,
> >
> >          panel.segments(x0 = log10(df$Concentration), x1 =
> > log10(df$Concentration),
> >
> > But this is not really a scalable approach. You should check if
> > Hmisc::xYplot suits your needs:
> >
> > https://search.r-project.org/CRAN/refmans/Hmisc/html/xYplot.html
> >
> > Best,
> > -Deepayan
> >
> > > What is the correct syntax? can I use raw data instead of making the
> > > mean and std dev separately?
> > > Thanks
> > >
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Oct 12 05:29:34 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 11 Oct 2021 23:29:34 -0400
Subject: [R] assumptions about how things are done
In-Reply-To: <C9330D44-9671-438C-9FC2-5F0CC11C8C32@roku.com>
References: <C9330D44-9671-438C-9FC2-5F0CC11C8C32@roku.com>
Message-ID: <01fc01d7bf19$61025770$23070650$@verizon.net>

I appreciate the feedback from several people. As noted, I do not want a deep philosophical discussion here and my main point remains not to expect software you "borrow" to do what you WANT but to accommodate it doing what it should.

Most of the time, I would say that a I want a vectorized function to do things exactly the way ifelse() does it. A mean A+B vectorized adds corresponding entries in any order and perhaps even using multiple cores to do it concurrently for larger vectors. Bu we normally don't care about the details, just the result. We want ALL the conditions evaluated and all the then and else parts and the appropriate ones combined into a result. Other than some storage considerations, and maybe efficiency considerations, it matters little if it is done in a gradual loop way or some other.

My point is some are used to loops and if they assume everything will not be evaluated, may have problems if that is a problem. Your example about division by zero is an example where you might change your code to avoid it. One way is to compute the then or else vector before calling ifelse() on the result and doing that calculation carefully as in a way that tests for dividing by zero and does something appropriate to avoid it or trap the error or something. Another is the wrapper method I mentioned, And, if you really need not to evaluate some things such as to avoid side effects, ifelse() may not be what you use then.

I was wondering if I do depend on the times R does non-standard evaluation too much that I think it can be done anytime. Obviously, not. I have often seen anomalous results when I forgot that changing something multiple times that gets evaluated ONCE later, does not work even if my intent was say to make lines that are dashed then others that are dotted and so on.

Many other languages I use do not have this gimmick and it can be annoying but realistic to have to pass some things explicitly such as a text version of the formula used so it can be displayed in the result. Most functions only see the result of arguments passed after evaluation.

So a strength of R can also be ...

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jorgen Harmse via R-help
Sent: Monday, October 11, 2021 11:08 AM
To: r-help at r-project.org
Subject: Re: [R] assumptions about how things are done

As noted by Richard O'Keefe, what usually happens in an R function is that any argument is evaluated either in its entirety or not at all. A few functions use substitute or similar trickery, but then expectations should be documented. I can understand that you want something like ifelse(y>x,x/y,z) to run without warning about division by zero, but how would that be implemented in general? Even a subexpression as simple as f(a,b) presents a problem: you want f(a,b)[cond], but you don't know how the function f works. It might be just a vector operation (and then perhaps f(a[cond],b[cond]) is what we want), or it might return a+rev(b). Avi Gross correctly notes that the implementation is not what he wants, but I think that what he wants is possible only in special cases.

Regards,
Jorgen Harmse. 

?

    Message: 2
    Date: Sat, 9 Oct 2021 15:35:55 -0400
    From: "Avi Gross" <avigross at verizon.net>
    To: <r-help at r-project.org>
    Subject: [R] assumptions about how things are done
    Message-ID: <029401d7bd44$e10843c0$a318cb40$@verizon.net>
    Content-Type: text/plain; charset="utf-8"

    This is supposed to be a forum for help so general and philosophical
    discussions belong elsewhere, or nowhere.



    Having said that, I want to make a brief point. Both new and experienced
    people make implicit assumptions about the code they use. Often nobody looks
    at how the sausage is made. The recent discussion of ifelse() made me take a
    look and I was not thrilled.



    My NA VE view was that ifelse() was implemented as a sort of loop construct.
    I mean if I have a vector of length N and perhaps a few other vectors of the
    same length, I might say:



    result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
    result-if-false-using-vectors)



    So say I want to take a vector of integers from 1 to N and make an output a
    second vector where you have either a prime number or NA. If I have a
    function called is.prime() that checks a single number and returns
    TRUE/FALSE, it might look like this:



    primed <- ifelse(is.prime(A, A, NA)



    So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
    composite becomes NA and so on.



    If you wrote the above using loops, it would be to range from index 1 to N
    and apply the above. There are many complications as R allows vectors to be
    longer or to be repeated as needed.



    What I found ifelse() as implemented to do, is sort of like this:



    Make a vector of the right length for the results, initially empty.



    Make a vector evaluating the condition so it is effectively a Boolean
    result.

    Calculate which indices are TRUE. Secondarily, calculate another set of
    indices that are false.



    Calculate ALL the THEN conditions and ditto all the ELSE conditions.



    Now copy into the result all the THEN values indexed by the TRUE above and
    than all the ELSE values indicated by the FALSE above.



    In plain English, make a result from two other results based on picking
    either one from menu A or one from menu B.



    That is not a bad algorithm and in a vectorized language like R, maybe even
    quite effective and efficient. It does lots of extra work as by definition
    it throws at least half away.



    I suspect the implementation could be made much faster by making some of it
    done internally using a language like C.



    But now that I know what this implementation did, I might have some qualms
    at using it in some situations. The original complaint led to other
    observations and needs and perhaps blindly using a supplied function like
    ifelse() may not be a decent solution for some needs.



    I note how I had to reorient my work elsewhere using a group of packages
    called the tidyverse when they added a function to allow rowwise
    manipulation of the data as compared to an ifelse-like method using all
    columns at once. There is room for many approaches and if a function may not
    be doing quite what you want, something else may better meet your needs OR
    you may want to see if you can copy the existing function and modify it for
    your own personal needs.



    In the case we mentioned, the goal was to avoid printing selected warnings.
    Since the function is readable, it can easily be modified in a copy to find
    what is causing the warnings and either rewrite a bit to avoid them or start
    over with perhaps your own function that tests before doing things and
    avoids tripping the condition (generating a NaN) entirely.



    Like may languages, R is a bit too rich. You can piggyback on the work of
    others but with some caution as they did not necessarily have you in mind
    with what they created.






    	[[alternative HTML version deleted]]





    ------------------------------

    Message: 4
    Date: Sun, 10 Oct 2021 08:34:52 +1100
    From: Jim Lemon <drjimlemon at gmail.com>
    To: Avi Gross <avigross at verizon.net>
    Cc: r-help mailing list <r-help at r-project.org>
    Subject: Re: [R] assumptions about how things are done
    Message-ID:
    	<CA+8X3fUQvXUx0=cVvNVTv144PQrRHgHgp1iBiXk23R8V+9=71g at mail.gmail.com>
    Content-Type: text/plain; charset="utf-8"

    Hi Avi,
    Definitely a learning moment. I may consider writing an ifElse() for
    my own use and sharing it if anyone wants it.

    Jim

    On Sun, Oct 10, 2021 at 6:36 AM Avi Gross via R-help
    <r-help at r-project.org> wrote:
    >
    > This is supposed to be a forum for help so general and philosophical
    > discussions belong elsewhere, or nowhere.
    >
    >
    >
    > Having said that, I want to make a brief point. Both new and experienced
    > people make implicit assumptions about the code they use. Often nobody looks
    > at how the sausage is made. The recent discussion of ifelse() made me take a
    > look and I was not thrilled.
    >
    >
    >
    > My NA?VE view was that ifelse() was implemented as a sort of loop construct.
    > I mean if I have a vector of length N and perhaps a few other vectors of the
    > same length, I might say:
    >
    >
    >
    > result <- ifelse(condition-on-vector-A, result-if-true-using-vectors,
    > result-if-false-using-vectors)
    >
    >
    >
    > So say I want to take a vector of integers from 1 to N and make an output a
    > second vector where you have either a prime number or NA. If I have a
    > function called is.prime() that checks a single number and returns
    > TRUE/FALSE, it might look like this:
    >
    >
    >
    > primed <- ifelse(is.prime(A, A, NA)
    >
    >
    >
    > So A[1] will be mapped to 1 and A[2} to 2 and A[3] to 3, but A[4] being
    > composite becomes NA and so on.
    >
    >
    >
    > If you wrote the above using loops, it would be to range from index 1 to N
    > and apply the above. There are many complications as R allows vectors to be
    > longer or to be repeated as needed.
    >
    >
    >
    > What I found ifelse() as implemented to do, is sort of like this:
    >
    >
    >
    > Make a vector of the right length for the results, initially empty.
    >
    >
    >
    > Make a vector evaluating the condition so it is effectively a Boolean
    > result.
    >
    > Calculate which indices are TRUE. Secondarily, calculate another set of
    > indices that are false.
    >
    >
    >
    > Calculate ALL the THEN conditions and ditto all the ELSE conditions.
    >
    >
    >
    > Now copy into the result all the THEN values indexed by the TRUE above and
    > than all the ELSE values indicated by the FALSE above.
    >
    >
    >
    > In plain English, make a result from two other results based on picking
    > either one from menu A or one from menu B.
    >
    >
    >
    > That is not a bad algorithm and in a vectorized language like R, maybe even
    > quite effective and efficient. It does lots of extra work as by definition
    > it throws at least half away.
    >
    >
    >
    > I suspect the implementation could be made much faster by making some of it
    > done internally using a language like C.
    >
    >
    >
    > But now that I know what this implementation did, I might have some qualms
    > at using it in some situations. The original complaint led to other
    > observations and needs and perhaps blindly using a supplied function like
    > ifelse() may not be a decent solution for some needs.
    >
    >
    >
    > I note how I had to reorient my work elsewhere using a group of packages
    > called the tidyverse when they added a function to allow rowwise
    > manipulation of the data as compared to an ifelse-like method using all
    > columns at once. There is room for many approaches and if a function may not
    > be doing quite what you want, something else may better meet your needs OR
    > you may want to see if you can copy the existing function and modify it for
    > your own personal needs.
    >
    >
    >
    > In the case we mentioned, the goal was to avoid printing selected warnings.
    > Since the function is readable, it can easily be modified in a copy to find
    > what is causing the warnings and either rewrite a bit to avoid them or start
    > over with perhaps your own function that tests before doing things and
    > avoids tripping the condition (generating a NaN) entirely.
    >
    >
    >
    > Like may languages, R is a bit too rich. You can piggyback on the work of
    > others but with some caution as they did not necessarily have you in mind
    > with what they created.
    >
    >
    >
    >
    >
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.




______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Oct 12 08:28:26 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 12 Oct 2021 08:28:26 +0200
Subject: [R] How to add error bars to lattice xyplot
In-Reply-To: <CAGxFJbSmBR-B8V8c+-LGe4BtALjE=uN9hhd-pTNPAB9AwyD2fA@mail.gmail.com>
References: <CAMk+s2TMivV+OOT-Saapdz_HJhD8-rFfkdRBxdfOYyhkkm10WQ@mail.gmail.com>
 <CADfFDC4bYN4cv87AcddwdFL7Pg2u6bCOZrNHuKB7Y3anisF4Jw@mail.gmail.com>
 <CAMk+s2Qo6gOzDsbtykvDzxF6hGGo5TSw9VBu8zMhyereJMmvbQ@mail.gmail.com>
 <CAGxFJbSmBR-B8V8c+-LGe4BtALjE=uN9hhd-pTNPAB9AwyD2fA@mail.gmail.com>
Message-ID: <CAMk+s2S0FmGFOze6CJjuQer2zYE1kJGa4Kv8hquVKBE3xGxf6A@mail.gmail.com>

Thank you, but on the example in use, it draws at each x a triplet of
y from the same class linked by a segment. It is essentially a strip
plot rather than a scatter plot...

On Mon, Oct 11, 2021 at 10:28 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Your panel function needs to plot the points! See at ############ below
>
> xyplot(Value ~ Concentration,
>        group = Substance, data = df,
>        pch = 16, cex = 1.2, type = "b",
>        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>        ylab=expression(bold("Infection rate")),
>        col=COLS,
>        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>        )
>        ),
>        key = list(space="top", columns=4, col = "black",
>                   points=list(pch=c(16, 16, 16, 16),
>                               col=COLS
>                   ),
>                   text=list(c("A", "B", "C", "D")
>                   )
>        ),
>        panel = function (x,y,...) {
>           panel.xyplot(x,y, ...)  ###########
>           panel.segments(x0 = log10(df$Concentration),
>                          x1 = log10(df$Concentration),
>                          y0 = df$Value - dfsd$Value,
>                          y1 = df$Value + dfsd$Value,
>                          col = COLS)
>        }
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Oct 11, 2021 at 12:24 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Thanks,
>> now I got the bars (although without notch) but I lost the main plot:
>> ```
>> xyplot(Value ~ Concentration,
>> group = Substance, data = df,
>> pch = 16, cex = 1.2, type = "b",
>> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>> ylab=expression(bold("Infection rate")),
>> col=COLS,
>> scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>> )
>> ),
>> key = list(space="top", columns=4, col = "black",
>> points=list(pch=c(16, 16, 16, 16),
>> col=COLS
>> ),
>> text=list(c("A", "B", "C", "D")
>> )
>> ),
>> panel = function (x,y) {
>> panel.segments(x0 = log10(df$Concentration),
>> x1 = log10(df$Concentration),
>> y0 = df$Value - dfsd$Value,
>> y1 = df$Value + dfsd$Value,
>> col = COLS)
>> }
>>
>> )
>> ```
>> I will check xYplot out, I think it is the tool for the job.
>>
>> On Mon, Oct 11, 2021 at 3:56 PM Deepayan Sarkar
>> <deepayan.sarkar at gmail.com> wrote:
>> >
>> > On Mon, Oct 11, 2021 at 5:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> > >
>> > > Hello,
>> > > I am trying to plot data using lattice. The basic plot works:
>> > > ```
>> > > Substance = rep(c("A", "B", "C", "D"),4)
>> > > Concentration = rep(1:4,4),
>> > > Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
>> > >           92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
>> > >           25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
>> > >           0.06333333)
>> > > df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
>> > > Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
>> > > 14.0874424,
>> > >        38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
>> > >        0.2498666,  8.4537585, 10.8058456,  0.1096966)
>> > > dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
>> > >
>> > > library(lattice)
>> > > COLS = c("gold", "forestgreen", "darkslategray3", "purple")
>> > > xyplot(Value ~ Concentration,
>> > >        group = Substance, data = df,
>> > >        pch = 16, cex = 1.2, type = "b",
>> > >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>> > >        ylab=expression(bold("Infection rate")),
>> > >        col=COLS,
>> > >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>> > >        )
>> > >        ),
>> > >        key = list(space="top", columns=4, col = "black",
>> > >                   points=list(pch=c(16, 16, 16, 16),
>> > >                               col=COLS,
>> > >                               text=list(c("6-PN", "8-PN", "IX", "XN")
>> > >                               )
>> > >                   )
>> > >        )
>> > >
>> > > )
>> > > ```
>> > > but how do I add the error bars?
>> > > I tried with
>> > > ```
>> > > xyplot(Value ~ Concentration,
>> > >        group = Substance, data = df,
>> > >        pch = 16, cex = 1.2, type = "b",
>> > >        xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>> > >        ylab=expression(bold("Infection rate")),
>> > >        col=COLS,
>> > >        scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>> > >        )
>> > >        ),
>> > >        key = list(space="top", columns=4, col = "black",
>> > >                   points=list(pch=c(16, 16, 16, 16),
>> > >                               col=COLS,
>> > >                               text=list(c("6-PN", "8-PN", "IX", "XN")
>> > >                               )
>> > >                   )
>> > >        ),
>> > >        panel = function (x,y,) {
>> > >          panel.segments(x0 = df$Concentration, x1 = df$Concentration,
>> > >                         y0 = df$Value - dfsd$Value,
>> > >                         y1 = df$Value + dfsd$Value,
>> > >                         col = COLS)
>> > >        }
>> > >
>> > > )
>> > > ```
>> > > but the bars are plotted outside the graph.
>> >
>> > You need to apply the log-transformation yourself, e.g.,
>> >
>> >          panel.segments(x0 = log10(df$Concentration), x1 =
>> > log10(df$Concentration),
>> >
>> > But this is not really a scalable approach. You should check if
>> > Hmisc::xYplot suits your needs:
>> >
>> > https://search.r-project.org/CRAN/refmans/Hmisc/html/xYplot.html
>> >
>> > Best,
>> > -Deepayan
>> >
>> > > What is the correct syntax? can I use raw data instead of making the
>> > > mean and std dev separately?
>> > > Thanks
>> > >
>> > > --
>> > > Best regards,
>> > > Luigi
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Oct 12 13:16:04 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 12 Oct 2021 11:16:04 +0000
Subject: [R] complicated sequence with preset length
Message-ID: <7cac22e35cf344558818acfe3a70209d@SRVEXCHCM1302.precheza.cz>

Dear all

I know it is quite easy to get a simple seqence by rep function
> c(rep(1:3, 2), rep(4:6,2))
 [1] 1 2 3 1 2 3 4 5 6 4 5 6

I could easily get vector of length 24 or 36 using another rep

> rep(c(rep(1:3, 2), rep(4:6,2)),2)
 [1] 1 2 3 1 2 3 4 5 6 4 5 6 1 2 3 1 2 3 4 5 6 4 5 6

> length(rep(c(rep(1:3, 2), rep(4:6,2)),2))
[1] 24
> length(rep(c(rep(1:3, 2), rep(4:6,2)),3))
[1] 36

But what about vector of length 30 i.e. 

> length(c(rep(c(rep(1:3, 2), rep(4:6,2)),2), rep(1:3,2)))
[1] 30

I know I could make some if construction based on known vector length but is
there a way to use "vector recycling" if I know the desired length and want
to "fill in" the values to get required length vector?

Here is my complicated solution

len <- 30
vec1 <- rep(1:3, 2)
vec2 <- rep(4:6, 2)
base.vec <- c(vec1, vec2)
base.len <- length(c(vec1, vec2))
part <- (len/base.len-trunc(len/base.len))
result <- if (part==0) rep(c(vec1,vec2), len/base.len) else
c(rep(c(vec1,vec2), len/base.len), base.vec[1:(base.len*part)])

Is there any way how to achieve the result by simpler way?

Best regards
Petr

From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Oct 12 13:27:34 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 12 Oct 2021 07:27:34 -0400
Subject: [R] complicated sequence with preset length
In-Reply-To: <7cac22e35cf344558818acfe3a70209d@SRVEXCHCM1302.precheza.cz>
References: <7cac22e35cf344558818acfe3a70209d@SRVEXCHCM1302.precheza.cz>
Message-ID: <2c7a5211-eb12-44c8-9cd3-8fd478a10d1e@gmail.com>

On 12/10/2021 7:16 a.m., PIKAL Petr wrote:
> Dear all
> 
> I know it is quite easy to get a simple seqence by rep function
>> c(rep(1:3, 2), rep(4:6,2))
>   [1] 1 2 3 1 2 3 4 5 6 4 5 6
> 
> I could easily get vector of length 24 or 36 using another rep
> 
>> rep(c(rep(1:3, 2), rep(4:6,2)),2)
>   [1] 1 2 3 1 2 3 4 5 6 4 5 6 1 2 3 1 2 3 4 5 6 4 5 6
> 
>> length(rep(c(rep(1:3, 2), rep(4:6,2)),2))
> [1] 24
>> length(rep(c(rep(1:3, 2), rep(4:6,2)),3))
> [1] 36
> 
> But what about vector of length 30 i.e.
> 
>> length(c(rep(c(rep(1:3, 2), rep(4:6,2)),2), rep(1:3,2)))
> [1] 30
> 
> I know I could make some if construction based on known vector length but is
> there a way to use "vector recycling" if I know the desired length and want
> to "fill in" the values to get required length vector?
> 
> Here is my complicated solution
> 
> len <- 30
> vec1 <- rep(1:3, 2)
> vec2 <- rep(4:6, 2)
> base.vec <- c(vec1, vec2)
> base.len <- length(c(vec1, vec2))
> part <- (len/base.len-trunc(len/base.len))
> result <- if (part==0) rep(c(vec1,vec2), len/base.len) else
> c(rep(c(vec1,vec2), len/base.len), base.vec[1:(base.len*part)])
> 
> Is there any way how to achieve the result by simpler way?
> 

You can use the length.out argument to repeat the input as often as 
necessary, e.g.

  rep(c(rep(1:3, 2), rep(4:6,2)), length.out = 30)
  #>  [1] 1 2 3 1 2 3 4 5 6 4 5 6 1 2 3 1 2 3 4 5 6 4 5 6 1 2 3 1 2 3

Duncan Murdoch
Duncan Murdoch


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Oct 12 15:49:01 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 12 Oct 2021 15:49:01 +0200
Subject: [R] How to convert line plot to lattice xtplot?
Message-ID: <CAMk+s2TLo+-o4x9zL-BCa0PyZSrjs8U9+B0Hvgt2Kp8w=m6AQQ@mail.gmail.com>

Hello,
I have drawn data from a dataframe as follows:
```
Substance = rep(c("A", "B", "C", "D"),4)
Concentration = rep(1:4,4)
Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
0.06333333)
df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
14.0874424,
38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
0.2498666,  8.4537585, 10.8058456,  0.1096966)
dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
COLS = c("gold", "green", "purple", "blue")

plot(df$Value[df$Substance == "A"] ~ unique(df$Concentration),
xlab=expression(bold(paste("Concentration (", mu, "M)"))),
ylab=expression(bold("Value")),
type = "o", col = "gold", pch = 16,
xaxt="n", las=3, log = "x",
ylim = c(0, max(df$Value+dfsd$Value))
)
points(df$Value[df$Substance == "B"] ~ unique(df$Concentration),
type = "o", col = "green", pch = 16)
points(df$Value[df$Substance == "C"] ~ unique(df$Concentration),
type = "o", col = "purple", pch = 16)
points(df$Value[df$Substance == "D"] ~ unique(df$Concentration),
type = "o", col = "blue", pch = 16)
legend("topright", legend = LETTERS[1:4],
lty = 1, pch = 16,
col = COLS)
```
I then tried to use lattice but I got a stripplot instead. At each x
(1:4) only one group (A:D) is drawn. What am I missing?
```
library(lattice)
xyplot(Value ~ Concentration,
group = Substance, data = df,
pch = 16, cex = 1.2, type = "b",
xlab=expression(bold(paste("Concentration (", mu, "M)"))),
ylab=expression(bold("Infection rate")),
col=COLS,
scales = list(x = list(log = 10, at=c(unique(df$Concentration))
)
),
key = list(space="top", columns=4, col = "black",
points=list(pch=c(16, 16, 16, 16),
col=COLS
),
text=list(c("A", "B", "C", "D")
)
)
)
```

Thank you

-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Tue Oct 12 16:20:38 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 12 Oct 2021 07:20:38 -0700
Subject: [R] How to convert line plot to lattice xtplot?
In-Reply-To: <CAMk+s2TLo+-o4x9zL-BCa0PyZSrjs8U9+B0Hvgt2Kp8w=m6AQQ@mail.gmail.com>
References: <CAMk+s2TLo+-o4x9zL-BCa0PyZSrjs8U9+B0Hvgt2Kp8w=m6AQQ@mail.gmail.com>
Message-ID: <CAGxFJbSQCRKxZNOMK98YS1uP1f-VyEvOMwiw-tgXPbTUMfTG6w@mail.gmail.com>

You have misspecified the grouping.

df$subs <- rep(1:4, e=4)

xyplot(Value ~ Concentration,
       groups = subs, data = df,  ##... etc.



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Oct 12, 2021 at 6:49 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have drawn data from a dataframe as follows:
> ```
> Substance = rep(c("A", "B", "C", "D"),4)
> Concentration = rep(1:4,4)
> Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,
> 14.82333333,
> 92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
> 25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
> 0.06333333)
> df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
> Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
> 14.0874424,
> 38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
> 0.2498666,  8.4537585, 10.8058456,  0.1096966)
> dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors =
> FALSE)
> COLS = c("gold", "green", "purple", "blue")
>
> plot(df$Value[df$Substance == "A"] ~ unique(df$Concentration),
> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> ylab=expression(bold("Value")),
> type = "o", col = "gold", pch = 16,
> xaxt="n", las=3, log = "x",
> ylim = c(0, max(df$Value+dfsd$Value))
> )
> points(df$Value[df$Substance == "B"] ~ unique(df$Concentration),
> type = "o", col = "green", pch = 16)
> points(df$Value[df$Substance == "C"] ~ unique(df$Concentration),
> type = "o", col = "purple", pch = 16)
> points(df$Value[df$Substance == "D"] ~ unique(df$Concentration),
> type = "o", col = "blue", pch = 16)
> legend("topright", legend = LETTERS[1:4],
> lty = 1, pch = 16,
> col = COLS)
> ```
> I then tried to use lattice but I got a stripplot instead. At each x
> (1:4) only one group (A:D) is drawn. What am I missing?
> ```
> library(lattice)
> xyplot(Value ~ Concentration,
> group = Substance, data = df,
> pch = 16, cex = 1.2, type = "b",
> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
> ylab=expression(bold("Infection rate")),
> col=COLS,
> scales = list(x = list(log = 10, at=c(unique(df$Concentration))
> )
> ),
> key = list(space="top", columns=4, col = "black",
> points=list(pch=c(16, 16, 16, 16),
> col=COLS
> ),
> text=list(c("A", "B", "C", "D")
> )
> )
> )
> ```
>
> Thank you
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Oct 12 19:09:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 12 Oct 2021 19:09:05 +0200
Subject: [R] How to convert line plot to lattice xtplot?
In-Reply-To: <CAGxFJbSQCRKxZNOMK98YS1uP1f-VyEvOMwiw-tgXPbTUMfTG6w@mail.gmail.com>
References: <CAMk+s2TLo+-o4x9zL-BCa0PyZSrjs8U9+B0Hvgt2Kp8w=m6AQQ@mail.gmail.com>
 <CAGxFJbSQCRKxZNOMK98YS1uP1f-VyEvOMwiw-tgXPbTUMfTG6w@mail.gmail.com>
Message-ID: <CAMk+s2RZQuEQuLWV6hLhz+6-KPyKT1yZ7AOiiKOaQkvK=_782w@mail.gmail.com>

Awesome, thanks!

On Tue, Oct 12, 2021 at 4:20 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You have misspecified the grouping.
>
> df$subs <- rep(1:4, e=4)
>
> xyplot(Value ~ Concentration,
>        groups = subs, data = df,  ##... etc.
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Oct 12, 2021 at 6:49 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have drawn data from a dataframe as follows:
>> ```
>> Substance = rep(c("A", "B", "C", "D"),4)
>> Concentration = rep(1:4,4)
>> Value = c(62.80666667, 116.26333333,  92.26000000,   9.87333333,  14.82333333,
>> 92.37333333, 98.95666667,   1.48333333,   0.64666667,  50.66000000,
>> 25.75333333,   0.69000000, 0.21666667,   7.40666667,   6.92000000,
>> 0.06333333)
>> df = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
>> Value = c(15.2974126, 16.3196089, 57.4294280,  9.1943370, 20.5567321,
>> 14.0874424,
>> 38.3626672, 0.3780653,  0.4738495, 37.9124874, 16.2473916,  0.7218726,
>> 0.2498666,  8.4537585, 10.8058456,  0.1096966)
>> dfsd = data.frame(Substance, Concentration, Value, stringsAsFactors = FALSE)
>> COLS = c("gold", "green", "purple", "blue")
>>
>> plot(df$Value[df$Substance == "A"] ~ unique(df$Concentration),
>> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>> ylab=expression(bold("Value")),
>> type = "o", col = "gold", pch = 16,
>> xaxt="n", las=3, log = "x",
>> ylim = c(0, max(df$Value+dfsd$Value))
>> )
>> points(df$Value[df$Substance == "B"] ~ unique(df$Concentration),
>> type = "o", col = "green", pch = 16)
>> points(df$Value[df$Substance == "C"] ~ unique(df$Concentration),
>> type = "o", col = "purple", pch = 16)
>> points(df$Value[df$Substance == "D"] ~ unique(df$Concentration),
>> type = "o", col = "blue", pch = 16)
>> legend("topright", legend = LETTERS[1:4],
>> lty = 1, pch = 16,
>> col = COLS)
>> ```
>> I then tried to use lattice but I got a stripplot instead. At each x
>> (1:4) only one group (A:D) is drawn. What am I missing?
>> ```
>> library(lattice)
>> xyplot(Value ~ Concentration,
>> group = Substance, data = df,
>> pch = 16, cex = 1.2, type = "b",
>> xlab=expression(bold(paste("Concentration (", mu, "M)"))),
>> ylab=expression(bold("Infection rate")),
>> col=COLS,
>> scales = list(x = list(log = 10, at=c(unique(df$Concentration))
>> )
>> ),
>> key = list(space="top", columns=4, col = "black",
>> points=list(pch=c(16, 16, 16, 16),
>> col=COLS
>> ),
>> text=list(c("A", "B", "C", "D")
>> )
>> )
>> )
>> ```
>>
>> Thank you
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Oct 12 22:42:26 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 12 Oct 2021 22:42:26 +0200
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
Message-ID: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>

Hello,
I would like to show a density plot of the Y axis. To do that, I would
like to split the plot into a panel 2/3 long and a density plot 1/3
long. The problem is that, since the density is on the Y axis, the
density plot should be rotated byb90 degrees. I tried with the package
gridGraphics but it rotates both panels.
```
negative_y <- runif(50, 0, 0.099)
negative_x <- runif(50, 1, 40)
positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
uncertain_y <- runif(10, 0.099, 0.2)
uncertain_x <- runif(10, 2, 40)
# plot on MR/FCN space
layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
xlab=expression(bold("X")),
ylab=expression(bold("Y")))
points(positive_x, positive_y, pch=16, cex=1.5)
points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
legend("topleft",
legend = c("Positives", "Negatives", "Uncertains"),
pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
# plot density
plot(density(c(negative_y, uncertain_y, positive_y)),
yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
library(gridGraphics)
grab_grob <- function(){
grid.echo()
grid.grab()
}
g <- grab_grob()
grid.newpage()
pushViewport(viewport(width=0.7,angle=270))
grid.draw(g)
```
How can I rotate only the second panel? I tried to assign the second
plot to an object p and then call grid.draw(p), or to assign g to the
second plot, but they did not work...
Thanks


-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct 13 01:17:22 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 12 Oct 2021 16:17:22 -0700
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
In-Reply-To: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
References: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
Message-ID: <CAGxFJbTFZhC-d+ovCeywMJA1Vb59kBJW3DnkCdMr3=VYnq6WXQ@mail.gmail.com>

I don't know the gridGraphics package, and I haven't looked closely at what
you are trying to do. But note that lattice functions construct grid
"grobs" that can be saved and plotted in arbitrary, including rotated,
viewports, using the print.trellis function. I frankly am pretty ignorant
about such things, but this simple little example might give you some
notion of how to proceed. You may also be able to do what you want with
grid.layout() and pushing a suitably rotated viewport onto a layout. Others
would have to advise on such details, if so.

If I'm wrong and this is useless, just ignore without comment.



dp <- densityplot(~y, main = "",
                  xlab = "", ylab = "")
grid.newpage()
pushViewport(
   viewport(width = unit(.5,"npc"),
            height = unit(.3,"npc"),
            angle = 270))
print(dp, newp = FALSE,  ## this is the print.trellis method
      panel.width = list(1,"npc"),
      panel.height = list(1, "npc")
)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Oct 12, 2021 at 1:43 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I would like to show a density plot of the Y axis. To do that, I would
> like to split the plot into a panel 2/3 long and a density plot 1/3
> long. The problem is that, since the density is on the Y axis, the
> density plot should be rotated byb90 degrees. I tried with the package
> gridGraphics but it rotates both panels.
> ```
> negative_y <- runif(50, 0, 0.099)
> negative_x <- runif(50, 1, 40)
> positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
> uncertain_y <- runif(10, 0.099, 0.2)
> uncertain_x <- runif(10, 2, 40)
> # plot on MR/FCN space
> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> xlab=expression(bold("X")),
> ylab=expression(bold("Y")))
> points(positive_x, positive_y, pch=16, cex=1.5)
> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
> legend("topleft",
> legend = c("Positives", "Negatives", "Uncertains"),
> pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
> # plot density
> plot(density(c(negative_y, uncertain_y, positive_y)),
> yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
> library(gridGraphics)
> grab_grob <- function(){
> grid.echo()
> grid.grab()
> }
> g <- grab_grob()
> grid.newpage()
> pushViewport(viewport(width=0.7,angle=270))
> grid.draw(g)
> ```
> How can I rotate only the second panel? I tried to assign the second
> plot to an object p and then call grid.draw(p), or to assign g to the
> second plot, but they did not work...
> Thanks
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Oct 13 01:29:31 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 13 Oct 2021 12:29:31 +1300
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
In-Reply-To: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
References: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
Message-ID: <6815ddd1-787b-8e3c-143b-3de1d5167e37@stat.auckland.ac.nz>

Hi

I don't think you need (or want) the 'gridGraphics' package for this.
You just need to flip the x-/y-data that you get from density() (and 
make sure that you align the y-axes of the two plots).
The following code shows an example (and adds a bit of par() control to 
eliminate white space).


layout(matrix(c(1,2),nrow=1), widths=c(3,1))
par(mar=c(5, 4, 2, 1))
plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
      xlab=expression(bold("X")),
      ylab=expression(bold("Y")))
points(positive_x, positive_y, pch=16, cex=1.5)
points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
legend("topleft",
        legend = c("Positives", "Negatives", "Uncertains"),
        pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
# plot density
d <- density(c(negative_y, uncertain_y, positive_y))
par(mar=c(5, 1, 2, 1))
plot(d$y, d$x, ylim=c(0,0.5), type="l",
      yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)


Does that produce the sort of thing you want?

Paul


On 13/10/2021 9:42 am, Luigi Marongiu wrote:
> Hello,
> I would like to show a density plot of the Y axis. To do that, I would
> like to split the plot into a panel 2/3 long and a density plot 1/3
> long. The problem is that, since the density is on the Y axis, the
> density plot should be rotated byb90 degrees. I tried with the package
> gridGraphics but it rotates both panels.
> ```
> negative_y <- runif(50, 0, 0.099)
> negative_x <- runif(50, 1, 40)
> positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
> uncertain_y <- runif(10, 0.099, 0.2)
> uncertain_x <- runif(10, 2, 40)
> # plot on MR/FCN space
> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> xlab=expression(bold("X")),
> ylab=expression(bold("Y")))
> points(positive_x, positive_y, pch=16, cex=1.5)
> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
> legend("topleft",
> legend = c("Positives", "Negatives", "Uncertains"),
> pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
> # plot density
> plot(density(c(negative_y, uncertain_y, positive_y)),
> yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
> library(gridGraphics)
> grab_grob <- function(){
> grid.echo()
> grid.grab()
> }
> g <- grab_grob()
> grid.newpage()
> pushViewport(viewport(width=0.7,angle=270))
> grid.draw(g)
> ```
> How can I rotate only the second panel? I tried to assign the second
> plot to an object p and then call grid.draw(p), or to assign g to the
> second plot, but they did not work...
> Thanks
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Oct 13 08:42:58 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 13 Oct 2021 08:42:58 +0200
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
In-Reply-To: <CAGxFJbTFZhC-d+ovCeywMJA1Vb59kBJW3DnkCdMr3=VYnq6WXQ@mail.gmail.com>
References: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
 <CAGxFJbTFZhC-d+ovCeywMJA1Vb59kBJW3DnkCdMr3=VYnq6WXQ@mail.gmail.com>
Message-ID: <CAMk+s2RHe68as2sHL0LHtZzMm6MGDth2n0DMdCPPuXaZZwjVeA@mail.gmail.com>

I have seen that the only package that easily rotate the plot is
ggplot, so I ran:
```
library(ggplot2)
df = data.frame(MR = c(negative_mr, uncertain_mr, positive_mr),
FCN = c(negative_fcn, uncertain_fcn, positive_fcn))
p <- ggplot(df, aes(x=MR)) +
geom_density()
p + coord_flip()
```
Even in this case, the plot is correctly rotated, but I can't place it
in the allocated panel. ggplot2 simply overwrites the whole plot. This
means I need to do the whole thing in ggplot2 (would lattice have an
equivalent?) and split the plot into uneven panels with ggplot2.
Changing x into y is a clever approach, but it is not the same as
rotating a plot. But YES, that is exactly what I wanted to plot. Thank
you!

On Wed, Oct 13, 2021 at 1:17 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I don't know the gridGraphics package, and I haven't looked closely at what you are trying to do. But note that lattice functions construct grid "grobs" that can be saved and plotted in arbitrary, including rotated, viewports, using the print.trellis function. I frankly am pretty ignorant about such things, but this simple little example might give you some notion of how to proceed. You may also be able to do what you want with grid.layout() and pushing a suitably rotated viewport onto a layout. Others would have to advise on such details, if so.
>
> If I'm wrong and this is useless, just ignore without comment.
>
>
>
> dp <- densityplot(~y, main = "",
>                   xlab = "", ylab = "")
> grid.newpage()
> pushViewport(
>    viewport(width = unit(.5,"npc"),
>             height = unit(.3,"npc"),
>             angle = 270))
> print(dp, newp = FALSE,  ## this is the print.trellis method
>       panel.width = list(1,"npc"),
>       panel.height = list(1, "npc")
> )
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Oct 12, 2021 at 1:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I would like to show a density plot of the Y axis. To do that, I would
>> like to split the plot into a panel 2/3 long and a density plot 1/3
>> long. The problem is that, since the density is on the Y axis, the
>> density plot should be rotated byb90 degrees. I tried with the package
>> gridGraphics but it rotates both panels.
>> ```
>> negative_y <- runif(50, 0, 0.099)
>> negative_x <- runif(50, 1, 40)
>> positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
>> positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
>> uncertain_y <- runif(10, 0.099, 0.2)
>> uncertain_x <- runif(10, 2, 40)
>> # plot on MR/FCN space
>> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
>> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
>> xlab=expression(bold("X")),
>> ylab=expression(bold("Y")))
>> points(positive_x, positive_y, pch=16, cex=1.5)
>> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
>> legend("topleft",
>> legend = c("Positives", "Negatives", "Uncertains"),
>> pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
>> # plot density
>> plot(density(c(negative_y, uncertain_y, positive_y)),
>> yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
>> library(gridGraphics)
>> grab_grob <- function(){
>> grid.echo()
>> grid.grab()
>> }
>> g <- grab_grob()
>> grid.newpage()
>> pushViewport(viewport(width=0.7,angle=270))
>> grid.draw(g)
>> ```
>> How can I rotate only the second panel? I tried to assign the second
>> plot to an object p and then call grid.draw(p), or to assign g to the
>> second plot, but they did not work...
>> Thanks
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Oct 13 11:11:13 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 13 Oct 2021 11:11:13 +0200
Subject: [R] How to find local minimum between distributions using mixtools?
Message-ID: <CAMk+s2TEAYzPc_6kMSv6C4rXNaKTqupk5STksSpMtCT9dBwaxw@mail.gmail.com>

Hello,
I have two peaks distributions (and some noise values in between), and
I used mixtools to characterize the two overlapping data. How can I
find the minimum between the peak distributions?
The sigma value of the second population is close to that value, but I
am not sure if this is really the cut-off point between the two
distributions (by eye, I would say the value is 0.125 against 0.1 of
the sigma value). Is there a better approach?
Thanks

```
set.seed(10)
negative_mr <- runif(50, 0, 0.099)
negative_fcn <- runif(50, 1, 40)
positive_mr <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
positive_fcn <- c(runif(30, 25, 40), runif(20, 10, 25))
uncertain_mr <- runif(10, 0.099, 0.2)
uncertain_fcn <- runif(10, 2, 40)
df <- data.frame(Y=c(negative_mr, uncertain_mr, positive_mr),
X=c(negative_fcn, uncertain_fcn, positive_fcn),
GROUP=c(rep("negative", length(negative_mr)),
rep("uncertain", length(uncertain_mr)),
rep("positive", length(positive_mr))))
library(mixtools)
model = normalmixEM((x = df$Y))
summary(model)
# plot
plot(model, which=2)
Cut_off <- model$sigma[2]
Cut_offE <- 0.125
abline(v=Cut_off, col="blue", lwd=2)
abline(v=Cut_offE, col="blue", lwd=2, lty=2)
plot(df$Y[df$GROUP=="negative"]~df$X[df$GROUP=="negative"],
pch=1, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
xlab=expression(bold("X")),
ylab=expression(bold("Y")))
points(df$Y[df$GROUP=="positive"]~df$X[df$GROUP=="positive"],
pch=16, cex=1.5)
points(df$Y[df$GROUP=="uncertain"]~df$X[df$GROUP=="uncertain"],
pch=16, cex=1.5, col="grey")
abline(h=Cut_off, col="blue", lwd=2)
abline(h=Cut_offE, col="blue", lwd=2, lty=2)
```


-- 
Best regards,
Luigi


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Wed Oct 13 12:00:04 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Wed, 13 Oct 2021 15:30:04 +0530
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
In-Reply-To: <CAMk+s2RHe68as2sHL0LHtZzMm6MGDth2n0DMdCPPuXaZZwjVeA@mail.gmail.com>
References: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
 <CAGxFJbTFZhC-d+ovCeywMJA1Vb59kBJW3DnkCdMr3=VYnq6WXQ@mail.gmail.com>
 <CAMk+s2RHe68as2sHL0LHtZzMm6MGDth2n0DMdCPPuXaZZwjVeA@mail.gmail.com>
Message-ID: <CADfFDC6O8gmiu4uWGB=hTwVkW55eL=q=Z9rQVX-kbehcP6Tk=Q@mail.gmail.com>

On Wed, Oct 13, 2021 at 12:13 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> I have seen that the only package that easily rotate the plot is
> ggplot, so I ran:
> ```
> library(ggplot2)
> df = data.frame(MR = c(negative_mr, uncertain_mr, positive_mr),
> FCN = c(negative_fcn, uncertain_fcn, positive_fcn))
> p <- ggplot(df, aes(x=MR)) +
> geom_density()
> p + coord_flip()
> ```
> Even in this case, the plot is correctly rotated, but I can't place it
> in the allocated panel. ggplot2 simply overwrites the whole plot. This
> means I need to do the whole thing in ggplot2 (would lattice have an
> equivalent?) and split the plot into uneven panels with ggplot2.
> Changing x into y is a clever approach, but it is not the same as
> rotating a plot. But YES, that is exactly what I wanted to plot. Thank
> you!

Well, traditional R graphics (as well as lattice) requires a more DIY
approach. As Paul already indicated, you need to control what you are
plotting instead of relying on plot(density(...)) doing the right
thing.

Modifying your original code:

```
layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly

plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
     xlab=expression(bold("X")),
     ylab=expression(bold("Y")))
points(positive_x, positive_y, pch=16, cex=1.5)
points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
legend("topleft",
       legend = c("Positives", "Negatives", "Uncertains"),
       pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)

## calculate density (but don't plot yet)
d <- density(c(negative_y, uncertain_y, positive_y))

## Your original code is equivalent to this
## plot(d,
##      yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)

plot(d$y, d$x, type = "l",
     ##yaxt="n",
     xaxt="n", main=NA, ylab=NA, xlab=NA)
```

Note that in the last plot, I have plot(d$y, d$x, ...) instead of
plot(d$x, d$y, ...).

I have commented out your yaxt="n" to highlight something that may not
be initially obvious, which is that the axis limits of your two plots
do not match. To ensure that, you would additionally need to match
ylim:

```
plot(d$y, d$x, type = "l", ylim=c(0,0.5),
     yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
```

Best,
-Deepayan

> On Wed, Oct 13, 2021 at 1:17 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I don't know the gridGraphics package, and I haven't looked closely at what you are trying to do. But note that lattice functions construct grid "grobs" that can be saved and plotted in arbitrary, including rotated, viewports, using the print.trellis function. I frankly am pretty ignorant about such things, but this simple little example might give you some notion of how to proceed. You may also be able to do what you want with grid.layout() and pushing a suitably rotated viewport onto a layout. Others would have to advise on such details, if so.
> >
> > If I'm wrong and this is useless, just ignore without comment.
> >
> >
> >
> > dp <- densityplot(~y, main = "",
> >                   xlab = "", ylab = "")
> > grid.newpage()
> > pushViewport(
> >    viewport(width = unit(.5,"npc"),
> >             height = unit(.3,"npc"),
> >             angle = 270))
> > print(dp, newp = FALSE,  ## this is the print.trellis method
> >       panel.width = list(1,"npc"),
> >       panel.height = list(1, "npc")
> > )
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Oct 12, 2021 at 1:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>
> >> Hello,
> >> I would like to show a density plot of the Y axis. To do that, I would
> >> like to split the plot into a panel 2/3 long and a density plot 1/3
> >> long. The problem is that, since the density is on the Y axis, the
> >> density plot should be rotated byb90 degrees. I tried with the package
> >> gridGraphics but it rotates both panels.
> >> ```
> >> negative_y <- runif(50, 0, 0.099)
> >> negative_x <- runif(50, 1, 40)
> >> positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> >> positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
> >> uncertain_y <- runif(10, 0.099, 0.2)
> >> uncertain_x <- runif(10, 2, 40)
> >> # plot on MR/FCN space
> >> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
> >> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> >> xlab=expression(bold("X")),
> >> ylab=expression(bold("Y")))
> >> points(positive_x, positive_y, pch=16, cex=1.5)
> >> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
> >> legend("topleft",
> >> legend = c("Positives", "Negatives", "Uncertains"),
> >> pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
> >> # plot density
> >> plot(density(c(negative_y, uncertain_y, positive_y)),
> >> yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
> >> library(gridGraphics)
> >> grab_grob <- function(){
> >> grid.echo()
> >> grid.grab()
> >> }
> >> g <- grab_grob()
> >> grid.newpage()
> >> pushViewport(viewport(width=0.7,angle=270))
> >> grid.draw(g)
> >> ```
> >> How can I rotate only the second panel? I tried to assign the second
> >> plot to an object p and then call grid.draw(p), or to assign g to the
> >> second plot, but they did not work...
> >> Thanks
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Oct 13 12:04:14 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 13 Oct 2021 12:04:14 +0200
Subject: [R] How to rotate only one panel by 90 degrees in R plot?
In-Reply-To: <CADfFDC6O8gmiu4uWGB=hTwVkW55eL=q=Z9rQVX-kbehcP6Tk=Q@mail.gmail.com>
References: <CAMk+s2TAx0mXygcfSaNT9YxJg62d4Mk=_WczipVgB6uFDvZWFQ@mail.gmail.com>
 <CAGxFJbTFZhC-d+ovCeywMJA1Vb59kBJW3DnkCdMr3=VYnq6WXQ@mail.gmail.com>
 <CAMk+s2RHe68as2sHL0LHtZzMm6MGDth2n0DMdCPPuXaZZwjVeA@mail.gmail.com>
 <CADfFDC6O8gmiu4uWGB=hTwVkW55eL=q=Z9rQVX-kbehcP6Tk=Q@mail.gmail.com>
Message-ID: <CAMk+s2TfKOsiU6FX_Mxiv5x3Lk1AmbfhQsfgMWyjyB6QGqM+MQ@mail.gmail.com>

Thank you!

On Wed, Oct 13, 2021 at 12:00 PM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Wed, Oct 13, 2021 at 12:13 PM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
> >
> > I have seen that the only package that easily rotate the plot is
> > ggplot, so I ran:
> > ```
> > library(ggplot2)
> > df = data.frame(MR = c(negative_mr, uncertain_mr, positive_mr),
> > FCN = c(negative_fcn, uncertain_fcn, positive_fcn))
> > p <- ggplot(df, aes(x=MR)) +
> > geom_density()
> > p + coord_flip()
> > ```
> > Even in this case, the plot is correctly rotated, but I can't place it
> > in the allocated panel. ggplot2 simply overwrites the whole plot. This
> > means I need to do the whole thing in ggplot2 (would lattice have an
> > equivalent?) and split the plot into uneven panels with ggplot2.
> > Changing x into y is a clever approach, but it is not the same as
> > rotating a plot. But YES, that is exactly what I wanted to plot. Thank
> > you!
>
> Well, traditional R graphics (as well as lattice) requires a more DIY
> approach. As Paul already indicated, you need to control what you are
> plotting instead of relying on plot(density(...)) doing the right
> thing.
>
> Modifying your original code:
>
> ```
> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
>
> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
>      xlab=expression(bold("X")),
>      ylab=expression(bold("Y")))
> points(positive_x, positive_y, pch=16, cex=1.5)
> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
> legend("topleft",
>        legend = c("Positives", "Negatives", "Uncertains"),
>        pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
>
> ## calculate density (but don't plot yet)
> d <- density(c(negative_y, uncertain_y, positive_y))
>
> ## Your original code is equivalent to this
> ## plot(d,
> ##      yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
>
> plot(d$y, d$x, type = "l",
>      ##yaxt="n",
>      xaxt="n", main=NA, ylab=NA, xlab=NA)
> ```
>
> Note that in the last plot, I have plot(d$y, d$x, ...) instead of
> plot(d$x, d$y, ...).
>
> I have commented out your yaxt="n" to highlight something that may not
> be initially obvious, which is that the axis limits of your two plots
> do not match. To ensure that, you would additionally need to match
> ylim:
>
> ```
> plot(d$y, d$x, type = "l", ylim=c(0,0.5),
>      yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
> ```
>
> Best,
> -Deepayan
>
> > On Wed, Oct 13, 2021 at 1:17 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > I don't know the gridGraphics package, and I haven't looked closely at what you are trying to do. But note that lattice functions construct grid "grobs" that can be saved and plotted in arbitrary, including rotated, viewports, using the print.trellis function. I frankly am pretty ignorant about such things, but this simple little example might give you some notion of how to proceed. You may also be able to do what you want with grid.layout() and pushing a suitably rotated viewport onto a layout. Others would have to advise on such details, if so.
> > >
> > > If I'm wrong and this is useless, just ignore without comment.
> > >
> > >
> > >
> > > dp <- densityplot(~y, main = "",
> > >                   xlab = "", ylab = "")
> > > grid.newpage()
> > > pushViewport(
> > >    viewport(width = unit(.5,"npc"),
> > >             height = unit(.3,"npc"),
> > >             angle = 270))
> > > print(dp, newp = FALSE,  ## this is the print.trellis method
> > >       panel.width = list(1,"npc"),
> > >       panel.height = list(1, "npc")
> > > )
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Tue, Oct 12, 2021 at 1:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >>
> > >> Hello,
> > >> I would like to show a density plot of the Y axis. To do that, I would
> > >> like to split the plot into a panel 2/3 long and a density plot 1/3
> > >> long. The problem is that, since the density is on the Y axis, the
> > >> density plot should be rotated byb90 degrees. I tried with the package
> > >> gridGraphics but it rotates both panels.
> > >> ```
> > >> negative_y <- runif(50, 0, 0.099)
> > >> negative_x <- runif(50, 1, 40)
> > >> positive_y <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> > >> positive_x <- c(runif(30, 25, 40), runif(20, 10, 25))
> > >> uncertain_y <- runif(10, 0.099, 0.2)
> > >> uncertain_x <- runif(10, 2, 40)
> > >> # plot on MR/FCN space
> > >> layout(matrix(c(1,2),nrow=1), widths=c(3,1)) # split panels unevenly
> > >> plot(negative_x, negative_y, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> > >> xlab=expression(bold("X")),
> > >> ylab=expression(bold("Y")))
> > >> points(positive_x, positive_y, pch=16, cex=1.5)
> > >> points(uncertain_x, uncertain_y, pch=16, cex=1.5, col="grey")
> > >> legend("topleft",
> > >> legend = c("Positives", "Negatives", "Uncertains"),
> > >> pch = c(16, 1, 16), col=c("black", "black", "grey"), cex=0.8)
> > >> # plot density
> > >> plot(density(c(negative_y, uncertain_y, positive_y)),
> > >> yaxt="n", xaxt="n", main=NA, ylab=NA, xlab=NA)
> > >> library(gridGraphics)
> > >> grab_grob <- function(){
> > >> grid.echo()
> > >> grid.grab()
> > >> }
> > >> g <- grab_grob()
> > >> grid.newpage()
> > >> pushViewport(viewport(width=0.7,angle=270))
> > >> grid.draw(g)
> > >> ```
> > >> How can I rotate only the second panel? I tried to assign the second
> > >> plot to an object p and then call grid.draw(p), or to assign g to the
> > >> second plot, but they did not work...
> > >> Thanks
> > >>
> > >>
> > >> --
> > >> Best regards,
> > >> Luigi
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From Ry@n@Der|ck@on @end|ng |rom v@@gov  Wed Oct 13 16:09:12 2021
From: Ry@n@Der|ck@on @end|ng |rom v@@gov (Derickson, Ryan, VHA NCOD)
Date: Wed, 13 Oct 2021 14:09:12 +0000
Subject: [R] unexpected behavior in apply
In-Reply-To: <a71107e9441e476db477fe28acfff8d1@SRVEXCHCM1302.precheza.cz>
References: <DM8PR09MB733303431EF91EF8B137EB94F7B29@DM8PR09MB7333.namprd09.prod.outlook.com>
 <CAGiFhPN4C2zinAm7_UjrdkYvtMVu7SUvVV3VUMLJYbG4Pd+XMA@mail.gmail.com>
 <CAGiFhPNg+3A+gQjXOGEM=_tVAi=41hpW_Xp-F4VrZOfSCn-y4A@mail.gmail.com>
 <a71107e9441e476db477fe28acfff8d1@SRVEXCHCM1302.precheza.cz>
Message-ID: <DM8PR09MB733335A9C841028D14AA8081F7B79@DM8PR09MB7333.namprd09.prod.outlook.com>

If an oven expects fried potatoes and I put a cake in, I would hope it
complains or does nothing rather than surreptitiously poisoning my cake.
Jiefei's finding that "6" becomes " 6" during matrix coercion (apparently
for aesthetic reasons only) feels more like the latter. But I appreciate the
explanation and the solutions.   



-----Original Message-----
From: PIKAL Petr <petr.pikal at precheza.cz> 
Sent: Monday, October 11, 2021 5:15 AM
To: Jiefei Wang <szwjf08 at gmail.com>; Derickson, Ryan, VHA NCOD
<Ryan.Derickson at va.gov>
Cc: r-help at r-project.org
Subject: [EXTERNAL] RE: [R] unexpected behavior in apply

Hi

it is not surprising at all.

from apply documentation

Arguments
X	
an array, including a matrix.

data.frame is not matrix or array (even if it rather resembles one)

So if you put a cake into oven you cannot expect getting fried potatoes from
it.

For data frames sapply or lapply is preferable as it is designed for lists
and data frame is (again from documentation)

A data frame is a list of variables of the same number of rows with unique
row names, given class "data.frame".

> sapply(d,function(x) all(x[!is.na(x)]<=3))
   d1    d2    d3 
FALSE  TRUE FALSE 

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jiefei Wang
> Sent: Friday, October 8, 2021 8:22 PM
> To: Derickson, Ryan, VHA NCOD <Ryan.Derickson at va.gov>
> Cc: r-help at r-project.org
> Subject: Re: [R] unexpected behavior in apply
> 
> Ok, it turns out that this is documented, even though it looks surprising.
> 
> First of all, the apply function will try to convert any object with the
dim
> attribute to a matrix(my intuition agrees with you that there should be no
> conversion), so the first step of the apply function is
> 
> > as.matrix.data.frame(d)
>      d1  d2  d3
> [1,] "a" "1" NA
> [2,] "b" "2" NA
> [3,] "c" "3" " 6"
> 
> Since the data frame `d` is a mixture of character and non-character
values,
> the non-character value will be converted to the character using the
function
> `format`. However, the problem is that the NA value will also be formatted
to
> the character
> 
> > format(c(NA, 6))
> [1] "NA" " 6"
> 
> That's where the space comes from. It is purely for making the result
pretty...
> The character NA will be removed later, but the space is not stripped. I
would
> say this is not a good design, and it might be worth not including the NA
value
> in the format function. At the current stage, I will suggest using the
function
> `lapply` to do what you want.
> 
> > lapply(d, FUN=function(x)all(x[!is.na(x)] <= 3))
> $d1
> [1] FALSE
> $d2
> [1] TRUE
> $d3
> [1] FALSE
> 
> Everything should work as you expect.
> 
> Best,
> Jiefei
> 
> On Sat, Oct 9, 2021 at 2:03 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> > Hi,
> >
> > I guess this can tell you what happens behind the scene
> >
> >
> > > d<-data.frame(d1 = letters[1:3],
> > +               d2 = c(1,2,3),
> > +               d3 = c(NA,NA,6))
> > > apply(d, 2, FUN=function(x)x)
> >      d1  d2  d3
> > [1,] "a" "1" NA
> > [2,] "b" "2" NA
> > [3,] "c" "3" " 6"
> > > "a"<=3
> > [1] FALSE
> > > "2"<=3
> > [1] TRUE
> > > "6"<=3
> > [1] FALSE
> >
> > Note that there is an additional space in the character value " 6",
> > that's why your comparison fails. I do not understand why but this
> > might be a bug in R
> >
> > Best,
> > Jiefei
> >
> > On Sat, Oct 9, 2021 at 1:49 AM Derickson, Ryan, VHA NCOD via R-help
> > <r-help at r-project.org> wrote:
> > >
> > > Hello,
> > >
> > > I'm seeing unexpected behavior when using apply() compared to a for
> loop when a character vector is part of the data subjected to the apply
> statement. Below, I check whether all non-missing values are <= 3. If I
> include a character column, apply incorrectly returns TRUE for d3. If I
only
> pass the numeric columns to apply, it is correct for d3. If I use a for
loop, it is
> correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(NA,NA,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1 NA
> > > 2  b  2 NA
> > > 3  c  3  6
> > > >
> > > > # results are incorrect
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE  TRUE
> > > >
> > > > # results are correct
> > > > apply(d[,2:3], 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d2    d3
> > >  TRUE FALSE
> > > >
> > > > # results are correct
> > > > for(i in names(d)){
> > > +   print(all(d[!is.na(d[,i]),i] <= 3)) }
> > > [1] FALSE
> > > [1] TRUE
> > > [1] FALSE
> > >
> > >
> > > Finally, if I remove the NA values from d3 and include the character
> column in apply, it is correct.
> > >
> > > > d<-data.frame(d1 = letters[1:3],
> > > +               d2 = c(1,2,3),
> > > +               d3 = c(4,5,6))
> > > >
> > > > d
> > >   d1 d2 d3
> > > 1  a  1  4
> > > 2  b  2  5
> > > 3  c  3  6
> > > >
> > > > # results are correct
> > > > apply(d, 2, FUN=function(x)all(x[!is.na(x)] <= 3))
> > >    d1    d2    d3
> > > FALSE  TRUE FALSE
> > >
> > >
> > > Can someone help me understand what's happening?
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@oknz @end|ng |rom gm@||@com  Thu Oct 14 09:06:29 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 14 Oct 2021 20:06:29 +1300
Subject: [R] 
 How to find local minimum between distributions using mixtools?
In-Reply-To: <CAMk+s2TEAYzPc_6kMSv6C4rXNaKTqupk5STksSpMtCT9dBwaxw@mail.gmail.com>
References: <CAMk+s2TEAYzPc_6kMSv6C4rXNaKTqupk5STksSpMtCT9dBwaxw@mail.gmail.com>
Message-ID: <CABcYAd+0x8CF=Y3bJEPK4OGZhRBcRhX-4QRHMvDzVPJ5KzLiqA@mail.gmail.com>

Do you really want the minimum?
It sounds as though your model is a*N(x1,s1) + (1-a)*N(x2,s2) where
you use mixtools to estimate
the parameters.  Finding the derivative of that is fairly
straightforward calculus, and solving for the
derivative being zero gives you extrema (you want the one between x1 and x2).

In practice I might start with a quick and dirty hack like
x <- seq(from min(x1,x2), to=max(x1,x2), length=399)
p <- a*dnorm(x, x1, s1) + (1-a)*dnorm(x, x2, s2)
m <- min(p)
x[x == m]

On Wed, 13 Oct 2021 at 22:12, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have two peaks distributions (and some noise values in between), and
> I used mixtools to characterize the two overlapping data. How can I
> find the minimum between the peak distributions?
> The sigma value of the second population is close to that value, but I
> am not sure if this is really the cut-off point between the two
> distributions (by eye, I would say the value is 0.125 against 0.1 of
> the sigma value). Is there a better approach?
> Thanks
>
> ```
> set.seed(10)
> negative_mr <- runif(50, 0, 0.099)
> negative_fcn <- runif(50, 1, 40)
> positive_mr <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> positive_fcn <- c(runif(30, 25, 40), runif(20, 10, 25))
> uncertain_mr <- runif(10, 0.099, 0.2)
> uncertain_fcn <- runif(10, 2, 40)
> df <- data.frame(Y=c(negative_mr, uncertain_mr, positive_mr),
> X=c(negative_fcn, uncertain_fcn, positive_fcn),
> GROUP=c(rep("negative", length(negative_mr)),
> rep("uncertain", length(uncertain_mr)),
> rep("positive", length(positive_mr))))
> library(mixtools)
> model = normalmixEM((x = df$Y))
> summary(model)
> # plot
> plot(model, which=2)
> Cut_off <- model$sigma[2]
> Cut_offE <- 0.125
> abline(v=Cut_off, col="blue", lwd=2)
> abline(v=Cut_offE, col="blue", lwd=2, lty=2)
> plot(df$Y[df$GROUP=="negative"]~df$X[df$GROUP=="negative"],
> pch=1, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> xlab=expression(bold("X")),
> ylab=expression(bold("Y")))
> points(df$Y[df$GROUP=="positive"]~df$X[df$GROUP=="positive"],
> pch=16, cex=1.5)
> points(df$Y[df$GROUP=="uncertain"]~df$X[df$GROUP=="uncertain"],
> pch=16, cex=1.5, col="grey")
> abline(h=Cut_off, col="blue", lwd=2)
> abline(h=Cut_offE, col="blue", lwd=2, lty=2)
> ```
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Oct 14 09:51:10 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 14 Oct 2021 09:51:10 +0200
Subject: [R] How to select given row of conditionally subsetted dataframe?
Message-ID: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>

Hello,
I have selected a subset of a dataframe with the vector syntax (if
this is the name):
```
> df[(df$Y>0.2) & (df$X<10),]
     Y                X
10 0.2200642 1.591589
13 0.2941828 1.485951
```
How can I select only the second row? I only managed to get the whole
of whole columns:
```
> df[(df$Y>0.2) & (df$X<10),2]
[1] 1.591589 1.485951
> df[(df$Y>0.2) & (df$X<10),][2]
     X
10 1.591589
13 1.485951
> df[(df$Y>0.2) & (df$X<10),][1]
     Y
10 0.2200642
13 0.2941828
```
Thank you


From er|cjberger @end|ng |rom gm@||@com  Thu Oct 14 09:59:03 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 14 Oct 2021 10:59:03 +0300
Subject: [R] 
 How to select given row of conditionally subsetted dataframe?
In-Reply-To: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
References: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
Message-ID: <CAGgJW76nXV1-uLZy6q-dCXdd18Ub=0UtS_vRve_nq7qxDVe_yw@mail.gmail.com>

df[(df$Y>0.2) & (df$X<10),][2,]

On Thu, Oct 14, 2021 at 10:52 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have selected a subset of a dataframe with the vector syntax (if
> this is the name):
> ```
> > df[(df$Y>0.2) & (df$X<10),]
>      Y                X
> 10 0.2200642 1.591589
> 13 0.2941828 1.485951
> ```
> How can I select only the second row? I only managed to get the whole
> of whole columns:
> ```
> > df[(df$Y>0.2) & (df$X<10),2]
> [1] 1.591589 1.485951
> > df[(df$Y>0.2) & (df$X<10),][2]
>      X
> 10 1.591589
> 13 1.485951
> > df[(df$Y>0.2) & (df$X<10),][1]
>      Y
> 10 0.2200642
> 13 0.2941828
> ```
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Thu Oct 14 09:57:47 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 14 Oct 2021 03:57:47 -0400
Subject: [R] 
 How to select given row of conditionally subsetted dataframe?
In-Reply-To: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
References: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
Message-ID: <CAPcHnpQ10GYQqBiKkVBHWVbfg4bW=v-OcgQg6eqBSF2j=7fsGQ@mail.gmail.com>

You're missing a comma, this should fix it

df[(df$Y>0.2) & (df$X<10),][2, ]

On Thu, Oct 14, 2021, 03:51 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Hello,
> I have selected a subset of a dataframe with the vector syntax (if
> this is the name):
> ```
> > df[(df$Y>0.2) & (df$X<10),]
>      Y                X
> 10 0.2200642 1.591589
> 13 0.2941828 1.485951
> ```
> How can I select only the second row? I only managed to get the whole
> of whole columns:
> ```
> > df[(df$Y>0.2) & (df$X<10),2]
> [1] 1.591589 1.485951
> > df[(df$Y>0.2) & (df$X<10),][2]
>      X
> 10 1.591589
> 13 1.485951
> > df[(df$Y>0.2) & (df$X<10),][1]
>      Y
> 10 0.2200642
> 13 0.2941828
> ```
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Oct 14 10:17:33 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 14 Oct 2021 10:17:33 +0200
Subject: [R] 
 How to select given row of conditionally subsetted dataframe?
In-Reply-To: <CAGgJW76nXV1-uLZy6q-dCXdd18Ub=0UtS_vRve_nq7qxDVe_yw@mail.gmail.com>
References: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
 <CAGgJW76nXV1-uLZy6q-dCXdd18Ub=0UtS_vRve_nq7qxDVe_yw@mail.gmail.com>
Message-ID: <CAMk+s2Q0DLK+NyFu4weCU=shiUTAfLFLbgkRXQnUa=4s20DsAQ@mail.gmail.com>

Got it, thanks!

On Thu, Oct 14, 2021 at 9:59 AM Eric Berger <ericjberger at gmail.com> wrote:
>
> df[(df$Y>0.2) & (df$X<10),][2,]
>
> On Thu, Oct 14, 2021 at 10:52 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have selected a subset of a dataframe with the vector syntax (if
>> this is the name):
>> ```
>> > df[(df$Y>0.2) & (df$X<10),]
>>      Y                X
>> 10 0.2200642 1.591589
>> 13 0.2941828 1.485951
>> ```
>> How can I select only the second row? I only managed to get the whole
>> of whole columns:
>> ```
>> > df[(df$Y>0.2) & (df$X<10),2]
>> [1] 1.591589 1.485951
>> > df[(df$Y>0.2) & (df$X<10),][2]
>>      X
>> 10 1.591589
>> 13 1.485951
>> > df[(df$Y>0.2) & (df$X<10),][1]
>>      Y
>> 10 0.2200642
>> 13 0.2941828
>> ```
>> Thank you
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Oct 14 11:41:16 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 14 Oct 2021 10:41:16 +0100
Subject: [R] 
 How to select given row of conditionally subsetted dataframe?
In-Reply-To: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
References: <CAMk+s2S_631d_LKGD8cn548Od44qKdH+i=EvedQWexrR2+u9Ww@mail.gmail.com>
Message-ID: <a935d8d5-e06e-afc4-26ab-808d4da81e44@sapo.pt>

Hello,

If the sub-df has more than 2 rows,


tail(df[(df$Y>0.2) & (df$X<10),], 1)


Hope this helps,

Rui Barradas

?s 08:51 de 14/10/21, Luigi Marongiu escreveu:
> Hello,
> I have selected a subset of a dataframe with the vector syntax (if
> this is the name):
> ```
>> df[(df$Y>0.2) & (df$X<10),]
>       Y                X
> 10 0.2200642 1.591589
> 13 0.2941828 1.485951
> ```
> How can I select only the second row? I only managed to get the whole
> of whole columns:
> ```
>> df[(df$Y>0.2) & (df$X<10),2]
> [1] 1.591589 1.485951
>> df[(df$Y>0.2) & (df$X<10),][2]
>       X
> 10 1.591589
> 13 1.485951
>> df[(df$Y>0.2) & (df$X<10),][1]
>       Y
> 10 0.2200642
> 13 0.2941828
> ```
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Oct 14 12:42:27 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 14 Oct 2021 12:42:27 +0200
Subject: [R] 
 How to find local minimum between distributions using mixtools?
In-Reply-To: <CABcYAd+0x8CF=Y3bJEPK4OGZhRBcRhX-4QRHMvDzVPJ5KzLiqA@mail.gmail.com>
References: <CAMk+s2TEAYzPc_6kMSv6C4rXNaKTqupk5STksSpMtCT9dBwaxw@mail.gmail.com>
 <CABcYAd+0x8CF=Y3bJEPK4OGZhRBcRhX-4QRHMvDzVPJ5KzLiqA@mail.gmail.com>
Message-ID: <CAMk+s2T3JzMJhsmX-PFa0qt2xd0k=Q1q0QXaAt2BOx1dKWjr0A@mail.gmail.com>

Thank you, I hoped there might be an automatic method more than
function analysis...

On Thu, Oct 14, 2021 at 9:06 AM Richard O'Keefe <raoknz at gmail.com> wrote:
>
> Do you really want the minimum?
> It sounds as though your model is a*N(x1,s1) + (1-a)*N(x2,s2) where
> you use mixtools to estimate
> the parameters.  Finding the derivative of that is fairly
> straightforward calculus, and solving for the
> derivative being zero gives you extrema (you want the one between x1 and x2).
>
> In practice I might start with a quick and dirty hack like
> x <- seq(from min(x1,x2), to=max(x1,x2), length=399)
> p <- a*dnorm(x, x1, s1) + (1-a)*dnorm(x, x2, s2)
> m <- min(p)
> x[x == m]
>
> On Wed, 13 Oct 2021 at 22:12, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have two peaks distributions (and some noise values in between), and
> > I used mixtools to characterize the two overlapping data. How can I
> > find the minimum between the peak distributions?
> > The sigma value of the second population is close to that value, but I
> > am not sure if this is really the cut-off point between the two
> > distributions (by eye, I would say the value is 0.125 against 0.1 of
> > the sigma value). Is there a better approach?
> > Thanks
> >
> > ```
> > set.seed(10)
> > negative_mr <- runif(50, 0, 0.099)
> > negative_fcn <- runif(50, 1, 40)
> > positive_mr <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> > positive_fcn <- c(runif(30, 25, 40), runif(20, 10, 25))
> > uncertain_mr <- runif(10, 0.099, 0.2)
> > uncertain_fcn <- runif(10, 2, 40)
> > df <- data.frame(Y=c(negative_mr, uncertain_mr, positive_mr),
> > X=c(negative_fcn, uncertain_fcn, positive_fcn),
> > GROUP=c(rep("negative", length(negative_mr)),
> > rep("uncertain", length(uncertain_mr)),
> > rep("positive", length(positive_mr))))
> > library(mixtools)
> > model = normalmixEM((x = df$Y))
> > summary(model)
> > # plot
> > plot(model, which=2)
> > Cut_off <- model$sigma[2]
> > Cut_offE <- 0.125
> > abline(v=Cut_off, col="blue", lwd=2)
> > abline(v=Cut_offE, col="blue", lwd=2, lty=2)
> > plot(df$Y[df$GROUP=="negative"]~df$X[df$GROUP=="negative"],
> > pch=1, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> > xlab=expression(bold("X")),
> > ylab=expression(bold("Y")))
> > points(df$Y[df$GROUP=="positive"]~df$X[df$GROUP=="positive"],
> > pch=16, cex=1.5)
> > points(df$Y[df$GROUP=="uncertain"]~df$X[df$GROUP=="uncertain"],
> > pch=16, cex=1.5, col="grey")
> > abline(h=Cut_off, col="blue", lwd=2)
> > abline(h=Cut_offE, col="blue", lwd=2, lty=2)
> > ```
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From r@oknz @end|ng |rom gm@||@com  Thu Oct 14 13:08:02 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 15 Oct 2021 00:08:02 +1300
Subject: [R] 
 How to find local minimum between distributions using mixtools?
In-Reply-To: <CAMk+s2T3JzMJhsmX-PFa0qt2xd0k=Q1q0QXaAt2BOx1dKWjr0A@mail.gmail.com>
References: <CAMk+s2TEAYzPc_6kMSv6C4rXNaKTqupk5STksSpMtCT9dBwaxw@mail.gmail.com>
 <CABcYAd+0x8CF=Y3bJEPK4OGZhRBcRhX-4QRHMvDzVPJ5KzLiqA@mail.gmail.com>
 <CAMk+s2T3JzMJhsmX-PFa0qt2xd0k=Q1q0QXaAt2BOx1dKWjr0A@mail.gmail.com>
Message-ID: <CABcYAdK=-aC2Wqd=BirxBkj1LBY5HZz3DZL0eZq9ouaAagg-mg@mail.gmail.com>

I presumed there was some reason why the 'optimise' function did not suit you.

optimize(function (x) a*dnorm(x, x1, s1) + (1-a)*dnorm(x, x2, s2),
range(c(x1, x2)))

should do the trick.

On Thu, 14 Oct 2021 at 23:42, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you, I hoped there might be an automatic method more than
> function analysis...
>
> On Thu, Oct 14, 2021 at 9:06 AM Richard O'Keefe <raoknz at gmail.com> wrote:
> >
> > Do you really want the minimum?
> > It sounds as though your model is a*N(x1,s1) + (1-a)*N(x2,s2) where
> > you use mixtools to estimate
> > the parameters.  Finding the derivative of that is fairly
> > straightforward calculus, and solving for the
> > derivative being zero gives you extrema (you want the one between x1 and x2).
> >
> > In practice I might start with a quick and dirty hack like
> > x <- seq(from min(x1,x2), to=max(x1,x2), length=399)
> > p <- a*dnorm(x, x1, s1) + (1-a)*dnorm(x, x2, s2)
> > m <- min(p)
> > x[x == m]
> >
> > On Wed, 13 Oct 2021 at 22:12, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have two peaks distributions (and some noise values in between), and
> > > I used mixtools to characterize the two overlapping data. How can I
> > > find the minimum between the peak distributions?
> > > The sigma value of the second population is close to that value, but I
> > > am not sure if this is really the cut-off point between the two
> > > distributions (by eye, I would say the value is 0.125 against 0.1 of
> > > the sigma value). Is there a better approach?
> > > Thanks
> > >
> > > ```
> > > set.seed(10)
> > > negative_mr <- runif(50, 0, 0.099)
> > > negative_fcn <- runif(50, 1, 40)
> > > positive_mr <- c(runif(30, 0.2, 0.5), runif(20, 0.4, 0.5))
> > > positive_fcn <- c(runif(30, 25, 40), runif(20, 10, 25))
> > > uncertain_mr <- runif(10, 0.099, 0.2)
> > > uncertain_fcn <- runif(10, 2, 40)
> > > df <- data.frame(Y=c(negative_mr, uncertain_mr, positive_mr),
> > > X=c(negative_fcn, uncertain_fcn, positive_fcn),
> > > GROUP=c(rep("negative", length(negative_mr)),
> > > rep("uncertain", length(uncertain_mr)),
> > > rep("positive", length(positive_mr))))
> > > library(mixtools)
> > > model = normalmixEM((x = df$Y))
> > > summary(model)
> > > # plot
> > > plot(model, which=2)
> > > Cut_off <- model$sigma[2]
> > > Cut_offE <- 0.125
> > > abline(v=Cut_off, col="blue", lwd=2)
> > > abline(v=Cut_offE, col="blue", lwd=2, lty=2)
> > > plot(df$Y[df$GROUP=="negative"]~df$X[df$GROUP=="negative"],
> > > pch=1, ylim=c(0,0.5), xlim=c(0,41), cex=1.5,
> > > xlab=expression(bold("X")),
> > > ylab=expression(bold("Y")))
> > > points(df$Y[df$GROUP=="positive"]~df$X[df$GROUP=="positive"],
> > > pch=16, cex=1.5)
> > > points(df$Y[df$GROUP=="uncertain"]~df$X[df$GROUP=="uncertain"],
> > > pch=16, cex=1.5, col="grey")
> > > abline(h=Cut_off, col="blue", lwd=2)
> > > abline(h=Cut_offE, col="blue", lwd=2, lty=2)
> > > ```
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 14 19:03:04 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 14 Oct 2021 19:03:04 +0200
Subject: [R] Sebastian Meyer joins the R core team
Message-ID: <24936.25288.415151.966468@stat.math.ethz.ch>


We are very happy to announce that

Sebastian Meyer (http://www.imbe.med.uni-erlangen.de/ma/S.Meyer ;
                 Twitter @bastistician; also https://github.com/bastistician/)

has joined the R core team yesterday (Oct 13).  He has been an
active contributor notably in handling and fixing R bugzilla issues in
dozens of contributions and also by direct communication,
mainly during the last 2 years but starting considerably earlier.

The R Core team

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Oct 14 19:10:12 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 14 Oct 2021 12:10:12 -0500
Subject: [R] how to do inverse log of every value in every column in data
 frame
Message-ID: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>

Hi All,

I have a data frame like this:

> head(b)
     LRET02    LRET04    LRET06    LRET08    LRET10    LRET12    LRET14
1         0 0.6931472         . 1.0986123 1.0986123 1.0986123 0.6931472
2 2.1972246 2.4849066 2.4849066         . 2.5649494 2.6390573 2.6390573
3 1.6094379 1.7917595 1.6094379 1.7917595 2.0794415 1.9459101 2.0794415
4         0         0         0         0         0         0         0
5 0.6931472         0 1.0986123 1.0986123 0.6931472 0.6931472 0.6931472
6 1.0986123 1.0986123 1.0986123 0.6931472 1.0986123 1.3862944 1.0986123

All values in this data frame are product of natural log. I have to do
inverse of it.
So for example do do inverse of 0.6931472 I would do:
> 2.718281828^0.6931472
[1] 2

How do I perform this operation for every single value in this data frame?

The original data frame is this dimension:
> dim(b)
[1] 1441   18

Thanks
Ana

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Thu Oct 14 19:16:41 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 14 Oct 2021 17:16:41 +0000
Subject: [R] 
 [External] how to do inverse log of every value in every column
 in data frame
In-Reply-To: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
Message-ID: <558EC0CA-8075-4351-A452-C72C530407C8@temple.edu>

> tmp <- data.frame(a=1:3,b=4:6)
> exp(tmp)
          a         b
1  2.718282  54.59815
2  7.389056 148.41316
3 20.085537 403.42879
> 2.718281828^tmp
          a         b
1  2.718282  54.59815
2  7.389056 148.41316
3 20.085537 403.42879


> On Oct 14, 2021, at 13:10, Ana Marija <sokovic.anamarija at gmail.com> wrote:
> 
>> 2.718281828^


From bgunter@4567 @end|ng |rom gm@||@com  Thu Oct 14 19:17:16 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 14 Oct 2021 10:17:16 -0700
Subject: [R] 
 how to do inverse log of every value in every column in data frame
In-Reply-To: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
Message-ID: <CAGxFJbSRk-6cr6Dr+LsUujB4UwHCsUgo3AYy4wQ7b6ggK65c0w@mail.gmail.com>

As all of your columns are numeric, you should probably convert your df to
a matrix. Then use exp() on that, of course:
exp(as.matrix(b))

see ?exp

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Oct 14, 2021 at 10:10 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi All,
>
> I have a data frame like this:
>
> > head(b)
>      LRET02    LRET04    LRET06    LRET08    LRET10    LRET12    LRET14
> 1         0 0.6931472         . 1.0986123 1.0986123 1.0986123 0.6931472
> 2 2.1972246 2.4849066 2.4849066         . 2.5649494 2.6390573 2.6390573
> 3 1.6094379 1.7917595 1.6094379 1.7917595 2.0794415 1.9459101 2.0794415
> 4         0         0         0         0         0         0         0
> 5 0.6931472         0 1.0986123 1.0986123 0.6931472 0.6931472 0.6931472
> 6 1.0986123 1.0986123 1.0986123 0.6931472 1.0986123 1.3862944 1.0986123
>
> All values in this data frame are product of natural log. I have to do
> inverse of it.
> So for example do do inverse of 0.6931472 I would do:
> > 2.718281828^0.6931472
> [1] 2
>
> How do I perform this operation for every single value in this data frame?
>
> The original data frame is this dimension:
> > dim(b)
> [1] 1441   18
>
> Thanks
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Oct 14 19:23:40 2021
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 14 Oct 2021 12:23:40 -0500
Subject: [R] 
 how to do inverse log of every value in every column in data frame
In-Reply-To: <CAGxFJbSRk-6cr6Dr+LsUujB4UwHCsUgo3AYy4wQ7b6ggK65c0w@mail.gmail.com>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
 <CAGxFJbSRk-6cr6Dr+LsUujB4UwHCsUgo3AYy4wQ7b6ggK65c0w@mail.gmail.com>
Message-ID: <CAF9-5jNOibnLU7txSxDKpSg31GKL2eSEzeO81sY_C4c18vWrtQ@mail.gmail.com>

Thank you so much!

On Thu, Oct 14, 2021 at 12:17 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> As all of your columns are numeric, you should probably convert your df to
> a matrix. Then use exp() on that, of course:
> exp(as.matrix(b))
>
> see ?exp
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Oct 14, 2021 at 10:10 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hi All,
>>
>> I have a data frame like this:
>>
>> > head(b)
>>      LRET02    LRET04    LRET06    LRET08    LRET10    LRET12    LRET14
>> 1         0 0.6931472         . 1.0986123 1.0986123 1.0986123 0.6931472
>> 2 2.1972246 2.4849066 2.4849066         . 2.5649494 2.6390573 2.6390573
>> 3 1.6094379 1.7917595 1.6094379 1.7917595 2.0794415 1.9459101 2.0794415
>> 4         0         0         0         0         0         0         0
>> 5 0.6931472         0 1.0986123 1.0986123 0.6931472 0.6931472 0.6931472
>> 6 1.0986123 1.0986123 1.0986123 0.6931472 1.0986123 1.3862944 1.0986123
>>
>> All values in this data frame are product of natural log. I have to do
>> inverse of it.
>> So for example do do inverse of 0.6931472 I would do:
>> > 2.718281828^0.6931472
>> [1] 2
>>
>> How do I perform this operation for every single value in this data frame?
>>
>> The original data frame is this dimension:
>> > dim(b)
>> [1] 1441   18
>>
>> Thanks
>> Ana
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Oct 14 20:18:53 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 14 Oct 2021 19:18:53 +0100
Subject: [R] 
 how to do inverse log of every value in every column in data frame
In-Reply-To: <CAF9-5jNOibnLU7txSxDKpSg31GKL2eSEzeO81sY_C4c18vWrtQ@mail.gmail.com>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
 <CAGxFJbSRk-6cr6Dr+LsUujB4UwHCsUgo3AYy4wQ7b6ggK65c0w@mail.gmail.com>
 <CAF9-5jNOibnLU7txSxDKpSg31GKL2eSEzeO81sY_C4c18vWrtQ@mail.gmail.com>
Message-ID: <fcb88878-533b-3d6a-201c-299542fe4a66@sapo.pt>

Hello,

The answer is given but there is no need to coerce to matrix first, as 
long as the columns are numeric.
 From ?exp, right at the beginning of section Details:

Details
All except logb are generic functions: methods can be defined for them 
individually or via the Math group generic.


Follow the link Math:


Details
There are four groups for which S3 methods can be written, namely the 
"Math", "Ops", "Summary" and "Complex" groups. These are not R objects 
in base R, but methods can be supplied for them and base R contains 
factor, data.frame and difftime methods for the first three groups.


And exp is the group "Math", 2nd bullet.

class(mtcars)
#[1] "data.frame"
exp(mtcars)
# output omitted


But if a column is not numeric the method Math.data.frame throws an error.


exp(iris)
#Error in Math.data.frame(iris) :
#  non-numeric-alike variable(s) in data frame: Species

exp(iris[-5])     # remove the offending column
# output omitted


Hope this helps,

Rui Barradas


?s 18:23 de 14/10/21, Ana Marija escreveu:
> Thank you so much!
> 
> On Thu, Oct 14, 2021 at 12:17 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> As all of your columns are numeric, you should probably convert your df to
>> a matrix. Then use exp() on that, of course:
>> exp(as.matrix(b))
>>
>> see ?exp
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Oct 14, 2021 at 10:10 AM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>
>>> Hi All,
>>>
>>> I have a data frame like this:
>>>
>>>> head(b)
>>>       LRET02    LRET04    LRET06    LRET08    LRET10    LRET12    LRET14
>>> 1         0 0.6931472         . 1.0986123 1.0986123 1.0986123 0.6931472
>>> 2 2.1972246 2.4849066 2.4849066         . 2.5649494 2.6390573 2.6390573
>>> 3 1.6094379 1.7917595 1.6094379 1.7917595 2.0794415 1.9459101 2.0794415
>>> 4         0         0         0         0         0         0         0
>>> 5 0.6931472         0 1.0986123 1.0986123 0.6931472 0.6931472 0.6931472
>>> 6 1.0986123 1.0986123 1.0986123 0.6931472 1.0986123 1.3862944 1.0986123
>>>
>>> All values in this data frame are product of natural log. I have to do
>>> inverse of it.
>>> So for example do do inverse of 0.6931472 I would do:
>>>> 2.718281828^0.6931472
>>> [1] 2
>>>
>>> How do I perform this operation for every single value in this data frame?
>>>
>>> The original data frame is this dimension:
>>>> dim(b)
>>> [1] 1441   18
>>>
>>> Thanks
>>> Ana
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Oct 14 20:27:27 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 14 Oct 2021 19:27:27 +0100
Subject: [R] 
 [External] how to do inverse log of every value in every column
 in data frame
In-Reply-To: <558EC0CA-8075-4351-A452-C72C530407C8@temple.edu>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
 <558EC0CA-8075-4351-A452-C72C530407C8@temple.edu>
Message-ID: <90539599-b613-a429-63b1-12396c7a2d6a@sapo.pt>

Hello,

exp() is better, see the 2nd identical:


identical(
   exp(tmp),
   2.718281828^tmp
)
#[1] FALSE
identical(
   exp(tmp),
   exp(1)^tmp
)
#[1] FALSE

all.equal(
   exp(tmp),
   2.718281828^tmp
)
#[1] TRUE
all.equal(
   exp(tmp),
   exp(1)^tmp
)
#[1] TRUE





?s 18:16 de 14/10/21, Richard M. Heiberger escreveu:
>> tmp <- data.frame(a=1:3,b=4:6)
>> exp(tmp)
>            a         b
> 1  2.718282  54.59815
> 2  7.389056 148.41316
> 3 20.085537 403.42879
>> 2.718281828^tmp
>            a         b
> 1  2.718282  54.59815
> 2  7.389056 148.41316
> 3 20.085537 403.42879
> 
> 
>> On Oct 14, 2021, at 13:10, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>>> 2.718281828^
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Thu Oct 14 21:53:13 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 14 Oct 2021 12:53:13 -0700
Subject: [R] 
 how to do inverse log of every value in every column in data frame
In-Reply-To: <fcb88878-533b-3d6a-201c-299542fe4a66@sapo.pt>
References: <CAF9-5jO-X8Ni=a4xUqvcEE-VLKHQj6B55Pc5MHt0Szi+_Nbbhw@mail.gmail.com>
 <CAGxFJbSRk-6cr6Dr+LsUujB4UwHCsUgo3AYy4wQ7b6ggK65c0w@mail.gmail.com>
 <CAF9-5jNOibnLU7txSxDKpSg31GKL2eSEzeO81sY_C4c18vWrtQ@mail.gmail.com>
 <fcb88878-533b-3d6a-201c-299542fe4a66@sapo.pt>
Message-ID: <CAGxFJbRs1=8JvBfDmnQOK0+s4A9xzMnfR=qH6ZFRKxKjMRCLhA@mail.gmail.com>

This was already clear from Rich Heiberger's reply. But my point was not
that the as.matrix() coercion was necessary, but that it would be wise, as
operations with matrices are generally (often much) more efficient than
with data frames. Of course, other considerations may exist, but that was
my point, which I should evidently have made clearer.

Cheers,
Bert
On Thu, Oct 14, 2021 at 11:19 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> The answer is given but there is no need to coerce to matrix first, as
> long as the columns are numeric.
>  From ?exp, right at the beginning of section Details:
>
> Details
> All except logb are generic functions: methods can be defined for them
> individually or via the Math group generic.
>
>
> Follow the link Math:
>
>
> Details
> There are four groups for which S3 methods can be written, namely the
> "Math", "Ops", "Summary" and "Complex" groups. These are not R objects
> in base R, but methods can be supplied for them and base R contains
> factor, data.frame and difftime methods for the first three groups.
>
>
> And exp is the group "Math", 2nd bullet.
>
> class(mtcars)
> #[1] "data.frame"
> exp(mtcars)
> # output omitted
>
>
> But if a column is not numeric the method Math.data.frame throws an error.
>
>
> exp(iris)
> #Error in Math.data.frame(iris) :
> #  non-numeric-alike variable(s) in data frame: Species
>
> exp(iris[-5])     # remove the offending column
> # output omitted
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 18:23 de 14/10/21, Ana Marija escreveu:
> > Thank you so much!
> >
> > On Thu, Oct 14, 2021 at 12:17 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> As all of your columns are numeric, you should probably convert your df
> to
> >> a matrix. Then use exp() on that, of course:
> >> exp(as.matrix(b))
> >>
> >> see ?exp
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Thu, Oct 14, 2021 at 10:10 AM Ana Marija <
> sokovic.anamarija at gmail.com>
> >> wrote:
> >>
> >>> Hi All,
> >>>
> >>> I have a data frame like this:
> >>>
> >>>> head(b)
> >>>       LRET02    LRET04    LRET06    LRET08    LRET10    LRET12
> LRET14
> >>> 1         0 0.6931472         . 1.0986123 1.0986123 1.0986123 0.6931472
> >>> 2 2.1972246 2.4849066 2.4849066         . 2.5649494 2.6390573 2.6390573
> >>> 3 1.6094379 1.7917595 1.6094379 1.7917595 2.0794415 1.9459101 2.0794415
> >>> 4         0         0         0         0         0         0         0
> >>> 5 0.6931472         0 1.0986123 1.0986123 0.6931472 0.6931472 0.6931472
> >>> 6 1.0986123 1.0986123 1.0986123 0.6931472 1.0986123 1.3862944 1.0986123
> >>>
> >>> All values in this data frame are product of natural log. I have to do
> >>> inverse of it.
> >>> So for example do do inverse of 0.6931472 I would do:
> >>>> 2.718281828^0.6931472
> >>> [1] 2
> >>>
> >>> How do I perform this operation for every single value in this data
> frame?
> >>>
> >>> The original data frame is this dimension:
> >>>> dim(b)
> >>> [1] 1441   18
> >>>
> >>> Thanks
> >>> Ana
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @tyen @end|ng |rom ntu@edu@tw  Sat Oct 16 03:23:56 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sat, 16 Oct 2021 09:23:56 +0800
Subject: [R] Subset command
Message-ID: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>

The following "subset command works. I was hoping the second would as 
well but it does not.

My definition of exclude is rejected.

Help please? Thanks.

 > mydata<-subset(mydata,
+??????????????? prim>-9???? & highsch>-9? & tert>-9 &
+??????????????? govt>-9???? & nongovt>-9? &
+??????????????? married>-9? & urban>-9??? &
+??????????????? smhmyes>-9? & smhmno>-9?? & smhmnoru>-9 &
+??????????????? workouts>-9 & seconhan>-9 & reliyes>-9)

 > exclude<-????? prim==-9???? | highsch==-9? | tert==-9 |
+??????????????? govt==-9???? | nongovt==-9? |
+??????????????? married==-9? | urban==-9??? |
+??????????????? smhmyes==-9? | smhmno==-9?? | smhmnoru==-9 |
+??????????????? workouts==-9 | seconhan==-9 | reliyes==-9
Error: object 'prim' not found
 > mydata<-subset(mydata,-exclude)
Error in eval(e, x, parent.frame()) : object 'exclude' not found
 >


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Oct 16 03:35:31 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 15 Oct 2021 18:35:31 -0700
Subject: [R] Subset command
In-Reply-To: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
References: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
Message-ID: <AC15BD67-9D8E-43C4-B113-03677A91E085@dcn.davis.ca.us>

I don't see a "second one". Looks like you forgot the subset function call?

On October 15, 2021 6:23:56 PM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>The following "subset command works. I was hoping the second would as 
>well but it does not.
>
>My definition of exclude is rejected.
>
>Help please? Thanks.
>
> > mydata<-subset(mydata,
>+??????????????? prim>-9???? & highsch>-9? & tert>-9 &
>+??????????????? govt>-9???? & nongovt>-9? &
>+??????????????? married>-9? & urban>-9??? &
>+??????????????? smhmyes>-9? & smhmno>-9?? & smhmnoru>-9 &
>+??????????????? workouts>-9 & seconhan>-9 & reliyes>-9)
>
> > exclude<-????? prim==-9???? | highsch==-9? | tert==-9 |
>+??????????????? govt==-9???? | nongovt==-9? |
>+??????????????? married==-9? | urban==-9??? |
>+??????????????? smhmyes==-9? | smhmno==-9?? | smhmnoru==-9 |
>+??????????????? workouts==-9 | seconhan==-9 | reliyes==-9
>Error: object 'prim' not found
> > mydata<-subset(mydata,-exclude)
>Error in eval(e, x, parent.frame()) : object 'exclude' not found
> >
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rmh @end|ng |rom temp|e@edu  Sat Oct 16 03:38:07 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sat, 16 Oct 2021 01:38:07 +0000
Subject: [R] [External]  Subset command
In-Reply-To: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
References: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
Message-ID: <473FE05D-F86A-4183-B865-80AA2496C9AE@temple.edu>

the second  command doesn't tell R that the variables are in the data.frame mydata.

you will need
exclude <- with(mydata, 
                         prim==-9 | etc)

also you will need logical negation !
not arithmetic negation -

> -c(TRUE,FALSE)
[1] -1  0
> as.logical(-c(TRUE,FALSE))
[1]  TRUE FALSE

> !c(TRUE,FALSE)
[1] FALSE  TRUE



> On Oct 15, 2021, at 21:23, Steven Yen <styen at ntu.edu.tw> wrote:
> 
> The following "subset command works. I was hoping the second would as well but it does not.
> 
> My definition of exclude is rejected.
> 
> Help please? Thanks.
> 
> > mydata<-subset(mydata,
> +                prim>-9     & highsch>-9  & tert>-9 &
> +                govt>-9     & nongovt>-9  &
> +                married>-9  & urban>-9    &
> +                smhmyes>-9  & smhmno>-9   & smhmnoru>-9 &
> +                workouts>-9 & seconhan>-9 & reliyes>-9)
> 
> > exclude<-      prim==-9     | highsch==-9  | tert==-9 |
> +                govt==-9     | nongovt==-9  |
> +                married==-9  | urban==-9    |
> +                smhmyes==-9  | smhmno==-9   | smhmnoru==-9 |
> +                workouts==-9 | seconhan==-9 | reliyes==-9
> Error: object 'prim' not found
> > mydata<-subset(mydata,-exclude)
> Error in eval(e, x, parent.frame()) : object 'exclude' not found
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7Ca1d470378fc24c832f7708d99043b804%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637699443365577347%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=DFLP8ZLggvu1NVs9ufyWUdT5hJNKd0v7UYwcHCXncVk%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7Ca1d470378fc24c832f7708d99043b804%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637699443365577347%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=4g2tnLBCnnWezCp%2FZIYFRCxrIKa4VDD46WRQohT5Ftk%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Sat Oct 16 03:39:47 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sat, 16 Oct 2021 09:39:47 +0800
Subject: [R] Subset command
In-Reply-To: <AC15BD67-9D8E-43C4-B113-03677A91E085@dcn.davis.ca.us>
References: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
 <AC15BD67-9D8E-43C4-B113-03677A91E085@dcn.davis.ca.us>
Message-ID: <8e9f8547-95e6-b571-9f12-fbbdca7f5226@ntu.edu.tw>

Thanks. YES the second call to subset is there, trying to use my failed 
definition of "exclude". Read on..

On 2021/10/16 ?? 09:35, Jeff Newmiller wrote:
> I don't see a "second one". Looks like you forgot the subset function call?
>
> On October 15, 2021 6:23:56 PM PDT, Steven Yen <styen at ntu.edu.tw> wrote:
>> The following "subset command works. I was hoping the second would as
>> well but it does not.
>>
>> My definition of exclude is rejected.
>>
>> Help please? Thanks.
>>
>>> mydata<-subset(mydata,
>> +??????????????? prim>-9???? & highsch>-9? & tert>-9 &
>> +??????????????? govt>-9???? & nongovt>-9? &
>> +??????????????? married>-9? & urban>-9??? &
>> +??????????????? smhmyes>-9? & smhmno>-9?? & smhmnoru>-9 &
>> +??????????????? workouts>-9 & seconhan>-9 & reliyes>-9)
>>
>>> exclude<-????? prim==-9???? | highsch==-9? | tert==-9 |
>> +??????????????? govt==-9???? | nongovt==-9? |
>> +??????????????? married==-9? | urban==-9??? |
>> +??????????????? smhmyes==-9? | smhmno==-9?? | smhmnoru==-9 |
>> +??????????????? workouts==-9 | seconhan==-9 | reliyes==-9
>> Error: object 'prim' not found
>>> mydata<-subset(mydata,-exclude)
>> Error in eval(e, x, parent.frame()) : object 'exclude' not found
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @tyen @end|ng |rom ntu@edu@tw  Sat Oct 16 03:46:07 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Sat, 16 Oct 2021 09:46:07 +0800
Subject: [R] [External]  Subset command
In-Reply-To: <473FE05D-F86A-4183-B865-80AA2496C9AE@temple.edu>
References: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
 <473FE05D-F86A-4183-B865-80AA2496C9AE@temple.edu>
Message-ID: <987cf781-a466-5e0e-e16c-5ddbea59d858@ntu.edu.tw>

Great. Thanks!

On 2021/10/16 ?? 09:38, Richard M. Heiberger wrote:
> the second  command doesn't tell R that the variables are in the data.frame mydata.
>
> you will need
> exclude <- with(mydata,
>                           prim==-9 | etc)
>
> also you will need logical negation !
> not arithmetic negation -
>
>> -c(TRUE,FALSE)
> [1] -1  0
>> as.logical(-c(TRUE,FALSE))
> [1]  TRUE FALSE
>
>> !c(TRUE,FALSE)
> [1] FALSE  TRUE
>
>
>
>> On Oct 15, 2021, at 21:23, Steven Yen <styen at ntu.edu.tw> wrote:
>>
>> The following "subset command works. I was hoping the second would as well but it does not.
>>
>> My definition of exclude is rejected.
>>
>> Help please? Thanks.
>>
>>> mydata<-subset(mydata,
>> +                prim>-9     & highsch>-9  & tert>-9 &
>> +                govt>-9     & nongovt>-9  &
>> +                married>-9  & urban>-9    &
>> +                smhmyes>-9  & smhmno>-9   & smhmnoru>-9 &
>> +                workouts>-9 & seconhan>-9 & reliyes>-9)
>>
>>> exclude<-      prim==-9     | highsch==-9  | tert==-9 |
>> +                govt==-9     | nongovt==-9  |
>> +                married==-9  | urban==-9    |
>> +                smhmyes==-9  | smhmno==-9   | smhmnoru==-9 |
>> +                workouts==-9 | seconhan==-9 | reliyes==-9
>> Error: object 'prim' not found
>>> mydata<-subset(mydata,-exclude)
>> Error in eval(e, x, parent.frame()) : object 'exclude' not found
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7Crmh%40temple.edu%7Ca1d470378fc24c832f7708d99043b804%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637699443365577347%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=DFLP8ZLggvu1NVs9ufyWUdT5hJNKd0v7UYwcHCXncVk%3D&amp;reserved=0
>> PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7Crmh%40temple.edu%7Ca1d470378fc24c832f7708d99043b804%7C716e81efb52244738e3110bd02ccf6e5%7C0%7C0%7C637699443365577347%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=4g2tnLBCnnWezCp%2FZIYFRCxrIKa4VDD46WRQohT5Ftk%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Oct 16 03:46:04 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 15 Oct 2021 18:46:04 -0700
Subject: [R] Subset command
In-Reply-To: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
References: <3a5e4e85-fe17-bec7-9e89-cb693c2485b7@ntu.edu.tw>
Message-ID: <CAGxFJbQ19nfqV4o3_RgRRkADC_ZcjmEGKMtyGH9xk74dGWuh2g@mail.gmail.com>

I assume that prim, etc. are columns of your data frame, mydata. Ergo, the
error message "prim not found" as 'prim' etc. does not exist in the Global
environment.

exclude <- with(mydata, prim == -9, etc. ) should get what you want to
evaluate your second subset statement if I have understood correctly, as it
will look for those names within mydata.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Oct 15, 2021 at 6:24 PM Steven Yen <styen at ntu.edu.tw> wrote:

> The following "subset command works. I was hoping the second would as
> well but it does not.
>
> My definition of exclude is rejected.
>
> Help please? Thanks.
>
>  > mydata<-subset(mydata,
> +                prim>-9     & highsch>-9  & tert>-9 &
> +                govt>-9     & nongovt>-9  &
> +                married>-9  & urban>-9    &
> +                smhmyes>-9  & smhmno>-9   & smhmnoru>-9 &
> +                workouts>-9 & seconhan>-9 & reliyes>-9)
>
>  > exclude<-      prim==-9     | highsch==-9  | tert==-9 |
> +                govt==-9     | nongovt==-9  |
> +                married==-9  | urban==-9    |
> +                smhmyes==-9  | smhmno==-9   | smhmnoru==-9 |
> +                workouts==-9 | seconhan==-9 | reliyes==-9
> Error: object 'prim' not found
>  > mydata<-subset(mydata,-exclude)
> Error in eval(e, x, parent.frame()) : object 'exclude' not found
>  >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m||o@@z@rkov|c @end|ng |rom gm@||@com  Sat Oct 16 17:51:17 2021
From: m||o@@z@rkov|c @end|ng |rom gm@||@com (=?UTF-8?B?TWlsb8WhIMW9YXJrb3ZpxIc=?=)
Date: Sat, 16 Oct 2021 17:51:17 +0200
Subject: [R] Chi-square test: Specifying expected proportions for two way
 table
Message-ID: <CANgWSHAqzbC0URS2Kt0xjRPe6oL-OvxR2gfYrV0yf0NYJZYEZw@mail.gmail.com>

Hi,

Is there a function where I can specify expected proportions for the
two-way table to
calculate the Chi-square test? chisq.test allows specifying only the
one-way table.
Otherwise, I will have to write the function, but I never trust myself not
to make a mess
programing.

Thanks,

Milo?

Milo? ?arkovi?
Professor of Internal Medicine
School of Medicine, University of Belgrade
Clinic of Endocrinology, Clinical Centre of Serbia
11000 Belgrade
PAK 112113
Serbia
Phone +381 11 3639 724
email milos.zarkovic at med.bg.ac.rs
        milos.zarkovic at gmail.com

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Oct 16 18:12:35 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 16 Oct 2021 09:12:35 -0700
Subject: [R] 
 Chi-square test: Specifying expected proportions for two way table
In-Reply-To: <CANgWSHAqzbC0URS2Kt0xjRPe6oL-OvxR2gfYrV0yf0NYJZYEZw@mail.gmail.com>
References: <CANgWSHAqzbC0URS2Kt0xjRPe6oL-OvxR2gfYrV0yf0NYJZYEZw@mail.gmail.com>
Message-ID: <CAGxFJbRNCTj6F1G1fo_z7mcRV9D40vGx4bOfhC9WxmfTQmt9pQ@mail.gmail.com>

Perhaps I misunderstand, but ?chisq.test explicitly says:

"If x is a matrix with at least two rows and columns, it is taken as a
two-dimensional contingency table: the entries of x must be
non-negative integers. Otherwise, x and y must be vectors or factors
of the same length; cases with missing values are removed, the objects
are coerced to factors, and the contingency table is computed from
these. Then Pearson's chi-squared test is performed of the null
hypothesis that the joint distribution of the cell counts in a
2-dimensional contingency table is the product of the row and column
marginals."

Moreover, expected counts are one component of the returned result
(see the "value" section). Proportions can of course easily then be
obtained if so desired.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Oct 16, 2021 at 8:52 AM Milo? ?arkovi? <milos.zarkovic at gmail.com> wrote:
>
> Hi,
>
> Is there a function where I can specify expected proportions for the
> two-way table to
> calculate the Chi-square test? chisq.test allows specifying only the
> one-way table.
> Otherwise, I will have to write the function, but I never trust myself not
> to make a mess
> programing.
>
> Thanks,
>
> Milo?
>
> Milo? ?arkovi?
> Professor of Internal Medicine
> School of Medicine, University of Belgrade
> Clinic of Endocrinology, Clinical Centre of Serbia
> 11000 Belgrade
> PAK 112113
> Serbia
> Phone +381 11 3639 724
> email milos.zarkovic at med.bg.ac.rs
>         milos.zarkovic at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Oct 17 05:31:35 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 17 Oct 2021 16:31:35 +1300
Subject: [R] New version of the deldir package.
Message-ID: <20211017163135.3ac74008@rolf-Latitude-E7470>


A substantially revised version of deldir (1.0-5) has recently been
installed on CRAN.  The package has been tidied up a bit, the
(essentially unused) dummy points facility has been removed, and
various bugs and documentation infelicities have been fixed.

The argument processing protocol has been changed slightly, but
most (for some value of "most") calls made with the previous syntax
should still work.  When the unexpected happens, read the help!!!

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Oct 17 05:46:57 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 17 Oct 2021 16:46:57 +1300
Subject: [R] New version of mixreg.
Message-ID: <20211017164657.4a9a1bf1@rolf-Latitude-E7470>


A very much revised version (2.0-10) of the mixreg (mixtures of
regressions) package has recently been installed on CRAN. The previously
existing version (0.0-6) was long overdue for an overhaul.

The new version now provides a formula oriented syntax for the
main function (mixreg()).  An important addition is the function
visualFit() which allows the user to determine starting values by
visual/graphical means (in the case of models with a single predictor).

A vignette "mystMix" ("The Mysteries of Mixtures of Regressions") has
been added to the package.

I am confident that this package will now be much more useful than
it was previously.

Enjoy! :-)

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From p@m|rnov2000 @end|ng |rom gm@||@com  Fri Oct 15 22:31:18 2021
From: p@m|rnov2000 @end|ng |rom gm@||@com (petr smirnov)
Date: Fri, 15 Oct 2021 16:31:18 -0400
Subject: [R] Does intersect preserve order?
Message-ID: <CABAj7xcmtSD9OC0smNoD3yD0=aEFFVFe00KAOZ+E7qjSV4Owyg@mail.gmail.com>

Hi,

Is base::intersect guaranteed to return items in the order they (first)
appear in the first argument? I couldn't find any mention of this in the
help file for set operations.

If so, could this be documented on the help page?

Thanks,
Petr

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Oct 17 11:49:15 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 17 Oct 2021 05:49:15 -0400
Subject: [R] Does intersect preserve order?
In-Reply-To: <CABAj7xcmtSD9OC0smNoD3yD0=aEFFVFe00KAOZ+E7qjSV4Owyg@mail.gmail.com>
References: <CABAj7xcmtSD9OC0smNoD3yD0=aEFFVFe00KAOZ+E7qjSV4Owyg@mail.gmail.com>
Message-ID: <8a7fd033-a006-8b83-8804-84d4e9ffaf12@gmail.com>

On 15/10/2021 4:31 p.m., petr smirnov wrote:
> Hi,
> 
> Is base::intersect guaranteed to return items in the order they (first)
> appear in the first argument? I couldn't find any mention of this in the
> help file for set operations.

No, that's just what the current implementation does.

It's conceivable that swapping x and y could let it be faster in some 
circumstances.  Or maybe there's a completely different implementation 
that's better for some data types.  In either of those cases the order 
could change.

Generally speaking, the functions that treat vectors as sets make no 
assumptions and no guarantees about order, because sets are unordered.

If you need the current behaviour to be guaranteed, probably the easiest 
way is to copy the function:  it's very simple.

Duncan Murdoch

> 
> If so, could this be documented on the help page?
> 
> Thanks,
> Petr


From er|cjberger @end|ng |rom gm@||@com  Sun Oct 17 11:56:50 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 17 Oct 2021 12:56:50 +0300
Subject: [R] Does intersect preserve order?
In-Reply-To: <8a7fd033-a006-8b83-8804-84d4e9ffaf12@gmail.com>
References: <CABAj7xcmtSD9OC0smNoD3yD0=aEFFVFe00KAOZ+E7qjSV4Owyg@mail.gmail.com>
 <8a7fd033-a006-8b83-8804-84d4e9ffaf12@gmail.com>
Message-ID: <CAGgJW74meQNg54Xb3sfWNNyhd2ao50N17kc2GsY-3cfNrFxrgw@mail.gmail.com>

As Duncan notes, it is easy to get the current implementation. Just type
the function name at the prompt:

> intersect
{
     y <- as.vector(y)
    unique(y[match(as.vector(x), y, 0L)])
}

On Sun, Oct 17, 2021 at 12:49 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 15/10/2021 4:31 p.m., petr smirnov wrote:
> > Hi,
> >
> > Is base::intersect guaranteed to return items in the order they (first)
> > appear in the first argument? I couldn't find any mention of this in the
> > help file for set operations.
>
> No, that's just what the current implementation does.
>
> It's conceivable that swapping x and y could let it be faster in some
> circumstances.  Or maybe there's a completely different implementation
> that's better for some data types.  In either of those cases the order
> could change.
>
> Generally speaking, the functions that treat vectors as sets make no
> assumptions and no guarantees about order, because sets are unordered.
>
> If you need the current behaviour to be guaranteed, probably the easiest
> way is to copy the function:  it's very simple.
>
> Duncan Murdoch
>
> >
> > If so, could this be documented on the help page?
> >
> > Thanks,
> > Petr
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Sun Oct 17 22:23:06 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 17 Oct 2021 15:23:06 -0500
Subject: [R] here Package
References: <00fd01d7c394$cb8fe420$62afac60$.ref@sbcglobal.net>
Message-ID: <00fd01d7c394$cb8fe420$62afac60$@sbcglobal.net>

R-help

 

I have a R project that contains an R Notebook and I am trying to use the
"here" function  to access a file.  Before using R projects file I would set
the working dir in a R setup chunk and run the following command (for
example)

 

creditsub <- read.csv(unz(Data.zip", "creditcardsub.csv"))

 

This works just fine but I'm trying to see if I can use the here function
now but no luck. I sort of assumed it would be something like 

 

creditsub <- read.csv(unz(here::here(Data.zip", "creditcardsub.csv"))) -
nope. I've also tried placing it in other locations  still no luck so I'm
wondering if I can even use it in this application

 

Jeff

 


	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Sun Oct 17 22:35:25 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Sun, 17 Oct 2021 16:35:25 -0400
Subject: [R] here Package
In-Reply-To: <00fd01d7c394$cb8fe420$62afac60$@sbcglobal.net>
References: <00fd01d7c394$cb8fe420$62afac60$.ref@sbcglobal.net>
 <00fd01d7c394$cb8fe420$62afac60$@sbcglobal.net>
Message-ID: <CAPcHnpSmxGwkeQzHYy02wM5UDRy2jVgtwwXb5C7ifOrfUO_HSA@mail.gmail.com>

You've just got the brackets in the wrong spot:


creditsub <- read.csv(unz(here::here("Data.zip"), "creditcardsub.csv"))

instead of

creditsub <- read.csv(unz(here::here("Data.zip", "creditcardsub.csv")))


Also, you probably want to save that connection and close it manually.


creditsub <- read.csv(con <- unz(here::here("Data.zip"),
"creditcardsub.csv")) ; close(con)


I hope this helps!

On Sun, Oct 17, 2021 at 4:23 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> R-help
>
>
>
> I have a R project that contains an R Notebook and I am trying to use the
> "here" function  to access a file.  Before using R projects file I would
> set
> the working dir in a R setup chunk and run the following command (for
> example)
>
>
>
> creditsub <- read.csv(unz(Data.zip", "creditcardsub.csv"))
>
>
>
> This works just fine but I'm trying to see if I can use the here function
> now but no luck. I sort of assumed it would be something like
>
>
>
> creditsub <- read.csv(unz(here::here(Data.zip", "creditcardsub.csv"))) -
> nope. I've also tried placing it in other locations  still no luck so I'm
> wondering if I can even use it in this application
>
>
>
> Jeff
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Oct 18 00:59:23 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 17 Oct 2021 18:59:23 -0400
Subject: [R] Does intersect preserve order?
In-Reply-To: <8a7fd033-a006-8b83-8804-84d4e9ffaf12@gmail.com>
References: <CABAj7xcmtSD9OC0smNoD3yD0=aEFFVFe00KAOZ+E7qjSV4Owyg@mail.gmail.com>
 <8a7fd033-a006-8b83-8804-84d4e9ffaf12@gmail.com>
Message-ID: <01ef01d7c3aa$a0c12c70$e2438550$@verizon.net>

intersect() is a generic function so the question is which one does someone
want to know if it remains in the same order?

But a deeper question is what ORDER? 

intersect(A, B)
intersect(B, A)

Note the results have to be the same but not the order unless they start
sorted the same way.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Duncan Murdoch
Sent: Sunday, October 17, 2021 5:49 AM
To: petr smirnov <psmirnov2000 at gmail.com>; r-help at r-project.org
Subject: Re: [R] Does intersect preserve order?

On 15/10/2021 4:31 p.m., petr smirnov wrote:
> Hi,
> 
> Is base::intersect guaranteed to return items in the order they 
> (first) appear in the first argument? I couldn't find any mention of 
> this in the help file for set operations.

No, that's just what the current implementation does.

It's conceivable that swapping x and y could let it be faster in some
circumstances.  Or maybe there's a completely different implementation
that's better for some data types.  In either of those cases the order could
change.

Generally speaking, the functions that treat vectors as sets make no
assumptions and no guarantees about order, because sets are unordered.

If you need the current behaviour to be guaranteed, probably the easiest way
is to copy the function:  it's very simple.

Duncan Murdoch

> 
> If so, could this be documented on the help page?
> 
> Thanks,
> Petr

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Mon Oct 18 01:08:16 2021
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Sun, 17 Oct 2021 18:08:16 -0500
Subject: [R] here Package
In-Reply-To: <CAPcHnpSmxGwkeQzHYy02wM5UDRy2jVgtwwXb5C7ifOrfUO_HSA@mail.gmail.com>
References: <00fd01d7c394$cb8fe420$62afac60$.ref@sbcglobal.net>
 <00fd01d7c394$cb8fe420$62afac60$@sbcglobal.net>
 <CAPcHnpSmxGwkeQzHYy02wM5UDRy2jVgtwwXb5C7ifOrfUO_HSA@mail.gmail.com>
Message-ID: <011001d7c3ab$df395760$9dac0620$@sbcglobal.net>

Andrew

 

Thank you so much. That was an easy fix. 

 

I you have some time I?d like some more info on the close function close(con)

 

Jeff

 

From: Andrew Simmons <akwsimmo at gmail.com> 
Sent: Sunday, October 17, 2021 3:35 PM
To: reichmanj at sbcglobal.net
Cc: R-help Mailing List <R-help at r-project.org>
Subject: Re: [R] here Package

 

You've just got the brackets in the wrong spot:

 

 

creditsub <- read.csv(unz(here::here("Data.zip"), "creditcardsub.csv")) 

 

instead of

 

creditsub <- read.csv(unz(here::here("Data.zip", "creditcardsub.csv"))) 

 

 

Also, you probably want to save that connection and close it manually.

 

 

creditsub <- read.csv(con <- unz(here::here("Data.zip"), "creditcardsub.csv")) ; close(con)

 

 

I hope this helps! 

 

On Sun, Oct 17, 2021 at 4:23 PM Jeff Reichman <reichmanj at sbcglobal.net <mailto:reichmanj at sbcglobal.net> > wrote:

R-help



I have a R project that contains an R Notebook and I am trying to use the
"here" function  to access a file.  Before using R projects file I would set
the working dir in a R setup chunk and run the following command (for
example)



creditsub <- read.csv(unz(Data.zip", "creditcardsub.csv"))



This works just fine but I'm trying to see if I can use the here function
now but no luck. I sort of assumed it would be something like 



creditsub <- read.csv(unz(here::here(Data.zip", "creditcardsubcsv"))) -
nope. I've also tried placing it in other locations  still no luck so I'm
wondering if I can even use it in this application



Jeff




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Mon Oct 18 03:14:42 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Mon, 18 Oct 2021 01:14:42 +0000
Subject: [R] Rising and falling bar-plots simultaneously
Message-ID: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

Sorry for a very basic question. I have the following data set containing 2 columns.

> dput(BAS1)

structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
2L))

I want to draw bar chart in such a way that column 1 is drawn on primary y axis with bars rising, while the column 2 is draw on a secondary y axis with bar-plots falling down from the top exactly on the top of rising bars. For example, the plot of 1st row of column one should be overshadowed by the bar of 1st row of column 2. Additionally, I want all the bars to be red while 3rd and 102nd bar of rising and falling bars to be coloured green.

I hope I am clear ?. Thank-you very much in advance.



regards,

Eliza

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Mon Oct 18 04:41:22 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Mon, 18 Oct 2021 02:41:22 +0000
Subject: [R] [External]  Rising and falling bar-plots simultaneously
In-Reply-To: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <27072361-ECFC-49FB-8C0F-BB742DE78134@temple.edu>

This does what I think you are asking for.

If this isn't what you are looking for, please draw by brute force what you want
for just the first 6 rows and post the R code.  Or draw by hand for just the first 6 rows and post a png.

## install.packages("HH") ## if you don't already have HH
library(HH)

tmp <- cbind(BAS1[,2], 0, BAS1[,1], 0)
tmp[c(3,102), c(2:1, 4:3)] <- tmp[c(3,102),]
likert(tmp, horizontal=FALSE, col=c("red","green","red","green"), scales=list(x=list(rot=90, cex=.4)))


> On Oct 17, 2021, at 21:14, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
>> BAS1)
> 
> structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
> 3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
> 3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
> 4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
> 3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
> 3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
> 4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
> 2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
> 6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
> 3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
> 3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
> 3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
> 2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
> 2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
> 6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
> 6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
> 2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
> 2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
> 2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
> 6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
> 2L))


From drj|m|emon @end|ng |rom gm@||@com  Mon Oct 18 06:01:53 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 18 Oct 2021 15:01:53 +1100
Subject: [R] Rising and falling bar-plots simultaneously
In-Reply-To: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>

Hi Eliza,
Try this:

BAS1<-
structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
2L))
library(plotrix)
x11(width=12,height=5)
barp(BAS1[,1],main="Plot of BAS1",ylim=c(0,10),col="green")
plotlim<-par("usr")
rect(seq(0.6,123.6,1),plotlim[4]-BAS1[,2],
 seq(1.4,124.4,1),plotlim[4],col="red")

This clearly needs refinement, but it's a start.

Jim

On Mon, Oct 18, 2021 at 12:15 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> Sorry for a very basic question. I have the following data set containing 2 columns.
>
> > dput(BAS1)
>
> structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
> 3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
> 3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
> 4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
> 3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
> 3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
> 4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
> 2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
> 6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
> 3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
> 3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
> 3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
> 2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
> 2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
> 6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
> 6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
> 2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
> 2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
> 2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
> 6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
> 2L))
>
> I want to draw bar chart in such a way that column 1 is drawn on primary y axis with bars rising, while the column 2 is draw on a secondary y axis with bar-plots falling down from the top exactly on the top of rising bars. For example, the plot of 1st row of column one should be overshadowed by the bar of 1st row of column 2. Additionally, I want all the bars to be red while 3rd and 102nd bar of rising and falling bars to be coloured green.
>
> I hope I am clear ?. Thank-you very much in advance.
>
>
>
> regards,
>
> Eliza
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|n||68 @end|ng |rom gm@||@com  Mon Oct 18 08:04:47 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Mon, 18 Oct 2021 17:04:47 +1100
Subject: [R] spm2: A new package for (spatial) predictive modelling
Message-ID: <CAGu_3ZL5cc2AY7XNVxFcaUqKhPSS_YqDiZgmJfhSjOxPVzuDBg@mail.gmail.com>

Dear all,

A new package, spm2_1.1.0, for (spatial) predictive modelling has just been
made available on CRAN. It is an updated and extended version of 'spm'
package, by introducing some further novel functions for modern statistical
methods (i.e., generalised linear models, glmnet,  generalised least
squares), support vector machine, .... For each method, two functions are
provided, with one  function for assessing the predictive errors and
accuracy of the method based on cross-validation, and the other for
generating spatial predictions. It also contains a couple of functions for
data preparation and predictive accuracy assessment.

Any feedback is welcome and appreciated.

-- 
Jin
------------------------------------------
Jin Li, PhD
Founder, Data2action, Australia
https://www.researchgate.net/profile/Jin_Li32
https://scholar.google.com/citations?user=Jeot53EAAAAJ&hl=en

	[[alternative HTML version deleted]]


From @tch|rume @end|ng |rom gm@||@com  Mon Oct 18 13:26:11 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Mon, 18 Oct 2021 13:26:11 +0200
Subject: [R] creating a new variable and merging it on the dataframe
In-Reply-To: <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
Message-ID: <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>

Good day colleagues. Below is a csv file attached which i am using in my
analysis.



hh.id

hd17.perm

hd17employ

health.exp

total.food.exp

total.nfood.exp

1

2

yes

1654

23654

23655

2

2

yes

2564

265897

65984

3

6

no

2547

123311

52416

4

8

no

5698

13648

12544

5

6

no

1254

36549

12365

6

8

yes

1236

236541

26522

7

8

no

4521

13264

23698





So I created a df using the above csv file as follows

wbpractice <- read.csv("world_practice.csv")

Now, I wanted to create a new variable called gap and scripted and executed
the following command :

wbpractice %>%

mutate(gap = total.food.exp-total.nfood.exp)  #gen a variable



By recalling  wbpractice, I could not see the new variable created. Running
the command;

names(wbpractice)



shows the old variables only. Any help on how to append the newly created
variable on my data?


Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504



>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Oct 18 13:34:48 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 18 Oct 2021 11:34:48 +0000
Subject: [R] creating a new variable and merging it on the dataframe
In-Reply-To: <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
Message-ID: <974651b34694405d95a4e5501af373ee@SRVEXCHCM1302.precheza.cz>

Hi

I cannot say anything about mutate but

read.csv results in data frame

you can use then

wbpractice$gap <- with(wbpractice, total.food.exp-total.nfood.exp)

Cheers
Petr

BTW, do not use HTML formating your email is a mess.


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Admire Tarisirayi
> Chirume
> Sent: Monday, October 18, 2021 1:26 PM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: [R] creating a new variable and merging it on the dataframe
> 
> Good day colleagues. Below is a csv file attached which i am using in my
> analysis.
> 
> 
> 
> hh.id
> 
> hd17.perm
> 
> hd17employ
> 
> health.exp
> 
> total.food.exp
> 
> total.nfood.exp
> 
> 1
> 
> 2
> 
> yes
> 
> 1654
> 
> 23654
> 
> 23655
> 
> 2
> 
> 2
> 
> yes
> 
> 2564
> 
> 265897
> 
> 65984
> 
> 3
> 
> 6
> 
> no
> 
> 2547
> 
> 123311
> 
> 52416
> 
> 4
> 
> 8
> 
> no
> 
> 5698
> 
> 13648
> 
> 12544
> 
> 5
> 
> 6
> 
> no
> 
> 1254
> 
> 36549
> 
> 12365
> 
> 6
> 
> 8
> 
> yes
> 
> 1236
> 
> 236541
> 
> 26522
> 
> 7
> 
> 8
> 
> no
> 
> 4521
> 
> 13264
> 
> 23698
> 
> 
> 
> 
> 
> So I created a df using the above csv file as follows
> 
> wbpractice <- read.csv("world_practice.csv")
> 
> Now, I wanted to create a new variable called gap and scripted and
executed
> the following command :
> 
> wbpractice %>%
> 
> mutate(gap = total.food.exp-total.nfood.exp)  #gen a variable
> 
> 
> 
> By recalling  wbpractice, I could not see the new variable created.
Running
> the command;
> 
> names(wbpractice)
> 
> 
> 
> shows the old variables only. Any help on how to append the newly created
> variable on my data?
> 
> 
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
> 
> 
> 
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From g@@mo||n@k|1 @end|ng |rom gm@||@com  Mon Oct 18 14:09:51 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Mon, 18 Oct 2021 14:09:51 +0200
Subject: [R] creating a new variable and merging it on the dataframe
In-Reply-To: <974651b34694405d95a4e5501af373ee@SRVEXCHCM1302.precheza.cz>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <974651b34694405d95a4e5501af373ee@SRVEXCHCM1302.precheza.cz>
Message-ID: <CABxpnnnJ=L2V53HZRTKrcQtyZvhRbKKB+wLQ-_pvStbePBi9cA@mail.gmail.com>

Hi,

If you had really just used:

wbpractice %>%
mutate(gap = total.food.exp-total.nfood.exp)  #gen a variable

and then checked by:

names(wbpractice)

then the problem is just with missed assignment, i.e. it should be:

wbpractice <- wbpractice %>%
mutate(gap = total.food.exp-total.nfood.exp)  #gen a variable

Best regards,
Grzegorz

pon., 18 pa? 2021 o 13:37 PIKAL Petr <petr.pikal at precheza.cz> napisa?(a):
>
> Hi
>
> I cannot say anything about mutate but
>
> read.csv results in data frame
>
> you can use then
>
> wbpractice$gap <- with(wbpractice, total.food.exp-total.nfood.exp)
>
> Cheers
> Petr
>
> BTW, do not use HTML formating your email is a mess.
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Admire Tarisirayi
> > Chirume
> > Sent: Monday, October 18, 2021 1:26 PM
> > To: Jim Lemon <drjimlemon at gmail.com>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: [R] creating a new variable and merging it on the dataframe
> >
> > Good day colleagues. Below is a csv file attached which i am using in my
> > analysis.
> >
> >
> >
> > hh.id
> >
> > hd17.perm
> >
> > hd17employ
> >
> > health.exp
> >
> > total.food.exp
> >
> > total.nfood.exp
> >
> > 1
> >
> > 2
> >
> > yes
> >
> > 1654
> >
> > 23654
> >
> > 23655
> >
> > 2
> >
> > 2
> >
> > yes
> >
> > 2564
> >
> > 265897
> >
> > 65984
> >
> > 3
> >
> > 6
> >
> > no
> >
> > 2547
> >
> > 123311
> >
> > 52416
> >
> > 4
> >
> > 8
> >
> > no
> >
> > 5698
> >
> > 13648
> >
> > 12544
> >
> > 5
> >
> > 6
> >
> > no
> >
> > 1254
> >
> > 36549
> >
> > 12365
> >
> > 6
> >
> > 8
> >
> > yes
> >
> > 1236
> >
> > 236541
> >
> > 26522
> >
> > 7
> >
> > 8
> >
> > no
> >
> > 4521
> >
> > 13264
> >
> > 23698
> >
> >
> >
> >
> >
> > So I created a df using the above csv file as follows
> >
> > wbpractice <- read.csv("world_practice.csv")
> >
> > Now, I wanted to create a new variable called gap and scripted and
> executed
> > the following command :
> >
> > wbpractice %>%
> >
> > mutate(gap = total.food.exp-total.nfood.exp)  #gen a variable
> >
> >
> >
> > By recalling  wbpractice, I could not see the new variable created.
> Running
> > the command;
> >
> > names(wbpractice)
> >
> >
> >
> > shows the old variables only. Any help on how to append the newly created
> > variable on my data?
> >
> >
> > Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> > Skype: admirechirume
> > Call: +263773369884
> > whatsapp: +818099861504
> >
> >
> >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @tch|rume @end|ng |rom gm@||@com  Mon Oct 18 14:38:35 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Mon, 18 Oct 2021 14:38:35 +0200
Subject: [R] Replacing NA s with the average
In-Reply-To: <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
Message-ID: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>

Good day colleagues. Below is a csv file attached which i am using in my
> analysis.
>
>
>
> household.id <http://hh.id>
>
> hd17.perm
>
> hd17employ
>
> health.exp
>
> total.food.exp
>
> total.nfood.exp
>
> 1
>
> 2
>
> yes
>
> 1654
>
> 23654
>
> 23655
>
> 2
>
> 2
>
> yes
>
> NA
>
> NA
>
> 65984
>
> 3
>
> 6
>
> no
>
> 2547
>
> 123311
>
> 52416
>
> 4
>
> 8
>
> NA
>
> 2365
>
> 13648
>
> 12544
>
> 5
>
> 6
>
> NA
>
> 1254
>
> 36549
>
> 12365
>
> 6
>
> 8
>
> yes
>
> 1236
>
> 236541
>
> 26522
>
> 7
>
> 8
>
> no
>
> NA
>
> 13264
>
> 23698
>
>
>
>
>
> So I created a df using the above and its a csv file as follows
>
> wbpractice <- read.csv("world_practice.csv")
>
> Now i am doing data cleaning and trying to replace all missing values with
> the averages of the respective columns.
>
> the dimension of the actual dataset is;
>
> dim(wbpractice)
[1] 31998    6

I used the following script which i executed by i got some error messages

for(i in 1:ncol( wbpractice  )){
     wbpractice  [is.na( wbpractice  [,i]), i] <- mean( wbpractice  [,i],
na.rm = TRUE)
    }

Any help to replace all NAs with average values in my dataframe?



>
>>

	[[alternative HTML version deleted]]


From e||z@_botto @end|ng |rom out|ook@com  Mon Oct 18 16:11:02 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Mon, 18 Oct 2021 14:11:02 +0000
Subject: [R] Rising and falling bar-plots simultaneously
In-Reply-To: <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
Message-ID: <AS8P194MB0999640AF2387D6B661F89699ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Thanks everyone. It helped.

________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Monday 18 October 2021 04:01
To: Eliza Botto <eliza_botto at outlook.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Rising and falling bar-plots simultaneously

Hi Eliza,
Try this:

BAS1<-
structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
2L))
library(plotrix)
x11(width=12,height=5)
barp(BAS1[,1],main="Plot of BAS1",ylim=c(0,10),col="green")
plotlim<-par("usr")
rect(seq(0.6,123.6,1),plotlim[4]-BAS1[,2],
 seq(1.4,124.4,1),plotlim[4],col="red")

This clearly needs refinement, but it's a start.

Jim

On Mon, Oct 18, 2021 at 12:15 PM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> Sorry for a very basic question. I have the following data set containing 2 columns.
>
> > dput(BAS1)
>
> structure(c(3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 2, 3, 3, 4, 3, 2, 2,
> 3, 2, 3, 3, 3, 4, 5, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3,
> 3, 4, 3, 3, 4, 5, 4, 4, 4, 3, 4, 3, 3, 3, 3, 4, 4, 5, 4, 3, 4,
> 4, 2, 3, 3, 3, 2, 4, 4, 3, 3, 4, 3, 3, 3, 3, 4, 4, 3, 3, 2, 3,
> 3, 3, 3, 2, 5, 2, 4, 3, 2, 3, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 2,
> 3, 4, 3, 4, 4, 3, 3, 3, 3, 5, 3, 3, 5, 3, 4, 2, 3, 3, 3, 3, 3,
> 4, 3, 3.93, 3.509, 2.464, 2.72, 2.304, 3.517, 3.517, 6.675, 6.597,
> 2.715, 2.849, 2.618, 3.126, 2.715, 3.931, 3.709, 3.931, 4.145,
> 6.585, 3.907, 3.132, 2.568, 3.883, 2.447, 3.517, 7.098, 3.027,
> 3.003, 7.098, 2.374, 2.065, 2.95, 3.559, 5.102, 3.907, 3.204,
> 3.207, 2.791, 2.116, 3.003, 3.003, 3.003, 6.049, 3.52, 2.241,
> 3.883, 4.145, 3.334, 3.151, 6.269, 4.04, 3.883, 2.27, 3.304,
> 2.464, 4.111, 2.728, 3.93, 3.911, 2.447, 3.202, 2.375, 2.442,
> 2.442, 2.592, 2.13, 3.122, 5.657, 6.076, 4.186, 2.115, 2.623,
> 6.076, 2.467, 2.623, 2.629, 2.517, 2.623, 2.517, 4.32, 4.045,
> 6.597, 4.079, 3.817, 3.521, 2.564, 3.071, 2.447, 3.334, 2.442,
> 2.248, 3.094, 4.045, 4.045, 2.252, 2.971, 3.727, 2.184, 2.783,
> 2.849, 3.529, 2.484, 2.184, 2.313, 2.512, 3.4, 4.096, 3.572,
> 2.663, 3.405, 5.102, 3.267, 2.987, 2.123, 3.47, 2.512, 2.783,
> 6.597, 6.435, 4.921, 3.351, 2.07, 2.07, 2.442), .Dim = c(124L,
> 2L))
>
> I want to draw bar chart in such a way that column 1 is drawn on primary y axis with bars rising, while the column 2 is draw on a secondary y axis with bar-plots falling down from the top exactly on the top of rising bars. For example, the plot of 1st row of column one should be overshadowed by the bar of 1st row of column 2. Additionally, I want all the bars to be red while 3rd and 102nd bar of rising and falling bars to be coloured green.
>
> I hope I am clear ?. Thank-you very much in advance.
>
>
>
> regards,
>
> Eliza
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Oct 18 16:43:35 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 18 Oct 2021 14:43:35 +0000
Subject: [R] Replacing NA s with the average
In-Reply-To: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
Message-ID: <97f0dff5ab204a7eb7ef583ff698eb8b@SRVEXCHCM1302.precheza.cz>

Hi.

sometimes is worth to try google first

R fill NA with average

resulted in

https://stackoverflow.com/questions/25835643/replace-missing-values-with-col
umn-mean

and from that

library(zoo)
na.aggregate(DF)

will replace all numeric NA values with column averages.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Admire Tarisirayi
> Chirume
> Sent: Monday, October 18, 2021 2:39 PM
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: [R] Replacing NA s with the average
> 
> Good day colleagues. Below is a csv file attached which i am using in my
> > analysis.
> >
> >
> >
> > household.id <http://hh.id>
> >
> > hd17.perm
> >
> > hd17employ
> >
> > health.exp
> >
> > total.food.exp
> >
> > total.nfood.exp
> >
> > 1
> >
> > 2
> >
> > yes
> >
> > 1654
> >
> > 23654
> >
> > 23655
> >
> > 2
> >
> > 2
> >
> > yes
> >
> > NA
> >
> > NA
> >
> > 65984
> >
> > 3
> >
> > 6
> >
> > no
> >
> > 2547
> >
> > 123311
> >
> > 52416
> >
> > 4
> >
> > 8
> >
> > NA
> >
> > 2365
> >
> > 13648
> >
> > 12544
> >
> > 5
> >
> > 6
> >
> > NA
> >
> > 1254
> >
> > 36549
> >
> > 12365
> >
> > 6
> >
> > 8
> >
> > yes
> >
> > 1236
> >
> > 236541
> >
> > 26522
> >
> > 7
> >
> > 8
> >
> > no
> >
> > NA
> >
> > 13264
> >
> > 23698
> >
> >
> >
> >
> >
> > So I created a df using the above and its a csv file as follows
> >
> > wbpractice <- read.csv("world_practice.csv")
> >
> > Now i am doing data cleaning and trying to replace all missing values
> > with the averages of the respective columns.
> >
> > the dimension of the actual dataset is;
> >
> > dim(wbpractice)
> [1] 31998    6
> 
> I used the following script which i executed by i got some error messages
> 
> for(i in 1:ncol( wbpractice  )){
>      wbpractice  [is.na( wbpractice  [,i]), i] <- mean( wbpractice  [,i],
na.rm =
> TRUE)
>     }
> 
> Any help to replace all NAs with average values in my dataframe?
> 
> 
> 
> >
> >>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 18 16:58:38 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 18 Oct 2021 15:58:38 +0100
Subject: [R] Replacing NA s with the average
In-Reply-To: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
Message-ID: <4af5526c-9bb8-21a1-8063-a2d0ce54523b@sapo.pt>

Hello,

Please don't post in HTML, post in plain text like the posting guide 
asks for. Your data is unreadable.

Here are two test data sets, one with all columns numeric, the other 
with some columns numeric.


wbpractice1 <- mtcars  # all columns are numeric
wbpractice2 <- iris    # not all columns are numeric
wbpractice1[] <- lapply(wbpractice1, \(x){
   is.na(x) <- sample(length(x), 0.25*length(x))
   x
})
wbpractice2[-5] <- lapply(wbpractice2[-5], \(x){
   is.na(x) <- sample(length(x), 0.25*length(x))
   x
})


#---

If all columns are numeric just lapply an anonymous function to each of 
them replacing the values where is.na is TRUE by the mean.


wbpractice1[] <- lapply(wbpractice1, \(x){
   x[is.na(x)] <- mean(x, na.rm = TRUE)
   x
})


But if some columns are not numeric, determine which are first, then 
apply the same code to that subset.


num_cols <- sapply(wbpractice2, is.numeric)
wbpractice2[num_cols] <- lapply(wbpractice2[num_cols], \(x){
   x[is.na(x)] <- mean(x, na.rm = TRUE)
   x
})


And here are dplyr solutions.


library(dplyr)

wbpractice1 %>%
   mutate(across(everything(), ~ifelse(is.na(.x), mean(.x, na.rm = 
TRUE), .x)))

wbpractice2 %>%
   mutate(across(where(is.numeric), ~ifelse(is.na(.x), mean(.x, na.rm = 
TRUE), .x)))



Hope this helps,

Rui Barradas


?s 13:38 de 18/10/21, Admire Tarisirayi Chirume escreveu:
> Good day colleagues. Below is a csv file attached which i am using in my
>> analysis.
>>
>>
>>
>> household.id <http://hh.id>
>>
>> hd17.perm
>>
>> hd17employ
>>
>> health.exp
>>
>> total.food.exp
>>
>> total.nfood.exp
>>
>> 1
>>
>> 2
>>
>> yes
>>
>> 1654
>>
>> 23654
>>
>> 23655
>>
>> 2
>>
>> 2
>>
>> yes
>>
>> NA
>>
>> NA
>>
>> 65984
>>
>> 3
>>
>> 6
>>
>> no
>>
>> 2547
>>
>> 123311
>>
>> 52416
>>
>> 4
>>
>> 8
>>
>> NA
>>
>> 2365
>>
>> 13648
>>
>> 12544
>>
>> 5
>>
>> 6
>>
>> NA
>>
>> 1254
>>
>> 36549
>>
>> 12365
>>
>> 6
>>
>> 8
>>
>> yes
>>
>> 1236
>>
>> 236541
>>
>> 26522
>>
>> 7
>>
>> 8
>>
>> no
>>
>> NA
>>
>> 13264
>>
>> 23698
>>
>>
>>
>>
>>
>> So I created a df using the above and its a csv file as follows
>>
>> wbpractice <- read.csv("world_practice.csv")
>>
>> Now i am doing data cleaning and trying to replace all missing values with
>> the averages of the respective columns.
>>
>> the dimension of the actual dataset is;
>>
>> dim(wbpractice)
> [1] 31998    6
> 
> I used the following script which i executed by i got some error messages
> 
> for(i in 1:ncol( wbpractice  )){
>       wbpractice  [is.na( wbpractice  [,i]), i] <- mean( wbpractice  [,i],
> na.rm = TRUE)
>      }
> 
> Any help to replace all NAs with average values in my dataframe?
> 
> 
> 
>>
>>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @nne@p|otet @end|ng |rom gm@||@com  Mon Oct 18 20:59:23 2021
From: @nne@p|otet @end|ng |rom gm@||@com (Anne)
Date: Mon, 18 Oct 2021 20:59:23 +0200
Subject: [R] Insu scribe
Message-ID: <CAK7cGBeyS8EqkqxkixHnkY0xwhrtUFnzfc5WS28XX0+Lkd43JQ@mail.gmail.com>

-- 
Anne ??

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 18 21:33:50 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 18 Oct 2021 20:33:50 +0100
Subject: [R] Insu scribe
In-Reply-To: <CAK7cGBeyS8EqkqxkixHnkY0xwhrtUFnzfc5WS28XX0+Lkd43JQ@mail.gmail.com>
References: <CAK7cGBeyS8EqkqxkixHnkY0xwhrtUFnzfc5WS28XX0+Lkd43JQ@mail.gmail.com>
Message-ID: <978da556-2b19-8adb-3ccb-23bca7074ddf@sapo.pt>

Hello,

Only you can unsubscribe from R-Help.
Please see the link at the bottom of this and every R-Help e-mail.
UNSUBSCRIBE is written in upper case letters.

Hope this helps,

Rui Barradas

?s 19:59 de 18/10/21, Anne escreveu:


From r@oknz @end|ng |rom gm@||@com  Tue Oct 19 03:22:53 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 19 Oct 2021 14:22:53 +1300
Subject: [R] Replacing NA s with the average
In-Reply-To: <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
Message-ID: <CABcYAdL5r-JLAERuNwQDLXtOhvq6d4426KnGbMHZw3x0ybqFYQ@mail.gmail.com>

It *sounds* as though you are trying to impute missing data.
There are better approaches than just plugging in means.
You might want to look into CALIBERrfimpute or missForest.

On Tue, 19 Oct 2021 at 01:39, Admire Tarisirayi Chirume
<atchirume at gmail.com> wrote:
>
> Good day colleagues. Below is a csv file attached which i am using in my
> > analysis.
> >
> >
> >
> > household.id <http://hh.id>
> >
> > hd17.perm
> >
> > hd17employ
> >
> > health.exp
> >
> > total.food.exp
> >
> > total.nfood.exp
> >
> > 1
> >
> > 2
> >
> > yes
> >
> > 1654
> >
> > 23654
> >
> > 23655
> >
> > 2
> >
> > 2
> >
> > yes
> >
> > NA
> >
> > NA
> >
> > 65984
> >
> > 3
> >
> > 6
> >
> > no
> >
> > 2547
> >
> > 123311
> >
> > 52416
> >
> > 4
> >
> > 8
> >
> > NA
> >
> > 2365
> >
> > 13648
> >
> > 12544
> >
> > 5
> >
> > 6
> >
> > NA
> >
> > 1254
> >
> > 36549
> >
> > 12365
> >
> > 6
> >
> > 8
> >
> > yes
> >
> > 1236
> >
> > 236541
> >
> > 26522
> >
> > 7
> >
> > 8
> >
> > no
> >
> > NA
> >
> > 13264
> >
> > 23698
> >
> >
> >
> >
> >
> > So I created a df using the above and its a csv file as follows
> >
> > wbpractice <- read.csv("world_practice.csv")
> >
> > Now i am doing data cleaning and trying to replace all missing values with
> > the averages of the respective columns.
> >
> > the dimension of the actual dataset is;
> >
> > dim(wbpractice)
> [1] 31998    6
>
> I used the following script which i executed by i got some error messages
>
> for(i in 1:ncol( wbpractice  )){
>      wbpractice  [is.na( wbpractice  [,i]), i] <- mean( wbpractice  [,i],
> na.rm = TRUE)
>     }
>
> Any help to replace all NAs with average values in my dataframe?
>
>
>
> >
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ne|@onr@y|14 @end|ng |rom gm@||@com  Fri Oct 15 23:55:29 2021
From: ne|@onr@y|14 @end|ng |rom gm@||@com (Nelson Rayl)
Date: Fri, 15 Oct 2021 14:55:29 -0700
Subject: [R] [R-pkgs] lmForc
Message-ID: <CAKN1paY=J_vzhwvAc-rAbv3q4-wJFuOTdUJv-jfs5w3BqBZrZw@mail.gmail.com>

The R package lmForc (lmForc 0.0.1) is now available on CRAN. lmForc
introduces functions for evaluating linear forecasting models and a new
class for working with forecast data: Forecast. Test linear models
out-of-sample by conditioning on realized values, vintage forecasts, or
lagged values. Create and test performance weighted forecasts
out-of-sample. Collect multiple forecasts and evaluate MSE or RMSE. These
functions are built around the Forecast class which matches the simplicity
and interpretability of linear models.

For additional information and examples, please visit the lmForc GitHub
repository or check out the lmForc vignette.

GitHub:
https://github.com/lucius-verus-fan/lmForc

Vignette:
https://cran.r-project.org/web/packages/lmForc/vignettes/lmForc.html

CRAN:
https://CRAN.R-project.org/package=lmForc

Best,
Nelson Rayl

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 19 09:32:00 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 19 Oct 2021 09:32:00 +0200
Subject: [R] Replacing NA s with the average
In-Reply-To: <CABcYAdL5r-JLAERuNwQDLXtOhvq6d4426KnGbMHZw3x0ybqFYQ@mail.gmail.com>
References: <AS8P194MB099969BD047734F93A7291B19ABC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <CA+8X3fXD4=1f9UTZt8evOiBRLG85LVBusCJ=nZ__Yhervzg1Wg@mail.gmail.com>
 <CAFfFd+vtmz6nYQxGQ8ZReAy2BnVhfhh1=6jDs+PPhK9+6j365A@mail.gmail.com>
 <CAFfFd+sFZOz_uFtGvxWp5SW=tGbSQgd6DJ+gOLf3p1jeSt8wdA@mail.gmail.com>
 <CABcYAdL5r-JLAERuNwQDLXtOhvq6d4426KnGbMHZw3x0ybqFYQ@mail.gmail.com>
Message-ID: <24942.29808.23166.363975@stat.math.ethz.ch>

>>>>> Richard O'Keefe 
>>>>>     on Tue, 19 Oct 2021 14:22:53 +1300 writes:

    > It *sounds* as though you are trying to impute missing data.
    > There are better approaches than just plugging in means.
    > You might want to look into CALIBERrfimpute or missForest.

Yes, indeed!
Put even more strongly:  "Imputation" has been an
important topic for decennia and it has been shown since the
1980s that plugging in columns means can be *very misleading*
for everything you do later with that modified data set.

The Wikipedia page is quite good as short intro
  https://en.wikipedia.org/wiki/Imputation_(statistics)

When I've been teaching about this, I've strongly recommended
multiple imputation and the "state-of-the-art" package  'mice'
which comes with a really good text book:

  Stef van Buuren (2012) -- Flexible Imputation of Missing Data 
  https://doi.org/10.1201/b11826 
  (= reference [12] in the Wikipedia article)

where in the first chapter you see a nice example on how bad
mean imputation typically will be ..

The JSS paper on mice is a more technical (I'd say "to be used
once you are already aware that 'mean imputation' should rarely be used):

> citation(package="mice")

To cite mice in publications use:

  Stef van Buuren, Karin Groothuis-Oudshoorn (2011). mice: Multivariate
  Imputation by Chained Equations in R. Journal of Statistical Software, 45(3),
  1-67. URL https://www.jstatsoft.org/v45/i03/.


Best regards,
Martin Maechler
ETH Zurich   and  R Core team


    > On Tue, 19 Oct 2021 at 01:39, Admire Tarisirayi Chirume
    > <atchirume at gmail.com> wrote:
    >> 
    >> Good day colleagues. Below is a csv file attached which i am using in my
    >> > analysis.
    >> >
    >> >
    >> >
    >> > household.id <http://hh.id>
    >> >
    >> > hd17.perm
    >> >
    >> > hd17employ
    >> >
    >> > health.exp
    >> >
    >> > total.food.exp
    >> >
    >> > total.nfood.exp
    >> >
    >> > 1
    >> >
    >> > 2
    >> >
    >> > yes
    >> >
    >> > 1654
    >> >
    >> > 23654
    >> >
    >> > 23655
    >> >
    >> > 2
    >> >
    >> > 2
    >> >
    >> > yes
    >> >
    >> > NA
    >> >
    >> > NA
    >> >
    >> > 65984
    >> >
    >> > 3
    >> >
    >> > 6
    >> >
    >> > no
    >> >
    >> > 2547
    >> >
    >> > 123311
    >> >
    >> > 52416
    >> >
    >> > 4
    >> >
    >> > 8
    >> >
    >> > NA
    >> >
    >> > 2365
    >> >
    >> > 13648
    >> >
    >> > 12544
    >> >
    >> > 5
    >> >
    >> > 6
    >> >
    >> > NA
    >> >
    >> > 1254
    >> >
    >> > 36549
    >> >
    >> > 12365
    >> >
    >> > 6
    >> >
    >> > 8
    >> >
    >> > yes
    >> >
    >> > 1236
    >> >
    >> > 236541
    >> >
    >> > 26522
    >> >
    >> > 7
    >> >
    >> > 8
    >> >
    >> > no
    >> >
    >> > NA
    >> >
    >> > 13264
    >> >
    >> > 23698
    >> >
    >> >
    >> >
    >> >
    >> >
    >> > So I created a df using the above and its a csv file as follows
    >> >
    >> > wbpractice <- read.csv("world_practice.csv")
    >> >
    >> > Now i am doing data cleaning and trying to replace all missing values with
    >> > the averages of the respective columns.
    >> >
    >> > the dimension of the actual dataset is;
    >> >
    >> > dim(wbpractice)
    >> [1] 31998    6
    >> 
    >> I used the following script which i executed by i got some error messages
    >> 
    >> for(i in 1:ncol( wbpractice  )){
    >> wbpractice  [is.na( wbpractice  [,i]), i] <- mean( wbpractice  [,i],
    >> na.rm = TRUE)
    >> }
    >> 
    >> Any help to replace all NAs with average values in my dataframe?
    >>


From m@rc_grt @end|ng |rom y@hoo@|r  Wed Oct 20 12:19:51 2021
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Wed, 20 Oct 2021 12:19:51 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
Message-ID: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>

Dear R-helpers

Do you know how to not show a "message d'avis" that qbeta reports. 
suppressMessages and capture.output are not working.

(PS I Know that qbeta with shape2 being 1e-7 is "strange"... this is 
obtained during an optimization process. Just I don't want see the 
messages).

Thanks

Marc Girondot

q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 = 0.0000001)
Message d'avis :
Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
 ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate

suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, 
shape2 = 0.0000001))
Message d'avis :
Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
 ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate

capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 
= 0.0000001), type = "message")
character(0)
Message d'avis :
Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
 ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate

capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 
= 0.0000001), type = "output")
character(0)
Message d'avis :
Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
 ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Oct 20 12:28:17 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 20 Oct 2021 12:28:17 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr> (Marc Girondot
 via's message of "Wed, 20 Oct 2021 12:19:51 +0200")
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
Message-ID: <87bl3k2doe.fsf@enricoschumann.net>

On Wed, 20 Oct 2021, Marc Girondot via R-help writes:

> Dear R-helpers
>
> Do you know how to not show a "message d'avis" that
> qbeta reports. suppressMessages and capture.output are
> not working.
>
> (PS I Know that qbeta with shape2 being 1e-7 is
> "strange"... this is obtained during an optimization
> process. Just I don't want see the messages).
>
> Thanks
>
> Marc Girondot
>
> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 = 0.0000001)
> Message d'avis :
> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
> ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>
> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
> 3.3108797, shape2 = 0.0000001))
> Message d'avis :
> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
> ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>
> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
> 3.3108797, shape2 = 0.0000001), type = "message")
> character(0)
> Message d'avis :
> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
> ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>
> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
> 3.3108797, shape2 = 0.0000001), type = "output")
> character(0)
> Message d'avis :
> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
> ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>

Try 'suppressWarnings'.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From m@rc_grt @end|ng |rom y@hoo@|r  Wed Oct 20 12:47:35 2021
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Wed, 20 Oct 2021 12:47:35 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <87bl3k2doe.fsf@enricoschumann.net>
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
 <87bl3k2doe.fsf@enricoschumann.net>
Message-ID: <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>

Thanks ! It works.

So "Warnings" has been translated in French by "Message d'avis :" !
 > warning("Essai")
Message d'avis :
Essai

It is not the best translation...
I would prefer: "Attention: "

Marc

Le 20/10/2021 ? 12:28, Enrico Schumann a ?crit?:
> On Wed, 20 Oct 2021, Marc Girondot via R-help writes:
>
>> Dear R-helpers
>>
>> Do you know how to not show a "message d'avis" that
>> qbeta reports. suppressMessages and capture.output are
>> not working.
>>
>> (PS I Know that qbeta with shape2 being 1e-7 is
>> "strange"... this is obtained during an optimization
>> process. Just I don't want see the messages).
>>
>> Thanks
>>
>> Marc Girondot
>>
>> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 = 0.0000001)
>> Message d'avis :
>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>  ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>
>> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
>> 3.3108797, shape2 = 0.0000001))
>> Message d'avis :
>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>  ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>
>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>> 3.3108797, shape2 = 0.0000001), type = "message")
>> character(0)
>> Message d'avis :
>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>  ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>
>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>> 3.3108797, shape2 = 0.0000001), type = "output")
>> character(0)
>> Message d'avis :
>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>  ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>
> Try 'suppressWarnings'.
>
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Oct 20 13:17:30 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 20 Oct 2021 07:17:30 -0400
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
 <87bl3k2doe.fsf@enricoschumann.net>
 <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>
Message-ID: <111eddeb-9a6b-60ac-9ace-ac6d27b26921@gmail.com>

Translations are done by the translation teams, listed here: 
<https://developer.r-project.org/TranslationTeams.html>.  If you'd like 
to offer help, you could contact someone on that list.

Duncan Murdoch

On 20/10/2021 6:47 a.m., Marc Girondot via R-help wrote:
> Thanks ! It works.
> 
> So "Warnings" has been translated in French by "Message d'avis :" !
>   > warning("Essai")
> Message d'avis :
> Essai
> 
> It is not the best translation...
> I would prefer: "Attention: "
> 
> Marc
> 
> Le 20/10/2021 ? 12:28, Enrico Schumann a ?crit?:
>> On Wed, 20 Oct 2021, Marc Girondot via R-help writes:
>>
>>> Dear R-helpers
>>>
>>> Do you know how to not show a "message d'avis" that
>>> qbeta reports. suppressMessages and capture.output are
>>> not working.
>>>
>>> (PS I Know that qbeta with shape2 being 1e-7 is
>>> "strange"... this is obtained during an optimization
>>> process. Just I don't want see the messages).
>>>
>>> Thanks
>>>
>>> Marc Girondot
>>>
>>> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797, shape2 = 0.0000001)
>>> Message d'avis :
>>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>   ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>>
>>> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>> 3.3108797, shape2 = 0.0000001))
>>> Message d'avis :
>>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>   ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>>
>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>> 3.3108797, shape2 = 0.0000001), type = "message")
>>> character(0)
>>> Message d'avis :
>>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>   ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>>
>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>> 3.3108797, shape2 = 0.0000001), type = "output")
>>> character(0)
>>> Message d'avis :
>>> Dans qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>   ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997 is not accurate
>>>
>> Try 'suppressWarnings'.
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@zh@o @end|ng |rom ye@h@net  Wed Oct 20 14:57:23 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 20 Oct 2021 20:57:23 +0800
Subject: [R] small object but huge RData file exported
Message-ID: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>

Hi there,

I have a RData file that is obtained by save.image() with size about 
74.0 MB (77,608,222 bytes).

When load into R, I measured the size of each object with object.size():

> object.size(combn.rda.m)
105448 bytes
> object.size(cross)
102064 bytes
> object.size(denitr.1)
25032 bytes
> object.size(rda.denitr.1)
600280 bytes
> object.size(xh)
7792 bytes
> object.size(xh.x)
6064 bytes
> object.size(xh.x.1)
24144 bytes
> object.size(xh.x.2)
24144 bytes
> object.size(xh.x.3)
24144 bytes
> object.size(xh.y)
2384 bytes

There are all small objects.

If I delete the largest one "rda.denitr.1", and save.image("xx.RData"). 
It has the size of 22.6 KB (23,244 bytes). All seem OK.

However, when I save(rda.denitr.1, file = "yy.RData"), then it has the 
size of 73.9 MB (77,574,869 bytes).

I don't know why...

Any hint?

Best wishes,

Jinsong


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Oct 20 15:05:55 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 20 Oct 2021 09:05:55 -0400
Subject: [R] small object but huge RData file exported
In-Reply-To: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
Message-ID: <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>

On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
> Hi there,
> 
> I have a RData file that is obtained by save.image() with size about
> 74.0 MB (77,608,222 bytes).
> 
> When load into R, I measured the size of each object with object.size():
> 
>> object.size(combn.rda.m)
> 105448 bytes
>> object.size(cross)
> 102064 bytes
>> object.size(denitr.1)
> 25032 bytes
>> object.size(rda.denitr.1)
> 600280 bytes
>> object.size(xh)
> 7792 bytes
>> object.size(xh.x)
> 6064 bytes
>> object.size(xh.x.1)
> 24144 bytes
>> object.size(xh.x.2)
> 24144 bytes
>> object.size(xh.x.3)
> 24144 bytes
>> object.size(xh.y)
> 2384 bytes
> 
> There are all small objects.
> 
> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
> It has the size of 22.6 KB (23,244 bytes). All seem OK.
> 
> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
> size of 73.9 MB (77,574,869 bytes).
> 
> I don't know why...
> 
> Any hint?

As the docs for object.size() say, "Exactly which parts of the memory 
allocation should be attributed to which object is not clear-cut."  In 
particular, if a function or formula has an associated environment, it 
isn't included, but it is sometimes saved in the image.

So I'd suspect rda.denitr.1 contains something that references an 
environment, and it's an environment that would be saved.  (I forget the 
exact rules, but I think that means it's not the global environment and 
it's not a package environment.)

Duncan Murdoch


From j@zh@o @end|ng |rom ye@h@net  Wed Oct 20 15:20:41 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 20 Oct 2021 21:20:41 +0800
Subject: [R] small object but huge RData file exported
In-Reply-To: <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
Message-ID: <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>

On 2021/10/20 21:05, Duncan Murdoch wrote:
> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>> Hi there,
>>
>> I have a RData file that is obtained by save.image() with size about
>> 74.0 MB (77,608,222 bytes).
>>
>> When load into R, I measured the size of each object with object.size():
>>
>>> object.size(combn.rda.m)
>> 105448 bytes
>>> object.size(cross)
>> 102064 bytes
>>> object.size(denitr.1)
>> 25032 bytes
>>> object.size(rda.denitr.1)
>> 600280 bytes
>>> object.size(xh)
>> 7792 bytes
>>> object.size(xh.x)
>> 6064 bytes
>>> object.size(xh.x.1)
>> 24144 bytes
>>> object.size(xh.x.2)
>> 24144 bytes
>>> object.size(xh.x.3)
>> 24144 bytes
>>> object.size(xh.y)
>> 2384 bytes
>>
>> There are all small objects.
>>
>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>
>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>> size of 73.9 MB (77,574,869 bytes).
>>
>> I don't know why...
>>
>> Any hint?
> 
> As the docs for object.size() say, "Exactly which parts of the memory 
> allocation should be attributed to which object is not clear-cut."? In 
> particular, if a function or formula has an associated environment, it 
> isn't included, but it is sometimes saved in the image.
> 
> So I'd suspect rda.denitr.1 contains something that references an 
> environment, and it's an environment that would be saved.? (I forget the 
> exact rules, but I think that means it's not the global environment and 
> it's not a package environment.)
> 
> Duncan Murdoch


The rda.denitr.1 is only a list with length 2:
rda.denitr.1[[1]] is a vector with length 10;
rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]] 
to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from 
vegan package.

If I
 > a <- rda.denitr.1[[2]][[1]]
 > object.size(a)
59896 bytes
 > save(a, file = "abc.RData")
It also has a large size of 73.9 MB (77,536,611 bytes)

Jinsong


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Oct 20 21:56:50 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 20 Oct 2021 15:56:50 -0400
Subject: [R] small object but huge RData file exported
In-Reply-To: <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
Message-ID: <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>

On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
> On 2021/10/20 21:05, Duncan Murdoch wrote:
>> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>>> Hi there,
>>>
>>> I have a RData file that is obtained by save.image() with size about
>>> 74.0 MB (77,608,222 bytes).
>>>
>>> When load into R, I measured the size of each object with object.size():
>>>
>>>> object.size(combn.rda.m)
>>> 105448 bytes
>>>> object.size(cross)
>>> 102064 bytes
>>>> object.size(denitr.1)
>>> 25032 bytes
>>>> object.size(rda.denitr.1)
>>> 600280 bytes
>>>> object.size(xh)
>>> 7792 bytes
>>>> object.size(xh.x)
>>> 6064 bytes
>>>> object.size(xh.x.1)
>>> 24144 bytes
>>>> object.size(xh.x.2)
>>> 24144 bytes
>>>> object.size(xh.x.3)
>>> 24144 bytes
>>>> object.size(xh.y)
>>> 2384 bytes
>>>
>>> There are all small objects.
>>>
>>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>>
>>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>>> size of 73.9 MB (77,574,869 bytes).
>>>
>>> I don't know why...
>>>
>>> Any hint?
>>
>> As the docs for object.size() say, "Exactly which parts of the memory
>> allocation should be attributed to which object is not clear-cut."? In
>> particular, if a function or formula has an associated environment, it
>> isn't included, but it is sometimes saved in the image.
>>
>> So I'd suspect rda.denitr.1 contains something that references an
>> environment, and it's an environment that would be saved.? (I forget the
>> exact rules, but I think that means it's not the global environment and
>> it's not a package environment.)
>>
>> Duncan Murdoch
> 
> 
> The rda.denitr.1 is only a list with length 2:
> rda.denitr.1[[1]] is a vector with length 10;
> rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
> to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
> vegan package.
> 
> If I
>   > a <- rda.denitr.1[[2]][[1]]
>   > object.size(a)
> 59896 bytes
>   > save(a, file = "abc.RData")
> It also has a large size of 73.9 MB (77,536,611 bytes)
> 
> Jinsong
> 

The rda() function uses formulas.  If it saves the formula in the 
result, then it references the environment of that formula, typically 
the environment where the formula was created.

Duncan Murdoch


From henr|k@bengt@@on @end|ng |rom gm@||@com  Wed Oct 20 22:06:06 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 20 Oct 2021 13:06:06 -0700
Subject: [R] small object but huge RData file exported
In-Reply-To: <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
 <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
Message-ID: <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>

Example illustrating what Duncan says:

> make_formula <- function() { large <- rnorm(1e6); x ~ y }
> formula <- make_formula()

# "Apparent" size of object
> object.size(formula)
728 bytes

# Actual serialization size
> length(serialize(formula, connection = NULL))
[1] 8000203

# A better size estimate
> lobstr::obj_size(formula)
8,000,888 B

/Henrik

On Wed, Oct 20, 2021 at 12:57 PM Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
> > On 2021/10/20 21:05, Duncan Murdoch wrote:
> >> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
> >>> Hi there,
> >>>
> >>> I have a RData file that is obtained by save.image() with size about
> >>> 74.0 MB (77,608,222 bytes).
> >>>
> >>> When load into R, I measured the size of each object with object.size():
> >>>
> >>>> object.size(combn.rda.m)
> >>> 105448 bytes
> >>>> object.size(cross)
> >>> 102064 bytes
> >>>> object.size(denitr.1)
> >>> 25032 bytes
> >>>> object.size(rda.denitr.1)
> >>> 600280 bytes
> >>>> object.size(xh)
> >>> 7792 bytes
> >>>> object.size(xh.x)
> >>> 6064 bytes
> >>>> object.size(xh.x.1)
> >>> 24144 bytes
> >>>> object.size(xh.x.2)
> >>> 24144 bytes
> >>>> object.size(xh.x.3)
> >>> 24144 bytes
> >>>> object.size(xh.y)
> >>> 2384 bytes
> >>>
> >>> There are all small objects.
> >>>
> >>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
> >>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
> >>>
> >>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
> >>> size of 73.9 MB (77,574,869 bytes).
> >>>
> >>> I don't know why...
> >>>
> >>> Any hint?
> >>
> >> As the docs for object.size() say, "Exactly which parts of the memory
> >> allocation should be attributed to which object is not clear-cut."  In
> >> particular, if a function or formula has an associated environment, it
> >> isn't included, but it is sometimes saved in the image.
> >>
> >> So I'd suspect rda.denitr.1 contains something that references an
> >> environment, and it's an environment that would be saved.  (I forget the
> >> exact rules, but I think that means it's not the global environment and
> >> it's not a package environment.)
> >>
> >> Duncan Murdoch
> >
> >
> > The rda.denitr.1 is only a list with length 2:
> > rda.denitr.1[[1]] is a vector with length 10;
> > rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
> > to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
> > vegan package.
> >
> > If I
> >   > a <- rda.denitr.1[[2]][[1]]
> >   > object.size(a)
> > 59896 bytes
> >   > save(a, file = "abc.RData")
> > It also has a large size of 73.9 MB (77,536,611 bytes)
> >
> > Jinsong
> >
>
> The rda() function uses formulas.  If it saves the formula in the
> result, then it references the environment of that formula, typically
> the environment where the formula was created.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Oct 20 22:11:34 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 20 Oct 2021 22:11:34 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <111eddeb-9a6b-60ac-9ace-ac6d27b26921@gmail.com>
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
 <87bl3k2doe.fsf@enricoschumann.net>
 <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>
 <111eddeb-9a6b-60ac-9ace-ac6d27b26921@gmail.com>
Message-ID: <24944.30710.154243.846948@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Wed, 20 Oct 2021 07:17:30 -0400 writes:

    > Translations are done by the translation teams, listed
    > here:
    > <https://developer.r-project.org/TranslationTeams.html>.
    > If you'd like to offer help, you could contact someone on
    > that list.

    > Duncan Murdoch

Indeed.   Currently, the French team is just one person, and
maybe they will be happy to share the workload  or to get
another pair of eyes to look at it...

Martin Maechler


    > On 20/10/2021 6:47 a.m., Marc Girondot via R-help wrote:
    >> Thanks ! It works.
    >> 
    >> So "Warnings" has been translated in French by "Message
    >> d'avis :" !  > warning("Essai") Message d'avis : Essai
    >> 
    >> It is not the best translation...  I would prefer:
    >> "Attention: "
    >> 
    >> Marc
    >> 
    >> Le 20/10/2021 ? 12:28, Enrico Schumann a ?crit?:
    >>> On Wed, 20 Oct 2021, Marc Girondot via R-help writes:
    >>> 
    >>>> Dear R-helpers
    >>>> 
    >>>> Do you know how to not show a "message d'avis" that
    >>>> qbeta reports. suppressMessages and capture.output are
    >>>> not working.
    >>>> 
    >>>> (PS I Know that qbeta with shape2 being 1e-7 is
    >>>> "strange"... this is obtained during an optimization
    >>>> process. Just I don't want see the messages).
    >>>> 
    >>>> Thanks
    >>>> 
    >>>> Marc Girondot
    >>>> 
    >>>> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797,
    >>>> shape2 = 0.0000001) Message d'avis : Dans qbeta(p =
    >>>> c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
    >>>> ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| =
    >>>> 0.024997 is not accurate
    >>>> 
    >>>> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
    >>>> 3.3108797, shape2 = 0.0000001)) Message d'avis : Dans
    >>>> qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 =
    >>>> 1e-07) : ? qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha|
    >>>> = 0.024997 is not accurate
    >>>> 
    >>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
    >>>> 3.3108797, shape2 = 0.0000001), type = "message")
    >>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
    >>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) : ?
    >>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
    >>>> is not accurate
    >>>> 
    >>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
    >>>> 3.3108797, shape2 = 0.0000001), type = "output")
    >>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
    >>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) : ?
    >>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
    >>>> is not accurate
    >>>> 
    >>> Try 'suppressWarnings'.
    >>> 
    >>> 
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From phgro@je@n @end|ng |rom @c|v|ew@@org  Thu Oct 21 07:38:52 2021
From: phgro@je@n @end|ng |rom @c|v|ew@@org (SciViews)
Date: Thu, 21 Oct 2021 07:38:52 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <24944.30710.154243.846948@stat.math.ethz.ch>
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
 <87bl3k2doe.fsf@enricoschumann.net>
 <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>
 <111eddeb-9a6b-60ac-9ace-ac6d27b26921@gmail.com>
 <24944.30710.154243.846948@stat.math.ethz.ch>
Message-ID: <D6BA053A-44D3-43A6-A98F-467A051ECA20@sciviews.org>

Martin Maechler wrote:
> Currently, the French team is just one person


This is not quite true. The people that contributed to the translation in French are listed here: https://github.com/phgrosjean/rfrench <https://github.com/phgrosjean/rfrench>. As you can see, there is a total of nine people among which two have actively contributed to the update of the translations for R 4.1. The page https://developer.r-project.org/TranslationTeams.html <https://developer.r-project.org/TranslationTeams.html> only exhibits the name of the contact person for each team.

Regarding the translation of ?Warning? into ?Message d?avis? raised by Marc, I gave him an extended explanation offline, that I summarise here. ?Warning? was finally translated into ?avis? after considering ?avertissement?, which is closer to the meaning in the context. However, we got problems with ?avertissement? because some sentences became longer than in English. This produced sometimes weird display of the whole message, given that there are (was?) hard breaks in the middle of some of them.

Finally, it is not ?warning? that is translated to ?message d?avis?, but it is ?warning message? in the original sentences. For instance, for R 4.1.0 I, base/po/R-fr.po, I got line 1660: ?Summary of (a total of %d) warning messages:? I don?t think that the translation proposed by Marc is good in that context. It would give "R?sum? (d?un total de %d) attentions:? Indeed, it is currently R?sum? (d?un total de %d) messages d?avis:?

All the best,

Philippe Grosjean

> On 20 Oct 2021, at 22:11, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Duncan Murdoch 
>>>>>>    on Wed, 20 Oct 2021 07:17:30 -0400 writes:
> 
>> Translations are done by the translation teams, listed
>> here:
>> <https://developer.r-project.org/TranslationTeams.html>.
>> If you'd like to offer help, you could contact someone on
>> that list.
> 
>> Duncan Murdoch
> 
> Indeed.   Currently, the French team is just one person, and
> maybe they will be happy to share the workload  or to get
> another pair of eyes to look at it...
> 
> Martin Maechler
> 
> 
>> On 20/10/2021 6:47 a.m., Marc Girondot via R-help wrote:
>>> Thanks ! It works.
>>> 
>>> So "Warnings" has been translated in French by "Message
>>> d'avis :" !  > warning("Essai") Message d'avis : Essai
>>> 
>>> It is not the best translation...  I would prefer:
>>> "Attention: "
>>> 
>>> Marc
>>> 
>>> Le 20/10/2021 ? 12:28, Enrico Schumann a ?crit :
>>>> On Wed, 20 Oct 2021, Marc Girondot via R-help writes:
>>>> 
>>>>> Dear R-helpers
>>>>> 
>>>>> Do you know how to not show a "message d'avis" that
>>>>> qbeta reports. suppressMessages and capture.output are
>>>>> not working.
>>>>> 
>>>>> (PS I Know that qbeta with shape2 being 1e-7 is
>>>>> "strange"... this is obtained during an optimization
>>>>> process. Just I don't want see the messages).
>>>>> 
>>>>> Thanks
>>>>> 
>>>>> Marc Girondot
>>>>> 
>>>>> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797,
>>>>> shape2 = 0.0000001) Message d'avis : Dans qbeta(p =
>>>>> c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>>>   qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| =
>>>>> 0.024997 is not accurate
>>>>> 
>>>>> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>> 3.3108797, shape2 = 0.0000001)) Message d'avis : Dans
>>>>> qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 =
>>>>> 1e-07) :   qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha|
>>>>> = 0.024997 is not accurate
>>>>> 
>>>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>> 3.3108797, shape2 = 0.0000001), type = "message")
>>>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
>>>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) :  
>>>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
>>>>> is not accurate
>>>>> 
>>>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>> 3.3108797, shape2 = 0.0000001), type = "output")
>>>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
>>>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) :  
>>>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
>>>>> is not accurate
>>>>> 
>>>> Try 'suppressWarnings'.
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide
>>> commented, minimal, self-contained, reproducible code.
>>> 
> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html and provide
>> commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From j@zh@o @end|ng |rom ye@h@net  Thu Oct 21 08:09:10 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Thu, 21 Oct 2021 14:09:10 +0800
Subject: [R] small object but huge RData file exported
In-Reply-To: <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
 <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
 <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>
Message-ID: <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>

This example has demoed the similar or same characteristics of my question.

If I
 > save(formula, file = "abc.RData")
and then in a new launched R session, I
 > load("abc.RData")
 > formula
x ~ y
<environment: 0x00000000171e4be8>

I want to know what are stored in the <environment: 0x00000000171e4be8>, 
and how to access it, or how to save the object without the environment.

Best,
Jinsong

On 2021/10/21 4:06, Henrik Bengtsson wrote:
> Example illustrating what Duncan says:
> 
>> make_formula <- function() { large <- rnorm(1e6); x ~ y }
>> formula <- make_formula()
> 
> # "Apparent" size of object
>> object.size(formula)
> 728 bytes
> 
> # Actual serialization size
>> length(serialize(formula, connection = NULL))
> [1] 8000203
> 
> # A better size estimate
>> lobstr::obj_size(formula)
> 8,000,888 B
> 
> /Henrik
> 
> On Wed, Oct 20, 2021 at 12:57 PM Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
>>> On 2021/10/20 21:05, Duncan Murdoch wrote:
>>>> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>>>>> Hi there,
>>>>>
>>>>> I have a RData file that is obtained by save.image() with size about
>>>>> 74.0 MB (77,608,222 bytes).
>>>>>
>>>>> When load into R, I measured the size of each object with object.size():
>>>>>
>>>>>> object.size(combn.rda.m)
>>>>> 105448 bytes
>>>>>> object.size(cross)
>>>>> 102064 bytes
>>>>>> object.size(denitr.1)
>>>>> 25032 bytes
>>>>>> object.size(rda.denitr.1)
>>>>> 600280 bytes
>>>>>> object.size(xh)
>>>>> 7792 bytes
>>>>>> object.size(xh.x)
>>>>> 6064 bytes
>>>>>> object.size(xh.x.1)
>>>>> 24144 bytes
>>>>>> object.size(xh.x.2)
>>>>> 24144 bytes
>>>>>> object.size(xh.x.3)
>>>>> 24144 bytes
>>>>>> object.size(xh.y)
>>>>> 2384 bytes
>>>>>
>>>>> There are all small objects.
>>>>>
>>>>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>>>>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>>>>
>>>>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>>>>> size of 73.9 MB (77,574,869 bytes).
>>>>>
>>>>> I don't know why...
>>>>>
>>>>> Any hint?
>>>>
>>>> As the docs for object.size() say, "Exactly which parts of the memory
>>>> allocation should be attributed to which object is not clear-cut."  In
>>>> particular, if a function or formula has an associated environment, it
>>>> isn't included, but it is sometimes saved in the image.
>>>>
>>>> So I'd suspect rda.denitr.1 contains something that references an
>>>> environment, and it's an environment that would be saved.  (I forget the
>>>> exact rules, but I think that means it's not the global environment and
>>>> it's not a package environment.)
>>>>
>>>> Duncan Murdoch
>>>
>>>
>>> The rda.denitr.1 is only a list with length 2:
>>> rda.denitr.1[[1]] is a vector with length 10;
>>> rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
>>> to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
>>> vegan package.
>>>
>>> If I
>>>    > a <- rda.denitr.1[[2]][[1]]
>>>    > object.size(a)
>>> 59896 bytes
>>>    > save(a, file = "abc.RData")
>>> It also has a large size of 73.9 MB (77,536,611 bytes)
>>>
>>> Jinsong
>>>
>>
>> The rda() function uses formulas.  If it saves the formula in the
>> result, then it references the environment of that formula, typically
>> the environment where the formula was created.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Oct 21 08:36:54 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 20 Oct 2021 23:36:54 -0700
Subject: [R] small object but huge RData file exported
In-Reply-To: <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
 <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
 <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>
 <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>
Message-ID: <4030087F-846E-4A59-9B58-7B683C47D9CF@dcn.davis.ca.us>

That depends what was in the active environment when you created that formula. You would probably benefit from reading https://adv-r.hadley.nz/environments.html about now, though you are about to enter a complex interaction between functions, formulas and environments.  A rational option is consider not saving this object to a file at all, but instead to extract what value you need from it now and save that.

On October 20, 2021 11:09:10 PM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>This example has demoed the similar or same characteristics of my question.
>
>If I
> > save(formula, file = "abc.RData")
>and then in a new launched R session, I
> > load("abc.RData")
> > formula
>x ~ y
><environment: 0x00000000171e4be8>
>
>I want to know what are stored in the <environment: 0x00000000171e4be8>, 
>and how to access it, or how to save the object without the environment.
>
>Best,
>Jinsong
>
>On 2021/10/21 4:06, Henrik Bengtsson wrote:
>> Example illustrating what Duncan says:
>> 
>>> make_formula <- function() { large <- rnorm(1e6); x ~ y }
>>> formula <- make_formula()
>> 
>> # "Apparent" size of object
>>> object.size(formula)
>> 728 bytes
>> 
>> # Actual serialization size
>>> length(serialize(formula, connection = NULL))
>> [1] 8000203
>> 
>> # A better size estimate
>>> lobstr::obj_size(formula)
>> 8,000,888 B
>> 
>> /Henrik
>> 
>> On Wed, Oct 20, 2021 at 12:57 PM Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>
>>> On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
>>>> On 2021/10/20 21:05, Duncan Murdoch wrote:
>>>>> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>>>>>> Hi there,
>>>>>>
>>>>>> I have a RData file that is obtained by save.image() with size about
>>>>>> 74.0 MB (77,608,222 bytes).
>>>>>>
>>>>>> When load into R, I measured the size of each object with object.size():
>>>>>>
>>>>>>> object.size(combn.rda.m)
>>>>>> 105448 bytes
>>>>>>> object.size(cross)
>>>>>> 102064 bytes
>>>>>>> object.size(denitr.1)
>>>>>> 25032 bytes
>>>>>>> object.size(rda.denitr.1)
>>>>>> 600280 bytes
>>>>>>> object.size(xh)
>>>>>> 7792 bytes
>>>>>>> object.size(xh.x)
>>>>>> 6064 bytes
>>>>>>> object.size(xh.x.1)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.x.2)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.x.3)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.y)
>>>>>> 2384 bytes
>>>>>>
>>>>>> There are all small objects.
>>>>>>
>>>>>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>>>>>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>>>>>
>>>>>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>>>>>> size of 73.9 MB (77,574,869 bytes).
>>>>>>
>>>>>> I don't know why...
>>>>>>
>>>>>> Any hint?
>>>>>
>>>>> As the docs for object.size() say, "Exactly which parts of the memory
>>>>> allocation should be attributed to which object is not clear-cut."  In
>>>>> particular, if a function or formula has an associated environment, it
>>>>> isn't included, but it is sometimes saved in the image.
>>>>>
>>>>> So I'd suspect rda.denitr.1 contains something that references an
>>>>> environment, and it's an environment that would be saved.  (I forget the
>>>>> exact rules, but I think that means it's not the global environment and
>>>>> it's not a package environment.)
>>>>>
>>>>> Duncan Murdoch
>>>>
>>>>
>>>> The rda.denitr.1 is only a list with length 2:
>>>> rda.denitr.1[[1]] is a vector with length 10;
>>>> rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
>>>> to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
>>>> vegan package.
>>>>
>>>> If I
>>>>    > a <- rda.denitr.1[[2]][[1]]
>>>>    > object.size(a)
>>>> 59896 bytes
>>>>    > save(a, file = "abc.RData")
>>>> It also has a large size of 73.9 MB (77,536,611 bytes)
>>>>
>>>> Jinsong
>>>>
>>>
>>> The rda() function uses formulas.  If it saves the formula in the
>>> result, then it references the environment of that formula, typically
>>> the environment where the formula was created.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j@zh@o @end|ng |rom ye@h@net  Thu Oct 21 10:51:25 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Thu, 21 Oct 2021 16:51:25 +0800
Subject: [R] small object but huge RData file exported
In-Reply-To: <4030087F-846E-4A59-9B58-7B683C47D9CF@dcn.davis.ca.us>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
 <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
 <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>
 <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>
 <4030087F-846E-4A59-9B58-7B683C47D9CF@dcn.davis.ca.us>
Message-ID: <ee5e5702-0570-0f28-b23a-ac24e150f1cc@yeah.net>

Thanks a lot for your kindly reply and explanation. Environment is 
something hard for me. I will follow the advice from Duncan and Jeff.

Best,
Jinsong

On 2021/10/21 14:36, Jeff Newmiller wrote:
> That depends what was in the active environment when you created that formula. You would probably benefit from reading https://adv-r.hadley.nz/environments.html about now, though you are about to enter a complex interaction between functions, formulas and environments.  A rational option is consider not saving this object to a file at all, but instead to extract what value you need from it now and save that.
> 
> On October 20, 2021 11:09:10 PM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>> This example has demoed the similar or same characteristics of my question.
>>
>> If I
>>> save(formula, file = "abc.RData")
>> and then in a new launched R session, I
>>> load("abc.RData")
>>> formula
>> x ~ y
>> <environment: 0x00000000171e4be8>
>>
>> I want to know what are stored in the <environment: 0x00000000171e4be8>,
>> and how to access it, or how to save the object without the environment.
>>
>> Best,
>> Jinsong
>>
>> On 2021/10/21 4:06, Henrik Bengtsson wrote:
>>> Example illustrating what Duncan says:
>>>
>>>> make_formula <- function() { large <- rnorm(1e6); x ~ y }
>>>> formula <- make_formula()
>>>
>>> # "Apparent" size of object
>>>> object.size(formula)
>>> 728 bytes
>>>
>>> # Actual serialization size
>>>> length(serialize(formula, connection = NULL))
>>> [1] 8000203
>>>
>>> # A better size estimate
>>>> lobstr::obj_size(formula)
>>> 8,000,888 B
>>>
>>> /Henrik
>>>
>>> On Wed, Oct 20, 2021 at 12:57 PM Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>>
>>>> On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
>>>>> On 2021/10/20 21:05, Duncan Murdoch wrote:
>>>>>> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>>>>>>> Hi there,
>>>>>>>
>>>>>>> I have a RData file that is obtained by save.image() with size about
>>>>>>> 74.0 MB (77,608,222 bytes).
>>>>>>>
>>>>>>> When load into R, I measured the size of each object with object.size():
>>>>>>>
>>>>>>>> object.size(combn.rda.m)
>>>>>>> 105448 bytes
>>>>>>>> object.size(cross)
>>>>>>> 102064 bytes
>>>>>>>> object.size(denitr.1)
>>>>>>> 25032 bytes
>>>>>>>> object.size(rda.denitr.1)
>>>>>>> 600280 bytes
>>>>>>>> object.size(xh)
>>>>>>> 7792 bytes
>>>>>>>> object.size(xh.x)
>>>>>>> 6064 bytes
>>>>>>>> object.size(xh.x.1)
>>>>>>> 24144 bytes
>>>>>>>> object.size(xh.x.2)
>>>>>>> 24144 bytes
>>>>>>>> object.size(xh.x.3)
>>>>>>> 24144 bytes
>>>>>>>> object.size(xh.y)
>>>>>>> 2384 bytes
>>>>>>>
>>>>>>> There are all small objects.
>>>>>>>
>>>>>>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>>>>>>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>>>>>>
>>>>>>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>>>>>>> size of 73.9 MB (77,574,869 bytes).
>>>>>>>
>>>>>>> I don't know why...
>>>>>>>
>>>>>>> Any hint?
>>>>>>
>>>>>> As the docs for object.size() say, "Exactly which parts of the memory
>>>>>> allocation should be attributed to which object is not clear-cut."  In
>>>>>> particular, if a function or formula has an associated environment, it
>>>>>> isn't included, but it is sometimes saved in the image.
>>>>>>
>>>>>> So I'd suspect rda.denitr.1 contains something that references an
>>>>>> environment, and it's an environment that would be saved.  (I forget the
>>>>>> exact rules, but I think that means it's not the global environment and
>>>>>> it's not a package environment.)
>>>>>>
>>>>>> Duncan Murdoch
>>>>>
>>>>>
>>>>> The rda.denitr.1 is only a list with length 2:
>>>>> rda.denitr.1[[1]] is a vector with length 10;
>>>>> rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
>>>>> to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
>>>>> vegan package.
>>>>>
>>>>> If I
>>>>>     > a <- rda.denitr.1[[2]][[1]]
>>>>>     > object.size(a)
>>>>> 59896 bytes
>>>>>     > save(a, file = "abc.RData")
>>>>> It also has a large size of 73.9 MB (77,536,611 bytes)
>>>>>
>>>>> Jinsong
>>>>>
>>>>
>>>> The rda() function uses formulas.  If it saves the formula in the
>>>> result, then it references the environment of that formula, typically
>>>> the environment where the formula was created.
>>>>
>>>> Duncan Murdoch


From j@zh@o @end|ng |rom ye@h@net  Thu Oct 21 10:54:53 2021
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Thu, 21 Oct 2021 16:54:53 +0800
Subject: [R] polygon is not filled by color with alpha when outside of plot
 region
Message-ID: <57e25416-5822-25b1-6fbc-05fbed955c3a@yeah.net>

Hi there,

Here is the codes that could demo the problem:

# work as expected
plot(1:5)
polygon(c(1.5, 6.5, 6.5, 1.5), c(1.5, 1.5, 6.5, 6.5), col = "gray")

# the polygon at right upper is not filled by gray with alpha = 0.5
plot(1:5)
polygon(c(1.5, 6.5, 6.5, 1.5), c(1.5, 1.5, 6.5, 6.5), col = 
adjustcolor("gray", 0.5))

# however, colors with alpha = 0.5 could be used with polygon
polygon(c(1.5, 5.0, 5.0, 1.5), c(1.5, 1.5, 5.0, 5.0), col = 
adjustcolor("gray", 0.5))

If the polygon is in the plot region(?) wholly, color with alpha works.

Is it designed?

 > R.version
                _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          4
minor          1.1
year           2021
month          08
day            10
svn rev        80725
language       R
version.string R version 4.1.1 (2021-08-10)
nickname       Kick Things

Best,
Jinsong


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Oct 20 18:05:10 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 20 Oct 2021 18:05:10 +0200
Subject: [R] [R-pkgs] NMOF 2.5-0 (Numerical Methods and Optimization in
 Finance)
Message-ID: <87o87jd6mh.fsf@enricoschumann.net>

Dear all,

version 2.5-0 of package NMOF is on CRAN now.
(Incidentally, today is 20 October 2021, which marks the
10th anniversary of NMOF on CRAN.)

NMOF stands for 'Numerical Methods and Optimization in
Finance', and it accompanies the book with the same name,
written by Manfred Gilli, Dietmar Maringer and Enrico
Schumann.[1]

Since the last announcement on this list, functionality has
been added to the package, e.g. for computing minimum-CVaR
and tracking portfolios, or downloading IPO data.  See the
NEWS file [2] for all changes.  The documentation has also
been expanded.

Comments/corrections/remarks/suggestions are -- as always --
very welcome; please send them to the maintainer (me)
directly.

Kind regards
      Enrico

[1] http://enricoschumann.net/NMOF.htm
[2] https://gitlab.com/NMOF/NMOF/-/blob/master/NEWS


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@rc_grt @end|ng |rom y@hoo@|r  Thu Oct 21 13:43:36 2021
From: m@rc_grt @end|ng |rom y@hoo@|r (Marc Girondot)
Date: Thu, 21 Oct 2021 13:43:36 +0200
Subject: [R] Do not show a "message d'avis" that qbeta reports
In-Reply-To: <D6BA053A-44D3-43A6-A98F-467A051ECA20@sciviews.org>
References: <bf531c86-f34f-bfeb-0bd3-eef19c4c7771.ref@yahoo.fr>
 <bf531c86-f34f-bfeb-0bd3-eef19c4c7771@yahoo.fr>
 <87bl3k2doe.fsf@enricoschumann.net>
 <ae4e4e96-23a0-0278-8098-e3621958af1b@yahoo.fr>
 <111eddeb-9a6b-60ac-9ace-ac6d27b26921@gmail.com>
 <24944.30710.154243.846948@stat.math.ethz.ch>
 <D6BA053A-44D3-43A6-A98F-467A051ECA20@sciviews.org>
Message-ID: <7272e01f-6056-8dcc-daeb-88613cae3c09@yahoo.fr>

Philippe has convinced me that the translation "Message d'avis" was the 
best based on the constraints in the way R displays messages. I agree 
that Avertissement was much better but it was too long.

Then the solution is to force the console messages to be in English when 
there is something strange:

 > warning("Essai")
Message d'avis :
Essai
 > Sys.setenv(LANG = "en")
 > warning("Essai")
Warning message:
Essai

Thanks a lot to the translation team for their great work.

Marc

Le 21/10/2021 ? 07:38, SciViews a ?crit?:
> Martin Maechler wrote:
>> Currently, the French team is just one person
>
> This is not quite true. The people that contributed to the translation in French are listed here: https://github.com/phgrosjean/rfrench <https://github.com/phgrosjean/rfrench>. As you can see, there is a total of nine people among which two have actively contributed to the update of the translations for R 4.1. The page https://developer.r-project.org/TranslationTeams.html <https://developer.r-project.org/TranslationTeams.html> only exhibits the name of the contact person for each team.
>
> Regarding the translation of ?Warning? into ?Message d?avis? raised by Marc, I gave him an extended explanation offline, that I summarise here. ?Warning? was finally translated into ?avis? after considering ?avertissement?, which is closer to the meaning in the context. However, we got problems with ?avertissement? because some sentences became longer than in English. This produced sometimes weird display of the whole message, given that there are (was?) hard breaks in the middle of some of them.
>
> Finally, it is not ?warning? that is translated to ?message d?avis?, but it is ?warning message? in the original sentences. For instance, for R 4.1.0 I, base/po/R-fr.po, I got line 1660: ?Summary of (a total of %d) warning messages:? I don?t think that the translation proposed by Marc is good in that context. It would give "R?sum? (d?un total de %d) attentions:? Indeed, it is currently R?sum? (d?un total de %d) messages d?avis:?
>
> All the best,
>
> Philippe Grosjean
>
>> On 20 Oct 2021, at 22:11, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>
>>>>>>> Duncan Murdoch
>>>>>>>     on Wed, 20 Oct 2021 07:17:30 -0400 writes:
>>> Translations are done by the translation teams, listed
>>> here:
>>> <https://developer.r-project.org/TranslationTeams.html>.
>>> If you'd like to offer help, you could contact someone on
>>> that list.
>>> Duncan Murdoch
>> Indeed.   Currently, the French team is just one person, and
>> maybe they will be happy to share the workload  or to get
>> another pair of eyes to look at it...
>>
>> Martin Maechler
>>
>>
>>> On 20/10/2021 6:47 a.m., Marc Girondot via R-help wrote:
>>>> Thanks ! It works.
>>>>
>>>> So "Warnings" has been translated in French by "Message
>>>> d'avis :" !  > warning("Essai") Message d'avis : Essai
>>>>
>>>> It is not the best translation...  I would prefer:
>>>> "Attention:"
>>>>
>>>> Marc
>>>>
>>>> Le 20/10/2021 ? 12:28, Enrico Schumann a ?crit :
>>>>> On Wed, 20 Oct 2021, Marc Girondot via R-help writes:
>>>>>
>>>>>> Dear R-helpers
>>>>>>
>>>>>> Do you know how to not show a "message d'avis" that
>>>>>> qbeta reports. suppressMessages and capture.output are
>>>>>> not working.
>>>>>>
>>>>>> (PS I Know that qbeta with shape2 being 1e-7 is
>>>>>> "strange"... this is obtained during an optimization
>>>>>> process. Just I don't want see the messages).
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> Marc Girondot
>>>>>>
>>>>>> q <- qbeta(p=c(0.025, 0.975), shape1 = 3.3108797,
>>>>>> shape2 = 0.0000001) Message d'avis : Dans qbeta(p =
>>>>>> c(0.025, 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>>>>    qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| =
>>>>>> 0.024997 is not accurate
>>>>>>
>>>>>> suppressMessages(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>>> 3.3108797, shape2 = 0.0000001)) Message d'avis : Dans
>>>>>> qbeta(p = c(0.025, 0.975), shape1 = 3.3108797, shape2 =
>>>>>> 1e-07) :   qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha|
>>>>>> = 0.024997 is not accurate
>>>>>>
>>>>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>>> 3.3108797, shape2 = 0.0000001), type = "message")
>>>>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
>>>>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
>>>>>> is not accurate
>>>>>>
>>>>>> capture.output(q <- qbeta(p=c(0.025, 0.975), shape1 =
>>>>>> 3.3108797, shape2 = 0.0000001), type = "output")
>>>>>> character(0) Message d'avis : Dans qbeta(p = c(0.025,
>>>>>> 0.975), shape1 = 3.3108797, shape2 = 1e-07) :
>>>>>> qbeta(a, *) =: x0 with |pbeta(x0,*) - alpha| = 0.024997
>>>>>> is not accurate
>>>>>>
>>>>> Try 'suppressWarnings'.
>>>>>
>>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html and provide
>>>> commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide
>>> commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Oct 21 13:47:41 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 21 Oct 2021 07:47:41 -0400
Subject: [R] small object but huge RData file exported
In-Reply-To: <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>
References: <8df188dd-18bc-269d-7d29-07939504dfc1@yeah.net>
 <7e39d397-03af-63c3-8d04-cfdfc6e450f7@gmail.com>
 <766df553-9cdf-41b9-8752-a518fce84f18@yeah.net>
 <bb84f227-d3e5-2918-f21c-f449bf341ac0@gmail.com>
 <CAFDcVCSrtShY7TreT=pUn=uki5GRP6Oko=gPoULp9FJ3FoQWHQ@mail.gmail.com>
 <31afee93-baff-3858-e582-e826996ba4f8@yeah.net>
Message-ID: <1c0408ab-daad-35bb-5ec5-b66494826468@gmail.com>

On 21/10/2021 2:09 a.m., Jinsong Zhao wrote:
> This example has demoed the similar or same characteristics of my question.
> 
> If I
>   > save(formula, file = "abc.RData")
> and then in a new launched R session, I
>   > load("abc.RData")
>   > formula
> x ~ y
> <environment: 0x00000000171e4be8>
> 
> I want to know what are stored in the <environment: 0x00000000171e4be8>,
> and how to access it, or how to save the object without the environment.

Using Henrik's example, the environment would contain all the local 
variables of the make_formula call.  In his case, that's just the 
"large" variable, but in real examples, it can be quite a few things.

To access it, you can do

e <- environment(formula)

ls(e) # shows just "large"
e$large  # extracts that value

It is possible to save the formula without the environment, but you 
should *never* do that.  That changes the meaning of the formula and is 
almost certain to lead to bugs in the future.

For example, consider this slightly more complicated example like Henrik's:

make_formula <- function() {
   x <- rnorm(100)
   y <- rnorm(100)
   x ~ y
}
formula <- make_formula()
lm(formula)
#>
#> Call:
#> lm(formula = formula)
#>
#> Coefficients:
#> (Intercept)            y
#>     -0.1584      -0.0805

Here the lm() function finds the variables used in the formula in the 
formula's attached environment.  You'd get a completely different answer 
(probably wrong) if you removed the environment.

In your real example where the save files are too big, the solution is 
to find where those RDA objects were created, and make sure there are no 
unused local variables at the time you return the result.  Any local 
variable that's mentioned in the formula should be kept, but other 
variables that may have been used to construct them can be removed, e.g.

make_formula <- function() {
   # Create a local variable
   large <- rnorm(100000)

   # Use it to create variables in the formula
   x <- large + 1
   y <- large + rnorm(100000)

   # Remove the temporary one
   rm(large)

   # Return the formula
   x ~ y
}

Duncan Murdoch

> 
> Best,
> Jinsong
> 
> On 2021/10/21 4:06, Henrik Bengtsson wrote:
>> Example illustrating what Duncan says:
>>
>>> make_formula <- function() { large <- rnorm(1e6); x ~ y }
>>> formula <- make_formula()
>>
>> # "Apparent" size of object
>>> object.size(formula)
>> 728 bytes
>>
>> # Actual serialization size
>>> length(serialize(formula, connection = NULL))
>> [1] 8000203
>>
>> # A better size estimate
>>> lobstr::obj_size(formula)
>> 8,000,888 B
>>
>> /Henrik
>>
>> On Wed, Oct 20, 2021 at 12:57 PM Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>
>>> On 20/10/2021 9:20 a.m., Jinsong Zhao wrote:
>>>> On 2021/10/20 21:05, Duncan Murdoch wrote:
>>>>> On 20/10/2021 8:57 a.m., Jinsong Zhao wrote:
>>>>>> Hi there,
>>>>>>
>>>>>> I have a RData file that is obtained by save.image() with size about
>>>>>> 74.0 MB (77,608,222 bytes).
>>>>>>
>>>>>> When load into R, I measured the size of each object with object.size():
>>>>>>
>>>>>>> object.size(combn.rda.m)
>>>>>> 105448 bytes
>>>>>>> object.size(cross)
>>>>>> 102064 bytes
>>>>>>> object.size(denitr.1)
>>>>>> 25032 bytes
>>>>>>> object.size(rda.denitr.1)
>>>>>> 600280 bytes
>>>>>>> object.size(xh)
>>>>>> 7792 bytes
>>>>>>> object.size(xh.x)
>>>>>> 6064 bytes
>>>>>>> object.size(xh.x.1)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.x.2)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.x.3)
>>>>>> 24144 bytes
>>>>>>> object.size(xh.y)
>>>>>> 2384 bytes
>>>>>>
>>>>>> There are all small objects.
>>>>>>
>>>>>> If I delete the largest one "rda.denitr.1", and save.image("xx.RData").
>>>>>> It has the size of 22.6 KB (23,244 bytes). All seem OK.
>>>>>>
>>>>>> However, when I save(rda.denitr.1, file = "yy.RData"), then it has the
>>>>>> size of 73.9 MB (77,574,869 bytes).
>>>>>>
>>>>>> I don't know why...
>>>>>>
>>>>>> Any hint?
>>>>>
>>>>> As the docs for object.size() say, "Exactly which parts of the memory
>>>>> allocation should be attributed to which object is not clear-cut."  In
>>>>> particular, if a function or formula has an associated environment, it
>>>>> isn't included, but it is sometimes saved in the image.
>>>>>
>>>>> So I'd suspect rda.denitr.1 contains something that references an
>>>>> environment, and it's an environment that would be saved.  (I forget the
>>>>> exact rules, but I think that means it's not the global environment and
>>>>> it's not a package environment.)
>>>>>
>>>>> Duncan Murdoch
>>>>
>>>>
>>>> The rda.denitr.1 is only a list with length 2:
>>>> rda.denitr.1[[1]] is a vector with length 10;
>>>> rda.denitr.2[[2]] is a list with the length 10. rda.denitr.1[[2]][[1]]
>>>> to rda.denitr.1[[2]][[10]] are small RDA objects generated by rda() from
>>>> vegan package.
>>>>
>>>> If I
>>>>     > a <- rda.denitr.1[[2]][[1]]
>>>>     > object.size(a)
>>>> 59896 bytes
>>>>     > save(a, file = "abc.RData")
>>>> It also has a large size of 73.9 MB (77,536,611 bytes)
>>>>
>>>> Jinsong
>>>>
>>>
>>> The rda() function uses formulas.  If it saves the formula in the
>>> result, then it references the environment of that formula, typically
>>> the environment where the formula was created.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Oct 21 23:00:24 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 21 Oct 2021 23:00:24 +0200
Subject: [R] Split plot panel into rows with different columns
Message-ID: <CAMk+s2Rnzt9kAL0uGyCXei_u_sMsFhxfhYa_igROY9yzro9Bcw@mail.gmail.com>

Hello,
I would like to draw 5 figures in the same plot. The layout is:
  first row: 1 column
  second row: 2 columns
  third row: 2 columns
I have used split.screen:
```
> split.screen(c(3, 1))       # split display into 3 screens
[1] 1 2 3
> split.screen(c(1, 2), screen = 2) # split second screen into two columns
[1] 4 5
> split.screen(c(1, 2), screen = 3) # split third screen into two columns
[1] 6 7
> screen(1)
> plot(classified$MR[classified$Class == "positive"] ~
+ classified$FCN[classified$Class == "positive"], cex=1.5, pch=16,
+ xlim=c(0,50), ylim=c(0,0.45),
+ xlab=expression(bold("FCN")), ylab=expression(bold("MR")))
Error in plot.new() : figure margins too large
```
Is this the correct syntax? Then I simply plot into each of the 7
screens. So the error is about margins/
Or is it simply that the layout is not correct?
Thank you


From bgunter@4567 @end|ng |rom gm@||@com  Thu Oct 21 23:42:27 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 21 Oct 2021 14:42:27 -0700
Subject: [R] Split plot panel into rows with different columns
In-Reply-To: <CAMk+s2Rnzt9kAL0uGyCXei_u_sMsFhxfhYa_igROY9yzro9Bcw@mail.gmail.com>
References: <CAMk+s2Rnzt9kAL0uGyCXei_u_sMsFhxfhYa_igROY9yzro9Bcw@mail.gmail.com>
Message-ID: <CAGxFJbQ=Xve6Lebc8xy1j7YdCL_wiHXUK-+N78Lhc=Ggby6GOQ@mail.gmail.com>

The syntax is correct; the default margins are too large for your device.

For example, using your split screen specs on the RStudioGD

> split.screen(c(3, 1))       # split display into 3 screens
[1] 1 2 3
>
> split.screen(c(1, 2), screen = 2) # split second screen into two columns
[1] 4 5
>
> split.screen(c(1, 2), screen = 3) # split third screen into two columns
[1] 6 7
>
> screen(1)

> plot(1:10)
Error in plot.new() : figure margins too large
> par(mar = c(2,1,1,1))
> plot(1:10)
## plots on screen 1


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Oct 21, 2021 at 2:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I would like to draw 5 figures in the same plot. The layout is:
>   first row: 1 column
>   second row: 2 columns
>   third row: 2 columns
> I have used split.screen:
> ```
> > split.screen(c(3, 1))       # split display into 3 screens
> [1] 1 2 3
> > split.screen(c(1, 2), screen = 2) # split second screen into two columns
> [1] 4 5
> > split.screen(c(1, 2), screen = 3) # split third screen into two columns
> [1] 6 7
> > screen(1)
> > plot(classified$MR[classified$Class == "positive"] ~
> + classified$FCN[classified$Class == "positive"], cex=1.5, pch=16,
> + xlim=c(0,50), ylim=c(0,0.45),
> + xlab=expression(bold("FCN")), ylab=expression(bold("MR")))
> Error in plot.new() : figure margins too large
> ```
> Is this the correct syntax? Then I simply plot into each of the 7
> screens. So the error is about margins/
> Or is it simply that the layout is not correct?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Oct 22 04:31:28 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 22 Oct 2021 13:31:28 +1100
Subject: [R] Split plot panel into rows with different columns
In-Reply-To: <CAGxFJbQ=Xve6Lebc8xy1j7YdCL_wiHXUK-+N78Lhc=Ggby6GOQ@mail.gmail.com>
References: <CAMk+s2Rnzt9kAL0uGyCXei_u_sMsFhxfhYa_igROY9yzro9Bcw@mail.gmail.com>
 <CAGxFJbQ=Xve6Lebc8xy1j7YdCL_wiHXUK-+N78Lhc=Ggby6GOQ@mail.gmail.com>
Message-ID: <CA+8X3fU9GW4iwGMd5MxoWsy9HUXc34K8tbaHdyeNL8tkVRbviA@mail.gmail.com>

Hi Luigi,
Bert has identified the problem. If the ordinates in each row are the
same, you can save quite a bit of space by setting the left and right
margins to zero on all but the left plots in each row. This will jam
the plots together at the sides, but that may not matter to you.
Remember that you have to set the margins for each plot. If you do
this, it is usually better looking if you specify more room for the
leftmost panels.

Jim

On Fri, Oct 22, 2021 at 8:43 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> The syntax is correct; the default margins are too large for your device.
>
> For example, using your split screen specs on the RStudioGD
>
> > split.screen(c(3, 1))       # split display into 3 screens
> [1] 1 2 3
> >
> > split.screen(c(1, 2), screen = 2) # split second screen into two columns
> [1] 4 5
> >
> > split.screen(c(1, 2), screen = 3) # split third screen into two columns
> [1] 6 7
> >
> > screen(1)
>
> > plot(1:10)
> Error in plot.new() : figure margins too large
> > par(mar = c(2,1,1,1))
> > plot(1:10)
> ## plots on screen 1
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Oct 21, 2021 at 2:00 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
>
> > Hello,
> > I would like to draw 5 figures in the same plot. The layout is:
> >   first row: 1 column
> >   second row: 2 columns
> >   third row: 2 columns
> > I have used split.screen:
> > ```
> > > split.screen(c(3, 1))       # split display into 3 screens
> > [1] 1 2 3
> > > split.screen(c(1, 2), screen = 2) # split second screen into two columns
> > [1] 4 5
> > > split.screen(c(1, 2), screen = 3) # split third screen into two columns
> > [1] 6 7
> > > screen(1)
> > > plot(classified$MR[classified$Class == "positive"] ~
> > + classified$FCN[classified$Class == "positive"], cex=1.5, pch=16,
> > + xlim=c(0,50), ylim=c(0,0.45),
> > + xlab=expression(bold("FCN")), ylab=expression(bold("MR")))
> > Error in plot.new() : figure margins too large
> > ```
> > Is this the correct syntax? Then I simply plot into each of the 7
> > screens. So the error is about margins/
> > Or is it simply that the layout is not correct?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Oct 22 08:14:03 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 22 Oct 2021 08:14:03 +0200
Subject: [R] Split plot panel into rows with different columns
In-Reply-To: <CAGxFJbQ=Xve6Lebc8xy1j7YdCL_wiHXUK-+N78Lhc=Ggby6GOQ@mail.gmail.com>
References: <CAMk+s2Rnzt9kAL0uGyCXei_u_sMsFhxfhYa_igROY9yzro9Bcw@mail.gmail.com>
 <CAGxFJbQ=Xve6Lebc8xy1j7YdCL_wiHXUK-+N78Lhc=Ggby6GOQ@mail.gmail.com>
Message-ID: <CAMk+s2Q4qKS2kBctD=x16yvNm1MVr+63jc=w7wW25qhACdbmwA@mail.gmail.com>

Yes, you are right, it works fine when plotting on file.
Thank you!

On Thu, Oct 21, 2021 at 11:42 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> The syntax is correct; the default margins are too large for your device.
>
> For example, using your split screen specs on the RStudioGD
>
> > split.screen(c(3, 1))       # split display into 3 screens
> [1] 1 2 3
> >
> > split.screen(c(1, 2), screen = 2) # split second screen into two columns
> [1] 4 5
> >
> > split.screen(c(1, 2), screen = 3) # split third screen into two columns
> [1] 6 7
> >
> > screen(1)
>
> > plot(1:10)
> Error in plot.new() : figure margins too large
> > par(mar = c(2,1,1,1))
> > plot(1:10)
> ## plots on screen 1
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Oct 21, 2021 at 2:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I would like to draw 5 figures in the same plot. The layout is:
>>   first row: 1 column
>>   second row: 2 columns
>>   third row: 2 columns
>> I have used split.screen:
>> ```
>> > split.screen(c(3, 1))       # split display into 3 screens
>> [1] 1 2 3
>> > split.screen(c(1, 2), screen = 2) # split second screen into two columns
>> [1] 4 5
>> > split.screen(c(1, 2), screen = 3) # split third screen into two columns
>> [1] 6 7
>> > screen(1)
>> > plot(classified$MR[classified$Class == "positive"] ~
>> + classified$FCN[classified$Class == "positive"], cex=1.5, pch=16,
>> + xlim=c(0,50), ylim=c(0,0.45),
>> + xlab=expression(bold("FCN")), ylab=expression(bold("MR")))
>> Error in plot.new() : figure margins too large
>> ```
>> Is this the correct syntax? Then I simply plot into each of the 7
>> screens. So the error is about margins/
>> Or is it simply that the layout is not correct?
>> Thank you
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From @tyen @end|ng |rom ntu@edu@tw  Fri Oct 22 11:20:30 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 22 Oct 2021 17:20:30 +0800
Subject: [R] Wild cards for dataframes
Message-ID: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>

I like to be able to use a command with something similar to a "wild 
card". Below, lines 4 works to delete all three dataframes, but line 5 
does not work. Any elegant way to accomplish this? My list of dataframes 
can be long and so this would be convenient.

data.1<-data.frame(x=1:3,y=4:6,z=7:9)
data.2<-data.1
data.3<-data.1
rm(data.1,data.2,data.3)
rm(data.*)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct 22 12:22:44 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 22 Oct 2021 11:22:44 +0100
Subject: [R] Wild cards for dataframes
In-Reply-To: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
References: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
Message-ID: <2c58dd2c-0e6f-5c06-ad89-fd36b2333250@sapo.pt>

Hello,

Use ls() with argument pattern. It accepts a regex and returns a vector 
of objects names matching the pattern.


rm(list = ls(pattern = "data\\..*$"))


Hope this helps,

Rui Barradas

?s 10:20 de 22/10/21, Steven Yen escreveu:
> I like to be able to use a command with something similar to a "wild 
> card". Below, lines 4 works to delete all three dataframes, but line 5 
> does not work. Any elegant way to accomplish this? My list of dataframes 
> can be long and so this would be convenient.
> 
> data.1<-data.frame(x=1:3,y=4:6,z=7:9)
> data.2<-data.1
> data.3<-data.1
> rm(data.1,data.2,data.3)
> rm(data.*)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mou@e||m|@|@mpro@ @end|ng |rom gm@||@com  Thu Oct 21 08:22:21 2021
From: mou@e||m|@|@mpro@ @end|ng |rom gm@||@com (lampros mouselimis)
Date: Thu, 21 Oct 2021 09:22:21 +0300
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
Message-ID: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>

Dear R-help team,

I'm the maintainer of the textTinyR package. Currently the package fails on
the Solaris Operating System (OS), you can see the results in the following
weblink: https://cran.r-project.org/web/checks/check_results_textTinyR.html

All my packages are tested on Solaris OS automatically but I never check my
R packages before submitting to CRAN on Solaris OS because I don't have any
experience using it. I also won't be in place to fix this error (even if I
utilize a Virtual Machine). Due to the fact that my package works on Linux,
Windows and Macintosh (I can fix the errors in all these three OS because I
have installations in my Computer) can I request to exclude the textTinyR
package from the Solaris OS testing / CRAN checking (that means the Solaris
test frameworks will not appear in the CRAN Package test results page)?
Moreover, whom should I send an e-mail to make this request?

I processed the data of all current packages on CRAN
<https://cran.r-project.org/web/checks/check_summary_by_package.html> and
there are 153 submitted packages that are not tested on Solaris (I attach
the csv file of these packages in this e-mail), which means it's possible
for a package to not be tested on this OS.

I'd like an answer before the 27th October otherwise the package will be
removed from CRAN.

Thank you in advance and for your time,
Lampros Mouselimis

From dj@ndr|j@ @end|ng |rom gm@||@com  Fri Oct 22 08:25:26 2021
From: dj@ndr|j@ @end|ng |rom gm@||@com (Andrija Djurovic)
Date: Fri, 22 Oct 2021 08:25:26 +0200
Subject: [R] [R-pkgs] monobin: new version 0.2.0
Message-ID: <CABcwgRSCrqq4u=UWYuja=XzOdqBBTUZXmjPFOQ8GKYxHsoazCA@mail.gmail.com>

Dear R users,

the new version of monobin package is now on CRAN.
Additional binning algorithm is implemented - monotonic binning driven by
decision tree (mdt.bin).

For details and examples, install the new version of the monobin
(install.packages("monobin")) and check the help page of the function
(?mdt.bin) or visit the github page:
https://github.com/andrija-djurovic/monobin

Soon I will upload to the CRAN updated version of monobinShiny package in
order to reflect changes from the monobin. Until then users can install
github version (https://github.com/andrija-djurovic/monobinShiny) where new
binning algorithm is already implemented.

BR,
Andrija Djurovic

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @tyen @end|ng |rom ntu@edu@tw  Fri Oct 22 14:48:22 2021
From: @tyen @end|ng |rom ntu@edu@tw (Steven Yen)
Date: Fri, 22 Oct 2021 20:48:22 +0800
Subject: [R] Wild cards for dataframes
In-Reply-To: <2c58dd2c-0e6f-5c06-ad89-fd36b2333250@sapo.pt>
References: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
 <2c58dd2c-0e6f-5c06-ad89-fd36b2333250@sapo.pt>
Message-ID: <ea7685f3-23fc-51a0-82c8-f00858f19d29@ntu.edu.tw>

Thanks, it works!

What can I read to understand more about this part "\\..*$" of the 
pattern? And more such as ^ and $ that I know from experience?

On 2021/10/22 ?? 06:22, Rui Barradas wrote:
> Hello,
>
> Use ls() with argument pattern. It accepts a regex and returns a 
> vector of objects names matching the pattern.
>
>
> rm(list = ls(pattern = "data\\..*$"))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 10:20 de 22/10/21, Steven Yen escreveu:
>> I like to be able to use a command with something similar to a "wild 
>> card". Below, lines 4 works to delete all three dataframes, but line 
>> 5 does not work. Any elegant way to accomplish this? My list of 
>> dataframes can be long and so this would be convenient.
>>
>> data.1<-data.frame(x=1:3,y=4:6,z=7:9)
>> data.2<-data.1
>> data.3<-data.1
>> rm(data.1,data.2,data.3)
>> rm(data.*)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Fri Oct 22 14:55:24 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 22 Oct 2021 15:55:24 +0300
Subject: [R] Wild cards for dataframes
In-Reply-To: <ea7685f3-23fc-51a0-82c8-f00858f19d29@ntu.edu.tw>
References: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
 <2c58dd2c-0e6f-5c06-ad89-fd36b2333250@sapo.pt>
 <ea7685f3-23fc-51a0-82c8-f00858f19d29@ntu.edu.tw>
Message-ID: <CAGgJW75rq2hzYr-biYHQRsBpJGoD=iVheydn5d-0r0VsW2-5ZQ@mail.gmail.com>

You can check out Wikipedia for regular expressions:

https://en.wikipedia.org/wiki/Regular_expression




On Fri, Oct 22, 2021 at 3:48 PM Steven Yen <styen at ntu.edu.tw> wrote:

> Thanks, it works!
>
> What can I read to understand more about this part "\\..*$" of the
> pattern? And more such as ^ and $ that I know from experience?
>
> On 2021/10/22 ?? 06:22, Rui Barradas wrote:
> > Hello,
> >
> > Use ls() with argument pattern. It accepts a regex and returns a
> > vector of objects names matching the pattern.
> >
> >
> > rm(list = ls(pattern = "data\\..*$"))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 10:20 de 22/10/21, Steven Yen escreveu:
> >> I like to be able to use a command with something similar to a "wild
> >> card". Below, lines 4 works to delete all three dataframes, but line
> >> 5 does not work. Any elegant way to accomplish this? My list of
> >> dataframes can be long and so this would be convenient.
> >>
> >> data.1<-data.frame(x=1:3,y=4:6,z=7:9)
> >> data.2<-data.1
> >> data.3<-data.1
> >> rm(data.1,data.2,data.3)
> >> rm(data.*)
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Oct 22 15:01:36 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 22 Oct 2021 16:01:36 +0300
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
Message-ID: <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>

Hi Lampros,
I cannot answer your question but I believe the correct place to post
such a question would be the r-package-devel list

https://stat.ethz.ch/mailman/listinfo/r-package-devel

Good luck


On Fri, Oct 22, 2021 at 2:13 PM lampros mouselimis
<mouselimislampros at gmail.com> wrote:
>
> Dear R-help team,
>
> I'm the maintainer of the textTinyR package. Currently the package fails on
> the Solaris Operating System (OS), you can see the results in the following
> weblink: https://cran.r-project.org/web/checks/check_results_textTinyR.html
>
> All my packages are tested on Solaris OS automatically but I never check my
> R packages before submitting to CRAN on Solaris OS because I don't have any
> experience using it. I also won't be in place to fix this error (even if I
> utilize a Virtual Machine). Due to the fact that my package works on Linux,
> Windows and Macintosh (I can fix the errors in all these three OS because I
> have installations in my Computer) can I request to exclude the textTinyR
> package from the Solaris OS testing / CRAN checking (that means the Solaris
> test frameworks will not appear in the CRAN Package test results page)?
> Moreover, whom should I send an e-mail to make this request?
>
> I processed the data of all current packages on CRAN
> <https://cran.r-project.org/web/checks/check_summary_by_package.html> and
> there are 153 submitted packages that are not tested on Solaris (I attach
> the csv file of these packages in this e-mail), which means it's possible
> for a package to not be tested on this OS.
>
> I'd like an answer before the 27th October otherwise the package will be
> removed from CRAN.
>
> Thank you in advance and for your time,
> Lampros Mouselimis
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g@@mo||n@k|1 @end|ng |rom gm@||@com  Fri Oct 22 15:19:03 2021
From: g@@mo||n@k|1 @end|ng |rom gm@||@com (=?UTF-8?Q?Grzegorz_Smoli=C5=84ski?=)
Date: Fri, 22 Oct 2021 15:19:03 +0200
Subject: [R] Wild cards for dataframes
In-Reply-To: <CAGgJW75rq2hzYr-biYHQRsBpJGoD=iVheydn5d-0r0VsW2-5ZQ@mail.gmail.com>
References: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
 <2c58dd2c-0e6f-5c06-ad89-fd36b2333250@sapo.pt>
 <ea7685f3-23fc-51a0-82c8-f00858f19d29@ntu.edu.tw>
 <CAGgJW75rq2hzYr-biYHQRsBpJGoD=iVheydn5d-0r0VsW2-5ZQ@mail.gmail.com>
Message-ID: <CABxpnnmB408Hj98fZkA-xhMN9ncuduU3NzbKMx9dPxAyVJPTRw@mail.gmail.com>

Well, Wikipedia is probably the place where people who know some topic
can check if people who wrote the article did it right :)

You can try this short subchapter in R for Data Science (by Hadley
Wickham) as a starting point:

https://r4ds.had.co.nz/strings.html#matching-patterns-with-regular-expressions

Best regards,
Grzegorz


pt., 22 pa? 2021 o 15:14 Eric Berger <ericjberger at gmail.com> napisa?(a):
>
> You can check out Wikipedia for regular expressions:
>
> https://en.wikipedia.org/wiki/Regular_expression
>
>
>
>
> On Fri, Oct 22, 2021 at 3:48 PM Steven Yen <styen at ntu.edu.tw> wrote:
>
> > Thanks, it works!
> >
> > What can I read to understand more about this part "\\..*$" of the
> > pattern? And more such as ^ and $ that I know from experience?
> >
> > On 2021/10/22 ?? 06:22, Rui Barradas wrote:
> > > Hello,
> > >
> > > Use ls() with argument pattern. It accepts a regex and returns a
> > > vector of objects names matching the pattern.
> > >
> > >
> > > rm(list = ls(pattern = "data\\..*$"))
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > ?s 10:20 de 22/10/21, Steven Yen escreveu:
> > >> I like to be able to use a command with something similar to a "wild
> > >> card". Below, lines 4 works to delete all three dataframes, but line
> > >> 5 does not work. Any elegant way to accomplish this? My list of
> > >> dataframes can be long and so this would be convenient.
> > >>
> > >> data.1<-data.frame(x=1:3,y=4:6,z=7:9)
> > >> data.2<-data.1
> > >> data.3<-data.1
> > >> rm(data.1,data.2,data.3)
> > >> rm(data.*)
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Oct 22 15:47:05 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 22 Oct 2021 09:47:05 -0400
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
Message-ID: <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>

Hi,

Just to add some additional comments that may be helpful.

1. The CRAN repository policy here:

   https://cran.r-project.org/web/packages/policies.html

notes:

"Package authors should make all reasonable efforts to provide 
cross-platform portable code. Packages will not normally be accepted 
that do not run on at least two of the major R platforms. Cases for 
Windows-only packages will be considered, but CRAN may not be the most 
appropriate place to host them."

That would seem to infer that, with reasonable justification, one may be 
able to make a request of the CRAN maintainers to exclude at least one 
of the OS platforms from testing. A request that would be at the 
discretion of the CRAN maintainers and Solaris, in light of the low 
market prevalence, may be a more common exclusion as you have noted below.


2. If you wish to test your package on Solaris, in the absence of using 
a VM, there is a blog post here:

   https://blog.r-hub.io/2020/05/14/checking-your-r-package-on-solaris/

that you may find helpful.


Eric has suggested posting to r-package-devel, and I would agree in 
terms of a larger and focused R package development audience. Albeit, 
you would eventually need to make a direct request to the CRAN 
maintainers (CRAN at R-project.org) to exclude Solaris from testing.

You have specified a deadline below which is only 5 days away, and not 
likely a reasonable constraint, given the volunteer service nature of 
the folks that maintain CRAN. I would suggest that you contact them 
using the e-mail address above, without the deadline, and afford them 
the opportunity to reply to you with what may be reasonable next steps 
given the issues you face.

Regards,

Marc Schwartz



Eric Berger wrote on 10/22/21 9:01 AM:
> Hi Lampros,
> I cannot answer your question but I believe the correct place to post
> such a question would be the r-package-devel list
> 
> https://stat.ethz.ch/mailman/listinfo/r-package-devel
> 
> Good luck
> 
> 
> On Fri, Oct 22, 2021 at 2:13 PM lampros mouselimis
> <mouselimislampros at gmail.com> wrote:
>>
>> Dear R-help team,
>>
>> I'm the maintainer of the textTinyR package. Currently the package fails on
>> the Solaris Operating System (OS), you can see the results in the following
>> weblink: https://cran.r-project.org/web/checks/check_results_textTinyR.html
>>
>> All my packages are tested on Solaris OS automatically but I never check my
>> R packages before submitting to CRAN on Solaris OS because I don't have any
>> experience using it. I also won't be in place to fix this error (even if I
>> utilize a Virtual Machine). Due to the fact that my package works on Linux,
>> Windows and Macintosh (I can fix the errors in all these three OS because I
>> have installations in my Computer) can I request to exclude the textTinyR
>> package from the Solaris OS testing / CRAN checking (that means the Solaris
>> test frameworks will not appear in the CRAN Package test results page)?
>> Moreover, whom should I send an e-mail to make this request?
>>
>> I processed the data of all current packages on CRAN
>> <https://cran.r-project.org/web/checks/check_summary_by_package.html> and
>> there are 153 submitted packages that are not tested on Solaris (I attach
>> the csv file of these packages in this e-mail), which means it's possible
>> for a package to not be tested on this OS.
>>
>> I'd like an answer before the 27th October otherwise the package will be
>> removed from CRAN.
>>
>> Thank you in advance and for your time,
>> Lampros Mouselimis


From bgunter@4567 @end|ng |rom gm@||@com  Fri Oct 22 16:11:07 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 22 Oct 2021 07:11:07 -0700
Subject: [R] Wild cards for dataframes
In-Reply-To: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
References: <04412860-656a-faa9-7d5e-8e6c525c3e99@ntu.edu.tw>
Message-ID: <CAGxFJbQ5OwU_RrOLR5tD579XP0Y7vzZhgM9WdUa_kbHcdjUT1A@mail.gmail.com>

A terse but useful resource is to use R's Help docs: ?regex. It also gives
the R regex syntax, which can of course differ from others, especially in
regard to escapes.
Do note that the rseek.org site is a better place to ask for such info than
here. Or just searching on "regular expressions R".

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Oct 22, 2021 at 2:21 AM Steven Yen <styen at ntu.edu.tw> wrote:

> I like to be able to use a command with something similar to a "wild
> card". Below, lines 4 works to delete all three dataframes, but line 5
> does not work. Any elegant way to accomplish this? My list of dataframes
> can be long and so this would be convenient.
>
> data.1<-data.frame(x=1:3,y=4:6,z=7:9)
> data.2<-data.1
> data.3<-data.1
> rm(data.1,data.2,data.3)
> rm(data.*)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @te|@nML @end|ng |rom co||oc@t|on@@de  Fri Oct 22 16:30:05 2021
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Fri, 22 Oct 2021 16:30:05 +0200
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
 <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
Message-ID: <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>

Just to add my personal cent to this:  I've had similar issues with an R package some time ago, which kept crashing somewhat unpredictably in the Solaris tests.

Debugging was hard because it only happened on Solaris, but in the end it turned out to be due to serious bugs in the code that only happened to surface in the Solaris tests.   I would think that it's likely to be the same for your package, so the segfaults shouldn't be accepted too readily as a platform quirk.

Best
SE


> On 22 Oct 2021, at 15:47, Marc Schwartz via R-help <r-help at r-project.org> wrote:
> 
> 
> 1. The CRAN repository policy here:
> 
>  https://cran.r-project.org/web/packages/policies.html
> 
> notes:
> 
> "Package authors should make all reasonable efforts to provide cross-platform portable code. Packages will not normally be accepted that do not run on at least two of the major R platforms. Cases for Windows-only packages will be considered, but CRAN may not be the most appropriate place to host them."
> 
> That would seem to infer that, with reasonable justification, one may be able to make a request of the CRAN maintainers to exclude at least one of the OS platforms from testing. A request that would be at the discretion of the CRAN maintainers and Solaris, in light of the low market prevalence, may be a more common exclusion as you have noted below.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Oct 22 16:35:46 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 22 Oct 2021 07:35:46 -0700
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
 <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
 <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>
Message-ID: <CAHqSRuRT0SGzMHr9i=_0hL29HaMYRfBOnmapetF-sx6BnZBBYQ@mail.gmail.com>

I agree with Stefan.  Try using valgrind (on Linux) to check for memory
misuse:

R --debugger=valgrind --debugger-args="--leak-check=full
--track-origins=yes"
...
> yourTests()
> q("no")

-Bill


On Fri, Oct 22, 2021 at 7:30 AM Stefan Evert <stefanML at collocations.de>
wrote:

> Just to add my personal cent to this:  I've had similar issues with an R
> package some time ago, which kept crashing somewhat unpredictably in the
> Solaris tests.
>
> Debugging was hard because it only happened on Solaris, but in the end it
> turned out to be due to serious bugs in the code that only happened to
> surface in the Solaris tests.   I would think that it's likely to be the
> same for your package, so the segfaults shouldn't be accepted too readily
> as a platform quirk.
>
> Best
> SE
>
>
> > On 22 Oct 2021, at 15:47, Marc Schwartz via R-help <r-help at r-project.org>
> wrote:
> >
> >
> > 1. The CRAN repository policy here:
> >
> >  https://cran.r-project.org/web/packages/policies.html
> >
> > notes:
> >
> > "Package authors should make all reasonable efforts to provide
> cross-platform portable code. Packages will not normally be accepted that
> do not run on at least two of the major R platforms. Cases for Windows-only
> packages will be considered, but CRAN may not be the most appropriate place
> to host them."
> >
> > That would seem to infer that, with reasonable justification, one may be
> able to make a request of the CRAN maintainers to exclude at least one of
> the OS platforms from testing. A request that would be at the discretion of
> the CRAN maintainers and Solaris, in light of the low market prevalence,
> may be a more common exclusion as you have noted below.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Oct 22 16:49:08 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 22 Oct 2021 16:49:08 +0200
Subject: [R] machine learning to define contours in R
Message-ID: <CAMk+s2TWSoHNe2tTxw1oqYbN-jAzArbruJjoGEM8g6_YC2Ha1w@mail.gmail.com>

Hello,
I have run some support vector machine analysis. If I draw a grid of
10*10 points in a space, the model I built will assign the points to a
given group. Lets' say:
```
results1 = data.frame(row_1 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                                   row_2 = c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0),
                                   row_3 = c(0, 0, 1, 1, 1, 0, 0, 0, 0, 0),
                                   row_4 = c(0, 1, 1, 1, 1, 1, 0, 0, 0, 0),
                                   row_5 = c(0, 0, 1, 1, 1, 0, 0, 0, 0, 0),
                                   row_6 = c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0),
                                   row_7 = c(0, 0, 0, 0, 0, 2, 2, 2, 0, 0),
                                   row_8 = c(0, 0, 0, 0, 0, 2, 2, 2, 0, 0),
                                   row_9 = c(0, 0, 0, 0, 0, 2, 2, 2, 0, 0),
                                 row_10 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0))
```
If I repeat the analysis, the assignment is different:
 ```
results2 = data.frame(row_1 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                                   row_2 = c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0),
                                   row_3 = c(0, 0, 1, 1, 1, 0, 0, 0, 0, 0),
                                   row_4 = c(0, 0, 1, 1, 1, 1, 1, 1, 0, 0),
                                   row_5 = c(0, 0, 1, 1, 1, 0, 0, 0, 0, 0),
                                   row_6 = c(0, 1, 0, 1, 1, 0, 0, 0, 0, 0),
                                   row_7 = c(0, 0, 0, 0, 0, 2, 2, 2, 0, 0),
                                   row_8 = c(0, 0, 0, 0, 0, 0, 2, 0, 0, 0),
                                   row_9 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
                                 row_10 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0))
```
To note that in results2 there are differences in rows 4, 6, 8, 9.
Is it possible to create a new object containing the points with 100%
(or 95%) identity? Some kind of machine learning algorithm?
Thank you


From henr|k@bengt@@on @end|ng |rom gm@||@com  Fri Oct 22 19:30:27 2021
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 22 Oct 2021 10:30:27 -0700
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CAHqSRuRT0SGzMHr9i=_0hL29HaMYRfBOnmapetF-sx6BnZBBYQ@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
 <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
 <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>
 <CAHqSRuRT0SGzMHr9i=_0hL29HaMYRfBOnmapetF-sx6BnZBBYQ@mail.gmail.com>
Message-ID: <CAFDcVCTcaQ0zqr4FwSoPHMoWuAtVxNZN9hj+T5B-fbj5RedMbQ@mail.gmail.com>

I agree with others that this suggests there is a hidden bug in the
code.  In addition to running with Valgrind, R-hub's

> rhub::check(platform="linux-x86_64-rocker-gcc-san")

will compile the native code with the Address Sanitizer (ASan) and the
UndefinedBehaviorSanitizer (UBSan).  Those have helped me in the past
to track down mistakes, and even spot things I was not aware of.  And
it's an ease of mind as a developer when these tools and Valgrind
checks give all OK reports.

The R-hub services is cross-platform and requires no local setup.

/Henrik

On Fri, Oct 22, 2021 at 7:41 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> I agree with Stefan.  Try using valgrind (on Linux) to check for memory
> misuse:
>
> R --debugger=valgrind --debugger-args="--leak-check=full
> --track-origins=yes"
> ...
> > yourTests()
> > q("no")
>
> -Bill
>
>
> On Fri, Oct 22, 2021 at 7:30 AM Stefan Evert <stefanML at collocations.de>
> wrote:
>
> > Just to add my personal cent to this:  I've had similar issues with an R
> > package some time ago, which kept crashing somewhat unpredictably in the
> > Solaris tests.
> >
> > Debugging was hard because it only happened on Solaris, but in the end it
> > turned out to be due to serious bugs in the code that only happened to
> > surface in the Solaris tests.   I would think that it's likely to be the
> > same for your package, so the segfaults shouldn't be accepted too readily
> > as a platform quirk.
> >
> > Best
> > SE
> >
> >
> > > On 22 Oct 2021, at 15:47, Marc Schwartz via R-help <r-help at r-project.org>
> > wrote:
> > >
> > >
> > > 1. The CRAN repository policy here:
> > >
> > >  https://cran.r-project.org/web/packages/policies.html
> > >
> > > notes:
> > >
> > > "Package authors should make all reasonable efforts to provide
> > cross-platform portable code. Packages will not normally be accepted that
> > do not run on at least two of the major R platforms. Cases for Windows-only
> > packages will be considered, but CRAN may not be the most appropriate place
> > to host them."
> > >
> > > That would seem to infer that, with reasonable justification, one may be
> > able to make a request of the CRAN maintainers to exclude at least one of
> > the OS platforms from testing. A request that would be at the discretion of
> > the CRAN maintainers and Solaris, in light of the low market prevalence,
> > may be a more common exclusion as you have noted below.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mou@e||m|@|@mpro@ @end|ng |rom gm@||@com  Fri Oct 22 20:07:32 2021
From: mou@e||m|@|@mpro@ @end|ng |rom gm@||@com (lampros mouselimis)
Date: Fri, 22 Oct 2021 21:07:32 +0300
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CAFDcVCTcaQ0zqr4FwSoPHMoWuAtVxNZN9hj+T5B-fbj5RedMbQ@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
 <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
 <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>
 <CAHqSRuRT0SGzMHr9i=_0hL29HaMYRfBOnmapetF-sx6BnZBBYQ@mail.gmail.com>
 <CAFDcVCTcaQ0zqr4FwSoPHMoWuAtVxNZN9hj+T5B-fbj5RedMbQ@mail.gmail.com>
Message-ID: <CADmY=VG8DHosNAf_Lc67obDUmJLu70cJu+P9VMCYMG6yzPkHyA@mail.gmail.com>

Thank you all for your answers,

I'll give it a try using both valgrind (on linux) and the rhub's linux gcc
Address Sanitizers (Asan). I've already used rhub to test the package on
the Solaris OS but it didn't give any error (it seems to me that the
configurations between CRAN and rhub differ).

Lampros

On Fri, 22 Oct 2021 at 20:31, Henrik Bengtsson <henrik.bengtsson at gmail.com>
wrote:

> I agree with others that this suggests there is a hidden bug in the
> code.  In addition to running with Valgrind, R-hub's
>
> > rhub::check(platform="linux-x86_64-rocker-gcc-san")
>
> will compile the native code with the Address Sanitizer (ASan) and the
> UndefinedBehaviorSanitizer (UBSan).  Those have helped me in the past
> to track down mistakes, and even spot things I was not aware of.  And
> it's an ease of mind as a developer when these tools and Valgrind
> checks give all OK reports.
>
> The R-hub services is cross-platform and requires no local setup.
>
> /Henrik
>
> On Fri, Oct 22, 2021 at 7:41 AM Bill Dunlap <williamwdunlap at gmail.com>
> wrote:
> >
> > I agree with Stefan.  Try using valgrind (on Linux) to check for memory
> > misuse:
> >
> > R --debugger=valgrind --debugger-args="--leak-check=full
> > --track-origins=yes"
> > ...
> > > yourTests()
> > > q("no")
> >
> > -Bill
> >
> >
> > On Fri, Oct 22, 2021 at 7:30 AM Stefan Evert <stefanML at collocations.de>
> > wrote:
> >
> > > Just to add my personal cent to this:  I've had similar issues with an
> R
> > > package some time ago, which kept crashing somewhat unpredictably in
> the
> > > Solaris tests.
> > >
> > > Debugging was hard because it only happened on Solaris, but in the end
> it
> > > turned out to be due to serious bugs in the code that only happened to
> > > surface in the Solaris tests.   I would think that it's likely to be
> the
> > > same for your package, so the segfaults shouldn't be accepted too
> readily
> > > as a platform quirk.
> > >
> > > Best
> > > SE
> > >
> > >
> > > > On 22 Oct 2021, at 15:47, Marc Schwartz via R-help <
> r-help at r-project.org>
> > > wrote:
> > > >
> > > >
> > > > 1. The CRAN repository policy here:
> > > >
> > > >  https://cran.r-project.org/web/packages/policies.html
> > > >
> > > > notes:
> > > >
> > > > "Package authors should make all reasonable efforts to provide
> > > cross-platform portable code. Packages will not normally be accepted
> that
> > > do not run on at least two of the major R platforms. Cases for
> Windows-only
> > > packages will be considered, but CRAN may not be the most appropriate
> place
> > > to host them."
> > > >
> > > > That would seem to infer that, with reasonable justification, one
> may be
> > > able to make a request of the CRAN maintainers to exclude at least one
> of
> > > the OS platforms from testing. A request that would be at the
> discretion of
> > > the CRAN maintainers and Solaris, in light of the low market
> prevalence,
> > > may be a more common exclusion as you have noted below.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Oct 22 20:43:34 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 22 Oct 2021 11:43:34 -0700
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CADmY=VG8DHosNAf_Lc67obDUmJLu70cJu+P9VMCYMG6yzPkHyA@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
 <CAGgJW74J9rQfsT9r4qR_CkqUeSj07jDVswxerfc8ayNM=3DSrQ@mail.gmail.com>
 <2b326bb4-8bc7-df46-7c2d-5b0d2f847d6b@me.com>
 <86462747-8C3D-48FE-AA81-9269D6582E96@collocations.de>
 <CAHqSRuRT0SGzMHr9i=_0hL29HaMYRfBOnmapetF-sx6BnZBBYQ@mail.gmail.com>
 <CAFDcVCTcaQ0zqr4FwSoPHMoWuAtVxNZN9hj+T5B-fbj5RedMbQ@mail.gmail.com>
 <CADmY=VG8DHosNAf_Lc67obDUmJLu70cJu+P9VMCYMG6yzPkHyA@mail.gmail.com>
Message-ID: <CAHqSRuSeusnibwHd7QGSPjCvA5VqBHjB5gadjEmEs1RO4kOmvg@mail.gmail.com>

gctorture(TRUE) helps too, but it will take a long time.

-Bill

On Fri, Oct 22, 2021 at 11:07 AM lampros mouselimis <
mouselimislampros at gmail.com> wrote:

> Thank you all for your answers,
>
> I'll give it a try using both valgrind (on linux) and the rhub's linux gcc
> Address Sanitizers (Asan). I've already used rhub to test the package on
> the Solaris OS but it didn't give any error (it seems to me that the
> configurations between CRAN and rhub differ).
>
> Lampros
>
> On Fri, 22 Oct 2021 at 20:31, Henrik Bengtsson <henrik.bengtsson at gmail.com>
> wrote:
>
>> I agree with others that this suggests there is a hidden bug in the
>> code.  In addition to running with Valgrind, R-hub's
>>
>> > rhub::check(platform="linux-x86_64-rocker-gcc-san")
>>
>> will compile the native code with the Address Sanitizer (ASan) and the
>> UndefinedBehaviorSanitizer (UBSan).  Those have helped me in the past
>> to track down mistakes, and even spot things I was not aware of.  And
>> it's an ease of mind as a developer when these tools and Valgrind
>> checks give all OK reports.
>>
>> The R-hub services is cross-platform and requires no local setup.
>>
>> /Henrik
>>
>> On Fri, Oct 22, 2021 at 7:41 AM Bill Dunlap <williamwdunlap at gmail.com>
>> wrote:
>> >
>> > I agree with Stefan.  Try using valgrind (on Linux) to check for memory
>> > misuse:
>> >
>> > R --debugger=valgrind --debugger-args="--leak-check=full
>> > --track-origins=yes"
>> > ...
>> > > yourTests()
>> > > q("no")
>> >
>> > -Bill
>> >
>> >
>> > On Fri, Oct 22, 2021 at 7:30 AM Stefan Evert <stefanML at collocations.de>
>> > wrote:
>> >
>> > > Just to add my personal cent to this:  I've had similar issues with
>> an R
>> > > package some time ago, which kept crashing somewhat unpredictably in
>> the
>> > > Solaris tests.
>> > >
>> > > Debugging was hard because it only happened on Solaris, but in the
>> end it
>> > > turned out to be due to serious bugs in the code that only happened to
>> > > surface in the Solaris tests.   I would think that it's likely to be
>> the
>> > > same for your package, so the segfaults shouldn't be accepted too
>> readily
>> > > as a platform quirk.
>> > >
>> > > Best
>> > > SE
>> > >
>> > >
>> > > > On 22 Oct 2021, at 15:47, Marc Schwartz via R-help <
>> r-help at r-project.org>
>> > > wrote:
>> > > >
>> > > >
>> > > > 1. The CRAN repository policy here:
>> > > >
>> > > >  https://cran.r-project.org/web/packages/policies.html
>> > > >
>> > > > notes:
>> > > >
>> > > > "Package authors should make all reasonable efforts to provide
>> > > cross-platform portable code. Packages will not normally be accepted
>> that
>> > > do not run on at least two of the major R platforms. Cases for
>> Windows-only
>> > > packages will be considered, but CRAN may not be the most appropriate
>> place
>> > > to host them."
>> > > >
>> > > > That would seem to infer that, with reasonable justification, one
>> may be
>> > > able to make a request of the CRAN maintainers to exclude at least
>> one of
>> > > the OS platforms from testing. A request that would be at the
>> discretion of
>> > > the CRAN maintainers and Solaris, in light of the low market
>> prevalence,
>> > > may be a more common exclusion as you have noted below.
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct 23 22:15:40 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 23 Oct 2021 22:15:40 +0200
Subject: [R] generate average frame from different data frames
Message-ID: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>

Hello,
I have a series of classifications of the same data. I saved this
classification in a single dataframe (but it could be a list). X and Y
are the variable and Z is the classification by three raters. `I` is
the individual identifier of each entry:
```
z1 = c(0,0,0,0,0,1,0,0,0,2,
0,1,1,1,0,0,0,1,0,2,
0,1,1,2,0,0,0,1,0,2,
1,1,1,2,1,0,0,1,1,2,
1,0,0,2,1,1,0,1,2,0)
z2 = c(0,0,0,0,0,1,0,0,1,1,
0,1,1,2,0,0,0,1,1,2,
0,0,0,1,0,0,0,1,0,0,
1,2,1,2,1,0,0,1,1,2,
1,0,1,2,1,1,0,1,2,0)
z3 = c(0,0,0,2,0,0,0,0,0,2,
0,1,0,2,0,0,0,1,0,2,
0,1,1,2,0,0,0,1,0,2,
1,1,1,2,1,0,0,2,1,2,
2,0,1,1,1,1,0,1,1,0)
df = data.frame(X=rep(1:5,3), Y=rep(1:5,3), Z=factor(c(z1,z2,z3)), I =1:150)
```
Is there a way to obtain a kind of heath map for each point? Let's say
for the point (x=1,y-1), what was the most common (average)
classification? Is it possible to get the 95% CI of that mean?
Would Two-Dimensional Kernel Density Estimation be the right path?
Thank you


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sat Oct 23 22:19:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sat, 23 Oct 2021 22:19:02 +0200
Subject: [R] create mean ksvm model
Message-ID: <CAMk+s2T8PrAEH-Q5qTi5JOvr+We8TxG11MK6d=wuEpcrR9QGyw@mail.gmail.com>

Hello,
I am using the ksvm function from the library kernlab to generate an
SVM classification. I am running the model with k-mean
cross-validation, thus obtaining different accuracy.
Is it possible to merge the different models obtained with the
separate data set to generate a kind of median model, one that
accounts for all the datasets used for the training?
Thank you


From bgunter@4567 @end|ng |rom gm@||@com  Sat Oct 23 23:42:09 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 23 Oct 2021 14:42:09 -0700
Subject: [R] create mean ksvm model
In-Reply-To: <CAMk+s2T8PrAEH-Q5qTi5JOvr+We8TxG11MK6d=wuEpcrR9QGyw@mail.gmail.com>
References: <CAMk+s2T8PrAEH-Q5qTi5JOvr+We8TxG11MK6d=wuEpcrR9QGyw@mail.gmail.com>
Message-ID: <CAGxFJbTc7HpOvTe8BGuNdDtgjotxPMaw1Z=TnzKj26DMahGPqQ@mail.gmail.com>

You appear to be bombarding the list with statistics questions. Please note
per the posting guide linked below:

"*Questions about statistics:* The R mailing lists are primarily intended
for questions and discussion about the R software. However, questions about
statistical methodology are sometimes posted. If the question is well-asked
and of interest to someone on the list, it *may* elicit an informative
up-to-date answer."

So you should not be surprised if you do not receive any responses. You
*may* do better posting such questions on Cross Validated:
https://stats.stackexchange.com/ .

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Oct 23, 2021 at 1:19 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I am using the ksvm function from the library kernlab to generate an
> SVM classification. I am running the model with k-mean
> cross-validation, thus obtaining different accuracy.
> Is it possible to merge the different models obtained with the
> separate data set to generate a kind of median model, one that
> accounts for all the datasets used for the training?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Oct 24 00:08:44 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 24 Oct 2021 09:08:44 +1100
Subject: [R] generate average frame from different data frames
In-Reply-To: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>
References: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>
Message-ID: <CA+8X3fVAtGuioczrJN=3VXD+hukKNpSJ2R+so8iXyPbAY3xGag@mail.gmail.com>

Hi Luigi,
I may be missing the point, but:

matrix((z1+z2+z3)/3,ncol=10)

gives you the mean rating for each item, and depending upon what
distribution you choose, the confidence intervals could be calculated
in much the same way.

Jim

On Sun, Oct 24, 2021 at 7:16 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a series of classifications of the same data. I saved this
> classification in a single dataframe (but it could be a list). X and Y
> are the variable and Z is the classification by three raters. `I` is
> the individual identifier of each entry:
> ```
> z1 = c(0,0,0,0,0,1,0,0,0,2,
> 0,1,1,1,0,0,0,1,0,2,
> 0,1,1,2,0,0,0,1,0,2,
> 1,1,1,2,1,0,0,1,1,2,
> 1,0,0,2,1,1,0,1,2,0)
> z2 = c(0,0,0,0,0,1,0,0,1,1,
> 0,1,1,2,0,0,0,1,1,2,
> 0,0,0,1,0,0,0,1,0,0,
> 1,2,1,2,1,0,0,1,1,2,
> 1,0,1,2,1,1,0,1,2,0)
> z3 = c(0,0,0,2,0,0,0,0,0,2,
> 0,1,0,2,0,0,0,1,0,2,
> 0,1,1,2,0,0,0,1,0,2,
> 1,1,1,2,1,0,0,2,1,2,
> 2,0,1,1,1,1,0,1,1,0)
> df = data.frame(X=rep(1:5,3), Y=rep(1:5,3), Z=factor(c(z1,z2,z3)), I =1:150)
> ```
> Is there a way to obtain a kind of heath map for each point? Let's say
> for the point (x=1,y-1), what was the most common (average)
> classification? Is it possible to get the 95% CI of that mean?
> Would Two-Dimensional Kernel Density Estimation be the right path?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Oct 24 07:39:34 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Oct 2021 07:39:34 +0200
Subject: [R] generate average frame from different data frames
In-Reply-To: <CA+8X3fVAtGuioczrJN=3VXD+hukKNpSJ2R+so8iXyPbAY3xGag@mail.gmail.com>
References: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>
 <CA+8X3fVAtGuioczrJN=3VXD+hukKNpSJ2R+so8iXyPbAY3xGag@mail.gmail.com>
Message-ID: <CAMk+s2SFYRw6VFGeY5do3pm6nCwA0oEkt5TVbcWxfFd95m=5Eg@mail.gmail.com>

Thank you. Sorry for the fuzziness of the question but I find it
difficult to give a proper definition of the problem. I have given a
graphical rendering on this post
https://www.researchgate.net/post/How_to_find_95_CI_of_a_matrix_of_classification_data
As you can see in the figure, there are dots where the same value is
represented all the time, and others where the values fluctuate. I
would like to generate the "mean" merge of the figures. (Perhaps also
with lines saying: this value comes out 9/10 of times, this 5/10 of
times...).
The problem is that the Z values are factors, not numbers.

On Sun, Oct 24, 2021 at 12:08 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> I may be missing the point, but:
>
> matrix((z1+z2+z3)/3,ncol=10)
>
> gives you the mean rating for each item, and depending upon what
> distribution you choose, the confidence intervals could be calculated
> in much the same way.
>
> Jim
>
> On Sun, Oct 24, 2021 at 7:16 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have a series of classifications of the same data. I saved this
> > classification in a single dataframe (but it could be a list). X and Y
> > are the variable and Z is the classification by three raters. `I` is
> > the individual identifier of each entry:
> > ```
> > z1 = c(0,0,0,0,0,1,0,0,0,2,
> > 0,1,1,1,0,0,0,1,0,2,
> > 0,1,1,2,0,0,0,1,0,2,
> > 1,1,1,2,1,0,0,1,1,2,
> > 1,0,0,2,1,1,0,1,2,0)
> > z2 = c(0,0,0,0,0,1,0,0,1,1,
> > 0,1,1,2,0,0,0,1,1,2,
> > 0,0,0,1,0,0,0,1,0,0,
> > 1,2,1,2,1,0,0,1,1,2,
> > 1,0,1,2,1,1,0,1,2,0)
> > z3 = c(0,0,0,2,0,0,0,0,0,2,
> > 0,1,0,2,0,0,0,1,0,2,
> > 0,1,1,2,0,0,0,1,0,2,
> > 1,1,1,2,1,0,0,2,1,2,
> > 2,0,1,1,1,1,0,1,1,0)
> > df = data.frame(X=rep(1:5,3), Y=rep(1:5,3), Z=factor(c(z1,z2,z3)), I =1:150)
> > ```
> > Is there a way to obtain a kind of heath map for each point? Let's say
> > for the point (x=1,y-1), what was the most common (average)
> > classification? Is it possible to get the 95% CI of that mean?
> > Would Two-Dimensional Kernel Density Estimation be the right path?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Oct 24 07:40:15 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Oct 2021 07:40:15 +0200
Subject: [R] create mean ksvm model
In-Reply-To: <CAGxFJbTc7HpOvTe8BGuNdDtgjotxPMaw1Z=TnzKj26DMahGPqQ@mail.gmail.com>
References: <CAMk+s2T8PrAEH-Q5qTi5JOvr+We8TxG11MK6d=wuEpcrR9QGyw@mail.gmail.com>
 <CAGxFJbTc7HpOvTe8BGuNdDtgjotxPMaw1Z=TnzKj26DMahGPqQ@mail.gmail.com>
Message-ID: <CAMk+s2R-8jk+cTNO4ZqAZXteRFXrG0gMvBcCHW+0tMJopbMbeg@mail.gmail.com>

Thank you for the clarification.

On Sat, Oct 23, 2021 at 11:42 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You appear to be bombarding the list with statistics questions. Please note per the posting guide linked below:
>
> "Questions about statistics: The R mailing lists are primarily intended for questions and discussion about the R software. However, questions about statistical methodology are sometimes posted. If the question is well-asked and of interest to someone on the list, it may elicit an informative up-to-date answer."
>
> So you should not be surprised if you do not receive any responses. You *may* do better posting such questions on Cross Validated:  https://stats.stackexchange.com/ .
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Oct 23, 2021 at 1:19 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I am using the ksvm function from the library kernlab to generate an
>> SVM classification. I am running the model with k-mean
>> cross-validation, thus obtaining different accuracy.
>> Is it possible to merge the different models obtained with the
>> separate data set to generate a kind of median model, one that
>> accounts for all the datasets used for the training?
>> Thank you
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From drj|m|emon @end|ng |rom gm@||@com  Sun Oct 24 08:07:43 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 24 Oct 2021 17:07:43 +1100
Subject: [R] generate average frame from different data frames
In-Reply-To: <CAMk+s2SFYRw6VFGeY5do3pm6nCwA0oEkt5TVbcWxfFd95m=5Eg@mail.gmail.com>
References: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>
 <CA+8X3fVAtGuioczrJN=3VXD+hukKNpSJ2R+so8iXyPbAY3xGag@mail.gmail.com>
 <CAMk+s2SFYRw6VFGeY5do3pm6nCwA0oEkt5TVbcWxfFd95m=5Eg@mail.gmail.com>
Message-ID: <CA+8X3fX2m7Mrt2o+1rk9zupWnzFiDp7PFtggRZCSLmNAj6mpMw@mail.gmail.com>

Hi Luigi,
In that case you will want a binomial confidence interval.

Jim

On Sun, Oct 24, 2021 at 4:39 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you. Sorry for the fuzziness of the question but I find it
> difficult to give a proper definition of the problem. I have given a
> graphical rendering on this post
> https://www.researchgate.net/post/How_to_find_95_CI_of_a_matrix_of_classification_data
> As you can see in the figure, there are dots where the same value is
> represented all the time, and others where the values fluctuate. I
> would like to generate the "mean" merge of the figures. (Perhaps also
> with lines saying: this value comes out 9/10 of times, this 5/10 of
> times...).
> The problem is that the Z values are factors, not numbers.
>
> On Sun, Oct 24, 2021 at 12:08 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > I may be missing the point, but:
> >
> > matrix((z1+z2+z3)/3,ncol=10)
> >
> > gives you the mean rating for each item, and depending upon what
> > distribution you choose, the confidence intervals could be calculated
> > in much the same way.
> >
> > Jim
> >
> > On Sun, Oct 24, 2021 at 7:16 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have a series of classifications of the same data. I saved this
> > > classification in a single dataframe (but it could be a list). X and Y
> > > are the variable and Z is the classification by three raters. `I` is
> > > the individual identifier of each entry:
> > > ```
> > > z1 = c(0,0,0,0,0,1,0,0,0,2,
> > > 0,1,1,1,0,0,0,1,0,2,
> > > 0,1,1,2,0,0,0,1,0,2,
> > > 1,1,1,2,1,0,0,1,1,2,
> > > 1,0,0,2,1,1,0,1,2,0)
> > > z2 = c(0,0,0,0,0,1,0,0,1,1,
> > > 0,1,1,2,0,0,0,1,1,2,
> > > 0,0,0,1,0,0,0,1,0,0,
> > > 1,2,1,2,1,0,0,1,1,2,
> > > 1,0,1,2,1,1,0,1,2,0)
> > > z3 = c(0,0,0,2,0,0,0,0,0,2,
> > > 0,1,0,2,0,0,0,1,0,2,
> > > 0,1,1,2,0,0,0,1,0,2,
> > > 1,1,1,2,1,0,0,2,1,2,
> > > 2,0,1,1,1,1,0,1,1,0)
> > > df = data.frame(X=rep(1:5,3), Y=rep(1:5,3), Z=factor(c(z1,z2,z3)), I =1:150)
> > > ```
> > > Is there a way to obtain a kind of heath map for each point? Let's say
> > > for the point (x=1,y-1), what was the most common (average)
> > > classification? Is it possible to get the 95% CI of that mean?
> > > Would Two-Dimensional Kernel Density Estimation be the right path?
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Sun Oct 24 18:58:28 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Sun, 24 Oct 2021 18:58:28 +0200
Subject: [R] generate average frame from different data frames
In-Reply-To: <CA+8X3fX2m7Mrt2o+1rk9zupWnzFiDp7PFtggRZCSLmNAj6mpMw@mail.gmail.com>
References: <CAMk+s2RLnOehim-bjJgssjK5J+tVm_XwFRy6sfo9NpPjcom93A@mail.gmail.com>
 <CA+8X3fVAtGuioczrJN=3VXD+hukKNpSJ2R+so8iXyPbAY3xGag@mail.gmail.com>
 <CAMk+s2SFYRw6VFGeY5do3pm6nCwA0oEkt5TVbcWxfFd95m=5Eg@mail.gmail.com>
 <CA+8X3fX2m7Mrt2o+1rk9zupWnzFiDp7PFtggRZCSLmNAj6mpMw@mail.gmail.com>
Message-ID: <CAMk+s2TidoY+OGQ+_vjuP82rgR_sEd1SHjbnfOQMLSz7cqvPBA@mail.gmail.com>

Thanks for the tip! I'll check it out.

On Sun, Oct 24, 2021 at 8:07 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> In that case you will want a binomial confidence interval.
>
> Jim
>
> On Sun, Oct 24, 2021 at 4:39 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thank you. Sorry for the fuzziness of the question but I find it
> > difficult to give a proper definition of the problem. I have given a
> > graphical rendering on this post
> > https://www.researchgate.net/post/How_to_find_95_CI_of_a_matrix_of_classification_data
> > As you can see in the figure, there are dots where the same value is
> > represented all the time, and others where the values fluctuate. I
> > would like to generate the "mean" merge of the figures. (Perhaps also
> > with lines saying: this value comes out 9/10 of times, this 5/10 of
> > times...).
> > The problem is that the Z values are factors, not numbers.
> >
> > On Sun, Oct 24, 2021 at 12:08 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > I may be missing the point, but:
> > >
> > > matrix((z1+z2+z3)/3,ncol=10)
> > >
> > > gives you the mean rating for each item, and depending upon what
> > > distribution you choose, the confidence intervals could be calculated
> > > in much the same way.
> > >
> > > Jim
> > >
> > > On Sun, Oct 24, 2021 at 7:16 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have a series of classifications of the same data. I saved this
> > > > classification in a single dataframe (but it could be a list). X and Y
> > > > are the variable and Z is the classification by three raters. `I` is
> > > > the individual identifier of each entry:
> > > > ```
> > > > z1 = c(0,0,0,0,0,1,0,0,0,2,
> > > > 0,1,1,1,0,0,0,1,0,2,
> > > > 0,1,1,2,0,0,0,1,0,2,
> > > > 1,1,1,2,1,0,0,1,1,2,
> > > > 1,0,0,2,1,1,0,1,2,0)
> > > > z2 = c(0,0,0,0,0,1,0,0,1,1,
> > > > 0,1,1,2,0,0,0,1,1,2,
> > > > 0,0,0,1,0,0,0,1,0,0,
> > > > 1,2,1,2,1,0,0,1,1,2,
> > > > 1,0,1,2,1,1,0,1,2,0)
> > > > z3 = c(0,0,0,2,0,0,0,0,0,2,
> > > > 0,1,0,2,0,0,0,1,0,2,
> > > > 0,1,1,2,0,0,0,1,0,2,
> > > > 1,1,1,2,1,0,0,2,1,2,
> > > > 2,0,1,1,1,1,0,1,1,0)
> > > > df = data.frame(X=rep(1:5,3), Y=rep(1:5,3), Z=factor(c(z1,z2,z3)), I =1:150)
> > > > ```
> > > > Is there a way to obtain a kind of heath map for each point? Let's say
> > > > for the point (x=1,y-1), what was the most common (average)
> > > > classification? Is it possible to get the 95% CI of that mean?
> > > > Would Two-Dimensional Kernel Density Estimation be the right path?
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Sun Oct 24 22:57:26 2021
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Sun, 24 Oct 2021 22:57:26 +0200
Subject: [R] problem with plotting clustered data with convex hull using
 ggfortify
Message-ID: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>

Dear all:

I have some data that I want to cluster and display as groups surrounded 
by convex hulls. Here, i use the iris data as an example:

library(ggfortify)
autoplot(fanny(iris[-5], 3), frame = TRUE)

I used this code before, about a year ago, and then it resulted in data 
surrounded by convex hulls., just as may be seen in the description of 
ggfortify here:


http://rstudio-pubs-static.s3.amazonaws.com/53162_cd16ee63c24747459ccd180f69f07810.html


Presently, no hulls are drawn; instead some line is projected on each 
cluster.

I found out that there is an addition to autoplot command, "frame.type = 
c("convex", "norm", "t"). Whereas ""norm" and "t"  give confidence 
ellipses as expected, "convex" results in a straight line as mentioned 
above.

Any help would be appreciated.

Best

-- 
Karl Schilling


From bgunter@4567 @end|ng |rom gm@||@com  Sun Oct 24 23:19:48 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 24 Oct 2021 14:19:48 -0700
Subject: [R] problem with plotting clustered data with convex hull using
 ggfortify
In-Reply-To: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>
References: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>
Message-ID: <CAGxFJbRL2iOKbe0BmOfNcjwuRumojFYGwkT9TFk-axRk_HC2SA@mail.gmail.com>

ggfortify is a (nonstandard) contributed package. Please note that per the
posting guide linked below:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<https://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So while you may get help here, the above may be a better course of action.
Also, if all you have done is copy and paste code, you should consider
going through the vignettes for the package. They seem fairly extensive
from my quick look and may well provide the answers you seek.

Bert Gunter



On Sun, Oct 24, 2021 at 1:57 PM Karl Schilling <karl.schilling at uni-bonn.de>
wrote:

> Dear all:
>
> I have some data that I want to cluster and display as groups surrounded
> by convex hulls. Here, i use the iris data as an example:
>
> library(ggfortify)
> autoplot(fanny(iris[-5], 3), frame = TRUE)
>
> I used this code before, about a year ago, and then it resulted in data
> surrounded by convex hulls., just as may be seen in the description of
> ggfortify here:
>
>
>
> http://rstudio-pubs-static.s3.amazonaws.com/53162_cd16ee63c24747459ccd180f69f07810.html
>
>
> Presently, no hulls are drawn; instead some line is projected on each
> cluster.
>
> I found out that there is an addition to autoplot command, "frame.type =
> c("convex", "norm", "t"). Whereas ""norm" and "t"  give confidence
> ellipses as expected, "convex" results in a straight line as mentioned
> above.
>
> Any help would be appreciated.
>
> Best
>
> --
> Karl Schilling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 25 00:32:03 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 24 Oct 2021 23:32:03 +0100
Subject: [R] problem with plotting clustered data with convex hull using
 ggfortify
In-Reply-To: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>
References: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>
Message-ID: <a2d27e8d-c357-b1e4-27bc-d9b2733b0d09@sapo.pt>

Hello,

R 4.1.1 on Ubuntu 20.04.3 LTS.

I can reproduce this error. It happens with ggfortify 0.4.12 but not 
with 0.4.11.

First ggfortify 0.4.11, notice the warnings.


rui at rui:~$ R -q -f rhelp.R
 > library(ggfortify)
Loading required package: ggplot2
 > library(cluster)
 >
 > autoplot(fanny(iris[-5], 3), frame = TRUE)
Warning messages:
1: `select_()` was deprecated in dplyr 0.7.0.
Please use `select()` instead.
This warning is displayed once every 8 hours.
Call `lifecycle::last_warnings()` to see where this warning was generated.
2: `group_by_()` was deprecated in dplyr 0.7.0.
Please use `group_by()` instead.
See vignette('programming') for more help
This warning is displayed once every 8 hours.
Call `lifecycle::last_warnings()` to see where this warning was generated.
 > packageVersion("cluster")
[1] ?2.1.2?
 > packageVersion("ggfortify")
[1] ?0.4.11?
 >
 > sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS
[...]


#---------------

Now ggfortify 0.4.12, notice that the errors are gone but there's a 
message, probably printed with cat().



rui at rui-p6550pt:~$ R -q -f rhelp.R
 > library(ggfortify)
Loading required package: ggplot2
 > library(cluster)
 >
 > autoplot(fanny(iris[-5], 3), frame = TRUE)
Adding missing grouping variables: `cluster`
 > packageVersion("cluster")
[1] ?2.1.2?
 > packageVersion("ggfortify")
[1] ?0.4.12?
 >
 > sessionInfo()
R version 4.1.1 (2021-08-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.3 LTS
[...]


One problem was fixed, another showed up.
You should contact the package maintainer.


Hope this helps,

Rui Barradas


?s 21:57 de 24/10/21, Karl Schilling escreveu:
> Dear all:
> 
> I have some data that I want to cluster and display as groups surrounded 
> by convex hulls. Here, i use the iris data as an example:
> 
> library(ggfortify)
> autoplot(fanny(iris[-5], 3), frame = TRUE)
> 
> I used this code before, about a year ago, and then it resulted in data 
> surrounded by convex hulls., just as may be seen in the description of 
> ggfortify here:
> 
> 
> http://rstudio-pubs-static.s3.amazonaws.com/53162_cd16ee63c24747459ccd180f69f07810.html 
> 
> 
> 
> Presently, no hulls are drawn; instead some line is projected on each 
> cluster.
> 
> I found out that there is an addition to autoplot command, "frame.type = 
> c("convex", "norm", "t"). Whereas ""norm" and "t"? give confidence 
> ellipses as expected, "convex" results in a straight line as mentioned 
> above.
> 
> Any help would be appreciated.
> 
> Best
>


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Mon Oct 25 01:00:07 2021
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Mon, 25 Oct 2021 01:00:07 +0200
Subject: [R] problem with plotting clustered data with convex hull using
 ggfortify
In-Reply-To: <a2d27e8d-c357-b1e4-27bc-d9b2733b0d09@sapo.pt>
References: <99026900-41d5-078f-3012-41d6c2113c3b@uni-bonn.de>
 <a2d27e8d-c357-b1e4-27bc-d9b2733b0d09@sapo.pt>
Message-ID: <01223d14-3252-5a0a-1cbe-7e935e61c3a7@uni-bonn.de>

Dear Mr Barradas,

thank you so much. After going back to the 4.1.1  version, the convex 
hulls were plotted again (R 4.1.0. Windows).

Will forward all this to the package maintainer.

But for the moment, your hint is of great help.

Thank you, all my best

Karl

On 25.10.2021 00:32, Rui Barradas wrote:
> Hello,
> 
> R 4.1.1 on Ubuntu 20.04.3 LTS.
> 
> I can reproduce this error. It happens with ggfortify 0.4.12 but not 
> with 0.4.11.
> 
> First ggfortify 0.4.11, notice the warnings.
> 
> 
> rui at rui:~$ R -q -f rhelp.R
>  > library(ggfortify)
> Loading required package: ggplot2
>  > library(cluster)
>  >
>  > autoplot(fanny(iris[-5], 3), frame = TRUE)
> Warning messages:
> 1: `select_()` was deprecated in dplyr 0.7.0.
> Please use `select()` instead.
> This warning is displayed once every 8 hours.
> Call `lifecycle::last_warnings()` to see where this warning was generated.
> 2: `group_by_()` was deprecated in dplyr 0.7.0.
> Please use `group_by()` instead.
> See vignette('programming') for more help
> This warning is displayed once every 8 hours.
> Call `lifecycle::last_warnings()` to see where this warning was generated.
>  > packageVersion("cluster")
> [1] ?2.1.2?
>  > packageVersion("ggfortify")
> [1] ?0.4.11?
>  >
>  > sessionInfo()
> R version 4.1.1 (2021-08-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.3 LTS
> [...]
> 
> 
> #---------------
> 
> Now ggfortify 0.4.12, notice that the errors are gone but there's a 
> message, probably printed with cat().
> 
> 
> 
> rui at rui-p6550pt:~$ R -q -f rhelp.R
>  > library(ggfortify)
> Loading required package: ggplot2
>  > library(cluster)
>  >
>  > autoplot(fanny(iris[-5], 3), frame = TRUE)
> Adding missing grouping variables: `cluster`
>  > packageVersion("cluster")
> [1] ?2.1.2?
>  > packageVersion("ggfortify")
> [1] ?0.4.12?
>  >
>  > sessionInfo()
> R version 4.1.1 (2021-08-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.3 LTS
> [...]
> 
> 
> One problem was fixed, another showed up.
> You should contact the package maintainer.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 21:57 de 24/10/21, Karl Schilling escreveu:
>> Dear all:
>>
>> I have some data that I want to cluster and display as groups 
>> surrounded by convex hulls. Here, i use the iris data as an example:
>>
>> library(ggfortify)
>> autoplot(fanny(iris[-5], 3), frame = TRUE)
>>
>> I used this code before, about a year ago, and then it resulted in 
>> data surrounded by convex hulls., just as may be seen in the 
>> description of ggfortify here:
>>
>>
>> http://rstudio-pubs-static.s3.amazonaws.com/53162_cd16ee63c24747459ccd180f69f07810.html 
>>
>>
>>
>> Presently, no hulls are drawn; instead some line is projected on each 
>> cluster.
>>
>> I found out that there is an addition to autoplot command, "frame.type 
>> = c("convex", "norm", "t"). Whereas ""norm" and "t"? give confidence 
>> ellipses as expected, "convex" results in a straight line as mentioned 
>> above.
>>
>> Any help would be appreciated.
>>
>> Best

-- 
Karl Schilling


From no@p@m @end|ng |rom ||@@e@NA  Mon Oct 25 13:25:44 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Mon, 25 Oct 2021 13:25:44 +0200
Subject: [R] cleanup/replacing a value on condition of another value
Message-ID: <sl647p$17td$1@ciao.gmane.io>

Hi,

I have data from JHU via the 'coronavirus' package which has a value for
the confirmed cases for 2021-10-23 which differs drastically (357) from
what is reported in country (23).

	# A tibble: 962 ? 4
	  country date       type      cases
	  <chr>   <date>     <chr>     <int>
	1 Namibia 2021-10-24 confirmed    23
	2 Namibia 2021-10-24 death         4
	3 Namibia 2021-10-23 confirmed   357
	4 Namibia 2021-10-23 death         1
	5 Namibia 2021-10-22 confirmed    30
	6 Namibia 2021-10-22 death         1
	# ? with 956 more rows

I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA
using something like

	country == 'Namibia' & date == '2021-10-23' & cases == 357

so that if or when the data-set is corrected I don't have to change the
code (immediately), even after some googling.

I can do

	cases == 357

only, but that could find other cases as well, which is obviously not 
the thing to do

Any suggestions?

greetings, el


From er|cjberger @end|ng |rom gm@||@com  Mon Oct 25 13:31:52 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 25 Oct 2021 14:31:52 +0300
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <sl647p$17td$1@ciao.gmane.io>
References: <sl647p$17td$1@ciao.gmane.io>
Message-ID: <CAGgJW77+qR80bVrT6ipCEqBd55TD_DRShtqWZAZ_0MT_tO7dkw@mail.gmail.com>

The tibble shows the 'date' column as type date but you are comparing
io a string.
Perhaps replace that piece by

date == as.Date("2021-10-23")

Not tested.
HTH,
Eric

On Mon, Oct 25, 2021 at 2:26 PM Dr Eberhard W Lisse <nospam at lisse.na> wrote:
>
> Hi,
>
> I have data from JHU via the 'coronavirus' package which has a value for
> the confirmed cases for 2021-10-23 which differs drastically (357) from
> what is reported in country (23).
>
>         # A tibble: 962 ? 4
>           country date       type      cases
>           <chr>   <date>     <chr>     <int>
>         1 Namibia 2021-10-24 confirmed    23
>         2 Namibia 2021-10-24 death         4
>         3 Namibia 2021-10-23 confirmed   357
>         4 Namibia 2021-10-23 death         1
>         5 Namibia 2021-10-22 confirmed    30
>         6 Namibia 2021-10-22 death         1
>         # ? with 956 more rows
>
> I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA
> using something like
>
>         country == 'Namibia' & date == '2021-10-23' & cases == 357
>
> so that if or when the data-set is corrected I don't have to change the
> code (immediately), even after some googling.
>
> I can do
>
>         cases == 357
>
> only, but that could find other cases as well, which is obviously not
> the thing to do
>
> Any suggestions?
>
> greetings, el
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 25 17:26:23 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 25 Oct 2021 16:26:23 +0100
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <sl647p$17td$1@ciao.gmane.io>
References: <sl647p$17td$1@ciao.gmane.io>
Message-ID: <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt>

Hello,

The following works with me.


library(coronavirus)
library(dplyr)

data(coronavirus, package = "coronavirus")
#update_dataset(silence = FALSE)

coronavirus %>%
   select(country, date, type, cases) %>%
   filter(
     country == 'Namibia',
     date == '2021-10-23',
     cases == 357
   )



Can you post the pipe code you are running?

Hope this helps,

Rui Barradas

?s 12:25 de 25/10/21, Dr Eberhard W Lisse escreveu:
> Hi,
> 
> I have data from JHU via the 'coronavirus' package which has a value for
> the confirmed cases for 2021-10-23 which differs drastically (357) from
> what is reported in country (23).
> 
>  ????# A tibble: 962 ? 4
>  ????? country date?????? type????? cases
>  ????? <chr>?? <date>???? <chr>???? <int>
>  ????1 Namibia 2021-10-24 confirmed??? 23
>  ????2 Namibia 2021-10-24 death???????? 4
>  ????3 Namibia 2021-10-23 confirmed?? 357
>  ????4 Namibia 2021-10-23 death???????? 1
>  ????5 Namibia 2021-10-22 confirmed??? 30
>  ????6 Namibia 2021-10-22 death???????? 1
>  ????# ? with 956 more rows
> 
> I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA
> using something like
> 
>  ????country == 'Namibia' & date == '2021-10-23' & cases == 357
> 
> so that if or when the data-set is corrected I don't have to change the
> code (immediately), even after some googling.
> 
> I can do
> 
>  ????cases == 357
> 
> only, but that could find other cases as well, which is obviously not 
> the thing to do
> 
> Any suggestions?
> 
> greetings, el
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@p@rk4 @end|ng |rom u|c@edu  Mon Oct 25 17:36:07 2021
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Mon, 25 Oct 2021 15:36:07 +0000
Subject: [R] KeyboardSimulator mouse.get_cursor() Not Working
Message-ID: <CH2PR13MB3640AC1CE98EF0F7D67B3B10FA839@CH2PR13MB3640.namprd13.prod.outlook.com>

Hi,

I tried using the mouse.get_cursor() function in the KeyboardSimulator library but it appears to no longer be working.

When I first tried it I got an error message

Error in get_cursor() :

  function 'Rcpp_precious_remove' not provided by package 'Rcpp'.

I installed and loaded the Rcpp library and then why I try the get_cursor() function it freezes my Windows gui version of R.

My Sys.info() is shown below.

Any help would be appreciated.

Thanks.
--John Sparks,

> Sys.info()
       sysname        release        version       nodename        machine          login
     "Windows"       "10 x64"  "build 19043"    "SPARKS-PC"       "x86-64"      "JSparks"
          user effective_user
     "JSparks"      "JSparks"







	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Mon Oct 25 17:49:02 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Mon, 25 Oct 2021 17:49:02 +0200
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt>
References: <sl647p$17td$1@ciao.gmane.io>
 <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt>
Message-ID: <sl6jlj$14mf$1@ciao.gmane.io>

Rui,

that works for me too, but is not what I need to do.

I want to make the 'cases' value for this particular country AND this
particular date AND this particular type AND this particular value (ie
ALL conditions must be fulfilled) become NA so that the tibble would
change from

	[...]
	2 Namibia 2021-10-24 death         4
	3 Namibia 2021-10-23 confirmed   357
	4 Namibia 2021-10-23 death         1
	[...]

to

	[...]
	2 Namibia 2021-10-24 death         4
	3 Namibia 2021-10-23 confirmed   357
	4 Namibia 2021-10-23 death         1
	[...]

as long as they don't fix the dataset, and if/when they do it goes to
the expected 23 value :-)-O

greetings, el

On 2021-10-25 17:26 , Rui Barradas wrote:
 > Hello,
 >
 > The following works with me.
 >
 >
 > library(coronavirus)
 > library(dplyr)
 >
 > data(coronavirus, package = "coronavirus")
 > #update_dataset(silence = FALSE)
 >
 > coronavirus %>%
 >    select(country, date, type, cases) %>%
 >    filter(
 >      country == 'Namibia',
 >      date == '2021-10-23',
 >      cases == 357
 >    )
 >
 >
 >
 > Can you post the pipe code you are running?
 >
 > Hope this helps,
 >
 > Rui Barradas
 >
 > ?s 12:25 de 25/10/21, Dr Eberhard W Lisse escreveu:
 >> Hi,
 >>
 >> I have data from JHU via the 'coronavirus' package which has a value for
 >> the confirmed cases for 2021-10-23 which differs drastically (357) from
 >> what is reported in country (23).
 >>
 >>      # A tibble: 962 ? 4
 >>        country date       type      cases
 >>        <chr>   <date>     <chr>     <int>
 >>      1 Namibia 2021-10-24 confirmed    23
 >>      2 Namibia 2021-10-24 death         4
 >>      3 Namibia 2021-10-23 confirmed   357
 >>      4 Namibia 2021-10-23 death         1
 >>      5 Namibia 2021-10-22 confirmed    30
 >>      6 Namibia 2021-10-22 death         1
 >>      # ? with 956 more rows
 >>
 >> I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA
 >> using something like
 >>
 >>      country == 'Namibia' & date == '2021-10-23' & cases == 357
 >>
 >> so that if or when the data-set is corrected I don't have to change the
 >> code (immediately), even after some googling.
 >>
 >> I can do
 >>
 >>      cases == 357
 >>
 >> only, but that could find other cases as well, which is obviously not
 >> the thing to do
 >>
 >> Any suggestions?
 >>
 >> greetings, el
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct 25 19:06:22 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 25 Oct 2021 18:06:22 +0100
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <sl6jlj$14mf$1@ciao.gmane.io>
References: <sl647p$17td$1@ciao.gmane.io>
 <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt> <sl6jlj$14mf$1@ciao.gmane.io>
Message-ID: <43faf7c8-e011-2e4e-880a-ea56ed1ebedb@sapo.pt>

Hello,

Here is a pipe to replace based on the composite condition.
It uses ?base::replace with an integer index vector.

In the end, filter is meant to show the changed value in context, remove 
it and assign the data.frame or tibble back to the input to change the 
original.


library(dplyr)

data(coronavirus, package = "coronavirus")

coronavirus %>%
   select(country, date, type, cases) -> covid

covid %>%
   mutate(cases = replace(cases,
                          which(country == 'Namibia' &
                                  date == '2021-10-23' &
                                  cases == 357), NA)
   ) %>%
   filter(
     country == 'Namibia',
     date >= '2021-10-22' & date <= '2021-10-24'
   )


Hope this helps,

Rui Barradas

?s 16:49 de 25/10/21, Dr Eberhard W Lisse escreveu:
> Rui,
> 
> that works for me too, but is not what I need to do.
> 
> I want to make the 'cases' value for this particular country AND this
> particular date AND this particular type AND this particular value (ie
> ALL conditions must be fulfilled) become NA so that the tibble would
> change from
> 
>  ????[...]
>  ????2 Namibia 2021-10-24 death???????? 4
>  ????3 Namibia 2021-10-23 confirmed?? 357
>  ????4 Namibia 2021-10-23 death???????? 1
>  ????[...]
> 
> to
> 
>  ????[...]
>  ????2 Namibia 2021-10-24 death???????? 4
>  ????3 Namibia 2021-10-23 confirmed?? 357
>  ????4 Namibia 2021-10-23 death???????? 1
>  ????[...]
> 
> as long as they don't fix the dataset, and if/when they do it goes to
> the expected 23 value :-)-O
> 
> greetings, el
> 
> On 2021-10-25 17:26 , Rui Barradas wrote:
>  > Hello,
>  >
>  > The following works with me.
>  >
>  >
>  > library(coronavirus)
>  > library(dplyr)
>  >
>  > data(coronavirus, package = "coronavirus")
>  > #update_dataset(silence = FALSE)
>  >
>  > coronavirus %>%
>  >??? select(country, date, type, cases) %>%
>  >??? filter(
>  >????? country == 'Namibia',
>  >????? date == '2021-10-23',
>  >????? cases == 357
>  >??? )
>  >
>  >
>  >
>  > Can you post the pipe code you are running?
>  >
>  > Hope this helps,
>  >
>  > Rui Barradas
>  >
>  > ?s 12:25 de 25/10/21, Dr Eberhard W Lisse escreveu:
>  >> Hi,
>  >>
>  >> I have data from JHU via the 'coronavirus' package which has a value 
> for
>  >> the confirmed cases for 2021-10-23 which differs drastically (357) from
>  >> what is reported in country (23).
>  >>
>  >>????? # A tibble: 962 ? 4
>  >>??????? country date?????? type????? cases
>  >>??????? <chr>?? <date>???? <chr>???? <int>
>  >>????? 1 Namibia 2021-10-24 confirmed??? 23
>  >>????? 2 Namibia 2021-10-24 death???????? 4
>  >>????? 3 Namibia 2021-10-23 confirmed?? 357
>  >>????? 4 Namibia 2021-10-23 death???????? 1
>  >>????? 5 Namibia 2021-10-22 confirmed??? 30
>  >>????? 6 Namibia 2021-10-22 death???????? 1
>  >>????? # ? with 956 more rows
>  >>
>  >> I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA
>  >> using something like
>  >>
>  >>????? country == 'Namibia' & date == '2021-10-23' & cases == 357
>  >>
>  >> so that if or when the data-set is corrected I don't have to change the
>  >> code (immediately), even after some googling.
>  >>
>  >> I can do
>  >>
>  >>????? cases == 357
>  >>
>  >> only, but that could find other cases as well, which is obviously not
>  >> the thing to do
>  >>
>  >> Any suggestions?
>  >>
>  >> greetings, el
>  >>
>  >> ______________________________________________
>  >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  >> https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide
>  >> http://www.R-project.org/posting-guide.html
>  >> and provide commented, minimal, self-contained, reproducible code.
>  >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From no@p@m @end|ng |rom ||@@e@NA  Mon Oct 25 19:26:03 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Mon, 25 Oct 2021 19:26:03 +0200
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <43faf7c8-e011-2e4e-880a-ea56ed1ebedb@sapo.pt>
References: <sl647p$17td$1@ciao.gmane.io>
 <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt> <sl6jlj$14mf$1@ciao.gmane.io>
 <43faf7c8-e011-2e4e-880a-ea56ed1ebedb@sapo.pt>
Message-ID: <sl6pbg$asu$1@ciao.gmane.io>


Thank you very much,

'which' does the trick :-)-O

greetings, el

On 2021-10-25 19:06 , Rui Barradas wrote:
> Hello,
> 
> Here is a pipe to replace based on the composite condition.
> It uses ?base::replace with an integer index vector.
> 
[...]
> library(dplyr)
> 
> data(coronavirus, package = "coronavirus")
> 
> coronavirus %>%
[...]
>  ? mutate(cases = replace(cases,
>  ???????????????????????? which(country == 'Namibia' &
>  ???????????????????????????????? date == '2021-10-23' &
>  ???????????????????????????????? cases == 357), NA)
>  ? )
[...]
> 
> Hope this helps,
> 
> Rui Barradas
[...]


From S@ndhy@pr@k@@hyj97 @end|ng |rom out|ook@com  Sat Oct 23 13:50:43 2021
From: S@ndhy@pr@k@@hyj97 @end|ng |rom out|ook@com (Sandhya Prakash)
Date: Sat, 23 Oct 2021 11:50:43 +0000
Subject: [R] 
 Error: the leading minor of order 6 is not positive definite
Message-ID: <HKAPR01MB373096AF40371243EF9A3BB2DB819@HKAPR01MB3730.apcprd01.prod.exchangelabs.com>

Hi I'm too running a canonical correlation code but I'm getting my error like this can you please help me

Get Outlook for Android<https://aka.ms/AAb9ysg>

	[[alternative HTML version deleted]]


From prmonk @end|ng |rom gm@||@com  Mon Oct 25 16:09:24 2021
From: prmonk @end|ng |rom gm@||@com (Philip Monk)
Date: Mon, 25 Oct 2021 15:09:24 +0100
Subject: [R] Dates as headers causing confusion but needed to convert to
 Julian days for ANOVA
Message-ID: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>

Hello,

First post - apologies if I get anything wrong - either in describing the
question (I've only been using R for a week) or etiquette.

I have CSV files of Land Surface Temperature (LST) data derived from
Landsat 8 data and exported from Google Earth Engine.  I am investigating
whether the construction of utility-scale solar power plants affects the
local climate.

I need to tidy the CSV files so that I can use Two-way ANOVA w/repeated
measures but am having problems due to column headers (necessarily, I
think) being dates.

Each CSV currently has the following columns:

Buffer
Values 100-2000 in 100 increments.  Buffers are 100m wide and extend
outwards from each site boundary.

24 columns of monthly data.
Column headers are in date format (currently dd/mm/yyyy in Excel) and
relate to the date on which the original Landsat 8 image from which the LST
data are derived was captured.
I need these dates to calculate the 'Julian day' (1-365.25) for each month,
and also to extract the Year.

Time
Currently 1 = pre-construction and 2 = post-construction.

The data frame created when importing one of these CSV's into R looks like
this:

'data.frame':	20 obs. of  14 variables:
 $ Buffer     : int  100 200 300 400 500 600 700 800 900 1000 ...
 $ X15.01.2010: num  6.09 5.27 4.45 3.39 2.9 ...
 $ X16.02.2010: num  6.41 5.99 5.61 4.78 4.31 ...
 $ X20.03.2010: num  8.93 7.38 6.12 5.61 5.61 ...
 $ X24.04.2011: num  6.28 5.81 5.15 4.54 4.32 ...
 $ X07.05.2010: num  6.13 5.54 5.35 4.82 4.52 ...
 $ X08.06.2010: num  7.71 7.4 6.82 6.14 5.82 ...
 $ X13.07.2011: num  4.07 2.93 2.69 2.47 2.53 ...
 $ X11.08.2010: num  5.96 5.68 5.38 4.96 4.57 ...
 $ X12.09.2010: num  5.76 5.15 4.54 3.87 3.46 ...
 $ X17.10.2011: num  3.16 2.51 2.51 2.06 2.01 ...
 $ X15.11.2010: num  4.72 3.77 3.24 2.74 2.49 ...
 $ X01.12.2010: num  4.26 3.516 2.154 1.056 0.315 ...
 $ Time       : int  1 1 1 1 1 1 1 1 1 1 ...


Importing a CSV into R that has a date as a column header (in whatever
format) causes problems!  R adds the 'X', and converts the separator.

I was using 'gather' and 'pivot_longer' (see below) but the date issue has
wrecked that approach.  I've tried reformating the date, trying to remove
the X, and going away to learn more about data frames, dplyr, and readr.
I'm not making any progress, though, and I'm just getting more confused.

Helped requested
~~~~~~~~~~~~~~

How should I proceed to tidy the data such that I can:

*) extract the year and Julian day for each date, then convert the date to
the name of the month?
*) create a tidy table with columns for Buffer, Month, Year, Julian day,
LST (the values), and Time (1 = pre-construction, 2 = post-construction of
a solar farm).

Prior to deciding I needed to calculate the Julian day for use in ANOVA I
was doing this (with month names rather than dates - please remember I'm a
newbie!):

data <- read.csv(...
attach(data)
# data_long <- data %>% pivot_longer(!Buffer, names_to = "month", values_to
= "LST")
# data_long <- data %>% pivot_longer(!Buffer, names_to = c("month",
"Time"), names_sep = 13, values_to = "LST")
data_long <- gather(data, Month, LST, January:December, factor_key=TRUE)
data_long$Time <- as.factor(data$Time)
str(data_long)

'pivot_longer' didn't work, but 'gather' did to create the long data needed
for ANOVA.

For example:

'data.frame': 480 obs. of  4 variables:
 $ Buffer: int  100 200 300 400 500 600 700 800 900 1000 ...
 $ Time  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
 $ Month : Factor w/ 12 levels "January","February",..: 1 1 1 1 1 1 1 1 1 1
...
 $ LST   : num  NA 0.803 0.803 1.044 0.475 ...

Suggestions/hints/solutions would be most welcome.  :)

Thanks for your time,

Philip

Part-time PhD Student (Environmental Science)
Lancaster University, UK.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Oct 25 23:02:58 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 25 Oct 2021 14:02:58 -0700
Subject: [R] Dates as headers causing confusion but needed to convert to
 Julian days for ANOVA
In-Reply-To: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
References: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
Message-ID: <CAGxFJbRNanu-AtTYdttqjU86P4YKjTioC-MZ+eYQXW4x2XtFMA@mail.gmail.com>

Well, both newbies and oldies need to read and follow the Help files
carefully. In this case, note the "check.names" argument of ?read.csv.  You
need to set it to FALSE in your (omitted) read.csv call, because your
strings are not syntactically valid names (follow the "make.names" link to
learn what are valid names). Here is a little example:

> z1 <- read.csv('mydat')
> z2 <- read.csv('mydat', check.names = FALSE)
> z1
  X01.12.2019 X02.15.2020
1           1           5
2           2           6
3           3           7

> z2
  01/12/2019 02/15/2020
1          1          5
2          2          6
3          3          7

However, because your column names are *not* syntactically valid, you'll
have to change them anyway to avoid further infelicities in accessing and
manipulating the data(e.g. see ?names). How you choose to do this is up to
you.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Oct 25, 2021 at 1:26 PM Philip Monk <prmonk at gmail.com> wrote:

> Hello,
>
> First post - apologies if I get anything wrong - either in describing the
> question (I've only been using R for a week) or etiquette.
>
> I have CSV files of Land Surface Temperature (LST) data derived from
> Landsat 8 data and exported from Google Earth Engine.  I am investigating
> whether the construction of utility-scale solar power plants affects the
> local climate.
>
> I need to tidy the CSV files so that I can use Two-way ANOVA w/repeated
> measures but am having problems due to column headers (necessarily, I
> think) being dates.
>
> Each CSV currently has the following columns:
>
> Buffer
> Values 100-2000 in 100 increments.  Buffers are 100m wide and extend
> outwards from each site boundary.
>
> 24 columns of monthly data.
> Column headers are in date format (currently dd/mm/yyyy in Excel) and
> relate to the date on which the original Landsat 8 image from which the LST
> data are derived was captured.
> I need these dates to calculate the 'Julian day' (1-365.25) for each month,
> and also to extract the Year.
>
> Time
> Currently 1 = pre-construction and 2 = post-construction.
>
> The data frame created when importing one of these CSV's into R looks like
> this:
>
> 'data.frame':   20 obs. of  14 variables:
>  $ Buffer     : int  100 200 300 400 500 600 700 800 900 1000 ...
>  $ X15.01.2010: num  6.09 5.27 4.45 3.39 2.9 ...
>  $ X16.02.2010: num  6.41 5.99 5.61 4.78 4.31 ...
>  $ X20.03.2010: num  8.93 7.38 6.12 5.61 5.61 ...
>  $ X24.04.2011: num  6.28 5.81 5.15 4.54 4.32 ...
>  $ X07.05.2010: num  6.13 5.54 5.35 4.82 4.52 ...
>  $ X08.06.2010: num  7.71 7.4 6.82 6.14 5.82 ...
>  $ X13.07.2011: num  4.07 2.93 2.69 2.47 2.53 ...
>  $ X11.08.2010: num  5.96 5.68 5.38 4.96 4.57 ...
>  $ X12.09.2010: num  5.76 5.15 4.54 3.87 3.46 ...
>  $ X17.10.2011: num  3.16 2.51 2.51 2.06 2.01 ...
>  $ X15.11.2010: num  4.72 3.77 3.24 2.74 2.49 ...
>  $ X01.12.2010: num  4.26 3.516 2.154 1.056 0.315 ...
>  $ Time       : int  1 1 1 1 1 1 1 1 1 1 ...
>
>
> Importing a CSV into R that has a date as a column header (in whatever
> format) causes problems!  R adds the 'X', and converts the separator.
>
> I was using 'gather' and 'pivot_longer' (see below) but the date issue has
> wrecked that approach.  I've tried reformating the date, trying to remove
> the X, and going away to learn more about data frames, dplyr, and readr.
> I'm not making any progress, though, and I'm just getting more confused.
>
> Helped requested
> ~~~~~~~~~~~~~~
>
> How should I proceed to tidy the data such that I can:
>
> *) extract the year and Julian day for each date, then convert the date to
> the name of the month?
> *) create a tidy table with columns for Buffer, Month, Year, Julian day,
> LST (the values), and Time (1 = pre-construction, 2 = post-construction of
> a solar farm).
>
> Prior to deciding I needed to calculate the Julian day for use in ANOVA I
> was doing this (with month names rather than dates - please remember I'm a
> newbie!):
>
> data <- read.csv(...
> attach(data)
> # data_long <- data %>% pivot_longer(!Buffer, names_to = "month", values_to
> = "LST")
> # data_long <- data %>% pivot_longer(!Buffer, names_to = c("month",
> "Time"), names_sep = 13, values_to = "LST")
> data_long <- gather(data, Month, LST, January:December, factor_key=TRUE)
> data_long$Time <- as.factor(data$Time)
> str(data_long)
>
> 'pivot_longer' didn't work, but 'gather' did to create the long data needed
> for ANOVA.
>
> For example:
>
> 'data.frame': 480 obs. of  4 variables:
>  $ Buffer: int  100 200 300 400 500 600 700 800 900 1000 ...
>  $ Time  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
>  $ Month : Factor w/ 12 levels "January","February",..: 1 1 1 1 1 1 1 1 1 1
> ...
>  $ LST   : num  NA 0.803 0.803 1.044 0.475 ...
>
> Suggestions/hints/solutions would be most welcome.  :)
>
> Thanks for your time,
>
> Philip
>
> Part-time PhD Student (Environmental Science)
> Lancaster University, UK.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Oct 25 23:14:25 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 25 Oct 2021 17:14:25 -0400
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <sl6jlj$14mf$1@ciao.gmane.io>
References: <sl647p$17td$1@ciao.gmane.io>
 <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt> <sl6jlj$14mf$1@ciao.gmane.io>
Message-ID: <005501d7c9e5$4a13bbe0$de3b33a0$@verizon.net>

I wonder why it is not as simple as:

Call mutate on the data and have a condition that looks like:

data %>% mutate(cases = ifelse(multiple_cond, NA, cases) -> output

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Eberhard W Lisse
Sent: Monday, October 25, 2021 11:49 AM
To: r-help at r-project.org
Subject: Re: [R] cleanup/replacing a value on condition of another value

Rui,

that works for me too, but is not what I need to do.

I want to make the 'cases' value for this particular country AND this particular date AND this particular type AND this particular value (ie ALL conditions must be fulfilled) become NA so that the tibble would change from

	[...]
	2 Namibia 2021-10-24 death         4
	3 Namibia 2021-10-23 confirmed   357
	4 Namibia 2021-10-23 death         1
	[...]

to

	[...]
	2 Namibia 2021-10-24 death         4
	3 Namibia 2021-10-23 confirmed   357
	4 Namibia 2021-10-23 death         1
	[...]

as long as they don't fix the dataset, and if/when they do it goes to the expected 23 value :-)-O

greetings, el

On 2021-10-25 17:26 , Rui Barradas wrote:
 > Hello,
 >
 > The following works with me.
 >
 >
 > library(coronavirus)
 > library(dplyr)
 >
 > data(coronavirus, package = "coronavirus")  > #update_dataset(silence = FALSE)  >  > coronavirus %>%
 >    select(country, date, type, cases) %>%
 >    filter(
 >      country == 'Namibia',
 >      date == '2021-10-23',
 >      cases == 357
 >    )
 >
 >
 >
 > Can you post the pipe code you are running?
 >
 > Hope this helps,
 >
 > Rui Barradas
 >
 > ?s 12:25 de 25/10/21, Dr Eberhard W Lisse escreveu:
 >> Hi,
 >>
 >> I have data from JHU via the 'coronavirus' package which has a value for  >> the confirmed cases for 2021-10-23 which differs drastically (357) from  >> what is reported in country (23).
 >>
 >>      # A tibble: 962 ? 4
 >>        country date       type      cases
 >>        <chr>   <date>     <chr>     <int>
 >>      1 Namibia 2021-10-24 confirmed    23
 >>      2 Namibia 2021-10-24 death         4
 >>      3 Namibia 2021-10-23 confirmed   357
 >>      4 Namibia 2021-10-23 death         1
 >>      5 Namibia 2021-10-22 confirmed    30
 >>      6 Namibia 2021-10-22 death         1
 >>      # ? with 956 more rows
 >>
 >> I am using a '%>%' pipeline and am struggling to mutate 'cases' to NA  >> using something like  >>
 >>      country == 'Namibia' & date == '2021-10-23' & cases == 357
 >>
 >> so that if or when the data-set is corrected I don't have to change the  >> code (immediately), even after some googling.
 >>
 >> I can do
 >>
 >>      cases == 357
 >>
 >> only, but that could find other cases as well, which is obviously not  >> the thing to do  >>  >> Any suggestions?
 >>
 >> greetings, el
 >>
 >> ______________________________________________
 >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal, self-contained, reproducible code.
 >

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Oct 25 23:22:43 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 25 Oct 2021 14:22:43 -0700
Subject: [R] Dates as headers causing confusion but needed to convert to
 Julian days for ANOVA
In-Reply-To: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
References: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
Message-ID: <6DDFF3C0-33A4-4BA8-BB3A-B25EFBDB021F@dcn.davis.ca.us>

You did not say which function you used to import the csv file, but it looks like you probably used read.csv without setting the check.names argument to FALSE.

Whether you change that out not, once you have reshaped the data, you can use a format specifier with as.Date to extract a date. (See ?strptime for format string specifiers.)

On October 25, 2021 7:09:24 AM PDT, Philip Monk <prmonk at gmail.com> wrote:
>Hello,
>
>First post - apologies if I get anything wrong - either in describing the
>question (I've only been using R for a week) or etiquette.
>
>I have CSV files of Land Surface Temperature (LST) data derived from
>Landsat 8 data and exported from Google Earth Engine.  I am investigating
>whether the construction of utility-scale solar power plants affects the
>local climate.
>
>I need to tidy the CSV files so that I can use Two-way ANOVA w/repeated
>measures but am having problems due to column headers (necessarily, I
>think) being dates.
>
>Each CSV currently has the following columns:
>
>Buffer
>Values 100-2000 in 100 increments.  Buffers are 100m wide and extend
>outwards from each site boundary.
>
>24 columns of monthly data.
>Column headers are in date format (currently dd/mm/yyyy in Excel) and
>relate to the date on which the original Landsat 8 image from which the LST
>data are derived was captured.
>I need these dates to calculate the 'Julian day' (1-365.25) for each month,
>and also to extract the Year.
>
>Time
>Currently 1 = pre-construction and 2 = post-construction.
>
>The data frame created when importing one of these CSV's into R looks like
>this:
>
>'data.frame':	20 obs. of  14 variables:
> $ Buffer     : int  100 200 300 400 500 600 700 800 900 1000 ...
> $ X15.01.2010: num  6.09 5.27 4.45 3.39 2.9 ...
> $ X16.02.2010: num  6.41 5.99 5.61 4.78 4.31 ...
> $ X20.03.2010: num  8.93 7.38 6.12 5.61 5.61 ...
> $ X24.04.2011: num  6.28 5.81 5.15 4.54 4.32 ...
> $ X07.05.2010: num  6.13 5.54 5.35 4.82 4.52 ...
> $ X08.06.2010: num  7.71 7.4 6.82 6.14 5.82 ...
> $ X13.07.2011: num  4.07 2.93 2.69 2.47 2.53 ...
> $ X11.08.2010: num  5.96 5.68 5.38 4.96 4.57 ...
> $ X12.09.2010: num  5.76 5.15 4.54 3.87 3.46 ...
> $ X17.10.2011: num  3.16 2.51 2.51 2.06 2.01 ...
> $ X15.11.2010: num  4.72 3.77 3.24 2.74 2.49 ...
> $ X01.12.2010: num  4.26 3.516 2.154 1.056 0.315 ...
> $ Time       : int  1 1 1 1 1 1 1 1 1 1 ...
>
>
>Importing a CSV into R that has a date as a column header (in whatever
>format) causes problems!  R adds the 'X', and converts the separator.
>
>I was using 'gather' and 'pivot_longer' (see below) but the date issue has
>wrecked that approach.  I've tried reformating the date, trying to remove
>the X, and going away to learn more about data frames, dplyr, and readr.
>I'm not making any progress, though, and I'm just getting more confused.
>
>Helped requested
>~~~~~~~~~~~~~~
>
>How should I proceed to tidy the data such that I can:
>
>*) extract the year and Julian day for each date, then convert the date to
>the name of the month?
>*) create a tidy table with columns for Buffer, Month, Year, Julian day,
>LST (the values), and Time (1 = pre-construction, 2 = post-construction of
>a solar farm).
>
>Prior to deciding I needed to calculate the Julian day for use in ANOVA I
>was doing this (with month names rather than dates - please remember I'm a
>newbie!):
>
>data <- read.csv(...
>attach(data)
># data_long <- data %>% pivot_longer(!Buffer, names_to = "month", values_to
>= "LST")
># data_long <- data %>% pivot_longer(!Buffer, names_to = c("month",
>"Time"), names_sep = 13, values_to = "LST")
>data_long <- gather(data, Month, LST, January:December, factor_key=TRUE)
>data_long$Time <- as.factor(data$Time)
>str(data_long)
>
>'pivot_longer' didn't work, but 'gather' did to create the long data needed
>for ANOVA.
>
>For example:
>
>'data.frame': 480 obs. of  4 variables:
> $ Buffer: int  100 200 300 400 500 600 700 800 900 1000 ...
> $ Time  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
> $ Month : Factor w/ 12 levels "January","February",..: 1 1 1 1 1 1 1 1 1 1
>...
> $ LST   : num  NA 0.803 0.803 1.044 0.475 ...
>
>Suggestions/hints/solutions would be most welcome.  :)
>
>Thanks for your time,
>
>Philip
>
>Part-time PhD Student (Environmental Science)
>Lancaster University, UK.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From djnord|und @end|ng |rom gm@||@com  Tue Oct 26 00:15:03 2021
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Mon, 25 Oct 2021 15:15:03 -0700
Subject: [R] Dates as headers causing confusion but needed to convert to
 Julian days for ANOVA
In-Reply-To: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
References: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
Message-ID: <76a3c480-b578-bde8-0bac-1ed040005589@gmail.com>

On 10/25/2021 7:09 AM, Philip Monk wrote:
> Hello,
>
> First post - apologies if I get anything wrong - either in describing the
> question (I've only been using R for a week) or etiquette.
>
> I have CSV files of Land Surface Temperature (LST) data derived from
> Landsat 8 data and exported from Google Earth Engine.  I am investigating
> whether the construction of utility-scale solar power plants affects the
> local climate.
>
> I need to tidy the CSV files so that I can use Two-way ANOVA w/repeated
> measures but am having problems due to column headers (necessarily, I
> think) being dates.
>
> Each CSV currently has the following columns:
>
> Buffer
> Values 100-2000 in 100 increments.  Buffers are 100m wide and extend
> outwards from each site boundary.
>
> 24 columns of monthly data.
> Column headers are in date format (currently dd/mm/yyyy in Excel) and
> relate to the date on which the original Landsat 8 image from which the LST
> data are derived was captured.
> I need these dates to calculate the 'Julian day' (1-365.25) for each month,
> and also to extract the Year.
>
> Time
> Currently 1 = pre-construction and 2 = post-construction.
>
> The data frame created when importing one of these CSV's into R looks like
> this:
>
> 'data.frame':	20 obs. of  14 variables:
>   $ Buffer     : int  100 200 300 400 500 600 700 800 900 1000 ...
>   $ X15.01.2010: num  6.09 5.27 4.45 3.39 2.9 ...
>   $ X16.02.2010: num  6.41 5.99 5.61 4.78 4.31 ...
>   $ X20.03.2010: num  8.93 7.38 6.12 5.61 5.61 ...
>   $ X24.04.2011: num  6.28 5.81 5.15 4.54 4.32 ...
>   $ X07.05.2010: num  6.13 5.54 5.35 4.82 4.52 ...
>   $ X08.06.2010: num  7.71 7.4 6.82 6.14 5.82 ...
>   $ X13.07.2011: num  4.07 2.93 2.69 2.47 2.53 ...
>   $ X11.08.2010: num  5.96 5.68 5.38 4.96 4.57 ...
>   $ X12.09.2010: num  5.76 5.15 4.54 3.87 3.46 ...
>   $ X17.10.2011: num  3.16 2.51 2.51 2.06 2.01 ...
>   $ X15.11.2010: num  4.72 3.77 3.24 2.74 2.49 ...
>   $ X01.12.2010: num  4.26 3.516 2.154 1.056 0.315 ...
>   $ Time       : int  1 1 1 1 1 1 1 1 1 1 ...
>
>
> Importing a CSV into R that has a date as a column header (in whatever
> format) causes problems!  R adds the 'X', and converts the separator.
>
> I was using 'gather' and 'pivot_longer' (see below) but the date issue has
> wrecked that approach.  I've tried reformating the date, trying to remove
> the X, and going away to learn more about data frames, dplyr, and readr.
> I'm not making any progress, though, and I'm just getting more confused.
>
> Helped requested
> ~~~~~~~~~~~~~~
>
> How should I proceed to tidy the data such that I can:
>
> *) extract the year and Julian day for each date, then convert the date to
> the name of the month?
> *) create a tidy table with columns for Buffer, Month, Year, Julian day,
> LST (the values), and Time (1 = pre-construction, 2 = post-construction of
> a solar farm).
>
> Prior to deciding I needed to calculate the Julian day for use in ANOVA I
> was doing this (with month names rather than dates - please remember I'm a
> newbie!):
>
> data <- read.csv(...
> attach(data)
> # data_long <- data %>% pivot_longer(!Buffer, names_to = "month", values_to
> = "LST")
> # data_long <- data %>% pivot_longer(!Buffer, names_to = c("month",
> "Time"), names_sep = 13, values_to = "LST")
> data_long <- gather(data, Month, LST, January:December, factor_key=TRUE)
> data_long$Time <- as.factor(data$Time)
> str(data_long)
>
> 'pivot_longer' didn't work, but 'gather' did to create the long data needed
> for ANOVA.
>
> For example:
>
> 'data.frame': 480 obs. of  4 variables:
>   $ Buffer: int  100 200 300 400 500 600 700 800 900 1000 ...
>   $ Time  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
>   $ Month : Factor w/ 12 levels "January","February",..: 1 1 1 1 1 1 1 1 1 1
> ...
>   $ LST   : num  NA 0.803 0.803 1.044 0.475 ...
>
> Suggestions/hints/solutions would be most welcome.  :)
>
> Thanks for your time,
>
> Philip
>
> Part-time PhD Student (Environmental Science)
> Lancaster University, UK.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Using the data that you read in, you can use "pivot_longer", and various 
"date" functions to get what you want. For example

# pivot your data
data_long <- data %>% pivot_longer(starts_with("X"), names_to = 
"chr_date", values_to = "LST")

# now you can use various data functions to get your month, day, and year
# for example
data_long$month <- month(as.Date(data_long$chr_date,"X%d.%m.%Y"))

You may want to read up on the various date functions built in to R such 
as as.POSIXct, as.POSIXlt, as.Date, and maybe look at the contributed 
package, lubridate.

Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Oct 26 01:34:51 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 25 Oct 2021 16:34:51 -0700
Subject: [R] Dates as headers causing confusion but needed to convert to
 Julian days for ANOVA
In-Reply-To: <CAGxFJbRNanu-AtTYdttqjU86P4YKjTioC-MZ+eYQXW4x2XtFMA@mail.gmail.com>
References: <CAMVDa_5H3TN-+sn==zoV9E_StWk2RJfXd8AAVCDvhe4FsmSjcA@mail.gmail.com>
 <CAGxFJbRNanu-AtTYdttqjU86P4YKjTioC-MZ+eYQXW4x2XtFMA@mail.gmail.com>
Message-ID: <1EF51985-F85C-4249-A03F-76025139D6DE@dcn.davis.ca.us>

I use check.names=FALSE more often than not, and I almost never end up changing them "anyway". Back-ticks as quotes are very effective at allowing unusual column names to be used in R code. (The only exception I have to this is when programatically building formulas the eval step gets quite convoluted.)

And in this case he will be reshaping almost immediately so these weird column names will become entries in an identifier column.

On October 25, 2021 2:02:58 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Well, both newbies and oldies need to read and follow the Help files
>carefully. In this case, note the "check.names" argument of ?read.csv.  You
>need to set it to FALSE in your (omitted) read.csv call, because your
>strings are not syntactically valid names (follow the "make.names" link to
>learn what are valid names). Here is a little example:
>
>> z1 <- read.csv('mydat')
>> z2 <- read.csv('mydat', check.names = FALSE)
>> z1
>  X01.12.2019 X02.15.2020
>1           1           5
>2           2           6
>3           3           7
>
>> z2
>  01/12/2019 02/15/2020
>1          1          5
>2          2          6
>3          3          7
>
>However, because your column names are *not* syntactically valid, you'll
>have to change them anyway to avoid further infelicities in accessing and
>manipulating the data(e.g. see ?names). How you choose to do this is up to
>you.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Mon, Oct 25, 2021 at 1:26 PM Philip Monk <prmonk at gmail.com> wrote:
>
>> Hello,
>>
>> First post - apologies if I get anything wrong - either in describing the
>> question (I've only been using R for a week) or etiquette.
>>
>> I have CSV files of Land Surface Temperature (LST) data derived from
>> Landsat 8 data and exported from Google Earth Engine.  I am investigating
>> whether the construction of utility-scale solar power plants affects the
>> local climate.
>>
>> I need to tidy the CSV files so that I can use Two-way ANOVA w/repeated
>> measures but am having problems due to column headers (necessarily, I
>> think) being dates.
>>
>> Each CSV currently has the following columns:
>>
>> Buffer
>> Values 100-2000 in 100 increments.  Buffers are 100m wide and extend
>> outwards from each site boundary.
>>
>> 24 columns of monthly data.
>> Column headers are in date format (currently dd/mm/yyyy in Excel) and
>> relate to the date on which the original Landsat 8 image from which the LST
>> data are derived was captured.
>> I need these dates to calculate the 'Julian day' (1-365.25) for each month,
>> and also to extract the Year.
>>
>> Time
>> Currently 1 = pre-construction and 2 = post-construction.
>>
>> The data frame created when importing one of these CSV's into R looks like
>> this:
>>
>> 'data.frame':   20 obs. of  14 variables:
>>  $ Buffer     : int  100 200 300 400 500 600 700 800 900 1000 ...
>>  $ X15.01.2010: num  6.09 5.27 4.45 3.39 2.9 ...
>>  $ X16.02.2010: num  6.41 5.99 5.61 4.78 4.31 ...
>>  $ X20.03.2010: num  8.93 7.38 6.12 5.61 5.61 ...
>>  $ X24.04.2011: num  6.28 5.81 5.15 4.54 4.32 ...
>>  $ X07.05.2010: num  6.13 5.54 5.35 4.82 4.52 ...
>>  $ X08.06.2010: num  7.71 7.4 6.82 6.14 5.82 ...
>>  $ X13.07.2011: num  4.07 2.93 2.69 2.47 2.53 ...
>>  $ X11.08.2010: num  5.96 5.68 5.38 4.96 4.57 ...
>>  $ X12.09.2010: num  5.76 5.15 4.54 3.87 3.46 ...
>>  $ X17.10.2011: num  3.16 2.51 2.51 2.06 2.01 ...
>>  $ X15.11.2010: num  4.72 3.77 3.24 2.74 2.49 ...
>>  $ X01.12.2010: num  4.26 3.516 2.154 1.056 0.315 ...
>>  $ Time       : int  1 1 1 1 1 1 1 1 1 1 ...
>>
>>
>> Importing a CSV into R that has a date as a column header (in whatever
>> format) causes problems!  R adds the 'X', and converts the separator.
>>
>> I was using 'gather' and 'pivot_longer' (see below) but the date issue has
>> wrecked that approach.  I've tried reformating the date, trying to remove
>> the X, and going away to learn more about data frames, dplyr, and readr.
>> I'm not making any progress, though, and I'm just getting more confused.
>>
>> Helped requested
>> ~~~~~~~~~~~~~~
>>
>> How should I proceed to tidy the data such that I can:
>>
>> *) extract the year and Julian day for each date, then convert the date to
>> the name of the month?
>> *) create a tidy table with columns for Buffer, Month, Year, Julian day,
>> LST (the values), and Time (1 = pre-construction, 2 = post-construction of
>> a solar farm).
>>
>> Prior to deciding I needed to calculate the Julian day for use in ANOVA I
>> was doing this (with month names rather than dates - please remember I'm a
>> newbie!):
>>
>> data <- read.csv(...
>> attach(data)
>> # data_long <- data %>% pivot_longer(!Buffer, names_to = "month", values_to
>> = "LST")
>> # data_long <- data %>% pivot_longer(!Buffer, names_to = c("month",
>> "Time"), names_sep = 13, values_to = "LST")
>> data_long <- gather(data, Month, LST, January:December, factor_key=TRUE)
>> data_long$Time <- as.factor(data$Time)
>> str(data_long)
>>
>> 'pivot_longer' didn't work, but 'gather' did to create the long data needed
>> for ANOVA.
>>
>> For example:
>>
>> 'data.frame': 480 obs. of  4 variables:
>>  $ Buffer: int  100 200 300 400 500 600 700 800 900 1000 ...
>>  $ Time  : Factor w/ 2 levels "1","2": 1 1 1 1 1 1 1 1 1 1 ...
>>  $ Month : Factor w/ 12 levels "January","February",..: 1 1 1 1 1 1 1 1 1 1
>> ...
>>  $ LST   : num  NA 0.803 0.803 1.044 0.475 ...
>>
>> Suggestions/hints/solutions would be most welcome.  :)
>>
>> Thanks for your time,
>>
>> Philip
>>
>> Part-time PhD Student (Environmental Science)
>> Lancaster University, UK.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From phii m@iii@g oii phiiipsmith@c@  Tue Oct 26 03:08:21 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Mon, 25 Oct 2021 21:08:21 -0400
Subject: [R] Putting colours in ggplot facets
Message-ID: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>

I am using ggplot2 and I want to use different colours for some facets. 
Here is a reprex:

library(tidyverse)
date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
   2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
   3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
geo <- as.factor(c("Canada","Canada","Nova Scotia",
   "Nova Scotia","Manitoba","Manitoba","Canada",
   "Canada","Nova Scotia","Nova Scotia","Manitoba",
   "Manitoba","Canada","Canada","Nova Scotia",
   "Nova Scotia","Manitoba","Manitoba"))
est <- as.factor(c("Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income","Wages and salaries",
   "Gross mixed income"))
df <- data.frame(date,vari,geo,est)
ct <- unique(df[,c('est','geo')])
colr=c("blue","forestgreen","red","lightblue",
   "brown","gold")
p0 <- ggplot(df,aes(x=date,y=vari))+
   geom_rect(data=ct,aes(fill=geo),
     xmin=-Inf,xmax=Inf,
     ymin=-Inf,ymax=Inf,alpha = 0.3)+
   scale_fill_manual(values=colr)+
   geom_bar(stat="identity")+
   facet_grid(est~geo)
p0

I have tried several approaches and Googled for help, but to no avail. I 
am getting the error message: Error: Aesthetics must be either length 1 
or the same as the data (6): x and y

Thanks for some help.

Philip


From btupper @end|ng |rom b|ge|ow@org  Tue Oct 26 04:37:41 2021
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Mon, 25 Oct 2021 22:37:41 -0400
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
Message-ID: <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>

Hi,

I don't quite follow what you want to achieve - colored backgrounds
for each panel?  You could RSeek.org for some ideas on how to fish the
panels grobs out... https://rseek.org/?q=ggplot+facet+backgound+color

https://rseek.org/?q=ggplot+facet+backgound+color


I can get sort of close by skipping the use of table ct and instead
filling the panels using your df table. But it doesn't color each
panel instead it colors each geo group.

ggplot(df,aes(x=date,y=vari))+
  geom_rect(aes(fill=geo),
            xmin=-Inf,xmax=Inf,
            ymin=-Inf,ymax=Inf,alpha = 0.3)+
  scale_fill_manual(values=colr)+
  geom_bar(stat="identity")+
  facet_grid(est~geo)


You could add another column, composed of geo and est, and fill by that...

df <- dplyr::tibble(date,vari,geo,est) %>%
  dplyr::mutate(colr = paste(geo, est))

ggplot(df,aes(x=date,y=vari))+
  theme(panel.background = element_rect(fill = colr)) +
  scale_fill_manual(values=colr)+
  geom_bar(stat="identity")+
  facet_grid(est~geo)

But it makes for a long set of labels on the scale bar thingy.

I hope that helps.

Ben


On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
>
> I am using ggplot2 and I want to use different colours for some facets.
> Here is a reprex:
>
> library(tidyverse)
> date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
>    2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
> vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
>    3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
> geo <- as.factor(c("Canada","Canada","Nova Scotia",
>    "Nova Scotia","Manitoba","Manitoba","Canada",
>    "Canada","Nova Scotia","Nova Scotia","Manitoba",
>    "Manitoba","Canada","Canada","Nova Scotia",
>    "Nova Scotia","Manitoba","Manitoba"))
> est <- as.factor(c("Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income","Wages and salaries",
>    "Gross mixed income"))
> df <- data.frame(date,vari,geo,est)
> ct <- unique(df[,c('est','geo')])
> colr=c("blue","forestgreen","red","lightblue",
>    "brown","gold")
> p0 <- ggplot(df,aes(x=date,y=vari))+
>    geom_rect(data=ct,aes(fill=geo),
>      xmin=-Inf,xmax=Inf,
>      ymin=-Inf,ymax=Inf,alpha = 0.3)+
>    scale_fill_manual(values=colr)+
>    geom_bar(stat="identity")+
>    facet_grid(est~geo)
> p0
>
> I have tried several approaches and Googled for help, but to no avail. I
> am getting the error message: Error: Aesthetics must be either length 1
> or the same as the data (6): x and y
>
> Thanks for some help.
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper (he/him)
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From btupper @end|ng |rom b|ge|ow@org  Tue Oct 26 04:40:20 2021
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Mon, 25 Oct 2021 22:40:20 -0400
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
 <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
Message-ID: <CALrbzg2ByTGbjt354VA0BAA9FfA_9Y4yZzTPxOLiy3jksNZang@mail.gmail.com>

Whoopsie.  Misfired cut and paste - all 13 fingers are thumbs today.

That second one should be...

df <- dplyr::tibble(date,vari,geo,est) %>%
  dplyr::mutate(colr = paste(geo, est))

ggplot(df,aes(x=date,y=vari))+
  geom_rect(aes(fill=colr),
            xmin=-Inf,xmax=Inf,
            ymin=-Inf,ymax=Inf,alpha = 0.3)+
  scale_fill_manual(values=colr)+
  geom_bar(stat="identity")+
  facet_grid(est~geo)

On Mon, Oct 25, 2021 at 10:37 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi,
>
> I don't quite follow what you want to achieve - colored backgrounds
> for each panel?  You could RSeek.org for some ideas on how to fish the
> panels grobs out... https://rseek.org/?q=ggplot+facet+backgound+color
>
> https://rseek.org/?q=ggplot+facet+backgound+color
>
>
> I can get sort of close by skipping the use of table ct and instead
> filling the panels using your df table. But it doesn't color each
> panel instead it colors each geo group.
>
> ggplot(df,aes(x=date,y=vari))+
>   geom_rect(aes(fill=geo),
>             xmin=-Inf,xmax=Inf,
>             ymin=-Inf,ymax=Inf,alpha = 0.3)+
>   scale_fill_manual(values=colr)+
>   geom_bar(stat="identity")+
>   facet_grid(est~geo)
>
>
> You could add another column, composed of geo and est, and fill by that...
>
> df <- dplyr::tibble(date,vari,geo,est) %>%
>   dplyr::mutate(colr = paste(geo, est))
>
> ggplot(df,aes(x=date,y=vari))+
>   theme(panel.background = element_rect(fill = colr)) +
>   scale_fill_manual(values=colr)+
>   geom_bar(stat="identity")+
>   facet_grid(est~geo)
>
> But it makes for a long set of labels on the scale bar thingy.
>
> I hope that helps.
>
> Ben
>
>
> On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
> >
> > I am using ggplot2 and I want to use different colours for some facets.
> > Here is a reprex:
> >
> > library(tidyverse)
> > date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
> >    2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
> > vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
> >    3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
> > geo <- as.factor(c("Canada","Canada","Nova Scotia",
> >    "Nova Scotia","Manitoba","Manitoba","Canada",
> >    "Canada","Nova Scotia","Nova Scotia","Manitoba",
> >    "Manitoba","Canada","Canada","Nova Scotia",
> >    "Nova Scotia","Manitoba","Manitoba"))
> > est <- as.factor(c("Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income","Wages and salaries",
> >    "Gross mixed income"))
> > df <- data.frame(date,vari,geo,est)
> > ct <- unique(df[,c('est','geo')])
> > colr=c("blue","forestgreen","red","lightblue",
> >    "brown","gold")
> > p0 <- ggplot(df,aes(x=date,y=vari))+
> >    geom_rect(data=ct,aes(fill=geo),
> >      xmin=-Inf,xmax=Inf,
> >      ymin=-Inf,ymax=Inf,alpha = 0.3)+
> >    scale_fill_manual(values=colr)+
> >    geom_bar(stat="identity")+
> >    facet_grid(est~geo)
> > p0
> >
> > I have tried several approaches and Googled for help, but to no avail. I
> > am getting the error message: Error: Aesthetics must be either length 1
> > or the same as the data (6): x and y
> >
> > Thanks for some help.
> >
> > Philip
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Ben Tupper (he/him)
> Bigelow Laboratory for Ocean Science
> East Boothbay, Maine
> http://www.bigelow.org/
> https://eco.bigelow.org



-- 
Ben Tupper (he/him)
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From phii m@iii@g oii phiiipsmith@c@  Tue Oct 26 04:40:53 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Mon, 25 Oct 2021 22:40:53 -0400
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
 <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
Message-ID: <047f05de5c931546326ec2b61db65555@philipsmith.ca>

Thanks for the suggestions. As it happens, I just a moment ago found a 
solution. By adding the lines: ct$date <- 1 and ct$vari <- 1 everything 
works as I want it to.

Philip

On 2021-10-25 22:37, Ben Tupper wrote:
> Hi,
> 
> I don't quite follow what you want to achieve - colored backgrounds
> for each panel?  You could RSeek.org for some ideas on how to fish the
> panels grobs out... https://rseek.org/?q=ggplot+facet+backgound+color
> 
> https://rseek.org/?q=ggplot+facet+backgound+color
> 
> 
> I can get sort of close by skipping the use of table ct and instead
> filling the panels using your df table. But it doesn't color each
> panel instead it colors each geo group.
> 
> ggplot(df,aes(x=date,y=vari))+
>   geom_rect(aes(fill=geo),
>             xmin=-Inf,xmax=Inf,
>             ymin=-Inf,ymax=Inf,alpha = 0.3)+
>   scale_fill_manual(values=colr)+
>   geom_bar(stat="identity")+
>   facet_grid(est~geo)
> 
> 
> You could add another column, composed of geo and est, and fill by 
> that...
> 
> df <- dplyr::tibble(date,vari,geo,est) %>%
>   dplyr::mutate(colr = paste(geo, est))
> 
> ggplot(df,aes(x=date,y=vari))+
>   theme(panel.background = element_rect(fill = colr)) +
>   scale_fill_manual(values=colr)+
>   geom_bar(stat="identity")+
>   facet_grid(est~geo)
> 
> But it makes for a long set of labels on the scale bar thingy.
> 
> I hope that helps.
> 
> Ben
> 
> 
> On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
>> 
>> I am using ggplot2 and I want to use different colours for some 
>> facets.
>> Here is a reprex:
>> 
>> library(tidyverse)
>> date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
>>    2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
>> vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
>>    3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
>> geo <- as.factor(c("Canada","Canada","Nova Scotia",
>>    "Nova Scotia","Manitoba","Manitoba","Canada",
>>    "Canada","Nova Scotia","Nova Scotia","Manitoba",
>>    "Manitoba","Canada","Canada","Nova Scotia",
>>    "Nova Scotia","Manitoba","Manitoba"))
>> est <- as.factor(c("Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income","Wages and salaries",
>>    "Gross mixed income"))
>> df <- data.frame(date,vari,geo,est)
>> ct <- unique(df[,c('est','geo')])
>> colr=c("blue","forestgreen","red","lightblue",
>>    "brown","gold")
>> p0 <- ggplot(df,aes(x=date,y=vari))+
>>    geom_rect(data=ct,aes(fill=geo),
>>      xmin=-Inf,xmax=Inf,
>>      ymin=-Inf,ymax=Inf,alpha = 0.3)+
>>    scale_fill_manual(values=colr)+
>>    geom_bar(stat="identity")+
>>    facet_grid(est~geo)
>> p0
>> 
>> I have tried several approaches and Googled for help, but to no avail. 
>> I
>> am getting the error message: Error: Aesthetics must be either length 
>> 1
>> or the same as the data (6): x and y
>> 
>> Thanks for some help.
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Oct 26 09:51:56 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 26 Oct 2021 09:51:56 +0200
Subject: [R] KeyboardSimulator mouse.get_cursor() Not Working
In-Reply-To: <CH2PR13MB3640AC1CE98EF0F7D67B3B10FA839@CH2PR13MB3640.namprd13.prod.outlook.com>
References: <CH2PR13MB3640AC1CE98EF0F7D67B3B10FA839@CH2PR13MB3640.namprd13.prod.outlook.com>
Message-ID: <24951.45980.546222.912832@stat.math.ethz.ch>

>>>>> Sparks, John 
>>>>>     on Mon, 25 Oct 2021 15:36:07 +0000 writes:

    > Hi, I tried using the mouse.get_cursor() function in the
    > KeyboardSimulator library but it appears to no longer be
    > working.

    > When I first tried it I got an error message

    > Error in get_cursor() :

    >   function 'Rcpp_precious_remove' not provided by package
    > 'Rcpp'.

    > I installed and loaded the Rcpp library and then why I try
    > the get_cursor() function it freezes my Windows gui
    > version of R.

    > My Sys.info() is shown below.

    > Any help would be appreciated.

    > Thanks.  --John Sparks,

    >> Sys.info()
    >        sysname release version nodename machine login
    > "Windows" "10 x64" "build 19043" "SPARKS-PC" "x86-64"
    > "JSparks" user effective_user "JSparks" "JSparks"

BTW: A package *only* available on Windows

What was the answer of

     maintainer("KeyboardSimulator")

when you asked him about the problem?
This is *the* approach to take first in such cases... unless
for standard R ("base" + "Recommended") packages or other
very very widely used packages, say ggplot2.

Best regards,
Martin

--
Martin Maechler
ETH Zurich  and R Core team


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Tue Oct 26 22:09:50 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Wed, 27 Oct 2021 01:09:50 +0500
Subject: [R] Need help in R
Message-ID: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>

I need help to these questions

### Question 1
Create a variable containing a sequence of numbers from 1 to 100:

Iterate over the variables and print those numbers which are prime.


### Question 2
Create a matrix of size 3x3 called mat_1:

 Iterate over all the values one by one and print the element as well as
the position in the matrix (row, col)

	[[alternative HTML version deleted]]


From kev|n@thorpe @end|ng |rom utoronto@c@  Tue Oct 26 22:16:16 2021
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin Thorpe)
Date: Tue, 26 Oct 2021 20:16:16 +0000
Subject: [R] Need help in R
In-Reply-To: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
Message-ID: <4E491D16-42C3-4F09-9B70-71E37143AF78@utoronto.ca>

This looks suspiciously like homework and this list does have a no homework policy. If it is not homework, please forgive the assumption.


> On Oct 26, 2021, at 4:09 PM, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
> 
> I need help to these questions
> 
> ### Question 1
> Create a variable containing a sequence of numbers from 1 to 100:
> 
> Iterate over the variables and print those numbers which are prime.
> 
> 
> ### Question 2
> Create a matrix of size 3x3 called mat_1:
> 
> Iterate over all the values one by one and print the element as well as
> the position in the matrix (row, col)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael?s Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Oct 26 22:27:29 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 26 Oct 2021 13:27:29 -0700
Subject: [R] Need help in R
In-Reply-To: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
Message-ID: <76431E79-6F32-4AB3-BD83-EA84AA423CC7@dcn.davis.ca.us>

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

One of the items mentioned in the Posting Guide is that homework questions are not okay... we don't know what your instructor is looking for, and they are expected to provide support for their instruction plan.

On October 26, 2021 1:09:50 PM PDT, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>I need help to these questions
>
>### Question 1
>Create a variable containing a sequence of numbers from 1 to 100:
>
>Iterate over the variables and print those numbers which are prime.
>
>
>### Question 2
>Create a matrix of size 3x3 called mat_1:
>
> Iterate over all the values one by one and print the element as well as
>the position in the matrix (row, col)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Oct 26 22:35:09 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 27 Oct 2021 09:35:09 +1300
Subject: [R] Need help in R
In-Reply-To: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
Message-ID: <20211027093509.423eda06@rolf-Latitude-E7470>


On Wed, 27 Oct 2021 01:09:50 +0500
Anas Jamshed <anasjamshed1994 at gmail.com> wrote:

> I need help to these questions
> 
> ### Question 1
> Create a variable containing a sequence of numbers from 1 to 100:
> 
> Iterate over the variables and print those numbers which are prime.
> 
> 
> ### Question 2
> Create a matrix of size 3x3 called mat_1:
> 
>  Iterate over all the values one by one and print the element as well
> as the position in the matrix (row, col)

You really should do your own homework.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Tue Oct 26 22:39:23 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Wed, 27 Oct 2021 01:39:23 +0500
Subject: [R] Need help in R
In-Reply-To: <20211027093509.423eda06@rolf-Latitude-E7470>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
 <20211027093509.423eda06@rolf-Latitude-E7470>
Message-ID: <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>

Its not homework . Basically i want to get easy solution:
I am trying this for ist problem:

n= seq(1,100)

for (j in n:100) {
      f = 1
      i = 2
      n = j
      while (i <= n / 2) {
        if (n %% i == 0) {
          f = 0
          break
        }
        i = i + 1
      }
      if (f == 1) {
        print(paste("Number is prime :", n))
      }
    }

On Wed, Oct 27, 2021 at 1:35 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On Wed, 27 Oct 2021 01:09:50 +0500
> Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> > I need help to these questions
> >
> > ### Question 1
> > Create a variable containing a sequence of numbers from 1 to 100:
> >
> > Iterate over the variables and print those numbers which are prime.
> >
> >
> > ### Question 2
> > Create a matrix of size 3x3 called mat_1:
> >
> >  Iterate over all the values one by one and print the element as well
> > as the position in the matrix (row, col)
>
> You really should do your own homework.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>

	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Tue Oct 26 22:59:00 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Tue, 26 Oct 2021 22:59:00 +0200
Subject: [R] cleanup/replacing a value on condition of another value
In-Reply-To: <005501d7c9e5$4a13bbe0$de3b33a0$@verizon.net>
References: <sl647p$17td$1@ciao.gmane.io>
 <5ce539e3-8117-29e4-6c39-edfb3dd02b1f@sapo.pt> <sl6jlj$14mf$1@ciao.gmane.io>
 <005501d7c9e5$4a13bbe0$de3b33a0$@verizon.net>
Message-ID: <sl9q6k$ut9$1@ciao.gmane.io>

Thanks.

Your method

    mutate(
       cases = ifelse(
          country == 'Namibia'
             & type == 'confirmed'
             & date == '2021-10-23'
             & cases == 357,
          NA,
          cases
       )
    )

works, as does Rui's

    mutate(
       cases = replace(
          cases,
          which(country == 'Namibia'
             & type == 'confirmed'
             & date == '2021-10-23'
             & cases == 357),
          NA
       )
    )

Thank you both, again.

el

On 2021-10-25 23:14 , Avi Gross via R-help wrote:
 > I wonder why it is not as simple as:
 >
 > Call mutate on the data and have a condition that looks like:
 >
 > data %>% mutate(cases = ifelse(multiple_cond, NA, cases) -> output
[...]


From ycd|ng @end|ng |rom coh@org  Wed Oct 27 00:38:35 2021
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Tue, 26 Oct 2021 22:38:35 +0000
Subject: [R] how to include if conditions in dplyr filter function
Message-ID: <SJ0PR02MB7645BA3559C616135446E976D4849@SJ0PR02MB7645.namprd02.prod.outlook.com>

Hi R users,

I thought the follow R code should work, but I got error, Can you fix my code?

Thank you,

Ding


outlier_tcga_MAD3 <- outlier_tcga %>% filter(n_two >0) %>% 
      mutate(freqMAD3_gain2ratio = N_MAD3_gain2/n_two )%>% 
  if (N_MAD3 < 9) {filter(freqMAD3_gain >=1)} else if (N_MAD3 > n_two*2 )
                  {filter (freqMAD3_gain >= 0.8 & freqMAD3_gain2ratio >= 0.33)} else 
                  {filter(freqMAD3_gain2 >=0.3 )} %>% 
  arrange(desc(N_MAD3))


Error in if (.) N_MAD3 < 9 else { : 
  argument is not interpretable as logical
In addition: Warning message:
In if (.) N_MAD3 < 9 else { :
  the condition has length > 1 and only the first element will be used

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Oct 27 01:18:16 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 27 Oct 2021 12:18:16 +1300
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <047f05de5c931546326ec2b61db65555@philipsmith.ca>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
 <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
 <047f05de5c931546326ec2b61db65555@philipsmith.ca>
Message-ID: <87777c50-ffd8-6143-7888-520274ea7316@stat.auckland.ac.nz>

Hi

Another alternative (using 'gggrid' to add a 'grid' rect grob as the 
background), just for the record ...

library(gggrid)

bgrect <- function(data, coords) {
     rectGrob(gp=gpar(col=NA, fill=adjustcolor(data$fill[1], alpha=.3)))
}

ggplot(df, aes(x=date, y=vari)) +
     grid_panel(bgrect, aes(fill=geo)) +
     scale_fill_manual(values=colr) +
     geom_bar(stat="identity")+
     facet_grid(est ~ geo)

Paul

On 26/10/2021 3:40 pm, phil at philipsmith.ca wrote:
> Thanks for the suggestions. As it happens, I just a moment ago found a
> solution. By adding the lines: ct$date <- 1 and ct$vari <- 1 everything
> works as I want it to.
> 
> Philip
> 
> On 2021-10-25 22:37, Ben Tupper wrote:
>  > Hi,
>  >
>  > I don't quite follow what you want to achieve - colored backgrounds
>  > for each panel? You could RSeek.org for some ideas on how to fish the
>  > panels grobs out... https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>
>  >
>  > https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>
>  >
>  >
>  > I can get sort of close by skipping the use of table ct and instead
>  > filling the panels using your df table. But it doesn't color each
>  > panel instead it colors each geo group.
>  >
>  > ggplot(df,aes(x=date,y=vari))+
>  > geom_rect(aes(fill=geo),
>  > xmin=-Inf,xmax=Inf,
>  > ymin=-Inf,ymax=Inf,alpha = 0.3)+
>  > scale_fill_manual(values=colr)+
>  > geom_bar(stat="identity")+
>  > facet_grid(est~geo)
>  >
>  >
>  > You could add another column, composed of geo and est, and fill by
>  > that...
>  >
>  > df <- dplyr::tibble(date,vari,geo,est) %>%
>  > dplyr::mutate(colr = paste(geo, est))
>  >
>  > ggplot(df,aes(x=date,y=vari))+
>  > theme(panel.background = element_rect(fill = colr)) +
>  > scale_fill_manual(values=colr)+
>  > geom_bar(stat="identity")+
>  > facet_grid(est~geo)
>  >
>  > But it makes for a long set of labels on the scale bar thingy.
>  >
>  > I hope that helps.
>  >
>  > Ben
>  >
>  >
>  > On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
>  >>
>  >> I am using ggplot2 and I want to use different colours for some
>  >> facets.
>  >> Here is a reprex:
>  >>
>  >> library(tidyverse)
>  >> date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
>  >> 2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
>  >> vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
>  >> 3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
>  >> geo <- as.factor(c("Canada","Canada","Nova Scotia",
>  >> "Nova Scotia","Manitoba","Manitoba","Canada",
>  >> "Canada","Nova Scotia","Nova Scotia","Manitoba",
>  >> "Manitoba","Canada","Canada","Nova Scotia",
>  >> "Nova Scotia","Manitoba","Manitoba"))
>  >> est <- as.factor(c("Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income","Wages and salaries",
>  >> "Gross mixed income"))
>  >> df <- data.frame(date,vari,geo,est)
>  >> ct <- unique(df[,c('est','geo')])
>  >> colr=c("blue","forestgreen","red","lightblue",
>  >> "brown","gold")
>  >> p0 <- ggplot(df,aes(x=date,y=vari))+
>  >> geom_rect(data=ct,aes(fill=geo),
>  >> xmin=-Inf,xmax=Inf,
>  >> ymin=-Inf,ymax=Inf,alpha = 0.3)+
>  >> scale_fill_manual(values=colr)+
>  >> geom_bar(stat="identity")+
>  >> facet_grid(est~geo)
>  >> p0
>  >>
>  >> I have tried several approaches and Googled for help, but to no avail.
>  >> I
>  >> am getting the error message: Error: Aesthetics must be either length
>  >> 1
>  >> or the same as the data (6): x and y
>  >>
>  >> Thanks for some help.
>  >>
>  >> Philip
>  >>
>  >> ______________________________________________
>  >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  >> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>  >> PLEASE do read the posting guide
>  >> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>  >> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From phii m@iii@g oii phiiipsmith@c@  Wed Oct 27 01:55:12 2021
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 26 Oct 2021 19:55:12 -0400
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <87777c50-ffd8-6143-7888-520274ea7316@stat.auckland.ac.nz>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
 <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
 <047f05de5c931546326ec2b61db65555@philipsmith.ca>
 <87777c50-ffd8-6143-7888-520274ea7316@stat.auckland.ac.nz>
Message-ID: <a64c44767867951a5f96042c48673c40@philipsmith.ca>

Thanks for this. I was unable to install the gggrid package apparently 
because it is unavailable for my version of R (4.1.1 (2021-08-10)). But 
I found it here https://github.com/pmur002/gggrid/releases/tag/v0.1-0, 
copied the code into your code, and it worked very well.

On 2021-10-26 19:18, Paul Murrell wrote:
> Hi
> 
> Another alternative (using 'gggrid' to add a 'grid' rect grob as the
> background), just for the record ...
> 
> library(gggrid)
> 
> bgrect <- function(data, coords) {
>     rectGrob(gp=gpar(col=NA, fill=adjustcolor(data$fill[1], alpha=.3)))
> }
> 
> ggplot(df, aes(x=date, y=vari)) +
>     grid_panel(bgrect, aes(fill=geo)) +
>     scale_fill_manual(values=colr) +
>     geom_bar(stat="identity")+
>     facet_grid(est ~ geo)
> 
> Paul
> 
> On 26/10/2021 3:40 pm, phil at philipsmith.ca wrote:
>> Thanks for the suggestions. As it happens, I just a moment ago found a
>> solution. By adding the lines: ct$date <- 1 and ct$vari <- 1 
>> everything
>> works as I want it to.
>> 
>> Philip
>> 
>> On 2021-10-25 22:37, Ben Tupper wrote:
>>  > Hi,
>>  >
>>  > I don't quite follow what you want to achieve - colored backgrounds
>>  > for each panel? You could RSeek.org for some ideas on how to fish 
>> the
>>  > panels grobs out... 
>> https://rseek.org/?q=ggplot+facet+backgound+color 
>> <https://rseek.org/?q=ggplot+facet+backgound+color>
>>  >
>>  > https://rseek.org/?q=ggplot+facet+backgound+color 
>> <https://rseek.org/?q=ggplot+facet+backgound+color>
>>  >
>>  >
>>  > I can get sort of close by skipping the use of table ct and instead
>>  > filling the panels using your df table. But it doesn't color each
>>  > panel instead it colors each geo group.
>>  >
>>  > ggplot(df,aes(x=date,y=vari))+
>>  > geom_rect(aes(fill=geo),
>>  > xmin=-Inf,xmax=Inf,
>>  > ymin=-Inf,ymax=Inf,alpha = 0.3)+
>>  > scale_fill_manual(values=colr)+
>>  > geom_bar(stat="identity")+
>>  > facet_grid(est~geo)
>>  >
>>  >
>>  > You could add another column, composed of geo and est, and fill by
>>  > that...
>>  >
>>  > df <- dplyr::tibble(date,vari,geo,est) %>%
>>  > dplyr::mutate(colr = paste(geo, est))
>>  >
>>  > ggplot(df,aes(x=date,y=vari))+
>>  > theme(panel.background = element_rect(fill = colr)) +
>>  > scale_fill_manual(values=colr)+
>>  > geom_bar(stat="identity")+
>>  > facet_grid(est~geo)
>>  >
>>  > But it makes for a long set of labels on the scale bar thingy.
>>  >
>>  > I hope that helps.
>>  >
>>  > Ben
>>  >
>>  >
>>  > On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
>>  >>
>>  >> I am using ggplot2 and I want to use different colours for some
>>  >> facets.
>>  >> Here is a reprex:
>>  >>
>>  >> library(tidyverse)
>>  >> date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
>>  >> 2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
>>  >> vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
>>  >> 3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
>>  >> geo <- as.factor(c("Canada","Canada","Nova Scotia",
>>  >> "Nova Scotia","Manitoba","Manitoba","Canada",
>>  >> "Canada","Nova Scotia","Nova Scotia","Manitoba",
>>  >> "Manitoba","Canada","Canada","Nova Scotia",
>>  >> "Nova Scotia","Manitoba","Manitoba"))
>>  >> est <- as.factor(c("Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income","Wages and salaries",
>>  >> "Gross mixed income"))
>>  >> df <- data.frame(date,vari,geo,est)
>>  >> ct <- unique(df[,c('est','geo')])
>>  >> colr=c("blue","forestgreen","red","lightblue",
>>  >> "brown","gold")
>>  >> p0 <- ggplot(df,aes(x=date,y=vari))+
>>  >> geom_rect(data=ct,aes(fill=geo),
>>  >> xmin=-Inf,xmax=Inf,
>>  >> ymin=-Inf,ymax=Inf,alpha = 0.3)+
>>  >> scale_fill_manual(values=colr)+
>>  >> geom_bar(stat="identity")+
>>  >> facet_grid(est~geo)
>>  >> p0
>>  >>
>>  >> I have tried several approaches and Googled for help, but to no 
>> avail.
>>  >> I
>>  >> am getting the error message: Error: Aesthetics must be either 
>> length
>>  >> 1
>>  >> or the same as the data (6): x and y
>>  >>
>>  >> Thanks for some help.
>>  >>
>>  >> Philip
>>  >>
>>  >> ______________________________________________
>>  >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>  >> https://stat.ethz.ch/mailman/listinfo/r-help 
>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>  >> PLEASE do read the posting guide
>>  >> http://www.R-project.org/posting-guide.html 
>> <http://www.R-project.org/posting-guide.html>
>>  >> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help 
>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html 
>> <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct 27 02:12:45 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 26 Oct 2021 17:12:45 -0700
Subject: [R] Need help in R
In-Reply-To: <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
 <20211027093509.423eda06@rolf-Latitude-E7470>
 <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>
Message-ID: <CAGxFJbTDAKGS-dZoGpJO2Mfm=ktT5boeHRfKHVhEidt8x1i6GQ@mail.gmail.com>

Well, OK. I'll provide you an alternative and explanation.

The way you are going about it would work, but it is usually not the best
approach in R. Typically, the key in R is to whenever possible use whole
object manipulation rather than iteration. This hides the iteration details
and often pushes them down to the much more efficient underlying C code. So
here's one way to do it in R:

findprm <- function(n){
   nn <- seq.int(2, n)
   i <- 2
   while(i <= floor(sqrt( n))){
      nn <- nn[(nn <= i) | (nn %% i > 0)]
      i <- nn[nn > i][1]
   }
   nn
}

Example:
> findprm(66)
 [1]  2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61

I'll leave it to you to work out the details for how it works. :-)
And, of course, there are almost certainly even better ways to do this, but
this should get you started.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Oct 26, 2021 at 1:59 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> Its not homework . Basically i want to get easy solution:
> I am trying this for ist problem:
>
> n= seq(1,100)
>
> for (j in n:100) {
>       f = 1
>       i = 2
>       n = j
>       while (i <= n / 2) {
>         if (n %% i == 0) {
>           f = 0
>           break
>         }
>         i = i + 1
>       }
>       if (f == 1) {
>         print(paste("Number is prime :", n))
>       }
>     }
>
> On Wed, Oct 27, 2021 at 1:35 AM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
>
> >
> > On Wed, 27 Oct 2021 01:09:50 +0500
> > Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
> >
> > > I need help to these questions
> > >
> > > ### Question 1
> > > Create a variable containing a sequence of numbers from 1 to 100:
> > >
> > > Iterate over the variables and print those numbers which are prime.
> > >
> > >
> > > ### Question 2
> > > Create a matrix of size 3x3 called mat_1:
> > >
> > >  Iterate over all the values one by one and print the element as well
> > > as the position in the matrix (row, col)
> >
> > You really should do your own homework.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Oct 27 02:20:50 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 26 Oct 2021 20:20:50 -0400
Subject: [R] Need help in R
In-Reply-To: <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
 <20211027093509.423eda06@rolf-Latitude-E7470>
 <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>
Message-ID: <00d001d7cac8$7f4b7300$7de25900$@verizon.net>

There can be people doing homework for a course and as noted, the normal
expectation is to use the resources provided including classroom instruction
(or the often ZOOM or recordings) as well as textbooks.

Forums like this are not a substitute and some nice people will sometimes
volunteer not to do homework but help someone a bit such as asking them to
think about the problem, what data structures or loops might be needed OR
help them understand an error message or after seeing their attempts, point
out a subtle flaw.

There are some who are teaching themselves and are not being graded but are
trying little project to learn. But again, it is best they learn for
themselves and not be handed an answer.

Some mailing lists have rules and perhaps might answer someone more if it is
WORK question like how to fine tune a graph after they have most of it
working.

So, I am looking at the follow-up below with a jaundiced eye as I just saw
something similar enough being asked on a Python board. 

The first question strikes me as odd because it contains a completely
un-necessary looking part. 

> > ### Question 1
> > Create a variable containing a sequence of numbers from 1 to 100:
> >
> > Iterate over the variables and print those numbers which are prime.

You do not really need to create a sequence and then again loop over the
same sequence. The following code is shown:

n= seq(1,100)

for (j in n:100) {

Well, the look could have been using n directly or using 1:100 but uses
nonsense. To say n:100 requires n to be an integer, not some kind of
sequence or vector. And why go to 200 in any case? 

The rest gets worse and worse with oddities like using just letters of the
alphabet without meanings as variables, using integers like "f = 1" rather
than Booleans for such flags, and using the "=" operator rather than the
more accepted "<-" operator. The loop uses variable j then ignores it and
keeps manipulating i. 

Someone wanting help might want to let people know what the algorithm is
supposed to do. 

I won't try to guess and certainly won't supply a valid solution here!

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Anas Jamshed
Sent: Tuesday, October 26, 2021 4:39 PM
To: Rolf Turner <r.turner at auckland.ac.nz>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] Need help in R

Its not homework . Basically i want to get easy solution:
I am trying this for ist problem:

n= seq(1,100)

for (j in n:100) {
      f = 1
      i = 2
      n = j
      while (i <= n / 2) {
        if (n %% i == 0) {
          f = 0
          break
        }
        i = i + 1
      }
      if (f == 1) {
        print(paste("Number is prime :", n))
      }
    }

On Wed, Oct 27, 2021 at 1:35 AM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On Wed, 27 Oct 2021 01:09:50 +0500
> Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> > I need help to these questions
> >
> > ### Question 1
> > Create a variable containing a sequence of numbers from 1 to 100:
> >
> > Iterate over the variables and print those numbers which are prime.
> >
> >
> > ### Question 2
> > Create a matrix of size 3x3 called mat_1:
> >
> >  Iterate over all the values one by one and print the element as 
> > well as the position in the matrix (row, col)
>
> You really should do your own homework.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Oct 27 02:28:43 2021
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Wed, 27 Oct 2021 13:28:43 +1300
Subject: [R] Putting colours in ggplot facets
In-Reply-To: <a64c44767867951a5f96042c48673c40@philipsmith.ca>
References: <232d28a86b90695172399dcfdc81adbe@philipsmith.ca>
 <CALrbzg3vb3N4eXh3gw-5zrRLZqnj0Bk+qDQocFjNwvsvscYV3A@mail.gmail.com>
 <047f05de5c931546326ec2b61db65555@philipsmith.ca>
 <87777c50-ffd8-6143-7888-520274ea7316@stat.auckland.ac.nz>
 <a64c44767867951a5f96042c48673c40@philipsmith.ca>
Message-ID: <c2d8cd98-c271-d233-91ff-868d4d252bbd@stat.auckland.ac.nz>


Sorry, forgot to point out that you would need something like this to 
install ...

remotes::install_github("pmur002/gggrid")

Paul

On 27/10/2021 12:55 pm, phil at philipsmith.ca wrote:
> Thanks for this. I was unable to install the gggrid package apparently
> because it is unavailable for my version of R (4.1.1 (2021-08-10)). But
> I found it here https://github.com/pmur002/gggrid/releases/tag/v0.1-0 
> <https://github.com/pmur002/gggrid/releases/tag/v0.1-0>, 
> 
> copied the code into your code, and it worked very well.
> 
> On 2021-10-26 19:18, Paul Murrell wrote:
>  > Hi
>  >
>  > Another alternative (using 'gggrid' to add a 'grid' rect grob as the
>  > background), just for the record ...
>  >
>  > library(gggrid)
>  >
>  > bgrect <- function(data, coords) {
>  > rectGrob(gp=gpar(col=NA, fill=adjustcolor(data$fill[1], alpha=.3)))
>  > }
>  >
>  > ggplot(df, aes(x=date, y=vari)) +
>  > grid_panel(bgrect, aes(fill=geo)) +
>  > scale_fill_manual(values=colr) +
>  > geom_bar(stat="identity")+
>  > facet_grid(est ~ geo)
>  >
>  > Paul
>  >
>  > On 26/10/2021 3:40 pm, phil at philipsmith.ca wrote:
>  >> Thanks for the suggestions. As it happens, I just a moment ago found a
>  >> solution. By adding the lines: ct$date <- 1 and ct$vari <- 1
>  >> everything
>  >> works as I want it to.
>  >>
>  >> Philip
>  >>
>  >> On 2021-10-25 22:37, Ben Tupper wrote:
>  >> > Hi,
>  >> >
>  >> > I don't quite follow what you want to achieve - colored backgrounds
>  >> > for each panel? You could RSeek.org for some ideas on how to fish
>  >> the
>  >> > panels grobs out...
>  >> https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>
>  >> <https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>>
>  >> >
>  >> > https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>
>  >> <https://rseek.org/?q=ggplot+facet+backgound+color 
> <https://rseek.org/?q=ggplot+facet+backgound+color>>
>  >> >
>  >> >
>  >> > I can get sort of close by skipping the use of table ct and instead
>  >> > filling the panels using your df table. But it doesn't color each
>  >> > panel instead it colors each geo group.
>  >> >
>  >> > ggplot(df,aes(x=date,y=vari))+
>  >> > geom_rect(aes(fill=geo),
>  >> > xmin=-Inf,xmax=Inf,
>  >> > ymin=-Inf,ymax=Inf,alpha = 0.3)+
>  >> > scale_fill_manual(values=colr)+
>  >> > geom_bar(stat="identity")+
>  >> > facet_grid(est~geo)
>  >> >
>  >> >
>  >> > You could add another column, composed of geo and est, and fill by
>  >> > that...
>  >> >
>  >> > df <- dplyr::tibble(date,vari,geo,est) %>%
>  >> > dplyr::mutate(colr = paste(geo, est))
>  >> >
>  >> > ggplot(df,aes(x=date,y=vari))+
>  >> > theme(panel.background = element_rect(fill = colr)) +
>  >> > scale_fill_manual(values=colr)+
>  >> > geom_bar(stat="identity")+
>  >> > facet_grid(est~geo)
>  >> >
>  >> > But it makes for a long set of labels on the scale bar thingy.
>  >> >
>  >> > I hope that helps.
>  >> >
>  >> > Ben
>  >> >
>  >> >
>  >> > On Mon, Oct 25, 2021 at 9:08 PM <phil at philipsmith.ca> wrote:
>  >> >>
>  >> >> I am using ggplot2 and I want to use different colours for some
>  >> >> facets.
>  >> >> Here is a reprex:
>  >> >>
>  >> >> library(tidyverse)
>  >> >> date <- as.numeric(c(2017,2017,2017,2017,2017,2017,2018,2018,
>  >> >> 2018,2018,2018,2018,2019,2019,2019,2019,2019,2019))
>  >> >> vari <- as.numeric(c(4.8,3.3,4.2,5.2,4.8,5.7,5.4,3.1,5.7,4.1,
>  >> >> 3.1,1.5,4.5,4.4,2.8,2.0,2.1,2.2))
>  >> >> geo <- as.factor(c("Canada","Canada","Nova Scotia",
>  >> >> "Nova Scotia","Manitoba","Manitoba","Canada",
>  >> >> "Canada","Nova Scotia","Nova Scotia","Manitoba",
>  >> >> "Manitoba","Canada","Canada","Nova Scotia",
>  >> >> "Nova Scotia","Manitoba","Manitoba"))
>  >> >> est <- as.factor(c("Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income","Wages and salaries",
>  >> >> "Gross mixed income"))
>  >> >> df <- data.frame(date,vari,geo,est)
>  >> >> ct <- unique(df[,c('est','geo')])
>  >> >> colr=c("blue","forestgreen","red","lightblue",
>  >> >> "brown","gold")
>  >> >> p0 <- ggplot(df,aes(x=date,y=vari))+
>  >> >> geom_rect(data=ct,aes(fill=geo),
>  >> >> xmin=-Inf,xmax=Inf,
>  >> >> ymin=-Inf,ymax=Inf,alpha = 0.3)+
>  >> >> scale_fill_manual(values=colr)+
>  >> >> geom_bar(stat="identity")+
>  >> >> facet_grid(est~geo)
>  >> >> p0
>  >> >>
>  >> >> I have tried several approaches and Googled for help, but to no
>  >> avail.
>  >> >> I
>  >> >> am getting the error message: Error: Aesthetics must be either
>  >> length
>  >> >> 1
>  >> >> or the same as the data (6): x and y
>  >> >>
>  >> >> Thanks for some help.
>  >> >>
>  >> >> Philip
>  >> >>
>  >> >> ______________________________________________
>  >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  >> >> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help> 
> 
>  >> <https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>>
>  >> >> PLEASE do read the posting guide
>  >> >> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html> 
> 
>  >> <http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>>
>  >> >> and provide commented, minimal, self-contained, reproducible code.
>  >>
>  >> ______________________________________________
>  >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  >> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help> 
> 
>  >> <https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>>
>  >> PLEASE do read the posting guide
>  >> http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html> 
> 
>  >> <http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>>
>  >> and provide commented, minimal, self-contained, reproducible code.

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Oct 27 03:26:53 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Tue, 26 Oct 2021 21:26:53 -0400
Subject: [R] how to include if conditions in dplyr filter function
In-Reply-To: <SJ0PR02MB7645BA3559C616135446E976D4849@SJ0PR02MB7645.namprd02.prod.outlook.com>
References: <SJ0PR02MB7645BA3559C616135446E976D4849@SJ0PR02MB7645.namprd02.prod.outlook.com>
Message-ID: <011501d7cad1$b9577090$2c0651b0$@verizon.net>

The error below was fairly clear. The R 'if" statement is not vectorized and
takes a single logical argument. It is not normally used in a pipeline
unless at that point the data has been reduced to a vector of length 1.

I do not want to look at your code further without the data behind it but
suggest there is a vectorized ifelse() function that might fit your needs
but since you use filter(0 so many times in there, maybe this should not be
one long pipeline.



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Yuan Chun Ding via
R-help
Sent: Tuesday, October 26, 2021 6:39 PM
To: r-help at r-project.org
Subject: [R] how to include if conditions in dplyr filter function

Hi R users,

I thought the follow R code should work, but I got error, Can you fix my
code?

Thank you,

Ding


outlier_tcga_MAD3 <- outlier_tcga %>% filter(n_two >0) %>% 
      mutate(freqMAD3_gain2ratio = N_MAD3_gain2/n_two )%>%
  if (N_MAD3 < 9) {filter(freqMAD3_gain >=1)} else if (N_MAD3 > n_two*2 )
                  {filter (freqMAD3_gain >= 0.8 & freqMAD3_gain2ratio >=
0.33)} else 
                  {filter(freqMAD3_gain2 >=0.3 )} %>%
  arrange(desc(N_MAD3))


Error in if (.) N_MAD3 < 9 else { : 
  argument is not interpretable as logical In addition: Warning message:
In if (.) N_MAD3 < 9 else { :
  the condition has length > 1 and only the first element will be used

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or
entity to which they are addressed. This communication may contain
information that is privileged, confidential, or exempt from disclosure
under applicable law (e.g., personal health information, research data,
financial information). Because this e-mail has been sent without
encryption, individuals other than the intended recipient may be able to
view the information, forward it to others or tamper with the information
without the knowledge or consent of the sender. If you are not the intended
recipient, or the employee or person responsible for delivering the message
to the intended recipient, any dissemination, distribution or copying of the
communication is strictly prohibited. If you received the communication in
error, please notify the sender immediately by replying to this message and
deleting the message and any accompanying files from your system. If, due to
the security risks, you do not wish to receive further communications via
e-mail, please reply to this message and inform the sender that you do not
wish to receive further e-mail from the sender. (LCP301)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m|n@h@|| @end|ng |rom um|ch@edu  Wed Oct 27 05:29:17 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Wed, 27 Oct 2021 06:29:17 +0300
Subject: [R] Need help in R
In-Reply-To: <CAGxFJbTDAKGS-dZoGpJO2Mfm=ktT5boeHRfKHVhEidt8x1i6GQ@mail.gmail.com>
References: <CAG0CrLjPNL6BKw-_2KbKA-UzV4kqqs3cssLG=FJVodZvCkpJ_g@mail.gmail.com>
 <20211027093509.423eda06@rolf-Latitude-E7470>
 <CAG0CrLjeuwz1jKyMaQaMXCTJKVRoFyrwdcnEgwhcNcMXUHR0tg@mail.gmail.com>
 <CAGxFJbTDAKGS-dZoGpJO2Mfm=ktT5boeHRfKHVhEidt8x1i6GQ@mail.gmail.com>
Message-ID: <388681.1635305357@apollo2.minshall.org>

Bert,

> findprm <- function(n){
>    nn <- seq.int(2, n)
>    i <- 2
>    while(i <= floor(sqrt( n))){
>       nn <- nn[(nn <= i) | (nn %% i > 0)]
>       i <- nn[nn > i][1]
>    }
>    nn
> }

+1 -- thanks!


From t@n@@@ @end|ng |rom gm@||@com  Wed Oct 27 19:17:52 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 27 Oct 2021 10:17:52 -0700
Subject: [R] R code in RData
Message-ID: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>

Dear all, would you please advice :

I have an Rdata file, what is the way to print the R code that has been
used inside the Rdata file ?

thank you,

Bogdan

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Oct 27 19:47:14 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 27 Oct 2021 10:47:14 -0700
Subject: [R] R code in RData
In-Reply-To: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>
References: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>
Message-ID: <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>

See ?load, but you may be confused. Strictly speaking, there is no code in
an .Rdata file, only a (typically binary, but possibly ascii)
representation of objects, usually as produced by ?save. Of course,
functions are also objects, so that if you load a file with functions, the
function code is available.

You can save and load command histories via ?savehistory, which, like ?save
and ?load can usually be accessed through any GUI interface that you are
using.

Warning: I believe the above is correct, but I may be wrong in at least
some details, so give others a chance to reply and possibly correct.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Oct 27, 2021 at 10:18 AM Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all, would you please advice :
>
> I have an Rdata file, what is the way to print the R code that has been
> used inside the Rdata file ?
>
> thank you,
>
> Bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Oct 27 20:43:08 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Oct 2021 11:43:08 -0700
Subject: [R] R code in RData
In-Reply-To: <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>
References: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>
 <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>
Message-ID: <41B5E8D8-8EF5-4A8D-ADA6-B428C25878D5@dcn.davis.ca.us>

Sounds right, though the OP appears to be assuming that the code used to generate the data objects in the file will also be there, and we need to be more definitive about that: it is not. Depending how the code was constructed, there may be useful information in the functions that were stored in the environment from which the save file was created, but this is not in any way guaranteed to be useful. In particular, there is no trace IN the RData file of which packages need to be loaded in order to access the objects stored in that RData file.

This is one of the reasons depending on RData files for archiving work is not advisable... and why putting code in R scripts or Sweave/knitr-based literate programming files IS recommended.

On October 27, 2021 10:47:14 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>See ?load, but you may be confused. Strictly speaking, there is no code in
>an .Rdata file, only a (typically binary, but possibly ascii)
>representation of objects, usually as produced by ?save. Of course,
>functions are also objects, so that if you load a file with functions, the
>function code is available.
>
>You can save and load command histories via ?savehistory, which, like ?save
>and ?load can usually be accessed through any GUI interface that you are
>using.
>
>Warning: I believe the above is correct, but I may be wrong in at least
>some details, so give others a chance to reply and possibly correct.
>
>Cheers,
>Bert
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Oct 27, 2021 at 10:18 AM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
>> Dear all, would you please advice :
>>
>> I have an Rdata file, what is the way to print the R code that has been
>> used inside the Rdata file ?
>>
>> thank you,
>>
>> Bogdan
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From t@n@@@ @end|ng |rom gm@||@com  Wed Oct 27 20:52:37 2021
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Wed, 27 Oct 2021 11:52:37 -0700
Subject: [R] docker containers and R
Message-ID: <CA+JEM00fsq9rREkuWTB8AtHriMsNgx-7r13mCGNmvXZwwDGdyw@mail.gmail.com>

Dear all, would you please advise :

shall I have a container that runs R (below), and install specifically a
package called UMI4Cats, obviously, a lot of other libraries are
installed.How can I save the docker container that contains the additional
libraries that I have installed and are required by UMI4Cats ?

https://www.bioconductor.org/help/docker/#running


-> % docker run -it --entrypoint=Rscript
bioconductor/bioconductor_docker:RELEASE_3_13 -e 'capabilities()'
       jpeg         png        tiff       tcltk         X11        aqua
       TRUE        TRUE        TRUE        TRUE       FALSE       FALSE
   http/ftp     sockets      libxml        fifo      cledit       iconv
       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE
        NLS       Rprof     profmem       cairo         ICU long.double
      FALSE        TRUE        TRUE        TRUE        TRUE        TRUE
    libcurl
       TRUE

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Wed Oct 27 22:25:57 2021
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Wed, 27 Oct 2021 22:25:57 +0200
Subject: [R] docker containers and R
In-Reply-To: <CA+JEM00fsq9rREkuWTB8AtHriMsNgx-7r13mCGNmvXZwwDGdyw@mail.gmail.com>
References: <CA+JEM00fsq9rREkuWTB8AtHriMsNgx-7r13mCGNmvXZwwDGdyw@mail.gmail.com>
Message-ID: <CAGAA5bcy-JT+F1_7=YVFH+-3v9odTLwMKGoeJTCjPy-e9p9orQ@mail.gmail.com>

On Wed, 27 Oct 2021 at 20:53, Bogdan Tanasa <tanasa at gmail.com> wrote:

> Dear all, would you please advise :
>
> shall I have a container that runs R (below), and install specifically a
> package called UMI4Cats, obviously, a lot of other libraries are
> installed.How can I save the docker container that contains the additional
> libraries that I have installed and are required by UMI4Cats ?
>

You use "docker commit" - see
https://docs.docker.com/engine/reference/commandline/commit/

But consider making a Dockerfile instead.

Regards
Martin

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Oct 27 22:39:30 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Oct 2021 13:39:30 -0700
Subject: [R] docker containers and R
In-Reply-To: <CA+JEM00fsq9rREkuWTB8AtHriMsNgx-7r13mCGNmvXZwwDGdyw@mail.gmail.com>
References: <CA+JEM00fsq9rREkuWTB8AtHriMsNgx-7r13mCGNmvXZwwDGdyw@mail.gmail.com>
Message-ID: <58DC95C2-570A-408B-8239-109F91960767@dcn.davis.ca.us>

Docker containers are built from some starting point defined using docker conventions. They have nothing to do with how you may have installed or configured R on your computer, other than perhaps what you learned but forgot about all that stuff. So the answer depends on what docker image you are starting from, and what the requirements are for your packages, but this list is about R, not docker, or docker images, or about specific contributed packages (see the Posting Guide).

Some packages have extensive dependencies, and you may need to explicitly install all of them in your build file to get it to work at all, much less in a minimal container size.

On October 27, 2021 11:52:37 AM PDT, Bogdan Tanasa <tanasa at gmail.com> wrote:
>Dear all, would you please advise :
>
>shall I have a container that runs R (below), and install specifically a
>package called UMI4Cats, obviously, a lot of other libraries are
>installed.How can I save the docker container that contains the additional
>libraries that I have installed and are required by UMI4Cats ?
>
>https://www.bioconductor.org/help/docker/#running
>
>
>-> % docker run -it --entrypoint=Rscript
>bioconductor/bioconductor_docker:RELEASE_3_13 -e 'capabilities()'
>       jpeg         png        tiff       tcltk         X11        aqua
>       TRUE        TRUE        TRUE        TRUE       FALSE       FALSE
>   http/ftp     sockets      libxml        fifo      cledit       iconv
>       TRUE        TRUE        TRUE        TRUE       FALSE        TRUE
>        NLS       Rprof     profmem       cairo         ICU long.double
>      FALSE        TRUE        TRUE        TRUE        TRUE        TRUE
>    libcurl
>       TRUE
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Oct 28 07:41:24 2021
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 28 Oct 2021 11:11:24 +0530
Subject: [R] Error with RMySQL
Message-ID: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>

Dear R - users,

I have 2 databases on a MySQL server. I am able to access the old one
but not the freshly created one.

library(RMySQL)
# This one is the old one, I am able to access it,
> con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")

# This is the new one. I am getting an error.
> con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
Error in .local(drv, ...) :
  Failed to connect to database: Error: Access denied for user
'user2'@'myserver' (using password: YES)
>

Can someone please point me in the right direction? The error is not
clear. I do not think I have mistyped the credentials.

Many thanks,
Ashim


From drj|m|emon @end|ng |rom gm@||@com  Thu Oct 28 07:57:07 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Oct 2021 16:57:07 +1100
Subject: [R] Error with RMySQL
In-Reply-To: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
Message-ID: <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>

HI Ashim,
That error means that your user number or group is not allowed to
access it. Did you create the new one as a different user, maybe as
root?

Jim

On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear R - users,
>
> I have 2 databases on a MySQL server. I am able to access the old one
> but not the freshly created one.
>
> library(RMySQL)
> # This one is the old one, I am able to access it,
> > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
>
> # This is the new one. I am getting an error.
> > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> Error in .local(drv, ...) :
>   Failed to connect to database: Error: Access denied for user
> 'user2'@'myserver' (using password: YES)
> >
>
> Can someone please point me in the right direction? The error is not
> clear. I do not think I have mistyped the credentials.
>
> Many thanks,
> Ashim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Oct 28 08:00:46 2021
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 28 Oct 2021 11:30:46 +0530
Subject: [R] Error with RMySQL
In-Reply-To: <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
 <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
Message-ID: <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>

Dear Jim,

> That error means that your user number or group is not allowed to
> access it. Did you create the new one as a different user, maybe as
> root?

Here is what I did:

I switched to root in the MySQL Server, created a new user called
user2. I GRANTed user2 all permissions to access db2. I did NOT
restart the mysql server as I think the GRANT  does not need a restart
of the MySQL server.

> Jim
>
> On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear R - users,
> >
> > I have 2 databases on a MySQL server. I am able to access the old one
> > but not the freshly created one.
> >
> > library(RMySQL)
> > # This one is the old one, I am able to access it,
> > > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
> >
> > # This is the new one. I am getting an error.
> > > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> > Error in .local(drv, ...) :
> >   Failed to connect to database: Error: Access denied for user
> > 'user2'@'myserver' (using password: YES)
> > >
> >
> > Can someone please point me in the right direction? The error is not
> > clear. I do not think I have mistyped the credentials.
> >
> > Many thanks,
> > Ashim
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Oct 28 09:13:42 2021
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 28 Oct 2021 12:43:42 +0530
Subject: [R] Error with RMySQL
In-Reply-To: <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
 <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
 <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>
Message-ID: <CAC8=1eq4ii15V1pGuGSNnpqA5doyQS1dE63gmbRLqzt6T3cC4g@mail.gmail.com>

Dear Jim,

Can you please help me? I am a little confused here.

Best,
Ashim

On Thu, Oct 28, 2021 at 11:30 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Jim,
>
> > That error means that your user number or group is not allowed to
> > access it. Did you create the new one as a different user, maybe as
> > root?
>
> Here is what I did:
>
> I switched to root in the MySQL Server, created a new user called
> user2. I GRANTed user2 all permissions to access db2. I did NOT
> restart the mysql server as I think the GRANT  does not need a restart
> of the MySQL server.
>
> > Jim
> >
> > On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > >
> > > Dear R - users,
> > >
> > > I have 2 databases on a MySQL server. I am able to access the old one
> > > but not the freshly created one.
> > >
> > > library(RMySQL)
> > > # This one is the old one, I am able to access it,
> > > > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
> > >
> > > # This is the new one. I am getting an error.
> > > > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> > > Error in .local(drv, ...) :
> > >   Failed to connect to database: Error: Access denied for user
> > > 'user2'@'myserver' (using password: YES)
> > > >
> > >
> > > Can someone please point me in the right direction? The error is not
> > > clear. I do not think I have mistyped the credentials.
> > >
> > > Many thanks,
> > > Ashim
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Oct 28 09:55:06 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Oct 2021 18:55:06 +1100
Subject: [R] Error with RMySQL
In-Reply-To: <CAC8=1eq4ii15V1pGuGSNnpqA5doyQS1dE63gmbRLqzt6T3cC4g@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
 <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
 <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>
 <CAC8=1eq4ii15V1pGuGSNnpqA5doyQS1dE63gmbRLqzt6T3cC4g@mail.gmail.com>
Message-ID: <CA+8X3fXoVptBLcvrrwCOuxCvHqzkVB978hXk7DqEd_SYtFbgsA@mail.gmail.com>

Hi Ashim,
I was out for a while. I would first try to restart MySQL, then if
that didn't fix it, try logging in as root and accessing the database.
While I can't debug this at a distance, I'm pretty sure that the
database thinks that you aren't authorized to access it. If the
restart works, your problem is solved. If you have to log in as root,
it's more difficult to know how this happened.

Jim

On Thu, Oct 28, 2021 at 6:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Jim,
>
> Can you please help me? I am a little confused here.
>
> Best,
> Ashim
>
> On Thu, Oct 28, 2021 at 11:30 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear Jim,
> >
> > > That error means that your user number or group is not allowed to
> > > access it. Did you create the new one as a different user, maybe as
> > > root?
> >
> > Here is what I did:
> >
> > I switched to root in the MySQL Server, created a new user called
> > user2. I GRANTed user2 all permissions to access db2. I did NOT
> > restart the mysql server as I think the GRANT  does not need a restart
> > of the MySQL server.
> >
> > > Jim
> > >
> > > On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > >
> > > > Dear R - users,
> > > >
> > > > I have 2 databases on a MySQL server. I am able to access the old one
> > > > but not the freshly created one.
> > > >
> > > > library(RMySQL)
> > > > # This one is the old one, I am able to access it,
> > > > > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
> > > >
> > > > # This is the new one. I am getting an error.
> > > > > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> > > > Error in .local(drv, ...) :
> > > >   Failed to connect to database: Error: Access denied for user
> > > > 'user2'@'myserver' (using password: YES)
> > > > >
> > > >
> > > > Can someone please point me in the right direction? The error is not
> > > > clear. I do not think I have mistyped the credentials.
> > > >
> > > > Many thanks,
> > > > Ashim
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Oct 28 10:08:49 2021
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 28 Oct 2021 13:38:49 +0530
Subject: [R] Error with RMySQL
In-Reply-To: <CA+8X3fXoVptBLcvrrwCOuxCvHqzkVB978hXk7DqEd_SYtFbgsA@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
 <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
 <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>
 <CAC8=1eq4ii15V1pGuGSNnpqA5doyQS1dE63gmbRLqzt6T3cC4g@mail.gmail.com>
 <CA+8X3fXoVptBLcvrrwCOuxCvHqzkVB978hXk7DqEd_SYtFbgsA@mail.gmail.com>
Message-ID: <CAC8=1er2GBQO+2ZS1N4G9hK9p5kMuud9yJwV2Q+8WFRAym9oMw@mail.gmail.com>

Dear Jim,

Many thanks. I will try your suggestion and come back to you.

Many thanks,
Ashim

On Thu, Oct 28, 2021 at 1:25 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ashim,
> I was out for a while. I would first try to restart MySQL, then if
> that didn't fix it, try logging in as root and accessing the database.
> While I can't debug this at a distance, I'm pretty sure that the
> database thinks that you aren't authorized to access it. If the
> restart works, your problem is solved. If you have to log in as root,
> it's more difficult to know how this happened.
>
> Jim
>
> On Thu, Oct 28, 2021 at 6:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear Jim,
> >
> > Can you please help me? I am a little confused here.
> >
> > Best,
> > Ashim
> >
> > On Thu, Oct 28, 2021 at 11:30 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > >
> > > Dear Jim,
> > >
> > > > That error means that your user number or group is not allowed to
> > > > access it. Did you create the new one as a different user, maybe as
> > > > root?
> > >
> > > Here is what I did:
> > >
> > > I switched to root in the MySQL Server, created a new user called
> > > user2. I GRANTed user2 all permissions to access db2. I did NOT
> > > restart the mysql server as I think the GRANT  does not need a restart
> > > of the MySQL server.
> > >
> > > > Jim
> > > >
> > > > On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > > >
> > > > > Dear R - users,
> > > > >
> > > > > I have 2 databases on a MySQL server. I am able to access the old one
> > > > > but not the freshly created one.
> > > > >
> > > > > library(RMySQL)
> > > > > # This one is the old one, I am able to access it,
> > > > > > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
> > > > >
> > > > > # This is the new one. I am getting an error.
> > > > > > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> > > > > Error in .local(drv, ...) :
> > > > >   Failed to connect to database: Error: Access denied for user
> > > > > 'user2'@'myserver' (using password: YES)
> > > > > >
> > > > >
> > > > > Can someone please point me in the right direction? The error is not
> > > > > clear. I do not think I have mistyped the credentials.
> > > > >
> > > > > Many thanks,
> > > > > Ashim
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Thu Oct 28 10:19:22 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Thu, 28 Oct 2021 13:19:22 +0500
Subject: [R] Need help to print matrix with element and position
Message-ID: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>

I create a matrix of size 3x3 called mat_1 and then I want to iterate over
all the values one by one and print the element as well as the position in
the matrix:

My code is :

mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
3,byrow = TRUE)
mat_1
# Loop over my_matrix
for(row in 1:nrow(mat_1)) {
    for(col in 1:ncol(mat_1)) {
        print(mat_1[row, col])
    }
}

But I don't know how to print elements and positions as well of this matrix?

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Oct 28 10:54:03 2021
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 28 Oct 2021 14:24:03 +0530
Subject: [R] Error with RMySQL
In-Reply-To: <CAC8=1er2GBQO+2ZS1N4G9hK9p5kMuud9yJwV2Q+8WFRAym9oMw@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
 <CA+8X3fVq3YcemHWcg_1YymKxvpvm-kWVDxthQiUDzzY0ZTgE6w@mail.gmail.com>
 <CAC8=1eoJwkV2p2txRr-DwVMUUJ4uG3XBqE9PFf4JkqUXc4mgFQ@mail.gmail.com>
 <CAC8=1eq4ii15V1pGuGSNnpqA5doyQS1dE63gmbRLqzt6T3cC4g@mail.gmail.com>
 <CA+8X3fXoVptBLcvrrwCOuxCvHqzkVB978hXk7DqEd_SYtFbgsA@mail.gmail.com>
 <CAC8=1er2GBQO+2ZS1N4G9hK9p5kMuud9yJwV2Q+8WFRAym9oMw@mail.gmail.com>
Message-ID: <CAC8=1eqws0o8qLN-GDps42wdjtkLaRsNQYjpAVTke4BtZ0JQ=g@mail.gmail.com>

Dear Jim,

I restarted the mariadb.service but I am STILL not able to access the server.

I can access one database from one user but not from another user. The
credentials seem to be OK to me.

If I can figure this out I will post it here.

Many thanks,
Ashim

On Thu, Oct 28, 2021 at 1:38 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Jim,
>
> Many thanks. I will try your suggestion and come back to you.
>
> Many thanks,
> Ashim
>
> On Thu, Oct 28, 2021 at 1:25 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ashim,
> > I was out for a while. I would first try to restart MySQL, then if
> > that didn't fix it, try logging in as root and accessing the database.
> > While I can't debug this at a distance, I'm pretty sure that the
> > database thinks that you aren't authorized to access it. If the
> > restart works, your problem is solved. If you have to log in as root,
> > it's more difficult to know how this happened.
> >
> > Jim
> >
> > On Thu, Oct 28, 2021 at 6:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > >
> > > Dear Jim,
> > >
> > > Can you please help me? I am a little confused here.
> > >
> > > Best,
> > > Ashim
> > >
> > > On Thu, Oct 28, 2021 at 11:30 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > >
> > > > Dear Jim,
> > > >
> > > > > That error means that your user number or group is not allowed to
> > > > > access it. Did you create the new one as a different user, maybe as
> > > > > root?
> > > >
> > > > Here is what I did:
> > > >
> > > > I switched to root in the MySQL Server, created a new user called
> > > > user2. I GRANTed user2 all permissions to access db2. I did NOT
> > > > restart the mysql server as I think the GRANT  does not need a restart
> > > > of the MySQL server.
> > > >
> > > > > Jim
> > > > >
> > > > > On Thu, Oct 28, 2021 at 4:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> > > > > >
> > > > > > Dear R - users,
> > > > > >
> > > > > > I have 2 databases on a MySQL server. I am able to access the old one
> > > > > > but not the freshly created one.
> > > > > >
> > > > > > library(RMySQL)
> > > > > > # This one is the old one, I am able to access it,
> > > > > > > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user= "user1",password ="mypass1")
> > > > > >
> > > > > > # This is the new one. I am getting an error.
> > > > > > > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user= "user2",password="mypass2")
> > > > > > Error in .local(drv, ...) :
> > > > > >   Failed to connect to database: Error: Access denied for user
> > > > > > 'user2'@'myserver' (using password: YES)
> > > > > > >
> > > > > >
> > > > > > Can someone please point me in the right direction? The error is not
> > > > > > clear. I do not think I have mistyped the credentials.
> > > > > >
> > > > > > Many thanks,
> > > > > > Ashim
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Oct 28 10:58:09 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Oct 2021 19:58:09 +1100
Subject: [R] Need help to print matrix with element and position
In-Reply-To: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
References: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
Message-ID: <CA+8X3fWfikAST441-=YPimWrcNGMj7Lz8WdCvzmWueF-yNfooA@mail.gmail.com>

Hi Anas,
How about:

cat(row,col,mat_1[row,col],"\n")

Jim

On Thu, Oct 28, 2021 at 7:19 PM Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> I create a matrix of size 3x3 called mat_1 and then I want to iterate over
> all the values one by one and print the element as well as the position in
> the matrix:
>
> My code is :
>
> mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
> 3,byrow = TRUE)
> mat_1
> # Loop over my_matrix
> for(row in 1:nrow(mat_1)) {
>     for(col in 1:ncol(mat_1)) {
>         print(mat_1[row, col])
>     }
> }
>
> But I don't know how to print elements and positions as well of this matrix?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Thu Oct 28 11:01:39 2021
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Thu, 28 Oct 2021 14:01:39 +0500
Subject: [R] Need help to print matrix with element and position
In-Reply-To: <CA+8X3fWfikAST441-=YPimWrcNGMj7Lz8WdCvzmWueF-yNfooA@mail.gmail.com>
References: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
 <CA+8X3fWfikAST441-=YPimWrcNGMj7Lz8WdCvzmWueF-yNfooA@mail.gmail.com>
Message-ID: <CAG0CrLjyVcuKwfy+rMkDsZs9zTvhKMYLPhK9zoExbxW=ogWRfg@mail.gmail.com>

where should I place  cat(row,col,mat_1[row,col],"\n")?

On Thu, Oct 28, 2021 at 1:58 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Anas,
> How about:
>
> cat(row,col,mat_1[row,col],"\n")
>
> Jim
>
> On Thu, Oct 28, 2021 at 7:19 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> wrote:
> >
> > I create a matrix of size 3x3 called mat_1 and then I want to iterate
> over
> > all the values one by one and print the element as well as the position
> in
> > the matrix:
> >
> > My code is :
> >
> > mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
> > 3,byrow = TRUE)
> > mat_1
> > # Loop over my_matrix
> > for(row in 1:nrow(mat_1)) {
> >     for(col in 1:ncol(mat_1)) {
> >         print(mat_1[row, col])
> >     }
> > }
> >
> > But I don't know how to print elements and positions as well of this
> matrix?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Oct 28 11:04:22 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Oct 2021 20:04:22 +1100
Subject: [R] Need help to print matrix with element and position
In-Reply-To: <CAG0CrLjyVcuKwfy+rMkDsZs9zTvhKMYLPhK9zoExbxW=ogWRfg@mail.gmail.com>
References: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
 <CA+8X3fWfikAST441-=YPimWrcNGMj7Lz8WdCvzmWueF-yNfooA@mail.gmail.com>
 <CAG0CrLjyVcuKwfy+rMkDsZs9zTvhKMYLPhK9zoExbxW=ogWRfg@mail.gmail.com>
Message-ID: <CA+8X3fXrfsUiXkQpZ58yHMZxLR5fz6u1-QyinRG_14rpZK848Q@mail.gmail.com>

mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
3,byrow = TRUE)
mat_1
# Loop over my_matrix
for(row in 1:nrow(mat_1)) {
    for(col in 1:ncol(mat_1)) {
        cat(row,col,mat_1[row,col],"\n")
    }
}

On Thu, Oct 28, 2021 at 8:01 PM Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>
> where should I place  cat(row,col,mat_1[row,col],"\n")?
>
> On Thu, Oct 28, 2021 at 1:58 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Anas,
>> How about:
>>
>> cat(row,col,mat_1[row,col],"\n")
>>
>> Jim
>>
>> On Thu, Oct 28, 2021 at 7:19 PM Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>> >
>> > I create a matrix of size 3x3 called mat_1 and then I want to iterate over
>> > all the values one by one and print the element as well as the position in
>> > the matrix:
>> >
>> > My code is :
>> >
>> > mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
>> > 3,byrow = TRUE)
>> > mat_1
>> > # Loop over my_matrix
>> > for(row in 1:nrow(mat_1)) {
>> >     for(col in 1:ncol(mat_1)) {
>> >         print(mat_1[row, col])
>> >     }
>> > }
>> >
>> > But I don't know how to print elements and positions as well of this matrix?
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Oct 28 11:39:20 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 28 Oct 2021 10:39:20 +0100
Subject: [R] Need help to print matrix with element and position
In-Reply-To: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
References: <CAG0CrLg18Qoa_Qcx3EnBPoW3V-6NoDrWkcqmHb14LF6v8sCzsQ@mail.gmail.com>
Message-ID: <271cba91-1735-9506-c3ec-06d61f059fb1@sapo.pt>

Hello,

With no loops:


cbind(
   row = c(t(row(mat_1))),
   col = c(t(col(mat_1))),
   mat_1 = as.numeric(t(mat_1))
)


If the matrix entries are not numeric, use cbind.data.frame. This will 
keep the row and column numbers as numbers, the default cbind method 
would coerce them to the class of mat_1's elements.


cbind.data.frame(
   row = c(t(row(mat_1))),
   col = c(t(col(mat_1))),
   mat_1 = c(t(mat_1))
)


Hope this helps,

Rui Barradas


?s 09:19 de 28/10/21, Anas Jamshed escreveu:
> I create a matrix of size 3x3 called mat_1 and then I want to iterate over
> all the values one by one and print the element as well as the position in
> the matrix:
> 
> My code is :
> 
> mat_1= matrix( c('1','2','3','4','5','6','7','8','9'), nrow = 3, ncol =
> 3,byrow = TRUE)
> mat_1
> # Loop over my_matrix
> for(row in 1:nrow(mat_1)) {
>      for(col in 1:ncol(mat_1)) {
>          print(mat_1[row, col])
>      }
> }
> 
> But I don't know how to print elements and positions as well of this matrix?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 28 17:15:37 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Oct 2021 17:15:37 +0200
Subject: [R] R code in RData
In-Reply-To: <41B5E8D8-8EF5-4A8D-ADA6-B428C25878D5@dcn.davis.ca.us>
References: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>
 <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>
 <41B5E8D8-8EF5-4A8D-ADA6-B428C25878D5@dcn.davis.ca.us>
Message-ID: <24954.48793.602239.481408@stat.math.ethz.ch>

>>>>> Jeff Newmiller 
>>>>>     on Wed, 27 Oct 2021 11:43:08 -0700 writes:

    > Sounds right, though the OP appears to be assuming that the code used to generate the data objects in the file will also be there, and we need to be more definitive about that: it is not. Depending how the code was constructed, there may be useful information in the functions that were stored in the environment from which the save file was created, but this is not in any way guaranteed to be useful. In particular, there is no trace IN the RData file of which packages need to be loaded in order to access the objects stored in that RData file.
    > This is one of the reasons depending on RData files for archiving work is not advisable... and why putting code in R scripts or Sweave/knitr-based literate programming files IS recommended.

Yes, very strongly recommended.

Citation:

  The source code is real.  Objects are realizations of the source code.
  ------------------------  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

This has been the philosophy of using R-like systems
with ESS ("Emacs Speaks Statistics",  formerly 'S-mode') since the late 1980s,
also adopted by RStudio since 2011.


    > On October 27, 2021 10:47:14 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >> See ?load, but you may be confused. Strictly speaking, there is no code in
    >> an .Rdata file, only a (typically binary, but possibly ascii)
    >> representation of objects, usually as produced by ?save. Of course,
    >> functions are also objects, so that if you load a file with functions, the
    >> function code is available.
    >> 
    >> You can save and load command histories via ?savehistory, which, like ?save
    >> and ?load can usually be accessed through any GUI interface that you are
    >> using.
    >> 
    >> Warning: I believe the above is correct, but I may be wrong in at least
    >> some details, so give others a chance to reply and possibly correct.
    >> 
    >> Cheers,
    >> Bert
    >> 
    >> Bert Gunter
    >> 
    >> "The trouble with having an open mind is that people keep coming along and
    >> sticking things into it."
    >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    >> 
    >> 
    >> On Wed, Oct 27, 2021 at 10:18 AM Bogdan Tanasa <tanasa at gmail.com> wrote:
    >> 
    >>> Dear all, would you please advice :
    >>> 
    >>> I have an Rdata file, what is the way to print the R code that has been
    >>> used inside the Rdata file ?
    >>> 
    >>> thank you,
    >>> 
    >>> Bogdan
    >>> 
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide
    >>> http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >>> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > -- 
    > Sent from my phone. Please excuse my brevity.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Oct 28 17:24:46 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 28 Oct 2021 17:24:46 +0200
Subject: [R] R code in RData
In-Reply-To: <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>
References: <CA+JEM03916-RUiLAU3HhskpKcPu0myz6vP1SeLJV3Mo1-6+jkg@mail.gmail.com>
 <CAGxFJbSStbTBuUi4GamGn8NQKh4q=N2pgAtaRpdEBdhh83XO5w@mail.gmail.com>
Message-ID: <24954.49342.943790.21959@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Wed, 27 Oct 2021 10:47:14 -0700 writes:

    > See ?load, but you may be confused. Strictly speaking, there is no code in
    > an .Rdata file, only a (typically binary, but possibly ascii)
    > representation of objects, usually as produced by ?save. Of course,
    > functions are also objects, so that if you load a file with functions, the
    > function code is available.

    > You can save and load command histories via ?savehistory, which, like ?save
    > and ?load can usually be accessed through any GUI interface that you are
    > using.

    > Warning: I believe the above is correct, but I may be wrong in at least
    > some details, so give others a chance to reply and possibly correct.

    > Cheers,
    > Bert

    > Bert Gunter

In spite of really not recommending to work with .RData but
rather with R *scripts*  (or R Sweave / R markdown documents),
an often forgotten considerably more flexible and in that sense better
alternative to load() in such situations is  attach()
which creates an environment in which the objects are loaded and
attaches that to the search() path.

Example (from my current R console):

> save.image() # creates .RData
> attach(".RData")
> ls.str(pos=2)
logi :  Named logi [1:3] FALSE NA TRUE
Mlibrary : function (pkg, lib = NULL, check64.32 = TRUE, ...)  
ncF :  int [1:5, 1:3] 5 6 2 1 15 5 6 2 1 15 ...
nchars : function (x, ...)  
ncT :  int [1:5, 1:3] 5 6 NA 1 15 5 6 NA 1 15 ...
x :  chr [1:5] "asfef" "qwerty" NA "b" "stuff.blah.yech"
> 

So, indeed,  ls.str()  comes handy as well..

Best,
Martin


From jrkr|de@u @end|ng |rom gm@||@com  Thu Oct 28 17:57:06 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Thu, 28 Oct 2021 11:57:06 -0400
Subject: [R] 
 Error: the leading minor of order 6 is not positive definite
In-Reply-To: <HKAPR01MB373096AF40371243EF9A3BB2DB819@HKAPR01MB3730.apcprd01.prod.exchangelabs.com>
References: <HKAPR01MB373096AF40371243EF9A3BB2DB819@HKAPR01MB3730.apcprd01.prod.exchangelabs.com>
Message-ID: <CAKZQJMA=+jz9iUG0HTByTo3m_dbnZg+teVEq6ArM42duL5c46A@mail.gmail.com>

I think we need the code you are running, any error messages you are
getting and some sample data. A handy way to supply sample data is to
use the dput() function. See ?dput.  If you have a very large data set
then something like head(dput(myfile), 100) will likely supply enough
data for us to work with.

On Mon, 25 Oct 2021 at 16:26, Sandhya Prakash
<Sandhyaprakashyj97 at outlook.com> wrote:
>
> Hi I'm too running a canonical correlation code but I'm getting my error like this can you please help me
>
> Get Outlook for Android<https://aka.ms/AAb9ysg>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From ken @end|ng |rom pubbox@net  Thu Oct 28 07:53:59 2021
From: ken @end|ng |rom pubbox@net (Ken Peng)
Date: Thu, 28 Oct 2021 13:53:59 +0800
Subject: [R] Error with RMySQL
In-Reply-To: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
References: <CAC8=1eodWL8o8o46Hoid2ggxkm-Xu1xAwR9_n9C1cA9WYXqDcQ@mail.gmail.com>
Message-ID: <CALUE4BLQUPAHzMCuJ84FVY-3fXYHq7R3tCy2UVDWdZs7DppBPw@mail.gmail.com>

It seems like mysql server doesn't open the right authentication for your
access, such as user or host permissions.

Thanks.

On Thu, Oct 28, 2021 at 1:42 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear R - users,
>
> I have 2 databases on a MySQL server. I am able to access the old one
> but not the freshly created one.
>
> library(RMySQL)
> # This one is the old one, I am able to access it,
> > con1<- dbConnect(MySQL(),host= "myserver", db="db1", user=
> "user1",password ="mypass1")
>
> # This is the new one. I am getting an error.
> > con2 <- dbConnect(MySQL(),host= "myserver", db="db2", user=
> "user2",password="mypass2")
> Error in .local(drv, ...) :
>   Failed to connect to database: Error: Access denied for user
> 'user2'@'myserver' (using password: YES)
> >
>
> Can someone please point me in the right direction? The error is not
> clear. I do not think I have mistyped the credentials.
>
> Many thanks,
> Ashim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w@|t @end|ng |rom purp|eem@||@com  Thu Oct 28 08:57:14 2021
From: w@|t @end|ng |rom purp|eem@||@com (Catherine Walt)
Date: Thu, 28 Oct 2021 06:57:14 +0000
Subject: [R] R vs Numpy
Message-ID: <35301f35d969a9f72b26eab90be59019@purpleemail.com>

Hello members,

I am familiar with python's Numpy.
Now I am looking into R language.
What is the main difference between these two languages? including advantages or disadvantages.

Thanks.


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Oct 28 20:22:00 2021
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 28 Oct 2021 14:22:00 -0400
Subject: [R] R vs Numpy
In-Reply-To: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <f212a193-d3e4-e6c2-7ad0-75a6dd7d64ca@gmail.com>

https://www.ibm.com/cloud/blog/python-vs-r

On 2021-10-28 2:57 a.m., Catherine Walt wrote:
> Hello members,
> 
> I am familiar with python's Numpy.
> Now I am looking into R language.
> What is the main difference between these two languages? including advantages or disadvantages.
> 
> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Thu Oct 28 20:24:44 2021
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Thu, 28 Oct 2021 18:24:44 +0000
Subject: [R] R vs Numpy
In-Reply-To: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <MN2PR03MB5167166BE378ECCD41EC29B8E2869@MN2PR03MB5167.namprd03.prod.outlook.com>

Catherine,

R is a program that is designed for the statistical analysis and visual display of data. Advantages and disadvantages depend on what you want to do with the language. 

John


________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Catherine Walt <walt at purpleemail.com>
Sent: Thursday, October 28, 2021 2:57 AM
To: r-help at r-project.org
Subject: [R] R vs Numpy

Hello members,

I am familiar with python's Numpy.
Now I am looking into R language.
What is the main difference between these two languages? including advantages or disadvantages.

Thanks.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam11.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7Cd7ce49543170430f10a208d99a3e8bc4%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637710416263711233%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=ada4s6jHFFpT09%2BnKV0hhXgA4dczZ88wNqqjMGED7Zg%3D&amp;reserved=0
PLEASE do read the posting guide https://nam11.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=04%7C01%7CJSorkin%40som.umaryland.edu%7Cd7ce49543170430f10a208d99a3e8bc4%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637710416263711233%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000&amp;sdata=qNxgDcGORjIZ4Q3BTkvdQ%2BRwODlFsFpFxwZCNyx06Vk%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Oct 28 20:43:35 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 28 Oct 2021 11:43:35 -0700
Subject: [R] R vs Numpy
In-Reply-To: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <5A26FC97-967C-4844-800D-71CE55D685DB@dcn.davis.ca.us>

This is dangerously close to off topic, or at least it could be fuel for divisive argument rather than informed discussion (most readers here might be short on details of NumPy and long on details regarding R).

Have you used a search engine? Google found https://www.r-bloggers.com/2011/03/a-short-side-by-side-comparison-of-the-r-and-numpy-array-types/ for me.

Under the hood, R and NumPy often use the same compiled code for numerical algorithms, so to some degree it is more a matter of taste in how you get at those algorithms.

On October 27, 2021 11:57:14 PM PDT, Catherine Walt <walt at purpleemail.com> wrote:
>Hello members,
>
>I am familiar with python's Numpy.
>Now I am looking into R language.
>What is the main difference between these two languages? including advantages or disadvantages.
>
>Thanks.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Oct 28 21:32:52 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 28 Oct 2021 15:32:52 -0400
Subject: [R] R vs Numpy
In-Reply-To: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <011101d7cc32$99d98700$cd8c9500$@verizon.net>

I am not sure your overall question fits into this forum but a brief
internet search can find plenty of info.

But in brief, R is a language in which much of what numpy does was built in
from the start and many things are vectorized. Much of what the python
pandas language does is also part of native R. There are additional packages
(python called them modules) freely available that greatly extend those
capabilities and I doubt there is very much you can do in numpy that cannot
also often easily be done in R.

Realistically, there are several reasons the numpy module is so commonly
used in python. They left something like vectors out of the language. Yes,
they have dictionaries and lists and sets and all kinds of objects. So numpy
was made mostly in C to provide numeric processing of things that are more
like vectors efficiently. In R, everything is a vector as in a simple
variable is just a vector of length one!

I program in both and in other languages as many do. Reasons to choose one
or another vary. Python can do many things easily and with complexity and is
a rather full-blown and complex language with real object-oriented
capabilities and also functional programming. It is interpreted but also has
a way to save partially compiled code. R is pretty much all interpreted
albeit many things are written I C or C++ pr other compiled languages and
stuffed into libraries. 

One main reason to choose is programming style but there are TONS of
differences that can bite you such as R sometimes deferring evaluation of
code which can be an advantage or the opposite. But a huge reason I think
that people choose one or the other is the availability of packages that do
much of what they want. Some, for example, love a set of packages they call
the tidyverse and do much of their work largely within it rather than base
R. Many love the graphics package called ggplot.

But over time, I see more and more functionality available within the Python
community that rivals or perhaps exceeds such as the machine learning tools.

I have an interesting solution I sometimes use as you can run programs in R
using a package that allows the same data to be accessed back and forth
between an attached R interpreter and a Python interpreter. So if you want
to use python features like dictionaries and list comprehensions to massage
the data then have R do additional things and perhaps make graphs, you can
get some of both worlds.

As noted, a detailed answer is way beyond here. R has packages that probably
let you add things and it has too many object-oriented subsystems, most of
them not complete.

Good Luck,

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Catherine Walt
Sent: Thursday, October 28, 2021 2:57 AM
To: r-help at r-project.org
Subject: [R] R vs Numpy

Hello members,

I am familiar with python's Numpy.
Now I am looking into R language.
What is the main difference between these two languages? including
advantages or disadvantages.

Thanks.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Oct 28 21:54:45 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 28 Oct 2021 21:54:45 +0200
Subject: [R] R vs Numpy
In-Reply-To: <35301f35d969a9f72b26eab90be59019@purpleemail.com> (Catherine
 Walt's message of "Thu, 28 Oct 2021 06:57:14 +0000")
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <87y26cncvu.fsf@enricoschumann.net>

On Thu, 28 Oct 2021, Catherine Walt writes:

> Hello members,
>
> I am familiar with python's Numpy.
> Now I am looking into R language.
> What is the main difference between these two languages? including advantages or disadvantages.
>
> Thanks.
>

Perhaps also of interest:
    https://github.com/matloff/R-vs.-Python-for-Data-Science


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ken @end|ng |rom pubbox@net  Fri Oct 29 08:39:07 2021
From: ken @end|ng |rom pubbox@net (Ken Peng)
Date: Fri, 29 Oct 2021 14:39:07 +0800
Subject: [R] generate random numeric
Message-ID: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>

I saw runif(1) can generate a random num, is this the true random?

> runif(1)
[1] 0.8945383

What's the other better method?

Thank you.

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Fri Oct 29 08:50:56 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Fri, 29 Oct 2021 02:50:56 -0400
Subject: [R] generate random numeric
In-Reply-To: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
References: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
Message-ID: <CAPcHnpQanSEiP1nrneEaYY6=XySSfTWFLn1Tmu3ZAXbpmBDXiQ@mail.gmail.com>

It might not be random, depending upon a seed being used (usually by
set.seed or RNGkind).

However, it's the best method for generating a random number within a
specified range without weights.

If you want weights, there are many other random number generation
functions, most notably rnorm. You can find a lot more in the stats
package.


On Fri, Oct 29, 2021, 02:39 Ken Peng <ken at pubbox.net> wrote:

> I saw runif(1) can generate a random num, is this the true random?
>
> > runif(1)
> [1] 0.8945383
>
> What's the other better method?
>
> Thank you.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Oct 29 08:55:04 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 29 Oct 2021 09:55:04 +0300
Subject: [R] R vs Numpy
In-Reply-To: <87y26cncvu.fsf@enricoschumann.net>
References: <35301f35d969a9f72b26eab90be59019@purpleemail.com>
 <87y26cncvu.fsf@enricoschumann.net>
Message-ID: <CAGgJW74fMZ6bnOw2x6USFJYh=VKfuxaXa6Mp57OMrtBe2UXHdg@mail.gmail.com>

I think a Cheat Sheet that gives a side-by-side comparison of numpy
and R would be relevant here.

I found something like that for pandas and R (link below), but not for numpy.
https://github.com/yl3738/Python-vs.-R-Cheatsheet/blob/main/community%20contribution_CC%20group14.pdf


On Thu, Oct 28, 2021 at 10:55 PM Enrico Schumann <es at enricoschumann.net> wrote:
>
> On Thu, 28 Oct 2021, Catherine Walt writes:
>
> > Hello members,
> >
> > I am familiar with python's Numpy.
> > Now I am looking into R language.
> > What is the main difference between these two languages? including advantages or disadvantages.
> >
> > Thanks.
> >
>
> Perhaps also of interest:
>     https://github.com/matloff/R-vs.-Python-for-Data-Science
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w@|t @end|ng |rom purp|eem@||@com  Fri Oct 29 09:06:14 2021
From: w@|t @end|ng |rom purp|eem@||@com (Catherine Walt)
Date: Fri, 29 Oct 2021 07:06:14 +0000
Subject: [R] customize the step value
Message-ID: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>

dear members,

Sorry I am newbie on R.
as we saw below:

> 1.5:3.5
[1] 1.5 2.5 3.5

How can I make the step to 0.5?
I want the result:

1.5 2.0 2.5 3.0 3.5

Thanks.
Cathy


From w@|t @end|ng |rom purp|eem@||@com  Fri Oct 29 09:14:21 2021
From: w@|t @end|ng |rom purp|eem@||@com (Catherine Walt)
Date: Fri, 29 Oct 2021 07:14:21 +0000
Subject: [R] R vs Numpy
In-Reply-To: <011101d7cc32$99d98700$cd8c9500$@verizon.net>
References: <011101d7cc32$99d98700$cd8c9500$@verizon.net>
 <35301f35d969a9f72b26eab90be59019@purpleemail.com>
Message-ID: <110202a77066a64e1f8b4a06f23e98ac@purpleemail.com>

Thanks for Avi. and all other people's helps.

I am using Numpy primarily for machine learning, for example, Keras tasks can use Numpy heavily.

Now I got a task to analyze the BIO data, for which the Prof tell me R is better.
So I am looking into R. and I was just serious if Numpy can handle the BIO data well?

Regards
Cathy



October 29, 2021 3:32 AM, "Avi Gross via R-help" <r-help at r-project.org> wrote:

> I am not sure your overall question fits into this forum but a brief
> internet search can find plenty of info.
> 
> But in brief, R is a language in which much of what numpy does was built in
> from the start and many things are vectorized. Much of what the python
> pandas language does is also part of native R. There are additional packages
> (python called them modules) freely available that greatly extend those
> capabilities and I doubt there is very much you can do in numpy that cannot
> also often easily be done in R.
> 
> Realistically, there are several reasons the numpy module is so commonly
> used in python. They left something like vectors out of the language. Yes,
> they have dictionaries and lists and sets and all kinds of objects. So numpy
> was made mostly in C to provide numeric processing of things that are more
> like vectors efficiently. In R, everything is a vector as in a simple
> variable is just a vector of length one!
> 
> I program in both and in other languages as many do. Reasons to choose one
> or another vary. Python can do many things easily and with complexity and is
> a rather full-blown and complex language with real object-oriented
> capabilities and also functional programming. It is interpreted but also has
> a way to save partially compiled code. R is pretty much all interpreted
> albeit many things are written I C or C++ pr other compiled languages and
> stuffed into libraries. 
> 
> One main reason to choose is programming style but there are TONS of
> differences that can bite you such as R sometimes deferring evaluation of
> code which can be an advantage or the opposite. But a huge reason I think
> that people choose one or the other is the availability of packages that do
> much of what they want. Some, for example, love a set of packages they call
> the tidyverse and do much of their work largely within it rather than base
> R. Many love the graphics package called ggplot.
> 
> But over time, I see more and more functionality available within the Python
> community that rivals or perhaps exceeds such as the machine learning tools.
> 
> I have an interesting solution I sometimes use as you can run programs in R
> using a package that allows the same data to be accessed back and forth
> between an attached R interpreter and a Python interpreter. So if you want
> to use python features like dictionaries and list comprehensions to massage
> the data then have R do additional things and perhaps make graphs, you can
> get some of both worlds.
> 
> As noted, a detailed answer is way beyond here. R has packages that probably
> let you add things and it has too many object-oriented subsystems, most of
> them not complete.
> 
> Good Luck,
> 
> Avi
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Catherine Walt
> Sent: Thursday, October 28, 2021 2:57 AM
> To: r-help at r-project.org
> Subject: [R] R vs Numpy
> 
> Hello members,
> 
> I am familiar with python's Numpy.
> Now I am looking into R language.
> What is the main difference between these two languages? including
> advantages or disadvantages.
> 
> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Fri Oct 29 09:17:14 2021
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Fri, 29 Oct 2021 09:17:14 +0200
Subject: [R] customize the step value
In-Reply-To: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
Message-ID: <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>

seq(1.5,3.5,0.5)

The docs for seq will show you many more options.

> On 29.10.2021, at 09:06, Catherine Walt <walt at purpleemail.com> wrote:
> 
> dear members,
> 
> Sorry I am newbie on R.
> as we saw below:
> 
>> 1.5:3.5
> [1] 1.5 2.5 3.5
> 
> How can I make the step to 0.5?
> I want the result:
> 
> 1.5 2.0 2.5 3.0 3.5
> 
> Thanks.
> Cathy
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Oct 29 10:34:54 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 29 Oct 2021 08:34:54 +0000
Subject: [R] customize the step value
In-Reply-To: <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
 <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
Message-ID: <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>

Hi

One has to be careful when using fractions in seq step.

Although it works for 0.5
> (seq(0,10, .5) - round(seq(0,10,.5),2))==0
 [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
TRUE
[16] TRUE TRUE TRUE TRUE TRUE TRUE

in case of 0.3 (or others) it does not always result in expected values (see
FAQ 7.31 for explanation)

> (seq(0,10, .3) - round(seq(0,10,.3),2))==0
 [1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
[13] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE
[25] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
>
Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Erich
Subscriptions
> Sent: Friday, October 29, 2021 9:17 AM
> To: Catherine Walt <walt at purpleemail.com>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] customize the step value
> 
> seq(1.5,3.5,0.5)
> 
> The docs for seq will show you many more options.
> 
> > On 29.10.2021, at 09:06, Catherine Walt <walt at purpleemail.com> wrote:
> >
> > dear members,
> >
> > Sorry I am newbie on R.
> > as we saw below:
> >
> >> 1.5:3.5
> > [1] 1.5 2.5 3.5
> >
> > How can I make the step to 0.5?
> > I want the result:
> >
> > 1.5 2.0 2.5 3.0 3.5
> >
> > Thanks.
> > Cathy
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Oct 29 15:07:31 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Oct 2021 09:07:31 -0400
Subject: [R] customize the step value
In-Reply-To: <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
 <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
 <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>
Message-ID: <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>

On 29/10/2021 4:34 a.m., PIKAL Petr wrote:
> Hi
> 
> One has to be careful when using fractions in seq step.
> 
> Although it works for 0.5
>> (seq(0,10, .5) - round(seq(0,10,.5),2))==0
>   [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
> TRUE
> [16] TRUE TRUE TRUE TRUE TRUE TRUE
> 
> in case of 0.3 (or others) it does not always result in expected values (see
> FAQ 7.31 for explanation)
> 
>> (seq(0,10, .3) - round(seq(0,10,.3),2))==0
>   [1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
> [13] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE
> [25] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE


Petr is right, it's unsafe to use fractional values for the step.  0.5 
works because it has a power of 2 in the denominator and so does the 
start value, but it's easy to make mistakes when you rely on that (e.g. 
changing the step size from 0.5 to 0.3 would break things).

A better idea is to modify a sequence of integers.  For example, to get 
1.5 to 3.5 by 0.5, you can do (3:7)*0.5, and for 0 to 3 by 0.3, use 
(0:10)*0.3.

Duncan Murdoch


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Oct 29 15:49:36 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Oct 2021 06:49:36 -0700
Subject: [R] generate random numeric
In-Reply-To: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
References: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
Message-ID: <160C9B09-9C54-4DE6-B041-AF558867C919@dcn.davis.ca.us>

It is difficult to do "truly random" number generation with computers, but fortunately number sequences that appear random but progress consistently from an initial seed value (?set.seed) are actually much more useful for analysis purposes than true randomness is.

On October 28, 2021 11:39:07 PM PDT, Ken Peng <ken at pubbox.net> wrote:
>I saw runif(1) can generate a random num, is this the true random?
>
>> runif(1)
>[1] 0.8945383
>
>What's the other better method?
>
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Oct 29 17:04:20 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 29 Oct 2021 17:04:20 +0200
Subject: [R] customize the step value
In-Reply-To: <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
 <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
 <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>
 <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>
Message-ID: <24956.3444.258317.466788@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 29 Oct 2021 09:07:31 -0400 writes:

    > On 29/10/2021 4:34 a.m., PIKAL Petr wrote:
    >> Hi
    >> 
    >> One has to be careful when using fractions in seq step.
    >> 
    >> Although it works for 0.5
    >>> (seq(0,10, .5) - round(seq(0,10,.5),2))==0
    >> [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
    >> TRUE
    >> [16] TRUE TRUE TRUE TRUE TRUE TRUE
    >> 
    >> in case of 0.3 (or others) it does not always result in expected values (see
    >> FAQ 7.31 for explanation)
    >> 
    >>> (seq(0,10, .3) - round(seq(0,10,.3),2))==0
    >> [1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
    >> [13] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE
    >> [25] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE


    > Petr is right, it's unsafe to use fractional values for the step.  0.5 
    > works because it has a power of 2 in the denominator and so does the 
    > start value, but it's easy to make mistakes when you rely on that (e.g. 
    > changing the step size from 0.5 to 0.3 would break things).

    > A better idea is to modify a sequence of integers.  For example, to get 
    > 1.5 to 3.5 by 0.5, you can do (3:7)*0.5, and for 0 to 3 by 0.3, use 
    > (0:10)*0.3.


Well, but you will not get truly equidistant (to the last bit)
sequences also by that and people who are not aware of
FAQ 7.31  and its consequences do wrongly assume that

length(unique(diff(seqVec))) == 1

for any      seqVec <-  k * seq(....)   # k a "scalar" (of length 1)

but the reality of floating point arithmetic can be quite
different than pure math :

In this case and on my platform the two ways to construct the
sequence are even identical:

> identical((0:10)*0.3, seq(0, 3, by=.3))
[1] TRUE
> sv <- (0:10)*0.3
> length(unique(diff(sv))) # you'd like |-->  1 (the number 0.3 !)
[1] 5
>

Martin


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Oct 29 17:20:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 29 Oct 2021 16:20:01 +0100
Subject: [R] customize the step value
In-Reply-To: <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
 <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
 <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>
 <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>
Message-ID: <e778f584-4937-c9c9-e935-3f423fdd1d30@sapo.pt>

Hello,

?s 14:07 de 29/10/21, Duncan Murdoch escreveu:
> On 29/10/2021 4:34 a.m., PIKAL Petr wrote:
>> Hi
>>
>> One has to be careful when using fractions in seq step.
>>
>> Although it works for 0.5
>>> (seq(0,10, .5) - round(seq(0,10,.5),2))==0
>> ? [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE 
>> TRUE
>> TRUE
>> [16] TRUE TRUE TRUE TRUE TRUE TRUE
>>
>> in case of 0.3 (or others) it does not always result in expected 
>> values (see
>> FAQ 7.31 for explanation)
>>
>>> (seq(0,10, .3) - round(seq(0,10,.3),2))==0
>> ? [1]? TRUE? TRUE? TRUE FALSE? TRUE? TRUE FALSE? TRUE? TRUE FALSE  
>> TRUE? TRUE
>> [13] FALSE? TRUE? TRUE? TRUE? TRUE? TRUE FALSE? TRUE? TRUE? TRUE? TRUE 
>> FALSE
>> [25] FALSE? TRUE? TRUE? TRUE? TRUE? TRUE? TRUE FALSE? TRUE? TRUE
> 
> 
> Petr is right, it's unsafe to use fractional values for the step.? 0.5 
> works because it has a power of 2 in the denominator and so does the 
> start value, but it's easy to make mistakes when you rely on that (e.g. 
> changing the step size from 0.5 to 0.3 would break things).
> 
> A better idea is to modify a sequence of integers.? For example, to get 
> 1.5 to 3.5 by 0.5, you can do (3:7)*0.5, and for 0 to 3 by 0.3, use 
> (0:10)*0.3.

But even this is not safe.
Perhaps the most frequent sequence causing problems (R-Help questions) 
is the one from 0 to 1 by 0.1 and why it always returns FALSE when 
tested against certain values such as 0.6.
And it also fails to create it with (0:10)*0.1.


x <- seq(0, 1, by = 0.1)
any(x == 0.6)
#[1] FALSE

y <- (0:10)*0.1
any(y == 0.6)
#[1] FALSE

all(x == y)
#[1] TRUE


Off-topic: FAQ 7.31 addresses this.

Hope this helps,

Rui Barradas

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Oct 29 17:36:14 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 29 Oct 2021 08:36:14 -0700
Subject: [R] Probably off topic but I hope amusing
Message-ID: <CAGxFJbTpp+tC2mQECS1owYATgD7BeAjpnDi27DfVeu3witsL=w@mail.gmail.com>

There was a little discussion today (yet again) about floating point
arithmetic. Perhaps related to this, I subscribe to the online NYTimes,
which flashes U.S. stock index prices at the top of its home page. Today,
instead of the Nasdaq price being flashed, there was this:

undefined-NaN%

I wonder if this means that R is being used as a backend for this or
whether this way of displaying what I think is 0/0 in FP is common.

Anyway, what do you think most readers reaction to this was?!

Best to all,
Bert

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Oct 29 18:03:08 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Oct 2021 12:03:08 -0400
Subject: [R] customize the step value
In-Reply-To: <24956.3444.258317.466788@stat.math.ethz.ch>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
 <33317FE3-9F16-48F6-8FF5-55B6CFFF1FF1@neuwirth.priv.at>
 <f151ee8f3b3040baae95747cb17c5e95@SRVEXCHCM1302.precheza.cz>
 <576db0d7-64d3-144c-a7f9-c75004143c32@gmail.com>
 <24956.3444.258317.466788@stat.math.ethz.ch>
Message-ID: <fa901d94-a394-7da6-7b7e-cbc6b9cdf6c4@gmail.com>

On 29/10/2021 11:04 a.m., Martin Maechler wrote:
>>>>>> Duncan Murdoch
>>>>>>      on Fri, 29 Oct 2021 09:07:31 -0400 writes:
> 
>      > On 29/10/2021 4:34 a.m., PIKAL Petr wrote:
>      >> Hi
>      >>
>      >> One has to be careful when using fractions in seq step.
>      >>
>      >> Although it works for 0.5
>      >>> (seq(0,10, .5) - round(seq(0,10,.5),2))==0
>      >> [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
>      >> TRUE
>      >> [16] TRUE TRUE TRUE TRUE TRUE TRUE
>      >>
>      >> in case of 0.3 (or others) it does not always result in expected values (see
>      >> FAQ 7.31 for explanation)
>      >>
>      >>> (seq(0,10, .3) - round(seq(0,10,.3),2))==0
>      >> [1]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
>      >> [13] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE
>      >> [25] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE
> 
> 
>      > Petr is right, it's unsafe to use fractional values for the step.  0.5
>      > works because it has a power of 2 in the denominator and so does the
>      > start value, but it's easy to make mistakes when you rely on that (e.g.
>      > changing the step size from 0.5 to 0.3 would break things).
> 
>      > A better idea is to modify a sequence of integers.  For example, to get
>      > 1.5 to 3.5 by 0.5, you can do (3:7)*0.5, and for 0 to 3 by 0.3, use
>      > (0:10)*0.3.
> 
> 
> Well, but you will not get truly equidistant (to the last bit)
> sequences also by that and people who are not aware of
> FAQ 7.31  and its consequences do wrongly assume that

No, that would be impossible.

> 
> length(unique(diff(seqVec))) == 1
> 
> for any      seqVec <-  k * seq(....)   # k a "scalar" (of length 1)
> 
> but the reality of floating point arithmetic can be quite
> different than pure math :
> 
> In this case and on my platform the two ways to construct the
> sequence are even identical:
> 
>> identical((0:10)*0.3, seq(0, 3, by=.3))
> [1] TRUE
>> sv <- (0:10)*0.3
>> length(unique(diff(sv))) # you'd like |-->  1 (the number 0.3 !)
> [1] 5

But I suspect that's not guaranteed for every step size.

The really serious problem (which R tries hard to avoid, but again I 
doubt it's guaranteed) is to ask for

   seq(a, b, step = (b-a)/n)

for an integer n and get a sequence that stops one step early and 
doesn't include b.   For this case, I would always use the replacement

   a + (0:n)*(b - a)/n

I suspect this is also not guaranteed to return b, but it is guaranteed 
to return a value very close to it.

Duncan Murdoch


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Oct 29 18:16:17 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 29 Oct 2021 12:16:17 -0400
Subject: [R] customize the step value
In-Reply-To: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
References: <0ee4778e20f60611c62abbf0e29dd3ba@purpleemail.com>
Message-ID: <012f01d7cce0$4d840fc0$e88c2f40$@verizon.net>

As others have replied, the customary way is to use the seq() function that
takes additional arguments besides a from= and a to= such as by= to specify
the step size and two others sometimes handy of length.out= and along.with=

In your case seq(from=1.5, to=3.5, by=0.5) works as well as the shorter
positional version of seq(1.5, 3.5, 0.5)

But as others have noted, certain calculations with floating point
arithmetic in pretty much any language can be imprecise in the final bits. I
doubt it matters for you but there are ways to do a comparison that allows
for a little leeway and still tests equal. 

The suggestion others have made is a good choice too, especially when you
know exactly what you need in advance and can adjust:

> seq(1.5, 3.5, 0.5)
[1] 1.5 2.0 2.5 3.0 3.5
> seq(3, 7) / 2
[1] 1.5 2.0 2.5 3.0 3.5
> 0.5*(3:7)
[1] 1.5 2.0 2.5 3.0 3.5


If you do this often and for larger vectors and efficiency matters, consider
using seq.int() in the latter cases as it is much faster when working on
just integers. 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Catherine Walt
Sent: Friday, October 29, 2021 3:06 AM
To: R mailing list <r-help at r-project.org>
Subject: [R] customize the step value

dear members,

Sorry I am newbie on R.
as we saw below:

> 1.5:3.5
[1] 1.5 2.5 3.5

How can I make the step to 0.5?
I want the result:

1.5 2.0 2.5 3.0 3.5

Thanks.
Cathy

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Oct 29 18:29:41 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 29 Oct 2021 12:29:41 -0400
Subject: [R] generate random numeric
In-Reply-To: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
References: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
Message-ID: <fbbe40aa-ad8f-78c8-64e4-0e69370950ea@me.com>

Ken Peng wrote on 10/29/21 2:39 AM:
> I saw runif(1) can generate a random num, is this the true random?
> 
>> runif(1)
> [1] 0.8945383
> 
> What's the other better method?
> 
> Thank you.
> 
Hi,

You do not indicate your use case, and that can be important.

The numbers generated by R's default RNGs are "pseudo random" (PRNGs), 
which means that for most general purpose applications, such as common 
Monte Carlo simulations or randomized clinical trial treatment 
allocations, as suggested by the other replies, they will work fine.

As PRNGs, the actual pseudo-random permutations can be replicated by 
setting the same 'seed' value each cycle for the PRNG in use.

For example:

 > runif(5)
[1] 0.6238892 0.8307422 0.4955693 0.4182567 0.9818217

 > runif(5)
[1] 0.2423170 0.4129066 0.9213000 0.8290358 0.1644403

will yield two different, pseudo-random, sequences.

However:

 > set.seed(1)
 > runif(5)
[1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819

 > set.seed(1)
 > runif(5)
[1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819

will yield the same sequence given the use of the same seed value before 
each call to runif().

Thus, the sequences will appear to be random, but given a specific 
algorithm and seed value, they are deterministic.

That repeatable behavior can be important if one wishes to come back at 
some future date and replicate the exact same output sequence, presuming 
other factors have not changed in the mean time, such as occurred with R 
version 3.6.0, which is referenced in ?Random, where a default changed 
to improve behavior.

Also, some R functions may use simulation or resampling approaches to 
create various parameters, and you may wish to replicate the same result 
with each iteration. Setting the seed value prior to the relevant 
function call can enable that.

Also, review the resources at https://www.random.org for additional 
references on the differences between PRNGs and other implementations, 
especially if you might need something closer to a "true" RNG for more 
rigorous work.

Regards,

Marc Schwartz


From ton|ght@then|ght @end|ng |rom gm@||@com  Fri Oct 29 19:21:45 2021
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Fri, 29 Oct 2021 10:21:45 -0700
Subject: [R] Format utils::bibentry with a 'corporate name'
Message-ID: <CADkXsV2f6hMGFAAiebC0HyJ6dYF5Vn=4aViwxk_dp=s43TjV7w@mail.gmail.com>

Hi all,

Does anyone know of a way to force utils::bibentry to mimic the BibTex
behaviour of using double { to force a "corporate name" in the author
field to print correctly? For example take this bibentry:

entry <- utils::bibentry(
  bibtype = "Manual",
  title = "The Thing",
  author = "The Data People",
  organization = "The Data Org",
  year = format(Sys.Date(), "%Y")
)

entry
#> People TD (2021). _The Thing_. The Data Org.
print(entry, style = "citation")
#>
#> People TD (2021). _The Thing_. The Data Org.
#>
#> A BibTeX entry for LaTeX users is
#>
#>   @Manual{,
#>     title = {The Thing},
#>     author = {The Data People},
#>     organization = {The Data Org},
#>     year = {2021},
#>   }

I can simply add "{" right in the author string which then passes that
to the Bibtex entry but the author field is still thinking it is a
person with a name and I also get some warnings:

entry <- utils::bibentry(
  bibtype = "Manual",
  title = "The Thing",
  author = "{The Data People}",
  organization = "The Data Org",
  year = format(Sys.Date(), "%Y")
)


print(entry, style = "citation")
#> Warning in parseLatex(x): x:1: unexpected '}'
#> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
#> Warning in parseLatex(x): x:1: unexpected '}'
#> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
#> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
"UTF-8", :
#> <connection>:1: unexpected '}'
#> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
"UTF-8", : <connection>:4: unexpected END_OF_INPUT 'The Data Org.
#> '
#>
#> People D (2021). _The Thing_. The Data Org.
#>
#> A BibTeX entry for LaTeX users is
#>
#>   @Manual{,
#>     title = {The Thing},
#>     author = {{The Data People}},
#>     organization = {The Data Org},
#>     year = {2021},
#>   }

Any thoughts?

Thanks in advance,

Sam


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Oct 29 19:34:54 2021
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Fri, 29 Oct 2021 12:34:54 -0500
Subject: [R] Format utils::bibentry with a 'corporate name'
In-Reply-To: <CADkXsV2f6hMGFAAiebC0HyJ6dYF5Vn=4aViwxk_dp=s43TjV7w@mail.gmail.com>
References: <CADkXsV2f6hMGFAAiebC0HyJ6dYF5Vn=4aViwxk_dp=s43TjV7w@mail.gmail.com>
Message-ID: <CACxE24kxvQEg0u_9wdNeBf9Lr1GJXwDHNBaa=9Z6WObfxQS_3w@mail.gmail.com>

Maybe use \{ for the second one?

On Fri, Oct 29, 2021 at 11:22 AM Sam Albers <tonightsthenight at gmail.com>
wrote:

> Hi all,
>
> Does anyone know of a way to force utils::bibentry to mimic the BibTex
> behaviour of using double { to force a "corporate name" in the author
> field to print correctly? For example take this bibentry:
>
> entry <- utils::bibentry(
>   bibtype = "Manual",
>   title = "The Thing",
>   author = "The Data People",
>   organization = "The Data Org",
>   year = format(Sys.Date(), "%Y")
> )
>
> entry
> #> People TD (2021). _The Thing_. The Data Org.
> print(entry, style = "citation")
> #>
> #> People TD (2021). _The Thing_. The Data Org.
> #>
> #> A BibTeX entry for LaTeX users is
> #>
> #>   @Manual{,
> #>     title = {The Thing},
> #>     author = {The Data People},
> #>     organization = {The Data Org},
> #>     year = {2021},
> #>   }
>
> I can simply add "{" right in the author string which then passes that
> to the Bibtex entry but the author field is still thinking it is a
> person with a name and I also get some warnings:
>
> entry <- utils::bibentry(
>   bibtype = "Manual",
>   title = "The Thing",
>   author = "{The Data People}",
>   organization = "The Data Org",
>   year = format(Sys.Date(), "%Y")
> )
>
>
> print(entry, style = "citation")
> #> Warning in parseLatex(x): x:1: unexpected '}'
> #> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
> #> Warning in parseLatex(x): x:1: unexpected '}'
> #> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
> #> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
> "UTF-8", :
> #> <connection>:1: unexpected '}'
> #> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
> "UTF-8", : <connection>:4: unexpected END_OF_INPUT 'The Data Org.
> #> '
> #>
> #> People D (2021). _The Thing_. The Data Org.
> #>
> #> A BibTeX entry for LaTeX users is
> #>
> #>   @Manual{,
> #>     title = {The Thing},
> #>     author = {{The Data People}},
> #>     organization = {The Data Org},
> #>     year = {2021},
> #>   }
>
> Any thoughts?
>
> Thanks in advance,
>
> Sam
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Oct 29 19:46:34 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Oct 2021 13:46:34 -0400
Subject: [R] Format utils::bibentry with a 'corporate name'
In-Reply-To: <CADkXsV2f6hMGFAAiebC0HyJ6dYF5Vn=4aViwxk_dp=s43TjV7w@mail.gmail.com>
References: <CADkXsV2f6hMGFAAiebC0HyJ6dYF5Vn=4aViwxk_dp=s43TjV7w@mail.gmail.com>
Message-ID: <600e5eb1-b9e9-2df0-91d5-f81ed4780d1f@gmail.com>

On 29/10/2021 1:21 p.m., Sam Albers wrote:
> Hi all,
> 
> Does anyone know of a way to force utils::bibentry to mimic the BibTex
> behaviour of using double { to force a "corporate name" in the author
> field to print correctly? For example take this bibentry:

Enter it like this:

entry <- utils::bibentry(
   bibtype = "Manual",
   title = "The Thing",
   author = person("The Data People"),
   organization = "The Data Org",
   year = format(Sys.Date(), "%Y")
)


There's an example just like this in the help page.  Sometimes it helps 
to look there.

Duncan Murdoch

> 
> entry <- utils::bibentry(
>    bibtype = "Manual",
>    title = "The Thing",
>    author = "The Data People",
>    organization = "The Data Org",
>    year = format(Sys.Date(), "%Y")
> )
> 
> entry
> #> People TD (2021). _The Thing_. The Data Org.
> print(entry, style = "citation")
> #>
> #> People TD (2021). _The Thing_. The Data Org.
> #>
> #> A BibTeX entry for LaTeX users is
> #>
> #>   @Manual{,
> #>     title = {The Thing},
> #>     author = {The Data People},
> #>     organization = {The Data Org},
> #>     year = {2021},
> #>   }
> 
> I can simply add "{" right in the author string which then passes that
> to the Bibtex entry but the author field is still thinking it is a
> person with a name and I also get some warnings:
> 
> entry <- utils::bibentry(
>    bibtype = "Manual",
>    title = "The Thing",
>    author = "{The Data People}",
>    organization = "The Data Org",
>    year = format(Sys.Date(), "%Y")
> )
> 
> 
> print(entry, style = "citation")
> #> Warning in parseLatex(x): x:1: unexpected '}'
> #> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
> #> Warning in parseLatex(x): x:1: unexpected '}'
> #> Warning in parseLatex(x): x:1: unexpected END_OF_INPUT 'The'
> #> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
> "UTF-8", :
> #> <connection>:1: unexpected '}'
> #> Warning in withCallingHandlers(.External2(C_parseRd, tcon, srcfile,
> "UTF-8", : <connection>:4: unexpected END_OF_INPUT 'The Data Org.
> #> '
> #>
> #> People D (2021). _The Thing_. The Data Org.
> #>
> #> A BibTeX entry for LaTeX users is
> #>
> #>   @Manual{,
> #>     title = {The Thing},
> #>     author = {{The Data People}},
> #>     organization = {The Data Org},
> #>     year = {2021},
> #>   }
> 
> Any thoughts?
> 
> Thanks in advance,
> 
> Sam
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Oct 29 19:55:52 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 29 Oct 2021 13:55:52 -0400
Subject: [R] Probably off topic but I hope amusing
In-Reply-To: <CAGxFJbTpp+tC2mQECS1owYATgD7BeAjpnDi27DfVeu3witsL=w@mail.gmail.com>
References: <CAGxFJbTpp+tC2mQECS1owYATgD7BeAjpnDi27DfVeu3witsL=w@mail.gmail.com>
Message-ID: <01b901d7ccee$36fe7ed0$a4fb7c70$@verizon.net>

Bert,

R is used all over the place, sometimes not visibly.

A search shows the NY times using it in 2011, 2009, ...:

https://www.nytimes.com/2009/01/07/technology/business-computing/07program.h
tml

https://blog.revolutionanalytics.com/2011/03/how-the-new-york-times-uses-r-f
or-data-visualization.html

There also seem to be several packages for interfacing with the NY Times,
albeit that does not mean much about their usage.

However, the error message using the phrase "NaN" is not a guarantee as
there are other languages that use the concept, albeit may not capitalize it
the same way. But in an error message, any programmer can be setting up the
text. According to this reference, Rust and ECMAScript also call it a NaN:

https://en.wikipedia.org/wiki/NaN

I am a tad confused it lists a form of "NaN%" without specifying if any
language specifically uses it and your example ended with a percent sign.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
Sent: Friday, October 29, 2021 11:36 AM
To: R-help <r-help at r-project.org>
Subject: [R] Probably off topic but I hope amusing

There was a little discussion today (yet again) about floating point
arithmetic. Perhaps related to this, I subscribe to the online NYTimes,
which flashes U.S. stock index prices at the top of its home page. Today,
instead of the Nasdaq price being flashed, there was this:

undefined-NaN%

I wonder if this means that R is being used as a backend for this or whether
this way of displaying what I think is 0/0 in FP is common.

Anyway, what do you think most readers reaction to this was?!

Best to all,
Bert

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Oct 29 20:28:29 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Oct 2021 11:28:29 -0700
Subject: [R] Probably off topic but I hope amusing
In-Reply-To: <01b901d7ccee$36fe7ed0$a4fb7c70$@verizon.net>
References: <CAGxFJbTpp+tC2mQECS1owYATgD7BeAjpnDi27DfVeu3witsL=w@mail.gmail.com>
 <01b901d7ccee$36fe7ed0$a4fb7c70$@verizon.net>
Message-ID: <5FA2765A-7959-452E-AFEF-91F2184E59C2@dcn.davis.ca.us>

AFAIK NaN originated in the floating point standard IEEE754-1985 as a range of bit patterns that have all 1 bits in the exponent, and the convention to convert such bit patterns to the string "NaN" is an obvious way to handle output of such patterns, regardless of language. Pasting a % symbol after a converted floating point number is likewise common. Not sure I see R lurking here... could just as easily be Python or Java or some other programming language.

On October 29, 2021 10:55:52 AM PDT, Avi Gross via R-help <r-help at r-project.org> wrote:
>Bert,
>
>R is used all over the place, sometimes not visibly.
>
>A search shows the NY times using it in 2011, 2009, ...:
>
>https://www.nytimes.com/2009/01/07/technology/business-computing/07program.h
>tml
>
>https://blog.revolutionanalytics.com/2011/03/how-the-new-york-times-uses-r-f
>or-data-visualization.html
>
>There also seem to be several packages for interfacing with the NY Times,
>albeit that does not mean much about their usage.
>
>However, the error message using the phrase "NaN" is not a guarantee as
>there are other languages that use the concept, albeit may not capitalize it
>the same way. But in an error message, any programmer can be setting up the
>text. According to this reference, Rust and ECMAScript also call it a NaN:
>
>https://en.wikipedia.org/wiki/NaN
>
>I am a tad confused it lists a form of "NaN%" without specifying if any
>language specifically uses it and your example ended with a percent sign.
>
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of Bert Gunter
>Sent: Friday, October 29, 2021 11:36 AM
>To: R-help <r-help at r-project.org>
>Subject: [R] Probably off topic but I hope amusing
>
>There was a little discussion today (yet again) about floating point
>arithmetic. Perhaps related to this, I subscribe to the online NYTimes,
>which flashes U.S. stock index prices at the top of its home page. Today,
>instead of the Nasdaq price being flashed, there was this:
>
>undefined-NaN%
>
>I wonder if this means that R is being used as a backend for this or whether
>this way of displaying what I think is 0/0 in FP is common.
>
>Anyway, what do you think most readers reaction to this was?!
>
>Best to all,
>Bert
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kw@@t@t @end|ng |rom gm@||@com  Fri Oct 29 20:49:53 2021
From: kw@@t@t @end|ng |rom gm@||@com (Kevin Wright)
Date: Fri, 29 Oct 2021 13:49:53 -0500
Subject: [R] I'd like to request that my R CRAN package is not tested on
 Solaris OS
In-Reply-To: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
References: <CADmY=VHtHS+5h-OvLH3p=t3BYWLKxtGdFJkKTexfFwqSNgzEoA@mail.gmail.com>
Message-ID: <CAKFxdiRM3ZgKXB1zCdESoj0k7Ee3Tw0pKHL3wH+ec7p5ScbCMw@mail.gmail.com>

Lampros,

You can use Rhub for testing packages on various platforms.  I had a
similar issue to you...I had a tiny bug that was only failing on M1mac.  I
was able to resolve it by repeatedly testing my package on Rhub.  Here's
how I did that:
https://github.com/kwstat/nipals/issues/5

Kevin Wright


On Fri, Oct 22, 2021 at 6:13 AM lampros mouselimis <
mouselimislampros at gmail.com> wrote:

> Dear R-help team,
>
> I'm the maintainer of the textTinyR package. Currently the package fails on
> the Solaris Operating System (OS), you can see the results in the following
> weblink:
> https://cran.r-project.org/web/checks/check_results_textTinyR.html
>
> All my packages are tested on Solaris OS automatically but I never check my
> R packages before submitting to CRAN on Solaris OS because I don't have any
> experience using it. I also won't be in place to fix this error (even if I
> utilize a Virtual Machine). Due to the fact that my package works on Linux,
> Windows and Macintosh (I can fix the errors in all these three OS because I
> have installations in my Computer) can I request to exclude the textTinyR
> package from the Solaris OS testing / CRAN checking (that means the Solaris
> test frameworks will not appear in the CRAN Package test results page)?
> Moreover, whom should I send an e-mail to make this request?
>
> I processed the data of all current packages on CRAN
> <https://cran.r-project.org/web/checks/check_summary_by_package.html> and
> there are 153 submitted packages that are not tested on Solaris (I attach
> the csv file of these packages in this e-mail), which means it's possible
> for a package to not be tested on this OS.
>
> I'd like an answer before the 27th October otherwise the package will be
> removed from CRAN.
>
> Thank you in advance and for your time,
> Lampros Mouselimis
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Kevin Wright

	[[alternative HTML version deleted]]


From m||net@ @end|ng |rom tut@@|o  Fri Oct 29 21:17:42 2021
From: m||net@ @end|ng |rom tut@@|o (T. A. Milne)
Date: Fri, 29 Oct 2021 21:17:42 +0200 (CEST)
Subject: [R] Probably off topic but I hope amusing
Message-ID: <MnCU6n1--3-2@tuta.io>

I think Jeff is right, but there is a minor bit of history that is missing.

The Intel 8087 numeric coprocessor, announced in 1980, was (in effect) based on a draft version of what later became the IEEE754-1985 standard, and the 8087 included "NaN" as part of its exception handling routines.? However, these days "NaN" is usually translated as "not a number", while the Intel manuals for the 8087 usually translate the acronym as "Non-Number".

So, "NaN" is just a bit older than "IEEE754-1985" might suggest.


>AFAIK NaN originated in the floating point standard IEEE754-1985 as a range of bit >patterns that have all 1 bits in the exponent, and the convention to convert such bit >patterns to the string "NaN" is an obvious way to handle output of such patterns, >regardless of language. Pasting a % symbol after a converted floating point number is >likewise common. Not sure I see R lurking here... could just as easily be Python or Java >or some other programming language.>On October 29, 2021 10:55:52 AM PDT, Avi Gross via R-help <r-help at r-project.org> <mailto:r-help at r-project.org> wrote:

> Bert,R is used all over the place, sometimes not visibly.A search shows the NY times using it in 2011, 2009, ...:> https://www.nytimes.com/2009/01/07/technology/business-computing/07program.h> tml> https://blog.revolutionanalytics.com/2011/03/how-the-new-york-times-uses-r-f> or-data-visualization.htmlThere also seem to be several packages for interfacing with the NY Times,albeit that does not mean much about their usage.However, the error message using the phrase "NaN" is not a guarantee asthere are other languages that use the concept, albeit may not capitalize itthe same way. But in an error message, any programmer can be setting up thetext. According to this reference, Rust and ECMAScript also call it a NaN:> https://en.wikipedia.org/wiki/NaN> I am a tad confused it lists a form of "NaN%" without specifying if anylanguage specifically uses it and your example ended with a percent sign.-----Original Message-----From: R-help > <r-help-bounces at r-project.org> <mailto:r-help-bounces at r-project.org>>  On Behalf Of Bert GunterSent: Friday, October 29, 2021 11:36 AMTo: R-help > <r-help at r-project.org> <mailto:r-help at r-project.org>> Subject: [R] Probably off topic but I hope amusingThere was a little discussion today (yet again) about floating pointarithmetic. Perhaps related to this, I subscribe to the online NYTimes,which flashes U.S. stock index prices at the top of its home page. Today,instead of the Nasdaq price being flashed, there was this:undefined-NaN%I wonder if this means that R is being used as a backend for this or whetherthis way of displaying what I think is 0/0 in FP is common.Anyway, what do you think most readers reaction to this was?!Best to all,Bert	______________________________________________> R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide > http://www.R-project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.
>


- T. Arthur Milne


From ken @end|ng |rom pubbox@net  Sat Oct 30 02:08:44 2021
From: ken @end|ng |rom pubbox@net (Ken Peng)
Date: Sat, 30 Oct 2021 08:08:44 +0800
Subject: [R] generate random numeric
In-Reply-To: <fbbe40aa-ad8f-78c8-64e4-0e69370950ea@me.com>
References: <CALUE4BJJoqA43DjpSFrAtMB178HVsivCXuVYXrzVZ4HO+ounww@mail.gmail.com>
 <fbbe40aa-ad8f-78c8-64e4-0e69370950ea@me.com>
Message-ID: <CALUE4B+kQPN5a6P57bPJQF1do71MUrOxROepDZz08zpmUvHVxA@mail.gmail.com>

That's all right. Thanks.

On Sat, Oct 30, 2021 at 12:29 AM Marc Schwartz <marc_schwartz at me.com> wrote:

> Ken Peng wrote on 10/29/21 2:39 AM:
> > I saw runif(1) can generate a random num, is this the true random?
> >
> >> runif(1)
> > [1] 0.8945383
> >
> > What's the other better method?
> >
> > Thank you.
> >
> Hi,
>
> You do not indicate your use case, and that can be important.
>
> The numbers generated by R's default RNGs are "pseudo random" (PRNGs),
> which means that for most general purpose applications, such as common
> Monte Carlo simulations or randomized clinical trial treatment
> allocations, as suggested by the other replies, they will work fine.
>
> As PRNGs, the actual pseudo-random permutations can be replicated by
> setting the same 'seed' value each cycle for the PRNG in use.
>
> For example:
>
>  > runif(5)
> [1] 0.6238892 0.8307422 0.4955693 0.4182567 0.9818217
>
>  > runif(5)
> [1] 0.2423170 0.4129066 0.9213000 0.8290358 0.1644403
>
> will yield two different, pseudo-random, sequences.
>
> However:
>
>  > set.seed(1)
>  > runif(5)
> [1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819
>
>  > set.seed(1)
>  > runif(5)
> [1] 0.2655087 0.3721239 0.5728534 0.9082078 0.2016819
>
> will yield the same sequence given the use of the same seed value before
> each call to runif().
>
> Thus, the sequences will appear to be random, but given a specific
> algorithm and seed value, they are deterministic.
>
> That repeatable behavior can be important if one wishes to come back at
> some future date and replicate the exact same output sequence, presuming
> other factors have not changed in the mean time, such as occurred with R
> version 3.6.0, which is referenced in ?Random, where a default changed
> to improve behavior.
>
> Also, some R functions may use simulation or resampling approaches to
> create various parameters, and you may wish to replicate the same result
> with each iteration. Setting the seed value prior to the relevant
> function call can enable that.
>
> Also, review the resources at https://www.random.org for additional
> references on the differences between PRNGs and other implementations,
> especially if you might need something closer to a "true" RNG for more
> rigorous work.
>
> Regards,
>
> Marc Schwartz
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Oct 30 02:19:29 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 30 Oct 2021 13:19:29 +1300
Subject: [R] The "inset" argument in legend().
Message-ID: <20211030131929.4012ddae@rolf-Latitude-E7470>


I cannot get the "inset" argument in legend() to produce the results
that I want.  It seems to me that when the legend position argument is
set to "bottom" then only the second (y-component) entry of "inset"
has any effect, and when the position argument is "left" then only
the first (x-component)  entry of "inset" has any effect.

I have attached a file "legDemo.txt" which can be sourced to
demonstrate the behaviour that I am encountering.

I thought that maybe if one uses "inset" then one should not specify
the legend position, but that causes an error to be thrown.

I want to have a near the bottom of the plot and to adjust its
position, in the horizontal direction by means of "inset", but nothing
that I try has the desired effect.

Am I misunderstanding something?  Or is there perhaps a bug in
legend()?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: legDemo.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20211030/9436a173/attachment.txt>

From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Oct 30 02:29:06 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 29 Oct 2021 20:29:06 -0400
Subject: [R] The "inset" argument in legend().
In-Reply-To: <20211030131929.4012ddae@rolf-Latitude-E7470>
References: <20211030131929.4012ddae@rolf-Latitude-E7470>
Message-ID: <4bba3e61-1d60-2538-e480-8d9c453efdfd@gmail.com>

On 29/10/2021 8:19 p.m., Rolf Turner wrote:
> 
> I cannot get the "inset" argument in legend() to produce the results
> that I want.  It seems to me that when the legend position argument is
> set to "bottom" then only the second (y-component) entry of "inset"
> has any effect, and when the position argument is "left" then only
> the first (x-component)  entry of "inset" has any effect.
> 
> I have attached a file "legDemo.txt" which can be sourced to
> demonstrate the behaviour that I am encountering.
> 
> I thought that maybe if one uses "inset" then one should not specify
> the legend position, but that causes an error to be thrown.
> 
> I want to have a near the bottom of the plot and to adjust its
> position, in the horizontal direction by means of "inset", but nothing
> that I try has the desired effect.
> 
> Am I misunderstanding something?  Or is there perhaps a bug in
> legend()?

I think it is working as designed.  If you say "bottom", the y distance 
will be ignored:  it would only be considered for things that are placed 
relative to the vertical margins, i.e. bottomright, bottomleft, etc. 
The design doesn't say what an "inset" of the middle value would be.

To move things slightly away from the middle, I think you've got to look 
at par("usr") and place it yourself, giving numerical values for x and y.

Duncan Murdoch


From k|ebyn @end|ng |rom y@hoo@com@br  Sat Oct 30 18:42:10 2021
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber Borges)
Date: Sat, 30 Oct 2021 13:42:10 -0300
Subject: [R] png raster in 3D chart
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
Message-ID: <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>

Hello all

How to plot a raster image (like the R logo for example) on a plane of a 
3D chart?

My intention is to plot an image on each plane: xy, yz, xz...

I've seen something a long time ago on the internet but I can't find it 
anymore.

Thanks in advance for any help.

Cleber Borges


-- 
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Oct 30 18:58:31 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 30 Oct 2021 12:58:31 -0400
Subject: [R] png raster in 3D chart
In-Reply-To: <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
Message-ID: <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>

On 30/10/2021 12:42 p.m., Cleber Borges via R-help wrote:
> Hello all
> 
> How to plot a raster image (like the R logo for example) on a plane of a
> 3D chart?
> 
> My intention is to plot an image on each plane: xy, yz, xz...
> 
> I've seen something a long time ago on the internet but I can't find it
> anymore.
> 
> Thanks in advance for any help.

How are you drawing the plot?  If you are using rgl you could display a 
PNG file as a texture on a quadrilateral, or use the show2d() function 
to draw an R flat graphic and display that on a quadrilateral.

Duncan Murdoch


From k|ebyn @end|ng |rom y@hoo@com@br  Sat Oct 30 21:06:48 2021
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber Borges)
Date: Sat, 30 Oct 2021 16:06:48 -0300
Subject: [R] png raster in 3D chart
In-Reply-To: <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
 <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
Message-ID: <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>

Thanks Duncan for your answer.
and I apologize for not mentioning more details.

What I intend to do is more artistic than a scatter plot. I just really 
want the raster images in the 3 planes and the space will be empty anyway.

I still haven't got results but below is my attempts with your tip.

Many thanks,

Cleber

####################

 ?Rlogo <- "C:/R/doc/html/logo.jpg"
 ?library( jpeg ); ? library( rgl );? library( grid )
 ?logo <- readJPEG( Rlogo )

 ?x <- seq( 0,1,len=10 )

 ?open3d()

 ?plot3d( x, x, x, type='n' )

 ? show2d({
 ? par(mar=c(0,0,0,0))
 ? grid.raster( logo, x=0, width=1, y=0 )
 ? })






Em 30/10/2021 13:58, Duncan Murdoch escreveu:
> On 30/10/2021 12:42 p.m., Cleber Borges via R-help wrote:
>> Hello all
>>
>> How to plot a raster image (like the R logo for example) on a plane of a
>> 3D chart?
>>
>> My intention is to plot an image on each plane: xy, yz, xz...
>>
>> I've seen something a long time ago on the internet but I can't find it
>> anymore.
>>
>> Thanks in advance for any help.
>
> How are you drawing the plot?? If you are using rgl you could display 
> a PNG file as a texture on a quadrilateral, or use the show2d() 
> function to draw an R flat graphic and display that on a quadrilateral.
>
> Duncan Murdoch

-- 
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Oct 30 23:34:00 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 30 Oct 2021 17:34:00 -0400
Subject: [R] png raster in 3D chart
In-Reply-To: <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
 <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
 <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>
Message-ID: <da67e105-09af-6285-9a09-dd6f7f5f7087@gmail.com>

On 30/10/2021 3:06 p.m., Cleber Borges via R-help wrote:
>  ?library( jpeg ); ? library( rgl );? library( grid )
>   ?logo <- readJPEG( Rlogo )
> 
>   ?x <- seq( 0,1,len=10 )
> 
>   ?open3d()
> 
>   ?plot3d( x, x, x, type='n' )
> 
>   ? show2d({
>   ? par(mar=c(0,0,0,0))
>   ? grid.raster( logo, x=0, width=1, y=0 )
>   ? })


That's close; the only change I'd make is to the location:

library( jpeg );   library( rgl );  library( grid )
   logo <- readJPEG( Rlogo )

   x <- seq( 0,1,len=10 )

   open3d()

   plot3d( x, x, x, type='n' )

    show2d({
    par(mar=c(0,0,0,0))
    grid.raster( logo, x=0.5, width=1, y=0.5 )
    })

Duncan Murdoch


From k|ebyn @end|ng |rom y@hoo@com@br  Sat Oct 30 23:48:22 2021
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber Borges)
Date: Sat, 30 Oct 2021 18:48:22 -0300
Subject: [R] png raster in 3D chart
In-Reply-To: <da67e105-09af-6285-9a09-dd6f7f5f7087@gmail.com>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
 <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
 <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>
 <da67e105-09af-6285-9a09-dd6f7f5f7087@gmail.com>
Message-ID: <18a4e988-44a7-3633-985d-abeaa31d1b15@yahoo.com.br>

After a lot of testing and reading the manuals, I think I came pretty 
close to what I wanted (code below).

But some Cartesian axes do not appear.

I placed each axis separately and the corners where the raster images 
coincide overlapping the axes. The others have no problems.


Many thanks,

Cleber

######################


library( rgl ); library( grid ); library( jpeg )

Rlogo <- "C:/R/doc/html/logo.jpg"
logo <- readJPEG( Rlogo )

open3d( ); view3d( theta=300, phi=15, zoom=1.2 )

show2d({ par(mar=c(0,0,0,0)); 
grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="xx", rev=1)
show2d({ par(mar=c(0,0,0,0)); 
grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="y-", rev=1)
show2d({ par(mar=c(0,0,0,0)); 
grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="z-")

box3d( floating=NA? )
axes3d( c("x","x-+","x+-","y","y++","z","z--","z++"), tick=FALSE, 
labels=FALSE, expand=1.1 )




Em 30/10/2021 18:34, Duncan Murdoch escreveu:
> On 30/10/2021 3:06 p.m., Cleber Borges via R-help wrote:
>> ??library( jpeg ); ? library( rgl ); library( grid )
>> ? ?logo <- readJPEG( Rlogo )
>>
>> ? ?x <- seq( 0,1,len=10 )
>>
>> ? ?open3d()
>>
>> ? ?plot3d( x, x, x, type='n' )
>>
>> ? ? show2d({
>> ? ? par(mar=c(0,0,0,0))
>> ? ? grid.raster( logo, x=0, width=1, y=0 )
>> ? ? })
>
>
> That's close; the only change I'd make is to the location:
>
> library( jpeg );?? library( rgl );? library( grid )
> ? logo <- readJPEG( Rlogo )
>
> ? x <- seq( 0,1,len=10 )
>
> ? open3d()
>
> ? plot3d( x, x, x, type='n' )
>
> ?? show2d({
> ?? par(mar=c(0,0,0,0))
> ?? grid.raster( logo, x=0.5, width=1, y=0.5 )
> ?? })
>
> Duncan Murdoch

-- 
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From k|ebyn @end|ng |rom y@hoo@com@br  Sun Oct 31 03:35:02 2021
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber Borges)
Date: Sat, 30 Oct 2021 23:35:02 -0300
Subject: [R] all letters like the R Logo
References: <12b687b2-2ff6-bfa7-da92-b144976be712.ref@yahoo.com.br>
Message-ID: <12b687b2-2ff6-bfa7-da92-b144976be712@yahoo.com.br>

I once saw an internet article someone who made all the letters of the 
alphabet with the R logo style (font type, blue color and bow).
I tried several Google searches with different combinations of strings 
but I couldn't find it.

Would anyone know to give news of this article?
Thanks in advance for tips.
Cleber Borges


-- 
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From drj|m|emon @end|ng |rom gm@||@com  Sun Oct 31 05:30:42 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 31 Oct 2021 15:30:42 +1100
Subject: [R] all letters like the R Logo
In-Reply-To: <12b687b2-2ff6-bfa7-da92-b144976be712@yahoo.com.br>
References: <12b687b2-2ff6-bfa7-da92-b144976be712.ref@yahoo.com.br>
 <12b687b2-2ff6-bfa7-da92-b144976be712@yahoo.com.br>
Message-ID: <CA+8X3fWerazZzZV7_RAuYDJbAmLJyjj_QpjadYSY4MSRHLBqCw@mail.gmail.com>

Hi Cleber,
Looks like Deja Vu Sans Bold to me. If you have the GIMP, check it out.

Jim

On Sun, Oct 31, 2021 at 1:35 PM Cleber Borges via R-help
<r-help at r-project.org> wrote:
>
> I once saw an internet article someone who made all the letters of the
> alphabet with the R logo style (font type, blue color and bow).
> I tried several Google searches with different combinations of strings
> but I couldn't find it.
>
> Would anyone know to give news of this article?
> Thanks in advance for tips.
> Cleber Borges
>
>
> --
> Este email foi escaneado pelo Avast antiv?rus.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Oct 31 12:09:19 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 31 Oct 2021 07:09:19 -0400
Subject: [R] png raster in 3D chart
In-Reply-To: <18a4e988-44a7-3633-985d-abeaa31d1b15@yahoo.com.br>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
 <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
 <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>
 <da67e105-09af-6285-9a09-dd6f7f5f7087@gmail.com>
 <18a4e988-44a7-3633-985d-abeaa31d1b15@yahoo.com.br>
Message-ID: <e3f36b21-8a4e-0fa9-4dce-ac40f0f80102@gmail.com>

On 30/10/2021 5:48 p.m., Cleber Borges via R-help wrote:
> After a lot of testing and reading the manuals, I think I came pretty
> close to what I wanted (code below).
> 
> But some Cartesian axes do not appear.
> 
> I placed each axis separately and the corners where the raster images
> coincide overlapping the axes. The others have no problems.
> 
> 
> Many thanks,
> 
> Cleber
> 
> ######################
> 
> 
> library( rgl ); library( grid ); library( jpeg )
> 
> Rlogo <- "C:/R/doc/html/logo.jpg"

That won't work on most systems.  Please use something like

Rlogo <- file.path(R.home(), "doc/html/logo.jpg")


> logo <- readJPEG( Rlogo )
> 
> open3d( ); view3d( theta=300, phi=15, zoom=1.2 )
> 
> show2d({ par(mar=c(0,0,0,0));
> grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="xx", rev=1)
> show2d({ par(mar=c(0,0,0,0));
> grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="y-", rev=1)
> show2d({ par(mar=c(0,0,0,0));
> grid.raster(logo,0.5,0.5,.80,.80,"center")}, face="z-")
> 
> box3d( floating=NA? )

I don't think that has ever worked.  "floating=NA" is a special value 
that means something in mtext3d() and related function, but it's not a 
legal value for floating in general.

> axes3d( c("x","x-+","x+-","y","y++","z","z--","z++"), tick=FALSE,
> labels=FALSE, expand=1.1 )
>

I don't understand what you are trying to accomplish with this.  There 
are 12 possible locations for axes; this draws 7 of them (since "z" and 
"z--" mean the same thing).  Maybe this is why you aren't seeing some axes?

Another possibility is "z-fighting".  If you try to draw two 3D objects 
at the exact same location, only one will be displayed, and it's hard to 
predict which.  Rounding error sometimes goes one way, sometimes the 
other.  You can mitigate this by using the "polygon_offset = 1" material 
property on the polygons drawn by show2d().

Duncan Murdoch


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Sun Oct 31 12:47:03 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Sun, 31 Oct 2021 04:47:03 -0700
Subject: [R] extracting bootstrap statistics by group with loop
Message-ID: <CAMwU6B02iPv_otu5FN=X6R_fSPdD2nH+aXbQ1zM37dmVVdayeQ@mail.gmail.com>

Hi R users,
I was trying to extract the bootstrap mean and its SE by group but I have
been doing  it by separating the group manually. The data set is big so
doing it manually is a kind of tedious task. I am wondering whether there
is a possibility to do it by creating a loop. I am weak in writing loop
functions. I am attaching an example data and how I performed the
analysis, see below.
Thanks for your help.
Sincerely,
MW
####
library(boot)
DaT<-structure(list(bothTimes = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L),
total = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), Area = c("A",
"A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "A", "A",
"A", "A", "A", "A", "B", "B", "B", "B", "B", "B"), Year = c(2015L, 2015L,
2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
2016L, 2016L, 2016L, 2016L, 2016L)), class = "data.frame", row.names =
c(NA, -24L))

head(DaT)
R=100
bootprop <- function(data, index){
  d <- data[index, ]
  sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
}

###################
#2015
###################
#-----Year2015_pooled
Y2015_pooled<-subset(DaT, DaT$Year=="2015")
Y2015_pooled_boot <- boot(Y2015_pooled, bootprop, R)
boot_Y2015_pooled<-data.frame(Year="2015", Area= "Pooled", bootMean=
Y2015_pooled_boot$t0, SE=sd(Y2015_pooled_boot$t))
#-----Year2015_AreaA
Y2015_A<-subset(DaT, DaT$Year=="2015" & DaT$Area=="A")
Y2015_A_boot <- boot(Y2015_A, bootprop, R)
boot_Y2015_A<-data.frame(Year="2015", Area= "A", bootMean= Y2015_A_boot$t0,
SE=sd(Y2015_A_boot$t))
#----Year2015_AreaB
Y2015_B<-subset(DaT, DaT$Year=="2015" & DaT$Area=="B")
Y2015_B_boot <- boot(Y2015_B, bootprop, R)
boot_Y2015_B<-data.frame(Year="2015", Area= "B", bootMean= Y2015_B_boot$t0,
SE=sd(Y2015_B_boot$t))
###################
#2016
###################
#-----Year2016_pooled
Y2016_pooled<-subset(DaT, DaT$Year=="2016")
Y2016_pooled_boot <- boot(Y2016_pooled, bootprop, R)
boot_Y2016_pooled<-data.frame(Year="2016", Area= "Pooled", bootMean=
Y2016_pooled_boot$t0, SE=sd(Y2016_pooled_boot$t))

#-----Year2016_AreaA
Y2016_A<-subset(DaT, DaT$Year=="2016" & DaT$Area=="A")
Y2016_A_boot <- boot(Y2016_A, bootprop, R)

boot_Y2016_A<-data.frame(Year="2016", Area= "A", bootMean= Y2016_A_boot$t0,
SE=sd(Y2016_A_boot$t))
#----Year2016_AreaB
Y2016_B<-subset(DaT, DaT$Year=="2016" & DaT$Area=="B")
Y2016_B_boot <- boot(Y2016_B, bootprop, R)
boot_Y2016_B<-data.frame(Year="2016", Area= "B", bootMean= Y2016_B_boot$t0,
SE=sd(Y2016_B_boot$t))

## output data.matrix
BootMean_All<-rbind(boot_Y2015_pooled,boot_Y2015_A,boot_Y2015_B,boot_Y2016_pooled,boot_Y2016_A,boot_Y2016_B)
BootMean_All

	[[alternative HTML version deleted]]


From eng|@nder00000 @end|ng |rom gm@||@com  Sat Oct 30 05:30:16 2021
From: eng|@nder00000 @end|ng |rom gm@||@com (Mathew Englander)
Date: Fri, 29 Oct 2021 20:30:16 -0700
Subject: [R] typo in documentation for array
Message-ID: <CA+uxVQmDV-oae9hAA55eyMMnXjSLqtWR9vyWxUPSKchhOJWWJw@mail.gmail.com>

I noticed a typo in the ?array help-file ("Multi-way Arrays"), which is
also at this web page:
https://stat.ethz.ch/R-manual/R-patched/library/base/html/array.html

In the "Arguments" section of that page, under the subheading "dimnames",
the second sentence begins "This must a list..." and it ought to read,
"This must be a list...".

I'm not subscribed to the mailing list, so please reply by email to let me
know where I should report typos like this if I find any, in the future. I
considered filing a bug report on Bugzilla but this obviously is not a bug
in R, but just a mistake in the manual. I figured that someone reading this
mailing list would know the proper person to alert, to fix the typo in the
next edition of the R Manual.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Oct 31 17:48:08 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 31 Oct 2021 16:48:08 +0000
Subject: [R] extracting bootstrap statistics by group with loop
In-Reply-To: <CAMwU6B02iPv_otu5FN=X6R_fSPdD2nH+aXbQ1zM37dmVVdayeQ@mail.gmail.com>
References: <CAMwU6B02iPv_otu5FN=X6R_fSPdD2nH+aXbQ1zM37dmVVdayeQ@mail.gmail.com>
Message-ID: <553dbf33-3a9d-f55c-f92a-e3a729acba28@sapo.pt>

Hello,

Try to aggregate with ?by.


bootprop <- function(data, index){
   d <- data[index, ]
   sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
}
boot_mean_se <- function(data, statistic, R){
   b <- boot::boot(DaT, bootprop, R = R)
   c(bootMean = mean(b$t), bootSE = sd(b$t))
}

boot_year <- by(DaT, DaT$Year, boot_mean_se, statistic = bootprop, R = R)
boot_year_area <- by(DaT,
                      INDICES = list(Year = DaT$Year, Area = DaT$Area),
                      FUN = boot_mean_se,
                      statistic = bootprop, R = R)
boot_year
boot_year_area

boot_year <- do.call(rbind, boot_year)

d <- dimnames(boot_year_area)
boot_year_area <- cbind(Reduce(expand.grid, rev(d))[2:1],
                         do.call(rbind, boot_year_area))
names(boot_year_area)[1:2] <- names(d)
boot_year_area


Hope this helps,

Rui Barradas

?s 11:47 de 31/10/21, Marna Wagley escreveu:
> Hi R users,
> I was trying to extract the bootstrap mean and its SE by group but I have
> been doing  it by separating the group manually. The data set is big so
> doing it manually is a kind of tedious task. I am wondering whether there
> is a possibility to do it by creating a loop. I am weak in writing loop
> functions. I am attaching an example data and how I performed the
> analysis, see below.
> Thanks for your help.
> Sincerely,
> MW
> ####
> library(boot)
> DaT<-structure(list(bothTimes = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
> 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L),
> total = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), Area = c("A",
> "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "A", "A",
> "A", "A", "A", "A", "B", "B", "B", "B", "B", "B"), Year = c(2015L, 2015L,
> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
> 2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
> 2016L, 2016L, 2016L, 2016L, 2016L)), class = "data.frame", row.names =
> c(NA, -24L))
> 
> head(DaT)
> R=100
> bootprop <- function(data, index){
>    d <- data[index, ]
>    sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
> }
> 
> ###################
> #2015
> ###################
> #-----Year2015_pooled
> Y2015_pooled<-subset(DaT, DaT$Year=="2015")
> Y2015_pooled_boot <- boot(Y2015_pooled, bootprop, R)
> boot_Y2015_pooled<-data.frame(Year="2015", Area= "Pooled", bootMean=
> Y2015_pooled_boot$t0, SE=sd(Y2015_pooled_boot$t))
> #-----Year2015_AreaA
> Y2015_A<-subset(DaT, DaT$Year=="2015" & DaT$Area=="A")
> Y2015_A_boot <- boot(Y2015_A, bootprop, R)
> boot_Y2015_A<-data.frame(Year="2015", Area= "A", bootMean= Y2015_A_boot$t0,
> SE=sd(Y2015_A_boot$t))
> #----Year2015_AreaB
> Y2015_B<-subset(DaT, DaT$Year=="2015" & DaT$Area=="B")
> Y2015_B_boot <- boot(Y2015_B, bootprop, R)
> boot_Y2015_B<-data.frame(Year="2015", Area= "B", bootMean= Y2015_B_boot$t0,
> SE=sd(Y2015_B_boot$t))
> ###################
> #2016
> ###################
> #-----Year2016_pooled
> Y2016_pooled<-subset(DaT, DaT$Year=="2016")
> Y2016_pooled_boot <- boot(Y2016_pooled, bootprop, R)
> boot_Y2016_pooled<-data.frame(Year="2016", Area= "Pooled", bootMean=
> Y2016_pooled_boot$t0, SE=sd(Y2016_pooled_boot$t))
> 
> #-----Year2016_AreaA
> Y2016_A<-subset(DaT, DaT$Year=="2016" & DaT$Area=="A")
> Y2016_A_boot <- boot(Y2016_A, bootprop, R)
> 
> boot_Y2016_A<-data.frame(Year="2016", Area= "A", bootMean= Y2016_A_boot$t0,
> SE=sd(Y2016_A_boot$t))
> #----Year2016_AreaB
> Y2016_B<-subset(DaT, DaT$Year=="2016" & DaT$Area=="B")
> Y2016_B_boot <- boot(Y2016_B, bootprop, R)
> boot_Y2016_B<-data.frame(Year="2016", Area= "B", bootMean= Y2016_B_boot$t0,
> SE=sd(Y2016_B_boot$t))
> 
> ## output data.matrix
> BootMean_All<-rbind(boot_Y2015_pooled,boot_Y2015_A,boot_Y2015_B,boot_Y2016_pooled,boot_Y2016_A,boot_Y2016_B)
> BootMean_All
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From k|ebyn @end|ng |rom y@hoo@com@br  Sun Oct 31 17:49:24 2021
From: k|ebyn @end|ng |rom y@hoo@com@br (Cleber Borges)
Date: Sun, 31 Oct 2021 13:49:24 -0300
Subject: [R] png raster in 3D chart
In-Reply-To: <e3f36b21-8a4e-0fa9-4dce-ac40f0f80102@gmail.com>
References: <2c137dde-b787-eef2-f852-3ef967da4e8a.ref@yahoo.com.br>
 <2c137dde-b787-eef2-f852-3ef967da4e8a@yahoo.com.br>
 <d371fee9-57ca-7fe0-05b7-37079e0af008@gmail.com>
 <1b485cbe-9f40-11ce-c644-ccd8e2fcea47@yahoo.com.br>
 <da67e105-09af-6285-9a09-dd6f7f5f7087@gmail.com>
 <18a4e988-44a7-3633-985d-abeaa31d1b15@yahoo.com.br>
 <e3f36b21-8a4e-0fa9-4dce-ac40f0f80102@gmail.com>
Message-ID: <0f07e631-863f-bb82-954c-864d1d020810@yahoo.com.br>


Em 31/10/2021 08:09, Duncan Murdoch escreveu:
>
>> Rlogo <- "C:/R/doc/html/logo.jpg"
> That won't work on most systems.? Please use something like
> Rlogo <- file.path(R.home(), "doc/html/logo.jpg")

Ok. Done!


>> box3d( floating=NA? )
>
> I don't think that has ever worked.? "floating=NA" is a special value 
> that means something in mtext3d() and related function, but it's not a 
> legal value for floating in general.

I used this function just to center the axes on the screen. Despite the 
error, she still has this behavior and I still haven't found the correct 
solution to do this.

It's already working almost 100%.

It's just a toy to put inside Shiny...
It's for learning (see the difference between rgl inside R and via webGL).


Thanks for your attention...

Cleber Borges


-- 
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Oct 31 17:55:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 31 Oct 2021 16:55:01 +0000
Subject: [R] extracting bootstrap statistics by group with loop
In-Reply-To: <553dbf33-3a9d-f55c-f92a-e3a729acba28@sapo.pt>
References: <CAMwU6B02iPv_otu5FN=X6R_fSPdD2nH+aXbQ1zM37dmVVdayeQ@mail.gmail.com>
 <553dbf33-3a9d-f55c-f92a-e3a729acba28@sapo.pt>
Message-ID: <e5cb46d7-5f74-7220-71d1-fb3aeb715c57@sapo.pt>

Hello,

Sorry, bug. In both by instructions it's boot_mean_se, not bootprop.


boot_year <- by(DaT, DaT$Year, boot_mean_se, statistic = bootprop, R = R)
boot_year_area <- by(DaT,
                      INDICES = list(Year = DaT$Year, Area = DaT$Area),
                      FUN = boot_mean_se,
                      statistic = bootprop, R = R)


Hope this helps,

Rui Barradas

?s 16:48 de 31/10/21, Rui Barradas escreveu:
> Hello,
> 
> Try to aggregate with ?by.
> 
> 
> bootprop <- function(data, index){
>  ? d <- data[index, ]
>  ? sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
> }
> boot_mean_se <- function(data, statistic, R){
>  ? b <- boot::boot(DaT, bootprop, R = R)
>  ? c(bootMean = mean(b$t), bootSE = sd(b$t))
> }
> 
> boot_year <- by(DaT, DaT$Year, boot_mean_se, statistic = bootprop, R = R)
> boot_year_area <- by(DaT,
>  ???????????????????? INDICES = list(Year = DaT$Year, Area = DaT$Area),
>  ???????????????????? FUN = boot_mean_se,
>  ???????????????????? statistic = bootprop, R = R)
> boot_year
> boot_year_area
> 
> boot_year <- do.call(rbind, boot_year)
> 
> d <- dimnames(boot_year_area)
> boot_year_area <- cbind(Reduce(expand.grid, rev(d))[2:1],
>  ??????????????????????? do.call(rbind, boot_year_area))
> names(boot_year_area)[1:2] <- names(d)
> boot_year_area
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 11:47 de 31/10/21, Marna Wagley escreveu:
>> Hi R users,
>> I was trying to extract the bootstrap mean and its SE by group but I have
>> been doing? it by separating the group manually. The data set is big so
>> doing it manually is a kind of tedious task. I am wondering whether there
>> is a possibility to do it by creating a loop. I am weak in writing loop
>> functions. I am attaching an example data and how I performed the
>> analysis, see below.
>> Thanks for your help.
>> Sincerely,
>> MW
>> ####
>> library(boot)
>> DaT<-structure(list(bothTimes = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
>> 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L),
>> total = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), Area = c("A",
>> "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "A", "A",
>> "A", "A", "A", "A", "B", "B", "B", "B", "B", "B"), Year = c(2015L, 2015L,
>> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
>> 2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
>> 2016L, 2016L, 2016L, 2016L, 2016L)), class = "data.frame", row.names =
>> c(NA, -24L))
>>
>> head(DaT)
>> R=100
>> bootprop <- function(data, index){
>> ?? d <- data[index, ]
>> ?? sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
>> }
>>
>> ###################
>> #2015
>> ###################
>> #-----Year2015_pooled
>> Y2015_pooled<-subset(DaT, DaT$Year=="2015")
>> Y2015_pooled_boot <- boot(Y2015_pooled, bootprop, R)
>> boot_Y2015_pooled<-data.frame(Year="2015", Area= "Pooled", bootMean=
>> Y2015_pooled_boot$t0, SE=sd(Y2015_pooled_boot$t))
>> #-----Year2015_AreaA
>> Y2015_A<-subset(DaT, DaT$Year=="2015" & DaT$Area=="A")
>> Y2015_A_boot <- boot(Y2015_A, bootprop, R)
>> boot_Y2015_A<-data.frame(Year="2015", Area= "A", bootMean= 
>> Y2015_A_boot$t0,
>> SE=sd(Y2015_A_boot$t))
>> #----Year2015_AreaB
>> Y2015_B<-subset(DaT, DaT$Year=="2015" & DaT$Area=="B")
>> Y2015_B_boot <- boot(Y2015_B, bootprop, R)
>> boot_Y2015_B<-data.frame(Year="2015", Area= "B", bootMean= 
>> Y2015_B_boot$t0,
>> SE=sd(Y2015_B_boot$t))
>> ###################
>> #2016
>> ###################
>> #-----Year2016_pooled
>> Y2016_pooled<-subset(DaT, DaT$Year=="2016")
>> Y2016_pooled_boot <- boot(Y2016_pooled, bootprop, R)
>> boot_Y2016_pooled<-data.frame(Year="2016", Area= "Pooled", bootMean=
>> Y2016_pooled_boot$t0, SE=sd(Y2016_pooled_boot$t))
>>
>> #-----Year2016_AreaA
>> Y2016_A<-subset(DaT, DaT$Year=="2016" & DaT$Area=="A")
>> Y2016_A_boot <- boot(Y2016_A, bootprop, R)
>>
>> boot_Y2016_A<-data.frame(Year="2016", Area= "A", bootMean= 
>> Y2016_A_boot$t0,
>> SE=sd(Y2016_A_boot$t))
>> #----Year2016_AreaB
>> Y2016_B<-subset(DaT, DaT$Year=="2016" & DaT$Area=="B")
>> Y2016_B_boot <- boot(Y2016_B, bootprop, R)
>> boot_Y2016_B<-data.frame(Year="2016", Area= "B", bootMean= 
>> Y2016_B_boot$t0,
>> SE=sd(Y2016_B_boot$t))
>>
>> ## output data.matrix
>> BootMean_All<-rbind(boot_Y2015_pooled,boot_Y2015_A,boot_Y2015_B,boot_Y2016_pooled,boot_Y2016_A,boot_Y2016_B) 
>>
>> BootMean_All
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Oct 31 18:15:59 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 31 Oct 2021 17:15:59 +0000
Subject: [R] extracting bootstrap statistics by group with loop
In-Reply-To: <e5cb46d7-5f74-7220-71d1-fb3aeb715c57@sapo.pt>
References: <CAMwU6B02iPv_otu5FN=X6R_fSPdD2nH+aXbQ1zM37dmVVdayeQ@mail.gmail.com>
 <553dbf33-3a9d-f55c-f92a-e3a729acba28@sapo.pt>
 <e5cb46d7-5f74-7220-71d1-fb3aeb715c57@sapo.pt>
Message-ID: <385714c8-f415-8d9a-864f-f67c1b604642@sapo.pt>

Hello,

Now I'm spamming the list, not one of my days.

My first post was right, there was no bug and the 2nd one was exactly 
the same code, it corrected nothing at all.

Apologies for the noise,

Rui Barradas

?s 16:55 de 31/10/21, Rui Barradas escreveu:
> Hello,
> 
> Sorry, bug. In both by instructions it's boot_mean_se, not bootprop.
> 
> 
> boot_year <- by(DaT, DaT$Year, boot_mean_se, statistic = bootprop, R = R)
> boot_year_area <- by(DaT,
>  ???????????????????? INDICES = list(Year = DaT$Year, Area = DaT$Area),
>  ???????????????????? FUN = boot_mean_se,
>  ???????????????????? statistic = bootprop, R = R)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 16:48 de 31/10/21, Rui Barradas escreveu:
>> Hello,
>>
>> Try to aggregate with ?by.
>>
>>
>> bootprop <- function(data, index){
>> ?? d <- data[index, ]
>> ?? sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
>> }
>> boot_mean_se <- function(data, statistic, R){
>> ?? b <- boot::boot(DaT, bootprop, R = R)
>> ?? c(bootMean = mean(b$t), bootSE = sd(b$t))
>> }
>>
>> boot_year <- by(DaT, DaT$Year, boot_mean_se, statistic = bootprop, R = R)
>> boot_year_area <- by(DaT,
>> ????????????????????? INDICES = list(Year = DaT$Year, Area = DaT$Area),
>> ????????????????????? FUN = boot_mean_se,
>> ????????????????????? statistic = bootprop, R = R)
>> boot_year
>> boot_year_area
>>
>> boot_year <- do.call(rbind, boot_year)
>>
>> d <- dimnames(boot_year_area)
>> boot_year_area <- cbind(Reduce(expand.grid, rev(d))[2:1],
>> ???????????????????????? do.call(rbind, boot_year_area))
>> names(boot_year_area)[1:2] <- names(d)
>> boot_year_area
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 11:47 de 31/10/21, Marna Wagley escreveu:
>>> Hi R users,
>>> I was trying to extract the bootstrap mean and its SE by group but I 
>>> have
>>> been doing? it by separating the group manually. The data set is big so
>>> doing it manually is a kind of tedious task. I am wondering whether 
>>> there
>>> is a possibility to do it by creating a loop. I am weak in writing loop
>>> functions. I am attaching an example data and how I performed the
>>> analysis, see below.
>>> Thanks for your help.
>>> Sincerely,
>>> MW
>>> ####
>>> library(boot)
>>> DaT<-structure(list(bothTimes = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 0L,
>>> 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L),
>>> total = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), Area = c("A",
>>> "A", "A", "A", "A", "A", "B", "B", "B", "B", "B", "B", "A", "A",
>>> "A", "A", "A", "A", "B", "B", "B", "B", "B", "B"), Year = c(2015L, 
>>> 2015L,
>>> 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L, 2015L,
>>> 2015L, 2015L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L, 2016L,
>>> 2016L, 2016L, 2016L, 2016L, 2016L)), class = "data.frame", row.names =
>>> c(NA, -24L))
>>>
>>> head(DaT)
>>> R=100
>>> bootprop <- function(data, index){
>>> ?? d <- data[index, ]
>>> ?? sum(d[["bothTimes"]], na.rm = TRUE)/sum(d[["total"]], na.rm = TRUE)#
>>> }
>>>
>>> ###################
>>> #2015
>>> ###################
>>> #-----Year2015_pooled
>>> Y2015_pooled<-subset(DaT, DaT$Year=="2015")
>>> Y2015_pooled_boot <- boot(Y2015_pooled, bootprop, R)
>>> boot_Y2015_pooled<-data.frame(Year="2015", Area= "Pooled", bootMean=
>>> Y2015_pooled_boot$t0, SE=sd(Y2015_pooled_boot$t))
>>> #-----Year2015_AreaA
>>> Y2015_A<-subset(DaT, DaT$Year=="2015" & DaT$Area=="A")
>>> Y2015_A_boot <- boot(Y2015_A, bootprop, R)
>>> boot_Y2015_A<-data.frame(Year="2015", Area= "A", bootMean= 
>>> Y2015_A_boot$t0,
>>> SE=sd(Y2015_A_boot$t))
>>> #----Year2015_AreaB
>>> Y2015_B<-subset(DaT, DaT$Year=="2015" & DaT$Area=="B")
>>> Y2015_B_boot <- boot(Y2015_B, bootprop, R)
>>> boot_Y2015_B<-data.frame(Year="2015", Area= "B", bootMean= 
>>> Y2015_B_boot$t0,
>>> SE=sd(Y2015_B_boot$t))
>>> ###################
>>> #2016
>>> ###################
>>> #-----Year2016_pooled
>>> Y2016_pooled<-subset(DaT, DaT$Year=="2016")
>>> Y2016_pooled_boot <- boot(Y2016_pooled, bootprop, R)
>>> boot_Y2016_pooled<-data.frame(Year="2016", Area= "Pooled", bootMean=
>>> Y2016_pooled_boot$t0, SE=sd(Y2016_pooled_boot$t))
>>>
>>> #-----Year2016_AreaA
>>> Y2016_A<-subset(DaT, DaT$Year=="2016" & DaT$Area=="A")
>>> Y2016_A_boot <- boot(Y2016_A, bootprop, R)
>>>
>>> boot_Y2016_A<-data.frame(Year="2016", Area= "A", bootMean= 
>>> Y2016_A_boot$t0,
>>> SE=sd(Y2016_A_boot$t))
>>> #----Year2016_AreaB
>>> Y2016_B<-subset(DaT, DaT$Year=="2016" & DaT$Area=="B")
>>> Y2016_B_boot <- boot(Y2016_B, bootprop, R)
>>> boot_Y2016_B<-data.frame(Year="2016", Area= "B", bootMean= 
>>> Y2016_B_boot$t0,
>>> SE=sd(Y2016_B_boot$t))
>>>
>>> ## output data.matrix
>>> BootMean_All<-rbind(boot_Y2015_pooled,boot_Y2015_A,boot_Y2015_B,boot_Y2016_pooled,boot_Y2016_A,boot_Y2016_B) 
>>>
>>> BootMean_All
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @||ce @end|ng |rom co@km@||@com  Sun Oct 31 07:33:28 2021
From: @||ce @end|ng |rom co@km@||@com (Alice)
Date: Sun, 31 Oct 2021 14:33:28 +0800
Subject: [R] Translation of the charter
Message-ID: <CALUE4BLJttZjWc1=6CdcRFx4-SnNSAFJs7JTSpeivaWUQ48j7w@mail.gmail.com>

Dear members,

How to translate the charter to the underline inter?
I tried this:

> x <- c("a","b","c")

> as.numeric(x)

[1] NA NA NA

Warning message:

NAs introduced by coercion


It didn't work.

Sorry for my newbie questions.


B.R.

Alice

	[[alternative HTML version deleted]]


From @||ce @end|ng |rom co@km@||@com  Sun Oct 31 08:21:38 2021
From: @||ce @end|ng |rom co@km@||@com (Alice)
Date: Sun, 31 Oct 2021 15:21:38 +0800
Subject: [R] How to slice the array?
Message-ID: <CALUE4BLsnfEGK56CX0h+ucYmtb-snb7gDgLs38q7kJja8AGaXw@mail.gmail.com>

How to slice the array with the condition?
For example, in perl I can get the elements greater than 2.

$ perl -le '@x=(1,2,3,4,5);@y=grep {$_>2} @x;print "@y"'

3 4 5


in R I know which(x>2), but it will return the indexes instead of an array.


Thanks again.


Alice

	[[alternative HTML version deleted]]


From @@zh@o19 @end|ng |rom out|ook@com  Sun Oct 31 16:57:37 2021
From: @@zh@o19 @end|ng |rom out|ook@com (Zhao Shanshan)
Date: Sun, 31 Oct 2021 15:57:37 +0000
Subject: [R] 
 Error in dis[sppInSample,sppInSample]:subscript out of bounds
Message-ID: <PN3PR01MB5461B9AE4F38535016D59EBDC8899@PN3PR01MB5461.INDPRD01.PROD.OUTLOOK.COM>

Hi, I have the same problem, can you tell me how to solve it?





Hello,

I am new to R and am encountering an error message that I cannot find a solution for.

I am attempting to calculate MPD (mean pairwise distance), without weighting for abundance, with a community species list and a phylogenetic tree in newick format with branch lengths.

I have read in both list and tree .txt files and calculated PD without any problem.

To calculate MPD I have entered:>MPD1=mpd(list,cophenetic(tree))

Error:Error in dis[sppInSample, sppInSample] : subscript out of bounds

Thank you for you helpCheersMarion.

        [[alternative HTML version deleted]]



	[[alternative HTML version deleted]]


