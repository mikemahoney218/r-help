From drj|m|emon @end|ng |rom gm@||@com  Wed Apr  1 00:45:27 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 1 Apr 2020 09:45:27 +1100
Subject: [R] How to match strings in two files and replace strings?
In-Reply-To: <20200331034255.GC498099@jrl.uk.to>
References: <CAF9-5jOTxXFB81PLfqS_w9=Jx5yy_bMHkrUQDFvhmKphAP303g@mail.gmail.com>
 <CA+8X3fWDycMX8yCMKeiFbKP+jG=EOK8SEUUekEVRsy=1RgjBAg@mail.gmail.com>
 <CAF9-5jPaBP94dRWmo2TrXW1x8Qg=iDtxttgDv4fP5wFWJBF7=Q@mail.gmail.com>
 <20200331034255.GC498099@jrl.uk.to>
Message-ID: <CA+8X3fXtOCu7eyf_uLtj+KHwsjDvnqLZY3Gw52FohVhNhnRuxQ@mail.gmail.com>

Nice improvement.

Jim

On Wed, Apr 1, 2020 at 3:18 AM Rasmus Liland
<jensrli at student.ikos.uio.no> wrote:
>
> On 2020-03-30 21:43 -0500, Ana Marija wrote:
> > I did run your workflow and this is what I got:
> >
> > > newout<-merge(output11.frq,marker_info[,c("V5","match_col")],by="match_col")
> > Error in `[.data.frame`(marker_info, , c("V5", "match_col")) :
> >   undefined columns selected
> >
> > this is how marker-info looks like:
>
> Hi Ana,
>
> perhaps adding comment.char="#" as an argument to read.csv might
> help?
>
> Making the output11.frq$match_col column might perhaps be easier
> using gsub, have a look:
>
> marker_info <- "#Column Description:
> #Column is separated by ','.
> #Chr:   Chromosome on NCBI reference genome.
> #Pos:   chromosome position when snp has unique hit on reference genome. Otherwise this field is NULL.
> #Submitter_snp_name:    The string identifier of snp on the platform.  This is the dbSNP local_snp_id.
> #Ss#:   dbSNP submitted snp Id. Each snp sequence on the platform gets a unique ss#.
> #Rs#:   refSNP cluster accession. Rs# for the dbSNP refSNP cluster that the sequence for this ss# maps to.
> #Genome_build_id:       Genome build used to map the SNP (a string)
> #ALLELE1_genome_orient: genome orientation allele1, same as which genotypes are reported.
> #ALLELE2_genome_orient: genome orientation allele2, same as which genotypes are reported.
> #ALLELE1_orig_assay_orient:     original reported orientation for the SNP assay, will correspond to CEL files and the ss_id.
> #ALLELE2_orig_assay_orient:     original reported orientation for the SNP assay, will correspond to CEL files and the ss_id.
> #QC_TYPE:       A-autosomal and P-pseudo-autosomal; X: X-linked; Y-Y-linked;NA-disable QC for this snp.
> #SNP_flank_sequence:    snp sequence on the reference genome orientation. 40bp on each side of variation.
> #SOURCE:         Platform specific string identifying assay (e.g. HBA_CHIP)
> #Ss2rs_orientation:     ss to rs orientation. +: same; -: opposite strand.
> #Rs2genome_orienation:  Orientation of rs flanking sequence to reference genome. +: same orientation, -: opposite.
> #Orien_flipped_assay_to_genome: y/n: this column would be the value of the exclusive OR from ss2rs_orientation  XOR rs2genome_orientation.
> #Probe_id:       NCBI probe_id.
> #neighbor_snp_list:     List of neighbor snp and position within 40kb up/downstream.
> #dbSNP_build_id:        dbSNP build id.
> #study_id:      unique id with prefix: phs.
> #
> # Chr,Pos,Submitter_snp_name,Ss#,Rs#,Genome_build_id,ALLELE1_genome_orient,ALLELE2_genome_orient,ALLELE1_orig_assay_orient,ALLELE2_orig_assay_orient,QC_TYPE,SNP_flank_sequence,SOURCE,Ss2rs_orientation,Rs2genome_orienation,Orien_flipped_assay_to_genome,Probe_id,neighbor_snp_list,dbSNP_build_id,study_id
> 1,742429,SNP_A-1909444,ss66079302,rs3094315,36.2,G,A,C,T,A,GCACAGCAAGAGAAAC[A/G]TTTGACAGAGAATACA,Sty,+,-,y,,,127,phs000018
> 1,769185,SNP_A-4303947,ss66273559,rs4040617,36.2,A,G,A,G,A,GCTGTGAGAGAGAACA[A/G]TGTCCCAATTTTGCCC,Sty,+,+,n,,,127,phs000018
> 1,775852,SNP_A-1886933,ss66317030,rs2980300,36.2,T,C,A,G,A,GAATGACTGTGTCTCT[C/T]TGAGTTAGTGAAGTCA,Nsp,-,+,y,,,127,phs000018
> "
> marker_info <-
>   read.csv(text=marker_info,
>     header=FALSE,
>     stringsAsFactors=FALSE,
>     comment.char="#")
>
> output11.frq <-
> "CHR  SNP A1 A2  MAF  NCHROBS
> 1      1:775852:T:C    T    C       0.1707     3444
> 1     1:1120590:A:C    C    A      0.08753     3496
> 1     1:1145994:T:C    C    T       0.1765     3496
> 1     1:1148494:A:G    A    G       0.1059     3464
> 1     1:1201155:C:T    T    C      0.07923     3496"
> output11.frq <-
>   read.table(text=output11.frq, header=TRUE,
>     stringsAsFactors=FALSE)
>
> output11.frq$match_col <-
>   gsub("^([0-9]+):([0-9]+).*", "\\1:\\2",
>        output11.frq$SNP)
>
> marker_info$match_col <-
>   apply(marker_info[,1:2], 1, paste,
>         collapse=":")
>
> merge(x=output11.frq,
>       y=marker_info[,c("V5", "match_col")],
>       by="match_col")
>
>
> Regards,
> Rasmus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Wed Apr  1 00:46:58 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Tue, 31 Mar 2020 22:46:58 +0000
Subject: [R] Problems using predict with GEE
Message-ID: <MN2PR03MB51675A0015FC4BF1436E61BFE2C80@MN2PR03MB5167.namprd03.prod.outlook.com>

I am running gee with a an offset followed by predict to get predicted values. The GEE analysis runs without error. When I run the predict function, I get the following error message:

Error in seq_len(p) : argument must be coercible to non-negative integer
In addition: Warning messages:
1: In predict.lm(object, newdata, se.fit, scale = 1, type = if (type ==  :
  calling predict.lm(<fake-lm-object>) ...
2: In seq_len(p) : first element used of 'length.out' argument

The error does not appear to be related to the offset values.

I hope someone can help me correct the error. Reproducible code follows:

Thank you,
John


install.packages("gee")
library(gee)

myData2 <- structure(list(HG = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
                                 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,
                                 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0),
                          Group = structure(c(1L,
                                              1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
                                              1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
                                              1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
                                              2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
                                              2L, 2L, 2L, 2L, 2L, 2L, 2L),
                                            .Label = c("Group1", "Group2"), class = "factor")),
                     class = "data.frame", row.names = c(NA,-72L))
myData2
# Define offset
FU <- 1
# Run GEE wiht offset
fitGEE <- gee(HG+offset(log(FU))~Group,family=quasi,
              data=myData2,id=AllData$"Subject ID",corstr="exchangeable",subset=subset)
print(summary(fitGEE))

# Create a dataframe with data used in predict.
# FU =1
new.data <- data.frame(Group=c("Group1","Group2"),FU=1)
cat("These are the data used by predict\n")
print(new.data)
# This predict fails
LogPtEst <- predict(fitGEE,newdata=new.data)

# Create a dataframe with data used in predict.
# FU =0
new.data <- data.frame(Group=c("Group1","Group2"),FU=0)
cat("These are the data used by predict\n")
print(new.data)
# This predict also fails
LogPtEst <- predict(fitGEE,newdata=new.data)

Many thanks,
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Wed Apr  1 02:54:27 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Wed, 1 Apr 2020 09:54:27 +0900
Subject: [R] Mapping of countries
In-Reply-To: <CAGsroM3Hxq9xx-YgLqpOsE9fY2dAvPfNQmOWwDKigCd3TZOdRQ@mail.gmail.com>
References: <CAGsroM29gXKXRNURDAmzotgnMtDLqAZgGoc66iuoJ4zBcmNm0A@mail.gmail.com>
 <CA+8X3fXDjKjCyceJUyJPkgQnmVbEzNFLuqJCPsyDbRwYEM8hGA@mail.gmail.com>
 <CAGsroM1hppxCmg3xfmdsWGP=XvEHjyVAaHAboOwF=FcyhrZzeg@mail.gmail.com>
 <CAGsroM3Hxq9xx-YgLqpOsE9fY2dAvPfNQmOWwDKigCd3TZOdRQ@mail.gmail.com>
Message-ID: <CAHXS41xr+Zo-T3rrTYGpFAQxbu+mJo_yg6P8xEPMoyv44iU0QA@mail.gmail.com>

Maybe simply add:


points(station$Lon, station$Lat, col="red", pch=16, label="Your Country")
text(station$Lon, station$Lat,"Your Country",
     col="black", pos=3, cex=1)

station$Lon and Lat in your coordinate position.

Regards,
Ani


On Tue, Mar 31, 2020 at 10:58 PM george brida <george.brida at gmail.com> wrote:
>
> Dear Jim,
>
> Is it possible to add also a title to this map?
>
> Many thanks
>
>
>
> On Tue, Mar 31, 2020 at 2:29 PM george brida <george.brida at gmail.com> wrote:
>
> > Dear Jim,
> >
> > Thank you very much. I obtained now the required map. I would like to know
> > how to add the names of the countries.
> >
> > Best
> > George
> >
> > On Tue, Mar 31, 2020 at 10:10 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi George,
> >> Try this:
> >>
> >> library(maps)
> >> map("world",xlim=c(34.353,60.369),ylim=c(16.7,32.193),
> >>  regions="Saudi Arabia",col="yellow",fill=TRUE)
> >> map("world",regions="Bahrain",col="yellow",fill=TRUE,add=TRUE)
> >> map("world",regions="Kuwait",col="lightblue",fill=TRUE,add=TRUE)
> >> map("world",regions="Qatar",col="yellow",fill=TRUE,add=TRUE)
> >> map("world",regions="United Arab
> >> Emirates",col="lightblue",fill=TRUE,add=TRUE)
> >> map("world",regions="Oman",col="lightgreen",fill=TRUE,add=TRUE)
> >>
> >> Jim
> >>
> >> On Tue, Mar 31, 2020 at 12:39 PM george brida <george.brida at gmail.com>
> >> wrote:
> >> >
> >> > Dear R users,
> >> >
> >> > i would like to plot the maps of the Gulf Cooperation Council (GCC)
> >> > countries (KSA, Qatar, Bahrain, Kuwait, UAE and Oman) with these
> >> > constraints: i/ KSA , Qatar and Bahrain have the same face color , ii/
> >> > Kuweit and UAE with the same face color and iii/Oman  with another face
> >> > color. Is there any code in R doing this task.
> >> >
> >> > Many thanks.
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nev||@@mo@ @end|ng |rom gm@||@com  Wed Apr  1 03:18:37 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Wed, 1 Apr 2020 12:18:37 +1100
Subject: [R] repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
Message-ID: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>

Hi

I can achieve this using two for loops but it is slow  I need to do this on
many matrices with tens of millions of rows of x,y,z and k

What is a faster method to achieve this, I cannot use rep as j changes in
each row of the new matrix
###############################################
M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4, 2, 1, 3, 2
), 4,4, dimnames = list(NULL, c("x", "y", "z","k")))

Print(M)
#Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
#repeated k times with column j numbered from 1:k
# ! can do with nested loops but this is very slow ( example below)
#How do I acheive this quickly without loops?
Mout<-NULL

for(i in 1:nrow(M)){
  a=M[i,c("x","y","z")]
  for (j in 1:M[i,"k"]){
    b=c(a,j)
    Mout<-rbind(Mout,b)
    }
}
colnames(Mout)[4]<-"j"
print(Mout)

#########################################################

Thanks

Nevil Amos

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr  1 03:33:10 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Mar 2020 18:33:10 -0700
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
Message-ID: <36E14856-9EAC-4401-9C39-CD08059B8D7F@dcn.davis.ca.us>

False premise: rep works fine

Mout2 <- cbind(M[ rep(seq.int(nrow(M)),M[,"k"]), c("x","y","z")],unlist(lapply(M[,"k"],seq.int)))

On March 31, 2020 6:18:37 PM PDT, nevil amos <nevil.amos at gmail.com> wrote:
>Hi
>
>I can achieve this using two for loops but it is slow  I need to do
>this on
>many matrices with tens of millions of rows of x,y,z and k
>
>What is a faster method to achieve this, I cannot use rep as j changes
>in
>each row of the new matrix
>###############################################
>M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4, 2, 1, 3, 2
>), 4,4, dimnames = list(NULL, c("x", "y", "z","k")))
>
>Print(M)
>#Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
>#repeated k times with column j numbered from 1:k
># ! can do with nested loops but this is very slow ( example below)
>#How do I acheive this quickly without loops?
>Mout<-NULL
>
>for(i in 1:nrow(M)){
>  a=M[i,c("x","y","z")]
>  for (j in 1:M[i,"k"]){
>    b=c(a,j)
>    Mout<-rbind(Mout,b)
>    }
>}
>colnames(Mout)[4]<-"j"
>print(Mout)
>
>#########################################################
>
>Thanks
>
>Nevil Amos
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From nev||@@mo@ @end|ng |rom gm@||@com  Wed Apr  1 04:42:07 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Wed, 1 Apr 2020 13:42:07 +1100
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
Message-ID: <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>

Well,
I found a way to do it partly using rep(), and one loop that makes it 10x
or more faster however would still be good to do without the loop at all
matrix made slightly beigger (10000 rows):

M<-matrix(c(1:30000
), 10000,3)
M<-cbind(M,sample(1:5,size = 10000,replace = T))
#Print(M)
#Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
#repeated k times with column j numbered from 1:k
# ! can do with nested loops but this is very slow ( example below)
#How do I acheive this quickly without loops?
print("double loop")
print(system.time({
Mout<-NULL

for(i in 1:nrow(M)){
  a=M[i,1:3]
  k=M[i,4]
  for (j in 1:k){
    b=c(a,j)
    Mout<-rbind(Mout,b)
    }
}
colnames(Mout)<-c("x","y","z","j")
}))

print("rep and single loop")
print(system.time({
  j<-NULL
  MOut<-NULL
  MOut<-M[,1:3][rep(1:nrow(M), times = M[,4]), ]
  for(i in M[,4])(j<-c(j,1:i))
  MOut<-cbind(MOut,j)
  colnames(Mout)<-c("x","y","z","j")
}))

On Wed, 1 Apr 2020 at 12:18, nevil amos <nevil.amos at gmail.com> wrote:

> Hi
>
> I can achieve this using two for loops but it is slow  I need to do this
> on many matrices with tens of millions of rows of x,y,z and k
>
> What is a faster method to achieve this, I cannot use rep as j changes in
> each row of the new matrix
> ###############################################
> M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4, 2, 1, 3, 2
> ), 4,4, dimnames = list(NULL, c("x", "y", "z","k")))
>
> Print(M)
> #Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
> #repeated k times with column j numbered from 1:k
> # ! can do with nested loops but this is very slow ( example below)
> #How do I acheive this quickly without loops?
> Mout<-NULL
>
> for(i in 1:nrow(M)){
>   a=M[i,c("x","y","z")]
>   for (j in 1:M[i,"k"]){
>     b=c(a,j)
>     Mout<-rbind(Mout,b)
>     }
> }
> colnames(Mout)[4]<-"j"
> print(Mout)
>
> #########################################################
>
> Thanks
>
> Nevil Amos
>

	[[alternative HTML version deleted]]


From nev||@@mo@ @end|ng |rom gm@||@com  Wed Apr  1 05:00:55 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Wed, 1 Apr 2020 14:00:55 +1100
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
 <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
Message-ID: <CAN9eD7mgpXZgZSM47SHYfD9CLu-nc8xaZrcT6sjffjve-oxeeA@mail.gmail.com>

OK sorted - hope these postings might help someone else

Any even faster options would be appreciated still

#seq() does not work but  sequence() does
print("rep and sequence")
print(system.time({
  j<-NULL
  MOut<-NULL
  MOut<-M[rep(1:nrow(M), times = M[,4]), ]
  j<-sequence(M[,4])
  MOut<-cbind(MOut,j)
  colnames(Mout)<-c("x","y","z","j")
}))

On Wed, 1 Apr 2020 at 13:42, nevil amos <nevil.amos at gmail.com> wrote:

> Well,
> I found a way to do it partly using rep(), and one loop that makes it 10x
> or more faster however would still be good to do without the loop at all
> matrix made slightly beigger (10000 rows):
>
> M<-matrix(c(1:30000
> ), 10000,3)
> M<-cbind(M,sample(1:5,size = 10000,replace = T))
> #Print(M)
> #Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
> #repeated k times with column j numbered from 1:k
> # ! can do with nested loops but this is very slow ( example below)
> #How do I acheive this quickly without loops?
> print("double loop")
> print(system.time({
> Mout<-NULL
>
> for(i in 1:nrow(M)){
>   a=M[i,1:3]
>   k=M[i,4]
>   for (j in 1:k){
>     b=c(a,j)
>     Mout<-rbind(Mout,b)
>     }
> }
> colnames(Mout)<-c("x","y","z","j")
> }))
>
> print("rep and single loop")
> print(system.time({
>   j<-NULL
>   MOut<-NULL
>   MOut<-M[,1:3][rep(1:nrow(M), times = M[,4]), ]
>   for(i in M[,4])(j<-c(j,1:i))
>   MOut<-cbind(MOut,j)
>   colnames(Mout)<-c("x","y","z","j")
> }))
>
> On Wed, 1 Apr 2020 at 12:18, nevil amos <nevil.amos at gmail.com> wrote:
>
>> Hi
>>
>> I can achieve this using two for loops but it is slow  I need to do this
>> on many matrices with tens of millions of rows of x,y,z and k
>>
>> What is a faster method to achieve this, I cannot use rep as j changes in
>> each row of the new matrix
>> ###############################################
>> M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4, 2, 1, 3, 2
>> ), 4,4, dimnames = list(NULL, c("x", "y", "z","k")))
>>
>> Print(M)
>> #Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
>> #repeated k times with column j numbered from 1:k
>> # ! can do with nested loops but this is very slow ( example below)
>> #How do I acheive this quickly without loops?
>> Mout<-NULL
>>
>> for(i in 1:nrow(M)){
>>   a=M[i,c("x","y","z")]
>>   for (j in 1:M[i,"k"]){
>>     b=c(a,j)
>>     Mout<-rbind(Mout,b)
>>     }
>> }
>> colnames(Mout)[4]<-"j"
>> print(Mout)
>>
>> #########################################################
>>
>> Thanks
>>
>> Nevil Amos
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Apr  1 06:33:39 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 1 Apr 2020 15:33:39 +1100
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
 <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
Message-ID: <CA+8X3fV2NVMPdkdu_HhgVqwqjPPt-j2Qn0UqzbQ4z-Kz61ROSA@mail.gmail.com>

Hi Nevil,
It's a nasty piece of work, but:

M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4,2,1,3,2),4,4,
dimnames = list(NULL, c("x", "y", "z","k")))
M
reprow<-function(x)
 return(matrix(rep(x,x[length(x)]),nrow=x[length(x)],byrow=TRUE))
toseq<-function(x) return(1:x)
j<-unlist(sapply(M[,"k"],toseq))
Mlist<-apply(M,1,reprow)
Mlist
newM<-Mlist[[1]]
for(i in 2:length(Mlist)) newM<-rbind(newM,Mlist[[i]])
newM
newM<-cbind(newM,j)
colnames(newM)<-c(colnames(M),"j")
newM

Jim

On Wed, Apr 1, 2020 at 1:43 PM nevil amos <nevil.amos at gmail.com> wrote:
>
> Well,
> I found a way to do it partly using rep(), and one loop that makes it 10x
> or more faster however would still be good to do without the loop at all
> matrix made slightly beigger (10000 rows):
>
> M<-matrix(c(1:30000
> ), 10000,3)
> M<-cbind(M,sample(1:5,size = 10000,replace = T))
> #Print(M)
> #Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
> #repeated k times with column j numbered from 1:k
> # ! can do with nested loops but this is very slow ( example below)
> #How do I acheive this quickly without loops?
> print("double loop")
> print(system.time({
> Mout<-NULL
>
> for(i in 1:nrow(M)){
>   a=M[i,1:3]
>   k=M[i,4]
>   for (j in 1:k){
>     b=c(a,j)
>     Mout<-rbind(Mout,b)
>     }
> }
> colnames(Mout)<-c("x","y","z","j")
> }))
>
> print("rep and single loop")
> print(system.time({
>   j<-NULL
>   MOut<-NULL
>   MOut<-M[,1:3][rep(1:nrow(M), times = M[,4]), ]
>   for(i in M[,4])(j<-c(j,1:i))
>   MOut<-cbind(MOut,j)
>   colnames(Mout)<-c("x","y","z","j")
> }))
>
> On Wed, 1 Apr 2020 at 12:18, nevil amos <nevil.amos at gmail.com> wrote:
>
> > Hi
> >
> > I can achieve this using two for loops but it is slow  I need to do this
> > on many matrices with tens of millions of rows of x,y,z and k
> >
> > What is a faster method to achieve this, I cannot use rep as j changes in
> > each row of the new matrix
> > ###############################################
> > M<-matrix(c(1,2,3,4,1,2,3,4,1,2,3,4, 2, 1, 3, 2
> > ), 4,4, dimnames = list(NULL, c("x", "y", "z","k")))
> >
> > Print(M)
> > #Create matrix (Mout) in this case 8 rows with x,y,z in each row of M
> > #repeated k times with column j numbered from 1:k
> > # ! can do with nested loops but this is very slow ( example below)
> > #How do I acheive this quickly without loops?
> > Mout<-NULL
> >
> > for(i in 1:nrow(M)){
> >   a=M[i,c("x","y","z")]
> >   for (j in 1:M[i,"k"]){
> >     b=c(a,j)
> >     Mout<-rbind(Mout,b)
> >     }
> > }
> > colnames(Mout)[4]<-"j"
> > print(Mout)
> >
> > #########################################################
> >
> > Thanks
> >
> > Nevil Amos
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From george@br|d@ @end|ng |rom gm@||@com  Wed Apr  1 20:57:28 2020
From: george@br|d@ @end|ng |rom gm@||@com (george brida)
Date: Wed, 1 Apr 2020 20:57:28 +0200
Subject: [R] Mapping of countries
In-Reply-To: <CAHXS41xr+Zo-T3rrTYGpFAQxbu+mJo_yg6P8xEPMoyv44iU0QA@mail.gmail.com>
References: <CAGsroM29gXKXRNURDAmzotgnMtDLqAZgGoc66iuoJ4zBcmNm0A@mail.gmail.com>
 <CA+8X3fXDjKjCyceJUyJPkgQnmVbEzNFLuqJCPsyDbRwYEM8hGA@mail.gmail.com>
 <CAGsroM1hppxCmg3xfmdsWGP=XvEHjyVAaHAboOwF=FcyhrZzeg@mail.gmail.com>
 <CAGsroM3Hxq9xx-YgLqpOsE9fY2dAvPfNQmOWwDKigCd3TZOdRQ@mail.gmail.com>
 <CAHXS41xr+Zo-T3rrTYGpFAQxbu+mJo_yg6P8xEPMoyv44iU0QA@mail.gmail.com>
Message-ID: <CAGsroM2f7eu7T1r_d1p73770MDXsg4KcsgMaoE1yr2fh7Vkh2w@mail.gmail.com>

Thanks a lot Jim..

Thank you Ani and Rasmus.

Best

On Wed, Apr 1, 2020 at 2:54 AM ani jaya <gaaauul at gmail.com> wrote:

> Maybe simply add:
>
>
> points(station$Lon, station$Lat, col="red", pch=16, label="Your Country")
> text(station$Lon, station$Lat,"Your Country",
>      col="black", pos=3, cex=1)
>
> station$Lon and Lat in your coordinate position.
>
> Regards,
> Ani
>
>
> On Tue, Mar 31, 2020 at 10:58 PM george brida <george.brida at gmail.com>
> wrote:
> >
> > Dear Jim,
> >
> > Is it possible to add also a title to this map?
> >
> > Many thanks
> >
> >
> >
> > On Tue, Mar 31, 2020 at 2:29 PM george brida <george.brida at gmail.com>
> wrote:
> >
> > > Dear Jim,
> > >
> > > Thank you very much. I obtained now the required map. I would like to
> know
> > > how to add the names of the countries.
> > >
> > > Best
> > > George
> > >
> > > On Tue, Mar 31, 2020 at 10:10 AM Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >
> > >> Hi George,
> > >> Try this:
> > >>
> > >> library(maps)
> > >> map("world",xlim=c(34.353,60.369),ylim=c(16.7,32.193),
> > >>  regions="Saudi Arabia",col="yellow",fill=TRUE)
> > >> map("world",regions="Bahrain",col="yellow",fill=TRUE,add=TRUE)
> > >> map("world",regions="Kuwait",col="lightblue",fill=TRUE,add=TRUE)
> > >> map("world",regions="Qatar",col="yellow",fill=TRUE,add=TRUE)
> > >> map("world",regions="United Arab
> > >> Emirates",col="lightblue",fill=TRUE,add=TRUE)
> > >> map("world",regions="Oman",col="lightgreen",fill=TRUE,add=TRUE)
> > >>
> > >> Jim
> > >>
> > >> On Tue, Mar 31, 2020 at 12:39 PM george brida <george.brida at gmail.com
> >
> > >> wrote:
> > >> >
> > >> > Dear R users,
> > >> >
> > >> > i would like to plot the maps of the Gulf Cooperation Council (GCC)
> > >> > countries (KSA, Qatar, Bahrain, Kuwait, UAE and Oman) with these
> > >> > constraints: i/ KSA , Qatar and Bahrain have the same face color ,
> ii/
> > >> > Kuweit and UAE with the same face color and iii/Oman  with another
> face
> > >> > color. Is there any code in R doing this task.
> > >> >
> > >> > Many thanks.
> > >> >
> > >> >         [[alternative HTML version deleted]]
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 10:30:29 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 10:30:29 +0200
Subject: [R] project path in Rmd
Message-ID: <239110ee-781d-be75-9d97-306296816233@rgzm.de>

Dear useRs,

I believe this is R code so appropriate for this list, but let me know
if this relates more to RStudio itself.

I am working on an RStudio project. In that project directory, I have a
folder called 'analysis' and in there a folder called 'scripts'
('~/analysis/scripts').
My data files needed for the scripts are in '~/analysis/raw_data' and
the output should be in '~/analysis/derived_data'.

My scripts are Rmd files, so when I knit them, their working directory
is where they are located, i.e. '~/analysis/scripts'. The problem I then
have is to specify the path for 'raw_data' and 'derived_data' since
during the rendering I am not relative to the project directory anymore.
And these folders are not subfolders of the working directory?
'~/analysis/scripts'.
I hope I am clear here...

I would like to avoid absolute paths of course, but I do not know how to
proceed.
What would be nice is a way to get the project directory in the scripts,
rather than their working directory.
Does that make sense?

Thank you in advance
Best,
Ivan

-- 
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr  2 10:37:59 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Apr 2020 01:37:59 -0700
Subject: [R] project path in Rmd
In-Reply-To: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
Message-ID: <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>

I recommend not using setwd. Then you can always assume your current working directory is your project directory and reference relative to that.

On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Dear useRs,
>
>I believe this is R code so appropriate for this list, but let me know
>if this relates more to RStudio itself.
>
>I am working on an RStudio project. In that project directory, I have a
>folder called 'analysis' and in there a folder called 'scripts'
>('~/analysis/scripts').
>My data files needed for the scripts are in '~/analysis/raw_data' and
>the output should be in '~/analysis/derived_data'.
>
>My scripts are Rmd files, so when I knit them, their working directory
>is where they are located, i.e. '~/analysis/scripts'. The problem I
>then
>have is to specify the path for 'raw_data' and 'derived_data' since
>during the rendering I am not relative to the project directory
>anymore.
>And these folders are not subfolders of the working directory?
>'~/analysis/scripts'.
>I hope I am clear here...
>
>I would like to avoid absolute paths of course, but I do not know how
>to
>proceed.
>What would be nice is a way to get the project directory in the
>scripts,
>rather than their working directory.
>Does that make sense?
>
>Thank you in advance
>Best,
>Ivan

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 10:40:07 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 10:40:07 +0200
Subject: [R] project path in Rmd
In-Reply-To: <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
Message-ID: <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>

Hi Jeff,

But if I do not use setwd(), the current working directory is NOT the
project directory.

That's what my problem is about... I guess I was not clear in my email...

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 10:37, Jeff Newmiller wrote:
> I recommend not using setwd. Then you can always assume your current working directory is your project directory and reference relative to that.
>
> On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I believe this is R code so appropriate for this list, but let me know
>> if this relates more to RStudio itself.
>>
>> I am working on an RStudio project. In that project directory, I have a
>> folder called 'analysis' and in there a folder called 'scripts'
>> ('~/analysis/scripts').
>> My data files needed for the scripts are in '~/analysis/raw_data' and
>> the output should be in '~/analysis/derived_data'.
>>
>> My scripts are Rmd files, so when I knit them, their working directory
>> is where they are located, i.e. '~/analysis/scripts'. The problem I
>> then
>> have is to specify the path for 'raw_data' and 'derived_data' since
>> during the rendering I am not relative to the project directory
>> anymore.
>> And these folders are not subfolders of the working directory?
>> '~/analysis/scripts'.
>> I hope I am clear here...
>>
>> I would like to avoid absolute paths of course, but I do not know how
>> to
>> proceed.
>> What would be nice is a way to get the project directory in the
>> scripts,
>> rather than their working directory.
>> Does that make sense?
>>
>> Thank you in advance
>> Best,
>> Ivan


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr  2 10:56:14 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Apr 2020 01:56:14 -0700
Subject: [R] project path in Rmd
In-Reply-To: <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
 <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>
Message-ID: <94BDC03F-4996-447E-91FD-D165A324A8A9@dcn.davis.ca.us>

Make it so. Outside R.

At the command line, use cd before you start R. This should feel natural.

In a GUI file browser, double clicking on a file type assigned to a program by default sets the containing directory to be current directory before kicking off the program, so double-clicking on an empty Project.RData file will do it. Or you can use RStudio Project.Rproj files the same way.

On April 2, 2020 1:40:07 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Hi Jeff,
>
>But if I do not use setwd(), the current working directory is NOT the
>project directory.
>
>That's what my problem is about... I guess I was not clear in my
>email...
>
>Ivan
>
>--
>Dr. Ivan Calandra
>TraCEr, laboratory for Traceology and Controlled Experiments
>MONREPOS Archaeological Research Centre and
>Museum for Human Behavioural Evolution
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>On 02/04/2020 10:37, Jeff Newmiller wrote:
>> I recommend not using setwd. Then you can always assume your current
>working directory is your project directory and reference relative to
>that.
>>
>> On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de>
>wrote:
>>> Dear useRs,
>>>
>>> I believe this is R code so appropriate for this list, but let me
>know
>>> if this relates more to RStudio itself.
>>>
>>> I am working on an RStudio project. In that project directory, I
>have a
>>> folder called 'analysis' and in there a folder called 'scripts'
>>> ('~/analysis/scripts').
>>> My data files needed for the scripts are in '~/analysis/raw_data'
>and
>>> the output should be in '~/analysis/derived_data'.
>>>
>>> My scripts are Rmd files, so when I knit them, their working
>directory
>>> is where they are located, i.e. '~/analysis/scripts'. The problem I
>>> then
>>> have is to specify the path for 'raw_data' and 'derived_data' since
>>> during the rendering I am not relative to the project directory
>>> anymore.
>>> And these folders are not subfolders of the working directory?
>>> '~/analysis/scripts'.
>>> I hope I am clear here...
>>>
>>> I would like to avoid absolute paths of course, but I do not know
>how
>>> to
>>> proceed.
>>> What would be nice is a way to get the project directory in the
>>> scripts,
>>> rather than their working directory.
>>> Does that make sense?
>>>
>>> Thank you in advance
>>> Best,
>>> Ivan
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 10:59:03 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 10:59:03 +0200
Subject: [R] project path in Rmd
In-Reply-To: <94BDC03F-4996-447E-91FD-D165A324A8A9@dcn.davis.ca.us>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
 <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>
 <94BDC03F-4996-447E-91FD-D165A324A8A9@dcn.davis.ca.us>
Message-ID: <5dc0f14a-017b-7870-477b-457a013cbd1e@rgzm.de>

So what you're saying is that I should have scripts in the project
directory and not in a subfolder within it, right?

But what if I need (or at least want) to?

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 10:56, Jeff Newmiller wrote:
> Make it so. Outside R.
>
> At the command line, use cd before you start R. This should feel natural.
>
> In a GUI file browser, double clicking on a file type assigned to a program by default sets the containing directory to be current directory before kicking off the program, so double-clicking on an empty Project.RData file will do it. Or you can use RStudio Project.Rproj files the same way.
>
> On April 2, 2020 1:40:07 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Hi Jeff,
>>
>> But if I do not use setwd(), the current working directory is NOT the
>> project directory.
>>
>> That's what my problem is about... I guess I was not clear in my
>> email...
>>
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 02/04/2020 10:37, Jeff Newmiller wrote:
>>> I recommend not using setwd. Then you can always assume your current
>> working directory is your project directory and reference relative to
>> that.
>>> On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de>
>> wrote:
>>>> Dear useRs,
>>>>
>>>> I believe this is R code so appropriate for this list, but let me
>> know
>>>> if this relates more to RStudio itself.
>>>>
>>>> I am working on an RStudio project. In that project directory, I
>> have a
>>>> folder called 'analysis' and in there a folder called 'scripts'
>>>> ('~/analysis/scripts').
>>>> My data files needed for the scripts are in '~/analysis/raw_data'
>> and
>>>> the output should be in '~/analysis/derived_data'.
>>>>
>>>> My scripts are Rmd files, so when I knit them, their working
>> directory
>>>> is where they are located, i.e. '~/analysis/scripts'. The problem I
>>>> then
>>>> have is to specify the path for 'raw_data' and 'derived_data' since
>>>> during the rendering I am not relative to the project directory
>>>> anymore.
>>>> And these folders are not subfolders of the working directory?
>>>> '~/analysis/scripts'.
>>>> I hope I am clear here...
>>>>
>>>> I would like to avoid absolute paths of course, but I do not know
>> how
>>>> to
>>>> proceed.
>>>> What would be nice is a way to get the project directory in the
>>>> scripts,
>>>> rather than their working directory.
>>>> Does that make sense?
>>>>
>>>> Thank you in advance
>>>> Best,
>>>> Ivan
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Apr  2 10:54:55 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 2 Apr 2020 11:54:55 +0300
Subject: [R] project path in Rmd
In-Reply-To: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
Message-ID: <20200402115455.2ff55c1f@Tarkus>

On Thu, 2 Apr 2020 10:30:29 +0200
Ivan Calandra <calandra at rgzm.de> wrote:

> The problem I then have is to specify the path for 'raw_data' and
> 'derived_data' <...> And these folders are not subfolders of
> the working directory '~/analysis/scripts'.
 
> I would like to avoid absolute paths of course

Is there a reason to avoid relative paths built using '..' to access
parent directories?

-- 
Best regards,
Ivan


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 11:02:56 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 11:02:56 +0200
Subject: [R] project path in Rmd
In-Reply-To: <20200402115455.2ff55c1f@Tarkus>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <20200402115455.2ff55c1f@Tarkus>
Message-ID: <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>

I do not know this ".." command (could you please show me how to use it
in a relative path?), but it sounds like a good start.

But it implies that I know in advance how many folders up the parent
directory is. I guess in most cases it will always be the same, but it
would be even better if it could be applied generically.

As I said, ideally, I would like to get the project directory from a
script located in a subfolder.

Thanks!
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 10:54, Ivan Krylov wrote:
> On Thu, 2 Apr 2020 10:30:29 +0200
> Ivan Calandra <calandra at rgzm.de> wrote:
>
>> The problem I then have is to specify the path for 'raw_data' and
>> 'derived_data' <...> And these folders are not subfolders of
>> the working directory '~/analysis/scripts'.
>  
>> I would like to avoid absolute paths of course
> Is there a reason to avoid relative paths built using '..' to access
> parent directories?
>


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 11:08:58 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 11:08:58 +0200
Subject: [R] project path in Rmd
In-Reply-To: <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <20200402115455.2ff55c1f@Tarkus>
 <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
Message-ID: <7a52ee1a-54b9-f9ed-d785-2b9c3e917af6@rgzm.de>

What about searching for the .Rproj file and using its path as the new
working directory using setwd()?
But I know that it is indeed not recommended in knitted files (FAQ #5
<https://yihui.org/knitr/faq/>).

And I do not know how to search up the folder structure anyway...

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 11:02, Ivan Calandra wrote:
> I do not know this ".." command (could you please show me how to use it
> in a relative path?), but it sounds like a good start.
>
> But it implies that I know in advance how many folders up the parent
> directory is. I guess in most cases it will always be the same, but it
> would be even better if it could be applied generically.
>
> As I said, ideally, I would like to get the project directory from a
> script located in a subfolder.
>
> Thanks!
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 02/04/2020 10:54, Ivan Krylov wrote:
>> On Thu, 2 Apr 2020 10:30:29 +0200
>> Ivan Calandra <calandra at rgzm.de> wrote:
>>
>>> The problem I then have is to specify the path for 'raw_data' and
>>> 'derived_data' <...> And these folders are not subfolders of
>>> the working directory '~/analysis/scripts'.
>>  
>>> I would like to avoid absolute paths of course
>> Is there a reason to avoid relative paths built using '..' to access
>> parent directories?
>>


From nev||@@mo@ @end|ng |rom gm@||@com  Thu Apr  2 11:16:53 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Thu, 2 Apr 2020 20:16:53 +1100
Subject: [R] disk.frame change default directory that disk.frames are saved
 in?
Message-ID: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>

I would like to change the default  directory within which all disk frames
are saved  to a directory on an SSD, which is not the drive there the r
tempdir is located. for example instead of saving all disk.frames in
tempdir the are all saved in ./media/SSDdrive/DF?


Thanks

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 11:21:47 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 10:21:47 +0100
Subject: [R] project path in Rmd
In-Reply-To: <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <20200402115455.2ff55c1f@Tarkus>
 <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
Message-ID: <09f30516-7af5-fee7-5efd-e6db69c75fb3@sapo.pt>

Hello,

This is not an answer to the original problem, it's about '..'. (And a 
bit more.)

About '..', see if the following sequence of instructions can help.
Subdirectories '~/tmp' and '~/snap' exist on my PC, change to 
'~/analysis/scripts' or to what makes sense on yours.

od <- getwd()          # save this for later

setwd('~/tmp')         #
list.files('../snap')  # goes up one level and
                        # executes a SO/files related command
curr <- getwd()
basename(curr)         # these two instructions are meant to show that
dirname(curr)          # you don't need to know how many levels you have
                        # to go up, you can parse 'curr' if basename and
                        # dirname are not enough

setwd(od)              # back to where I was


Hope this helps,

Rui Barradas

?s 10:02 de 02/04/20, Ivan Calandra escreveu:
> I do not know this ".." command (could you please show me how to use it
> in a relative path?), but it sounds like a good start.
> 
> But it implies that I know in advance how many folders up the parent
> directory is. I guess in most cases it will always be the same, but it
> would be even better if it could be applied generically.
> 
> As I said, ideally, I would like to get the project directory from a
> script located in a subfolder.
> 
> Thanks!
> Ivan
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 02/04/2020 10:54, Ivan Krylov wrote:
>> On Thu, 2 Apr 2020 10:30:29 +0200
>> Ivan Calandra <calandra at rgzm.de> wrote:
>>
>>> The problem I then have is to specify the path for 'raw_data' and
>>> 'derived_data' <...> And these folders are not subfolders of
>>> the working directory '~/analysis/scripts'.
>>   
>>> I would like to avoid absolute paths of course
>> Is there a reason to avoid relative paths built using '..' to access
>> parent directories?
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Apr  2 11:34:05 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 2 Apr 2020 12:34:05 +0300
Subject: [R] project path in Rmd
In-Reply-To: <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <20200402115455.2ff55c1f@Tarkus>
 <3b3b4384-cea9-5a72-542d-88c5db564b82@rgzm.de>
Message-ID: <20200402123405.6fafdc8d@Tarkus>

On Thu, 2 Apr 2020 11:02:56 +0200
Ivan Calandra <calandra at rgzm.de> wrote:

> I do not know this ".." command (could you please show me how to use
> it in a relative path?), but it sounds like a good start.

Each '..' in the path moves you up one level in the directory tree.
Here I use '..' once to access the sibling of the current directory,
then verify my assumption using the absolute path:

setwd('~/temp')
setwd('../archive')
getwd() == path.expand('~/archive')
# [1] TRUE

A related thing is using '.' to mean the *current* directory (i.e. the
value of getwd()). It is sometimes useful e.g. if you have a file named
'~' in your current directory and want to avoid expanding it to your
home directory.

> But it implies that I know in advance how many folders up the parent
> directory is.

Yes, I think that hardcoding some part of *within-project* directory
structure is unavoidable. But it shouldn't cause any troubles as long
as the project (analysis/{scripts,raw_data,derived_data}) is considered
as a whole.

-- 
Best regards,
Ivan


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 12:58:33 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 11:58:33 +0100
Subject: [R] 
 disk.frame change default directory that disk.frames are saved in?
In-Reply-To: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>
References: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>
Message-ID: <05442e64-a3d0-928e-8f0a-b3c9b8a3be90@sapo.pt>

Hello,

This is SO dependent, see if this StackOverflow post can be of help.

https://stackoverflow.com/questions/17107206/change-temporary-directory

Hope this helps,

Rui Barradas

?s 10:16 de 02/04/20, nevil amos escreveu:
> I would like to change the default  directory within which all disk frames
> are saved  to a directory on an SSD, which is not the drive there the r
> tempdir is located. for example instead of saving all disk.frames in
> tempdir the are all saved in ./media/SSDdrive/DF?
> 
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tr|ng @end|ng |rom gvdnet@dk  Thu Apr  2 13:07:51 2020
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Thu, 2 Apr 2020 13:07:51 +0200
Subject: [R] nls problem
Message-ID: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>

Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem with
nls which apparently gives a decent fit to the parable below, even without
starting values. But when I then think I know the meaning of the three
parameters a, b, and d it goes very wrong. I guess I am again overlooking
something easy but cannot spot it.

BW
Troels Ring,

Aalborg, Denmark

 

 

aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247, -0.302691, 

            -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906

), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818, 

          7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
row.names = c(NA, 

 
-10L))

m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))

 

with(aedf,plot(pH,Flux))

with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))

 

m

# a        b        d 

# -1630.70   457.67   -32.11 

 

fitted(m)

# 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742 -0.50048799

# [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657

 

FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2

 

FPG(aedf$pH)

# [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467

# [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917

 

# So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?

 


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com
<http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
p&url=/> 

	[[alternative HTML version deleted]]


From t|m@how@rd @end|ng |rom dec@ny@gov  Thu Apr  2 13:08:21 2020
From: t|m@how@rd @end|ng |rom dec@ny@gov (Howard, Tim G (DEC))
Date: Thu, 2 Apr 2020 11:08:21 +0000
Subject: [R] project path in Rmd (Ivan Calandra)
In-Reply-To: <mailman.358172.1.1585821936.37868.r-help@r-project.org>
References: <mailman.358172.1.1585821936.37868.r-help@r-project.org>
Message-ID: <BL0PR0901MB2996CE08C66147139CD22C1CA8C60@BL0PR0901MB2996.namprd09.prod.outlook.com>

You also should be able to reference locations from the 'root' of your project using the here() package. 

https://here.r-lib.org/

Best, 
Tim Howard


> Date: Thu, 2 Apr 2020 10:21:47 +0100

> From: Rui Barradas <ruipbarradas at sapo.pt>

> To: Ivan Calandra <calandra at rgzm.de>

> Cc: "r-help at r-project.org" <r-help at r-project.org>

> Subject: Re: [R] project path in Rmd

> Message-ID: <09f30516-7af5-fee7-5efd-e6db69c75fb3 at sapo.pt>

> Content-Type: text/plain; charset="utf-8"; Format="flowed"

> 

> Hello,

> 

> This is not an answer to the original problem, it's about '..'. (And a

> bit more.)

> 

> About '..', see if the following sequence of instructions can help.

> Subdirectories '~/tmp' and '~/snap' exist on my PC, change to

> '~/analysis/scripts' or to what makes sense on yours.

> 

> od <- getwd()????????? # save this for later

> 

> setwd('~/tmp')???????? #

> list.files('../snap')? # goes up one level and

> ??????????????????????? # executes a SO/files related command

> curr <- getwd()

> basename(curr)???????? # these two instructions are meant to show that

> dirname(curr)????????? # you don't need to know how many levels you have

> ??????????????????????? # to go up, you can parse 'curr' if basename and

> ??????????????????????? # dirname are not enough

> 

> setwd(od)????????????? # back to where I was

> 

> 

> Hope this helps,

> Rui Barradas

> ?s 10:02 de 02/04/20, Ivan Calandra escreveu:

> I do not know this ".." command (could you please show me how to use it

> in a relative path?), but it sounds like a good start.

>

> But it implies that I know in advance how many folders up the parent

> directory is. I guess in most cases it will always be the same, but it

> would be even better if it could be applied generically.

>

> As I said, ideally, I would like to get the project directory from a

> script located in a subfolder.

>

> Thanks!

> Ivan

>

> --

> Dr. Ivan Calandra

> TraCEr, laboratory for Traceology and Controlled Experiments

> MONREPOS Archaeological Research Centre and

> Museum for Human Behavioural Evolution

> Schloss Monrepos

> 56567 Neuwied, Germany

> +49 (0) 2631 9772-243

> https://www.researchgate.net/profile/Ivan_Calandra

>

> On 02/04/2020 10:54, Ivan Krylov wrote:

>> On Thu, 2 Apr 2020 10:30:29 +0200

>> Ivan Calandra <calandra at rgzm.de> wrote:

>>

>>> The problem I then have is to specify the path for 'raw_data' and

>>> 'derived_data' <...> And these folders are not subfolders of

>>> the working directory '~/analysis/scripts'.

>>

>>> I would like to avoid absolute paths of course

>> Is there a reason to avoid relative paths built using '..' to access

>> parent directories?

>>

>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 13:30:33 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 12:30:33 +0100
Subject: [R] nls problem
In-Reply-To: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
Message-ID: <0ec086b1-7710-8ebc-8293-5a5ac47fc7be@sapo.pt>

Hello,

Tip: in a formula, pH^2 = pH*pH is an interaction.

pH^2 = pH*pH = pH + pH + pH:pH = pH

Try I(pH^2)

Hope this helps,

Rui Barradas

?s 12:07 de 02/04/20, Troels Ring escreveu:
> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem with
> nls which apparently gives a decent fit to the parable below, even without
> starting values. But when I then think I know the meaning of the three
> parameters a, b, and d it goes very wrong. I guess I am again overlooking
> something easy but cannot spot it.
> 
> BW
> Troels Ring,
> 
> Aalborg, Denmark
> 
>   
> 
>   
> 
> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247, -0.302691,
> 
>              -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906
> 
> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
> 
>            7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
> row.names = c(NA,
> 
>   
> -10L))
> 
> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
> 
>   
> 
> with(aedf,plot(pH,Flux))
> 
> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
> 
>   
> 
> m
> 
> # a        b        d
> 
> # -1630.70   457.67   -32.11
> 
>   
> 
> fitted(m)
> 
> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742 -0.50048799
> 
> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
> 
>   
> 
> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
> 
>   
> 
> FPG(aedf$pH)
> 
> # [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467
> 
> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
> 
>   
> 
> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
> 
>   
> 
> 
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 13:41:44 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 13:41:44 +0200
Subject: [R] project path in Rmd (Ivan Calandra)
In-Reply-To: <BL0PR0901MB2996CE08C66147139CD22C1CA8C60@BL0PR0901MB2996.namprd09.prod.outlook.com>
References: <mailman.358172.1.1585821936.37868.r-help@r-project.org>
 <BL0PR0901MB2996CE08C66147139CD22C1CA8C60@BL0PR0901MB2996.namprd09.prod.outlook.com>
Message-ID: <e58b44fc-1be7-6761-d6bf-f047b0e0c04b@rgzm.de>

Thanks Tim, that's exactly what I needed.

I came across the here package before, but I didn't see the point of
using it since RStudio already deals with relative paths and sets up the
working directory where the file is.

I didn't notice the functionality of getting the project directory with
the here package. IMHO, this functionality should be more advertised;
this seems to me to be the greatest advantage of using it!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 13:08, Howard, Tim G (DEC) wrote:
> You also should be able to reference locations from the 'root' of your project using the here() package. 
>
> https://here.r-lib.org/
>
> Best, 
> Tim Howard
>
>
>> Date: Thu, 2 Apr 2020 10:21:47 +0100
>> From: Rui Barradas <ruipbarradas at sapo.pt>
>> To: Ivan Calandra <calandra at rgzm.de>
>> Cc: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: Re: [R] project path in Rmd
>> Message-ID: <09f30516-7af5-fee7-5efd-e6db69c75fb3 at sapo.pt>
>> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>> Hello,
>> This is not an answer to the original problem, it's about '..'. (And a
>> bit more.)
>> About '..', see if the following sequence of instructions can help.
>> Subdirectories '~/tmp' and '~/snap' exist on my PC, change to
>> '~/analysis/scripts' or to what makes sense on yours.
>> od <- getwd()????????? # save this for later
>> setwd('~/tmp')???????? #
>> list.files('../snap')? # goes up one level and
>> ??????????????????????? # executes a SO/files related command
>> curr <- getwd()
>> basename(curr)???????? # these two instructions are meant to show that
>> dirname(curr)????????? # you don't need to know how many levels you have
>> ??????????????????????? # to go up, you can parse 'curr' if basename and
>> ??????????????????????? # dirname are not enough
>> setwd(od)????????????? # back to where I was
>> Hope this helps,
>> Rui Barradas
>> ?s 10:02 de 02/04/20, Ivan Calandra escreveu:
>> I do not know this ".." command (could you please show me how to use it
>> in a relative path?), but it sounds like a good start.
>> But it implies that I know in advance how many folders up the parent
>> directory is. I guess in most cases it will always be the same, but it
>> would be even better if it could be applied generically.
>> As I said, ideally, I would like to get the project directory from a
>> script located in a subfolder.
>> Thanks!
>> Ivan
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>> On 02/04/2020 10:54, Ivan Krylov wrote:
>>> On Thu, 2 Apr 2020 10:30:29 +0200
>>> Ivan Calandra <calandra at rgzm.de> wrote:
>>>> The problem I then have is to specify the path for 'raw_data' and
>>>> 'derived_data' <...> And these folders are not subfolders of
>>>> the working directory '~/analysis/scripts'.
>>>> I would like to avoid absolute paths of course
>>> Is there a reason to avoid relative paths built using '..' to access
>>> parent directories?


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 13:56:40 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 12:56:40 +0100
Subject: [R] nls problem
In-Reply-To: <0ec086b1-7710-8ebc-8293-5a5ac47fc7be@sapo.pt>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
 <0ec086b1-7710-8ebc-8293-5a5ac47fc7be@sapo.pt>
Message-ID: <4047c739-bd0d-9139-8f10-2e252fd9a2bf@sapo.pt>

Hello,

Sorry, disregard my previous e-mail.
Instead of your FPG function try


FPG <- function(pH, model) {
   coef(model)[1] + coef(model)[2]*pH + coef(model)[3]*pH^2
}

FPG(aedf$pH, m)
fitted(m)


Hope this helps,

Rui Barradas

?s 12:30 de 02/04/20, Rui Barradas escreveu:
> Hello,
> 
> Tip: in a formula, pH^2 = pH*pH is an interaction.
> 
> pH^2 = pH*pH = pH + pH + pH:pH = pH
> 
> Try I(pH^2)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 12:07 de 02/04/20, Troels Ring escreveu:
>> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple 
>> problem with
>> nls which apparently gives a decent fit to the parable below, even 
>> without
>> starting values. But when I then think I know the meaning of the three
>> parameters a, b, and d it goes very wrong. I guess I am again overlooking
>> something easy but cannot spot it.
>>
>> BW
>> Troels Ring,
>>
>> Aalborg, Denmark
>>
>>
>>
>> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247, 
>> -0.302691,
>>
>> ???????????? -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, 
>> -1.76906
>>
>> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
>>
>> ?????????? 7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
>> row.names = c(NA,
>>
>> -10L))
>>
>> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
>>
>>
>> with(aedf,plot(pH,Flux))
>>
>> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
>>
>>
>> m
>>
>> # a??????? b??????? d
>>
>> # -1630.70?? 457.67?? -32.11
>>
>>
>> fitted(m)
>>
>> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742 
>> -0.50048799
>>
>> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
>>
>>
>> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
>>
>>
>> FPG(aedf$pH)
>>
>> # [1] -0.016359649? 0.107602395? 0.074773375 -0.007166685 -0.133786467
>>
>> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
>>
>>
>> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
>>
>>
>>
>> This email has been scanned by BullGuard antivirus protection.
>> For more info visit www.bullguard.com
>> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt 
>>
>> p&url=/>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 14:01:16 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 13:01:16 +0100
Subject: [R] nls problem
In-Reply-To: <4047c739-bd0d-9139-8f10-2e252fd9a2bf@sapo.pt>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
 <0ec086b1-7710-8ebc-8293-5a5ac47fc7be@sapo.pt>
 <4047c739-bd0d-9139-8f10-2e252fd9a2bf@sapo.pt>
Message-ID: <1658ebed-e765-9858-8545-402b43ad5901@sapo.pt>

Simpler:


FPG2 <- function(x, model){
   as.vector(cbind(1, x, x^2) %*% coef(model))
}


Hope this helps,

Rui Barradas

?s 12:56 de 02/04/20, Rui Barradas escreveu:
> Hello,
> 
> Sorry, disregard my previous e-mail.
> Instead of your FPG function try
> 
> 
> FPG <- function(pH, model) {
>  ? coef(model)[1] + coef(model)[2]*pH + coef(model)[3]*pH^2
> }
> 
> FPG(aedf$pH, m)
> fitted(m)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 12:30 de 02/04/20, Rui Barradas escreveu:
>> Hello,
>>
>> Tip: in a formula, pH^2 = pH*pH is an interaction.
>>
>> pH^2 = pH*pH = pH + pH + pH:pH = pH
>>
>> Try I(pH^2)
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 12:07 de 02/04/20, Troels Ring escreveu:
>>> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple 
>>> problem with
>>> nls which apparently gives a decent fit to the parable below, even 
>>> without
>>> starting values. But when I then think I know the meaning of the three
>>> parameters a, b, and d it goes very wrong. I guess I am again 
>>> overlooking
>>> something easy but cannot spot it.
>>>
>>> BW
>>> Troels Ring,
>>>
>>> Aalborg, Denmark
>>>
>>>
>>>
>>> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247, 
>>> -0.302691,
>>>
>>> ???????????? -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, 
>>> -1.76906
>>>
>>> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
>>>
>>> ?????????? 7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
>>> row.names = c(NA,
>>>
>>> -10L))
>>>
>>> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
>>>
>>>
>>> with(aedf,plot(pH,Flux))
>>>
>>> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
>>>
>>>
>>> m
>>>
>>> # a??????? b??????? d
>>>
>>> # -1630.70?? 457.67?? -32.11
>>>
>>>
>>> fitted(m)
>>>
>>> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742 
>>> -0.50048799
>>>
>>> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
>>>
>>>
>>> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
>>>
>>>
>>> FPG(aedf$pH)
>>>
>>> # [1] -0.016359649? 0.107602395? 0.074773375 -0.007166685 -0.133786467
>>>
>>> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
>>>
>>>
>>> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
>>>
>>>
>>>
>>> This email has been scanned by BullGuard antivirus protection.
>>> For more info visit www.bullguard.com
>>> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt 
>>>
>>> p&url=/>
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr  2 14:39:53 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Apr 2020 12:39:53 +0000
Subject: [R] ggplot stat smooth and poly
Message-ID: <37de34217e244f10bcc7b5e5215609de@SRVEXCHCM1302.precheza.cz>

Dear all

I am not sure, but I believe that in past it was possible to add smoothing
lines in ggplot even if some group did not have enough points to perform
calculation (although I did not find any version which could deliver it).

Here is the code and data

library(ggplot2)
p <- ggplot(test, aes(x=one, y=two, colour=three))
p+geom_point(size=5)+stat_smooth(method="lm")
***line added to each group

p+geom_point(size=5)+stat_smooth(method="lm", formula=y~poly(x,2))
Warning message:
Computation failed in `stat_smooth()`:
'degree' must be less than number of unique points 
***no line added to any group

test <- structure(list(one = 1:20, two = c(1L, 4L, 9L, 16L, 25L, 36L, 
49L, 64L, 81L, 100L, 121L, 144L, 169L, 196L, 225L, 256L, 289L, 
324L, 361L, 400L), three = c("a", "a", "a", "a", "b", "b", "b", 
"b", "c", "c", "c", "c", "c", "d", "d", "e", "e", "e", "e", "e"
)), class = "data.frame", row.names = c(NA, -20L))

My question:  
Is it possible to add smoothing line just to the groups where it can be
added? I know that I could exclude "d" level from my data but I would prefer
to keep them and add only smoothing lines where they could be computed.

Best regards
Petr

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr  2 15:40:07 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Apr 2020 06:40:07 -0700
Subject: [R] project path in Rmd
In-Reply-To: <5dc0f14a-017b-7870-477b-457a013cbd1e@rgzm.de>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
 <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>
 <94BDC03F-4996-447E-91FD-D165A324A8A9@dcn.davis.ca.us>
 <5dc0f14a-017b-7870-477b-457a013cbd1e@rgzm.de>
Message-ID: <5567F296-7EEB-415A-AB43-A313516556A3@dcn.davis.ca.us>

Where did this false dichotomy come from? The rmarkdown::render function has quite flexible parameters for compiling rmarkdown files in subdirectories without changing the current directory. And RStudio has a Global configuration to enable compiling using the Project directory as "current" under the RMarkdown settings.

On April 2, 2020 1:59:03 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>So what you're saying is that I should have scripts in the project
>directory and not in a subfolder within it, right?
>
>But what if I need (or at least want) to?
>
>Ivan
>
>--
>Dr. Ivan Calandra
>TraCEr, laboratory for Traceology and Controlled Experiments
>MONREPOS Archaeological Research Centre and
>Museum for Human Behavioural Evolution
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>On 02/04/2020 10:56, Jeff Newmiller wrote:
>> Make it so. Outside R.
>>
>> At the command line, use cd before you start R. This should feel
>natural.
>>
>> In a GUI file browser, double clicking on a file type assigned to a
>program by default sets the containing directory to be current
>directory before kicking off the program, so double-clicking on an
>empty Project.RData file will do it. Or you can use RStudio
>Project.Rproj files the same way.
>>
>> On April 2, 2020 1:40:07 AM PDT, Ivan Calandra <calandra at rgzm.de>
>wrote:
>>> Hi Jeff,
>>>
>>> But if I do not use setwd(), the current working directory is NOT
>the
>>> project directory.
>>>
>>> That's what my problem is about... I guess I was not clear in my
>>> email...
>>>
>>> Ivan
>>>
>>> --
>>> Dr. Ivan Calandra
>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>> MONREPOS Archaeological Research Centre and
>>> Museum for Human Behavioural Evolution
>>> Schloss Monrepos
>>> 56567 Neuwied, Germany
>>> +49 (0) 2631 9772-243
>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>
>>> On 02/04/2020 10:37, Jeff Newmiller wrote:
>>>> I recommend not using setwd. Then you can always assume your
>current
>>> working directory is your project directory and reference relative
>to
>>> that.
>>>> On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de>
>>> wrote:
>>>>> Dear useRs,
>>>>>
>>>>> I believe this is R code so appropriate for this list, but let me
>>> know
>>>>> if this relates more to RStudio itself.
>>>>>
>>>>> I am working on an RStudio project. In that project directory, I
>>> have a
>>>>> folder called 'analysis' and in there a folder called 'scripts'
>>>>> ('~/analysis/scripts').
>>>>> My data files needed for the scripts are in '~/analysis/raw_data'
>>> and
>>>>> the output should be in '~/analysis/derived_data'.
>>>>>
>>>>> My scripts are Rmd files, so when I knit them, their working
>>> directory
>>>>> is where they are located, i.e. '~/analysis/scripts'. The problem
>I
>>>>> then
>>>>> have is to specify the path for 'raw_data' and 'derived_data'
>since
>>>>> during the rendering I am not relative to the project directory
>>>>> anymore.
>>>>> And these folders are not subfolders of the working directory?
>>>>> '~/analysis/scripts'.
>>>>> I hope I am clear here...
>>>>>
>>>>> I would like to avoid absolute paths of course, but I do not know
>>> how
>>>>> to
>>>>> proceed.
>>>>> What would be nice is a way to get the project directory in the
>>>>> scripts,
>>>>> rather than their working directory.
>>>>> Does that make sense?
>>>>>
>>>>> Thank you in advance
>>>>> Best,
>>>>> Ivan
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr  2 15:42:28 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Apr 2020 15:42:28 +0200
Subject: [R] project path in Rmd
In-Reply-To: <5567F296-7EEB-415A-AB43-A313516556A3@dcn.davis.ca.us>
References: <239110ee-781d-be75-9d97-306296816233@rgzm.de>
 <CA2DCCC8-A281-4A94-BF67-634A4EA88A11@dcn.davis.ca.us>
 <0319b44a-a2ae-70aa-4cd8-f457b10e02df@rgzm.de>
 <94BDC03F-4996-447E-91FD-D165A324A8A9@dcn.davis.ca.us>
 <5dc0f14a-017b-7870-477b-457a013cbd1e@rgzm.de>
 <5567F296-7EEB-415A-AB43-A313516556A3@dcn.davis.ca.us>
Message-ID: <d33fa2eb-a46c-a2a1-b864-6ce4f8f51f43@rgzm.de>

Thanks Jeff,

I was just completely unaware of these options! Now I know.

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 02/04/2020 15:40, Jeff Newmiller wrote:
> Where did this false dichotomy come from? The rmarkdown::render function has quite flexible parameters for compiling rmarkdown files in subdirectories without changing the current directory. And RStudio has a Global configuration to enable compiling using the Project directory as "current" under the RMarkdown settings.
>
> On April 2, 2020 1:59:03 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> So what you're saying is that I should have scripts in the project
>> directory and not in a subfolder within it, right?
>>
>> But what if I need (or at least want) to?
>>
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 02/04/2020 10:56, Jeff Newmiller wrote:
>>> Make it so. Outside R.
>>>
>>> At the command line, use cd before you start R. This should feel
>> natural.
>>> In a GUI file browser, double clicking on a file type assigned to a
>> program by default sets the containing directory to be current
>> directory before kicking off the program, so double-clicking on an
>> empty Project.RData file will do it. Or you can use RStudio
>> Project.Rproj files the same way.
>>> On April 2, 2020 1:40:07 AM PDT, Ivan Calandra <calandra at rgzm.de>
>> wrote:
>>>> Hi Jeff,
>>>>
>>>> But if I do not use setwd(), the current working directory is NOT
>> the
>>>> project directory.
>>>>
>>>> That's what my problem is about... I guess I was not clear in my
>>>> email...
>>>>
>>>> Ivan
>>>>
>>>> --
>>>> Dr. Ivan Calandra
>>>> TraCEr, laboratory for Traceology and Controlled Experiments
>>>> MONREPOS Archaeological Research Centre and
>>>> Museum for Human Behavioural Evolution
>>>> Schloss Monrepos
>>>> 56567 Neuwied, Germany
>>>> +49 (0) 2631 9772-243
>>>> https://www.researchgate.net/profile/Ivan_Calandra
>>>>
>>>> On 02/04/2020 10:37, Jeff Newmiller wrote:
>>>>> I recommend not using setwd. Then you can always assume your
>> current
>>>> working directory is your project directory and reference relative
>> to
>>>> that.
>>>>> On April 2, 2020 1:30:29 AM PDT, Ivan Calandra <calandra at rgzm.de>
>>>> wrote:
>>>>>> Dear useRs,
>>>>>>
>>>>>> I believe this is R code so appropriate for this list, but let me
>>>> know
>>>>>> if this relates more to RStudio itself.
>>>>>>
>>>>>> I am working on an RStudio project. In that project directory, I
>>>> have a
>>>>>> folder called 'analysis' and in there a folder called 'scripts'
>>>>>> ('~/analysis/scripts').
>>>>>> My data files needed for the scripts are in '~/analysis/raw_data'
>>>> and
>>>>>> the output should be in '~/analysis/derived_data'.
>>>>>>
>>>>>> My scripts are Rmd files, so when I knit them, their working
>>>> directory
>>>>>> is where they are located, i.e. '~/analysis/scripts'. The problem
>> I
>>>>>> then
>>>>>> have is to specify the path for 'raw_data' and 'derived_data'
>> since
>>>>>> during the rendering I am not relative to the project directory
>>>>>> anymore.
>>>>>> And these folders are not subfolders of the working directory?
>>>>>> '~/analysis/scripts'.
>>>>>> I hope I am clear here...
>>>>>>
>>>>>> I would like to avoid absolute paths of course, but I do not know
>>>> how
>>>>>> to
>>>>>> proceed.
>>>>>> What would be nice is a way to get the project directory in the
>>>>>> scripts,
>>>>>> rather than their working directory.
>>>>>> Does that make sense?
>>>>>>
>>>>>> Thank you in advance
>>>>>> Best,
>>>>>> Ivan
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr  2 15:58:40 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Apr 2020 06:58:40 -0700
Subject: [R] 
 disk.frame change default directory that disk.frames are saved in?
In-Reply-To: <05442e64-a3d0-928e-8f0a-b3c9b8a3be90@sapo.pt>
References: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>
 <05442e64-a3d0-928e-8f0a-b3c9b8a3be90@sapo.pt>
Message-ID: <4B0050B8-21C9-4722-8181-FFAC1345F306@dcn.davis.ca.us>

What does SO dependent mean? Cross posted with Stack Overflow?

The question appears to be to be about a contributed package called disk.frame, which I don't use. The examples I see explicitly call out using the tmpdir function... so simply replacing the use of not the tmpdir function with an R variable seems like an obvious solution.

On April 2, 2020 3:58:33 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>This is SO dependent, see if this StackOverflow post can be of help.
>
>https://stackoverflow.com/questions/17107206/change-temporary-directory
>
>Hope this helps,
>
>Rui Barradas
>
>?s 10:16 de 02/04/20, nevil amos escreveu:
>> I would like to change the default  directory within which all disk
>frames
>> are saved  to a directory on an SSD, which is not the drive there the
>r
>> tempdir is located. for example instead of saving all disk.frames in
>> tempdir the are all saved in ./media/SSDdrive/DF?
>> 
>> 
>> Thanks
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From er|cjberger @end|ng |rom gm@||@com  Thu Apr  2 16:53:24 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 2 Apr 2020 17:53:24 +0300
Subject: [R] 
 disk.frame change default directory that disk.frames are saved in?
In-Reply-To: <4B0050B8-21C9-4722-8181-FFAC1345F306@dcn.davis.ca.us>
References: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>
 <05442e64-a3d0-928e-8f0a-b3c9b8a3be90@sapo.pt>
 <4B0050B8-21C9-4722-8181-FFAC1345F306@dcn.davis.ca.us>
Message-ID: <CAGgJW75n7o35UiN+hWdZVtVsz8KUpd-J1kZ+KpshiAkhZzNSow@mail.gmail.com>

Rui wrote: " This is SO dependent,"
I think it's a typo. He meant to write
"This is OS dependent"
The Stack Overflow link he provided has info for both Windows and Linux.


On Thu, Apr 2, 2020 at 4:59 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> What does SO dependent mean? Cross posted with Stack Overflow?
>
> The question appears to be to be about a contributed package called
> disk.frame, which I don't use. The examples I see explicitly call out using
> the tmpdir function... so simply replacing the use of not the tmpdir
> function with an R variable seems like an obvious solution.
>
> On April 2, 2020 3:58:33 AM PDT, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >Hello,
> >
> >This is SO dependent, see if this StackOverflow post can be of help.
> >
> >https://stackoverflow.com/questions/17107206/change-temporary-directory
> >
> >Hope this helps,
> >
> >Rui Barradas
> >
> >?s 10:16 de 02/04/20, nevil amos escreveu:
> >> I would like to change the default  directory within which all disk
> >frames
> >> are saved  to a directory on an SSD, which is not the drive there the
> >r
> >> tempdir is located. for example instead of saving all disk.frames in
> >> tempdir the are all saved in ./media/SSDdrive/DF?
> >>
> >>
> >> Thanks
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  2 17:25:10 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Apr 2020 16:25:10 +0100
Subject: [R] 
 disk.frame change default directory that disk.frames are saved in?
In-Reply-To: <CAGgJW75n7o35UiN+hWdZVtVsz8KUpd-J1kZ+KpshiAkhZzNSow@mail.gmail.com>
References: <CAN9eD7niuyC9tYNWD1pmiPK7x+kEhkALS+oqq2OTu-TQobAFtA@mail.gmail.com>
 <05442e64-a3d0-928e-8f0a-b3c9b8a3be90@sapo.pt>
 <4B0050B8-21C9-4722-8181-FFAC1345F306@dcn.davis.ca.us>
 <CAGgJW75n7o35UiN+hWdZVtVsz8KUpd-J1kZ+KpshiAkhZzNSow@mail.gmail.com>
Message-ID: <8808c49f-25a8-2016-7b7e-0e6b7f397874@sapo.pt>

Hello,



?s 15:53 de 02/04/20, Eric Berger escreveu:
> Rui wrote: " This is SO dependent,"
> I think it's a typo. He meant to write
> "This is OS dependent"

Right. SO is Portuguese :(.
Sorry for the mess.

Rui Barradas

> The Stack Overflow link he provided has info for both Windows and Linux.
> 
> 
> On Thu, Apr 2, 2020 at 4:59 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
> <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
> 
>     What does SO dependent mean? Cross posted with Stack Overflow?
> 
>     The question appears to be to be about a contributed package called
>     disk.frame, which I don't use. The examples I see explicitly call
>     out using the tmpdir function... so simply replacing the use of not
>     the tmpdir function with an R variable seems like an obvious solution.
> 
>     On April 2, 2020 3:58:33 AM PDT, Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
>      >Hello,
>      >
>      >This is SO dependent, see if this StackOverflow post can be of help.
>      >
>      >https://stackoverflow.com/questions/17107206/change-temporary-directory
>      >
>      >Hope this helps,
>      >
>      >Rui Barradas
>      >
>      >?s 10:16 de 02/04/20, nevil amos escreveu:
>      >> I would like to change the default? directory within which all disk
>      >frames
>      >> are saved? to a directory on an SSD, which is not the drive
>     there the
>      >r
>      >> tempdir is located. for example instead of saving all disk.frames in
>      >> tempdir the are all saved in ./media/SSDdrive/DF?
>      >>
>      >>
>      >> Thanks
>      >>
>      >>? ? ? [[alternative HTML version deleted]]
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      >> https://stat.ethz.ch/mailman/listinfo/r-help
>      >> PLEASE do read the posting guide
>      >http://www.R-project.org/posting-guide.html
>      >> and provide commented, minimal, self-contained, reproducible code.
>      >>
>      >
>      >______________________________________________
>      >R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>      >https://stat.ethz.ch/mailman/listinfo/r-help
>      >PLEASE do read the posting guide
>      >http://www.R-project.org/posting-guide.html
>      >and provide commented, minimal, self-contained, reproducible code.
> 
>     -- 
>     Sent from my phone. Please excuse my brevity.
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From wdun|@p @end|ng |rom t|bco@com  Thu Apr  2 18:50:05 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 2 Apr 2020 09:50:05 -0700
Subject: [R] nls problem
In-Reply-To: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
Message-ID: <CAF8bMcYy_FP4-zNbcyh=vACNL2KutXJLRcTq+RxaNu5e+1BP4g@mail.gmail.com>

Roundoff/cancelation error: compare the following.  The first is equivalent
to your function, the last to fitted().

> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=2)))
            [,1]      [,2]       [,3]         [,4]       [,5]       [,6]
    [,7]       [,8]       [,9]     [,10]
[1,] -0.01635965 0.1076024 0.07477337 -0.007166685 -0.1337865 -0.2851877
-0.4804638 -0.6865135 -0.9870137 -1.398027
> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=4)))
           [,1]        [,2]       [,3]       [,4]       [,5]       [,6]
  [,7]      [,8]      [,9]     [,10]
[1,] -0.2196286 -0.09864071 -0.1345213 -0.2180792 -0.3463237 -0.4991861
-0.6959856 -0.903394 -1.205598 -1.618608
> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=16)))
           [,1]        [,2]       [,3]       [,4]       [,5]      [,6]
 [,7]       [,8]      [,9]     [,10]
[1,] -0.2208705 -0.09989926 -0.1357969 -0.2193638 -0.3476174 -0.500488
-0.697296 -0.9047119 -1.206926 -1.619947

Note that your model is linear and could be fitted with
   lm(data=aedf, Flux ~ pH + I(pH^2))
   lm(data=aedf, Flux ~ poly(pH, 2))
The latter uses a more stable parameterization.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Apr 2, 2020 at 4:15 AM Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem
> with
> nls which apparently gives a decent fit to the parable below, even without
> starting values. But when I then think I know the meaning of the three
> parameters a, b, and d it goes very wrong. I guess I am again overlooking
> something easy but cannot spot it.
>
> BW
> Troels Ring,
>
> Aalborg, Denmark
>
>
>
>
>
> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247,
> -0.302691,
>
>             -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906
>
> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
>
>           7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
> row.names = c(NA,
>
>
> -10L))
>
> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
>
>
>
> with(aedf,plot(pH,Flux))
>
> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
>
>
>
> m
>
> # a        b        d
>
> # -1630.70   457.67   -32.11
>
>
>
> fitted(m)
>
> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742
> -0.50048799
>
> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
>
>
>
> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
>
>
>
> FPG(aedf$pH)
>
> # [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467
>
> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
>
>
>
> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
>
>
>
>
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <
> http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smtp&url=/>>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Apr  2 20:06:01 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 2 Apr 2020 14:06:01 -0400
Subject: [R] nls problem
In-Reply-To: <CAF8bMcYy_FP4-zNbcyh=vACNL2KutXJLRcTq+RxaNu5e+1BP4g@mail.gmail.com>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
 <CAF8bMcYy_FP4-zNbcyh=vACNL2KutXJLRcTq+RxaNu5e+1BP4g@mail.gmail.com>
Message-ID: <36551789-6b4b-a7bb-8421-c34571f968d8@gmail.com>

Yes, I was waiting to see how long before it would be noticed that this is
not the sort of problem for which nls() is appropriate.

And I'll beat the drum again that nls() uses a simple (and generally
deprecated) forward difference derivative approximation that gets into
trouble a VERY high proportion of applications. Duncan Murdoch and I
published nlsr to overcome several of the weaknesses in nls(). nls()
was very advanced when it first appeared, but I've always felt it was
intended for use by very advanced craftsmen rather than general users.
Indeed, it can do some things nlsr won't do, but usually only if handled
skillfully.

JN


On 2020-04-02 12:50 p.m., William Dunlap via R-help wrote:
> Roundoff/cancelation error: compare the following.  The first is equivalent
> to your function, the last to fitted().
> 
>> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=2)))
>             [,1]      [,2]       [,3]         [,4]       [,5]       [,6]
>     [,7]       [,8]       [,9]     [,10]
> [1,] -0.01635965 0.1076024 0.07477337 -0.007166685 -0.1337865 -0.2851877
> -0.4804638 -0.6865135 -0.9870137 -1.398027
>> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=4)))
>            [,1]        [,2]       [,3]       [,4]       [,5]       [,6]
>   [,7]      [,8]      [,9]     [,10]
> [1,] -0.2196286 -0.09864071 -0.1345213 -0.2180792 -0.3463237 -0.4991861
> -0.6959856 -0.903394 -1.205598 -1.618608
>> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=16)))
>            [,1]        [,2]       [,3]       [,4]       [,5]      [,6]
>  [,7]       [,8]      [,9]     [,10]
> [1,] -0.2208705 -0.09989926 -0.1357969 -0.2193638 -0.3476174 -0.500488
> -0.697296 -0.9047119 -1.206926 -1.619947
> 
> Note that your model is linear and could be fitted with
>    lm(data=aedf, Flux ~ pH + I(pH^2))
>    lm(data=aedf, Flux ~ poly(pH, 2))
> The latter uses a more stable parameterization.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Thu, Apr 2, 2020 at 4:15 AM Troels Ring <tring at gvdnet.dk> wrote:
> 
>> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem
>> with
>> nls which apparently gives a decent fit to the parable below, even without
>> starting values. But when I then think I know the meaning of the three
>> parameters a, b, and d it goes very wrong. I guess I am again overlooking
>> something easy but cannot spot it.
>>
>> BW
>> Troels Ring,
>>
>> Aalborg, Denmark
>>
>>
>>
>>
>>
>> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247,
>> -0.302691,
>>
>>             -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906
>>
>> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
>>
>>           7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
>> row.names = c(NA,
>>
>>
>> -10L))
>>
>> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
>>
>>
>>
>> with(aedf,plot(pH,Flux))
>>
>> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
>>
>>
>>
>> m
>>
>> # a        b        d
>>
>> # -1630.70   457.67   -32.11
>>
>>
>>
>> fitted(m)
>>
>> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742
>> -0.50048799
>>
>> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
>>
>>
>>
>> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
>>
>>
>>
>> FPG(aedf$pH)
>>
>> # [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467
>>
>> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
>>
>>
>>
>> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
>>
>>
>>
>>
>> This email has been scanned by BullGuard antivirus protection.
>> For more info visit www.bullguard.com
>> <
>> http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
>> p&url=/
>> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smtp&url=/>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From h||m @end|ng |rom gm@c@com  Thu Apr  2 12:26:07 2020
From: h||m @end|ng |rom gm@c@com (Lim, Hwanggyu)
Date: Thu, 2 Apr 2020 10:26:07 +0000
Subject: [R] Question about nlminb function
Message-ID: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>

Hello,

My name is Hwanggyu Lim. I am working estimating parameters of non-negative function, which has local maximums. For example, the function has three parameters (e.g., f(a, b, c)) and I need to estimate them.
For this, I am using nlminb optimization function and it works fine.

Here is my question. I want to specify the absolute difference stopping tolerance (or stopping criterion) to stop the iteration of estimation algorithm. For example, when n-1th estimates and nth estimates have absolute differences less than 0.001 for all three parameters, the iteration must stop. In this case, is there any way that I can do? I know that nlminb function has several control parameters to specify the tolerance. But, I am not sure how I can specify the absolute difference stopping tolerance. (I think that abs.tol argument is not relevant to my question because it only works for functions whose minimum is 0.

Could you please provide any idea about my situation if you have? Thanks!

Best,
Hwanggyu
The information in this transmission is confidential and intended only for the recipient listed above. If you are not the intended recipient, please advise the sender immediately by reply e-mail and delete this message and any attachments without retaining a copy. If you are not the intended recipient, you are hereby notified that any disclosure, copying or distribution of this message, or the taking of any action based upon it, is strictly prohibited.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Apr  2 22:39:29 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Apr 2020 07:39:29 +1100
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <20200402200447.GA1856@jrl.uk.to>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
 <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
 <CA+8X3fV2NVMPdkdu_HhgVqwqjPPt-j2Qn0UqzbQ4z-Kz61ROSA@mail.gmail.com>
 <20200402200447.GA1856@jrl.uk.to>
Message-ID: <CA+8X3fU6g0HsKn71-8Xt1Yxcq-a4WwAFjKjDRtZSP6qyeLGoQg@mail.gmail.com>

Hi Rasmus,
Very nice. The R help list is a bit like a quiz show where the
contestants must balance the alacrity with which they press their
buttons with the confidence that they have the correct answer. A slow
motion game of wits in which the prizes are self-awarded.

Jim

On Fri, Apr 3, 2020 at 7:04 AM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-01 15:33 +1100, Jim Lemon wrote:
> > Hi Nevil,
> > It's a nasty piece of work, but:
>
> Hi!  How about this one:
>
>     data <- c(rep(1:4, times=3), 2, 1, 3, 2)
>     dimnames <- list(NULL, c("x", "y", "z", "k"))
>     ncol <- length(data)/4
>     M <- matrix(data=data, nrow=ncol, ncol=ncol, dimnames=dimnames)
>
>     FUN <- function(x) {
>       out <- matrix(rep(x[1:3], times=x[4]),
>                     byrow=TRUE, nrow=x[4])
>       return(cbind(out, x[4]))
>     }
>     newM <- do.call(rbind, apply(X=M, MARGIN=1, FUN=FUN))
>     dimnames(newM) <- list(NULL, c("x", "y", "z", "k"))
>     newM <- cbind(newM, "j"=sequence(M[,"k"]))
>     newM
>
> Regards,
> Rasmus


From cry@n @end|ng |rom b|ngh@mton@edu  Thu Apr  2 23:23:22 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Thu, 2 Apr 2020 17:23:22 -0400
Subject: [R] arranging multiple lattice graphs on a page
Message-ID: <1297a2fd-e1a6-698d-ebf8-29c75f03e161@binghamton.edu>

I would like to place two separate plots, one above the other, something
like this (MWE for illustration):

library(lattice)
data(iris)
layout(matrix(c(1,2), 2, 1, byrow = TRUE))
with(iris, (plot(Sepal.Length ~ Petal.Length)))
with(iris, (plot(Sepal.Length ~ Petal.Width)))

but with lattice, so one of the plots can have panels. So something like
this:

library(lattice)
data(iris)
layout(matrix(c(1,2), 2, 1, byrow = TRUE))
xyplot(Sepal.Length ~ Petal.Length, data = iris)
xyplot(Sepal.Length ~ Petal.Width | Species, data = iris, layout = c(3,1))

But the latter does not accomplish my goal. Appreciate any advice.

Thanks.

--Chris Ryan
SUNY Upstate Medical University
Binghamton, NY


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr  3 00:45:58 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 2 Apr 2020 15:45:58 -0700
Subject: [R] arranging multiple lattice graphs on a page
In-Reply-To: <1297a2fd-e1a6-698d-ebf8-29c75f03e161@binghamton.edu>
References: <1297a2fd-e1a6-698d-ebf8-29c75f03e161@binghamton.edu>
Message-ID: <CAGxFJbSCUbRAsSxO4DCvrO=+gE=UKXr8EQLxwmpAdjXym8pxsA@mail.gmail.com>

See ?print.trellis, especially the "split" argument.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Apr 2, 2020 at 2:23 PM Christopher W. Ryan <cryan at binghamton.edu> wrote:
>
> I would like to place two separate plots, one above the other, something
> like this (MWE for illustration):
>
> library(lattice)
> data(iris)
> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
> with(iris, (plot(Sepal.Length ~ Petal.Length)))
> with(iris, (plot(Sepal.Length ~ Petal.Width)))
>
> but with lattice, so one of the plots can have panels. So something like
> this:
>
> library(lattice)
> data(iris)
> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
> xyplot(Sepal.Length ~ Petal.Length, data = iris)
> xyplot(Sepal.Length ~ Petal.Width | Species, data = iris, layout = c(3,1))
>
> But the latter does not accomplish my goal. Appreciate any advice.
>
> Thanks.
>
> --Chris Ryan
> SUNY Upstate Medical University
> Binghamton, NY
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr  2 22:04:47 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 2 Apr 2020 22:04:47 +0200
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CA+8X3fV2NVMPdkdu_HhgVqwqjPPt-j2Qn0UqzbQ4z-Kz61ROSA@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
 <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
 <CA+8X3fV2NVMPdkdu_HhgVqwqjPPt-j2Qn0UqzbQ4z-Kz61ROSA@mail.gmail.com>
Message-ID: <20200402200447.GA1856@jrl.uk.to>

On 2020-04-01 15:33 +1100, Jim Lemon wrote:
> Hi Nevil,
> It's a nasty piece of work, but:

Hi!  How about this one:

    data <- c(rep(1:4, times=3), 2, 1, 3, 2)
    dimnames <- list(NULL, c("x", "y", "z", "k"))
    ncol <- length(data)/4
    M <- matrix(data=data, nrow=ncol, ncol=ncol, dimnames=dimnames)
    
    FUN <- function(x) {
      out <- matrix(rep(x[1:3], times=x[4]),
                    byrow=TRUE, nrow=x[4])
      return(cbind(out, x[4]))
    }
    newM <- do.call(rbind, apply(X=M, MARGIN=1, FUN=FUN))
    dimnames(newM) <- list(NULL, c("x", "y", "z", "k"))
    newM <- cbind(newM, "j"=sequence(M[,"k"]))
    newM

Regards,
Rasmus


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr  2 23:06:07 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 2 Apr 2020 23:06:07 +0200
Subject: [R] 
 repeat rows of matrix by number (k) in one colummatrix adding
 column j with values 1:k
In-Reply-To: <CA+8X3fU6g0HsKn71-8Xt1Yxcq-a4WwAFjKjDRtZSP6qyeLGoQg@mail.gmail.com>
References: <CAN9eD7=nXQP0KycwDBfoUWHUMc_Y+cPcmyRaFBWDx2ZC+OzjKQ@mail.gmail.com>
 <CAN9eD7kfBmK1pF1fOh+TgpDf3M1BA5=JDTUJN4KsHCVo6o9bpw@mail.gmail.com>
 <CA+8X3fV2NVMPdkdu_HhgVqwqjPPt-j2Qn0UqzbQ4z-Kz61ROSA@mail.gmail.com>
 <20200402200447.GA1856@jrl.uk.to>
 <CA+8X3fU6g0HsKn71-8Xt1Yxcq-a4WwAFjKjDRtZSP6qyeLGoQg@mail.gmail.com>
Message-ID: <20200402210607.GB1856@jrl.uk.to>

On 2020-04-03 07:39 +1100, Jim Lemon wrote:
| 
| Hi Rasmus,
| Very nice. The R help list is a bit like a 
| quiz show where the contestants must 
| balance the alacrity with which they press 
| their buttons with the confidence that they 
| have the correct answer. A slow motion game 
| of wits in which the prizes are 
| self-awarded.

Hi Jim,
Thank you.  I try my best to understand the 
question at hand, and thus can only hope to 
nail a right balance on this 
alacrity-confidence quiz show scale or yours 
:)  I'm glad if this could help us understand 
R better.

Regards,
Rasmus


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Apr  3 01:52:27 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Thu, 02 Apr 2020 19:52:27 -0400
Subject: [R] [External Email] Re: arranging multiple lattice graphs on a
 page
In-Reply-To: <CAGxFJbSCUbRAsSxO4DCvrO=+gE=UKXr8EQLxwmpAdjXym8pxsA@mail.gmail.com>
References: <1297a2fd-e1a6-698d-ebf8-29c75f03e161@binghamton.edu>
 <CAGxFJbSCUbRAsSxO4DCvrO=+gE=UKXr8EQLxwmpAdjXym8pxsA@mail.gmail.com>
Message-ID: <277B790C-87D1-4FF3-ABD6-BBD5B444D3EF@binghamton.edu>

Thanks, I'll take a look. I also finally came across gridExtra, which allows me to do it as well.

--Chris Ryan

On April 2, 2020 6:45:58 PM EDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>See ?print.trellis, especially the "split" argument.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Thu, Apr 2, 2020 at 2:23 PM Christopher W. Ryan
><cryan at binghamton.edu> wrote:
>>
>> I would like to place two separate plots, one above the other,
>something
>> like this (MWE for illustration):
>>
>> library(lattice)
>> data(iris)
>> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
>> with(iris, (plot(Sepal.Length ~ Petal.Length)))
>> with(iris, (plot(Sepal.Length ~ Petal.Width)))
>>
>> but with lattice, so one of the plots can have panels. So something
>like
>> this:
>>
>> library(lattice)
>> data(iris)
>> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
>> xyplot(Sepal.Length ~ Petal.Length, data = iris)
>> xyplot(Sepal.Length ~ Petal.Width | Species, data = iris, layout =
>c(3,1))
>>
>> But the latter does not accomplish my goal. Appreciate any advice.
>>
>> Thanks.
>>
>> --Chris Ryan
>> SUNY Upstate Medical University
>> Binghamton, NY
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Apr  3 02:18:24 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 2 Apr 2020 20:18:24 -0400
Subject: [R] [External Email] Re: arranging multiple lattice graphs on a
 page
In-Reply-To: <277B790C-87D1-4FF3-ABD6-BBD5B444D3EF@binghamton.edu>
References: <1297a2fd-e1a6-698d-ebf8-29c75f03e161@binghamton.edu>
 <CAGxFJbSCUbRAsSxO4DCvrO=+gE=UKXr8EQLxwmpAdjXym8pxsA@mail.gmail.com>
 <277B790C-87D1-4FF3-ABD6-BBD5B444D3EF@binghamton.edu>
Message-ID: <CAGx1TMCZRkdtMGbi-FD3f3P4qRZqskQPn7WiNW5y1E1=6iT7qQ@mail.gmail.com>

don't forget
library(latticeExtra)

latticeExtra provides many very useful user-level functions.

On Thu, Apr 2, 2020 at 7:52 PM Christopher W. Ryan <cryan at binghamton.edu> wrote:
>
> Thanks, I'll take a look. I also finally came across gridExtra, which allows me to do it as well.
>
> --Chris Ryan
>
> On April 2, 2020 6:45:58 PM EDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >See ?print.trellis, especially the "split" argument.
> >
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >On Thu, Apr 2, 2020 at 2:23 PM Christopher W. Ryan
> ><cryan at binghamton.edu> wrote:
> >>
> >> I would like to place two separate plots, one above the other,
> >something
> >> like this (MWE for illustration):
> >>
> >> library(lattice)
> >> data(iris)
> >> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
> >> with(iris, (plot(Sepal.Length ~ Petal.Length)))
> >> with(iris, (plot(Sepal.Length ~ Petal.Width)))
> >>
> >> but with lattice, so one of the plots can have panels. So something
> >like
> >> this:
> >>
> >> library(lattice)
> >> data(iris)
> >> layout(matrix(c(1,2), 2, 1, byrow = TRUE))
> >> xyplot(Sepal.Length ~ Petal.Length, data = iris)
> >> xyplot(Sepal.Length ~ Petal.Width | Species, data = iris, layout =
> >c(3,1))
> >>
> >> But the latter does not accomplish my goal. Appreciate any advice.
> >>
> >> Thanks.
> >>
> >> --Chris Ryan
> >> SUNY Upstate Medical University
> >> Binghamton, NY
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@|kremk @end|ng |rom gm@||@com  Fri Apr  3 04:29:24 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Thu, 2 Apr 2020 21:29:24 -0500
Subject: [R] Label
Message-ID: <CAJOiR6Y8vjmt_yqoKiuuYqrs6hjC-We1KhOXZuigFiA-Eu5tvg@mail.gmail.com>

Hi all,

I have a sample of data set,

dat <- read.table(header=TRUE, text='Lab count
A 24
B 19
C 30
D 18')

barplot(dat$count, names.arg=c("A", "B", "C","D"),
        col="blue",
        ylim = c(0,30),
        ylab = "Count",
        xlab = "Grade")

I want add the number of counts at the top of each bar plot. How can I do that?
Thank you in advance


From drj|m|emon @end|ng |rom gm@||@com  Fri Apr  3 04:37:48 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Apr 2020 13:37:48 +1100
Subject: [R] Label
In-Reply-To: <CAJOiR6Y8vjmt_yqoKiuuYqrs6hjC-We1KhOXZuigFiA-Eu5tvg@mail.gmail.com>
References: <CAJOiR6Y8vjmt_yqoKiuuYqrs6hjC-We1KhOXZuigFiA-Eu5tvg@mail.gmail.com>
Message-ID: <CA+8X3fXV6ozXs29=2mWo7RkaYZXqZK1ScsrWUvrpABH0j_N80A@mail.gmail.com>

Hi Val,

library(plotrix)
barpos<-barplot(dat$count, names.arg=c("A", "B", "C","D"),
         col="blue",
         ylim = c(0,30),
         ylab = "Count",
         xlab = "Grade")
barlabels(barpos,dat$count,prop=1)

Jim

On Fri, Apr 3, 2020 at 1:31 PM Val <valkremk at gmail.com> wrote:
>
> Hi all,
>
> I have a sample of data set,
>
> dat <- read.table(header=TRUE, text='Lab count
> A 24
> B 19
> C 30
> D 18')
>
> barplot(dat$count, names.arg=c("A", "B", "C","D"),
>         col="blue",
>         ylim = c(0,30),
>         ylab = "Count",
>         xlab = "Grade")
>
> I want add the number of counts at the top of each bar plot. How can I do that?
> Thank you in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr|ng @end|ng |rom gvdnet@dk  Fri Apr  3 06:43:47 2020
From: tr|ng @end|ng |rom gvdnet@dk (Troels Ring)
Date: Fri, 3 Apr 2020 06:43:47 +0200
Subject: [R] nls problem
In-Reply-To: K32njLQyQXsnsK32oj0izu
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk> K32njLQyQXsnsK32oj0izu
Message-ID: <000001d60972$77a397e0$66eac7a0$@gvdnet.dk>

Thank you ? yes indeed, on suggestion from Rui I noticed that the problem was mainly that I took the parameters from ?m? instead of coef(m) i.e

a        b        d 

-1630.71   457.68   -32.11

Instead of

          a           b           d 
-1630.70993   457.67555   -32.11469 

 

And that alone saves me. 

BW
Troels

 

Fra: William Dunlap <wdunlap at tibco.com> 
Sendt: 2. april 2020 18:50
Til: Troels Ring <tring at gvdnet.dk>
Cc: r-help mailing list <r-help at r-project.org>
Emne: Re: [R] nls problem

 

Roundoff/cancelation error: compare the following.  The first is equivalent to your function, the last to fitted().  

 

> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=2)))
            [,1]      [,2]       [,3]         [,4]       [,5]       [,6]       [,7]       [,8]       [,9]     [,10]
[1,] -0.01635965 0.1076024 0.07477337 -0.007166685 -0.1337865 -0.2851877 -0.4804638 -0.6865135 -0.9870137 -1.398027
> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=4)))
           [,1]        [,2]       [,3]       [,4]       [,5]       [,6]       [,7]      [,8]      [,9]     [,10]
[1,] -0.2196286 -0.09864071 -0.1345213 -0.2180792 -0.3463237 -0.4991861 -0.6959856 -0.903394 -1.205598 -1.618608
> with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=16)))
           [,1]        [,2]       [,3]       [,4]       [,5]      [,6]      [,7]       [,8]      [,9]     [,10]
[1,] -0.2208705 -0.09989926 -0.1357969 -0.2193638 -0.3476174 -0.500488 -0.697296 -0.9047119 -1.206926 -1.619947

 

Note that your model is linear and could be fitted with

   lm(data=aedf, Flux ~ pH + I(pH^2))

   lm(data=aedf, Flux ~ poly(pH, 2))
The latter uses a more stable parameterization.




Bill Dunlap
TIBCO Software
wdunlap tibco.com <http://tibco.com> 

 

 

On Thu, Apr 2, 2020 at 4:15 AM Troels Ring <tring at gvdnet.dk <mailto:tring at gvdnet.dk> > wrote:

Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem with
nls which apparently gives a decent fit to the parable below, even without
starting values. But when I then think I know the meaning of the three
parameters a, b, and d it goes very wrong. I guess I am again overlooking
something easy but cannot spot it.

BW
Troels Ring,

Aalborg, Denmark





aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247, -0.302691, 

            -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906

), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818, 

          7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
row.names = c(NA, 


-10L))

m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))



with(aedf,plot(pH,Flux))

with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))



m

# a        b        d 

# -1630.70   457.67   -32.11 



fitted(m)

# 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742 -0.50048799

# [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657



FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2



FPG(aedf$pH)

# [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467

# [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917



# So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?




This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com <http://www.bullguard.com> 
<http://www.bullguard.com/tracking.aspx?affiliate=bullguard <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smtp&url=/> &buyaffiliate=smt
p&url=/> 

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smtp&url=/> 

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Apr  3 11:24:56 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 3 Apr 2020 12:24:56 +0300
Subject: [R] Question about nlminb function
In-Reply-To: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>
References: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>
Message-ID: <20200403122456.6e2073ea@Tarkus>

On Thu, 2 Apr 2020 10:26:07 +0000
"Lim, Hwanggyu" <hlim at gmac.com> wrote:

> when n-1th estimates and nth estimates have absolute differences
> less than 0.001 for all three parameters, the iteration must stop

> I am using nlminb optimization function

nlminb function uses the PORT library. According to [1], the closest
thing PORT has to what you want is the notion of X-convergence, namely,
stopping when max(scale * abs(x - xstar))/max(scale * abs(x + xstar)) is
considered to be below control$x.tol (with xstar being supposed local
minimiser and scale being all ones by default). Using it as an absolute
stopping criterion in x requires knowledge of at least order of
magnitude of xstar, though, so it might not be feasible.

Note that ?nlminb says in the description that it is there "for
historical compatibility."

The nloptr package offers an xtol_abs option [2] that results in the
behaviour you want.

-- 
Best regards,
Ivan

[1] David M. Gay, Usage Summary for Selected Optimization Routines.
<http://web.archive.org/web/20070508140716/http://netlib.bell-labs.com/cm/cs/cstr/153.pdf>

[2]
https://nlopt.readthedocs.io/en/latest/NLopt_Reference/#stopping-criteria


From pro|jcn@@h @end|ng |rom gm@||@com  Fri Apr  3 15:48:32 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 3 Apr 2020 09:48:32 -0400
Subject: [R] Question about nlminb function
In-Reply-To: <20200403122456.6e2073ea@Tarkus>
References: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>
 <20200403122456.6e2073ea@Tarkus>
Message-ID: <a3f6f60e-bf7f-2863-fe39-6de1a20f0a3d@gmail.com>

This thread points out the important and often overlooked
difference between "convergence" of an algorithm and "termination"
of a program. I've been pushing this button for over 30 years,
and I suspect that it will continue to come up from time to time.

Sometimes it is helpful to put termination criteria actually into
the user function. Alternatively try a different optimizer. The optimx
package wraps several, including a few for bounds constrained optimization.
Note that a new version will go up once revdeps have been checked. Dylan
Beijers noted a minor glitch if users want to "maximize".

If the termination criteria are really critical, some of the methods now
merged into optimx (Rvmmin, Rcgmin, Rtnmin) are all in R. I won't pretend
that diving in and making changes is easy, though I've tried to move the
code more and more to maintainability and transparency. If anyone is
interested in pursuing that sort of thing, I'll be willing to advise or
help as long as the requests aren't too strident.

For information, while all-R programs used to be much slower than those
in Fortran or C or C++, users should time their problems rather than just
assume a great penalty for running things completely in R. The human time
saving is generally more important.

Best, John Nash


On 2020-04-03 5:24 a.m., Ivan Krylov wrote:
> On Thu, 2 Apr 2020 10:26:07 +0000
> "Lim, Hwanggyu" <hlim at gmac.com> wrote:
> 
>> when n-1th estimates and nth estimates have absolute differences
>> less than 0.001 for all three parameters, the iteration must stop
> 
>> I am using nlminb optimization function
> 
> nlminb function uses the PORT library. According to [1], the closest
> thing PORT has to what you want is the notion of X-convergence, namely,
> stopping when max(scale * abs(x - xstar))/max(scale * abs(x + xstar)) is
> considered to be below control$x.tol (with xstar being supposed local
> minimiser and scale being all ones by default). Using it as an absolute
> stopping criterion in x requires knowledge of at least order of
> magnitude of xstar, though, so it might not be feasible.
> 
> Note that ?nlminb says in the description that it is there "for
> historical compatibility."
> 
> The nloptr package offers an xtol_abs option [2] that results in the
> behaviour you want.
>


From wdun|@p @end|ng |rom t|bco@com  Fri Apr  3 16:46:27 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 3 Apr 2020 07:46:27 -0700
Subject: [R] nls problem
In-Reply-To: <000001d60972$77a397e0$66eac7a0$@gvdnet.dk>
References: <2ce8c01d608de$f3e4d330$dbae7990$@gvdnet.dk>
 <000001d60972$77a397e0$66eac7a0$@gvdnet.dk>
Message-ID: <CAF8bMcZ20eWon4KDDT=bp==E3GPU1LUcOvRqux9eaX1xv_pmCA@mail.gmail.com>

If you will be copying the printed coefficients into your function (instead
of just using fitted() or predict()), then use dput(coef(m)) to get them
printed to full precision.

Also, if you regress on pH-7 instead of pH you don't have to worry so much
about the roundoff or cancellation error.  This is akin to what
poly(pH,degree) does.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Apr 2, 2020 at 9:44 PM Troels Ring <tring at gvdnet.dk> wrote:

> Thank you ? yes indeed, on suggestion from Rui I noticed that the problem
> was mainly that I took the parameters from ?m? instead of coef(m) i.e
>
> a        b        d
>
> -1630.71   457.68   -32.11
>
> Instead of
>
>           a           b           d
>
> -1630.70993   457.67555   -32.11469
>
>
>
> And that alone saves me.
>
> BW
> Troels
>
>
>
> *Fra:* William Dunlap <wdunlap at tibco.com>
> *Sendt:* 2. april 2020 18:50
> *Til:* Troels Ring <tring at gvdnet.dk>
> *Cc:* r-help mailing list <r-help at r-project.org>
> *Emne:* Re: [R] nls problem
>
>
>
> Roundoff/cancelation error: compare the following.  The first is
> equivalent to your function, the last to fitted().
>
>
>
> > with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=2)))
>             [,1]      [,2]       [,3]         [,4]       [,5]       [,6]
>     [,7]       [,8]       [,9]     [,10]
> [1,] -0.01635965 0.1076024 0.07477337 -0.007166685 -0.1337865 -0.2851877
> -0.4804638 -0.6865135 -0.9870137 -1.398027
> > with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=4)))
>            [,1]        [,2]       [,3]       [,4]       [,5]       [,6]
>     [,7]      [,8]      [,9]     [,10]
> [1,] -0.2196286 -0.09864071 -0.1345213 -0.2180792 -0.3463237 -0.4991861
> -0.6959856 -0.903394 -1.205598 -1.618608
> > with(aedf, t(cbind(1, pH, pH^2) %*% round(coef(m), digits=16)))
>            [,1]        [,2]       [,3]       [,4]       [,5]      [,6]
>  [,7]       [,8]      [,9]     [,10]
> [1,] -0.2208705 -0.09989926 -0.1357969 -0.2193638 -0.3476174 -0.500488
> -0.697296 -0.9047119 -1.206926 -1.619947
>
>
>
> Note that your model is linear and could be fitted with
>
>    lm(data=aedf, Flux ~ pH + I(pH^2))
>
>    lm(data=aedf, Flux ~ poly(pH, 2))
> The latter uses a more stable parameterization.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
>
>
>
> On Thu, Apr 2, 2020 at 4:15 AM Troels Ring <tring at gvdnet.dk> wrote:
>
> Dear friends - I'm on Win10 with R 6.3.1 and have a very simple problem
> with
> nls which apparently gives a decent fit to the parable below, even without
> starting values. But when I then think I know the meaning of the three
> parameters a, b, and d it goes very wrong. I guess I am again overlooking
> something easy but cannot spot it.
>
> BW
> Troels Ring,
>
> Aalborg, Denmark
>
>
>
>
>
> aedf <- structure(list(Flux = c(-0.141256, -0.154709, -0.215247,
> -0.302691,
>
>             -0.32287, -0.511211, -0.605381, -0.813901, -1.11659, -1.76906
>
> ), pH = c(7.06273, 7.11182, 7.16182, 7.18818, 7.21455, 7.23818,
>
>           7.26273, 7.28455, 7.31182, 7.34364)), class = "data.frame",
> row.names = c(NA,
>
>
> -10L))
>
> m <- with(aedf,nls(Flux~a + b*pH + d*pH^2))
>
>
>
> with(aedf,plot(pH,Flux))
>
> with(aedf,lines(pH,fitted(m),lty=1,col="red",lwd=3))
>
>
>
> m
>
> # a        b        d
>
> # -1630.70   457.67   -32.11
>
>
>
> fitted(m)
>
> # 1] -0.22087053 -0.09989926 -0.13579690 -0.21936385 -0.34761742
> -0.50048799
>
> # [7] -0.69729602 -0.90471194 -1.20692552 -1.61994657
>
>
>
> FPG <- function(pH) -1630.70 + 457.67*pH -32.11*pH^2
>
>
>
> FPG(aedf$pH)
>
> # [1] -0.016359649  0.107602395  0.074773375 -0.007166685 -0.133786467
>
> # [6] -0.285187665 -0.480463769 -0.686513537 -0.987013685 -1.398026917
>
>
>
> # So why aren't fitted(m) and FPG(aedf$pH) not closer ("equal")?
>
>
>
>
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <
> http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smtp&url=/>
>

	[[alternative HTML version deleted]]


From 538280 @end|ng |rom gm@||@com  Fri Apr  3 17:45:20 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Fri, 3 Apr 2020 09:45:20 -0600
Subject: [R] ncol() vs. length() on data.frames
In-Reply-To: <1df86ec9-c3c1-3c65-160c-17b7b4d75547@rgzm.de>
References: <a355b6f4-5bc5-6e32-ba5c-ae4993b65d08@rgzm.de>
 <20200331170009.6240febb@Tarkus>
 <1df86ec9-c3c1-3c65-160c-17b7b4d75547@rgzm.de>
Message-ID: <CAFEqCdy+GYz5ZXD16tjLR2ipnO46uY=yoYYmM+0jw-xKuvL7DA@mail.gmail.com>

As others have pointed out, ncol calls the length function, so you are
pretty safe in terms of output of getting the same result when applied
to the results of functions like read.csv (there will be a big
difference if you ever apply those functions to a matrix or some other
data structures).

One thing that I have not seen yet is a comparison on timing, so here goes:

> library(microbenchmark)
> microbenchmark(
+ length = length(iris),
+ ncol = ncol(iris)
+ )
Unit: nanoseconds
   expr  min   lq mean median   uq   max neval
 length  700  750  869    800  800  7400   100
   ncol 2400 2500 2981   2600 2700 31900   100

So ncol takes about 3 times as long to run as length on the iris data
frame (5 columns), you can rerun the above code with data frames more
the size that you will be using to see if that makes any difference.
But also notice that the units are nanoseconds, so the median time for
ncol to run is less than the time it takes light to travel a kilometer
in a vacuum, or about the time it takes light to go 1/3 of a mile
through a fiber optic cable (en.wikipedia.org/wiki/Microsecond).  If
this is used as part of a simulation or other repeated procedure and
it is done one million times then you will add about 2 seconds to the
overall run.  If this is just part of code where length/ncol will be
called fewer than 10 times then nobody is going to notice.

So the trade-off of moving from length to ncol is a slight decrease in
speed for an increase of readability.  I think that I would go with
the readability myself.

On Tue, Mar 31, 2020 at 8:11 AM Ivan Calandra <calandra at rgzm.de> wrote:
>
> Thanks Ivan for the answer.
>
> So it confirms my first thought that these two functions are equivalent
> when applied to a "simple" data.frame.
>
> The reason I was asking is because I have gotten used to use length() in
> my scripts. It works perfectly and I understand it easily. But to be
> honest, ncol() is more intuitive to most users (especially the novice)
> so I was thinking about switching to using this function instead (all my
> data.frames are created from read.csv() or similar functions so there
> should not be any issue). But before doing that, I want to be sure that
> it is not going to create unexpected results.
>
> Thank you,
> Ivan
>
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
>
> On 31/03/2020 16:00, Ivan Krylov wrote:
> > On Tue, 31 Mar 2020 14:47:54 +0200
> > Ivan Calandra <calandra at rgzm.de> wrote:
> >
> >> On a simple data.frame (i.e. each element is a vector), ncol() and
> >> length() will give the same result.
> >> Are they just equivalent on such objects, or are they differences in
> >> some cases?
> > I am not aware of any exceptions to ncol(dataframe)==length(dataframe)
> > (in fact, ncol(x) is dim(x)[2L] and ?dim says that dim(dataframe)
> > returns c(length(attr(dataframe, 'row.names')), length(dataframe))), but
> > watch out for AsIs columns which can have columns of their own:
> >
> > x <- data.frame(I(volcano))
> > dim(x)
> > # [1] 87  1
> > length(x)
> > # [1] 1
> > dim(x[,1])
> > # [1] 87 61
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From v@|kremk @end|ng |rom gm@||@com  Fri Apr  3 20:19:22 2020
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Fri, 3 Apr 2020 13:19:22 -0500
Subject: [R] Label
In-Reply-To: <CA+8X3fXV6ozXs29=2mWo7RkaYZXqZK1ScsrWUvrpABH0j_N80A@mail.gmail.com>
References: <CAJOiR6Y8vjmt_yqoKiuuYqrs6hjC-We1KhOXZuigFiA-Eu5tvg@mail.gmail.com>
 <CA+8X3fXV6ozXs29=2mWo7RkaYZXqZK1ScsrWUvrpABH0j_N80A@mail.gmail.com>
Message-ID: <CAJOiR6Z8jjcYdwsuNM4rpkJxr24q_oSaabR3creuf6drXcnfyw@mail.gmail.com>

Thank you Jim,

Is it possible to format the label box? The labels(numbers) are
surrounded by a big square and wanted to remove it. I just want
display only the number.  I searched up the documentation  for
"barlabels" and there is no such example

barlabels(xpos,ypos,labels=NULL,cex=1,prop=0.5,miny=0,offset=0,...)

Thank you.

On Thu, Apr 2, 2020 at 9:38 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Val,
>
> library(plotrix)
> barpos<-barplot(dat$count, names.arg=c("A", "B", "C","D"),
>          col="blue",
>          ylim = c(0,30),
>          ylab = "Count",
>          xlab = "Grade")
> barlabels(barpos,dat$count,prop=1)
>
> Jim
>
> On Fri, Apr 3, 2020 at 1:31 PM Val <valkremk at gmail.com> wrote:
> >
> > Hi all,
> >
> > I have a sample of data set,
> >
> > dat <- read.table(header=TRUE, text='Lab count
> > A 24
> > B 19
> > C 30
> > D 18')
> >
> > barplot(dat$count, names.arg=c("A", "B", "C","D"),
> >         col="blue",
> >         ylim = c(0,30),
> >         ylab = "Count",
> >         xlab = "Grade")
> >
> > I want add the number of counts at the top of each bar plot. How can I do that?
> > Thank you in advance
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Fri Apr  3 20:57:28 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 3 Apr 2020 18:57:28 +0000
Subject: [R] a simple reshape
Message-ID: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>

Hi R users,

I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?

Thank you,

Ding

test1 data frame is long file and test2 is the wide file I want to get

test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
                     val =c(0.98,0.02, 0.59,0.12,0.11,0.04))

test2  <- data.frame(vntr1=c("v1","v2"),
                     a1 =c(0.98, 0.5693),
                     a2 = c(0.02, 0.12),
                     a3 =c(NA, 0.11),
                     a4=c(NA, 0.04))

the following code does not work
test2 <-test1 %>%spread(vntr1, val)

 Error: Each row of output must be identified by a unique combination of keys.
Keys are shared for 6 rows:
* 1, 2
* 3, 4, 5, 6
Do you need to create unique ID with tibble::rowid_to_column()?
Call `rlang::last_error()` to see a backtrace 

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr  3 21:08:01 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 3 Apr 2020 20:08:01 +0100
Subject: [R] a simple reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
Message-ID: <4f017a7b-e5ed-a954-e252-ba03d34f08bc@sapo.pt>

Hello,

It's a bit more complicated than you have coded it.
I will use pivot_wider, it's now the natural way of doing it.


test1 %>%
   group_by(vntr1) %>%
   mutate(group = row_number()) %>%
   ungroup() %>%
   pivot_wider(
     id_cols ="vntr1",
     names_from = "group",
     names_prefix = "a",
     values_from = "val"
   )


Hope this helps,

Rui Barradas

?s 19:57 de 03/04/20, Yuan Chun Ding escreveu:
> Hi R users,
> 
> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
> 
> Thank you,
> 
> Ding
> 
> test1 data frame is long file and test2 is the wide file I want to get
> 
> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>                       val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
> 
> test2  <- data.frame(vntr1=c("v1","v2"),
>                       a1 =c(0.98, 0.5693),
>                       a2 = c(0.02, 0.12),
>                       a3 =c(NA, 0.11),
>                       a4=c(NA, 0.04))
> 
> the following code does not work
> test2 <-test1 %>%spread(vntr1, val)
> 
>   Error: Each row of output must be identified by a unique combination of keys.
> Keys are shared for 6 rows:
> * 1, 2
> * 3, 4, 5, 6
> Do you need to create unique ID with tibble::rowid_to_column()?
> Call `rlang::last_error()` to see a backtrace
> 
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> 
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From ycd|ng @end|ng |rom coh@org  Fri Apr  3 21:17:54 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Fri, 3 Apr 2020 19:17:54 +0000
Subject: [R] a simple reshape
In-Reply-To: <4f017a7b-e5ed-a954-e252-ba03d34f08bc@sapo.pt>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>,
 <4f017a7b-e5ed-a954-e252-ba03d34f08bc@sapo.pt>
Message-ID: <A86C6438FB909A409DDEF926277952B6113D8111@PPWEXCH2KX14.coh.org>

Hi Rui,

Thanks a lot,

i got this error, I have library(tidyverse).

Ding

 Error in pivot_wider(., id_cols = "vntr1", names_from = "group", names_prefix = "a",  : 
  could not find function "pivot_wider" 
________________________________________
From: Rui Barradas [ruipbarradas at sapo.pt]
Sent: Friday, April 3, 2020 12:08 PM
To: Yuan Chun Ding; r-help mailing list
Subject: Re: [R] a simple reshape

Hello,

It's a bit more complicated than you have coded it.
I will use pivot_wider, it's now the natural way of doing it.


test1 %>%
   group_by(vntr1) %>%
   mutate(group = row_number()) %>%
   ungroup() %>%
   pivot_wider(
     id_cols ="vntr1",
     names_from = "group",
     names_prefix = "a",
     values_from = "val"
   )


Hope this helps,

Rui Barradas

?s 19:57 de 03/04/20, Yuan Chun Ding escreveu:
> Hi R users,
>
> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
>
> Thank you,
>
> Ding
>
> test1 data frame is long file and test2 is the wide file I want to get
>
> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>                       val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>
> test2  <- data.frame(vntr1=c("v1","v2"),
>                       a1 =c(0.98, 0.5693),
>                       a2 = c(0.02, 0.12),
>                       a3 =c(NA, 0.11),
>                       a4=c(NA, 0.04))
>
> the following code does not work
> test2 <-test1 %>%spread(vntr1, val)
>
>   Error: Each row of output must be identified by a unique combination of keys.
> Keys are shared for 6 rows:
> * 1, 2
> * 3, 4, 5, 6
> Do you need to create unique ID with tibble::rowid_to_column()?
> Call `rlang::last_error()` to see a backtrace
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oSGZ-U4t$
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oR2DUtwI$
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Apr  3 21:26:00 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 03 Apr 2020 12:26:00 -0700
Subject: [R] a simple reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D8111@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>,
 <4f017a7b-e5ed-a954-e252-ba03d34f08bc@sapo.pt>
 <A86C6438FB909A409DDEF926277952B6113D8111@PPWEXCH2KX14.coh.org>
Message-ID: <03AF5FC4-B790-4315-95CE-453A613DC879@dcn.davis.ca.us>

Update your packages. If you still have issues post the output of sessionInfo().

On April 3, 2020 12:17:54 PM PDT, Yuan Chun Ding <ycding at coh.org> wrote:
>Hi Rui,
>
>Thanks a lot,
>
>i got this error, I have library(tidyverse).
>
>Ding
>
>Error in pivot_wider(., id_cols = "vntr1", names_from = "group",
>names_prefix = "a",  : 
>  could not find function "pivot_wider" 
>________________________________________
>From: Rui Barradas [ruipbarradas at sapo.pt]
>Sent: Friday, April 3, 2020 12:08 PM
>To: Yuan Chun Ding; r-help mailing list
>Subject: Re: [R] a simple reshape
>
>Hello,
>
>It's a bit more complicated than you have coded it.
>I will use pivot_wider, it's now the natural way of doing it.
>
>
>test1 %>%
>   group_by(vntr1) %>%
>   mutate(group = row_number()) %>%
>   ungroup() %>%
>   pivot_wider(
>     id_cols ="vntr1",
>     names_from = "group",
>     names_prefix = "a",
>     values_from = "val"
>   )
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 19:57 de 03/04/20, Yuan Chun Ding escreveu:
>> Hi R users,
>>
>> I want to do a data reshape from long to wide, I thought it was easy
>using tidyverse spread function, but it did not work well. Can you help
>me?
>>
>> Thank you,
>>
>> Ding
>>
>> test1 data frame is long file and test2 is the wide file I want to
>get
>>
>> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>>                       val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>>
>> test2  <- data.frame(vntr1=c("v1","v2"),
>>                       a1 =c(0.98, 0.5693),
>>                       a2 = c(0.02, 0.12),
>>                       a3 =c(NA, 0.11),
>>                       a4=c(NA, 0.04))
>>
>> the following code does not work
>> test2 <-test1 %>%spread(vntr1, val)
>>
>>   Error: Each row of output must be identified by a unique
>combination of keys.
>> Keys are shared for 6 rows:
>> * 1, 2
>> * 3, 4, 5, 6
>> Do you need to create unique ID with tibble::rowid_to_column()?
>> Call `rlang::last_error()` to see a backtrace
>>
>>
>----------------------------------------------------------------------
>> ------------------------------------------------------------
>> -SECURITY/CONFIDENTIALITY WARNING-
>>
>> This message and any attachments are intended solely for the
>individual or entity to which they are addressed. This communication
>may contain information that is privileged, confidential, or exempt
>from disclosure under applicable law (e.g., personal health
>information, research data, financial information). Because this e-mail
>has been sent without encryption, individuals other than the intended
>recipient may be able to view the information, forward it to others or
>tamper with the information without the knowledge or consent of the
>sender. If you are not the intended recipient, or the employee or
>person responsible for delivering the message to the intended
>recipient, any dissemination, distribution or copying of the
>communication is strictly prohibited. If you received the communication
>in error, please notify the sender immediately by replying to this
>message and deleting the message and any accompanying files from your
>system. If, due to the security risks, you do not wish to receive
>further communications via e-mail, please reply to this message and
>inform the sender that you do not wish to receive further e-mail from
>the sender. (LCP301)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oSGZ-U4t$
>> PLEASE do read the posting guide
>https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oR2DUtwI$
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr  3 23:30:07 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 3 Apr 2020 22:30:07 +0100
Subject: [R] a simple reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D8111@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
 <4f017a7b-e5ed-a954-e252-ba03d34f08bc@sapo.pt>
 <A86C6438FB909A409DDEF926277952B6113D8111@PPWEXCH2KX14.coh.org>
Message-ID: <b2c4e697-a4f9-7952-fe04-56bfbec3769f@sapo.pt>

Hello,

That function is new (tidyr 1.0.0) and exists in

packageVersion('tidyverse')
#[1] ?1.3.0?
packageVersion('tidyr')
#[1] ?1.0.2?

 From the help page ?pivot_wider:

Details

pivot_wider() is an updated approach to spread(), designed to be both 
simpler to use and to handle more use cases. We recommend you use 
pivot_wider() for new code; spread() isn't going away but is no longer 
under active development.


So you must update your packages.

Hope this helps,

Rui Barradas


?s 20:17 de 03/04/20, Yuan Chun Ding escreveu:
> Hi Rui,
> 
> Thanks a lot,
> 
> i got this error, I have library(tidyverse).
> 
> Ding
> 
>   Error in pivot_wider(., id_cols = "vntr1", names_from = "group", names_prefix = "a",  :
>    could not find function "pivot_wider"
> ________________________________________
> From: Rui Barradas [ruipbarradas at sapo.pt]
> Sent: Friday, April 3, 2020 12:08 PM
> To: Yuan Chun Ding; r-help mailing list
> Subject: Re: [R] a simple reshape
> 
> Hello,
> 
> It's a bit more complicated than you have coded it.
> I will use pivot_wider, it's now the natural way of doing it.
> 
> 
> test1 %>%
>     group_by(vntr1) %>%
>     mutate(group = row_number()) %>%
>     ungroup() %>%
>     pivot_wider(
>       id_cols ="vntr1",
>       names_from = "group",
>       names_prefix = "a",
>       values_from = "val"
>     )
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 19:57 de 03/04/20, Yuan Chun Ding escreveu:
>> Hi R users,
>>
>> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
>>
>> Thank you,
>>
>> Ding
>>
>> test1 data frame is long file and test2 is the wide file I want to get
>>
>> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>>                        val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>>
>> test2  <- data.frame(vntr1=c("v1","v2"),
>>                        a1 =c(0.98, 0.5693),
>>                        a2 = c(0.02, 0.12),
>>                        a3 =c(NA, 0.11),
>>                        a4=c(NA, 0.04))
>>
>> the following code does not work
>> test2 <-test1 %>%spread(vntr1, val)
>>
>>    Error: Each row of output must be identified by a unique combination of keys.
>> Keys are shared for 6 rows:
>> * 1, 2
>> * 3, 4, 5, 6
>> Do you need to create unique ID with tibble::rowid_to_column()?
>> Call `rlang::last_error()` to see a backtrace
>>
>> ----------------------------------------------------------------------
>> ------------------------------------------------------------
>> -SECURITY/CONFIDENTIALITY WARNING-
>>
>> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oSGZ-U4t$
>> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!5JdwuHJ-WxfEwZqhEKnPmaGJJqCVHrJXr2iVwpKZ8UBKwdjSGRA4oR2DUtwI$
>> and provide commented, minimal, self-contained, reproducible code.
>>

From drj|m|emon @end|ng |rom gm@||@com  Fri Apr  3 23:36:25 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 4 Apr 2020 08:36:25 +1100
Subject: [R] Label
In-Reply-To: <CAJOiR6Z8jjcYdwsuNM4rpkJxr24q_oSaabR3creuf6drXcnfyw@mail.gmail.com>
References: <CAJOiR6Y8vjmt_yqoKiuuYqrs6hjC-We1KhOXZuigFiA-Eu5tvg@mail.gmail.com>
 <CA+8X3fXV6ozXs29=2mWo7RkaYZXqZK1ScsrWUvrpABH0j_N80A@mail.gmail.com>
 <CAJOiR6Z8jjcYdwsuNM4rpkJxr24q_oSaabR3creuf6drXcnfyw@mail.gmail.com>
Message-ID: <CA+8X3fUEjFnTWZf_DwxOhwrAMViD3pZjHg4OP47U_nCN9wc9CA@mail.gmail.com>

Hi Val,
A good suggestion. The revised code is below and it will be in the
next version of plotrix.

barlabels<-function(xpos,ypos,labels=NULL,cex=1,prop=0.5,miny=0,offset=0,
 nobox=FALSE,...) {

 if(is.data.frame(ypos)) ypos<-as.matrix(ypos)
 if(is.null(labels)) labels<-ypos
 # usually don't want to display zero labels
 display<-ypos > miny
 if(is.matrix(ypos)) {
  # prop is within the scope of the current environment
  cumcenter<-function(x,pos) return(cumsum(x)-x*prop)
  stacked<-length(xpos) < length(ypos)
  if(stacked) {
   # replicate the x positions one by one, but the offsets group by group
   xpos<-rep(xpos,each=length(ypos)/length(xpos))+
    rep(c(-offset,offset),length(ypos)/(2*length(xpos)))
   ypos<-apply(ypos,2,cumcenter)
  }
  else ypos<-ypos*prop
 }
 else ypos<-ypos*prop
 # allow labels to extend beyond the plot area
 par(xpd=TRUE)
 if(nobox) text(xpos[display],ypos[display],labels[display],cex=cex,...)
 else boxed.labels(xpos[display],ypos[display],labels[display],cex=cex,...)
 par(xpd=FALSE)
}

Just set "nobox" to TRUE. You can add a "col=" argument at the end and
it will be passed to "text".

Jim

On Sat, Apr 4, 2020 at 5:20 AM Val <valkremk at gmail.com> wrote:
>
> Thank you Jim,
>
> Is it possible to format the label box? The labels(numbers) are
> surrounded by a big square and wanted to remove it. I just want
> display only the number.  I searched up the documentation  for
> "barlabels" and there is no such example
>
> barlabels(xpos,ypos,labels=NULL,cex=1,prop=0.5,miny=0,offset=0,...)
>
> Thank you.
>
> On Thu, Apr 2, 2020 at 9:38 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Val,
> >
> > library(plotrix)
> > barpos<-barplot(dat$count, names.arg=c("A", "B", "C","D"),
> >          col="blue",
> >          ylim = c(0,30),
> >          ylab = "Count",
> >          xlab = "Grade")
> > barlabels(barpos,dat$count,prop=1)
> >
> > Jim
> >
> > On Fri, Apr 3, 2020 at 1:31 PM Val <valkremk at gmail.com> wrote:
> > >
> > > Hi all,
> > >
> > > I have a sample of data set,
> > >
> > > dat <- read.table(header=TRUE, text='Lab count
> > > A 24
> > > B 19
> > > C 30
> > > D 18')
> > >
> > > barplot(dat$count, names.arg=c("A", "B", "C","D"),
> > >         col="blue",
> > >         ylim = c(0,30),
> > >         ylab = "Count",
> > >         xlab = "Grade")
> > >
> > > I want add the number of counts at the top of each bar plot. How can I do that?
> > > Thank you in advance
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Apr  3 23:44:03 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 4 Apr 2020 08:44:03 +1100
Subject: [R] a simple reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
Message-ID: <CA+8X3fWdhT2yW4pYT3AJj2SowJAdY5KropOd5cnro2w=VedZeA@mail.gmail.com>

Hi Ding,
If you are still having trouble, perhaps:

library(prettyR)
stretch_df(test1,"vntr1","val")

Jim

On Sat, Apr 4, 2020 at 5:58 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
>
> Thank you,
>
> Ding
>
> test1 data frame is long file and test2 is the wide file I want to get
>
> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>                      val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>
> test2  <- data.frame(vntr1=c("v1","v2"),
>                      a1 =c(0.98, 0.5693),
>                      a2 = c(0.02, 0.12),
>                      a3 =c(NA, 0.11),
>                      a4=c(NA, 0.04))
>
> the following code does not work
> test2 <-test1 %>%spread(vntr1, val)
>
>  Error: Each row of output must be identified by a unique combination of keys.
> Keys are shared for 6 rows:
> * 1, 2
> * 3, 4, 5, 6
> Do you need to create unique ID with tibble::rowid_to_column()?
> Call `rlang::last_error()` to see a backtrace
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Apr  4 12:10:48 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 4 Apr 2020 15:40:48 +0530
Subject: [R] a simple reshape
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>
Message-ID: <CADfFDC56GLwW45BN=jmHpStVS-CHbLvTWBMe3q3S=QVtdS1D-w@mail.gmail.com>

Hi,

[For a non-tidyverse solution:]

Your problem is ambiguous without a 'time' variable; e.g., why should
the answer not be

test2  <- data.frame(vntr1=c("v1","v2"),
                     a1 =c(NA, 0.5693),
                     a2 = c(0.02, 0.12),
                     a3 =c(NA, 0.11),
                     a4=c(0.98, 0.04))

? If you do add an artificial time variable, say using

test1 <- transform(test1,
    time = unsplit(lapply(split(vntr1, vntr1), seq_along), vntr1))

to give

> test1
 vntr1  val time
1    v1 0.98    1
2    v1 0.02    2
3    v2 0.59    1
4    v2 0.12    2
5    v2 0.11    3
6    v2 0.04    4

then either reshape() or dcast() easily gives you what you want:

> reshape(test1, v.names = "val", idvar = "vntr1", direction = "wide", timevar = "time")
 vntr1 val.1 val.2 val.3 val.4
1    v1  0.98  0.02    NA    NA
3    v2  0.59  0.12  0.11  0.04

> reshape2::dcast(test1, vntr1 ~ time, value.var="val")
 vntr1    1    2    3    4
1    v1 0.98 0.02   NA   NA
2    v2 0.59 0.12 0.11 0.04

-Deepayan

On Sat, Apr 4, 2020 at 12:28 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
>
> Thank you,
>
> Ding
>
> test1 data frame is long file and test2 is the wide file I want to get
>
> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>                      val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>
> test2  <- data.frame(vntr1=c("v1","v2"),
>                      a1 =c(0.98, 0.5693),
>                      a2 = c(0.02, 0.12),
>                      a3 =c(NA, 0.11),
>                      a4=c(NA, 0.04))
>
> the following code does not work
> test2 <-test1 %>%spread(vntr1, val)
>
>  Error: Each row of output must be identified by a unique combination of keys.
> Keys are shared for 6 rows:
> * 1, 2
> * 3, 4, 5, 6
> Do you need to create unique ID with tibble::rowid_to_column()?
> Call `rlang::last_error()` to see a backtrace
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From megh@@j456 @end|ng |rom gm@||@com  Thu Apr  2 00:46:47 2020
From: megh@@j456 @end|ng |rom gm@||@com (Megha Joshi)
Date: Wed, 1 Apr 2020 17:46:47 -0500
Subject: [R] [R-pkgs] simhelpers: Helper Functions for Simulation Studies
Message-ID: <CAC1PbYRmsFor1_5bf9reOpBQHrq3qNP7B9PVsZLx9t=ZDZgPmw@mail.gmail.com>

Hi :)

Hope you are doing well!

I have been working on an R package that has helper functions for
simulation studies. First version of the package is on CRAN now ?
Here is the website for the package:
https://meghapsimatrix.github.io/simhelpers/index.html

Hope it is useful to you for running simulations in R :)

Hope you are safe and healthy!!


-- 
Megha Joshi
(she/her/hers)
meghapsimatrix.com
Doctoral student
Quantitative Methods
*The University of Texas at Austin*

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From or|@ndomontre@| @end|ng |rom y@hoo@com  Thu Apr  2 18:27:48 2020
From: or|@ndomontre@| @end|ng |rom y@hoo@com (Orlando Ramirez)
Date: Thu, 2 Apr 2020 16:27:48 +0000 (UTC)
Subject: [R] error:  Error in if (any(DF[A, ] != DF[B,
 ])) { :    missing value where TRUE/FALSE needed
References: <1144438423.1020445.1585844868171.ref@mail.yahoo.com>
Message-ID: <1144438423.1020445.1585844868171@mail.yahoo.com>

Hello this is my code and then i show you the result...please how i reapir this error...thanks lot off
library(igraph)
#################################################
# Lecture du fichier 0. edges
MyGraphData <- read.graph ( file = "0.edges" , directed = FALSE )
# Nombre de noeuds dans le graphe
Nb_noeuds <- vcount ( MyGraphData )
Nb_noeuds
# [1] 348
# Pour enlever les doublons et les boucles dans le graphe
MyGraphData <- simplify ( MyGraphData , remove.multiple = TRUE , remove.loops = TRUE )
# Nombre d ' arr?tes dans le graphe
Nb_arretes <- ecount ( MyGraphData )
Nb_arretes
# [1] 2519
# Structure hi?rarchique des noeuds
cluster <- edge.betweenness.community ( MyGraphData )
cluster
# > cluster
# # les noeuds dans chaque communaut?
# IGRAPH clustering edge betweenness, groups: 51, mod: 0.42
# + groups:
#?? $`1`
# [1] 1
# 
# $`2`
# [1]?? 2? 25? 49? 54? 58? 74? 81? 93? 95 102 127 131 181 188 192 195 197 205 243 250 255 267 300
# [24] 301 303 331 347
# 
# $`3`
# [1]?? 3? 15? 18? 20? 21? 29? 33? 42? 45? 94 112 113 116 117 138 139 141 145 150 152 163 168 175
# [24] 215 217 221 227 244 263 280 290 294 306 311 313 327 334 338 344
# + ... omitted several groups/vertices
# fc <- cluster_fast_greedy(MyGraphData)
#? plot_dendrogram(fc)
# Visualisation
plot_dendrogram (cluster? ) 
Error in if (any(DF[A, ] != DF[B, ])) { : 
? missing value where TRUE/FALSE needed



? ???????????????????????????????????  ?
????  ? ?
	[[alternative HTML version deleted]]


From @nj@|ygmenon9 @end|ng |rom gm@||@com  Fri Apr  3 02:45:30 2020
From: @nj@|ygmenon9 @end|ng |rom gm@||@com (anjaly menon)
Date: Fri, 3 Apr 2020 12:45:30 +1200
Subject: [R] MAP HELP
Message-ID: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>

Hello,

I have a dataset with latitude, longitude, station serial numbers of my
fish samples collected from the Barents Sea. I need to plot out from where
the samples are coming from using the latitude and longitude and the range
of body sizes (length of fishes) using R.
I installed packages like sp, maptools, mapdata, rgdal,shape, maps. Is
there any code to do this task? Please let me know.

Cheers

-- 
*Anjaly Govindankutty Menon*
Erasmus Mundus Scholar
Universite de Bordeaux, France

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Sat Apr  4 22:30:15 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sat, 4 Apr 2020 14:30:15 -0600
Subject: [R] MAP HELP
In-Reply-To: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>
References: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>
Message-ID: <CACxE24kt=CTY8U91SqYci6GmBNcgLRe6BN5pfsmJD0Esj6S9GQ@mail.gmail.com>

Hi!

What kind of a map are you looking for?  Google Earth, Open Street map or
something else, please?

Is your data in a data frame?

Thanks,
Erin


On Sat, Apr 4, 2020 at 2:10 PM anjaly menon <anjalygmenon9 at gmail.com> wrote:

> Hello,
>
> I have a dataset with latitude, longitude, station serial numbers of my
> fish samples collected from the Barents Sea. I need to plot out from where
> the samples are coming from using the latitude and longitude and the range
> of body sizes (length of fishes) using R.
> I installed packages like sp, maptools, mapdata, rgdal,shape, maps. Is
> there any code to do this task? Please let me know.
>
> Cheers
>
> --
> *Anjaly Govindankutty Menon*
> Erasmus Mundus Scholar
> Universite de Bordeaux, France
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Apr  5 00:53:52 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 5 Apr 2020 08:53:52 +1000
Subject: [R] MAP HELP
In-Reply-To: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>
References: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>
Message-ID: <CA+8X3fXG=W0KLLe1p0DB99vu5k4Sw3kt=LEeK_vrXjwfFte75w@mail.gmail.com>

Hi Anjaly,
Here is a very simple way to plot something like this. There are many
ways to do this and of course easier ways to automate the placement of
the points and labels.

library(maps)
library(plotrix)
map("world",xlim=c(13.548932,53.407331),ylim=c(70.824046,78.764113))
box()
segments(20,76,25,77)
points(25,77,pch=19)
boxed.labels(20,76,"Kraken\nn=2\nlat=20 lon=76\nlength=10-20M")
segments(40,72,51,71)
points(51,71,pch=19)
boxed.labels(40,72,"Herring\nn=20000\nlat=51 lon=70\nlength=15-20cm")

Jim

On Sun, Apr 5, 2020 at 6:10 AM anjaly menon <anjalygmenon9 at gmail.com> wrote:
>
> Hello,
>
> I have a dataset with latitude, longitude, station serial numbers of my
> fish samples collected from the Barents Sea. I need to plot out from where
> the samples are coming from using the latitude and longitude and the range
> of body sizes (length of fishes) using R.
> I installed packages like sp, maptools, mapdata, rgdal,shape, maps. Is
> there any code to do this task? Please let me know.
>
> Cheers
>
> --
> *Anjaly Govindankutty Menon*
> Erasmus Mundus Scholar
> Universite de Bordeaux, France
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycd|ng @end|ng |rom coh@org  Sun Apr  5 01:48:29 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sat, 4 Apr 2020 23:48:29 +0000
Subject: [R] a simple reshape
In-Reply-To: <CADfFDC56GLwW45BN=jmHpStVS-CHbLvTWBMe3q3S=QVtdS1D-w@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113D80E4@PPWEXCH2KX14.coh.org>,
 <CADfFDC56GLwW45BN=jmHpStVS-CHbLvTWBMe3q3S=QVtdS1D-w@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113D82BA@PPWEXCH2KX14.coh.org>

Hi Deepayan,

Thank you very much!! Yes, your method also works very well,  I thought about creating an extra time variable, but did not know how to do it.

Ding
________________________________________
From: Deepayan Sarkar [deepayan.sarkar at gmail.com]
Sent: Saturday, April 4, 2020 3:10 AM
To: Yuan Chun Ding
Cc: r-help mailing list
Subject: Re: [R] a simple reshape

Hi,

[For a non-tidyverse solution:]

Your problem is ambiguous without a 'time' variable; e.g., why should
the answer not be

test2  <- data.frame(vntr1=c("v1","v2"),
                     a1 =c(NA, 0.5693),
                     a2 = c(0.02, 0.12),
                     a3 =c(NA, 0.11),
                     a4=c(0.98, 0.04))

? If you do add an artificial time variable, say using

test1 <- transform(test1,
    time = unsplit(lapply(split(vntr1, vntr1), seq_along), vntr1))

to give

> test1
 vntr1  val time
1    v1 0.98    1
2    v1 0.02    2
3    v2 0.59    1
4    v2 0.12    2
5    v2 0.11    3
6    v2 0.04    4

then either reshape() or dcast() easily gives you what you want:

> reshape(test1, v.names = "val", idvar = "vntr1", direction = "wide", timevar = "time")
 vntr1 val.1 val.2 val.3 val.4
1    v1  0.98  0.02    NA    NA
3    v2  0.59  0.12  0.11  0.04

> reshape2::dcast(test1, vntr1 ~ time, value.var="val")
 vntr1    1    2    3    4
1    v1 0.98 0.02   NA   NA
2    v2 0.59 0.12 0.11 0.04

-Deepayan

On Sat, Apr 4, 2020 at 12:28 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
> I want to do a data reshape from long to wide, I thought it was easy using tidyverse spread function, but it did not work well. Can you help me?
>
> Thank you,
>
> Ding
>
> test1 data frame is long file and test2 is the wide file I want to get
>
> test1 <- data.frame (vntr1=c("v1","v1", "v2","v2","v2","v2"),
>                      val =c(0.98,0.02, 0.59,0.12,0.11,0.04))
>
> test2  <- data.frame(vntr1=c("v1","v2"),
>                      a1 =c(0.98, 0.5693),
>                      a2 = c(0.02, 0.12),
>                      a3 =c(NA, 0.11),
>                      a4=c(NA, 0.04))
>
> the following code does not work
> test2 <-test1 %>%spread(vntr1, val)
>
>  Error: Each row of output must be identified by a unique combination of keys.
> Keys are shared for 6 rows:
> * 1, 2
> * 3, 4, 5, 6
> Do you need to create unique ID with tibble::rowid_to_column()?
> Call `rlang::last_error()` to see a backtrace
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!_gFkJ_Cf4ZEMwLhfpOwr3W8LB2SUv3_s6vPFDW1_kVUN891RfsB4KvcZNHBM$
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!_gFkJ_Cf4ZEMwLhfpOwr3W8LB2SUv3_s6vPFDW1_kVUN891RfsB4KkMsIU01$
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Sun Apr  5 06:25:34 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 5 Apr 2020 07:25:34 +0300
Subject: [R] error: Error in if (any(DF[A, ] != DF[B,
 ])) { : missing value where TRUE/FALSE needed
In-Reply-To: <1144438423.1020445.1585844868171@mail.yahoo.com>
References: <1144438423.1020445.1585844868171.ref@mail.yahoo.com>
 <1144438423.1020445.1585844868171@mail.yahoo.com>
Message-ID: <CAGgJW77z19uePjYKF6o-nh4Km5TkKSADrzfqvGcb_SUM+FKuLQ@mail.gmail.com>

Hi Orlando,
This is not a reproducible example because of the line
MyGraphData <- read.graph ( file = "0.edges" , directed = FALSE )
We don't have the file   "0.edges" .

But here's an example that reproduces the error message. Maybe it will help
you find your problem.

DF <- data.frame( x=NA, y=5 )
if ( any( DF[1,] != DF[2,]) ) cat("hello world\n")

#  Error in if ( any( DF[1,] != DF[2,]) ) cat("hello world\n") :
#     missing value where TRUE/FALSE needed

HTH,
Eric


On Sat, Apr 4, 2020 at 11:10 PM Orlando Ramirez via R-help <
r-help at r-project.org> wrote:

> Hello this is my code and then i show you the result...please how i reapir
> this error...thanks lot off
> library(igraph)
> #################################################
> # Lecture du fichier 0. edges
> MyGraphData <- read.graph ( file = "0.edges" , directed = FALSE )
> # Nombre de noeuds dans le graphe
> Nb_noeuds <- vcount ( MyGraphData )
> Nb_noeuds
> # [1] 348
> # Pour enlever les doublons et les boucles dans le graphe
> MyGraphData <- simplify ( MyGraphData , remove.multiple = TRUE ,
> remove.loops = TRUE )
> # Nombre d ' arr?tes dans le graphe
> Nb_arretes <- ecount ( MyGraphData )
> Nb_arretes
> # [1] 2519
> # Structure hi?rarchique des noeuds
> cluster <- edge.betweenness.community ( MyGraphData )
> cluster
> # > cluster
> # # les noeuds dans chaque communaut?
> # IGRAPH clustering edge betweenness, groups: 51, mod: 0.42
> # + groups:
> #   $`1`
> # [1] 1
> #
> # $`2`
> # [1]   2  25  49  54  58  74  81  93  95 102 127 131 181 188 192 195 197
> 205 243 250 255 267 300
> # [24] 301 303 331 347
> #
> # $`3`
> # [1]   3  15  18  20  21  29  33  42  45  94 112 113 116 117 138 139 141
> 145 150 152 163 168 175
> # [24] 215 217 221 227 244 263 280 290 294 306 311 313 327 334 338 344
> # + ... omitted several groups/vertices
> # fc <- cluster_fast_greedy(MyGraphData)
> #  plot_dendrogram(fc)
> # Visualisation
> plot_dendrogram (cluster  )
> Error in if (any(DF[A, ] != DF[B, ])) { :
>   missing value where TRUE/FALSE needed
>
>
>
>                                        ?
> ?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sun Apr  5 13:46:11 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sun, 5 Apr 2020 17:16:11 +0530
Subject: [R] ggplot stat smooth and poly
In-Reply-To: <37de34217e244f10bcc7b5e5215609de@SRVEXCHCM1302.precheza.cz>
References: <37de34217e244f10bcc7b5e5215609de@SRVEXCHCM1302.precheza.cz>
Message-ID: <CADfFDC5aSOu9MNND-2UOLg8GjgKWaihJVKw5CyftYAzvsZYwdw@mail.gmail.com>

On Thu, Apr 2, 2020 at 6:10 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Dear all
>
> I am not sure, but I believe that in past it was possible to add smoothing
> lines in ggplot even if some group did not have enough points to perform
> calculation (although I did not find any version which could deliver it).
>
> Here is the code and data
>
> library(ggplot2)
> p <- ggplot(test, aes(x=one, y=two, colour=three))
> p+geom_point(size=5)+stat_smooth(method="lm")
> ***line added to each group
>
> p+geom_point(size=5)+stat_smooth(method="lm", formula=y~poly(x,2))
> Warning message:
> Computation failed in `stat_smooth()`:
> 'degree' must be less than number of unique points
> ***no line added to any group
>
> test <- structure(list(one = 1:20, two = c(1L, 4L, 9L, 16L, 25L, 36L,
> 49L, 64L, 81L, 100L, 121L, 144L, 169L, 196L, 225L, 256L, 289L,
> 324L, 361L, 400L), three = c("a", "a", "a", "a", "b", "b", "b",
> "b", "c", "c", "c", "c", "c", "d", "d", "e", "e", "e", "e", "e"
> )), class = "data.frame", row.names = c(NA, -20L))
>
> My question:
> Is it possible to add smoothing line just to the groups where it can be
> added? I know that I could exclude "d" level from my data but I would
> prefer
> to keep them and add only smoothing lines where they could be computed.
>

Looks like there's a tryCatch around each panel, but not for each group
within panel. So this would work:

p + geom_point(size=2) + facet_wrap(~three) +
    stat_smooth(method="lm", formula=y~poly(x,2))

but one problematic group is enough to make a whole panel fail.

Other than rewriting StatSmooth$compute_panel to protect each per-group
call, a workaround could be to replace method="lm" by a safe wrapper, e.g.,:

plm <- function(formula, data, ...)
{
    ocall <- match.call(expand.dots = TRUE)
    ocall[[1]] <- quote(lm)
    fm <- try(eval(ocall, parent.frame()), silent = TRUE)
    if (inherits(fm, "try-error"))
    {
        ocall[[2]] <- y ~ x
        fm <- eval(ocall, parent.frame())
    }
    fm
}

p + geom_point(size=2) + stat_smooth(method=plm, formula=y~poly(x,2))

-Deepayan

Best regards
> Petr
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Sun Apr  5 20:53:10 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Sun, 5 Apr 2020 14:53:10 -0400
Subject: [R] Curve fitting
Message-ID: <DEBA84FA-98F9-4B53-BA6C-CFD18322F45E@comcast.net>

Any recommendations on an R package to fit data to a nonlinear model Y=f(x) with a single x and y variable? 

I want to be able to generate parameter uncertainty estimates and prediction uncertainties if possible.

Bernard
Sent from my iPhone so please excuse the spelling!"

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr  5 21:14:15 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Apr 2020 12:14:15 -0700
Subject: [R] Curve fitting
In-Reply-To: <DEBA84FA-98F9-4B53-BA6C-CFD18322F45E@comcast.net>
References: <DEBA84FA-98F9-4B53-BA6C-CFD18322F45E@comcast.net>
Message-ID: <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>

stats::nlm?

On April 5, 2020 11:53:10 AM PDT, Bernard Comcast <mcgarvey.bernard at comcast.net> wrote:
>Any recommendations on an R package to fit data to a nonlinear model
>Y=f(x) with a single x and y variable? 
>
>I want to be able to generate parameter uncertainty estimates and
>prediction uncertainties if possible.
>
>Bernard
>Sent from my iPhone so please excuse the spelling!"
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr  5 21:20:58 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Apr 2020 12:20:58 -0700
Subject: [R] Curve fitting
In-Reply-To: <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>
References: <DEBA84FA-98F9-4B53-BA6C-CFD18322F45E@comcast.net>
 <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>
Message-ID: <851C25D9-A5CA-4FAF-9CE9-78DE14680F80@dcn.davis.ca.us>

err... stats::nls...

On April 5, 2020 12:14:15 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>stats::nlm?
>
>On April 5, 2020 11:53:10 AM PDT, Bernard Comcast
><mcgarvey.bernard at comcast.net> wrote:
>>Any recommendations on an R package to fit data to a nonlinear model
>>Y=f(x) with a single x and y variable? 
>>
>>I want to be able to generate parameter uncertainty estimates and
>>prediction uncertainties if possible.
>>
>>Bernard
>>Sent from my iPhone so please excuse the spelling!"
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Sun Apr  5 21:50:28 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Sun, 5 Apr 2020 15:50:28 -0400
Subject: [R] Curve fitting
In-Reply-To: <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>
References: <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>
Message-ID: <794B36B9-1891-45F1-A104-82240C2C5D92@comcast.net>

Thanks Jeff

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 5, 2020, at 3:14 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> ?stats::nlm?
> 
>> On April 5, 2020 11:53:10 AM PDT, Bernard Comcast <mcgarvey.bernard at comcast.net> wrote:
>> Any recommendations on an R package to fit data to a nonlinear model
>> Y=f(x) with a single x and y variable? 
>> 
>> I want to be able to generate parameter uncertainty estimates and
>> prediction uncertainties if possible.
>> 
>> Bernard
>> Sent from my iPhone so please excuse the spelling!"
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Apr  5 23:18:46 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 5 Apr 2020 17:18:46 -0400
Subject: [R] Curve fitting
In-Reply-To: <851C25D9-A5CA-4FAF-9CE9-78DE14680F80@dcn.davis.ca.us>
References: <DEBA84FA-98F9-4B53-BA6C-CFD18322F45E@comcast.net>
 <168557D3-3746-4E56-A1DB-D41903C93A30@dcn.davis.ca.us>
 <851C25D9-A5CA-4FAF-9CE9-78DE14680F80@dcn.davis.ca.us>
Message-ID: <3394ac1d-b1b4-5790-b89b-67e952e34dad@gmail.com>

Generally nlsr package has better reliability in getting parameter estimates
because it tries to use automatic derivatives rather than a rather poor numerical
estimate, and also uses a Levenberg-Marquardt stabilization of the linearized
model. However, nls() can sometimes be a bit more flexible.

JN

On 2020-04-05 3:20 p.m., Jeff Newmiller wrote:
> err... stats::nls...
> 
> On April 5, 2020 12:14:15 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> stats::nlm?
>>
>> On April 5, 2020 11:53:10 AM PDT, Bernard Comcast
>> <mcgarvey.bernard at comcast.net> wrote:
>>> Any recommendations on an R package to fit data to a nonlinear model
>>> Y=f(x) with a single x and y variable? 
>>>
>>> I want to be able to generate parameter uncertainty estimates and
>>> prediction uncertainties if possible.
>>>
>>> Bernard
>>> Sent from my iPhone so please excuse the spelling!"
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From bj@@m|@r@ @end|ng |rom gm@||@com  Mon Apr  6 06:27:08 2020
From: bj@@m|@r@ @end|ng |rom gm@||@com (Bijesh Mishra)
Date: Sun, 5 Apr 2020 23:27:08 -0500
Subject: [R] Help needed: gdal-configuration to install sf package in Mac OS
 Catalina
Message-ID: <CAJ5oOKWwDiFa=y7fecW4xrCNz6AtsFeQ-by-4ke_w2qqThJ8Zg@mail.gmail.com>

Hi,
I am using R in Mac. I was trying to install sf package but could not and
got error. Detail message of error is under this email. It seems like I
have to run gdal- configuration, but not sure what that means. Do you have
any idea about that?

This is the message I got while installing SF package:

configure: error: gdal-config not found or not executable.
ERROR: configuration failed for package ?sf?
* removing
?/Library/Frameworks/R.framework/Versions/3.6/Resources/library/sf?
Error: Failed to install 'sf' from GitHub:
  (converted from warning) installation of package
?/var/folders/5_/74nhx31d521cjc_gjz58nh8r0000gn/T//RtmpO7v2bW/filea6321afd2c24/sf_0.9-1.tar.gz?
had non-zero exit status

-- 
Kind Regards,
Bijesh Mishra.
***********************************************************************************************

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Apr  6 08:48:23 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Apr 2020 08:48:23 +0200
Subject: [R] ncol() vs. length() on data.frames
In-Reply-To: <CAFEqCdy+GYz5ZXD16tjLR2ipnO46uY=yoYYmM+0jw-xKuvL7DA@mail.gmail.com>
References: <a355b6f4-5bc5-6e32-ba5c-ae4993b65d08@rgzm.de>
 <20200331170009.6240febb@Tarkus>
 <1df86ec9-c3c1-3c65-160c-17b7b4d75547@rgzm.de>
 <CAFEqCdy+GYz5ZXD16tjLR2ipnO46uY=yoYYmM+0jw-xKuvL7DA@mail.gmail.com>
Message-ID: <3622ef9d-55f8-c2c4-490f-cadc30294a3d@rgzm.de>

Thank you Greg for the insights!

I agree with you that the decrease in speed is not worth the decrease in
readability, and I'll change my length() calls to ncol().

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 03/04/2020 17:45, Greg Snow wrote:
> As others have pointed out, ncol calls the length function, so you are
> pretty safe in terms of output of getting the same result when applied
> to the results of functions like read.csv (there will be a big
> difference if you ever apply those functions to a matrix or some other
> data structures).
>
> One thing that I have not seen yet is a comparison on timing, so here goes:
>
>> library(microbenchmark)
>> microbenchmark(
> + length = length(iris),
> + ncol = ncol(iris)
> + )
> Unit: nanoseconds
>    expr  min   lq mean median   uq   max neval
>  length  700  750  869    800  800  7400   100
>    ncol 2400 2500 2981   2600 2700 31900   100
>
> So ncol takes about 3 times as long to run as length on the iris data
> frame (5 columns), you can rerun the above code with data frames more
> the size that you will be using to see if that makes any difference.
> But also notice that the units are nanoseconds, so the median time for
> ncol to run is less than the time it takes light to travel a kilometer
> in a vacuum, or about the time it takes light to go 1/3 of a mile
> through a fiber optic cable (en.wikipedia.org/wiki/Microsecond).  If
> this is used as part of a simulation or other repeated procedure and
> it is done one million times then you will add about 2 seconds to the
> overall run.  If this is just part of code where length/ncol will be
> called fewer than 10 times then nobody is going to notice.
>
> So the trade-off of moving from length to ncol is a slight decrease in
> speed for an increase of readability.  I think that I would go with
> the readability myself.
>
> On Tue, Mar 31, 2020 at 8:11 AM Ivan Calandra <calandra at rgzm.de> wrote:
>> Thanks Ivan for the answer.
>>
>> So it confirms my first thought that these two functions are equivalent
>> when applied to a "simple" data.frame.
>>
>> The reason I was asking is because I have gotten used to use length() in
>> my scripts. It works perfectly and I understand it easily. But to be
>> honest, ncol() is more intuitive to most users (especially the novice)
>> so I was thinking about switching to using this function instead (all my
>> data.frames are created from read.csv() or similar functions so there
>> should not be any issue). But before doing that, I want to be sure that
>> it is not going to create unexpected results.
>>
>> Thank you,
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 31/03/2020 16:00, Ivan Krylov wrote:
>>> On Tue, 31 Mar 2020 14:47:54 +0200
>>> Ivan Calandra <calandra at rgzm.de> wrote:
>>>
>>>> On a simple data.frame (i.e. each element is a vector), ncol() and
>>>> length() will give the same result.
>>>> Are they just equivalent on such objects, or are they differences in
>>>> some cases?
>>> I am not aware of any exceptions to ncol(dataframe)==length(dataframe)
>>> (in fact, ncol(x) is dim(x)[2L] and ?dim says that dim(dataframe)
>>> returns c(length(attr(dataframe, 'row.names')), length(dataframe))), but
>>> watch out for AsIs columns which can have columns of their own:
>>>
>>> x <- data.frame(I(volcano))
>>> dim(x)
>>> # [1] 87  1
>>> length(x)
>>> # [1] 1
>>> dim(x[,1])
>>> # [1] 87 61
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Apr  6 09:11:27 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 6 Apr 2020 10:11:27 +0300
Subject: [R] 
 Help needed: gdal-configuration to install sf package in Mac OS
 Catalina
In-Reply-To: <CAJ5oOKWwDiFa=y7fecW4xrCNz6AtsFeQ-by-4ke_w2qqThJ8Zg@mail.gmail.com>
References: <CAJ5oOKWwDiFa=y7fecW4xrCNz6AtsFeQ-by-4ke_w2qqThJ8Zg@mail.gmail.com>
Message-ID: <20200406101127.63958cc7@Tarkus>

On Sun, 5 Apr 2020 23:27:08 -0500
Bijesh Mishra <bjs.misra at gmail.com> wrote:

> configure: error: gdal-config not found or not executable.

This would mean that gdal [1], which is a dependency of the sf package,
is not installed (or not available on $PATH, or...). If you use
Homebrew [2], try running 'brew install gdal'. If you are still having
problems, consider asking on R-SIG-Mac list [3].

-- 
Best regards,
Ivan

[1] https://gdal.org/

[2] https://brew.sh/

[3] https://stat.ethz.ch/mailman/listinfo/r-sig-mac


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Apr  6 10:29:30 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 6 Apr 2020 08:29:30 +0000
Subject: [R] nearest lower and higher integers to a multiple of another
 integer
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>

Dear R list members,
given an integer x, I would need to find the nearest lower and higher integers (xmin and xmax) to a multiple of another integer n.

Example: if x is -2 and n is 4, xmin becomes -4 and xmax is 0.

I tried to manage it with simple "if" statements, but this is not efficient at all.
Could please somebody help me to find an easy way to implement it?

Thank you for your attention and your help
Stefano Sofia

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Apr  6 10:45:52 2020
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 6 Apr 2020 10:45:52 +0200
Subject: [R] nearest lower and higher integers to a multiple of another
 integer
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>
Message-ID: <ddba8722-bd0f-93ea-3fc2-3bd3ace42590@math.uni-giessen.de>

Hi Stefano,

maybe floor(x / n) * n and ceiling(x / n) * n does what you want?

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 06.04.2020 um 10:29 schrieb Stefano Sofia:
> Dear R list members,
> given an integer x, I would need to find the nearest lower and higher integers (xmin and xmax) to a multiple of another integer n.
> 
> Example: if x is -2 and n is 4, xmin becomes -4 and xmax is 0.
> 
> I tried to manage it with simple "if" statements, but this is not efficient at all.
> Could please somebody help me to find an easy way to implement it?
> 
> Thank you for your attention and your help
> Stefano Sofia
> 
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> 
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr  6 10:45:29 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Apr 2020 01:45:29 -0700
Subject: [R] nearest lower and higher integers to a multiple of another
 integer
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>
Message-ID: <FCC13E41-DC42-4850-96D4-687283BAB6CB@dcn.davis.ca.us>

x <- -2
xi <- x %/% 4
xmin <- 4 * xi
xmax <- 4 * ( 1 + xi )

On April 6, 2020 1:29:30 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
>Dear R list members,
>given an integer x, I would need to find the nearest lower and higher
>integers (xmin and xmax) to a multiple of another integer n.
>
>Example: if x is -2 and n is 4, xmin becomes -4 and xmax is 0.
>
>I tried to manage it with simple "if" statements, but this is not
>efficient at all.
>Could please somebody help me to find an easy way to implement it?
>
>Thank you for your attention and your help
>Stefano Sofia
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail: stefano.sofia at regione.marche.it
>---Oo---------oO----------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>--
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Apr  6 11:31:47 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 6 Apr 2020 09:31:47 +0000
Subject: [R] nearest lower and higher integers to a multiple of another
 integer
In-Reply-To: <FCC13E41-DC42-4850-96D4-687283BAB6CB@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F809A13C3@ESINO.regionemarche.intra>,
 <FCC13E41-DC42-4850-96D4-687283BAB6CB@dcn.davis.ca.us>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F809A13E1@ESINO.regionemarche.intra>

Thank you very much.
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Jeff Newmiller [jdnewmil at dcn.davis.ca.us]
Inviato: luned? 6 aprile 2020 10.45
A: r-help at r-project.org; Stefano Sofia; r-help at r-project.org
Oggetto: Re: [R] nearest lower and higher integers to a multiple of another integer

x <- -2
xi <- x %/% 4
xmin <- 4 * xi
xmax <- 4 * ( 1 + xi )

On April 6, 2020 1:29:30 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
>Dear R list members,
>given an integer x, I would need to find the nearest lower and higher
>integers (xmin and xmax) to a multiple of another integer n.
>
>Example: if x is -2 and n is 4, xmin becomes -4 and xmax is 0.
>
>I tried to manage it with simple "if" statements, but this is not
>efficient at all.
>Could please somebody help me to find an easy way to implement it?
>
>Thank you for your attention and your help
>Stefano Sofia
>
>         (oo)
>--oOO--( )--OOo----------------
>Stefano Sofia PhD
>Civil Protection - Marche Region
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona
>Uff: 071 806 7743
>E-mail: stefano.sofia at regione.marche.it
>---Oo---------oO----------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
>informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate alla ricezione. I messaggi di posta elettronica per i
>client di Regione Marche possono contenere informazioni confidenziali e
>con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>
>--
>Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>This message was scanned by Libra ESVA and is believed to be clean.
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
>PLEASE do read the posting guide
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Apr  6 15:26:24 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 6 Apr 2020 15:26:24 +0200
Subject: [R] correlated metrics using AutoSpearman
Message-ID: <CA+nrPnuLLUPQoa7_tXF4R7u-jspOhG2bdn4wPGMWipAdc5RLWw@mail.gmail.com>

Hello

I am using feature selection using AutoSpearman but I have no idea what to
do after the 'plotVarClus' function, which is just a graph and red bars are
going out of the input metrics.

My question is what is the next step to perform the feature selection
(exclude correlated metrics).

I used the following code.

library("Rnalytica")
Data = loadDefectDataset("eclipse-2.0")
plotVarClus(dataset = Data$data, metrics = Data$indep,
             correlation = "spearman",
             correlation.threshold = 0.7, vif.threshold = 5)

	[[alternative HTML version deleted]]


From @co|we|| @end|ng |rom uogue|ph@c@  Mon Apr  6 18:37:18 2020
From: @co|we|| @end|ng |rom uogue|ph@c@ (Scott Colwell)
Date: Mon, 6 Apr 2020 16:37:18 +0000
Subject: [R] Quantitative Methods Workshops in May 2020
Message-ID: <D153B79E-82FE-4A0B-8FF3-5B034094EE8B@uoguelph.ca>

FORWARDED ? The following message has been forwarded and is not related to the University of Guelph.

Apologies for the cross-posting.

Good morning everyone. We sincerely hope you are all keeping safe and healthy while we all endure this pandemic.

As a result of the restrictions on public gatherings, we are going to be delivering our May 2020 workshops via online live streaming now as opposed to face-to-face at McMaster University. We will be providing materials ahead of time for all participants and will still include time for individual consultation regarding your own data (which can be scheduled at the live-stream workshop).

Each workshop provides a hands-on opportunity to learn using both R (with R-Studio) and Mplus.

For further information and to register, please go to: https://workshops.enablytics.com/


[1] Introduction to Structural Equation Modeling

This one-day hands-on workshop covers various introductory topics in structural equation modeling with continuous and categorical variables. Topics include, assumptions and data considerations, model creation, identification, and evaluation, multiple regression vs path analysis, path analysis, testing direct and indirect effects, and confirmatory factor analysis. Examples will be demonstrated in both R (using R-Studio) and Mplus. Syntax and output for both programs will be provided for all examples covered in the workshop.

[2] Advanced Structural Equation Modeling

This one-day hands-on workshop covers various advanced topics in structural equation modeling with continuous and categorical variables. Topics include, model creation, identification, and evaluation, testing moderation, mediation and moderated mediation, multiple group modeling, handling missing data, measurement invariance and power analysis. Examples will be demonstrated in both R (using R-Studio) and Mplus. Syntax and output for both programs will be provided for all examples covered in the workshop.

[3] Growth Modeling

This one-day hands-on workshop covers various topics in growth modeling (longitudinal modeling) with continuous and categorical variables. Topics include, growth modeling without covariates, growth modeling with time invariant and varying covariates, centering points, piecewise growth modeling, missing data and power analysis. Examples will be demonstrated in both R (using R-Studio) and Mplus. Syntax and output for both programs will be provided for all examples covered in the workshop.

[4] Multilevel Modeling

This two day hands-on workshop covers various topics in multilevel modeling with continuous and categorical variables. Topics include, when multilevel analysis is necessary, multilevel regression, random slopes and cross-level effects, multilevel confirmatory factor analysis and the MIMIC model, multilevel path analysis, multilevel mediation and moderation, multilevel latent variable modeling, longitudinal data, and power analysis. Examples will be demonstrated in both R (using R-Studio) and Mplus. Syntax and output for both programs will be provided for all examples covered in the workshop.

Thank you,

Scott





	[[alternative HTML version deleted]]


From hp@ge@ @end|ng |rom |redhutch@org  Tue Apr  7 02:56:57 2020
From: hp@ge@ @end|ng |rom |redhutch@org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 6 Apr 2020 17:56:57 -0700
Subject: [R] ncol() vs. length() on data.frames
In-Reply-To: <eca60220-bc69-09b0-163a-73c7427a4296@rgzm.de>
References: <a355b6f4-5bc5-6e32-ba5c-ae4993b65d08@rgzm.de>
 <CAGgJW75awWd+ebqGuXEEaXg3i-7z3U5FpgWUxOuz7HauvFCXxw@mail.gmail.com>
 <6838c19f-5d00-bc0d-5a08-c1ba26fe1705@rgzm.de>
 <CAGgJW77jmY4=YhOt2Ye=1x2niLx-nBS9O0+kd8tfNdXuZE_t2Q@mail.gmail.com>
 <eca60220-bc69-09b0-163a-73c7427a4296@rgzm.de>
Message-ID: <3998dab7-eb58-e738-baa5-6ecfcad9eed8@fredhutch.org>

Hi Ivan,

On 3/31/20 06:44, Ivan Calandra wrote:
> That's exactly why I was asking if it really is equivalent and if there
> are issues using one function or the other

Not that I know. It's mostly a matter of taste and code readability.

Either use the 2D interface:

    ncol(df), colnames(df), df[ , "somecol"], cbind(), etc...

or the list interface:

    length(df), names(df), df[["somecol"]], c(), etc...

to operate on your data.frames. They're equivalent. One advantage of 
using the latter though is that your code would also work on list 
objects that are not data.frames. But maybe you don't need or care about 
that in which case using one interface or the other makes no difference.

Note that the 2D interface is richer because it has nrow(), rownames(), 
rbind() that are not part of the list interface.

 From a code readability point of view I think one should be consistent 
and avoid mixing the 2 styles. For example IMO using length(df) and 
colnames(df) in the same function body is not good style. Either use 
length(df) and names(df), or use ncol(df) and colnames(df). If in the 
same function body you need to also access the rownames() then it would 
make sense to stick to the 2D interface throughout the entire body of 
your function.

Cheers,
H.

> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
> 
> On 31/03/2020 15:39, Eric Berger wrote:
>> Yes it does because?length(list) gives you the number of elements of
>> the list. And in the case of a data frame object that is the number of
>> columns, or ncol().
>>
>> On Tue, Mar 31, 2020 at 4:37 PM Ivan Calandra <calandra at rgzm.de
>> <mailto:calandra at rgzm.de>> wrote:
>>
>>      Thanks Eric,
>>
>>      I know that, but that doesn't really answer my question, does it?
>>
>>      Ivan
>>
>>      --
>>      Dr. Ivan Calandra
>>      TraCEr, laboratory for Traceology and Controlled Experiments
>>      MONREPOS Archaeological Research Centre and
>>      Museum for Human Behavioural Evolution
>>      Schloss Monrepos
>>      56567 Neuwied, Germany
>>      +49 (0) 2631 9772-243
>>      https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
>>
>>      On 31/03/2020 15:26, Eric Berger wrote:
>>      > A data frame is a special case of a list. It is a list of its
>>      columns.
>>      >
>>      > > is.list( your_data_frame )
>>      >
>>      > # TRUE
>>      >
>>      >
>>      > On Tue, Mar 31, 2020 at 4:04 PM Ivan Calandra <calandra at rgzm.de
>>      <mailto:calandra at rgzm.de>
>>      > <mailto:calandra at rgzm.de <mailto:calandra at rgzm.de>>> wrote:
>>      >
>>      >? ? ?Dear useRs,
>>      >
>>      >? ? ?I have a very simple question:
>>      >? ? ?On a simple data.frame (i.e. each element is a vector),
>>      ncol() and
>>      >? ? ?length() will give the same result.
>>      >
>>      >? ? ?Are they just equivalent on such objects, or are they
>>      differences in
>>      >? ? ?some cases?
>>      >? ? ?Is one of them to be preferred for whatever reason?
>>      >
>>      >? ? ?Thanks you,
>>      >? ? ?Ivan
>>      >
>>      >? ? ?--
>>      >? ? ?Dr. Ivan Calandra
>>      >? ? ?TraCEr, laboratory for Traceology and Controlled Experiments
>>      >? ? ?MONREPOS Archaeological Research Centre and
>>      >? ? ?Museum for Human Behavioural Evolution
>>      >? ? ?Schloss Monrepos
>>      >? ? ?56567 Neuwied, Germany
>>      >? ? ?+49 (0) 2631 9772-243
>>      >? ? ?https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
>>      >
>>      >? ? ?______________________________________________
>>      >? ? ?R-help at r-project.org <mailto:R-help at r-project.org>
>>      <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>      mailing list --
>>      >? ? ?To UNSUBSCRIBE and more, see
>>      >? ? ?https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
>>      >? ? ?PLEASE do read the posting guide
>>      >? ? ?https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
>>      >? ? ?and provide commented, minimal, self-contained, reproducible
>>      code.
>>      >
>>
>>      ______________________________________________
>>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>      To UNSUBSCRIBE and more, see
>>      https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
>>      PLEASE do read the posting guide
>>      https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
>>      and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Apr  7 08:46:42 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 7 Apr 2020 08:46:42 +0200
Subject: [R] ncol() vs. length() on data.frames
In-Reply-To: <3998dab7-eb58-e738-baa5-6ecfcad9eed8@fredhutch.org>
References: <a355b6f4-5bc5-6e32-ba5c-ae4993b65d08@rgzm.de>
 <CAGgJW75awWd+ebqGuXEEaXg3i-7z3U5FpgWUxOuz7HauvFCXxw@mail.gmail.com>
 <6838c19f-5d00-bc0d-5a08-c1ba26fe1705@rgzm.de>
 <CAGgJW77jmY4=YhOt2Ye=1x2niLx-nBS9O0+kd8tfNdXuZE_t2Q@mail.gmail.com>
 <eca60220-bc69-09b0-163a-73c7427a4296@rgzm.de>
 <3998dab7-eb58-e738-baa5-6ecfcad9eed8@fredhutch.org>
Message-ID: <0b658d90-c02f-8b66-feb0-2e9b8cca6b19@rgzm.de>

Dear Herv?,

This is indeed a wise recommendation; I hadn't thought about colnames()
vs. names(), and in general 2D vs. list notations.
I will have to edit a bit more than I thought.

Thank you all for all these hints!

Best,
Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 07/04/2020 02:56, Herv? Pag?s wrote:
> Hi Ivan,
>
> On 3/31/20 06:44, Ivan Calandra wrote:
>> That's exactly why I was asking if it really is equivalent and if there
>> are issues using one function or the other
>
> Not that I know. It's mostly a matter of taste and code readability.
>
> Either use the 2D interface:
>
> ?? ncol(df), colnames(df), df[ , "somecol"], cbind(), etc...
>
> or the list interface:
>
> ?? length(df), names(df), df[["somecol"]], c(), etc...
>
> to operate on your data.frames. They're equivalent. One advantage of
> using the latter though is that your code would also work on list
> objects that are not data.frames. But maybe you don't need or care
> about that in which case using one interface or the other makes no
> difference.
>
> Note that the 2D interface is richer because it has nrow(),
> rownames(), rbind() that are not part of the list interface.
>
> From a code readability point of view I think one should be consistent
> and avoid mixing the 2 styles. For example IMO using length(df) and
> colnames(df) in the same function body is not good style. Either use
> length(df) and names(df), or use ncol(df) and colnames(df). If in the
> same function body you need to also access the rownames() then it
> would make sense to stick to the 2D interface throughout the entire
> body of your function.
>
> Cheers,
> H.
>
>>
>> -- 
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
>>
>>
>> On 31/03/2020 15:39, Eric Berger wrote:
>>> Yes it does because?length(list) gives you the number of elements of
>>> the list. And in the case of a data frame object that is the number of
>>> columns, or ncol().
>>>
>>> On Tue, Mar 31, 2020 at 4:37 PM Ivan Calandra <calandra at rgzm.de
>>> <mailto:calandra at rgzm.de>> wrote:
>>>
>>> ???? Thanks Eric,
>>>
>>> ???? I know that, but that doesn't really answer my question, does it?
>>>
>>> ???? Ivan
>>>
>>> ???? --
>>> ???? Dr. Ivan Calandra
>>> ???? TraCEr, laboratory for Traceology and Controlled Experiments
>>> ???? MONREPOS Archaeological Research Centre and
>>> ???? Museum for Human Behavioural Evolution
>>> ???? Schloss Monrepos
>>> ???? 56567 Neuwied, Germany
>>> ???? +49 (0) 2631 9772-243
>>> ????
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
>>>
>>> ???? On 31/03/2020 15:26, Eric Berger wrote:
>>> ???? > A data frame is a special case of a list. It is a list of its
>>> ???? columns.
>>> ???? >
>>> ???? > > is.list( your_data_frame )
>>> ???? >
>>> ???? > # TRUE
>>> ???? >
>>> ???? >
>>> ???? > On Tue, Mar 31, 2020 at 4:04 PM Ivan Calandra <calandra at rgzm.de
>>> ???? <mailto:calandra at rgzm.de>
>>> ???? > <mailto:calandra at rgzm.de <mailto:calandra at rgzm.de>>> wrote:
>>> ???? >
>>> ???? >? ? ?Dear useRs,
>>> ???? >
>>> ???? >? ? ?I have a very simple question:
>>> ???? >? ? ?On a simple data.frame (i.e. each element is a vector),
>>> ???? ncol() and
>>> ???? >? ? ?length() will give the same result.
>>> ???? >
>>> ???? >? ? ?Are they just equivalent on such objects, or are they
>>> ???? differences in
>>> ???? >? ? ?some cases?
>>> ???? >? ? ?Is one of them to be preferred for whatever reason?
>>> ???? >
>>> ???? >? ? ?Thanks you,
>>> ???? >? ? ?Ivan
>>> ???? >
>>> ???? >? ? ?--
>>> ???? >? ? ?Dr. Ivan Calandra
>>> ???? >? ? ?TraCEr, laboratory for Traceology and Controlled Experiments
>>> ???? >? ? ?MONREPOS Archaeological Research Centre and
>>> ???? >? ? ?Museum for Human Behavioural Evolution
>>> ???? >? ? ?Schloss Monrepos
>>> ???? >? ? ?56567 Neuwied, Germany
>>> ???? >? ? ?+49 (0) 2631 9772-243
>>> ???? >? ?
>>> ?https://urldefense.proofpoint.com/v2/url?u=https-3A__www.researchgate.net_profile_Ivan-5FCalandra&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=rSFaISqU4VRbZBhLtnKvwJmxwkKQ0kAN0sIAfSBWUkw&e=
>>> ???? >
>>> ???? >? ? ?______________________________________________
>>> ???? >? ? ?R-help at r-project.org <mailto:R-help at r-project.org>
>>> ???? <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>> ???? mailing list --
>>> ???? >? ? ?To UNSUBSCRIBE and more, see
>>> ???? >? ?
>>> ?https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
>>> ???? >? ? ?PLEASE do read the posting guide
>>> ???? >? ?
>>> ?https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
>>> ???? >? ? ?and provide commented, minimal, self-contained, reproducible
>>> ???? code.
>>> ???? >
>>>
>>> ???? ______________________________________________
>>> ???? R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>> ???? To UNSUBSCRIBE and more, see
>>> ????
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
>>> ???? PLEASE do read the posting guide
>>> ????
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
>>> ???? and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=RzvpfqevFgNjYNRLX0nYF8un-5x7k-QG5h0465YA7mQ&e=
>>
>> PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=yZXfRqVdJeNf73bgLhzIctzOWowNX-0ccnNHdReiprw&s=kL6q9dyo4ScG-oZCxbTTWwVV389KO1pOpXMWZWd15bs&e=
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr  7 11:52:01 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 7 Apr 2020 19:52:01 +1000
Subject: [R] MAP HELP
In-Reply-To: <CAJxCbFY4RXuXit_HXou2ChpFbUNbG=AbY0Yu8-Sm2HTMpp62jA@mail.gmail.com>
References: <CAJxCbFY=LfymhXhK3=+iQo4-WzeW35b4EnVn728q2BCTN8ortA@mail.gmail.com>
 <CA+8X3fXG=W0KLLe1p0DB99vu5k4Sw3kt=LEeK_vrXjwfFte75w@mail.gmail.com>
 <CAJxCbFZZadH4DYKO_h4Cz8U-i7Bqt72nJ4AXv+0kNDQzU+RrfQ@mail.gmail.com>
 <CA+8X3fWgRaFo7yx4Y0QfsPQqLwxHiPmt4KXNLVKcqsZ-Xsj8Tg@mail.gmail.com>
 <CAJxCbFY3rC__OLGKhVgTiFPQqZLVu255hHQNgWDzZzQ2JZ6SnA@mail.gmail.com>
 <CA+8X3fUCLvXrQA0pEFwdVyBkQRP2V-5kL7XUsWVuaRi1o=q2wg@mail.gmail.com>
 <CAJxCbFY4RXuXit_HXou2ChpFbUNbG=AbY0Yu8-Sm2HTMpp62jA@mail.gmail.com>
Message-ID: <CA+8X3fXbJUwK6O4YsHgKVSpycuNi+_u=fpnuRr2WVyPxoLo0dQ@mail.gmail.com>

Hi Anjaly,
I think that replacing the "geom_point" argument with "geom_text" will
do what you want. Unfortunately I can't get an example to work (as
usual) so I'm copying this back the the R help list in the hope that
someone will provide the answer for you.

Jim

On Tue, Apr 7, 2020 at 7:29 PM anjaly menon <anjalygmenon9 at gmail.com> wrote:
>
> I'll show you the dataset with long and lat. There are 184 observations. The number of fishes collected is one per observation.
> I am attaching the codes too
> library(tidyverse)
> library(rnaturalearth)
> library(rnaturalearthdata)
> library(sf)
> world <- ne_countries(scale = "medium", returnclass = "sf")
> geo1 <- read_csv(file = "geo1.csv")
> varNumber <- geo1 %>% group_by(lat, long) %>% summarize(Number_sum = sum (Number))
> ggplot(data = world) +
>   geom_sf() +
>   xlab("Longitude") + ylab("Latitude") +
>   coord_sf(xlim = c(15, 37), ylim = c(69, 76), expand = FALSE) +
>   geom_point(data = varNumber, aes(x = long, y = lat, size = Number_sum))
>
> My task is "how many fish are sampled in each location (plotting symbol sizes by number)
> I am not sure whether what I did on my map is correct or not.
> Could you please improve the script and make those changes?
> Instead of the dots, numbers!
>


From g@br|e|@ho||m@n @end|ng |rom m@@m@edu  Tue Apr  7 16:23:29 2020
From: g@br|e|@ho||m@n @end|ng |rom m@@m@edu (Hoffman, Gabriel)
Date: Tue, 7 Apr 2020 14:23:29 +0000
Subject: [R] Basic XML function not working
Message-ID: <629AADA4-D51E-4D40-AAED-5DD03C048029@contoso.com>

I am having an issue with the XML package failing on a basic function.  This makes packages that depend on this function also fail:

> library(XML)
> newXMLNode("bob")
I/O error : flush error

I can?t find any reference to the error online

> sessionInfo()
R version 3.6.0 (2019-04-26)
Platform: x86_64-apple-darwin18.6.0 (64-bit)
Running under: macOS  10.15.3

Matrix products: default
BLAS:   /Users/gabrielhoffman/Downloads/R-3.6.0/lib/libRblas.dylib
LAPACK: /Users/gabrielhoffman/Downloads/R-3.6.0/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] XML_3.99-0.3

loaded via a namespace (and not attached):
[1] compiler_3.6.0 tools_3.6.0    tcltk_3.6.0

# The expected result is: <bob/>
# This works fine in R 3.5.1 on the same machine

> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS  10.15.3

Matrix products: default
BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] XML_3.99-0.3

loaded via a namespace (and not attached):
[1] compiler_3.5.1 tools_3.5.1

# It also fails on R development version
> sessionInfo()
R Under development (unstable) (2020-03-16 r77979)
Platform: x86_64-apple-darwin19.3.0 (64-bit)
Running under: macOS Catalina 10.15.3

Matrix products: default
BLAS:   /Users/gabrielhoffman/Downloads/R-devel/lib/libRblas.dylib
LAPACK: /Users/gabrielhoffman/Downloads/R-devel/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices datasets  utils     methods   base

other attached packages:
[1] XML_3.99-0.3

loaded via a namespace (and not attached):
[1] compiler_4.0.0


Best
- Gabriel


	[[alternative HTML version deleted]]


From e@||e@jen @end|ng |rom gm@||@com  Mon Apr  6 21:49:42 2020
From: e@||e@jen @end|ng |rom gm@||@com (Stefi Killing)
Date: Mon, 6 Apr 2020 21:49:42 +0200
Subject: [R] Fwd: Sensitivity+Uncertainty Analysis//Evaporation//Markdown
In-Reply-To: <CAJyvPA9S-JE2wy2ATS2w9TjHgqBqcExs7YSL746z=rG84DFtmg@mail.gmail.com>
References: <CAJyvPA9S-JE2wy2ATS2w9TjHgqBqcExs7YSL746z=rG84DFtmg@mail.gmail.com>
Message-ID: <CAJyvPA_Ho1k_D4VYm22z1JH-6aPmsujyAYp=cgB39s=paRh0Xw@mail.gmail.com>

Dear helpers,

my script for my* Sensitivity + Uncertainty Analysis* concerning *evaporation
processes *with the *Matt Shuttleworth-Equation* is not knitting to *markdown
*completely. There are some problems with the figures I guess. May somebody
help me?

I would be very very grateful!

Yours,
Stef

From J4T5U8 @end|ng |rom protonm@||@com  Tue Apr  7 16:22:07 2020
From: J4T5U8 @end|ng |rom protonm@||@com (J4T5U8)
Date: Tue, 07 Apr 2020 14:22:07 +0000
Subject: [R] Error using R caret package (train) with C5.0 decision tree to
 do K-fold cross validation
Message-ID: <Hcs58Tg7irCszsZa0DBHlWXZU9XChgpQymLzlOoW4HBlRhlldRTzx159aNxIpK62szbQodTYogcBcRLSNv7Uf7ds8dGkuLXMDjnZspT4MDc=@protonmail.com>

I'm trying to use the caret package to do repeated k-fold cross validation with C5.0 decision trees.

The following code generates a working C5.0 decision tree (68% accuracy on confusion matrix):

    > model <- C5.0(as.factor(OneGM) ~., data=OneT.train)
    > results <- predict(object=model, newdata=OneT.test, type="class")

The caret package code gives these errors:

    > train_control <- trainControl(method="repeatedcv", number=10, repeats=10)

    > model <- train(as.factor(OneGM) ~., data=OneT.train, trControl=train_control, method="C5.0")
    Error in na.fail.default(list(`as.factor(OneGM)` = c(1L, 1L, 1L, 1L,  : missing values in object

    > model <- train(OneGM ~., data=OneT.train, trControl=train_control, method="C5.0")
    Error in na.fail.default(list(OneGM = c(FALSE, FALSE, FALSE, FALSE,  : missing values in object

The data is loaded from a .csv file, and OneGM is either TRUE or FALSE (a text column in the .csv).

I would like to use the one-line caret package approach above (which I've seen used in multiple places), and I'm not looking for solutions that do cross validation manually.

Thanks for any help.
	[[alternative HTML version deleted]]


From jen@r@@mu@ @end|ng |rom gm@||@com  Tue Apr  7 16:56:08 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Tue, 7 Apr 2020 16:56:08 +0200
Subject: [R] Basic XML function not working
In-Reply-To: <629AADA4-D51E-4D40-AAED-5DD03C048029@contoso.com>
References: <629AADA4-D51E-4D40-AAED-5DD03C048029@contoso.com>
Message-ID: <20200407145608.GA187643@jrl.uk.to>

On 2020-04-07 14:23 +0000, Hoffman, Gabriel wrote:
| I am having an issue with the XML package 
| failing on a basic function.  This makes 
| packages that depend on this function also 
| fail:

Hi!  So XML::newXMLNode("bob") only works on 
the R 3.5.1, or r77979 as well?

So the question might be what is the 
difference between the R versions in 
Accelerate.framework compared to those in 
~/Downloads ?  Maybe the different versions 
of apple-darwin has something to do with it, 
but this remains speculation on my part ... 
quoted from your email:

| R version 3.6.0 (2019-04-26)
| Platform: x86_64-apple-darwin18.6.0 (64-bit)
| 
| R version 3.5.1 (2018-07-02)
| Platform: x86_64-apple-darwin15.6.0 (64-bit)
| 
| R Under development (unstable) (2020-03-16 r77979)
| Platform: x86_64-apple-darwin19.3.0 (64-bit)


This might not matter much, but I get the 
expected result here on 3.6.3 ...:

> XML::newXMLNode("bob")
<bob/>
> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Arch Linux

Matrix products: default
BLAS:   /usr/lib/libopenblasp-r0.3.9.so
LAPACK: /usr/lib/liblapack.so.3.9.0

locale:
 [1] LC_CTYPE=en_GB.UTF-8
 [2] LC_NUMERIC=C
 [3] LC_TIME=en_DK.UTF-8
 [4] LC_COLLATE=en_GB.UTF-8
 [5] LC_MONETARY=nb_NO.UTF-8
 [6] LC_MESSAGES=en_GB.UTF-8
 [7] LC_PAPER=nb_NO.UTF-8
 [8] LC_NAME=C
 [9] LC_ADDRESS=C
[10] LC_TELEPHONE=C
[11] LC_MEASUREMENT=nb_NO.UTF-8
[12] LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils
[5] datasets  methods   base

other attached packages:
[1] XML_3.99-0.3

loaded via a namespace (and not attached):
[1] compiler_3.6.3 tools_3.6.3
> system("uname -a")
Linux twentyfive 5.5.10-arch1-1 #1 SMP PREEMPT Wed, 18 Mar 2020 08:40:35 +0000 x86_64 GNU/Linux

Best,
Rasmus


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Apr  7 18:19:25 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 7 Apr 2020 09:19:25 -0700
Subject: [R] 
 Help needed: gdal-configuration to install sf package in Mac OS
 Catalina
In-Reply-To: <CAJ5oOKWwDiFa=y7fecW4xrCNz6AtsFeQ-by-4ke_w2qqThJ8Zg@mail.gmail.com>
References: <CAJ5oOKWwDiFa=y7fecW4xrCNz6AtsFeQ-by-4ke_w2qqThJ8Zg@mail.gmail.com>
Message-ID: <cbb1193a-5870-ec4a-3420-d3a09caf1d08@comcast.net>


On 4/5/20 9:27 PM, Bijesh Mishra wrote:
> Hi,
> I am using R in Mac. I was trying to install sf package but could not and
> got error. Detail message of error is under this email. It seems like I
> have to run gdal- configuration, but not sure what that means. Do you have
> any idea about that?


GDAL is an external system resource for spatial modeling. The advice to 
install using homebrew might not succeed if you are not skilled in 
managing Mac Unix facilities, as it appears you are not. My 
recommendation would be to first try installing GDAL from the Kingchaos 
Frameworks website: https://www.kyngchaos.com/software/frameworks/

As mentioned you have posted to the wrong mailing list and this should 
have been posted to the R-SIG-Mac list. Instructions fro subscribing can 
be found here: https://stat.ethz.ch/mailman/listinfo/r-sig-mac

-- 

David.

>
> This is the message I got while installing SF package:
>
> configure: error: gdal-config not found or not executable.
> ERROR: configuration failed for package ?sf?
> * removing
> ?/Library/Frameworks/R.framework/Versions/3.6/Resources/library/sf?
> Error: Failed to install 'sf' from GitHub:
>    (converted from warning) installation of package
> ?/var/folders/5_/74nhx31d521cjc_gjz58nh8r0000gn/T//RtmpO7v2bW/filea6321afd2c24/sf_0.9-1.tar.gz?
> had non-zero exit status
>


From ycd|ng @end|ng |rom coh@org  Tue Apr  7 20:34:37 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Tue, 7 Apr 2020 18:34:37 +0000
Subject: [R] to create a new variable based on values in other variables
Message-ID: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>

Hi R users,


I want to create a new variable, Ravg, in data frame tem2 based on values of two other variables m1 and m2.

the condition:

if m1 = 23 and m2 =23 then Ravg =23; 
else if m1 != 23 and m2=23 then Ravg =m1;
else if m1 =23 and m2 !=23 then Ravg=m2;
else Ravg=average of m1 and m2;

the Ravg variable should be  same as  m3 variable in the following small example.

my R code did not generate errors but not generate a new variable.

Ravg <- "rare_allele"
  tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))
  for (r in 1:nrow(tem2)) { 
  if (tem2$m1[r] ==23 & tem2$m2[r] ==23) {
    tem2[[Ravg]][r] ==23} else if(tem2$m1[r] ==23 & tem2$m2[r] !=23){
    tem2[[Ravg]][r] ==tem2$m2[r]} else if (tem2$m1[r] !=23 & tem2$m2[r] ==23) {
    tem2[[Ravg]][r] ==tem2$m1[r]} else {
    tem2[[Ravg]][r] == mean(tem2$m1[r] + tem2$m2[r])}
                          }

Thank you,

Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Apr  7 20:48:12 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 7 Apr 2020 20:48:12 +0200
Subject: [R] to create a new variable based on values in other variables
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>
Message-ID: <CAJuCY5xsV+GBcNQmGJSwrFCPipv90yTWxRbJf-=BRMxxQNPRSA@mail.gmail.com>

Dear Ding,

It seems that you are looking for the ifelse() function. Clear use of
pmax() and pmin() reduces the number of if statements.

m1 <- c(12, 23, 22, 23)
m2 <- c(23, 23, 3, 5)

Ravg <- ifelse(
  pmax(m1, m2) == 23,
  pmin(m1, m2),
  (m1 + m2) / 2
)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 7 apr. 2020 om 20:35 schreef Yuan Chun Ding <ycding at coh.org>:

> Hi R users,
>
>
> I want to create a new variable, Ravg, in data frame tem2 based on values
> of two other variables m1 and m2.
>
> the condition:
>
> if m1 = 23 and m2 =23 then Ravg =23;
> else if m1 != 23 and m2=23 then Ravg =m1;
> else if m1 =23 and m2 !=23 then Ravg=m2;
> else Ravg=average of m1 and m2;
>
> the Ravg variable should be  same as  m3 variable in the following small
> example.
>
> my R code did not generate errors but not generate a new variable.
>
> Ravg <- "rare_allele"
>   tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12,
> 23, 12.5, 5))
>   for (r in 1:nrow(tem2)) {
>   if (tem2$m1[r] ==23 & tem2$m2[r] ==23) {
>     tem2[[Ravg]][r] ==23} else if(tem2$m1[r] ==23 & tem2$m2[r] !=23){
>     tem2[[Ravg]][r] ==tem2$m2[r]} else if (tem2$m1[r] !=23 & tem2$m2[r]
> ==23) {
>     tem2[[Ravg]][r] ==tem2$m1[r]} else {
>     tem2[[Ravg]][r] == mean(tem2$m1[r] + tem2$m2[r])}
>                           }
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Tue Apr  7 21:05:32 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Tue, 7 Apr 2020 19:05:32 +0000
Subject: [R] to create a new variable based on values in other variables
In-Reply-To: <CAJuCY5xsV+GBcNQmGJSwrFCPipv90yTWxRbJf-=BRMxxQNPRSA@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>,
 <CAJuCY5xsV+GBcNQmGJSwrFCPipv90yTWxRbJf-=BRMxxQNPRSA@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113D8A2B@PPWEXCH2KX14.coh.org>


Hi Thierry,

the values in the example data frame are fake numbers, my original data frame has hundreds of row and values are in wide range, not min or max of two variables, also the number 23 is also different in different data frames.

I agree I need to use vectorized ifelse, but I got confused when there are more than two conditions inside of ifelse function. I will look into ifelse function

Thank you,

Ding



From: Thierry Onkelinx [thierry.onkelinx at inbo.be]

Sent: Tuesday, April 7, 2020 11:48 AM

To: Yuan Chun Ding

Cc: r-help mailing list

Subject: Re: [R] to create a new variable based on values in other variables


Dear Ding,

It seems that you are looking for the ifelse() function. Clear use of pmax() and pmin() reduces the number of if statements.

m1 <- c(12, 23, 22, 23)
m2 <- c(23, 23, 3, 5)

Ravg <- ifelse(

  pmax(m1, m2) == 23,

  pmin(m1, m2),

  (m1 + m2) / 2

)

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders

INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND FOREST

Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance 

thierry.onkelinx at inbo.be

Havenlaan 88 bus 73, 1000 Brussel

www.inbo.be




///////////////////////////////////////////////////////////////////////////////////////////

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data. ~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey

///////////////////////////////////////////////////////////////////////////////////////////






























Op di 7 apr. 2020 om 20:35 schreef Yuan Chun Ding <ycding at coh.org>:



Hi R users,





I want to create a new variable, Ravg, in data frame tem2 based on values of two other variables m1 and m2.



the condition:



if m1 = 23 and m2 =23 then Ravg =23; 

else if m1 != 23 and m2=23 then Ravg =m1;

else if m1 =23 and m2 !=23 then Ravg=m2;

else Ravg=average of m1 and m2;



the Ravg variable should be  same as  m3 variable in the following small example.



my R code did not generate errors but not generate a new variable.



Ravg <- "rare_allele"

  tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))

  for (r in 1:nrow(tem2)) { 

  if (tem2$m1[r] ==23 & tem2$m2[r] ==23) {

    tem2[[Ravg]][r] ==23} else if(tem2$m1[r] ==23 & tem2$m2[r] !=23){

    tem2[[Ravg]][r] ==tem2$m2[r]} else if (tem2$m1[r] !=23 & tem2$m2[r] ==23) {

    tem2[[Ravg]][r] ==tem2$m1[r]} else {

    tem2[[Ravg]][r] == mean(tem2$m1[r] + tem2$m2[r])}

                          }



Thank you,



Ding



----------------------------------------------------------------------

------------------------------------------------------------

-SECURITY/CONFIDENTIALITY WARNING-  



This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health
 information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge
 or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received
 the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail,
 please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.








From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  7 21:53:19 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 7 Apr 2020 12:53:19 -0700
Subject: [R] to create a new variable based on values in other variables
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbRMJc+YBH8DCqPYc8M3qKDfStFh9LiPrZxVH54+dMkxOg@mail.gmail.com>

You can use subscripting to generalize and avoid multiply nested
ifelse's which, I agree, can be a nightmare. However, you have to be
very careful about the logic of the conditions you create and the
order in which you apply them. It is very easy to wipe out an earlier
relationship with a later one (I speak from sad experience here). Note
that because the following uses subscripting, it's vectorized. But you
of course have to set up all your conditions manually. Note that your
last example condition is redundant, btw. As Thierry indicated,
depending on what you do, there can be shortcuts. To keep the solution
generalizable, I have not used any.

> tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))
> tem2$ravg <- rowMeans(tem2[,c("m1","m2")])
## or use with() or within() for more complex functions that  you have
to code yourself.
> cond1 <- with(tem2,m1!= 23 & m2 == 23)
> cond2  <- with(tem2, m1 == 23 & m2 != 23)
## etc.
> tem2 <- within(tem2,{
+       ravg[cond1] <- m1[cond1]
+       ravg[cond2] <- m2[cond2]
+    })
>
> tem2
  m1 m2   m3 ravg
1 12 23 12.0 12.0
2 23 23 23.0 23.0
3 22  3 12.5 12.5
4 23  5  5.0  5.0


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Apr 7, 2020 at 11:34 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
>
> I want to create a new variable, Ravg, in data frame tem2 based on values of two other variables m1 and m2.
>
> the condition:
>
> if m1 = 23 and m2 =23 then Ravg =23;
> else if m1 != 23 and m2=23 then Ravg =m1;
> else if m1 =23 and m2 !=23 then Ravg=m2;
> else Ravg=average of m1 and m2;
>
> the Ravg variable should be  same as  m3 variable in the following small example.
>
> my R code did not generate errors but not generate a new variable.
>
> Ravg <- "rare_allele"
>   tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))
>   for (r in 1:nrow(tem2)) {
>   if (tem2$m1[r] ==23 & tem2$m2[r] ==23) {
>     tem2[[Ravg]][r] ==23} else if(tem2$m1[r] ==23 & tem2$m2[r] !=23){
>     tem2[[Ravg]][r] ==tem2$m2[r]} else if (tem2$m1[r] !=23 & tem2$m2[r] ==23) {
>     tem2[[Ravg]][r] ==tem2$m1[r]} else {
>     tem2[[Ravg]][r] == mean(tem2$m1[r] + tem2$m2[r])}
>                           }
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h||m @end|ng |rom gm@c@com  Tue Apr  7 21:34:20 2020
From: h||m @end|ng |rom gm@c@com (Lim, Hwanggyu)
Date: Tue, 7 Apr 2020 19:34:20 +0000
Subject: [R] Question about nlminb function
In-Reply-To: <20200403122456.6e2073ea@Tarkus>
References: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>
 <20200403122456.6e2073ea@Tarkus>
Message-ID: <BL0PR05MB47888DA69B0E861504B61B8DBDC30@BL0PR05MB4788.namprd05.prod.outlook.com>

Hello Ivan,

Thank you so much for your valuable comments. I will definitely look at the R package of nloptr you introduced.

Best,
Hwanggyu



-----Original Message-----
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: Friday, April 3, 2020 5:25 AM
To: Lim, Hwanggyu <hlim at gmac.com>
Cc: r-help at r-project.org
Subject: Re: [R] Question about nlminb function

On Thu, 2 Apr 2020 10:26:07 +0000
"Lim, Hwanggyu" <hlim at gmac.com> wrote:

> when n-1th estimates and nth estimates have absolute differences less
> than 0.001 for all three parameters, the iteration must stop

> I am using nlminb optimization function

nlminb function uses the PORT library. According to [1], the closest thing PORT has to what you want is the notion of X-convergence, namely, stopping when max(scale * abs(x - xstar))/max(scale * abs(x + xstar)) is considered to be below control$x.tol (with xstar being supposed local minimiser and scale being all ones by default). Using it as an absolute stopping criterion in x requires knowledge of at least order of magnitude of xstar, though, so it might not be feasible.

Note that ?nlminb says in the description that it is there "for historical compatibility."

The nloptr package offers an xtol_abs option [2] that results in the behaviour you want.

--
Best regards,
Ivan

[1] David M. Gay, Usage Summary for Selected Optimization Routines.
<http://web.archive.org/web/20070508140716/http://netlib.bell-labs.com/cm/cs/cstr/153.pdf>

[2]
https://nlopt.readthedocs.io/en/latest/NLopt_Reference/#stopping-criteria
The information in this transmission is confidential and intended only for the recipient listed above. If you are not the intended recipient, please advise the sender immediately by reply e-mail and delete this message and any attachments without retaining a copy. If you are not the intended recipient, you are hereby notified that any disclosure, copying or distribution of this message, or the taking of any action based upon it, is strictly prohibited.


From h||m @end|ng |rom gm@c@com  Tue Apr  7 21:38:44 2020
From: h||m @end|ng |rom gm@c@com (Lim, Hwanggyu)
Date: Tue, 7 Apr 2020 19:38:44 +0000
Subject: [R] Question about nlminb function
In-Reply-To: <a3f6f60e-bf7f-2863-fe39-6de1a20f0a3d@gmail.com>
References: <BL0PR05MB4788929E27A04D79A97FB7EFBDC60@BL0PR05MB4788.namprd05.prod.outlook.com>
 <20200403122456.6e2073ea@Tarkus>
 <a3f6f60e-bf7f-2863-fe39-6de1a20f0a3d@gmail.com>
Message-ID: <BL0PR05MB4788F5C855CAFB9B5EC15CEEBDC30@BL0PR05MB4788.namprd05.prod.outlook.com>

Hello John,

Thank you so much for your valuable response. I think using several new optimization function (e.g., Rvmmin) would be a good option for me. I will dive into those function. Thank you again!

Best,
Hwanggyu

-----Original Message-----
From: J C Nash <profjcnash at gmail.com>
Sent: Friday, April 3, 2020 9:49 AM
To: Ivan Krylov <krylov.r00t at gmail.com>; Lim, Hwanggyu <hlim at gmac.com>
Cc: r-help at r-project.org
Subject: Re: [R] Question about nlminb function

This thread points out the important and often overlooked difference between "convergence" of an algorithm and "termination"
of a program. I've been pushing this button for over 30 years, and I suspect that it will continue to come up from time to time.

Sometimes it is helpful to put termination criteria actually into the user function. Alternatively try a different optimizer. The optimx package wraps several, including a few for bounds constrained optimization.
Note that a new version will go up once revdeps have been checked. Dylan Beijers noted a minor glitch if users want to "maximize".

If the termination criteria are really critical, some of the methods now merged into optimx (Rvmmin, Rcgmin, Rtnmin) are all in R. I won't pretend that diving in and making changes is easy, though I've tried to move the code more and more to maintainability and transparency. If anyone is interested in pursuing that sort of thing, I'll be willing to advise or help as long as the requests aren't too strident.

For information, while all-R programs used to be much slower than those in Fortran or C or C++, users should time their problems rather than just assume a great penalty for running things completely in R. The human time saving is generally more important.

Best, John Nash


On 2020-04-03 5:24 a.m., Ivan Krylov wrote:
> On Thu, 2 Apr 2020 10:26:07 +0000
> "Lim, Hwanggyu" <hlim at gmac.com> wrote:
>
>> when n-1th estimates and nth estimates have absolute differences less
>> than 0.001 for all three parameters, the iteration must stop
>
>> I am using nlminb optimization function
>
> nlminb function uses the PORT library. According to [1], the closest
> thing PORT has to what you want is the notion of X-convergence,
> namely, stopping when max(scale * abs(x - xstar))/max(scale * abs(x +
> xstar)) is considered to be below control$x.tol (with xstar being
> supposed local minimiser and scale being all ones by default). Using
> it as an absolute stopping criterion in x requires knowledge of at
> least order of magnitude of xstar, though, so it might not be feasible.
>
> Note that ?nlminb says in the description that it is there "for
> historical compatibility."
>
> The nloptr package offers an xtol_abs option [2] that results in the
> behaviour you want.
>
The information in this transmission is confidential and intended only for the recipient listed above. If you are not the intended recipient, please advise the sender immediately by reply e-mail and delete this message and any attachments without retaining a copy. If you are not the intended recipient, you are hereby notified that any disclosure, copying or distribution of this message, or the taking of any action based upon it, is strictly prohibited.

From ycd|ng @end|ng |rom coh@org  Wed Apr  8 02:04:45 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Wed, 8 Apr 2020 00:04:45 +0000
Subject: [R] to create a new variable based on values in other variables
In-Reply-To: <CAGxFJbRMJc+YBH8DCqPYc8M3qKDfStFh9LiPrZxVH54+dMkxOg@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113D89DD@PPWEXCH2KX14.coh.org>,
 <CAGxFJbRMJc+YBH8DCqPYc8M3qKDfStFh9LiPrZxVH54+dMkxOg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113D8A9C@PPWEXCH2KX14.coh.org>

Hi Bert,

your code worked perfect.  you always make me learn new R code skills!

Thank you so much!!

Ding
________________________________________
From: Bert Gunter [bgunter.4567 at gmail.com]
Sent: Tuesday, April 7, 2020 12:53 PM
To: Yuan Chun Ding
Cc: r-help mailing list
Subject: Re: [R] to create a new variable based on values in other variables

You can use subscripting to generalize and avoid multiply nested
ifelse's which, I agree, can be a nightmare. However, you have to be
very careful about the logic of the conditions you create and the
order in which you apply them. It is very easy to wipe out an earlier
relationship with a later one (I speak from sad experience here). Note
that because the following uses subscripting, it's vectorized. But you
of course have to set up all your conditions manually. Note that your
last example condition is redundant, btw. As Thierry indicated,
depending on what you do, there can be shortcuts. To keep the solution
generalizable, I have not used any.

> tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))
> tem2$ravg <- rowMeans(tem2[,c("m1","m2")])
## or use with() or within() for more complex functions that  you have
to code yourself.
> cond1 <- with(tem2,m1!= 23 & m2 == 23)
> cond2  <- with(tem2, m1 == 23 & m2 != 23)
## etc.
> tem2 <- within(tem2,{
+       ravg[cond1] <- m1[cond1]
+       ravg[cond2] <- m2[cond2]
+    })
>
> tem2
  m1 m2   m3 ravg
1 12 23 12.0 12.0
2 23 23 23.0 23.0
3 22  3 12.5 12.5
4 23  5  5.0  5.0


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Apr 7, 2020 at 11:34 AM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R users,
>
>
> I want to create a new variable, Ravg, in data frame tem2 based on values of two other variables m1 and m2.
>
> the condition:
>
> if m1 = 23 and m2 =23 then Ravg =23;
> else if m1 != 23 and m2=23 then Ravg =m1;
> else if m1 =23 and m2 !=23 then Ravg=m2;
> else Ravg=average of m1 and m2;
>
> the Ravg variable should be  same as  m3 variable in the following small example.
>
> my R code did not generate errors but not generate a new variable.
>
> Ravg <- "rare_allele"
>   tem2 <-data.frame(m1=c(12, 23, 22, 23), m2=c(23, 23, 3, 5), m3 =c(12, 23, 12.5, 5))
>   for (r in 1:nrow(tem2)) {
>   if (tem2$m1[r] ==23 & tem2$m2[r] ==23) {
>     tem2[[Ravg]][r] ==23} else if(tem2$m1[r] ==23 & tem2$m2[r] !=23){
>     tem2[[Ravg]][r] ==tem2$m2[r]} else if (tem2$m1[r] !=23 & tem2$m2[r] ==23) {
>     tem2[[Ravg]][r] ==tem2$m1[r]} else {
>     tem2[[Ravg]][r] == mean(tem2$m1[r] + tem2$m2[r])}
>                           }
>
> Thank you,
>
> Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!5Ho4zb8Yy0d9gaWdgkNkC1NGMpUUY6kjUlH-XhJmj9UzTaeukRr5IuBRIePx$
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!5Ho4zb8Yy0d9gaWdgkNkC1NGMpUUY6kjUlH-XhJmj9UzTaeukRr5Io0-e-EB$
> and provide commented, minimal, self-contained, reproducible code.


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Wed Apr  8 07:19:38 2020
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Wed, 8 Apr 2020 17:19:38 +1200
Subject: [R] TWITTER API environment variables
Message-ID: <20200408051938.GA4690@slingshot.co.nz>

I'm using the rtweet package which makes use of the Twitter API which
requires a token alluded to by an environment variable.

That environment variable is automatically set up from the Twitter web
site and takes the name TWITTER_<username> (where <username> is the
name of the user in block letters).  That worked fine on my work
computer where my username is 'work'.  When I copied that working
directory to my home computer, the environment variable became
TWITTER_HOME but the rtweet package was looking for
TWITTER_WORK. There was no error message: just a null result from the
search_users() function.

I tried editing the ~/.Renviron entry to
TWITTER_WORK=/home/home/.rtweet_token.rds

That worked for a short time but soon ceased working.  Then I noticed
a new entry had been automatically added to ~/.Renviron

TWITTER_HOME=/home/home/.rtweet_token1.rds

So now I had two environment variables which also worked for a short
time.

Recommendations please.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From m@||||@t@ @end|ng |rom pp@|net@||  Wed Apr  8 07:55:31 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Wed, 08 Apr 2020 08:55:31 +0300
Subject: [R] TWITTER API environment variables
In-Reply-To: <20200408051938.GA4690@slingshot.co.nz>
References: <20200408051938.GA4690@slingshot.co.nz>
Message-ID: <130bd81aa540ab1f8a9715f9cd5190c7642050c7.camel@pp.inet.fi>

Hi!

Have you already read this:

https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html

I think they explain rather well how to use Twitter tokens with
rtweet...

HTH,
Kimmo

ke, 2020-04-08 kello 17:19 +1200, Patrick Connolly kirjoitti:
> I'm using the rtweet package which makes use of the Twitter API which
> requires a token alluded to by an environment variable.
> 
> That environment variable is automatically set up from the Twitter
> web
> site and takes the name TWITTER_<username> (where <username> is the
> name of the user in block letters).  That worked fine on my work
> computer where my username is 'work'.  When I copied that working
> directory to my home computer, the environment variable became
> TWITTER_HOME but the rtweet package was looking for
> TWITTER_WORK. There was no error message: just a null result from the
> search_users() function.
> 
> I tried editing the ~/.Renviron entry to
> TWITTER_WORK=/home/home/.rtweet_token.rds
> 
> That worked for a short time but soon ceased working.  Then I noticed
> a new entry had been automatically added to ~/.Renviron
> 
> TWITTER_HOME=/home/home/.rtweet_token1.rds
> 
> So now I had two environment variables which also worked for a short
> time.
> 
> Recommendations please.
>


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Wed Apr  8 09:02:06 2020
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Wed, 8 Apr 2020 19:02:06 +1200
Subject: [R] TWITTER API environment variables
In-Reply-To: <130bd81aa540ab1f8a9715f9cd5190c7642050c7.camel@pp.inet.fi>
References: <20200408051938.GA4690@slingshot.co.nz>
 <130bd81aa540ab1f8a9715f9cd5190c7642050c7.camel@pp.inet.fi>
Message-ID: <20200408070206.GB4690@slingshot.co.nz>

Hello Kimmo,

Yes.  I did that and it worked fine -- as far as it goes.  But it
didn't cover what to do when using the same twitter account on a
computer with a different user name -- which is what my question was
about.


On Wed, 08-Apr-2020 at 08:55AM +0300, K. Elo wrote:

|> Hi!
|> 
|> Have you already read this:
|> 
|> https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html
|> 
|> I think they explain rather well how to use Twitter tokens with
|> rtweet...
|> 
|> HTH,
|> Kimmo
|> 
|> ke, 2020-04-08 kello 17:19 +1200, Patrick Connolly kirjoitti:
|> > I'm using the rtweet package which makes use of the Twitter API which
|> > requires a token alluded to by an environment variable.
|> > 
|> > That environment variable is automatically set up from the Twitter
|> > web
|> > site and takes the name TWITTER_<username> (where <username> is the
|> > name of the user in block letters).  That worked fine on my work
|> > computer where my username is 'work'.  When I copied that working
|> > directory to my home computer, the environment variable became
|> > TWITTER_HOME but the rtweet package was looking for
|> > TWITTER_WORK. There was no error message: just a null result from the
|> > search_users() function.
|> > 
|> > I tried editing the ~/.Renviron entry to
|> > TWITTER_WORK=/home/home/.rtweet_token.rds
|> > 
|> > That worked for a short time but soon ceased working.  Then I noticed
|> > a new entry had been automatically added to ~/.Renviron
|> > 
|> > TWITTER_HOME=/home/home/.rtweet_token1.rds
|> > 
|> > So now I had two environment variables which also worked for a short
|> > time.
|> > 
|> > Recommendations please.
|> >
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Apr  8 09:31:44 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 8 Apr 2020 09:31:44 +0200
Subject: [R] R Markdown & chunk extraction in R
Message-ID: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>

Hi,

exists a possibility to extract chunks from a R Markdown file and to 
return them as (named) list in R?

Thanks Sigbert

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Apr  8 09:43:24 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 8 Apr 2020 13:13:24 +0530
Subject: [R] R Markdown & chunk extraction in R
In-Reply-To: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
References: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
Message-ID: <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>

Dear Sigbert,

Please see this.

https://bookdown.org/yihui/rmarkdown-cookbook/purl.html

Best,
Ashim

On Wed, Apr 8, 2020 at 1:02 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
wrote:

> Hi,
>
> exists a possibility to extract chunks from a R Markdown file and to
> return them as (named) list in R?
>
> Thanks Sigbert
>
> --
> https://hu.berlin/sk
> https://hu.berlin/mmstat3
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Apr  8 09:53:04 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 8 Apr 2020 13:23:04 +0530
Subject: [R] R Markdown & chunk extraction in R
In-Reply-To: <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>
References: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
 <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>
Message-ID: <CAC8=1er471jZx_aGkSSA8Q6fMu7f28mew-Srx1GBC_2FsUN+ng@mail.gmail.com>

Dear Sigbert,

Also see this :-

https://www.rdocumentation.org/packages/knitr/versions/1.28/topics/knit_code

Best,
Ashim

On Wed, Apr 8, 2020 at 1:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Sigbert,
>
> Please see this.
>
> https://bookdown.org/yihui/rmarkdown-cookbook/purl.html
>
> Best,
> Ashim
>
> On Wed, Apr 8, 2020 at 1:02 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
> wrote:
>
>> Hi,
>>
>> exists a possibility to extract chunks from a R Markdown file and to
>> return them as (named) list in R?
>>
>> Thanks Sigbert
>>
>> --
>> https://hu.berlin/sk
>> https://hu.berlin/mmstat3
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@||||@t@ @end|ng |rom pp@|net@||  Wed Apr  8 11:32:04 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (K. Elo)
Date: Wed, 08 Apr 2020 12:32:04 +0300
Subject: [R] TWITTER API environment variables
In-Reply-To: <20200408070206.GB4690@slingshot.co.nz>
References: <20200408051938.GA4690@slingshot.co.nz>
 <130bd81aa540ab1f8a9715f9cd5190c7642050c7.camel@pp.inet.fi>
 <20200408070206.GB4690@slingshot.co.nz>
Message-ID: <24de83f433d028f764716b6140f33ab3a3ff7918.camel@pp.inet.fi>

Hi again,

ok, I see. How about repeating the steps described in the tutorial on
your second computer instead of cloning the settings from the computer
#1? There might be some other settings not correctly copied.

HTH,
Kimmo

ke, 2020-04-08 kello 19:02 +1200, Patrick Connolly kirjoitti:
> Hello Kimmo,
> 
> Yes.  I did that and it worked fine -- as far as it goes.  But it
> didn't cover what to do when using the same twitter account on a
> computer with a different user name -- which is what my question was
> about.
> 
> 
> On Wed, 08-Apr-2020 at 08:55AM +0300, K. Elo wrote:
> 
> > > Hi!
> > > 
> > > Have you already read this:
> > > 
> > > 
https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html
> > > 
> > > I think they explain rather well how to use Twitter tokens with
> > > rtweet...
> > > 
> > > HTH,
> > > Kimmo
> > > 
> > > ke, 2020-04-08 kello 17:19 +1200, Patrick Connolly kirjoitti:
> > > > I'm using the rtweet package which makes use of the Twitter API
> > > > which
> > > > requires a token alluded to by an environment variable.
> > > > 
> > > > That environment variable is automatically set up from the
> > > > Twitter
> > > > web
> > > > site and takes the name TWITTER_<username> (where <username> is
> > > > the
> > > > name of the user in block letters).  That worked fine on my
> > > > work
> > > > computer where my username is 'work'.  When I copied that
> > > > working
> > > > directory to my home computer, the environment variable became
> > > > TWITTER_HOME but the rtweet package was looking for
> > > > TWITTER_WORK. There was no error message: just a null result
> > > > from the
> > > > search_users() function.
> > > > 
> > > > I tried editing the ~/.Renviron entry to
> > > > TWITTER_WORK=/home/home/.rtweet_token.rds
> > > > 
> > > > That worked for a short time but soon ceased working.  Then I
> > > > noticed
> > > > a new entry had been automatically added to ~/.Renviron
> > > > 
> > > > TWITTER_HOME=/home/home/.rtweet_token1.rds
> > > > 
> > > > So now I had two environment variables which also worked for a
> > > > short
> > > > time.
> > > > 
> > > > Recommendations please.
> > > > 
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible
> > > code.
> 
>


From x|e @end|ng |rom y|hu|@n@me  Wed Apr  8 17:17:25 2020
From: x|e @end|ng |rom y|hu|@n@me (Yihui Xie)
Date: Wed, 8 Apr 2020 10:17:25 -0500
Subject: [R] R Markdown & chunk extraction in R
In-Reply-To: <CAC8=1er471jZx_aGkSSA8Q6fMu7f28mew-Srx1GBC_2FsUN+ng@mail.gmail.com>
References: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
 <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>
 <CAC8=1er471jZx_aGkSSA8Q6fMu7f28mew-Srx1GBC_2FsUN+ng@mail.gmail.com>
Message-ID: <CANROs4d9zvdQqEryv5+9Py+ar5LikptsNhxH-i-5EHcT1T6XJA@mail.gmail.com>

And please note that knitr::knit_code$get() only works (i.e. returns a
named list of code chunks) inside a knitr document when the document
_is being knitted_. It doesn't work outside the document. Ideally, you
should use the document parser of knitr, but it is not exported.

Regards,
Yihui
--
https://yihui.org

On Wed, Apr 8, 2020 at 2:54 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Sigbert,
>
> Also see this :-
>
> https://www.rdocumentation.org/packages/knitr/versions/1.28/topics/knit_code
>
> Best,
> Ashim
>
> On Wed, Apr 8, 2020 at 1:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> > Dear Sigbert,
> >
> > Please see this.
> >
> > https://bookdown.org/yihui/rmarkdown-cookbook/purl.html
> >
> > Best,
> > Ashim
> >
> > On Wed, Apr 8, 2020 at 1:02 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
> > wrote:
> >
> >> Hi,
> >>
> >> exists a possibility to extract chunks from a R Markdown file and to
> >> return them as (named) list in R?
> >>
> >> Thanks Sigbert
> >>
> >> --
> >> https://hu.berlin/sk
> >> https://hu.berlin/mmstat3
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@h|mk@poor @end|ng |rom gm@||@com  Wed Apr  8 17:24:17 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Wed, 8 Apr 2020 20:54:17 +0530
Subject: [R] R Markdown & chunk extraction in R
In-Reply-To: <CANROs4d9zvdQqEryv5+9Py+ar5LikptsNhxH-i-5EHcT1T6XJA@mail.gmail.com>
References: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
 <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>
 <CAC8=1er471jZx_aGkSSA8Q6fMu7f28mew-Srx1GBC_2FsUN+ng@mail.gmail.com>
 <CANROs4d9zvdQqEryv5+9Py+ar5LikptsNhxH-i-5EHcT1T6XJA@mail.gmail.com>
Message-ID: <CAC8=1epN-FssVEmuFK9aLVMaz5-Xn+ksT+rVUKW4nHkT3UiP6A@mail.gmail.com>

Dear Yihui,

Can we not 1st use read_chunk to import an Rmd and then do knit_code()$get
? I could be mistaken. Please correct me if I am wrong.

Best,
Ashim

On Wed, Apr 8, 2020 at 8:47 PM Yihui Xie <xie at yihui.name> wrote:

> And please note that knitr::knit_code$get() only works (i.e. returns a
> named list of code chunks) inside a knitr document when the document
> _is being knitted_. It doesn't work outside the document. Ideally, you
> should use the document parser of knitr, but it is not exported.
>
> Regards,
> Yihui
> --
> https://yihui.org
>
> On Wed, Apr 8, 2020 at 2:54 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >
> > Dear Sigbert,
> >
> > Also see this :-
> >
> >
> https://www.rdocumentation.org/packages/knitr/versions/1.28/topics/knit_code
> >
> > Best,
> > Ashim
> >
> > On Wed, Apr 8, 2020 at 1:13 PM Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> >
> > > Dear Sigbert,
> > >
> > > Please see this.
> > >
> > > https://bookdown.org/yihui/rmarkdown-cookbook/purl.html
> > >
> > > Best,
> > > Ashim
> > >
> > > On Wed, Apr 8, 2020 at 1:02 PM Sigbert Klinke <
> sigbert at wiwi.hu-berlin.de>
> > > wrote:
> > >
> > >> Hi,
> > >>
> > >> exists a possibility to extract chunks from a R Markdown file and to
> > >> return them as (named) list in R?
> > >>
> > >> Thanks Sigbert
> > >>
> > >> --
> > >> https://hu.berlin/sk
> > >> https://hu.berlin/mmstat3
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jeremyc|@rkb|o @end|ng |rom gm@||@com  Wed Apr  8 18:22:28 2020
From: jeremyc|@rkb|o @end|ng |rom gm@||@com (A Biologist)
Date: Wed, 8 Apr 2020 18:22:28 +0200
Subject: [R] R create .docx file ?
Message-ID: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>

Dear All,

Mac Catalina - R 3.6.3 - all up-to-date packages.
I would like to re-create the functionality which was found in the package
{ReporteRs} by creating a .docx file in a folder on my computer from within
R - which can subsequently be used by the {officer} function read_docx.
The function read_docx on my system does NOT create a new document, and
neither does the following code:
new.word.doc=function(){ report = read_docx(path ..name.. ".docx"))
return(report) }
doc=new.word.doc()

I can use {base} file.create to create a file with an extension .docx - but
apparently this is not a .docx file - and read_docx can't read it.
Is there another R package or function which I can use in order to create
(and then close the link to R so that it can be used by another package) a
.docx file ?

Many thanks in advance.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr  8 18:31:41 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Apr 2020 09:31:41 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
Message-ID: <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>

This sounds like the sort of specialized question that should be directed
to the maintainer (?maintainer) rather than to a general Help list such as
this.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 8, 2020 at 9:23 AM A Biologist <jeremyclarkbio at gmail.com> wrote:

> Dear All,
>
> Mac Catalina - R 3.6.3 - all up-to-date packages.
> I would like to re-create the functionality which was found in the package
> {ReporteRs} by creating a .docx file in a folder on my computer from within
> R - which can subsequently be used by the {officer} function read_docx.
> The function read_docx on my system does NOT create a new document, and
> neither does the following code:
> new.word.doc=function(){ report = read_docx(path ..name.. ".docx"))
> return(report) }
> doc=new.word.doc()
>
> I can use {base} file.create to create a file with an extension .docx - but
> apparently this is not a .docx file - and read_docx can't read it.
> Is there another R package or function which I can use in order to create
> (and then close the link to R so that it can be used by another package) a
> .docx file ?
>
> Many thanks in advance.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr  8 18:56:04 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Apr 2020 09:56:04 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
 <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
Message-ID: <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>

But before hassling the maintainer the OP should read the package vignettes and run some examples... read_docx does not write to any files, so complaining that it doesn't will be fruitless. 

On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>This sounds like the sort of specialized question that should be
>directed
>to the maintainer (?maintainer) rather than to a general Help list such
>as
>this.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Wed, Apr 8, 2020 at 9:23 AM A Biologist <jeremyclarkbio at gmail.com>
>wrote:
>
>> Dear All,
>>
>> Mac Catalina - R 3.6.3 - all up-to-date packages.
>> I would like to re-create the functionality which was found in the
>package
>> {ReporteRs} by creating a .docx file in a folder on my computer from
>within
>> R - which can subsequently be used by the {officer} function
>read_docx.
>> The function read_docx on my system does NOT create a new document,
>and
>> neither does the following code:
>> new.word.doc=function(){ report = read_docx(path ..name.. ".docx"))
>> return(report) }
>> doc=new.word.doc()
>>
>> I can use {base} file.create to create a file with an extension .docx
>- but
>> apparently this is not a .docx file - and read_docx can't read it.
>> Is there another R package or function which I can use in order to
>create
>> (and then close the link to R so that it can be used by another
>package) a
>> .docx file ?
>>
>> Many thanks in advance.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr  8 19:08:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Apr 2020 10:08:09 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
 <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
 <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>
Message-ID: <CAGxFJbRvzg=nKyDThGeSasJNznA5dgN9D8SOw8uQr7zTdD+EoA@mail.gmail.com>

But the OP explicitly notes that the read_docx package does *not* write
files and asks whether there are *other* packages or functions that provide
that functionality. It still seems to me that the ReporteR maintainer might
be the best place to go for that info, although there is certainly no
assurance that he can provide it.

Bert

On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> But before hassling the maintainer the OP should read the package
> vignettes and run some examples... read_docx does not write to any files,
> so complaining that it doesn't will be fruitless.
>
> On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >This sounds like the sort of specialized question that should be
> >directed
> >to the maintainer (?maintainer) rather than to a general Help list such
> >as
> >this.
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist <jeremyclarkbio at gmail.com>
> >wrote:
> >
> >> Dear All,
> >>
> >> Mac Catalina - R 3.6.3 - all up-to-date packages.
> >> I would like to re-create the functionality which was found in the
> >package
> >> {ReporteRs} by creating a .docx file in a folder on my computer from
> >within
> >> R - which can subsequently be used by the {officer} function
> >read_docx.
> >> The function read_docx on my system does NOT create a new document,
> >and
> >> neither does the following code:
> >> new.word.doc=function(){ report = read_docx(path ..name.. ".docx"))
> >> return(report) }
> >> doc=new.word.doc()
> >>
> >> I can use {base} file.create to create a file with an extension .docx
> >- but
> >> apparently this is not a .docx file - and read_docx can't read it.
> >> Is there another R package or function which I can use in order to
> >create
> >> (and then close the link to R so that it can be used by another
> >package) a
> >> .docx file ?
> >>
> >> Many thanks in advance.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr  8 19:21:49 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Apr 2020 10:21:49 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <CAGxFJbRvzg=nKyDThGeSasJNznA5dgN9D8SOw8uQr7zTdD+EoA@mail.gmail.com>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
 <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
 <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>
 <CAGxFJbRvzg=nKyDThGeSasJNznA5dgN9D8SOw8uQr7zTdD+EoA@mail.gmail.com>
Message-ID: <E2A1D3A9-5818-434F-BA93-38A95B815D35@dcn.davis.ca.us>

The OP clearly hasn't followed the excellent documentation... this is not a maintainer problem. It is the act of printing the completed object that puts a file on disk.

However, the package author recommends in the README that help be requested from stackoverflow, as the mailing list Posting Guidelines do warn that contributed packages are not technically on topic in R-help. (Simply from a practicality standpoint... there are thousands of them, each with potentially voluminous details to distract from the R language itself.)

On April 8, 2020 10:08:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>But the OP explicitly notes that the read_docx package does *not* write
>files and asks whether there are *other* packages or functions that
>provide
>that functionality. It still seems to me that the ReporteR maintainer
>might
>be the best place to go for that info, although there is certainly no
>assurance that he can provide it.
>
>Bert
>
>On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> But before hassling the maintainer the OP should read the package
>> vignettes and run some examples... read_docx does not write to any
>files,
>> so complaining that it doesn't will be fruitless.
>>
>> On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> >This sounds like the sort of specialized question that should be
>> >directed
>> >to the maintainer (?maintainer) rather than to a general Help list
>such
>> >as
>> >this.
>> >
>> >Bert Gunter
>> >
>> >"The trouble with having an open mind is that people keep coming
>along
>> >and
>> >sticking things into it."
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist
><jeremyclarkbio at gmail.com>
>> >wrote:
>> >
>> >> Dear All,
>> >>
>> >> Mac Catalina - R 3.6.3 - all up-to-date packages.
>> >> I would like to re-create the functionality which was found in the
>> >package
>> >> {ReporteRs} by creating a .docx file in a folder on my computer
>from
>> >within
>> >> R - which can subsequently be used by the {officer} function
>> >read_docx.
>> >> The function read_docx on my system does NOT create a new
>document,
>> >and
>> >> neither does the following code:
>> >> new.word.doc=function(){ report = read_docx(path ..name..
>".docx"))
>> >> return(report) }
>> >> doc=new.word.doc()
>> >>
>> >> I can use {base} file.create to create a file with an extension
>.docx
>> >- but
>> >> apparently this is not a .docx file - and read_docx can't read it.
>> >> Is there another R package or function which I can use in order to
>> >create
>> >> (and then close the link to R so that it can be used by another
>> >package) a
>> >> .docx file ?
>> >>
>> >> Many thanks in advance.
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From x|e @end|ng |rom y|hu|@n@me  Wed Apr  8 21:45:42 2020
From: x|e @end|ng |rom y|hu|@n@me (Yihui Xie)
Date: Wed, 8 Apr 2020 14:45:42 -0500
Subject: [R] R Markdown & chunk extraction in R
In-Reply-To: <CAC8=1epN-FssVEmuFK9aLVMaz5-Xn+ksT+rVUKW4nHkT3UiP6A@mail.gmail.com>
References: <5f56fff0-c4a2-1e55-0d39-583cc8b0a5b8@wiwi.hu-berlin.de>
 <CAC8=1eo4W408mSh6jmOMaZv_S+y3SteWF3wmT3Q3FrHcAeie6w@mail.gmail.com>
 <CAC8=1er471jZx_aGkSSA8Q6fMu7f28mew-Srx1GBC_2FsUN+ng@mail.gmail.com>
 <CANROs4d9zvdQqEryv5+9Py+ar5LikptsNhxH-i-5EHcT1T6XJA@mail.gmail.com>
 <CAC8=1epN-FssVEmuFK9aLVMaz5-Xn+ksT+rVUKW4nHkT3UiP6A@mail.gmail.com>
Message-ID: <CANROs4coPgpXjmxYn=0kYqLE4oqsz_NioN_4TXqT962cwR+T7w@mail.gmail.com>

Hi Ashim,

read_chunk() can only read R scripts.

Regards,
Yihui
--
https://yihui.org

On Wed, Apr 8, 2020 at 10:24 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
> Dear Yihui,
>
> Can we not 1st use read_chunk to import an Rmd and then do knit_code()$get ? I could be mistaken. Please correct me if I am wrong.
>
> Best,
> Ashim
>
> On Wed, Apr 8, 2020 at 8:47 PM Yihui Xie <xie at yihui.name> wrote:
>>
>> And please note that knitr::knit_code$get() only works (i.e. returns a
>> named list of code chunks) inside a knitr document when the document
>> _is being knitted_. It doesn't work outside the document. Ideally, you
>> should use the document parser of knitr, but it is not exported.
>>
>> Regards,
>> Yihui
>> --
>> https://yihui.org
>>
>> On Wed, Apr 8, 2020 at 2:54 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>> >
>> > Dear Sigbert,
>> >
>> > Also see this :-
>> >
>> > https://www.rdocumentation.org/packages/knitr/versions/1.28/topics/knit_code
>> >
>> > Best,
>> > Ashim
>> >
>> > On Wed, Apr 8, 2020 at 1:13 PM Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>> >
>> > > Dear Sigbert,
>> > >
>> > > Please see this.
>> > >
>> > > https://bookdown.org/yihui/rmarkdown-cookbook/purl.html
>> > >
>> > > Best,
>> > > Ashim
>> > >
>> > > On Wed, Apr 8, 2020 at 1:02 PM Sigbert Klinke <sigbert at wiwi.hu-berlin.de>
>> > > wrote:
>> > >
>> > >> Hi,
>> > >>
>> > >> exists a possibility to extract chunks from a R Markdown file and to
>> > >> return them as (named) list in R?
>> > >>
>> > >> Thanks Sigbert
>> > >>
>> > >> --
>> > >> https://hu.berlin/sk
>> > >> https://hu.berlin/mmstat3
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >>
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Apr  8 22:17:38 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 8 Apr 2020 15:17:38 -0500
Subject: [R] how to create a new column with conditions
Message-ID: <CAF9-5jN6E7=Qqsh+z0Y_4TQnOF-fxQB1B+XtPbnUsSEX0rtOrQ@mail.gmail.com>

Hi,

I have a data frame like this:

> head(a)
            FID LASER2 CURRELIG PLASER RTNPTHY
1 fam1000_G1000      1        1      1       1
2 fam1001_G1001      1        1      1       1
3 fam1003_G1003      2        1      2       2
4 fam1005_G1005      1        1      1       2
5 fam1009_G1009      1        1      1       2
6 fam1052_G1052      1        1      1       2
...

I would like to create a new column called PHENO which would satisfy these
conditions:

if CURRELIG=1 and RTNPTHY=1 than PHENO=1
if PLASER=2 than PHENO=2
otherwise is -9

Thanks
Ana

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr  8 22:31:45 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Apr 2020 13:31:45 -0700
Subject: [R] how to create a new column with conditions
In-Reply-To: <CAF9-5jN6E7=Qqsh+z0Y_4TQnOF-fxQB1B+XtPbnUsSEX0rtOrQ@mail.gmail.com>
References: <CAF9-5jN6E7=Qqsh+z0Y_4TQnOF-fxQB1B+XtPbnUsSEX0rtOrQ@mail.gmail.com>
Message-ID: <43733584-5519-4DFD-AADB-8DBF11595B45@dcn.davis.ca.us>

Now that you have been shown how to do this, post your (non-working) code next time. And configure your email program to send plain text so we will see what you saw.

a$PHENO <- ifelse( a$CURRELIG==1
                 & a$RTNPTHY==1
                 , 1
                 ,  ifelse( a$PLASER==2
                          , 2
                          , -9 ) )

or

a$PHENO <- with( a
               , ifelse( CURRELIG==1
                       & RTNPTHY==1
                       , 1
                       , ifelse( PLASER==2
                               , 2
                               , -9 ) ) )


On April 8, 2020 1:17:38 PM PDT, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hi,
>
>I have a data frame like this:
>
>> head(a)
>            FID LASER2 CURRELIG PLASER RTNPTHY
>1 fam1000_G1000      1        1      1       1
>2 fam1001_G1001      1        1      1       1
>3 fam1003_G1003      2        1      2       2
>4 fam1005_G1005      1        1      1       2
>5 fam1009_G1009      1        1      1       2
>6 fam1052_G1052      1        1      1       2
>...
>
>I would like to create a new column called PHENO which would satisfy
>these
>conditions:
>
>if CURRELIG=1 and RTNPTHY=1 than PHENO=1
>if PLASER=2 than PHENO=2
>otherwise is -9
>
>Thanks
>Ana
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Wed Apr  8 23:06:35 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 8 Apr 2020 14:06:35 -0700
Subject: [R] how to create a new column with conditions
In-Reply-To: <43733584-5519-4DFD-AADB-8DBF11595B45@dcn.davis.ca.us>
References: <CAF9-5jN6E7=Qqsh+z0Y_4TQnOF-fxQB1B+XtPbnUsSEX0rtOrQ@mail.gmail.com>
 <43733584-5519-4DFD-AADB-8DBF11595B45@dcn.davis.ca.us>
Message-ID: <CAF8bMcbqMHz68mVEe7371e7A0UddJGPFpNXNFRfJt3MMLJ0Xvw@mail.gmail.com>

>I would like to create a new column called PHENO which would satisfy
>these
>conditions:
>
>if CURRELIG=1 and RTNPTHY=1 than PHENO=1
>if PLASER=2 than PHENO=2
>otherwise is -9

I assume that if CURRELIG==1 and RNPTHY==1 and PLASER==2 then PHENO should
be 1.  Or should that case flag a data error?.

In the former case try
a$PHENO <- with(a, {
    tmp <- rep(-9, length(CURRELIG)),
    tmp[CURRELIG==1 & RTNPTHY==1] <- 1
    tmp[PLASER==2] <- 2
    tmp})

In the latter case add some calls to stop() or warning() if any of the
"impossible" cases are seen.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Apr 8, 2020 at 1:32 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Now that you have been shown how to do this, post your (non-working) code
> next time. And configure your email program to send plain text so we will
> see what you saw.
>
> a$PHENO <- ifelse( a$CURRELIG==1
>                  & a$RTNPTHY==1
>                  , 1
>                  ,  ifelse( a$PLASER==2
>                           , 2
>                           , -9 ) )
>
> or
>
> a$PHENO <- with( a
>                , ifelse( CURRELIG==1
>                        & RTNPTHY==1
>                        , 1
>                        , ifelse( PLASER==2
>                                , 2
>                                , -9 ) ) )
>
>
> On April 8, 2020 1:17:38 PM PDT, Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >Hi,
> >
> >I have a data frame like this:
> >
> >> head(a)
> >            FID LASER2 CURRELIG PLASER RTNPTHY
> >1 fam1000_G1000      1        1      1       1
> >2 fam1001_G1001      1        1      1       1
> >3 fam1003_G1003      2        1      2       2
> >4 fam1005_G1005      1        1      1       2
> >5 fam1009_G1009      1        1      1       2
> >6 fam1052_G1052      1        1      1       2
> >...
> >
> >I would like to create a new column called PHENO which would satisfy
> >these
> >conditions:
> >
> >if CURRELIG=1 and RTNPTHY=1 than PHENO=1
> >if PLASER=2 than PHENO=2
> >otherwise is -9
> >
> >Thanks
> >Ana
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jen@r@@mu@ @end|ng |rom gm@||@com  Wed Apr  8 23:33:52 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Wed, 8 Apr 2020 23:33:52 +0200
Subject: [R] how to create a new column with conditions
In-Reply-To: <CAF8bMcbqMHz68mVEe7371e7A0UddJGPFpNXNFRfJt3MMLJ0Xvw@mail.gmail.com>
References: <CAF9-5jN6E7=Qqsh+z0Y_4TQnOF-fxQB1B+XtPbnUsSEX0rtOrQ@mail.gmail.com>
 <43733584-5519-4DFD-AADB-8DBF11595B45@dcn.davis.ca.us>
 <CAF8bMcbqMHz68mVEe7371e7A0UddJGPFpNXNFRfJt3MMLJ0Xvw@mail.gmail.com>
Message-ID: <20200408213352.GB187643@jrl.uk.to>

On April 8, 2020 1:17:38 PM PDT, Ana Marija wrote:
| Hi,
| 
| I have a data frame like this:

Or ... *drum-roll* ... you could use plain 
old indexing.  Have a look:

a <-
"FID	LASER2	CURRELIG	PLASER	RTNPTHY
fam1000_G1000	1	1	1	1
fam1001_G1001	1	1	1	1
fam1003_G1003	2	1	2	2
fam1005_G1005	1	1	1	2
fam1009_G1009	1	1	1	2
fam1052_G1052	1	1	1	2"
a <- read.delim(text=a)

a$PHENO <- -9
a[a$CURRELIG==1 & a$RTNPTHY==1,"PHENO"] <- 1
a[a$PLASER==2,"PHENO"] <- 2

Best,
Rasmus


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Thu Apr  9 01:00:29 2020
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Thu, 9 Apr 2020 11:00:29 +1200
Subject: [R] TWITTER API environment variables
In-Reply-To: <24de83f433d028f764716b6140f33ab3a3ff7918.camel@pp.inet.fi>
References: <20200408051938.GA4690@slingshot.co.nz>
 <130bd81aa540ab1f8a9715f9cd5190c7642050c7.camel@pp.inet.fi>
 <20200408070206.GB4690@slingshot.co.nz>
 <24de83f433d028f764716b6140f33ab3a3ff7918.camel@pp.inet.fi>
Message-ID: <20200408230029.GC4690@slingshot.co.nz>



Apart from allowing the twitter app access, I didn't do anything to
adjust the settings other than editing the ~/.Renviron file which set up
the environment variable/s.

It appears to me that they are appropriate since they work if I use R
from the bash prompt or Rstudio.  The problem is apparantly with ESS.
I really don't want to use Rstudio.  It's so clunky to edit and debug
functions, and of course, the bash CLI is even more clunky.

I'll ask on the ESS list.



On Wed, 08-Apr-2020 at 12:32PM +0300, K. Elo wrote:

|> Hi again,
|> 
|> ok, I see. How about repeating the steps described in the tutorial on
|> your second computer instead of cloning the settings from the computer
|> #1? There might be some other settings not correctly copied.
|> 
|> HTH,
|> Kimmo
|> 
|> ke, 2020-04-08 kello 19:02 +1200, Patrick Connolly kirjoitti:
|> > Hello Kimmo,
|> > 
|> > Yes.  I did that and it worked fine -- as far as it goes.  But it
|> > didn't cover what to do when using the same twitter account on a
|> > computer with a different user name -- which is what my question was
|> > about.
|> > 
|> > 
|> > On Wed, 08-Apr-2020 at 08:55AM +0300, K. Elo wrote:
|> > 
|> > > > Hi!
|> > > > 
|> > > > Have you already read this:
|> > > > 
|> > > > 
|> https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html
|> > > > 
|> > > > I think they explain rather well how to use Twitter tokens with
|> > > > rtweet...
|> > > > 
|> > > > HTH,
|> > > > Kimmo
|> > > > 
|> > > > ke, 2020-04-08 kello 17:19 +1200, Patrick Connolly kirjoitti:
|> > > > > I'm using the rtweet package which makes use of the Twitter API
|> > > > > which
|> > > > > requires a token alluded to by an environment variable.
|> > > > > 
|> > > > > That environment variable is automatically set up from the
|> > > > > Twitter
|> > > > > web
|> > > > > site and takes the name TWITTER_<username> (where <username> is
|> > > > > the
|> > > > > name of the user in block letters).  That worked fine on my
|> > > > > work
|> > > > > computer where my username is 'work'.  When I copied that
|> > > > > working
|> > > > > directory to my home computer, the environment variable became
|> > > > > TWITTER_HOME but the rtweet package was looking for
|> > > > > TWITTER_WORK. There was no error message: just a null result
|> > > > > from the
|> > > > > search_users() function.
|> > > > > 
|> > > > > I tried editing the ~/.Renviron entry to
|> > > > > TWITTER_WORK=/home/home/.rtweet_token.rds
|> > > > > 
|> > > > > That worked for a short time but soon ceased working.  Then I
|> > > > > noticed
|> > > > > a new entry had been automatically added to ~/.Renviron
|> > > > > 
|> > > > > TWITTER_HOME=/home/home/.rtweet_token1.rds
|> > > > > 
|> > > > > So now I had two environment variables which also worked for a
|> > > > > short
|> > > > > time.
|> > > > > 
|> > > > > Recommendations please.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr  9 17:12:04 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 09 Apr 2020 08:12:04 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <b9061db7-3821-400f-81d9-0965580af6db@email.android.com>
References: <b9061db7-3821-400f-81d9-0965580af6db@email.android.com>
Message-ID: <58D36CD1-BDA6-4E16-8D76-AEACCFA21A81@dcn.davis.ca.us>

Rmarkdown is my first choice as well... but the options available there for controlling PDF output via LaTeX macros are incredibly powerful, while the options available for controlling Word output from Rmarkdown are extremely limited by comparison. ReporteRs and officeR provide considerably more fine-grained control over Word formatting and layout than Rmarkdown supports, so for meshing R output into an existing Word-based workflow without lots of manual tweaking there is no comparison.

On April 8, 2020 10:12:36 PM PDT, cpolwart at chemo.org.uk wrote:
>DocX is quite a complex file..it's actually a zip file which contains
>an XML file describing the text and sub folders with other content such
>as images.
>
>
>The description of need is a little vague - but may be the way it is
>described. Rmarkdown For instance can generate output to word. 
>ODFweave (now discontinued I think) can output to odx which can be
>opened in word. Although it starts with a odx file and generated a new
>version of it.
>
>
>I use Rmarkdown to generate reports (mine are PDF) and if someone said
>could I do a word document report I'd start with markdown...
>
>
>
>
>
>On 8 Apr 2020 18:08, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>But the OP explicitly notes that the read_docx package does *not* write
>
>files and asks whether there are *other* packages or functions that
>provide 
>that functionality. It still seems to me that the ReporteR maintainer
>might 
>be the best place to go for that info, although there is certainly no 
>assurance that he can provide it. 
>
>Bert 
>
>On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> 
>wrote: 
>
>> But before hassling the maintainer the OP should read the package 
>> vignettes and run some examples... read_docx does not write to any
>files, 
>> so complaining that it doesn't will be fruitless. 
>> 
>> On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
>
>> wrote: 
>> >This sounds like the sort of specialized question that should be 
>> >directed 
>> >to the maintainer (?maintainer) rather than to a general Help list
>such 
>> >as 
>> >this. 
>> > 
>> >Bert Gunter 
>> > 
>> >"The trouble with having an open mind is that people keep coming
>along 
>> >and 
>> >sticking things into it." 
>> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 
>> > 
>> > 
>> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist
><jeremyclarkbio at gmail.com> 
>> >wrote: 
>> > 
>> >> Dear All, 
>> >> 
>> >> Mac Catalina - R 3.6.3 - all up-to-date packages. 
>> >> I would like to re-create the functionality which was found in the
>
>> >package 
>> >> {ReporteRs} by creating a .docx file in a folder on my computer
>from 
>> >within 
>> >> R - which can subsequently be used by the {officer} function 
>> >read_docx. 
>> >> The function read_docx on my system does NOT create a new
>document, 
>> >and 
>> >> neither does the following code: 
>> >> new.word.doc=function(){ report = read_docx(path ..name..
>".docx")) 
>> >> return(report) } 
>> >> doc=new.word.doc() 
>> >> 
>> >> I can use {base} file.create to create a file with an extension
>.docx 
>> >- but 
>> >> apparently this is not a .docx file - and read_docx can't read it.
>
>> >> Is there another R package or function which I can use in order to
>
>> >create 
>> >> (and then close the link to R so that it can be used by another 
>> >package) a 
>> >> .docx file ? 
>> >> 
>> >> Many thanks in advance. 
>> >> 
>> >>         [[alternative HTML version deleted]] 
>> >> 
>> >> ______________________________________________ 
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> >> https://stat.ethz.ch/mailman/listinfo/r-help 
>> >> PLEASE do read the posting guide 
>> >> http://www.R-project.org/posting-guide.html 
>> >> and provide commented, minimal, self-contained, reproducible code.
>
>> >> 
>> > 
>> >       [[alternative HTML version deleted]] 
>> > 
>> >______________________________________________ 
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> >https://stat.ethz.ch/mailman/listinfo/r-help 
>> >PLEASE do read the posting guide 
>> >http://www.R-project.org/posting-guide.html 
>> >and provide commented, minimal, self-contained, reproducible code. 
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity. 
>> 
>
>	[[alternative HTML version deleted]] 
>
>______________________________________________ 
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help 
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html 
>and provide commented, minimal, self-contained, reproducible code. 

-- 
Sent from my phone. Please excuse my brevity.


From ||9212001 @end|ng |rom y@hoo@com  Thu Apr  9 17:00:31 2020
From: ||9212001 @end|ng |rom y@hoo@com (aiguo li)
Date: Thu, 9 Apr 2020 15:00:31 +0000 (UTC)
Subject: [R] create a r list from dataframe using the first column as list
 names
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
Message-ID: <561222591.3082527.1586444431196@mail.yahoo.com>

Hello allI need to create a r list with each row as a list object and named with the element in the first column.? Illustrated below:> a<- as.data.frame(matrix(LETTERS[1:16],nrow = 4))> a? V1 V2 V3 V41 ?A ?E ?I ?M2 ?B ?F ?J ?N3 ?C ?G ?K ?O4 ?D ?H ?L ?P
I want the list looks like$A[1] E I MLevels: E I M
$B[1] F J NLevels: F J N
$C[1] G K OLevels: G K O
$D[1] H L PLevels: H L P

I used the script below, it does not work the way I wantlapply(split(a,a$V1), function(x) as.list(a[-1]))?
any help would be greatly appreciated!
Anna
	[[alternative HTML version deleted]]


From jeremyc|@rkb|o @end|ng |rom gm@||@com  Thu Apr  9 19:15:39 2020
From: jeremyc|@rkb|o @end|ng |rom gm@||@com (A Biologist)
Date: Thu, 9 Apr 2020 19:15:39 +0200
Subject: [R] R create .docx file ?
In-Reply-To: <58D36CD1-BDA6-4E16-8D76-AEACCFA21A81@dcn.davis.ca.us>
References: <b9061db7-3821-400f-81d9-0965580af6db@email.android.com>
 <58D36CD1-BDA6-4E16-8D76-AEACCFA21A81@dcn.davis.ca.us>
Message-ID: <CACyTWRaf=q9fy20DhgUa7NVb-jOL+tg7DLYazjg88-ZoDEhHqw@mail.gmail.com>

Many thanks ! Bert Gunter's answer is of course correct. The maintainer
suggests Stackoverflow or commercial advice - which is worrying as I have
some further questions concerning lists in [officer} - but first I'll do
some more research !


On Thu, Apr 9, 2020 at 5:12 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Rmarkdown is my first choice as well... but the options available there
> for controlling PDF output via LaTeX macros are incredibly powerful, while
> the options available for controlling Word output from Rmarkdown are
> extremely limited by comparison. ReporteRs and officeR provide considerably
> more fine-grained control over Word formatting and layout than Rmarkdown
> supports, so for meshing R output into an existing Word-based workflow
> without lots of manual tweaking there is no comparison.
>
> On April 8, 2020 10:12:36 PM PDT, cpolwart at chemo.org.uk wrote:
> >DocX is quite a complex file..it's actually a zip file which contains
> >an XML file describing the text and sub folders with other content such
> >as images.
> >
> >
> >The description of need is a little vague - but may be the way it is
> >described. Rmarkdown For instance can generate output to word.
> >ODFweave (now discontinued I think) can output to odx which can be
> >opened in word. Although it starts with a odx file and generated a new
> >version of it.
> >
> >
> >I use Rmarkdown to generate reports (mine are PDF) and if someone said
> >could I do a word document report I'd start with markdown...
> >
> >
> >
> >
> >
> >On 8 Apr 2020 18:08, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> >But the OP explicitly notes that the read_docx package does *not* write
> >
> >files and asks whether there are *other* packages or functions that
> >provide
> >that functionality. It still seems to me that the ReporteR maintainer
> >might
> >be the best place to go for that info, although there is certainly no
> >assurance that he can provide it.
> >
> >Bert
> >
> >On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> But before hassling the maintainer the OP should read the package
> >> vignettes and run some examples... read_docx does not write to any
> >files,
> >> so complaining that it doesn't will be fruitless.
> >>
> >> On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> >
> >> wrote:
> >> >This sounds like the sort of specialized question that should be
> >> >directed
> >> >to the maintainer (?maintainer) rather than to a general Help list
> >such
> >> >as
> >> >this.
> >> >
> >> >Bert Gunter
> >> >
> >> >"The trouble with having an open mind is that people keep coming
> >along
> >> >and
> >> >sticking things into it."
> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist
> ><jeremyclarkbio at gmail.com>
> >> >wrote:
> >> >
> >> >> Dear All,
> >> >>
> >> >> Mac Catalina - R 3.6.3 - all up-to-date packages.
> >> >> I would like to re-create the functionality which was found in the
> >
> >> >package
> >> >> {ReporteRs} by creating a .docx file in a folder on my computer
> >from
> >> >within
> >> >> R - which can subsequently be used by the {officer} function
> >> >read_docx.
> >> >> The function read_docx on my system does NOT create a new
> >document,
> >> >and
> >> >> neither does the following code:
> >> >> new.word.doc=function(){ report = read_docx(path ..name..
> >".docx"))
> >> >> return(report) }
> >> >> doc=new.word.doc()
> >> >>
> >> >> I can use {base} file.create to create a file with an extension
> >.docx
> >> >- but
> >> >> apparently this is not a .docx file - and read_docx can't read it.
> >
> >> >> Is there another R package or function which I can use in order to
> >
> >> >create
> >> >> (and then close the link to R so that it can be used by another
> >> >package) a
> >> >> .docx file ?
> >> >>
> >> >> Many thanks in advance.
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>


-- 

dr hab. n. med. Jeremy Clark, prof. PUM,

Department of Clinical & Molecular Biochemistry,

Pomeranian Medical University in Szczecin; Pomorski Uniwersytet Medyczny w
Szczecinie,

Zak?ad Biochemii Klinicznej i Molekularnej,

ul. Powstancow Wlkp. 72, 70-111 Szczecin, Poland.

Tel. 0048 570112192; Tel. 004891 4661490; Fax. 004891 4661492

Email:   jeremyclarkbio at gmail.com

	[[alternative HTML version deleted]]


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr  9 19:28:57 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 9 Apr 2020 19:28:57 +0200
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <561222591.3082527.1586444431196@mail.yahoo.com>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
Message-ID: <20200409172857.GC187643@jrl.uk.to>

On 2020-04-09 15:00 +0000, aiguo li via R-help wrote:
| Hello allI need to create a r list with 
| each row as a list object and named with 
| the element in the first column.? 

Dear aiguo,

Perhaps this fits your bill?

  a <- matrix(LETTERS[1:16], nrow = 4)
  FUN <- function(x) { as.factor(x[-1]) }
  lapply(X=split(a, a[,1]), FUN=FUN)

Best,
Rasmus


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr  9 19:50:24 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 9 Apr 2020 18:50:24 +0100
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <561222591.3082527.1586444431196@mail.yahoo.com>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
Message-ID: <e528bfc4-0033-2e7f-497b-6478459d16b8@sapo.pt>

Hello,

Your post is unreadable, please repost in *plain text*, not HTML.

Rui Barradas

?s 16:00 de 09/04/20, aiguo li via R-help escreveu:
> Hello allI need to create a r list with each row as a list object and named with the element in the first column.? Illustrated below:> a<- as.data.frame(matrix(LETTERS[1:16],nrow = 4))> a? V1 V2 V3 V41 ?A ?E ?I ?M2 ?B ?F ?J ?N3 ?C ?G ?K ?O4 ?D ?H ?L ?P
> I want the list looks like$A[1] E I MLevels: E I M
> $B[1] F J NLevels: F J N
> $C[1] G K OLevels: G K O
> $D[1] H L PLevels: H L P
> 
> I used the script below, it does not work the way I wantlapply(split(a,a$V1), function(x) as.list(a[-1]))
> any help would be greatly appreciated!
> Anna
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr  9 20:21:39 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 9 Apr 2020 20:21:39 +0200
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <e528bfc4-0033-2e7f-497b-6478459d16b8@sapo.pt>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
 <e528bfc4-0033-2e7f-497b-6478459d16b8@sapo.pt>
Message-ID: <20200409182139.GD187643@jrl.uk.to>

On 2020-04-09 18:50 +0100, Rui Barradas wrote:
| Hello,
| 
| Your post is unreadable, please repost in 
| *plain text*, not HTML.

Hi!  It was not so bad?  I was able to 
extract out the core parts at least to 
prepare an answer ... maybe a bit hard with 
no line breaks, but ... 

Best,
Rasmus


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr  9 20:23:16 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 9 Apr 2020 20:23:16 +0200
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <268200624.3334981.1586455221416@mail.yahoo.com>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
 <20200409172857.GC187643@jrl.uk.to>
 <268200624.3334981.1586455221416@mail.yahoo.com>
Message-ID: <20200409182316.GE187643@jrl.uk.to>

On 2020-04-09 18:00 +0000, aiguo li wrote:
| That is awesome!  Thanks.

I'm glad this was helpful for you!


From j@vedbtk111 @end|ng |rom gm@||@com  Fri Apr 10 00:49:44 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Fri, 10 Apr 2020 00:49:44 +0200
Subject: [R] different validation methods produce same results
Message-ID: <CAJhui+uW5u70ugPhLRrX3Piry8jg2iXb=a2TtRM=BkxFYUZ4uQ@mail.gmail.com>

I am using different validation methods (mentioned below in code) for
software defect prediction dataset. I am using them for Random and Grid
searches and all the validation methods produce same results i.e. random
search with all validation methods produce same results and same is the
case with grid search.

Am I doing something wrong?


ct_rand <- trainControl(method = "repeatedcv", number=10, repeats=10,index
= index_2, search="random")
ct_grid <- trainControl(method = "repeatedcv", number=10, repeats=10,index
= index_2, search="grid")


ct_boot1 <- trainControl(method = "boot", number=100,  index = index_2,
search="random")
ct_boot2 <- trainControl(method = "boot", number=100,  index = index_2,
search="grid")

ct_locv <- trainControl(method = "LOOCV",  search="random")
ct_locv2 <- trainControl(method = "LOOCV",   search="grid")

ct_rand5CV <- trainControl(method = "repeatedcv", number=5,
repeats=10,index = index_2, search="random")
ct_grid5CV <- trainControl(method = "repeatedcv", number=5,
repeats=10,index = index_2, search="grid")

	[[alternative HTML version deleted]]


From r|@ngu@ge22 @end|ng |rom gm@||@com  Thu Apr  9 23:42:06 2020
From: r|@ngu@ge22 @end|ng |rom gm@||@com (Kumar t)
Date: Thu, 9 Apr 2020 16:42:06 -0500
Subject: [R] Learning Shinny
Message-ID: <CAPEb7FQ=3cWiNh=Ee_FAFozC-OE0YX_YeRcY+xy59faoNKHOcQ@mail.gmail.com>

Hello all ,

Very sorry to ask you question that might have been answered earlier . I
could not able to find right answer .

My requirement is get decent level of proficiency  in the R-Shiny . Is
there path ( I mean do I need to have knowledge of Dplyr to get data in
right format )  that I need to follow . Any good references to  papers  or
books or online resources .

I am new learner to R language .

Thanks
Phani

	[[alternative HTML version deleted]]


From p@m|rnov2000 @end|ng |rom gm@||@com  Fri Apr 10 00:59:04 2020
From: p@m|rnov2000 @end|ng |rom gm@||@com (petr smirnov)
Date: Thu, 9 Apr 2020 18:59:04 -0400
Subject: [R] Having trouble understanding the sapply/vapply documentation
 and behaviour of USE.NAMES
Message-ID: <CABAj7xcXm=NaApNSPtym8ajha9BRmZ5FMxAgc=FFHi5fP8FvLA@mail.gmail.com>

I am having trouble parsing the documentation for sapply and vapply,
and I cannot understand if it explains the different behaviour of
USE.NAMES between the two.

I noticed the following different behaviour between the two functions:

> sapply(c("1"=1, "2"=2, "3"=3), function(x) {r <- list(x); r}, USE.NAMES=FALSE)
$`1`
[1] 1

$`2`
[1] 2

$`3`
[1] 3

> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <- list(x); r}, FUN.VALUE=list(1), USE.NAMES=FALSE)
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

In the sapply case, the names of the input vector are retained. In the
vapply case, they are dropped. Note that this is not true when
USE.NAMES=TRUE:

> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <- list(x); r}, FUN.VALUE=list(1), USE.NAMES=TRUE)
$`1`
[1] 1

$`2`
[1] 2

$`3`
[1] 3

The manual page explains this for the names of the result of vapply:

The (Dim)names of the array value are taken from the FUN.VALUE if it
is named, otherwise from the result of the first function call. Column
names of the matrix or more generally the names of the last dimension
of the array value or names of the vector value are set from X as in
sapply.


If this explains the behaviour, could someone break it down for me and
help me understand the reasoning?
Otherwise, is this different behaviour intentional? Should it be
documented more clearly?

Thank you in advance!
-- 
Petr Smirnov
Department of Medical Biophysics, University of Toronto
Princess Margaret Cancer Centre, University Health Network


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Fri Apr 10 02:09:25 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 9 Apr 2020 20:09:25 -0400
Subject: [R] Correlated sampling
Message-ID: <69491F7B-E289-4962-B524-4799F761F78A@comcast.net>

I want to create a Monte Carlo simulation with 4 input parameters that are correlated with each other. The parameters have normal distributions and the variance/covariance matrix is known. Are there any R functions available to generate such correlated normal random variables?

Bernard
Sent from my iPhone so please excuse the spelling!"

From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Apr 10 02:23:49 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 10 Apr 2020 12:23:49 +1200
Subject: [R] [FORGED] Having trouble understanding the sapply/vapply
 documentation and behaviour of USE.NAMES
In-Reply-To: <CABAj7xcXm=NaApNSPtym8ajha9BRmZ5FMxAgc=FFHi5fP8FvLA@mail.gmail.com>
References: <CABAj7xcXm=NaApNSPtym8ajha9BRmZ5FMxAgc=FFHi5fP8FvLA@mail.gmail.com>
Message-ID: <4b61dc7f-b5e2-dcc8-a44d-9a581a5de5ff@auckland.ac.nz>


On 10/04/20 10:59 am, petr smirnov wrote:

> I am having trouble parsing the documentation for sapply and vapply,
> and I cannot understand if it explains the different behaviour of
> USE.NAMES between the two.
> 
> I noticed the following different behaviour between the two functions:
> 
>> sapply(c("1"=1, "2"=2, "3"=3), function(x) {r <- list(x); r}, USE.NAMES=FALSE)
> $`1`
> [1] 1
> 
> $`2`
> [1] 2
> 
> $`3`
> [1] 3
> 
>> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <- list(x); r}, FUN.VALUE=list(1), USE.NAMES=FALSE)
> [[1]]
> [1] 1
> 
> [[2]]
> [1] 2
> 
> [[3]]
> [1] 3
> 
> In the sapply case, the names of the input vector are retained. In the
> vapply case, they are dropped. Note that this is not true when
> USE.NAMES=TRUE:
> 
>> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <- list(x); r}, FUN.VALUE=list(1), USE.NAMES=TRUE)
> $`1`
> [1] 1
> 
> $`2`
> [1] 2
> 
> $`3`
> [1] 3
> 
> The manual page explains this for the names of the result of vapply:
> 
> The (Dim)names of the array value are taken from the FUN.VALUE if it
> is named, otherwise from the result of the first function call. Column
> names of the matrix or more generally the names of the last dimension
> of the array value or names of the vector value are set from X as in
> sapply.
> 
> 
> If this explains the behaviour, could someone break it down for me and
> help me understand the reasoning?
> Otherwise, is this different behaviour intentional? Should it be
> documented more clearly?

IMHO there is an error in the documentation here.  Clearly USE.NAMES has 
a different impact on vapply() than it has on sapply() and the 
documentation does not indicate this, in fact quite the opposite.

It might be appropriate to submit a bug report (see
https://www.r-project.org/bugs.html) but it's probably not worth the 
hassle.  It's a pretty minor error.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Fri Apr 10 03:19:45 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Fri, 10 Apr 2020 13:19:45 +1200
Subject: [R] [FORGED]  Correlated sampling
In-Reply-To: <69491F7B-E289-4962-B524-4799F761F78A@comcast.net>
References: <69491F7B-E289-4962-B524-4799F761F78A@comcast.net>
Message-ID: <7b98a85d-ccea-7f08-702d-625ce1167441@auckland.ac.nz>


On 10/04/20 12:09 pm, Bernard Comcast wrote:

> I want to create a Monte Carlo simulation with 4 input parameters
> that are correlated with each other. The parameters have normal
> distributions and the variance/covariance matrix is known. Are there
> any R functions available to generate such correlated normal random
> variables?

?MASS::mvrnorm

?mvtnorm::rmvnorm

There may be others!

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jen@r@@mu@ @end|ng |rom gm@||@com  Fri Apr 10 18:14:32 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Fri, 10 Apr 2020 18:14:32 +0200
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <268200624.3334981.1586455221416@mail.yahoo.com>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
 <20200409172857.GC187643@jrl.uk.to>
 <268200624.3334981.1586455221416@mail.yahoo.com>
Message-ID: <20200410161432.GF187643@jrl.uk.to>

On 2020-04-09 18:00 +0000, aiguo li wrote:
| That is awesome!  Thanks.

Dear AiGuo,

I thought: why make this overly 
complicated, when this is also 
possible:

  a <- matrix(LETTERS[1:16], nrow=4)
  X <- split(x=a[,-1], f=a[,1])
  lapply(X=X, FUN=as.factor)

Best,
Rasmus


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 18:15:45 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 11:15:45 -0500
Subject: [R] how to get all strings in a data frame that start with a
 particular string
Message-ID: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>

Hello,

Hello,

I have a data frame (tot) with about 2000 columns. How can I extract
from it all strings that start with E14?

I tried this:
e14 <- sapply(tot, function(x) grepl("^E14", x))

but this returns me just TRUE and FALSE vector, how do I get actual
strings that start with E14?

Thanks
Ana


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Apr 10 18:43:01 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 10 Apr 2020 17:43:01 +0100
Subject: [R] how to get all strings in a data frame that start with a
 particular string
In-Reply-To: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>
References: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>
Message-ID: <3f544cc9-d3b7-05d1-613b-c02a59bb32ec@dewey.myzen.co.uk>

Dear Ana

Would it not be possible to use grep instead of grepl and get the values 
using the value = TRUE parameter?

Michael

On 10/04/2020 17:15, Ana Marija wrote:
> Hello,
> 
> Hello,
> 
> I have a data frame (tot) with about 2000 columns. How can I extract
> from it all strings that start with E14?
> 
> I tried this:
> e14 <- sapply(tot, function(x) grepl("^E14", x))
> 
> but this returns me just TRUE and FALSE vector, how do I get actual
> strings that start with E14?
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jen@r@@mu@ @end|ng |rom gm@||@com  Fri Apr 10 19:00:48 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Fri, 10 Apr 2020 19:00:48 +0200
Subject: [R] how to get all strings in a data frame that start with a
 particular string
In-Reply-To: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>
References: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>
Message-ID: <20200410170048.GG187643@jrl.uk.to>

On 2020-04-10 11:15 -0500, Ana Marija wrote:
> I have a data frame (tot) with about 
> 2000 columns. How can I extract from 
> it all strings that start with E14?
> 
> I tried this:
> e14 <- sapply(tot, function(x) grepl("^E14", x))
> 
> but this returns me just TRUE and 
> FALSE vector, how do I get actual 
> strings that start with E14?

Dear Ana,

perhaps you thought of something along 
the lines of this:

  ncol <- 2000
  nrow <- 3
  line <-
    c("a", "b",
      "some text E14 bla bla some more text",
      "d",
      "E14 ... hey this starts and also ends with E14",
      "E14 something-something",
      "another string")
  tot <-
    as.data.frame(matrix(rep(line,
      times=ncol*nrow),
      ncol=ncol,
      byrow=T))
  
  # Now, tot is a df with some cells
  # containing replicates of line, some
  # cells there are now starting with E14
  # ... so we need to convert it to a
  # character matrix to be able to find
  # the indecies of the cells starting
  # with E14:
  
  tot <- as.matrix(tot)
  idx <- grepl("^E14", tot)
  tot[idx]

Best,
Rasmus


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 10 20:07:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 10 Apr 2020 11:07:47 -0700
Subject: [R] 
 create a r list from dataframe using the first column as list names
In-Reply-To: <20200410161432.GF187643@jrl.uk.to>
References: <561222591.3082527.1586444431196.ref@mail.yahoo.com>
 <561222591.3082527.1586444431196@mail.yahoo.com>
 <20200409172857.GC187643@jrl.uk.to>
 <268200624.3334981.1586455221416@mail.yahoo.com>
 <20200410161432.GF187643@jrl.uk.to>
Message-ID: <CAGxFJbQmQpWm+tVzsUAgK1ZJZw0SLX-TPTb6DYVRkHb=TeAYCg@mail.gmail.com>

"I thought: why make this overly complicated,..."

Indeed, though "complicated" is in the eyes of the beholder.
One wonders whether any of this is necessary, though: see ?apply , as in
apply(a, 1, whatever...)
to do things rowwise.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 10, 2020 at 9:14 AM Rasmus Liland <jensrasmus at gmail.com> wrote:

> On 2020-04-09 18:00 +0000, aiguo li wrote:
> | That is awesome!  Thanks.
>
> Dear AiGuo,
>
> I thought: why make this overly
> complicated, when this is also
> possible:
>
>   a <- matrix(LETTERS[1:16], nrow=4)
>   X <- split(x=a[,-1], f=a[,1])
>   lapply(X=X, FUN=as.factor)
>
> Best,
> Rasmus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 20:14:15 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 13:14:15 -0500
Subject: [R] how to get all strings in a data frame that start with a
 particular string
In-Reply-To: <20200410170048.GG187643@jrl.uk.to>
References: <CAF9-5jNTAHSSP9n=a9kNUOe5zEAayF1QR8=4VS-mFBrTcgyYfA@mail.gmail.com>
 <20200410170048.GG187643@jrl.uk.to>
Message-ID: <CAF9-5jMdKyEhDz-2-ArA3g-Smzcr3p4Q5MtQNYd6nfC3pMK==w@mail.gmail.com>

Thank you so much!

On Fri, Apr 10, 2020 at 12:00 PM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-10 11:15 -0500, Ana Marija wrote:
> > I have a data frame (tot) with about
> > 2000 columns. How can I extract from
> > it all strings that start with E14?
> >
> > I tried this:
> > e14 <- sapply(tot, function(x) grepl("^E14", x))
> >
> > but this returns me just TRUE and
> > FALSE vector, how do I get actual
> > strings that start with E14?
>
> Dear Ana,
>
> perhaps you thought of something along
> the lines of this:
>
>   ncol <- 2000
>   nrow <- 3
>   line <-
>     c("a", "b",
>       "some text E14 bla bla some more text",
>       "d",
>       "E14 ... hey this starts and also ends with E14",
>       "E14 something-something",
>       "another string")
>   tot <-
>     as.data.frame(matrix(rep(line,
>       times=ncol*nrow),
>       ncol=ncol,
>       byrow=T))
>
>   # Now, tot is a df with some cells
>   # containing replicates of line, some
>   # cells there are now starting with E14
>   # ... so we need to convert it to a
>   # character matrix to be able to find
>   # the indecies of the cells starting
>   # with E14:
>
>   tot <- as.matrix(tot)
>   idx <- grepl("^E14", tot)
>   tot[idx]
>
> Best,
> Rasmus


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 21:46:18 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 14:46:18 -0500
Subject: [R] question about system.file()
Message-ID: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>

Hello,

I would like to try this example in this link:
https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS

for example this line:

bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")

I have in current directory from where I would run this function a
file named output4.bed

in order to run the above, can I just run this:
bed.fn <- system.file("output4.bed", package="SNPRelate")

what is "extdata" ? Do I need it if my output4.bed is in the directory
from where I am running this?

Also do I need to have .gz format of output4.bed?

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 21:49:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 14:49:03 -0500
Subject: [R] question about system.file()
In-Reply-To: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
Message-ID: <CAF9-5jOHBghSvMGPDeV+MPVZBH+LTMGQ-PCqU2BbAgyirKdE_w@mail.gmail.com>

I tried to do this but I got this error:

> bed.fn <- system.file("output4.bed", package="SNPRelate")
> dim(bed.fn)
NULL
> fam.fn <- system.file("output4.fam", package="SNPRelate")
> bim.fn <- system.file("output4.bim", package="SNPRelate")
> snpgdsBED2GDS(bed.fn, fam.fn, bim.fn, "HapMap.gds")
Start file conversion from PLINK BED to SNP GDS ...
Error in (function (con, what, n = 1L, size = NA_integer_, signed = TRUE,  :
  can only read from a binary connection
In addition: Warning message:
In file(filename, "rb") :
  file("") only supports open = "w+" and open = "w+b": using the former

On Fri, Apr 10, 2020 at 2:46 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I would like to try this example in this link:
> https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
>
> for example this line:
>
> bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")
>
> I have in current directory from where I would run this function a
> file named output4.bed
>
> in order to run the above, can I just run this:
> bed.fn <- system.file("output4.bed", package="SNPRelate")
>
> what is "extdata" ? Do I need it if my output4.bed is in the directory
> from where I am running this?
>
> Also do I need to have .gz format of output4.bed?
>
> Thanks
> Ana


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Apr 10 21:54:48 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 10 Apr 2020 15:54:48 -0400
Subject: [R] question about system.file()
In-Reply-To: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
Message-ID: <0a96ac94-7b17-1959-bdd4-74193a359844@gmail.com>

On 10/04/2020 3:46 p.m., Ana Marija wrote:
> Hello,
> 
> I would like to try this example in this link:
> https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
> 
> for example this line:
> 
> bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")
> 
> I have in current directory from where I would run this function a
> file named output4.bed

Just use "output4.bed" as the filename.  The system.file() function is 
for working out the filename of files installed in packages.

Duncan Murdoch

> 
> in order to run the above, can I just run this:
> bed.fn <- system.file("output4.bed", package="SNPRelate")
> 
> what is "extdata" ? Do I need it if my output4.bed is in the directory
> from where I am running this?
> 
> Also do I need to have .gz format of output4.bed?
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 22:14:05 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 15:14:05 -0500
Subject: [R] question about system.file()
In-Reply-To: <0a96ac94-7b17-1959-bdd4-74193a359844@gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
 <0a96ac94-7b17-1959-bdd4-74193a359844@gmail.com>
Message-ID: <CAF9-5jN9zwoShza3u6poXYqi9Bd-a-EkoVGchY_jybAyGWLE3Q@mail.gmail.com>

Got it, thanks!

On Fri, Apr 10, 2020 at 2:54 PM Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On 10/04/2020 3:46 p.m., Ana Marija wrote:
> > Hello,
> >
> > I would like to try this example in this link:
> > https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
> >
> > for example this line:
> >
> > bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")
> >
> > I have in current directory from where I would run this function a
> > file named output4.bed
>
> Just use "output4.bed" as the filename.  The system.file() function is
> for working out the filename of files installed in packages.
>
> Duncan Murdoch
>
> >
> > in order to run the above, can I just run this:
> > bed.fn <- system.file("output4.bed", package="SNPRelate")
> >
> > what is "extdata" ? Do I need it if my output4.bed is in the directory
> > from where I am running this?
> >
> > Also do I need to have .gz format of output4.bed?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Apr 10 22:38:28 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 15:38:28 -0500
Subject: [R] matching doesn't work
Message-ID: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>

Hi,

I have this code:

library(SNPRelate)

# get PLINK output
plink.genome <- read.table("plink.genome", header=TRUE)

> head(plink.genome)
     FID1  IID1    FID2  IID2 RT EZ     Z0     Z1     Z2 PI_HAT PHE      DST
1 fam1054 G1054 fam1054  G700 OT  0 0.0045 0.9938 0.0017 0.4986  -1 0.839150
2 fam1054 G1054 fam1054  G701 OT  0 0.0000 1.0000 0.0000 0.5000  -1 0.838381
3 fam1079 G1079 fam2484 G2484 UN NA 0.0000 0.0007 0.9993 0.9997  -1 0.999889
4 fam1245 G1237 fam1245 G1245 OT  0 0.0036 0.9964 0.0000 0.4982  -1 0.838770
5 fam1245 G1241 fam1245 G1245 OT  0 0.0042 0.9854 0.0104 0.5031  -1 0.840569
6 fam0176  G174 fam0176  G176 OT  0 0.0000 1.0000 0.0000 0.5000  -1 0.837799

> head(plink.genome$IID1)
[1] G1054 G1054 G1079 G1237 G1241 G174
33 Levels: G1054 G1079 G1237 G1241 G174 G175 G177 G178 G1818 G2007 ... G578

snpgdsBED2GDS("output4.bed", "output4.fam","output4.bim", "HapMap.gds")
genofile <- snpgdsOpen("HapMap.gds")

# get SNPRelate output
ibd <- snpgdsIBDMoM(genofile, remove.monosnp=FALSE, kinship=TRUE)
head(ibdlist <- snpgdsIBDSelection(ibd))
   ID1   ID2        k0         k1     kinship
1 G1000 G1001 1.0000000 0.00000000 0.000000000
2 G1000 G1003 0.9938901 0.00000000 0.003054932
3 G1000 G1005 1.0000000 0.00000000 0.000000000
4 G1000 G1009 1.0000000 0.00000000 0.000000000

# adjust for the orders of sample pair
pair.samp <- paste(ibdlist$ID1, ibdlist$ID2, sep=" ")
 head(pair.samp)
[1] "G1000 G1001" "G1000 G1003" "G1000 G1005" "G1000 G1009" "G1000 G1052"
[6] "G1000 G1054"

plink.genome <- plink.genome[match(
    paste(plink.genome$IID1, plink.genome$IID2, sep=" "), pair.samp), ]
> head(plink.genome)
     FID1 IID1 FID2 IID2   RT EZ Z0 Z1 Z2 PI_HAT PHE DST PPC RATIO IBS0 IBS1
NA   <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA
NA.1 <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA
NA.2 <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA
NA.3 <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA
NA.4 <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA
NA.5 <NA> <NA> <NA> <NA> <NA> NA NA NA NA     NA  NA  NA  NA    NA   NA   NA

So nothing is matching here. Can you please advise,

Thanks
Ana


From jen@r@@mu@ @end|ng |rom gm@||@com  Fri Apr 10 22:45:19 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Fri, 10 Apr 2020 22:45:19 +0200
Subject: [R] question about system.file()
In-Reply-To: <CAF9-5jN9zwoShza3u6poXYqi9Bd-a-EkoVGchY_jybAyGWLE3Q@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
 <0a96ac94-7b17-1959-bdd4-74193a359844@gmail.com>
 <CAF9-5jN9zwoShza3u6poXYqi9Bd-a-EkoVGchY_jybAyGWLE3Q@mail.gmail.com>
Message-ID: <20200410204519.GH187643@jrl.uk.to>

On Fri, Apr 10, 2020 at 2:54 PM Duncan Murdoch wrote:
> On 10/04/2020 3:46 p.m., Ana Marija wrote:
> > I have in current directory from 
> > where I would run this function a 
> > file named output4.bed
>
> Just use "output4.bed" as the 
> filename.  The system.file() function 
> is for working out the filename of 
> files installed in packages.
>
> > what is "extdata" ? Do I need it if 
> > my output4.bed is in the directory 
> > from where I am running this?

"extdata" is a directory of five example 
files from the SNPRelate package: 
hapmap_geno.gds, plinkhapmap.bed.gz, 
plinkhapmap.bim.gz, plinkhapmap.fam.gz, 
and sequence.vcf.  On my system the 
directory is in 
~/R/x86_64-pc-linux-gnu-library/3.6/SNPRelate/extdata 
...

> > Also do I need to have .gz format of 
> > output4.bed?

Not if the files were not gzipped, you 
do not.  Example files in packages are 
compressed to save space for example 
code you will maybe will try only once, 
four of the files in that directory are 
gzipped, I do not know about that vCard 
file ...  Just input your own paths.

Try to find your files using 
list.files(".", "bed$") or something 
...

On 2020-04-10 14:49 -0500, Ana Marija wrote:
> I tried to do this but I got this 

Thus, try this:

  bed.fn <- "output4.bed"
  fam.fn <- "output4.fam"
  bim.fn <- "output4.bim"
  SNPRelate::snpgdsBED2GDS(bed.fn, fam.fn, bim.fn, "output4.gds")

Best,
Rasmus


From jen@r@@mu@ @end|ng |rom gm@||@com  Fri Apr 10 23:24:16 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Fri, 10 Apr 2020 23:24:16 +0200
Subject: [R] matching doesn't work
In-Reply-To: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
Message-ID: <20200410212416.GI187643@jrl.uk.to>

On 2020-04-10 15:38 -0500, Ana Marija wrote:
| Hi,
| 
| I have this code:

Dear Ana,

none of the ID tuples in the head 
outputs you provided matches, so I added 
two lines in ibdlist that matches up;  
perhaps if you provided more lines that 
would have matched in a pastebin 
somewhere ...


options(stringsAsFactors=FALSE)
plink.genome <-
"FID1	IID1	FID2	IID2	RT	EZ	Z0	Z1	Z2	PI_HAT	PHE	DST
fam1054	G1054	fam1054	G700	OT	0	0.0045	0.9938	0.0017	0.4986	-1	0.839150
fam1054	G1054	fam1054	G701	OT	0	0.0000	1.0000	0.0000	0.5000	-1	0.838381
fam1079	G1079	fam2484	G2484	UN		0.0000	0.0007	0.9993	0.9997	-1	0.999889
fam1245	G1237	fam1245	G1245	OT	0	0.0036	0.9964	0.0000	0.4982	-1	0.838770
fam1245	G1241	fam1245	G1245	OT	0	0.0042	0.9854	0.0104	0.5031	-1	0.840569
fam0176	G174	fam0176	G176	OT	0	0.0000	1.0000	0.0000	0.5000	-1	0.837799"

plink.genome <-
read.delim(text=plink.genome, header=TRUE)

ibdlist <-
"ID1	ID2	k0	k1	kinship
G1000	G1001	1.0000000	0.00000000	0.000000000
G1000	G1003	0.9938901	0.00000000	0.003054932
G1241	G1245	1.0000000	0.00000000	0.000000000
G1000	G1005	1.0000000	0.00000000	0.000000000
G1079	G2484	0.9938901	0.00000000	0.003054932
G1000	G1009	1.0000000	0.00000000	0.000000000"
ibdlist <-
read.delim(text=ibdlist)

idx <-
match(paste(plink.genome$IID1, plink.genome$IID2),
  paste(ibdlist$ID1, ibdlist$ID2))
plink.genome[idx,]


See if this fits the rest of your 
data.frames ...  Did I nail it here, or?  

Best,
Rasmus


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Apr 11 00:05:19 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 17:05:19 -0500
Subject: [R] matching doesn't work
In-Reply-To: <20200410212416.GI187643@jrl.uk.to>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
Message-ID: <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>

it didn't work unfortunately with your example:

> plink.genome[idx,]
character(0)

here is my whole:
plink.genome <- read.table("plink.genome", header=TRUE)

    FID1   IID1     FID2   IID2 RT    EZ      Z0      Z1      Z2
PI_HAT PHE       DST     PPC   RATIO    IBS0    IBS1    IBS2  HOMHOM
HETHET
  fam1054  G1054  fam1054   G700 OT     0  0.0045  0.9938  0.0017
0.4986  -1  0.839150  1.0000 209.7368     103  118630  250667 19.0000
3985.0000
  fam1054  G1054  fam1054   G701 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.838381  1.0000 266.0667      81  119124  249829 15.0000
3991.0000
  fam1079  G1079  fam2484  G2484 UN    NA  0.0000  0.0007  0.9993
0.9997  -1  0.999889  1.0000      NA       0      82  370250  0.0000
4591.0000
  fam1245  G1237  fam1245  G1245 OT     0  0.0036  0.9964  0.0000
0.4982  -1  0.838770  1.0000 188.4762      83  118647  249728 21.0000
3958.0000
  fam1245  G1241  fam1245  G1245 OT     0  0.0042  0.9854  0.0104
0.5031  -1  0.840569  1.0000 265.8667      97  117116  250690 15.0000
3988.0000
  fam0176   G174  fam0176   G176 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.837799  1.0000 190.0476     107  118306  246937 21.0000
3991.0000
  fam0176   G175  fam0176   G176 OT     0  0.0045  0.9909  0.0046
0.5001  -1  0.839611  1.0000 198.6500     102  117026  248327 20.0000
3973.0000
  fam0179   G177  fam0179   G179 OT     0  0.0091  0.9903  0.0006
0.4958  -1  0.838517  1.0000 116.5000     207  117568  247532 34.0000
3961.0000
  fam0179   G178  fam0179   G179 OT     0  0.0098  0.9902  0.0000
0.4951  -1  0.838160  1.0000 90.4318     224  117440  246548 44.0000
3979.0000
  fam1818  G1818  fam1818  G1819 OT     0  0.0050  0.9884  0.0066
0.5008  -1  0.839882  1.0000 208.8947     115  117679  250401 19.0000
3969.0000
  fam1818  G1818  fam1818  G1820 OT     0  0.0050  0.9950  0.0000
0.4975  -1  0.838709  1.0000 208.6842     115  119083  250671 19.0000
3965.0000
  fam2450  G2007  fam2450  G2450 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.831786  1.0000 79.0196     278  120248  238553 51.0000
4030.0000
  fam2450  G2024  fam2450  G2450 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.832052  1.0000 104.6750     242  118317  235124 40.0000
4187.0000
  fam2181  G2181  fam5745  G5745 UN    NA  0.0002  0.0034  0.9964
0.9981  -1  0.999402  1.0000      NA       4     432  367475  0.0000
4613.0000
  fam2183  G2183  fam2183  G2184 OT     0  0.0058  0.9836  0.0106
0.5024  -1  0.840452  1.0000 164.9583     133  117858  252192 24.0000
3959.0000
  fam2183  G2183  fam2183  G2185 OT     0  0.0045  0.9929  0.0026
0.4990  -1  0.839280  1.0000 136.2414     105  118760  251251 29.0000
3951.0000
  fam2280  G2280  fam2280  G2281 OT     0  0.0042  0.9893  0.0065
0.5011  -1  0.839937  1.0000 248.7500      97  117600  250265 16.0000
3980.0000
  fam2280  G2280  fam2280  G2282 OT     0  0.0033  0.9885  0.0082
0.5024  -1  0.840294  1.0000 264.8000      76  117095  249900 15.0000
3972.0000
  fam2286  G2284  fam2286  G2286 OT     0  0.0048  0.9952  0.0000
0.4976  -1  0.838745  1.0000 179.5909     112  118986  250534 22.0000
3951.0000
  fam2286  G2285  fam2286  G2286 OT     0  0.0046  0.9846  0.0108
0.5031  -1  0.840586  1.0000 331.4167     105  116441  249328 12.0000
3977.0000
  fam2813  G2813  fam4274  G4274 UN    NA  0.0058  0.0495  0.9447
0.9695  -1  0.990555  1.0000 239.2105     131    6616  357351 19.0000
4545.0000
  fam3238  G3237  fam3238  G3238 OT     0  0.0055  0.9913  0.0033
0.4989  -1  0.839299  1.0000 160.6800     125  117652  249060 25.0000
4017.0000
  fam3238  G3238  fam3238  G3264 OT     0  0.0035  0.9855  0.0110
0.5037  -1  0.840733  1.0000 173.3043      81  116986  250706 23.0000
3986.0000
  fam4257  G4257  fam0891   G891 UN    NA  0.2323  0.4978  0.2699
0.5188  -1  0.859862  1.0000 10.1332    5314   92050  268982 383.0000
3881.0000
  fam4275  G4275  fam4275  G4304 OT     0  0.0053  0.9947  0.0000
0.4973  -1  0.837959  1.0000 136.0345     122  118563  247910 29.0000
3945.0000
  fam4275  G4275  fam4275  G4352 OT     0  0.0048  0.9798  0.0154
0.5053  -1  0.841317  1.0000 209.3684     110  116482  251129 19.0000
3978.0000
  fam4454  G4452  fam4454  G4454 OT     0  0.0055  0.9840  0.0104
0.5024  -1  0.840440  1.0000 136.8966     127  116709  249681 29.0000
3970.0000
  fam4454  G4453  fam4454  G4454 OT     0  0.0057  0.9842  0.0101
0.5022  -1  0.840379  1.0000 160.0000     130  116255  248588 25.0000
4000.0000
  fam4666  G4666  fam0686   G686 UN    NA  0.0000  0.0026  0.9974
0.9987  -1  0.999576  1.0000      NA       0     312  367735  0.0000
4580.0000
  fam4691  G4691  fam4722  G4722 UN    NA  0.3986  0.4841  0.1173
0.3593  -1  0.818992  1.0000  5.9269    9073  113787  241580 602.0000
3568.0000
  fam5092  G5089  fam5092  G5092 OT     0  0.0051  0.9928  0.0022
0.4985  -1  0.839156  1.0000 234.4706     117  118225  249900 17.0000
3986.0000
  fam5092  G5092  fam5092  G5097 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.837560  1.0000 218.9444     100  119554  248956 18.0000
3941.0000
  fam5365  G5106  fam5365  G5365 OT     0  0.0057  0.9916  0.0027
0.4985  -1  0.839191  1.0000 208.0000     131  118747  251154 19.0000
3952.0000
  fam5365  G5118  fam5365  G5365 OT     0  0.0052  0.9886  0.0061
0.5004  -1  0.839781  1.0000 164.8750     121  118035  250954 24.0000
3957.0000
  fam0523   G523  fam0523   G551 OT     0  0.0037  0.9829  0.0135
0.5049  -1  0.841107  1.0000 180.6818      85  116769  251126 22.0000
3975.0000
  fam0523   G523  fam0523   G552 OT     0  0.0000  1.0000  0.0000
0.5000  -1  0.838173  1.0000 225.2353      81  119148  249406 17.0000
3829.0000
  fam5282  G5282  fam5282  G5328 OT     0  0.0033  0.9933  0.0035
0.5001  -1  0.839545  1.0000 232.1765      75  117898  249882 17.0000
3947.0000
  fam5681  G5681  fam0587   G587 UN    NA  0.0035  0.9871  0.0094
0.5030  -1  0.840482  1.0000 188.9524      79  116708  249522 21.0000
3968.0000
  fam0578   G578  fam6039  G6039 UN    NA  0.0000  0.0095  0.9905
0.9952  -1  0.998462  1.0000 4553.0000       1    1123  364629  1.0000
4553.0000

On Fri, Apr 10, 2020 at 4:24 PM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-10 15:38 -0500, Ana Marija wrote:
> | Hi,
> |
> | I have this code:
>
> Dear Ana,
>
> none of the ID tuples in the head
> outputs you provided matches, so I added
> two lines in ibdlist that matches up;
> perhaps if you provided more lines that
> would have matched in a pastebin
> somewhere ...
>
>
> options(stringsAsFactors=FALSE)
> plink.genome <-
> "FID1   IID1    FID2    IID2    RT      EZ      Z0      Z1      Z2      PI_HAT  PHE     DST
> fam1054 G1054   fam1054 G700    OT      0       0.0045  0.9938  0.0017  0.4986  -1      0.839150
> fam1054 G1054   fam1054 G701    OT      0       0.0000  1.0000  0.0000  0.5000  -1      0.838381
> fam1079 G1079   fam2484 G2484   UN              0.0000  0.0007  0.9993  0.9997  -1      0.999889
> fam1245 G1237   fam1245 G1245   OT      0       0.0036  0.9964  0.0000  0.4982  -1      0.838770
> fam1245 G1241   fam1245 G1245   OT      0       0.0042  0.9854  0.0104  0.5031  -1      0.840569
> fam0176 G174    fam0176 G176    OT      0       0.0000  1.0000  0.0000  0.5000  -1      0.837799"
>
> plink.genome <-
> read.delim(text=plink.genome, header=TRUE)
>
> ibdlist <-
> "ID1    ID2     k0      k1      kinship
> G1000   G1001   1.0000000       0.00000000      0.000000000
> G1000   G1003   0.9938901       0.00000000      0.003054932
> G1241   G1245   1.0000000       0.00000000      0.000000000
> G1000   G1005   1.0000000       0.00000000      0.000000000
> G1079   G2484   0.9938901       0.00000000      0.003054932
> G1000   G1009   1.0000000       0.00000000      0.000000000"
> ibdlist <-
> read.delim(text=ibdlist)
>
> idx <-
> match(paste(plink.genome$IID1, plink.genome$IID2),
>   paste(ibdlist$ID1, ibdlist$ID2))
> plink.genome[idx,]
>
>
> See if this fits the rest of your
> data.frames ...  Did I nail it here, or?
>
> Best,
> Rasmus


From jen@r@@mu@ @end|ng |rom gm@||@com  Sat Apr 11 01:03:21 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Sat, 11 Apr 2020 01:03:21 +0200
Subject: [R] matching doesn't work
In-Reply-To: <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
 <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
Message-ID: <20200410230321.GJ187643@jrl.uk.to>

On 2020-04-10 17:05 -0500, Ana Marija wrote:
> it didn't work unfortunately with your 
> example:
> 
> > plink.genome[idx,]
> character(0)

Hi!  Perhaps csv formatting are better 
suited for these emails ... the two 
ibdlist lines I added still matches in 
this example, added lookup for kinship 
... see if this works for you:


plink.genome <- "FID1,IID1,FID2,IID2,RT,EZ,Z0,Z1,Z2,PI_HAT,PHE,DST,PPC,RATIO,IBS0,IBS1,IBS2,HOMHOM,HETHET
fam1054,G1054,fam1054,G700,OT,0,0.0045,0.9938,0.0017,0.4986,-1,0.839150,1.0000,209.7368,103,118630,250667,19.0000,3985.0000
fam1054,G1054,fam1054,G701,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.838381,1.0000,266.0667,81,119124,249829,15.0000,3991.0000
fam1079,G1079,fam2484,G2484,UN,NA,0.0000,0.0007,0.9993,0.9997,-1,0.999889,1.0000,NA,0,82,370250,0.0000,4591.0000
fam1245,G1237,fam1245,G1245,OT,0,0.0036,0.9964,0.0000,0.4982,-1,0.838770,1.0000,188.4762,83,118647,249728,21.0000,3958.0000
fam1245,G1241,fam1245,G1245,OT,0,0.0042,0.9854,0.0104,0.5031,-1,0.840569,1.0000,265.8667,97,117116,250690,15.0000,3988.0000
fam0176,G174,fam0176,G176,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.837799,1.0000,190.0476,107,118306,246937,21.0000,3991.0000
fam0176,G175,fam0176,G176,OT,0,0.0045,0.9909,0.0046,0.5001,-1,0.839611,1.0000,198.6500,102,117026,248327,20.0000,3973.0000
fam0179,G177,fam0179,G179,OT,0,0.0091,0.9903,0.0006,0.4958,-1,0.838517,1.0000,116.5000,207,117568,247532,34.0000,3961.0000
fam0179,G178,fam0179,G179,OT,0,0.0098,0.9902,0.0000,0.4951,-1,0.838160,1.0000,90.4318,224,117440,246548,44.0000,3979.0000
fam1818,G1818,fam1818,G1819,OT,0,0.0050,0.9884,0.0066,0.5008,-1,0.839882,1.0000,208.8947,115,117679,250401,19.0000,3969.0000
fam1818,G1818,fam1818,G1820,OT,0,0.0050,0.9950,0.0000,0.4975,-1,0.838709,1.0000,208.6842,115,119083,250671,19.0000,3965.0000
fam2450,G2007,fam2450,G2450,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.831786,1.0000,79.0196,278,120248,238553,51.0000,4030.0000
fam2450,G2024,fam2450,G2450,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.832052,1.0000,104.6750,242,118317,235124,40.0000,4187.0000
fam2181,G2181,fam5745,G5745,UN,NA,0.0002,0.0034,0.9964,0.9981,-1,0.999402,1.0000,NA,4,432,367475,0.0000,4613.0000
fam2183,G2183,fam2183,G2184,OT,0,0.0058,0.9836,0.0106,0.5024,-1,0.840452,1.0000,164.9583,133,117858,252192,24.0000,3959.0000
fam2183,G2183,fam2183,G2185,OT,0,0.0045,0.9929,0.0026,0.4990,-1,0.839280,1.0000,136.2414,105,118760,251251,29.0000,3951.0000
fam2280,G2280,fam2280,G2281,OT,0,0.0042,0.9893,0.0065,0.5011,-1,0.839937,1.0000,248.7500,97,117600,250265,16.0000,3980.0000
fam2280,G2280,fam2280,G2282,OT,0,0.0033,0.9885,0.0082,0.5024,-1,0.840294,1.0000,264.8000,76,117095,249900,15.0000,3972.0000
fam2286,G2284,fam2286,G2286,OT,0,0.0048,0.9952,0.0000,0.4976,-1,0.838745,1.0000,179.5909,112,118986,250534,22.0000,3951.0000
fam2286,G2285,fam2286,G2286,OT,0,0.0046,0.9846,0.0108,0.5031,-1,0.840586,1.0000,331.4167,105,116441,249328,12.0000,3977.0000
fam2813,G2813,fam4274,G4274,UN,NA,0.0058,0.0495,0.9447,0.9695,-1,0.990555,1.0000,239.2105,131,6616,357351,19.0000,4545.0000
fam3238,G3237,fam3238,G3238,OT,0,0.0055,0.9913,0.0033,0.4989,-1,0.839299,1.0000,160.6800,125,117652,249060,25.0000,4017.0000
fam3238,G3238,fam3238,G3264,OT,0,0.0035,0.9855,0.0110,0.5037,-1,0.840733,1.0000,173.3043,81,116986,250706,23.0000,3986.0000
fam4257,G4257,fam0891,G891,UN,NA,0.2323,0.4978,0.2699,0.5188,-1,0.859862,1.0000,10.1332,5314,92050,268982,383.0000,3881.0000
fam4275,G4275,fam4275,G4304,OT,0,0.0053,0.9947,0.0000,0.4973,-1,0.837959,1.0000,136.0345,122,118563,247910,29.0000,3945.0000
fam4275,G4275,fam4275,G4352,OT,0,0.0048,0.9798,0.0154,0.5053,-1,0.841317,1.0000,209.3684,110,116482,251129,19.0000,3978.0000
fam4454,G4452,fam4454,G4454,OT,0,0.0055,0.9840,0.0104,0.5024,-1,0.840440,1.0000,136.8966,127,116709,249681,29.0000,3970.0000
fam4454,G4453,fam4454,G4454,OT,0,0.0057,0.9842,0.0101,0.5022,-1,0.840379,1.0000,160.0000,130,116255,248588,25.0000,4000.0000
fam4666,G4666,fam0686,G686,UN,NA,0.0000,0.0026,0.9974,0.9987,-1,0.999576,1.0000,NA,0,312,367735,0.0000,4580.0000
fam4691,G4691,fam4722,G4722,UN,NA,0.3986,0.4841,0.1173,0.3593,-1,0.818992,1.0000,5.9269,9073,113787,241580,602.0000,3568.0000
fam5092,G5089,fam5092,G5092,OT,0,0.0051,0.9928,0.0022,0.4985,-1,0.839156,1.0000,234.4706,117,118225,249900,17.0000,3986.0000
fam5092,G5092,fam5092,G5097,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.837560,1.0000,218.9444,100,119554,248956,18.0000,3941.0000
fam5365,G5106,fam5365,G5365,OT,0,0.0057,0.9916,0.0027,0.4985,-1,0.839191,1.0000,208.0000,131,118747,251154,19.0000,3952.0000
fam5365,G5118,fam5365,G5365,OT,0,0.0052,0.9886,0.0061,0.5004,-1,0.839781,1.0000,164.8750,121,118035,250954,24.0000,3957.0000
fam0523,G523,fam0523,G551,OT,0,0.0037,0.9829,0.0135,0.5049,-1,0.841107,1.0000,180.6818,85,116769,251126,22.0000,3975.0000
fam0523,G523,fam0523,G552,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.838173,1.0000,225.2353,81,119148,249406,17.0000,3829.0000
fam5282,G5282,fam5282,G5328,OT,0,0.0033,0.9933,0.0035,0.5001,-1,0.839545,1.0000,232.1765,75,117898,249882,17.0000,3947.0000
fam5681,G5681,fam0587,G587,UN,NA,0.0035,0.9871,0.0094,0.5030,-1,0.840482,1.0000,188.9524,79,116708,249522,21.0000,3968.0000
fam0578,G578,fam6039,G6039,UN,NA,0.0000,0.0095,0.9905,0.9952,-1,0.998462,1.0000,4553.0000,1,1123,364629,1.0000,4553.0000"
plink.genome <- read.csv(text=plink.genome)

ibdlist <- "ID1,ID2,k0,k1,kinship
G1000,G1001,1.0000000,0.00000000,0.000000000
G1000,G1003,0.9938901,0.00000000,0.003054932
G1241,G1245,1.0000000,0.00000000,0.000000000
G1000,G1005,1.0000000,0.00000000,0.000000000
G1079,G2484,0.9938901,0.00000000,0.003054932
G1000,G1009,1.0000000,0.00000000,0.000000000"
ibdlist <- read.csv(text=ibdlist)

x <- paste(plink.genome$IID1, plink.genome$IID2)
table <- paste(ibdlist$ID1, ibdlist$ID2)
idx <- match(x=x, table=table)
ibdlist[idx,"kinship"]


Best,
Rasmus


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Apr 11 01:46:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 18:46:03 -0500
Subject: [R] matching doesn't work
In-Reply-To: <20200410230321.GJ187643@jrl.uk.to>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
 <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
 <20200410230321.GJ187643@jrl.uk.to>
Message-ID: <CAF9-5jME3zCJr6Bn5fwEibik5fVWrpqDNCLUb4X=dXgYXGpJUA@mail.gmail.com>

so if I understand correctly you would just remove sep=" " from my codes?

Thank you so much for working on this.
Is there is any chance you can change my original code (pasted bellow)
with changes you think should work?

library(SNPRelate)

# get PLINK output
plink.genome <- read.table("plink.genome", header=TRUE)

snpgdsBED2GDS("output4.bed", "output4.fam","output4.bim", "HapMap.gds")
genofile <- snpgdsOpen("HapMap.gds")

# get SNPRelate output
ibd <- snpgdsIBDMoM(genofile, remove.monosnp=FALSE, kinship=TRUE)

# adjust for the orders of sample pair
pair.samp <- paste(ibdlist$ID1, ibdlist$ID2, sep=" ")
plink.genome <- plink.genome[match(
    paste(plink.genome$IID1, plink.genome$IID2, sep=" "), pair.samp), ]

On Fri, Apr 10, 2020 at 6:03 PM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-10 17:05 -0500, Ana Marija wrote:
> > it didn't work unfortunately with your
> > example:
> >
> > > plink.genome[idx,]
> > character(0)
>
> Hi!  Perhaps csv formatting are better
> suited for these emails ... the two
> ibdlist lines I added still matches in
> this example, added lookup for kinship
> ... see if this works for you:
>
>
> plink.genome <- "FID1,IID1,FID2,IID2,RT,EZ,Z0,Z1,Z2,PI_HAT,PHE,DST,PPC,RATIO,IBS0,IBS1,IBS2,HOMHOM,HETHET
> fam1054,G1054,fam1054,G700,OT,0,0.0045,0.9938,0.0017,0.4986,-1,0.839150,1.0000,209.7368,103,118630,250667,19.0000,3985.0000
> fam1054,G1054,fam1054,G701,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.838381,1.0000,266.0667,81,119124,249829,15.0000,3991.0000
> fam1079,G1079,fam2484,G2484,UN,NA,0.0000,0.0007,0.9993,0.9997,-1,0.999889,1.0000,NA,0,82,370250,0.0000,4591.0000
> fam1245,G1237,fam1245,G1245,OT,0,0.0036,0.9964,0.0000,0.4982,-1,0.838770,1.0000,188.4762,83,118647,249728,21.0000,3958.0000
> fam1245,G1241,fam1245,G1245,OT,0,0.0042,0.9854,0.0104,0.5031,-1,0.840569,1.0000,265.8667,97,117116,250690,15.0000,3988.0000
> fam0176,G174,fam0176,G176,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.837799,1.0000,190.0476,107,118306,246937,21.0000,3991.0000
> fam0176,G175,fam0176,G176,OT,0,0.0045,0.9909,0.0046,0.5001,-1,0.839611,1.0000,198.6500,102,117026,248327,20.0000,3973.0000
> fam0179,G177,fam0179,G179,OT,0,0.0091,0.9903,0.0006,0.4958,-1,0.838517,1.0000,116.5000,207,117568,247532,34.0000,3961.0000
> fam0179,G178,fam0179,G179,OT,0,0.0098,0.9902,0.0000,0.4951,-1,0.838160,1.0000,90.4318,224,117440,246548,44.0000,3979.0000
> fam1818,G1818,fam1818,G1819,OT,0,0.0050,0.9884,0.0066,0.5008,-1,0.839882,1.0000,208.8947,115,117679,250401,19.0000,3969.0000
> fam1818,G1818,fam1818,G1820,OT,0,0.0050,0.9950,0.0000,0.4975,-1,0.838709,1.0000,208.6842,115,119083,250671,19.0000,3965.0000
> fam2450,G2007,fam2450,G2450,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.831786,1.0000,79.0196,278,120248,238553,51.0000,4030.0000
> fam2450,G2024,fam2450,G2450,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.832052,1.0000,104.6750,242,118317,235124,40.0000,4187.0000
> fam2181,G2181,fam5745,G5745,UN,NA,0.0002,0.0034,0.9964,0.9981,-1,0.999402,1.0000,NA,4,432,367475,0.0000,4613.0000
> fam2183,G2183,fam2183,G2184,OT,0,0.0058,0.9836,0.0106,0.5024,-1,0.840452,1.0000,164.9583,133,117858,252192,24.0000,3959.0000
> fam2183,G2183,fam2183,G2185,OT,0,0.0045,0.9929,0.0026,0.4990,-1,0.839280,1.0000,136.2414,105,118760,251251,29.0000,3951.0000
> fam2280,G2280,fam2280,G2281,OT,0,0.0042,0.9893,0.0065,0.5011,-1,0.839937,1.0000,248.7500,97,117600,250265,16.0000,3980.0000
> fam2280,G2280,fam2280,G2282,OT,0,0.0033,0.9885,0.0082,0.5024,-1,0.840294,1.0000,264.8000,76,117095,249900,15.0000,3972.0000
> fam2286,G2284,fam2286,G2286,OT,0,0.0048,0.9952,0.0000,0.4976,-1,0.838745,1.0000,179.5909,112,118986,250534,22.0000,3951.0000
> fam2286,G2285,fam2286,G2286,OT,0,0.0046,0.9846,0.0108,0.5031,-1,0.840586,1.0000,331.4167,105,116441,249328,12.0000,3977.0000
> fam2813,G2813,fam4274,G4274,UN,NA,0.0058,0.0495,0.9447,0.9695,-1,0.990555,1.0000,239.2105,131,6616,357351,19.0000,4545.0000
> fam3238,G3237,fam3238,G3238,OT,0,0.0055,0.9913,0.0033,0.4989,-1,0.839299,1.0000,160.6800,125,117652,249060,25.0000,4017.0000
> fam3238,G3238,fam3238,G3264,OT,0,0.0035,0.9855,0.0110,0.5037,-1,0.840733,1.0000,173.3043,81,116986,250706,23.0000,3986.0000
> fam4257,G4257,fam0891,G891,UN,NA,0.2323,0.4978,0.2699,0.5188,-1,0.859862,1.0000,10.1332,5314,92050,268982,383.0000,3881.0000
> fam4275,G4275,fam4275,G4304,OT,0,0.0053,0.9947,0.0000,0.4973,-1,0.837959,1.0000,136.0345,122,118563,247910,29.0000,3945.0000
> fam4275,G4275,fam4275,G4352,OT,0,0.0048,0.9798,0.0154,0.5053,-1,0.841317,1.0000,209.3684,110,116482,251129,19.0000,3978.0000
> fam4454,G4452,fam4454,G4454,OT,0,0.0055,0.9840,0.0104,0.5024,-1,0.840440,1.0000,136.8966,127,116709,249681,29.0000,3970.0000
> fam4454,G4453,fam4454,G4454,OT,0,0.0057,0.9842,0.0101,0.5022,-1,0.840379,1.0000,160.0000,130,116255,248588,25.0000,4000.0000
> fam4666,G4666,fam0686,G686,UN,NA,0.0000,0.0026,0.9974,0.9987,-1,0.999576,1.0000,NA,0,312,367735,0.0000,4580.0000
> fam4691,G4691,fam4722,G4722,UN,NA,0.3986,0.4841,0.1173,0.3593,-1,0.818992,1.0000,5.9269,9073,113787,241580,602.0000,3568.0000
> fam5092,G5089,fam5092,G5092,OT,0,0.0051,0.9928,0.0022,0.4985,-1,0.839156,1.0000,234.4706,117,118225,249900,17.0000,3986.0000
> fam5092,G5092,fam5092,G5097,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.837560,1.0000,218.9444,100,119554,248956,18.0000,3941.0000
> fam5365,G5106,fam5365,G5365,OT,0,0.0057,0.9916,0.0027,0.4985,-1,0.839191,1.0000,208.0000,131,118747,251154,19.0000,3952.0000
> fam5365,G5118,fam5365,G5365,OT,0,0.0052,0.9886,0.0061,0.5004,-1,0.839781,1.0000,164.8750,121,118035,250954,24.0000,3957.0000
> fam0523,G523,fam0523,G551,OT,0,0.0037,0.9829,0.0135,0.5049,-1,0.841107,1.0000,180.6818,85,116769,251126,22.0000,3975.0000
> fam0523,G523,fam0523,G552,OT,0,0.0000,1.0000,0.0000,0.5000,-1,0.838173,1.0000,225.2353,81,119148,249406,17.0000,3829.0000
> fam5282,G5282,fam5282,G5328,OT,0,0.0033,0.9933,0.0035,0.5001,-1,0.839545,1.0000,232.1765,75,117898,249882,17.0000,3947.0000
> fam5681,G5681,fam0587,G587,UN,NA,0.0035,0.9871,0.0094,0.5030,-1,0.840482,1.0000,188.9524,79,116708,249522,21.0000,3968.0000
> fam0578,G578,fam6039,G6039,UN,NA,0.0000,0.0095,0.9905,0.9952,-1,0.998462,1.0000,4553.0000,1,1123,364629,1.0000,4553.0000"
> plink.genome <- read.csv(text=plink.genome)
>
> ibdlist <- "ID1,ID2,k0,k1,kinship
> G1000,G1001,1.0000000,0.00000000,0.000000000
> G1000,G1003,0.9938901,0.00000000,0.003054932
> G1241,G1245,1.0000000,0.00000000,0.000000000
> G1000,G1005,1.0000000,0.00000000,0.000000000
> G1079,G2484,0.9938901,0.00000000,0.003054932
> G1000,G1009,1.0000000,0.00000000,0.000000000"
> ibdlist <- read.csv(text=ibdlist)
>
> x <- paste(plink.genome$IID1, plink.genome$IID2)
> table <- paste(ibdlist$ID1, ibdlist$ID2)
> idx <- match(x=x, table=table)
> ibdlist[idx,"kinship"]
>
>
> Best,
> Rasmus


From jen@r@@mu@ @end|ng |rom gm@||@com  Sat Apr 11 02:01:15 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Sat, 11 Apr 2020 02:01:15 +0200
Subject: [R] matching doesn't work
In-Reply-To: <CAF9-5jME3zCJr6Bn5fwEibik5fVWrpqDNCLUb4X=dXgYXGpJUA@mail.gmail.com>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
 <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
 <20200410230321.GJ187643@jrl.uk.to>
 <CAF9-5jME3zCJr6Bn5fwEibik5fVWrpqDNCLUb4X=dXgYXGpJUA@mail.gmail.com>
Message-ID: <20200411000115.GA452264@jrl.uk.to>

On 2020-04-10 18:46 -0500, Ana Marija wrote:
> so if I understand correctly you would just remove sep=" " from my codes?
> 
> Thank you so much for working on this.
> Is there is any chance you can change my original code (pasted bellow)
> with changes you think should work?
> 
> library(SNPRelate)
> 
> # get PLINK output
> plink.genome <- read.table("plink.genome", header=TRUE)
> 
> snpgdsBED2GDS("output4.bed", "output4.fam","output4.bim", "HapMap.gds")
> genofile <- snpgdsOpen("HapMap.gds")
> 
> # get SNPRelate output
> ibd <- snpgdsIBDMoM(genofile, remove.monosnp=FALSE, kinship=TRUE)
> 
> # adjust for the orders of sample pair
> pair.samp <- paste(ibdlist$ID1, ibdlist$ID2, sep=" ")
> plink.genome <- plink.genome[match(
>     paste(plink.genome$IID1, plink.genome$IID2, sep=" "), pair.samp), ]

Yes, it seems like my tab separated values got converted to 
spaces ... so comma separated values seemed like a sane choice 
...

But ... I do not have all those specific files called here ... 
this seems very similar to what you had before ... what is it 
that does not work?  Do you get any errors here at all, or?


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Apr 11 02:05:32 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 10 Apr 2020 19:05:32 -0500
Subject: [R] matching doesn't work
In-Reply-To: <20200411000115.GA452264@jrl.uk.to>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
 <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
 <20200410230321.GJ187643@jrl.uk.to>
 <CAF9-5jME3zCJr6Bn5fwEibik5fVWrpqDNCLUb4X=dXgYXGpJUA@mail.gmail.com>
 <20200411000115.GA452264@jrl.uk.to>
Message-ID: <CAF9-5jOByR-vaT3ShY0vjrb0s1XUBGqdqKY_uBzZY8JQ3abfLg@mail.gmail.com>

I am not sure what I am suppose to run from your codes.
Can you just send me lines of codes which I should run? (without part
where you are loading your data frames)
(assuming my files are as I showed them)

Or the whole idea was to remove sep=" " from everywhere?

On Fri, Apr 10, 2020 at 7:01 PM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-10 18:46 -0500, Ana Marija wrote:
> > so if I understand correctly you would just remove sep=" " from my codes?
> >
> > Thank you so much for working on this.
> > Is there is any chance you can change my original code (pasted bellow)
> > with changes you think should work?
> >
> > library(SNPRelate)
> >
> > # get PLINK output
> > plink.genome <- read.table("plink.genome", header=TRUE)
> >
> > snpgdsBED2GDS("output4.bed", "output4.fam","output4.bim", "HapMap.gds")
> > genofile <- snpgdsOpen("HapMap.gds")
> >
> > # get SNPRelate output
> > ibd <- snpgdsIBDMoM(genofile, remove.monosnp=FALSE, kinship=TRUE)
> >
> > # adjust for the orders of sample pair
> > pair.samp <- paste(ibdlist$ID1, ibdlist$ID2, sep=" ")
> > plink.genome <- plink.genome[match(
> >     paste(plink.genome$IID1, plink.genome$IID2, sep=" "), pair.samp), ]
>
> Yes, it seems like my tab separated values got converted to
> spaces ... so comma separated values seemed like a sane choice
> ...
>
> But ... I do not have all those specific files called here ...
> this seems very similar to what you had before ... what is it
> that does not work?  Do you get any errors here at all, or?


From @n@ndmenon@12 @end|ng |rom gm@||@com  Sat Apr 11 05:33:41 2020
From: @n@ndmenon@12 @end|ng |rom gm@||@com (Anand Menon)
Date: Fri, 10 Apr 2020 23:33:41 -0400
Subject: [R] question about system.file()
In-Reply-To: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
Message-ID: <CAGmqtKjwfMWxkNxqHi-rzyzGa2n8-CCbq7z5=T3D0Q5hCngjHw@mail.gmail.com>

Hello, Could you please help unsubscribe me from these emails. Thank you.

Kind Regards,
Anand K Menon
Cell: 1-416-939-3671


On Fri, Apr 10, 2020 at 3:46 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I would like to try this example in this link:
>
> https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
>
> for example this line:
>
> bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")
>
> I have in current directory from where I would run this function a
> file named output4.bed
>
> in order to run the above, can I just run this:
> bed.fn <- system.file("output4.bed", package="SNPRelate")
>
> what is "extdata" ? Do I need it if my output4.bed is in the directory
> from where I am running this?
>
> Also do I need to have .gz format of output4.bed?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Apr 11 12:41:09 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 11 Apr 2020 11:41:09 +0100
Subject: [R] question about system.file()
In-Reply-To: <CAGmqtKjwfMWxkNxqHi-rzyzGa2n8-CCbq7z5=T3D0Q5hCngjHw@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
 <CAGmqtKjwfMWxkNxqHi-rzyzGa2n8-CCbq7z5=T3D0Q5hCngjHw@mail.gmail.com>
Message-ID: <f0627d3d-fbfd-a9ae-a661-f5f981fbb18f@sapo.pt>

Hello,

There are instructions to unsubscribe at the bottom of this e-mail and 
of every R-Help e-mail, see the all capital letters word.

Hope this helps,

Rui Barradas

?s 04:33 de 11/04/20, Anand Menon escreveu:
> Hello, Could you please help unsubscribe me from these emails. Thank you.
> 
> Kind Regards,
> Anand K Menon
> Cell: 1-416-939-3671
> 
> 
> On Fri, Apr 10, 2020 at 3:46 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> 
>> Hello,
>>
>> I would like to try this example in this link:
>>
>> https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
>>
>> for example this line:
>>
>> bed.fn <- system.file("extdata", "plinkhapmap.bed.gz", package="SNPRelate")
>>
>> I have in current directory from where I would run this function a
>> file named output4.bed
>>
>> in order to run the above, can I just run this:
>> bed.fn <- system.file("output4.bed", package="SNPRelate")
>>
>> what is "extdata" ? Do I need it if my output4.bed is in the directory
>> from where I am running this?
>>
>> Also do I need to have .gz format of output4.bed?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From t@n@@@ @end|ng |rom gm@||@com  Sat Apr 11 12:44:51 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 11 Apr 2020 03:44:51 -0700
Subject: [R] 2 docker containers with R ?
Message-ID: <CA+JEM019LpDXGfbfS-BOJfLuzo-8RjKr=AE-SdxSbXE66O4T+A@mail.gmail.com>

Dear all,

we wish everyone a safe and healthy time !

i'm looking forward to have you suggestions please : I am using a R package
that is called Seurat for scRNA-seq analysis (https://satijalab.org/seurat/)
that has two versions (version 2 or version3 with distinct functions);

i'd appreciate if you could please let me know how could I have Seurat2 and
Seurat3 on the same machine, and preferentially run either Seurat2 or
Seurat3 ? I believe that I could use 2 docker containers (how could install
R in 2 different containers ?), or is there another solution ? thanks a lot
!

-- bogdan

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Apr 11 13:16:29 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 11 Apr 2020 14:16:29 +0300
Subject: [R] 2 docker containers with R ?
In-Reply-To: <CA+JEM019LpDXGfbfS-BOJfLuzo-8RjKr=AE-SdxSbXE66O4T+A@mail.gmail.com>
References: <CA+JEM019LpDXGfbfS-BOJfLuzo-8RjKr=AE-SdxSbXE66O4T+A@mail.gmail.com>
Message-ID: <20200411141629.40d9aa8f@Tarkus>

On Sat, 11 Apr 2020 03:44:51 -0700
Bogdan Tanasa <tanasa at gmail.com> wrote:

> how could I have Seurat2 and Seurat3 on the same machine

What I would try first is to install Seurat2 and Seurat3 in separate
library directories: add the `lib` argument to install.packages when
installing a given version and `lib.loc` when loading it using
library().

While Docker is definitely able to solve this problem, in my opinion,
virtualising a whole operating system is overkill in this case.

-- 
Best regards,
Ivan


From @@h|mk@poor @end|ng |rom gm@||@com  Sat Apr 11 13:25:04 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Sat, 11 Apr 2020 16:55:04 +0530
Subject: [R] 2 docker containers with R ?
In-Reply-To: <20200411141629.40d9aa8f@Tarkus>
References: <CA+JEM019LpDXGfbfS-BOJfLuzo-8RjKr=AE-SdxSbXE66O4T+A@mail.gmail.com>
 <20200411141629.40d9aa8f@Tarkus>
Message-ID: <CAC8=1eosbeZRtFP6No_64Evc1nsnB0ESojyeK9vz1V9vs4G-=w@mail.gmail.com>

Dear Bogdan,

Perhaps

https://rstudio.github.io/packrat/

can be of help?

Best,
Ashim

On Sat, Apr 11, 2020 at 4:47 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:

> On Sat, 11 Apr 2020 03:44:51 -0700
> Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> > how could I have Seurat2 and Seurat3 on the same machine
>
> What I would try first is to install Seurat2 and Seurat3 in separate
> library directories: add the `lib` argument to install.packages when
> installing a given version and `lib.loc` when loading it using
> library().
>
> While Docker is definitely able to solve this problem, in my opinion,
> virtualising a whole operating system is overkill in this case.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 11 14:43:08 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 11 Apr 2020 05:43:08 -0700
Subject: [R] question about system.file()
In-Reply-To: <CAGmqtKjwfMWxkNxqHi-rzyzGa2n8-CCbq7z5=T3D0Q5hCngjHw@mail.gmail.com>
References: <CAF9-5jOyu_d9=MTWtdxrfuS3+txEfzet_cR7E4hvCNHKT-jyJg@mail.gmail.com>
 <CAGmqtKjwfMWxkNxqHi-rzyzGa2n8-CCbq7z5=T3D0Q5hCngjHw@mail.gmail.com>
Message-ID: <DAFAE256-722A-4151-8C0E-23EA17420210@dcn.davis.ca.us>

Only you have the power to solve your problem. Follow the instructions in the footer of any R-help email.

On April 10, 2020 8:33:41 PM PDT, Anand Menon <anandmenon.12 at gmail.com> wrote:
>Hello, Could you please help unsubscribe me from these emails. Thank
>you.
>
>Kind Regards,
>Anand K Menon
>Cell: 1-416-939-3671
>
>
>On Fri, Apr 10, 2020 at 3:46 PM Ana Marija
><sokovic.anamarija at gmail.com>
>wrote:
>
>> Hello,
>>
>> I would like to try this example in this link:
>>
>>
>https://www.rdocumentation.org/packages/SNPRelate/versions/1.6.4/topics/snpgdsBED2GDS
>>
>> for example this line:
>>
>> bed.fn <- system.file("extdata", "plinkhapmap.bed.gz",
>package="SNPRelate")
>>
>> I have in current directory from where I would run this function a
>> file named output4.bed
>>
>> in order to run the above, can I just run this:
>> bed.fn <- system.file("output4.bed", package="SNPRelate")
>>
>> what is "extdata" ? Do I need it if my output4.bed is in the
>directory
>> from where I am running this?
>>
>> Also do I need to have .gz format of output4.bed?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Apr 11 16:00:21 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 11 Apr 2020 14:00:21 +0000 (UTC)
Subject: [R] Add Gauss normal curve ?
References: <560631430.7107376.1586613621651.ref@mail.yahoo.com>
Message-ID: <560631430.7107376.1586613621651@mail.yahoo.com>

Dear R-experts,

Here below my reproducible example. I would like to fit/add the Gauss normal curve to this data. 
I don't get it. There is no error message but I don't get what I am looking for. 
Many thanks for your help.

############################################################
mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))

nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)

plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))

x <- seq(min(mydates), max(mydates), 0.1) 

curve(dnorm(x, mean(nc), sd(nc)), add=TRUE, col="red", lwd=2)
############################################################


From jen@r@@mu@ @end|ng |rom gm@||@com  Sat Apr 11 16:51:22 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Sat, 11 Apr 2020 16:51:22 +0200
Subject: [R] matching doesn't work
In-Reply-To: <CAF9-5jOByR-vaT3ShY0vjrb0s1XUBGqdqKY_uBzZY8JQ3abfLg@mail.gmail.com>
References: <CAF9-5jNcj0F4=kp-DfoU-VMkQuBC_dDCj_taLQ8vb2dhG5ic1w@mail.gmail.com>
 <20200410212416.GI187643@jrl.uk.to>
 <CAF9-5jN5Kd91_oaSPQ7-sqtZg19kPDr35A-tPVpZTZAsi7_igg@mail.gmail.com>
 <20200410230321.GJ187643@jrl.uk.to>
 <CAF9-5jME3zCJr6Bn5fwEibik5fVWrpqDNCLUb4X=dXgYXGpJUA@mail.gmail.com>
 <20200411000115.GA452264@jrl.uk.to>
 <CAF9-5jOByR-vaT3ShY0vjrb0s1XUBGqdqKY_uBzZY8JQ3abfLg@mail.gmail.com>
Message-ID: <20200411145122.GK187643@jrl.uk.to>

On 2020-04-10 19:05 -0500, Ana Marija wrote:
> I am not sure what I am suppose to run 
> from your codes.  Can you just send me 
> lines of codes which I should run? 
> (without part where you are loading 
> your data frames) (assuming my files 
> are as I showed them)

Dear Ana,

try these lines:


plink.genome <-
  read.table("plink.genome", header=TRUE)
SNPRelate::snpgdsBED2GDS(
  "output4.bed",
  "output4.fam",
  "output4.bim",
  "HapMap.gds")
genofile <-
  SNPRelate::snpgdsOpen("HapMap.gds")
ibd <- SNPRelate::snpgdsIBDMoM(
  genofile,
  remove.monosnp=FALSE,
  kinship=TRUE)
x <- paste(plink.genome$IID1,
           plink.genome$IID2)
table <- paste(ibd$ID1, ibd$ID2)
idx <- match(x=x, table=table)
plink.genome[idx,]


Best,
Rasmus


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Apr 11 17:00:45 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 11 Apr 2020 08:00:45 -0700
Subject: [R] Add Gauss normal curve ?
In-Reply-To: <560631430.7107376.1586613621651@mail.yahoo.com>
References: <560631430.7107376.1586613621651.ref@mail.yahoo.com>
 <560631430.7107376.1586613621651@mail.yahoo.com>
Message-ID: <44feecb3-1e4f-ca45-d04e-1563f172ace3@comcast.net>


On 4/11/20 7:00 AM, varin sacha via R-help wrote:
> Dear R-experts,
>
> Here below my reproducible example. I would like to fit/add the Gauss normal curve to this data.
> I don't get it. There is no error message but I don't get what I am looking for.
> Many thanks for your help.
>
> ############################################################
> mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))
>
> nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)
>
> plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))
>
> x <- seq(min(mydates), max(mydates), 0.1)
>
> curve(dnorm(x, mean(nc), sd(nc)), add=TRUE, col="red", lwd=2)


(I infer) The values in the `nc` vector are not taken from observations 
that are interpretable as independent sampling from a continuous random 
vector. They are counts, i.e. "new cases".


Furthermore, the "x" value in your plot is not the `nc` vector but 
rather it is the the ""y"-vector, so even if it were appropriate to use 
a Normal curve for fitting you would need to take the `nc` vector as 
corresponding to a density along the time axis.

You could probably do as well by "eyeballing" where you want the 
"normal" curve to sit, since there would be no theoretical support for 
more refined curve fitting efforts. You might also need to scale the 
density values so they would appear as something other than a flat line.

And the `curve` function does need an expression but it would be 
plotting that result far to the left of your current plotting range 
which is set by the integer values of those dates, i.e values in the 
tens of thousands. Use the `lines` function for better control.


lines( x= as.numeric(mydates),

 ? ? ? ? ? ? ? ? ? # 3000 was eyeball guess as to a scaling factor that 
might work

 ????????????????? # but needed a larger number to make the curves 
commensurate

 ?????? y=10000* dnorm( x= as.numeric(mydates),? #set a proper x scale

 ??????????????? ? ? ?? mean= as.numeric( mydates[ which.max(nc) ]),? 
#use location of max

 ???????????????? ? ? ? sd= 7) )


Might need to use smaller value for the "standard deviation" and higher 
scaling factor to improve the eyeball fit.You might like a value of 
sd=4, but it would remain an unsupportable effort from a statistical 
viewpoint.



-- 

David

> ############################################################
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Sat Apr 11 17:02:33 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 11 Apr 2020 17:02:33 +0200
Subject: [R] Add Gauss normal curve ?
In-Reply-To: <560631430.7107376.1586613621651@mail.yahoo.com>
References: <560631430.7107376.1586613621651.ref@mail.yahoo.com>
 <560631430.7107376.1586613621651@mail.yahoo.com>
Message-ID: <DD5E081F-BC95-4928-91F9-10D34EC401DC@gmail.com>

Two obvious problems: 

1. mean(nc) is a count, not a date, sd likewise
2. the scale of dnorm() is density, not count

So (slightly inefficient, but who cares...):

y <- rep(mydates, nc)
n <- sum(nc)
curve(n*dnorm(x, mean(y), sd(y)), add=TRUE, col="red", lwd=2)

-pd

> On 11 Apr 2020, at 16:00 , varin sacha via R-help <r-help at r-project.org> wrote:
> 
> Dear R-experts,
> 
> Here below my reproducible example. I would like to fit/add the Gauss normal curve to this data. 
> I don't get it. There is no error message but I don't get what I am looking for. 
> Many thanks for your help.
> 
> ############################################################
> mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))
> 
> nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)
> 
> plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))
> 
> x <- seq(min(mydates), max(mydates), 0.1) 
> 
> curve(dnorm(x, mean(nc), sd(nc)), add=TRUE, col="red", lwd=2)
> ############################################################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Apr 11 17:36:41 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 11 Apr 2020 15:36:41 +0000 (UTC)
Subject: [R] Add Gauss normal curve ?
In-Reply-To: <DD5E081F-BC95-4928-91F9-10D34EC401DC@gmail.com>
References: <560631430.7107376.1586613621651.ref@mail.yahoo.com>
 <560631430.7107376.1586613621651@mail.yahoo.com>
 <DD5E081F-BC95-4928-91F9-10D34EC401DC@gmail.com>
Message-ID: <1023087292.7101722.1586619401718@mail.yahoo.com>

Dear Peter, 
Dear David,

Many thanks for your response. 
Indeed, counts do not have a Gaussian distribution, even if.... sometimes one approximates the distribution by a Gaussian one, usually using the argument of the Central Limit Theorem.

Here below the reproducible example. 
One last thing. Now if I want to move my red Gaussian curve to the right or to the left, for example on the graph I can see that the Gaussian curve is centered around the 5th of April.

Is it possible to move the Gaussian curve to make the center of the Gaussian curve on the 30th of March for example ? If yes, how to do ?

############################################################
mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))

nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)

plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))

y <- rep(mydates, nc)
n <- sum(nc)
curve(n*dnorm(x, mean(y), sd(y)), add=TRUE, col="red", lwd=2)
############################################################







Le samedi 11 avril 2020 ? 17:02:36 UTC+2, peter dalgaard <pdalgd at gmail.com> a ?crit : 





Two obvious problems: 

1. mean(nc) is a count, not a date, sd likewise
2. the scale of dnorm() is density, not count

So (slightly inefficient, but who cares...):

y <- rep(mydates, nc)
n <- sum(nc)
curve(n*dnorm(x, mean(y), sd(y)), add=TRUE, col="red", lwd=2)

-pd

> On 11 Apr 2020, at 16:00 , varin sacha via R-help <r-help at r-project.org> wrote:
> 
> Dear R-experts,
> 
> Here below my reproducible example. I would like to fit/add the Gauss normal curve to this data. 
> I don't get it. There is no error message but I don't get what I am looking for. 
> Many thanks for your help.
> 
> ############################################################
> mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))
> 
> nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)
> 
> plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))
> 
> x <- seq(min(mydates), max(mydates), 0.1) 
> 
> curve(dnorm(x, mean(nc), sd(nc)), add=TRUE, col="red", lwd=2)
> ############################################################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Apr 11 20:09:07 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 11 Apr 2020 20:09:07 +0200
Subject: [R] 
 Having trouble understanding the sapply/vapply documentation
 and behaviour of USE.NAMES
In-Reply-To: <4b61dc7f-b5e2-dcc8-a44d-9a581a5de5ff@auckland.ac.nz>
References: <CABAj7xcXm=NaApNSPtym8ajha9BRmZ5FMxAgc=FFHi5fP8FvLA@mail.gmail.com>
 <4b61dc7f-b5e2-dcc8-a44d-9a581a5de5ff@auckland.ac.nz>
Message-ID: <24210.1987.386863.744269@stat.math.ethz.ch>

>>>>> Rolf Turner 
>>>>>     on Fri, 10 Apr 2020 12:23:49 +1200 writes:

    > On 10/04/20 10:59 am, petr smirnov wrote:

    >> I am having trouble parsing the documentation for sapply
    >> and vapply, and I cannot understand if it explains the
    >> different behaviour of USE.NAMES between the two.
    >> 
    >> I noticed the following different behaviour between the
    >> two functions:
    >> 
    >>> sapply(c("1"=1, "2"=2, "3"=3), function(x) {r <-
    >>> list(x); r}, USE.NAMES=FALSE)
    >> $`1` [1] 1
    >> 
    >> $`2` [1] 2
    >> 
    >> $`3` [1] 3
    >> 
    >>> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <-
    >>> list(x); r}, FUN.VALUE=list(1), USE.NAMES=FALSE)
    >> [[1]] [1] 1
    >> 
    >> [[2]] [1] 2
    >> 
    >> [[3]] [1] 3
    >> 
    >> In the sapply case, the names of the input vector are
    >> retained. In the vapply case, they are dropped. Note that
    >> this is not true when USE.NAMES=TRUE:
    >> 
    >>> vapply(c("1"=1, "2"=2, "3"=3), function(x) { r <-
    >>> list(x); r}, FUN.VALUE=list(1), USE.NAMES=TRUE)
    >> $`1` [1] 1
    >> 
    >> $`2` [1] 2
    >> 
    >> $`3` [1] 3
    >> 
    >> The manual page explains this for the names of the result
    >> of vapply:
    >> 
    >> The (Dim)names of the array value are taken from the
    >> FUN.VALUE if it is named, otherwise from the result of
    >> the first function call. Column names of the matrix or
    >> more generally the names of the last dimension of the
    >> array value or names of the vector value are set from X
    >> as in sapply.
    >> 
    >> If this explains the behaviour, could someone break it
    >> down for me and help me understand the reasoning?

1) sapply() exists longer than R  with the current semantic:

  If the original list (or named vector or..) already *has* 'names',
  they are not explicitly removed, and so  USE.NAMES has no
  effect for sapply().

  This is "logical" if you think what sapply() had been created
  for:  sapply(..) := "simplified lapply(..)"
  and then it got the *new* option to *add* names when there
  were none in the original lapply() result:

 The very first paragraph on the help page where 'sapply' is
 mentioned reads (with line breaks modified to be even clearer here) :

    'sapply' is a user-friendly version and wrapper of 'lapply' by
    default returning a vector, matrix or, if 'simplify = "array"', an
    array if appropriate, by applying 'simplify2array()'.  
    'sapply(x, f, simplify = FALSE, USE.NAMES = FALSE)'   is the same as
    'lapply(x, f)'.

 From this alone (and some thinking about reasonable lapply() semantics)
 it's easy to conclude that indeed  sapply(*, USE.NAMES=FALSE)
 should *not* remove names that were there already after lapply().

 {One possibility would be to allow a new *third* option for
  USE.NAMES, say  USE.NAMES="never" .. but I'd tend to consider
  that superfluous and hence just an unnecessary complication}

2) vapply()  had been proposed and introduced about two
   decennia after sapply() [had been introduced into S, R's precursor].

   For that, it's implementor must have chosen to use
   'USE.NAMES' more intuitively... and in that case, it also
   makes a *lot* of sense implementation wise, because vapply()
   does *not* go via lapply().

    >> Otherwise, is this different behaviour intentional?

yes, see above.


    >> Should it be documented more clearly?

If both you and Rolf find the current help page confusing about
this, I'd  agree that it probably could be improved.
Improvement is not easy so:  As we observe help pages are very
very rarely read carefully nowadays (not even by you in this
case (!), see below),  so it's not entirely obvious if adding
verbosity to an existing help page is any improvement.

    > IMHO there is an error in the documentation here.  Clearly
    > USE.NAMES has a different impact on vapply() than it has
    > on sapply() and the documentation does not indicate this,
    > in fact quite the opposite.

Strictly speaking, that is not true; there is *NO* error:
The documentation never explicitly says what happens with USE.NAMES=FALSE,
whereas it clearly and correctly specifies the effect of  USE.NAMES=TRUE,
and everything it says is correct (and as mentioned initially,
it notably indirectly specifies that sapply(*, USE.NAMES=FALSE)
would *not* remove existing names.

  [....]

    > cheers,
    > Rolf Turner
n
    > -- 
    > Honorary Research Fellow Department of Statistics
    > University of Auckland Phone: +64-9-373-7599 ext. 88276


From djnord|und @end|ng |rom gm@||@com  Sat Apr 11 20:37:37 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sat, 11 Apr 2020 11:37:37 -0700
Subject: [R] Add Gauss normal curve ?
In-Reply-To: <1023087292.7101722.1586619401718@mail.yahoo.com>
References: <560631430.7107376.1586613621651.ref@mail.yahoo.com>
 <560631430.7107376.1586613621651@mail.yahoo.com>
 <DD5E081F-BC95-4928-91F9-10D34EC401DC@gmail.com>
 <1023087292.7101722.1586619401718@mail.yahoo.com>
Message-ID: <797a8ee8-142f-12f0-ad50-7b0f5663b282@gmail.com>

Just replace 'mean(y)' in your curve() function with 
as.Date("whatever-date")

curve(n*dnorm(x, as.Date("2020-03-30"), sd(y)), add=TRUE, col="red", lwd=2)

Dan

On 4/11/2020 8:36 AM, varin sacha via R-help wrote:
> Dear Peter,
> Dear David,
>
> Many thanks for your response.
> Indeed, counts do not have a Gaussian distribution, even if.... sometimes one approximates the distribution by a Gaussian one, usually using the argument of the Central Limit Theorem.
>
> Here below the reproducible example.
> One last thing. Now if I want to move my red Gaussian curve to the right or to the left, for example on the graph I can see that the Gaussian curve is centered around the 5th of April.
>
> Is it possible to move the Gaussian curve to make the center of the Gaussian curve on the 30th of March for example ? If yes, how to do ?
>
> ############################################################
> mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))
>
> nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)
>
> plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))
>
> y <- rep(mydates, nc)
> n <- sum(nc)
> curve(n*dnorm(x, mean(y), sd(y)), add=TRUE, col="red", lwd=2)
> ############################################################
>
>
>
>
>
>
>
> Le samedi 11 avril 2020 ? 17:02:36 UTC+2, peter dalgaard <pdalgd at gmail.com> a ?crit :
>
>
>
>
>
> Two obvious problems:
>
> 1. mean(nc) is a count, not a date, sd likewise
> 2. the scale of dnorm() is density, not count
>
> So (slightly inefficient, but who cares...):
>
> y <- rep(mydates, nc)
> n <- sum(nc)
> curve(n*dnorm(x, mean(y), sd(y)), add=TRUE, col="red", lwd=2)
>
> -pd
>
>> On 11 Apr 2020, at 16:00 , varin sacha via R-help <r-help at r-project.org> wrote:
>>
>> Dear R-experts,
>>
>> Here below my reproducible example. I would like to fit/add the Gauss normal curve to this data.
>> I don't get it. There is no error message but I don't get what I am looking for.
>> Many thanks for your help.
>>
>> ############################################################
>> mydates <- as.Date(c("2020-03-15", "2020-03-16","2020-03-17","2020-03-18","2020-03-19","2020-03-20","2020-03-21","2020-03-22","2020-03-23","2020-03-24","2020-03-25","2020-03-26","2020-03-27","2020-03-28","2020-03-29","2020-03-30","2020-03-31","2020-04-01","2020-04-02","2020-04-03","2020-04-04","2020-04-05","2020-04-06","2020-04-07","2020-04-08","2020-04-09","2020-04-10"))
>>
>> nc<-c(1,1,2,7,3,6,6,20,17,46,67,71,56,70,85,93,301,339,325,226,608,546,1069,1264,1340,813,608)
>>
>> plot(as.Date(mydates),nc,pch=16,type="o",col="blue",ylim=c(1,1400), xlim=c(min(as.Date(mydates)),max(as.Date(mydates))))
>>
>> x <- seq(min(mydates), max(mydates), 0.1)
>>
>> curve(dnorm(x, mean(nc), sd(nc)), add=TRUE, col="red", lwd=2)
>> ############################################################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Daniel Nordlund
Port Townsend, WA  USA


From g|ennm@chu|tz @end|ng |rom me@com  Sat Apr 11 15:52:54 2020
From: g|ennm@chu|tz @end|ng |rom me@com (Glenn Schultz)
Date: Sat, 11 Apr 2020 13:52:54 -0000
Subject: [R] setting serialization
Message-ID: <323f5cc7-88e5-46da-aa17-b4a68f360549@me.com>

All,

I have a set up as shown below. ?Everything works fine but the new serialization default is 3, I would like it to serialize to version = 2. ?I've tried a couple of different ways to set version and googled around but so far I've had no luck. ?The package builds fine but then sets dependency to R(>= 3.5.0) this no backward compatibility. ?Actually, I don't mind this personally but is there a way with the below set-up to avoid this?

Best,
Glenn

zzz.r file as below
???????.onAttach <- function(libname, pkgname){
??????packageStartupMessage(
??????"Bond Lab is a registered trademark of Bond Lab Technologies.")
??????BondLabSetUp()
??????}

A file in my inst directory with functions that I serialize on load an example of which is below.
?????????Scenario(
?????????Name = "NCs",
?????????Type = "Immediate",
?????????ShiftType = "Parallel",
?????????Shiftbps = "0",
?????????Formula = function(rates.data = vector(), Shiftbps = "character"){
?????????yield.basis = 100
?????????pmax(0.01, as.numeric(rates.data) + (as.numeric(Shiftbps)/yield.basis))
?????????})

A .R file?BondLabSetUp.R #' Setup function for the R package BondLab to create the needed objects
#' 
#' @export
BondLabSetUp <- function(){

do.call(source, 
list(file = paste(system.file(package = "BondLab"), 
"/Scenario/Scenario_SpotCurve", sep = ""),
local = TRUE))


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Apr 12 03:04:48 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 12 Apr 2020 13:04:48 +1200
Subject: [R] 
 Having trouble understanding the sapply/vapply documentation
 and behaviour of USE.NAMES
In-Reply-To: <24210.1987.386863.744269@stat.math.ethz.ch>
References: <CABAj7xcXm=NaApNSPtym8ajha9BRmZ5FMxAgc=FFHi5fP8FvLA@mail.gmail.com>
 <4b61dc7f-b5e2-dcc8-a44d-9a581a5de5ff@auckland.ac.nz>
 <24210.1987.386863.744269@stat.math.ethz.ch>
Message-ID: <54ce7d6b-c320-50b9-38f3-c18df214f9f0@auckland.ac.nz>


On 12/04/20 6:09 am, Martin Maechler wrote:

>>>>>> Rolf Turner
>>>>>>      on Fri, 10 Apr 2020 12:23:49 +1200 writes:

<SNIP>

> 
>      > IMHO there is an error in the documentation here.  Clearly
>      > USE.NAMES has a different impact on vapply() than it has
>      > on sapply() and the documentation does not indicate this,
>      > in fact quite the opposite.
> 
> Strictly speaking, that is not true; there is *NO* error:
> The documentation never explicitly says what happens with USE.NAMES=FALSE,
> whereas it clearly and correctly specifies the effect of  USE.NAMES=TRUE,
> and everything it says is correct (and as mentioned initially,
> it notably indirectly specifies that sapply(*, USE.NAMES=FALSE)
> would *not* remove existing names.

<SNIP>

This reminds me slightly of fortunes::fortune(313). :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From t@n@@@ @end|ng |rom gm@||@com  Sun Apr 12 04:06:21 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Sat, 11 Apr 2020 19:06:21 -0700
Subject: [R] 2 docker containers with R ?
In-Reply-To: <CAC8=1eosbeZRtFP6No_64Evc1nsnB0ESojyeK9vz1V9vs4G-=w@mail.gmail.com>
References: <CA+JEM019LpDXGfbfS-BOJfLuzo-8RjKr=AE-SdxSbXE66O4T+A@mail.gmail.com>
 <20200411141629.40d9aa8f@Tarkus>
 <CAC8=1eosbeZRtFP6No_64Evc1nsnB0ESojyeK9vz1V9vs4G-=w@mail.gmail.com>
Message-ID: <CA+JEM00Gydo_U0J-xHrM-q2eZDMtccQQig1eqv0jYPTzs+aD5w@mail.gmail.com>

thanks a lot, Ashim, and Ivan !

On Sat, Apr 11, 2020 at 4:25 AM Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Bogdan,
>
> Perhaps
>
> https://rstudio.github.io/packrat/
>
> can be of help?
>
> Best,
> Ashim
>
> On Sat, Apr 11, 2020 at 4:47 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
>> On Sat, 11 Apr 2020 03:44:51 -0700
>> Bogdan Tanasa <tanasa at gmail.com> wrote:
>>
>> > how could I have Seurat2 and Seurat3 on the same machine
>>
>> What I would try first is to install Seurat2 and Seurat3 in separate
>> library directories: add the `lib` argument to install.packages when
>> installing a given version and `lib.loc` when loading it using
>> library().
>>
>> While Docker is definitely able to solve this problem, in my opinion,
>> virtualising a whole operating system is overkill in this case.
>>
>> --
>> Best regards,
>> Ivan
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From jte||er|@@rproject @end|ng |rom gm@||@com  Sun Apr 12 17:04:28 2020
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Sun, 12 Apr 2020 17:04:28 +0200
Subject: [R] Learning Shinny
In-Reply-To: <CAPEb7FQ=3cWiNh=Ee_FAFozC-OE0YX_YeRcY+xy59faoNKHOcQ@mail.gmail.com>
References: <CAPEb7FQ=3cWiNh=Ee_FAFozC-OE0YX_YeRcY+xy59faoNKHOcQ@mail.gmail.com>
Message-ID: <CAJXDcw2ieAut2Qx=KPzL1wz6h8aDB9X+JVdnzkBjg=QN5YoA7g@mail.gmail.com>

You could use the following rmarkdown book, with last chapter debited to
shiny :)

https://bookdown.org/yihui/rmarkdown/

El jueves, 9 de abril de 2020, Kumar t <rlanguage22 at gmail.com> escribi?:

> Hello all ,
>
> Very sorry to ask you question that might have been answered earlier . I
> could not able to find right answer .
>
> My requirement is get decent level of proficiency  in the R-Shiny . Is
> there path ( I mean do I need to have knowledge of Dplyr to get data in
> right format )  that I need to follow . Any good references to  papers  or
> books or online resources .
>
> I am new learner to R language .
>
> Thanks
> Phani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr 12 17:20:38 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 12 Apr 2020 08:20:38 -0700
Subject: [R] Learning Shinny
In-Reply-To: <CAPEb7FQ=3cWiNh=Ee_FAFozC-OE0YX_YeRcY+xy59faoNKHOcQ@mail.gmail.com>
References: <CAPEb7FQ=3cWiNh=Ee_FAFozC-OE0YX_YeRcY+xy59faoNKHOcQ@mail.gmail.com>
Message-ID: <9302B10A-2576-4EFB-A209-CB2C4AB3A5C5@dcn.davis.ca.us>

Your best bet is to become proficient in R. The dplyr contributed package is _not_ a requirement, though you may also find it useful. Shiny is a way to run R interactively, so if you have nothing you know how to _do_ with R then Shiny won't be very useful.

But you should also read the Posting Guide... this mailing list is about R language, and Shiny is a contributed package that is not technically on-topic here. The Shiny package README [1] directs you to the RStudio forum for questions about Shiny.

[1] https://cran.r-project.org/web/packages/shiny/readme/README.html

On April 9, 2020 2:42:06 PM PDT, Kumar t <rlanguage22 at gmail.com> wrote:
>Hello all ,
>
>Very sorry to ask you question that might have been answered earlier .
>I
>could not able to find right answer .
>
>My requirement is get decent level of proficiency  in the R-Shiny . Is
>there path ( I mean do I need to have knowledge of Dplyr to get data in
>right format )  that I need to follow . Any good references to  papers 
>or
>books or online resources .
>
>I am new learner to R language .
>
>Thanks
>Phani
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Sun Apr 12 21:06:29 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Sun, 12 Apr 2020 21:06:29 +0200
Subject: [R] About bootstrap validation method
Message-ID: <CA+nrPnvmO_NUkcORwrv19TSvysXhYUh3ksWiGYrOzOaZEfGbxw@mail.gmail.com>

If we have to perform 100 iterations of the out-of-sample bootstrap, do we
need to just enter the number 100 as:

trainControl (method="boot", number = 100)

Regards

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 13 01:30:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 12 Apr 2020 16:30:09 -0700
Subject: [R] A stopifnot() nastiness, even if not a bug
Message-ID: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>

Don't know if this has come up before, but ...

> x <- c(0,0)
> length(x)
[1] 2
## but
> stopifnot(length(x))
Error: length(x) is not TRUE
Called from: top level
## but
> stopifnot(length(x) > 0)  ## not an error;  nor is
> stopifnot(as.logical(length(x)))
## Ouch!

Maybe the man page should say something about not assuming automatic
coercion to logical, which is the usual expectation. Or fix this.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Apr 13 11:15:54 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 13 Apr 2020 11:15:54 +0200
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
Message-ID: <24212.11722.632757.269523@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Sun, 12 Apr 2020 16:30:09 -0700 writes:

    > Don't know if this has come up before, but ...
    >> x <- c(0,0)
    >> length(x)
    > [1] 2
    > ## but
    >> stopifnot(length(x))
    > Error: length(x) is not TRUE
    > Called from: top level
    > ## but
    >> stopifnot(length(x) > 0)  ## not an error;  nor is
    >> stopifnot(as.logical(length(x)))
    > ## Ouch!

    > Maybe the man page should say something about not assuming automatic
    > coercion to logical, which is the usual expectation. Or fix this.

    > Bert Gunter

Well, what about the top most paragraph of the help page is not clear here ?

> Description:

>      If any of the expressions (in '...' or 'exprs') are not 'all'
>      'TRUE', 'stop' is called, producing an error message indicating
>      the _first_ expression which was not ('all') true.

If useR's expectations alone would guide the behavior of a
computer language, the language would have to behave
"personalized" and give different results depending on the user,
which may be desirable in medicine or psychotherapy but not with R.

Martin


From pd@|gd @end|ng |rom gm@||@com  Mon Apr 13 12:00:38 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 13 Apr 2020 12:00:38 +0200
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <24212.11722.632757.269523@stat.math.ethz.ch>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
Message-ID: <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>

Inline...

> On 13 Apr 2020, at 11:15 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Bert Gunter 
>>>>>>    on Sun, 12 Apr 2020 16:30:09 -0700 writes:
> 
>> Don't know if this has come up before, but ...
>>> x <- c(0,0)
>>> length(x)
>> [1] 2
>> ## but
>>> stopifnot(length(x))
>> Error: length(x) is not TRUE
>> Called from: top level
>> ## but
>>> stopifnot(length(x) > 0)  ## not an error;  nor is
>>> stopifnot(as.logical(length(x)))
>> ## Ouch!
> 
>> Maybe the man page should say something about not assuming automatic
>> coercion to logical, which is the usual expectation. Or fix this.
> 
>> Bert Gunter
> 
> Well, what about the top most paragraph of the help page is not clear here ?
> 
>> Description:
> 
>>     If any of the expressions (in '...' or 'exprs') are not 'all'
>>     'TRUE', 'stop' is called, producing an error message indicating
>>     the _first_ expression which was not ('all') true.
> 

This, however, is somewhat less clear:

..., exprs: any number of (typically but not necessarily ?logical?) R
          expressions, which should each evaluate to (a logical vector
          of all) ?TRUE?.  Use _either_ ?...? _or_ ?exprs?, the latter
   
What does it mean, "typically but not necessarily ?logical?"? The code actually tests explicitly with is.logical, as far as I can tell.

This creates a discrepancy between if(!...)stop(...) and stopifnot(), as in

> f <- function (x) if (!x) stop(paste(deparse(substitute(x)), "is not TRUE"))
> f(0)
Error in f(0) : 0 is not TRUE
> f(1)
> stopifnot(0)
Error: 0 is not TRUE
> stopifnot(1)
Error: 1 is not TRUE

-pd


> If useR's expectations alone would guide the behavior of a
> computer language, the language would have to behave
> "personalized" and give different results depending on the user,
> which may be desirable in medicine or psychotherapy but not with R.
> 
> Martin
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Apr 13 14:30:18 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 13 Apr 2020 14:30:18 +0200
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
Message-ID: <24212.23386.542411.93591@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Mon, 13 Apr 2020 12:00:38 +0200 writes:

    > Inline...
    >> On 13 Apr 2020, at 11:15 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >> 
    >>>>>>> Bert Gunter 
    >>>>>>> on Sun, 12 Apr 2020 16:30:09 -0700 writes:
    >> 
    >>> Don't know if this has come up before, but ...
    >>>> x <- c(0,0)
    >>>> length(x)
    >>> [1] 2
    >>> ## but
    >>>> stopifnot(length(x))
    >>> Error: length(x) is not TRUE
    >>> Called from: top level
    >>> ## but
    >>>> stopifnot(length(x) > 0)  ## not an error;  nor is
    >>>> stopifnot(as.logical(length(x)))
    >>> ## Ouch!
    >> 
    >>> Maybe the man page should say something about not assuming automatic
    >>> coercion to logical, which is the usual expectation. Or fix this.
    >> 
    >>> Bert Gunter
    >> 
    >> Well, what about the top most paragraph of the help page is not clear here ?
    >> 
    >>> Description:
    >> 
    >>> If any of the expressions (in '...' or 'exprs') are not 'all'
    >>> 'TRUE', 'stop' is called, producing an error message indicating
    >>> the _first_ expression which was not ('all') true.
    >> 

    > This, however, is somewhat less clear:

    > ..., exprs: any number of (typically but not necessarily ?logical?) R
    > expressions, which should each evaluate to (a logical vector
    > of all) ?TRUE?.  Use _either_ ?...? _or_ ?exprs?, the latter
   
    > What does it mean, "typically but not necessarily ?logical?"? 

That's a good question: The '(....)' must have been put there a while ago.
I agree that it's not at all helpful. Strictly, we are really
dealing with unevaluated expressions anyway ("promises"), but
definitely all of them must evaluate to logical (vector or
array..) of all TRUE values.  In the very beginning of
stopifnot(), I had thought that it should also work in other
cases, e.g.,  for    Matrix(TRUE, 4,5)  {from the Matrix package} etc,
but several use cases had convinced us / me that stopifnot
should be stricter...

    > The code actually tests explicitly with is.logical, as far as I can tell.

    > This creates a discrepancy between if(!...)stop(...) and stopifnot(), 

yes indeed, on purpose now, for a very long time ...

There's another discrepancy, more dangerous I think,
as shown in the following
{Note this discrepancy has been noted for a long time .. also on
 this R-devel list} :

  m <- matrix(1:12, 3,4)
  i <- (1:4) %% 2 == 1  & (0:3) %% 5 == 0

  stopifnot(dim(m[,i]) == c(3,1))       # seems fine
  
  if(dim(m[,i]) != c(3,1)) stop("wrong dim") # gives an error (but not ..)


Martin

    >> as in
    >> f <- function (x) if (!x) stop(paste(deparse(substitute(x)), "is not TRUE"))
    >> f(0)
    > Error in f(0) : 0 is not TRUE
    >> f(1)
    >> stopifnot(0)
    > Error: 0 is not TRUE
    >> stopifnot(1)
    > Error: 1 is not TRUE

    > -pd


    >> If useR's expectations alone would guide the behavior of a
    >> computer language, the language would have to behave
    >> "personalized" and give different results depending on the user,
    >> which may be desirable in medicine or psychotherapy but not with R.
    >> 
    >> Martin
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > -- 
    > Peter Dalgaard, Professor,
    > Center for Statistics, Copenhagen Business School
    > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    > Phone: (+45)38153501
    > Office: A 4.23
    > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hp@ge@ @end|ng |rom |redhutch@org  Mon Apr 13 18:27:37 2020
From: hp@ge@ @end|ng |rom |redhutch@org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Mon, 13 Apr 2020 09:27:37 -0700
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <24212.23386.542411.93591@stat.math.ethz.ch>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
Message-ID: <93676b28-7b79-b70e-f2e4-1f1527fb80e6@fredhutch.org>



On 4/13/20 05:30, Martin Maechler wrote:
>>>>>> peter dalgaard
>>>>>>      on Mon, 13 Apr 2020 12:00:38 +0200 writes:
> 
>      > Inline...
>      >> On 13 Apr 2020, at 11:15 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>      >>
>      >>>>>>> Bert Gunter
>      >>>>>>> on Sun, 12 Apr 2020 16:30:09 -0700 writes:
>      >>
>      >>> Don't know if this has come up before, but ...
>      >>>> x <- c(0,0)
>      >>>> length(x)
>      >>> [1] 2
>      >>> ## but
>      >>>> stopifnot(length(x))
>      >>> Error: length(x) is not TRUE
>      >>> Called from: top level
>      >>> ## but
>      >>>> stopifnot(length(x) > 0)  ## not an error;  nor is
>      >>>> stopifnot(as.logical(length(x)))
>      >>> ## Ouch!
>      >>
>      >>> Maybe the man page should say something about not assuming automatic
>      >>> coercion to logical, which is the usual expectation. Or fix this.
>      >>
>      >>> Bert Gunter
>      >>
>      >> Well, what about the top most paragraph of the help page is not clear here ?
>      >>
>      >>> Description:
>      >>
>      >>> If any of the expressions (in '...' or 'exprs') are not 'all'
>      >>> 'TRUE', 'stop' is called, producing an error message indicating
>      >>> the _first_ expression which was not ('all') true.
>      >>
> 
>      > This, however, is somewhat less clear:
> 
>      > ..., exprs: any number of (typically but not necessarily ?logical?) R
>      > expressions, which should each evaluate to (a logical vector
>      > of all) ?TRUE?.  Use _either_ ?...? _or_ ?exprs?, the latter
>     
>      > What does it mean, "typically but not necessarily ?logical?"?
> 
> That's a good question: The '(....)' must have been put there a while ago.
> I agree that it's not at all helpful. Strictly, we are really
> dealing with unevaluated expressions anyway ("promises"), but
> definitely all of them must evaluate to logical (vector or
> array..) of all TRUE values.  In the very beginning of
> stopifnot(), I had thought that it should also work in other
> cases, e.g.,  for    Matrix(TRUE, 4,5)  {from the Matrix package} etc,
> but several use cases had convinced us / me that stopifnot
> should be stricter...
> 
>      > The code actually tests explicitly with is.logical, as far as I can tell.
> 
>      > This creates a discrepancy between if(!...)stop(...) and stopifnot(),
> 
> yes indeed, on purpose now, for a very long time ...
> 
> There's another discrepancy, more dangerous I think,
> as shown in the following
> {Note this discrepancy has been noted for a long time .. also on
>   this R-devel list} :
> 
>    m <- matrix(1:12, 3,4)
>    i <- (1:4) %% 2 == 1  & (0:3) %% 5 == 0
> 
>    stopifnot(dim(m[,i]) == c(3,1))       # seems fine
>    
>    if(dim(m[,i]) != c(3,1)) stop("wrong dim") # gives an error (but not ..)

mmh... that is not good. I was under the impression that we could at 
least expect 'stopifnot(x)' to be equivalent to 'if (!isTRUE(x)) 
stop(...)'. I'll have to revisit my use of stopifnot() in many many 
places... again :-/ Or may be just stop using it and use 'if 
(!isTRUE(...))' instead.

H.

> 
> 
> Martin
> 
>      >> as in
>      >> f <- function (x) if (!x) stop(paste(deparse(substitute(x)), "is not TRUE"))
>      >> f(0)
>      > Error in f(0) : 0 is not TRUE
>      >> f(1)
>      >> stopifnot(0)
>      > Error: 0 is not TRUE
>      >> stopifnot(1)
>      > Error: 1 is not TRUE
> 
>      > -pd
> 
> 
>      >> If useR's expectations alone would guide the behavior of a
>      >> computer language, the language would have to behave
>      >> "personalized" and give different results depending on the user,
>      >> which may be desirable in medicine or psychotherapy but not with R.
>      >>
>      >> Martin
>      >>
>      >> ______________________________________________
>      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
>      >> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
>      >> and provide commented, minimal, self-contained, reproducible code.
> 
>      > --
>      > Peter Dalgaard, Professor,
>      > Center for Statistics, Copenhagen Business School
>      > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>      > Phone: (+45)38153501
>      > Office: A 4.23
>      > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
> PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From wdun|@p @end|ng |rom t|bco@com  Mon Apr 13 18:57:11 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 13 Apr 2020 09:57:11 -0700
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <93676b28-7b79-b70e-f2e4-1f1527fb80e6@fredhutch.org>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
 <93676b28-7b79-b70e-f2e4-1f1527fb80e6@fredhutch.org>
Message-ID: <CAF8bMcZD12+L606rwH7+KRUCqzpEFTrnkbm09u+MWGxhSrh5FQ@mail.gmail.com>

You can avoid the problem in Martin's example by only giving scalars to
stopifnot().  E.g., using stopifnot(all(x>0)) or stopifnot(length(x)==1,
x>0) instead of stopifnot(x>0).  I think having stopifnot call
all(predicate) if length(predicate)!=1 was probably a mistake.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 13, 2020 at 9:28 AM Herv? Pag?s <hpages at fredhutch.org> wrote:

>
>
> On 4/13/20 05:30, Martin Maechler wrote:
> >>>>>> peter dalgaard
> >>>>>>      on Mon, 13 Apr 2020 12:00:38 +0200 writes:
> >
> >      > Inline...
> >      >> On 13 Apr 2020, at 11:15 , Martin Maechler <
> maechler at stat.math.ethz.ch> wrote:
> >      >>
> >      >>>>>>> Bert Gunter
> >      >>>>>>> on Sun, 12 Apr 2020 16:30:09 -0700 writes:
> >      >>
> >      >>> Don't know if this has come up before, but ...
> >      >>>> x <- c(0,0)
> >      >>>> length(x)
> >      >>> [1] 2
> >      >>> ## but
> >      >>>> stopifnot(length(x))
> >      >>> Error: length(x) is not TRUE
> >      >>> Called from: top level
> >      >>> ## but
> >      >>>> stopifnot(length(x) > 0)  ## not an error;  nor is
> >      >>>> stopifnot(as.logical(length(x)))
> >      >>> ## Ouch!
> >      >>
> >      >>> Maybe the man page should say something about not assuming
> automatic
> >      >>> coercion to logical, which is the usual expectation. Or fix
> this.
> >      >>
> >      >>> Bert Gunter
> >      >>
> >      >> Well, what about the top most paragraph of the help page is not
> clear here ?
> >      >>
> >      >>> Description:
> >      >>
> >      >>> If any of the expressions (in '...' or 'exprs') are not 'all'
> >      >>> 'TRUE', 'stop' is called, producing an error message indicating
> >      >>> the _first_ expression which was not ('all') true.
> >      >>
> >
> >      > This, however, is somewhat less clear:
> >
> >      > ..., exprs: any number of (typically but not necessarily
> ?logical?) R
> >      > expressions, which should each evaluate to (a logical vector
> >      > of all) ?TRUE?.  Use _either_ ?...? _or_ ?exprs?, the latter
> >
> >      > What does it mean, "typically but not necessarily ?logical?"?
> >
> > That's a good question: The '(....)' must have been put there a while
> ago.
> > I agree that it's not at all helpful. Strictly, we are really
> > dealing with unevaluated expressions anyway ("promises"), but
> > definitely all of them must evaluate to logical (vector or
> > array..) of all TRUE values.  In the very beginning of
> > stopifnot(), I had thought that it should also work in other
> > cases, e.g.,  for    Matrix(TRUE, 4,5)  {from the Matrix package} etc,
> > but several use cases had convinced us / me that stopifnot
> > should be stricter...
> >
> >      > The code actually tests explicitly with is.logical, as far as I
> can tell.
> >
> >      > This creates a discrepancy between if(!...)stop(...) and
> stopifnot(),
> >
> > yes indeed, on purpose now, for a very long time ...
> >
> > There's another discrepancy, more dangerous I think,
> > as shown in the following
> > {Note this discrepancy has been noted for a long time .. also on
> >   this R-devel list} :
> >
> >    m <- matrix(1:12, 3,4)
> >    i <- (1:4) %% 2 == 1  & (0:3) %% 5 == 0
> >
> >    stopifnot(dim(m[,i]) == c(3,1))       # seems fine
> >
> >    if(dim(m[,i]) != c(3,1)) stop("wrong dim") # gives an error (but not
> ..)
>
> mmh... that is not good. I was under the impression that we could at
> least expect 'stopifnot(x)' to be equivalent to 'if (!isTRUE(x))
> stop(...)'. I'll have to revisit my use of stopifnot() in many many
> places... again :-/ Or may be just stop using it and use 'if
> (!isTRUE(...))' instead.
>
> H.
>
> >
> >
> > Martin
> >
> >      >> as in
> >      >> f <- function (x) if (!x) stop(paste(deparse(substitute(x)), "is
> not TRUE"))
> >      >> f(0)
> >      > Error in f(0) : 0 is not TRUE
> >      >> f(1)
> >      >> stopifnot(0)
> >      > Error: 0 is not TRUE
> >      >> stopifnot(1)
> >      > Error: 1 is not TRUE
> >
> >      > -pd
> >
> >
> >      >> If useR's expectations alone would guide the behavior of a
> >      >> computer language, the language would have to behave
> >      >> "personalized" and give different results depending on the user,
> >      >> which may be desirable in medicine or psychotherapy but not with
> R.
> >      >>
> >      >> Martin
> >      >>
> >      >> ______________________________________________
> >      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >      >>
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
> >      >> PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
> >      >> and provide commented, minimal, self-contained, reproducible
> code.
> >
> >      > --
> >      > Peter Dalgaard, Professor,
> >      > Center for Statistics, Copenhagen Business School
> >      > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >      > Phone: (+45)38153501
> >      > Office: A 4.23
> >      > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
> > PLEASE do read the posting guide
> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Herv? Pag?s
>
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
>
> E-mail: hpages at fredhutch.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Iurii@Cher@i@ti@ m@iii@g oii t-systems@com  Mon Apr 13 20:50:16 2020
From: Iurii@Cher@i@ti@ m@iii@g oii t-systems@com (Iurii@Cher@i@ti@ m@iii@g oii t-systems@com)
Date: Mon, 13 Apr 2020 18:50:16 +0000
Subject: [R] Error with devTools
Message-ID: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>

Hi everyone!
Could somebody help me, I`m trying to run devtools::test() from R-console and it doesn't` work, but it works via RStudio if I will remove devtools before.

 Error from console:


Loading space
Error in (function (command = NULL, args = character(), error_on_status = TRUE,  :
  System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
E> * installing *source* package 'space' ...
E> ** using staged installation
E> ** libs
E> no DLL was created
E> ERROR: compilation failed for package 'space'
E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
Type .Last.error.trace to see where the error occured
>
>
>
> .Last.error.trace

Stack trace:

1. devtools::test()
2. devtools:::load_all(pkg$path, quiet = TRUE, export_all = export_all)
3. pkgload::load_all(path = path, reset = reset, recompile = recompile,  ...
4. pkgbuild::compile_dll(path, quiet = quiet)
5. withr::with_makevars(compiler_flags(TRUE), assignment = "+=",  ...
6. withr:::with_envvar(c(R_MAKEVARS_USER = makevars_file), { ...
7. base:::force(code)
8. base:::force(code)
9. pkgbuild:::install_min(path, dest = install_dir, components = "libs",  ...
10. pkgbuild:::rcmd_build_tools("INSTALL", c(path, paste("--library=",  ...
11. pkgbuild:::with_build_tools(callr::rcmd_safe(..., env = env,  ...
12. withr::with_path(rtools_path(), code)
13. base:::force(code)
14. callr::rcmd_safe(..., env = env, spinner = FALSE, show = FALSE,  ...
15. callr:::run_r(options)
16. base:::with(options, with_envvar(env, do.call(processx::run,  ...
17. base:::with.default(options, with_envvar(env, do.call(processx::run,  ...
18. base:::eval(substitute(expr), data, enclos = parent.frame())
19. base:::eval(substitute(expr), data, enclos = parent.frame())
20. callr:::with_envvar(env, do.call(processx::run, c(list(bin, args = real_cmd ...
21. base:::force(code)
22. base:::do.call(processx::run, c(list(bin, args = real_cmdargs,  ...
23. (function (command = NULL, args = character(), error_on_status = TRUE,  ...
24. throw(new_process_error(res, call = sys.call(), echo = echo,  ...

x System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
E> * installing *source* package 'space' ...
E> ** using staged installation
E> ** libs
E> no DLL was created
E> ERROR: compilation failed for package 'space'
E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'



Environment:

1)     Windows 10 X64

2)     R lib : 3.6.3

3)     R-Studio 1.2.5042


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Apr 13 22:30:35 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 13 Apr 2020 22:30:35 +0200
Subject: [R] A stopifnot() nastiness, even if not a bug
In-Reply-To: <CAF8bMcZD12+L606rwH7+KRUCqzpEFTrnkbm09u+MWGxhSrh5FQ@mail.gmail.com>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
 <93676b28-7b79-b70e-f2e4-1f1527fb80e6@fredhutch.org>
 <CAF8bMcZD12+L606rwH7+KRUCqzpEFTrnkbm09u+MWGxhSrh5FQ@mail.gmail.com>
Message-ID: <24212.52203.211594.608671@stat.math.ethz.ch>

>>>>> William Dunlap 
>>>>>     on Mon, 13 Apr 2020 09:57:11 -0700 writes:

    > You can avoid the problem in Martin's example by only giving scalars to
    > stopifnot().  E.g., using stopifnot(all(x>0)) or stopifnot(length(x)==1,
    x> 0) instead of stopifnot(x>0).  I think having stopifnot call
    > all(predicate) if length(predicate)!=1 was probably a mistake.

well, maybe.
As I brougth up the 0-length example:  One could think of making
an exception for  logical(0)  and treat that as non-TRUE.

(for R-devel only, but still probably not this close before
 releasing R 4.0.0)

Martin

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com


    > On Mon, Apr 13, 2020 at 9:28 AM Herv? Pag?s <hpages at fredhutch.org> wrote:

    >> 
    >> 
    >> On 4/13/20 05:30, Martin Maechler wrote:
    >> >>>>>> peter dalgaard
    >> >>>>>>      on Mon, 13 Apr 2020 12:00:38 +0200 writes:
    >> >
    >> >      > Inline...
    >> >      >> On 13 Apr 2020, at 11:15 , Martin Maechler <
    >> maechler at stat.math.ethz.ch> wrote:
    >> >      >>
    >> >      >>>>>>> Bert Gunter
    >> >      >>>>>>> on Sun, 12 Apr 2020 16:30:09 -0700 writes:
    >> >      >>
    >> >      >>> Don't know if this has come up before, but ...
    >> >      >>>> x <- c(0,0)
    >> >      >>>> length(x)
    >> >      >>> [1] 2
    >> >      >>> ## but
    >> >      >>>> stopifnot(length(x))
    >> >      >>> Error: length(x) is not TRUE
    >> >      >>> Called from: top level
    >> >      >>> ## but
    >> >      >>>> stopifnot(length(x) > 0)  ## not an error;  nor is
    >> >      >>>> stopifnot(as.logical(length(x)))
    >> >      >>> ## Ouch!
    >> >      >>
    >> >      >>> Maybe the man page should say something about not assuming
    >> automatic
    >> >      >>> coercion to logical, which is the usual expectation. Or fix
    >> this.
    >> >      >>
    >> >      >>> Bert Gunter
    >> >      >>
    >> >      >> Well, what about the top most paragraph of the help page is not
    >> clear here ?
    >> >      >>
    >> >      >>> Description:
    >> >      >>
    >> >      >>> If any of the expressions (in '...' or 'exprs') are not 'all'
    >> >      >>> 'TRUE', 'stop' is called, producing an error message indicating
    >> >      >>> the _first_ expression which was not ('all') true.
    >> >      >>
    >> >
    >> >      > This, however, is somewhat less clear:
    >> >
    >> >      > ..., exprs: any number of (typically but not necessarily
    >> ?logical?) R
    >> >      > expressions, which should each evaluate to (a logical vector
    >> >      > of all) ?TRUE?.  Use _either_ ?...? _or_ ?exprs?, the latter
    >> >
    >> >      > What does it mean, "typically but not necessarily ?logical?"?
    >> >
    >> > That's a good question: The '(....)' must have been put there a while
    >> ago.
    >> > I agree that it's not at all helpful. Strictly, we are really
    >> > dealing with unevaluated expressions anyway ("promises"), but
    >> > definitely all of them must evaluate to logical (vector or
    >> > array..) of all TRUE values.  In the very beginning of
    >> > stopifnot(), I had thought that it should also work in other
    >> > cases, e.g.,  for    Matrix(TRUE, 4,5)  {from the Matrix package} etc,
    >> > but several use cases had convinced us / me that stopifnot
    >> > should be stricter...
    >> >
    >> >      > The code actually tests explicitly with is.logical, as far as I
    >> can tell.
    >> >
    >> >      > This creates a discrepancy between if(!...)stop(...) and
    >> stopifnot(),
    >> >
    >> > yes indeed, on purpose now, for a very long time ...
    >> >
    >> > There's another discrepancy, more dangerous I think,
    >> > as shown in the following
    >> > {Note this discrepancy has been noted for a long time .. also on
    >> >   this R-devel list} :
    >> >
    >> >    m <- matrix(1:12, 3,4)
    >> >    i <- (1:4) %% 2 == 1  & (0:3) %% 5 == 0
    >> >
    >> >    stopifnot(dim(m[,i]) == c(3,1))       # seems fine
    >> >
    >> >    if(dim(m[,i]) != c(3,1)) stop("wrong dim") # gives an error (but not
    >> ..)
    >> 
    >> mmh... that is not good. I was under the impression that we could at
    >> least expect 'stopifnot(x)' to be equivalent to 'if (!isTRUE(x))
    >> stop(...)'. I'll have to revisit my use of stopifnot() in many many
    >> places... again :-/ Or may be just stop using it and use 'if
    >> (!isTRUE(...))' instead.
    >> 
    >> H.
    >> 
    >> >
    >> >
    >> > Martin
    >> >
    >> >      >> as in
    >> >      >> f <- function (x) if (!x) stop(paste(deparse(substitute(x)), "is
    >> not TRUE"))
    >> >      >> f(0)
    >> >      > Error in f(0) : 0 is not TRUE
    >> >      >> f(1)
    >> >      >> stopifnot(0)
    >> >      > Error: 0 is not TRUE
    >> >      >> stopifnot(1)
    >> >      > Error: 1 is not TRUE
    >> >
    >> >      > -pd
    >> >
    >> >
    >> >      >> If useR's expectations alone would guide the behavior of a
    >> >      >> computer language, the language would have to behave
    >> >      >> "personalized" and give different results depending on the user,
    >> >      >> which may be desirable in medicine or psychotherapy but not with
    >> R.
    >> >      >>
    >> >      >> Martin
    >> >      >>
    >> >      >> ______________________________________________
    >> >      >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
    >> see
    >> >      >>
    >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
    >> >      >> PLEASE do read the posting guide
    >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
    >> >      >> and provide commented, minimal, self-contained, reproducible
    >> code.
    >> >
    >> >      > --
    >> >      > Peter Dalgaard, Professor,
    >> >      > Center for Statistics, Copenhagen Business School
    >> >      > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    >> >      > Phone: (+45)38153501
    >> >      > Office: A 4.23
    >> >      > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    >> >
    >> > ______________________________________________
    >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> >
    >> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=W8I5sRKBBKZgSjXrQC_PQw6XXUApw5h2DI5EUoDdl9w&e=
    >> > PLEASE do read the posting guide
    >> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=BK7q3XeAvimeWdGbWY_wJYbW0WYiZvSXAJJKaaPhzWA&m=2kAPk_-c9XEQGS0BB1rf03oPxqQtflyqhqi-0BT8bWE&s=ADWOmjdAMLWT3rJRMz411RnDjrc6Vyj4NNmZMoM3Sck&e=
    >> > and provide commented, minimal, self-contained, reproducible code.
    >> >
    >> 
    >> --
    >> Herv? Pag?s
    >> 
    >> Program in Computational Biology
    >> Division of Public Health Sciences
    >> Fred Hutchinson Cancer Research Center
    >> 1100 Fairview Ave. N, M1-B514
    >> P.O. Box 19024
    >> Seattle, WA 98109-1024
    >> 
    >> E-mail: hpages at fredhutch.org
    >> Phone:  (206) 667-5791
    >> Fax:    (206) 667-1319
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >>


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Apr 13 22:32:30 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Apr 2020 16:32:30 -0400
Subject: [R] Error with devTools
In-Reply-To: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>
References: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>
Message-ID: <5969c0c8-0df7-8440-c3b0-00fd7fcc7803@gmail.com>

On 13/04/2020 2:50 p.m., Iurii.Cherniatin at t-systems.com wrote:
> Hi everyone!
> Could somebody help me, I`m trying to run devtools::test() from R-console and it doesn't` work, but it works via RStudio if I will remove devtools before.

I'd guess you don't have the PATH set properly so compilers etc can't be 
found, but devtools::test hides the information that would confirm that, 
because it compiles with quiet = TRUE hard coded.

Duncan Murdoch

> 
>   Error from console:
> 
> 
> Loading space
> Error in (function (command = NULL, args = character(), error_on_status = TRUE,  :
>    System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> E> * installing *source* package 'space' ...
> E> ** using staged installation
> E> ** libs
> E> no DLL was created
> E> ERROR: compilation failed for package 'space'
> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> Type .Last.error.trace to see where the error occured
>>
>>
>>
>> .Last.error.trace
> 
> Stack trace:
> 
> 1. devtools::test()
> 2. devtools:::load_all(pkg$path, quiet = TRUE, export_all = export_all)
> 3. pkgload::load_all(path = path, reset = reset, recompile = recompile,  ...
> 4. pkgbuild::compile_dll(path, quiet = quiet)
> 5. withr::with_makevars(compiler_flags(TRUE), assignment = "+=",  ...
> 6. withr:::with_envvar(c(R_MAKEVARS_USER = makevars_file), { ...
> 7. base:::force(code)
> 8. base:::force(code)
> 9. pkgbuild:::install_min(path, dest = install_dir, components = "libs",  ...
> 10. pkgbuild:::rcmd_build_tools("INSTALL", c(path, paste("--library=",  ...
> 11. pkgbuild:::with_build_tools(callr::rcmd_safe(..., env = env,  ...
> 12. withr::with_path(rtools_path(), code)
> 13. base:::force(code)
> 14. callr::rcmd_safe(..., env = env, spinner = FALSE, show = FALSE,  ...
> 15. callr:::run_r(options)
> 16. base:::with(options, with_envvar(env, do.call(processx::run,  ...
> 17. base:::with.default(options, with_envvar(env, do.call(processx::run,  ...
> 18. base:::eval(substitute(expr), data, enclos = parent.frame())
> 19. base:::eval(substitute(expr), data, enclos = parent.frame())
> 20. callr:::with_envvar(env, do.call(processx::run, c(list(bin, args = real_cmd ...
> 21. base:::force(code)
> 22. base:::do.call(processx::run, c(list(bin, args = real_cmdargs,  ...
> 23. (function (command = NULL, args = character(), error_on_status = TRUE,  ...
> 24. throw(new_process_error(res, call = sys.call(), echo = echo,  ...
> 
> x System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> E> * installing *source* package 'space' ...
> E> ** using staged installation
> E> ** libs
> E> no DLL was created
> E> ERROR: compilation failed for package 'space'
> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> 
> 
> 
> Environment:
> 
> 1)     Windows 10 X64
> 
> 2)     R lib : 3.6.3
> 
> 3)     R-Studio 1.2.5042
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Iurii@Cher@i@ti@ m@iii@g oii t-systems@com  Tue Apr 14 10:18:03 2020
From: Iurii@Cher@i@ti@ m@iii@g oii t-systems@com (Iurii@Cher@i@ti@ m@iii@g oii t-systems@com)
Date: Tue, 14 Apr 2020 08:18:03 +0000
Subject: [R] Error with devTools
In-Reply-To: <5969c0c8-0df7-8440-c3b0-00fd7fcc7803@gmail.com>
References: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>
 <5969c0c8-0df7-8440-c3b0-00fd7fcc7803@gmail.com>
Message-ID: <6275f4f0a4a945f192b88cb0bb811ea9@HE202260.emea2.cds.t-internal.com>

Hi Duncan ,
   Thank you for your answer, you mean R path?  
 I have in PATH  "C:\Program Files\R\R-3.6.2\bin\x64"
   

Maybe you can provide me , how I can switch quiet = TRUE to False?




-----Original Message-----
From: Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent: Monday, April 13, 2020 11:33 PM
To: Cherniatin, Iurii <Iurii.Cherniatin at t-systems.com>; r-help at r-project.org
Subject: Re: [R] Error with devTools

On 13/04/2020 2:50 p.m., Iurii.Cherniatin at t-systems.com wrote:
> Hi everyone!
> Could somebody help me, I`m trying to run devtools::test() from R-console and it doesn't` work, but it works via RStudio if I will remove devtools before.

I'd guess you don't have the PATH set properly so compilers etc can't be found, but devtools::test hides the information that would confirm that, because it compiles with quiet = TRUE hard coded.

Duncan Murdoch

> 
>   Error from console:
> 
> 
> Loading space
> Error in (function (command = NULL, args = character(), error_on_status = TRUE,  :
>    System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> E> * installing *source* package 'space' ...
> E> ** using staged installation
> E> ** libs
> E> no DLL was created
> E> ERROR: compilation failed for package 'space'
> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> Type .Last.error.trace to see where the error occured
>>
>>
>>
>> .Last.error.trace
> 
> Stack trace:
> 
> 1. devtools::test()
> 2. devtools:::load_all(pkg$path, quiet = TRUE, export_all = 
> export_all) 3. pkgload::load_all(path = path, reset = reset, recompile = recompile,  ...
> 4. pkgbuild::compile_dll(path, quiet = quiet) 5. 
> withr::with_makevars(compiler_flags(TRUE), assignment = "+=",  ...
> 6. withr:::with_envvar(c(R_MAKEVARS_USER = makevars_file), { ...
> 7. base:::force(code)
> 8. base:::force(code)
> 9. pkgbuild:::install_min(path, dest = install_dir, components = "libs",  ...
> 10. pkgbuild:::rcmd_build_tools("INSTALL", c(path, paste("--library=",  ...
> 11. pkgbuild:::with_build_tools(callr::rcmd_safe(..., env = env,  ...
> 12. withr::with_path(rtools_path(), code) 13. base:::force(code) 14. 
> callr::rcmd_safe(..., env = env, spinner = FALSE, show = FALSE,  ...
> 15. callr:::run_r(options)
> 16. base:::with(options, with_envvar(env, do.call(processx::run,  ...
> 17. base:::with.default(options, with_envvar(env, do.call(processx::run,  ...
> 18. base:::eval(substitute(expr), data, enclos = parent.frame()) 19. 
> base:::eval(substitute(expr), data, enclos = parent.frame()) 20. 
> callr:::with_envvar(env, do.call(processx::run, c(list(bin, args = real_cmd ...
> 21. base:::force(code)
> 22. base:::do.call(processx::run, c(list(bin, args = real_cmdargs,  ...
> 23. (function (command = NULL, args = character(), error_on_status = TRUE,  ...
> 24. throw(new_process_error(res, call = sys.call(), echo = echo,  ...
> 
> x System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> E> * installing *source* package 'space' ...
> E> ** using staged installation
> E> ** libs
> E> no DLL was created
> E> ERROR: compilation failed for package 'space'
> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> 
> 
> 
> Environment:
> 
> 1)     Windows 10 X64
> 
> 2)     R lib : 3.6.3
> 
> 3)     R-Studio 1.2.5042
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 14 11:13:33 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 14 Apr 2020 05:13:33 -0400
Subject: [R] Error with devTools
In-Reply-To: <6275f4f0a4a945f192b88cb0bb811ea9@HE202260.emea2.cds.t-internal.com>
References: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>
 <5969c0c8-0df7-8440-c3b0-00fd7fcc7803@gmail.com>
 <6275f4f0a4a945f192b88cb0bb811ea9@HE202260.emea2.cds.t-internal.com>
Message-ID: <c7740dc8-e6cb-aefc-a476-7d6fbbef0388@gmail.com>

No, I mean the path to the other Rtools.  I think the only solution to 
avoid the quiet = TRUE is to modify the devtools package, or don't use it.

Duncan Murdoch

On 14/04/2020 4:18 a.m., Iurii.Cherniatin at t-systems.com wrote:
> Hi Duncan ,
>     Thank you for your answer, you mean R path?
>   I have in PATH  "C:\Program Files\R\R-3.6.2\bin\x64"
>     
> 
> Maybe you can provide me , how I can switch quiet = TRUE to False?
> 
> 
> 
> 
> -----Original Message-----
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> Sent: Monday, April 13, 2020 11:33 PM
> To: Cherniatin, Iurii <Iurii.Cherniatin at t-systems.com>; r-help at r-project.org
> Subject: Re: [R] Error with devTools
> 
> On 13/04/2020 2:50 p.m., Iurii.Cherniatin at t-systems.com wrote:
>> Hi everyone!
>> Could somebody help me, I`m trying to run devtools::test() from R-console and it doesn't` work, but it works via RStudio if I will remove devtools before.
> 
> I'd guess you don't have the PATH set properly so compilers etc can't be found, but devtools::test hides the information that would confirm that, because it compiles with quiet = TRUE hard coded.
> 
> Duncan Murdoch
> 
>>
>>    Error from console:
>>
>>
>> Loading space
>> Error in (function (command = NULL, args = character(), error_on_status = TRUE,  :
>>     System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
>> E> * installing *source* package 'space' ...
>> E> ** using staged installation
>> E> ** libs
>> E> no DLL was created
>> E> ERROR: compilation failed for package 'space'
>> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
>> Type .Last.error.trace to see where the error occured
>>>
>>>
>>>
>>> .Last.error.trace
>>
>> Stack trace:
>>
>> 1. devtools::test()
>> 2. devtools:::load_all(pkg$path, quiet = TRUE, export_all =
>> export_all) 3. pkgload::load_all(path = path, reset = reset, recompile = recompile,  ...
>> 4. pkgbuild::compile_dll(path, quiet = quiet) 5.
>> withr::with_makevars(compiler_flags(TRUE), assignment = "+=",  ...
>> 6. withr:::with_envvar(c(R_MAKEVARS_USER = makevars_file), { ...
>> 7. base:::force(code)
>> 8. base:::force(code)
>> 9. pkgbuild:::install_min(path, dest = install_dir, components = "libs",  ...
>> 10. pkgbuild:::rcmd_build_tools("INSTALL", c(path, paste("--library=",  ...
>> 11. pkgbuild:::with_build_tools(callr::rcmd_safe(..., env = env,  ...
>> 12. withr::with_path(rtools_path(), code) 13. base:::force(code) 14.
>> callr::rcmd_safe(..., env = env, spinner = FALSE, show = FALSE,  ...
>> 15. callr:::run_r(options)
>> 16. base:::with(options, with_envvar(env, do.call(processx::run,  ...
>> 17. base:::with.default(options, with_envvar(env, do.call(processx::run,  ...
>> 18. base:::eval(substitute(expr), data, enclos = parent.frame()) 19.
>> base:::eval(substitute(expr), data, enclos = parent.frame()) 20.
>> callr:::with_envvar(env, do.call(processx::run, c(list(bin, args = real_cmd ...
>> 21. base:::force(code)
>> 22. base:::do.call(processx::run, c(list(bin, args = real_cmdargs,  ...
>> 23. (function (command = NULL, args = character(), error_on_status = TRUE,  ...
>> 24. throw(new_process_error(res, call = sys.call(), echo = echo,  ...
>>
>> x System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
>> E> * installing *source* package 'space' ...
>> E> ** using staged installation
>> E> ** libs
>> E> no DLL was created
>> E> ERROR: compilation failed for package 'space'
>> E> * removing 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
>>
>>
>>
>> Environment:
>>
>> 1)     Windows 10 X64
>>
>> 2)     R lib : 3.6.3
>>
>> 3)     R-Studio 1.2.5042
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From @@mch@ry@ @end|ng |rom y@hoo@com@@u  Tue Apr 14 11:28:24 2020
From: @@mch@ry@ @end|ng |rom y@hoo@com@@u (Sam Charya)
Date: Tue, 14 Apr 2020 09:28:24 +0000 (UTC)
Subject: [R] A simple string alienation question.
In-Reply-To: <24212.23386.542411.93591@stat.math.ethz.ch>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
Message-ID: <580244792.176097.1586856504159@mail.yahoo.com>

 

Hello Dear R Community,
I would ask a little bit of help from you please:I have a dataset, which is in a CSV file ? I have read it into R as follows:?
? ? ? ? ? ? ? ? ?V11? ?tropical fruit"2? ? ? ?whole milk"3? ? ? ? pip fruit"4 other vegetables"5? ? ? ?whole milk"6? ? ? ?rolls/buns"
The issue is: the data set in Csv file also appears with the quotation marks ?. I can?t get rid of the quotation marks. I want to do it in R. The Quotes only appear at the end of the string. The dataset has many rows ? this is just a copy. My intention is to be able to get rid of the quotes and then want to separate the strings with a ?/?. i.e. rolls/buns should be rolls in one column and buns in another.
I know this is something very simple I am lacking ? but if you could please show me how to do this? If someone could throw some light please.?I read the data in with a simple read.csv statement:?
? calc <- read.csv("Fight.csv", stringsAsFactors = F, header = F)?? str(x)?
Output:?> str(calc)'data.frame': 38765 obs. of? 1 variable:?$ V1: chr? "tropical fruit\"" "whole milk\"" "pip fruit\"" "other vegetables\"" ...
Many Thanks in advance for your help.
Kind Regards,
Sam.?




	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Apr 14 11:34:08 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Apr 2020 12:34:08 +0300
Subject: [R] Error with devTools
In-Reply-To: <c7740dc8-e6cb-aefc-a476-7d6fbbef0388@gmail.com>
References: <24c858c1252a4c12bbfabfb51542c892@HE202260.emea2.cds.t-internal.com>
 <5969c0c8-0df7-8440-c3b0-00fd7fcc7803@gmail.com>
 <6275f4f0a4a945f192b88cb0bb811ea9@HE202260.emea2.cds.t-internal.com>
 <c7740dc8-e6cb-aefc-a476-7d6fbbef0388@gmail.com>
Message-ID: <CAGgJW75Q795asx1cVQNsU=ZqDoZPr3gtW15CMXytPgrzRcnr_w@mail.gmail.com>

RStudio provides a terminal window. You could print out the environment
variables there and then adjust the ones in your R console session
appropriately. I could give you some guidance under linux, but it seems you
use Windows. Perhaps others can help with the details.

On Tue, Apr 14, 2020 at 12:14 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> No, I mean the path to the other Rtools.  I think the only solution to
> avoid the quiet = TRUE is to modify the devtools package, or don't use it.
>
> Duncan Murdoch
>
> On 14/04/2020 4:18 a.m., Iurii.Cherniatin at t-systems.com wrote:
> > Hi Duncan ,
> >     Thank you for your answer, you mean R path?
> >   I have in PATH  "C:\Program Files\R\R-3.6.2\bin\x64"
> >
> >
> > Maybe you can provide me , how I can switch quiet = TRUE to False?
> >
> >
> >
> >
> > -----Original Message-----
> > From: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Sent: Monday, April 13, 2020 11:33 PM
> > To: Cherniatin, Iurii <Iurii.Cherniatin at t-systems.com>;
> r-help at r-project.org
> > Subject: Re: [R] Error with devTools
> >
> > On 13/04/2020 2:50 p.m., Iurii.Cherniatin at t-systems.com wrote:
> >> Hi everyone!
> >> Could somebody help me, I`m trying to run devtools::test() from
> R-console and it doesn't` work, but it works via RStudio if I will remove
> devtools before.
> >
> > I'd guess you don't have the PATH set properly so compilers etc can't be
> found, but devtools::test hides the information that would confirm that,
> because it compiles with quiet = TRUE hard coded.
> >
> > Duncan Murdoch
> >
> >>
> >>    Error from console:
> >>
> >>
> >> Loading space
> >> Error in (function (command = NULL, args = character(), error_on_status
> = TRUE,  :
> >>     System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> >> E> * installing *source* package 'space' ...
> >> E> ** using staged installation
> >> E> ** libs
> >> E> no DLL was created
> >> E> ERROR: compilation failed for package 'space'
> >> E> * removing
> 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> >> Type .Last.error.trace to see where the error occured
> >>>
> >>>
> >>>
> >>> .Last.error.trace
> >>
> >> Stack trace:
> >>
> >> 1. devtools::test()
> >> 2. devtools:::load_all(pkg$path, quiet = TRUE, export_all =
> >> export_all) 3. pkgload::load_all(path = path, reset = reset, recompile
> = recompile,  ...
> >> 4. pkgbuild::compile_dll(path, quiet = quiet) 5.
> >> withr::with_makevars(compiler_flags(TRUE), assignment = "+=",  ...
> >> 6. withr:::with_envvar(c(R_MAKEVARS_USER = makevars_file), { ...
> >> 7. base:::force(code)
> >> 8. base:::force(code)
> >> 9. pkgbuild:::install_min(path, dest = install_dir, components =
> "libs",  ...
> >> 10. pkgbuild:::rcmd_build_tools("INSTALL", c(path, paste("--library=",
> ...
> >> 11. pkgbuild:::with_build_tools(callr::rcmd_safe(..., env = env,  ...
> >> 12. withr::with_path(rtools_path(), code) 13. base:::force(code) 14.
> >> callr::rcmd_safe(..., env = env, spinner = FALSE, show = FALSE,  ...
> >> 15. callr:::run_r(options)
> >> 16. base:::with(options, with_envvar(env, do.call(processx::run,  ...
> >> 17. base:::with.default(options, with_envvar(env,
> do.call(processx::run,  ...
> >> 18. base:::eval(substitute(expr), data, enclos = parent.frame()) 19.
> >> base:::eval(substitute(expr), data, enclos = parent.frame()) 20.
> >> callr:::with_envvar(env, do.call(processx::run, c(list(bin, args =
> real_cmd ...
> >> 21. base:::force(code)
> >> 22. base:::do.call(processx::run, c(list(bin, args = real_cmdargs,  ...
> >> 23. (function (command = NULL, args = character(), error_on_status =
> TRUE,  ...
> >> 24. throw(new_process_error(res, call = sys.call(), echo = echo,  ...
> >>
> >> x System command 'Rcmd.exe' failed, exit status: 1, stdout + stderr:
> >> E> * installing *source* package 'space' ...
> >> E> ** using staged installation
> >> E> ** libs
> >> E> no DLL was created
> >> E> ERROR: compilation failed for package 'space'
> >> E> * removing
> 'C:/Users/user/AppData/Local/Temp/RtmpSESXUZ/devtools_install_3f9853f01a48/space'
> >>
> >>
> >>
> >> Environment:
> >>
> >> 1)     Windows 10 X64
> >>
> >> 2)     R lib : 3.6.3
> >>
> >> 3)     R-Studio 1.2.5042
> >>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Apr 14 11:48:22 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Apr 2020 12:48:22 +0300
Subject: [R] A simple string alienation question.
In-Reply-To: <580244792.176097.1586856504159@mail.yahoo.com>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
 <580244792.176097.1586856504159@mail.yahoo.com>
Message-ID: <CAGgJW74BSAoNksuMk3aAbb8peCh_HZ4WApXszdYTr+yxBYG9Rg@mail.gmail.com>

Hi Sam,
This should be straightforward. But to help out the people who could give
you an answer it would be better if you could provide the information a bit
more clearly as follows:
1. send your email in plain text mode. If you use gmail, when you are
composing your email, you can click on the 3 dots in the lower right and
select 'Plain text mode'. The R-help list doesn't handle HTML.
2. We cannot see your "Fight.csv" file. Include in your email, say, the
first couple of lines of this file.
3. Also provide the sample output (or data frame) that you would like to
get from this shortened version of your input.

Best,
Eric


On Tue, Apr 14, 2020 at 12:29 PM Sam Charya via R-help <r-help at r-project.org>
wrote:

>
>
> Hello Dear R Community,
> I would ask a little bit of help from you please:I have a dataset, which
> is in a CSV file ? I have read it into R as follows:
>                  V11   tropical fruit"2       whole milk"3        pip
> fruit"4 other vegetables"5       whole milk"6       rolls/buns"
> The issue is: the data set in Csv file also appears with the quotation
> marks ?. I can?t get rid of the quotation marks. I want to do it in R. The
> Quotes only appear at the end of the string. The dataset has many rows ?
> this is just a copy. My intention is to be able to get rid of the quotes
> and then want to separate the strings with a ?/?. i.e. rolls/buns should be
> rolls in one column and buns in another.
> I know this is something very simple I am lacking ? but if you could
> please show me how to do this? If someone could throw some light please. I
> read the data in with a simple read.csv statement:
> ? calc <- read.csv("Fight.csv", stringsAsFactors = F, header = F) ? str(x)
> Output: > str(calc)'data.frame': 38765 obs. of  1 variable: $ V1: chr
> "tropical fruit\"" "whole milk\"" "pip fruit\"" "other vegetables\"" ...
> Many Thanks in advance for your help.
> Kind Regards,
> Sam.
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Apr 14 15:06:30 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Apr 2020 16:06:30 +0300
Subject: [R] A simple string alienation problem
In-Reply-To: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
References: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
Message-ID: <CAGgJW74SWT93c_LBiotsuj_oAnr4CZyo_Ps_VH2a4cF7ULRcTg@mail.gmail.com>

Hi Sam,
My code below adds new columns to your data frame so you have the original
columns in order to compare.
(Also this could help in case there are a few rows that don't work in the
full set.)

> x <- read.csv("Fight.csv", stringsAsFactors = F, header = F)
>  x$V3 <- sub("\\\"","",x$V1)  # remove the "
> iV <- grep("/",x$V3)  # get the indices of the rows that have / in the
name
> x$V4 <- x$V2  # or rep(NA,nrow(x))
> x$V4[iV] <- sub(".*/","",x$V3[iV])  # remove up-to-and-including the /
> x$V3[iV] <- sub("/.*","",x$V3[iV])  # remove from the / and beyond
> x

HTH,
Eric




On Tue, Apr 14, 2020 at 1:55 PM Soumyadip Bhattacharyya <
s.b.sam2801 at gmail.com> wrote:

> ***Dear Eric,*****
> sending from gmail following the way you suggested. Hope now everyone
> can see this email. **** I have also attached the first 50 rows of the
> FIght.csv.***
> ***Output - I will try to do Market basket analysis on this to find
> out rules that I am learning. so once I have the data in transactional
> format - then I can run the algorithm and keep learning. This little
> problem has caused a barrier in my path - I can alienate the string in
> excel - but wanted to do in R - so researching I tried doing this:
> x<- substr(x, 1, nchar(x) - 1)  // but I wasn't successful and I tried
> many other things - its not coming in the transactional format. ***
> Hence now reached out to the experts.**** Many Thanks.
>
> Hello Dear R Community,
>
> I would ask a little bit of help from you please:I have a dataset,
> which is in a CSV file ? I have read it into R as follows:
>
>       V1
> tropical fruit"
> whole milk"
> pip fruit"
> other vegetables"
> whole milk"
> rolls/buns"
>
> The issue is: the data set in csv file also appears with the quotation
> marks ?. I can?t get rid of the quotation marks. I want to do it in R.
> The Quotes only appear at the end of the string. The dataset has many
> rows ? this is just a copy. My intention is to be able to get rid of
> the quotes and then want to separate the strings with a ?/?. i.e.
> rolls/buns should be rolls in one column and buns in another.
>
> I know this is something very simple I am lacking ? but if you could
> please show me how to do this? If someone could throw some light
> please. I read the data in with a simple read.csv statement:
>
> > x <- read.csv("Fight.csv", stringsAsFactors = F, header = F)
> > str(x)
> Output:
> > str(calc)
> 'data.frame':   38765 obs. of  1 variable:
> $ V1: chr  "tropical fruit\"" "whole milk\"" "pip fruit\"" "other
> vegetables\"" ...
>
> Many Thanks in advance for your help.
> Kind Regards,
> Sam.
>

	[[alternative HTML version deleted]]


From @@b@@@m2801 @end|ng |rom gm@||@com  Tue Apr 14 12:55:17 2020
From: @@b@@@m2801 @end|ng |rom gm@||@com (Soumyadip Bhattacharyya)
Date: Tue, 14 Apr 2020 16:25:17 +0530
Subject: [R] A simple string alienation problem
Message-ID: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>

***Dear Eric,*****
sending from gmail following the way you suggested. Hope now everyone
can see this email. **** I have also attached the first 50 rows of the
FIght.csv.***
***Output - I will try to do Market basket analysis on this to find
out rules that I am learning. so once I have the data in transactional
format - then I can run the algorithm and keep learning. This little
problem has caused a barrier in my path - I can alienate the string in
excel - but wanted to do in R - so researching I tried doing this:
x<- substr(x, 1, nchar(x) - 1)  // but I wasn't successful and I tried
many other things - its not coming in the transactional format. ***
Hence now reached out to the experts.**** Many Thanks.

Hello Dear R Community,

I would ask a little bit of help from you please:I have a dataset,
which is in a CSV file ? I have read it into R as follows:

      V1
tropical fruit"
whole milk"
pip fruit"
other vegetables"
whole milk"
rolls/buns"

The issue is: the data set in csv file also appears with the quotation
marks ?. I can?t get rid of the quotation marks. I want to do it in R.
The Quotes only appear at the end of the string. The dataset has many
rows ? this is just a copy. My intention is to be able to get rid of
the quotes and then want to separate the strings with a ?/?. i.e.
rolls/buns should be rolls in one column and buns in another.

I know this is something very simple I am lacking ? but if you could
please show me how to do this? If someone could throw some light
please. I read the data in with a simple read.csv statement:

> x <- read.csv("Fight.csv", stringsAsFactors = F, header = F)
> str(x)
Output:
> str(calc)
'data.frame':   38765 obs. of  1 variable:
$ V1: chr  "tropical fruit\"" "whole milk\"" "pip fruit\"" "other
vegetables\"" ...

Many Thanks in advance for your help.
Kind Regards,
Sam.

From pedone@m@uro @end|ng |rom gm@||@com  Tue Apr 14 12:26:03 2020
From: pedone@m@uro @end|ng |rom gm@||@com (Mauro Pedone)
Date: Tue, 14 Apr 2020 12:26:03 +0200
Subject: [R] spatstat installation
Message-ID: <CAKZHKxSbpEoNE-QfVp0sgt7gF4rfCdPtrw3dAh_1ktz0yeG-XA@mail.gmail.com>

Hello ,
I am trying the spatstat package installation
on R 3.3.0

the package is spatstat_1.63-3.tar.gz
,the OS is oracle enterprise linux 7

at the end I receive the error
Error : .onAttach failed in attachNamespace() for 'spatstat', details:
  call: if (today - as.Date(rdate) > 365) {
  error: missing value where TRUE/FALSE needed

ask to the community if someone encountered this problem.

thanks and regards

Mauro




root at ctrdb10 supporting]#  R CMD INSTALL spatstat_1.63-3.tar.gz
* installing to library ?/usr/lib64/R/library?
* installing *source* package ?spatstat? ...
** package ?spatstat? successfully unpacked and MD5 sums checked
** libs
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Ediggatsti.c -o
Ediggatsti.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Ediggra.c -o
Ediggra.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Efiksel.c -o
Efiksel.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Egeyer.c -o Egeyer.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Estrauss.c -o
Estrauss.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Kborder.c -o
Kborder.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Knone.c -o Knone.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Krect.c -o Krect.o
g++ -m64 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Perfect.cc -o
Perfect.o
gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
-I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
-I/systemr/port/Linux-X64/include/bzip2
-I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c areadiff.c -o
areadiff.o

....................................

....................................

    vcov.mppm                               html
    vcov.ppm                                html
    vcov.slrm                               html
    venn.tess                               html
    vertices                                html
    volume                                  html
    weighted.median                         html
    where.max                               html
    whichhalfplane                          html
    whist                                   html
    will.expand                             html
    with.fv                                 html
    with.hyperframe                         html
    with.msr                                html
    with.ssf                                html
    yardstick                               html
    zapsmall.im                             html
    zclustermodel                           html
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error : .onAttach failed in attachNamespace() for 'spatstat', details:
  call: if (today - as.Date(rdate) > 365) {
  error: missing value where TRUE/FALSE needed
Error: loading failed
Execution halted
ERROR: loading failed
* removing ?/usr/lib64/R/library/spatstat?

	[[alternative HTML version deleted]]


From er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t  Tue Apr 14 17:40:45 2020
From: er|ch@@ub@ @end|ng |rom neuw|rth@pr|v@@t (Erich Subscriptions)
Date: Tue, 14 Apr 2020 17:40:45 +0200
Subject: [R] A simple string alienation question.
In-Reply-To: <580244792.176097.1586856504159@mail.yahoo.com>
References: <CAGxFJbSAA1t7GF6=2Sv+43syUQtjq1pY-DBppsqE+OE5Rnvp5Q@mail.gmail.com>
 <24212.11722.632757.269523@stat.math.ethz.ch>
 <AA9D2F47-252B-4D37-9F75-027818AE810E@gmail.com>
 <24212.23386.542411.93591@stat.math.ethz.ch>
 <580244792.176097.1586856504159@mail.yahoo.com>
Message-ID: <264659DE-C84C-49ED-BE28-871028646AFC@neuwirth.priv.at>

read.csv has parameters sep, quote and dec
You have to get these right to represent the structure of you input file.

> On 14.04.2020, at 11:28, Sam Charya via R-help <r-help at r-project.org> wrote:
> 
> 
> 
> Hello Dear R Community,
> I would ask a little bit of help from you please:I have a dataset, which is in a CSV file ? I have read it into R as follows: 
>                  V11   tropical fruit"2       whole milk"3        pip fruit"4 other vegetables"5       whole milk"6       rolls/buns"
> The issue is: the data set in Csv file also appears with the quotation marks ?. I can?t get rid of the quotation marks. I want to do it in R. The Quotes only appear at the end of the string. The dataset has many rows ? this is just a copy. My intention is to be able to get rid of the quotes and then want to separate the strings with a ?/?. i.e. rolls/buns should be rolls in one column and buns in another.
> I know this is something very simple I am lacking ? but if you could please show me how to do this? If someone could throw some light please. I read the data in with a simple read.csv statement: 
> ? calc <- read.csv("Fight.csv", stringsAsFactors = F, header = F) ? str(x) 
> Output: > str(calc)'data.frame': 38765 obs. of  1 variable: $ V1: chr  "tropical fruit\"" "whole milk\"" "pip fruit\"" "other vegetables\"" ...
> Many Thanks in advance for your help.
> Kind Regards,
> Sam. 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btupper @end|ng |rom b|ge|ow@org  Tue Apr 14 19:41:26 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 14 Apr 2020 13:41:26 -0400
Subject: [R] Package renv and Rscript
Message-ID: <CALrbzg2+k0VVM56_cip0NVZpL8RHxCiVBz3CcnBTV8vcf5xwDg@mail.gmail.com>

Hi,

I am using renv (https://rstudio.github.io/renv/) to maintain a project
environment in a directory (ala /path/to/project)


Within the project I have a number of scripts that I call using...

$ Rscript /path/to/script.R /path/to/config_file

I can kick this off successfully with the renv environment when I manually
start Rscript within the project directory. Now I would like to be able to
hand the script kick off to either crontab or the PBS queueing system.

At first I thought I would actually call a wrapper script such that
accepted two arguments '/path/to/script.R' and '/path/to/config_file'. I
planned to use

renv::run('/path/to/script.R',


-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Tue Apr 14 19:52:37 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 14 Apr 2020 13:52:37 -0400
Subject: [R] Package renv and Rscript
In-Reply-To: <CALrbzg2+k0VVM56_cip0NVZpL8RHxCiVBz3CcnBTV8vcf5xwDg@mail.gmail.com>
References: <CALrbzg2+k0VVM56_cip0NVZpL8RHxCiVBz3CcnBTV8vcf5xwDg@mail.gmail.com>
Message-ID: <CALrbzg2bb_11vBC7UQJSBnjuhOJSN7y9=XV=1tzB7yA2NV5xSQ@mail.gmail.com>

Whoops!  The silly "send" button jumped out and grabbed my cursor before I
was ready for it.  Second try...

I am using renv (https://rstudio.github.io/renv/) to maintain a project
environment in a directory (ala '/path/to/project').

Within the project I have a number of scripts that I call with one argument
using...

$ Rscript /path/to/script.R /path/to/config_file

I can kick this off successfully with the renv environment when I manually
start Rscript within the project directory. Now I would like to be able to
hand the script kick-off to either crontab or the PBS queueing system.  But
I haven't figured out how to get the instance of R that is kicked off to do
so using the renv project space (i.e. using the R libraries as established
in the project.)

At first I thought I would call a simple wrapper script such that accepted
two arguments '/path/to/script.R' and '/path/to/config_file'. I planned to
use ...

###
args <- commandArgs(trailingOnly = TRUE)
path_to_script <- args[1]
path_to_config <- args[2]
renv::run(path_to_script,
          project = '/path/to/project')
###

Unfortunately renv::run() doesn't provide a vehicle for passing other
script arguments along.  So, in this case, there's no way to communicate
the configuration file to the script.

Is there a recommended way to call Rscript such that the renv environment
gets picked up?

Thanks!
Ben


On Tue, Apr 14, 2020 at 1:41 PM Ben Tupper <btupper at bigelow.org> wrote:

> Hi,
>
> I am using renv (https://rstudio.github.io/renv/) to maintain a project
> environment in a directory (ala /path/to/project)
>
>
> Within the project I have a number of scripts that I call using...
>
> $ Rscript /path/to/script.R /path/to/config_file
>
> I can kick this off successfully with the renv environment when I manually
> start Rscript within the project directory. Now I would like to be able to
> hand the script kick off to either crontab or the PBS queueing system.
>
> At first I thought I would actually call a wrapper script such that
> accepted two arguments '/path/to/script.R' and '/path/to/config_file'. I
> planned to use
>
> renv::run('/path/to/script.R',
>
>
> --
> Ben Tupper
> Bigelow Laboratory for Ocean Science
> East Boothbay, Maine
> http://www.bigelow.org/
> https://eco.bigelow.org
>
>

-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr 14 19:56:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 14 Apr 2020 10:56:04 -0700
Subject: [R] spatstat installation
In-Reply-To: <CAKZHKxSbpEoNE-QfVp0sgt7gF4rfCdPtrw3dAh_1ktz0yeG-XA@mail.gmail.com>
References: <CAKZHKxSbpEoNE-QfVp0sgt7gF4rfCdPtrw3dAh_1ktz0yeG-XA@mail.gmail.com>
Message-ID: <CAGxFJbTYuxpFAR2L3WpChWZ5m9MShUeYwfPd+3NK2tmh-wJ1+w@mail.gmail.com>

If you don't receive a satisfactory answer here in a day or so, post
on the R-sig-geo list where the experts in this sort of thing hang
around.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Apr 14, 2020 at 8:39 AM Mauro Pedone <pedone.mauro at gmail.com> wrote:
>
> Hello ,
> I am trying the spatstat package installation
> on R 3.3.0
>
> the package is spatstat_1.63-3.tar.gz
> ,the OS is oracle enterprise linux 7
>
> at the end I receive the error
> Error : .onAttach failed in attachNamespace() for 'spatstat', details:
>   call: if (today - as.Date(rdate) > 365) {
>   error: missing value where TRUE/FALSE needed
>
> ask to the community if someone encountered this problem.
>
> thanks and regards
>
> Mauro
>
>
>
>
> root at ctrdb10 supporting]#  R CMD INSTALL spatstat_1.63-3.tar.gz
> * installing to library ?/usr/lib64/R/library?
> * installing *source* package ?spatstat? ...
> ** package ?spatstat? successfully unpacked and MD5 sums checked
> ** libs
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Ediggatsti.c -o
> Ediggatsti.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Ediggra.c -o
> Ediggra.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Efiksel.c -o
> Efiksel.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Egeyer.c -o Egeyer.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Estrauss.c -o
> Estrauss.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Kborder.c -o
> Kborder.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Knone.c -o Knone.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Krect.c -o Krect.o
> g++ -m64 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c Perfect.cc -o
> Perfect.o
> gcc -m64 -std=gnu99 -I/usr/lib64/R/../../include/R -DNDEBUG
> -I/systemr/port/Linux-X64/include/zlib -I/systemr/port/Linux-X64/include/xz
> -I/systemr/port/Linux-X64/include/bzip2
> -I/systemr/port/Linux-X64/include     -fpic  -g -O2  -c areadiff.c -o
> areadiff.o
>
> ....................................
>
> ....................................
>
>     vcov.mppm                               html
>     vcov.ppm                                html
>     vcov.slrm                               html
>     venn.tess                               html
>     vertices                                html
>     volume                                  html
>     weighted.median                         html
>     where.max                               html
>     whichhalfplane                          html
>     whist                                   html
>     will.expand                             html
>     with.fv                                 html
>     with.hyperframe                         html
>     with.msr                                html
>     with.ssf                                html
>     yardstick                               html
>     zapsmall.im                             html
>     zclustermodel                           html
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error : .onAttach failed in attachNamespace() for 'spatstat', details:
>   call: if (today - as.Date(rdate) > 365) {
>   error: missing value where TRUE/FALSE needed
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing ?/usr/lib64/R/library/spatstat?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Apr 14 20:13:17 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 14 Apr 2020 20:13:17 +0200
Subject: [R] Package renv and Rscript
In-Reply-To: <CALrbzg2bb_11vBC7UQJSBnjuhOJSN7y9=XV=1tzB7yA2NV5xSQ@mail.gmail.com>
References: <CALrbzg2+k0VVM56_cip0NVZpL8RHxCiVBz3CcnBTV8vcf5xwDg@mail.gmail.com>
 <CALrbzg2bb_11vBC7UQJSBnjuhOJSN7y9=XV=1tzB7yA2NV5xSQ@mail.gmail.com>
Message-ID: <CAJuCY5w4evguYu1U8XoZYRKGy6t0h3KBKm=R35K98CXdFQxpCQ@mail.gmail.com>

Dear Ben,

I think that you first need to go to your project and then start Rscript
from that location. renv() needs to pick up the .Renviron file located at
the root of your project.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 14 apr. 2020 om 19:53 schreef Ben Tupper <btupper at bigelow.org>:

> Whoops!  The silly "send" button jumped out and grabbed my cursor before I
> was ready for it.  Second try...
>
> I am using renv (https://rstudio.github.io/renv/) to maintain a project
> environment in a directory (ala '/path/to/project').
>
> Within the project I have a number of scripts that I call with one argument
> using...
>
> $ Rscript /path/to/script.R /path/to/config_file
>
> I can kick this off successfully with the renv environment when I manually
> start Rscript within the project directory. Now I would like to be able to
> hand the script kick-off to either crontab or the PBS queueing system.  But
> I haven't figured out how to get the instance of R that is kicked off to do
> so using the renv project space (i.e. using the R libraries as established
> in the project.)
>
> At first I thought I would call a simple wrapper script such that accepted
> two arguments '/path/to/script.R' and '/path/to/config_file'. I planned to
> use ...
>
> ###
> args <- commandArgs(trailingOnly = TRUE)
> path_to_script <- args[1]
> path_to_config <- args[2]
> renv::run(path_to_script,
>           project = '/path/to/project')
> ###
>
> Unfortunately renv::run() doesn't provide a vehicle for passing other
> script arguments along.  So, in this case, there's no way to communicate
> the configuration file to the script.
>
> Is there a recommended way to call Rscript such that the renv environment
> gets picked up?
>
> Thanks!
> Ben
>
>
> On Tue, Apr 14, 2020 at 1:41 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> > Hi,
> >
> > I am using renv (https://rstudio.github.io/renv/) to maintain a project
> > environment in a directory (ala /path/to/project)
> >
> >
> > Within the project I have a number of scripts that I call using...
> >
> > $ Rscript /path/to/script.R /path/to/config_file
> >
> > I can kick this off successfully with the renv environment when I
> manually
> > start Rscript within the project directory. Now I would like to be able
> to
> > hand the script kick off to either crontab or the PBS queueing system.
> >
> > At first I thought I would actually call a wrapper script such that
> > accepted two arguments '/path/to/script.R' and '/path/to/config_file'. I
> > planned to use
> >
> > renv::run('/path/to/script.R',
> >
> >
> > --
> > Ben Tupper
> > Bigelow Laboratory for Ocean Science
> > East Boothbay, Maine
> > http://www.bigelow.org/
> > https://eco.bigelow.org
> >
> >
>
> --
> Ben Tupper
> Bigelow Laboratory for Ocean Science
> East Boothbay, Maine
> http://www.bigelow.org/
> https://eco.bigelow.org
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mure|th|h@dd|@on @end|ng |rom gm@||@com  Tue Apr 14 21:21:42 2020
From: mure|th|h@dd|@on @end|ng |rom gm@||@com (Haddison Mureithi)
Date: Tue, 14 Apr 2020 22:21:42 +0300
Subject: [R] Difference in offset values in R and STATA
Message-ID: <CABVwvn7N1Q-BcWtA0EzqgkzWWWU_YkWg5j5++fYSzNK7RuXzOg@mail.gmail.com>

Hae guys,
When performing a poisson regression sometimes one has to input the
offset/exposure variable to account for individual time spent in a certain
therapy before acquiring a certain condition of interest, whereby in r
offset(log(months)) and in STATA offset(log(months)) results differ.
Thereby increasing the difference of the overall outcome, i don't know why
any one know why?

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Tue Apr 14 21:36:12 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Tue, 14 Apr 2020 19:36:12 +0000
Subject: [R] Difference in offset values in R and STATA
In-Reply-To: <CABVwvn7N1Q-BcWtA0EzqgkzWWWU_YkWg5j5++fYSzNK7RuXzOg@mail.gmail.com>
References: <CABVwvn7N1Q-BcWtA0EzqgkzWWWU_YkWg5j5++fYSzNK7RuXzOg@mail.gmail.com>
Message-ID: <2B5B8B9F-C4FA-4C4F-B50D-492014FE2CFC@som.umaryland.edu>

Your question is unlikely to be answered unless you post code demonstrating the problem
J

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street<x-apple-data-detectors://12>
GRECC<x-apple-data-detectors://12> (BT/18/GR)
Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
(Phone) 410-605-711<tel:410-605-7119>9
(Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)

On Apr 14, 2020, at 3:23 PM, Haddison Mureithi <mureithihaddison at gmail.com> wrote:

?Hae guys,
When performing a poisson regression sometimes one has to input the
offset/exposure variable to account for individual time spent in a certain
therapy before acquiring a certain condition of interest, whereby in r
offset(log(months)) and in STATA offset(log(months)) results differ.
Thereby increasing the difference of the overall outcome, i don't know why
any one know why?

   [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cb386607c67fa45f5ac3508d7e0a923cc%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637224889939614430&amp;sdata=VsicWcmiBw162nLk6CZGKx5pKW4SbBliXeYY%2BLYu90Q%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cb386607c67fa45f5ac3508d7e0a923cc%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637224889939614430&amp;sdata=D4wrhP70NpBLjcE8Yd9JZCIykwqf4dDTla4Zkyk%2FQ5Q%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Tue Apr 14 21:37:29 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Tue, 14 Apr 2020 15:37:29 -0400
Subject: [R] Difference in offset values in R and STATA
In-Reply-To: <2B5B8B9F-C4FA-4C4F-B50D-492014FE2CFC@som.umaryland.edu>
References: <CABVwvn7N1Q-BcWtA0EzqgkzWWWU_YkWg5j5++fYSzNK7RuXzOg@mail.gmail.com>
 <2B5B8B9F-C4FA-4C4F-B50D-492014FE2CFC@som.umaryland.edu>
Message-ID: <CAJc=yOE8B4N-hgXdzoPHMZ2JB2jwKB9Ldu=fUROo+53=5bJbHg@mail.gmail.com>

Also, is the default base for "log" the same in both programs?


On Tue, Apr 14, 2020 at 3:36 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> Your question is unlikely to be answered unless you post code demonstrating the problem
> J
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street<x-apple-data-detectors://12>
> GRECC<x-apple-data-detectors://12> (BT/18/GR)
> Baltimore, MD 21201-1524<x-apple-data-detectors://13/0>
> (Phone) 410-605-711<tel:410-605-7119>9
> (Fax) 410-605-7913<tel:410-605-7913> (Please call phone number above prior to faxing)
>
> On Apr 14, 2020, at 3:23 PM, Haddison Mureithi <mureithihaddison at gmail.com> wrote:
>
> ?Hae guys,
> When performing a poisson regression sometimes one has to input the
> offset/exposure variable to account for individual time spent in a certain
> therapy before acquiring a certain condition of interest, whereby in r
> offset(log(months)) and in STATA offset(log(months)) results differ.
> Thereby increasing the difference of the overall outcome, i don't know why
> any one know why?
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cb386607c67fa45f5ac3508d7e0a923cc%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637224889939614430&amp;sdata=VsicWcmiBw162nLk6CZGKx5pKW4SbBliXeYY%2BLYu90Q%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cb386607c67fa45f5ac3508d7e0a923cc%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637224889939614430&amp;sdata=D4wrhP70NpBLjcE8Yd9JZCIykwqf4dDTla4Zkyk%2FQ5Q%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Apr 14 23:00:34 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 14 Apr 2020 21:00:34 +0000 (UTC)
Subject: [R] Span for loess regression
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
Message-ID: <546404572.1122955.1586898034318@mail.yahoo.com>

Dear R-experts,

I am trying to find the best span for my loess regression. Here below a reproducible example. I don't get the result. Am I missing something ?

Many thanks for your help.

############################################################
a<-c(2,3,4,3,2,6,5,7,4,5,12,13,21,6,4,5,6,7)
b<-c(12,13,32,14,23,21,76,34,12,32,43,23,12,32,43,12,32,11)
model <- loess(b ~ a)
bestLoess <- function(model, spans = c(.05, .95)) {
?f <- function(span) {
???????? mod <- update(model, span = span)
???????? loessGCV(mod)[["gcv"]]
???? }
???? result <- optimize(f, spans)
???? result
?}
#######################################################################


From btupper @end|ng |rom b|ge|ow@org  Tue Apr 14 23:12:31 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 14 Apr 2020 17:12:31 -0400
Subject: [R] Package renv and Rscript
In-Reply-To: <CAJuCY5w4evguYu1U8XoZYRKGy6t0h3KBKm=R35K98CXdFQxpCQ@mail.gmail.com>
References: <CALrbzg2+k0VVM56_cip0NVZpL8RHxCiVBz3CcnBTV8vcf5xwDg@mail.gmail.com>
 <CALrbzg2bb_11vBC7UQJSBnjuhOJSN7y9=XV=1tzB7yA2NV5xSQ@mail.gmail.com>
 <CAJuCY5w4evguYu1U8XoZYRKGy6t0h3KBKm=R35K98CXdFQxpCQ@mail.gmail.com>
Message-ID: <CALrbzg1RFvsX_PMX0=o5TJt6Hr_OjhucmfJ_6PwNO6LL1MSTFw@mail.gmail.com>

Hi,

Ah, of course - the wrapper would be a shell wrapper not an R wrapper ...

###
#!/bin/sh
cd /path/to/project
Rscript /path/to/script.R /path/to/config_file
###

Thanks so much!
Ben

On Tue, Apr 14, 2020 at 2:13 PM Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Ben,
>
> I think that you first need to go to your project and then start Rscript
> from that location. renv() needs to pick up the .Renviron file located at
> the root of your project.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op di 14 apr. 2020 om 19:53 schreef Ben Tupper <btupper at bigelow.org>:
>
>> Whoops!  The silly "send" button jumped out and grabbed my cursor before I
>> was ready for it.  Second try...
>>
>> I am using renv (https://rstudio.github.io/renv/) to maintain a project
>> environment in a directory (ala '/path/to/project').
>>
>> Within the project I have a number of scripts that I call with one
>> argument
>> using...
>>
>> $ Rscript /path/to/script.R /path/to/config_file
>>
>> I can kick this off successfully with the renv environment when I manually
>> start Rscript within the project directory. Now I would like to be able to
>> hand the script kick-off to either crontab or the PBS queueing system.
>> But
>> I haven't figured out how to get the instance of R that is kicked off to
>> do
>> so using the renv project space (i.e. using the R libraries as established
>> in the project.)
>>
>> At first I thought I would call a simple wrapper script such that accepted
>> two arguments '/path/to/script.R' and '/path/to/config_file'. I planned to
>> use ...
>>
>> ###
>> args <- commandArgs(trailingOnly = TRUE)
>> path_to_script <- args[1]
>> path_to_config <- args[2]
>> renv::run(path_to_script,
>>           project = '/path/to/project')
>> ###
>>
>> Unfortunately renv::run() doesn't provide a vehicle for passing other
>> script arguments along.  So, in this case, there's no way to communicate
>> the configuration file to the script.
>>
>> Is there a recommended way to call Rscript such that the renv environment
>> gets picked up?
>>
>> Thanks!
>> Ben
>>
>>
>> On Tue, Apr 14, 2020 at 1:41 PM Ben Tupper <btupper at bigelow.org> wrote:
>>
>> > Hi,
>> >
>> > I am using renv (https://rstudio.github.io/renv/) to maintain a project
>> > environment in a directory (ala /path/to/project)
>> >
>> >
>> > Within the project I have a number of scripts that I call using...
>> >
>> > $ Rscript /path/to/script.R /path/to/config_file
>> >
>> > I can kick this off successfully with the renv environment when I
>> manually
>> > start Rscript within the project directory. Now I would like to be able
>> to
>> > hand the script kick off to either crontab or the PBS queueing system.
>> >
>> > At first I thought I would actually call a wrapper script such that
>> > accepted two arguments '/path/to/script.R' and '/path/to/config_file'. I
>> > planned to use
>> >
>> > renv::run('/path/to/script.R',
>> >
>> >
>> > --
>> > Ben Tupper
>> > Bigelow Laboratory for Ocean Science
>> > East Boothbay, Maine
>> > http://www.bigelow.org/
>> > https://eco.bigelow.org
>> >
>> >
>>
>> --
>> Ben Tupper
>> Bigelow Laboratory for Ocean Science
>> East Boothbay, Maine
>> http://www.bigelow.org/
>> https://eco.bigelow.org
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Apr 15 08:16:49 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 15 Apr 2020 06:16:49 +0000
Subject: [R] A simple string alienation problem
In-Reply-To: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
References: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
Message-ID: <e1de1058ee4f40d3ac5fdc39050ac7d6@SRVEXCHCM1302.precheza.cz>

Hi

attachement did not went through, only limited attachement types are allowed - see Posting guide.

I am not sure if R is the best possibility to remove some characters. If " is at the end of all your strings

> dput(test)
structure(list(V1 = c("adfvadfg\"", "sdfasd\"", "vafdv\"", "hjk/tiuk\""
)), class = "data.frame", row.names = c(NA, -4L))
> test2 <- sapply(test, function(x) substr(x, 1, as.numeric(apply(test, 2, nchar))-1))

combination of sapply, apply and substr could remove trailing ".
> test2
     V1        
[1,] "adfvadfg"
[2,] "sdfasd"  
[3,] "vafdv"   
[4,] "hjk/tiuk"
>
And splitting acccording to / is simpler but it ends in list

> sapply(test2, function(x) strsplit(x, "/"))
$adfvadfg
[1] "adfvadfg"

$sdfasd
[1] "sdfasd"

$vafdv
[1] "vafdv"

$`hjk/tiuk`
[1] "hjk"  "tiuk"

Changing to data frame you could find yourself, I believe it is mentioned several times on Stackexchange, simple as.data.frame is not a best option.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Soumyadip
> Bhattacharyya
> Sent: Tuesday, April 14, 2020 12:55 PM
> To: r-help-request at r-project.org; r-help-owner at r-project.org; r-help at r-
> project.org; ericjberger at gmail.com
> Subject: [R] A simple string alienation problem
> 
> ***Dear Eric,*****
> sending from gmail following the way you suggested. Hope now everyone can
> see this email. **** I have also attached the first 50 rows of the
> FIght.csv.***
> ***Output - I will try to do Market basket analysis on this to find out rules
> that I am learning. so once I have the data in transactional format - then I can
> run the algorithm and keep learning. This little problem has caused a barrier
> in my path - I can alienate the string in excel - but wanted to do in R - so
> researching I tried doing this:
> x<- substr(x, 1, nchar(x) - 1)  // but I wasn't successful and I tried many other
> things - its not coming in the transactional format. *** Hence now reached
> out to the experts.**** Many Thanks.
> 
> Hello Dear R Community,
> 
> I would ask a little bit of help from you please:I have a dataset, which is in a
> CSV file ? I have read it into R as follows:
> 
>       V1
> tropical fruit"
> whole milk"
> pip fruit"
> other vegetables"
> whole milk"
> rolls/buns"
> 
> The issue is: the data set in csv file also appears with the quotation marks ?. I
> can?t get rid of the quotation marks. I want to do it in R.
> The Quotes only appear at the end of the string. The dataset has many rows ?
> this is just a copy. My intention is to be able to get rid of the quotes and then
> want to separate the strings with a ?/?. i.e.
> rolls/buns should be rolls in one column and buns in another.
> 
> I know this is something very simple I am lacking ? but if you could please
> show me how to do this? If someone could throw some light please. I read
> the data in with a simple read.csv statement:
> 
> > x <- read.csv("Fight.csv", stringsAsFactors = F, header = F)
> > str(x)
> Output:
> > str(calc)
> 'data.frame':   38765 obs. of  1 variable:
> $ V1: chr  "tropical fruit\"" "whole milk\"" "pip fruit\"" "other vegetables\"" ...
> 
> Many Thanks in advance for your help.
> Kind Regards,
> Sam.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From kry|ov@r00t @end|ng |rom gm@||@com  Wed Apr 15 09:49:20 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 15 Apr 2020 10:49:20 +0300
Subject: [R] Span for loess regression
In-Reply-To: <546404572.1122955.1586898034318@mail.yahoo.com>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
Message-ID: <20200415104920.0e4d68c5@Tarkus>

On Tue, 14 Apr 2020 21:00:34 +0000 (UTC)
varin sacha via R-help <r-help at r-project.org> wrote:

> Here below a reproducible example. I don't get the result.

Thanks for providing a concise piece of code.

The code doesn't return any visible results because the bestLoess
function created by it is never called. To get the results you should
call the function and pass the model object to it as an argument.

Another problem with the code is missing definition for loessGCV
function. I can only assume that the code is supposed to reference the
recently archived NormalizeMets CRAN package.

-- 
Best regards,
Ivan


From r@oknz @end|ng |rom gm@||@com  Wed Apr 15 14:17:29 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 16 Apr 2020 00:17:29 +1200
Subject: [R] A simple string alienation problem
In-Reply-To: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
References: <CANbGZRPvdOovYynS7pWHhLLiKS_opU0L9NdZ-SDpmHt0S60BQw@mail.gmail.com>
Message-ID: <CABcYAd+--hL_v=oFyjMW918FuGe+mYDa_8S+d8vTAJooXs4vcg@mail.gmail.com>

I'm very confused by the phrase "string alienation".
You mention two problems:
(1) remove " from a string
      sub('"', '', vector.of.strings)
      will do that.  See
      ?grep
      for details.
(2) split a string at occurrences of /
      strsplit(vector.of.strings, "/")
      will do that.  It gives you a list of vectors of strings.  See
      ?strsplit
      for details.


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Wed Apr 15 15:27:39 2020
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Wed, 15 Apr 2020 14:27:39 +0100
Subject: [R] Online course with on-demand video and live meetings:
 Introduction to Regression Models with Spatial Correlation using R-INLA
Message-ID: <98d49fb0-b45b-628d-ad7b-440db7ce892a@highstat.com>

We would like to announce the following online statistics course:


Online course with on-demand video and live meetings: 'Introduction to 
Regression Models with Spatial Correlation using R-INLA'

Remark: The course fee includes a 1-hour face-to-face video chat with 
one or both instructors.

When: 20 July - 7 August 2020
Time zone for live meetings: Multiple time zones, see the flyer.

Flyer: 
http://highstat.com/Courses/Flyers/2020/Flyer2020_07_SpatialGLM_Online.pdf

Website: http://highstat.com/index.php/courses-upcoming


Kind regards,


Alain Zuur

-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email:highstat at highstat.com
URL:www.highstat.com


	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Wed Apr 15 16:01:54 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 15 Apr 2020 14:01:54 +0000 (UTC)
Subject: [R] Span for loess regression
In-Reply-To: <20200415104920.0e4d68c5@Tarkus>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
 <20200415104920.0e4d68c5@Tarkus>
Message-ID: <1644618754.1831484.1586959314842@mail.yahoo.com>

Dear Ivan,

Many thanks I got it now. 

Best,




Le mercredi 15 avril 2020 ? 09:49:26 UTC+2, Ivan Krylov <krylov.r00t at gmail.com> a ?crit : 





On Tue, 14 Apr 2020 21:00:34 +0000 (UTC)

varin sacha via R-help <r-help at r-project.org> wrote:

> Here below a reproducible example. I don't get the result.


Thanks for providing a concise piece of code.

The code doesn't return any visible results because the bestLoess
function created by it is never called. To get the results you should
call the function and pass the model object to it as an argument.

Another problem with the code is missing definition for loessGCV
function. I can only assume that the code is supposed to reference the
recently archived NormalizeMets CRAN package.

-- 
Best regards,
Ivan


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Wed Apr 15 16:16:18 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Wed, 15 Apr 2020 14:16:18 +0000
Subject: [R] Correct way to cite R and RStudio in a manuscipt
Message-ID: <MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>

What is the proper way to cite R and Rstudio is a manuscript?
John


John David Sorkin M.D., Ph.D.

Professor of Medicine

Chief, Biostatistics and Informatics

University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine

Baltimore VA Medical Center

10 North Greene Street

GRECC (BT/18/GR)

Baltimore, MD 21201-1524

(Phone) 410-605-7119

(Fax) 410-605-7913 (Please call phone number above prior to faxing) 



From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 15 16:19:52 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 15 Apr 2020 07:19:52 -0700
Subject: [R] Fwd:  Correct way to cite R and RStudio in a manuscipt
In-Reply-To: <CAGxFJbS11Vtk-K2L-WGz1PGiE-0XJgNXHk1uw-o7NPec2GQevQ@mail.gmail.com>
References: <MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>
 <CAGxFJbS11Vtk-K2L-WGz1PGiE-0XJgNXHk1uw-o7NPec2GQevQ@mail.gmail.com>
Message-ID: <CAGxFJbRGJgicXJeNG7Vi1oFUqNsYwAXJH+pQzhGh2UGwMdJnFg@mail.gmail.com>

Sorry, neglected to respond to the list.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


---------- Forwarded message ---------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Apr 15, 2020 at 7:18 AM
Subject: Re: [R] Correct way to cite R and RStudio in a manuscipt
To: Sorkin, John <jsorkin at som.umaryland.edu>


?citation

As RStudio is not part of R, you'll have to ask that on their website.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 15, 2020 at 7:16 AM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> What is the proper way to cite R and Rstudio is a manuscript?
> John
>
>
> John David Sorkin M.D., Ph.D.
>
> Professor of Medicine
>
> Chief, Biostatistics and Informatics
>
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>
> Baltimore VA Medical Center
>
> 10 North Greene Street
>
> GRECC (BT/18/GR)
>
> Baltimore, MD 21201-1524
>
> (Phone) 410-605-7119
>
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Wed Apr 15 17:31:34 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 15 Apr 2020 15:31:34 +0000
Subject: [R] Correct way to cite R and RStudio in a manuscipt
In-Reply-To: <2803_1586960198_03FEGcVB013606_MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <2803_1586960198_03FEGcVB013606_MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <11FD26C1-69B2-44FE-A351-9CB1618C0B73@mcmaster.ca>

Dear John,

For R, see citation() .

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 15, 2020, at 10:16 AM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> What is the proper way to cite R and Rstudio is a manuscript?
> John
> 
> 
> John David Sorkin M.D., Ph.D.
> 
> Professor of Medicine
> 
> Chief, Biostatistics and Informatics
> 
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> 
> Baltimore VA Medical Center
> 
> 10 North Greene Street
> 
> GRECC (BT/18/GR)
> 
> Baltimore, MD 21201-1524
> 
> (Phone) 410-605-7119
> 
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Apr 15 19:14:12 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 15 Apr 2020 18:14:12 +0100
Subject: [R] Correct way to cite R and RStudio in a manuscipt
In-Reply-To: <MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB516789C2B0E19D657D3BDB2EE2DB0@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <a6c9f928-1c1a-68bd-2a2c-4f9e667e648a@sapo.pt>

Hello,

Run
to cite R:

citation()

to cite RStudio

RStudio.Version()

Hope this helps,

Rui Barradas

?s 15:16 de 15/04/20, Sorkin, John escreveu:
> What is the proper way to cite R and Rstudio is a manuscript?
> John
> 
> 
> John David Sorkin M.D., Ph.D.
> 
> Professor of Medicine
> 
> Chief, Biostatistics and Informatics
> 
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> 
> Baltimore VA Medical Center
> 
> 10 North Greene Street
> 
> GRECC (BT/18/GR)
> 
> Baltimore, MD 21201-1524
> 
> (Phone) 410-605-7119
> 
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@u|@b|v@nd @end|ng |rom gm@||@com  Wed Apr 15 19:33:05 2020
From: p@u|@b|v@nd @end|ng |rom gm@||@com (Paul Bivand)
Date: Wed, 15 Apr 2020 18:33:05 +0100
Subject: [R] R create .docx file ?
In-Reply-To: <E2A1D3A9-5818-434F-BA93-38A95B815D35@dcn.davis.ca.us>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
 <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
 <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>
 <CAGxFJbRvzg=nKyDThGeSasJNznA5dgN9D8SOw8uQr7zTdD+EoA@mail.gmail.com>
 <E2A1D3A9-5818-434F-BA93-38A95B815D35@dcn.davis.ca.us>
Message-ID: <CAC=KSNh4CX+XVy6vVXEmiEnk00UqPP=Q6ZAbsmwfsXNfe0gkog@mail.gmail.com>

However, the Reporters github page clearly says that the package has
been removed from CRAN and it has been replaced by the officer
package.

Note that ReporteRs has been removed from CRAN the 16th of July 2018
and is not maintained anymore. please migrate to officer.

https://cran.r-project.org/web/packages/officer/index.html

Paul


On Wed, 8 Apr 2020 at 18:22, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> The OP clearly hasn't followed the excellent documentation... this is not a maintainer problem. It is the act of printing the completed object that puts a file on disk.
>
> However, the package author recommends in the README that help be requested from stackoverflow, as the mailing list Posting Guidelines do warn that contributed packages are not technically on topic in R-help. (Simply from a practicality standpoint... there are thousands of them, each with potentially voluminous details to distract from the R language itself.)
>
> On April 8, 2020 10:08:09 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >But the OP explicitly notes that the read_docx package does *not* write
> >files and asks whether there are *other* packages or functions that
> >provide
> >that functionality. It still seems to me that the ReporteR maintainer
> >might
> >be the best place to go for that info, although there is certainly no
> >assurance that he can provide it.
> >
> >Bert
> >
> >On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> But before hassling the maintainer the OP should read the package
> >> vignettes and run some examples... read_docx does not write to any
> >files,
> >> so complaining that it doesn't will be fruitless.
> >>
> >> On April 8, 2020 9:31:41 AM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> >This sounds like the sort of specialized question that should be
> >> >directed
> >> >to the maintainer (?maintainer) rather than to a general Help list
> >such
> >> >as
> >> >this.
> >> >
> >> >Bert Gunter
> >> >
> >> >"The trouble with having an open mind is that people keep coming
> >along
> >> >and
> >> >sticking things into it."
> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >
> >> >
> >> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist
> ><jeremyclarkbio at gmail.com>
> >> >wrote:
> >> >
> >> >> Dear All,
> >> >>
> >> >> Mac Catalina - R 3.6.3 - all up-to-date packages.
> >> >> I would like to re-create the functionality which was found in the
> >> >package
> >> >> {ReporteRs} by creating a .docx file in a folder on my computer
> >from
> >> >within
> >> >> R - which can subsequently be used by the {officer} function
> >> >read_docx.
> >> >> The function read_docx on my system does NOT create a new
> >document,
> >> >and
> >> >> neither does the following code:
> >> >> new.word.doc=function(){ report = read_docx(path ..name..
> >".docx"))
> >> >> return(report) }
> >> >> doc=new.word.doc()
> >> >>
> >> >> I can use {base} file.create to create a file with an extension
> >.docx
> >> >- but
> >> >> apparently this is not a .docx file - and read_docx can't read it.
> >> >> Is there another R package or function which I can use in order to
> >> >create
> >> >> (and then close the link to R so that it can be used by another
> >> >package) a
> >> >> .docx file ?
> >> >>
> >> >> Many thanks in advance.
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 15 19:41:12 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 15 Apr 2020 10:41:12 -0700
Subject: [R] R create .docx file ?
In-Reply-To: <CAC=KSNh4CX+XVy6vVXEmiEnk00UqPP=Q6ZAbsmwfsXNfe0gkog@mail.gmail.com>
References: <CACyTWRZvrrVnmZaV31rXp-pz8KuWz0ys4TY74WB=CUBcCvuqyw@mail.gmail.com>
 <CAGxFJbR=TZi4i2LXcuLoFq+dgJVRp-O3cfJEOs48kUo__jWgfQ@mail.gmail.com>
 <8E5526F2-4B61-4EDD-81E6-E1F0D4DEB0B4@dcn.davis.ca.us>
 <CAGxFJbRvzg=nKyDThGeSasJNznA5dgN9D8SOw8uQr7zTdD+EoA@mail.gmail.com>
 <E2A1D3A9-5818-434F-BA93-38A95B815D35@dcn.davis.ca.us>
 <CAC=KSNh4CX+XVy6vVXEmiEnk00UqPP=Q6ZAbsmwfsXNfe0gkog@mail.gmail.com>
Message-ID: <21CEFC2E-460A-4356-A067-EC2352DA4527@dcn.davis.ca.us>

Indeed, replacing ReporteRs functionality was the topic of this thread. I know... it can be a bit much to read an entire thread, but reading is needed if you want to avoid non-sequitur, especially when the thread was not on topic for this mailing list to begin with.

On April 15, 2020 10:33:05 AM PDT, Paul Bivand <paul.bivand at gmail.com> wrote:
>However, the Reporters github page clearly says that the package has
>been removed from CRAN and it has been replaced by the officer
>package.
>
>Note that ReporteRs has been removed from CRAN the 16th of July 2018
>and is not maintained anymore. please migrate to officer.
>
>https://cran.r-project.org/web/packages/officer/index.html
>
>Paul
>
>
>On Wed, 8 Apr 2020 at 18:22, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>>
>> The OP clearly hasn't followed the excellent documentation... this is
>not a maintainer problem. It is the act of printing the completed
>object that puts a file on disk.
>>
>> However, the package author recommends in the README that help be
>requested from stackoverflow, as the mailing list Posting Guidelines do
>warn that contributed packages are not technically on topic in R-help.
>(Simply from a practicality standpoint... there are thousands of them,
>each with potentially voluminous details to distract from the R
>language itself.)
>>
>> On April 8, 2020 10:08:09 AM PDT, Bert Gunter
><bgunter.4567 at gmail.com> wrote:
>> >But the OP explicitly notes that the read_docx package does *not*
>write
>> >files and asks whether there are *other* packages or functions that
>> >provide
>> >that functionality. It still seems to me that the ReporteR
>maintainer
>> >might
>> >be the best place to go for that info, although there is certainly
>no
>> >assurance that he can provide it.
>> >
>> >Bert
>> >
>> >On Wed, Apr 8, 2020 at 9:56 AM Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> But before hassling the maintainer the OP should read the package
>> >> vignettes and run some examples... read_docx does not write to any
>> >files,
>> >> so complaining that it doesn't will be fruitless.
>> >>
>> >> On April 8, 2020 9:31:41 AM PDT, Bert Gunter
><bgunter.4567 at gmail.com>
>> >> wrote:
>> >> >This sounds like the sort of specialized question that should be
>> >> >directed
>> >> >to the maintainer (?maintainer) rather than to a general Help
>list
>> >such
>> >> >as
>> >> >this.
>> >> >
>> >> >Bert Gunter
>> >> >
>> >> >"The trouble with having an open mind is that people keep coming
>> >along
>> >> >and
>> >> >sticking things into it."
>> >> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>)
>> >> >
>> >> >
>> >> >On Wed, Apr 8, 2020 at 9:23 AM A Biologist
>> ><jeremyclarkbio at gmail.com>
>> >> >wrote:
>> >> >
>> >> >> Dear All,
>> >> >>
>> >> >> Mac Catalina - R 3.6.3 - all up-to-date packages.
>> >> >> I would like to re-create the functionality which was found in
>the
>> >> >package
>> >> >> {ReporteRs} by creating a .docx file in a folder on my computer
>> >from
>> >> >within
>> >> >> R - which can subsequently be used by the {officer} function
>> >> >read_docx.
>> >> >> The function read_docx on my system does NOT create a new
>> >document,
>> >> >and
>> >> >> neither does the following code:
>> >> >> new.word.doc=function(){ report = read_docx(path ..name..
>> >".docx"))
>> >> >> return(report) }
>> >> >> doc=new.word.doc()
>> >> >>
>> >> >> I can use {base} file.create to create a file with an extension
>> >.docx
>> >> >- but
>> >> >> apparently this is not a .docx file - and read_docx can't read
>it.
>> >> >> Is there another R package or function which I can use in order
>to
>> >> >create
>> >> >> (and then close the link to R so that it can be used by another
>> >> >package) a
>> >> >> .docx file ?
>> >> >>
>> >> >> Many thanks in advance.
>> >> >>
>> >> >>         [[alternative HTML version deleted]]
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible
>code.
>> >> >>
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Apr 15 23:32:03 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 15 Apr 2020 23:32:03 +0200
Subject: [R] Error: all the ROC metric values are missing:
Message-ID: <CA+nrPnsVCejYdcXKRz=8MZrviRWEjKh8t+vwC0rA9SfvW_m5sw@mail.gmail.com>

What is the problem is the code..

d=readARFF("CM1.arff")

index <- createDataPartition(d$Defective, p = .70,list = FALSE)
tr <- d[index, ]
ts <- d[-index, ]
index_2 <- createFolds(tr$Defective, returnTrain = TRUE, list = TRUE)

ctrl <- trainControl(method = "boot", number=100, index = index_2,
search="random", classProbs = TRUE,
 summaryFunction=twoClassSummary,savePredictions = T)


net <- train(Defective ~ ., data = tr,
           method = "nnet",
           metric = "ROC",
           preProc = c("center", "scale", "nzv" ),
           trControl = ctrl, na.action=na.exclude)
getTrainPerf(net)


I am getting the error as below:

Something is wrong; all the ROC metric values are missing:
      ROC           Sens          Spec
 Min.   : NA   Min.   : NA   Min.   : NA
 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
 Median : NA   Median : NA   Median : NA
 Mean   :NaN   Mean   :NaN   Mean   :NaN
 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
 Max.   : NA   Max.   : NA   Max.   : NA
 NA's   :3     NA's   :3     NA's   :3

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 15 23:55:13 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 15 Apr 2020 14:55:13 -0700
Subject: [R] Error: all the ROC metric values are missing:
In-Reply-To: <CA+nrPnsVCejYdcXKRz=8MZrviRWEjKh8t+vwC0rA9SfvW_m5sw@mail.gmail.com>
References: <CA+nrPnsVCejYdcXKRz=8MZrviRWEjKh8t+vwC0rA9SfvW_m5sw@mail.gmail.com>
Message-ID: <BEE3DEAB-EFD5-4DA4-812D-4A5F9E607F7A@dcn.davis.ca.us>

Someday, Neha, you will learn to post a reproducible example using plain text. I hope.

Try using the reprex package.

On April 15, 2020 2:32:03 PM PDT, Neha gupta <neha.bologna90 at gmail.com> wrote:
>What is the problem is the code..
>
>d=readARFF("CM1.arff")
>
>index <- createDataPartition(d$Defective, p = .70,list = FALSE)
>tr <- d[index, ]
>ts <- d[-index, ]
>index_2 <- createFolds(tr$Defective, returnTrain = TRUE, list = TRUE)
>
>ctrl <- trainControl(method = "boot", number=100, index = index_2,
>search="random", classProbs = TRUE,
> summaryFunction=twoClassSummary,savePredictions = T)
>
>
>net <- train(Defective ~ ., data = tr,
>           method = "nnet",
>           metric = "ROC",
>           preProc = c("center", "scale", "nzv" ),
>           trControl = ctrl, na.action=na.exclude)
>getTrainPerf(net)
>
>
>I am getting the error as below:
>
>Something is wrong; all the ROC metric values are missing:
>      ROC           Sens          Spec
> Min.   : NA   Min.   : NA   Min.   : NA
> 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
> Median : NA   Median : NA   Median : NA
> Mean   :NaN   Mean   :NaN   Mean   :NaN
> 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
> Max.   : NA   Max.   : NA   Max.   : NA
> NA's   :3     NA's   :3     NA's   :3
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Thu Apr 16 00:05:41 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Thu, 16 Apr 2020 00:05:41 +0200
Subject: [R] Error: all the ROC metric values are missing:
In-Reply-To: <BEE3DEAB-EFD5-4DA4-812D-4A5F9E607F7A@dcn.davis.ca.us>
References: <CA+nrPnsVCejYdcXKRz=8MZrviRWEjKh8t+vwC0rA9SfvW_m5sw@mail.gmail.com>
 <BEE3DEAB-EFD5-4DA4-812D-4A5F9E607F7A@dcn.davis.ca.us>
Message-ID: <CA+nrPntVQ3Jdk8y2rG2MfuAT3DPGBMksT6ew+CF36hs01t2YcA@mail.gmail.com>

d=readARFF("CM1.arff")
dput( head( d, 50 ) )

structure(list(LOC_BLANK = c(6, 15, 27, 1, 7, 51, 3, 13, 22,
16, 4, 23, 23, 40, 23, 8, 2, 19, 0, 7, 6, 134, 9, 164, 27, 4,
5, 7, 16, 15, 19, 19, 15, 13, 14, 12, 23, 155, 42, 30, 9, 26,
40, 7, 7, 93, 9, 3, 12, 31), BRANCH_COUNT = c(9, 7, 9, 1, 3,
25, 5, 9, 29, 9, 3, 13, 13, 9, 9, 3, 1, 3, 1, 6, 7, 60, 8, 110,
24, 1, 5, 9, 5, 7, 5, 7, 11, 3, 9, 9, 9, 71, 11, 19, 3, 17, 11,
3, 7, 25, 5, 1, 7, 11), CALL_PAIRS = c(2, 3, 1, 2, 2, 13, 2,
5, 0, 2, 0, 0, 0, 4, 6, 1, 1, 1, 1, 0, 0, 9, 2, 26, 11, 1, 1,
3, 7, 3, 4, 5, 4, 1, 3, 4, 5, 5, 10, 5, 2, 4, 12, 2, 2, 10, 3,
1, 2, 5), LOC_CODE_AND_COMMENT = c(1, 1, 4, 0, 0, 0, 0, 12, 8,
11, 2, 10, 10, 2, 3, 6, 1, 2, 1, 1, 6, 63, 4, 37, 3, 0, 0, 4,
2, 3, 2, 5, 5, 3, 2, 2, 10, 14, 5, 6, 0, 5, 3, 0, 0, 11, 2, 0,
2, 7), LOC_COMMENTS = c(0, 19, 22, 0, 0, 14, 0, 16, 35, 28, 4,
17, 17, 15, 20, 5, 1, 0, 1, 0, 0, 31, 5, 191, 48, 10, 0, 5, 24,
8, 16, 10, 19, 18, 20, 12, 9, 170, 44, 45, 7, 32, 47, 6, 8, 57,
2, 3, 2, 30), CONDITION_COUNT = c(16, 12, 16, 0, 4, 48, 8, 16,
44, 12, 4, 24, 24, 16, 16, 4, 0, 4, 0, 0, 10, 38, 8, 128, 34,
0, 8, 14, 8, 12, 8, 12, 20, 4, 16, 16, 16, 122, 20, 36, 4, 28,
20, 0, 12, 48, 8, 0, 12, 20), CYCLOMATIC_COMPLEXITY = c(5, 4,
5, 1, 2, 13, 3, 5, 15, 5, 2, 7, 7, 5, 5, 2, 1, 2, 1, 5, 4, 41,
5, 70, 13, 1, 3, 5, 3, 4, 3, 4, 6, 2, 5, 5, 5, 37, 6, 10, 2,
9, 6, 2, 4, 13, 3, 1, 4, 6), CYCLOMATIC_DENSITY = c(0.2, 0.13,
0.15, 0.14, 0.17, 0.12, 0.2, 0.14, 0.28, 0.11, 0.17, 0.21, 0.21,
0.15, 0.19, 0.11, 0.14, 0.06, 0.14, 0.12, 0.15, 0.17, 0.28, 0.18,
0.16, 0.03, 0.15, 0.16, 0.18, 0.25, 0.11, 0.15, 0.18, 0.1, 0.19,
0.13, 0.12, 0.18, 0.16, 0.13, 0.13, 0.13, 0.14, 0.25, 0.16, 0.08,
0.16, 0.13, 0.2, 0.15), DECISION_COUNT = c(8, 6, 8, 0, 2, 24,
4, 8, 16, 4, 2, 12, 12, 8, 8, 2, 0, 2, 0, 0, 4, 16, 4, 54, 14,
0, 4, 6, 4, 6, 4, 6, 10, 2, 8, 8, 8, 58, 10, 18, 2, 12, 10, 0,
6, 24, 4, 0, 6, 10), DECISION_DENSITY = c(2, 2, 2, NA, 2, 2,
2, 2, 2.75, 3, 2, 2, 2, 2, 2, 2, NA, 2, NA, NA, 2.5, 2.38, 2,
2.37, 2.43, NA, 2, 2.33, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2.1, 2, 2,
2, 2.33, 2, NA, 2, 2, 2, NA, 2, 2), DESIGN_COMPLEXITY = c(3,
2, 3, 1, 2, 11, 3, 5, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1,
23, 3, 46, 10, 1, 3, 3, 3, 4, 3, 4, 4, 2, 3, 5, 5, 26, 6, 9,
2, 6, 5, 1, 1, 12, 3, 1, 4, 5), DESIGN_DENSITY = c(0.6, 0.5,
0.6, 1, 1, 0.85, 1, 1, 0.07, 0.2, 0.5, 0.14, 0.14, 0.4, 0.4,
0.5, 1, 1, 1, 0.2, 0.25, 0.56, 0.6, 0.66, 0.77, 1, 1, 0.6, 1,
1, 1, 1, 0.67, 1, 0.6, 1, 1, 0.7, 1, 0.9, 1, 0.67, 0.83, 0.5,
0.25, 0.92, 1, 1, 1, 0.83), EDGE_COUNT = c(17, 17, 18, 3, 6,
96, 12, 21, 45, 21, 6, 27, 27, 21, 23, 7, 2, 23, 2, 12, 13, 118,
14, 241, 53, 2, 10, 20, 15, 15, 14, 15, 23, 6, 21, 22, 21, 148,
30, 48, 6, 39, 40, 8, 16, 69, 11, 7, 14, 26), ESSENTIAL_COMPLEXITY = c(1,
1, 1, 1, 1, 1, 1, 5, 3, 5, 1, 5, 5, 1, 1, 1, 1, 1, 1, 1, 4, 6,
1, 27, 7, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 5, 21, 1, 8, 1, 4,
1, 1, 1, 1, 1, 1, 1, 1), ESSENTIAL_DENSITY = c(0, 0, 0, 0, 0,
0, 0, 1, 0.14, 1, 0, 0.67, 0.67, 0, 0, 0, 0, 0, 0, 0, 1, 0.13,
0, 0.38, 0.5, 0, 0, 0.5, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0.56, 0,
0.78, 0, 0.38, 0, 0, 0, 0, 0, 0, 0, 0), LOC_EXECUTABLE = c(24,
31, 29, 7, 12, 106, 15, 25, 46, 34, 10, 23, 23, 31, 24, 13, 6,
33, 6, 41, 21, 177, 14, 361, 76, 31, 20, 27, 15, 13, 25, 22,
28, 18, 24, 38, 31, 196, 32, 71, 15, 62, 41, 8, 25, 143, 17,
8, 18, 33), PARAMETER_COUNT = c(3, 1, 0, 1, 2, 2, 1, 4, 0, 2,
1, 3, 3, 0, 0, 1, 1, 0, 1, 1, 1, 5, 0, 1, 1, 0, 1, 0, 1, 0, 1,
1, 2, 2, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0),
GLOBAL_DATA_COMPLEXITY = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0), GLOBAL_DATA_DENSITY = c(0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0), HALSTEAD_CONTENT = c(32.54, 38.55, 52.03, 17.43, 14.62,
101.31, 8.17, 38.51, 61.1, 41.24, 15.9, 27.4, 17.45, 47.41, 43.1,
29.61, 13.88, 64.01, 13.88, 36.35, 21.34, 101.81, 12.36, 157.03,
60.5, 116.21, 34.17, 24.71, 36.19, 26.75, 48.49, 28.43, 30.61,
25.62, 27.08, 54.44, 54.55, 127.7, 53.31, 46.15, 27.05, 97.49,
61.64, 28.75, 31.67, 175.18, 36.74, 24.41, 54.3, 53.63),
HALSTEAD_DIFFICULTY = c(9.5,
21.52, 12.33, 2, 6.43, 27.04, 18, 14.25, 22.3, 20.76, 9, 28.12,
27.22, 27.5, 15.2, 9.15, 4, 11.65, 4, 21.98, 24.44, 54.82, 15,
97.73, 32.21, 22.83, 10.29, 21.86, 7.18, 11.03, 14.11, 13.42,
23.1, 24.42, 39.72, 19.25, 14.84, 71.54, 12.89, 27.11, 14.25,
20.91, 16.96, 5.5, 15, 28.52, 14.57, 8.36, 7.89, 18.46), HALSTEAD_EFFORT =
c(2936.77,
17846.19, 7914.68, 69.74, 604.36, 74089.87, 2648.68, 7820.87,
30377.95, 17773.08, 1287.55, 21659.58, 12929.85, 35852.6, 9958,
2480.95, 222.03, 8684.99, 222.03, 17553.08, 12748.97, 305928.62,
2781.99, 1499684.32, 62767.66, 60566.12, 3620.93, 11802.86, 1867.89,
3253.68, 9649.29, 5120.93, 16332.07, 15282.02, 42716.37, 20172.82,
12009.6, 653537.1, 8852.8, 33930.43, 5493.37, 42621.97, 17733.62,
869.68, 7125, 142535.33, 7799.92, 1704.86, 3382.91, 18269.63),
    HALSTEAD_ERROR_EST = c(0.1, 0.28, 0.21, 0.01, 0.03, 0.91,
    0.05, 0.18, 0.45, 0.29, 0.05, 0.26, 0.16, 0.43, 0.22, 0.09,
    0.02, 0.25, 0.02, 0.27, 0.17, 1.86, 0.06, 5.12, 0.65, 0.88,
    0.12, 0.18, 0.09, 0.1, 0.23, 0.13, 0.24, 0.21, 0.36, 0.35,
    0.27, 3.05, 0.23, 0.42, 0.13, 0.68, 0.35, 0.05, 0.16, 1.67,
    0.18, 0.07, 0.14, 0.33), HALSTEAD_LENGTH = c(63, 141, 111,
    11, 23, 421, 36, 107, 239, 155, 35, 157, 105, 231, 120, 57,
    15, 135, 15, 157, 98, 767, 41, 1844, 298, 461, 71, 108, 52,
    59, 120, 75, 128, 122, 197, 176, 140, 1177, 123, 211, 74,
    314, 177, 36, 95, 695, 102, 51, 80, 172), HALSTEAD_LEVEL = c(0.11,
    0.05, 0.08, 0.5, 0.16, 0.04, 0.06, 0.07, 0.04, 0.05, 0.11,
    0.04, 0.04, 0.04, 0.07, 0.11, 0.25, 0.09, 0.25, 0.05, 0.04,
    0.02, 0.07, 0.01, 0.03, 0.04, 0.1, 0.05, 0.14, 0.09, 0.07,
    0.07, 0.04, 0.04, 0.03, 0.05, 0.07, 0.01, 0.08, 0.04, 0.07,
    0.05, 0.06, 0.18, 0.07, 0.04, 0.07, 0.12, 0.13, 0.05),
HALSTEAD_PROG_TIME = c(163.15,
    991.46, 439.7, 3.87, 33.58, 4116.1, 147.15, 434.49, 1687.66,
    987.39, 71.53, 1203.31, 718.32, 1991.81, 553.22, 137.83,
    12.33, 482.5, 12.33, 975.17, 708.28, 16996.03, 154.56, 83315.8,
    3487.09, 3364.78, 201.16, 655.71, 103.77, 180.76, 536.07,
    284.5, 907.34, 849, 2373.13, 1120.71, 667.2, 36307.62, 491.82,
    1885.02, 305.19, 2367.89, 985.2, 48.32, 395.83, 7918.63,
    433.33, 94.71, 187.94, 1014.98), HALSTEAD_VOLUME = c(309.13,
    829.45, 641.73, 34.87, 94.01, 2739.78, 147.15, 548.83, 1362.41,
    856.15, 143.06, 770.38, 474.97, 1303.73, 655.13, 271.03,
    55.51, 745.68, 55.51, 798.73, 521.54, 5580.79, 185.47, 15345.64,
    1948.67, 2653, 351.75, 540, 260, 295, 684.05, 381.56, 707.02,
    625.77, 1075.51, 1047.94, 809.39, 9135.35, 686.95, 1251.39,
    385.5, 2038.44, 1045.52, 158.12, 475, 4996.93, 535.29, 204,
    428.6, 989.84), MAINTENANCE_SEVERITY = c(0.2, 0.25, 0.2,
    1, 0.5, 0.08, 0.33, 1, 0.2, 1, 0.5, 0.71, 0.71, 0.2, 0.2,
    0.5, 1, 0.5, 1, 0.2, 1, 0.15, 0.2, 0.39, 0.54, 1, 0.33, 0.6,
    0.33, 0.25, 0.33, 1, 0.17, 0.5, 0.2, 0.2, 1, 0.57, 0.17,
    0.8, 0.5, 0.44, 0.17, 0.5, 0.25, 0.08, 0.33, 1, 0.25, 0.17
    ), MODIFIED_CONDITION_COUNT = c(4, 3, 4, 0, 1, 12, 2, 4,
    14, 4, 1, 6, 6, 4, 4, 1, 0, 1, 0, 0, 3, 11, 2, 37, 10, 0,
    2, 4, 2, 3, 2, 3, 5, 1, 4, 4, 4, 32, 5, 9, 1, 8, 5, 0, 3,
    12, 2, 0, 3, 5), MULTIPLE_CONDITION_COUNT = c(8, 6, 8, 0,
    2, 24, 4, 8, 22, 6, 2, 12, 12, 8, 8, 2, 0, 2, 0, 0, 5, 19,
    4, 66, 19, 0, 4, 7, 4, 6, 4, 6, 10, 2, 8, 8, 8, 61, 10, 18,
    2, 14, 10, 0, 6, 24, 4, 0, 6, 10), NODE_COUNT = c(14, 15,
    15, 4, 6, 85, 11, 18, 32, 18, 6, 22, 22, 18, 20, 7, 3, 23,
    3, 9, 11, 79, 11, 173, 42, 3, 9, 17, 14, 13, 13, 13, 19,
    6, 18, 19, 18, 113, 26, 40, 6, 32, 36, 8, 14, 58, 10, 8,
    12, 22), NORMALIZED_CYLOMATIC_COMPLEXITY = c(0.16, 0.06,
    0.06, 0.11, 0.1, 0.08, 0.16, 0.07, 0.13, 0.06, 0.1, 0.09,
    0.09, 0.06, 0.07, 0.06, 0.09, 0.04, 0.11, 0.1, 0.12, 0.1,
    0.15, 0.09, 0.08, 0.02, 0.12, 0.11, 0.05, 0.1, 0.04, 0.07,
    0.08, 0.04, 0.07, 0.07, 0.07, 0.07, 0.05, 0.07, 0.06, 0.07,
    0.05, 0.09, 0.1, 0.04, 0.1, 0.03, 0.11, 0.06), NUM_OPERANDS = c(19,
    51, 37, 5, 9, 192, 15, 38, 110, 59, 16, 43, 35, 70, 40, 17,
    5, 66, 5, 71, 40, 268, 16, 711, 102, 144, 25, 34, 21, 25,
    49, 34, 55, 58, 87, 70, 61, 454, 47, 73, 27, 115, 63, 10,
    30, 290, 36, 13, 34, 68), NUM_OPERATORS = c(44, 90, 74, 6,
    14, 229, 21, 69, 129, 96, 19, 114, 70, 161, 80, 40, 10, 69,
    10, 86, 58, 499, 25, 1133, 196, 317, 46, 74, 31, 34, 71,
    41, 73, 64, 110, 106, 79, 723, 76, 138, 47, 199, 114, 26,
    65, 405, 66, 38, 46, 104), NUM_UNIQUE_OPERANDS = c(15, 32,
    33, 5, 7, 71, 5, 20, 37, 27, 8, 13, 9, 28, 25, 13, 5, 34,
    5, 21, 18, 110, 8, 251, 57, 41, 17, 14, 19, 17, 33, 19, 25,
    19, 23, 40, 37, 165, 31, 35, 18, 66, 39, 10, 16, 122, 21,
    7, 28, 35), NUM_UNIQUE_OPERATORS = c(15, 27, 22, 4, 10, 20,
    12, 15, 15, 19, 9, 17, 14, 22, 19, 14, 8, 12, 8, 13, 22,
    45, 15, 69, 36, 13, 14, 18, 13, 15, 19, 15, 21, 16, 21, 22,
    18, 52, 17, 26, 19, 24, 21, 11, 16, 24, 17, 9, 13, 19), NUMBER_OF_LINES
= c(32,
    67, 83, 9, 20, 172, 19, 67, 112, 90, 21, 74, 74, 89, 71,
    33, 11, 55, 9, 50, 34, 406, 33, 764, 155, 46, 26, 44, 58,
    40, 70, 57, 75, 53, 68, 73, 74, 536, 124, 153, 32, 126, 132,
    22, 41, 305, 31, 32, 35, 102), PATHOLOGICAL_COMPLEXITY = c(1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), PERCENT_COMMENTS = c(4,
    39.22, 47.27, 0, 0, 11.67, 0, 52.83, 48.31, 53.42, 37.5,
    54, 54, 35.42, 48.94, 45.83, 25, 5.71, 25, 2.38, 22.22, 34.69,
    39.13, 38.71, 40.16, 24.39, 0, 25, 63.41, 45.83, 41.86, 40.54,
    46.15, 53.85, 47.83, 26.92, 38, 48.42, 60.49, 41.8, 31.82,
    37.37, 54.95, 42.86, 24.24, 32.22, 19.05, 27.27, 18.18, 52.86
    ), LOC_TOTAL = c(25, 32, 33, 7, 12, 106, 15, 37, 54, 45,
    12, 33, 33, 33, 27, 19, 7, 35, 7, 42, 27, 240, 18, 398, 79,
    31, 20, 31, 17, 16, 27, 27, 33, 21, 26, 40, 41, 210, 37,
    77, 15, 67, 44, 8, 25, 154, 19, 8, 20, 40), Defective = structure(c(2L,
    1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L,
    2L, 2L, 2L, 1L), .Label = c("Y", "N"), class = "factor")), row.names =
c(NA,
50L), class = "data.frame")
>

On Wed, Apr 15, 2020 at 11:55 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Someday, Neha, you will learn to post a reproducible example using plain
> text. I hope.
>
> Try using the reprex package.
>
> On April 15, 2020 2:32:03 PM PDT, Neha gupta <neha.bologna90 at gmail.com>
> wrote:
> >What is the problem is the code..
> >
> >d=readARFF("CM1.arff")
> >
> >index <- createDataPartition(d$Defective, p = .70,list = FALSE)
> >tr <- d[index, ]
> >ts <- d[-index, ]
> >index_2 <- createFolds(tr$Defective, returnTrain = TRUE, list = TRUE)
> >
> >ctrl <- trainControl(method = "boot", number=100, index = index_2,
> >search="random", classProbs = TRUE,
> > summaryFunction=twoClassSummary,savePredictions = T)
> >
> >
> >net <- train(Defective ~ ., data = tr,
> >           method = "nnet",
> >           metric = "ROC",
> >           preProc = c("center", "scale", "nzv" ),
> >           trControl = ctrl, na.action=na.exclude)
> >getTrainPerf(net)
> >
> >
> >I am getting the error as below:
> >
> >Something is wrong; all the ROC metric values are missing:
> >      ROC           Sens          Spec
> > Min.   : NA   Min.   : NA   Min.   : NA
> > 1st Qu.: NA   1st Qu.: NA   1st Qu.: NA
> > Median : NA   Median : NA   Median : NA
> > Mean   :NaN   Mean   :NaN   Mean   :NaN
> > 3rd Qu.: NA   3rd Qu.: NA   3rd Qu.: NA
> > Max.   : NA   Max.   : NA   Max.   : NA
> > NA's   :3     NA's   :3     NA's   :3
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Thu Apr 16 00:26:06 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 16 Apr 2020 10:26:06 +1200
Subject: [R] Online course with on-demand video and live meetings:
 Introduction to Regression Models with Spatial Correlation using R-INLA
In-Reply-To: <98d49fb0-b45b-628d-ad7b-440db7ce892a@highstat.com>
References: <98d49fb0-b45b-628d-ad7b-440db7ce892a@highstat.com>
Message-ID: <CAB8pepx9Nf9yqjLoh2V4rHtafUgo2OubG+fFpL6dScNm9vLHhw@mail.gmail.com>

My guess is that this mailing list is not designed for advertising, but...

Why is the source file for the package 320 MB?
https://inla.r-inla-download.org/R/stable/src/contrib/

And are there any other reasons why this package is not on CRAN (or
bioconductor)?


On Thu, Apr 16, 2020 at 1:28 AM Highland Statistics Ltd
<highstat at highstat.com> wrote:
>
> We would like to announce the following online statistics course:
>
>
> Online course with on-demand video and live meetings: 'Introduction to
> Regression Models with Spatial Correlation using R-INLA'
>
> Remark: The course fee includes a 1-hour face-to-face video chat with
> one or both instructors.
>
> When: 20 July - 7 August 2020
> Time zone for live meetings: Multiple time zones, see the flyer.
>
> Flyer:
> http://highstat.com/Courses/Flyers/2020/Flyer2020_07_SpatialGLM_Online.pdf
>
> Website: http://highstat.com/index.php/courses-upcoming
>
>
> Kind regards,
>
>
> Alain Zuur
>
> --
>
> Dr. Alain F. Zuur
> Highland Statistics Ltd.
> 9 St Clair Wynd
> AB41 6DZ Newburgh, UK
> Email:highstat at highstat.com
> URL:www.highstat.com
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pne|@on1 @end|ng |rom uc@c@edu  Wed Apr 15 20:31:11 2020
From: pne|@on1 @end|ng |rom uc@c@edu (Peter Nelson)
Date: Wed, 15 Apr 2020 11:31:11 -0700
Subject: [R] parsing DOB data
Message-ID: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>

I have a data set (.csv) with date (eg date of birth) information stored as character vectors that I?m attempting to transform to POSIXct objects using the package lubridate (1.7.4). The problem that I?m trying to address is that my two digit years are invariably (?) parsed to 20xx. For example,

x <- c("45-12-03","01-06-24","64-9-15?)
ymd(x)
[1] "2045-12-03" "2001-06-24" "2064-09-15?

These should be parsed as ?1945-12-03? ?2001-06-24? ?1964-09-15?. 

I've tried to use parse_date_time()?based on the documentation it looks to me as though the argument cutoff_2000 should allow me to address this, but it?s unclear to me how to implement this. As an example, I?ve tried

parse_date_time(x, cutoff_2000 = 01)

but get the following error message (and similar for other similar attempts, including cutoff_2000 = 01L)

Error in parse_date_time(x, cutoff_2000 = 1) : 
  unused argument (cutoff_2000 = 1)

Thanks for your help!

Peter Nelson, PhD
Institute of Marine Sciences
University of California, Santa Cruz
Center for Ocean Health, Long Marine Lab
115 McAllistair Way
Santa Cruz, CA, 95076, USA
707-267-5896






	[[alternative HTML version deleted]]


From ||9212001 @end|ng |rom y@hoo@com  Wed Apr 15 23:27:58 2020
From: ||9212001 @end|ng |rom y@hoo@com (aiguo li)
Date: Wed, 15 Apr 2020 21:27:58 +0000 (UTC)
Subject: [R] calculate row median of every three columns for a dataframe
References: <2049048336.1192800.1586986078421.ref@mail.yahoo.com>
Message-ID: <2049048336.1192800.1586986078421@mail.yahoo.com>

 Hi all,
I need to calculate a row median for every three columns of a dataframe.? I made it work using the following script, but not happy with the script.? Is there a simpler way for doing this?
df = data.frame("a"=c(2,3,4), "b"=c(3,5,1),"c"=c(1,3,6),"d"=c(7,2,1),"e"=c(2,5,3),"f"=c(4,5,1))tmed <- function(dt) {x = apply(dt,1,median); return(x)}n =seq(1, ncol(df),3)w=0;for (i in n) {?? m=i+2;? dt = df[,i:m];? ?y=tmed(dt);?? ?w = cbind(w,y)}t.med <- w[,2:3]
Thanks,
Anna


	[[alternative HTML version deleted]]


From M@rk@Purver @end|ng |rom Ju@t|ce@gov@uk  Thu Apr 16 12:02:09 2020
From: M@rk@Purver @end|ng |rom Ju@t|ce@gov@uk (Purver, Mark)
Date: Thu, 16 Apr 2020 10:02:09 +0000
Subject: [R] Changes to stats::glm function between R versions 3.4.0 and
 3.5.1
Message-ID: <LO2P123MB2205DC4A5BD853CDF88B0A49C0D80@LO2P123MB2205.GBRP123.PROD.OUTLOOK.COM>

Hi all,

Does anyone know whether there was a change to the algorithm of the glm function between versions 3.4.0 and 3.5.1 of the stats package? I noticed the introduction of the 'singular.ok' option, but I'm seeing more fundamental differences in the output of Generalised Linear Models between the two versions, particularly when the models don't converge.

In the later version, I'm seeing more variables 'blowing up' and giving large or NA standard error values when a model doesn't converge, but I'm using the same value of 'maxit' for both versions.

The numerical precision seems to be the same in versions 3.4.0 and 3.5.1 of R, as far as I can tell, but perhaps there is some difference that is indirectly affecting glm? Alternatively, there is a C function named Cdqrls that is called by glm, and I wondered if this had changed?

I have rather limited control over the version of R that I use, so I'm hoping I can produce results with 3.5.1 that are as similar as possible to those of 3.4.0.

Many thanks,

Mark Purver
Statistician, UK Ministry of Justice
________________________________
 This e-mail and any attachments is intended only for the attention of the addressee(s). Its unauthorised use, disclosure, storage or copying is not permitted. If you are not the intended recipient, please destroy all copies and inform the sender by return e-mail. Internet e-mail is not a secure medium. Any reply to this message could be intercepted and read by someone else. Please bear that in mind when deciding whether to send material in response to this message by e-mail. This e-mail (whether you are the sender or the recipient) may be monitored, recorded and retained by the Ministry of Justice. Monitoring / blocking software may be used, and e-mail content may be read at any time. You have a responsibility to ensure laws are not broken when composing or forwarding e-mails and their contents.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 16 16:47:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Apr 2020 07:47:10 -0700
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <2049048336.1192800.1586986078421@mail.yahoo.com>
References: <2049048336.1192800.1586986078421.ref@mail.yahoo.com>
 <2049048336.1192800.1586986078421@mail.yahoo.com>
Message-ID: <CAGxFJbTN+QB0svn4WLcjDGnP0rGSdR0KNT883qS4Yfgu=9qUow@mail.gmail.com>

You have *not* calculated row medians for all combinations of (is that
what you meant?) 3 columns of your data frame.
?combn  with column indexing can help you do that. If that is not what
you meant, then ??


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Apr 16, 2020 at 7:32 AM aiguo li via R-help
<r-help at r-project.org> wrote:
>
>  Hi all,
> I need to calculate a row median for every three columns of a dataframe.  I made it work using the following script, but not happy with the script.  Is there a simpler way for doing this?
> df = data.frame("a"=c(2,3,4), "b"=c(3,5,1),"c"=c(1,3,6),"d"=c(7,2,1),"e"=c(2,5,3),"f"=c(4,5,1))tmed <- function(dt) {x = apply(dt,1,median); return(x)}n =seq(1, ncol(df),3)w=0;for (i in n) {   m=i+2;  dt = df[,i:m];   y=tmed(dt);    w = cbind(w,y)}t.med <- w[,2:3]
> Thanks,
> Anna
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@r@|e|jonhu|vud @end|ng |rom reg|onjh@@e  Thu Apr 16 19:01:18 2020
From: p@r@|e|jonhu|vud @end|ng |rom reg|onjh@@e (=?utf-8?B?UMOkciBMZWlqb25odWZ2dWQ=?=)
Date: Thu, 16 Apr 2020 17:01:18 +0000
Subject: [R] parsing DOB data
In-Reply-To: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>
References: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>
Message-ID: <HE1PR04MB3115A207F75B28E6AB7E812182D80@HE1PR04MB3115.eurprd04.prod.outlook.com>

Hi!

For more solutions look at https://stackoverflow.com/questions/33221603/r-lubridate-returns-unwanted-century-when-given-two-digit-year

The  proposed solution:
   some_dates <- c("3/18/75", "March 10, 1994", "10/1/80", "June 15, 1979")
   dates <- mdy(some_dates)
   future_dates <- year(dates) > year(Sys.Date())
   year(dates[future_dates]) <- year(dates[future_dates]) - 100

Should work for your case with one adaption (change mdy to ymd). At least it worked on your example.

Yours,

/P?r

--
P?r Leijonhufvud               .                                    par.leijonhufvud at regionjh.se
Sjukhuskemist                                                        +46(0)63-153 376, +46-(0)70-242 7006
Laboratoriemedicin
?stersunds sjukhus

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Peter Nelson via R-help
Sent: den 15 april 2020 20:31
To: r-help at r-project.org
Subject: [R] parsing DOB data

I have a data set (.csv) with date (eg date of birth) information stored as character vectors that I?m attempting to transform to POSIXct objects using the package lubridate (1.7.4). The problem that I?m trying to address is that my two digit years are invariably (?) parsed to 20xx. For example,

x <- c("45-12-03","01-06-24","64-9-15?)
ymd(x)
[1] "2045-12-03" "2001-06-24" "2064-09-15?

These should be parsed as ?1945-12-03? ?2001-06-24? ?1964-09-15?.

I've tried to use parse_date_time()?based on the documentation it looks to me as though the argument cutoff_2000 should allow me to address this, but it?s unclear to me how to implement this. As an example, I?ve tried

parse_date_time(x, cutoff_2000 = 01)

but get the following error message (and similar for other similar attempts, including cutoff_2000 = 01L)

Error in parse_date_time(x, cutoff_2000 = 1) :
  unused argument (cutoff_2000 = 1)

Thanks for your help!

Peter Nelson, PhD
Institute of Marine Sciences
University of California, Santa Cruz
Center for Ocean Health, Long Marine Lab
115 McAllistair Way
Santa Cruz, CA, 95076, USA
707-267-5896






[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Region J?mtland H?rjedalen behandlar dina personuppgifter vid kommunikation via e-post. Hanteringen av personuppgifter f?ljer g?llande dataskyddslagstiftning. Du kan l?sa mer om hur vi behandlar dina uppgifter p? https://regionjh.se/gdpr

From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Apr 16 22:47:59 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 16 Apr 2020 16:47:59 -0400
Subject: [R] Interactive stats packages
Message-ID: <4CF634B7-9C5C-4442-BBF7-F47B450BD3CB@comcast.net>

Do any of you know of any interactive stats analysis packages built on top of R?

Bernard
Sent from my iPhone so please excuse the spelling!"

From |@t@z@hn @end|ng |rom gm@||@com  Thu Apr 16 23:44:02 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 16 Apr 2020 17:44:02 -0400
Subject: [R] Interactive stats packages
In-Reply-To: <4CF634B7-9C5C-4442-BBF7-F47B450BD3CB@comcast.net>
References: <4CF634B7-9C5C-4442-BBF7-F47B450BD3CB@comcast.net>
Message-ID: <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>

On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
<mcgarvey.bernard at comcast.net> wrote:
>
> Do any of you know of any interactive stats analysis packages built on top of R?

R _is_ an interactive stats package, please be more specific :-)

Maybe you mean something like https://dreamrs.github.io/esquisse/index.html

Best,
Ista

>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 17 00:10:29 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Apr 2020 15:10:29 -0700
Subject: [R] Interactive stats packages
In-Reply-To: <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>
References: <4CF634B7-9C5C-4442-BBF7-F47B450BD3CB@comcast.net>
 <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>
Message-ID: <CAGxFJbSMki6y2Zs3So8WVQR3neQTi0KcZNbxB1OKdv3HwbX4nQ@mail.gmail.com>

In addition ...

https://cran.r-project.org/web/views/TeachingStatistics.html

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Apr 16, 2020 at 2:44 PM Ista Zahn <istazahn at gmail.com> wrote:
>
> On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
> <mcgarvey.bernard at comcast.net> wrote:
> >
> > Do any of you know of any interactive stats analysis packages built on top of R?
>
> R _is_ an interactive stats package, please be more specific :-)
>
> Maybe you mean something like https://dreamrs.github.io/esquisse/index.html
>
> Best,
> Ista
>
> >
> > Bernard
> > Sent from my iPhone so please excuse the spelling!"
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Fri Apr 17 02:05:28 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 16 Apr 2020 20:05:28 -0400
Subject: [R] Interactive stats packages
In-Reply-To: <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>
References: <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>
Message-ID: <2C36D7D2-7DD0-42F3-A3CA-D840EE2A2B30@comcast.net>

Yes Ista, that is what I meant by interactive. Something that is menu driven with a GUI rather than command line.

Thanks

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 16, 2020, at 5:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> ?On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
> <mcgarvey.bernard at comcast.net> wrote:
>> 
>> Do any of you know of any interactive stats analysis packages built on top of R?
> 
> R _is_ an interactive stats package, please be more specific :-)
> 
> Maybe you mean something like https://dreamrs.github.io/esquisse/index.html
> 
> Best,
> Ista
> 
>> 
>> Bernard
>> Sent from my iPhone so please excuse the spelling!"
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Apr 17 02:28:15 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Apr 2020 10:28:15 +1000
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <2049048336.1192800.1586986078421@mail.yahoo.com>
References: <2049048336.1192800.1586986078421.ref@mail.yahoo.com>
 <2049048336.1192800.1586986078421@mail.yahoo.com>
Message-ID: <CA+8X3fWosHkTHM1jz8pVb2NzP1JUXqu=rQpGaHiA2jT6k=Dw-w@mail.gmail.com>

Hi Anna,
I can't think of a simple way, but this function may make you happier:

step_median<-function(x,window) {
 x<-unlist(x)
 stop<-length(x)-window+1
 xout<-NA
 nindx<-1
 for(i in seq(1,stop,by=window)) {
  xout[nindx]<-do.call("median",list(x[i:(i+window-1)]))
  nindx<-nindx+1
 }
 return(xout)
}
apply(df,1,step_median,3)

This should return a matrix where the columns are the medians
calculated from blocks of "window" width on each row of "df". As Bert
noted, you may want to think about a "rolling" median where the
"windows" overlap. This can be done like so:

library(zoo)
apply(df,1,rollmedian,3)

Jim

On Fri, Apr 17, 2020 at 12:32 AM aiguo li via R-help
<r-help at r-project.org> wrote:
>
>  Hi all,
> I need to calculate a row median for every three columns of a dataframe.  I made it work using the following script, but not happy with the script.  Is there a simpler way for doing this?
> df = data.frame("a"=c(2,3,4), "b"=c(3,5,1),"c"=c(1,3,6),"d"=c(7,2,1),"e"=c(2,5,3),"f"=c(4,5,1))tmed <- function(dt) {x = apply(dt,1,median); return(x)}n =seq(1, ncol(df),3)w=0;for (i in n) {   m=i+2;  dt = df[,i:m];   y=tmed(dt);    w = cbind(w,y)}t.med <- w[,2:3]
> Thanks,
> Anna
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@t@z@hn @end|ng |rom gm@||@com  Fri Apr 17 03:01:09 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 16 Apr 2020 21:01:09 -0400
Subject: [R] Interactive stats packages
In-Reply-To: <2C36D7D2-7DD0-42F3-A3CA-D840EE2A2B30@comcast.net>
References: <CA+vqiLEGGvd7Vb9yAVgno3LWDhwLv4n2aMqjoKNasy+4DNZ9hQ@mail.gmail.com>
 <2C36D7D2-7DD0-42F3-A3CA-D840EE2A2B30@comcast.net>
Message-ID: <CA+vqiLHi-dSNTnoEm0TqmJ6m8vOpkeeSLaDtgT8_3Tw8-6dEnQ@mail.gmail.com>

On Thu, Apr 16, 2020 at 8:05 PM Bernard Comcast
<mcgarvey.bernard at comcast.net> wrote:
>
> Yes Ista, that is what I meant by interactive. Something that is menu driven with a GUI rather than command line.

There are several. I'm aware of these

https://jasp-stats.org/
https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/
http://www.deducer.org/pmwiki/pmwiki.php?n=Main.DeducerManual

There are undoubtedly others.

--Ista


>
> Thanks
>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
>
> > On Apr 16, 2020, at 5:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >
> > ?On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
> > <mcgarvey.bernard at comcast.net> wrote:
> >>
> >> Do any of you know of any interactive stats analysis packages built on top of R?
> >
> > R _is_ an interactive stats package, please be more specific :-)
> >
> > Maybe you mean something like https://dreamrs.github.io/esquisse/index.html
> >
> > Best,
> > Ista
> >
> >>
> >> Bernard
> >> Sent from my iPhone so please excuse the spelling!"
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 17 03:04:35 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 16 Apr 2020 18:04:35 -0700
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <CA+8X3fWosHkTHM1jz8pVb2NzP1JUXqu=rQpGaHiA2jT6k=Dw-w@mail.gmail.com>
References: <2049048336.1192800.1586986078421.ref@mail.yahoo.com>
 <2049048336.1192800.1586986078421@mail.yahoo.com>
 <CA+8X3fWosHkTHM1jz8pVb2NzP1JUXqu=rQpGaHiA2jT6k=Dw-w@mail.gmail.com>
Message-ID: <CAGxFJbQb_4rhe6h1djMK_tcS9bx9-BS8+rFZV7xSpv9E8sCzbg@mail.gmail.com>

Inline.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 16, 2020 at 5:28 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Anna,
> I can't think of a simple way, but this function may make you happier:
>
> step_median<-function(x,window) {
>  x<-unlist(x)
>  stop<-length(x)-window+1
>  xout<-NA
>  nindx<-1
>  for(i in seq(1,stop,by=window)) {
>   xout[nindx]<-do.call("median",list(x[i:(i+window-1)]))
>   nindx<-nindx+1
>  }
>  return(xout)
> }
> apply(df,1,step_median,3)
>
> This should return a matrix where the columns are the medians
> calculated from blocks of "window" width on each row of "df". As Bert
> noted,

Nope. This was *not* what Bert noted. But what Bert noted may not be at all
what
Aiguo wanted anyway.

-- Bert



> you may want to think about a "rolling" median where the
> "windows" overlap. This can be done like so:
>
> library(zoo)
> apply(df,1,rollmedian,3)
>
> Jim
>
> On Fri, Apr 17, 2020 at 12:32 AM aiguo li via R-help
> <r-help at r-project.org> wrote:
> >
> >  Hi all,
> > I need to calculate a row median for every three columns of a
> dataframe.  I made it work using the following script, but not happy with
> the script.  Is there a simpler way for doing this?
> > df = data.frame("a"=c(2,3,4),
> "b"=c(3,5,1),"c"=c(1,3,6),"d"=c(7,2,1),"e"=c(2,5,3),"f"=c(4,5,1))tmed <-
> function(dt) {x = apply(dt,1,median); return(x)}n =seq(1,
> ncol(df),3)w=0;for (i in n) {   m=i+2;  dt = df[,i:m];   y=tmed(dt);    w =
> cbind(w,y)}t.med <- w[,2:3]
> > Thanks,
> > Anna
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Fri Apr 17 03:15:56 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 16 Apr 2020 21:15:56 -0400
Subject: [R] Interactive stats packages
In-Reply-To: <CAGxFJbSMki6y2Zs3So8WVQR3neQTi0KcZNbxB1OKdv3HwbX4nQ@mail.gmail.com>
References: <CAGxFJbSMki6y2Zs3So8WVQR3neQTi0KcZNbxB1OKdv3HwbX4nQ@mail.gmail.com>
Message-ID: <C08546A3-4154-4E4D-9B33-AC5AEA30164F@comcast.net>

Thanks

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 16, 2020, at 6:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?In addition ...
> 
> https://cran.r-project.org/web/views/TeachingStatistics.html
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
>> On Thu, Apr 16, 2020 at 2:44 PM Ista Zahn <istazahn at gmail.com> wrote:
>> 
>>> On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
>>> <mcgarvey.bernard at comcast.net> wrote:
>>> 
>>> Do any of you know of any interactive stats analysis packages built on top of R?
>> 
>> R _is_ an interactive stats package, please be more specific :-)
>> 
>> Maybe you mean something like https://dreamrs.github.io/esquisse/index.html
>> 
>> Best,
>> Ista
>> 
>>> 
>>> Bernard
>>> Sent from my iPhone so please excuse the spelling!"
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Fri Apr 17 03:15:42 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 16 Apr 2020 21:15:42 -0400
Subject: [R] Interactive stats packages
In-Reply-To: <CA+vqiLHi-dSNTnoEm0TqmJ6m8vOpkeeSLaDtgT8_3Tw8-6dEnQ@mail.gmail.com>
References: <CA+vqiLHi-dSNTnoEm0TqmJ6m8vOpkeeSLaDtgT8_3Tw8-6dEnQ@mail.gmail.com>
Message-ID: <A3B57F9F-2B03-4385-AA9C-6AC3CD5A8877@comcast.net>

Thanks

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 16, 2020, at 9:01 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> ?On Thu, Apr 16, 2020 at 8:05 PM Bernard Comcast
> <mcgarvey.bernard at comcast.net> wrote:
>> 
>> Yes Ista, that is what I meant by interactive. Something that is menu driven with a GUI rather than command line.
> 
> There are several. I'm aware of these
> 
> https://jasp-stats.org/
> https://socialsciences.mcmaster.ca/jfox/Misc/Rcmdr/
> http://www.deducer.org/pmwiki/pmwiki.php?n=Main.DeducerManual
> 
> There are undoubtedly others.
> 
> --Ista
> 
> 
>> 
>> Thanks
>> 
>> Bernard
>> Sent from my iPhone so please excuse the spelling!"
>> 
>>>> On Apr 16, 2020, at 5:44 PM, Ista Zahn <istazahn at gmail.com> wrote:
>>> 
>>> ?On Thu, Apr 16, 2020 at 4:48 PM Bernard Comcast
>>> <mcgarvey.bernard at comcast.net> wrote:
>>>> 
>>>> Do any of you know of any interactive stats analysis packages built on top of R?
>>> 
>>> R _is_ an interactive stats package, please be more specific :-)
>>> 
>>> Maybe you mean something like https://dreamrs.github.io/esquisse/index.html
>>> 
>>> Best,
>>> Ista
>>> 
>>>> 
>>>> Bernard
>>>> Sent from my iPhone so please excuse the spelling!"
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 


From drj|m|emon @end|ng |rom gm@||@com  Fri Apr 17 03:30:26 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Apr 2020 11:30:26 +1000
Subject: [R] parsing DOB data
In-Reply-To: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>
References: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>
Message-ID: <CA+8X3fUJdUR9cec=02AdQXK52c=4gFVPNg_kTjZOZi1GDUhUEw@mail.gmail.com>

Hi Peter,
One way is to process the strings before converting them to dates:

x2<-c("45-12-03","01-06-24","04-9-15","1901-03-04")
add_century<-function(x,changeover=68,previous=19,current=20) {
 centuries<-sapply(sapply(x,strsplit,"-"),"[",1)
 shortyears<-which(!(nchar(centuries)>2))
 century<-rep("",length(x))
 century[shortyears]<-ifelse(centuries[shortyears]>changeover,previous,current)
 newx<-paste0(century,x)
 return(newx)
}
add_century(x2,1)

Jim

On Fri, Apr 17, 2020 at 12:34 AM Peter Nelson via R-help
<r-help at r-project.org> wrote:
>
> I have a data set (.csv) with date (eg date of birth) information stored as character vectors that I?m attempting to transform to POSIXct objects using the package lubridate (1.7.4). The problem that I?m trying to address is that my two digit years are invariably (?) parsed to 20xx. For example,
>
> x <- c("45-12-03","01-06-24","64-9-15?)
> ymd(x)
> [1] "2045-12-03" "2001-06-24" "2064-09-15?
>
> These should be parsed as ?1945-12-03? ?2001-06-24? ?1964-09-15?.
>
> I've tried to use parse_date_time()?based on the documentation it looks to me as though the argument cutoff_2000 should allow me to address this, but it?s unclear to me how to implement this. As an example, I?ve tried
>
> parse_date_time(x, cutoff_2000 = 01)
>
> but get the following error message (and similar for other similar attempts, including cutoff_2000 = 01L)
>
> Error in parse_date_time(x, cutoff_2000 = 1) :
>   unused argument (cutoff_2000 = 1)
>
> Thanks for your help!
>
> Peter Nelson, PhD
> Institute of Marine Sciences
> University of California, Santa Cruz
> Center for Ocean Health, Long Marine Lab
> 115 McAllistair Way
> Santa Cruz, CA, 95076, USA
> 707-267-5896
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dmcp @end|ng |rom webm@||@co@z@  Fri Apr 17 07:49:54 2020
From: dmcp @end|ng |rom webm@||@co@z@ (David McPearson)
Date: Fri, 17 Apr 2020 07:49:54 +0200
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <DM6PR13MB3100A062333CC1859DB99AB882D90@DM6PR13MB3100.namprd13.prod.outlook.com>
References: <DM6PR13MB3100A062333CC1859DB99AB882D90@DM6PR13MB3100.namprd13.prod.outlook.com>
Message-ID: <b10fbbe38c4b7a64d3620eb72427892d@webmail.co.za>

Anna wrote:
> 
> Hi all,
> I need to calculate a row median for every three columns of a 
> dataframe.  I made it work using the following script, but not happy 
> with the script.  Is there a simpler way for doing this?
> 



To which Jim L responded:
> 
> Hi Anna,
> I can't think of a simple way, but this function may make you happier:
> 
> step_median<-function(x,window) {
> x<-unlist(x)
> stop<-length(x)-window+1
> xout<-NA
> nindx<-1
> for(i in seq(1,stop,by=window)) {
> xout[nindx]<-do.call("median",list(x[i:(i+window-1)]))
> nindx<-nindx+1
> }
> return(xout)
> }
> apply(df,1,step_median,3)
> 
> This should return a matrix where the columns are the medians
> calculated from blocks of "window" width on each row of "df". As Bert
> noted, you may want to think about a "rolling" median where the
> "windows" overlap. This can be done like so:
> 
> library(zoo)
> apply(df,1,rollmedian,3)
> 
> Jim

Another approach you might try is multiple calls to sapply/lapply. This 
won't rid you of loops, but it will hide them:

# Example data. Some names changed to avoid collisions between
# R functions (collisions are in the gap between the headphones,
# not i R).

dfr <- data.frame(a = c(2,3,4), b = c(3,5,1), c = c(1,3,6),
   d = c(7,2,1), e = c(2,5,3), f = c(4,5,1))

# Turn each of the three-column groups into their own element
# in a list. Note: the subsetting (probably) fails with an
# error if ncol(dfr) is not a multiple of 3

  dlist <- lapply(seq(1, ncol(dfr), by = 3), function(enn)
   dfr[ , enn + 0:2])

# Then you can use sapply to calculate the row medians for each
# of the elements..

# Both of the following seem to work. I'm not sure which is
# more readable?

  sapply(dlist, function(xx) apply(xx, 1, median))

  sapply(dlist, apply, 1, median)

# I'm sure the cognoscenti will have a much more elegant way
# of doing this.


Cheers y'all,
DMcP

From petr@p|k@| @end|ng |rom prechez@@cz  Fri Apr 17 08:53:43 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 17 Apr 2020 06:53:43 +0000
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <b10fbbe38c4b7a64d3620eb72427892d@webmail.co.za>
References: <DM6PR13MB3100A062333CC1859DB99AB882D90@DM6PR13MB3100.namprd13.prod.outlook.com>
 <b10fbbe38c4b7a64d3620eb72427892d@webmail.co.za>
Message-ID: <8b6e18485a8348f186a5bce128dc55e9@SRVEXCHCM1302.precheza.cz>

Hi

As usual in R, things could be done by different ways.

idx <- (0:(ncol(dfr)-1))%/%3

aggregate(t(dfr), list(idx), median)
  Group.1 V1 V2 V3
1       0  2  3  4
2       1  4  5  1

Results should be OK although its structure is different, performance is not tested.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of David McPearson
> Sent: Friday, April 17, 2020 7:50 AM
> To: r-help at r-project.org
> Cc: dcmcp at telstra.com
> Subject: Re: [R] calculate row median of every three columns for a dataframe
> 
> Anna wrote:
> >
> > Hi all,
> > I need to calculate a row median for every three columns of a
> > dataframe.  I made it work using the following script, but not happy
> > with the script.  Is there a simpler way for doing this?
> >
> 
> 
> 
> To which Jim L responded:
> >
> > Hi Anna,
> > I can't think of a simple way, but this function may make you happier:
> >
> > step_median<-function(x,window) {
> > x<-unlist(x)
> > stop<-length(x)-window+1
> > xout<-NA
> > nindx<-1
> > for(i in seq(1,stop,by=window)) {
> > xout[nindx]<-do.call("median",list(x[i:(i+window-1)]))
> > nindx<-nindx+1
> > }
> > return(xout)
> > }
> > apply(df,1,step_median,3)
> >
> > This should return a matrix where the columns are the medians
> > calculated from blocks of "window" width on each row of "df". As Bert
> > noted, you may want to think about a "rolling" median where the
> > "windows" overlap. This can be done like so:
> >
> > library(zoo)
> > apply(df,1,rollmedian,3)
> >
> > Jim
> 
> Another approach you might try is multiple calls to sapply/lapply. This won't
> rid you of loops, but it will hide them:
> 
> # Example data. Some names changed to avoid collisions between # R
> functions (collisions are in the gap between the headphones, # not i R).
> 
> dfr <- data.frame(a = c(2,3,4), b = c(3,5,1), c = c(1,3,6),
>    d = c(7,2,1), e = c(2,5,3), f = c(4,5,1))
> 
> # Turn each of the three-column groups into their own element # in a list.
> Note: the subsetting (probably) fails with an # error if ncol(dfr) is not a
> multiple of 3
> 
>   dlist <- lapply(seq(1, ncol(dfr), by = 3), function(enn)
>    dfr[ , enn + 0:2])
> 
> # Then you can use sapply to calculate the row medians for each # of the
> elements..
> 
> # Both of the following seem to work. I'm not sure which is # more readable?
> 
>   sapply(dlist, function(xx) apply(xx, 1, median))
> 
>   sapply(dlist, apply, 1, median)
> 
> # I'm sure the cognoscenti will have a much more elegant way # of doing this.
> 
> 
> Cheers y'all,
> DMcP
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drj|m|emon @end|ng |rom gm@||@com  Fri Apr 17 09:15:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 17 Apr 2020 17:15:09 +1000
Subject: [R] parsing DOB data
In-Reply-To: <CA+8X3fUJdUR9cec=02AdQXK52c=4gFVPNg_kTjZOZi1GDUhUEw@mail.gmail.com>
References: <6FFD3A74-262E-47F9-B38A-1C816B73347F@ucsc.edu>
 <CA+8X3fUJdUR9cec=02AdQXK52c=4gFVPNg_kTjZOZi1GDUhUEw@mail.gmail.com>
Message-ID: <CA+8X3fW0iL_JP=nEBb_4htsxbM2jrLW1QXCnhykXWGHCQfmMYQ@mail.gmail.com>

Hi Peter,
I worked out a neat function to add the century to short dates. It
works fine on its own, but sadly it bombs when used with sapply. Maybe
someone else can point out my mistake:

add_century<-function(x,changeover=68,previous=19,current=20,pos=1,sep="-") {
 xsplit<-unlist(strsplit(x,sep))
 # only add century to short dates
 if(nchar(xsplit[pos]) < 3) {
  century<-ifelse(as.numeric(xsplit[pos]) <= changeover,current,previous)
  xsplit[pos]<-paste0(century,xsplit[[pos]])
 }
 return(paste(xsplit,collapse=sep))
}
# these work
add_century(x3[1],changeover=1,pos=3,sep="/")
add_century(x3[2],changeover=1,pos=3,sep="/")
add_century(x3[3],changeover=1,pos=3,sep="/")
# this doesn't
sapply(x3,add_century,list(changeover=1,pos=3,sep="/"))

Jim

On Fri, Apr 17, 2020 at 11:30 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Peter,
> One way is to process the strings before converting them to dates:
>
> x2<-c("45-12-03","01-06-24","04-9-15","1901-03-04")
> add_century<-function(x,changeover=68,previous=19,current=20) {
>  centuries<-sapply(sapply(x,strsplit,"-"),"[",1)
>  shortyears<-which(!(nchar(centuries)>2))
>  century<-rep("",length(x))
>  century[shortyears]<-ifelse(centuries[shortyears]>changeover,previous,current)
>  newx<-paste0(century,x)
>  return(newx)
> }
> add_century(x2,1)
>
> Jim
>
> On Fri, Apr 17, 2020 at 12:34 AM Peter Nelson via R-help
> <r-help at r-project.org> wrote:
> >
> > I have a data set (.csv) with date (eg date of birth) information stored as character vectors that I?m attempting to transform to POSIXct objects using the package lubridate (1.7.4). The problem that I?m trying to address is that my two digit years are invariably (?) parsed to 20xx. For example,
> >
> > x <- c("45-12-03","01-06-24","64-9-15?)
> > ymd(x)
> > [1] "2045-12-03" "2001-06-24" "2064-09-15?
> >
> > These should be parsed as ?1945-12-03? ?2001-06-24? ?1964-09-15?.
> >
> > I've tried to use parse_date_time()?based on the documentation it looks to me as though the argument cutoff_2000 should allow me to address this, but it?s unclear to me how to implement this. As an example, I?ve tried
> >
> > parse_date_time(x, cutoff_2000 = 01)
> >
> > but get the following error message (and similar for other similar attempts, including cutoff_2000 = 01L)
> >
> > Error in parse_date_time(x, cutoff_2000 = 1) :
> >   unused argument (cutoff_2000 = 1)
> >
> > Thanks for your help!
> >
> > Peter Nelson, PhD
> > Institute of Marine Sciences
> > University of California, Santa Cruz
> > Center for Ocean Health, Long Marine Lab
> > 115 McAllistair Way
> > Santa Cruz, CA, 95076, USA
> > 707-267-5896
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Fri Apr 17 11:36:46 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 17 Apr 2020 12:36:46 +0300
Subject: [R] calculate row median of every three columns for a dataframe
In-Reply-To: <8b6e18485a8348f186a5bce128dc55e9@SRVEXCHCM1302.precheza.cz>
References: <DM6PR13MB3100A062333CC1859DB99AB882D90@DM6PR13MB3100.namprd13.prod.outlook.com>
 <b10fbbe38c4b7a64d3620eb72427892d@webmail.co.za>
 <8b6e18485a8348f186a5bce128dc55e9@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGgJW74u7Y1ph1Lfs=Qadr-OYWhV32TUKN-jWx4Pg0SRWACR_w@mail.gmail.com>

Some comments on the contributions:
a) for Petr's suggestion, to return the desired structure modify the
statement to
       t(aggregate(t(dfr), list(idx), median)[,-1])
    And, although less readable, can certainly be put in a one-liner
solution by removing the idx definition
        t(aggregate(t(dfr), list((0:(ncol(dfr)-1))%/%3), median)[,-1])
b) to DMcP: "# I'm sure the cognoscenti will have a much more elegant way"
       +1 for elegance (in my view)
c) to Jim: I think your code is instructive. From a style viewpoint I would
recommend against naming a local variable 'stop' :-)

Best,
Eric

On Fri, Apr 17, 2020 at 9:54 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> As usual in R, things could be done by different ways.
>
> idx <- (0:(ncol(dfr)-1))%/%3
>
> aggregate(t(dfr), list(idx), median)
>   Group.1 V1 V2 V3
> 1       0  2  3  4
> 2       1  4  5  1
>
> Results should be OK although its structure is different, performance is
> not tested.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of David McPearson
> > Sent: Friday, April 17, 2020 7:50 AM
> > To: r-help at r-project.org
> > Cc: dcmcp at telstra.com
> > Subject: Re: [R] calculate row median of every three columns for a
> dataframe
> >
> > Anna wrote:
> > >
> > > Hi all,
> > > I need to calculate a row median for every three columns of a
> > > dataframe.  I made it work using the following script, but not happy
> > > with the script.  Is there a simpler way for doing this?
> > >
> >
> >
> >
> > To which Jim L responded:
> > >
> > > Hi Anna,
> > > I can't think of a simple way, but this function may make you happier:
> > >
> > > step_median<-function(x,window) {
> > > x<-unlist(x)
> > > stop<-length(x)-window+1
> > > xout<-NA
> > > nindx<-1
> > > for(i in seq(1,stop,by=window)) {
> > > xout[nindx]<-do.call("median",list(x[i:(i+window-1)]))
> > > nindx<-nindx+1
> > > }
> > > return(xout)
> > > }
> > > apply(df,1,step_median,3)
> > >
> > > This should return a matrix where the columns are the medians
> > > calculated from blocks of "window" width on each row of "df". As Bert
> > > noted, you may want to think about a "rolling" median where the
> > > "windows" overlap. This can be done like so:
> > >
> > > library(zoo)
> > > apply(df,1,rollmedian,3)
> > >
> > > Jim
> >
> > Another approach you might try is multiple calls to sapply/lapply. This
> won't
> > rid you of loops, but it will hide them:
> >
> > # Example data. Some names changed to avoid collisions between # R
> > functions (collisions are in the gap between the headphones, # not i R).
> >
> > dfr <- data.frame(a = c(2,3,4), b = c(3,5,1), c = c(1,3,6),
> >    d = c(7,2,1), e = c(2,5,3), f = c(4,5,1))
> >
> > # Turn each of the three-column groups into their own element # in a
> list.
> > Note: the subsetting (probably) fails with an # error if ncol(dfr) is
> not a
> > multiple of 3
> >
> >   dlist <- lapply(seq(1, ncol(dfr), by = 3), function(enn)
> >    dfr[ , enn + 0:2])
> >
> > # Then you can use sapply to calculate the row medians for each # of the
> > elements..
> >
> > # Both of the following seem to work. I'm not sure which is # more
> readable?
> >
> >   sapply(dlist, function(xx) apply(xx, 1, median))
> >
> >   sapply(dlist, apply, 1, median)
> >
> > # I'm sure the cognoscenti will have a much more elegant way # of doing
> this.
> >
> >
> > Cheers y'all,
> > DMcP
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Fri Apr 17 21:06:03 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Fri, 17 Apr 2020 22:06:03 +0300
Subject: [R] Survival analysis
Message-ID: <CAH6117JxY_+SB5qj3dLSbn_2SFMRz1SyiTfP5veJuN+Rm_K+Tg@mail.gmail.com>

I can't understand how to do a survival analysis (?Surv ()) when some
event occurred before the start of observation (left censored). If I
understand correctly, there are two methods. I chose a method with: 1)
time from the start of treatment to the event and 2) the indicator of
the event. I did (in my data) the event indicator so:
1 - event, 2 - event before the start of observation, 0 - no event
---
library(survival)
left_censor_data <- read.table("left.csv", header = TRUE, sep = ";")
#sep = ";" it's right!
dput(left_censor_data, file="left_censor_data") #file attached
left_censor_data
   'data.frame':   11 obs. of  2 variables:
   $ timee : int  5 151 33 37 75 14 7 9 1 45 ...
   $ eventt: int  2 0 0 0 0 0 0 2 0 1 ...
   # 1?event, 2 ? event before the start of observation , 0 ? no event

sur <- Surv(time = left_censor_data$timee,  event =
left_censor_data$eventt, type = "left")
  Warning message:
  In Surv(time = left_censor_data$timee, event = left_censor_data$eventt,  :
  Invalid status value, converted to NA

#Why such a message?
#Then everything turns out wrong

From cpoiw@rt m@iii@g oii chemo@org@uk  Fri Apr 17 21:38:22 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Fri, 17 Apr 2020 20:38:22 +0100
Subject: [R] Survival analysis
In-Reply-To: <CAH6117JxY_+SB5qj3dLSbn_2SFMRz1SyiTfP5veJuN+Rm_K+Tg@mail.gmail.com>
References: <CAH6117JxY_+SB5qj3dLSbn_2SFMRz1SyiTfP5veJuN+Rm_K+Tg@mail.gmail.com>
Message-ID: <4f1b20f1659c631e44587651246ce23d@chemo.org.uk>

On 2020-04-17 20:06, Medic wrote:
> I can't understand how to do a survival analysis (?Surv ()) when some
> event occurred before the start of observation (left censored). If I
> understand correctly, there are two methods. I chose a method with: 1)
> time from the start of treatment to the event and 2) the indicator of
> the event. I did (in my data) the event indicator so:
> 1 - event, 2 - event before the start of observation, 0 - no event

I have no experience of left censoring beyond the text book.  Is your 
left censored data the SAME event or a different event?

> ---
> library(survival)
> left_censor_data <- read.table("left.csv", header = TRUE, sep = ";")
> #sep = ";" it's right!
> dput(left_censor_data, file="left_censor_data") #file attached
> left_censor_data
>    'data.frame':   11 obs. of  2 variables:
>    $ timee : int  5 151 33 37 75 14 7 9 1 45 ...
>    $ eventt: int  2 0 0 0 0 0 0 2 0 1 ...
>    # 1?event, 2 ? event before the start of observation , 0 ? no event
> 

So if I read this data correctly the first observation is left censored. 
  What does the time "5" refer to?  Is that 5 days BEFORE observation the 
event happened?  Or 5 days after another event happened?  My text book 
understanding of left censored data was that your censored points would 
have time 0.

> sur <- Surv(time = left_censor_data$timee,  event =
> left_censor_data$eventt, type = "left")
>   Warning message:
>   In Surv(time = left_censor_data$timee, event = 
> left_censor_data$eventt,  :
>   Invalid status value, converted to NA
> 
> #Why such a message?
> #Then everything turns out wrong


Is the censoring type you want LEFT TRUNCATION rather than LEFT.  If 
they are also right censored I think R Surv calls these Counting.

See: https://folk.ntnu.no/bo/TMA4275/Download/R.tutorialDiez.pdf

Any help?


From m@|||P@dpo@t @end|ng |rom gm@||@com  Fri Apr 17 23:03:37 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Sat, 18 Apr 2020 00:03:37 +0300
Subject: [R] Survival analysis
Message-ID: <CAH6117KNsjA_geySGQbguGnRAMXCoTV952xq7V7uYw6aM-8s6Q@mail.gmail.com>

On 2020-04-17 20:06, Medic wrote:
> I can't understand how to do a survival analysis (?Surv ()) when some
> event occurred before the start of observation (left censored). If I
> understand correctly, there are two methods. I chose a method with: 1)
> time from the start of treatment to the event and 2) the indicator of
> the event. I did (in my data) the event indicator so:
> 1 - event, 2 - event before the start of observation, 0 - no event

I have no experience of left censoring beyond the text book.  Is your
left censored data the SAME event or a different event?

YES, THE SAME!

> ---
> library(survival)
> left_censor_data <- read.table("left.csv", header = TRUE, sep = ";")
> #sep = ";" it's right!
> dput(left_censor_data, file="left_censor_data") #file attached
> left_censor_data
>    'data.frame':   11 obs. of  2 variables:
>    $ timee : int  5 151 33 37 75 14 7 9 1 45 ...
>    $ eventt: int  2 0 0 0 0 0 0 2 0 1 ...
>    # 1?event, 2 ? event before the start of observation , 0 ? no event

So if I read this data correctly the first observation is left censored.
What does the time "5" refer to?  Is that 5 days BEFORE observation the
event happened?

YES, EXACTLY!

My text book understanding of left censored data was that your
censored points would
have time 0.

I TRIED TO SET TIME 0 NOW (for censored points), AND RECEIVED THE SAME
WARNING (AND THE CURVE TURNED OUT WRONG)

> sur <- Surv(time = left_censor_data$timee,  event =
> left_censor_data$eventt, type = "left")
>   WARNING message:
>   In Surv(time = left_censor_data$timee, event =
> left_censor_data$eventt,  :
>   Invalid status value, converted to NA
>
> #Why such a WARNING message?
> #Then everything turns out wrong

Is the censoring type you want LEFT TRUNCATION rather than LEFT.
If they are also right censored I think R Surv calls these Counting.

I SAY ABOUT LEFT CENSORING (NOT ABOUT LEFT TRUNCATION)!
(COUNTING? I DO NOT UNDERSTAND THIS.)

THANKS! I HOPE SOMEONE EXPLAIN TO ME
1) HOW TO COMPILE THE DATA and
2) WRITE A CODE


From mon|c@p@|@|ovejoy @end|ng |rom gm@||@com  Fri Apr 17 21:55:48 2020
From: mon|c@p@|@|ovejoy @end|ng |rom gm@||@com (Monica Palaseanu-Lovejoy)
Date: Fri, 17 Apr 2020 15:55:48 -0400
Subject: [R] custom function gives unexpected result - for me
Message-ID: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>

Hi,

I wrote a relatively simple function. If i run the code inside the function
line by line i am getting the result i was expecting, but if i run the
function, i get a different result.

The function:

grr1 <- function(rn) {
r.up <- c()
for (i in 1:rn-1) {
if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
r.up <- c(r.up, ru)
}
return(r.up)
}

So, if rn is 3 for example i would expect to get 1 1 2

grr1(3)
[1] 1 0 1 1 2

If i run it line by line inside the function:
r.up <- c()
> r.up
NULL

i=1
if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> ru
[1] 1

r.up <- c(r.up, ru)
r.up
[1] 1

i=2
if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
ru
[1] 1 2
r.up <- c(r.up, ru)
> r.up
[1] 1 1 2

So - i am getting the result i am expecting. From where the 1 0 before what
i expect as a result comes from? I am sure i am doing some very basic
error, but it seems i cannot figure it out.

I run R x64  3.2.6. I know it is not the latest version, but it should not
give me unexpected results because of that i would think.

sessionInfo()
R version 3.6.2 (2019-12-12)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 17763)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.6.2

Thanks,
Monica

	[[alternative HTML version deleted]]


From tr|@t@n@ko@c|uch @end|ng |rom m@||@mcg|||@c@  Sat Apr 18 00:45:33 2020
From: tr|@t@n@ko@c|uch @end|ng |rom m@||@mcg|||@c@ (Tristan Kosciuch)
Date: Fri, 17 Apr 2020 22:45:33 +0000
Subject: [R] Multi response GAM
Message-ID: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>

Hello,

I am modelling the diet of Nile perch through time. I have 3 diet classes as
my response variables; fish 1, fish 2, and invertebrates.

The response variables are correlated, declines in invert consumption ~
increase in fish consumption. Any advice on how to handle this would be
appreciated. I would like to use GAMs as my time series shows fluctuations
that could only be fit by high order polynomials if I were to use a linear
model, but open to suggestions.

Thank you for your time.

P.s. I will be comparing the fit of the time series GAM with a model based
on other predictors, with a training and validation split for my data.



---

Tristan Kosciuch

Stewart Biology Building, McGill University

1205 Dr Penfield Ave, Montreal QC H3A 1B1

	[[alternative HTML version deleted]]


From peter@|@ng|e|der @end|ng |rom gm@||@com  Sat Apr 18 01:05:50 2020
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Fri, 17 Apr 2020 16:05:50 -0700
Subject: [R] custom function gives unexpected result - for me
In-Reply-To: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
References: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
Message-ID: <CA+hbrhX9JtEaAMttbe1ksxfc4dof2XLYAFS-PNUCTbur0t58OA@mail.gmail.com>

You need 1:(m-1) in your function. The operator : has precedence over -:

> 1:3-1
[1] 0 1 2
> 1:(3-1)
[1] 1 2

Happened to me a few times as well before I remembered.

HTH,

Peter

On Fri, Apr 17, 2020 at 3:50 PM Monica Palaseanu-Lovejoy
<monicapalalovejoy at gmail.com> wrote:
>
> Hi,
>
> I wrote a relatively simple function. If i run the code inside the function
> line by line i am getting the result i was expecting, but if i run the
> function, i get a different result.
>
> The function:
>
> grr1 <- function(rn) {
> r.up <- c()
> for (i in 1:rn-1) {
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> r.up <- c(r.up, ru)
> }
> return(r.up)
> }
>
> So, if rn is 3 for example i would expect to get 1 1 2
>
> grr1(3)
> [1] 1 0 1 1 2
>
> If i run it line by line inside the function:
> r.up <- c()
> > r.up
> NULL
>
> i=1
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> > ru
> [1] 1
>
> r.up <- c(r.up, ru)
> r.up
> [1] 1
>
> i=2
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> ru
> [1] 1 2
> r.up <- c(r.up, ru)
> > r.up
> [1] 1 1 2
>
> So - i am getting the result i am expecting. From where the 1 0 before what
> i expect as a result comes from? I am sure i am doing some very basic
> error, but it seems i cannot figure it out.
>
> I run R x64  3.2.6. I know it is not the latest version, but it should not
> give me unexpected results because of that i would think.
>
> sessionInfo()
> R version 3.6.2 (2019-12-12)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.6.2
>
> Thanks,
> Monica
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Apr 18 01:18:21 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 18 Apr 2020 11:18:21 +1200
Subject: [R] Multi response GAM
In-Reply-To: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAB8pepz8tfumZ4Qzo=eR_am-QFsZQVXh1kRPo8U44RH3Nn_8jg@mail.gmail.com>

It might be possible via the VGAM package:
https://cran.r-project.org/package=VGAM

But I've never used this package, so not sure.

It may also be possible to use a single response, by including
additional explanatory terms.
This is what I would do, if I could...

Noting that some GAM implementations allow categorical variables and
interactions.


On Sat, Apr 18, 2020 at 11:00 AM Tristan Kosciuch
<tristan.kosciuch at mail.mcgill.ca> wrote:
>
> Hello,
>
> I am modelling the diet of Nile perch through time. I have 3 diet classes as
> my response variables; fish 1, fish 2, and invertebrates.
>
> The response variables are correlated, declines in invert consumption ~
> increase in fish consumption. Any advice on how to handle this would be
> appreciated. I would like to use GAMs as my time series shows fluctuations
> that could only be fit by high order polynomials if I were to use a linear
> model, but open to suggestions.
>
> Thank you for your time.
>
> P.s. I will be comparing the fit of the time series GAM with a model based
> on other predictors, with a training and validation split for my data.
>
>
>
> ---
>
> Tristan Kosciuch
>
> Stewart Biology Building, McGill University
>
> 1205 Dr Penfield Ave, Montreal QC H3A 1B1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Apr 18 01:26:19 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 18 Apr 2020 11:26:19 +1200
Subject: [R] [FORGED]  custom function gives unexpected result - for me
In-Reply-To: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
References: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
Message-ID: <69ed870d-115d-2a4e-b627-3be02892e8dc@auckland.ac.nz>



The answer is very simple:  parentheses.  (Also think about "operator 
precedence".) If you assign rn <- 3, then 1:rn-1 is:

[1] 0 1 2

The "-" operator is applied *after*  the ":" operator.

You want 1:(rn-1) which gives

[1] 1 2

and the desired result.

cheers,

Rolf Turner

On 18/04/20 7:55 am, Monica Palaseanu-Lovejoy wrote:
> Hi,
> 
> I wrote a relatively simple function. If i run the code inside the function
> line by line i am getting the result i was expecting, but if i run the
> function, i get a different result.
> 
> The function:
> 
> grr1 <- function(rn) {
> r.up <- c()
> for (i in 1:rn-1) {
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> r.up <- c(r.up, ru)
> }
> return(r.up)
> }
> 
> So, if rn is 3 for example i would expect to get 1 1 2
> 
> grr1(3)
> [1] 1 0 1 1 2
> 
> If i run it line by line inside the function:
> r.up <- c()
>> r.up
> NULL
> 
> i=1
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>> ru
> [1] 1
> 
> r.up <- c(r.up, ru)
> r.up
> [1] 1
> 
> i=2
> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> ru
> [1] 1 2
> r.up <- c(r.up, ru)
>> r.up
> [1] 1 1 2
> 
> So - i am getting the result i am expecting. From where the 1 0 before what
> i expect as a result comes from? I am sure i am doing some very basic
> error, but it seems i cannot figure it out.
> 
> I run R x64  3.2.6. I know it is not the latest version, but it should not
> give me unexpected results because of that i would think.
> 
> sessionInfo()
> R version 3.6.2 (2019-12-12)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 17763)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.6.2
> 
> Thanks,
> Monica


From bgunter@4567 @end|ng |rom gm@||@com  Sat Apr 18 01:28:06 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 17 Apr 2020 16:28:06 -0700
Subject: [R] Multi response GAM
In-Reply-To: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQO8rr2u=3Vs2y3-0e7HrgJhUwHM=_POVD154uwfjFPWg@mail.gmail.com>

https://cran.r-project.org/web/views/Multivariate.html
https://cran.r-project.org/web/views/Environmetrics.html
https://cran.r-project.org/web/views/TimeSeries.html

Also search on "multiresponse GAM" or similar at rseek.org. This brought up
what looked to me like useful hits.
And of course, don't forget Mama Google.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 17, 2020 at 4:00 PM Tristan Kosciuch <
tristan.kosciuch at mail.mcgill.ca> wrote:

> Hello,
>
> I am modelling the diet of Nile perch through time. I have 3 diet classes
> as
> my response variables; fish 1, fish 2, and invertebrates.
>
> The response variables are correlated, declines in invert consumption ~
> increase in fish consumption. Any advice on how to handle this would be
> appreciated. I would like to use GAMs as my time series shows fluctuations
> that could only be fit by high order polynomials if I were to use a linear
> model, but open to suggestions.
>
> Thank you for your time.
>
> P.s. I will be comparing the fit of the time series GAM with a model based
> on other predictors, with a training and validation split for my data.
>
>
>
> ---
>
> Tristan Kosciuch
>
> Stewart Biology Building, McGill University
>
> 1205 Dr Penfield Ave, Montreal QC H3A 1B1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 18 02:11:40 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 17 Apr 2020 17:11:40 -0700
Subject: [R] [FORGED]  custom function gives unexpected result - for me
In-Reply-To: <69ed870d-115d-2a4e-b627-3be02892e8dc@auckland.ac.nz>
References: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
 <69ed870d-115d-2a4e-b627-3be02892e8dc@auckland.ac.nz>
Message-ID: <3C0A9C13-924F-48C4-85A5-FE304002F9C9@dcn.davis.ca.us>

A useful help page:

?Syntax

On April 17, 2020 4:26:19 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
>The answer is very simple:  parentheses.  (Also think about "operator 
>precedence".) If you assign rn <- 3, then 1:rn-1 is:
>
>[1] 0 1 2
>
>The "-" operator is applied *after*  the ":" operator.
>
>You want 1:(rn-1) which gives
>
>[1] 1 2
>
>and the desired result.
>
>cheers,
>
>Rolf Turner
>
>On 18/04/20 7:55 am, Monica Palaseanu-Lovejoy wrote:
>> Hi,
>> 
>> I wrote a relatively simple function. If i run the code inside the
>function
>> line by line i am getting the result i was expecting, but if i run
>the
>> function, i get a different result.
>> 
>> The function:
>> 
>> grr1 <- function(rn) {
>> r.up <- c()
>> for (i in 1:rn-1) {
>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>> r.up <- c(r.up, ru)
>> }
>> return(r.up)
>> }
>> 
>> So, if rn is 3 for example i would expect to get 1 1 2
>> 
>> grr1(3)
>> [1] 1 0 1 1 2
>> 
>> If i run it line by line inside the function:
>> r.up <- c()
>>> r.up
>> NULL
>> 
>> i=1
>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>>> ru
>> [1] 1
>> 
>> r.up <- c(r.up, ru)
>> r.up
>> [1] 1
>> 
>> i=2
>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>> ru
>> [1] 1 2
>> r.up <- c(r.up, ru)
>>> r.up
>> [1] 1 1 2
>> 
>> So - i am getting the result i am expecting. From where the 1 0
>before what
>> i expect as a result comes from? I am sure i am doing some very basic
>> error, but it seems i cannot figure it out.
>> 
>> I run R x64  3.2.6. I know it is not the latest version, but it
>should not
>> give me unexpected results because of that i would think.
>> 
>> sessionInfo()
>> R version 3.6.2 (2019-12-12)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 17763)
>> 
>> Matrix products: default
>> 
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] compiler_3.6.2
>> 
>> Thanks,
>> Monica
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 18 02:34:23 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 17 Apr 2020 17:34:23 -0700
Subject: [R] [FORGED]  custom function gives unexpected result - for me
In-Reply-To: <3C0A9C13-924F-48C4-85A5-FE304002F9C9@dcn.davis.ca.us>
References: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
 <69ed870d-115d-2a4e-b627-3be02892e8dc@auckland.ac.nz>
 <3C0A9C13-924F-48C4-85A5-FE304002F9C9@dcn.davis.ca.us>
Message-ID: <8B6402BC-3C12-46AA-8A4D-EA92CCB09965@dcn.davis.ca.us>

A different solution:

grr2 <- function( rn ) {
  f <- function( i ) {
    if ( 0 == i %% 2 ) seq.int( i )
    else seq( i, 1 )
  }
  L <- lapply( seq.int( rn - 1 ), f )
  do.call( c, L )
}

On April 17, 2020 5:11:40 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>A useful help page:
>
>?Syntax
>
>On April 17, 2020 4:26:19 PM PDT, Rolf Turner <r.turner at auckland.ac.nz>
>wrote:
>>
>>
>>The answer is very simple:  parentheses.  (Also think about "operator 
>>precedence".) If you assign rn <- 3, then 1:rn-1 is:
>>
>>[1] 0 1 2
>>
>>The "-" operator is applied *after*  the ":" operator.
>>
>>You want 1:(rn-1) which gives
>>
>>[1] 1 2
>>
>>and the desired result.
>>
>>cheers,
>>
>>Rolf Turner
>>
>>On 18/04/20 7:55 am, Monica Palaseanu-Lovejoy wrote:
>>> Hi,
>>> 
>>> I wrote a relatively simple function. If i run the code inside the
>>function
>>> line by line i am getting the result i was expecting, but if i run
>>the
>>> function, i get a different result.
>>> 
>>> The function:
>>> 
>>> grr1 <- function(rn) {
>>> r.up <- c()
>>> for (i in 1:rn-1) {
>>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>>> r.up <- c(r.up, ru)
>>> }
>>> return(r.up)
>>> }
>>> 
>>> So, if rn is 3 for example i would expect to get 1 1 2
>>> 
>>> grr1(3)
>>> [1] 1 0 1 1 2
>>> 
>>> If i run it line by line inside the function:
>>> r.up <- c()
>>>> r.up
>>> NULL
>>> 
>>> i=1
>>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>>>> ru
>>> [1] 1
>>> 
>>> r.up <- c(r.up, ru)
>>> r.up
>>> [1] 1
>>> 
>>> i=2
>>> if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
>>> ru
>>> [1] 1 2
>>> r.up <- c(r.up, ru)
>>>> r.up
>>> [1] 1 1 2
>>> 
>>> So - i am getting the result i am expecting. From where the 1 0
>>before what
>>> i expect as a result comes from? I am sure i am doing some very
>basic
>>> error, but it seems i cannot figure it out.
>>> 
>>> I run R x64  3.2.6. I know it is not the latest version, but it
>>should not
>>> give me unexpected results because of that i would think.
>>> 
>>> sessionInfo()
>>> R version 3.6.2 (2019-12-12)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 17763)
>>> 
>>> Matrix products: default
>>> 
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.6.2
>>> 
>>> Thanks,
>>> Monica
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From mon|c@p@|@|ovejoy @end|ng |rom gm@||@com  Sat Apr 18 02:49:22 2020
From: mon|c@p@|@|ovejoy @end|ng |rom gm@||@com (Monica Palaseanu-Lovejoy)
Date: Fri, 17 Apr 2020 20:49:22 -0400
Subject: [R] custom function gives unexpected result - for me
In-Reply-To: <CA+hbrhX9JtEaAMttbe1ksxfc4dof2XLYAFS-PNUCTbur0t58OA@mail.gmail.com>
References: <CABnpDg0X3qjNMH+o8ZTGGpB8xVnP4tXLUU8F137dw8PyjY30Ng@mail.gmail.com>
 <CA+hbrhX9JtEaAMttbe1ksxfc4dof2XLYAFS-PNUCTbur0t58OA@mail.gmail.com>
Message-ID: <CABnpDg1WLd_uY44v84GLYV+hZ1jxk-CydVA==2b5GRtZmLqQ+g@mail.gmail.com>

Hi,

I cannot believe I did that. Usually I remember to add parenthesis but this
time obviously I didn?t. Thank you all so much for answering so quickly.

Thanks,
Monica

On Fri, Apr 17, 2020 at 7:06 PM Peter Langfelder <peter.langfelder at gmail.com>
wrote:

> You need 1:(m-1) in your function. The operator : has precedence over -:
>
> > 1:3-1
> [1] 0 1 2
> > 1:(3-1)
> [1] 1 2
>
> Happened to me a few times as well before I remembered.
>
> HTH,
>
> Peter
>
> On Fri, Apr 17, 2020 at 3:50 PM Monica Palaseanu-Lovejoy
> <monicapalalovejoy at gmail.com> wrote:
> >
> > Hi,
> >
> > I wrote a relatively simple function. If i run the code inside the
> function
> > line by line i am getting the result i was expecting, but if i run the
> > function, i get a different result.
> >
> > The function:
> >
> > grr1 <- function(rn) {
> > r.up <- c()
> > for (i in 1:rn-1) {
> > if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> > r.up <- c(r.up, ru)
> > }
> > return(r.up)
> > }
> >
> > So, if rn is 3 for example i would expect to get 1 1 2
> >
> > grr1(3)
> > [1] 1 0 1 1 2
> >
> > If i run it line by line inside the function:
> > r.up <- c()
> > > r.up
> > NULL
> >
> > i=1
> > if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> > > ru
> > [1] 1
> >
> > r.up <- c(r.up, ru)
> > r.up
> > [1] 1
> >
> > i=2
> > if (i%%2==0) ru <- seq(1,i) else ru <- seq(i,1)
> > ru
> > [1] 1 2
> > r.up <- c(r.up, ru)
> > > r.up
> > [1] 1 1 2
> >
> > So - i am getting the result i am expecting. From where the 1 0 before
> what
> > i expect as a result comes from? I am sure i am doing some very basic
> > error, but it seems i cannot figure it out.
> >
> > I run R x64  3.2.6. I know it is not the latest version, but it should
> not
> > give me unexpected results because of that i would think.
> >
> > sessionInfo()
> > R version 3.6.2 (2019-12-12)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 10 x64 (build 17763)
> >
> > Matrix products: default
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_3.6.2
> >
> > Thanks,
> > Monica
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h|gh@t@t @end|ng |rom h|gh@t@t@com  Sat Apr 18 12:25:01 2020
From: h|gh@t@t @end|ng |rom h|gh@t@t@com (Highland Statistics Ltd)
Date: Sat, 18 Apr 2020 11:25:01 +0100
Subject: [R] Multi response GAM
In-Reply-To: <mailman.358392.1.1587204002.54702.r-help@r-project.org>
References: <mailman.358392.1.1587204002.54702.r-help@r-project.org>
Message-ID: <eb3046ea-dfe6-f8d6-dcb8-67142a561c27@highstat.com>

Try R-INLA. It will allow you to model all three diet class time series 
in one model (even allowing for different distributions if required). 
And you can also include correlation between the time series. And test 
whether those diet classes have the same trend or not.

Alain


------------------------------

Message: 5
Date: Fri, 17 Apr 2020 22:45:33 +0000
From: Tristan Kosciuch <tristan.kosciuch at mail.mcgill.ca>
To: "r-help at R-project.org" <r-help at R-project.org>
Subject: [R] Multi response GAM
Message-ID:
<YQBPR0101MB134869D0F8483166E80901E5BBD90 at YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>

Content-Type: text/plain; charset="utf-8"

Hello,

I am modelling the diet of Nile perch through time. I have 3 diet classes as
my response variables; fish 1, fish 2, and invertebrates.

The response variables are correlated, declines in invert consumption ~
increase in fish consumption. Any advice on how to handle this would be
appreciated. I would like to use GAMs as my time series shows fluctuations
that could only be fit by high order polynomials if I were to use a linear
model, but open to suggestions.

Thank you for your time.

P.s. I will be comparing the fit of the time series GAM with a model based
on other predictors, with a training and validation split for my data.



---

Tristan Kosciuch

Stewart Biology Building, McGill University

1205 Dr Penfield Ave, Montreal QC H3A 1B1

[[alternative HTML version deleted]]




-- 

Dr. Alain F. Zuur
Highland Statistics Ltd.
9 St Clair Wynd
AB41 6DZ Newburgh, UK
Email: highstat at highstat.com
URL:   www.highstat.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Sat Apr 18 17:39:34 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Sat, 18 Apr 2020 17:39:34 +0200
Subject: [R] Changes to stats::glm function between R versions 3.4.0 and
 3.5.1
In-Reply-To: <LO2P123MB2205DC4A5BD853CDF88B0A49C0D80@LO2P123MB2205.GBRP123.PROD.OUTLOOK.COM>
References: <LO2P123MB2205DC4A5BD853CDF88B0A49C0D80@LO2P123MB2205.GBRP123.PROD.OUTLOOK.COM>
Message-ID: <24219.7990.267854.272291@stat.math.ethz.ch>

>>>>> Purver, Mark 
>>>>>     on Thu, 16 Apr 2020 10:02:09 +0000 writes:

    > Hi all,
    > Does anyone know whether there was a change to the algorithm of the glm function between versions 3.4.0 and 3.5.1 of the stats package? I noticed the introduction of the 'singular.ok' option, but I'm seeing more fundamental differences in the output of Generalised Linear Models between the two versions, particularly when the models don't converge.

    > In the later version, I'm seeing more variables 'blowing up' and giving large or NA standard error values when a model doesn't converge, but I'm using the same value of 'maxit' for both versions.

    > The numerical precision seems to be the same in versions 3.4.0 and 3.5.1 of R, as far as I can tell, but perhaps there is some difference that is indirectly affecting glm? Alternatively, there is a C function named Cdqrls that is called by glm, and I wondered if this had changed?

    > I have rather limited control over the version of R that I use, so I'm hoping I can produce results with 3.5.1 that are as similar as possible to those of 3.4.0.

    > Many thanks,

    > Mark Purver
    > Statistician, UK Ministry of Justice
    > ________________________________

Dear Mark,
is there any chance you can add a reproducible example to what
you claim above?

In general: Yes, there are changes between R versions, but of
course they should be improvements (aka "bug fixes").  So, for
this case, we really need a "repr.ex.", ideally as small as
possible.

OTOH, both 3.4.x  and  3.5.y  are "very old" in our eyes,
and at the moment, the smallest R version we could possibly
change is 4.0.0, but almost surely your problem would not be
both grave and simple to fix enough, and so a change would be
for R 4.0.1

Best regards,
Martin Maechler
ETH Zurich  and  R Core team


From m@|tr@ @end|ng |rom em@||@com  Sat Apr 18 21:10:29 2020
From: m@|tr@ @end|ng |rom em@||@com (Ranjan Maitra)
Date: Sat, 18 Apr 2020 14:10:29 -0500
Subject: [R] display math with subscripts from a sequence
Message-ID: <20200418141029.30013573b40bb066573338b1@email.com>

Dear friends,

I am trying to display a sequence of characters x_1, x_2, ... x_30 on a plot.

I know that I can use expression to  do this by expression("x"[1]), etc. But, how do I do this efficiently for an entire sequence without having to type the individual expressions one by one?

Many thanks,
Ranjan


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Apr 18 21:34:03 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 18 Apr 2020 15:34:03 -0400
Subject: [R] display math with subscripts from a sequence
In-Reply-To: <20200418141029.30013573b40bb066573338b1@email.com>
References: <20200418141029.30013573b40bb066573338b1@email.com>
Message-ID: <646ab8cf-10c2-aded-757b-ce433779af03@gmail.com>

On 18/04/2020 3:10 p.m., Ranjan Maitra wrote:
> Dear friends,
> 
> I am trying to display a sequence of characters x_1, x_2, ... x_30 on a plot.
> 
> I know that I can use expression to  do this by expression("x"[1]), etc. But, how do I do this efficiently for an entire sequence without having to type the individual expressions one by one?

e <- expression()
for (i in 1:30) e <- c(e, eval(substitute(expression(x[i]), list(i = i))))
plot(1:30, 1:30, type="n")
text(1:30, 1:30, labels=e)

Duncan Murdoch


From tr|@t@n@ko@c|uch @end|ng |rom m@||@mcg|||@c@  Sat Apr 18 02:08:31 2020
From: tr|@t@n@ko@c|uch @end|ng |rom m@||@mcg|||@c@ (Tristan Kosciuch)
Date: Sat, 18 Apr 2020 00:08:31 +0000
Subject: [R] Multi response GAM
In-Reply-To: <CAGxFJbQO8rr2u=3Vs2y3-0e7HrgJhUwHM=_POVD154uwfjFPWg@mail.gmail.com>
References: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>,
 <CAGxFJbQO8rr2u=3Vs2y3-0e7HrgJhUwHM=_POVD154uwfjFPWg@mail.gmail.com>
Message-ID: <YQBPR0101MB134861603718E7051F16FDB3BBD60@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>

Thanks, I think

family=mvn(d=3)

?in mgcv gam() works!



---

Tristan Kosciuch

Stewart Biology Building, McGill University

1205 Dr Penfield Ave, Montreal QC H3A 1B1

________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Friday, April 17, 2020 7:28 PM
To: Tristan Kosciuch <tristan.kosciuch at mail.mcgill.ca>
Cc: r-help at R-project.org <r-help at r-project.org>
Subject: Re: [R] Multi response GAM

https://cran.r-project.org/web/views/Multivariate.html
https://cran.r-project.org/web/views/Environmetrics.html
https://cran.r-project.org/web/views/TimeSeries.html

Also search on "multiresponse GAM" or similar at rseek.org<http://rseek.org>. This brought up what looked to me like useful hits.
And of course, don't forget Mama Google.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 17, 2020 at 4:00 PM Tristan Kosciuch <tristan.kosciuch at mail.mcgill.ca<mailto:tristan.kosciuch at mail.mcgill.ca>> wrote:
Hello,

I am modelling the diet of Nile perch through time. I have 3 diet classes as
my response variables; fish 1, fish 2, and invertebrates.

The response variables are correlated, declines in invert consumption ~
increase in fish consumption. Any advice on how to handle this would be
appreciated. I would like to use GAMs as my time series shows fluctuations
that could only be fit by high order polynomials if I were to use a linear
model, but open to suggestions.

Thank you for your time.

P.s. I will be comparing the fit of the time series GAM with a model based
on other predictors, with a training and validation split for my data.



---

Tristan Kosciuch

Stewart Biology Building, McGill University

1205 Dr Penfield Ave, Montreal QC H3A 1B1

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From chr|@@prener @end|ng |rom @|u@edu  Fri Apr 17 22:18:31 2020
From: chr|@@prener @end|ng |rom @|u@edu (Chris Prener)
Date: Fri, 17 Apr 2020 20:18:31 +0000
Subject: [R] useR! 2020 St. Louis Update
References: <f6c2c5c4-e314-416b-9960-411b2fc5bbef@Spark>
Message-ID: <346ddc98-80c7-4af7-88da-3ca906f65900@Spark>

Hello all:
We have made the disappointing decision to cancel useR! 2020 in St. Louis. This has been in process for several weeks, but we have not been able to share details publicly until today. We've appreciated the R community's patience as we've worked on this.

We have not made any final decisions about what comes next for useR! 2020. We?ll be working with the R Foundation, useR! 2020 Munich, and our local team next week to determine the best course of action for us to collectively take. We?ll be in touch soon about possible next steps.

If you have already registered for the conference, you can expect to hear from us early next week about refunds associated with your registration. Our sponsors, keynotes, tutorial leaders, presenters, and diversity scholars will be receiving updates from our team as well. If you have registered for a room with our venue, the Marriott St. Louis Grand, the hotel will be cancelling those reservations.

In the meantime, we hope you all remain healthy and well. We also want to thank the nearly 60 folks who have contributed to our organizing team and spent countless hours working towards a successful conference. Your hard work means the world to us.

Best,
Chris Prener, Ph.D. and Jenine Harris, Ph.D.
useR! 2020 St. Louis Co-lead Organizers

	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

From j|@r@ch @end|ng |rom gm@||@com  Sat Apr 18 22:50:02 2020
From: j|@r@ch @end|ng |rom gm@||@com (Julio Farach)
Date: Sat, 18 Apr 2020 16:50:02 -0400
Subject: [R] Web-scraping newbie - dynamic table into R?
Message-ID: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>

How do I scrape the last 10 Keno draws from the Georgia lottery into R?


I'm trying to pull the last 10 draws of a Keno lottery game into R.  I've
read several tutorials on how to scrape websites using the rvest package,
Chrome's Inspect Element, and CSS or XPath, but I'm likely stuck because
the table I seek is dynamically generated using Javascript.



I started with:

>        install.packages("rvest")

>   library(rvest)

>        Kenopage <- "
https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
"

> Keno <- Read.hmtl(Kenopage)

>From there, I've been unable to progress, despite hours spend on
combinations of CSS and XPath calls with "html_notes."

Failed example: DrawNumber <- Keno %>% rvest::html_nodes("body") %>%
xml2::xml_find_all("//span[contains(@class,'Draw Number')]") %>%
rvest::html_text()



Someone mentioned using the V8 package in R, but it's new to me.

How do I get started?

-- 

Julio Farach
https://www.linkedin.com/in/farach
cell phone:  804/363-2161
email:  JFarach at gmail.com

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr 19 22:10:24 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 19 Apr 2020 13:10:24 -0700
Subject: [R] Web-scraping newbie - dynamic table into R?
In-Reply-To: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
References: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
Message-ID: <99E554C6-66B2-4658-AC6E-9BB4B5CAFC78@dcn.davis.ca.us>

Web-scraping is not a common topic here, but one point that does come up is to be sure you are conforming with the website terms of use before getting in too deep.

Another bit of advice is to look for the underlying API... that is usually more performant than scraping anyway. Try using the developer tools in Chrome to find out how they are populating the page for clues, or just Google it.

Finally, you might try the RSelenium package. I don't have first hand experience with it but it is reputed to be designed to scrape dynamic web pages.

On April 18, 2020 1:50:02 PM PDT, Julio Farach <jfarach at gmail.com> wrote:
>How do I scrape the last 10 Keno draws from the Georgia lottery into R?
>
>
>I'm trying to pull the last 10 draws of a Keno lottery game into R. 
>I've
>read several tutorials on how to scrape websites using the rvest
>package,
>Chrome's Inspect Element, and CSS or XPath, but I'm likely stuck
>because
>the table I seek is dynamically generated using Javascript.
>
>
>
>I started with:
>
>>        install.packages("rvest")
>
>>   library(rvest)
>
>>        Kenopage <- "
>https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
>"
>
>> Keno <- Read.hmtl(Kenopage)
>
>From there, I've been unable to progress, despite hours spend on
>combinations of CSS and XPath calls with "html_notes."
>
>Failed example: DrawNumber <- Keno %>% rvest::html_nodes("body") %>%
>xml2::xml_find_all("//span[contains(@class,'Draw Number')]") %>%
>rvest::html_text()
>
>
>
>Someone mentioned using the V8 package in R, but it's new to me.
>
>How do I get started?

-- 
Sent from my phone. Please excuse my brevity.


From jrkr|de@u @end|ng |rom gm@||@com  Sun Apr 19 22:38:26 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 19 Apr 2020 16:38:26 -0400
Subject: [R] Web-scraping newbie - dynamic table into R?
In-Reply-To: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
References: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
Message-ID: <CAKZQJMDQ06ky2_EfCHYZLfoZUeT9UsQ=bokjx1xArFDqy4Z8WA@mail.gmail.com>

Keno <- read_html(Kenopage) ?

Or Am I misunderstanding the problem?

On Sun, 19 Apr 2020 at 15:10, Julio Farach <jfarach at gmail.com> wrote:

> How do I scrape the last 10 Keno draws from the Georgia lottery into R?
>
>
> I'm trying to pull the last 10 draws of a Keno lottery game into R.  I've
> read several tutorials on how to scrape websites using the rvest package,
> Chrome's Inspect Element, and CSS or XPath, but I'm likely stuck because
> the table I seek is dynamically generated using Javascript.
>
>
>
> I started with:
>
> >        install.packages("rvest")
>
> >   library(rvest)
>
> >        Kenopage <- "
>
> https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
> "
>
> > Keno <- Read.hmtl(Kenopage)
>
> From there, I've been unable to progress, despite hours spend on
> combinations of CSS and XPath calls with "html_notes."
>
> Failed example: DrawNumber <- Keno %>% rvest::html_nodes("body") %>%
> xml2::xml_find_all("//span[contains(@class,'Draw Number')]") %>%
> rvest::html_text()
>
>
>
> Someone mentioned using the V8 package in R, but it's new to me.
>
> How do I get started?
>
> --
>
> Julio Farach
> https://www.linkedin.com/in/farach
> cell phone:  804/363-2161
> email:  JFarach at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From he|en@@w@y@ @end|ng |rom hotm@||@com  Sun Apr 19 21:52:36 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Sun, 19 Apr 2020 19:52:36 +0000
Subject: [R] NA command in a 'for' loop
Message-ID: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>

Dear R experts,

I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single dataset (outside the loop). I've tried:

all.files <- list.files(".")
txt.files <- grep("threat.txt",all.files,value=T)

for(i in txt.files){
  d <- read.table(paste(i,sep=""),header=F)
  d[d==0] <- NA #replace zeros with NA
  write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
  d<-d[ ,-c(10,11)]
  d2<-d[complete.cases(d), ]
  d2$V4<-as.numeric(d2$V4)
  congruent <- (d2$V4 == 1) == TRUE
  x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
  write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}

I've also tried:

for(i in txt.files){
  d <- read.table(paste(i,sep=""),header=F)
  if (0 %in% d)
  {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
  d<-d[ ,-c(10,11)]
  d2<-d[complete.cases(d), ]
  d2$V4<-as.numeric(d2$V4)
  congruent <- (d2$V4 == 1) == TRUE
  x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
  write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}

Thank you for your help.
Sincerely
Helen

	[[alternative HTML version deleted]]


From ||9212001 @end|ng |rom y@hoo@com  Sun Apr 19 22:20:03 2020
From: ||9212001 @end|ng |rom y@hoo@com (aiguo li)
Date: Sun, 19 Apr 2020 20:20:03 +0000 (UTC)
Subject: [R] how to create a sorted barplot and colored by groups
References: <101378036.3109664.1587327603395.ref@mail.yahoo.com>
Message-ID: <101378036.3109664.1587327603395@mail.yahoo.com>

Dear all,
I need some help for creating a barplot as below.? I have three genes and a type column in the dataframe attached.? I would like to sort each gene from low to high within each type and create a barplot similar to the one below, but colored and grouped by type.?
Thanks in advance for your hep!
Aiguo


|  | types | MYC | MYCL | MYCN |
| TS603_1 | AnaplasticOligo | 7.97 | 2.98 | 0.48 |
| TS603_2 | AnaplasticOligo | 9.04 | 3.94 | 0.28 |
| TS603_3 | AnaplasticOligo | 9.35 | 3.29 | 0.33 |
| NCH612_1 | AnaplasticOligo | 13.86 | 0.88 | 33.5 |
| NCH612_2 | AnaplasticOligo | 14.02 | 0.88 | 36.12 |
| NCH612_3 | AnaplasticOligo | 15.99 | 0.95 | 35.67 |
| DIPG_XIX_2 | DIPG | 1.12 | 6.18 | 24.37 |
| DIPG_XIX_1 | DIPG | 1.27 | 6 | 25.63 |
| DIPG_XIX_3 | DIPG | 1.63 | 7.19 | 26.06 |
| DIPG_38_3 | DIPG | 3.18 | 14.08 | 8.52 |
| DIPG_38_1 | DIPG | 3.4 | 14.48 | 10.2 |
| DIPG_38_2 | DIPG | 5.62 | 12.27 | 12.37 |
| DIPG_36_1 | DIPG | 6.65 | 0.45 | 4.86 |
| DIPG_36_3 | DIPG | 7.04 | 0.28 | 4.55 |
| DIPG_29_1 | DIPG | 7.2 | 2.29 | 9.38 |
| DIPG_35_1 | DIPG | 7.87 | 1.34 | 8.87 |
| DIPG_36_2 | DIPG | 8.18 | 0.41 | 3 |
| DIPG_29_2 | DIPG | 8.85 | 1.53 | 10.97 |
| DIPG_35_2 | DIPG | 8.99 | 0.74 | 11.52 |
| DIPG_29_3 | DIPG | 9.66 | 1.03 | 9.46 |
| DIPG_35_3 | DIPG | 9.73 | 1.35 | 11.92 |
| DIPG_IV_3 | DIPG | 11.68 | 0.08 | 0 |
| DIPG_IV_1 | DIPG | 13.63 | 0.29 | 0 |
| DIPG_IV_2 | DIPG | 15.2 | 0.17 | 0 |
| DIPG_43_2 | DIPG | 17.77 | 3.72 | 10.33 |
| DIPG_43_3 | DIPG | 22.04 | 3.02 | 9.52 |
| DIPG_43_1 | DIPG | 22.87 | 3.42 | 9.24 |
| DIPG_13_3 | DIPG | 26.36 | 1.3 | 13.89 |
| DIPG_13_2 | DIPG | 26.44 | 1.4 | 13.88 |
| DIPG_50_3 | DIPG | 31.92 | 0.62 | 9.55 |
| DIPG_13_1 | DIPG | 32.57 | 1.41 | 14.78 |
| DIPG_50_2 | DIPG | 34.13 | 0.98 | 7.74 |
| DIPG_24_3 | DIPG | 34.22 | 0.75 | 11.73 |
| DIPG_24_1 | DIPG | 35.75 | 0.46 | 14.92 |
| DIPG_50_1 | DIPG | 35.78 | 1.03 | 10.75 |
| DIPG_24_2 | DIPG | 38.48 | 0.78 | 13.08 |
| DIPG_45_3 | DIPG | 59.56 | 2.34 | 9.1 |
| DIPG_45_2 | DIPG | 60.23 | 2.79 | 9.32 |
| DIPG_45_1 | DIPG | 63.19 | 2.59 | 9.7 |
| DIPG_SCG-1_1 | DIPG | 96.95 | 3.1 | 481.64 |
| DIPG_SCG-1_3 | DIPG | 106.77 | 3.79 | 481.03 |
| DIPG_SCG-1_2 | DIPG | 109.77 | 2.88 | 523.27 |
| DIPG_27_1 | DIPG | 195.07 | 2.23 | 5.92 |
| DIPG_27_3 | DIPG | 195.45 | 3.09 | 6.71 |
| DIPG_27_2 | DIPG | 205.33 | 3.28 | 6.26 |
| DIPGXVII_ONC206_2 | DIPG | 327.55 | 2.07 | 2.21 |
| DIPGXVII_ONC206_3 | DIPG | 358.3 | 1.8 | 2.55 |
| DIPGXVII_ONC206_1 | DIPG | 368.93 | 1.97 | 2.28 |
| DIPG_17_2 | DIPG | 424.17 | 7.35 | 5.18 |
| DIPG_25_1 | DIPG | 447.28 | 4.47 | 5.84 |
| DIPG_25_3 | DIPG | 458.31 | 4.98 | 6.18 |
| DIPG_17_1 | DIPG | 480.19 | 8.66 | 5.95 |
| DIPG_17_3 | DIPG | 488.79 | 9.64 | 5.16 |
| DIPG_25_2 | DIPG | 490.16 | 5.23 | 7.56 |
| DIPGXVII_1_3 | DIPG | 509.04 | 2.33 | 2.97 |
| DIPGXVII_ONC201_1 | DIPG | 509.05 | 2.51 | 2.58 |
| DIPGXVII_1_1 | DIPG | 541.42 | 2.79 | 2.91 |
| DIPGXVII_ONC201_3 | DIPG | 555.35 | 1.96 | 3.19 |
| DIPGXVII_1_2 | DIPG | 577.68 | 2.19 | 3.01 |
| DIPGXVII_ONC201_2 | DIPG | 580.61 | 2.38 | 2.8 |
| DIPGXVII_2_2 | DIPG | 585.22 | 2.34 | 3.36 |
| DIPGXVII_2_1 | DIPG | 591.72 | 2.62 | 3.01 |
| DIPGXVII_2_3 | DIPG | 619.18 | 3.04 | 2.35 |
| GSC627_1 | glioma | 0 | 0.79 | 597.07 |
| GSC627_2 | glioma | 0 | 1.25 | 615.02 |
| GSC627_3 | glioma | 0.07 | 1.01 | 632.08 |
| MGG152_2 | glioma | 0.13 | 13.37 | 916.02 |
| MGG152_1 | glioma | 0.18 | 12.92 | 895.3 |
| MGG152_3 | glioma | 0.22 | 14.47 | 935.56 |
| GBM1_3 | glioma | 4.58 | 6.73 | 291.75 |
| GBM1_1 | glioma | 4.96 | 6.36 | 276.04 |
| GBM1_2 | glioma | 5.35 | 7.21 | 280.6 |
| GSC17_3 | glioma | 7.54 | 3.89 | 59.22 |
| GSC17_2 | glioma | 8.38 | 3.89 | 60.65 |
| GSC17_1 | glioma | 9.8 | 4.77 | 57.33 |
| GBM164_3 | glioma | 11.14 | 1.42 | 7.04 |
| GBM164_1 | glioma | 11.89 | 1.53 | 6.04 |
| GBM164_2 | glioma | 12.69 | 1.85 | 6.8 |
| GSC923_3 | glioma | 14.93 | 6.59 | 216.57 |
| GSC923_2 | glioma | 15.63 | 5.75 | 226.94 |
| GSC923_1 | glioma | 16.93 | 5.75 | 207.18 |
| GSC268_3 | glioma | 16.94 | 0.14 | 7.14 |
| GSC268_1 | glioma | 17.8 | 0.01 | 8.25 |
| GSC268_2 | glioma | 19.97 | 0.11 | 6.24 |
| SF10602_3 | glioma | 23.81 | 2.39 | 0.47 |
| SF10602_1 | glioma | 25.38 | 2.72 | 0.43 |
| MGG119_1 | glioma | 25.49 | 6.84 | 9.8 |
| SF10602_2 | glioma | 25.61 | 2.5 | 0.55 |
| GSC827_2 | glioma | 27.67 | 2.32 | 128.56 |
| GSC827_3 | glioma | 28.2 | 3.22 | 128.85 |
| GSC827_1 | glioma | 30.6 | 3.15 | 126.77 |
| MGG119_2 | glioma | 31.43 | 5.86 | 9.02 |
| BT054_3 | glioma | 35.26 | 0.46 | 2.89 |
| MGG119_3 | glioma | 35.57 | 6.52 | 9.42 |
| BT054_2 | glioma | 39.74 | 0.53 | 3.29 |
| BT054_1 | glioma | 42.22 | 0.28 | 3.54 |
| SF10417_1 | glioma | 43.93 | 2.93 | 0.21 |
| SF10417_2 | glioma | 44.77 | 2.43 | 0.32 |
| GBM196_1 | glioma | 47.28 | 0.33 | 1.75 |
| GBM196_2 | glioma | 48.85 | 0.34 | 1.9 |
| SF10417_3 | glioma | 48.88 | 2.81 | 0.27 |
| GBM196_3 | glioma | 50.5 | 0.4 | 2.25 |
| BT088_1 | glioma | 65.83 | 4.3 | 12.17 |
| BT088_2 | glioma | 66.96 | 4.13 | 10.33 |
| TB096_1 | glioma | 71.38 | 5.55 | 0 |
| TB096_3 | glioma | 74.87 | 4.55 | 0.03 |
| TB096_2 | glioma | 80.34 | 4.37 | 0 |
| BT088_3 | glioma | 93.29 | 4.1 | 12.14 |
| GSC274_2 | glioma | 134.37 | 0.28 | 0.03 |
| GSC274_1 | glioma | 135.93 | 0.38 | 0.04 |
| GSC274_3 | glioma | 169.64 | 0.27 | 0.06 |
| GSC711_1 | glioma | 192.15 | 1.95 | 155.15 |
| GSC711_2 | glioma | 192.85 | 2.11 | 141.35 |
| GSC711_3 | glioma | 198.1 | 2.1 | 154.15 |
| XO1_1 | GSC | 0.22 | 0.35 | 661.86 |
| XO6_2 | GSC | 0.23 | 0.06 | 539.81 |
| XO1_3 | GSC | 0.31 | 0.32 | 709.18 |
| XO9_3 | GSC | 0.34 | 0.17 | 999.27 |
| XO6_1 | GSC | 0.37 | 0.09 | 523.3 |
| XO1_2 | GSC | 0.41 | 0.03 | 683.86 |
| XO9_2 | GSC | 0.48 | 0.15 | 992.87 |
| XO6_3 | GSC | 0.52 | 0.15 | 531.36 |
| XO9_1 | GSC | 0.67 | 0.32 | 919.95 |
| XO10_1 | GSC | 5 | 0.08 | 409.65 |
| XO10_3 | GSC | 5.49 | 0.11 | 335.44 |
| XO10_2 | GSC | 6.06 | 0.03 | 369.5 |
| L0_1 | GSC | 16.48 | 3.35 | 0.4 |
| L1_2 | GSC | 17.38 | 3.36 | 0.93 |
| L0_3 | GSC | 17.54 | 3.59 | 0.49 |
| L0_2 | GSC | 19.1 | 4.11 | 0.6 |
| L1_1 | GSC | 21.54 | 3.82 | 1 |
| L1_3 | GSC | 22.71 | 3.57 | 0.9 |
| GSC403_3 | GSC | 37.44 | 4.86 | 17.64 |
| GSC403_2 | GSC | 38.07 | 5.59 | 18.46 |
| GSC403_1 | GSC | 38.83 | 5.11 | 16.2 |
| XO2_2 | GSC | 78.66 | 0.01 | 0.88 |
| XO2_1 | GSC | 80.11 | 0.03 | 0.93 |
| XO2_3 | GSC | 90.97 | 0 | 1.01 |
| CA4_1_1 | GSC | 153.82 | 0.05 | 0 |
| CA4_1_3 | GSC | 155.24 | 0.13 | 0 |
| CA4_2_1 | GSC | 161 | 0 | 0.04 |
| CA4_1_2 | GSC | 162.61 | 0.08 | 0 |
| CA4_2_2 | GSC | 164.36 | 0.08 | 0 |
| CA4_2_3 | GSC | 175.21 | 0.11 | 0 |
| CA4_ONC201_2 | GSC | 196.03 | 0.21 | 0 |
| CA4_ONC201_3 | GSC | 208.01 | 0.15 | 0 |
| CA4_ONC201_1 | GSC | 217.87 | 0.03 | 0 |
| CA1_3 | GSC | 240.43 | 0.09 | 0 |
| CA1_1 | GSC | 253.36 | 0.18 | 0 |
| CA4_2 | GSC | 260.43 | 0.05 | 0 |
| CA4_ONC206_2 | GSC | 261.34 | 0.35 | 0.06 |
| CA4_3 | GSC | 266.39 | 0.07 | 0.06 |
| CA1_2 | GSC | 266.96 | 0.07 | 0.02 |
| CA4_1 | GSC | 273.27 | 0.11 | 0.04 |
| CA4_ONC206_1 | GSC | 279.86 | 0.36 | 0 |
| CA4_ONC206_3 | GSC | 281.32 | 0.37 | 0 |
| HW8_2 | HW | 15.39 | 7.56 | 23.16 |
| HW7_2_2 | HW | 17.31 | 6.38 | 23.78 |
| HW8_1 | HW | 18.19 | 7.38 | 20.54 |
| HW8_3 | HW | 19.71 | 7.42 | 23.85 |
| HW8_R132_1 | HW | 20.08 | 6.23 | 27 |
| HW5_1 | HW | 22.64 | 7.42 | 41.08 |
| HW7_1_2 | HW | 22.81 | 7.5 | 34.93 |
| HW7_2_3 | HW | 22.87 | 7.72 | 22.19 |
| HW7_1_1 | HW | 23.98 | 7.26 | 26.06 |
| HW5_3 | HW | 24.64 | 7.06 | 36.65 |
| HW8_R132_2 | HW | 24.77 | 6.09 | 25.01 |
| HW5_2 | HW | 25.16 | 7.47 | 39.44 |
| HW8_R132_3 | HW | 26.31 | 5.81 | 21.03 |
| HW7_1_3 | HW | 27.04 | 9.31 | 32.27 |
| HW7_2_1 | HW | 30.47 | 7.58 | 31.84 |
| HW10_1 | HW | 35.38 | 9.74 | 32.4 |
| HW10_3 | HW | 37.45 | 9.59 | 42.56 |
| HW10_2 | HW | 39.95 | 9.58 | 37 |
| HW10_R132H_2 | HW | 47.78 | 9.33 | 35.61 |
| HW10_R132H_3 | HW | 55.78 | 10.55 | 30.24 |
| HW10_R132H_1 | HW | 62.03 | 9.29 | 28.2 |
| LN229_2 | MCL | 5.09 | 0.56 | 22.21 |
| LN229_3 | MCL | 5.41 | 0.96 | 20.27 |
| LN229_1 | MCL | 6.3 | 0.67 | 24.38 |
| SW1088_2 | MCL | 11.59 | 0.14 | 0 |
| SW1088_3 | MCL | 15.17 | 0.37 | 0 |
| SW1088_1 | MCL | 18 | 0.11 | 0 |
| U251_3 | MCL | 19.74 | 0.45 | 0 |
| U251_1 | MCL | 21.4 | 0.31 | 0 |
| U251_2 | MCL | 23.51 | 0.45 | 0 |
| A172_2 | MCL | 41.43 | 0.72 | 0.03 |
| BT142_2 | MCL | 45.43 | 2.39 | 9.77 |
| BT142_1 | MCL | 45.95 | 2.02 | 8.23 |
| BT142_3 | MCL | 48.88 | 1.71 | 10.31 |
| A172_1 | MCL | 49.68 | 0.81 | 0.02 |
| A172_3 | MCL | 49.98 | 0.59 | 0 |
| NHA_R132H_1 | Normal astrocyte | 43.67 | 0.19 | 0 |
| NHA_3 | Normal astrocyte | 58.47 | 0.04 | 0 |
| NHA_R132H_2 | Normal astrocyte | 58.48 | 0.12 | 0 |
| NHA_1 | Normal astrocyte | 58.58 | 0.13 | 0 |
| NHA_2 | Normal astrocyte | 59.03 | 0.06 | 0 |
| NHA_R132H_3 | Normal astrocyte | 63.43 | 0.15 | 0 |



-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1587327345029blob.jpg
Type: image/png
Size: 10640 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200419/09f4b4a3/attachment.png>

From jrkr|de@u @end|ng |rom gm@||@com  Mon Apr 20 01:30:22 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 19 Apr 2020 19:30:22 -0400
Subject: [R] how to create a sorted barplot and colored by groups
In-Reply-To: <101378036.3109664.1587327603395@mail.yahoo.com>
References: <101378036.3109664.1587327603395.ref@mail.yahoo.com>
 <101378036.3109664.1587327603395@mail.yahoo.com>
Message-ID: <CAKZQJMDsbrj+5pGGQtX2T=A8sKW-2jpf+jHbE6ghD+461+210g@mail.gmail.com>

Hi,
At the moment I cannot make sense of your data. You write "I have three
genes and a type column in the dataframe" but it seems to have 5 columns.
Would you please supply us with the sample data in dput() format?

Here are some suggestions and an example on how to do this plus other
advice on asking a question.  http://adv-r.had.co.nz/Reproducibility.html

What if anything have you tried?

On Sun, 19 Apr 2020 at 18:44, aiguo li via R-help <r-help at r-project.org>
wrote:

> Dear all,
> I need some help for creating a barplot as below.  I have three genes and
> a type column in the dataframe attached.  I would like to sort each gene
> from low to high within each type and create a barplot similar to the one
> below, but colored and grouped by type.
> Thanks in advance for your hep!
> Aiguo
>
>
> |  | types | MYC | MYCL | MYCN |
> | TS603_1 | AnaplasticOligo | 7.97 | 2.98 | 0.48 |
> | TS603_2 | AnaplasticOligo | 9.04 | 3.94 | 0.28 |
> | TS603_3 | AnaplasticOligo | 9.35 | 3.29 | 0.33 |
> | NCH612_1 | AnaplasticOligo | 13.86 | 0.88 | 33.5 |
> | NCH612_2 | AnaplasticOligo | 14.02 | 0.88 | 36.12 |
> | NCH612_3 | AnaplasticOligo | 15.99 | 0.95 | 35.67 |
> | DIPG_XIX_2 | DIPG | 1.12 | 6.18 | 24.37 |
> | DIPG_XIX_1 | DIPG | 1.27 | 6 | 25.63 |
> | DIPG_XIX_3 | DIPG | 1.63 | 7.19 | 26.06 |
> | DIPG_38_3 | DIPG | 3.18 | 14.08 | 8.52 |
> | DIPG_38_1 | DIPG | 3.4 | 14.48 | 10.2 |
> | DIPG_38_2 | DIPG | 5.62 | 12.27 | 12.37 |
> | DIPG_36_1 | DIPG | 6.65 | 0.45 | 4.86 |
> | DIPG_36_3 | DIPG | 7.04 | 0.28 | 4.55 |
> | DIPG_29_1 | DIPG | 7.2 | 2.29 | 9.38 |
> | DIPG_35_1 | DIPG | 7.87 | 1.34 | 8.87 |
> | DIPG_36_2 | DIPG | 8.18 | 0.41 | 3 |
> | DIPG_29_2 | DIPG | 8.85 | 1.53 | 10.97 |
> | DIPG_35_2 | DIPG | 8.99 | 0.74 | 11.52 |
> | DIPG_29_3 | DIPG | 9.66 | 1.03 | 9.46 |
> | DIPG_35_3 | DIPG | 9.73 | 1.35 | 11.92 |
> | DIPG_IV_3 | DIPG | 11.68 | 0.08 | 0 |
> | DIPG_IV_1 | DIPG | 13.63 | 0.29 | 0 |
> | DIPG_IV_2 | DIPG | 15.2 | 0.17 | 0 |
> | DIPG_43_2 | DIPG | 17.77 | 3.72 | 10.33 |
> | DIPG_43_3 | DIPG | 22.04 | 3.02 | 9.52 |
> | DIPG_43_1 | DIPG | 22.87 | 3.42 | 9.24 |
> | DIPG_13_3 | DIPG | 26.36 | 1.3 | 13.89 |
> | DIPG_13_2 | DIPG | 26.44 | 1.4 | 13.88 |
> | DIPG_50_3 | DIPG | 31.92 | 0.62 | 9.55 |
> | DIPG_13_1 | DIPG | 32.57 | 1.41 | 14.78 |
> | DIPG_50_2 | DIPG | 34.13 | 0.98 | 7.74 |
> | DIPG_24_3 | DIPG | 34.22 | 0.75 | 11.73 |
> | DIPG_24_1 | DIPG | 35.75 | 0.46 | 14.92 |
> | DIPG_50_1 | DIPG | 35.78 | 1.03 | 10.75 |
> | DIPG_24_2 | DIPG | 38.48 | 0.78 | 13.08 |
> | DIPG_45_3 | DIPG | 59.56 | 2.34 | 9.1 |
> | DIPG_45_2 | DIPG | 60.23 | 2.79 | 9.32 |
> | DIPG_45_1 | DIPG | 63.19 | 2.59 | 9.7 |
> | DIPG_SCG-1_1 | DIPG | 96.95 | 3.1 | 481.64 |
> | DIPG_SCG-1_3 | DIPG | 106.77 | 3.79 | 481.03 |
> | DIPG_SCG-1_2 | DIPG | 109.77 | 2.88 | 523.27 |
> | DIPG_27_1 | DIPG | 195.07 | 2.23 | 5.92 |
> | DIPG_27_3 | DIPG | 195.45 | 3.09 | 6.71 |
> | DIPG_27_2 | DIPG | 205.33 | 3.28 | 6.26 |
> | DIPGXVII_ONC206_2 | DIPG | 327.55 | 2.07 | 2.21 |
> | DIPGXVII_ONC206_3 | DIPG | 358.3 | 1.8 | 2.55 |
> | DIPGXVII_ONC206_1 | DIPG | 368.93 | 1.97 | 2.28 |
> | DIPG_17_2 | DIPG | 424.17 | 7.35 | 5.18 |
> | DIPG_25_1 | DIPG | 447.28 | 4.47 | 5.84 |
> | DIPG_25_3 | DIPG | 458.31 | 4.98 | 6.18 |
> | DIPG_17_1 | DIPG | 480.19 | 8.66 | 5.95 |
> | DIPG_17_3 | DIPG | 488.79 | 9.64 | 5.16 |
> | DIPG_25_2 | DIPG | 490.16 | 5.23 | 7.56 |
> | DIPGXVII_1_3 | DIPG | 509.04 | 2.33 | 2.97 |
> | DIPGXVII_ONC201_1 | DIPG | 509.05 | 2.51 | 2.58 |
> | DIPGXVII_1_1 | DIPG | 541.42 | 2.79 | 2.91 |
> | DIPGXVII_ONC201_3 | DIPG | 555.35 | 1.96 | 3.19 |
> | DIPGXVII_1_2 | DIPG | 577.68 | 2.19 | 3.01 |
> | DIPGXVII_ONC201_2 | DIPG | 580.61 | 2.38 | 2.8 |
> | DIPGXVII_2_2 | DIPG | 585.22 | 2.34 | 3.36 |
> | DIPGXVII_2_1 | DIPG | 591.72 | 2.62 | 3.01 |
> | DIPGXVII_2_3 | DIPG | 619.18 | 3.04 | 2.35 |
> | GSC627_1 | glioma | 0 | 0.79 | 597.07 |
> | GSC627_2 | glioma | 0 | 1.25 | 615.02 |
> | GSC627_3 | glioma | 0.07 | 1.01 | 632.08 |
> | MGG152_2 | glioma | 0.13 | 13.37 | 916.02 |
> | MGG152_1 | glioma | 0.18 | 12.92 | 895.3 |
> | MGG152_3 | glioma | 0.22 | 14.47 | 935.56 |
> | GBM1_3 | glioma | 4.58 | 6.73 | 291.75 |
> | GBM1_1 | glioma | 4.96 | 6.36 | 276.04 |
> | GBM1_2 | glioma | 5.35 | 7.21 | 280.6 |
> | GSC17_3 | glioma | 7.54 | 3.89 | 59.22 |
> | GSC17_2 | glioma | 8.38 | 3.89 | 60.65 |
> | GSC17_1 | glioma | 9.8 | 4.77 | 57.33 |
> | GBM164_3 | glioma | 11.14 | 1.42 | 7.04 |
> | GBM164_1 | glioma | 11.89 | 1.53 | 6.04 |
> | GBM164_2 | glioma | 12.69 | 1.85 | 6.8 |
> | GSC923_3 | glioma | 14.93 | 6.59 | 216.57 |
> | GSC923_2 | glioma | 15.63 | 5.75 | 226.94 |
> | GSC923_1 | glioma | 16.93 | 5.75 | 207.18 |
> | GSC268_3 | glioma | 16.94 | 0.14 | 7.14 |
> | GSC268_1 | glioma | 17.8 | 0.01 | 8.25 |
> | GSC268_2 | glioma | 19.97 | 0.11 | 6.24 |
> | SF10602_3 | glioma | 23.81 | 2.39 | 0.47 |
> | SF10602_1 | glioma | 25.38 | 2.72 | 0.43 |
> | MGG119_1 | glioma | 25.49 | 6.84 | 9.8 |
> | SF10602_2 | glioma | 25.61 | 2.5 | 0.55 |
> | GSC827_2 | glioma | 27.67 | 2.32 | 128.56 |
> | GSC827_3 | glioma | 28.2 | 3.22 | 128.85 |
> | GSC827_1 | glioma | 30.6 | 3.15 | 126.77 |
> | MGG119_2 | glioma | 31.43 | 5.86 | 9.02 |
> | BT054_3 | glioma | 35.26 | 0.46 | 2.89 |
> | MGG119_3 | glioma | 35.57 | 6.52 | 9.42 |
> | BT054_2 | glioma | 39.74 | 0.53 | 3.29 |
> | BT054_1 | glioma | 42.22 | 0.28 | 3.54 |
> | SF10417_1 | glioma | 43.93 | 2.93 | 0.21 |
> | SF10417_2 | glioma | 44.77 | 2.43 | 0.32 |
> | GBM196_1 | glioma | 47.28 | 0.33 | 1.75 |
> | GBM196_2 | glioma | 48.85 | 0.34 | 1.9 |
> | SF10417_3 | glioma | 48.88 | 2.81 | 0.27 |
> | GBM196_3 | glioma | 50.5 | 0.4 | 2.25 |
> | BT088_1 | glioma | 65.83 | 4.3 | 12.17 |
> | BT088_2 | glioma | 66.96 | 4.13 | 10.33 |
> | TB096_1 | glioma | 71.38 | 5.55 | 0 |
> | TB096_3 | glioma | 74.87 | 4.55 | 0.03 |
> | TB096_2 | glioma | 80.34 | 4.37 | 0 |
> | BT088_3 | glioma | 93.29 | 4.1 | 12.14 |
> | GSC274_2 | glioma | 134.37 | 0.28 | 0.03 |
> | GSC274_1 | glioma | 135.93 | 0.38 | 0.04 |
> | GSC274_3 | glioma | 169.64 | 0.27 | 0.06 |
> | GSC711_1 | glioma | 192.15 | 1.95 | 155.15 |
> | GSC711_2 | glioma | 192.85 | 2.11 | 141.35 |
> | GSC711_3 | glioma | 198.1 | 2.1 | 154.15 |
> | XO1_1 | GSC | 0.22 | 0.35 | 661.86 |
> | XO6_2 | GSC | 0.23 | 0.06 | 539.81 |
> | XO1_3 | GSC | 0.31 | 0.32 | 709.18 |
> | XO9_3 | GSC | 0.34 | 0.17 | 999.27 |
> | XO6_1 | GSC | 0.37 | 0.09 | 523.3 |
> | XO1_2 | GSC | 0.41 | 0.03 | 683.86 |
> | XO9_2 | GSC | 0.48 | 0.15 | 992.87 |
> | XO6_3 | GSC | 0.52 | 0.15 | 531.36 |
> | XO9_1 | GSC | 0.67 | 0.32 | 919.95 |
> | XO10_1 | GSC | 5 | 0.08 | 409.65 |
> | XO10_3 | GSC | 5.49 | 0.11 | 335.44 |
> | XO10_2 | GSC | 6.06 | 0.03 | 369.5 |
> | L0_1 | GSC | 16.48 | 3.35 | 0.4 |
> | L1_2 | GSC | 17.38 | 3.36 | 0.93 |
> | L0_3 | GSC | 17.54 | 3.59 | 0.49 |
> | L0_2 | GSC | 19.1 | 4.11 | 0.6 |
> | L1_1 | GSC | 21.54 | 3.82 | 1 |
> | L1_3 | GSC | 22.71 | 3.57 | 0.9 |
> | GSC403_3 | GSC | 37.44 | 4.86 | 17.64 |
> | GSC403_2 | GSC | 38.07 | 5.59 | 18.46 |
> | GSC403_1 | GSC | 38.83 | 5.11 | 16.2 |
> | XO2_2 | GSC | 78.66 | 0.01 | 0.88 |
> | XO2_1 | GSC | 80.11 | 0.03 | 0.93 |
> | XO2_3 | GSC | 90.97 | 0 | 1.01 |
> | CA4_1_1 | GSC | 153.82 | 0.05 | 0 |
> | CA4_1_3 | GSC | 155.24 | 0.13 | 0 |
> | CA4_2_1 | GSC | 161 | 0 | 0.04 |
> | CA4_1_2 | GSC | 162.61 | 0.08 | 0 |
> | CA4_2_2 | GSC | 164.36 | 0.08 | 0 |
> | CA4_2_3 | GSC | 175.21 | 0.11 | 0 |
> | CA4_ONC201_2 | GSC | 196.03 | 0.21 | 0 |
> | CA4_ONC201_3 | GSC | 208.01 | 0.15 | 0 |
> | CA4_ONC201_1 | GSC | 217.87 | 0.03 | 0 |
> | CA1_3 | GSC | 240.43 | 0.09 | 0 |
> | CA1_1 | GSC | 253.36 | 0.18 | 0 |
> | CA4_2 | GSC | 260.43 | 0.05 | 0 |
> | CA4_ONC206_2 | GSC | 261.34 | 0.35 | 0.06 |
> | CA4_3 | GSC | 266.39 | 0.07 | 0.06 |
> | CA1_2 | GSC | 266.96 | 0.07 | 0.02 |
> | CA4_1 | GSC | 273.27 | 0.11 | 0.04 |
> | CA4_ONC206_1 | GSC | 279.86 | 0.36 | 0 |
> | CA4_ONC206_3 | GSC | 281.32 | 0.37 | 0 |
> | HW8_2 | HW | 15.39 | 7.56 | 23.16 |
> | HW7_2_2 | HW | 17.31 | 6.38 | 23.78 |
> | HW8_1 | HW | 18.19 | 7.38 | 20.54 |
> | HW8_3 | HW | 19.71 | 7.42 | 23.85 |
> | HW8_R132_1 | HW | 20.08 | 6.23 | 27 |
> | HW5_1 | HW | 22.64 | 7.42 | 41.08 |
> | HW7_1_2 | HW | 22.81 | 7.5 | 34.93 |
> | HW7_2_3 | HW | 22.87 | 7.72 | 22.19 |
> | HW7_1_1 | HW | 23.98 | 7.26 | 26.06 |
> | HW5_3 | HW | 24.64 | 7.06 | 36.65 |
> | HW8_R132_2 | HW | 24.77 | 6.09 | 25.01 |
> | HW5_2 | HW | 25.16 | 7.47 | 39.44 |
> | HW8_R132_3 | HW | 26.31 | 5.81 | 21.03 |
> | HW7_1_3 | HW | 27.04 | 9.31 | 32.27 |
> | HW7_2_1 | HW | 30.47 | 7.58 | 31.84 |
> | HW10_1 | HW | 35.38 | 9.74 | 32.4 |
> | HW10_3 | HW | 37.45 | 9.59 | 42.56 |
> | HW10_2 | HW | 39.95 | 9.58 | 37 |
> | HW10_R132H_2 | HW | 47.78 | 9.33 | 35.61 |
> | HW10_R132H_3 | HW | 55.78 | 10.55 | 30.24 |
> | HW10_R132H_1 | HW | 62.03 | 9.29 | 28.2 |
> | LN229_2 | MCL | 5.09 | 0.56 | 22.21 |
> | LN229_3 | MCL | 5.41 | 0.96 | 20.27 |
> | LN229_1 | MCL | 6.3 | 0.67 | 24.38 |
> | SW1088_2 | MCL | 11.59 | 0.14 | 0 |
> | SW1088_3 | MCL | 15.17 | 0.37 | 0 |
> | SW1088_1 | MCL | 18 | 0.11 | 0 |
> | U251_3 | MCL | 19.74 | 0.45 | 0 |
> | U251_1 | MCL | 21.4 | 0.31 | 0 |
> | U251_2 | MCL | 23.51 | 0.45 | 0 |
> | A172_2 | MCL | 41.43 | 0.72 | 0.03 |
> | BT142_2 | MCL | 45.43 | 2.39 | 9.77 |
> | BT142_1 | MCL | 45.95 | 2.02 | 8.23 |
> | BT142_3 | MCL | 48.88 | 1.71 | 10.31 |
> | A172_1 | MCL | 49.68 | 0.81 | 0.02 |
> | A172_3 | MCL | 49.98 | 0.59 | 0 |
> | NHA_R132H_1 | Normal astrocyte | 43.67 | 0.19 | 0 |
> | NHA_3 | Normal astrocyte | 58.47 | 0.04 | 0 |
> | NHA_R132H_2 | Normal astrocyte | 58.48 | 0.12 | 0 |
> | NHA_1 | Normal astrocyte | 58.58 | 0.13 | 0 |
> | NHA_2 | Normal astrocyte | 59.03 | 0.06 | 0 |
> | NHA_R132H_3 | Normal astrocyte | 63.43 | 0.15 | 0 |
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Mon Apr 20 03:23:43 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 19 Apr 2020 21:23:43 -0400
Subject: [R] how to create a sorted barplot and colored by groups
In-Reply-To: <1123828219.3209300.1587344157910@mail.yahoo.com>
References: <101378036.3109664.1587327603395.ref@mail.yahoo.com>
 <101378036.3109664.1587327603395@mail.yahoo.com>
 <CAKZQJMDsbrj+5pGGQtX2T=A8sKW-2jpf+jHbE6ghD+461+210g@mail.gmail.com>
 <1123828219.3209300.1587344157910@mail.yahoo.com>
Message-ID: <CAKZQJMD6m0sbP7eh=5ZOzSgaL4M-GBLbjMQko1r11W0NW_1GKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: dt.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200419/a8feab79/attachment.txt>

From drj|m|emon @end|ng |rom gm@||@com  Mon Apr 20 03:30:04 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 20 Apr 2020 11:30:04 +1000
Subject: [R] how to create a sorted barplot and colored by groups
In-Reply-To: <101378036.3109664.1587327603395@mail.yahoo.com>
References: <101378036.3109664.1587327603395.ref@mail.yahoo.com>
 <101378036.3109664.1587327603395@mail.yahoo.com>
Message-ID: <CA+8X3fVtajMAPzcybeW-cSpZXRj1OrKO-5JM2P29aa_Wx1Awzw@mail.gmail.com>

Hi aiguo,
I assume that the data in your request was a text file that you want
to read in. You can do it like this if you make a few changes as in
the attached "aiguo_example.txt". Here is some code that may be
helpful:

# let the pipes be read in as fields, then index them out
aiguo.df<-read.table("aiguo_example.txt",header=TRUE,
 stringsAsFactors=FALSE,fill=TRUE)[,c(2,4,6,8,10)]
table(aiguo.df$types)
# the last digit in the "gene" field seems to be what you want
# as there may be more than one underscore in the "gene" field
# write a wrapper for strsplit that returns the last element
get_last_digit<-function(x) {
 xsplit<-unlist(strsplit(x,"_"))
 return(xsplit[length(xsplit)])
}
# get a numeric gene number
aiguo.df$genenum<-as.numeric(unlist(lapply(aiguo.df$gene,get_last_digit)))
# create a new data frame ordered by gene number then MYC
aiguo.MYC<-aiguo.df[order(aiguo.df$genenum,aiguo.df$MYC),]
# make a plot
png("aiguoMYC,png")
barpos<-barplot(aiguo.MYC$MYC,col=unlist(aiguo.MYC$genenum)+1,
 main="Ordered by gene number and MYC",xlab="Gene",xaxt="n")
axis(1,at=barpos[c(33,99,165)],labels=1:3)
dev.off()
# same for MYCL
png("aiguoMYCL.png")
aiguo.MYCL<-aiguo.df[order(aiguo.df$genenum,aiguo.df$MYCL),]
barpos<-barplot(aiguo.MYCL$MYCL,col=unlist(aiguo.MYCL$genenum)+1,
 main="Ordered by gene number and MYCL",xlab="Gene",xaxt="n")
axis(1,at=barpos[c(33,99,165)],labels=1:3)
dev.off()
# and MYCN
png("aiguoMYCN.png")
aiguo.MYCN<-aiguo.df[order(aiguo.df$genenum,aiguo.df$MYCN),]
barpos<-barplot(aiguo.MYCN$MYCN,col=unlist(aiguo.MYCN$genenum)+1,
 main="Ordered by gene number and MYCN",xlab="Gene",xaxt="n")
axis(1,at=barpos[c(33,99,165)],labels=1:3)
dev.off()

Jim

On Mon, Apr 20, 2020 at 8:44 AM aiguo li via R-help
<r-help at r-project.org> wrote:
>
> Dear all,
> I need some help for creating a barplot as below.  I have three genes and a type column in the dataframe attached.  I would like to sort each gene from low to high within each type and create a barplot similar to the one below, but colored and grouped by type.
> Thanks in advance for your hep!
> Aiguo
>
>
> |  | types | MYC | MYCL | MYCN |
> | TS603_1 | AnaplasticOligo | 7.97 | 2.98 | 0.48 |
> | TS603_2 | AnaplasticOligo | 9.04 | 3.94 | 0.28 |
> | TS603_3 | AnaplasticOligo | 9.35 | 3.29 | 0.33 |
> | NCH612_1 | AnaplasticOligo | 13.86 | 0.88 | 33.5 |
> | NCH612_2 | AnaplasticOligo | 14.02 | 0.88 | 36.12 |
> | NCH612_3 | AnaplasticOligo | 15.99 | 0.95 | 35.67 |
> | DIPG_XIX_2 | DIPG | 1.12 | 6.18 | 24.37 |
> | DIPG_XIX_1 | DIPG | 1.27 | 6 | 25.63 |
> | DIPG_XIX_3 | DIPG | 1.63 | 7.19 | 26.06 |
> | DIPG_38_3 | DIPG | 3.18 | 14.08 | 8.52 |
> | DIPG_38_1 | DIPG | 3.4 | 14.48 | 10.2 |
> | DIPG_38_2 | DIPG | 5.62 | 12.27 | 12.37 |
> | DIPG_36_1 | DIPG | 6.65 | 0.45 | 4.86 |
> | DIPG_36_3 | DIPG | 7.04 | 0.28 | 4.55 |
> | DIPG_29_1 | DIPG | 7.2 | 2.29 | 9.38 |
> | DIPG_35_1 | DIPG | 7.87 | 1.34 | 8.87 |
> | DIPG_36_2 | DIPG | 8.18 | 0.41 | 3 |
> | DIPG_29_2 | DIPG | 8.85 | 1.53 | 10.97 |
> | DIPG_35_2 | DIPG | 8.99 | 0.74 | 11.52 |
> | DIPG_29_3 | DIPG | 9.66 | 1.03 | 9.46 |
> | DIPG_35_3 | DIPG | 9.73 | 1.35 | 11.92 |
> | DIPG_IV_3 | DIPG | 11.68 | 0.08 | 0 |
> | DIPG_IV_1 | DIPG | 13.63 | 0.29 | 0 |
> | DIPG_IV_2 | DIPG | 15.2 | 0.17 | 0 |
> | DIPG_43_2 | DIPG | 17.77 | 3.72 | 10.33 |
> | DIPG_43_3 | DIPG | 22.04 | 3.02 | 9.52 |
> | DIPG_43_1 | DIPG | 22.87 | 3.42 | 9.24 |
> | DIPG_13_3 | DIPG | 26.36 | 1.3 | 13.89 |
> | DIPG_13_2 | DIPG | 26.44 | 1.4 | 13.88 |
> | DIPG_50_3 | DIPG | 31.92 | 0.62 | 9.55 |
> | DIPG_13_1 | DIPG | 32.57 | 1.41 | 14.78 |
> | DIPG_50_2 | DIPG | 34.13 | 0.98 | 7.74 |
> | DIPG_24_3 | DIPG | 34.22 | 0.75 | 11.73 |
> | DIPG_24_1 | DIPG | 35.75 | 0.46 | 14.92 |
> | DIPG_50_1 | DIPG | 35.78 | 1.03 | 10.75 |
> | DIPG_24_2 | DIPG | 38.48 | 0.78 | 13.08 |
> | DIPG_45_3 | DIPG | 59.56 | 2.34 | 9.1 |
> | DIPG_45_2 | DIPG | 60.23 | 2.79 | 9.32 |
> | DIPG_45_1 | DIPG | 63.19 | 2.59 | 9.7 |
> | DIPG_SCG-1_1 | DIPG | 96.95 | 3.1 | 481.64 |
> | DIPG_SCG-1_3 | DIPG | 106.77 | 3.79 | 481.03 |
> | DIPG_SCG-1_2 | DIPG | 109.77 | 2.88 | 523.27 |
> | DIPG_27_1 | DIPG | 195.07 | 2.23 | 5.92 |
> | DIPG_27_3 | DIPG | 195.45 | 3.09 | 6.71 |
> | DIPG_27_2 | DIPG | 205.33 | 3.28 | 6.26 |
> | DIPGXVII_ONC206_2 | DIPG | 327.55 | 2.07 | 2.21 |
> | DIPGXVII_ONC206_3 | DIPG | 358.3 | 1.8 | 2.55 |
> | DIPGXVII_ONC206_1 | DIPG | 368.93 | 1.97 | 2.28 |
> | DIPG_17_2 | DIPG | 424.17 | 7.35 | 5.18 |
> | DIPG_25_1 | DIPG | 447.28 | 4.47 | 5.84 |
> | DIPG_25_3 | DIPG | 458.31 | 4.98 | 6.18 |
> | DIPG_17_1 | DIPG | 480.19 | 8.66 | 5.95 |
> | DIPG_17_3 | DIPG | 488.79 | 9.64 | 5.16 |
> | DIPG_25_2 | DIPG | 490.16 | 5.23 | 7.56 |
> | DIPGXVII_1_3 | DIPG | 509.04 | 2.33 | 2.97 |
> | DIPGXVII_ONC201_1 | DIPG | 509.05 | 2.51 | 2.58 |
> | DIPGXVII_1_1 | DIPG | 541.42 | 2.79 | 2.91 |
> | DIPGXVII_ONC201_3 | DIPG | 555.35 | 1.96 | 3.19 |
> | DIPGXVII_1_2 | DIPG | 577.68 | 2.19 | 3.01 |
> | DIPGXVII_ONC201_2 | DIPG | 580.61 | 2.38 | 2.8 |
> | DIPGXVII_2_2 | DIPG | 585.22 | 2.34 | 3.36 |
> | DIPGXVII_2_1 | DIPG | 591.72 | 2.62 | 3.01 |
> | DIPGXVII_2_3 | DIPG | 619.18 | 3.04 | 2.35 |
> | GSC627_1 | glioma | 0 | 0.79 | 597.07 |
> | GSC627_2 | glioma | 0 | 1.25 | 615.02 |
> | GSC627_3 | glioma | 0.07 | 1.01 | 632.08 |
> | MGG152_2 | glioma | 0.13 | 13.37 | 916.02 |
> | MGG152_1 | glioma | 0.18 | 12.92 | 895.3 |
> | MGG152_3 | glioma | 0.22 | 14.47 | 935.56 |
> | GBM1_3 | glioma | 4.58 | 6.73 | 291.75 |
> | GBM1_1 | glioma | 4.96 | 6.36 | 276.04 |
> | GBM1_2 | glioma | 5.35 | 7.21 | 280.6 |
> | GSC17_3 | glioma | 7.54 | 3.89 | 59.22 |
> | GSC17_2 | glioma | 8.38 | 3.89 | 60.65 |
> | GSC17_1 | glioma | 9.8 | 4.77 | 57.33 |
> | GBM164_3 | glioma | 11.14 | 1.42 | 7.04 |
> | GBM164_1 | glioma | 11.89 | 1.53 | 6.04 |
> | GBM164_2 | glioma | 12.69 | 1.85 | 6.8 |
> | GSC923_3 | glioma | 14.93 | 6.59 | 216.57 |
> | GSC923_2 | glioma | 15.63 | 5.75 | 226.94 |
> | GSC923_1 | glioma | 16.93 | 5.75 | 207.18 |
> | GSC268_3 | glioma | 16.94 | 0.14 | 7.14 |
> | GSC268_1 | glioma | 17.8 | 0.01 | 8.25 |
> | GSC268_2 | glioma | 19.97 | 0.11 | 6.24 |
> | SF10602_3 | glioma | 23.81 | 2.39 | 0.47 |
> | SF10602_1 | glioma | 25.38 | 2.72 | 0.43 |
> | MGG119_1 | glioma | 25.49 | 6.84 | 9.8 |
> | SF10602_2 | glioma | 25.61 | 2.5 | 0.55 |
> | GSC827_2 | glioma | 27.67 | 2.32 | 128.56 |
> | GSC827_3 | glioma | 28.2 | 3.22 | 128.85 |
> | GSC827_1 | glioma | 30.6 | 3.15 | 126.77 |
> | MGG119_2 | glioma | 31.43 | 5.86 | 9.02 |
> | BT054_3 | glioma | 35.26 | 0.46 | 2.89 |
> | MGG119_3 | glioma | 35.57 | 6.52 | 9.42 |
> | BT054_2 | glioma | 39.74 | 0.53 | 3.29 |
> | BT054_1 | glioma | 42.22 | 0.28 | 3.54 |
> | SF10417_1 | glioma | 43.93 | 2.93 | 0.21 |
> | SF10417_2 | glioma | 44.77 | 2.43 | 0.32 |
> | GBM196_1 | glioma | 47.28 | 0.33 | 1.75 |
> | GBM196_2 | glioma | 48.85 | 0.34 | 1.9 |
> | SF10417_3 | glioma | 48.88 | 2.81 | 0.27 |
> | GBM196_3 | glioma | 50.5 | 0.4 | 2.25 |
> | BT088_1 | glioma | 65.83 | 4.3 | 12.17 |
> | BT088_2 | glioma | 66.96 | 4.13 | 10.33 |
> | TB096_1 | glioma | 71.38 | 5.55 | 0 |
> | TB096_3 | glioma | 74.87 | 4.55 | 0.03 |
> | TB096_2 | glioma | 80.34 | 4.37 | 0 |
> | BT088_3 | glioma | 93.29 | 4.1 | 12.14 |
> | GSC274_2 | glioma | 134.37 | 0.28 | 0.03 |
> | GSC274_1 | glioma | 135.93 | 0.38 | 0.04 |
> | GSC274_3 | glioma | 169.64 | 0.27 | 0.06 |
> | GSC711_1 | glioma | 192.15 | 1.95 | 155.15 |
> | GSC711_2 | glioma | 192.85 | 2.11 | 141.35 |
> | GSC711_3 | glioma | 198.1 | 2.1 | 154.15 |
> | XO1_1 | GSC | 0.22 | 0.35 | 661.86 |
> | XO6_2 | GSC | 0.23 | 0.06 | 539.81 |
> | XO1_3 | GSC | 0.31 | 0.32 | 709.18 |
> | XO9_3 | GSC | 0.34 | 0.17 | 999.27 |
> | XO6_1 | GSC | 0.37 | 0.09 | 523.3 |
> | XO1_2 | GSC | 0.41 | 0.03 | 683.86 |
> | XO9_2 | GSC | 0.48 | 0.15 | 992.87 |
> | XO6_3 | GSC | 0.52 | 0.15 | 531.36 |
> | XO9_1 | GSC | 0.67 | 0.32 | 919.95 |
> | XO10_1 | GSC | 5 | 0.08 | 409.65 |
> | XO10_3 | GSC | 5.49 | 0.11 | 335.44 |
> | XO10_2 | GSC | 6.06 | 0.03 | 369.5 |
> | L0_1 | GSC | 16.48 | 3.35 | 0.4 |
> | L1_2 | GSC | 17.38 | 3.36 | 0.93 |
> | L0_3 | GSC | 17.54 | 3.59 | 0.49 |
> | L0_2 | GSC | 19.1 | 4.11 | 0.6 |
> | L1_1 | GSC | 21.54 | 3.82 | 1 |
> | L1_3 | GSC | 22.71 | 3.57 | 0.9 |
> | GSC403_3 | GSC | 37.44 | 4.86 | 17.64 |
> | GSC403_2 | GSC | 38.07 | 5.59 | 18.46 |
> | GSC403_1 | GSC | 38.83 | 5.11 | 16.2 |
> | XO2_2 | GSC | 78.66 | 0.01 | 0.88 |
> | XO2_1 | GSC | 80.11 | 0.03 | 0.93 |
> | XO2_3 | GSC | 90.97 | 0 | 1.01 |
> | CA4_1_1 | GSC | 153.82 | 0.05 | 0 |
> | CA4_1_3 | GSC | 155.24 | 0.13 | 0 |
> | CA4_2_1 | GSC | 161 | 0 | 0.04 |
> | CA4_1_2 | GSC | 162.61 | 0.08 | 0 |
> | CA4_2_2 | GSC | 164.36 | 0.08 | 0 |
> | CA4_2_3 | GSC | 175.21 | 0.11 | 0 |
> | CA4_ONC201_2 | GSC | 196.03 | 0.21 | 0 |
> | CA4_ONC201_3 | GSC | 208.01 | 0.15 | 0 |
> | CA4_ONC201_1 | GSC | 217.87 | 0.03 | 0 |
> | CA1_3 | GSC | 240.43 | 0.09 | 0 |
> | CA1_1 | GSC | 253.36 | 0.18 | 0 |
> | CA4_2 | GSC | 260.43 | 0.05 | 0 |
> | CA4_ONC206_2 | GSC | 261.34 | 0.35 | 0.06 |
> | CA4_3 | GSC | 266.39 | 0.07 | 0.06 |
> | CA1_2 | GSC | 266.96 | 0.07 | 0.02 |
> | CA4_1 | GSC | 273.27 | 0.11 | 0.04 |
> | CA4_ONC206_1 | GSC | 279.86 | 0.36 | 0 |
> | CA4_ONC206_3 | GSC | 281.32 | 0.37 | 0 |
> | HW8_2 | HW | 15.39 | 7.56 | 23.16 |
> | HW7_2_2 | HW | 17.31 | 6.38 | 23.78 |
> | HW8_1 | HW | 18.19 | 7.38 | 20.54 |
> | HW8_3 | HW | 19.71 | 7.42 | 23.85 |
> | HW8_R132_1 | HW | 20.08 | 6.23 | 27 |
> | HW5_1 | HW | 22.64 | 7.42 | 41.08 |
> | HW7_1_2 | HW | 22.81 | 7.5 | 34.93 |
> | HW7_2_3 | HW | 22.87 | 7.72 | 22.19 |
> | HW7_1_1 | HW | 23.98 | 7.26 | 26.06 |
> | HW5_3 | HW | 24.64 | 7.06 | 36.65 |
> | HW8_R132_2 | HW | 24.77 | 6.09 | 25.01 |
> | HW5_2 | HW | 25.16 | 7.47 | 39.44 |
> | HW8_R132_3 | HW | 26.31 | 5.81 | 21.03 |
> | HW7_1_3 | HW | 27.04 | 9.31 | 32.27 |
> | HW7_2_1 | HW | 30.47 | 7.58 | 31.84 |
> | HW10_1 | HW | 35.38 | 9.74 | 32.4 |
> | HW10_3 | HW | 37.45 | 9.59 | 42.56 |
> | HW10_2 | HW | 39.95 | 9.58 | 37 |
> | HW10_R132H_2 | HW | 47.78 | 9.33 | 35.61 |
> | HW10_R132H_3 | HW | 55.78 | 10.55 | 30.24 |
> | HW10_R132H_1 | HW | 62.03 | 9.29 | 28.2 |
> | LN229_2 | MCL | 5.09 | 0.56 | 22.21 |
> | LN229_3 | MCL | 5.41 | 0.96 | 20.27 |
> | LN229_1 | MCL | 6.3 | 0.67 | 24.38 |
> | SW1088_2 | MCL | 11.59 | 0.14 | 0 |
> | SW1088_3 | MCL | 15.17 | 0.37 | 0 |
> | SW1088_1 | MCL | 18 | 0.11 | 0 |
> | U251_3 | MCL | 19.74 | 0.45 | 0 |
> | U251_1 | MCL | 21.4 | 0.31 | 0 |
> | U251_2 | MCL | 23.51 | 0.45 | 0 |
> | A172_2 | MCL | 41.43 | 0.72 | 0.03 |
> | BT142_2 | MCL | 45.43 | 2.39 | 9.77 |
> | BT142_1 | MCL | 45.95 | 2.02 | 8.23 |
> | BT142_3 | MCL | 48.88 | 1.71 | 10.31 |
> | A172_1 | MCL | 49.68 | 0.81 | 0.02 |
> | A172_3 | MCL | 49.98 | 0.59 | 0 |
> | NHA_R132H_1 | Normal astrocyte | 43.67 | 0.19 | 0 |
> | NHA_3 | Normal astrocyte | 58.47 | 0.04 | 0 |
> | NHA_R132H_2 | Normal astrocyte | 58.48 | 0.12 | 0 |
> | NHA_1 | Normal astrocyte | 58.58 | 0.13 | 0 |
> | NHA_2 | Normal astrocyte | 59.03 | 0.06 | 0 |
> | NHA_R132H_3 | Normal astrocyte | 63.43 | 0.15 | 0 |
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: aiguo_example.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200420/9538c3f3/attachment.txt>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: aiguoMYCL.png
Type: image/png
Size: 10976 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200420/9538c3f3/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: aiguoMYCN.png
Type: image/png
Size: 9182 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200420/9538c3f3/attachment-0001.png>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Apr 20 08:05:37 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Apr 2020 07:05:37 +0100
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>

Hello,

Instead of

d[d == 0] <- NA

try

d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})


Also, in the first for loop

paste(i, sep = "")

does nothing, it's the same as i.
And the same for

(d2$V4 == 1) == TRUE

Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for

(.) == TRUE


Hope this helps,

Rui Barradas



?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> Dear R experts,
> 
> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single dataset (outside the loop). I've tried:
> 
> all.files <- list.files(".")
> txt.files <- grep("threat.txt",all.files,value=T)
> 
> for(i in txt.files){
>    d <- read.table(paste(i,sep=""),header=F)
>    d[d==0] <- NA #replace zeros with NA
>    write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>    d<-d[ ,-c(10,11)]
>    d2<-d[complete.cases(d), ]
>    d2$V4<-as.numeric(d2$V4)
>    congruent <- (d2$V4 == 1) == TRUE
>    x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>    write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> 
> I've also tried:
> 
> for(i in txt.files){
>    d <- read.table(paste(i,sep=""),header=F)
>    if (0 %in% d)
>    {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>    d<-d[ ,-c(10,11)]
>    d2<-d[complete.cases(d), ]
>    d2$V4<-as.numeric(d2$V4)
>    congruent <- (d2$V4 == 1) == TRUE
>    x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>    write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
> 
> Thank you for your help.
> Sincerely
> Helen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From he|en@@w@y@ @end|ng |rom hotm@||@com  Mon Apr 20 18:25:08 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Mon, 20 Apr 2020 16:25:08 +0000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>,
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
Message-ID: <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>

Thank you for your reply.

I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
?but I am still getting zeros instead of NAs in my output..

I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
________________________________
From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Monday, April 20, 2020 9:05 AM
To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
Subject: Re: [R] NA command in a 'for' loop

Hello,

Instead of

d[d == 0] <- NA

try

d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})


Also, in the first for loop

paste(i, sep = "")

does nothing, it's the same as i.
And the same for

(d2$V4 == 1) == TRUE

Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for

(.) == TRUE


Hope this helps,

Rui Barradas



?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> Dear R experts,
>
> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single dataset (outside the loop). I've tried:
>
> all.files <- list.files(".")
> txt.files <- grep("threat.txt",all.files,value=T)
>
> for(i in txt.files){
>    d <- read.table(paste(i,sep=""),header=F)
>    d[d==0] <- NA #replace zeros with NA
>    write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>    d<-d[ ,-c(10,11)]
>    d2<-d[complete.cases(d), ]
>    d2$V4<-as.numeric(d2$V4)
>    congruent <- (d2$V4 == 1) == TRUE
>    x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>    write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>
> I've also tried:
>
> for(i in txt.files){
>    d <- read.table(paste(i,sep=""),header=F)
>    if (0 %in% d)
>    {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>    d<-d[ ,-c(10,11)]
>    d2<-d[complete.cases(d), ]
>    d2$V4<-as.numeric(d2$V4)
>    congruent <- (d2$V4 == 1) == TRUE
>    x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>    write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>
> Thank you for your help.
> Sincerely
> Helen
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Apr 20 18:35:59 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 20 Apr 2020 17:35:59 +0100
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>

Just a thought Helen but is x being treated as a real and what you think 
are zero and are printed as zero are in fact some very small number? If 
so you need to alter your test appropriately.

Michael

On 20/04/2020 17:25, Helen Sawaya wrote:
> Thank you for your reply.
> 
> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> ?but I am still getting zeros instead of NAs in my output..
> 
> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
> ________________________________
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Monday, April 20, 2020 9:05 AM
> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
> Subject: Re: [R] NA command in a 'for' loop
> 
> Hello,
> 
> Instead of
> 
> d[d == 0] <- NA
> 
> try
> 
> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> 
> 
> Also, in the first for loop
> 
> paste(i, sep = "")
> 
> does nothing, it's the same as i.
> And the same for
> 
> (d2$V4 == 1) == TRUE
> 
> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> 
> (.) == TRUE
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>> Dear R experts,
>>
>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single dataset (outside the loop). I've tried:
>>
>> all.files <- list.files(".")
>> txt.files <- grep("threat.txt",all.files,value=T)
>>
>> for(i in txt.files){
>>     d <- read.table(paste(i,sep=""),header=F)
>>     d[d==0] <- NA #replace zeros with NA
>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>     d<-d[ ,-c(10,11)]
>>     d2<-d[complete.cases(d), ]
>>     d2$V4<-as.numeric(d2$V4)
>>     congruent <- (d2$V4 == 1) == TRUE
>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>
>> I've also tried:
>>
>> for(i in txt.files){
>>     d <- read.table(paste(i,sep=""),header=F)
>>     if (0 %in% d)
>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>     d<-d[ ,-c(10,11)]
>>     d2<-d[complete.cases(d), ]
>>     d2$V4<-as.numeric(d2$V4)
>>     congruent <- (d2$V4 == 1) == TRUE
>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>
>> Thank you for your help.
>> Sincerely
>> Helen
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From he|en@@w@y@ @end|ng |rom hotm@||@com  Mon Apr 20 18:48:29 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Mon, 20 Apr 2020 16:48:29 +0000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>,
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
Message-ID: <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>

I have one column that represents correct response versus error (correct is coded as 1 and error is coded as 0). Nowhere else in the dataset are there values of 0. The vector is treated as an integer.
________________________________
From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Monday, April 20, 2020 7:35 PM
To: Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
Subject: Re: [R] NA command in a 'for' loop

Just a thought Helen but is x being treated as a real and what you think
are zero and are printed as zero are in fact some very small number? If
so you need to alter your test appropriately.

Michael

On 20/04/2020 17:25, Helen Sawaya wrote:
> Thank you for your reply.
>
> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> ?but I am still getting zeros instead of NAs in my output..
>
> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
> ________________________________
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Monday, April 20, 2020 9:05 AM
> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
> Subject: Re: [R] NA command in a 'for' loop
>
> Hello,
>
> Instead of
>
> d[d == 0] <- NA
>
> try
>
> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>
>
> Also, in the first for loop
>
> paste(i, sep = "")
>
> does nothing, it's the same as i.
> And the same for
>
> (d2$V4 == 1) == TRUE
>
> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
>
> (.) == TRUE
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>> Dear R experts,
>>
>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single dataset (outside the loop). I've tried:
>>
>> all.files <- list.files(".")
>> txt.files <- grep("threat.txt",all.files,value=T)
>>
>> for(i in txt.files){
>>     d <- read.table(paste(i,sep=""),header=F)
>>     d[d==0] <- NA #replace zeros with NA
>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>     d<-d[ ,-c(10,11)]
>>     d2<-d[complete.cases(d), ]
>>     d2$V4<-as.numeric(d2$V4)
>>     congruent <- (d2$V4 == 1) == TRUE
>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>
>> I've also tried:
>>
>> for(i in txt.files){
>>     d <- read.table(paste(i,sep=""),header=F)
>>     if (0 %in% d)
>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>     d<-d[ ,-c(10,11)]
>>     d2<-d[complete.cases(d), ]
>>     d2$V4<-as.numeric(d2$V4)
>>     congruent <- (d2$V4 == 1) == TRUE
>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>
>> Thank you for your help.
>> Sincerely
>> Helen
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Apr 20 23:56:38 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 20 Apr 2020 22:56:38 +0100
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>

Hello,

I believe the only way we have to see what is happening is for you to 
post the output of


dput(head(d, 20))  # or 30


or, with d2 a subset of d that includes zeros,


dput(head(d2, 20))


Hope this helps,

Rui Barradas

?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> I have one column that represents correct response versus error (correct 
> is coded as 1 and error is coded as 0). Nowhere else in the dataset are 
> there values of 0. The vector is treated as an integer.
> ------------------------------------------------------------------------
> *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> *Sent:* Monday, April 20, 2020 7:35 PM
> *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas 
> <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> *Subject:* Re: [R] NA command in a 'for' loop
> Just a thought Helen but is x being treated as a real and what you think
> are zero and are printed as zero are in fact some very small number? If
> so you need to alter your test appropriately.
> 
> Michael
> 
> On 20/04/2020 17:25, Helen Sawaya wrote:
>> Thank you for your reply.
>> 
>> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>> ?but I am still getting zeros instead of NAs in my output..
>> 
>> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
>> ________________________________
>> From: Rui Barradas <ruipbarradas at sapo.pt>
>> Sent: Monday, April 20, 2020 9:05 AM
>> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
>> Subject: Re: [R] NA command in a 'for' loop
>> 
>> Hello,
>> 
>> Instead of
>> 
>> d[d == 0] <- NA
>> 
>> try
>> 
>> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>> 
>> 
>> Also, in the first for loop
>> 
>> paste(i, sep = "")
>> 
>> does nothing, it's the same as i.
>> And the same for
>> 
>> (d2$V4 == 1) == TRUE
>> 
>> Since (d2$V4 == 1)? already is FALSE/TRUE there is no need for
>> 
>> (.) == TRUE
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> 
>> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>>> Dear R experts,
>>>
>>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present.  Surprisingly, the functions work fine when I apply them to a single 
> dataset (outside the loop). I've tried:
>>>
>>> all.files <- list.files(".")
>>> txt.files <- grep("threat.txt",all.files,value=T)
>>>
>>> for(i in txt.files){
>>>???? d <- read.table(paste(i,sep=""),header=F)
>>>???? d[d==0] <- NA #replace zeros with NA
>>>???? write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>???? d<-d[ ,-c(10,11)]
>>>???? d2<-d[complete.cases(d), ]
>>>???? d2$V4<-as.numeric(d2$V4)
>>>???? congruent <- (d2$V4 == 1) == TRUE
>>>???? x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>???? write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>
>>> I've also tried:
>>>
>>> for(i in txt.files){
>>>???? d <- read.table(paste(i,sep=""),header=F)
>>>???? if (0 %in% d)
>>>???? {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>>???? d<-d[ ,-c(10,11)]
>>>???? d2<-d[complete.cases(d), ]
>>>???? d2$V4<-as.numeric(d2$V4)
>>>???? congruent <- (d2$V4 == 1) == TRUE
>>>???? x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>???? write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>>
>>> Thank you for your help.
>>> Sincerely
>>> Helen
>>>
>>>???????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> 
>>??????? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From r@oknz @end|ng |rom gm@||@com  Tue Apr 21 01:35:45 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 21 Apr 2020 11:35:45 +1200
Subject: [R] Multi response GAM
In-Reply-To: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR0101MB134869D0F8483166E80901E5BBD90@YQBPR0101MB1348.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CABcYAdJ7P1a10MmaPS=btHxE0J04Ce_ngL6n2+UYJJetGzLHvg@mail.gmail.com>

You might want to start by re-expressing the "amounts"
variables to
  total amount * (relative fish 1, relative fish 2, invertebrates)
and then using the Isometric Log-ratio transformation to
convert the compositional part to orthonormal coordinates.
https://stats.stackexchange.com/questions/259208/how-to-perform-isometric-log-ratio-transformation
may help.

I can't help wondering whether viewing the diet in terms of
the nutrients offered by the different components might yield
more insight.

On Sat, 18 Apr 2020 at 11:00, Tristan Kosciuch
<tristan.kosciuch at mail.mcgill.ca> wrote:
>
> Hello,
>
> I am modelling the diet of Nile perch through time. I have 3 diet classes as
> my response variables; fish 1, fish 2, and invertebrates.
>
> The response variables are correlated, declines in invert consumption ~
> increase in fish consumption. Any advice on how to handle this would be
> appreciated. I would like to use GAMs as my time series shows fluctuations
> that could only be fit by high order polynomials if I were to use a linear
> model, but open to suggestions.
>
> Thank you for your time.
>
> P.s. I will be comparing the fit of the time series GAM with a model based
> on other predictors, with a training and validation split for my data.
>
>
>
> ---
>
> Tristan Kosciuch
>
> Stewart Biology Building, McGill University
>
> 1205 Dr Penfield Ave, Montreal QC H3A 1B1
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr 21 01:52:08 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 21 Apr 2020 09:52:08 +1000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
Message-ID: <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>

Hi Helen,
Your problem may lie in using row.names=TRUE. I was puzzled when an
extra column kept popping up in the output files. For reading in and
replacing zeros with NAs, this seems to work:

for(mockdata in 1:3) {
 mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
 write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
  row.names=FALSE,col.names=FALSE)
}
txt.files<-list.files(".",pattern="threat[1-3]")
for(tf in txt.files) {
 d<-read.table(tf)
 d[,3][d[,3]==0]<-NA
 write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
}

Jim

On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I believe the only way we have to see what is happening is for you to
> post the output of
>
>
> dput(head(d, 20))  # or 30
>
>
> or, with d2 a subset of d that includes zeros,
>
>
> dput(head(d2, 20))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> > I have one column that represents correct response versus error (correct
> > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
> > there values of 0. The vector is treated as an integer.
> > ------------------------------------------------------------------------
> > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> > *Sent:* Monday, April 20, 2020 7:35 PM
> > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> > *Subject:* Re: [R] NA command in a 'for' loop
> > Just a thought Helen but is x being treated as a real and what you think
> > are zero and are printed as zero are in fact some very small number? If
> > so you need to alter your test appropriately.
> >
> > Michael
> >
> > On 20/04/2020 17:25, Helen Sawaya wrote:
> >> Thank you for your reply.
> >>
> >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >> but I am still getting zeros instead of NAs in my output..
> >>
> >> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
> >> ________________________________
> >> From: Rui Barradas <ruipbarradas at sapo.pt>
> >> Sent: Monday, April 20, 2020 9:05 AM
> >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
> >> Subject: Re: [R] NA command in a 'for' loop
> >>
> >> Hello,
> >>
> >> Instead of
> >>
> >> d[d == 0] <- NA
> >>
> >> try
> >>
> >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >>
> >>
> >> Also, in the first for loop
> >>
> >> paste(i, sep = "")
> >>
> >> does nothing, it's the same as i.
> >> And the same for
> >>
> >> (d2$V4 == 1) == TRUE
> >>
> >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> >>
> >> (.) == TRUE
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >>
> >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> >>> Dear R experts,
> >>>
> >>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present.  Surprisingly, the functions work fine when I apply them to a single
> > dataset (outside the loop). I've tried:
> >>>
> >>> all.files <- list.files(".")
> >>> txt.files <- grep("threat.txt",all.files,value=T)
> >>>
> >>> for(i in txt.files){
> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>>     d[d==0] <- NA #replace zeros with NA
> >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> >>>     d<-d[ ,-c(10,11)]
> >>>     d2<-d[complete.cases(d), ]
> >>>     d2$V4<-as.numeric(d2$V4)
> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> >>>
> >>> I've also tried:
> >>>
> >>> for(i in txt.files){
> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>>     if (0 %in% d)
> >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
> >>>     d<-d[ ,-c(10,11)]
> >>>     d2<-d[complete.cases(d), ]
> >>>     d2$V4<-as.numeric(d2$V4)
> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
> >>>
> >>> Thank you for your help.
> >>> Sincerely
> >>> Helen
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From he|en@@w@y@ @end|ng |rom hotm@||@com  Tue Apr 21 05:52:59 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Tue, 21 Apr 2020 03:52:59 +0000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>,
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
Message-ID: <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>

Thank you all for your input.

This is an example of one data file (I have 74 data files):

2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,           NA,           NA,  205,    0,  394
2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,           NA,           NA,  205,    0,  502
2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,           NA,           NA,  205,    1,  468
2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,           NA,           NA,  203,    1,  345
2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,           NA,           NA,  205,    1,  373
2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,           NA,           NA,  205,    1,  343
2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,           NA,           NA,  203,    1,  437
2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,           NA,           NA,  203,    1,  343
2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,           NA,           NA,  203,    1,  441
2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,           NA,           NA,  205,    1,  475

?Column 13 has values of 0s and 1s which my cognitive task outputted. Column 14 is the reaction time (ms) data. I want to get rid of the rows that contain zeros so I thought I'd first replace zeros with NAs then use complete.cases function to get rid of the NAs. I also wanted to apply other functions so I included them all in a loop. All work fine except for the one where I try to turn the zeros to NAs.

Jim when I tried your mockdata example, it worked fine. But when I translated it to my data, I still get zeros in the output. Can you identify any mistranslations I'm doing?

txt.files<-list.files(".",pattern="dotprobe") #all my data files are text files in one folder
for(tf in txt.files) {
  d<-read.table(tf)
  d[,13][d[,13]==0]<-NA #column 13 contains zeros
  d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
  write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
}

That's an example of one of the output I get:

V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343

Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
After all the data cleaning, the functions I'm interested in including in the loop are: get_tlbs and summarize_bias (and these also work fine in my loop).

Thanks again ?
Sincerely
Helen
________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Tuesday, April 21, 2020 2:52 AM
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
Subject: Re: [R] NA command in a 'for' loop

Hi Helen,
Your problem may lie in using row.names=TRUE. I was puzzled when an
extra column kept popping up in the output files. For reading in and
replacing zeros with NAs, this seems to work:

for(mockdata in 1:3) {
 mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
 write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
  row.names=FALSE,col.names=FALSE)
}
txt.files<-list.files(".",pattern="threat[1-3]")
for(tf in txt.files) {
 d<-read.table(tf)
 d[,3][d[,3]==0]<-NA
 write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
}

Jim

On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I believe the only way we have to see what is happening is for you to
> post the output of
>
>
> dput(head(d, 20))  # or 30
>
>
> or, with d2 a subset of d that includes zeros,
>
>
> dput(head(d2, 20))
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> > I have one column that represents correct response versus error (correct
> > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
> > there values of 0. The vector is treated as an integer.
> > ------------------------------------------------------------------------
> > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> > *Sent:* Monday, April 20, 2020 7:35 PM
> > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> > *Subject:* Re: [R] NA command in a 'for' loop
> > Just a thought Helen but is x being treated as a real and what you think
> > are zero and are printed as zero are in fact some very small number? If
> > so you need to alter your test appropriately.
> >
> > Michael
> >
> > On 20/04/2020 17:25, Helen Sawaya wrote:
> >> Thank you for your reply.
> >>
> >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >> but I am still getting zeros instead of NAs in my output..
> >>
> >> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
> >> ________________________________
> >> From: Rui Barradas <ruipbarradas at sapo.pt>
> >> Sent: Monday, April 20, 2020 9:05 AM
> >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
> >> Subject: Re: [R] NA command in a 'for' loop
> >>
> >> Hello,
> >>
> >> Instead of
> >>
> >> d[d == 0] <- NA
> >>
> >> try
> >>
> >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >>
> >>
> >> Also, in the first for loop
> >>
> >> paste(i, sep = "")
> >>
> >> does nothing, it's the same as i.
> >> And the same for
> >>
> >> (d2$V4 == 1) == TRUE
> >>
> >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> >>
> >> (.) == TRUE
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >>
> >>
> >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> >>> Dear R experts,
> >>>
> >>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present.  Surprisingly, the functions work fine when I apply them to a single
> > dataset (outside the loop). I've tried:
> >>>
> >>> all.files <- list.files(".")
> >>> txt.files <- grep("threat.txt",all.files,value=T)
> >>>
> >>> for(i in txt.files){
> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>>     d[d==0] <- NA #replace zeros with NA
> >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> >>>     d<-d[ ,-c(10,11)]
> >>>     d2<-d[complete.cases(d), ]
> >>>     d2$V4<-as.numeric(d2$V4)
> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> >>>
> >>> I've also tried:
> >>>
> >>> for(i in txt.files){
> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>>     if (0 %in% d)
> >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
> >>>     d<-d[ ,-c(10,11)]
> >>>     d2<-d[complete.cases(d), ]
> >>>     d2$V4<-as.numeric(d2$V4)
> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
> >>>
> >>> Thank you for your help.
> >>> Sincerely
> >>> Helen
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr 21 06:24:59 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 21 Apr 2020 14:24:59 +1000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fVmUM8h3yTG0FekxYudjs_tZ=UGc3GsBG_8xFiCKafNuQ@mail.gmail.com>

Hi Helen,
I can follow you this far:

# just read in the data from your example
d<-read.csv(text="2.90546E+11,threat,1,2,1,2,1,death,stove,NA,NA,205,0,394
2.90546E+11,threat,2,2,2,1,1,emaciated,shortened,NA,NA,205,0,502
2.90546E+11,threat,3,1,1,1,2,mutilate,consider,NA,NA,205,1,468
2.90546E+11,threat,6,1,2,2,1,weep,shop,NA,NA,203,1,345
2.90546E+11,threat,9,2,1,2,2,tormented,easygoing,NA,NA,205,1,373
2.90546E+11,threat,10,1,2,2,2,snake,table,NA,NA,205,1,343
2.90546E+11,threat,11,2,2,1,1,crisis,faucet,NA,NA,203,1,437
2.90546E+11,threat,12,1,1,1,1,victim,utensil,NA,NA,203,1,343
2.90546E+11,threat,14,1,2,2,1,depressed,repentant,NA,NA,203,1,441
2.90546E+11,threat,15,2,2,1,2,scum,shoe,NA,NA,205,1,475",
header=FALSE,stringsAsFactors=FALSE)
# get rows of d you want
d2<-d[d$V13==1,]
d2
congruent<-(d2$V4 == 1)
congruent

and things are as I expect even though I have shortened the code somewhat.
I'm not familiar with the "get_tlbs" function which I can find on GitHub
but not on CRAN, so if this:

x<-get_tlbs(d2$V14,congruent,prior_weights=NULL,method="weighted",
 fill_gaps = FALSE)

gives you the "x" that you want, I think we're close.

Jim

On Tue, Apr 21, 2020 at 1:53 PM Helen Sawaya <helensawaya at hotmail.com>
wrote:

> Thank you all for your input.
>
> This is an example of one data file (I have 74 data files):
>
> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,
>   NA,           NA,  205,    0,  394
> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,
>   NA,           NA,  205,    0,  502
> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,
>   NA,           NA,  205,    1,  468
> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,
>   NA,           NA,  203,    1,  345
> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,
>   NA,           NA,  205,    1,  373
> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,
>   NA,           NA,  205,    1,  343
> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,
>   NA,           NA,  203,    1,  437
> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,
>   NA,           NA,  203,    1,  343
> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,
>   NA,           NA,  203,    1,  441
> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,
>   NA,           NA,  205,    1,  475
>
> ?Column 13 has values of 0s and 1s which my cognitive task outputted.
> Column 14 is the reaction time (ms) data. I want to get rid of the rows
> that contain zeros so I thought I'd first replace zeros with NAs then use
> complete.cases function to get rid of the NAs. I also wanted to apply other
> functions so I included them all in a loop. All work fine except for the
> one where I try to turn the zeros to NAs.
>
> Jim when I tried your mockdata example, it worked fine. But when I
> translated it to my data, I still get zeros in the output. Can you identify
> any mistranslations I'm doing?
>
> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text
> files in one folder
> for(tf in txt.files) {
>   d<-read.table(tf)
>   d[,13][d[,13]==0]<-NA #column 13 contains zeros
>   d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>   write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
> }
>
> That's an example of one of the output I get:
>
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>
> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
> After all the data cleaning, the functions I'm interested in including in
> the loop are: get_tlbs and summarize_bias (and these also work fine in my
> loop).
>
> Thanks again ?
> Sincerely
> Helen
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* Tuesday, April 21, 2020 2:52 AM
> *To:* Rui Barradas <ruipbarradas at sapo.pt>
> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <
> lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
> *Subject:* Re: [R] NA command in a 'for' loop
>
> Hi Helen,
> Your problem may lie in using row.names=TRUE. I was puzzled when an
> extra column kept popping up in the output files. For reading in and
> replacing zeros with NAs, this seems to work:
>
> for(mockdata in 1:3) {
>  mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>  write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>   row.names=FALSE,col.names=FALSE)
> }
> txt.files<-list.files(".",pattern="threat[1-3]")
> for(tf in txt.files) {
>  d<-read.table(tf)
>  d[,3][d[,3]==0]<-NA
>  write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
> }
>
> Jim
>
> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > I believe the only way we have to see what is happening is for you to
> > post the output of
> >
> >
> > dput(head(d, 20))  # or 30
> >
> >
> > or, with d2 a subset of d that includes zeros,
> >
> >
> > dput(head(d2, 20))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> > > I have one column that represents correct response versus error
> (correct
> > > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
> > > there values of 0. The vector is treated as an integer.
> > >
> ------------------------------------------------------------------------
> > > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> > > *Sent:* Monday, April 20, 2020 7:35 PM
> > > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> > > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> > > *Subject:* Re: [R] NA command in a 'for' loop
> > > Just a thought Helen but is x being treated as a real and what you
> think
> > > are zero and are printed as zero are in fact some very small number? If
> > > so you need to alter your test appropriately.
> > >
> > > Michael
> > >
> > > On 20/04/2020 17:25, Helen Sawaya wrote:
> > >> Thank you for your reply.
> > >>
> > >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >> but I am still getting zeros instead of NAs in my output..
> > >>
> > >> I wonder if the problem is that some of my data files don't have any
> zeros (participants made no errors)..
> > >> ________________________________
> > >> From: Rui Barradas <ruipbarradas at sapo.pt>
> > >> Sent: Monday, April 20, 2020 9:05 AM
> > >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org
> <r-help at R-project.org>
> > >> Subject: Re: [R] NA command in a 'for' loop
> > >>
> > >> Hello,
> > >>
> > >> Instead of
> > >>
> > >> d[d == 0] <- NA
> > >>
> > >> try
> > >>
> > >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >>
> > >>
> > >> Also, in the first for loop
> > >>
> > >> paste(i, sep = "")
> > >>
> > >> does nothing, it's the same as i.
> > >> And the same for
> > >>
> > >> (d2$V4 == 1) == TRUE
> > >>
> > >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> > >>
> > >> (.) == TRUE
> > >>
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>
> > >>
> > >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> > >>> Dear R experts,
> > >>>
> > >>> I am using a 'for' loop to apply commands to multiple datasets (each
> file is one participant). The only one not working is the command that
> identifies zeros in my datasets and changes them to NAs. But when I look at
> the output, zeros ("0") are still present.  Surprisingly, the functions
> work fine when I apply them to a single
> > > dataset (outside the loop). I've tried:
> > >>>
> > >>> all.files <- list.files(".")
> > >>> txt.files <- grep("threat.txt",all.files,value=T)
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     d[d==0] <- NA #replace zeros with NA
> > >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method =
> "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>
> > >>> I've also tried:
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     if (0 %in% d)
> > >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with
> NA
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method =
> "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>
> > >>> Thank you for your help.
> > >>> Sincerely
> > >>> Helen
> > >>>
> > >>>         [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >
> > > --
> > > Michael
> > > http://www.dewey.myzen.co.uk/home.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr 21 06:29:07 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 20 Apr 2020 21:29:07 -0700
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQ=3XUs3MM50PO4jZ7VHGbF-FjW=KvBU4kj7q+qMPsztQ@mail.gmail.com>

Please follow Rui's advice and use dput to provide a small
reproducible example. You ask folks here to to help but won't make the
effort to enable them to do so, at least not without wasting a lot of
time trying to guess what's going on. And post in plain text, not
HTML. That is just common courtesy to follow the conventions of the
list.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 20, 2020 at 8:53 PM Helen Sawaya <helensawaya at hotmail.com> wrote:
>
> Thank you all for your input.
>
> This is an example of one data file (I have 74 data files):
>
> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,           NA,           NA,  205,    0,  394
> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,           NA,           NA,  205,    0,  502
> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,           NA,           NA,  205,    1,  468
> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,           NA,           NA,  203,    1,  345
> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,           NA,           NA,  205,    1,  373
> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,           NA,           NA,  205,    1,  343
> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,           NA,           NA,  203,    1,  437
> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,           NA,           NA,  203,    1,  343
> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,           NA,           NA,  203,    1,  441
> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,           NA,           NA,  205,    1,  475
>
> Column 13 has values of 0s and 1s which my cognitive task outputted. Column 14 is the reaction time (ms) data. I want to get rid of the rows that contain zeros so I thought I'd first replace zeros with NAs then use complete.cases function to get rid of the NAs. I also wanted to apply other functions so I included them all in a loop. All work fine except for the one where I try to turn the zeros to NAs.
>
> Jim when I tried your mockdata example, it worked fine. But when I translated it to my data, I still get zeros in the output. Can you identify any mistranslations I'm doing?
>
> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text files in one folder
> for(tf in txt.files) {
>   d<-read.table(tf)
>   d[,13][d[,13]==0]<-NA #column 13 contains zeros
>   d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>   write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
> }
>
> That's an example of one of the output I get:
>
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>
> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
> After all the data cleaning, the functions I'm interested in including in the loop are: get_tlbs and summarize_bias (and these also work fine in my loop).
>
> Thanks again
> Sincerely
> Helen
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, April 21, 2020 2:52 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
> Subject: Re: [R] NA command in a 'for' loop
>
> Hi Helen,
> Your problem may lie in using row.names=TRUE. I was puzzled when an
> extra column kept popping up in the output files. For reading in and
> replacing zeros with NAs, this seems to work:
>
> for(mockdata in 1:3) {
>  mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>  write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>   row.names=FALSE,col.names=FALSE)
> }
> txt.files<-list.files(".",pattern="threat[1-3]")
> for(tf in txt.files) {
>  d<-read.table(tf)
>  d[,3][d[,3]==0]<-NA
>  write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
> }
>
> Jim
>
> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > I believe the only way we have to see what is happening is for you to
> > post the output of
> >
> >
> > dput(head(d, 20))  # or 30
> >
> >
> > or, with d2 a subset of d that includes zeros,
> >
> >
> > dput(head(d2, 20))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> > > I have one column that represents correct response versus error (correct
> > > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
> > > there values of 0. The vector is treated as an integer.
> > > ------------------------------------------------------------------------
> > > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> > > *Sent:* Monday, April 20, 2020 7:35 PM
> > > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> > > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> > > *Subject:* Re: [R] NA command in a 'for' loop
> > > Just a thought Helen but is x being treated as a real and what you think
> > > are zero and are printed as zero are in fact some very small number? If
> > > so you need to alter your test appropriately.
> > >
> > > Michael
> > >
> > > On 20/04/2020 17:25, Helen Sawaya wrote:
> > >> Thank you for your reply.
> > >>
> > >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >> but I am still getting zeros instead of NAs in my output..
> > >>
> > >> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
> > >> ________________________________
> > >> From: Rui Barradas <ruipbarradas at sapo.pt>
> > >> Sent: Monday, April 20, 2020 9:05 AM
> > >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
> > >> Subject: Re: [R] NA command in a 'for' loop
> > >>
> > >> Hello,
> > >>
> > >> Instead of
> > >>
> > >> d[d == 0] <- NA
> > >>
> > >> try
> > >>
> > >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >>
> > >>
> > >> Also, in the first for loop
> > >>
> > >> paste(i, sep = "")
> > >>
> > >> does nothing, it's the same as i.
> > >> And the same for
> > >>
> > >> (d2$V4 == 1) == TRUE
> > >>
> > >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> > >>
> > >> (.) == TRUE
> > >>
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>
> > >>
> > >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> > >>> Dear R experts,
> > >>>
> > >>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present.  Surprisingly, the functions work fine when I apply them to a single
> > > dataset (outside the loop). I've tried:
> > >>>
> > >>> all.files <- list.files(".")
> > >>> txt.files <- grep("threat.txt",all.files,value=T)
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     d[d==0] <- NA #replace zeros with NA
> > >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
> > >>>
> > >>> I've also tried:
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     if (0 %in% d)
> > >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
> > >>>
> > >>> Thank you for your help.
> > >>> Sincerely
> > >>> Helen
> > >>>
> > >>>         [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >
> > > --
> > > Michael
> > > http://www.dewey.myzen.co.uk/home.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Apr 21 08:14:52 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Apr 2020 07:14:52 +0100
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>

Hello,

Thanks for the data. But since the replacements still do not work, 
please post the output of

dput(head(d, 10))


in order for us to have an *exact* copy of the data structure.
I had asked for 20 or 30 rows but given your post 10 are enough.
With a way to exactly reproduce what you have, it will be much easier to 
try code and find a solution. I, and I believe most R users, will run

str(d)

as one of the first steps to know what is in that problem column. And go 
from there.


Hope this helps,

Rui Barradas

?s 04:52 de 21/04/20, Helen Sawaya escreveu:
> Thank you all for your input.
> 
> This is an example of one data file (I have 74 data files):
> 
> 2.90546E+11, threat, ? ?1, 2, 1, 2, 1, ? ? ? ?death, ? ? ? ?stove,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?0, ?394
> 2.90546E+11, threat, ? ?2, 2, 2, 1, 1, ? ?emaciated, ? ?shortened,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?0, ?502
> 2.90546E+11, threat, ? ?3, 1, 1, 1, 2, ? ? mutilate, ? ? consider,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?1, ?468
> 2.90546E+11, threat, ? ?6, 1, 2, 2, 1, ? ? ? ? weep, ? ? ? ? shop,       
>  ? ? NA, ? ? ? ? ? NA, ?203, ? ?1, ?345
> 2.90546E+11, threat, ? ?9, 2, 1, 2, 2, ? ?tormented, ? ?easygoing,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?1, ?373
> 2.90546E+11, threat, ? 10, 1, 2, 2, 2, ? ? ? ?snake, ? ? ? ?table,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?1, ?343
> 2.90546E+11, threat, ? 11, 2, 2, 1, 1, ? ? ? crisis, ? ? ? faucet,       
>  ? ? NA, ? ? ? ? ? NA, ?203, ? ?1, ?437
> 2.90546E+11, threat, ? 12, 1, 1, 1, 1, ? ? ? victim, ? ? ?utensil,       
>  ? ? NA, ? ? ? ? ? NA, ?203, ? ?1, ?343
> 2.90546E+11, threat, ? 14, 1, 2, 2, 1, ? ?depressed, ? ?repentant,       
>  ? ? NA, ? ? ? ? ? NA, ?203, ? ?1, ?441
> 2.90546E+11, threat, ? 15, 2, 2, 1, 2, ? ? ? ? scum, ? ? ? ? shoe,       
>  ? ? NA, ? ? ? ? ? NA, ?205, ? ?1, ?475
> 
> ?Column 13 has values of 0s and 1s which my cognitive task outputted. 
> Column 14 is the reaction time (ms) data. I want to get rid of the rows 
> that contain zeros so I thought I'd first replace zeros with NAs then 
> use complete.cases function to get rid of the NAs. I also wanted to 
> apply other functions so I included them all in a loop. All work fine 
> except for the one where I try to turn the zeros to NAs.
> 
> Jim when I tried your mockdata example, it worked fine. But when I 
> translated it to my data, I still get zeros in the output. Can you 
> identify any mistranslations I'm doing?
> 
> txt.files<-list.files(".",pattern="dotprobe") #all my data files are 
> text files in one folder
> for(tf in txt.files) {
>  ? d<-read.table(tf)
>  ? d[,13][d[,13]==0]<-NA #column 13 contains zeros
>  ? d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>  ? write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
> }
> 
> That's an example of one of the output I get:
> 
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
> 
> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
> After all the data cleaning, the functions I'm interested in including 
> in the loop are: get_tlbs and summarize_bias (and these also work fine 
> in my loop).
> 
> Thanks again ?
> Sincerely
> Helen
> ------------------------------------------------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* Tuesday, April 21, 2020 2:52 AM
> *To:* Rui Barradas <ruipbarradas at sapo.pt>
> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey 
> <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
> *Subject:* Re: [R] NA command in a 'for' loop
> Hi Helen,
> Your problem may lie in using row.names=TRUE. I was puzzled when an
> extra column kept popping up in the output files. For reading in and
> replacing zeros with NAs, this seems to work:
> 
> for(mockdata in 1:3) {
>  ?mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>  ?write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>  ? row.names=FALSE,col.names=FALSE)
> }
> txt.files<-list.files(".",pattern="threat[1-3]")
> for(tf in txt.files) {
>  ?d<-read.table(tf)
>  ?d[,3][d[,3]==0]<-NA
>  ?write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
> }
> 
> Jim
> 
> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> I believe the only way we have to see what is happening is for you to
>> post the output of
>>
>>
>> dput(head(d, 20))? # or 30
>>
>>
>> or, with d2 a subset of d that includes zeros,
>>
>>
>> dput(head(d2, 20))
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
>> > I have one column that represents correct response versus error (correct
>> > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
>> > there values of 0. The vector is treated as an integer.
>> > ------------------------------------------------------------------------
>> > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
>> > *Sent:* Monday, April 20, 2020 7:35 PM
>> > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
>> > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
>> > *Subject:* Re: [R] NA command in a 'for' loop
>> > Just a thought Helen but is x being treated as a real and what you think
>> > are zero and are printed as zero are in fact some very small number? If
>> > so you need to alter your test appropriately.
>> >
>> > Michael
>> >
>> > On 20/04/2020 17:25, Helen Sawaya wrote:
>> >> Thank you for your reply.
>> >>
>> >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>> >> but I am still getting zeros instead of NAs in my output..
>> >>
>> >> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
>> >> ________________________________
>> >> From: Rui Barradas <ruipbarradas at sapo.pt>
>> >> Sent: Monday, April 20, 2020 9:05 AM
>> >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
>> >> Subject: Re: [R] NA command in a 'for' loop
>> >>
>> >> Hello,
>> >>
>> >> Instead of
>> >>
>> >> d[d == 0] <- NA
>> >>
>> >> try
>> >>
>> >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>> >>
>> >>
>> >> Also, in the first for loop
>> >>
>> >> paste(i, sep = "")
>> >>
>> >> does nothing, it's the same as i.
>> >> And the same for
>> >>
>> >> (d2$V4 == 1) == TRUE
>> >>
>> >> Since (d2$V4 == 1)? already is FALSE/TRUE there is no need for
>> >>
>> >> (.) == TRUE
>> >>
>> >>
>> >> Hope this helps,
>> >>
>> >> Rui Barradas
>> >>
>> >>
>> >>
>> >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>> >>> Dear R experts,
>> >>>
>> >>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single
>> > dataset (outside the loop). I've tried:
>> >>>
>> >>> all.files <- list.files(".")
>> >>> txt.files <- grep("threat.txt",all.files,value=T)
>> >>>
>> >>> for(i in txt.files){
>> >>>???? d <- read.table(paste(i,sep=""),header=F)
>> >>>???? d[d==0] <- NA #replace zeros with NA
>> >>>???? write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>> >>>???? d<-d[ ,-c(10,11)]
>> >>>???? d2<-d[complete.cases(d), ]
>> >>>???? d2$V4<-as.numeric(d2$V4)
>> >>>???? congruent <- (d2$V4 == 1) == TRUE
>> >>>???? x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>> >>>???? write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>> >>>
>> >>> I've also tried:
>> >>>
>> >>> for(i in txt.files){
>> >>>???? d <- read.table(paste(i,sep=""),header=F)
>> >>>???? if (0 %in% d)
>> >>>???? {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>> >>>???? d<-d[ ,-c(10,11)]
>> >>>???? d2<-d[complete.cases(d), ]
>> >>>???? d2$V4<-as.numeric(d2$V4)
>> >>>???? congruent <- (d2$V4 == 1) == TRUE
>> >>>???? x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>> >>>???? write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>> >>>
>> >>> Thank you for your help.
>> >>> Sincerely
>> >>> Helen
>> >>>
>> >>>???????? [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >>??????? [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >
>> > --
>> > Michael
>> > http://www.dewey.myzen.co.uk/home.html
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Tue Apr 21 06:39:22 2020
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Mon, 20 Apr 2020 21:39:22 -0700
Subject: [R] Help to download data from multiple URLs with API key
Message-ID: <CAEGXkYUjOjD8uj3=LQy+vyVWYY1YzxLik79OYJvhfhXe_UecbQ@mail.gmail.com>

Hello Everyone,

I am trying to download data from multiple websites using API key.
The  code to download from one URL is given below.

I have a list of multiple URLs' where the suffix URL 'c' keeps changing.

I would appreciate any help on how i can modify the code below that will
allow
 me to read multiple URLs and save the data from each URL as separate
csv file.

thanks,
bhaskar


#-----------------------------------------------------------------------
library(rjson)
setwd(Input)

base_url <- "abcd"         # This remains constant

b <-  "api_key"            # the api key - this remains constant

c <-  "series_id=1"        # Only this suffix URL changes.  I have a list
of multiple such URL's with different series ids.


full_url = paste0(base_url,
                  b,
                  c)


d3 <- lapply(fromJSON(file=full_url)[[2]], function(x) c(x["data"]))
d3 <- do.call(rbind, d3)

b <- as.data.frame(unlist(d3))
write.csv(b)

#-----------------------------------------------------------------------

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Apr 21 09:15:35 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 21 Apr 2020 10:15:35 +0300
Subject: [R] Help to download data from multiple URLs with API key
In-Reply-To: <CAEGXkYUjOjD8uj3=LQy+vyVWYY1YzxLik79OYJvhfhXe_UecbQ@mail.gmail.com>
References: <CAEGXkYUjOjD8uj3=LQy+vyVWYY1YzxLik79OYJvhfhXe_UecbQ@mail.gmail.com>
Message-ID: <CAGgJW76VB3Sv_qQ_RMgHAk70oEdcpaWDZrhJp9Or7t-GGpZ8Vw@mail.gmail.com>

Hi Bhaskar,
Why not just create a function that does the repetitive work, such as

doOne <- function( suffix ) {
   base_url <- "abcd"         # This remains constant
   b <-  "api_key"            # the api key - this remains constant
   c <-  paste("series_id=",suffix,sep="")
   full_url = paste0(base_url, b, c)
   d3 <- lapply(fromJSON(file=full_url)[[2]], function(x) c(x["data"]))
   d3 <- do.call(rbind, d3)
   b <- as.data.frame(unlist(d3))
   write.csv(b)
}

Then,
suffixes <- ... (whatever)
for ( s in suffixes )
    doOne( s )

You might need to also think about the filenames that you want to use in
the write.csv() command in the function doOne.

HTH,
Eric


On Tue, Apr 21, 2020 at 9:30 AM Bhaskar Mitra <bhaskar.kolkata at gmail.com>
wrote:

> Hello Everyone,
>
> I am trying to download data from multiple websites using API key.
> The  code to download from one URL is given below.
>
> I have a list of multiple URLs' where the suffix URL 'c' keeps changing.
>
> I would appreciate any help on how i can modify the code below that will
> allow
>  me to read multiple URLs and save the data from each URL as separate
> csv file.
>
> thanks,
> bhaskar
>
>
> #-----------------------------------------------------------------------
> library(rjson)
> setwd(Input)
>
> base_url <- "abcd"         # This remains constant
>
> b <-  "api_key"            # the api key - this remains constant
>
> c <-  "series_id=1"        # Only this suffix URL changes.  I have a list
> of multiple such URL's with different series ids.
>
>
> full_url = paste0(base_url,
>                   b,
>                   c)
>
>
> d3 <- lapply(fromJSON(file=full_url)[[2]], function(x) c(x["data"]))
> d3 <- do.call(rbind, d3)
>
> b <- as.data.frame(unlist(d3))
> write.csv(b)
>
> #-----------------------------------------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkr|de@u @end|ng |rom gm@||@com  Mon Apr 20 13:26:43 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 20 Apr 2020 07:26:43 -0400
Subject: [R] Web-scraping newbie - dynamic table into R?
In-Reply-To: <CADCh6xdLdQEc5qekeKvVdpAM3Jx8hGUorZAT+hh2KGPjf59=7w@mail.gmail.com>
References: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
 <CAKZQJMDQ06ky2_EfCHYZLfoZUeT9UsQ=bokjx1xArFDqy4Z8WA@mail.gmail.com>
 <CADCh6xdsUdj6zW4_85VxaRSARRAsvGNkVUYBLwQRJW1Xd5y8Kg@mail.gmail.com>
 <CADCh6xc=SzCqxWiQmnKDaLYhTjx1ya-2QrHG5ZvEsd2HvLZ2Vg@mail.gmail.com>
 <CAKZQJMBuLX-t7R1U8FnY=7Xwk-g2fWdAvNtJtdTskWJXv6KrNQ@mail.gmail.com>
 <CADCh6xdLdQEc5qekeKvVdpAM3Jx8hGUorZAT+hh2KGPjf59=7w@mail.gmail.com>
Message-ID: <CAKZQJMCH6AwMdAFCivbFNKG9GapPG9GuZNYwxT-Ohf4vm3jXxw-7173@mail.gmail.com>

Hi Julio,

I am just working on my first cup of tea of the morning so I am not
functioning all that well but I finally noticed that we have dropped the
R-help list.  I have put it back as a recipient as there are a lot of
people that know about 99%+ more than I do about the topic.

I'll keep poking around and see what I can find.

On Sun, 19 Apr 2020 at 22:34, Julio Farach <jfarach at gmail.com> wrote:

> John,
>
> I again thank you for the reply and continued support.  After a few hours,
> I arrived at the point you describe below; namely extracting elements, but
> from a different tab than the Last 10 Draws, or Winning Numbers tab.
>
> On the website, there are 5 tabs.  The elements you describe below are
> from the 3rd tab, "Odds & Prizes."  Instead of results, that tab describes
> the general odds of the Keno game.  But, I'm seeking the last 10 draws
> shown on the "Winning Numbers," or 4th tab.  I've played around with a CSS
> Selector tool, but I'm unable to extract any details (e.g., a draw number
> or Keno number) from the 4th tab.  I could extract elements of other tabs,
> like you did below, from the 3rd tab.
>
> Please let me know if you learn more or if you have other ideas for me to
> consider.
>
> Regards,
> Julio
>
> On Sun, Apr 19, 2020 at 7:00 PM John Kane <jrkrideau at gmail.com> wrote:
>
>> I am a comple newbie too but try this
>> library(rvest)
>>    Kenopage <- "
>> https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
>> "
>>
>> Keno <- read_html(Kenopage)
>>
>> tt  <-  html_table(Keno, fill= TRUE)
>>
>> This should give you a list with 10 elements, each of which should be a
>> data.frame
>> Example
>>
>> ken1  <-  tt[[1]]
>> str(ken1)
>>
>> > str(ken1)
>> 'data.frame': 12 obs. of  4 variables:
>>  $ Numbers Matched         : chr  "10" "9" "8" "7" ...
>>  $ Base Keno! Prize        : chr  "$100,000*" "$5,000" "$500" "$50" ...
>>  $ + Bulls-Eye Prize       : chr  "$200,000*" "$20,000" "$1,500" "$100"
>> ...
>>  $ Keno! w/ Bulls-Eye Prize: chr  "$300,000" "$25,000" "$2,000" "$150" ...
>> >
>>
>> I figured this out a little a few ago and just manually stepped through
>> the data.frames to get what I wanted. Brute force and stupidity but it
>> worked
>>
>> Someday I may figure out how to use things like SelectorGadget!
>>
>>
>>
>>
>> On Sun, 19 Apr 2020 at 17:46, Julio Farach <jfarach at gmail.com> wrote:
>>
>>> John - I corrected my email below for typos.
>>>
>>> On Sun, Apr 19, 2020 at 5:42 PM Julio Farach <jfarach at gmail.com> wrote:
>>>
>>>> John,
>>>>
>>>> Yes, while I can execute the line of code that I provided, I am still
>>>> unable to capture the table shown in the browser.  The last 10 draws are
>>>> shown in a table if you view the page:
>>>>
>>>> https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
>>>>
>>>>
>>>> But, despite using CSS and XPath combinations of
>>>> >html_nodes(x, CSS or XPath)
>>>> I am unable to copy that table into R.
>>>>
>>>> One commenter on another forum received an error and suggested that
>>>> perhaps bots lack permission to access the page.  But, I've used the
>>>> Robotstxt package to ensure that bots are indeed permitted.
>>>>
>>>> Any thoughts?
>>>>
>>>> Regards,
>>>> Julio
>>>>
>>>> On Sun, Apr 19, 2020 at 4:38 PM John Kane <jrkrideau at gmail.com> wrote:
>>>>
>>>>> Keno <- read_html(Kenopage) ?
>>>>>
>>>>> Or Am I misunderstanding the problem?
>>>>>
>>>>> On Sun, 19 Apr 2020 at 15:10, Julio Farach <jfarach at gmail.com> wrote:
>>>>>
>>>>>> How do I scrape the last 10 Keno draws from the Georgia lottery into
>>>>>> R?
>>>>>>
>>>>>>
>>>>>> I'm trying to pull the last 10 draws of a Keno lottery game into R.
>>>>>> I've
>>>>>> read several tutorials on how to scrape websites using the rvest
>>>>>> package,
>>>>>> Chrome's Inspect Element, and CSS or XPath, but I'm likely stuck
>>>>>> because
>>>>>> the table I seek is dynamically generated using Javascript.
>>>>>>
>>>>>>
>>>>>>
>>>>>> I started with:
>>>>>>
>>>>>> >        install.packages("rvest")
>>>>>>
>>>>>> >   library(rvest)
>>>>>>
>>>>>> >        Kenopage <- "
>>>>>>
>>>>>> https://www.galottery.com/en-us/games/draw-games/keno.html#tab-winningNumbers
>>>>>> "
>>>>>>
>>>>>> > Keno <- Read.hmtl(Kenopage)
>>>>>>
>>>>>> From there, I've been unable to progress, despite hours spend on
>>>>>> combinations of CSS and XPath calls with "html_notes."
>>>>>>
>>>>>> Failed example: DrawNumber <- Keno %>% rvest::html_nodes("body") %>%
>>>>>> xml2::xml_find_all("//span[contains(@class,'Draw Number')]") %>%
>>>>>> rvest::html_text()
>>>>>>
>>>>>>
>>>>>>
>>>>>> Someone mentioned using the V8 package in R, but it's new to me.
>>>>>>
>>>>>> How do I get started?
>>>>>>
>>>>>> --
>>>>>>
>>>>>> Julio Farach
>>>>>> https://www.linkedin.com/in/farach
>>>>>> cell phone:  804/363-2161
>>>>>> email:  JFarach at gmail.com
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> John Kane
>>>>> Kingston ON Canada
>>>>>
>>>>
>>>>
>>>> --
>>>>
>>>> Julio Farach
>>>> https://www.linkedin.com/in/farach
>>>> cell phone:  804/363-2161
>>>> email:  JFarach at gmail.com
>>>>
>>>>
>>>
>>> --
>>>
>>> Julio Farach
>>> https://www.linkedin.com/in/farach
>>> cell phone:  804/363-2161
>>> email:  JFarach at gmail.com
>>>
>>>
>>
>> --
>> John Kane
>> Kingston ON Canada
>>
>
>
> --
>
> Julio Farach
> https://www.linkedin.com/in/farach
> cell phone:  804/363-2161
> email:  JFarach at gmail.com
>
>

-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Apr 21 12:32:55 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 21 Apr 2020 13:32:55 +0300
Subject: [R] Web-scraping newbie - dynamic table into R?
In-Reply-To: <CAKZQJMCH6AwMdAFCivbFNKG9GapPG9GuZNYwxT-Ohf4vm3jXxw-7173@mail.gmail.com>
References: <CADCh6xcu1qU1nXp5C=GndJRvpQYU0oQ_r-VGYnOoeH9d66=g=w@mail.gmail.com>
 <CAKZQJMDQ06ky2_EfCHYZLfoZUeT9UsQ=bokjx1xArFDqy4Z8WA@mail.gmail.com>
 <CADCh6xdsUdj6zW4_85VxaRSARRAsvGNkVUYBLwQRJW1Xd5y8Kg@mail.gmail.com>
 <CADCh6xc=SzCqxWiQmnKDaLYhTjx1ya-2QrHG5ZvEsd2HvLZ2Vg@mail.gmail.com>
 <CAKZQJMBuLX-t7R1U8FnY=7Xwk-g2fWdAvNtJtdTskWJXv6KrNQ@mail.gmail.com>
 <CADCh6xdLdQEc5qekeKvVdpAM3Jx8hGUorZAT+hh2KGPjf59=7w@mail.gmail.com>
 <CAKZQJMCH6AwMdAFCivbFNKG9GapPG9GuZNYwxT-Ohf4vm3jXxw-7173@mail.gmail.com>
Message-ID: <20200421133255.54b02d79@Tarkus>

On Sun, 19 Apr 2020 at 22:34, Julio Farach <jfarach at gmail.com> wrote:

> But, I'm seeking the last 10 draws shown on the "Winning Numbers," or
> 4th tab.

The "Network" tab in browser developer tools (usually accessible by
pressing F12) demonstrates that the "Winning Numbers" are fetched in
JSON format by means of an XHR from
<https://www.galottery.com/api/v2/draw-games/draws/?previous-draws=10&game-names=ikeno>.

The server checks the User-Agent: header and returns a 403 error to
clients that don't look like browsers, which probably means that the
website ToS forbids programmatic access.

-- 
Best regards,
Ivan


From gor@n@bro@trom @end|ng |rom umu@@e  Tue Apr 21 16:09:52 2020
From: gor@n@bro@trom @end|ng |rom umu@@e (=?UTF-8?Q?G=c3=b6ran_Brostr=c3=b6m?=)
Date: Tue, 21 Apr 2020 16:09:52 +0200
Subject: [R] Survival analysis
In-Reply-To: <CAH6117KNsjA_geySGQbguGnRAMXCoTV952xq7V7uYw6aM-8s6Q@mail.gmail.com>
References: <CAH6117KNsjA_geySGQbguGnRAMXCoTV952xq7V7uYw6aM-8s6Q@mail.gmail.com>
Message-ID: <83141fb4-a8cf-ce46-7d8e-33b272586230@umu.se>

Dear dr Medic,

Den 2020-04-17 kl. 23:03, skrev Medic:
> On 2020-04-17 20:06, Medic wrote:
>> I can't understand how to do a survival analysis (?Surv ()) when some
>> event occurred before the start of observation (left censored). If I
>> understand correctly, there are two methods. I chose a method with: 1)
>> time from the start of treatment to the event and 2) the indicator of
>> the event. I did (in my data) the event indicator so:
>> 1 - event, 2 - event before the start of observation, 0 - no event
> 
> I have no experience of left censoring beyond the text book.  Is your
> left censored data the SAME event or a different event?
> 
> YES, THE SAME!
> 
>> ---
>> library(survival)
>> left_censor_data <- read.table("left.csv", header = TRUE, sep = ";")
>> #sep = ";" it's right!
>> dput(left_censor_data, file="left_censor_data") #file attached
>> left_censor_data
>>     'data.frame':   11 obs. of  2 variables:
>>     $ timee : int  5 151 33 37 75 14 7 9 1 45 ...
>>     $ eventt: int  2 0 0 0 0 0 0 2 0 1 ...
>>     # 1?event, 2 ? event before the start of observation , 0 ? no event
> 
> So if I read this data correctly the first observation is left censored.
> What does the time "5" refer to?  Is that 5 days BEFORE observation the
> event happened?
> 
> YES, EXACTLY!
> 
> My text book understanding of left censored data was that your
> censored points would
> have time 0.
> 
> I TRIED TO SET TIME 0 NOW (for censored points), AND RECEIVED THE SAME
> WARNING (AND THE CURVE TURNED OUT WRONG)
> 
>> sur <- Surv(time = left_censor_data$timee,  event =
>> left_censor_data$eventt, type = "left")
>>    WARNING message:
>>    In Surv(time = left_censor_data$timee, event =
>> left_censor_data$eventt,  :
>>    Invalid status value, converted to NA
>>
>> #Why such a WARNING message?

Because the choice "type = 'left'" is incompatible with an event 
variable taking three values, see the help page for survival::Surv. My 
guess from your (vague) description is that you want "type = 
'counting'", as indicated below.

>> #Then everything turns out wrong
> 
> Is the censoring type you want LEFT TRUNCATION rather than LEFT.
> If they are also right censored I think R Surv calls these Counting.
> 
> I SAY ABOUT LEFT CENSORING (NOT ABOUT LEFT TRUNCATION)!
> (COUNTING? I DO NOT UNDERSTAND THIS.)

Then you should read an elementary text on survival analysis or consult 
a local statistician.

G,

> 
> THANKS! I HOPE SOMEONE EXPLAIN TO ME
> 1) HOW TO COMPILE THE DATA and
> 2) WRITE A CODE
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Apr 21 16:53:33 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 21 Apr 2020 09:53:33 -0500
Subject: [R] how to merge two files while preserving the number of rows of
 one file in merged one?
Message-ID: <CAF9-5jOsne2DsqKTDEN0PA+P=B=ZkNfL6AaiG-HG=97yRE7ZyA@mail.gmail.com>

Hello,

> head(a)
           ID_1 pheno
1             0     B
2 fam1000_G1000     0
3 fam1001_G1001     0
4 fam1003_G1003     1
5 fam1005_G1005     0
6 fam1009_G1009     0
> head(b)
           ID_1          ID_2 missing
1             0             0       0
2 fam1000_G1000 fam1000_G1000       0
3 fam1001_G1001 fam1001_G1001       0
4 fam1003_G1003 fam1003_G1003       0
5 fam1005_G1005 fam1005_G1005       0
6 fam1009_G1009 fam1009_G1009       0
> dim(b)
[1] 1602    3
> dim(a)
[1] 1652    2
> m=merge(a,b,by="ID_1")
> dim(m)
[1] 1499    4
> head(m)
          ID_1 pheno         ID_2 missing
1            0     B            0       0
2 fam0110_G110     1 fam0110_G110       0
3 fam0117_G117     1 fam0117_G117       0
4 fam0124_G124  <NA> fam0124_G124       0

I would like my merged file (m) to have the same number of lines like
(b), that is 1602. Can you please let me know how would I do that?

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Apr 21 17:14:29 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 21 Apr 2020 10:14:29 -0500
Subject: [R] 
 how to merge two files while preserving the number of rows of
 one file in merged one?
In-Reply-To: <CAF9-5jOsne2DsqKTDEN0PA+P=B=ZkNfL6AaiG-HG=97yRE7ZyA@mail.gmail.com>
References: <CAF9-5jOsne2DsqKTDEN0PA+P=B=ZkNfL6AaiG-HG=97yRE7ZyA@mail.gmail.com>
Message-ID: <CAF9-5jPOxs-18BxP3ehsUAawfwV--JfMOeHp91aSCGUN9EzoFQ@mail.gmail.com>

this solved it:
 m=merge(a,b,by="ID_1",all.y = T)


On Tue, Apr 21, 2020 at 9:53 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> > head(a)
>            ID_1 pheno
> 1             0     B
> 2 fam1000_G1000     0
> 3 fam1001_G1001     0
> 4 fam1003_G1003     1
> 5 fam1005_G1005     0
> 6 fam1009_G1009     0
> > head(b)
>            ID_1          ID_2 missing
> 1             0             0       0
> 2 fam1000_G1000 fam1000_G1000       0
> 3 fam1001_G1001 fam1001_G1001       0
> 4 fam1003_G1003 fam1003_G1003       0
> 5 fam1005_G1005 fam1005_G1005       0
> 6 fam1009_G1009 fam1009_G1009       0
> > dim(b)
> [1] 1602    3
> > dim(a)
> [1] 1652    2
> > m=merge(a,b,by="ID_1")
> > dim(m)
> [1] 1499    4
> > head(m)
>           ID_1 pheno         ID_2 missing
> 1            0     B            0       0
> 2 fam0110_G110     1 fam0110_G110       0
> 3 fam0117_G117     1 fam0117_G117       0
> 4 fam0124_G124  <NA> fam0124_G124       0
>
> I would like my merged file (m) to have the same number of lines like
> (b), that is 1602. Can you please let me know how would I do that?
>
> Thanks
> Ana


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Apr 21 17:28:51 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 21 Apr 2020 08:28:51 -0700
Subject: [R] 
 how to merge two files while preserving the number of rows of
 one file in merged one?
In-Reply-To: <CAF9-5jOsne2DsqKTDEN0PA+P=B=ZkNfL6AaiG-HG=97yRE7ZyA@mail.gmail.com>
References: <CAF9-5jOsne2DsqKTDEN0PA+P=B=ZkNfL6AaiG-HG=97yRE7ZyA@mail.gmail.com>
Message-ID: <22BAF6F0-49AB-4EA4-B260-8437DBED9D70@dcn.davis.ca.us>

Read about the all.x and all.y arguments to ?merge.

On April 21, 2020 7:53:33 AM PDT, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hello,
>
>> head(a)
>           ID_1 pheno
>1             0     B
>2 fam1000_G1000     0
>3 fam1001_G1001     0
>4 fam1003_G1003     1
>5 fam1005_G1005     0
>6 fam1009_G1009     0
>> head(b)
>           ID_1          ID_2 missing
>1             0             0       0
>2 fam1000_G1000 fam1000_G1000       0
>3 fam1001_G1001 fam1001_G1001       0
>4 fam1003_G1003 fam1003_G1003       0
>5 fam1005_G1005 fam1005_G1005       0
>6 fam1009_G1009 fam1009_G1009       0
>> dim(b)
>[1] 1602    3
>> dim(a)
>[1] 1652    2
>> m=merge(a,b,by="ID_1")
>> dim(m)
>[1] 1499    4
>> head(m)
>          ID_1 pheno         ID_2 missing
>1            0     B            0       0
>2 fam0110_G110     1 fam0110_G110       0
>3 fam0117_G117     1 fam0117_G117       0
>4 fam0124_G124  <NA> fam0124_G124       0
>
>I would like my merged file (m) to have the same number of lines like
>(b), that is 1602. Can you please let me know how would I do that?
>
>Thanks
>Ana
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dm|try@@ergey @end|ng |rom gm@||@com  Tue Apr 21 17:11:32 2020
From: dm|try@@ergey @end|ng |rom gm@||@com (dmitry sergey)
Date: Tue, 21 Apr 2020 18:11:32 +0300
Subject: [R] Can I use R for comertial projects for free?
Message-ID: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>

Hi,

I kindly interesting can i use R for commercial projects for free? I am
going to get statistics in my commercial project with R and wanted to know
will it be legal or no?

Thanks in advance.

Best Regards,
Dmitry

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Tue Apr 21 18:02:26 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Tue, 21 Apr 2020 18:02:26 +0200
Subject: [R] ggplot2 error bars and convex hulls
Message-ID: <84c98d4e-17bf-8b68-5790-057bffa1d9d1@rgzm.de>

Dear useRs,

I would like to have horizontal and vertical error bars extending from
the means on two continuous variables.

This would be the "manual" way of doing it, computing the mean and sd
(or whatever stats) beforehand and then calling geom_errorbar() and
geom_errorbarh() with appropriate coordinates:
https://stackoverflow.com/questions/12570816/ggplot-scatter-plot-of-two-groups-with-superimposed-means-with-x-and-y-error-bar

But I am a bit surprised that there is no "built-in" way of doing it
with ggplot2. I mean not having to compute mean and sd beforehand and
not having to call both geom_errorbar() and geom_errorbarh() with a new
set of aesthetics.

In the same idea, I am looking at convex hulls and I was also expecting
to have a built-in way to do this in ggplot2. But I have only found this
"manual" way:
https://stats.stackexchange.com/questions/22805/how-to-draw-neat-polygons-around-scatterplot-regions-in-ggplot2

Thank you in advance for any pointer.
Ivan

-- 

Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 21 18:12:51 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 21 Apr 2020 12:12:51 -0400
Subject: [R] Can I use R for comertial projects for free?
In-Reply-To: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
References: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
Message-ID: <cfb59c6e-288c-0139-8adb-e617cab89648@gmail.com>

On 21/04/2020 11:11 a.m., dmitry sergey wrote:
> Hi,
> 
> I kindly interesting can i use R for commercial projects for free? I am
> going to get statistics in my commercial project with R and wanted to know
> will it be legal or no?

If you are distributing R as part of your project, then you will need to 
license your project in a compatible way, e.g. GPL, and distribute its 
full source.  Nothing stopping you from doing that commercially.

Duncan Murdoch

> 
> Thanks in advance.
> 
> Best Regards,
> Dmitry
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Apr 21 18:13:08 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 21 Apr 2020 09:13:08 -0700
Subject: [R] Can I use R for comertial projects for free?
In-Reply-To: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
References: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
Message-ID: <456C6C57-9C2C-4E07-93F0-E4B28E7DF93D@dcn.davis.ca.us>

If you comply with the relevant licenses... sure... open source can be compatible with commercial activity. But your description of your use case is way too deficient for anyone to even comment on. Since this is not a legal advice forum, go ask your question of a lawyer familiar with open source software licenses.

On April 21, 2020 8:11:32 AM PDT, dmitry sergey <dmitry.sergey at gmail.com> wrote:
>Hi,
>
>I kindly interesting can i use R for commercial projects for free? I am
>going to get statistics in my commercial project with R and wanted to
>know
>will it be legal or no?
>
>Thanks in advance.
>
>Best Regards,
>Dmitry
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Apr 21 19:06:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Apr 2020 18:06:19 +0100
Subject: [R] ggplot2 error bars and convex hulls
In-Reply-To: <84c98d4e-17bf-8b68-5790-057bffa1d9d1@rgzm.de>
References: <84c98d4e-17bf-8b68-5790-057bffa1d9d1@rgzm.de>
Message-ID: <d9d2d424-36be-e7b8-86ef-9b65a824469e@sapo.pt>

Hello,

As for convex hulls, there is an example of how to construct a stat_hull in

vignette("extending-ggplot2", package = "ggplot2")

There is also a geom_hull in a GitHub package:

devtools::install_github("cmartin/ggConvexHull")


Hope this helps,

Rui Barradas

?s 17:02 de 21/04/20, Ivan Calandra escreveu:
> Dear useRs,
> 
> I would like to have horizontal and vertical error bars extending from
> the means on two continuous variables.
> 
> This would be the "manual" way of doing it, computing the mean and sd
> (or whatever stats) beforehand and then calling geom_errorbar() and
> geom_errorbarh() with appropriate coordinates:
> https://stackoverflow.com/questions/12570816/ggplot-scatter-plot-of-two-groups-with-superimposed-means-with-x-and-y-error-bar
> 
> But I am a bit surprised that there is no "built-in" way of doing it
> with ggplot2. I mean not having to compute mean and sd beforehand and
> not having to call both geom_errorbar() and geom_errorbarh() with a new
> set of aesthetics.
> 
> In the same idea, I am looking at convex hulls and I was also expecting
> to have a built-in way to do this in ggplot2. But I have only found this
> "manual" way:
> https://stats.stackexchange.com/questions/22805/how-to-draw-neat-polygons-around-scatterplot-regions-in-ggplot2
> 
> Thank you in advance for any pointer.
> Ivan
>


From he|en@@w@y@ @end|ng |rom hotm@||@com  Tue Apr 21 19:11:34 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Tue, 21 Apr 2020 17:11:34 +0000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
Message-ID: <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>

Thank you for your patience.

This is the output of dput(head(d, 10))

structure(list(V1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L), .Label = "9.9761E+11,", class = "factor"), V2 = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "threat,", class = "factor"), 
    V3 = structure(c(1L, 28L, 37L, 48L, 55L, 63L, 73L, 88L, 2L, 
    20L), .Label = c("1,", "10,", "100,", "101,", "102,", "104,", 
    "107,", "108,", "109,", "110,", "111,", "112,", "113,", "114,", 
    "115,", "116,", "117,", "118,", "119,", "12,", "13,", "14,", 
    "15,", "16,", "17,", "18,", "19,", "2,", "20,", "21,", "22,", 
    "23,", "24,", "27,", "28,", "29,", "3,", "30,", "31,", "32,", 
    "33,", "34,", "35,", "36,", "37,", "38,", "39,", "4,", "42,", 
    "44,", "46,", "47,", "48,", "49,", "5,", "50,", "52,", "53,", 
    "54,", "55,", "57,", "59,", "6,", "60,", "61,", "62,", "63,", 
    "64,", "65,", "66,", "68,", "69,", "7,", "71,", "74,", "75,", 
    "76,", "78,", "81,", "82,", "83,", "84,", "85,", "86,", "87,", 
    "88,", "89,", "9,", "90,", "91,", "92,", "94,", "95,", "96,", 
    "97,", "98,"), class = "factor"), V4 = structure(c(1L, 2L, 
    1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L), .Label = c("1,", "2,"), class = "factor"), 
    V5 = structure(c(2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L), .Label = c("1,", 
    "2,"), class = "factor"), V6 = structure(c(2L, 1L, 2L, 2L, 
    1L, 2L, 2L, 1L, 2L, 2L), .Label = c("1,", "2,"), class = "factor"), 
    V7 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("1,", 
    "2,"), class = "factor"), V8 = structure(c(41L, 92L, 63L, 
    36L, 2L, 81L, 12L, 14L, 23L, 33L), .Label = c("abduction,", 
    "abortion,", "abuse,", "accident,", "addicted,", "agony,", 
    "anger,", "angry,", "anguish,", "assault,", "bankrupt,", 
    "bullet,", "burial,", "cancer,", "cemetery,", "coffin,", 
    "corpse,", "crash,", "crisis,", "cruel,", "death,", "defeated,", 
    "depressed,", "deserted,", "despair,", "destroy,", "disaster,", 
    "disloyal,", "distress,", "dreadful,", "drown,", "dull,", 
    "dump,", "emaciated,", "failure,", "fatigue,", "fault,", 
    "feeble,", "fever,", "filth,", "forlorn,", "germs,", "gloomy,", 
    "hardship,", "hell,", "helpless,", "horror,", "hostage,", 
    "hostile,", "hurt,", "idiot,", "infest,", "injury,", "irritable,", 
    "jail,", "killer,", "lonely,", "malaria,", "messy,", "misery,", 
    "mistake,", "morbid,", "murder,", "mutilate,", "pain,", "panic,", 
    "poison,", "prison,", "pus,", "rape,", "rat,", "rejected,", 
    "sad,", "scum,", "shame,", "sick,", "slap,", "snake,", "spider,", 
    "suicide,", "surgery,", "terrible,", "tormented,", "trash,", 
    "trauma,", "ugly,", "ulcer,", "unease,", "unhappy,", "useless,", 
    "victim,", "wasp,", "weep,", "worm,", "wound,"), class = "factor"), 
    V9 = structure(c(24L, 90L, 73L, 10L, 92L, 33L, 84L, 96L, 
    70L, 57L), .Label = c("alley,", "ankle,", "appliance,", "audience,", 
    "bandage,", "bathroom,", "bookcase,", "border,", "branch,", 
    "cabinet,", "category,", "clean,", "cliff,", "cold,", "consider,", 
    "consoled,", "context,", "country,", "crop,", "dentist,", 
    "detail,", "dinner,", "doctor,", "dynamic,", "easygoing,", 
    "elbow,", "energetic,", "farm,", "faucet,", "flat,", "flowing,", 
    "fork,", "freezer,", "glass,", "grass,", "guess,", "humble,", 
    "icebox,", "industry,", "invisible,", "jug,", "lighting,", 
    "lion,", "listen,", "little,", "machine,", "metal,", "month,", 
    "mushroom,", "napkin,", "news,", "noisy,", "north,", "nudge,", 
    "number,", "numerous,", "obey,", "odd,", "oval,", "plant,", 
    "possible,", "pot,", "public,", "puzzled,", "quarter,", "rational,", 
    "ready,", "reflect,", "reliable,", "repentant,", "sand,", 
    "school,", "secret,", "series,", "shark,", "shoe,", "shop,", 
    "shortened,", "skyline,", "stable,", "storm,", "stove,", 
    "table,", "theory,", "tower,", "truck,", "upgrade,", "upright,", 
    "utensil,", "vest,", "vision,", "volcano,", "walk,", "watchful,", 
    "window,", "winter,"), class = "factor"), V10 = structure(c(1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"), 
    V11 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"), 
    V12 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("203,", 
    "205,"), class = "factor"), V13 = structure(c(1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1,", class = "factor"), 
    V14 = c(4063L, 4914L, 1508L, 1819L, 1228L, 992L, 1898L, 1174L, 
    1294L, 1417L)), row.names = c(NA, 10L), class = "data.frame?)

When I use the following:

all.files <- list.files(".")
txt.files <- grep("threat.txt",all.files,value=T)

for(i in txt.files) {
  d<-read.table(i, header=FALSE)
  d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
  write.table(d,paste0(i, "trial.txt"), quote=FALSE, row.names=FALSE)}

I get this (an example of one of the output files with zeros in V13):

V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14
3.17903E+11, threat, 1, 1, 2, 2, 1, useless, flowing, NA, NA, 203, 1, 949
3.17903E+11, threat, 3, 2, 2, 1, 1, hostage, skyline, NA, NA, 203, 1, 1116
3.17903E+11, threat, 4, 1, 1, 1, 2, messy, ready, NA, NA, 205, 1, 1277
3.17903E+11, threat, 6, 2, 1, 2, 2, emaciated, shortened, NA, NA, 205, 1, 691
3.17903E+11, threat, 7, 1, 1, 1, 1, abuse, plant, NA, NA, 203, 1, 660
3.17903E+11, threat, 8, 2, 1, 2, 2, tormented, easygoing, NA, NA, 205, 1, 812
3.17903E+11, threat, 9, 1, 2, 2, 2, hurt, sand, NA, NA, 205, 1, 917
3.17903E+11, threat, 10, 1, 1, 1, 1, surgery, freezer, NA, NA, 203, 1, 1829
3.17903E+11, threat, 12, 2, 2, 1, 2, accident, category, NA, NA, 205, 1, 821
3.17903E+11, threat, 13, 2, 1, 2, 2, terrible, energetic, NA, NA, 205, 1, 783
3.17903E+11, threat, 14, 1, 2, 2, 1, wound, storm, NA, NA, 203, 1, 813
3.17903E+11, threat, 15, 1, 1, 1, 2, victim, utensil, NA, NA, 205, 1, 1132
3.17903E+11, threat, 16, 2, 2, 1, 2, bankrupt, lighting, NA, NA, 203, 0, 1510
3.17903E+11, threat, 17, 1, 1, 1, 2, anguish, country, NA, NA, 203, 0, 811
3.17903E+11, threat, 18, 2, 2, 1, 1, snake, table, NA, NA, 203, 1, 805
3.17903E+11, threat, 19, 1, 1, 1, 2, slap, crop, NA, NA, 205, 1, 1180
3.17903E+11, threat, 20, 2, 1, 2, 2, scum, shoe, NA, NA, 205, 1, 792
3.17903E+11, threat, 21, 1, 2, 2, 1, weep, shop, NA, NA, 203, 1, 870
3.17903E+11, threat, 23, 2, 1, 2, 1, spider, border, NA, NA, 203, 1, 871

str(d) gives me the following:

'data.frame':	96 obs. of  14 variables:
 $ V1 : Factor w/ 1 level "9.9761E+11,": 1 1 1 1 1 1 1 1 1 1 ...
 $ V2 : Factor w/ 1 level "threat,": 1 1 1 1 1 1 1 1 1 1 ...
 $ V3 : Factor w/ 96 levels "1,","10,","100,",..: 1 28 37 48 55 63 73 88 2 20 ...
 $ V4 : Factor w/ 2 levels "1,","2,": 1 2 1 2 2 2 2 2 1 1 ...
 $ V5 : Factor w/ 2 levels "1,","2,": 2 2 2 1 2 1 1 2 2 2 ...
 $ V6 : Factor w/ 2 levels "1,","2,": 2 1 2 2 1 2 2 1 2 2 ...
 $ V7 : Factor w/ 2 levels "1,","2,": 2 1 2 2 2 2 1 2 1 2 ...
 $ V8 : Factor w/ 95 levels "abduction,","abortion,",..: 41 92 63 36 2 81 12 14 23 33 ...
 $ V9 : Factor w/ 96 levels "alley,","ankle,",..: 24 90 73 10 92 33 84 96 70 57 ...
 $ V10: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
 $ V11: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
 $ V12: Factor w/ 2 levels "203,","205,": 2 1 2 2 2 2 1 2 1 2 ...
 $ V13: Factor w/ 1 level "1,": 1 1 1 1 1 1 1 1 1 1 ...
 $ V14: int  4063 4914 1508 1819 1228 992 1898 1174 1294 1417 ?

When I use this: 

for(i in txt.files) {
  d<-read.table(i, header=FALSE)
  d2<-d[d$V13==1,]
  write.table(d2,sub("[.]",".trial.",i),quote=FALSE,row.names=FALSE)
}

I get empty files:

str(d2)
'data.frame':	0 obs. of  14 variables:
 $ V1 : Factor w/ 1 level "9.9761E+11,": 
 $ V2 : Factor w/ 1 level "threat,": 
 $ V3 : Factor w/ 96 levels "1,","10,","100,",..: 
 $ V4 : Factor w/ 2 levels "1,","2,": 
 $ V5 : Factor w/ 2 levels "1,","2,": 
 $ V6 : Factor w/ 2 levels "1,","2,": 
 $ V7 : Factor w/ 2 levels "1,","2,": 
 $ V8 : Factor w/ 95 levels "abduction,","abortion,",..: 
 $ V9 : Factor w/ 96 levels "alley,","ankle,",..: 
 $ V10: Factor w/ 1 level "NA,": 
 $ V11: Factor w/ 1 level "NA,": 
 $ V12: Factor w/ 2 levels "203,","205,": 
 $ V13: Factor w/ 1 level "1,": 
 $ V14: int 

When I use as.integer to change V13 to an integer, the output of this column is replaced by 1s and 2s..


> On Apr 21, 2020, at 1:14 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Thanks for the data. But since the replacements still do not work, please post the output of
> 
> dput(head(d, 10))
> 
> 
> in order for us to have an *exact* copy of the data structure.
> I had asked for 20 or 30 rows but given your post 10 are enough.
> With a way to exactly reproduce what you have, it will be much easier to try code and find a solution. I, and I believe most R users, will run
> 
> str(d)
> 
> as one of the first steps to know what is in that problem column. And go from there.
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 04:52 de 21/04/20, Helen Sawaya escreveu:
>> Thank you all for your input.
>> This is an example of one data file (I have 74 data files):
>> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,            NA,           NA,  205,    0,  394
>> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,            NA,           NA,  205,    0,  502
>> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,            NA,           NA,  205,    1,  468
>> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,            NA,           NA,  203,    1,  345
>> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,            NA,           NA,  205,    1,  373
>> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,            NA,           NA,  205,    1,  343
>> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,            NA,           NA,  203,    1,  437
>> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,            NA,           NA,  203,    1,  343
>> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,            NA,           NA,  203,    1,  441
>> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,            NA,           NA,  205,    1,  475
>> ?Column 13 has values of 0s and 1s which my cognitive task outputted. Column 14 is the reaction time (ms) data. I want to get rid of the rows that contain zeros so I thought I'd first replace zeros with NAs then use complete.cases function to get rid of the NAs. I also wanted to apply other functions so I included them all in a loop. All work fine except for the one where I try to turn the zeros to NAs.
>> Jim when I tried your mockdata example, it worked fine. But when I translated it to my data, I still get zeros in the output. Can you identify any mistranslations I'm doing?
>> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text files in one folder
>> for(tf in txt.files) {
>>   d<-read.table(tf)
>>   d[,13][d[,13]==0]<-NA #column 13 contains zeros
>>   d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>>   write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
>> }
>> That's an example of one of the output I get:
>> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
>> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
>> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
>> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
>> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
>> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
>> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
>> After all the data cleaning, the functions I'm interested in including in the loop are: get_tlbs and summarize_bias (and these also work fine in my loop).
>> Thanks again ?
>> Sincerely
>> Helen
>> ------------------------------------------------------------------------
>> *From:* Jim Lemon <drjimlemon at gmail.com>
>> *Sent:* Tuesday, April 21, 2020 2:52 AM
>> *To:* Rui Barradas <ruipbarradas at sapo.pt>
>> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
>> *Subject:* Re: [R] NA command in a 'for' loop
>> Hi Helen,
>> Your problem may lie in using row.names=TRUE. I was puzzled when an
>> extra column kept popping up in the output files. For reading in and
>> replacing zeros with NAs, this seems to work:
>> for(mockdata in 1:3) {
>>  mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>>  write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>>   row.names=FALSE,col.names=FALSE)
>> }
>> txt.files<-list.files(".",pattern="threat[1-3]")
>> for(tf in txt.files) {
>>  d<-read.table(tf)
>>  d[,3][d[,3]==0]<-NA
>>  write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
>> }
>> Jim
>> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>> 
>>> Hello,
>>> 
>>> I believe the only way we have to see what is happening is for you to
>>> post the output of
>>> 
>>> 
>>> dput(head(d, 20))  # or 30
>>> 
>>> 
>>> or, with d2 a subset of d that includes zeros,
>>> 
>>> 
>>> dput(head(d2, 20))
>>> 
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
>>> > I have one column that represents correct response versus error (correct
>>> > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
>>> > there values of 0. The vector is treated as an integer.
>>> > ------------------------------------------------------------------------
>>> > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
>>> > *Sent:* Monday, April 20, 2020 7:35 PM
>>> > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
>>> > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
>>> > *Subject:* Re: [R] NA command in a 'for' loop
>>> > Just a thought Helen but is x being treated as a real and what you think
>>> > are zero and are printed as zero are in fact some very small number? If
>>> > so you need to alter your test appropriately.
>>> >
>>> > Michael
>>> >
>>> > On 20/04/2020 17:25, Helen Sawaya wrote:
>>> >> Thank you for your reply.
>>> >>
>>> >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>> >> but I am still getting zeros instead of NAs in my output..
>>> >>
>>> >> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
>>> >> ________________________________
>>> >> From: Rui Barradas <ruipbarradas at sapo.pt>
>>> >> Sent: Monday, April 20, 2020 9:05 AM
>>> >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
>>> >> Subject: Re: [R] NA command in a 'for' loop
>>> >>
>>> >> Hello,
>>> >>
>>> >> Instead of
>>> >>
>>> >> d[d == 0] <- NA
>>> >>
>>> >> try
>>> >>
>>> >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>> >>
>>> >>
>>> >> Also, in the first for loop
>>> >>
>>> >> paste(i, sep = "")
>>> >>
>>> >> does nothing, it's the same as i.
>>> >> And the same for
>>> >>
>>> >> (d2$V4 == 1) == TRUE
>>> >>
>>> >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
>>> >>
>>> >> (.) == TRUE
>>> >>
>>> >>
>>> >> Hope this helps,
>>> >>
>>> >> Rui Barradas
>>> >>
>>> >>
>>> >>
>>> >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>>> >>> Dear R experts,
>>> >>>
>>> >>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single
>>> > dataset (outside the loop). I've tried:
>>> >>>
>>> >>> all.files <- list.files(".")
>>> >>> txt.files <- grep("threat.txt",all.files,value=T)
>>> >>>
>>> >>> for(i in txt.files){
>>> >>>     d <- read.table(paste(i,sep=""),header=F)
>>> >>>     d[d==0] <- NA #replace zeros with NA
>>> >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>> >>>     d<-d[ ,-c(10,11)]
>>> >>>     d2<-d[complete.cases(d), ]
>>> >>>     d2$V4<-as.numeric(d2$V4)
>>> >>>     congruent <- (d2$V4 == 1) == TRUE
>>> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>> >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>> >>>
>>> >>> I've also tried:
>>> >>>
>>> >>> for(i in txt.files){
>>> >>>     d <- read.table(paste(i,sep=""),header=F)
>>> >>>     if (0 %in% d)
>>> >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>> >>>     d<-d[ ,-c(10,11)]
>>> >>>     d2<-d[complete.cases(d), ]
>>> >>>     d2$V4<-as.numeric(d2$V4)
>>> >>>     congruent <- (d2$V4 == 1) == TRUE
>>> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>> >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>> >>>
>>> >>> Thank you for your help.
>>> >>> Sincerely
>>> >>> Helen
>>> >>>
>>> >>>         [[alternative HTML version deleted]]
>>> >>>
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>>
>>> >>
>>> >>        [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>
>>> >
>>> > --
>>> > Michael
>>> > http://www.dewey.myzen.co.uk/home.html
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Apr 21 19:19:25 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 21 Apr 2020 10:19:25 -0700
Subject: [R] Can I use R for comertial projects for free?
In-Reply-To: <cfb59c6e-288c-0139-8adb-e617cab89648@gmail.com>
References: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
 <cfb59c6e-288c-0139-8adb-e617cab89648@gmail.com>
Message-ID: <8D58B177-84AC-4C6F-B6F8-DBB6E8FA8127@dcn.davis.ca.us>

The "contamination" of other code by GPL is not absolute... it _is_ possible to use GPL code without releasing your code similarly, and blithely suggesting otherwise perpetuates myths about GPL.

That said, it is very tricky to do so while presenting a clean user experience, and doing so is likely to raise objections on the part of consumers of your commercial product unless you do it right. The appropriate response here is to reccommend consultation with a lawyer familiar with these issues.

Informally, I would recommend against doing this from a user experience perspective... but not because of contamination.

On April 21, 2020 9:12:51 AM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 21/04/2020 11:11 a.m., dmitry sergey wrote:
>> Hi,
>> 
>> I kindly interesting can i use R for commercial projects for free? I
>am
>> going to get statistics in my commercial project with R and wanted to
>know
>> will it be legal or no?
>
>If you are distributing R as part of your project, then you will need
>to 
>license your project in a compatible way, e.g. GPL, and distribute its 
>full source.  Nothing stopping you from doing that commercially.
>
>Duncan Murdoch
>
>> 
>> Thanks in advance.
>> 
>> Best Regards,
>> Dmitry
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Tue Apr 21 20:20:05 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 21 Apr 2020 11:20:05 -0700
Subject: [R] NA command in a 'for' loop
In-Reply-To: <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
 <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
Message-ID: <CAF8bMcbw3dEyfB2oThDZ7udQaMM0Nj2xquVYpfA=+7T3GrFGzg@mail.gmail.com>

Read the files with read.csv(filename) or read.table(sep=",", filename) so
the commas don't become part of the R data.frame.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Apr 21, 2020 at 10:17 AM Helen Sawaya <helensawaya at hotmail.com>
wrote:

> Thank you for your patience.
>
> This is the output of dput(head(d, 10))
>
> structure(list(V1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L), .Label = "9.9761E+11,", class = "factor"), V2 = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "threat,", class =
> "factor"),
>     V3 = structure(c(1L, 28L, 37L, 48L, 55L, 63L, 73L, 88L, 2L,
>     20L), .Label = c("1,", "10,", "100,", "101,", "102,", "104,",
>     "107,", "108,", "109,", "110,", "111,", "112,", "113,", "114,",
>     "115,", "116,", "117,", "118,", "119,", "12,", "13,", "14,",
>     "15,", "16,", "17,", "18,", "19,", "2,", "20,", "21,", "22,",
>     "23,", "24,", "27,", "28,", "29,", "3,", "30,", "31,", "32,",
>     "33,", "34,", "35,", "36,", "37,", "38,", "39,", "4,", "42,",
>     "44,", "46,", "47,", "48,", "49,", "5,", "50,", "52,", "53,",
>     "54,", "55,", "57,", "59,", "6,", "60,", "61,", "62,", "63,",
>     "64,", "65,", "66,", "68,", "69,", "7,", "71,", "74,", "75,",
>     "76,", "78,", "81,", "82,", "83,", "84,", "85,", "86,", "87,",
>     "88,", "89,", "9,", "90,", "91,", "92,", "94,", "95,", "96,",
>     "97,", "98,"), class = "factor"), V4 = structure(c(1L, 2L,
>     1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L), .Label = c("1,", "2,"), class =
> "factor"),
>     V5 = structure(c(2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L), .Label =
> c("1,",
>     "2,"), class = "factor"), V6 = structure(c(2L, 1L, 2L, 2L,
>     1L, 2L, 2L, 1L, 2L, 2L), .Label = c("1,", "2,"), class = "factor"),
>     V7 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label =
> c("1,",
>     "2,"), class = "factor"), V8 = structure(c(41L, 92L, 63L,
>     36L, 2L, 81L, 12L, 14L, 23L, 33L), .Label = c("abduction,",
>     "abortion,", "abuse,", "accident,", "addicted,", "agony,",
>     "anger,", "angry,", "anguish,", "assault,", "bankrupt,",
>     "bullet,", "burial,", "cancer,", "cemetery,", "coffin,",
>     "corpse,", "crash,", "crisis,", "cruel,", "death,", "defeated,",
>     "depressed,", "deserted,", "despair,", "destroy,", "disaster,",
>     "disloyal,", "distress,", "dreadful,", "drown,", "dull,",
>     "dump,", "emaciated,", "failure,", "fatigue,", "fault,",
>     "feeble,", "fever,", "filth,", "forlorn,", "germs,", "gloomy,",
>     "hardship,", "hell,", "helpless,", "horror,", "hostage,",
>     "hostile,", "hurt,", "idiot,", "infest,", "injury,", "irritable,",
>     "jail,", "killer,", "lonely,", "malaria,", "messy,", "misery,",
>     "mistake,", "morbid,", "murder,", "mutilate,", "pain,", "panic,",
>     "poison,", "prison,", "pus,", "rape,", "rat,", "rejected,",
>     "sad,", "scum,", "shame,", "sick,", "slap,", "snake,", "spider,",
>     "suicide,", "surgery,", "terrible,", "tormented,", "trash,",
>     "trauma,", "ugly,", "ulcer,", "unease,", "unhappy,", "useless,",
>     "victim,", "wasp,", "weep,", "worm,", "wound,"), class = "factor"),
>     V9 = structure(c(24L, 90L, 73L, 10L, 92L, 33L, 84L, 96L,
>     70L, 57L), .Label = c("alley,", "ankle,", "appliance,", "audience,",
>     "bandage,", "bathroom,", "bookcase,", "border,", "branch,",
>     "cabinet,", "category,", "clean,", "cliff,", "cold,", "consider,",
>     "consoled,", "context,", "country,", "crop,", "dentist,",
>     "detail,", "dinner,", "doctor,", "dynamic,", "easygoing,",
>     "elbow,", "energetic,", "farm,", "faucet,", "flat,", "flowing,",
>     "fork,", "freezer,", "glass,", "grass,", "guess,", "humble,",
>     "icebox,", "industry,", "invisible,", "jug,", "lighting,",
>     "lion,", "listen,", "little,", "machine,", "metal,", "month,",
>     "mushroom,", "napkin,", "news,", "noisy,", "north,", "nudge,",
>     "number,", "numerous,", "obey,", "odd,", "oval,", "plant,",
>     "possible,", "pot,", "public,", "puzzled,", "quarter,", "rational,",
>     "ready,", "reflect,", "reliable,", "repentant,", "sand,",
>     "school,", "secret,", "series,", "shark,", "shoe,", "shop,",
>     "shortened,", "skyline,", "stable,", "storm,", "stove,",
>     "table,", "theory,", "tower,", "truck,", "upgrade,", "upright,",
>     "utensil,", "vest,", "vision,", "volcano,", "walk,", "watchful,",
>     "window,", "winter,"), class = "factor"), V10 = structure(c(1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class =
> "factor"),
>     V11 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
> "NA,", class = "factor"),
>     V12 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label =
> c("203,",
>     "205,"), class = "factor"), V13 = structure(c(1L, 1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1,", class = "factor"),
>     V14 = c(4063L, 4914L, 1508L, 1819L, 1228L, 992L, 1898L, 1174L,
>     1294L, 1417L)), row.names = c(NA, 10L), class = "data.frame?)
>
> When I use the following:
>
> all.files <- list.files(".")
> txt.files <- grep("threat.txt",all.files,value=T)
>
> for(i in txt.files) {
>   d<-read.table(i, header=FALSE)
>   d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>   write.table(d,paste0(i, "trial.txt"), quote=FALSE, row.names=FALSE)}
>
> I get this (an example of one of the output files with zeros in V13):
>
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14
> 3.17903E+11, threat, 1, 1, 2, 2, 1, useless, flowing, NA, NA, 203, 1, 949
> 3.17903E+11, threat, 3, 2, 2, 1, 1, hostage, skyline, NA, NA, 203, 1, 1116
> 3.17903E+11, threat, 4, 1, 1, 1, 2, messy, ready, NA, NA, 205, 1, 1277
> 3.17903E+11, threat, 6, 2, 1, 2, 2, emaciated, shortened, NA, NA, 205, 1,
> 691
> 3.17903E+11, threat, 7, 1, 1, 1, 1, abuse, plant, NA, NA, 203, 1, 660
> 3.17903E+11, threat, 8, 2, 1, 2, 2, tormented, easygoing, NA, NA, 205, 1,
> 812
> 3.17903E+11, threat, 9, 1, 2, 2, 2, hurt, sand, NA, NA, 205, 1, 917
> 3.17903E+11, threat, 10, 1, 1, 1, 1, surgery, freezer, NA, NA, 203, 1, 1829
> 3.17903E+11, threat, 12, 2, 2, 1, 2, accident, category, NA, NA, 205, 1,
> 821
> 3.17903E+11, threat, 13, 2, 1, 2, 2, terrible, energetic, NA, NA, 205, 1,
> 783
> 3.17903E+11, threat, 14, 1, 2, 2, 1, wound, storm, NA, NA, 203, 1, 813
> 3.17903E+11, threat, 15, 1, 1, 1, 2, victim, utensil, NA, NA, 205, 1, 1132
> 3.17903E+11, threat, 16, 2, 2, 1, 2, bankrupt, lighting, NA, NA, 203, 0,
> 1510
> 3.17903E+11, threat, 17, 1, 1, 1, 2, anguish, country, NA, NA, 203, 0, 811
> 3.17903E+11, threat, 18, 2, 2, 1, 1, snake, table, NA, NA, 203, 1, 805
> 3.17903E+11, threat, 19, 1, 1, 1, 2, slap, crop, NA, NA, 205, 1, 1180
> 3.17903E+11, threat, 20, 2, 1, 2, 2, scum, shoe, NA, NA, 205, 1, 792
> 3.17903E+11, threat, 21, 1, 2, 2, 1, weep, shop, NA, NA, 203, 1, 870
> 3.17903E+11, threat, 23, 2, 1, 2, 1, spider, border, NA, NA, 203, 1, 871
>
> str(d) gives me the following:
>
> 'data.frame':   96 obs. of  14 variables:
>  $ V1 : Factor w/ 1 level "9.9761E+11,": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V2 : Factor w/ 1 level "threat,": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V3 : Factor w/ 96 levels "1,","10,","100,",..: 1 28 37 48 55 63 73 88 2
> 20 ...
>  $ V4 : Factor w/ 2 levels "1,","2,": 1 2 1 2 2 2 2 2 1 1 ...
>  $ V5 : Factor w/ 2 levels "1,","2,": 2 2 2 1 2 1 1 2 2 2 ...
>  $ V6 : Factor w/ 2 levels "1,","2,": 2 1 2 2 1 2 2 1 2 2 ...
>  $ V7 : Factor w/ 2 levels "1,","2,": 2 1 2 2 2 2 1 2 1 2 ...
>  $ V8 : Factor w/ 95 levels "abduction,","abortion,",..: 41 92 63 36 2 81
> 12 14 23 33 ...
>  $ V9 : Factor w/ 96 levels "alley,","ankle,",..: 24 90 73 10 92 33 84 96
> 70 57 ...
>  $ V10: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V11: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V12: Factor w/ 2 levels "203,","205,": 2 1 2 2 2 2 1 2 1 2 ...
>  $ V13: Factor w/ 1 level "1,": 1 1 1 1 1 1 1 1 1 1 ...
>  $ V14: int  4063 4914 1508 1819 1228 992 1898 1174 1294 1417 ?
>
> When I use this:
>
> for(i in txt.files) {
>   d<-read.table(i, header=FALSE)
>   d2<-d[d$V13==1,]
>   write.table(d2,sub("[.]",".trial.",i),quote=FALSE,row.names=FALSE)
> }
>
> I get empty files:
>
> str(d2)
> 'data.frame':   0 obs. of  14 variables:
>  $ V1 : Factor w/ 1 level "9.9761E+11,":
>  $ V2 : Factor w/ 1 level "threat,":
>  $ V3 : Factor w/ 96 levels "1,","10,","100,",..:
>  $ V4 : Factor w/ 2 levels "1,","2,":
>  $ V5 : Factor w/ 2 levels "1,","2,":
>  $ V6 : Factor w/ 2 levels "1,","2,":
>  $ V7 : Factor w/ 2 levels "1,","2,":
>  $ V8 : Factor w/ 95 levels "abduction,","abortion,",..:
>  $ V9 : Factor w/ 96 levels "alley,","ankle,",..:
>  $ V10: Factor w/ 1 level "NA,":
>  $ V11: Factor w/ 1 level "NA,":
>  $ V12: Factor w/ 2 levels "203,","205,":
>  $ V13: Factor w/ 1 level "1,":
>  $ V14: int
>
> When I use as.integer to change V13 to an integer, the output of this
> column is replaced by 1s and 2s..
>
>
> > On Apr 21, 2020, at 1:14 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Thanks for the data. But since the replacements still do not work,
> please post the output of
> >
> > dput(head(d, 10))
> >
> >
> > in order for us to have an *exact* copy of the data structure.
> > I had asked for 20 or 30 rows but given your post 10 are enough.
> > With a way to exactly reproduce what you have, it will be much easier to
> try code and find a solution. I, and I believe most R users, will run
> >
> > str(d)
> >
> > as one of the first steps to know what is in that problem column. And go
> from there.
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 04:52 de 21/04/20, Helen Sawaya escreveu:
> >> Thank you all for your input.
> >> This is an example of one data file (I have 74 data files):
> >> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,
>       NA,           NA,  205,    0,  394
> >> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,
>       NA,           NA,  205,    0,  502
> >> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,
>       NA,           NA,  205,    1,  468
> >> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,
>       NA,           NA,  203,    1,  345
> >> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,
>       NA,           NA,  205,    1,  373
> >> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,
>       NA,           NA,  205,    1,  343
> >> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,
>       NA,           NA,  203,    1,  437
> >> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,
>       NA,           NA,  203,    1,  343
> >> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,
>       NA,           NA,  203,    1,  441
> >> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,
>       NA,           NA,  205,    1,  475
> >> ?Column 13 has values of 0s and 1s which my cognitive task outputted.
> Column 14 is the reaction time (ms) data. I want to get rid of the rows
> that contain zeros so I thought I'd first replace zeros with NAs then use
> complete.cases function to get rid of the NAs. I also wanted to apply other
> functions so I included them all in a loop. All work fine except for the
> one where I try to turn the zeros to NAs.
> >> Jim when I tried your mockdata example, it worked fine. But when I
> translated it to my data, I still get zeros in the output. Can you identify
> any mistranslations I'm doing?
> >> txt.files<-list.files(".",pattern="dotprobe") #all my data files are
> text files in one folder
> >> for(tf in txt.files) {
> >>   d<-read.table(tf)
> >>   d[,13][d[,13]==0]<-NA #column 13 contains zeros
> >>   d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
> >>   write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
> >> }
> >> That's an example of one of the output I get:
> >> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
> >> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
> >> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
> >> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
> >> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
> >> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
> >> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
> >> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
> >> After all the data cleaning, the functions I'm interested in including
> in the loop are: get_tlbs and summarize_bias (and these also work fine in
> my loop).
> >> Thanks again ?
> >> Sincerely
> >> Helen
> >> ------------------------------------------------------------------------
> >> *From:* Jim Lemon <drjimlemon at gmail.com>
> >> *Sent:* Tuesday, April 21, 2020 2:52 AM
> >> *To:* Rui Barradas <ruipbarradas at sapo.pt>
> >> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <
> lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
> >> *Subject:* Re: [R] NA command in a 'for' loop
> >> Hi Helen,
> >> Your problem may lie in using row.names=TRUE. I was puzzled when an
> >> extra column kept popping up in the output files. For reading in and
> >> replacing zeros with NAs, this seems to work:
> >> for(mockdata in 1:3) {
> >>  mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
> >>  write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
> >>   row.names=FALSE,col.names=FALSE)
> >> }
> >> txt.files<-list.files(".",pattern="threat[1-3]")
> >> for(tf in txt.files) {
> >>  d<-read.table(tf)
> >>  d[,3][d[,3]==0]<-NA
> >>  write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
> >> }
> >> Jim
> >> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >>>
> >>> Hello,
> >>>
> >>> I believe the only way we have to see what is happening is for you to
> >>> post the output of
> >>>
> >>>
> >>> dput(head(d, 20))  # or 30
> >>>
> >>>
> >>> or, with d2 a subset of d that includes zeros,
> >>>
> >>>
> >>> dput(head(d2, 20))
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> >>> > I have one column that represents correct response versus error
> (correct
> >>> > is coded as 1 and error is coded as 0). Nowhere else in the dataset
> are
> >>> > there values of 0. The vector is treated as an integer.
> >>> >
> ------------------------------------------------------------------------
> >>> > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> >>> > *Sent:* Monday, April 20, 2020 7:35 PM
> >>> > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> >>> > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> >>> > *Subject:* Re: [R] NA command in a 'for' loop
> >>> > Just a thought Helen but is x being treated as a real and what you
> think
> >>> > are zero and are printed as zero are in fact some very small number?
> If
> >>> > so you need to alter your test appropriately.
> >>> >
> >>> > Michael
> >>> >
> >>> > On 20/04/2020 17:25, Helen Sawaya wrote:
> >>> >> Thank you for your reply.
> >>> >>
> >>> >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >>> >> but I am still getting zeros instead of NAs in my output..
> >>> >>
> >>> >> I wonder if the problem is that some of my data files don't have
> any zeros (participants made no errors)..
> >>> >> ________________________________
> >>> >> From: Rui Barradas <ruipbarradas at sapo.pt>
> >>> >> Sent: Monday, April 20, 2020 9:05 AM
> >>> >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org
> <r-help at R-project.org>
> >>> >> Subject: Re: [R] NA command in a 'for' loop
> >>> >>
> >>> >> Hello,
> >>> >>
> >>> >> Instead of
> >>> >>
> >>> >> d[d == 0] <- NA
> >>> >>
> >>> >> try
> >>> >>
> >>> >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> >>> >>
> >>> >>
> >>> >> Also, in the first for loop
> >>> >>
> >>> >> paste(i, sep = "")
> >>> >>
> >>> >> does nothing, it's the same as i.
> >>> >> And the same for
> >>> >>
> >>> >> (d2$V4 == 1) == TRUE
> >>> >>
> >>> >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> >>> >>
> >>> >> (.) == TRUE
> >>> >>
> >>> >>
> >>> >> Hope this helps,
> >>> >>
> >>> >> Rui Barradas
> >>> >>
> >>> >>
> >>> >>
> >>> >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> >>> >>> Dear R experts,
> >>> >>>
> >>> >>> I am using a 'for' loop to apply commands to multiple datasets
> (each file is one participant). The only one not working is the command
> that identifies zeros in my datasets and changes them to NAs. But when I
> look at the output, zeros ("0") are still present. Surprisingly, the
> functions work fine when I apply them to a single
> >>> > dataset (outside the loop). I've tried:
> >>> >>>
> >>> >>> all.files <- list.files(".")
> >>> >>> txt.files <- grep("threat.txt",all.files,value=T)
> >>> >>>
> >>> >>> for(i in txt.files){
> >>> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>> >>>     d[d==0] <- NA #replace zeros with NA
> >>> >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> >>> >>>     d<-d[ ,-c(10,11)]
> >>> >>>     d2<-d[complete.cases(d), ]
> >>> >>>     d2$V4<-as.numeric(d2$V4)
> >>> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method
> = "weighted", fill_gaps = FALSE)
> >>> >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> >>> >>>
> >>> >>> I've also tried:
> >>> >>>
> >>> >>> for(i in txt.files){
> >>> >>>     d <- read.table(paste(i,sep=""),header=F)
> >>> >>>     if (0 %in% d)
> >>> >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros
> with NA
> >>> >>>     d<-d[ ,-c(10,11)]
> >>> >>>     d2<-d[complete.cases(d), ]
> >>> >>>     d2$V4<-as.numeric(d2$V4)
> >>> >>>     congruent <- (d2$V4 == 1) == TRUE
> >>> >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method
> = "weighted", fill_gaps = FALSE)
> >>> >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE,
> row.names=TRUE)}
> >>> >>>
> >>> >>> Thank you for your help.
> >>> >>> Sincerely
> >>> >>> Helen
> >>> >>>
> >>> >>>         [[alternative HTML version deleted]]
> >>> >>>
> >>> >>> ______________________________________________
> >>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> >>> and provide commented, minimal, self-contained, reproducible code.
> >>> >>>
> >>> >>
> >>> >>        [[alternative HTML version deleted]]
> >>> >>
> >>> >> ______________________________________________
> >>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> >> and provide commented, minimal, self-contained, reproducible code.
> >>> >>
> >>> >>
> >>> >
> >>> > --
> >>> > Michael
> >>> > http://www.dewey.myzen.co.uk/home.html
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Apr 21 20:38:48 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 21 Apr 2020 19:38:48 +0100
Subject: [R] NA command in a 'for' loop
In-Reply-To: <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
 <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
Message-ID: <be68e66f-6ca8-dd83-f564-93c68e6b3a48@sapo.pt>

Hello,

Much better, you have "," at the end of your data elements so nothing is 
working.

The following 3 instructions

1. remove those commas,
2. create a logical vector trying to guess which columns are numeric
3. coerce those columns to numeric.


d[] <- lapply(d, function(x){sub(",$", "", x)})
not_num <- sapply(d, function(x) all(is.na(as.numeric(as.character(x)))))
d[!not_num] <- lapply(d[!not_num], function(x) as.numeric(as.character(x)))



Then, if you want just d$V13 == 0 to become NA, this will do it.


is.na(d[["V13"]]) <- d[["V13"]] == 0


If you want to do this to all numeric columns, try


d[!not_num] <- lapply(d[!not_num], function(x){
   is.na(x) <- x == 0
   x
})


Hope this helps,

Rui Barradas


?s 18:11 de 21/04/20, Helen Sawaya escreveu:
> Thank you for your patience.
> 
> This is the output of dput(head(d, 10))
> 
> structure(list(V1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L), .Label = "9.9761E+11,", class = "factor"), V2 = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "threat,", class = "factor"),
>      V3 = structure(c(1L, 28L, 37L, 48L, 55L, 63L, 73L, 88L, 2L,
>      20L), .Label = c("1,", "10,", "100,", "101,", "102,", "104,",
>      "107,", "108,", "109,", "110,", "111,", "112,", "113,", "114,",
>      "115,", "116,", "117,", "118,", "119,", "12,", "13,", "14,",
>      "15,", "16,", "17,", "18,", "19,", "2,", "20,", "21,", "22,",
>      "23,", "24,", "27,", "28,", "29,", "3,", "30,", "31,", "32,",
>      "33,", "34,", "35,", "36,", "37,", "38,", "39,", "4,", "42,",
>      "44,", "46,", "47,", "48,", "49,", "5,", "50,", "52,", "53,",
>      "54,", "55,", "57,", "59,", "6,", "60,", "61,", "62,", "63,",
>      "64,", "65,", "66,", "68,", "69,", "7,", "71,", "74,", "75,",
>      "76,", "78,", "81,", "82,", "83,", "84,", "85,", "86,", "87,",
>      "88,", "89,", "9,", "90,", "91,", "92,", "94,", "95,", "96,",
>      "97,", "98,"), class = "factor"), V4 = structure(c(1L, 2L,
>      1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L), .Label = c("1,", "2,"), class = "factor"),
>      V5 = structure(c(2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L), .Label = c("1,",
>      "2,"), class = "factor"), V6 = structure(c(2L, 1L, 2L, 2L,
>      1L, 2L, 2L, 1L, 2L, 2L), .Label = c("1,", "2,"), class = "factor"),
>      V7 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("1,",
>      "2,"), class = "factor"), V8 = structure(c(41L, 92L, 63L,
>      36L, 2L, 81L, 12L, 14L, 23L, 33L), .Label = c("abduction,",
>      "abortion,", "abuse,", "accident,", "addicted,", "agony,",
>      "anger,", "angry,", "anguish,", "assault,", "bankrupt,",
>      "bullet,", "burial,", "cancer,", "cemetery,", "coffin,",
>      "corpse,", "crash,", "crisis,", "cruel,", "death,", "defeated,",
>      "depressed,", "deserted,", "despair,", "destroy,", "disaster,",
>      "disloyal,", "distress,", "dreadful,", "drown,", "dull,",
>      "dump,", "emaciated,", "failure,", "fatigue,", "fault,",
>      "feeble,", "fever,", "filth,", "forlorn,", "germs,", "gloomy,",
>      "hardship,", "hell,", "helpless,", "horror,", "hostage,",
>      "hostile,", "hurt,", "idiot,", "infest,", "injury,", "irritable,",
>      "jail,", "killer,", "lonely,", "malaria,", "messy,", "misery,",
>      "mistake,", "morbid,", "murder,", "mutilate,", "pain,", "panic,",
>      "poison,", "prison,", "pus,", "rape,", "rat,", "rejected,",
>      "sad,", "scum,", "shame,", "sick,", "slap,", "snake,", "spider,",
>      "suicide,", "surgery,", "terrible,", "tormented,", "trash,",
>      "trauma,", "ugly,", "ulcer,", "unease,", "unhappy,", "useless,",
>      "victim,", "wasp,", "weep,", "worm,", "wound,"), class = "factor"),
>      V9 = structure(c(24L, 90L, 73L, 10L, 92L, 33L, 84L, 96L,
>      70L, 57L), .Label = c("alley,", "ankle,", "appliance,", "audience,",
>      "bandage,", "bathroom,", "bookcase,", "border,", "branch,",
>      "cabinet,", "category,", "clean,", "cliff,", "cold,", "consider,",
>      "consoled,", "context,", "country,", "crop,", "dentist,",
>      "detail,", "dinner,", "doctor,", "dynamic,", "easygoing,",
>      "elbow,", "energetic,", "farm,", "faucet,", "flat,", "flowing,",
>      "fork,", "freezer,", "glass,", "grass,", "guess,", "humble,",
>      "icebox,", "industry,", "invisible,", "jug,", "lighting,",
>      "lion,", "listen,", "little,", "machine,", "metal,", "month,",
>      "mushroom,", "napkin,", "news,", "noisy,", "north,", "nudge,",
>      "number,", "numerous,", "obey,", "odd,", "oval,", "plant,",
>      "possible,", "pot,", "public,", "puzzled,", "quarter,", "rational,",
>      "ready,", "reflect,", "reliable,", "repentant,", "sand,",
>      "school,", "secret,", "series,", "shark,", "shoe,", "shop,",
>      "shortened,", "skyline,", "stable,", "storm,", "stove,",
>      "table,", "theory,", "tower,", "truck,", "upgrade,", "upright,",
>      "utensil,", "vest,", "vision,", "volcano,", "walk,", "watchful,",
>      "window,", "winter,"), class = "factor"), V10 = structure(c(1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"),
>      V11 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"),
>      V12 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("203,",
>      "205,"), class = "factor"), V13 = structure(c(1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1,", class = "factor"),
>      V14 = c(4063L, 4914L, 1508L, 1819L, 1228L, 992L, 1898L, 1174L,
>      1294L, 1417L)), row.names = c(NA, 10L), class = "data.frame?)
> 
> When I use the following:
> 
> all.files <- list.files(".")
> txt.files <- grep("threat.txt",all.files,value=T)
> 
> for(i in txt.files) {
>    d<-read.table(i, header=FALSE)
>    d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>    write.table(d,paste0(i, "trial.txt"), quote=FALSE, row.names=FALSE)}
> 
> I get this (an example of one of the output files with zeros in V13):
> 
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14
> 3.17903E+11, threat, 1, 1, 2, 2, 1, useless, flowing, NA, NA, 203, 1, 949
> 3.17903E+11, threat, 3, 2, 2, 1, 1, hostage, skyline, NA, NA, 203, 1, 1116
> 3.17903E+11, threat, 4, 1, 1, 1, 2, messy, ready, NA, NA, 205, 1, 1277
> 3.17903E+11, threat, 6, 2, 1, 2, 2, emaciated, shortened, NA, NA, 205, 1, 691
> 3.17903E+11, threat, 7, 1, 1, 1, 1, abuse, plant, NA, NA, 203, 1, 660
> 3.17903E+11, threat, 8, 2, 1, 2, 2, tormented, easygoing, NA, NA, 205, 1, 812
> 3.17903E+11, threat, 9, 1, 2, 2, 2, hurt, sand, NA, NA, 205, 1, 917
> 3.17903E+11, threat, 10, 1, 1, 1, 1, surgery, freezer, NA, NA, 203, 1, 1829
> 3.17903E+11, threat, 12, 2, 2, 1, 2, accident, category, NA, NA, 205, 1, 821
> 3.17903E+11, threat, 13, 2, 1, 2, 2, terrible, energetic, NA, NA, 205, 1, 783
> 3.17903E+11, threat, 14, 1, 2, 2, 1, wound, storm, NA, NA, 203, 1, 813
> 3.17903E+11, threat, 15, 1, 1, 1, 2, victim, utensil, NA, NA, 205, 1, 1132
> 3.17903E+11, threat, 16, 2, 2, 1, 2, bankrupt, lighting, NA, NA, 203, 0, 1510
> 3.17903E+11, threat, 17, 1, 1, 1, 2, anguish, country, NA, NA, 203, 0, 811
> 3.17903E+11, threat, 18, 2, 2, 1, 1, snake, table, NA, NA, 203, 1, 805
> 3.17903E+11, threat, 19, 1, 1, 1, 2, slap, crop, NA, NA, 205, 1, 1180
> 3.17903E+11, threat, 20, 2, 1, 2, 2, scum, shoe, NA, NA, 205, 1, 792
> 3.17903E+11, threat, 21, 1, 2, 2, 1, weep, shop, NA, NA, 203, 1, 870
> 3.17903E+11, threat, 23, 2, 1, 2, 1, spider, border, NA, NA, 203, 1, 871
> 
> str(d) gives me the following:
> 
> 'data.frame':	96 obs. of  14 variables:
>   $ V1 : Factor w/ 1 level "9.9761E+11,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V2 : Factor w/ 1 level "threat,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V3 : Factor w/ 96 levels "1,","10,","100,",..: 1 28 37 48 55 63 73 88 2 20 ...
>   $ V4 : Factor w/ 2 levels "1,","2,": 1 2 1 2 2 2 2 2 1 1 ...
>   $ V5 : Factor w/ 2 levels "1,","2,": 2 2 2 1 2 1 1 2 2 2 ...
>   $ V6 : Factor w/ 2 levels "1,","2,": 2 1 2 2 1 2 2 1 2 2 ...
>   $ V7 : Factor w/ 2 levels "1,","2,": 2 1 2 2 2 2 1 2 1 2 ...
>   $ V8 : Factor w/ 95 levels "abduction,","abortion,",..: 41 92 63 36 2 81 12 14 23 33 ...
>   $ V9 : Factor w/ 96 levels "alley,","ankle,",..: 24 90 73 10 92 33 84 96 70 57 ...
>   $ V10: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V11: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V12: Factor w/ 2 levels "203,","205,": 2 1 2 2 2 2 1 2 1 2 ...
>   $ V13: Factor w/ 1 level "1,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V14: int  4063 4914 1508 1819 1228 992 1898 1174 1294 1417 ?
> 
> When I use this:
> 
> for(i in txt.files) {
>    d<-read.table(i, header=FALSE)
>    d2<-d[d$V13==1,]
>    write.table(d2,sub("[.]",".trial.",i),quote=FALSE,row.names=FALSE)
> }
> 
> I get empty files:
> 
> str(d2)
> 'data.frame':	0 obs. of  14 variables:
>   $ V1 : Factor w/ 1 level "9.9761E+11,":
>   $ V2 : Factor w/ 1 level "threat,":
>   $ V3 : Factor w/ 96 levels "1,","10,","100,",..:
>   $ V4 : Factor w/ 2 levels "1,","2,":
>   $ V5 : Factor w/ 2 levels "1,","2,":
>   $ V6 : Factor w/ 2 levels "1,","2,":
>   $ V7 : Factor w/ 2 levels "1,","2,":
>   $ V8 : Factor w/ 95 levels "abduction,","abortion,",..:
>   $ V9 : Factor w/ 96 levels "alley,","ankle,",..:
>   $ V10: Factor w/ 1 level "NA,":
>   $ V11: Factor w/ 1 level "NA,":
>   $ V12: Factor w/ 2 levels "203,","205,":
>   $ V13: Factor w/ 1 level "1,":
>   $ V14: int
> 
> When I use as.integer to change V13 to an integer, the output of this column is replaced by 1s and 2s..
> 
> 
>> On Apr 21, 2020, at 1:14 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Thanks for the data. But since the replacements still do not work, please post the output of
>>
>> dput(head(d, 10))
>>
>>
>> in order for us to have an *exact* copy of the data structure.
>> I had asked for 20 or 30 rows but given your post 10 are enough.
>> With a way to exactly reproduce what you have, it will be much easier to try code and find a solution. I, and I believe most R users, will run
>>
>> str(d)
>>
>> as one of the first steps to know what is in that problem column. And go from there.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 04:52 de 21/04/20, Helen Sawaya escreveu:
>>> Thank you all for your input.
>>> This is an example of one data file (I have 74 data files):
>>> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,            NA,           NA,  205,    0,  394
>>> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,            NA,           NA,  205,    0,  502
>>> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,            NA,           NA,  205,    1,  468
>>> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,            NA,           NA,  203,    1,  345
>>> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,            NA,           NA,  205,    1,  373
>>> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,            NA,           NA,  205,    1,  343
>>> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,            NA,           NA,  203,    1,  437
>>> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,            NA,           NA,  203,    1,  343
>>> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,            NA,           NA,  203,    1,  441
>>> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,            NA,           NA,  205,    1,  475
>>> ?Column 13 has values of 0s and 1s which my cognitive task outputted. Column 14 is the reaction time (ms) data. I want to get rid of the rows that contain zeros so I thought I'd first replace zeros with NAs then use complete.cases function to get rid of the NAs. I also wanted to apply other functions so I included them all in a loop. All work fine except for the one where I try to turn the zeros to NAs.
>>> Jim when I tried your mockdata example, it worked fine. But when I translated it to my data, I still get zeros in the output. Can you identify any mistranslations I'm doing?
>>> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text files in one folder
>>> for(tf in txt.files) {
>>>    d<-read.table(tf)
>>>    d[,13][d[,13]==0]<-NA #column 13 contains zeros
>>>    d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>>>    write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
>>> }
>>> That's an example of one of the output I get:
>>> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
>>> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
>>> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
>>> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
>>> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
>>> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
>>> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>>> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
>>> After all the data cleaning, the functions I'm interested in including in the loop are: get_tlbs and summarize_bias (and these also work fine in my loop).
>>> Thanks again ?
>>> Sincerely
>>> Helen
>>> ------------------------------------------------------------------------
>>> *From:* Jim Lemon <drjimlemon at gmail.com>
>>> *Sent:* Tuesday, April 21, 2020 2:52 AM
>>> *To:* Rui Barradas <ruipbarradas at sapo.pt>
>>> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
>>> *Subject:* Re: [R] NA command in a 'for' loop
>>> Hi Helen,
>>> Your problem may lie in using row.names=TRUE. I was puzzled when an
>>> extra column kept popping up in the output files. For reading in and
>>> replacing zeros with NAs, this seems to work:
>>> for(mockdata in 1:3) {
>>>   mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>>>   write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>>>    row.names=FALSE,col.names=FALSE)
>>> }
>>> txt.files<-list.files(".",pattern="threat[1-3]")
>>> for(tf in txt.files) {
>>>   d<-read.table(tf)
>>>   d[,3][d[,3]==0]<-NA
>>>   write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
>>> }
>>> Jim
>>> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I believe the only way we have to see what is happening is for you to
>>>> post the output of
>>>>
>>>>
>>>> dput(head(d, 20))  # or 30
>>>>
>>>>
>>>> or, with d2 a subset of d that includes zeros,
>>>>
>>>>
>>>> dput(head(d2, 20))
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
>>>>> I have one column that represents correct response versus error (correct
>>>>> is coded as 1 and error is coded as 0). Nowhere else in the dataset are
>>>>> there values of 0. The vector is treated as an integer.
>>>>> ------------------------------------------------------------------------
>>>>> *From:* Michael Dewey <lists at dewey.myzen.co.uk>
>>>>> *Sent:* Monday, April 20, 2020 7:35 PM
>>>>> *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
>>>>> <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
>>>>> *Subject:* Re: [R] NA command in a 'for' loop
>>>>> Just a thought Helen but is x being treated as a real and what you think
>>>>> are zero and are printed as zero are in fact some very small number? If
>>>>> so you need to alter your test appropriately.
>>>>>
>>>>> Michael
>>>>>
>>>>> On 20/04/2020 17:25, Helen Sawaya wrote:
>>>>>> Thank you for your reply.
>>>>>>
>>>>>> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>>>>> but I am still getting zeros instead of NAs in my output..
>>>>>>
>>>>>> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
>>>>>> ________________________________
>>>>>> From: Rui Barradas <ruipbarradas at sapo.pt>
>>>>>> Sent: Monday, April 20, 2020 9:05 AM
>>>>>> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
>>>>>> Subject: Re: [R] NA command in a 'for' loop
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Instead of
>>>>>>
>>>>>> d[d == 0] <- NA
>>>>>>
>>>>>> try
>>>>>>
>>>>>> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>>>>>
>>>>>>
>>>>>> Also, in the first for loop
>>>>>>
>>>>>> paste(i, sep = "")
>>>>>>
>>>>>> does nothing, it's the same as i.
>>>>>> And the same for
>>>>>>
>>>>>> (d2$V4 == 1) == TRUE
>>>>>>
>>>>>> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
>>>>>>
>>>>>> (.) == TRUE
>>>>>>
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>>
>>>>>>
>>>>>> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>>>>>>> Dear R experts,
>>>>>>>
>>>>>>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single
>>>>> dataset (outside the loop). I've tried:
>>>>>>>
>>>>>>> all.files <- list.files(".")
>>>>>>> txt.files <- grep("threat.txt",all.files,value=T)
>>>>>>>
>>>>>>> for(i in txt.files){
>>>>>>>      d <- read.table(paste(i,sep=""),header=F)
>>>>>>>      d[d==0] <- NA #replace zeros with NA
>>>>>>>      write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>      d<-d[ ,-c(10,11)]
>>>>>>>      d2<-d[complete.cases(d), ]
>>>>>>>      d2$V4<-as.numeric(d2$V4)
>>>>>>>      congruent <- (d2$V4 == 1) == TRUE
>>>>>>>      x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>>>>>      write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>
>>>>>>> I've also tried:
>>>>>>>
>>>>>>> for(i in txt.files){
>>>>>>>      d <- read.table(paste(i,sep=""),header=F)
>>>>>>>      if (0 %in% d)
>>>>>>>      {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>>>>>>      d<-d[ ,-c(10,11)]
>>>>>>>      d2<-d[complete.cases(d), ]
>>>>>>>      d2$V4<-as.numeric(d2$V4)
>>>>>>>      congruent <- (d2$V4 == 1) == TRUE
>>>>>>>      x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>>>>>      write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>
>>>>>>> Thank you for your help.
>>>>>>> Sincerely
>>>>>>> Helen
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Michael
>>>>> http://www.dewey.myzen.co.uk/home.html
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>


From herd_dog @end|ng |rom cox@net  Tue Apr 21 22:47:19 2020
From: herd_dog @end|ng |rom cox@net (Phillip Heinrich)
Date: Tue, 21 Apr 2020 13:47:19 -0700
Subject: [R] Subtracting Data Frame With a Different Number of Rows
Message-ID: <4685A5060D104647A9F78F566F42EF8F@OWNERPC>

I have two small data frames of baseball data.  The first one is the mean 
number of runs that will score in each half inning for the 2018 Arizona 
Diamondbacks.  The second data frame is the same information but for only 
one player.  As you will see the individual player did not come up to bat 
any time during the season:
    with the bases loaded and no outs
    runners on first and third with one out

Overall

RunnerCode                Outs     MeanRuns
1 Bases Empty             0           0.5137615
2 Runner:1st                0           0.8967391
3 Runner:2nd               0           1.3018868
4 Runners:1st & 2nd    0           1.6551724
5 Runner:3rd                0           1.9545455
6 Runners:1st & 3rd     0           2.0571429
7 Runners:2nd & 3rd    0           2.1578947
8 Bases Loaded            0           3.2173913
9 Bases Empty              1           0.3963801
10 Runner:1st               1           0.6952596
11 Runner:2nd              1           0.9580838
12 Runners:1st & 2nd   1           1.4397163
13 Runner:3rd               1           1.5352113
14 Runners:1st & 3rd   1            1.5882353
15 Runners:2nd & 3rd  1            1.9215686
16 Bases Loaded          1            1.9193548
17 Bases Empty            2            0.4191011
18 Runner:1st               2            0.5531915
19 Runner:2nd              2            0.8777293
20 Runners:1st & 2nd  2             0.9553073
21 Runner:3rd              2             1.2783505
22 Runners:1st & 3rd   2             1.5851064
23 Runners:2nd & 3rd  2             1.2794118
24 Bases Loaded         2              1.388235

Individual Player

  RunnerCode              Outs           MeanRuns
1 Bases Empty             0                 0.4262295
2 Runner:1st                0                 1.3200000
3 Runner:2nd               0                 1.2857143
4 Runners:1st & 2nd   0                  0.5714286
5 Runner:3rd               0                  2.0000000
6 Runners:1st & 3rd    0                  3.5000000
7 Runners:2nd & 3rd   0                  1.0000000
8 Bases Empty             1                  0.5238095
9 Runner:1st                1                  0.6578947
10 Runner:2nd             1                  0.3750000
11 Runners:1st & 2nd 1                   1.4285714
12 Runner:3rd             1                   1.4285714
13 Runners:2nd & 3rd 1                   0.6666667
14 Bases Loaded         1                   3.0000000
15 Bases Empty           2                   0.3469388
16 Runner:1st              2                   0.1363636
17 Runner:2nd             2                   0.7142857
18 Runners:1st & 2nd  2                   1.6666667
19 Runner:3rd              2                   1.2500000
20 Runners:1st & 3rd  2                    2.1428571
21 Runners:2nd & 3rd 2                    1.5000000
22 Bases Loaded         2                    2.2000000

RunnersCode is a factor
Outs are integers
MeanRuns is numerical data

I would like to subtract the second from the first as a way to evaluate the 
players ability to produce runs. As part of this analysis I I would like to 
input the mean number of runs from the overall data frame into the two 
missing cells for the individual player:Bases Loaded no outs and 1st and 3rd 
one out.

Can anyone give me some advise?


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr 21 23:47:18 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 22 Apr 2020 07:47:18 +1000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
 <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>
Message-ID: <CA+8X3fVoWEi4At1YpSgVWpE4AOQ+BhCW=k4vKUn6_RXwddyPcQ@mail.gmail.com>

Hi Helen,
>From you last post, I think the best strategy is to make sure that the
operations you are performing are giving you the results you want. If so,
then we can tackle the multiple input files. As I don't have the library
you are using, I cannot access the function "get_tbls", so please replace:

# load whatever library you are using here
with
library(xxxx)
where xxxx is the name of the library

Then run the following script and tell us if you get your expected output

d<-read.table(
text="2.90546E+11,threat,1,2,1,2,1,death,stove,NA,NA,205,0,394
2.90546E+11,threat,2,2,2,1,1,emaciated,shortened,NA,NA,205,0,502
2.90546E+11,threat,3,1,1,1,2,mutilate,consider,NA,NA,205,1,468
2.90546E+11,threat,6,1,2,2,1,weep,shop,NA,NA,203,1,345
2.90546E+11,threat,9,2,1,2,2,tormented,easygoing,NA,NA,205,1,373
2.90546E+11,threat,10,1,2,2,2,snake,table,NA,NA,205,1,343
2.90546E+11,threat,11,2,2,1,1,crisis,faucet,NA,NA,203,1,437
2.90546E+11,threat,12,1,1,1,1,victim,utensil,NA,NA,203,1,343
2.90546E+11,threat,14,1,2,2,1,depressed,repentant,NA,NA,203,1,441
2.90546E+11,threat,15,2,2,1,2,scum,shoe,NA,NA,205,1,475",
header=FALSE,sep=",",stringsAsFactors=FALSE)
# look at at d, is it what you expect?
d
# let d2 be the rows of d where V13 is non-zero
d2<-d[d$V13!=0,]
# look at at d2, is it what you expect?
d2
congruent <-(d2$V4 == 1)
# look at at congruent, is it what you expect?
congruent
# load whatever library you are using here
x<-get_tlbs(d2$V14,congruent,prior_weights=NULL,method="weighted",
 fill_gaps = FALSE)
# look at at x, is it what you expect?
x
write.table(x,file="test_output.txt",quote=FALSE,row.names=FALSE)}
# open "test_output.txt" in a text editor. Is it what you want?

Jim

On Wed, Apr 22, 2020 at 3:11 AM Helen Sawaya <helensawaya at hotmail.com>
wrote:

> Thank you for your patience.
>
> You're welcome.

	[[alternative HTML version deleted]]


From he|en@@w@y@ @end|ng |rom hotm@||@com  Wed Apr 22 00:29:26 2020
From: he|en@@w@y@ @end|ng |rom hotm@||@com (Helen Sawaya)
Date: Tue, 21 Apr 2020 22:29:26 +0000
Subject: [R] NA command in a 'for' loop
In-Reply-To: <be68e66f-6ca8-dd83-f564-93c68e6b3a48@sapo.pt>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ae6f18ce-44eb-b4a8-c428-c5c7f9908bdd@sapo.pt>
 <63163B9C-9DB6-4D55-8D26-DE26E0611E5F@hotmail.com>,
 <be68e66f-6ca8-dd83-f564-93c68e6b3a48@sapo.pt>
Message-ID: <AM5PR10MB17469F3D40434631B95568A3B9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>

Thank you all. Your suggestions worked. As you said, the problem appeared to have been the commas that were part of the data frame.

Thanks again ?
________________________________
From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Tuesday, April 21, 2020 9:38 PM
To: Helen Sawaya <helensawaya at hotmail.com>
Cc: Jim Lemon <drjimlemon at gmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
Subject: Re: [R] NA command in a 'for' loop

Hello,

Much better, you have "," at the end of your data elements so nothing is
working.

The following 3 instructions

1. remove those commas,
2. create a logical vector trying to guess which columns are numeric
3. coerce those columns to numeric.


d[] <- lapply(d, function(x){sub(",$", "", x)})
not_num <- sapply(d, function(x) all(is.na(as.numeric(as.character(x)))))
d[!not_num] <- lapply(d[!not_num], function(x) as.numeric(as.character(x)))



Then, if you want just d$V13 == 0 to become NA, this will do it.


is.na(d[["V13"]]) <- d[["V13"]] == 0


If you want to do this to all numeric columns, try


d[!not_num] <- lapply(d[!not_num], function(x){
   is.na(x) <- x == 0
   x
})


Hope this helps,

Rui Barradas


?s 18:11 de 21/04/20, Helen Sawaya escreveu:
> Thank you for your patience.
>
> This is the output of dput(head(d, 10))
>
> structure(list(V1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L), .Label = "9.9761E+11,", class = "factor"), V2 = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "threat,", class = "factor"),
>      V3 = structure(c(1L, 28L, 37L, 48L, 55L, 63L, 73L, 88L, 2L,
>      20L), .Label = c("1,", "10,", "100,", "101,", "102,", "104,",
>      "107,", "108,", "109,", "110,", "111,", "112,", "113,", "114,",
>      "115,", "116,", "117,", "118,", "119,", "12,", "13,", "14,",
>      "15,", "16,", "17,", "18,", "19,", "2,", "20,", "21,", "22,",
>      "23,", "24,", "27,", "28,", "29,", "3,", "30,", "31,", "32,",
>      "33,", "34,", "35,", "36,", "37,", "38,", "39,", "4,", "42,",
>      "44,", "46,", "47,", "48,", "49,", "5,", "50,", "52,", "53,",
>      "54,", "55,", "57,", "59,", "6,", "60,", "61,", "62,", "63,",
>      "64,", "65,", "66,", "68,", "69,", "7,", "71,", "74,", "75,",
>      "76,", "78,", "81,", "82,", "83,", "84,", "85,", "86,", "87,",
>      "88,", "89,", "9,", "90,", "91,", "92,", "94,", "95,", "96,",
>      "97,", "98,"), class = "factor"), V4 = structure(c(1L, 2L,
>      1L, 2L, 2L, 2L, 2L, 2L, 1L, 1L), .Label = c("1,", "2,"), class = "factor"),
>      V5 = structure(c(2L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 2L, 2L), .Label = c("1,",
>      "2,"), class = "factor"), V6 = structure(c(2L, 1L, 2L, 2L,
>      1L, 2L, 2L, 1L, 2L, 2L), .Label = c("1,", "2,"), class = "factor"),
>      V7 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("1,",
>      "2,"), class = "factor"), V8 = structure(c(41L, 92L, 63L,
>      36L, 2L, 81L, 12L, 14L, 23L, 33L), .Label = c("abduction,",
>      "abortion,", "abuse,", "accident,", "addicted,", "agony,",
>      "anger,", "angry,", "anguish,", "assault,", "bankrupt,",
>      "bullet,", "burial,", "cancer,", "cemetery,", "coffin,",
>      "corpse,", "crash,", "crisis,", "cruel,", "death,", "defeated,",
>      "depressed,", "deserted,", "despair,", "destroy,", "disaster,",
>      "disloyal,", "distress,", "dreadful,", "drown,", "dull,",
>      "dump,", "emaciated,", "failure,", "fatigue,", "fault,",
>      "feeble,", "fever,", "filth,", "forlorn,", "germs,", "gloomy,",
>      "hardship,", "hell,", "helpless,", "horror,", "hostage,",
>      "hostile,", "hurt,", "idiot,", "infest,", "injury,", "irritable,",
>      "jail,", "killer,", "lonely,", "malaria,", "messy,", "misery,",
>      "mistake,", "morbid,", "murder,", "mutilate,", "pain,", "panic,",
>      "poison,", "prison,", "pus,", "rape,", "rat,", "rejected,",
>      "sad,", "scum,", "shame,", "sick,", "slap,", "snake,", "spider,",
>      "suicide,", "surgery,", "terrible,", "tormented,", "trash,",
>      "trauma,", "ugly,", "ulcer,", "unease,", "unhappy,", "useless,",
>      "victim,", "wasp,", "weep,", "worm,", "wound,"), class = "factor"),
>      V9 = structure(c(24L, 90L, 73L, 10L, 92L, 33L, 84L, 96L,
>      70L, 57L), .Label = c("alley,", "ankle,", "appliance,", "audience,",
>      "bandage,", "bathroom,", "bookcase,", "border,", "branch,",
>      "cabinet,", "category,", "clean,", "cliff,", "cold,", "consider,",
>      "consoled,", "context,", "country,", "crop,", "dentist,",
>      "detail,", "dinner,", "doctor,", "dynamic,", "easygoing,",
>      "elbow,", "energetic,", "farm,", "faucet,", "flat,", "flowing,",
>      "fork,", "freezer,", "glass,", "grass,", "guess,", "humble,",
>      "icebox,", "industry,", "invisible,", "jug,", "lighting,",
>      "lion,", "listen,", "little,", "machine,", "metal,", "month,",
>      "mushroom,", "napkin,", "news,", "noisy,", "north,", "nudge,",
>      "number,", "numerous,", "obey,", "odd,", "oval,", "plant,",
>      "possible,", "pot,", "public,", "puzzled,", "quarter,", "rational,",
>      "ready,", "reflect,", "reliable,", "repentant,", "sand,",
>      "school,", "secret,", "series,", "shark,", "shoe,", "shop,",
>      "shortened,", "skyline,", "stable,", "storm,", "stove,",
>      "table,", "theory,", "tower,", "truck,", "upgrade,", "upright,",
>      "utensil,", "vest,", "vision,", "volcano,", "walk,", "watchful,",
>      "window,", "winter,"), class = "factor"), V10 = structure(c(1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"),
>      V11 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "NA,", class = "factor"),
>      V12 = structure(c(2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 1L, 2L), .Label = c("203,",
>      "205,"), class = "factor"), V13 = structure(c(1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "1,", class = "factor"),
>      V14 = c(4063L, 4914L, 1508L, 1819L, 1228L, 992L, 1898L, 1174L,
>      1294L, 1417L)), row.names = c(NA, 10L), class = "data.frame?)
>
> When I use the following:
>
> all.files <- list.files(".")
> txt.files <- grep("threat.txt",all.files,value=T)
>
> for(i in txt.files) {
>    d<-read.table(i, header=FALSE)
>    d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>    write.table(d,paste0(i, "trial.txt"), quote=FALSE, row.names=FALSE)}
>
> I get this (an example of one of the output files with zeros in V13):
>
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14
> 3.17903E+11, threat, 1, 1, 2, 2, 1, useless, flowing, NA, NA, 203, 1, 949
> 3.17903E+11, threat, 3, 2, 2, 1, 1, hostage, skyline, NA, NA, 203, 1, 1116
> 3.17903E+11, threat, 4, 1, 1, 1, 2, messy, ready, NA, NA, 205, 1, 1277
> 3.17903E+11, threat, 6, 2, 1, 2, 2, emaciated, shortened, NA, NA, 205, 1, 691
> 3.17903E+11, threat, 7, 1, 1, 1, 1, abuse, plant, NA, NA, 203, 1, 660
> 3.17903E+11, threat, 8, 2, 1, 2, 2, tormented, easygoing, NA, NA, 205, 1, 812
> 3.17903E+11, threat, 9, 1, 2, 2, 2, hurt, sand, NA, NA, 205, 1, 917
> 3.17903E+11, threat, 10, 1, 1, 1, 1, surgery, freezer, NA, NA, 203, 1, 1829
> 3.17903E+11, threat, 12, 2, 2, 1, 2, accident, category, NA, NA, 205, 1, 821
> 3.17903E+11, threat, 13, 2, 1, 2, 2, terrible, energetic, NA, NA, 205, 1, 783
> 3.17903E+11, threat, 14, 1, 2, 2, 1, wound, storm, NA, NA, 203, 1, 813
> 3.17903E+11, threat, 15, 1, 1, 1, 2, victim, utensil, NA, NA, 205, 1, 1132
> 3.17903E+11, threat, 16, 2, 2, 1, 2, bankrupt, lighting, NA, NA, 203, 0, 1510
> 3.17903E+11, threat, 17, 1, 1, 1, 2, anguish, country, NA, NA, 203, 0, 811
> 3.17903E+11, threat, 18, 2, 2, 1, 1, snake, table, NA, NA, 203, 1, 805
> 3.17903E+11, threat, 19, 1, 1, 1, 2, slap, crop, NA, NA, 205, 1, 1180
> 3.17903E+11, threat, 20, 2, 1, 2, 2, scum, shoe, NA, NA, 205, 1, 792
> 3.17903E+11, threat, 21, 1, 2, 2, 1, weep, shop, NA, NA, 203, 1, 870
> 3.17903E+11, threat, 23, 2, 1, 2, 1, spider, border, NA, NA, 203, 1, 871
>
> str(d) gives me the following:
>
> 'data.frame': 96 obs. of  14 variables:
>   $ V1 : Factor w/ 1 level "9.9761E+11,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V2 : Factor w/ 1 level "threat,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V3 : Factor w/ 96 levels "1,","10,","100,",..: 1 28 37 48 55 63 73 88 2 20 ...
>   $ V4 : Factor w/ 2 levels "1,","2,": 1 2 1 2 2 2 2 2 1 1 ...
>   $ V5 : Factor w/ 2 levels "1,","2,": 2 2 2 1 2 1 1 2 2 2 ...
>   $ V6 : Factor w/ 2 levels "1,","2,": 2 1 2 2 1 2 2 1 2 2 ...
>   $ V7 : Factor w/ 2 levels "1,","2,": 2 1 2 2 2 2 1 2 1 2 ...
>   $ V8 : Factor w/ 95 levels "abduction,","abortion,",..: 41 92 63 36 2 81 12 14 23 33 ...
>   $ V9 : Factor w/ 96 levels "alley,","ankle,",..: 24 90 73 10 92 33 84 96 70 57 ...
>   $ V10: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V11: Factor w/ 1 level "NA,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V12: Factor w/ 2 levels "203,","205,": 2 1 2 2 2 2 1 2 1 2 ...
>   $ V13: Factor w/ 1 level "1,": 1 1 1 1 1 1 1 1 1 1 ...
>   $ V14: int  4063 4914 1508 1819 1228 992 1898 1174 1294 1417 ?
>
> When I use this:
>
> for(i in txt.files) {
>    d<-read.table(i, header=FALSE)
>    d2<-d[d$V13==1,]
>    write.table(d2,sub("[.]",".trial.",i),quote=FALSE,row.names=FALSE)
> }
>
> I get empty files:
>
> str(d2)
> 'data.frame': 0 obs. of  14 variables:
>   $ V1 : Factor w/ 1 level "9.9761E+11,":
>   $ V2 : Factor w/ 1 level "threat,":
>   $ V3 : Factor w/ 96 levels "1,","10,","100,",..:
>   $ V4 : Factor w/ 2 levels "1,","2,":
>   $ V5 : Factor w/ 2 levels "1,","2,":
>   $ V6 : Factor w/ 2 levels "1,","2,":
>   $ V7 : Factor w/ 2 levels "1,","2,":
>   $ V8 : Factor w/ 95 levels "abduction,","abortion,",..:
>   $ V9 : Factor w/ 96 levels "alley,","ankle,",..:
>   $ V10: Factor w/ 1 level "NA,":
>   $ V11: Factor w/ 1 level "NA,":
>   $ V12: Factor w/ 2 levels "203,","205,":
>   $ V13: Factor w/ 1 level "1,":
>   $ V14: int
>
> When I use as.integer to change V13 to an integer, the output of this column is replaced by 1s and 2s..
>
>
>> On Apr 21, 2020, at 1:14 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Thanks for the data. But since the replacements still do not work, please post the output of
>>
>> dput(head(d, 10))
>>
>>
>> in order for us to have an *exact* copy of the data structure.
>> I had asked for 20 or 30 rows but given your post 10 are enough.
>> With a way to exactly reproduce what you have, it will be much easier to try code and find a solution. I, and I believe most R users, will run
>>
>> str(d)
>>
>> as one of the first steps to know what is in that problem column. And go from there.
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 04:52 de 21/04/20, Helen Sawaya escreveu:
>>> Thank you all for your input.
>>> This is an example of one data file (I have 74 data files):
>>> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,            NA,           NA,  205,    0,  394
>>> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,            NA,           NA,  205,    0,  502
>>> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,            NA,           NA,  205,    1,  468
>>> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,            NA,           NA,  203,    1,  345
>>> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,            NA,           NA,  205,    1,  373
>>> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,            NA,           NA,  205,    1,  343
>>> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,            NA,           NA,  203,    1,  437
>>> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,            NA,           NA,  203,    1,  343
>>> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,            NA,           NA,  203,    1,  441
>>> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,            NA,           NA,  205,    1,  475
>>> ?Column 13 has values of 0s and 1s which my cognitive task outputted. Column 14 is the reaction time (ms) data. I want to get rid of the rows that contain zeros so I thought I'd first replace zeros with NAs then use complete.cases function to get rid of the NAs. I also wanted to apply other functions so I included them all in a loop. All work fine except for the one where I try to turn the zeros to NAs.
>>> Jim when I tried your mockdata example, it worked fine. But when I translated it to my data, I still get zeros in the output. Can you identify any mistranslations I'm doing?
>>> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text files in one folder
>>> for(tf in txt.files) {
>>>    d<-read.table(tf)
>>>    d[,13][d[,13]==0]<-NA #column 13 contains zeros
>>>    d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>>>    write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
>>> }
>>> That's an example of one of the output I get:
>>> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
>>> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
>>> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
>>> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
>>> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
>>> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
>>> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>>> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
>>> After all the data cleaning, the functions I'm interested in including in the loop are: get_tlbs and summarize_bias (and these also work fine in my loop).
>>> Thanks again ?
>>> Sincerely
>>> Helen
>>> ------------------------------------------------------------------------
>>> *From:* Jim Lemon <drjimlemon at gmail.com>
>>> *Sent:* Tuesday, April 21, 2020 2:52 AM
>>> *To:* Rui Barradas <ruipbarradas at sapo.pt>
>>> *Cc:* Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
>>> *Subject:* Re: [R] NA command in a 'for' loop
>>> Hi Helen,
>>> Your problem may lie in using row.names=TRUE. I was puzzled when an
>>> extra column kept popping up in the output files. For reading in and
>>> replacing zeros with NAs, this seems to work:
>>> for(mockdata in 1:3) {
>>>   mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>>>   write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>>>    row.names=FALSE,col.names=FALSE)
>>> }
>>> txt.files<-list.files(".",pattern="threat[1-3]")
>>> for(tf in txt.files) {
>>>   d<-read.table(tf)
>>>   d[,3][d[,3]==0]<-NA
>>>   write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
>>> }
>>> Jim
>>> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I believe the only way we have to see what is happening is for you to
>>>> post the output of
>>>>
>>>>
>>>> dput(head(d, 20))  # or 30
>>>>
>>>>
>>>> or, with d2 a subset of d that includes zeros,
>>>>
>>>>
>>>> dput(head(d2, 20))
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
>>>>> I have one column that represents correct response versus error (correct
>>>>> is coded as 1 and error is coded as 0). Nowhere else in the dataset are
>>>>> there values of 0. The vector is treated as an integer.
>>>>> ------------------------------------------------------------------------
>>>>> *From:* Michael Dewey <lists at dewey.myzen.co.uk>
>>>>> *Sent:* Monday, April 20, 2020 7:35 PM
>>>>> *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
>>>>> <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
>>>>> *Subject:* Re: [R] NA command in a 'for' loop
>>>>> Just a thought Helen but is x being treated as a real and what you think
>>>>> are zero and are printed as zero are in fact some very small number? If
>>>>> so you need to alter your test appropriately.
>>>>>
>>>>> Michael
>>>>>
>>>>> On 20/04/2020 17:25, Helen Sawaya wrote:
>>>>>> Thank you for your reply.
>>>>>>
>>>>>> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>>>>> but I am still getting zeros instead of NAs in my output..
>>>>>>
>>>>>> I wonder if the problem is that some of my data files don't have any zeros (participants made no errors)..
>>>>>> ________________________________
>>>>>> From: Rui Barradas <ruipbarradas at sapo.pt>
>>>>>> Sent: Monday, April 20, 2020 9:05 AM
>>>>>> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org <r-help at R-project.org>
>>>>>> Subject: Re: [R] NA command in a 'for' loop
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Instead of
>>>>>>
>>>>>> d[d == 0] <- NA
>>>>>>
>>>>>> try
>>>>>>
>>>>>> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
>>>>>>
>>>>>>
>>>>>> Also, in the first for loop
>>>>>>
>>>>>> paste(i, sep = "")
>>>>>>
>>>>>> does nothing, it's the same as i.
>>>>>> And the same for
>>>>>>
>>>>>> (d2$V4 == 1) == TRUE
>>>>>>
>>>>>> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
>>>>>>
>>>>>> (.) == TRUE
>>>>>>
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>>
>>>>>>
>>>>>> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
>>>>>>> Dear R experts,
>>>>>>>
>>>>>>> I am using a 'for' loop to apply commands to multiple datasets (each file is one participant). The only one not working is the command that identifies zeros in my datasets and changes them to NAs. But when I look at the output, zeros ("0") are still present. Surprisingly, the functions work fine when I apply them to a single
>>>>> dataset (outside the loop). I've tried:
>>>>>>>
>>>>>>> all.files <- list.files(".")
>>>>>>> txt.files <- grep("threat.txt",all.files,value=T)
>>>>>>>
>>>>>>> for(i in txt.files){
>>>>>>>      d <- read.table(paste(i,sep=""),header=F)
>>>>>>>      d[d==0] <- NA #replace zeros with NA
>>>>>>>      write.table(d, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>      d<-d[ ,-c(10,11)]
>>>>>>>      d2<-d[complete.cases(d), ]
>>>>>>>      d2$V4<-as.numeric(d2$V4)
>>>>>>>      congruent <- (d2$V4 == 1) == TRUE
>>>>>>>      x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>>>>>      write.table(x, paste0(i,".tlbs.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>
>>>>>>> I've also tried:
>>>>>>>
>>>>>>> for(i in txt.files){
>>>>>>>      d <- read.table(paste(i,sep=""),header=F)
>>>>>>>      if (0 %in% d)
>>>>>>>      {replace_with_na(d,replace = list(x = 0))} # replace zeros with NA
>>>>>>>      d<-d[ ,-c(10,11)]
>>>>>>>      d2<-d[complete.cases(d), ]
>>>>>>>      d2$V4<-as.numeric(d2$V4)
>>>>>>>      congruent <- (d2$V4 == 1) == TRUE
>>>>>>>      x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method = "weighted", fill_gaps = FALSE)
>>>>>>>      write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE, row.names=TRUE)}
>>>>>>>
>>>>>>> Thank you for your help.
>>>>>>> Sincerely
>>>>>>> Helen
>>>>>>>
>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Michael
>>>>> http://www.dewey.myzen.co.uk/home.html
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Apr 22 00:29:17 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Tue, 21 Apr 2020 15:29:17 -0700
Subject: [R] Subtracting Data Frame With a Different Number of Rows
In-Reply-To: <4685A5060D104647A9F78F566F42EF8F@OWNERPC>
References: <4685A5060D104647A9F78F566F42EF8F@OWNERPC>
Message-ID: <CAA99HCwSEe=g_kmH=52kyyOjgALTQdREYu+Ss0Bv0PqCwCbVQg@mail.gmail.com>

Hi Phillip,

You have two choices here: 1. Manually enter the missing rows into
your individual.df using rbind(), and cbind() the overall.df and
individual.df dataframes together (assuming the rows line up
properly), or 2. Use merge() to perform an SQL-like "Left Join", and
copy values from the "overall" columns to fill in missing values in
the "indiv" columns (imputation). Below is code starting from a .tsv
files showing the second (merge) method. Note: I've only included the
first 4 rows of data after the merge command (there are 24 rows
total):

> overall <- read.delim("overall.R", sep="\t")
> indiv <- read.delim("individual.R", sep="\t")
> merge(overall, indiv, all.x=TRUE, by.x=c("RunnerCode", "Outs"), by.y=c("RunnerCode", "Outs"))

        RunnerCode Outs X.x MeanRuns.x X.y MeanRuns.y
1       BasesEmpty    0   1  0.5137615   1  0.4262295
2       BasesEmpty    1   9  0.3963801   8  0.5238095
3       BasesEmpty    2  17  0.4191011  15  0.3469388
4      BasesLoaded    0   8  3.2173913  NA         NA


HTH, Bill.

W. Michels, Ph.D.


On Tue, Apr 21, 2020 at 1:47 PM Phillip Heinrich <herd_dog at cox.net> wrote:
>
> I have two small data frames of baseball data.  The first one is the mean
> number of runs that will score in each half inning for the 2018 Arizona
> Diamondbacks.  The second data frame is the same information but for only
> one player.  As you will see the individual player did not come up to bat
> any time during the season:
>     with the bases loaded and no outs
>     runners on first and third with one out
>
> Overall
>
> RunnerCode                Outs     MeanRuns
> 1 Bases Empty             0           0.5137615
> 2 Runner:1st                0           0.8967391
> 3 Runner:2nd               0           1.3018868
> 4 Runners:1st & 2nd    0           1.6551724
> 5 Runner:3rd                0           1.9545455
> 6 Runners:1st & 3rd     0           2.0571429
> 7 Runners:2nd & 3rd    0           2.1578947
> 8 Bases Loaded            0           3.2173913
> 9 Bases Empty              1           0.3963801
> 10 Runner:1st               1           0.6952596
> 11 Runner:2nd              1           0.9580838
> 12 Runners:1st & 2nd   1           1.4397163
> 13 Runner:3rd               1           1.5352113
> 14 Runners:1st & 3rd   1            1.5882353
> 15 Runners:2nd & 3rd  1            1.9215686
> 16 Bases Loaded          1            1.9193548
> 17 Bases Empty            2            0.4191011
> 18 Runner:1st               2            0.5531915
> 19 Runner:2nd              2            0.8777293
> 20 Runners:1st & 2nd  2             0.9553073
> 21 Runner:3rd              2             1.2783505
> 22 Runners:1st & 3rd   2             1.5851064
> 23 Runners:2nd & 3rd  2             1.2794118
> 24 Bases Loaded         2              1.388235
>
> Individual Player
>
>   RunnerCode              Outs           MeanRuns
> 1 Bases Empty             0                 0.4262295
> 2 Runner:1st                0                 1.3200000
> 3 Runner:2nd               0                 1.2857143
> 4 Runners:1st & 2nd   0                  0.5714286
> 5 Runner:3rd               0                  2.0000000
> 6 Runners:1st & 3rd    0                  3.5000000
> 7 Runners:2nd & 3rd   0                  1.0000000
> 8 Bases Empty             1                  0.5238095
> 9 Runner:1st                1                  0.6578947
> 10 Runner:2nd             1                  0.3750000
> 11 Runners:1st & 2nd 1                   1.4285714
> 12 Runner:3rd             1                   1.4285714
> 13 Runners:2nd & 3rd 1                   0.6666667
> 14 Bases Loaded         1                   3.0000000
> 15 Bases Empty           2                   0.3469388
> 16 Runner:1st              2                   0.1363636
> 17 Runner:2nd             2                   0.7142857
> 18 Runners:1st & 2nd  2                   1.6666667
> 19 Runner:3rd              2                   1.2500000
> 20 Runners:1st & 3rd  2                    2.1428571
> 21 Runners:2nd & 3rd 2                    1.5000000
> 22 Bases Loaded         2                    2.2000000
>
> RunnersCode is a factor
> Outs are integers
> MeanRuns is numerical data
>
> I would like to subtract the second from the first as a way to evaluate the
> players ability to produce runs. As part of this analysis I I would like to
> input the mean number of runs from the overall data frame into the two
> missing cells for the individual player:Bases Loaded no outs and 1st and 3rd
> one out.
>
> Can anyone give me some advise?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Apr 22 08:38:44 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 22 Apr 2020 08:38:44 +0200
Subject: [R] ggplot2 error bars and convex hulls
In-Reply-To: <d9d2d424-36be-e7b8-86ef-9b65a824469e@sapo.pt>
References: <84c98d4e-17bf-8b68-5790-057bffa1d9d1@rgzm.de>
 <d9d2d424-36be-e7b8-86ef-9b65a824469e@sapo.pt>
Message-ID: <5387e7e3-5062-d939-60b3-f3018780c23c@rgzm.de>

Thanks Rui for these 2 possibilities; I'll have a look.

Any one with pointers for the error bars issue?

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 21/04/2020 19:06, Rui Barradas wrote:
> Hello,
>
> As for convex hulls, there is an example of how to construct a
> stat_hull in
>
> vignette("extending-ggplot2", package = "ggplot2")
>
> There is also a geom_hull in a GitHub package:
>
> devtools::install_github("cmartin/ggConvexHull")
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 17:02 de 21/04/20, Ivan Calandra escreveu:
>> Dear useRs,
>>
>> I would like to have horizontal and vertical error bars extending from
>> the means on two continuous variables.
>>
>> This would be the "manual" way of doing it, computing the mean and sd
>> (or whatever stats) beforehand and then calling geom_errorbar() and
>> geom_errorbarh() with appropriate coordinates:
>> https://stackoverflow.com/questions/12570816/ggplot-scatter-plot-of-two-groups-with-superimposed-means-with-x-and-y-error-bar
>>
>>
>> But I am a bit surprised that there is no "built-in" way of doing it
>> with ggplot2. I mean not having to compute mean and sd beforehand and
>> not having to call both geom_errorbar() and geom_errorbarh() with a new
>> set of aesthetics.
>>
>> In the same idea, I am looking at convex hulls and I was also expecting
>> to have a built-in way to do this in ggplot2. But I have only found this
>> "manual" way:
>> https://stats.stackexchange.com/questions/22805/how-to-draw-neat-polygons-around-scatterplot-regions-in-ggplot2
>>
>>
>> Thank you in advance for any pointer.
>> Ivan
>>
>


From M@rk@Purver @end|ng |rom Ju@t|ce@gov@uk  Tue Apr 21 19:44:23 2020
From: M@rk@Purver @end|ng |rom Ju@t|ce@gov@uk (Purver, Mark)
Date: Tue, 21 Apr 2020 17:44:23 +0000
Subject: [R] Changes to stats::glm function between R versions 3.4.0 and
 3.5.1
In-Reply-To: <24219.7990.267854.272291@stat.math.ethz.ch>
References: <LO2P123MB2205DC4A5BD853CDF88B0A49C0D80@LO2P123MB2205.GBRP123.PROD.OUTLOOK.COM>
 <24219.7990.267854.272291@stat.math.ethz.ch>
Message-ID: <LO2P123MB2205CD1046A987526776FA46C0D50@LO2P123MB2205.GBRP123.PROD.OUTLOOK.COM>

Dear Martin,

Thanks so much for this response. I have attempted a reproducible example below. The 'real' issue involves a much larger data set, but the very small example below produces very small differences in the standard errors between different R versions, which may have the same root cause. I hope to understand whether such differences indicate any change to the 'glm' function between version 3.4.0 of the 'stats' package and later versions. These differences are only apparent when the model does not converge.

Thanks,
Mark


dat <- data.frame(
  a = c(1, 3, 8, 9, 2, 3, 4, 5),
  b = c(1, 3, 8, 8, 2, 3, 4, 5),
  x = c(1, 0, 0, 1, 0, 0, 0, 0)
)

m <- glm(x~a+b, family=binomial(), data=dat)

print(summary(m)))

# Standard errors of variables 'a' and 'b' are 580356.74 and 638232.37 in R 3.4.0, but 580356.25 and 638231.93 in R 3.4.2
________________________________
 This e-mail and any attachments is intended only for the attention of the addressee(s). Its unauthorised use, disclosure, storage or copying is not permitted. If you are not the intended recipient, please destroy all copies and inform the sender by return e-mail. Internet e-mail is not a secure medium. Any reply to this message could be intercepted and read by someone else. Please bear that in mind when deciding whether to send material in response to this message by e-mail. This e-mail (whether you are the sender or the recipient) may be monitored, recorded and retained by the Ministry of Justice. Monitoring / blocking software may be used, and e-mail content may be read at any time. You have a responsibility to ensure laws are not broken when composing or forwarding e-mails and their contents.


From ju||e @end|ng |rom e-po|tev|n@|r  Tue Apr 21 23:32:07 2020
From: ju||e @end|ng |rom e-po|tev|n@|r (Julie Poitevin)
Date: Tue, 21 Apr 2020 23:32:07 +0200
Subject: [R] Data frames intersections
Message-ID: <ECD4280C-0CF4-4491-BC85-92D640F35A9D@e-poitevin.fr>

Hello, 
> I want to build a map (bus accessibility map) and for that I need to identify some polygons intersections. To do that I have 2 data.frame: batiments (that gives buildings in a city) and arrets_buffer (that gives bus stops (points) with a buffer around the point).
> 
> I want to have a column giving the intersect binary result (TRUE or FALSE) in batiments data.frame. I use st_intersects from sf package.
> 
> For that I wanted to perform this loop, but it's not a good idea:
> 
> for (i in nrow(arrets_buffer)) {
>   batiments$in_recharges <- st_intersects(x = batiments, arrets_buffer[i,], sparse = FALSE)
> }
> 
> each time i is incremented, batiments$in_recharges is removed with new values. So at the end I have results for i=nrow(arrets_buffer) only....
> 
> No possibility to add a loop in the loop as the number of lines is quite important (the loop will turns a long time..)
> 
> Do you have some some idea to help me?
> 
> Many thanks for your help

	[[alternative HTML version deleted]]


From bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com  Wed Apr 22 04:41:44 2020
From: bh@@k@r@ko|k@t@ @end|ng |rom gm@||@com (Bhaskar Mitra)
Date: Tue, 21 Apr 2020 19:41:44 -0700
Subject: [R] Help to download data from multiple URLs with API key
In-Reply-To: <CAGgJW76VB3Sv_qQ_RMgHAk70oEdcpaWDZrhJp9Or7t-GGpZ8Vw@mail.gmail.com>
References: <CAEGXkYUjOjD8uj3=LQy+vyVWYY1YzxLik79OYJvhfhXe_UecbQ@mail.gmail.com>
 <CAGgJW76VB3Sv_qQ_RMgHAk70oEdcpaWDZrhJp9Or7t-GGpZ8Vw@mail.gmail.com>
Message-ID: <CAEGXkYXWqw9NyiUkXQkMg-vm-66VkVf-fy9na8QpwTyXTvqo-w@mail.gmail.com>

Hi Eric,

Thanks for your help. This is really helpful.
I have also adjusted the code to ensure  filename has the
base url and suffix as strings.

thanks,
bhaskar

On Tue, Apr 21, 2020 at 12:16 AM Eric Berger <ericjberger at gmail.com> wrote:

> Hi Bhaskar,
> Why not just create a function that does the repetitive work, such as
>
> doOne <- function( suffix ) {
>    base_url <- "abcd"         # This remains constant
>    b <-  "api_key"            # the api key - this remains constant
>    c <-  paste("series_id=",suffix,sep="")
>    full_url = paste0(base_url, b, c)
>    d3 <- lapply(fromJSON(file=full_url)[[2]], function(x) c(x["data"]))
>    d3 <- do.call(rbind, d3)
>    b <- as.data.frame(unlist(d3))
>    write.csv(b)
> }
>
> Then,
> suffixes <- ... (whatever)
> for ( s in suffixes )
>     doOne( s )
>
> You might need to also think about the filenames that you want to use in
> the write.csv() command in the function doOne.
>
> HTH,
> Eric
>
>
> On Tue, Apr 21, 2020 at 9:30 AM Bhaskar Mitra <bhaskar.kolkata at gmail.com>
> wrote:
>
>> Hello Everyone,
>>
>> I am trying to download data from multiple websites using API key.
>> The  code to download from one URL is given below.
>>
>> I have a list of multiple URLs' where the suffix URL 'c' keeps changing.
>>
>> I would appreciate any help on how i can modify the code below that will
>> allow
>>  me to read multiple URLs and save the data from each URL as separate
>> csv file.
>>
>> thanks,
>> bhaskar
>>
>>
>> #-----------------------------------------------------------------------
>> library(rjson)
>> setwd(Input)
>>
>> base_url <- "abcd"         # This remains constant
>>
>> b <-  "api_key"            # the api key - this remains constant
>>
>> c <-  "series_id=1"        # Only this suffix URL changes.  I have a list
>> of multiple such URL's with different series ids.
>>
>>
>> full_url = paste0(base_url,
>>                   b,
>>                   c)
>>
>>
>> d3 <- lapply(fromJSON(file=full_url)[[2]], function(x) c(x["data"]))
>> d3 <- do.call(rbind, d3)
>>
>> b <- as.data.frame(unlist(d3))
>> write.csv(b)
>>
>> #-----------------------------------------------------------------------
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Apr 22 11:07:59 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 22 Apr 2020 19:07:59 +1000
Subject: [R] Data frames intersections
In-Reply-To: <ECD4280C-0CF4-4491-BC85-92D640F35A9D@e-poitevin.fr>
References: <ECD4280C-0CF4-4491-BC85-92D640F35A9D@e-poitevin.fr>
Message-ID: <CA+8X3fUmxkR=SHrCQabz+8=QfPwsXo-RAHvLz-YxzrA9AMsjDg@mail.gmail.com>

Hi Julie,
Your task is a bit obscure and I don't have the function
"st_intersects", but I'll suggest this:

br_list<-list()
# your commands would have only run once
for (i in 1:nrow(arrets_buffer)) {
  br_list[[i]]<- st_intersects(x = batiments, arrets_buffer[i,], sparse = FALSE)
}

You should get a list with nrow(arrets_buffer) elements, each of which
will be the result of your "st_intersects" function.

Jim

On Wed, Apr 22, 2020 at 6:00 PM Julie Poitevin <julie at e-poitevin.fr> wrote:
>
> Hello,
> > I want to build a map (bus accessibility map) and for that I need to identify some polygons intersections. To do that I have 2 data.frame: batiments (that gives buildings in a city) and arrets_buffer (that gives bus stops (points) with a buffer around the point).
> >
> > I want to have a column giving the intersect binary result (TRUE or FALSE) in batiments data.frame. I use st_intersects from sf package.
> >
> > For that I wanted to perform this loop, but it's not a good idea:
> >
> > for (i in nrow(arrets_buffer)) {
> >   batiments$in_recharges <- st_intersects(x = batiments, arrets_buffer[i,], sparse = FALSE)
> > }
> >
> > each time i is incremented, batiments$in_recharges is removed with new values. So at the end I have results for i=nrow(arrets_buffer) only....
> >
> > No possibility to add a loop in the loop as the number of lines is quite important (the loop will turns a long time..)
> >
> > Do you have some some idea to help me?
> >
> > Many thanks for your help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mon|c@p@|@|ovejoy @end|ng |rom gm@||@com  Wed Apr 22 14:31:04 2020
From: mon|c@p@|@|ovejoy @end|ng |rom gm@||@com (Monica Palaseanu-Lovejoy)
Date: Wed, 22 Apr 2020 08:31:04 -0400
Subject: [R] ggraph and changing colors in geom_node_arc_bar
Message-ID: <CABnpDg1TfhUtGr9wr_1nhoFwH23PgTcKUAZz68r9Jgjhp-3eYQ@mail.gmail.com>

 Hi,

I am playing with the ggraph that is amazing. But i don't quite understand
some of the options it has. For example:

gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)

l <- ggraph(gr, layout = 'partition', circular = TRUE)
l + geom_node_arc_bar(aes(fill = depth)) +
    coord_fixed()

This will give a nice graph in shades of blue.
But if i want to change the fill aesthetic with a grey scale for example:

l + geom_node_arc_bar(aes(fill = grey(seq(0,1,length=252)))) +
    coord_fixed() +
theme(legend.position = "none")

This will give a graphic with set colors that definitely are not on a grey
scale. So i am missing a piece in my code.
I tried to add scale_edge_fill_manual(values= grey(seq(0,1,length=252)))
but to no avail, and besides this has to do with edges and not nodes. So
this is not the solution.

What i am doing wrong, or what i am missing from my command?

Also i am interested how the graph and ggraph plots, in the sense in what
order is the data plotted? I am interested in that because i may want to
set up either colors or widths of edges separately from my graph data for
visualization.

Thanks,
Monica

	[[alternative HTML version deleted]]


From c@deb @end|ng |rom u@g@@gov  Wed Apr 22 16:31:51 2020
From: c@deb @end|ng |rom u@g@@gov (Cade, Brian S)
Date: Wed, 22 Apr 2020 14:31:51 +0000
Subject: [R] overlaying graphs in xYplot (Hmisc)
Message-ID: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>

Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?

Brian


Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
tel:  970 226-9326


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 22 16:56:06 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Apr 2020 07:56:06 -0700
Subject: [R] overlaying graphs in xYplot (Hmisc)
In-Reply-To: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
References: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
Message-ID: <CAGxFJbTyTKDA8z=kVgpB4-XsZVajBQOjWY66Bp0QreEFhrSuew@mail.gmail.com>

Reproducible example with data via dput?
Code that you used that 'didn't work'?
Error messages or output and why it was not satisfactory?

Following the posting guide by providing such information is more
likely to generate useful answers and save both you and those who try
to help a lot of wasted time guessing.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 22, 2020 at 7:32 AM Cade, Brian S via R-help
<r-help at r-project.org> wrote:
>
> Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?
>
> Brian
>
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Apr 22 19:10:16 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 22 Apr 2020 10:10:16 -0700
Subject: [R] overlaying graphs in xYplot (Hmisc)
In-Reply-To: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
References: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
Message-ID: <818087e9-e3bc-36d7-f23b-e45a3d58fc69@comcast.net>


On 4/22/20 7:31 AM, Cade, Brian S via R-help wrote:
> Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?


I don't know the answer and you have presented no data or code, so I'm 
just going to address the question in the most halting and vague manner 
by first looking at the code and then looking at the documentaion. 
(That's possibly the reverse of the proper order.) The plotting 
functions in pkg:Hmisc can be in any of the three plotting paradigms. If 
you look at the code for xYplot it becomes almost immediately obvious 
that it is operative within the lattice plotting paradigm. (That means 
that using `new=T` or `add=T` would not work since those are base 
plotting strategies.)


I'm not sure what the term "Cbind argument" might mean to you (and I've 
never used it), but I suspect you are intending to use a call to `Cbind` 
on the left hand side of a formula argument for xYplot.

Re: The goal of "plotting the median, 10th, and 90th quantiles and also 
the cbind() argument for individual data values."

It appears to me from the documentation that you would be expected to do some pre-processing to aggregate your data into a summary format by groups before plotting and then use named arguments to Cbind to designate the appropriate columns to be used for median and the outer quantiles. See the example using the dataset named dfr in the ?xYplot page following these comments:

# The following example uses the summarize function in Hmisc to
# compute the median and outer quartiles.  The outer quartiles are
# displayed using "error bars"

It should be trivial to modify the call to `summarize` to get .1 and .9 quantiles instead of quartiles.

-- 
David.



>
> Brian
>
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@deb @end|ng |rom u@g@@gov  Wed Apr 22 20:14:06 2020
From: c@deb @end|ng |rom u@g@@gov (Cade, Brian S)
Date: Wed, 22 Apr 2020 18:14:06 +0000
Subject: [R] [EXTERNAL] Re:  overlaying graphs in xYplot (Hmisc)
In-Reply-To: <818087e9-e3bc-36d7-f23b-e45a3d58fc69@comcast.net>
References: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>,
 <818087e9-e3bc-36d7-f23b-e45a3d58fc69@comcast.net>
Message-ID: <BY5PR09MB5073E7D8349ACF3D5513407AD9D20@BY5PR09MB5073.namprd09.prod.outlook.com>

All the xYplot() functions using Cbind() or cbind() does just exactly what I want (Cbind provides aplot of 3 summary statistics and cbind provides the raw values).  I just cannot find anyway to overlay them.

Brian


Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
tel:  970 226-9326

________________________________
From: David Winsemius <dwinsemius at comcast.net>
Sent: Wednesday, April 22, 2020 11:10 AM
To: Cade, Brian S <cadeb at usgs.gov>; r-help <r-help at r-project.org>
Subject: [EXTERNAL] Re: [R] overlaying graphs in xYplot (Hmisc)


On 4/22/20 7:31 AM, Cade, Brian S via R-help wrote:
> Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?


I don't know the answer and you have presented no data or code, so I'm
just going to address the question in the most halting and vague manner
by first looking at the code and then looking at the documentaion.
(That's possibly the reverse of the proper order.) The plotting
functions in pkg:Hmisc can be in any of the three plotting paradigms. If
you look at the code for xYplot it becomes almost immediately obvious
that it is operative within the lattice plotting paradigm. (That means
that using `new=T` or `add=T` would not work since those are base
plotting strategies.)


I'm not sure what the term "Cbind argument" might mean to you (and I've
never used it), but I suspect you are intending to use a call to `Cbind`
on the left hand side of a formula argument for xYplot.

Re: The goal of "plotting the median, 10th, and 90th quantiles and also
the cbind() argument for individual data values."

It appears to me from the documentation that you would be expected to do some pre-processing to aggregate your data into a summary format by groups before plotting and then use named arguments to Cbind to designate the appropriate columns to be used for median and the outer quantiles. See the example using the dataset named dfr in the ?xYplot page following these comments:

# The following example uses the summarize function in Hmisc to
# compute the median and outer quartiles.  The outer quartiles are
# displayed using "error bars"

It should be trivial to modify the call to `summarize` to get .1 and .9 quantiles instead of quartiles.

--
David.



>
> Brian
>
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 22 20:53:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 22 Apr 2020 11:53:24 -0700
Subject: [R] [EXTERNAL] Re: overlaying graphs in xYplot (Hmisc)
In-Reply-To: <BY5PR09MB5073E7D8349ACF3D5513407AD9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
References: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
 <818087e9-e3bc-36d7-f23b-e45a3d58fc69@comcast.net>
 <BY5PR09MB5073E7D8349ACF3D5513407AD9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
Message-ID: <CAGxFJbR7eDuivNtDDDFojqxKA9X1hpBZB=RDYLLpgauQeDXaVQ@mail.gmail.com>

In lattice, e.g. xyplot, one simply uses panel functions to "overlay"
various constructs (point plots, smooth curves, text, etc.). If that
is relevant and you do not know about it, then you have homework to
do. ?xyplot or Deepayan's book or tutorials would be places to start
for that. Otherwise, ??.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 22, 2020 at 11:14 AM Cade, Brian S via R-help
<r-help at r-project.org> wrote:
>
> All the xYplot() functions using Cbind() or cbind() does just exactly what I want (Cbind provides aplot of 3 summary statistics and cbind provides the raw values).  I just cannot find anyway to overlay them.
>
> Brian
>
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
> ________________________________
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: Wednesday, April 22, 2020 11:10 AM
> To: Cade, Brian S <cadeb at usgs.gov>; r-help <r-help at r-project.org>
> Subject: [EXTERNAL] Re: [R] overlaying graphs in xYplot (Hmisc)
>
>
> On 4/22/20 7:31 AM, Cade, Brian S via R-help wrote:
> > Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?
>
>
> I don't know the answer and you have presented no data or code, so I'm
> just going to address the question in the most halting and vague manner
> by first looking at the code and then looking at the documentaion.
> (That's possibly the reverse of the proper order.) The plotting
> functions in pkg:Hmisc can be in any of the three plotting paradigms. If
> you look at the code for xYplot it becomes almost immediately obvious
> that it is operative within the lattice plotting paradigm. (That means
> that using `new=T` or `add=T` would not work since those are base
> plotting strategies.)
>
>
> I'm not sure what the term "Cbind argument" might mean to you (and I've
> never used it), but I suspect you are intending to use a call to `Cbind`
> on the left hand side of a formula argument for xYplot.
>
> Re: The goal of "plotting the median, 10th, and 90th quantiles and also
> the cbind() argument for individual data values."
>
> It appears to me from the documentation that you would be expected to do some pre-processing to aggregate your data into a summary format by groups before plotting and then use named arguments to Cbind to designate the appropriate columns to be used for median and the outer quantiles. See the example using the dataset named dfr in the ?xYplot page following these comments:
>
> # The following example uses the summarize function in Hmisc to
> # compute the median and outer quartiles.  The outer quartiles are
> # displayed using "error bars"
>
> It should be trivial to modify the call to `summarize` to get .1 and .9 quantiles instead of quartiles.
>
> --
> David.
>
>
>
> >
> > Brian
> >
> >
> > Brian S. Cade, PhD
> >
> > U. S. Geological Survey
> > Fort Collins Science Center
> > 2150 Centre Ave., Bldg. C
> > Fort Collins, CO  80526-8818
> >
> > email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> > tel:  970 226-9326
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 22 22:20:52 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 23 Apr 2020 08:20:52 +1200
Subject: [R] Can I use R for comertial projects for free?
In-Reply-To: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
References: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
Message-ID: <CAB8pepzW-b1n8hCkwSpi6DKS9G648rZVmAmScS41wQuasNz5pw@mail.gmail.com>

It is legal (subject to licensing conditions), as mentioned by Duncan and Jeff.

However, I would like to add two comments:
(1) If you use R in publications/reports, I strongly recommend you cite R.
(2) If you benefit from R, I strongly recommend contributing to R, in some form.

This could include hiring R programmers for more than the absolute
bare minimum of R work.
Noting that none of the employers in my country, except possibly
universities (and even then not much), are interested in cultivating
employees with significant R expertise.

It could also include making donations to the R Foundation, or
offering web hosting.
Anything is better than nothing...


On Wed, Apr 22, 2020 at 4:00 AM dmitry sergey <dmitry.sergey at gmail.com> wrote:
>
> Hi,
>
> I kindly interesting can i use R for commercial projects for free? I am
> going to get statistics in my commercial project with R and wanted to know
> will it be legal or no?
>
> Thanks in advance.
>
> Best Regards,
> Dmitry
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Wed Apr 22 23:04:14 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 23 Apr 2020 09:04:14 +1200
Subject: [R] Can I use R for comertial projects for free?
In-Reply-To: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
References: <CAADCDiBUBTTR-_a2PStqkvUMfv7tPfd8omWKMXsiOY0Wk5GrYQ@mail.gmail.com>
Message-ID: <CABcYAdKQcGmgAqoKkJg23v27O1HeW5R1sHmkAb37hZS-frw_KA@mail.gmail.com>

I cannot tell from your message whether
(a) your project is a statistical consulting one and you want to
     use R to do the calculations and graphics for it, but will not
     give your client R itself,or
(b) your project will deliver software to the client, and that
     software will include a copy of R.

In case (a), the answer is "of course you can".
In case (b), see the other replies.  But had you considered just
providing a little (shell or PowerShell) script your client can run
to download and install R themselves?

On Wed, 22 Apr 2020 at 04:00, dmitry sergey <dmitry.sergey at gmail.com> wrote:
>
> Hi,
>
> I kindly interesting can i use R for commercial projects for free? I am
> going to get statistics in my commercial project with R and wanted to know
> will it be legal or no?
>
> Thanks in advance.
>
> Best Regards,
> Dmitry
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Thu Apr 23 00:29:15 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Wed, 22 Apr 2020 22:29:15 +0000 (UTC)
Subject: [R] Add GAM fit on the plot ?
References: <1503431427.21637.1587594555500.ref@mail.yahoo.com>
Message-ID: <1503431427.21637.1587594555500@mail.yahoo.com>

Dear R-experts,

Here below the reproducible example. I can not add the "green" gam curve on the plot. The last line of my R code gives me problem. There is a message error that I don't understand. Many thanks for your precious help.

#######################################################
a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))

b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)

df<-data.frame(a,b)

plot(as.Date(a),b,pch=16,type="o",col="blue",ylab="nombre de nouveaux cas covid19",xlab="Dates", main="Nombre d?infect?s quotidien Covid-19 en Suisse" ,ylim=c(20,460), xlim=c(min(as.Date(a)),max(as.Date(a))))

##### fit loess curve with family symmetric
loess.smooth(a,b, span = 2/3, degree = 1,???? family = c("symmetric"))
lines(loess.smooth(a,b, span = 2/3, degree = 1,???? family = "symmetric"),col="purple")

d <-as.numeric(a)

##### Fit GAM
library(mgcv)
fit <- gam(b ~ s(d, bs="cr"),data=df)
summary(fit) 
lines(gam(b ~ s(d, bs="cr"),data=df,col="green"))
############################################################


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Apr 23 01:30:09 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 22 Apr 2020 16:30:09 -0700
Subject: [R] Add GAM fit on the plot ?
In-Reply-To: <1503431427.21637.1587594555500@mail.yahoo.com>
References: <1503431427.21637.1587594555500.ref@mail.yahoo.com>
 <1503431427.21637.1587594555500@mail.yahoo.com>
Message-ID: <a78ac7b0-ab44-1521-3b91-57be38d72348@comcast.net>


On 4/22/20 3:29 PM, varin sacha via R-help wrote:
> Dear R-experts,
>
> Here below the reproducible example. I can not add the "green" gam curve on the plot. The last line of my R code gives me problem. There is a message error that I don't understand. Many thanks for your precious help.
>
> #######################################################
> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
>
> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
>
> df<-data.frame(a,b)
>
> plot(as.Date(a),b,pch=16,type="o",col="blue",ylab="nombre de nouveaux cas covid19",xlab="Dates", main="Nombre d?infect?s quotidien Covid-19 en Suisse" ,ylim=c(20,460), xlim=c(min(as.Date(a)),max(as.Date(a))))
>
> ##### fit loess curve with family symmetric
> loess.smooth(a,b, span = 2/3, degree = 1,???? family = c("symmetric"))
> lines(loess.smooth(a,b, span = 2/3, degree = 1,???? family = "symmetric"),col="purple")
>
> d <-as.numeric(a)
>
> ##### Fit GAM
> library(mgcv)
> fit <- gam(b ~ s(d, bs="cr"),data=df)
> summary(fit)
> lines(gam(b ~ s(d, bs="cr"),data=df,col="green"))
> ############################################################


`plot` and `lines` will accept a list with named components 'x' and 'y'? 
as its first argument.? The `mgcv:gam` function does not return such a 
value. Read (and examine the code for the functions):

?lines

?points

?scatter.smooth

library(mgcv)

?gamObject

# And then read

?predict.gam ? # to see what might be useful as a y-argument to lines

# and do look at the Examples section of ?perdict.gam

-- 

David

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr 23 06:18:39 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 23 Apr 2020 05:18:39 +0100
Subject: [R] Add GAM fit on the plot ?
In-Reply-To: <1503431427.21637.1587594555500@mail.yahoo.com>
References: <1503431427.21637.1587594555500.ref@mail.yahoo.com>
 <1503431427.21637.1587594555500@mail.yahoo.com>
Message-ID: <4139bb63-2efe-4505-9d95-710611ce0085@sapo.pt>

Hello,

Inline.

?s 23:29 de 22/04/20, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Here below the reproducible example. I can not add the "green" gam curve on the plot. The last line of my R code gives me problem. There is a message error that I don't understand. Many thanks for your precious help.
> 
> #######################################################
> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
> 
> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
> 
> df<-data.frame(a,b)
> 
> plot(as.Date(a),b,pch=16,type="o",col="blue",ylab="nombre de nouveaux cas covid19",xlab="Dates", main="Nombre d?infect?s quotidien Covid-19 en Suisse" ,ylim=c(20,460), xlim=c(min(as.Date(a)),max(as.Date(a))))
> 
> ##### fit loess curve with family symmetric
> loess.smooth(a,b, span = 2/3, degree = 1,???? family = c("symmetric"))
> lines(loess.smooth(a,b, span = 2/3, degree = 1,???? family = "symmetric"),col="purple")
> 
> d <-as.numeric(a)
> 
> ##### Fit GAM
> library(mgcv)
> fit <- gam(b ~ s(d, bs="cr"),data=df)
> summary(fit)
> lines(gam(b ~ s(d, bs="cr"),data=df,col="green"))

Instead of this last line try

b.gam <- predict(gam(b ~ s(d, bs = "cr")))
lines(a, b.gam, col = "green")


Hope this helps,

Rui Barradas

> ############################################################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@oknz @end|ng |rom gm@||@com  Thu Apr 23 12:37:09 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 23 Apr 2020 22:37:09 +1200
Subject: [R] NA command in a 'for' loop
In-Reply-To: <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
References: <AM5PR10MB1746BD3E4FCB46D04FE920C8B9D70@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <a90f0147-0b33-3d37-8455-733c9752766a@sapo.pt>
 <AM5PR10MB174619F7C777A35BF41C5583B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <6e296f6d-57b2-d207-8215-d1b57a077dbd@dewey.myzen.co.uk>
 <AM5PR10MB17461E7EECE68B7F547E7FB2B9D40@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
 <ed5233af-018f-32cd-0210-ab187b079c25@sapo.pt>
 <CA+8X3fX8GYRrmHMf6p5z8HkNEF0ysicEOfU5_dT=owkhC-rCqA@mail.gmail.com>
 <AM5PR10MB17468DE9CA0AAE5332C9DD0CB9D50@AM5PR10MB1746.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <CABcYAdJWKMEvmMagZQ-hX22grkmWhQCqvdCgXAwScrVc-0T2Fw@mail.gmail.com>

You now say that you "want to get rid of" the rows
where V13 is 0.
  d1 <- d[d$V13 != 0,]
returns you a new data frame d1 containing all the
rows of d where V13 is not 0.

On Tue, 21 Apr 2020 at 15:53, Helen Sawaya <helensawaya at hotmail.com> wrote:

> Thank you all for your input.
>
> This is an example of one data file (I have 74 data files):
>
> 2.90546E+11, threat,    1, 2, 1, 2, 1,        death,        stove,
>    NA,           NA,  205,    0,  394
> 2.90546E+11, threat,    2, 2, 2, 1, 1,    emaciated,    shortened,
>    NA,           NA,  205,    0,  502
> 2.90546E+11, threat,    3, 1, 1, 1, 2,     mutilate,     consider,
>    NA,           NA,  205,    1,  468
> 2.90546E+11, threat,    6, 1, 2, 2, 1,         weep,         shop,
>    NA,           NA,  203,    1,  345
> 2.90546E+11, threat,    9, 2, 1, 2, 2,    tormented,    easygoing,
>    NA,           NA,  205,    1,  373
> 2.90546E+11, threat,   10, 1, 2, 2, 2,        snake,        table,
>    NA,           NA,  205,    1,  343
> 2.90546E+11, threat,   11, 2, 2, 1, 1,       crisis,       faucet,
>    NA,           NA,  203,    1,  437
> 2.90546E+11, threat,   12, 1, 1, 1, 1,       victim,      utensil,
>    NA,           NA,  203,    1,  343
> 2.90546E+11, threat,   14, 1, 2, 2, 1,    depressed,    repentant,
>    NA,           NA,  203,    1,  441
> 2.90546E+11, threat,   15, 2, 2, 1, 2,         scum,         shoe,
>    NA,           NA,  205,    1,  475
>
> ?Column 13 has values of 0s and 1s which my cognitive task outputted.
> Column 14 is the reaction time (ms) data. I want to get rid of the rows
> that contain zeros so I thought I'd first replace zeros with NAs then use
> complete.cases function to get rid of the NAs. I also wanted to apply other
> functions so I included them all in a loop. All work fine except for the
> one where I try to turn the zeros to NAs.
>
> Jim when I tried your mockdata example, it worked fine. But when I
> translated it to my data, I still get zeros in the output. Can you identify
> any mistranslations I'm doing?
>
> txt.files<-list.files(".",pattern="dotprobe") #all my data files are text
> files in one folder
> for(tf in txt.files) {
>   d<-read.table(tf)
>   d[,13][d[,13]==0]<-NA #column 13 contains zeros
>   d<-d[ ,-c(10,11)] #get rid of columns 10 and 11
>   write.table(d,sub("[.]",".tlbs.",tf),quote=FALSE, row.names=FALSE)
> }
>
> That's an example of one of the output I get:
>
> V1 V2 V3 V4 V5 V6 V7 V8 V9 V12 V13 V14
> 2.90546E+11, threat, 1, 2, 1, 2, 1, death, stove, 205, 0, 394
> 2.90546E+11, threat, 2, 2, 2, 1, 1, emaciated, shortened, 205, 0, 502
> 2.90546E+11, threat, 3, 1, 1, 1, 2, mutilate, consider, 205, 1, 468
> 2.90546E+11, threat, 6, 1, 2, 2, 1, weep, shop, 203, 1, 345
> 2.90546E+11, threat, 9, 2, 1, 2, 2, tormented, easygoing, 205, 1, 373
> 2.90546E+11, threat, 10, 1, 2, 2, 2, snake, table, 205, 1, 343
>
> Columns 10 and 11 were deleted. But zeros were not replaced by NAs.
> After all the data cleaning, the functions I'm interested in including in
> the loop are: get_tlbs and summarize_bias (and these also work fine in my
> loop).
>
> Thanks again ?
> Sincerely
> Helen
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Tuesday, April 21, 2020 2:52 AM
> To: Rui Barradas <ruipbarradas at sapo.pt>
> Cc: Helen Sawaya <helensawaya at hotmail.com>; Michael Dewey <
> lists at dewey.myzen.co.uk>; r-help at R-project.org <r-help at r-project.org>
> Subject: Re: [R] NA command in a 'for' loop
>
> Hi Helen,
> Your problem may lie in using row.names=TRUE. I was puzzled when an
> extra column kept popping up in the output files. For reading in and
> replacing zeros with NAs, this seems to work:
>
> for(mockdata in 1:3) {
>  mdf<-data.frame(sample(2:20,10),sample(2:20,10),sample(0:1,10,TRUE))
>  write.table(mdf,file=paste0("threat",mockdata,".txt"),quote=FALSE,
>   row.names=FALSE,col.names=FALSE)
> }
> txt.files<-list.files(".",pattern="threat[1-3]")
> for(tf in txt.files) {
>  d<-read.table(tf)
>  d[,3][d[,3]==0]<-NA
>  write.table(d,sub("[.]",".tbls.",tf),quote=FALSE,row.names=FALSE)
> }
>
> Jim
>
> On Tue, Apr 21, 2020 at 7:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > I believe the only way we have to see what is happening is for you to
> > post the output of
> >
> >
> > dput(head(d, 20))  # or 30
> >
> >
> > or, with d2 a subset of d that includes zeros,
> >
> >
> > dput(head(d2, 20))
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 17:48 de 20/04/20, Helen Sawaya escreveu:
> > > I have one column that represents correct response versus error
> (correct
> > > is coded as 1 and error is coded as 0). Nowhere else in the dataset are
> > > there values of 0. The vector is treated as an integer.
> > >
> ------------------------------------------------------------------------
> > > *From:* Michael Dewey <lists at dewey.myzen.co.uk>
> > > *Sent:* Monday, April 20, 2020 7:35 PM
> > > *To:* Helen Sawaya <helensawaya at hotmail.com>; Rui Barradas
> > > <ruipbarradas at sapo.pt>; r-help at R-project.org <r-help at R-project.org>
> > > *Subject:* Re: [R] NA command in a 'for' loop
> > > Just a thought Helen but is x being treated as a real and what you
> think
> > > are zero and are printed as zero are in fact some very small number? If
> > > so you need to alter your test appropriately.
> > >
> > > Michael
> > >
> > > On 20/04/2020 17:25, Helen Sawaya wrote:
> > >> Thank you for your reply.
> > >>
> > >> I tried d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >> but I am still getting zeros instead of NAs in my output..
> > >>
> > >> I wonder if the problem is that some of my data files don't have any
> zeros (participants made no errors)..
> > >> ________________________________
> > >> From: Rui Barradas <ruipbarradas at sapo.pt>
> > >> Sent: Monday, April 20, 2020 9:05 AM
> > >> To: Helen Sawaya <helensawaya at hotmail.com>; r-help at R-project.org
> <r-help at R-project.org>
> > >> Subject: Re: [R] NA command in a 'for' loop
> > >>
> > >> Hello,
> > >>
> > >> Instead of
> > >>
> > >> d[d == 0] <- NA
> > >>
> > >> try
> > >>
> > >> d[] <- lapply(d, function(x) {is.na(x) <- x == 0; x})
> > >>
> > >>
> > >> Also, in the first for loop
> > >>
> > >> paste(i, sep = "")
> > >>
> > >> does nothing, it's the same as i.
> > >> And the same for
> > >>
> > >> (d2$V4 == 1) == TRUE
> > >>
> > >> Since (d2$V4 == 1)  already is FALSE/TRUE there is no need for
> > >>
> > >> (.) == TRUE
> > >>
> > >>
> > >> Hope this helps,
> > >>
> > >> Rui Barradas
> > >>
> > >>
> > >>
> > >> ?s 20:52 de 19/04/20, Helen Sawaya escreveu:
> > >>> Dear R experts,
> > >>>
> > >>> I am using a 'for' loop to apply commands to multiple datasets (each
> file is one participant). The only one not working is the command that
> identifies zeros in my datasets and changes them to NAs. But when I look at
> the output, zeros ("0") are still present.  Surprisingly, the functions
> work fine when I apply them to a single
> > > dataset (outside the loop). I've tried:
> > >>>
> > >>> all.files <- list.files(".")
> > >>> txt.files <- grep("threat.txt",all.files,value=T)
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     d[d==0] <- NA #replace zeros with NA
> > >>>     write.table(d, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method =
> "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".tlbs.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>
> > >>> I've also tried:
> > >>>
> > >>> for(i in txt.files){
> > >>>     d <- read.table(paste(i,sep=""),header=F)
> > >>>     if (0 %in% d)
> > >>>     {replace_with_na(d,replace = list(x = 0))} # replace zeros with
> NA
> > >>>     d<-d[ ,-c(10,11)]
> > >>>     d2<-d[complete.cases(d), ]
> > >>>     d2$V4<-as.numeric(d2$V4)
> > >>>     congruent <- (d2$V4 == 1) == TRUE
> > >>>     x <- get_tlbs(d2$V14, congruent, prior_weights = NULL, method =
> "weighted", fill_gaps = FALSE)
> > >>>     write.table(x, paste0(i,".summaryoutput.txt"), quote=FALSE,
> row.names=TRUE)}
> > >>>
> > >>> Thank you for your help.
> > >>> Sincerely
> > >>> Helen
> > >>>
> > >>>         [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >
> > > --
> > > Michael
> > > http://www.dewey.myzen.co.uk/home.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mon|c@p@|@|ovejoy @end|ng |rom gm@||@com  Thu Apr 23 19:34:07 2020
From: mon|c@p@|@|ovejoy @end|ng |rom gm@||@com (Monica Palaseanu-Lovejoy)
Date: Thu, 23 Apr 2020 13:34:07 -0400
Subject: [R] ggraph and changing colors in geom_node_arc_bar
In-Reply-To: <CABnpDg1TfhUtGr9wr_1nhoFwH23PgTcKUAZz68r9Jgjhp-3eYQ@mail.gmail.com>
References: <CABnpDg1TfhUtGr9wr_1nhoFwH23PgTcKUAZz68r9Jgjhp-3eYQ@mail.gmail.com>
Message-ID: <CABnpDg1f8dbopZfZxs-+UAzZop14k-SxDSOOrnHUgOzPtD++DA@mail.gmail.com>

Hi,

I am not sure if anybody was able to tackle this subject, but finally after
hours of trolling the internet i came to this quite ugly solution - which
is partial but at least it changes the colors.
So, without further ado here you go:

library(tidygraph)
library(tidyverse)
library(ggraph)
library(igraph)
# i hope i remembered all the pertinent libraries i needed.

gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)

palette1 <- colorRampPalette(c("darkviolet","orange", "forestgreen",
"blue","black"))

hex <- palette1(252)

gr<- as_tbl_graph(gr)

gr <- gr %>%
    activate(nodes) %>%
    mutate(hex = ifelse(name, as.character(myHSB$hex)[shortName], NA)) %>%
    activate(edges) %>%
    mutate(hex = .N()$hex[to] == 'hex')

gr1 <- gr
gr1 <- gr1 %>%
    activate(nodes) %>%
mutate(hex=palette1(252)) %>%
activate(edges) %>%
mutate(hex=palette1(251))

laygr<- create_layout(gr1, layout = 'partition', circular=TRUE)

colsgr <- laygr$hex

ggraph(gr1, layout = 'partition', circular = TRUE) +
    geom_node_arc_bar(aes(fill=hex))+
scale_fill_manual(values=colsgr)+
scale_color_manual(values=colsgr)+
theme_graph(background="grey20", border=FALSE)+
theme(legend.position="none")

This code does actually changes the node colors, although it is still not
very clear in which order .... i tried different orders / sort solutions,
none very exciting. But i did change the colors. If you have other ideas
how to do it, i will very much welcome it.

Thanks,
Monica



On Wed, Apr 22, 2020 at 8:31 AM Monica Palaseanu-Lovejoy <
monicapalalovejoy at gmail.com> wrote:

> Hi,
>
> I am playing with the ggraph that is amazing. But i don't quite understand
> some of the options it has. For example:
>
> gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)
>
> l <- ggraph(gr, layout = 'partition', circular = TRUE)
> l + geom_node_arc_bar(aes(fill = depth)) +
>     coord_fixed()
>
> This will give a nice graph in shades of blue.
> But if i want to change the fill aesthetic with a grey scale for example:
>
> l + geom_node_arc_bar(aes(fill = grey(seq(0,1,length=252)))) +
>     coord_fixed() +
> theme(legend.position = "none")
>
> This will give a graphic with set colors that definitely are not on a grey
> scale. So i am missing a piece in my code.
> I tried to add scale_edge_fill_manual(values= grey(seq(0,1,length=252)))
> but to no avail, and besides this has to do with edges and not nodes. So
> this is not the solution.
>
> What i am doing wrong, or what i am missing from my command?
>
> Also i am interested how the graph and ggraph plots, in the sense in what
> order is the data plotted? I am interested in that because i may want to
> set up either colors or widths of edges separately from my graph data for
> visualization.
>
> Thanks,
> Monica
>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 23 19:45:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 23 Apr 2020 10:45:32 -0700
Subject: [R] ggraph and changing colors in geom_node_arc_bar
In-Reply-To: <CABnpDg1f8dbopZfZxs-+UAzZop14k-SxDSOOrnHUgOzPtD++DA@mail.gmail.com>
References: <CABnpDg1TfhUtGr9wr_1nhoFwH23PgTcKUAZz68r9Jgjhp-3eYQ@mail.gmail.com>
 <CABnpDg1f8dbopZfZxs-+UAzZop14k-SxDSOOrnHUgOzPtD++DA@mail.gmail.com>
Message-ID: <9D3F49A1-184C-442F-9644-5F87CF1636B5@dcn.davis.ca.us>

I don't know anything about ggraph, but I am pretty sure that ggplot does not work internally with data of character type... it converts such columns to factor. If you want to control the order of levels then you need to convert to factors before you give the data to ggplot. If you use the factor (not as.factor) function to do this, then you have full control of the sequence of levels, and you can assume this same sequence in your scale_color_ or scale_fill_ specifications.

On April 23, 2020 10:34:07 AM PDT, Monica Palaseanu-Lovejoy <monicapalalovejoy at gmail.com> wrote:
>Hi,
>
>I am not sure if anybody was able to tackle this subject, but finally
>after
>hours of trolling the internet i came to this quite ugly solution -
>which
>is partial but at least it changes the colors.
>So, without further ado here you go:
>
>library(tidygraph)
>library(tidyverse)
>library(ggraph)
>library(igraph)
># i hope i remembered all the pertinent libraries i needed.
>
>gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)
>
>palette1 <- colorRampPalette(c("darkviolet","orange", "forestgreen",
>"blue","black"))
>
>hex <- palette1(252)
>
>gr<- as_tbl_graph(gr)
>
>gr <- gr %>%
>    activate(nodes) %>%
> mutate(hex = ifelse(name, as.character(myHSB$hex)[shortName], NA)) %>%
>    activate(edges) %>%
>    mutate(hex = .N()$hex[to] == 'hex')
>
>gr1 <- gr
>gr1 <- gr1 %>%
>    activate(nodes) %>%
>mutate(hex=palette1(252)) %>%
>activate(edges) %>%
>mutate(hex=palette1(251))
>
>laygr<- create_layout(gr1, layout = 'partition', circular=TRUE)
>
>colsgr <- laygr$hex
>
>ggraph(gr1, layout = 'partition', circular = TRUE) +
>    geom_node_arc_bar(aes(fill=hex))+
>scale_fill_manual(values=colsgr)+
>scale_color_manual(values=colsgr)+
>theme_graph(background="grey20", border=FALSE)+
>theme(legend.position="none")
>
>This code does actually changes the node colors, although it is still
>not
>very clear in which order .... i tried different orders / sort
>solutions,
>none very exciting. But i did change the colors. If you have other
>ideas
>how to do it, i will very much welcome it.
>
>Thanks,
>Monica
>
>
>
>On Wed, Apr 22, 2020 at 8:31 AM Monica Palaseanu-Lovejoy <
>monicapalalovejoy at gmail.com> wrote:
>
>> Hi,
>>
>> I am playing with the ggraph that is amazing. But i don't quite
>understand
>> some of the options it has. For example:
>>
>> gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)
>>
>> l <- ggraph(gr, layout = 'partition', circular = TRUE)
>> l + geom_node_arc_bar(aes(fill = depth)) +
>>     coord_fixed()
>>
>> This will give a nice graph in shades of blue.
>> But if i want to change the fill aesthetic with a grey scale for
>example:
>>
>> l + geom_node_arc_bar(aes(fill = grey(seq(0,1,length=252)))) +
>>     coord_fixed() +
>> theme(legend.position = "none")
>>
>> This will give a graphic with set colors that definitely are not on a
>grey
>> scale. So i am missing a piece in my code.
>> I tried to add scale_edge_fill_manual(values=
>grey(seq(0,1,length=252)))
>> but to no avail, and besides this has to do with edges and not nodes.
>So
>> this is not the solution.
>>
>> What i am doing wrong, or what i am missing from my command?
>>
>> Also i am interested how the graph and ggraph plots, in the sense in
>what
>> order is the data plotted? I am interested in that because i may want
>to
>> set up either colors or widths of edges separately from my graph data
>for
>> visualization.
>>
>> Thanks,
>> Monica
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Thu Apr 23 21:35:15 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Thu, 23 Apr 2020 19:35:15 +0000 (UTC)
Subject: [R] Add GAM fit on the plot ?
In-Reply-To: <4139bb63-2efe-4505-9d95-710611ce0085@sapo.pt>
References: <1503431427.21637.1587594555500.ref@mail.yahoo.com>
 <1503431427.21637.1587594555500@mail.yahoo.com>
 <4139bb63-2efe-4505-9d95-710611ce0085@sapo.pt>
Message-ID: <1881125129.1067171.1587670515136@mail.yahoo.com>

David, 
Rui,

Many thanks for your response. Thanks Rui it perfectly works.

Best,







Le jeudi 23 avril 2020 ? 06:18:46 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

Inline.

?s 23:29 de 22/04/20, varin sacha via R-help escreveu:
> Dear R-experts,
> 
> Here below the reproducible example. I can not add the "green" gam curve on the plot. The last line of my R code gives me problem. There is a message error that I don't understand. Many thanks for your precious help.
> 
> #######################################################
> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
> 
> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
> 
> df<-data.frame(a,b)
> 
> plot(as.Date(a),b,pch=16,type="o",col="blue",ylab="nombre de nouveaux cas covid19",xlab="Dates", main="Nombre d?infect?s quotidien Covid-19 en Suisse" ,ylim=c(20,460), xlim=c(min(as.Date(a)),max(as.Date(a))))
> 
> ##### fit loess curve with family symmetric
> loess.smooth(a,b, span = 2/3, degree = 1,???? family = c("symmetric"))
> lines(loess.smooth(a,b, span = 2/3, degree = 1,???? family = "symmetric"),col="purple")
> 
> d <-as.numeric(a)
> 
> ##### Fit GAM
> library(mgcv)
> fit <- gam(b ~ s(d, bs="cr"),data=df)
> summary(fit)
> lines(gam(b ~ s(d, bs="cr"),data=df,col="green"))


Instead of this last line try

b.gam <- predict(gam(b ~ s(d, bs = "cr")))
lines(a, b.gam, col = "green")


Hope this helps,

Rui Barradas

> ############################################################
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

> 


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr 23 22:31:50 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 23 Apr 2020 21:31:50 +0100
Subject: [R] Add GAM fit on the plot ?
In-Reply-To: <1881125129.1067171.1587670515136@mail.yahoo.com>
References: <1503431427.21637.1587594555500.ref@mail.yahoo.com>
 <1503431427.21637.1587594555500@mail.yahoo.com>
 <4139bb63-2efe-4505-9d95-710611ce0085@sapo.pt>
 <1881125129.1067171.1587670515136@mail.yahoo.com>
Message-ID: <12f69e55-20b5-ab53-f2e2-c59535947537@sapo.pt>

Hello,

I'm glad it helped.
One more thing, I've just noticed that I copied the gam call in lines() 
but you don't have to refit the model,

b.gam <- predict(fit)

is enough.

Hope this helps,

Rui Barradas

?s 20:35 de 23/04/20, varin sacha escreveu:
> David,
> Rui,
> 
> Many thanks for your response. Thanks Rui it perfectly works.
> 
> Best,
> 
> 
> 
> 
> 
> 
> 
> Le jeudi 23 avril 2020 ? 06:18:46 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit :
> 
> 
> 
> 
> 
> Hello,
> 
> Inline.
> 
> ?s 23:29 de 22/04/20, varin sacha via R-help escreveu:
>> Dear R-experts,
>>
>> Here below the reproducible example. I can not add the "green" gam curve on the plot. The last line of my R code gives me problem. There is a message error that I don't understand. Many thanks for your precious help.
>>
>> #######################################################
>> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
>>
>> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
>>
>> df<-data.frame(a,b)
>>
>> plot(as.Date(a),b,pch=16,type="o",col="blue",ylab="nombre de nouveaux cas covid19",xlab="Dates", main="Nombre d?infect?s quotidien Covid-19 en Suisse" ,ylim=c(20,460), xlim=c(min(as.Date(a)),max(as.Date(a))))
>>
>> ##### fit loess curve with family symmetric
>> loess.smooth(a,b, span = 2/3, degree = 1,???? family = c("symmetric"))
>> lines(loess.smooth(a,b, span = 2/3, degree = 1,???? family = "symmetric"),col="purple")
>>
>> d <-as.numeric(a)
>>
>> ##### Fit GAM
>> library(mgcv)
>> fit <- gam(b ~ s(d, bs="cr"),data=df)
>> summary(fit)
>> lines(gam(b ~ s(d, bs="cr"),data=df,col="green"))
> 
> 
> Instead of this last line try
> 
> b.gam <- predict(gam(b ~ s(d, bs = "cr")))
> lines(a, b.gam, col = "green")
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
>> ############################################################
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
>>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr 24 06:58:24 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Apr 2020 05:58:24 +0100
Subject: [R] ggraph and changing colors in geom_node_arc_bar
In-Reply-To: <CABnpDg1f8dbopZfZxs-+UAzZop14k-SxDSOOrnHUgOzPtD++DA@mail.gmail.com>
References: <CABnpDg1TfhUtGr9wr_1nhoFwH23PgTcKUAZz68r9Jgjhp-3eYQ@mail.gmail.com>
 <CABnpDg1f8dbopZfZxs-+UAzZop14k-SxDSOOrnHUgOzPtD++DA@mail.gmail.com>
Message-ID: <5417ac4c-79d9-9c6e-1af7-59c45f338ff1@sapo.pt>

Hello,

Try a scale_fill_gradient*, there are several.


l + geom_node_arc_bar(aes(fill = depth)) +
   scale_fill_gradient(low = "gray80", high = "gray20") +
   coord_fixed() +
   theme(legend.position = "none")


This will map increasing values of the 'fill' aesthetics to colors 
between those limits, 'gray80' (lighter) and 'gray20' (darker).


Hope this helps,

Rui Barradas

?s 18:34 de 23/04/20, Monica Palaseanu-Lovejoy escreveu:
> Hi,
> 
> I am not sure if anybody was able to tackle this subject, but finally after
> hours of trolling the internet i came to this quite ugly solution - which
> is partial but at least it changes the colors.
> So, without further ado here you go:
> 
> library(tidygraph)
> library(tidyverse)
> library(ggraph)
> library(igraph)
> # i hope i remembered all the pertinent libraries i needed.
> 
> gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)
> 
> palette1 <- colorRampPalette(c("darkviolet","orange", "forestgreen",
> "blue","black"))
> 
> hex <- palette1(252)
> 
> gr<- as_tbl_graph(gr)
> 
> gr <- gr %>%
>      activate(nodes) %>%
>      mutate(hex = ifelse(name, as.character(myHSB$hex)[shortName], NA)) %>%
>      activate(edges) %>%
>      mutate(hex = .N()$hex[to] == 'hex')
> 
> gr1 <- gr
> gr1 <- gr1 %>%
>      activate(nodes) %>%
> mutate(hex=palette1(252)) %>%
> activate(edges) %>%
> mutate(hex=palette1(251))
> 
> laygr<- create_layout(gr1, layout = 'partition', circular=TRUE)
> 
> colsgr <- laygr$hex
> 
> ggraph(gr1, layout = 'partition', circular = TRUE) +
>      geom_node_arc_bar(aes(fill=hex))+
> scale_fill_manual(values=colsgr)+
> scale_color_manual(values=colsgr)+
> theme_graph(background="grey20", border=FALSE)+
> theme(legend.position="none")
> 
> This code does actually changes the node colors, although it is still not
> very clear in which order .... i tried different orders / sort solutions,
> none very exciting. But i did change the colors. If you have other ideas
> how to do it, i will very much welcome it.
> 
> Thanks,
> Monica
> 
> 
> 
> On Wed, Apr 22, 2020 at 8:31 AM Monica Palaseanu-Lovejoy <
> monicapalalovejoy at gmail.com> wrote:
> 
>> Hi,
>>
>> I am playing with the ggraph that is amazing. But i don't quite understand
>> some of the options it has. For example:
>>
>> gr <- graph_from_data_frame(flare$edges, vertices = flare$vertices)
>>
>> l <- ggraph(gr, layout = 'partition', circular = TRUE)
>> l + geom_node_arc_bar(aes(fill = depth)) +
>>      coord_fixed()
>>
>> This will give a nice graph in shades of blue.
>> But if i want to change the fill aesthetic with a grey scale for example:
>>
>> l + geom_node_arc_bar(aes(fill = grey(seq(0,1,length=252)))) +
>>      coord_fixed() +
>> theme(legend.position = "none")
>>
>> This will give a graphic with set colors that definitely are not on a grey
>> scale. So i am missing a piece in my code.
>> I tried to add scale_edge_fill_manual(values= grey(seq(0,1,length=252)))
>> but to no avail, and besides this has to do with edges and not nodes. So
>> this is not the solution.
>>
>> What i am doing wrong, or what i am missing from my command?
>>
>> Also i am interested how the graph and ggraph plots, in the sense in what
>> order is the data plotted? I am interested in that because i may want to
>> set up either colors or widths of edges separately from my graph data for
>> visualization.
>>
>> Thanks,
>> Monica
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pd@me@ @end|ng |rom cb@@dk  Fri Apr 24 09:21:04 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Fri, 24 Apr 2020 07:21:04 +0000
Subject: [R] R 4.0.0 is released
Message-ID: <BDD8A4E0-8C99-4939-AD23-70C17FCCB8E1@cbs.dk>

The build system rolled up R-4.0.0.tar.gz (codename "Arbor Day") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 9aafc4b3277fdf482cf8195f707ae758
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 48c487c68112cb3191f3015c6277a50b
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = bb45f89c01d509721c47fd41f147da60
MD5 (VERSION-INFO.dcf) = f6e4e96a451cc3131a18d9f63c4c67b8
MD5 (R-4/R-4.0.0.tar.gz) = 48c487c68112cb3191f3015c6277a50b

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
b9c6a73f2b03421d157185ee68c88a8e5a26b6f3e1edf977deb26a43c8ed98ed  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
06beb0291b569978484eb0dcb5d2339665ec745737bdfb4e873e7a5a75492940  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
2a8dca916cd92229ef9e328f3610ca204809c262823b860252b42072dac2473a  THANKS
47ad507cd5bbf2ad7a3de95b44b223052d4f53a3928aa3782957694d8c1cf05c  VERSION-INFO.dcf
06beb0291b569978484eb0dcb5d2339665ec745737bdfb4e873e7a5a75492940  R-4/R-4.0.0.tar.gz

This is the relevant part of the NEWS file

CHANGES IN 4.0.0:

  SIGNIFICANT USER-VISIBLE CHANGES:

    * Packages need to be (re-)installed under this version (4.0.0) of
      R.

    * matrix objects now also inherit from class "array", so e.g.,
      class(diag(1)) is c("matrix", "array").  This invalidates code
      incorrectly assuming that class(matrix_obj)) has length one.

      S3 methods for class "array" are now dispatched for matrix
      objects.

    * There is a new syntax for specifying _raw_ character constants
      similar to the one used in C++: r"(...)" with ... any character
      sequence not containing the sequence )".  This makes it easier to
      write strings that contain backslashes or both single and double
      quotes.  For more details see ?Quotes.

    * R now uses a stringsAsFactors = FALSE default, and hence by
      default no longer converts strings to factors in calls to
      data.frame() and read.table().

      A large number of packages relied on the previous behaviour and
      so have needed/will need updating.

    * The plot() S3 generic function is now in package base rather than
      package graphics, as it is reasonable to have methods that do not
      use the graphics package.  The generic is currently re-exported
      from the graphics namespace to allow packages importing it from
      there to continue working, but this may change in future.

      Packages which define S4 generics for plot() should be
      re-installed and package code using such generics from other
      packages needs to ensure that they are imported rather than rely
      on their being looked for on the search path (as in a namespace,
      the base namespace has precedence over the search path).

  REFERENCE COUNTING:

    * Reference counting is now used instead of the NAMED mechanism for
      determining when objects can be safely mutated in base C code.
      This reduces the need for copying in some cases and should allow
      further optimizations in the future.  It should help make the
      internal code easier to maintain.

      This change is expected to have almost no impact on packages
      using supported coding practices in their C/C++ code.

  MIGRATION TO PCRE2:

    * This version of R is built against the PCRE2 library for
      Perl-like regular expressions, if available.  (On non-Windows
      platforms PCRE1 can optionally be used if PCRE2 is not available
      at build time.)  The version of PCRE in use can be obtained _via_
      extSoftVersion(): PCRE1 (formerly known as 'PCRE') has versions
      <= 8, PCRE2 versions >= 10.

    * Making PCRE2 available when building R from source is strongly
      recommended (preferably version 10.30 or later) as PCRE1 is no
      longer developed: version 8.44 is 'likely to be the final
      release'.

    * PCRE2 reports errors for some regular expressions that were
      accepted by PCRE1.  A hyphen now has to be escaped in a character
      class to be interpreted as a literal (unless first or last in the
      class definition).  \R, \B and \X are no longer allowed in
      character classes (PCRE1 treated these as literals).

    * Option PCRE_study is no longer used with PCRE2, and is reported
      as FALSE when that is in use.

  NEW FEATURES:

    * assertError() and assertWarning() (in package tools) can now
      check for _specific_ error or warning classes _via_ the new
      optional second argument classes (which is not back compatible
      with previous use of an unnamed second argument).

    * DF2formula(), the utility for the data frame method of formula(),
      now works without parsing and explicit evaluation, starting from
      Suharto Anggono's suggestion in PR#17555.

    * approxfun() and approx() gain a new argument na.rm defaulting to
      true.  If set to false, missing y values now propagate into the
      interpolated values.

    * Long vectors are now supported as the seq argument of a for()
      loop.

    * str(x) gets a new deparse.lines option with a default to speed it
      up when x is a large call object.

    * The internal traceback object produced when an error is signalled
      (.Traceback), now contains the calls rather than the _deparse()d_
      calls, deferring the deparsing to the user-level functions
      .traceback() and traceback().  This fulfils the wish of PR#17580,
      reported including two patch proposals by Brodie Gaslam.

    * data.matrix() now converts character columns to factors and from
      this to integers.

    * package.skeleton() now explicitly lists all exports in the
      NAMESPACE file.

    * New function .S3method() to register S3 methods in R scripts.

    * file.path() has some support for file paths not in the session
      encoding, e.g. with UTF-8 inputs in a non-UTF-8 locale the output
      is marked as UTF-8.

    * Most functions with file-path inputs will give an explicit error
      if a file-path input in a marked encoding cannot be translated
      (to the native encoding or in some cases on Windows to UTF-8),
      rather than translate to a different file path using escapes.
      Some (such as dir.exists(), file.exists(), file.access(),
      file.info(), list.files(), normalizePath() and path.expand())
      treat this like any other non-existent file, often with a
      warning.

    * There is a new help document accessed by help("file path
      encoding") detailing how file paths with marked encodings are
      handled.

    * New function list2DF() for creating data frames from lists of
      variables.

    * iconv() has a new option sub = "Unicode" to translate UTF-8 input
      invalid in the to encoding using <U+xxxx> escapes.

    * There is a new function infoRDS() providing information about the
      serialization format of a serialized object.

    * S3 method lookup now by default skips the elements of the search
      path between the global and base environments.

    * Added an argument add_datalist(*, small.size = 0) to allow the
      creation of a data/datalist file even when the total size of the
      data sets is small.

    * The backquote function bquote() has a new argument splice to
      enable splicing a computed list of values into an expression,
      like ,@ in LISP's backquote.

    * The formula interface to t.test() and wilcox.test() has been
      extended to handle one-sample and paired tests.

    * The palette() function has a new default set of colours (which
      are less saturated and have better accessibility properties).
      There are also some new built-in palettes, which are listed by
      the new palette.pals() function.  These include the old default
      palette under the name "R3". Finally, the new palette.colors()
      function allows a subset of colours to be selected from any of
      the built-in palettes.

    * n2mfrow() gains an option asp = 1 to specify the aspect ratio,
      fulfilling the wish and extending the proposal of Michael Chirico
      in PR#17648.

    * For head(x, n) and tail() the default and other S3 methods
      notably for _vector_ n, e.g. to get a "corner" of a matrix, has
      been extended to array's of higher dimension thanks to the patch
      proposal by Gabe Becker in PR#17652.  Consequently, optional
      argument addrownums is deprecated and replaced by the (more
      general) argument keepnums.  An invalid second argument n now
      leads to typically more easily readable error messages.

    * New function .class2() provides the full character vector of
      class names used for S3 method dispatch.

    * Printing methods(..) now uses a new format() method.

    * sort.list(x) now works for non-atomic objects x and method =
      "auto" (the default) or "radix" in cases order(x) works.

    * Where they are available, writeBin() allows long vectors.

    * New function deparse1() produces one string, wrapping deparse(),
      to be used typically in deparse1(substitute(*)), e.g., to fix
      PR#17671.

    * wilcox.test() enhancements: In the (non-paired) two-sample case,
      Inf values are treated as very large for robustness consistency.
      If exact computations are used, the result now has "exact" in the
      method element of its return value.  New arguments tol.root and
      digits.rank where the latter may be used for stability to treat
      very close numbers as ties.

    * readBin() and writeBin() now report an error for an invalid
      endian value.  The affected code needs to be fixed with care as
      the old undocumented behavior was to swap endian-ness in such
      cases.

    * sequence() is now an S3 generic with an internally implemented
      default method, and gains arguments to generate more complex
      sequences.  Based on code from the S4Vectors Bioconductor package
      and the advice of Herv'e Pag`es.

    * print()'s default method and many other methods (by calling the
      default eventually and passing ...) now make use of a new
      optional width argument, avoiding the need for the user to set
      and reset options("width").

    * memDecompress() supports the RFC 1952 format (e.g. in-memory
      copies of gzip-compressed files) as well as RFC 1950.

    * memCompress() and memDecompress() support long raw vectors for
      types "gzip" and "zx".

    * sweep() and slice.index() can now use names of dimnames for their
      MARGIN argument (apply has had this for almost a decade).

    * New function proportions() and marginSums(). These should replace
      the unfortunately named prop.table() and margin.table(). They are
      drop-in replacements, but also add named-margin functionality.
      The old function names are retained as aliases for
      back-compatibility.

    * Functions rbinom(), rgeom(), rhyper(), rpois(), rnbinom(),
      rsignrank() and rwilcox() which have returned integer since R
      3.0.0 and hence NA when the numbers would have been outside the
      integer range, now return double vectors (without NAs, typically)
      in these cases.

    * matplot(x,y) (and hence matlines() and matpoints()) now call the
      corresponding methods of plot() and lines(), e.g, when x is a
      "Date" or "POSIXct" object; prompted by Spencer Graves'
      suggestion.

    * stopifnot() now allows customizing error messages via argument
      names, thanks to a patch proposal by Neal Fultz in PR#17688.

    * unlink() gains a new argument expand to disable wildcard and
      tilde expansion.  Elements of x of value "~" are now ignored.

    * mle() in the stats4 package has had its interface extended so
      that arguments to the negative log-likelihood function can be one
      or more vectors, with similar conventions applying to bounds,
      start values, and parameter values to be kept fixed.  This
      required a minor extension to class "mle", so saved objects from
      earlier versions may need to be recomputed.

    * The default for pdf() is now useDingbats = FALSE.

    * The default fill colour for hist() and boxplot() is now col =
      "lightgray".

    * The default order of the levels on the y-axis for spineplot() and
      cdplot() has been reversed.

    * If the R_ALWAYS_INSTALL_TESTS environment variable is set to a
      true value, R CMD INSTALL behaves as if the --install-tests
      option is always specified. Thanks to Reinhold Koch for the
      suggestion.

    * New function R_user_dir() in package tools suggests paths
      appropriate for storing R-related user-specific data,
      configuration and cache files.

    * capabilities() gains a new logical option Xchk to avoid warnings
      about X11-related capabilities.

    * The internal implementation of grid units has changed, but the
      only visible effects at user-level should be

        * a slightly different print format for some units (especially
          unit arithmetic),

        * faster performance (for unit operations) and

        * two new functions unitType() and unit.psum().

      Based on code contributed by Thomas Lin Pedersen.

    * When internal dispatch for rep.int() and rep_len() fails, there
      is an attempt to dispatch on the equivalent call to rep().

    * Object .Machine now contains new longdouble.* entries (when R
      uses long doubles internally).

    * news() has been enhanced to cover the news on R 3.x and 2.x.

    * For consistency, N <- NULL; N[[1]] <- val now turns N into a list
      also when val) has length one.  This enables dimnames(r1)[[1]] <-
      "R1" for a 1-row matrix r1, fixing PR#17719 reported by Serguei
      Sokol.

    * deparse(..), dump(..), and dput(x, control = "all") now include
      control option "digits17" which typically ensures 1:1
      invertibility.  New option control = "exact" ensures numeric
      exact invertibility via "hexDigits".

    * When loading data sets via read.table(), data() now uses
      LC_COLLATE=C to ensure locale-independent results for possible
      string-to-factor conversions.

    * A server socket connection, a new connection type representing a
      listening server socket, is created via serverSocket() and can
      accept multiple socket connections via socketAccept().

    * New function socketTimeout() changes the connection timeout of a
      socket connection.

    * The time needed to start a homogeneous PSOCK cluster on localhost
      with many nodes has been significantly reduced (package
      parallel).

    * New globalCallingHandlers() function to establish global
      condition handlers.  This allows registering default handlers for
      specific condition classes. Developed in collaboration with
      Lionel Henry.

    * New function tryInvokeRestart() to invoke a specified restart if
      one is available and return without signaling an error if no such
      restart is found.  Contributed by Lionel Henry in PR#17598.

    * str(x) now shows the length of attributes in some cases for a
      data frame x.

    * Rprof() gains a new argument filter.callframes to request that
      intervening call frames due to lazy evaluation or explicit eval()
      calls be omitted from the recorded profile data.  Contributed by
      Lionel Henry in PR#17595.

    * The handling of ${FOO-bar} and ${FOO:-bar} in Renviron files now
      follows POSIX shells (at least on a Unix-alike), so the first
      treats empty environment variables as set and the second does
      not.  Previously both ignored empty variables.  There are several
      uses of the first form in etc/Renviron.

    * New classes argument for suppressWarnings() and
      suppressMessages() to selectively suppress only warnings or
      messages that inherit from particular classes.  Based on patch
      from Lionel Henry submitted with PR#17619.

    * New function activeBindingFunction() retrieves the function of an
      active binding.

    * New "cairoFT" and "pango" components in the output of
      grSoftVersion().

    * New argument symbolfamily in cairo-based graphics devices and new
      function cairoSymbolFont() that can be used to provide the value
      for that argument.

  Windows:

    * Rterm now works also when invoked from MSYS2 terminals.  Line
      editing is possible when command winpty is installed.

    * normalizePath() now resolves symbolic links and normalizes case
      of long names of path elements in case-insensitive folders
      (PR#17165).

    * md5sum() supports UTF-8 file names with characters that cannot be
      translated to the native encoding (PR#17633).

    * Rterm gains a new option --workspace to specify the workspace to
      be restored.  This allows equals to be part of the name when
      opening _via_ Windows file associations (reported by Christian
      Asseburg).

    * Rterm now accepts ALT+xxx sequences also with NumLock on.  Tilde
      can be pasted with an Italian keyboard (PR#17679).

    * R falls back to copying when junction creation fails during
      package checking (patch from Duncan Murdoch).

  DEPRECATED AND DEFUNCT:

    * Make macro F77_VISIBILITY has been removed and replaced by
      F_VISIBILITY.

    * Make macros F77, FCPIFCPLAGS and SHLIB_OPENMP_FCFLAGS have been
      removed and replaced by FC, FPICFLAGS and SHLIB_OPENMP_FFLAGS
      respectively.  (Most make programs will set F77 to the value of
      FC, which is set for package compilation.  But portable code
      should not rely on this.)

    * The deprecated support for specifying C++98 for package
      installation has been removed.

    * R CMD config no longer knows about the unused settings F77 and
      FCPIFCPLAGS, nor CXX98 and similar.

    * Either PCRE2 or PCRE1 >= 8.32 (Nov 2012) is required: the
      deprecated provision for 8.20-8.31 has been removed.

    * Defunct functions mem.limits(), .readRDS(),
      .saveRDS(),..find.package(), and .path.package() from package
      base and allGenerics(), getAccess(), getAllMethods(),
      getClassName(), getClassPackage(), getExtends(), getProperties(),
      getPrototype(), getSubclasses(), getVirtual(), mlistMetaName(),
      removeMethodsObject(), seemsS4Object(), traceOff(), and traceOn()
      from methods have been removed.

  C-LEVEL FACILITIES:

    * installChar is now remapped in Rinternals.h to installTrChar, of
      which it has been a wrapper since R 3.6.0.  Neither are part of
      the API, but packages using installChar can replace it if they
      depend on R >= 3.6.2.

    * Header R_ext/Print.h defines R_USE_C99_IN_CXX and hence exposes
      Rvprintf and REvprintf if used with a C++11 (or later) compiler.

    * There are new Fortran subroutines dblepr1, realpr1 and intpr1 to
      print a scalar variable (gfortran 10 enforces the distinction
      between scalars and length-one arrays).  Also labelpr to print
      just a label.

    * R_withCallingErrorHandler is now available for establishing a
      calling handler in C code for conditions inheriting from class
      error.

  INSTALLATION on a UNIX-ALIKE:

    * User-set DEFS (e.g., in config.site) is now used for compiling
      packages (including base packages).

    * There is a new variant option --enable-lto=check for checking
      consistency of BLAS/LAPACK/LINPACK calls - see 'Writing R
      Extensions'.

    * A C++ compiler default is set only if the C++11 standard is
      supported: it no longer falls back to C++98.

    * PCRE2 is used if available.  To make use of PCRE1 if PCRE2 is
      unavailable, configure with option --with-pcre1.

    * The minimum required version of libcurl is now 7.28.0 (Oct 2012).

    * New make target distcheck checks

        * R can be rebuilt from the tarball created by make dist,

        * the build from the tarball passes make check-all,

        * the build installs and uninstalls,

        * the source files are properly cleaned by make distclean.

  UTILITIES:

    * R --help now mentions the option --no-echo (renamed from --slave)
      and its previously undocumented short form -s.

    * R CMD check now optionally checks configure and cleanup scripts
      for non-Bourne-shell code ('bashisms').

    * R CMD check --as-cran now runs \donttest examples (which are run
      by example()) instead of instructing the tester to do so.  This
      can be temporarily circumvented during development by setting
      environment variable _R_CHECK_DONTTEST_EXAMPLES_ to a false
      value.

  PACKAGE INSTALLATION:

    * There is the beginnings of support for the recently approved
      C++20 standard, specified analogously to C++14 and C++17.  There
      is currently only limited support for this in compilers, with
      flags such as -std=c++20 and -std=c++2a.  For the time being the
      configure test is of accepting one of these flags and compiling
      C++17 code.

  BUG FIXES:

    * formula(x) with length(x) > 1 character vectors, is deprecated
      now.  Such use has been rare, and has 'worked' as expected in
      some cases only.  In other cases, wrong x have silently been
      truncated, not detecting previous errors.

    * Long-standing issue where the X11 device could lose events
      shortly after startup has been addressed (PR#16702).

    * The data.frame method for rbind() no longer drops <NA> levels
      from factor columns by default (PR#17562).

    * available.packages() and hence install.packages() now pass their
      ... argument to download.file(), fulfilling the wish of PR#17532;
      subsequently, available.packages() gets new argument quiet,
      solving PR#17573.

    * stopifnot() gets new argument exprObject to allow an R object of
      class expression (or other 'language') to work more consistently,
      thanks to suggestions by Suharto Anggono.

    * conformMethod() now works correctly in cases containing a "&&
      logic" bug, reported by Henrik Bengtsson.  It now creates methods
      with "missing" entries in the signature.  Consequently,
      rematchDefinition() is amended to use appropriate .local() calls
      with named arguments where needed.

    * format.default(*, scientific = FALSE) now corresponds to a
      practically most extreme options(scipen = n) setting rather than
      arbitrary n = 100.

    * format(as.symbol("foo")) now works (returning "foo").

    * postscript(.., title = *) now signals an error when the title
      string contains a character which would produce corrupt
      PostScript, thanks to PR#17607 by Daisuko Ogawa.

    * Certain Ops (notably comparison such as ==) now also work for
      0-length data frames, after reports by Hilmar Berger.

    * methods(class = class(glm(..))) now warns more usefully and only
      once.

    * write.dcf() no longer mangles field names (PR#17589).

    * Primitive replacement functions no longer mutate a referenced
      first argument when used outside of a complex assignment context.

    * A better error message for contour(*, levels = Inf).

    * The return value of contourLines() is no longer invisible().

    * The Fortran code for calculating the coefficients component in
      lm.influence() was very inefficient. It has (for now) been
      replaced with much faster R code (PR#17624).

    * cm.colors(n) _etc_ no longer append the code for alpha = 1, "FF",
      to all colors.  Hence all eight *.colors() functions and
      rainbow() behave consistently and have the same non-explicit
      default (PR#17659).

    * dnorm had a problematic corner case with sd == -Inf or negative
      sd which was not flagged as an error in all cases. Thanks to
      Stephen D. Weigand for reporting and Wang Jiefei for analyzing
      this; similar change has been made in dlnorm().

    * The optional iter.smooth argument of plot.lm(), (the plot()
      method for lm and glm fits) now defaults to 0 for all glm fits.
      Especially for binary observations with high or low fitted
      probabilities, this effectively deleted all observations of 1 or
      0.  Also, the type of residuals used in the glm case has been
      switched to "pearson" since deviance residuals do not in general
      have approximately zero mean.

    * In plot.lm, Cook's distance was computed from unweighted
      residuals, leading to inconsistencies.  Replaced with usual
      weighted version. (PR#16056)

    * Time-series ts(*, start, end, frequency) with fractional
      frequency are supported more consistently; thanks to a report
      from Johann Kleinbub and analysis and patch by Duncan Murdoch in
      PR#17669.

    * In case of errors mcmapply() now preserves attributes of returned
      "try-error" objects and avoids simplification, overriding
      SIMPLIFY to FALSE. (PR#17653)

    * as.difftime() gets new optional tz = "UTC" argument which should
      fix behaviour during daylight-savings-changeover days, fixing
      PR#16764, thanks to proposals and analysis by Johannes Ranke and
      Kirill M"uller.

    * round() does a better job of rounding _"to nearest"_ by
      _measuring_ and _"to even"_; thanks to a careful algorithm
      originally prompted by the report from Adam Wheeler and then
      others, in PR#17668.
      round(x, dig) for _negative_ digits is much more rational now,
      notably for large |dig|.

    * Inheritance information on S4 classes is maintained more
      consistently, particularly in the case of class unions (in part
      due to PR#17596 and a report from Ezra Tucker).

    * is() behaves more robustly when its argument class2 is a
      classRepresentation object.

    * The warning message when attempting to export an nonexistent
      class is now more readable; thanks to Thierry Onkelinx for
      recognizing the problem.

    * choose() misbehaved in corner cases where it switched n - k for k
      and n was only _nearly_ integer (report from Erik Scott Wright).

    * mle() in the stats4 package had problems combining use of box
      constraints and fixed starting values (in particular, confidence
      intervals were affected).

    * Operator ? now has lower precedence than = to work as documented,
      so = behaves like <- in help expressions (PR#16710).

    * smoothEnds(x) now returns integer type in _both_ cases when x is
      integer, thanks to a report and proposal by Bill Dunlap PR#17693.

    * The methods package does a better job of tracking inheritance
      relationships across packages.

    * norm(diag(c(1, NA)), "2") now works.

    * subset() had problems with 0-col dataframes (reported by Bill
      Dunlap, PR#17721).

    * Several cases of integer overflow detected by the 'undefined
      behaviour sanitizer' of clang 10 have been circumvented.  One in
      rhyper() may change the generated value for large input values.

    * dotchart() now places the y-axis label (ylab) much better, not
      overplotting labels, thanks to a report and suggestion by Alexey
      Shipunov.

    * A rare C-level array overflow in chull() has been worked around.

    * Some invalid specifications of the day-of-the-year (_via_ %j,
      e.g. day 366 in 2017) or week plus day-of-the-week are now
      detected by strptime().  They now return NA but give a warning as
      they may have given random results or corrupted memory in earlier
      versions of R.

    * socketConnection(server = FALSE) now respects the connection
      timeout also on Linux.

    * socketConnection(server = FALSE) no longer leaks a connection
      that is available right away without waiting (e.g. on localhost).

    * Socket connections are now robust against spurious readability
      and spurious availability of an incoming connection.

    * blocking = FALSE is now respected also on the server side of a
      socket connection, allowing non-blocking read operations.

    * anova.glm() and anova.glmlist() computed incorrect score (Rao)
      tests in no-intercept cases. (Andr'e Gillibert, PR#17734)

    * summaryRprof() now should work correctly for the Rprof(*,
      memory.profiling=TRUE) case with small chunk size (and "tseries"
      or similar) thanks to a patch proposal by Benjamin Tyner, in
      PR#15886.

    * xgettext() ignores strings passed to ngettext(), since the latter
      is handled by xngettext(). Thanks to Daniele Medri for the report
      and all the recent work he has done on the Italian translations.

    * data(package = "P") for P in base and stats no longer reports the
      data sets from package datasets (which it did for back
      compatibility for 16 years), fixing PR#17730.

    * x[[Inf]] (returning NULL) no longer leads to undefined behavior,
      thanks to a report by Kirill M"uller in PR#17756.  Further,
      x[[-Inf]] and x[[-n]] now give more helpful error messages.

    * Gamma() family sometimes had trouble storing link name PR#15891

  BUG FIXES (Windows):

    * Sys.glob() now supports all characters from the Unicode Basic
      Multilingual Plane, no longer corrupting some (less commonly
      used) characters (PR#17638).

    * Rterm now correctly displays multi-byte-coded characters
      representable in the current native encoding (at least on Windows
      10 they were sometimes omitted, PR#17632).

    * scan() issues with UTF-8 data when running in a DBCS locale have
      been resolved (PR#16520, PR#16584).

    * RTerm now accepts enhanced/arrow keys also with ConPTY.

    * R can can now be started _via_ the launcher icon in a user
      documents directory whose path is not representable in the system
      encoding.

    * socketConnection(server = FALSE) now returns instantly also on
      Windows when connection failure is signalled.

    * Problems with UTF-16 surrogate pairs have been fixed in several
      functions, including tolower() and toupper() (PR#17645).

CHANGES in previous versions:

  * Older news can be found in text format in files NEWS.0, NEWS.1,
    NEWS.2 and NEWS.3 in the doc directory.  News in HTML format for R
    versions 3.x and from 2.10.0 to 2.15.3 is available at
    doc/html/NEWS.3.html and doc/html/NEWS.2.html.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Apr 24 09:24:33 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 24 Apr 2020 09:24:33 +0200
Subject: [R] Error in colouring by group in core plot R
Message-ID: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>

Hello,
I am trying to make an epidemic plot of the COVID pandemic using the core
plot function. I am looking at three countries and the countries are as
factors. The idea is to colour the entry by country, following this scheme:
```
df = data.frame(index = 1:10,
                value = c(rnorm(10), rnorm(10), rnorm(10)),
                set = c(rep("Group 1", 3), rep("Group 2", 3), rep("Group
3", 4)))
plot(df$index ~ df$value, col=c("blue", "orange", "purple")[df$set])
```
But in the actual graph there is only one colour:
```
Index = c(1:101)
g1 = c(0,259,457,688,769,1771,1459,1737,1981,2099,2589,2825,3235,3884,3694,

 3143,3385,2652,2973,2467,2015,14108,5090,2641,2008,2048,1888,1749,391,
       889,823,648,214,508,406,433,327,427,573,202,125,119,139,143,99,44,40,

 0,0,0,0,0,0,0,0,0,0,0,0,46,39,78,47,67,55,54,45,0,79,36,35,0,0,0,39,0,
       0,63,42,46,99,108,89,46,46,0,325,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
g2 =
c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
       0,0,0,0,0,0,0,59,283,125,130,240,184,341,401,779,930,924,1214,1459,
       2095,2960,2993,4528,2516,2509,4183,3935,4332,6615,6933,6824,4740,
       4450,4923,6173,6813,6365,4933,4031,3252,4288,5633,4939,3936,3281,
       2402,2218,2138,2543,2945,3699,2327,2018,1323,1388,2195,2481,0,0,
       0,0,0,0,0,0)
g3= c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,
      78,72,94,147,185,234,239,573,335,466,587,769,778,1247,1492,1797,977,
      2313,2651,2547,3497,3590,3233,3526,4207,5322,5986,6557,5560,4789,
      5249,5210,6203,5909,5974,5217,4050,4053,4782,4668,4585,4805,4316,
      3599,3039,3836,4204,3951,4694,4092,3153,3961,2667,3786,3493,3491,
      3047,2256,2729,3370,2646,0,0,0,0,0,0,0,0)
Incidence = c(g1, g2, g3)
Country = c(rep("China", length(Index)), rep("Germany", length(Index)),
            rep("Italy", length(Index)))
df = data.frame(Index, Incidence, Country)
plot(df$Incidence ~ df$Index,
     col = c("red", "black", "blue")[df$Country],
     type = "l", lwd = 2,
     xaxt = "n",
     xlab = expression(bold("Date")),
     ylab = expression(bold("Incidence")),
     main = "Raw values")
```

What am I missing?
Thank you

-- 
Best regards,
Luigi

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Apr 24 10:20:02 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 24 Apr 2020 11:20:02 +0300
Subject: [R] Error in colouring by group in core plot R
In-Reply-To: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
References: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
Message-ID: <CAGgJW75WrrXLwjEFaZNu+jRuxQ4XUAXP3AG=g17qngnpJYOMyg@mail.gmail.com>

Hi Luigi,
the problem is not the first graph vs the second graph. The first
graph would also show the same effect if you added type='l' to the
plot command.
There are various ways to approach this. A quick search turned up the
following which gives you different options.
https://stackoverflow.com/questions/14860078/plot-multiple-lines-data-series-each-with-unique-color-in-r

HTH,
Eric



On Fri, Apr 24, 2020 at 10:25 AM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I am trying to make an epidemic plot of the COVID pandemic using the core
> plot function. I am looking at three countries and the countries are as
> factors. The idea is to colour the entry by country, following this scheme:
> ```
> df = data.frame(index = 1:10,
>                 value = c(rnorm(10), rnorm(10), rnorm(10)),
>                 set = c(rep("Group 1", 3), rep("Group 2", 3), rep("Group
> 3", 4)))
> plot(df$index ~ df$value, col=c("blue", "orange", "purple")[df$set])
> ```
> But in the actual graph there is only one colour:
> ```
> Index = c(1:101)
> g1 = c(0,259,457,688,769,1771,1459,1737,1981,2099,2589,2825,3235,3884,3694,
>
>  3143,3385,2652,2973,2467,2015,14108,5090,2641,2008,2048,1888,1749,391,
>        889,823,648,214,508,406,433,327,427,573,202,125,119,139,143,99,44,40,
>
>  0,0,0,0,0,0,0,0,0,0,0,0,46,39,78,47,67,55,54,45,0,79,36,35,0,0,0,39,0,
>        0,63,42,46,99,108,89,46,46,0,325,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
> g2 =
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>        0,0,0,0,0,0,0,59,283,125,130,240,184,341,401,779,930,924,1214,1459,
>        2095,2960,2993,4528,2516,2509,4183,3935,4332,6615,6933,6824,4740,
>        4450,4923,6173,6813,6365,4933,4031,3252,4288,5633,4939,3936,3281,
>        2402,2218,2138,2543,2945,3699,2327,2018,1323,1388,2195,2481,0,0,
>        0,0,0,0,0,0)
> g3= c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,
>       78,72,94,147,185,234,239,573,335,466,587,769,778,1247,1492,1797,977,
>       2313,2651,2547,3497,3590,3233,3526,4207,5322,5986,6557,5560,4789,
>       5249,5210,6203,5909,5974,5217,4050,4053,4782,4668,4585,4805,4316,
>       3599,3039,3836,4204,3951,4694,4092,3153,3961,2667,3786,3493,3491,
>       3047,2256,2729,3370,2646,0,0,0,0,0,0,0,0)
> Incidence = c(g1, g2, g3)
> Country = c(rep("China", length(Index)), rep("Germany", length(Index)),
>             rep("Italy", length(Index)))
> df = data.frame(Index, Incidence, Country)
> plot(df$Incidence ~ df$Index,
>      col = c("red", "black", "blue")[df$Country],
>      type = "l", lwd = 2,
>      xaxt = "n",
>      xlab = expression(bold("Date")),
>      ylab = expression(bold("Incidence")),
>      main = "Raw values")
> ```
>
> What am I missing?
> Thank you
>
> --
> Best regards,
> Luigi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Apr 24 12:44:12 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 24 Apr 2020 20:44:12 +1000
Subject: [R] Error in colouring by group in core plot R
In-Reply-To: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
References: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
Message-ID: <CA+8X3fUe5dOyzhvA+uGZr0m=G-zc865nPhSEpjH=z_R65bhjnw@mail.gmail.com>

Hi Luigi,
This is pretty easy using "plot" and "lines":

# assume your example data
plot(g1,col ="red",type = "l", lwd = 2,
     xlab = "Days since start", ylab = "Count of infections",
     main = "Daily cases of COVID-19")
lines(g2,col="black", lwd = 2)
lines(g3,col="blue", lwd = 2)
text(c(15,80,53),rep(6000,3),
 c("China","Germany","Italy"),col=c("red","black","blue"))

Jim

On Fri, Apr 24, 2020 at 5:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I am trying to make an epidemic plot of the COVID pandemic using the core
> plot function. I am looking at three countries and the countries are as
> factors. The idea is to colour the entry by country, following this scheme:
> ```
> df = data.frame(index = 1:10,
>                 value = c(rnorm(10), rnorm(10), rnorm(10)),
>                 set = c(rep("Group 1", 3), rep("Group 2", 3), rep("Group
> 3", 4)))
> plot(df$index ~ df$value, col=c("blue", "orange", "purple")[df$set])
> ```
> But in the actual graph there is only one colour:
> ```
> Index = c(1:101)
> g1 = c(0,259,457,688,769,1771,1459,1737,1981,2099,2589,2825,3235,3884,3694,
>
>  3143,3385,2652,2973,2467,2015,14108,5090,2641,2008,2048,1888,1749,391,
>        889,823,648,214,508,406,433,327,427,573,202,125,119,139,143,99,44,40,
>
>  0,0,0,0,0,0,0,0,0,0,0,0,46,39,78,47,67,55,54,45,0,79,36,35,0,0,0,39,0,
>        0,63,42,46,99,108,89,46,46,0,325,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
> g2 =
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>        0,0,0,0,0,0,0,59,283,125,130,240,184,341,401,779,930,924,1214,1459,
>        2095,2960,2993,4528,2516,2509,4183,3935,4332,6615,6933,6824,4740,
>        4450,4923,6173,6813,6365,4933,4031,3252,4288,5633,4939,3936,3281,
>        2402,2218,2138,2543,2945,3699,2327,2018,1323,1388,2195,2481,0,0,
>        0,0,0,0,0,0)
> g3= c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,
>       78,72,94,147,185,234,239,573,335,466,587,769,778,1247,1492,1797,977,
>       2313,2651,2547,3497,3590,3233,3526,4207,5322,5986,6557,5560,4789,
>       5249,5210,6203,5909,5974,5217,4050,4053,4782,4668,4585,4805,4316,
>       3599,3039,3836,4204,3951,4694,4092,3153,3961,2667,3786,3493,3491,
>       3047,2256,2729,3370,2646,0,0,0,0,0,0,0,0)
> Incidence = c(g1, g2, g3)
> Country = c(rep("China", length(Index)), rep("Germany", length(Index)),
>             rep("Italy", length(Index)))
> df = data.frame(Index, Incidence, Country)
> plot(df$Incidence ~ df$Index,
>      col = c("red", "black", "blue")[df$Country],
>      type = "l", lwd = 2,
>      xaxt = "n",
>      xlab = expression(bold("Date")),
>      ylab = expression(bold("Incidence")),
>      main = "Raw values")
> ```
>
> What am I missing?
> Thank you
>
> --
> Best regards,
> Luigi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr 24 13:31:14 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 24 Apr 2020 12:31:14 +0100
Subject: [R] Error in colouring by group in core plot R
In-Reply-To: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
References: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
Message-ID: <1ba7a995-999d-6c7c-9788-85117758f4fa@sapo.pt>

Hello,

This is probably off-topic since you have chosen base graphics but this 
is much easier with ggplot.


library(ggplot2)

ggplot(df, aes(Index, Incidence, colour = Country)) +
   geom_line() +
   scale_colour_manual(values = c("red", "black", "blue")) +
   theme_minimal()


Hope this helps,

Rui Barradas


?s 08:24 de 24/04/20, Luigi Marongiu escreveu:
> Hello,
> I am trying to make an epidemic plot of the COVID pandemic using the core
> plot function. I am looking at three countries and the countries are as
> factors. The idea is to colour the entry by country, following this scheme:
> ```
> df = data.frame(index = 1:10,
>                  value = c(rnorm(10), rnorm(10), rnorm(10)),
>                  set = c(rep("Group 1", 3), rep("Group 2", 3), rep("Group
> 3", 4)))
> plot(df$index ~ df$value, col=c("blue", "orange", "purple")[df$set])
> ```
> But in the actual graph there is only one colour:
> ```
> Index = c(1:101)
> g1 = c(0,259,457,688,769,1771,1459,1737,1981,2099,2589,2825,3235,3884,3694,
> 
>   3143,3385,2652,2973,2467,2015,14108,5090,2641,2008,2048,1888,1749,391,
>         889,823,648,214,508,406,433,327,427,573,202,125,119,139,143,99,44,40,
> 
>   0,0,0,0,0,0,0,0,0,0,0,0,46,39,78,47,67,55,54,45,0,79,36,35,0,0,0,39,0,
>         0,63,42,46,99,108,89,46,46,0,325,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
> g2 =
> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>         0,0,0,0,0,0,0,59,283,125,130,240,184,341,401,779,930,924,1214,1459,
>         2095,2960,2993,4528,2516,2509,4183,3935,4332,6615,6933,6824,4740,
>         4450,4923,6173,6813,6365,4933,4031,3252,4288,5633,4939,3936,3281,
>         2402,2218,2138,2543,2945,3699,2327,2018,1323,1388,2195,2481,0,0,
>         0,0,0,0,0,0)
> g3= c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,
>        78,72,94,147,185,234,239,573,335,466,587,769,778,1247,1492,1797,977,
>        2313,2651,2547,3497,3590,3233,3526,4207,5322,5986,6557,5560,4789,
>        5249,5210,6203,5909,5974,5217,4050,4053,4782,4668,4585,4805,4316,
>        3599,3039,3836,4204,3951,4694,4092,3153,3961,2667,3786,3493,3491,
>        3047,2256,2729,3370,2646,0,0,0,0,0,0,0,0)
> Incidence = c(g1, g2, g3)
> Country = c(rep("China", length(Index)), rep("Germany", length(Index)),
>              rep("Italy", length(Index)))
> df = data.frame(Index, Incidence, Country)
> plot(df$Incidence ~ df$Index,
>       col = c("red", "black", "blue")[df$Country],
>       type = "l", lwd = 2,
>       xaxt = "n",
>       xlab = expression(bold("Date")),
>       ylab = expression(bold("Incidence")),
>       main = "Raw values")
> ```
> 
> What am I missing?
> Thank you
>


From iuke-tier@ey m@iii@g oii uiow@@edu  Fri Apr 24 14:51:48 2020
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Fri, 24 Apr 2020 07:51:48 -0500 (CDT)
Subject: [R] [External] Re:  Error in colouring by group in core plot R
In-Reply-To: <CA+8X3fUe5dOyzhvA+uGZr0m=G-zc865nPhSEpjH=z_R65bhjnw@mail.gmail.com>
References: <CAMk+s2R7wvayMEn31z2ABCSuJ8dm0f78T6W-5cNAP9MXe3vC4A@mail.gmail.com>
 <CA+8X3fUe5dOyzhvA+uGZr0m=G-zc865nPhSEpjH=z_R65bhjnw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.2004240748550.3189@luke-Latitude-7480>

Or using matplot:

matplot(cbind(g1, g2, g3), type = "l",
         col = c("red", "black", "blue"), lty = 1, lwd = 2)

Best,

luke

On Fri, 24 Apr 2020, Jim Lemon wrote:

> Hi Luigi,
> This is pretty easy using "plot" and "lines":
>
> # assume your example data
> plot(g1,col ="red",type = "l", lwd = 2,
>     xlab = "Days since start", ylab = "Count of infections",
>     main = "Daily cases of COVID-19")
> lines(g2,col="black", lwd = 2)
> lines(g3,col="blue", lwd = 2)
> text(c(15,80,53),rep(6000,3),
> c("China","Germany","Italy"),col=c("red","black","blue"))
>
> Jim
>
> On Fri, Apr 24, 2020 at 5:25 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I am trying to make an epidemic plot of the COVID pandemic using the core
>> plot function. I am looking at three countries and the countries are as
>> factors. The idea is to colour the entry by country, following this scheme:
>> ```
>> df = data.frame(index = 1:10,
>>                 value = c(rnorm(10), rnorm(10), rnorm(10)),
>>                 set = c(rep("Group 1", 3), rep("Group 2", 3), rep("Group
>> 3", 4)))
>> plot(df$index ~ df$value, col=c("blue", "orange", "purple")[df$set])
>> ```
>> But in the actual graph there is only one colour:
>> ```
>> Index = c(1:101)
>> g1 = c(0,259,457,688,769,1771,1459,1737,1981,2099,2589,2825,3235,3884,3694,
>>
>>  3143,3385,2652,2973,2467,2015,14108,5090,2641,2008,2048,1888,1749,391,
>>        889,823,648,214,508,406,433,327,427,573,202,125,119,139,143,99,44,40,
>>
>>  0,0,0,0,0,0,0,0,0,0,0,0,46,39,78,47,67,55,54,45,0,79,36,35,0,0,0,39,0,
>>        0,63,42,46,99,108,89,46,46,0,325,0,0,0,0,0,0,0,0,0,0,0,0,0,0)
>> g2 =
>> c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
>>        0,0,0,0,0,0,0,59,283,125,130,240,184,341,401,779,930,924,1214,1459,
>>        2095,2960,2993,4528,2516,2509,4183,3935,4332,6615,6933,6824,4740,
>>        4450,4923,6173,6813,6365,4933,4031,3252,4288,5633,4939,3936,3281,
>>        2402,2218,2138,2543,2945,3699,2327,2018,1323,1388,2195,2481,0,0,
>>        0,0,0,0,0,0)
>> g3= c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,
>>       78,72,94,147,185,234,239,573,335,466,587,769,778,1247,1492,1797,977,
>>       2313,2651,2547,3497,3590,3233,3526,4207,5322,5986,6557,5560,4789,
>>       5249,5210,6203,5909,5974,5217,4050,4053,4782,4668,4585,4805,4316,
>>       3599,3039,3836,4204,3951,4694,4092,3153,3961,2667,3786,3493,3491,
>>       3047,2256,2729,3370,2646,0,0,0,0,0,0,0,0)
>> Incidence = c(g1, g2, g3)
>> Country = c(rep("China", length(Index)), rep("Germany", length(Index)),
>>             rep("Italy", length(Index)))
>> df = data.frame(Index, Incidence, Country)
>> plot(df$Incidence ~ df$Index,
>>      col = c("red", "black", "blue")[df$Country],
>>      type = "l", lwd = 2,
>>      xaxt = "n",
>>      xlab = expression(bold("Date")),
>>      ylab = expression(bold("Incidence")),
>>      main = "Raw values")
>> ```
>>
>> What am I missing?
>> Thank you
>>
>> --
>> Best regards,
>> Luigi
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From @hubh@@m|t@@@@h@n| @end|ng |rom gm@||@com  Fri Apr 24 16:07:44 2020
From: @hubh@@m|t@@@@h@n| @end|ng |rom gm@||@com (Shubhasmita Sahani)
Date: Fri, 24 Apr 2020 19:37:44 +0530
Subject: [R] Problem with loop in folders
Message-ID: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>

Hi Everyone,
I am trying to loop through the folders in the major working directory.
Read the dbf file into the data frame then save the data frame as CSV file
in another folder.
For this, I have written this code, But not able to figure out where it is
going wrong. Any ideas will be of great support.


 setwd(choose.dir())
 csvpath= "C:/plan/Learning/dummydata/csv/"
 a<-list.dirs()
 inpath<-"C:/workplan/Q2/Project1"

 for (folder in list.dirs()[-1]) {

   path<-setwd(paste0("inpath",folder))
   dbf<-list.files(path, pattern = "*ward.dbf")
   df <- read.dbf(dbf)
   dbfname<-basename(dbf)
   name<-file_path_sans_ext(dbfname)  # get the name of the file like
agra_ward
   write.csv( df, file = paste0("csvpath",name,"csv"))
   print(path)

 }





-- 
Thanks & Regards,
Shubhasmita Sahani

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 24 16:50:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 24 Apr 2020 07:50:47 -0700
Subject: [R] Problem with loop in folders
In-Reply-To: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
References: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
Message-ID: <CAGxFJbQB+zFZwho-QqcBw+bG-vpu4X3VXQU12wvWZdx0fwYyFA@mail.gmail.com>

What package is "read.dbf" from? What error message/behavior did you see?
Should it be:
 path<-setwd(paste0("inpath/",folder)) ## did you forget the "/" ?

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Apr 24, 2020 at 7:08 AM Shubhasmita Sahani
<shubhasmita.sahani at gmail.com> wrote:
>
> Hi Everyone,
> I am trying to loop through the folders in the major working directory.
> Read the dbf file into the data frame then save the data frame as CSV file
> in another folder.
> For this, I have written this code, But not able to figure out where it is
> going wrong. Any ideas will be of great support.
>
>
>  setwd(choose.dir())
>  csvpath= "C:/plan/Learning/dummydata/csv/"
>  a<-list.dirs()
>  inpath<-"C:/workplan/Q2/Project1"
>
>  for (folder in list.dirs()[-1]) {
>
>    path<-setwd(paste0("inpath",folder))
>    dbf<-list.files(path, pattern = "*ward.dbf")
>    df <- read.dbf(dbf)
>    dbfname<-basename(dbf)
>    name<-file_path_sans_ext(dbfname)  # get the name of the file like
> agra_ward
>    write.csv( df, file = paste0("csvpath",name,"csv"))
>    print(path)
>
>  }
>
>
>
>
>
> --
> Thanks & Regards,
> Shubhasmita Sahani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Fri Apr 24 17:18:21 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 24 Apr 2020 11:18:21 -0400
Subject: [R] Problem with loop in folders
In-Reply-To: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
References: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
Message-ID: <CAM_vjunjbC5rLYVYD8HaVdh5ewcwOdmF-UkUp55Do=p__AX9OQ@mail.gmail.com>

I suspect much if not all of your trouble would be eliminated by using
file.path() instead of paste0().

https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/file.path

(Also check your file name - you probably want a . between name and
csv, so using paste(name, "csv", sep = ".") would create a more usual
file name.

It's always a good idea to work thru your loop by hand once, and look
at all the intermediate steps. Often that quickly shows you where you
went wrong.

Sarah

On Fri, Apr 24, 2020 at 10:08 AM Shubhasmita Sahani
<shubhasmita.sahani at gmail.com> wrote:
>
> Hi Everyone,
> I am trying to loop through the folders in the major working directory.
> Read the dbf file into the data frame then save the data frame as CSV file
> in another folder.
> For this, I have written this code, But not able to figure out where it is
> going wrong. Any ideas will be of great support.
>
>
>  setwd(choose.dir())
>  csvpath= "C:/plan/Learning/dummydata/csv/"
>  a<-list.dirs()
>  inpath<-"C:/workplan/Q2/Project1"
>
>  for (folder in list.dirs()[-1]) {
>
>    path<-setwd(paste0("inpath",folder))
>    dbf<-list.files(path, pattern = "*ward.dbf")
>    df <- read.dbf(dbf)
>    dbfname<-basename(dbf)
>    name<-file_path_sans_ext(dbfname)  # get the name of the file like
> agra_ward
>    write.csv( df, file = paste0("csvpath",name,"csv"))
>    print(path)
>
>  }
>
>
>
>
>
> --
> Thanks & Regards,
> Shubhasmita Sahani
>
-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@icei m@iii@g oii i@iomed@sid@cu  Fri Apr 24 17:51:39 2020
From: m@icei m@iii@g oii i@iomed@sid@cu (m@icei m@iii@g oii i@iomed@sid@cu)
Date: Fri, 24 Apr 2020 11:51:39 -0400
Subject: [R] incidence_fit  model for simulation
Message-ID: <20200424115139.16354za4mf2feoln@webmail.sld.cu>

Hello

How can I make a prediction with object type incidence_fit.
incidence_fit object is returned by the function fit in library(incidence).

Best regard
maicel


----------------------------------------------------------------




--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From @@r@h@go@|ee @end|ng |rom gm@||@com  Fri Apr 24 17:58:20 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 24 Apr 2020 11:58:20 -0400
Subject: [R] incidence_fit model for simulation
In-Reply-To: <20200424115139.16354za4mf2feoln@webmail.sld.cu>
References: <20200424115139.16354za4mf2feoln@webmail.sld.cu>
Message-ID: <CAM_vju=mwoc9AxHtv0LuPBDqQB2Z7jyikGwnCKjZiYfuWTWu2A@mail.gmail.com>

According to this handy vignette, the object contains the predicted
values in $pred

https://cran.r-project.org/web/packages/incidence/vignettes/overview.html

early.fit <- fit(i.7[1:20])
early.fit
#> <incidence_fit object>
#>
#> $model: regression of log-incidence over time
#>
#> $info: list containing the following items:
#>   $r (daily growth rate):
#> [1] 0.03175771
#>
#>   $r.conf (confidence interval):
#>           2.5 %     97.5 %
#> [1,] 0.02596229 0.03755314
#>
#>   $doubling (doubling time in days):
#> [1] 21.8261
#>
#>   $doubling.conf (confidence interval):
#>         2.5 %   97.5 %
#> [1,] 18.45777 26.69823
#>
#>   $pred: data.frame of incidence predictions (20 rows, 5 columns)

Sarah

On Fri, Apr 24, 2020 at 11:52 AM <maicel at infomed.sld.cu> wrote:
>
> Hello
>
> How can I make a prediction with object type incidence_fit.
> incidence_fit object is returned by the function fit in library(incidence).
>
> Best regard
> maicel
>
>
> ----------------------------------------------------------------
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From robert@dod|er @end|ng |rom gm@||@com  Fri Apr 24 20:11:44 2020
From: robert@dod|er @end|ng |rom gm@||@com (Robert Dodier)
Date: Fri, 24 Apr 2020 11:11:44 -0700
Subject: [R] Options for zooming plots other than zm()
Message-ID: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>

Hi,

I am making some plots with plot() which have a fair number of points
(thousands) and I would like to be able to interactively select a
region of the plot and zoom in on it. I tried the zoom package which
has the function zm() but I found that it was unworkably slow to
refresh the display. I guess I can set the x and y range via xlim and
ylim but I was hoping to do it interactively. Does someone have a
suggestion for that?

I looked at ggplot2 but I wasn't able to find something about
interactive zooming, only noninteractive via plot limits. Perhaps I
have overlooked something there?

I have searched the mailing list archive and web pages in general but
I haven't found anything other than zm(). Thank you in advance for
your help, I appreciate it very much.

best,

Robert Dodier


From |vmcph@|| @end|ng |rom gm@||@com  Fri Apr 24 21:52:04 2020
From: |vmcph@|| @end|ng |rom gm@||@com (Ian McPhail)
Date: Fri, 24 Apr 2020 15:52:04 -0400
Subject: [R] Computing tetrachoric covariance matrices for multiple imputed
 datasets using MICE package
Message-ID: <CAHF845G1bre=LaX1ZxgUxp3hooDntn9zk82TdVr0GEs+D0M-4Q@mail.gmail.com>

Using the mice package, I have created multiple imputed datasets to deal
with missing data. I am looking for an example of the R code to use in
order to analyze the set of imputed datasets using tetrachoric correlations
in such a way that after pooling, I will have a combined tetrachoric
covariance-variance matrix to use as input for an exploratory factor
analysis. I have taken a few attempts at the with() command in the mice
package, using the poly() function, but do not quite know what I'm doing so
am out of my depth with the R code. All of the examples for using the
with() command in the mice package involve lm() and regression formula.

I provide some examples below of what I have attempted, but I think my
question is about not understanding what the expression part of the with()
function code is about and how to implement different analysis onto the
imputed datasets using the with() function.

For example, using an example with only 3 variables, I have attempted the
following code,

imp<- mice(df, meth = pmm, m = 25)

fit <- with(imp, poly(var1, var2, var3))

Alternatively, I have tried:

imp<- mice(df, meth = pmm, m = 25)

fit <- with(imp, poly(var1:var3))

Alternatively, I have tried:

imp<- mice(df, meth = pmm, m = 25)

fit <- with(imp, poly(imp))

I have attempted the same series of code, but using the polychoric()
function in the psych package.

The data I am working with are 22 scale items that have a yes/no response
type. I am not very savvy with R, but I appreciate any help people are able
to provide.

tia,

Ian

	[[alternative HTML version deleted]]


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Apr 25 08:43:39 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 25 Apr 2020 12:13:39 +0530
Subject: [R] Options for zooming plots other than zm()
In-Reply-To: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
References: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
Message-ID: <CADfFDC60=Nf2JCYWYBMYT0GARa9PccT97Af1B3ogA-+8n20jwA@mail.gmail.com>

On Sat 25 Apr, 2020, 12:10 PM Robert Dodier, <robert.dodier at gmail.com>
wrote:

> Hi,
>
> I am making some plots with plot() which have a fair number of points
> (thousands) and I would like to be able to interactively select a
> region of the plot and zoom in on it. I tried the zoom package which
> has the function zm() but I found that it was unworkably slow to
> refresh the display. I guess I can set the x and y range via xlim and
> ylim but I was hoping to do it interactively. Does someone have a
> suggestion for that?
>
> I looked at ggplot2 but I wasn't able to find something about
> interactive zooming, only noninteractive via plot limits. Perhaps I
> have overlooked something there?
>


How about plotly? It supports ggplot2 plots through ggplotly().

-Deepayan


> I have searched the mailing list archive and web pages in general but
> I haven't found anything other than zm(). Thank you in advance for
> your help, I appreciate it very much.
>
> best,
>
> Robert Dodier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 25 08:52:04 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 24 Apr 2020 23:52:04 -0700
Subject: [R] Options for zooming plots other than zm()
In-Reply-To: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
References: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
Message-ID: <04FA0220-3622-4E75-987C-029D061E6BB1@dcn.davis.ca.us>

Plotly and dygraphs support this.

On April 24, 2020 11:11:44 AM PDT, Robert Dodier <robert.dodier at gmail.com> wrote:
>Hi,
>
>I am making some plots with plot() which have a fair number of points
>(thousands) and I would like to be able to interactively select a
>region of the plot and zoom in on it. I tried the zoom package which
>has the function zm() but I found that it was unworkably slow to
>refresh the display. I guess I can set the x and y range via xlim and
>ylim but I was hoping to do it interactively. Does someone have a
>suggestion for that?
>
>I looked at ggplot2 but I wasn't able to find something about
>interactive zooming, only noninteractive via plot limits. Perhaps I
>have overlooked something there?
>
>I have searched the mailing list archive and web pages in general but
>I haven't found anything other than zm(). Thank you in advance for
>your help, I appreciate it very much.
>
>best,
>
>Robert Dodier
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Sat Apr 25 13:12:57 2020
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Sat, 25 Apr 2020 16:42:57 +0530
Subject: [R] [EXTERNAL] Re: overlaying graphs in xYplot (Hmisc)
In-Reply-To: <BY5PR09MB5073E7D8349ACF3D5513407AD9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
References: <BY5PR09MB5073ED7856C76D94B541F508D9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
 <818087e9-e3bc-36d7-f23b-e45a3d58fc69@comcast.net>
 <BY5PR09MB5073E7D8349ACF3D5513407AD9D20@BY5PR09MB5073.namprd09.prod.outlook.com>
Message-ID: <CADfFDC6cfm7yzxRVPm=90OsVRH3ZrPGB=M1_n4FJx=SUW0YMSA@mail.gmail.com>

On Wed, Apr 22, 2020 at 11:44 PM Cade, Brian S via R-help
<r-help at r-project.org> wrote:
>
> All the xYplot() functions using Cbind() or cbind() does just exactly what I want (Cbind
> provides aplot of 3 summary statistics and cbind provides the raw values).  I just cannot
> find anyway to overlay them.

You are not really helping yourself by not providing reproducible code.

If you are lucky, the following might give you what you want:

library(latticeExtra)
p1 <- xYplot(...) # your first plot
p2 <- xYplot(...) # your second plot
p1 + p2

Or it might not.

-Deepayan

> Brian
>
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> tel:  970 226-9326
>
> ________________________________
> From: David Winsemius <dwinsemius at comcast.net>
> Sent: Wednesday, April 22, 2020 11:10 AM
> To: Cade, Brian S <cadeb at usgs.gov>; r-help <r-help at r-project.org>
> Subject: [EXTERNAL] Re: [R] overlaying graphs in xYplot (Hmisc)
>
>
> On 4/22/20 7:31 AM, Cade, Brian S via R-help wrote:
> > Hi All.  I am trying to construct a graph using the xYplot() function in Hmisc package (thank you Frank Harrell) taking advantage of the Cbind() argument for plotting the median, 10th, and 90th quantiles and also the cbind() argument for individual data values.  I know how to do both of these separately, but I would really like to have them overlayed on each other.  I've tried various approaches with add=T, new=T, etc and none of those seem to work with xYplot().  Any pointers?
>
>
> I don't know the answer and you have presented no data or code, so I'm
> just going to address the question in the most halting and vague manner
> by first looking at the code and then looking at the documentaion.
> (That's possibly the reverse of the proper order.) The plotting
> functions in pkg:Hmisc can be in any of the three plotting paradigms. If
> you look at the code for xYplot it becomes almost immediately obvious
> that it is operative within the lattice plotting paradigm. (That means
> that using `new=T` or `add=T` would not work since those are base
> plotting strategies.)
>
>
> I'm not sure what the term "Cbind argument" might mean to you (and I've
> never used it), but I suspect you are intending to use a call to `Cbind`
> on the left hand side of a formula argument for xYplot.
>
> Re: The goal of "plotting the median, 10th, and 90th quantiles and also
> the cbind() argument for individual data values."
>
> It appears to me from the documentation that you would be expected to do some pre-processing to aggregate your data into a summary format by groups before plotting and then use named arguments to Cbind to designate the appropriate columns to be used for median and the outer quantiles. See the example using the dataset named dfr in the ?xYplot page following these comments:
>
> # The following example uses the summarize function in Hmisc to
> # compute the median and outer quartiles.  The outer quartiles are
> # displayed using "error bars"
>
> It should be trivial to modify the call to `summarize` to get .1 and .9 quantiles instead of quartiles.
>
> --
> David.
>
>
>
> >
> > Brian
> >
> >
> > Brian S. Cade, PhD
> >
> > U. S. Geological Survey
> > Fort Collins Science Center
> > 2150 Centre Ave., Bldg. C
> > Fort Collins, CO  80526-8818
> >
> > email:  cadeb at usgs.gov<mailto:brian_cade at usgs.gov>
> > tel:  970 226-9326
> >
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v|to@muggeo @end|ng |rom un|p@@|t  Sat Apr 25 18:41:08 2020
From: v|to@muggeo @end|ng |rom un|p@@|t (Vito Michele Rosario Muggeo)
Date: Sat, 25 Apr 2020 18:41:08 +0200
Subject: [R] incidence_fit model for simulation
In-Reply-To: <CAM_vju=mwoc9AxHtv0LuPBDqQB2Z7jyikGwnCKjZiYfuWTWu2A@mail.gmail.com>
References: <20200424115139.16354za4mf2feoln@webmail.sld.cu>
 <CAM_vju=mwoc9AxHtv0LuPBDqQB2Z7jyikGwnCKjZiYfuWTWu2A@mail.gmail.com>
Message-ID: <20200425184108.Horde.IeYs865FVLK5ITomHOUCQQd@webmail.unipa.it>

dear all,
In addition to the thorough and intuitive incidence package, I would  
like to indicate a technical report on the same topic. R code and  
worked examples are reported.

https://www.researchgate.net/publication/340664370_Modelling_COVID-19_outbreak_segmented_regression_to_assess_lockdown_effectiveness

best,
vito



Sarah Goslee <sarah.goslee at gmail.com> ha scritto:

> According to this handy vignette, the object contains the predicted
> values in $pred
>
> https://cran.r-project.org/web/packages/incidence/vignettes/overview.html
>
> early.fit <- fit(i.7[1:20])
> early.fit
> #> <incidence_fit object>
> #>
> #> $model: regression of log-incidence over time
> #>
> #> $info: list containing the following items:
> #>   $r (daily growth rate):
> #> [1] 0.03175771
> #>
> #>   $r.conf (confidence interval):
> #>           2.5 %     97.5 %
> #> [1,] 0.02596229 0.03755314
> #>
> #>   $doubling (doubling time in days):
> #> [1] 21.8261
> #>
> #>   $doubling.conf (confidence interval):
> #>         2.5 %   97.5 %
> #> [1,] 18.45777 26.69823
> #>
> #>   $pred: data.frame of incidence predictions (20 rows, 5 columns)
>
> Sarah
>
> On Fri, Apr 24, 2020 at 11:52 AM <maicel at infomed.sld.cu> wrote:
>>
>> Hello
>>
>> How can I make a prediction with object type incidence_fit.
>> incidence_fit object is returned by the function fit in library(incidence).
>>
>> Best regard
>> maicel
>>
>>
>> ----------------------------------------------------------------
>>
>>
>>
>>
>> --
>> Este mensaje le ha llegado mediante el servicio de correo  
>> electronico que ofrece Infomed para respaldar el cumplimiento de  
>> las misiones del Sistema Nacional de Salud. La persona que envia  
>> este correo asume el compromiso de usar el servicio a tales fines y  
>> cumplir con las regulaciones establecidas
>>
>> Infomed: http://www.sld.cu/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d@rgo@ch @end|ng |rom gm@||@com  Sat Apr 25 20:53:35 2020
From: d@rgo@ch @end|ng |rom gm@||@com (Fredrik Karlsson)
Date: Sat, 25 Apr 2020 20:53:35 +0200
Subject: [R] Problem with loop in folders
In-Reply-To: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
References: <CAA5NU8oUUX8S5HwY5RD4rmycUdVKLwso_+G5GtAbioDrpXOaUQ@mail.gmail.com>
Message-ID: <CANO=ohL8Ag36E9VQg_eG8uiXO+m1jAi8ADG_BGCsPzjADdA+Cw@mail.gmail.com>

Hi,

I am sorry if I am misunderstanding what you are trying to do here, but can
you simplify it this way?
 (unfortualtely, this is untested since I dont have a suitable set of files
and a directory structure to test against)

dbifiles <- list.files(pattern="*.dbi",recursive=TRUE)

csvfiles <- gsub("dbi$","csv",dbifiles)

for(i in seq_along(csvfiles)){

    df <- read.dbf(dbfiles[i])

    write.csv( df, file =csvfiles[i])

}

or something along these lines?

Fredrik

On Fri, Apr 24, 2020 at 4:08 PM Shubhasmita Sahani <
shubhasmita.sahani at gmail.com> wrote:

> Hi Everyone,
> I am trying to loop through the folders in the major working directory.
> Read the dbf file into the data frame then save the data frame as CSV file
> in another folder.
> For this, I have written this code, But not able to figure out where it is
> going wrong. Any ideas will be of great support.
>
>
>  setwd(choose.dir())
>  csvpath= "C:/plan/Learning/dummydata/csv/"
>  a<-list.dirs()
>  inpath<-"C:/workplan/Q2/Project1"
>
>  for (folder in list.dirs()[-1]) {
>
>    path<-setwd(paste0("inpath",folder))
>    dbf<-list.files(path, pattern = "*ward.dbf")
>    df <- read.dbf(dbf)
>    dbfname<-basename(dbf)
>    name<-file_path_sans_ext(dbfname)  # get the name of the file like
> agra_ward
>    write.csv( df, file = paste0("csvpath",name,"csv"))
>    print(path)
>
>  }
>
>
>
>
>
> --
> Thanks & Regards,
> Shubhasmita Sahani
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
"Life is like a trumpet - if you don't put anything into it, you don't get
anything out of it."

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sat Apr 25 21:02:59 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sat, 25 Apr 2020 19:02:59 +0000 (UTC)
Subject: [R] Fit Gaussian curve on my data ?
References: <1530976294.485495.1587841379304.ref@mail.yahoo.com>
Message-ID: <1530976294.485495.1587841379304@mail.yahoo.com>

Dear R-experts,

I am trying to fit a gaussian density curve. More precisely, I would like to obtain the fitted "Gaussian curve". 
"m" is the gaussian mean, "sd" is the standard deviation and "k" is an arbitrary scaling parameter (since the gaussian density is constrained to integrate to 1, whereas my data isn't). 
There is no error message. In my opinion, the last command of my reproducible R script is not doing its job !

Many thanks for your lights.

############################################################
a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))

b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)

d <-as.numeric(a)

m<-11.84

sd<-3.93

k<-359.77

plot(b~d)

plot(function(d) k*exp(-0.5*(d-m)^2/sd^2),col=2,add=TRUE,xlim=range(d))
############################################################
?


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Apr 25 21:27:28 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 25 Apr 2020 22:27:28 +0300
Subject: [R] Fit Gaussian curve on my data ?
In-Reply-To: <1530976294.485495.1587841379304@mail.yahoo.com>
References: <1530976294.485495.1587841379304.ref@mail.yahoo.com>
 <1530976294.485495.1587841379304@mail.yahoo.com>
Message-ID: <20200425222728.19307f66@Tarkus>

On Sat, 25 Apr 2020 19:02:59 +0000 (UTC)
varin sacha via R-help <r-help at r-project.org> wrote:

> plot(function(d)
> k*exp(-0.5*(d-m)^2/sd^2),col=2,add=TRUE,xlim=range(d))

Remove the `add=TRUE` or calculate the values manually and you'll see
that the function value is zero because the values in `d` are too big
compared to `m` (where the function peak is). Compare your result to the
following:

plot(
	function(d) k*exp(-0.5*(d-m)^2/sd^2), 
	xlim = m + 3*sd * c(-1,+1)
)

Your parameters don't quite fit the observed values.

-- 
Best regards,
Ivan


From @purd|e@@ @end|ng |rom gm@||@com  Sat Apr 25 22:07:34 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 26 Apr 2020 08:07:34 +1200
Subject: [R] Fit Gaussian curve on my data ?
In-Reply-To: <1530976294.485495.1587841379304@mail.yahoo.com>
References: <1530976294.485495.1587841379304.ref@mail.yahoo.com>
 <1530976294.485495.1587841379304@mail.yahoo.com>
Message-ID: <CAB8pepytFUBjs86dwcCAfRVJCNvhxeyqabcV6bTo7PodvwmuxA@mail.gmail.com>

Have a look at the dnorm function:
?dnorm

Notes:
(1) You'd be better to say estimate (or fit) parameters (or
coefficients) and plot the resulting normal distribution (or normal
density), rather than say fit a density curve, because someone may
think you want a kernel density estimate with a Gaussian kernel.
(2) Densities integrate to one by definition. i.e. If a function
didn't integrate to one it wouldn't be a probability density function,
but still could be a function representing a probability
distribution...

On Sun, Apr 26, 2020 at 7:09 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> I am trying to fit a gaussian density curve. More precisely, I would like to obtain the fitted "Gaussian curve".
> "m" is the gaussian mean, "sd" is the standard deviation and "k" is an arbitrary scaling parameter (since the gaussian density is constrained to integrate to 1, whereas my data isn't).
> There is no error message. In my opinion, the last command of my reproducible R script is not doing its job !
>
> Many thanks for your lights.
>
> ############################################################
> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
>
> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
>
> d <-as.numeric(a)
>
> m<-11.84
>
> sd<-3.93
>
> k<-359.77
>
> plot(b~d)
>
> plot(function(d) k*exp(-0.5*(d-m)^2/sd^2),col=2,add=TRUE,xlim=range(d))
> ############################################################
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Apr 26 03:06:58 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 26 Apr 2020 13:06:58 +1200
Subject: [R] Options for zooming plots other than zm()
In-Reply-To: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
References: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
Message-ID: <CAB8pepyt_rQY_pZ6Szyg4hyuKyqmXdWQRL--1MupUOR2Bq7vEA@mail.gmail.com>

> I am making some plots with plot() which have a fair number of points
> (thousands) and I would like to be able to interactively select a
> region of the plot and zoom in on it.

This doesn't answer your question, but I was wondering why having
thousands of data points is problematic?

Sometimes overplotting of points can make plots difficult to interpret.
(This is probably the most common problem plotting large datasets).

Taking this problem (overplotting) in generality, zooming doesn't
necessarily fix the problem, and even if it does there's a risk of
creating other problems.
Simple solutions include using semitransparent points, plotting a
(smaller) sample, or (in a limited range of situations) using
"jitter".
More sophisticated solutions include plotting binned data or plotting
bivariate kernel density estimates.
It's also possible combine approaches, say plot points on top of a
heatmap representing bivariate kernel density estimates.

If the goal is to inspect specific points, say with individual labels,
or plot high density deterministic data, then may be zooming could be
of some value.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Apr 26 04:13:51 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 26 Apr 2020 14:13:51 +1200
Subject: [R] Problem with MASS::fitdistr().
Message-ID: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>


For some reason fitdistr() does not seem to be passing on the "..." 
argument "lower" to optim() in the proper manner, and as result
falls over.

Here is my example; note that data are attached in the file "x.txt".

dhse <- function(i,alpha,beta,topn) {
    x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
    p <- dbeta(x,alpha,beta)
    if(any(!is.finite(p))) browser()
    (p/sum(p))[i]
}

lwr  <- rep(sqrt(.Machine$double.eps),2)
par0 <- c(alpha=1.010652,beta=1.929018)
x    <- dget("x.txt")
fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
                       lower=lwr)

The browser() in dhse() allows you to see that alpha has gone negative,
taking a value:

>        alpha 
> -0.001999985 

Continuing causes fitdistr() to fall over with the error message:

> Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  : 
>   non-finite finite-difference value [1]

If I eschew using fitdistr() and "roll-my-own" as follows:

foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
                                           beta=par[2],
                                           topn=topn)))}

fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)

then optim() returns a result without complaint.

Am I somehow messing up the syntax for fitdistr()?

cheers,

Rolf Turner

P. S. I've tried supplying the "method" argument, method="L-BFGS-B" 
explicitly to fitdistr(); doesn't seem to help.

R.T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: x.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200426/f142865e/attachment.txt>

From @purd|e@@ @end|ng |rom gm@||@com  Sun Apr 26 07:50:23 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 26 Apr 2020 17:50:23 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
Message-ID: <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>

I haven't run your example.
I may try tomorrow-ish if no one else answers.

But one question: Are you sure the "x" and "i" are correct in your function?
It looks like a typo...


On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> For some reason fitdistr() does not seem to be passing on the "..."
> argument "lower" to optim() in the proper manner, and as result
> falls over.
>
> Here is my example; note that data are attached in the file "x.txt".
>
> dhse <- function(i,alpha,beta,topn) {
>     x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
>     p <- dbeta(x,alpha,beta)
>     if(any(!is.finite(p))) browser()
>     (p/sum(p))[i]
> }
>
> lwr  <- rep(sqrt(.Machine$double.eps),2)
> par0 <- c(alpha=1.010652,beta=1.929018)
> x    <- dget("x.txt")
> fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
>                        lower=lwr)
>
> The browser() in dhse() allows you to see that alpha has gone negative,
> taking a value:
>
> >        alpha
> > -0.001999985
>
> Continuing causes fitdistr() to fall over with the error message:
>
> > Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
> >   non-finite finite-difference value [1]
>
> If I eschew using fitdistr() and "roll-my-own" as follows:
>
> foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
>                                            beta=par[2],
>                                            topn=topn)))}
>
> fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
>
> then optim() returns a result without complaint.
>
> Am I somehow messing up the syntax for fitdistr()?
>
> cheers,
>
> Rolf Turner
>
> P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
> explicitly to fitdistr(); doesn't seem to help.
>
> R.T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Apr 26 09:02:08 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 26 Apr 2020 19:02:08 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
Message-ID: <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>

I ran your example.
It's possible that it's another bug in the optim function.

Here's the optim call (from within fitdistr):

stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,
1, 1, 1, 4, 4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, #more lines...
1, 4, 1, 1, 1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, #removed...
4, 5, 5), topn = 5, lower = lwr, par = list(alpha = 1.010652,
    beta = 1.929018), fn = function(parm, ...) -sum(log(dens(parm, ...))),
    hessian = TRUE, method = "L-BFGS-B")

And here's dens:

function (parm, x, ...)
densfun(x, parm[1], parm[2], ...)

I can't see any reason why it should call dens with parm[1] < lower[1].

On Sun, Apr 26, 2020 at 5:50 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I haven't run your example.
> I may try tomorrow-ish if no one else answers.
>
> But one question: Are you sure the "x" and "i" are correct in your function?
> It looks like a typo...
>
>
> On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > For some reason fitdistr() does not seem to be passing on the "..."
> > argument "lower" to optim() in the proper manner, and as result
> > falls over.
> >
> > Here is my example; note that data are attached in the file "x.txt".
> >
> > dhse <- function(i,alpha,beta,topn) {
> >     x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
> >     p <- dbeta(x,alpha,beta)
> >     if(any(!is.finite(p))) browser()
> >     (p/sum(p))[i]
> > }
> >
> > lwr  <- rep(sqrt(.Machine$double.eps),2)
> > par0 <- c(alpha=1.010652,beta=1.929018)
> > x    <- dget("x.txt")
> > fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
> >                        lower=lwr)
> >
> > The browser() in dhse() allows you to see that alpha has gone negative,
> > taking a value:
> >
> > >        alpha
> > > -0.001999985
> >
> > Continuing causes fitdistr() to fall over with the error message:
> >
> > > Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
> > >   non-finite finite-difference value [1]
> >
> > If I eschew using fitdistr() and "roll-my-own" as follows:
> >
> > foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
> >                                            beta=par[2],
> >                                            topn=topn)))}
> >
> > fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
> >
> > then optim() returns a result without complaint.
> >
> > Am I somehow messing up the syntax for fitdistr()?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
> > explicitly to fitdistr(); doesn't seem to help.
> >
> > R.T.
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From you@r|@|@nou@ @end|ng |rom gm@||@com  Sun Apr 26 05:25:50 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Sat, 25 Apr 2020 23:25:50 -0400
Subject: [R] How to edit a dataframe/tibble in R console
Message-ID: <CADsEwSfWyDaXs4t6ya6ag644V90HRvKArRpLzufRFRmyVr4qxg@mail.gmail.com>

I recently installed R 3.6.3 on my windows laptop.

R version 3.6.3 (2020-02-29)

I am trying to import a stata .dta file to R

>url<-?http://www.stata-press.com/data/r10/rootstock.dta?

>library(tidyverse)

>library(haven)

>rootstock<-read_dta(url)


All works as expected.


>class(rootstock)
[1] "tbl_df"     "tbl"        "data.frame"


Now I cannot use the edit command with a tibble or a data frame


> edit(rootstock)
Error in edit.data.frame(rootstock) :
  can only handle vector and factor elements


I noticed that their is an add-on package editData for Rstudio, but I
cannot use it from the console:

>library(editData)
>editData(rootstock)
Error: RStudio not running


How can I edit a tibble/dataframe from the console?


Yousri Fanous

Software Developer

IBM Canada

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Apr 26 09:29:03 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 26 Apr 2020 19:29:03 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
Message-ID: <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>

fitdistr computes a Hessian matrix.
I think optim ignores the lower value computing the Hessian.

Here's the result after removing the Hessian and Hessian-dependent info:

> str (fit)
List of 3
 $ estimate: Named num [1:2] 0.0000000149 1.0797684972
  ..- attr(*, "names")= chr [1:2] "alpha" "beta"
 $ loglik  : num -2039
 $ n       : int 1529
 - attr(*, "class")= chr "fitdistr"


On Sun, Apr 26, 2020 at 7:02 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I ran your example.
> It's possible that it's another bug in the optim function.
>
> Here's the optim call (from within fitdistr):
>
> stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,
> 1, 1, 1, 4, 4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, #more lines...
> 1, 4, 1, 1, 1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, #removed...
> 4, 5, 5), topn = 5, lower = lwr, par = list(alpha = 1.010652,
>     beta = 1.929018), fn = function(parm, ...) -sum(log(dens(parm, ...))),
>     hessian = TRUE, method = "L-BFGS-B")
>
> And here's dens:
>
> function (parm, x, ...)
> densfun(x, parm[1], parm[2], ...)
>
> I can't see any reason why it should call dens with parm[1] < lower[1].
>
> On Sun, Apr 26, 2020 at 5:50 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > I haven't run your example.
> > I may try tomorrow-ish if no one else answers.
> >
> > But one question: Are you sure the "x" and "i" are correct in your function?
> > It looks like a typo...
> >
> >
> > On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> > >
> > >
> > > For some reason fitdistr() does not seem to be passing on the "..."
> > > argument "lower" to optim() in the proper manner, and as result
> > > falls over.
> > >
> > > Here is my example; note that data are attached in the file "x.txt".
> > >
> > > dhse <- function(i,alpha,beta,topn) {
> > >     x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
> > >     p <- dbeta(x,alpha,beta)
> > >     if(any(!is.finite(p))) browser()
> > >     (p/sum(p))[i]
> > > }
> > >
> > > lwr  <- rep(sqrt(.Machine$double.eps),2)
> > > par0 <- c(alpha=1.010652,beta=1.929018)
> > > x    <- dget("x.txt")
> > > fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
> > >                        lower=lwr)
> > >
> > > The browser() in dhse() allows you to see that alpha has gone negative,
> > > taking a value:
> > >
> > > >        alpha
> > > > -0.001999985
> > >
> > > Continuing causes fitdistr() to fall over with the error message:
> > >
> > > > Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
> > > >   non-finite finite-difference value [1]
> > >
> > > If I eschew using fitdistr() and "roll-my-own" as follows:
> > >
> > > foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
> > >                                            beta=par[2],
> > >                                            topn=topn)))}
> > >
> > > fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
> > >
> > > then optim() returns a result without complaint.
> > >
> > > Am I somehow messing up the syntax for fitdistr()?
> > >
> > > cheers,
> > >
> > > Rolf Turner
> > >
> > > P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
> > > explicitly to fitdistr(); doesn't seem to help.
> > >
> > > R.T.
> > >
> > > --
> > > Honorary Research Fellow
> > > Department of Statistics
> > > University of Auckland
> > > Phone: +64-9-373-7599 ext. 88276
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Apr 26 10:50:36 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 26 Apr 2020 20:50:36 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
Message-ID: <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>


Dear Ms. Spurdle ,

Thanks for looking into this.  I think that you are correct in that it 
is a problem with the hessian calculation.  It seems that fitdistr() 
explicitly sets hessian=TRUE, with no possibility of opting out.

It also seems that optim() ignores the "lower" argument when computing 
the hessian.  I tried setting hessian=TRUE in my roll-your-own call to 
optim() and got the same crash, with alpha  = -0.001999985, which of 
course results in disaster.

Prof. Nash from time to time points out, on this and similar lists, that 
optim() --- which I believe he wrote --- is subject to problems. 
Perhaps this is one of them.  It makes sense that there would be 
difficulties with computing a hessian when the parameters are subject to 
constraints.

It's not at all clear to me how or if these difficulties can be 
circumvented.

I figured that it was kind of nice that fitdistr() provides standard 
errors for the parameter estimates, but this isn't really vital for what 
I am trying to do --- and if trying to find these standard errors makes 
the estimation procedure fall over, then clearly  standard errors have 
to be ditched.

Thanks again for looking into my problem.

cheers,

Rolf


On 26/04/20 7:29 pm, Abby Spurdle wrote:

> fitdistr computes a Hessian matrix.
> I think optim ignores the lower value computing the Hessian.
> 
> Here's the result after removing the Hessian and Hessian-dependent info:
> 
>> str (fit)
> List of 3
>   $ estimate: Named num [1:2] 0.0000000149 1.0797684972
>    ..- attr(*, "names")= chr [1:2] "alpha" "beta"
>   $ loglik  : num -2039
>   $ n       : int 1529
>   - attr(*, "class")= chr "fitdistr"
> 
> 
> On Sun, Apr 26, 2020 at 7:02 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> I ran your example.
>> It's possible that it's another bug in the optim function.
>>
>> Here's the optim call (from within fitdistr):
>>
>> stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,
>> 1, 1, 1, 4, 4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, #more lines...
>> 1, 4, 1, 1, 1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, #removed...
>> 4, 5, 5), topn = 5, lower = lwr, par = list(alpha = 1.010652,
>>      beta = 1.929018), fn = function(parm, ...) -sum(log(dens(parm, ...))),
>>      hessian = TRUE, method = "L-BFGS-B")
>>
>> And here's dens:
>>
>> function (parm, x, ...)
>> densfun(x, parm[1], parm[2], ...)
>>
>> I can't see any reason why it should call dens with parm[1] < lower[1].
>>
>> On Sun, Apr 26, 2020 at 5:50 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>
>>> I haven't run your example.
>>> I may try tomorrow-ish if no one else answers.
>>>
>>> But one question: Are you sure the "x" and "i" are correct in your function?
>>> It looks like a typo...
>>>
>>>
>>> On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>>
>>>> For some reason fitdistr() does not seem to be passing on the "..."
>>>> argument "lower" to optim() in the proper manner, and as result
>>>> falls over.
>>>>
>>>> Here is my example; note that data are attached in the file "x.txt".
>>>>
>>>> dhse <- function(i,alpha,beta,topn) {
>>>>      x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
>>>>      p <- dbeta(x,alpha,beta)
>>>>      if(any(!is.finite(p))) browser()
>>>>      (p/sum(p))[i]
>>>> }
>>>>
>>>> lwr  <- rep(sqrt(.Machine$double.eps),2)
>>>> par0 <- c(alpha=1.010652,beta=1.929018)
>>>> x    <- dget("x.txt")
>>>> fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
>>>>                         lower=lwr)
>>>>
>>>> The browser() in dhse() allows you to see that alpha has gone negative,
>>>> taking a value:
>>>>
>>>>>         alpha
>>>>> -0.001999985
>>>>
>>>> Continuing causes fitdistr() to fall over with the error message:
>>>>
>>>>> Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
>>>>>    non-finite finite-difference value [1]
>>>>
>>>> If I eschew using fitdistr() and "roll-my-own" as follows:
>>>>
>>>> foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
>>>>                                             beta=par[2],
>>>>                                             topn=topn)))}
>>>>
>>>> fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
>>>>
>>>> then optim() returns a result without complaint.
>>>>
>>>> Am I somehow messing up the syntax for fitdistr()?
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
>>>> explicitly to fitdistr(); doesn't seem to help.
>>>>
>>>> R.T.


From pd@|gd @end|ng |rom gm@||@com  Sun Apr 26 10:53:43 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 26 Apr 2020 10:53:43 +0200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
Message-ID: <9F394D95-E42B-4310-8AD3-4B5F5209EAFA@gmail.com>

The optim() function has trouble calculating derivatives at/near the boundary, because it is using a simplistic finite-difference formula centered on the parameter. optimx::optimr() may work better.

-pd

> On 26 Apr 2020, at 09:02 , Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
> I ran your example.
> It's possible that it's another bug in the optim function.
> 
> Here's the optim call (from within fitdistr):
> 
> stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,
> 1, 1, 1, 4, 4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, #more lines...
> 1, 4, 1, 1, 1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, #removed...
> 4, 5, 5), topn = 5, lower = lwr, par = list(alpha = 1.010652,
>    beta = 1.929018), fn = function(parm, ...) -sum(log(dens(parm, ...))),
>    hessian = TRUE, method = "L-BFGS-B")
> 
> And here's dens:
> 
> function (parm, x, ...)
> densfun(x, parm[1], parm[2], ...)
> 
> I can't see any reason why it should call dens with parm[1] < lower[1].
> 
> On Sun, Apr 26, 2020 at 5:50 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>> 
>> I haven't run your example.
>> I may try tomorrow-ish if no one else answers.
>> 
>> But one question: Are you sure the "x" and "i" are correct in your function?
>> It looks like a typo...
>> 
>> 
>> On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> 
>>> For some reason fitdistr() does not seem to be passing on the "..."
>>> argument "lower" to optim() in the proper manner, and as result
>>> falls over.
>>> 
>>> Here is my example; note that data are attached in the file "x.txt".
>>> 
>>> dhse <- function(i,alpha,beta,topn) {
>>>    x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
>>>    p <- dbeta(x,alpha,beta)
>>>    if(any(!is.finite(p))) browser()
>>>    (p/sum(p))[i]
>>> }
>>> 
>>> lwr  <- rep(sqrt(.Machine$double.eps),2)
>>> par0 <- c(alpha=1.010652,beta=1.929018)
>>> x    <- dget("x.txt")
>>> fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
>>>                       lower=lwr)
>>> 
>>> The browser() in dhse() allows you to see that alpha has gone negative,
>>> taking a value:
>>> 
>>>>       alpha
>>>> -0.001999985
>>> 
>>> Continuing causes fitdistr() to fall over with the error message:
>>> 
>>>> Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
>>>>  non-finite finite-difference value [1]
>>> 
>>> If I eschew using fitdistr() and "roll-my-own" as follows:
>>> 
>>> foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
>>>                                           beta=par[2],
>>>                                           topn=topn)))}
>>> 
>>> fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
>>> 
>>> then optim() returns a result without complaint.
>>> 
>>> Am I somehow messing up the syntax for fitdistr()?
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>>> 
>>> P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
>>> explicitly to fitdistr(); doesn't seem to help.
>>> 
>>> R.T.
>>> 
>>> --
>>> Honorary Research Fellow
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@|||P@dpo@t @end|ng |rom gm@||@com  Sun Apr 26 11:48:49 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Sun, 26 Apr 2020 12:48:49 +0300
Subject: [R] Survival analysis
Message-ID: <CAH6117LbMihS5Ge-kaUEWGdVYFBh1Wrbx4ccN5tJWsSQ3KvNHg@mail.gmail.com>

Very grateful for the all comments!

My data contains:
? left censored
? right censored
? events
(interval censored does not contain!)

(P.S. I understood, that the code with "type = 'left'" is not
suitable, because is ONLY for left-censored.)

I wanted to get the appropriate code for my so mix data mainly in
order to get a graphical display (graphic aspect) of such model.


From drj|m|emon @end|ng |rom gm@||@com  Sun Apr 26 12:32:02 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 26 Apr 2020 20:32:02 +1000
Subject: [R] Options for zooming plots other than zm()
In-Reply-To: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
References: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
Message-ID: <CA+8X3fXiLiGEA7bNWTG_fRvYWoxA-vmR2pY6uwe3YQUtnKcmaQ@mail.gmail.com>

Hi Robert,
Maybe you can use something simple like this:

zoomInScatterPlot<-function(x=NULL,y,...) {
 if(is.null(x)) x<-1:length(y)
 plot(x,y,...)
 xylim<-par("usr")
 boxed.labels(xylim[1]-diff(xylim[1:2])/20,
  xylim[3]-diff(xylim[3:4])/10,"Done")
 xy1<-locator(1)
 done<-FALSE
 while(!done) {
  if(xy1$x < xylim[1]) done<-TRUE
  else {
   xy2<-locator(1)
   xlim<-c(xy1$x,xy2$x)
   ylim<-c(xy1$y,xy2$y)
   plot(x,y,xlim=xlim,ylim=ylim,...)
   xylim<-par("usr")
   boxed.labels(xylim[1]-diff(xylim[1:2])/20,
    xylim[3]-diff(xylim[3:4])/10,"Done")
   xy1<-locator(1)
  }
 }
}
zoomInScatterPlot(rnorm(30),rnorm(30))

On Sat, Apr 25, 2020 at 4:40 PM Robert Dodier <robert.dodier at gmail.com> wrote:
>
> Hi,
>
> I am making some plots with plot() which have a fair number of points
> (thousands) and I would like to be able to interactively select a
> region of the plot and zoom in on it. I tried the zoom package which
> has the function zm() but I found that it was unworkably slow to
> refresh the display. I guess I can set the x and y range via xlim and
> ylim but I was hoping to do it interactively. Does someone have a
> suggestion for that?
>
> I looked at ggplot2 but I wasn't able to find something about
> interactive zooming, only noninteractive via plot limits. Perhaps I
> have overlooked something there?
>
> I have searched the mailing list archive and web pages in general but
> I haven't found anything other than zm(). Thank you in advance for
> your help, I appreciate it very much.
>
> best,
>
> Robert Dodier
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cpoiw@rt m@iii@g oii chemo@org@uk  Sun Apr 26 13:20:54 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Sun, 26 Apr 2020 12:20:54 +0100
Subject: [R] Survival analysis
In-Reply-To: <CAH6117LbMihS5Ge-kaUEWGdVYFBh1Wrbx4ccN5tJWsSQ3KvNHg@mail.gmail.com>
References: <CAH6117LbMihS5Ge-kaUEWGdVYFBh1Wrbx4ccN5tJWsSQ3KvNHg@mail.gmail.com>
Message-ID: <3a74abc6918971e9431ff3f47f8e346a@chemo.org.uk>

On 2020-04-26 10:48, Medic wrote:
> Very grateful for the all comments!
> 
> My data contains:
> ? left censored
> ? right censored
> ? events
> (interval censored does not contain!)
> 
> (P.S. I understood, that the code with "type = 'left'" is not
> suitable, because is ONLY for left-censored.)
> 
> I wanted to get the appropriate code for my so mix data mainly in
> order to get a graphical display (graphic aspect) of such model.

I know why you want the graphic.  We all want the graphic! But - the 
graphic is the end result of the model.  I'm worried that you know what 
you WANT the graphic to show and are trying to manipulate the model to 
show it.

I assume you aren't able to share the detail of what you are doing in 
terms of the data?  But can you share the concept?  By that I mean - 
what is the event, what does the left censoring mean etc.  Most studies 
show data from t=0 i.e. day of recruitment / randomisation.  There may 
be logic not to doing that,  for instance - I am involved in a study 
that recruits at t=0, but doesn't randomise until t=56 (if the event has 
occurred randomisation wouldn't happen in this study). It is possible 
that in that 56 days an event can occur (although relatively rare).  
(The stats for that study are not my problem so I don't know what their 
plan is - but it may require left truncating, either in the model - or 
simply only including patients who made it to randomisation in the 
analysis, and possibly taking the event analysis as time from 
randomisation, but that should all be in the stats plan so that the 
numbers can't be played later)

Provide us 10 lines of (interesting) data and talk us through what it 
means.  We don't need to know what "treatment" they had. We don't event 
need to know what the event was other than that the event can only 
happen once (death), or could happen more than once to the same patient 
(heart attack*).  *if that is the case tell us how a second event is 
shown in the data.

This is not a stats help forum, but if its simply sorting data 
structure, that is probably on topic.  If its is this the right test - 
thats off topic.

Have you already collected the data and are now doing analysis? or are 
you trying to structure the data in advance of analysis?


From you@r|@|@nou@ @end|ng |rom gm@||@com  Sun Apr 26 14:23:40 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Sun, 26 Apr 2020 08:23:40 -0400
Subject: [R] How to edit a dataframe/tibble in R console
In-Reply-To: <CADsEwSfWyDaXs4t6ya6ag644V90HRvKArRpLzufRFRmyVr4qxg@mail.gmail.com>
References: <CADsEwSfWyDaXs4t6ya6ag644V90HRvKArRpLzufRFRmyVr4qxg@mail.gmail.com>
Message-ID: <CADsEwSeG+e0NV9wVDhpT4=46u=U19ShqTSWsMR-Q+8=zncsqaw@mail.gmail.com>

Thank you Jim.
It works like a charm

Yousri

On Sat, Apr 25, 2020 at 11:25 PM Yousri Fanous <yousri.fanous at gmail.com>
wrote:

> I recently installed R 3.6.3 on my windows laptop.
>
> R version 3.6.3 (2020-02-29)
>
> I am trying to import a stata .dta file to R
>
> >url<-?http://www.stata-press.com/data/r10/rootstock.dta?
>
> >library(tidyverse)
>
> >library(haven)
>
> >rootstock<-read_dta(url)
>
>
> All works as expected.
>
>
> >class(rootstock)
> [1] "tbl_df"     "tbl"        "data.frame"
>
>
> Now I cannot use the edit command with a tibble or a data frame
>
>
> > edit(rootstock)
> Error in edit.data.frame(rootstock) :
>   can only handle vector and factor elements
>
>
> I noticed that their is an add-on package editData for Rstudio, but I
> cannot use it from the console:
>
> >library(editData)
> >editData(rootstock)
> Error: RStudio not running
>
>
> How can I edit a tibble/dataframe from the console?
>
>
> Yousri Fanous
>
> Software Developer
>
> IBM Canada
>
>
>
>
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Sun Apr 26 17:01:39 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Sun, 26 Apr 2020 11:01:39 -0400
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <9F394D95-E42B-4310-8AD3-4B5F5209EAFA@gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <9F394D95-E42B-4310-8AD3-4B5F5209EAFA@gmail.com>
Message-ID: <d5afaa7f-f6ee-77c7-fa88-68f52b015258@gmail.com>

Peter is correct. I was about to reply when I saw his post.

It should be possible to suppress the Hessian call. I try to do this
generally in my optimx package as computing the Hessian by finite differences
uses a lot more compute-time than solving the optimization problem that
precedes the usual Hessian calculation.

It may be time to consider some update to optim() in that regard, or to
put in some exception handling. It isn't likely in any main-line part
of optim() but in the post-solution phase of the routines. I'd welcome
some discussion on that with a view to improvement, but am not sure if
it should be R-devel or R-package-dev lists or off-list.

John Nash




On 2020-04-26 4:53 a.m., peter dalgaard wrote:
> The optim() function has trouble calculating derivatives at/near the boundary, because it is using a simplistic finite-difference formula centered on the parameter. optimx::optimr() may work better.
> 
> -pd
> 
>> On 26 Apr 2020, at 09:02 , Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> I ran your example.
>> It's possible that it's another bug in the optim function.
>>
>> Here's the optim call (from within fitdistr):
>>
>> stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,
>> 1, 1, 1, 4, 4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, #more lines...
>> 1, 4, 1, 1, 1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, #removed...
>> 4, 5, 5), topn = 5, lower = lwr, par = list(alpha = 1.010652,
>>    beta = 1.929018), fn = function(parm, ...) -sum(log(dens(parm, ...))),
>>    hessian = TRUE, method = "L-BFGS-B")
>>
>> And here's dens:
>>
>> function (parm, x, ...)
>> densfun(x, parm[1], parm[2], ...)
>>
>> I can't see any reason why it should call dens with parm[1] < lower[1].
>>
>> On Sun, Apr 26, 2020 at 5:50 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>
>>> I haven't run your example.
>>> I may try tomorrow-ish if no one else answers.
>>>
>>> But one question: Are you sure the "x" and "i" are correct in your function?
>>> It looks like a typo...
>>>
>>>
>>> On Sun, Apr 26, 2020 at 2:14 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>>
>>>>
>>>> For some reason fitdistr() does not seem to be passing on the "..."
>>>> argument "lower" to optim() in the proper manner, and as result
>>>> falls over.
>>>>
>>>> Here is my example; note that data are attached in the file "x.txt".
>>>>
>>>> dhse <- function(i,alpha,beta,topn) {
>>>>    x <- seq(0,1,length=topn+2)[-c(1,topn+2)]
>>>>    p <- dbeta(x,alpha,beta)
>>>>    if(any(!is.finite(p))) browser()
>>>>    (p/sum(p))[i]
>>>> }
>>>>
>>>> lwr  <- rep(sqrt(.Machine$double.eps),2)
>>>> par0 <- c(alpha=1.010652,beta=1.929018)
>>>> x    <- dget("x.txt")
>>>> fit  <- MASS::fitdistr(x,densfun=dhse,topn=5,start=as.list(par0),
>>>>                       lower=lwr)
>>>>
>>>> The browser() in dhse() allows you to see that alpha has gone negative,
>>>> taking a value:
>>>>
>>>>>       alpha
>>>>> -0.001999985
>>>>
>>>> Continuing causes fitdistr() to fall over with the error message:
>>>>
>>>>> Error in stats::optim(x = c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1,  :
>>>>>  non-finite finite-difference value [1]
>>>>
>>>> If I eschew using fitdistr() and "roll-my-own" as follows:
>>>>
>>>> foo <- function(par,x,topn){-sum(log(dhse(i=x,alpha=par[1],
>>>>                                           beta=par[2],
>>>>                                           topn=topn)))}
>>>>
>>>> fit <- optim(par0,fn=foo,method="L-BFGS-B",lower=lwr,topn=5,x=x)
>>>>
>>>> then optim() returns a result without complaint.
>>>>
>>>> Am I somehow messing up the syntax for fitdistr()?
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> P. S. I've tried supplying the "method" argument, method="L-BFGS-B"
>>>> explicitly to fitdistr(); doesn't seem to help.
>>>>
>>>> R.T.
>>>>
>>>> --
>>>> Honorary Research Fellow
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Apr 26 18:00:15 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 26 Apr 2020 09:00:15 -0700 (PDT)
Subject: [R] Automating package updates after major version change
Message-ID: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>

After upgrading from -3.6.2 to -4.0.0 I ran 'update.packages()' and spent
time rebuilding dependencies, too. Is there a script or method that
automates package updates after a major version change in R?

My web searches on this topic found tips for only regular package updates
without rebuilding multiple dependencies.

TIA,

Rich


From chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t  Sun Apr 26 13:43:14 2020
From: chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t (Blume Christine)
Date: Sun, 26 Apr 2020 11:43:14 +0000
Subject: [R] Package 'coin' - How to extract rho
Message-ID: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>

I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?

Kind regards,
Christine


	[[alternative HTML version deleted]]


From m@|||P@dpo@t @end|ng |rom gm@||@com  Sun Apr 26 18:31:30 2020
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Sun, 26 Apr 2020 19:31:30 +0300
Subject: [R] Survival analysis
Message-ID: <CAH6117KGyw39hzDPu+fXGWSC6Akt1PbSmcAaiyJgHrU+Xxu68w@mail.gmail.com>

cpolwart wrote:
> the event can only happen once
>
1. Yes, I'm not interested in repeat events.
2. I just had an interest in learning the code for survival analysis
in case there are: event, left censored (not left truncating) and
right censored, nothing more! But I no longer want to burden anyone
with my question. (It is not so important.) Thank you sincerely!


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr 26 18:55:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 26 Apr 2020 09:55:33 -0700
Subject: [R] Automating package updates after major version change
In-Reply-To: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbTMEgn9vM6HUsZRVObNL7CnKsVaEBU4eYe=9o4xUPzkdQ@mail.gmail.com>

?install.packages  (argument dependencies)
which is explicitly  pointed to by ?update.packages

"Warning

Take care when using dependencies (passed to install.packages) with
update.packages, for it is unclear where new dependencies should be
installed. The current implementation will only allow it if all the
packages to be updated are in a single library, when that library will
be used. "

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Apr 26, 2020 at 9:00 AM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> After upgrading from -3.6.2 to -4.0.0 I ran 'update.packages()' and spent
> time rebuilding dependencies, too. Is there a script or method that
> automates package updates after a major version change in R?
>
> My web searches on this topic found tips for only regular package updates
> without rebuilding multiple dependencies.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Apr 26 19:04:06 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 26 Apr 2020 10:04:06 -0700 (PDT)
Subject: [R] Automating package updates after major version change
In-Reply-To: <CAGxFJbTMEgn9vM6HUsZRVObNL7CnKsVaEBU4eYe=9o4xUPzkdQ@mail.gmail.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
 <CAGxFJbTMEgn9vM6HUsZRVObNL7CnKsVaEBU4eYe=9o4xUPzkdQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2004261002190.29900@salmo.appl-ecosys.com>

On Sun, 26 Apr 2020, Bert Gunter wrote:

> ?install.packages  (argument dependencies)
> which is explicitly  pointed to by ?update.packages
>
> "Warning
>
> Take care when using dependencies (passed to install.packages) with
> update.packages, for it is unclear where new dependencies should be
> installed. The current implementation will only allow it if all the
> packages to be updated are in a single library, when that library will
> be used. "

Bert,

Thank you. I'll read both help pages to better understand applying them to
unknown dependencies. Here, they're all in one library as I'm the only user.

Regards,

Rich


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Apr 26 19:11:45 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sun, 26 Apr 2020 13:11:45 -0400
Subject: [R] Automating package updates after major version change
In-Reply-To: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
Message-ID: <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>

Not so coincidentally, I just worked thru this for myself.

I did want to rebuild and reinstall everything, but as automatically
as possible, although in a way that let me see what happened and what
went wrong.

http://numberwright.com/2020/04/clean-and-new/

There are several things to consider: CRAN packages (easy), GitHub
packages (less easy), and random other packages (require manual
intervention).

I'm sure there are other possible workflows.

Sarah

On Sun, Apr 26, 2020 at 12:00 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> After upgrading from -3.6.2 to -4.0.0 I ran 'update.packages()' and spent
> time rebuilding dependencies, too. Is there a script or method that
> automates package updates after a major version change in R?
>
> My web searches on this topic found tips for only regular package updates
> without rebuilding multiple dependencies.
>
> TIA,
>
> Rich
>


-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sun Apr 26 19:16:43 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sun, 26 Apr 2020 13:16:43 -0400
Subject: [R] Automating package updates after major version change
In-Reply-To: <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
 <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>
Message-ID: <CAJc=yOFmC+Chyj3uU4Z9oJGewY-j_en4dXOD+nfsW6j5F+qz9Q@mail.gmail.com>

A package on github called yamlpack appears to do a lot of the work
involved. I can't vouch for it personally.

https://github.com/combiz/yamlpack

On Sun, Apr 26, 2020 at 1:12 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Not so coincidentally, I just worked thru this for myself.
>
> I did want to rebuild and reinstall everything, but as automatically
> as possible, although in a way that let me see what happened and what
> went wrong.
>
> http://numberwright.com/2020/04/clean-and-new/
>
> There are several things to consider: CRAN packages (easy), GitHub
> packages (less easy), and random other packages (require manual
> intervention).
>
> I'm sure there are other possible workflows.
>
> Sarah
>
> On Sun, Apr 26, 2020 at 12:00 PM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
> >
> > After upgrading from -3.6.2 to -4.0.0 I ran 'update.packages()' and spent
> > time rebuilding dependencies, too. Is there a script or method that
> > automates package updates after a major version change in R?
> >
> > My web searches on this topic found tips for only regular package updates
> > without rebuilding multiple dependencies.
> >
> > TIA,
> >
> > Rich
> >
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Apr 26 19:34:05 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 26 Apr 2020 10:34:05 -0700 (PDT)
Subject: [R] Automating package updates after major version change
In-Reply-To: <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
 <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2004261033360.29900@salmo.appl-ecosys.com>

On Sun, 26 Apr 2020, Sarah Goslee wrote:

> Not so coincidentally, I just worked thru this for myself.

Thanks, Sarah.

Stay well,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Apr 26 19:35:11 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 26 Apr 2020 10:35:11 -0700 (PDT)
Subject: [R] Automating package updates after major version change
In-Reply-To: <CAJc=yOFmC+Chyj3uU4Z9oJGewY-j_en4dXOD+nfsW6j5F+qz9Q@mail.gmail.com>
References: <alpine.LNX.2.20.2004260856590.29900@salmo.appl-ecosys.com>
 <CAM_vjum70bW89t5AyJF+GgjQHNqNb6Fk_5=-5YF--yLh43Ey_w@mail.gmail.com>
 <CAJc=yOFmC+Chyj3uU4Z9oJGewY-j_en4dXOD+nfsW6j5F+qz9Q@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2004261034320.29900@salmo.appl-ecosys.com>

On Sun, 26 Apr 2020, Patrick (Malone Quantitative) wrote:

> A package on github called yamlpack appears to do a lot of the work
> involved. I can't vouch for it personally.
> https://github.com/combiz/yamlpack

Thanks, Patrick. I'll take a close look at this, too.

Stay well,

Rich


From @|excd|14 @end|ng |rom gm@||@com  Sun Apr 26 20:26:48 2020
From: @|excd|14 @end|ng |rom gm@||@com (Alex Serafim)
Date: Sun, 26 Apr 2020 15:26:48 -0300
Subject: [R] confidence interval
Message-ID: <CAJEBK3gw-GgxSN3M11q-ZmpA4wLL=wPdLyUJqo9yPOFBN_4QGg@mail.gmail.com>

there is a function called "confbands", which is no longer available in
software R. It is not "confband" or "confBands", but "confbands", I need to
use this object to add confidence intervals in my work. Why is this
function not available?
attached is an image that shows how the graph should look, in another image
is the error that appears in the software. "confbands" object not
found. Also attached is an image showing the function functioning normally.
In which even the functions of the object appear.
-- 


<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Livre
de v?rus. www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>.
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Apr 26 21:00:02 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 26 Apr 2020 12:00:02 -0700
Subject: [R] confidence interval
In-Reply-To: <CAJEBK3gw-GgxSN3M11q-ZmpA4wLL=wPdLyUJqo9yPOFBN_4QGg@mail.gmail.com>
References: <CAJEBK3gw-GgxSN3M11q-ZmpA4wLL=wPdLyUJqo9yPOFBN_4QGg@mail.gmail.com>
Message-ID: <968758c1-652a-f64e-a754-ce7421c3140b@comcast.net>


On 4/26/20 11:26 AM, Alex Serafim wrote:
> there is a function called "confbands", which is no longer available in
> software R. It is not "confband" or "confBands", but "confbands", I need to
> use this object to add confidence intervals in my work. Why is this
> function not available?
> attached is an image that shows how the graph should look, in another image
> is the error that appears in the software. "confbands" object not
> found. Also attached is an image showing the function functioning normally.
> In which even the functions of the object appear.


There was no attached image or images. That is because you have not 
carefully read the information provided here: 
https://stat.ethz.ch/mailman/listinfo/r-help and in the Posting Guide.

R is composed of packages. You need to know which package the 
"confbands" function came from before we can identify the cause of its 
absence.

It could be that you have not installed or loaded the package into your 
session. Or it could be that the author of the package in which it used 
to be made available has not maintained it on CRAN. Or perhaps it was 
never on CRAN and was instead on some blog or class assignment where it 
was defined upstream and you failed to notice it. All these situations 
have been seen on Rhelp posted by persons claiming that a function has 
gone missing.


-- 

David.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Apr 26 22:34:26 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 26 Apr 2020 13:34:26 -0700
Subject: [R] (probably) SOLVED was .... Re:  confidence interval
In-Reply-To: <968758c1-652a-f64e-a754-ce7421c3140b@comcast.net>
References: <CAJEBK3gw-GgxSN3M11q-ZmpA4wLL=wPdLyUJqo9yPOFBN_4QGg@mail.gmail.com>
 <968758c1-652a-f64e-a754-ce7421c3140b@comcast.net>
Message-ID: <a1bcb291-1a43-054c-4b0c-954e4fa148b8@comcast.net>


On 4/26/20 12:00 PM, David Winsemius wrote:
>
> On 4/26/20 11:26 AM, Alex Serafim wrote:
>> there is a function called "confbands", which is no longer available in
>> software R. It is not "confband" or "confBands", but "confbands", I 
>> need to
>> use this object to add confidence intervals in my work. Why is this
>> function not available?
>> attached is an image that shows how the graph should look, in another 
>> image
>> is the error that appears in the software. "confbands" object not
>> found. Also attached is an image showing the function functioning 
>> normally.
>> In which even the functions of the object appear.
>
>
> There was no attached image or images. That is because you have not 
> carefully read the information provided here: 
> https://stat.ethz.ch/mailman/listinfo/r-help and in the Posting Guide.

Alex replied to me and failed to include the mailing list. He again 
attached images. One of these images showed a fragment of a console 
session where a `confbands` function was displayed in part. It had a 
parameter of newdata and used the function `mydeltaMethod`, so I did a 
google search on "confbands newdata mdeltamethod" and found this page of 
code:


http://arsilva.weebly.com/uploads/2/1/0/0/21008856/function_confbands.r


It matches the image exactly, so I think I have identified the missing 
function.

Alex: You still do need to read the Posting Guide and the list Info 
page. The next respondent on rhelp may not be as forgiving of your sins 
against protocol.

-- 

David

>
> R is composed of packages. You need to know which package the 
> "confbands" function came from before we can identify the cause of its 
> absence.
>
> It could be that you have not installed or loaded the package into 
> your session. Or it could be that the author of the package in which 
> it used to be made available has not maintained it on CRAN. Or perhaps 
> it was never on CRAN and was instead on some blog or class assignment 
> where it was defined upstream and you failed to notice it. All these 
> situations have been seen on Rhelp posted by persons claiming that a 
> function has gone missing.
>
>


From @purd|e@@ @end|ng |rom gm@||@com  Sun Apr 26 23:31:20 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 27 Apr 2020 09:31:20 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
 <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
Message-ID: <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>

> Dear Ms. Spurdle

I usually refer to myself as "He".
(But then, that's not the whole story...)

I'm not an expert on maximum likelihood approaches.
So, I apologize if the following suggestion is a poor one.

Does your likelihood function have a limit, as alpha approaches zero (say zero)?
If so, the limit of the log-likelihood would be -Inf, would it not.

You could create a function representing the likelihood or
log-likelihood by wrapping your density function.
The function could allow alpha/beta values equal to or below zero, and
return the limit.
This is mathematically incorrect, but may be sufficient for
permissible estimates of the second-order partial derivatives.
Depending on the shape of the likelihood function these
pseudo-likelihoods maybe able to be improved...?

You could then do a small modification on the source code for
MASS::fitdistr, such that the user specifies the likelihood function
or log-likelihood function, rather than the density...

The fitdistr function is relatively complex, however, you would only
need to modify a couple of lines, the lines that create the fn
function...


From you@r|@|@nou@ @end|ng |rom gm@||@com  Mon Apr 27 00:40:13 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Sun, 26 Apr 2020 18:40:13 -0400
Subject: [R] Fwd:  How to edit a dataframe/tibble in R console
In-Reply-To: <CA+8X3fVqHvAnSLQQt=GYWjz9zOscQGEvQOw3C2zARYWUpN6A7Q@mail.gmail.com>
References: <CADsEwSfWyDaXs4t6ya6ag644V90HRvKArRpLzufRFRmyVr4qxg@mail.gmail.com>
 <CA+8X3fVqHvAnSLQQt=GYWjz9zOscQGEvQOw3C2zARYWUpN6A7Q@mail.gmail.com>
Message-ID: <CADsEwSeGVuPts881PFcoX7NDBR2=tyGyGPdmoisHy=EEd6pecw@mail.gmail.com>

Jim solution posted

Yousri

---------- Forwarded message ---------
From: Jim Lemon <drjimlemon at gmail.com>
Date: Sun, Apr 26, 2020 at 6:30 AM
Subject: Re: [R] How to edit a dataframe/tibble in R console
To: Yousri Fanous <yousri.fanous at gmail.com>


Hi Yousri,
This may help:

rootstock.df<-as.data.frame(lapply(rootstock,as.vector))
edit(rootstock.df)

Jim

On Sun, Apr 26, 2020 at 5:21 PM Yousri Fanous <yousri.fanous at gmail.com>
wrote:
>
> I recently installed R 3.6.3 on my windows laptop.
>
> R version 3.6.3 (2020-02-29)
>
> I am trying to import a stata .dta file to R
>
> >url<-?http://www.stata-press.com/data/r10/rootstock.dta?
>
> >library(tidyverse)
>
> >library(haven)
>
> >rootstock<-read_dta(url)
>
>
> All works as expected.
>
>
> >class(rootstock)
> [1] "tbl_df"     "tbl"        "data.frame"
>
>
> Now I cannot use the edit command with a tibble or a data frame
>
>
> > edit(rootstock)
> Error in edit.data.frame(rootstock) :
>   can only handle vector and factor elements
>
>
> I noticed that their is an add-on package editData for Rstudio, but I
> cannot use it from the console:
>
> >library(editData)
> >editData(rootstock)
> Error: RStudio not running
>
>
> How can I edit a tibble/dataframe from the console?
>
>
> Yousri Fanous
>
> Software Developer
>
> IBM Canada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Apr 27 01:27:21 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 27 Apr 2020 11:27:21 +1200
Subject: [R] [FORGED] Re:  Problem with MASS::fitdistr().
In-Reply-To: <d5afaa7f-f6ee-77c7-fa88-68f52b015258@gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <9F394D95-E42B-4310-8AD3-4B5F5209EAFA@gmail.com>
 <d5afaa7f-f6ee-77c7-fa88-68f52b015258@gmail.com>
Message-ID: <69a19004-5752-f813-447a-7a8cecab184d@auckland.ac.nz>


On 27/04/20 3:01 am, J C Nash wrote:
:
> Peter is correct. I was about to reply when I saw his post.
> 
> It should be possible to suppress the Hessian call. I try to do this
> generally in my optimx package as computing the Hessian by finite differences
> uses a lot more compute-time than solving the optimization problem that
> precedes the usual Hessian calculation.
> 
> It may be time to consider some update to optim() in that regard, or to
> put in some exception handling. It isn't likely in any main-line part
> of optim() but in the post-solution phase of the routines. I'd welcome
> some discussion on that with a view to improvement, but am not sure if
> it should be R-devel or R-package-dev lists or off-list.

Thanks to Peter and John for this advice.

As to "suppressing the Hessian call" --- if I understand you correctly, 
this is not a problem with optim(); in fact by default optim() does not 
attempt to calculate the hessian.  The problem arises with 
MASS::fitdistr() which sets hessian=TRUE in the call to optim(), 
willy-nilly.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Mon Apr 27 02:54:43 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 27 Apr 2020 12:54:43 +1200
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
 <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
 <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>
Message-ID: <CAB8pepxF_PNiGdbwLm8U54=cmkaQVsUPeP1dk8mQRVWYZNuToQ@mail.gmail.com>

I thought about this some more and realized my last suggestion is
unlikely to work.
Another possibility would be to create a new function to compute the
Hessian with a smaller step size, but I suspect there will be more
problems.

Possibly a much simpler approach would be to:

Modify the source for fitdistr.
(Copy the source and create a new function, say fitdistr2).

Modify it not compute the Hessian in the optim call.
Then after the optim call, test the parameter estimates.
If they're very close to the boundaries (here zero), then they're
flagged as near-boundary cases and the fitdistr2 function returns the
parameter estimates without the Hessian and related info.
(Possibly generating a warning).

If they're sufficiently distant, the Hessian and related info can be
computed in separate steps and returned.
(Equivalent to what it does currently).

I note that there's at least one R package (numDeriv), and maybe more,
for computing the Hessian, numerically.


On Mon, Apr 27, 2020 at 9:31 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> > Dear Ms. Spurdle
>
> I usually refer to myself as "He".
> (But then, that's not the whole story...)
>
> I'm not an expert on maximum likelihood approaches.
> So, I apologize if the following suggestion is a poor one.
>
> Does your likelihood function have a limit, as alpha approaches zero (say zero)?
> If so, the limit of the log-likelihood would be -Inf, would it not.
>
> You could create a function representing the likelihood or
> log-likelihood by wrapping your density function.
> The function could allow alpha/beta values equal to or below zero, and
> return the limit.
> This is mathematically incorrect, but may be sufficient for
> permissible estimates of the second-order partial derivatives.
> Depending on the shape of the likelihood function these
> pseudo-likelihoods maybe able to be improved...?
>
> You could then do a small modification on the source code for
> MASS::fitdistr, such that the user specifies the likelihood function
> or log-likelihood function, rather than the density...
>
> The fitdistr function is relatively complex, however, you would only
> need to modify a couple of lines, the lines that create the fn
> function...


From m@rk|eed@2 @end|ng |rom gm@||@com  Mon Apr 27 03:18:27 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Sun, 26 Apr 2020 21:18:27 -0400
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAB8pepxF_PNiGdbwLm8U54=cmkaQVsUPeP1dk8mQRVWYZNuToQ@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
 <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
 <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>
 <CAB8pepxF_PNiGdbwLm8U54=cmkaQVsUPeP1dk8mQRVWYZNuToQ@mail.gmail.com>
Message-ID: <CAHz+bWbVAfiXG_ww2eU+fvGz2von+hi9pZfunK039vq6C=rD6w@mail.gmail.com>

it's been a looooooooong time but I vaguely remember Rvmminb computing
gradients ( and possibly hessians )
subject to constraints. John can say more about this but, if one is going
to go through the anguish of
creating a fitdstr2, then you may want to have it call Rvmminb instead of
whatever is currently
being called.



On Sun, Apr 26, 2020 at 8:55 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> I thought about this some more and realized my last suggestion is
> unlikely to work.
> Another possibility would be to create a new function to compute the
> Hessian with a smaller step size, but I suspect there will be more
> problems.
>
> Possibly a much simpler approach would be to:
>
> Modify the source for fitdistr.
> (Copy the source and create a new function, say fitdistr2).
>
> Modify it not compute the Hessian in the optim call.
> Then after the optim call, test the parameter estimates.
> If they're very close to the boundaries (here zero), then they're
> flagged as near-boundary cases and the fitdistr2 function returns the
> parameter estimates without the Hessian and related info.
> (Possibly generating a warning).
>
> If they're sufficiently distant, the Hessian and related info can be
> computed in separate steps and returned.
> (Equivalent to what it does currently).
>
> I note that there's at least one R package (numDeriv), and maybe more,
> for computing the Hessian, numerically.
>
>
> On Mon, Apr 27, 2020 at 9:31 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >
> > > Dear Ms. Spurdle
> >
> > I usually refer to myself as "He".
> > (But then, that's not the whole story...)
> >
> > I'm not an expert on maximum likelihood approaches.
> > So, I apologize if the following suggestion is a poor one.
> >
> > Does your likelihood function have a limit, as alpha approaches zero
> (say zero)?
> > If so, the limit of the log-likelihood would be -Inf, would it not.
> >
> > You could create a function representing the likelihood or
> > log-likelihood by wrapping your density function.
> > The function could allow alpha/beta values equal to or below zero, and
> > return the limit.
> > This is mathematically incorrect, but may be sufficient for
> > permissible estimates of the second-order partial derivatives.
> > Depending on the shape of the likelihood function these
> > pseudo-likelihoods maybe able to be improved...?
> >
> > You could then do a small modification on the source code for
> > MASS::fitdistr, such that the user specifies the likelihood function
> > or log-likelihood function, rather than the density...
> >
> > The fitdistr function is relatively complex, however, you would only
> > need to modify a couple of lines, the lines that create the fn
> > function...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From robert@dod|er @end|ng |rom gm@||@com  Mon Apr 27 07:12:10 2020
From: robert@dod|er @end|ng |rom gm@||@com (Robert Dodier)
Date: Sun, 26 Apr 2020 22:12:10 -0700
Subject: [R] Options for zooming plots other than zm()
In-Reply-To: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
References: <CAAsY_sSWYwfcvPccQgV2k1dTbgkFNqoTMa9dHchN=zvJmD_5tA@mail.gmail.com>
Message-ID: <CAAsY_sQxGr_A1WWfuExgurV0Htq2qBMzQ_ziWU-ZJT1aTandJg@mail.gmail.com>

Many thanks to everyone who contributed to this discussion. It looks
like plotly and dygraphs both work well for zooming plots with
thousands of points (and many other things).

Thanks again, I appreciate your help.

best,

Robert Dodier

On Fri, Apr 24, 2020 at 11:11 AM Robert Dodier <robert.dodier at gmail.com> wrote:
>
> Hi,
>
> I am making some plots with plot() which have a fair number of points
> (thousands) and I would like to be able to interactively select a
> region of the plot and zoom in on it. I tried the zoom package which
> has the function zm() but I found that it was unworkably slow to
> refresh the display. I guess I can set the x and y range via xlim and
> ylim but I was hoping to do it interactively. Does someone have a
> suggestion for that?
>
> I looked at ggplot2 but I wasn't able to find something about
> interactive zooming, only noninteractive via plot limits. Perhaps I
> have overlooked something there?
>
> I have searched the mailing list archive and web pages in general but
> I haven't found anything other than zm(). Thank you in advance for
> your help, I appreciate it very much.
>
> best,
>
> Robert Dodier


From j@zh@o @end|ng |rom ye@h@net  Mon Apr 27 09:50:54 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Mon, 27 Apr 2020 15:50:54 +0800
Subject: [R] help.start() caused high CPU loading
Message-ID: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>

Hi there,

After calling help.start(), I noticed that CPU loading is up to about 
25% (my CPU is core i5 with 4 core). In the out html page, if I click 
"Packages", the CPU loading may be up to 75% or much higher. After 
closing the browser, the CPU loading does not drop.

If I just use ?plot to open a specific help page, the CPU loading is not 
change dramatically. However, if I click the package name (base or 
graphics package in this example) in the help page to open the index 
page of the corresponding package, then the CPU loading will increase to 
more than 75%.

I do not know if this phenomenon could be reproduced... And I do not 
know how to trace the detailed information.

Best,
Jinsonng

 > sessionInfo()
R version 4.0.0 (2020-04-24)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.936
[2] LC_CTYPE=Chinese (Simplified)_China.936
[3] LC_MONETARY=Chinese (Simplified)_China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.0 tools_4.0.0


From @purd|e@@ @end|ng |rom gm@||@com  Mon Apr 27 10:54:40 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 27 Apr 2020 20:54:40 +1200
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
Message-ID: <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>

What's the benchmark?

I (still) have Windows 10 x64.
Opening the task manager, causes the CPU to jump to over 90%.

In regards to the CPU usage remaining high:
(1) Are you running R in a standard way?
(2) If (1) true, is R idle (i.e. waiting for user input)?
(3) If (2) true, how much CPU is R using?
(4) If (3) is zero, what processes are using the CPU the most?

If (1) is false, it's not R's fault.
If (1) is true and (2) is false, then I don't know, that would be interesting...
If (1) and (2) are true and (3) is high, then that would be a bug in R.

If (4) is processes other than R, it's also not R's fault.
But if you provide information, someone here maybe able to offer advise...


On Mon, Apr 27, 2020 at 7:51 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>
> Hi there,
>
> After calling help.start(), I noticed that CPU loading is up to about
> 25% (my CPU is core i5 with 4 core). In the out html page, if I click
> "Packages", the CPU loading may be up to 75% or much higher. After
> closing the browser, the CPU loading does not drop.
>
> If I just use ?plot to open a specific help page, the CPU loading is not
> change dramatically. However, if I click the package name (base or
> graphics package in this example) in the help page to open the index
> page of the corresponding package, then the CPU loading will increase to
> more than 75%.
>
> I do not know if this phenomenon could be reproduced... And I do not
> know how to trace the detailed information.
>
> Best,
> Jinsonng
>
>  > sessionInfo()
> R version 4.0.0 (2020-04-24)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Chinese (Simplified)_China.936
> [2] LC_CTYPE=Chinese (Simplified)_China.936
> [3] LC_MONETARY=Chinese (Simplified)_China.936
> [4] LC_NUMERIC=C
> [5] LC_TIME=Chinese (Simplified)_China.936
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.0 tools_4.0.0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@zh@o @end|ng |rom ye@h@net  Mon Apr 27 11:21:58 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Mon, 27 Apr 2020 17:21:58 +0800
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
Message-ID: <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>

On 2020/4/27 16:54, Abby Spurdle wrote:
> What's the benchmark?
I don't have any benchmark about this problem.

> 
> I (still) have Windows 10 x64.
> Opening the task manager, causes the CPU to jump to over 90%.

It will drop to about 0.5% or below very quickly.

> 
> In regards to the CPU usage remaining high:
> (1) Are you running R in a standard way?

TRUE. I closed all applications, and run the R using Rgui on Windows 10 x64.

> (2) If (1) true, is R idle (i.e. waiting for user input)?

TRUE.

> (3) If (2) true, how much CPU is R using?

0%.

> (4) If (3) is zero, what processes are using the CPU the most?

In such case, almost every processes is using the CPU in a very low 
percentage, i.e., 1% or below. I don't recognized those processes.

Now, I invoke help.start(), about 25% of CPU loading is used by R. Quit 
from R, the CPU loading go back to idle.

> 
> If (1) is false, it's not R's fault.
> If (1) is true and (2) is false, then I don't know, that would be interesting...
> If (1) and (2) are true and (3) is high, then that would be a bug in R.
> 
> If (4) is processes other than R, it's also not R's fault.
> But if you provide information, someone here maybe able to offer advise...
> 

Thanks for those suggestions.

Best,
Jinsong

> 
> On Mon, Apr 27, 2020 at 7:51 PM Jinsong Zhao <jszhao at yeah.net> wrote:
>>
>> Hi there,
>>
>> After calling help.start(), I noticed that CPU loading is up to about
>> 25% (my CPU is core i5 with 4 core). In the out html page, if I click
>> "Packages", the CPU loading may be up to 75% or much higher. After
>> closing the browser, the CPU loading does not drop.
>>
>> If I just use ?plot to open a specific help page, the CPU loading is not
>> change dramatically. However, if I click the package name (base or
>> graphics package in this example) in the help page to open the index
>> page of the corresponding package, then the CPU loading will increase to
>> more than 75%.
>>
>> I do not know if this phenomenon could be reproduced... And I do not
>> know how to trace the detailed information.
>>
>> Best,
>> Jinsonng
>>
>>   > sessionInfo()
>> R version 4.0.0 (2020-04-24)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 18363)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=Chinese (Simplified)_China.936
>> [2] LC_CTYPE=Chinese (Simplified)_China.936
>> [3] LC_MONETARY=Chinese (Simplified)_China.936
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=Chinese (Simplified)_China.936
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_4.0.0 tools_4.0.0


From edw@rd@m @end|ng |rom p@u@@c@th  Mon Apr 27 14:07:13 2020
From: edw@rd@m @end|ng |rom p@u@@c@th (Edward McNeil)
Date: Mon, 27 Apr 2020 19:07:13 +0700
Subject: [R] deciphering help for `attach`
Message-ID: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>

Hi,
I have two related questions.

1. In the help page for `attach` under "Details" it says in paragraph 3:
"By default the database is attached ..."

But then paragraph 4 starts: "The database is not actually attached."

Could somebody explain this contradiction? Is the data(base) attached or not?

2. What is meant by the 5th paragraph: "One useful ?trick? is to use what = NULL (or
equivalently a length-zero list) to create a new environment on the search path into
which objects can be assigned by `assign` ... "?

I don't understand what this "trick" is or why a "trick" needs to be performed here.

Thanks
-- 
Edward McNeil


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Apr 27 15:00:39 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 27 Apr 2020 13:00:39 +0000
Subject: [R] deciphering help for `attach`
In-Reply-To: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
Message-ID: <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>

Hi.

I strongly recommend not to use attach. I agree that mentioned statements are rather contradictory and probably others could give you more insightful answer. You could consider that by attaching some data, you create something like a copy of original data in your system with a feature that you can use column names directly. If you change something in the data after attachment, you change only attached version and not an original.

It is similar as if you take a picture of Gioconda an use some creativity to add a moustache to this picture. In any circumstances moustache does not propagate to the original Louvre painting. Do not perform any tricks, preferably do not perform attach.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward McNeil
> Sent: Monday, April 27, 2020 2:07 PM
> To: r-help at r-project.org
> Subject: [R] deciphering help for `attach`
> 
> Hi,
> I have two related questions.
> 
> 1. In the help page for `attach` under "Details" it says in paragraph 3:
> "By default the database is attached ..."
> 
> But then paragraph 4 starts: "The database is not actually attached."
> 
> Could somebody explain this contradiction? Is the data(base) attached or
> not?
> 
> 2. What is meant by the 5th paragraph: "One useful ?trick? is to use what =
> NULL (or equivalently a length-zero list) to create a new environment on the
> search path into which objects can be assigned by `assign` ... "?
> 
> I don't understand what this "trick" is or why a "trick" needs to be performed
> here.
> 
> Thanks
> --
> Edward McNeil
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From edw@rd@m @end|ng |rom p@u@@c@th  Mon Apr 27 15:26:11 2020
From: edw@rd@m @end|ng |rom p@u@@c@th (Edward McNeil)
Date: Mon, 27 Apr 2020 20:26:11 +0700
Subject: [R] deciphering help for `attach`
In-Reply-To: <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
 <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
Message-ID: <3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>

Dear Petr,
Thanks for your quick reply. Much appreciated. However, you haven't really answered
either of my questions, although I don't quite understand your reference to La Gioconda.

In any case, despite your strong recommendation not to use `attach`, I am going to keep
using it, as I have done successfully for the past 16 years, and keep teaching it, until
it either kills me or disappears from R. Unfortunately I have to teach R to students and
I don't like it when they ask me "tricky" questions to which I have no answer. ;)
-- 
Edward McNeil

On Mon, April 27, 2020 8:00 pm, PIKAL Petr wrote:
Hi.

I strongly recommend not to use attach. I agree that mentioned statements are rather
contradictory and probably others could give you more insightful answer. You could
consider that by attaching some data, you create something like a copy of original data
in your system with a feature that you can use column names directly. If you change
something in the data after attachment, you change only attached version and not an
original.

It is similar as if you take a picture of Gioconda an use some creativity to add a
moustache to this picture. In any circumstances moustache does not propagate to the
original Louvre painting. Do not perform any tricks, preferably do not perform attach.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward McNeil
> Sent: Monday, April 27, 2020 2:07 PM
> To: r-help at r-project.org
> Subject: [R] deciphering help for `attach`
>
> Hi,
> I have two related questions.
>
> 1. In the help page for `attach` under "Details" it says in paragraph 3:
> "By default the database is attached ..."
>
> But then paragraph 4 starts: "The database is not actually attached."
>
> Could somebody explain this contradiction? Is the data(base) attached or
> not?
>
> 2. What is meant by the 5th paragraph: "One useful ?trick? is to use what =
> NULL (or equivalently a length-zero list) to create a new environment on the
> search path into which objects can be assigned by `assign` ... "?
>
> I don't understand what this "trick" is or why a "trick" needs to be performed
> here.
>
> Thanks
> --
> Edward McNeil
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Apr 27 16:57:08 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 27 Apr 2020 14:57:08 +0000
Subject: [R] deciphering help for `attach`
In-Reply-To: <20751_1587994317_03RDVrcr024245_3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
 <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
 <20751_1587994317_03RDVrcr024245_3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
Message-ID: <385EEAF3-0534-42AF-B7C1-37DF76345255@mcmaster.ca>

Dear Edward,

Paragraph 4 in the help page goes on to say, "Rather, a new environment is created on the search path and the elements of a list (including columns of a data frame) or objects in a save file or an environment are copied into the new environment."

That seems reasonably clear to me. Here's an example that also illustrates how attach can lead to confusion:

------- snip --------

> str(cars)
'data.frame':	50 obs. of  2 variables:
 $ speed: num  4 4 7 7 8 9 10 10 10 11 ...
 $ dist : num  2 10 4 22 16 10 18 26 34 17 ...

> attach(cars)

> search()
 [1] ".GlobalEnv"        "cars"              "tools:rstudio"     "package:stats"    
 [5] "package:graphics"  "package:grDevices" "package:utils"     "package:datasets" 
 [9] "package:methods"   "Autoloads"         "package:base"   
  
> objects()
character(0)

> objects(pos=2)
[1] "dist"  "speed"

> str(get("dist", pos=2))
 num [1:50] 2 10 4 22 16 10 18 26 34 17 ...

> dist <- 1:10

> head(dist) # shadows dist in copy of cars
[1] 1 2 3 4 5 6

> head(get("dist", pos=2))
[1]  2 10  4 22 16 10

> assign("dist", 10:1, pos=2) # changes dist in objects copied from cars

> head(get("dist", pos=2))
[1] 10  9  8  7  6  5

------- snip --------

Paragraph 5 also seems clear to me. Here's an example:

------- snip --------

> attach(NULL)

> search()
 [1] ".GlobalEnv"        "NULL"              "cars"              "tools:rstudio"    
 [5] "package:stats"     "package:graphics"  "package:grDevices" "package:utils"    
 [9] "package:datasets"  "package:methods"   "Autoloads"         "package:base" 
    
> assign("x", 10, pos=2)

> x
[1] 10

------- snip --------

Now that may beg the question of why one would want to do something like this, which isn't addressed in the help file, but a fair comment is that if you don't need to store objects in an environment that's accessible on the path, why worry about it? After all, no one is forcing you to use this trick.

Finally, I too recommended that students use attach() when I first starting teaching with R, until I noticed that they frequently tied themselves into knots by attaching different versions of the same data during a session, producing confusion about where the data were coming from and what version they were using. It's not hard in R to avoid the use of attach(). Of course, attach() is still part of the language, so you, and your students, are free to continue using it if you wish, and perhaps your students avoid the problems that mine often created.

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 27, 2020, at 9:26 AM, Edward McNeil <edward.m at psu.ac.th> wrote:
> 
> Dear Petr,
> Thanks for your quick reply. Much appreciated. However, you haven't really answered
> either of my questions, although I don't quite understand your reference to La Gioconda.
> 
> In any case, despite your strong recommendation not to use `attach`, I am going to keep
> using it, as I have done successfully for the past 16 years, and keep teaching it, until
> it either kills me or disappears from R. Unfortunately I have to teach R to students and
> I don't like it when they ask me "tricky" questions to which I have no answer. ;)
> -- 
> Edward McNeil
> 
> On Mon, April 27, 2020 8:00 pm, PIKAL Petr wrote:
> Hi.
> 
> I strongly recommend not to use attach. I agree that mentioned statements are rather
> contradictory and probably others could give you more insightful answer. You could
> consider that by attaching some data, you create something like a copy of original data
> in your system with a feature that you can use column names directly. If you change
> something in the data after attachment, you change only attached version and not an
> original.
> 
> It is similar as if you take a picture of Gioconda an use some creativity to add a
> moustache to this picture. In any circumstances moustache does not propagate to the
> original Louvre painting. Do not perform any tricks, preferably do not perform attach.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward McNeil
>> Sent: Monday, April 27, 2020 2:07 PM
>> To: r-help at r-project.org
>> Subject: [R] deciphering help for `attach`
>> 
>> Hi,
>> I have two related questions.
>> 
>> 1. In the help page for `attach` under "Details" it says in paragraph 3:
>> "By default the database is attached ..."
>> 
>> But then paragraph 4 starts: "The database is not actually attached."
>> 
>> Could somebody explain this contradiction? Is the data(base) attached or
>> not?
>> 
>> 2. What is meant by the 5th paragraph: "One useful ?trick? is to use what =
>> NULL (or equivalently a length-zero list) to create a new environment on the
>> search path into which objects can be assigned by `assign` ... "?
>> 
>> I don't understand what this "trick" is or why a "trick" needs to be performed
>> here.
>> 
>> Thanks
>> --
>> Edward McNeil
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 27 17:25:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Apr 2020 08:25:47 -0700
Subject: [R] deciphering help for `attach`
In-Reply-To: <385EEAF3-0534-42AF-B7C1-37DF76345255@mcmaster.ca>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
 <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
 <20751_1587994317_03RDVrcr024245_3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
 <385EEAF3-0534-42AF-B7C1-37DF76345255@mcmaster.ca>
Message-ID: <CAGxFJbTe+S7mHMM_q4MsDmOaW3pCRi0QO0e3Rj9zJern2-DhRw@mail.gmail.com>

What is the use case for attach? As the Help says, I find that with()
or sometimes within() handles the situations where I would use it.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Apr 27, 2020 at 7:58 AM Fox, John <jfox at mcmaster.ca> wrote:
>
> Dear Edward,
>
> Paragraph 4 in the help page goes on to say, "Rather, a new environment is created on the search path and the elements of a list (including columns of a data frame) or objects in a save file or an environment are copied into the new environment."
>
> That seems reasonably clear to me. Here's an example that also illustrates how attach can lead to confusion:
>
> ------- snip --------
>
> > str(cars)
> 'data.frame':   50 obs. of  2 variables:
>  $ speed: num  4 4 7 7 8 9 10 10 10 11 ...
>  $ dist : num  2 10 4 22 16 10 18 26 34 17 ...
>
> > attach(cars)
>
> > search()
>  [1] ".GlobalEnv"        "cars"              "tools:rstudio"     "package:stats"
>  [5] "package:graphics"  "package:grDevices" "package:utils"     "package:datasets"
>  [9] "package:methods"   "Autoloads"         "package:base"
>
> > objects()
> character(0)
>
> > objects(pos=2)
> [1] "dist"  "speed"
>
> > str(get("dist", pos=2))
>  num [1:50] 2 10 4 22 16 10 18 26 34 17 ...
>
> > dist <- 1:10
>
> > head(dist) # shadows dist in copy of cars
> [1] 1 2 3 4 5 6
>
> > head(get("dist", pos=2))
> [1]  2 10  4 22 16 10
>
> > assign("dist", 10:1, pos=2) # changes dist in objects copied from cars
>
> > head(get("dist", pos=2))
> [1] 10  9  8  7  6  5
>
> ------- snip --------
>
> Paragraph 5 also seems clear to me. Here's an example:
>
> ------- snip --------
>
> > attach(NULL)
>
> > search()
>  [1] ".GlobalEnv"        "NULL"              "cars"              "tools:rstudio"
>  [5] "package:stats"     "package:graphics"  "package:grDevices" "package:utils"
>  [9] "package:datasets"  "package:methods"   "Autoloads"         "package:base"
>
> > assign("x", 10, pos=2)
>
> > x
> [1] 10
>
> ------- snip --------
>
> Now that may beg the question of why one would want to do something like this, which isn't addressed in the help file, but a fair comment is that if you don't need to store objects in an environment that's accessible on the path, why worry about it? After all, no one is forcing you to use this trick.
>
> Finally, I too recommended that students use attach() when I first starting teaching with R, until I noticed that they frequently tied themselves into knots by attaching different versions of the same data during a session, producing confusion about where the data were coming from and what version they were using. It's not hard in R to avoid the use of attach(). Of course, attach() is still part of the language, so you, and your students, are free to continue using it if you wish, and perhaps your students avoid the problems that mine often created.
>
> Best,
>  John
>
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> > On Apr 27, 2020, at 9:26 AM, Edward McNeil <edward.m at psu.ac.th> wrote:
> >
> > Dear Petr,
> > Thanks for your quick reply. Much appreciated. However, you haven't really answered
> > either of my questions, although I don't quite understand your reference to La Gioconda.
> >
> > In any case, despite your strong recommendation not to use `attach`, I am going to keep
> > using it, as I have done successfully for the past 16 years, and keep teaching it, until
> > it either kills me or disappears from R. Unfortunately I have to teach R to students and
> > I don't like it when they ask me "tricky" questions to which I have no answer. ;)
> > --
> > Edward McNeil
> >
> > On Mon, April 27, 2020 8:00 pm, PIKAL Petr wrote:
> > Hi.
> >
> > I strongly recommend not to use attach. I agree that mentioned statements are rather
> > contradictory and probably others could give you more insightful answer. You could
> > consider that by attaching some data, you create something like a copy of original data
> > in your system with a feature that you can use column names directly. If you change
> > something in the data after attachment, you change only attached version and not an
> > original.
> >
> > It is similar as if you take a picture of Gioconda an use some creativity to add a
> > moustache to this picture. In any circumstances moustache does not propagate to the
> > original Louvre painting. Do not perform any tricks, preferably do not perform attach.
> >
> > Cheers
> > Petr
> >
> >> -----Original Message-----
> >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward McNeil
> >> Sent: Monday, April 27, 2020 2:07 PM
> >> To: r-help at r-project.org
> >> Subject: [R] deciphering help for `attach`
> >>
> >> Hi,
> >> I have two related questions.
> >>
> >> 1. In the help page for `attach` under "Details" it says in paragraph 3:
> >> "By default the database is attached ..."
> >>
> >> But then paragraph 4 starts: "The database is not actually attached."
> >>
> >> Could somebody explain this contradiction? Is the data(base) attached or
> >> not?
> >>
> >> 2. What is meant by the 5th paragraph: "One useful ?trick? is to use what =
> >> NULL (or equivalently a length-zero list) to create a new environment on the
> >> search path into which objects can be assigned by `assign` ... "?
> >>
> >> I don't understand what this "trick" is or why a "trick" needs to be performed
> >> here.
> >>
> >> Thanks
> >> --
> >> Edward McNeil
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@@per@g@w@t@on @end|ng |rom gm@||@com  Sun Apr 26 01:08:43 2020
From: j@@per@g@w@t@on @end|ng |rom gm@||@com (Jasper Watson)
Date: Sun, 26 Apr 2020 11:08:43 +1200
Subject: [R] [R-pkgs] RBNZ: new package for downloading Reserve Bank of New
 Zealand data
Message-ID: <CAN+Ty_Ai+-6wA8sNEwH46cy25pjjGVuwX61G3XnS911rw4MGSQ@mail.gmail.com>

Hello,

I have just released to CRAN the RBNZ package which allows users to
download financial and economic data published by the Reserve Bank of New
Zealand. The data is provided on their website in spreadsheet format; this
package provides a method to download those spreadsheets and read them
directly into R.

CRAN: https://cran.r-project.org/web/packages/RBNZ/index.html
GitHub: https://github.com/rntq472/RBNZ
Data Source: https://www.rbnz.govt.nz/statistics

Cheers,

Jasper Watson

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From v@h|d@borj|65 @end|ng |rom gm@||@com  Mon Apr 27 15:30:14 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Mon, 27 Apr 2020 18:00:14 +0430
Subject: [R] Reading from a webpage
Message-ID: <CAEPHqha2jbPd+-UTMGOCRjLZ7=GAJq+A8Ld+6XNL=R-mwZN3MA@mail.gmail.com>

Hi there,

I am using R. I want to save a text, which is inside the following webpage,
in a variable, and then want to answer some questions.

http://en.neyshabur.ac.ir/en/119-about-city-of-neyshabur/1232-city-of-neyshabur

My questions are:

1) How many words do exist in the text (of the webpage)?

2) How many characters are there in the text (of the webpage)?

3) I want to find (specify) words (of the text) that have more than 9
letters. How can I do it?

4) I want to find words that are repeated at least four times in the text.
How can I do it?

5) Assume the words of the text are typed vice verse (from end to first),
how can I edit it?

	[[alternative HTML version deleted]]


From |eroy @end|ng |rom |cmpe@cnr@@|r  Mon Apr 27 16:03:30 2020
From: |eroy @end|ng |rom |cmpe@cnr@@|r (Labo Eric)
Date: Mon, 27 Apr 2020 16:03:30 +0200
Subject: [R] pair correlation function of 3D points
Message-ID: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>

Hi,

I have the coordinates of 3D points and I want to plot the pair 
correlation function of these points 
(https://en.wikipedia.org/wiki/Radial_distribution_function). I wonder 
if it possible to calculate this function with R. Maybe with the 
spatstat library? I tried but I found the way to do this with 3D points 
but not for 3D points.

Could you help me ?

Thank you,

Best regards,

-- 

From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 27 19:04:41 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 27 Apr 2020 10:04:41 -0700
Subject: [R] Reading from a webpage
In-Reply-To: <CAEPHqha2jbPd+-UTMGOCRjLZ7=GAJq+A8Ld+6XNL=R-mwZN3MA@mail.gmail.com>
References: <CAEPHqha2jbPd+-UTMGOCRjLZ7=GAJq+A8Ld+6XNL=R-mwZN3MA@mail.gmail.com>
Message-ID: <CAGxFJbTZyt-uyE-Q_SsuzdO-TYwtM6UJJENneCQLixkK0xx_Yg@mail.gmail.com>

This list provides "Help" ; it sounds like you are looking for a
tutorial with detailed instructions, which generally goes beyond what
will be provided here. See the posting guide linked at the bottom for
what you *can* expect.

https://cran.r-project.org/web/views/WebTechnologies.html
provides information that may well be relevant.

Also, try searching at rseek.org. Entering "scraping web pages" there
brought up what looked like useful information, for example.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Apr 27, 2020 at 8:56 AM Vahid Borji <vahid.borji65 at gmail.com> wrote:
>
> Hi there,
>
> I am using R. I want to save a text, which is inside the following webpage,
> in a variable, and then want to answer some questions.
>
> http://en.neyshabur.ac.ir/en/119-about-city-of-neyshabur/1232-city-of-neyshabur
>
> My questions are:
>
> 1) How many words do exist in the text (of the webpage)?
>
> 2) How many characters are there in the text (of the webpage)?
>
> 3) I want to find (specify) words (of the text) that have more than 9
> letters. How can I do it?
>
> 4) I want to find words that are repeated at least four times in the text.
> How can I do it?
>
> 5) Assume the words of the text are typed vice verse (from end to first),
> how can I edit it?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@h|d@borj|65 @end|ng |rom gm@||@com  Mon Apr 27 19:19:26 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Mon, 27 Apr 2020 21:49:26 +0430
Subject: [R] Information from a webpage using R
Message-ID: <CAEPHqhaWDEqN2=o3ckT6Ci4iHQ-8-J00QpuDcah9dyUJTmAsKw@mail.gmail.com>

Hi there,
I faced difficulty while programming in R. How can I save a text, which is
inside a webpage, in a variable, and then find (specify) words (of the
text) that have more than 9 letters?

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Mon Apr 27 19:22:55 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 27 Apr 2020 17:22:55 +0000
Subject: [R] deciphering help for `attach`
In-Reply-To: <CAGxFJbTe+S7mHMM_q4MsDmOaW3pCRi0QO0e3Rj9zJern2-DhRw@mail.gmail.com>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
 <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
 <20751_1587994317_03RDVrcr024245_3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
 <385EEAF3-0534-42AF-B7C1-37DF76345255@mcmaster.ca>
 <CAGxFJbTe+S7mHMM_q4MsDmOaW3pCRi0QO0e3Rj9zJern2-DhRw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC88CE5E340@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

> -----Original Message-----
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Monday, April 27, 2020 11:26 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: edward.m at psu.ac.th; r-help at r-project.org
> Subject: Re: [R] deciphering help for `attach`
> 
> What is the use case for attach? As the Help says, I find that with() or
> sometimes within() handles the situations where I would use it.

I don't believe that I was making a general case for using attach(), and in fact was arguing to the contrary that its use can produce confusion. I was simply trying to clarify what the help page says, which was the focus of the original question.

I've only once encountered a situation where I wanted to attach an environment (not a data frame) to the search path.

Best,
 John

> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Apr 27, 2020 at 7:58 AM Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Edward,
> >
> > Paragraph 4 in the help page goes on to say, "Rather, a new environment
> is created on the search path and the elements of a list (including
> columns of a data frame) or objects in a save file or an environment are
> copied into the new environment."
> >
> > That seems reasonably clear to me. Here's an example that also
> illustrates how attach can lead to confusion:
> >
> > ------- snip --------
> >
> > > str(cars)
> > 'data.frame':   50 obs. of  2 variables:
> >  $ speed: num  4 4 7 7 8 9 10 10 10 11 ...
> >  $ dist : num  2 10 4 22 16 10 18 26 34 17 ...
> >
> > > attach(cars)
> >
> > > search()
> >  [1] ".GlobalEnv"        "cars"              "tools:rstudio"
> "package:stats"
> >  [5] "package:graphics"  "package:grDevices" "package:utils"
> "package:datasets"
> >  [9] "package:methods"   "Autoloads"         "package:base"
> >
> > > objects()
> > character(0)
> >
> > > objects(pos=2)
> > [1] "dist"  "speed"
> >
> > > str(get("dist", pos=2))
> >  num [1:50] 2 10 4 22 16 10 18 26 34 17 ...
> >
> > > dist <- 1:10
> >
> > > head(dist) # shadows dist in copy of cars
> > [1] 1 2 3 4 5 6
> >
> > > head(get("dist", pos=2))
> > [1]  2 10  4 22 16 10
> >
> > > assign("dist", 10:1, pos=2) # changes dist in objects copied from
> > > cars
> >
> > > head(get("dist", pos=2))
> > [1] 10  9  8  7  6  5
> >
> > ------- snip --------
> >
> > Paragraph 5 also seems clear to me. Here's an example:
> >
> > ------- snip --------
> >
> > > attach(NULL)
> >
> > > search()
> >  [1] ".GlobalEnv"        "NULL"              "cars"
> "tools:rstudio"
> >  [5] "package:stats"     "package:graphics"  "package:grDevices"
> "package:utils"
> >  [9] "package:datasets"  "package:methods"   "Autoloads"
> "package:base"
> >
> > > assign("x", 10, pos=2)
> >
> > > x
> > [1] 10
> >
> > ------- snip --------
> >
> > Now that may beg the question of why one would want to do something like
> this, which isn't addressed in the help file, but a fair comment is that
> if you don't need to store objects in an environment that's accessible on
> the path, why worry about it? After all, no one is forcing you to use this
> trick.
> >
> > Finally, I too recommended that students use attach() when I first
> starting teaching with R, until I noticed that they frequently tied
> themselves into knots by attaching different versions of the same data
> during a session, producing confusion about where the data were coming
> from and what version they were using. It's not hard in R to avoid the use
> of attach(). Of course, attach() is still part of the language, so you,
> and your students, are free to continue using it if you wish, and perhaps
> your students avoid the problems that mine often created.
> >
> > Best,
> >  John
> >
> >   -----------------------------
> >   John Fox, Professor Emeritus
> >   McMaster University
> >   Hamilton, Ontario, Canada
> >   Web: http::/socserv.mcmaster.ca/jfox
> >
> > > On Apr 27, 2020, at 9:26 AM, Edward McNeil <edward.m at psu.ac.th> wrote:
> > >
> > > Dear Petr,
> > > Thanks for your quick reply. Much appreciated. However, you haven't
> > > really answered either of my questions, although I don't quite
> understand your reference to La Gioconda.
> > >
> > > In any case, despite your strong recommendation not to use `attach`,
> > > I am going to keep using it, as I have done successfully for the
> > > past 16 years, and keep teaching it, until it either kills me or
> > > disappears from R. Unfortunately I have to teach R to students and I
> > > don't like it when they ask me "tricky" questions to which I have no
> > > answer. ;)
> > > --
> > > Edward McNeil
> > >
> > > On Mon, April 27, 2020 8:00 pm, PIKAL Petr wrote:
> > > Hi.
> > >
> > > I strongly recommend not to use attach. I agree that mentioned
> > > statements are rather contradictory and probably others could give
> > > you more insightful answer. You could consider that by attaching
> > > some data, you create something like a copy of original data in your
> > > system with a feature that you can use column names directly. If you
> > > change something in the data after attachment, you change only
> attached version and not an original.
> > >
> > > It is similar as if you take a picture of Gioconda an use some
> > > creativity to add a moustache to this picture. In any circumstances
> > > moustache does not propagate to the original Louvre painting. Do not
> perform any tricks, preferably do not perform attach.
> > >
> > > Cheers
> > > Petr
> > >
> > >> -----Original Message-----
> > >> From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward
> > >> McNeil
> > >> Sent: Monday, April 27, 2020 2:07 PM
> > >> To: r-help at r-project.org
> > >> Subject: [R] deciphering help for `attach`
> > >>
> > >> Hi,
> > >> I have two related questions.
> > >>
> > >> 1. In the help page for `attach` under "Details" it says in paragraph
> 3:
> > >> "By default the database is attached ..."
> > >>
> > >> But then paragraph 4 starts: "The database is not actually attached."
> > >>
> > >> Could somebody explain this contradiction? Is the data(base)
> > >> attached or not?
> > >>
> > >> 2. What is meant by the 5th paragraph: "One useful ?trick? is to
> > >> use what = NULL (or equivalently a length-zero list) to create a
> > >> new environment on the search path into which objects can be assigned
> by `assign` ... "?
> > >>
> > >> I don't understand what this "trick" is or why a "trick" needs to
> > >> be performed here.
> > >>
> > >> Thanks
> > >> --
> > >> Edward McNeil
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >> guide.html and provide commented, minimal, self-contained,
> > >> reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From @purd|e@@ @end|ng |rom gm@||@com  Mon Apr 27 21:40:39 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Apr 2020 07:40:39 +1200
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
Message-ID: <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>

> > (3) If (2) true, how much CPU is R using?
> 0%.

> > (4) If (3) is zero, what processes are using the CPU the most?
> In such case, almost every processes is using the CPU in a very low
> percentage, i.e., 1% or below. I don't recognized those processes.
> Now, I invoke help.start(), about 25% of CPU loading is used by R. Quit
> from R, the CPU loading go back to idle.

Is R using 0% or 25%?

Again, if R was using 25% while showing the prompt and waiting for
user input, that would be a bug in R.

Or do you mean R is using 0% and total CPU usage *temporarily*
increases 25% *while* R is running?
If so, this could be the result of some security feature...? not sure
because this is outside my area...

I just found the following feature.
If you open powershell, one can run: ps | sort -desc cpu

This could be used if you want to show people what's happening.

PS C:\Users\spurdle> ps | sort -desc cpu

Handles  NPM(K)    PM(K)      WS(K)     CPU(s)     Id  SI ProcessName
-------  ------    -----      -----     ------     --  -- -----------
    625      28   108940     111644   4,900.52   8176   0 audiodg
    794      38   234888     177924      62.13   8652  19 chrome
   1673      71    84372     147628      61.97  10304  19 chrome
    330      25   100096     146968      55.80   1052  19 chrome
    391      26   141928     181264      35.27   6884  19 chrome
    291      20    46676      80472      15.25   5352  19 chrome
   2351      79    58404     107276      13.33   6940  19 explorer
    443      22    17916      34764      12.17   7196  19 chrome
   1331      90   107628      87596      10.86   9432  19 SearchUI
    671      41    56184      70320       9.94  10420  19 powershell
    362      24    51984      91568       9.06   4360  19 chrome
   1129     107   206988      31852       7.17   6740  19 SkypeApp
    696      40    26764      45620       5.33   4348  19
Lenovo.Modern.ImController.PluginHost.Device
    256      20    56860      84372       5.17   1660  19 chrome
    284      18    34532      62112       5.13   1212  19 chrome
    291      19     7048      16360       4.30   1476  19 chrome

Diverging, I can't figure out how to permanently stop Lenovo and Skype
processes, or why chrome (and edge) need so many copies of
themselves...
Anyway, the plan is to shift to Debian or OpenIndianna, and run
ReactOS via virtualization...


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Apr 27 22:04:12 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 27 Apr 2020 16:04:12 -0400
Subject: [R] Information from a webpage using R
In-Reply-To: <CAEPHqhaWDEqN2=o3ckT6Ci4iHQ-8-J00QpuDcah9dyUJTmAsKw@mail.gmail.com>
References: <CAEPHqhaWDEqN2=o3ckT6Ci4iHQ-8-J00QpuDcah9dyUJTmAsKw@mail.gmail.com>
Message-ID: <6a701868-44eb-f36e-f2a3-649b896b6329@gmail.com>

On 27/04/2020 1:19 p.m., Vahid Borji wrote:
> Hi there,
> I faced difficulty while programming in R. How can I save a text, which is
> inside a webpage, in a variable, and then find (specify) words (of the
> text) that have more than 9 letters?

You already asked this question a few hours ago.  I didn't answer it 
because it looks like homework (or a takehome exam), and we don't do 
those here.  I'd suggest you give some more context on why you need to 
do this, if it's not homework/exam.

Duncan Murdoch


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Apr 27 22:16:24 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 27 Apr 2020 20:16:24 +0000 (UTC)
Subject: [R] Fit Gaussian curve on my data ?
In-Reply-To: <CAB8pepytFUBjs86dwcCAfRVJCNvhxeyqabcV6bTo7PodvwmuxA@mail.gmail.com>
References: <1530976294.485495.1587841379304.ref@mail.yahoo.com>
 <1530976294.485495.1587841379304@mail.yahoo.com>
 <CAB8pepytFUBjs86dwcCAfRVJCNvhxeyqabcV6bTo7PodvwmuxA@mail.gmail.com>
Message-ID: <379064856.2262750.1588018584712@mail.yahoo.com>

Ivan, 
Abby,

Many thanks for your help. 
Best,









Le samedi 25 avril 2020 ? 22:09:03 UTC+2, Abby Spurdle <spurdle.a at gmail.com> a ?crit : 





Have a look at the dnorm function:
?dnorm

Notes:
(1) You'd be better to say estimate (or fit) parameters (or
coefficients) and plot the resulting normal distribution (or normal
density), rather than say fit a density curve, because someone may
think you want a kernel density estimate with a Gaussian kernel.
(2) Densities integrate to one by definition. i.e. If a function
didn't integrate to one it wouldn't be a probability density function,
but still could be a function representing a probability
distribution...

On Sun, Apr 26, 2020 at 7:09 AM varin sacha via R-help
<r-help at r-project.org> wrote:
>
> Dear R-experts,
>
> I am trying to fit a gaussian density curve. More precisely, I would like to obtain the fitted "Gaussian curve".
> "m" is the gaussian mean, "sd" is the standard deviation and "k" is an arbitrary scaling parameter (since the gaussian density is constrained to integrate to 1, whereas my data isn't).
> There is no error message. In my opinion, the last command of my reproducible R script is not doing its job !
>
> Many thanks for your lights.
>
> ############################################################
> a <- as.Date(c("2020-02-25", "2020-02-26","2020-02-27","2020-02-28","2020-03-1","2020-03-2","2020-03-3","2020-03-4","2020-03-5","2020-03-6","2020-03-7","2020-03-8","2020-03-9","2020-03-10","2020-03-11","2020-03-12","2020-03-13","2020-03-14","2020-03-15","2020-03-16"))
>
> b<- c(20,28,45,68,89,123,154,190,245,302,460,379,298,300,245,189,165,100,90,78)
>
> d <-as.numeric(a)
>
> m<-11.84
>
> sd<-3.93
>
> k<-359.77
>
> plot(b~d)
>
> plot(function(d) k*exp(-0.5*(d-m)^2/sd^2),col=2,add=TRUE,xlim=range(d))

> ############################################################
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Apr 27 22:30:03 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 27 Apr 2020 16:30:03 -0400
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <CAHz+bWbVAfiXG_ww2eU+fvGz2von+hi9pZfunK039vq6C=rD6w@mail.gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
 <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
 <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>
 <CAB8pepxF_PNiGdbwLm8U54=cmkaQVsUPeP1dk8mQRVWYZNuToQ@mail.gmail.com>
 <CAHz+bWbVAfiXG_ww2eU+fvGz2von+hi9pZfunK039vq6C=rD6w@mail.gmail.com>
Message-ID: <015bc5e6-c4a0-70dd-783d-2caab7fc1d18@gmail.com>

After looking at MASS::fitdistr and fitdistrplus::fitdist, the latter seems to have
code to detect (near-)singular hessian that is almost certainly the "crash site" for
this thread. Was that package tried in this work?

I agree with Mark that writing one's own code for this is a lot of work, and I know
the folk who worked on fitdistrplus did a lot more distribution fitting problems
than I ever did, and I suspect they encountered this issue on occasions.

JN

On 2020-04-26 9:18 p.m., Mark Leeds wrote:
> it's been a looooooooong time but I vaguely remember Rvmminb computing
> gradients ( and possibly hessians )
> subject to constraints. John can say more about this but, if one is going
> to go through the anguish of
> creating a fitdstr2, then you may want to have it call Rvmminb instead of
> whatever is currently
> being called.
> 
> 
> 
> On Sun, Apr 26, 2020 at 8:55 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> I thought about this some more and realized my last suggestion is
>> unlikely to work.
>> Another possibility would be to create a new function to compute the
>> Hessian with a smaller step size, but I suspect there will be more
>> problems.
>>
>> Possibly a much simpler approach would be to:
>>
>> Modify the source for fitdistr.
>> (Copy the source and create a new function, say fitdistr2).
>>
>> Modify it not compute the Hessian in the optim call.
>> Then after the optim call, test the parameter estimates.
>> If they're very close to the boundaries (here zero), then they're
>> flagged as near-boundary cases and the fitdistr2 function returns the
>> parameter estimates without the Hessian and related info.
>> (Possibly generating a warning).
>>
>> If they're sufficiently distant, the Hessian and related info can be
>> computed in separate steps and returned.
>> (Equivalent to what it does currently).
>>
>> I note that there's at least one R package (numDeriv), and maybe more,
>> for computing the Hessian, numerically.
>>
>>
>> On Mon, Apr 27, 2020 at 9:31 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>
>>>> Dear Ms. Spurdle
>>>
>>> I usually refer to myself as "He".
>>> (But then, that's not the whole story...)
>>>
>>> I'm not an expert on maximum likelihood approaches.
>>> So, I apologize if the following suggestion is a poor one.
>>>
>>> Does your likelihood function have a limit, as alpha approaches zero
>> (say zero)?
>>> If so, the limit of the log-likelihood would be -Inf, would it not.
>>>
>>> You could create a function representing the likelihood or
>>> log-likelihood by wrapping your density function.
>>> The function could allow alpha/beta values equal to or below zero, and
>>> return the limit.
>>> This is mathematically incorrect, but may be sufficient for
>>> permissible estimates of the second-order partial derivatives.
>>> Depending on the shape of the likelihood function these
>>> pseudo-likelihoods maybe able to be improved...?
>>>
>>> You could then do a small modification on the source code for
>>> MASS::fitdistr, such that the user specifies the likelihood function
>>> or log-likelihood function, rather than the density...
>>>
>>> The fitdistr function is relatively complex, however, you would only
>>> need to modify a couple of lines, the lines that create the fn
>>> function...
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Mon Apr 27 22:44:55 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Apr 2020 08:44:55 +1200
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
Message-ID: <CAB8pepy22zRo6qpPjo4FtwnUmKzOzwdL5o-VySY1XRxWCLRY7A@mail.gmail.com>

Just realized CPU(s) is time the process was running.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Apr 27 22:54:43 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Apr 2020 08:54:43 +1200
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <CAB8pepy22zRo6qpPjo4FtwnUmKzOzwdL5o-VySY1XRxWCLRY7A@mail.gmail.com>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
 <CAB8pepy22zRo6qpPjo4FtwnUmKzOzwdL5o-VySY1XRxWCLRY7A@mail.gmail.com>
Message-ID: <CAB8pepx5BdrB3e7h6C9vzfYNf+H_uzdN=ramNEVAn_Q8afcMpw@mail.gmail.com>

I give up.
(I was trying to emulate the top command).

You might have to manually type the contents of the task manager, with
process name and CPU usage.
That's if you still want to fix the problem...

On Tue, Apr 28, 2020 at 8:44 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Just realized CPU(s) is time the process was running.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Apr 27 22:56:28 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 27 Apr 2020 21:56:28 +0100
Subject: [R] Problem with MASS::fitdistr().
In-Reply-To: <015bc5e6-c4a0-70dd-783d-2caab7fc1d18@gmail.com>
References: <1c4f3159-ff7f-6a1b-f10d-86c021dd2b6f@auckland.ac.nz>
 <CAB8pepzWC1=jDqw6NDQ_P1=3v2v1-_GM_ELRBC5cNBM69+cmwQ@mail.gmail.com>
 <CAB8pepw042vtu=aBuzoZv1c+F_obm8rVhMphc4m7qTCrEwAUsQ@mail.gmail.com>
 <CAB8pepyP0fyvN+pnUUjNGowYW1tVuLkRO3kgED4sdzqDkPUQxQ@mail.gmail.com>
 <e6ba6280-d628-40e5-95d7-d50b615d2483@auckland.ac.nz>
 <CAB8pepztORcUzV+q_jNZ9ginQVPG3oJ6ANSUHhxv_0mZudHaSQ@mail.gmail.com>
 <CAB8pepxF_PNiGdbwLm8U54=cmkaQVsUPeP1dk8mQRVWYZNuToQ@mail.gmail.com>
 <CAHz+bWbVAfiXG_ww2eU+fvGz2von+hi9pZfunK039vq6C=rD6w@mail.gmail.com>
 <015bc5e6-c4a0-70dd-783d-2caab7fc1d18@gmail.com>
Message-ID: <3412b506-398a-969d-f31c-99605c5e1dd4@sapo.pt>

Hello,

Inline.

?s 21:30 de 27/04/20, J C Nash escreveu:
> After looking at MASS::fitdistr and fitdistrplus::fitdist, the latter seems to have
> code to detect (near-)singular hessian that is almost certainly the "crash site" for
> this thread. Was that package tried in this work?

I tried it. I didn't post the results because I thought that others had 
probably also tried it and I had no real contribution to give to this 
thread. Except maybe that fitdistrplus::fitdist also hardcodes

hessian = TRUE

in the calls to optim.

And that I had to add 'topn' in the 'start' list, not just 'par0'.
Here is what I got:


library(fitdistrplus)

fitdist(x, distr = dhse, start = as.list(c(par0, topn = 5)))
Called from: dhse(c(1, 4, 1, 2, 3, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 4,
4, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 4, 1,

[...]

5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 1, 2, 2, 2, 3, 1,
3, 2, 3, 1, 4, 1, 1, 3, 4, 2, 1, 1, 4, 3, 5, 5, 1, 1, 4, 1, 1,
1, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 3, 5, 4, 5, 2, 4, 5, 5),
     alpha = -0.0865702222222222, beta = 1.7577217037037, topn = 
5.77314814814815)
Browse[1]> Q


Hope this helps,

Rui Barradas

> 
> I agree with Mark that writing one's own code for this is a lot of work, and I know
> the folk who worked on fitdistrplus did a lot more distribution fitting problems
> than I ever did, and I suspect they encountered this issue on occasions.
> 
> JN
> 
> On 2020-04-26 9:18 p.m., Mark Leeds wrote:
>> it's been a looooooooong time but I vaguely remember Rvmminb computing
>> gradients ( and possibly hessians )
>> subject to constraints. John can say more about this but, if one is going
>> to go through the anguish of
>> creating a fitdstr2, then you may want to have it call Rvmminb instead of
>> whatever is currently
>> being called.
>>
>>
>>
>> On Sun, Apr 26, 2020 at 8:55 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>>> I thought about this some more and realized my last suggestion is
>>> unlikely to work.
>>> Another possibility would be to create a new function to compute the
>>> Hessian with a smaller step size, but I suspect there will be more
>>> problems.
>>>
>>> Possibly a much simpler approach would be to:
>>>
>>> Modify the source for fitdistr.
>>> (Copy the source and create a new function, say fitdistr2).
>>>
>>> Modify it not compute the Hessian in the optim call.
>>> Then after the optim call, test the parameter estimates.
>>> If they're very close to the boundaries (here zero), then they're
>>> flagged as near-boundary cases and the fitdistr2 function returns the
>>> parameter estimates without the Hessian and related info.
>>> (Possibly generating a warning).
>>>
>>> If they're sufficiently distant, the Hessian and related info can be
>>> computed in separate steps and returned.
>>> (Equivalent to what it does currently).
>>>
>>> I note that there's at least one R package (numDeriv), and maybe more,
>>> for computing the Hessian, numerically.
>>>
>>>
>>> On Mon, Apr 27, 2020 at 9:31 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>>>
>>>>> Dear Ms. Spurdle
>>>>
>>>> I usually refer to myself as "He".
>>>> (But then, that's not the whole story...)
>>>>
>>>> I'm not an expert on maximum likelihood approaches.
>>>> So, I apologize if the following suggestion is a poor one.
>>>>
>>>> Does your likelihood function have a limit, as alpha approaches zero
>>> (say zero)?
>>>> If so, the limit of the log-likelihood would be -Inf, would it not.
>>>>
>>>> You could create a function representing the likelihood or
>>>> log-likelihood by wrapping your density function.
>>>> The function could allow alpha/beta values equal to or below zero, and
>>>> return the limit.
>>>> This is mathematically incorrect, but may be sufficient for
>>>> permissible estimates of the second-order partial derivatives.
>>>> Depending on the shape of the likelihood function these
>>>> pseudo-likelihoods maybe able to be improved...?
>>>>
>>>> You could then do a small modification on the source code for
>>>> MASS::fitdistr, such that the user specifies the likelihood function
>>>> or log-likelihood function, rather than the density...
>>>>
>>>> The fitdistr function is relatively complex, however, you would only
>>>> need to modify a couple of lines, the lines that create the fn
>>>> function...
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From y@kov@go|dberg @end|ng |rom gm@||@com  Tue Apr 28 04:41:43 2020
From: y@kov@go|dberg @end|ng |rom gm@||@com (Yakov Goldberg)
Date: Mon, 27 Apr 2020 19:41:43 -0700
Subject: [R] Ubuntu 18.04 R repo bionic-cran35 seems to be broken
Message-ID: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>

Hello,
I'm using Ubuntu 18.04 R repo
https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/

Currently it is broken - missing Release file, which seems happened
accidentally, as other repos are functioning.
Could anyone of maintainers comment and fix if it is really a mistake?
Thanks, Yakov.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Apr 28 05:42:15 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 27 Apr 2020 20:42:15 -0700
Subject: [R] Ubuntu 18.04 R repo bionic-cran35 seems to be broken
In-Reply-To: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>
References: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>
Message-ID: <0545fd82-d0a8-912c-25f4-3e150fb9a7d6@comcast.net>


On 4/27/20 7:41 PM, Yakov Goldberg wrote:
> Hello,
> I'm using Ubuntu 18.04 R repo
> https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/


Perhaps because you misspelled it?


https://cloud.r-project.org/bin/linux/ubuntu/bionic-cran35/


Next time try going "upstream and then follow links (as I did).

>
> Currently it is broken - missing Release file, which seems happened
> accidentally, as other repos are functioning.
> Could anyone of maintainers comment and fix if it is really a mistake?

This is the wrong mailing list. The correct one is named something like 
R-SIG-debian.


-- 

David.

> Thanks, Yakov.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@zh@o @end|ng |rom ye@h@net  Tue Apr 28 07:39:57 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Tue, 28 Apr 2020 13:39:57 +0800
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
Message-ID: <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>

On 2020/4/28 3:40, Abby Spurdle wrote:
>>> (3) If (2) true, how much CPU is R using?
>> 0%.
> 
>>> (4) If (3) is zero, what processes are using the CPU the most?
>> In such case, almost every processes is using the CPU in a very low
>> percentage, i.e., 1% or below. I don't recognized those processes.
>> Now, I invoke help.start(), about 25% of CPU loading is used by R. Quit
>> from R, the CPU loading go back to idle.
> 
> Is R using 0% or 25%?
> 
> Again, if R was using 25% while showing the prompt and waiting for
> user input, that would be a bug in R.

25% CPU is used by R. And R shows the prompt and waits for user input.

Here is a report of the CPU usage by Rgui from Windows command line:
C:\Users\Jinso>typeperf "\Process(Rgui)\% Processor Time" -si 5
....
"04/28/2020 13:31:05.895","-1"
"04/28/2020 13:31:10.915","0.622494"
"04/28/2020 13:31:15.925","0.000000"
"04/28/2020 13:31:20.935","0.000000"
"04/28/2020 13:31:25.945","0.000000"
"04/28/2020 13:31:30.965","2.801177"
"04/28/2020 13:31:35.975","37.418638"
"04/28/2020 13:31:40.982","100.159072"
"04/28/2020 13:31:45.987","99.887614"
"04/28/2020 13:31:50.992","99.899896"
"04/28/2020 13:31:55.999","119.270784"
"04/28/2020 13:32:01.002","299.014789"
"04/28/2020 13:32:06.007","299.666184"
"04/28/2020 13:32:11.015","294.905707"
"04/28/2020 13:32:16.019","299.755921"
"04/28/2020 13:32:21.025","299.924392"
"04/28/2020 13:32:26.030","296.594191"
"04/28/2020 13:32:31.048","298.195791"
"04/28/2020 13:32:36.054","292.362986"
"04/28/2020 13:32:41.064","292.503832"
"04/28/2020 13:32:46.068","301.650976"
...
...

At about 10", I start Rgui, the CPU usage is about 0.5~1% (The second 
column number may be divided by 4).

At about 35", I call help.start() from menu of Rgui, you may notice that 
CPU usage increased to about 25%.

At about 55", I click on the ``Packages'' link in the browser. The CPU 
usage increased to about 70-75%, and closing browser does not have any 
effects on the CPU usage of R.


> 
> Or do you mean R is using 0% and total CPU usage *temporarily*
> increases 25% *while* R is running?
> If so, this could be the result of some security feature...? not sure
> because this is outside my area...
> 
> I just found the following feature.
> If you open powershell, one can run: ps | sort -desc cpu
> 
> This could be used if you want to show people what's happening.
> 
> PS C:\Users\spurdle> ps | sort -desc cpu
> 
> Handles  NPM(K)    PM(K)      WS(K)     CPU(s)     Id  SI ProcessName
> -------  ------    -----      -----     ------     --  -- -----------
>      625      28   108940     111644   4,900.52   8176   0 audiodg
>      794      38   234888     177924      62.13   8652  19 chrome
>     1673      71    84372     147628      61.97  10304  19 chrome
>      330      25   100096     146968      55.80   1052  19 chrome
>      391      26   141928     181264      35.27   6884  19 chrome
>      291      20    46676      80472      15.25   5352  19 chrome
>     2351      79    58404     107276      13.33   6940  19 explorer
>      443      22    17916      34764      12.17   7196  19 chrome
>     1331      90   107628      87596      10.86   9432  19 SearchUI
>      671      41    56184      70320       9.94  10420  19 powershell
>      362      24    51984      91568       9.06   4360  19 chrome
>     1129     107   206988      31852       7.17   6740  19 SkypeApp
>      696      40    26764      45620       5.33   4348  19
> Lenovo.Modern.ImController.PluginHost.Device
>      256      20    56860      84372       5.17   1660  19 chrome
>      284      18    34532      62112       5.13   1212  19 chrome
>      291      19     7048      16360       4.30   1476  19 chrome
> 
> Diverging, I can't figure out how to permanently stop Lenovo and Skype
> processes, or why chrome (and edge) need so many copies of
> themselves...
> Anyway, the plan is to shift to Debian or OpenIndianna, and run
> ReactOS via virtualization...
>


From j@zh@o @end|ng |rom ye@h@net  Tue Apr 28 07:49:08 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Tue, 28 Apr 2020 13:49:08 +0800
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
 <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>
Message-ID: <9b27728f-acc4-11ea-7631-becf8d725396@yeah.net>

I also test the same operations on R 3.6.3. The CPU usage does not 
change dramatically.

C:\Users\Jinso>typeperf "\Process(Rgui)\% Processor Time" -si 5
...
"04/28/2020 13:42:41.007","-1"
"04/28/2020 13:42:46.017","-1"
"04/28/2020 13:42:51.037","0.622240"
"04/28/2020 13:42:56.048","0.000000"
"04/28/2020 13:43:01.058","1.871148"
"04/28/2020 13:43:06.069","3.436832"
"04/28/2020 13:43:11.079","0.000000"
"04/28/2020 13:43:16.099","0.000000"
"04/28/2020 13:43:21.109","0.000000"
"04/28/2020 13:43:26.119","3.432397"
"04/28/2020 13:43:31.129","0.000000"
"04/28/2020 13:43:36.139","0.935587"
"04/28/2020 13:43:41.149","0.933886"
"04/28/2020 13:43:46.168","1.244979"
"04/28/2020 13:43:51.188","4.054443"
"04/28/2020 13:43:56.209","0.000000"
"04/28/2020 13:44:01.239","0.310505"
...

At 51", start Rgui, and 06" call help.start() from menu of Rgui, click 
on the ``Packages'' link, close browser, and so on. You may notice that 
there are no high CPU usage occurred.

Seems a bug in R 4.0.0...

Best,
Jinsong

On 2020/4/28 13:39, Jinsong Zhao wrote:
>> Again, if R was using 25% while showing the prompt and waiting for
>> user input, that would be a bug in R.
> 
> 25% CPU is used by R. And R shows the prompt and waits for user input.
> 
> Here is a report of the CPU usage by Rgui from Windows command line:
> C:\Users\Jinso>typeperf "\Process(Rgui)\% Processor Time" -si 5
> ....
> "04/28/2020 13:31:05.895","-1"
> "04/28/2020 13:31:10.915","0.622494"
> "04/28/2020 13:31:15.925","0.000000"
> "04/28/2020 13:31:20.935","0.000000"
> "04/28/2020 13:31:25.945","0.000000"
> "04/28/2020 13:31:30.965","2.801177"
> "04/28/2020 13:31:35.975","37.418638"
> "04/28/2020 13:31:40.982","100.159072"
> "04/28/2020 13:31:45.987","99.887614"
> "04/28/2020 13:31:50.992","99.899896"
> "04/28/2020 13:31:55.999","119.270784"
> "04/28/2020 13:32:01.002","299.014789"
> "04/28/2020 13:32:06.007","299.666184"
> "04/28/2020 13:32:11.015","294.905707"
> "04/28/2020 13:32:16.019","299.755921"
> "04/28/2020 13:32:21.025","299.924392"
> "04/28/2020 13:32:26.030","296.594191"
> "04/28/2020 13:32:31.048","298.195791"
> "04/28/2020 13:32:36.054","292.362986"
> "04/28/2020 13:32:41.064","292.503832"
> "04/28/2020 13:32:46.068","301.650976"
> ...
> ...
> 
> At about 10", I start Rgui, the CPU usage is about 0.5~1% (The second 
> column number may be divided by 4).
> 
> At about 35", I call help.start() from menu of Rgui, you may notice that 
> CPU usage increased to about 25%.
> 
> At about 55", I click on the ``Packages'' link in the browser. The CPU 
> usage increased to about 70-75%, and closing browser does not have any 
> effects on the CPU usage of R.
> 
>


From @purd|e@@ @end|ng |rom gm@||@com  Tue Apr 28 09:44:09 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 28 Apr 2020 19:44:09 +1200
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
 <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>
Message-ID: <CAB8pepxW70XfNmu+odmwu1TdWgZongEhvQ3ZOFO2_E=kWKhMVg@mail.gmail.com>

> > Again, if R was using 25% while showing the prompt and waiting for
> > user input, that would be a bug in R.
>
> 25% CPU is used by R. And R shows the prompt and waits for user input.
>
> Here is a report of the CPU usage by Rgui from Windows command line:
> C:\Users\Jinso>typeperf "\Process(Rgui)\% Processor Time" -si 5
> ....
> "04/28/2020 13:31:05.895","-1"
> "04/28/2020 13:31:10.915","0.622494"

I'm not sure how to interpret this.
And I don't see where you get the 25% from.

I was suggesting something resembling the top command.
(Re-iterating, I misinterpreted the ps command).


From j@zh@o @end|ng |rom ye@h@net  Tue Apr 28 10:05:52 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Tue, 28 Apr 2020 16:05:52 +0800
Subject: [R] help.start() caused high CPU loading
In-Reply-To: <CAB8pepxW70XfNmu+odmwu1TdWgZongEhvQ3ZOFO2_E=kWKhMVg@mail.gmail.com>
References: <8c1ea630-96e4-b1ec-b19c-8cb2d57f8551@yeah.net>
 <CAB8pepxfsgYSyBd12vjPmdN9sE2th2GKJEpSmywTx3NZTF0cVg@mail.gmail.com>
 <fb027507-9250-c626-cb15-82fd2f461f8e@yeah.net>
 <CAB8pepxvYAO=x5qQMWq66qwf4mEDQ5Ehb142a=Vk=7u78i_UFQ@mail.gmail.com>
 <41dd1c75-a6cd-0c86-5a3c-76244d23a5d7@yeah.net>
 <CAB8pepxW70XfNmu+odmwu1TdWgZongEhvQ3ZOFO2_E=kWKhMVg@mail.gmail.com>
Message-ID: <9ab3cf8c-c4e1-7a30-45e1-f2ae28b66596@yeah.net>

On 2020/4/28 15:44, Abby Spurdle wrote:
>>> Again, if R was using 25% while showing the prompt and waiting for
>>> user input, that would be a bug in R.
>>
>> 25% CPU is used by R. And R shows the prompt and waits for user input.
>>
>> Here is a report of the CPU usage by Rgui from Windows command line:
>> C:\Users\Jinso>typeperf "\Process(Rgui)\% Processor Time" -si 5
>> ....
>> "04/28/2020 13:31:05.895","-1"
>> "04/28/2020 13:31:10.915","0.622494"
> 
> I'm not sure how to interpret this.
> And I don't see where you get the 25% from.

The number in second column divided 4 would give the CPU usage, so, if 
the number is 100 or above, then the CPU usage is 25% or more...

> 
> I was suggesting something resembling the top command.
> (Re-iterating, I misinterpreted the ps command).

There are no ``top'' command on Windows. And I am not familiar with the 
command line utilities on Windows.

Since I can not reproduce the same problem using R 3.6.3, I think it is 
a bug in R 4.0.0. I have filed a bug report.

Thanks a lot for your help.

Best,
Jinsong


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Tue Apr 28 11:29:20 2020
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Tue, 28 Apr 2020 11:29:20 +0200
Subject: [R] regular expression, stringr::str_view, grep
Message-ID: <1002f7b7-ef2e-4993-967d-0744d874616e@wiwi.hu-berlin.de>

Hi,

we gave students the task to construct a regular expression selecting 
some texts. One send us back a program which gives different results on 
stringr::str_view and grep.

The problem is "[^[A-Z]]" / "[^[A-Z]" at the end of the regular 
expression. I would have expected that all four calls would give the 
same result; interpreting [ and ] within [...] as the characters `[` and 
`]`. Obviously this not the case and moreover stringr::str_view and grep 
interpret the regular expressions differently.

Any ideas?

Thanks Sigbert

---

aff <- c("affgfking", "fgok", "rafgkahe","a fgk", "bafghk", "affgm",
          "baffgkit", "afffhk", "affgfking", "fgok", "rafgkahe", "afg.K",
          "bafghk", "aff gm", "baffg kit", "afffhgk")

correct_brackets <- "af+g[^m$][^[A-Z]]"
missing_brackets <- "af+g[^m$][^[A-Z]"

library("stringr")
grep(correct_brackets, aff, value = TRUE) ### result: character(0)
grep(missing_brackets, aff, value = TRUE) ### correct result
str_view(aff, correct_brackets) ### correct result
str_view(aff, missing_brackets) ### error: missing closing bracket

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat3


From y@kov@go|dberg @end|ng |rom gm@||@com  Tue Apr 28 05:59:11 2020
From: y@kov@go|dberg @end|ng |rom gm@||@com (Yakov Goldberg)
Date: Mon, 27 Apr 2020 20:59:11 -0700
Subject: [R] Ubuntu 18.04 R repo bionic-cran35 seems to be broken
In-Reply-To: <0545fd82-d0a8-912c-25f4-3e150fb9a7d6@comcast.net>
References: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>
 <0545fd82-d0a8-912c-25f4-3e150fb9a7d6@comcast.net>
Message-ID: <CAPQ0CMjsjtjZ_p5uxWs0ZfV74t355G_magQGOni+ZXSr_mqG3w@mail.gmail.com>

I have not mispelled it.
That's how repo is added for Ubuntu.
The problem is: there is no Release file in that folder.

On Mon, Apr 27, 2020, 8:42 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 4/27/20 7:41 PM, Yakov Goldberg wrote:
> > Hello,
> > I'm using Ubuntu 18.04 R repo
> > https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/
>
>
> Perhaps because you misspelled it?
>
>
> https://cloud.r-project.org/bin/linux/ubuntu/bionic-cran35/
>
>
> Next time try going "upstream and then follow links (as I did).
>
> >
> > Currently it is broken - missing Release file, which seems happened
> > accidentally, as other repos are functioning.
> > Could anyone of maintainers comment and fix if it is really a mistake?
>
> This is the wrong mailing list. The correct one is named something like
> R-SIG-debian.
>
>
> --
>
> David.
>
> > Thanks, Yakov.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @yen @end|ng |rom hqu@edu@cn  Tue Apr 28 10:38:51 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Tue, 28 Apr 2020 16:38:51 +0800
Subject: [R] Rtools required
Message-ID: <25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>

Dear All

I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now 
the new default folder c:\rtools40). While compiling a package (binary) 
I received the follow marning message saying Rtools is required. Any 
clues? Thanks.

Steven Yen

WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding: https://cran.rstudio.com/bin/windows/Rtools/


	[[alternative HTML version deleted]]


From @yen04 @end|ng |rom gm@||@com  Tue Apr 28 11:57:47 2020
From: @yen04 @end|ng |rom gm@||@com (Steven T. Yen)
Date: Tue, 28 Apr 2020 17:57:47 +0800
Subject: [R] Rtools required
Message-ID: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>

Dear All

I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now 
the new default folder c:\rtools40). While compiling a package (binary) 
I received the follow marning message saying Rtools is required. Any 
clues? Thanks.

Steven Yen

WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding: https://cran.rstudio.com/bin/windows/Rtools/


	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Apr 28 14:29:20 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 28 Apr 2020 12:29:20 +0000
Subject: [R] Rtools required
In-Reply-To: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
Message-ID: <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>

Dear Steven,

Did you follow the instruction on the Rtools webpage to add 

	PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"

to your .Renviron file?

I hope this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> 
> Dear All
> 
> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now 
> the new default folder c:\rtools40). While compiling a package (binary) 
> I received the follow marning message saying Rtools is required. Any 
> clues? Thanks.
> 
> Steven Yen
> 
> WARNING: Rtools is required to build R packages but is not currently 
> installed. Please download and install the appropriate version of Rtools 
> before proceeding: https://cran.rstudio.com/bin/windows/Rtools/
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 28 14:39:58 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 28 Apr 2020 08:39:58 -0400
Subject: [R] Rtools required
In-Reply-To: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
Message-ID: <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>

On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
> Dear All
> 
> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
> the new default folder c:\rtools40). While compiling a package (binary)
> I received the follow marning message saying Rtools is required. Any
> clues? Thanks.

Presumably you didn't put it on your path, or you used a non-standard 
way to build.  You need to say what command you used.

Duncan Murdoch


From @te|@nML @end|ng |rom co||oc@t|on@@de  Tue Apr 28 15:11:45 2020
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Tue, 28 Apr 2020 15:11:45 +0200
Subject: [R] Ubuntu 18.04 R repo bionic-cran35 seems to be broken
In-Reply-To: <CAPQ0CMjsjtjZ_p5uxWs0ZfV74t355G_magQGOni+ZXSr_mqG3w@mail.gmail.com>
References: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>
 <0545fd82-d0a8-912c-25f4-3e150fb9a7d6@comcast.net>
 <CAPQ0CMjsjtjZ_p5uxWs0ZfV74t355G_magQGOni+ZXSr_mqG3w@mail.gmail.com>
Message-ID: <2ADE3996-A374-41DC-989E-2B8474BF20E6@collocations.de>



> On 28 Apr 2020, at 05:59, Yakov Goldberg <yakov.goldberg at gmail.com> wrote:
> 
> I have not mispelled it.
> That's how repo is added for Ubuntu.
> The problem is: there is no Release file in that folder.

But there is:

	https://cloud.r-project.org/bin/linux/ubuntu/bionic-cran35/Release

So the problem must be something else.

Best,
Stefan


From t@v|b@r @end|ng |rom gm@||@com  Tue Apr 28 15:43:30 2020
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 28 Apr 2020 16:43:30 +0300
Subject: [R] Ubuntu 18.04 R repo bionic-cran35 seems to be broken
In-Reply-To: <CAPQ0CMjsjtjZ_p5uxWs0ZfV74t355G_magQGOni+ZXSr_mqG3w@mail.gmail.com>
References: <CAPQ0CMhnMA+21-KRwL3TaNRaPavt2ydhkiyLkPiasu26cu4=GA@mail.gmail.com>
 <0545fd82-d0a8-912c-25f4-3e150fb9a7d6@comcast.net>
 <CAPQ0CMjsjtjZ_p5uxWs0ZfV74t355G_magQGOni+ZXSr_mqG3w@mail.gmail.com>
Message-ID: <2bb71f07-e9b8-ada1-b960-5615a97573bf@gmail.com>


On 4/28/20 6:59 AM, Yakov Goldberg wrote:
> I have not mispelled it.
> That's how repo is added for Ubuntu.
> The problem is: there is no Release file in that folder.


Just today I did a routine upgrade and got some updated packages from cran:


micha at RMS ~ $ tail -20 /var/log/apt/history.log
......
Start-Date: 2020-04-28? 14:33:35
Commandline: /usr/bin/apt upgrade
Requested-By: micha (1000)
Upgrade: libopenexr-dev:amd64 (2.2.0-11.1ubuntu1.1, 
2.2.0-11.1ubuntu1.2), libopenexr22:amd64 (2.2.0-11.1ubuntu1.1, 
2.2.0-11.1ubuntu1.2), r-cran-nlme:amd64 (3.1.144-1bionic0, 
3.1.147-1.1804.0), r-cran-survival:amd64 (3.1-11-1cran1bionic0, 
3.1-12-1cran1.1804.0), teamviewer:amd64 (15.4.4445, 15.5.3)
End-Date: 2020-04-28? 14:34:24

.....


In my sources.list:

micha at RMS ~ $ cat /etc/apt/sources.list.d/additional-repositories.list
deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/


Seems OK to me.


>
> On Mon, Apr 27, 2020, 8:42 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>> On 4/27/20 7:41 PM, Yakov Goldberg wrote:
>>> Hello,
>>> I'm using Ubuntu 18.04 R repo
>>> https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/
>>
>> Perhaps because you misspelled it?
>>
>>
>> https://cloud.r-project.org/bin/linux/ubuntu/bionic-cran35/
>>
>>
>> Next time try going "upstream and then follow links (as I did).
>>
>>> Currently it is broken - missing Release file, which seems happened
>>> accidentally, as other repos are functioning.
>>> Could anyone of maintainers comment and fix if it is really a mistake?
>> This is the wrong mailing list. The correct one is named something like
>> R-SIG-debian.
>>
>>
>> --
>>
>> David.
>>
>>> Thanks, Yakov.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918


From rmh @end|ng |rom temp|e@edu  Tue Apr 28 15:56:50 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 28 Apr 2020 09:56:50 -0400
Subject: [R] Rtools required
In-Reply-To: <25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
References: <25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
Message-ID: <CAGx1TMDbWLjx3X1c3Dbr0j-eRoG6mX9yM1VHmLYXzcYzJCfvuQ@mail.gmail.com>

did you change your path to the new location?

On Tue, Apr 28, 2020 at 07:25 Steven <syen at hqu.edu.cn> wrote:

> Dear All
>
> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
> the new default folder c:\rtools40). While compiling a package (binary)
> I received the follow marning message saying Rtools is required. Any
> clues? Thanks.
>
> Steven Yen
>
> WARNING: Rtools is required to build R packages but is not currently
> installed. Please download and install the appropriate version of Rtools
> before proceeding: https://cran.rstudio.com/bin/windows/Rtools/
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Tue Apr 28 16:38:09 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 28 Apr 2020 14:38:09 +0000
Subject: [R] Rtools required
In-Reply-To: <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC88CE62343@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

> -----Original Message-----
> From: Steven <syen at hqu.edu.cn>
> Sent: Tuesday, April 28, 2020 9:50 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: R-help Mailing List <r-help at r-project.org>
> Subject: Re: [R] Rtools required
> 
> Hello John,
> 
> Perhaps you can help me. I am an idiot. I visited the Rtools web page and
> learn to run the following lines in R: Still I am getting the same warning
> message.
> 
>  > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
> "~/.Renviron")
>  > Sys.which("make")
>  ????????????????????????????? make
> "C:\\rtools40\\usr\\bin\\make.exe

The first command writes the modification to your path in the .Renviron file in your home directory, which should be executed at the start of each R session. I assume that you executed the second command in a fresh session, and it indicates that the Rtools are indeed accessible. 

Given that, I don't know why you're still having a problem, assuming that you tried to build the package in a fresh session *after* you created .Renviron.

Sorry I can't be of more help,
 John

> 
> On 2020/4/28 ?? 08:29, Fox, John wrote:
> > Dear Steven,
> >
> > Did you follow the instruction on the Rtools webpage to add
> >
> > 	PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
> >
> > to your .Renviron file?
> >
> > I hope this helps,
> >   John
> >
> >    -----------------------------
> >    John Fox, Professor Emeritus
> >    McMaster University
> >    Hamilton, Ontario, Canada
> >    Web: http::/socserv.mcmaster.ca/jfox
> >
> >> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> >>
> >> Dear All
> >>
> >> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
> >> now the new default folder c:\rtools40). While compiling a package
> >> (binary) I received the follow marning message saying Rtools is
> >> required. Any clues? Thanks.
> >>
> >> Steven Yen
> >>
> >> WARNING: Rtools is required to build R packages but is not currently
> >> installed. Please download and install the appropriate version of
> >> Rtools before proceeding:
> >> https://cran.rstudio.com/bin/windows/Rtools/
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 28 16:55:26 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 28 Apr 2020 10:55:26 -0400
Subject: [R] Rtools required
In-Reply-To: <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
Message-ID: <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>

On 28/04/2020 9:56 a.m., Steven Yen wrote:
> Thanks. I visited the Rtools web page and learned to run the following
> lines. I am still getting the same warning message.

And you are still not telling us what command you used to trigger that 
message.

Duncan Murdoch

> 
>   > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
> "~/.Renviron")
>   > Sys.which("make")
>   ????????????????????????????? make
> "C:\\rtools40\\usr\\bin\\make.exe"
> 
> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>> Dear All
>>>
>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>>> the new default folder c:\rtools40). While compiling a package (binary)
>>> I received the follow marning message saying Rtools is required. Any
>>> clues? Thanks.
>>
>> Presumably you didn't put it on your path, or you used a non-standard
>> way to build.? You need to say what command you used.
>>
>> Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 28 17:08:11 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 28 Apr 2020 11:08:11 -0400
Subject: [R] Rtools required
In-Reply-To: <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
 <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
Message-ID: <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>

On 28/04/2020 11:02 a.m., Steven Yen wrote:
> In RStudio, I enter File -> Open Project -> and browse to open a .Rproj
> file. Then, I click Build -> Build Binary Package. Thanks.

Do it the standard way instead of using devtools.

Duncan Murdoch

> 
> On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
>> On 28/04/2020 9:56 a.m., Steven Yen wrote:
>>> Thanks. I visited the Rtools web page and learned to run the following
>>> lines. I am still getting the same warning message.
>>
>> And you are still not telling us what command you used to trigger that
>> message.
>>
>> Duncan Murdoch
>>
>>>
>>>  ? > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>>> "~/.Renviron")
>>>  ? > Sys.which("make")
>>>  ? ????????????????????????????? make
>>> "C:\\rtools40\\usr\\bin\\make.exe"
>>>
>>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>>>> Dear All
>>>>>
>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>>>>> the new default folder c:\rtools40). While compiling a package
>>>>> (binary)
>>>>> I received the follow marning message saying Rtools is required. Any
>>>>> clues? Thanks.
>>>>
>>>> Presumably you didn't put it on your path, or you used a non-standard
>>>> way to build.? You need to say what command you used.
>>>>
>>>> Duncan Murdoch
>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 28 17:30:09 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 28 Apr 2020 11:30:09 -0400
Subject: [R] Rtools required
In-Reply-To: <55d211a5-88fc-eaf7-0fb2-8ea556d5e98e@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
 <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
 <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>
 <55d211a5-88fc-eaf7-0fb2-8ea556d5e98e@gmail.com>
Message-ID: <9db9b9d0-867b-fa90-146c-f1b7145436c1@gmail.com>

On 28/04/2020 11:16 a.m., Steven Yen wrote:
> Thanks. Can you kindly tell me what to read to do it the "standard way"?

Start with ?INSTALL, and find more details in the Writing R Extensions 
manual.  I believe RStudio can be configured to use those tools rather 
than the devtools ones, but I don't know if it will still run its test 
for Rtools if you do it that way.

I imagine you can also update RStudio and all of your packages; 
eventually that will work, if this is really the issue.

Duncan Murdoch

> Also, where can I find file .Renviron.
> 
> On 2020/4/28 ?? 11:08, Duncan Murdoch wrote:
>> On 28/04/2020 11:02 a.m., Steven Yen wrote:
>>> In RStudio, I enter File -> Open Project -> and browse to open a .Rproj
>>> file. Then, I click Build -> Build Binary Package. Thanks.
>>
>> Do it the standard way instead of using devtools.
>>
>> Duncan Murdoch
>>
>>>
>>> On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
>>>> On 28/04/2020 9:56 a.m., Steven Yen wrote:
>>>>> Thanks. I visited the Rtools web page and learned to run the following
>>>>> lines. I am still getting the same warning message.
>>>>
>>>> And you are still not telling us what command you used to trigger that
>>>> message.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>>  ?? > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>>>>> "~/.Renviron")
>>>>>  ?? > Sys.which("make")
>>>>>  ?? ????????????????????????????? make
>>>>> "C:\\rtools40\\usr\\bin\\make.exe"
>>>>>
>>>>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>>>>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>>>>>> Dear All
>>>>>>>
>>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0
>>>>>>> (to now
>>>>>>> the new default folder c:\rtools40). While compiling a package
>>>>>>> (binary)
>>>>>>> I received the follow marning message saying Rtools is required. Any
>>>>>>> clues? Thanks.
>>>>>>
>>>>>> Presumably you didn't put it on your path, or you used a non-standard
>>>>>> way to build.? You need to say what command you used.
>>>>>>
>>>>>> Duncan Murdoch
>>>>
>>


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Apr 28 18:41:50 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 28 Apr 2020 09:41:50 -0700
Subject: [R] regular expression, stringr::str_view, grep
In-Reply-To: <1002f7b7-ef2e-4993-967d-0744d874616e@wiwi.hu-berlin.de>
References: <1002f7b7-ef2e-4993-967d-0744d874616e@wiwi.hu-berlin.de>
Message-ID: <5dd4adb3-0844-67d9-66b7-8a9a6d2a3f9b@comcast.net>


On 4/28/20 2:29 AM, Sigbert Klinke wrote:
> Hi,
>
> we gave students the task to construct a regular expression selecting 
> some texts. One send us back a program which gives different results 
> on stringr::str_view and grep.
>
> The problem is "[^[A-Z]]" / "[^[A-Z]" at the end of the regular 
> expression. I would have expected that all four calls would give the 
> same result; interpreting [ and ] within [...] as the characters `[` 
> and `]`. Obviously this not the case and moreover stringr::str_view 
> and grep interpret the regular expressions differently.
>
> Any ideas?
>
> Thanks Sigbert
>
> ---
>
> aff <- c("affgfking", "fgok", "rafgkahe","a fgk", "bafghk", "affgm",
> ???????? "baffgkit", "afffhk", "affgfking", "fgok", "rafgkahe", "afg.K",
> ???????? "bafghk", "aff gm", "baffg kit", "afffhgk")

TL;DR: different versions of regex character class syntax:


>
> correct_brackets <- "af+g[^m$][^[A-Z]]"
To me that looks "incorrect" because of an unnecessary square-bracket.
> missing_brackets <- "af+g[^m$][^[A-Z]"
And that one looks complete. To my mind it looks like the negation of a 
character class with "[" and the range A-Z.
>
> library("stringr")


I think this is the root of your problem. If you execute ?regex you 
should be given a choice of two different help pages and if you go to 
the one from pkg stringr it says in the Usage section:

regex
The default. Uses ICU regular expressions.

So that's probably different than the base regex convention which uses 
TRE regular expressions.


You should carefully review:


help('stringi-search-charclass' , pac=stringi)

 ?I think you should also find the adding square brackets around ranges 
is not needed in either type of regex syntax, but that stringi's regex 
(unlike base R's TRE regex) does allow multiple disjoint ranges inside 
the outer square brackets of a character class. I've never seen that in 
base R regex. So I think that this base regex pattern, 
grepl("([a-b]|[r-t])", letters) is the same as this stringi pattern:? 
str_view( letters, "[[a-c][r-t]]").


-- 

David.


> grep(correct_brackets, aff, value = TRUE) ### result: character(0)
> grep(missing_brackets, aff, value = TRUE) ### correct result
> str_view(aff, correct_brackets) ### correct result
> str_view(aff, missing_brackets) ### error: missing closing bracket
>


From @zwj|08 @end|ng |rom gm@||@com  Tue Apr 28 18:56:50 2020
From: @zwj|08 @end|ng |rom gm@||@com (Wang Jiefei)
Date: Wed, 29 Apr 2020 00:56:50 +0800
Subject: [R] Rtools required
In-Reply-To: <9db9b9d0-867b-fa90-146c-f1b7145436c1@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
 <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
 <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>
 <55d211a5-88fc-eaf7-0fb2-8ea556d5e98e@gmail.com>
 <9db9b9d0-867b-fa90-146c-f1b7145436c1@gmail.com>
Message-ID: <CAGiFhPNF_x_3c31_oVdHA-jHA_68_uj5TXFN80YHNhvmi6C_mA@mail.gmail.com>

I do not exactly know what is going on with your problem but it is better
to use the old-school method to install the package so that you can avoid
any problems with Rstudio.

>From your post, I guess you are using Windows, so please see this link for
how to add the Rtools and R to the environment variable PATH:

https://www.computerhope.com/issues/ch000549.htm

 Then go to the command prompt, here is how:

https://www.howtogeek.com/235101/10-ways-to-open-the-command-prompt-in-windows-10/

Type R and enter. If you can see welcome information from R, that means at
least you have correctly added R into PATH. Check whether the R version is
4.0

Type "q()" to quit R, then go to the directory where your package is. For
example, if your package is in "D:\packages\mypackage", go to
"D:\packages\".

Type "R CMD INSTALL  mypackage", replace mypackage with the true folder
name of your package.

If everything is correct, you should be able to install the package. If you
get the same error, type "echo %PATH%" and post here so we can know exactly
what is going on.

Best,
Jiefei

On Tue, Apr 28, 2020 at 11:39 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 28/04/2020 11:16 a.m., Steven Yen wrote:
> > Thanks. Can you kindly tell me what to read to do it the "standard way"?
>
> Start with ?INSTALL, and find more details in the Writing R Extensions
> manual.  I believe RStudio can be configured to use those tools rather
> than the devtools ones, but I don't know if it will still run its test
> for Rtools if you do it that way.
>
> I imagine you can also update RStudio and all of your packages;
> eventually that will work, if this is really the issue.
>
> Duncan Murdoch
>
> > Also, where can I find file .Renviron.
> >
> > On 2020/4/28 ?? 11:08, Duncan Murdoch wrote:
> >> On 28/04/2020 11:02 a.m., Steven Yen wrote:
> >>> In RStudio, I enter File -> Open Project -> and browse to open a .Rproj
> >>> file. Then, I click Build -> Build Binary Package. Thanks.
> >>
> >> Do it the standard way instead of using devtools.
> >>
> >> Duncan Murdoch
> >>
> >>>
> >>> On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
> >>>> On 28/04/2020 9:56 a.m., Steven Yen wrote:
> >>>>> Thanks. I visited the Rtools web page and learned to run the
> following
> >>>>> lines. I am still getting the same warning message.
> >>>>
> >>>> And you are still not telling us what command you used to trigger that
> >>>> message.
> >>>>
> >>>> Duncan Murdoch
> >>>>
> >>>>>
> >>>>>     > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
> >>>>> "~/.Renviron")
> >>>>>     > Sys.which("make")
> >>>>>                                   make
> >>>>> "C:\\rtools40\\usr\\bin\\make.exe"
> >>>>>
> >>>>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
> >>>>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
> >>>>>>> Dear All
> >>>>>>>
> >>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0
> >>>>>>> (to now
> >>>>>>> the new default folder c:\rtools40). While compiling a package
> >>>>>>> (binary)
> >>>>>>> I received the follow marning message saying Rtools is required.
> Any
> >>>>>>> clues? Thanks.
> >>>>>>
> >>>>>> Presumably you didn't put it on your path, or you used a
> non-standard
> >>>>>> way to build.  You need to say what command you used.
> >>>>>>
> >>>>>> Duncan Murdoch
> >>>>
> >>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 29 00:07:39 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 29 Apr 2020 10:07:39 +1200
Subject: [R] pair correlation function of 3D points
In-Reply-To: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
Message-ID: <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>

I haven't attempted this.
(Mainly because I'm not familiar with the theory surrounding it).

However, I looked at the documentation for the spatstat package.
There are are several functions prefixed with pcf, including one named pcf3est.
According to its description field:

          Estimates the pair correlation function
          from a three-dimensional point pattern.

*If* it does what it claims, would that solve your problem?

Note (to spatstat authors):

I'm not convinced this package is well documented.
In fact, I'm not even convinced it meets CRAN standards, which require
functions to have their arguments documented.

     X
    Three-dimensional point pattern (object of class "pp3").

Nowhere in the help page, does it say what a pp3 object is, or how to
create it, or where to find that information.
Potentially requiring a user to search through a 1766 page document
for the answer.
(Yes, I know there's a function named pp3, but I don't think that's
good enough).

If people are not going to document their packages properly, they
could try a little bit harder to answer R-help questions that involve
their packages...


On Tue, Apr 28, 2020 at 3:56 AM Labo Eric <leroy at icmpe.cnrs.fr> wrote:
>
> Hi,
>
> I have the coordinates of 3D points and I want to plot the pair
> correlation function of these points
> (https://en.wikipedia.org/wiki/Radial_distribution_function). I wonder
> if it possible to calculate this function with R. Maybe with the
> spatstat library? I tried but I found the way to do this with 3D points
> but not for 3D points.
>
> Could you help me ?
>
> Thank you,
>
> Best regards,
>
> --
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 29 00:18:54 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 28 Apr 2020 15:18:54 -0700
Subject: [R] pair correlation function of 3D points
In-Reply-To: <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
Message-ID: <DA3AB5EE-ECA1-45B6-A996-507054E3EB1D@dcn.davis.ca.us>

Technically, per the Posting Guide, help for contributed packages is supposed to come through different channel(s) than R-help as indicated in their DESCRIPTION file (typically searchable thru the package CRAN page). In practice this rule tends to only get invoked when the OT traffic gets too high, but it may be a bit much to expect maintainers to patrol R-help permanently. Feel free to direct OT questions toward the relevant CRAN page or the resources mentioned there.

On April 28, 2020 3:07:39 PM PDT, Abby Spurdle <spurdle.a at gmail.com> wrote:
>I haven't attempted this.
>(Mainly because I'm not familiar with the theory surrounding it).
>
>However, I looked at the documentation for the spatstat package.
>There are are several functions prefixed with pcf, including one named
>pcf3est.
>According to its description field:
>
>          Estimates the pair correlation function
>          from a three-dimensional point pattern.
>
>*If* it does what it claims, would that solve your problem?
>
>Note (to spatstat authors):
>
>I'm not convinced this package is well documented.
>In fact, I'm not even convinced it meets CRAN standards, which require
>functions to have their arguments documented.
>
>     X
>    Three-dimensional point pattern (object of class "pp3").
>
>Nowhere in the help page, does it say what a pp3 object is, or how to
>create it, or where to find that information.
>Potentially requiring a user to search through a 1766 page document
>for the answer.
>(Yes, I know there's a function named pp3, but I don't think that's
>good enough).
>
>If people are not going to document their packages properly, they
>could try a little bit harder to answer R-help questions that involve
>their packages...
>
>
>On Tue, Apr 28, 2020 at 3:56 AM Labo Eric <leroy at icmpe.cnrs.fr> wrote:
>>
>> Hi,
>>
>> I have the coordinates of 3D points and I want to plot the pair
>> correlation function of these points
>> (https://en.wikipedia.org/wiki/Radial_distribution_function). I
>wonder
>> if it possible to calculate this function with R. Maybe with the
>> spatstat library? I tried but I found the way to do this with 3D
>points
>> but not for 3D points.
>>
>> Could you help me ?
>>
>> Thank you,
>>
>> Best regards,
>>
>> --
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 29 00:34:14 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 29 Apr 2020 10:34:14 +1200
Subject: [R] pair correlation function of 3D points
In-Reply-To: <DA3AB5EE-ECA1-45B6-A996-507054E3EB1D@dcn.davis.ca.us>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <DA3AB5EE-ECA1-45B6-A996-507054E3EB1D@dcn.davis.ca.us>
Message-ID: <CAB8pepyxB28P1D2_o59=A1-3RX48RPn=oJHQEf5P6NgJDQ_S+g@mail.gmail.com>

This is probably completely off topic.

But I get the impression the spatstat package has turned into a super-package.
Which is likely to be difficult to maintain.

Wouldn't a better result be achieved by freezing work on the package,
and creating some smaller packages with a more specific focus, that
could be more easily maintained....?

On Wed, Apr 29, 2020 at 10:18 AM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> Technically, per the Posting Guide, help for contributed packages is supposed to come through different channel(s) than R-help as indicated in their DESCRIPTION file (typically searchable thru the package CRAN page). In practice this rule tends to only get invoked when the OT traffic gets too high, but it may be a bit much to expect maintainers to patrol R-help permanently. Feel free to direct OT questions toward the relevant CRAN page or the resources mentioned there.
>
> On April 28, 2020 3:07:39 PM PDT, Abby Spurdle <spurdle.a at gmail.com> wrote:
> >I haven't attempted this.
> >(Mainly because I'm not familiar with the theory surrounding it).
> >
> >However, I looked at the documentation for the spatstat package.
> >There are are several functions prefixed with pcf, including one named
> >pcf3est.
> >According to its description field:
> >
> >          Estimates the pair correlation function
> >          from a three-dimensional point pattern.
> >
> >*If* it does what it claims, would that solve your problem?
> >
> >Note (to spatstat authors):
> >
> >I'm not convinced this package is well documented.
> >In fact, I'm not even convinced it meets CRAN standards, which require
> >functions to have their arguments documented.
> >
> >     X
> >    Three-dimensional point pattern (object of class "pp3").
> >
> >Nowhere in the help page, does it say what a pp3 object is, or how to
> >create it, or where to find that information.
> >Potentially requiring a user to search through a 1766 page document
> >for the answer.
> >(Yes, I know there's a function named pp3, but I don't think that's
> >good enough).
> >
> >If people are not going to document their packages properly, they
> >could try a little bit harder to answer R-help questions that involve
> >their packages...
> >
> >
> >On Tue, Apr 28, 2020 at 3:56 AM Labo Eric <leroy at icmpe.cnrs.fr> wrote:
> >>
> >> Hi,
> >>
> >> I have the coordinates of 3D points and I want to plot the pair
> >> correlation function of these points
> >> (https://en.wikipedia.org/wiki/Radial_distribution_function). I
> >wonder
> >> if it possible to calculate this function with R. Maybe with the
> >> spatstat library? I tried but I found the way to do this with 3D
> >points
> >> but not for 3D points.
> >>
> >> Could you help me ?
> >>
> >> Thank you,
> >>
> >> Best regards,
> >>
> >> --
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From j@zh@o @end|ng |rom ye@h@net  Wed Apr 29 02:05:13 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 29 Apr 2020 08:05:13 +0800
Subject: [R] paste workable code to R 4.0.0 cause error
Message-ID: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>

Hi there,

I have a piece of source code with some inline comments in Chinese. It 
works well when I copy it from a editor (gvim here), and paste it to 
Rgui console on R 3.6.3, however, when I do the same thing, R 4.0.0 give 
error message:

Error: invalid multibyte character in parser at line 21

If I source() the code from Rgui console, it can run without any error.

Any hints?

BTW, I do not make a minimal workable example yet.

Best,
Jinsong


From j@zh@o @end|ng |rom ye@h@net  Wed Apr 29 04:25:03 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 29 Apr 2020 10:25:03 +0800
Subject: [R] paste workable code to R 4.0.0 cause error
In-Reply-To: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>
References: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>
Message-ID: <58aea81d-7894-b493-0fd0-1cc73797f826@yeah.net>

On 2020/4/29 8:05, Jinsong Zhao wrote:
> Hi there,
> 
> I have a piece of source code with some inline comments in Chinese. It 
> works well when I copy it from a editor (gvim here), and paste it to 
> Rgui console on R 3.6.3, however, when I do the same thing, R 4.0.0 give 
> error message:
> 
> Error: invalid multibyte character in parser at line 21
> 
> If I source() the code from Rgui console, it can run without any error.
> 
> Any hints?
> 
> BTW, I do not make a minimal workable example yet.
> 

Here is the MWE:

D:\system\Desktop>cat aaa.R
gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
gz <- within(gz,
               {
                  a <- x1      #a???????
                  bbbbb <- x10 #b???a????
                  ccccc <- x10 #c????????
                  ddddd <- x10 #d?????b????
                  eeeee <- x10 #e????????
                  fffff <- x10 #f?????c
               })

The ASCII character in the code could be replace by other ASCII 
character. The Chinese character could be replace by other Chinese 
character.

Calling source("aaa.R") could run normally. If you select all the code 
and paste it to Rgui console, it will give error:

 > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
 > gz <- within(gz,
+               {
+                  a <- x1      #a???????
+                  bbbbb <- x10 #b???a????
+                  ccccc <- x10 #c????????
+                  ddddd <- x10 #d?????b????
+                  eeeee <- x10 #e????????
+                  fffff <- x10 #f?????c
Error: invalid multibyte character in parser at line 9
 >               })
Error: unexpected '}' in "              }"
 >

If you delete any character from the comment, or add any character to 
the comment. The code can paste to the console without any error.

If you change the length of `bbbbb`...`fffff`, the code also could be 
paste and run without any error.

Best,
Jinsong


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Apr 29 05:25:45 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Apr 2020 15:25:45 +1200
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
Message-ID: <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>


On 29/04/20 10:07 am, Abby Spurdle wrote:

> I haven't attempted this.
> (Mainly because I'm not familiar with the theory surrounding it).
> 
> However, I looked at the documentation for the spatstat package.
> There are are several functions prefixed with pcf, including one named pcf3est.
> According to its description field:
> 
>            Estimates the pair correlation function
>            from a three-dimensional point pattern.
> 
> *If* it does what it claims ...

Why would you doubt that it does what it claims?

> ... would that solve your problem?
> 
> Note (to spatstat authors):
> 
> I'm not convinced this package is well documented.
> In fact, I'm not even convinced it meets CRAN standards, which require
> functions to have their arguments documented.
> 
>       X
>      Three-dimensional point pattern (object of class "pp3").
> 
> Nowhere in the help page, does it say what a pp3 object is, or how to
> create it, or where to find that information.
> Potentially requiring a user to search through a 1766 page document
> for the answer.
> (Yes, I know there's a function named pp3, but I don't think that's
> good enough).
> 
> If people are not going to document their packages properly, they
> could try a little bit harder to answer R-help questions that involve
> their packages...

<SNIP>

Wouldn't the first thing that one would try be:

   ??"pp3"

The required information is then immediately apparent.

Moreover if one takes the trouble to look at the examples, one is led to 
the function rpoispp3() which points to the function pp3().

This reminds not a little of fortunes::fortune(9).

Of course I'm biased, but IMHO spatstat is documented not only 
"properly", but superbly well! :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Apr 29 05:36:12 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 29 Apr 2020 15:36:12 +1200
Subject: [R] [FORGED] Re:  paste workable code to R 4.0.0 cause error
In-Reply-To: <58aea81d-7894-b493-0fd0-1cc73797f826@yeah.net>
References: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>
 <58aea81d-7894-b493-0fd0-1cc73797f826@yeah.net>
Message-ID: <b98b419d-ec06-f736-bbe5-896614ebdf5f@auckland.ac.nz>


The (excellent) MWE that you provided runs just fine for me (in R 4.0.0 
under Ubuntu 18.04) either by sourcing "aaa.R" or by using copy-and-paste.

Must be Windoze thing.  Switch to Linux!

cheers,

Rolf Turner

n 29/04/20 2:25 pm, Jinsong Zhao wrote:
> On 2020/4/29 8:05, Jinsong Zhao wrote:
>> Hi there,
>>
>> I have a piece of source code with some inline comments in Chinese. It 
>> works well when I copy it from a editor (gvim here), and paste it to 
>> Rgui console on R 3.6.3, however, when I do the same thing, R 4.0.0 
>> give error message:
>>
>> Error: invalid multibyte character in parser at line 21
>>
>> If I source() the code from Rgui console, it can run without any error.
>>
>> Any hints?
>>
>> BTW, I do not make a minimal workable example yet.
>>
> 
> Here is the MWE:
> 
> D:\system\Desktop>cat aaa.R
> gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
> gz <- within(gz,
>  ????????????? {
>  ???????????????? a <- x1????? #a???????
>  ???????????????? bbbbb <- x10 #b???a????
>  ???????????????? ccccc <- x10 #c????????
>  ???????????????? ddddd <- x10 #d?????b????
>  ???????????????? eeeee <- x10 #e????????
>  ???????????????? fffff <- x10 #f?????c
>  ????????????? })
> 
> The ASCII character in the code could be replace by other ASCII 
> character. The Chinese character could be replace by other Chinese 
> character.
> 
> Calling source("aaa.R") could run normally. If you select all the code 
> and paste it to Rgui console, it will give error:
> 
>  > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
>  > gz <- within(gz,
> +?????????????? {
> +????????????????? a <- x1????? #a???????
> +????????????????? bbbbb <- x10 #b???a????
> +????????????????? ccccc <- x10 #c????????
> +????????????????? ddddd <- x10 #d?????b????
> +????????????????? eeeee <- x10 #e????????
> +????????????????? fffff <- x10 #f?????c
> Error: invalid multibyte character in parser at line 9
>  >?????????????? })
> Error: unexpected '}' in "????????????? }"
>  >
> 
> If you delete any character from the comment, or add any character to 
> the comment. The code can paste to the console without any error.
> 
> If you change the length of `bbbbb`...`fffff`, the code also could be 
> paste and run without any error.
> 
> Best,
> Jinsong


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 29 05:43:12 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 28 Apr 2020 20:43:12 -0700
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
Message-ID: <755C0845-240E-4EDA-8C20-54EAD1CFA295@dcn.davis.ca.us>

Hackles down, Rolf... most documentation can benefit from the perspective of a new user. It would be helpful to link the mention of pp3 to the the pp3 function via hyperlink to help clarify what this argument is supposed to be.

Abby, FWIW I tend to recommend reading the vignettes before trying to absorb the function documentation... having a bird's-eye-view of how the package works will always make the function documentation easier to follow.

On April 28, 2020 8:25:45 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>On 29/04/20 10:07 am, Abby Spurdle wrote:
>
>> I haven't attempted this.
>> (Mainly because I'm not familiar with the theory surrounding it).
>> 
>> However, I looked at the documentation for the spatstat package.
>> There are are several functions prefixed with pcf, including one
>named pcf3est.
>> According to its description field:
>> 
>>            Estimates the pair correlation function
>>            from a three-dimensional point pattern.
>> 
>> *If* it does what it claims ...
>
>Why would you doubt that it does what it claims?
>
>> ... would that solve your problem?
>> 
>> Note (to spatstat authors):
>> 
>> I'm not convinced this package is well documented.
>> In fact, I'm not even convinced it meets CRAN standards, which
>require
>> functions to have their arguments documented.
>> 
>>       X
>>      Three-dimensional point pattern (object of class "pp3").
>> 
>> Nowhere in the help page, does it say what a pp3 object is, or how to
>> create it, or where to find that information.
>> Potentially requiring a user to search through a 1766 page document
>> for the answer.
>> (Yes, I know there's a function named pp3, but I don't think that's
>> good enough).
>> 
>> If people are not going to document their packages properly, they
>> could try a little bit harder to answer R-help questions that involve
>> their packages...
>
><SNIP>
>
>Wouldn't the first thing that one would try be:
>
>   ??"pp3"
>
>The required information is then immediately apparent.
>
>Moreover if one takes the trouble to look at the examples, one is led
>to 
>the function rpoispp3() which points to the function pp3().
>
>This reminds not a little of fortunes::fortune(9).
>
>Of course I'm biased, but IMHO spatstat is documented not only 
>"properly", but superbly well! :-)
>
>cheers,
>
>Rolf

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Wed Apr 29 05:53:14 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 29 Apr 2020 13:53:14 +1000
Subject: [R] Package 'coin' - How to extract rho
In-Reply-To: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
References: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
Message-ID: <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>

Hi Christine,
I noticed that your question did not receive a reply. As I don't know
exactly what you have tried, it is a bit difficult to suggest a
solution. If you are still unable to get this to work, could you
provide an example of your present code and data if necessary?

Jim

On Mon, Apr 27, 2020 at 3:09 AM Blume Christine
<christine.blume at sbg.ac.at> wrote:
>
> I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?
>
> Kind regards,
> Christine
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Wed Apr 29 05:55:41 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 28 Apr 2020 23:55:41 -0400
Subject: [R] [FORGED] Re: paste workable code to R 4.0.0 cause error
In-Reply-To: <b98b419d-ec06-f736-bbe5-896614ebdf5f@auckland.ac.nz>
References: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>
 <58aea81d-7894-b493-0fd0-1cc73797f826@yeah.net>
 <b98b419d-ec06-f736-bbe5-896614ebdf5f@auckland.ac.nz>
Message-ID: <CAGx1TMA5txZJ1_7jJ88gkfhvfiRUyi5JKNSVwWieboXz+669_w@mail.gmail.com>

I pasted it into Emacs ESS on Macintosh, Emacs ESS on Windows, and Rgui on
Windows.
All 4.0.0 .  It runs fine.

On Tue, Apr 28, 2020 at 11:36 PM Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> The (excellent) MWE that you provided runs just fine for me (in R 4.0.0
> under Ubuntu 18.04) either by sourcing "aaa.R" or by using copy-and-paste.
>
> Must be Windoze thing.  Switch to Linux!
>
> cheers,
>
> Rolf Turner
>
> n 29/04/20 2:25 pm, Jinsong Zhao wrote:
> > On 2020/4/29 8:05, Jinsong Zhao wrote:
> >> Hi there,
> >>
> >> I have a piece of source code with some inline comments in Chinese. It
> >> works well when I copy it from a editor (gvim here), and paste it to
> >> Rgui console on R 3.6.3, however, when I do the same thing, R 4.0.0
> >> give error message:
> >>
> >> Error: invalid multibyte character in parser at line 21
> >>
> >> If I source() the code from Rgui console, it can run without any error.
> >>
> >> Any hints?
> >>
> >> BTW, I do not make a minimal workable example yet.
> >>
> >
> > Here is the MWE:
> >
> > D:\system\Desktop>cat aaa.R
> > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
> > gz <- within(gz,
> >                {
> >                   a <- x1      #a???????
> >                   bbbbb <- x10 #b???a????
> >                   ccccc <- x10 #c????????
> >                   ddddd <- x10 #d?????b????
> >                   eeeee <- x10 #e????????
> >                   fffff <- x10 #f?????c
> >                })
> >
> > The ASCII character in the code could be replace by other ASCII
> > character. The Chinese character could be replace by other Chinese
> > character.
> >
> > Calling source("aaa.R") could run normally. If you select all the code
> > and paste it to Rgui console, it will give error:
> >
> >  > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
> >  > gz <- within(gz,
> > +               {
> > +                  a <- x1      #a???????
> > +                  bbbbb <- x10 #b???a????
> > +                  ccccc <- x10 #c????????
> > +                  ddddd <- x10 #d?????b????
> > +                  eeeee <- x10 #e????????
> > +                  fffff <- x10 #f?????c
> > Error: invalid multibyte character in parser at line 9
> >  >               })
> > Error: unexpected '}' in "              }"
> >  >
> >
> > If you delete any character from the comment, or add any character to
> > the comment. The code can paste to the console without any error.
> >
> > If you change the length of `bbbbb`...`fffff`, the code also could be
> > paste and run without any error.
> >
> > Best,
> > Jinsong
>
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 29 07:31:14 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 29 Apr 2020 17:31:14 +1200
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
Message-ID: <CAB8pepwxV1nyNKA85srFqxw=d5Fzb9k618d9=1tk1PRQdyb42A@mail.gmail.com>

I should have noted that my comments weren't directed towards the main
authors, but to all people listed in the description file, which is
many, including some R core members.

Also, overall, I'm impressed by the effort here. It's just I strongly
feel that good documentation is crucial (especially in open source),
and I was somewhat disappointed that, given how many people are/were
involved in this package, not one (after approx 24 hours) had tried to
help answer the OP's question.

> > *If* it does what it claims ...
> Why would you doubt that it does what it claims?

Because I didn't test it.

> Wouldn't the first thing that one would try be:
>    ??"pp3"

No, because I was reading the PDF version of the documentation.

> Of course I'm biased, but IMHO spatstat is documented not only
> "properly", but superbly well! :-)

I started reading the pcf function first.
This function has the same problem, it doesn't clearly describe the
function arguments.
It doesn't say whether it applies to 2d, 3d or higher-dimensional data.
After reading it, I had no idea whether the function could be applied
to 3d data or not.

In my opinion this is not sufficient.
Descriptions of function arguments and return values should be clear.

But here's a bigger problem.
The documentation says the pcf function is a generic, but the pcf3est
function isn't a method.
And the pcf documentation (along with the three methods) don't
reference the pcf3est function.

I found the pcf function via Googling the subject.
But unless someone goes through a list of all the help topics, they're
unlikely to find the pcf3est function.


From j@zh@o @end|ng |rom ye@h@net  Wed Apr 29 07:34:35 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Wed, 29 Apr 2020 13:34:35 +0800
Subject: [R] [FORGED] Re: paste workable code to R 4.0.0 cause error
In-Reply-To: <CAGx1TMA5txZJ1_7jJ88gkfhvfiRUyi5JKNSVwWieboXz+669_w@mail.gmail.com>
References: <ef20bbdb-ab6a-f58d-2d28-9e3d8c5e927f@yeah.net>
 <58aea81d-7894-b493-0fd0-1cc73797f826@yeah.net>
 <b98b419d-ec06-f736-bbe5-896614ebdf5f@auckland.ac.nz>
 <CAGx1TMA5txZJ1_7jJ88gkfhvfiRUyi5JKNSVwWieboXz+669_w@mail.gmail.com>
Message-ID: <9b2b4243-801e-eac3-5ba9-429591c62b1c@yeah.net>

On 2020/4/29 11:55, Richard M. Heiberger wrote:
> I pasted it into Emacs ESS on Macintosh, Emacs ESS on Windows, and Rgui 
> on Windows.
> All 4.0.0 .? It runs fine.

I test the code using ESS on Windows. It also give error, but with 
different position:

 > gz <- within(gz,
+               {
+                  a <- x1      #a???????
Error: invalid multibyte character in parser at line 4

Is it related with locale?

 > sessionInfo()
R version 4.0.0 (2020-04-24)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.936
[2] LC_CTYPE=Chinese (Simplified)_China.936
[3] LC_MONETARY=Chinese (Simplified)_China.936
[4] LC_NUMERIC=C
[5] LC_TIME=Chinese (Simplified)_China.936

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.0 tools_4.0.0


> 
> On Tue, Apr 28, 2020 at 11:36 PM Rolf Turner <r.turner at auckland.ac.nz 
> <mailto:r.turner at auckland.ac.nz>> wrote:
> 
> 
>     The (excellent) MWE that you provided runs just fine for me (in R 4.0.0
>     under Ubuntu 18.04) either by sourcing "aaa.R" or by using
>     copy-and-paste.
> 
>     Must be Windoze thing.? Switch to Linux!
> 
>     cheers,
> 
>     Rolf Turner
> 
>     n 29/04/20 2:25 pm, Jinsong Zhao wrote:
>      > On 2020/4/29 8:05, Jinsong Zhao wrote:
>      >> Hi there,
>      >>
>      >> I have a piece of source code with some inline comments in
>     Chinese. It
>      >> works well when I copy it from a editor (gvim here), and paste
>     it to
>      >> Rgui console on R 3.6.3, however, when I do the same thing, R 4.0.0
>      >> give error message:
>      >>
>      >> Error: invalid multibyte character in parser at line 21
>      >>
>      >> If I source() the code from Rgui console, it can run without any
>     error.
>      >>
>      >> Any hints?
>      >>
>      >> BTW, I do not make a minimal workable example yet.
>      >>
>      >
>      > Here is the MWE:
>      >
>      > D:\system\Desktop>cat aaa.R
>      > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
>      > gz <- within(gz,
>      >? ????????????? {
>      >? ???????????????? a <- x1????? #a???????
>      >? ???????????????? bbbbb <- x10 #b???a????
>      >? ???????????????? ccccc <- x10 #c????????
>      >? ???????????????? ddddd <- x10 #d?????b????
>      >? ???????????????? eeeee <- x10 #e????????
>      >? ???????????????? fffff <- x10 #f?????c
>      >? ????????????? })
>      >
>      > The ASCII character in the code could be replace by other ASCII
>      > character. The Chinese character could be replace by other Chinese
>      > character.
>      >
>      > Calling source("aaa.R") could run normally. If you select all the
>     code
>      > and paste it to Rgui console, it will give error:
>      >
>      >? > gz <- data.frame(x1 = rnorm(100), x10 = rnorm(100))
>      >? > gz <- within(gz,
>      > +?????????????? {
>      > +????????????????? a <- x1????? #a???????
>      > +????????????????? bbbbb <- x10 #b???a????
>      > +????????????????? ccccc <- x10 #c????????
>      > +????????????????? ddddd <- x10 #d?????b????
>      > +????????????????? eeeee <- x10 #e????????
>      > +????????????????? fffff <- x10 #f?????c
>      > Error: invalid multibyte character in parser at line 9
>      >? >?????????????? })
>      > Error: unexpected '}' in "????????????? }"
>      >? >
>      >
>      > If you delete any character from the comment, or add any
>     character to
>      > the comment. The code can paste to the console without any error.
>      >
>      > If you change the length of `bbbbb`...`fffff`, the code also
>     could be
>      > paste and run without any error.
>      >
>      > Best,
>      > Jinsong
> 
> 
>     -- 
>     Honorary Research Fellow
>     Department of Statistics
>     University of Auckland
>     Phone: +64-9-373-7599 ext. 88276
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t  Wed Apr 29 11:13:01 2020
From: chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t (Blume Christine)
Date: Wed, 29 Apr 2020 09:13:01 +0000
Subject: [R] Package 'coin' - How to extract rho
In-Reply-To: <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>
References: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
 <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>
Message-ID: <0bfbe64f1c7f493192d3c46c6c90f5ea@sbg.ac.at>

Dear Jim,



Many thanks for following up on this. Sure, I can provide a sample code. At the end of the code you see that I extract the p-value and the test statistic. However, I cannot find the correlation coefficient rho anywhere in the object ?r?.



Best,

Christine



if(!require(pacman)) install.packages("pacman")

pacman::p_load(sn, fGarch, coin)



# Happiness

central_tendency_sim <- 0

dispersion_sim <- 1

skewness_sim <- 1.5



N_sim <- 10000



Happiness <- seq(from = 0,

               to = 10,

               length.out = N_sim)



# City size

central_tendency_sim <- 3

dispersion_sim <- 1

skewness_sim <- 1.5



Citysize <- seq(from = 1,

                to = 5,

                length.out = N_sim)



# create dataframe

datastat <- data.frame(Happiness, Citysize)



# Bootstrapped correlation

r <- spearman_test(Happiness ~ Citysize, data = datastat, distribution = "approximate", alternative = c("two.sided"))

r

pvalue(r)

statistic(r)





-----Urspr?ngliche Nachricht-----
Von: Jim Lemon <drjimlemon at gmail.com>
Gesendet: Mittwoch, 29. April 2020 05:53
An: Blume Christine <christine.blume at sbg.ac.at>
Cc: r-help at r-project.org
Betreff: Re: [R] Package 'coin' - How to extract rho



Hi Christine,

I noticed that your question did not receive a reply. As I don't know exactly what you have tried, it is a bit difficult to suggest a solution. If you are still unable to get this to work, could you provide an example of your present code and data if necessary?



Jim



On Mon, Apr 27, 2020 at 3:09 AM Blume Christine <christine.blume at sbg.ac.at<mailto:christine.blume at sbg.ac.at>> wrote:

>

> I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?

>

> Kind regards,

> Christine

>

>

>         [[alternative HTML version deleted]]

>

> ______________________________________________

> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see

> https://stat.ethz.ch/mailman/listinfo/r-help

> PLEASE do read the posting guide

> http://www.R-project.org/posting-guide.html

> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Wed Apr 29 13:55:43 2020
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Wed, 29 Apr 2020 13:55:43 +0200 (CEST)
Subject: [R] Package 'coin' - How to extract rho
In-Reply-To: <0bfbe64f1c7f493192d3c46c6c90f5ea@sbg.ac.at>
References: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
 <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>
 <0bfbe64f1c7f493192d3c46c6c90f5ea@sbg.ac.at>
Message-ID: <alpine.DEB.2.22.394.2004291353350.1154503@paninaro>

Christine,

thanks for the example. As far as I can see, the "coin" package does not 
explicitly compute Spearman's rho. This is probably also the reason why it 
isn't reported in the test output. Thus, you would have to do this "by 
hand" using cor(..., method = "spearman").

Hope that helps,
Achim


On Wed, 29 Apr 2020, Blume Christine wrote:

> Dear Jim,
>
>
>
> Many thanks for following up on this. Sure, I can provide a sample code. At the end of the code you see that I extract the p-value and the test statistic. However, I cannot find the correlation coefficient rho anywhere in the object ?r?.
>
>
>
> Best,
>
> Christine
>
>
>
> if(!require(pacman)) install.packages("pacman")
>
> pacman::p_load(sn, fGarch, coin)
>
>
>
> # Happiness
>
> central_tendency_sim <- 0
>
> dispersion_sim <- 1
>
> skewness_sim <- 1.5
>
>
>
> N_sim <- 10000
>
>
>
> Happiness <- seq(from = 0,
>
>               to = 10,
>
>               length.out = N_sim)
>
>
>
> # City size
>
> central_tendency_sim <- 3
>
> dispersion_sim <- 1
>
> skewness_sim <- 1.5
>
>
>
> Citysize <- seq(from = 1,
>
>                to = 5,
>
>                length.out = N_sim)
>
>
>
> # create dataframe
>
> datastat <- data.frame(Happiness, Citysize)
>
>
>
> # Bootstrapped correlation
>
> r <- spearman_test(Happiness ~ Citysize, data = datastat, distribution = "approximate", alternative = c("two.sided"))
>
> r
>
> pvalue(r)
>
> statistic(r)
>
>
>
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Jim Lemon <drjimlemon at gmail.com>
> Gesendet: Mittwoch, 29. April 2020 05:53
> An: Blume Christine <christine.blume at sbg.ac.at>
> Cc: r-help at r-project.org
> Betreff: Re: [R] Package 'coin' - How to extract rho
>
>
>
> Hi Christine,
>
> I noticed that your question did not receive a reply. As I don't know exactly what you have tried, it is a bit difficult to suggest a solution. If you are still unable to get this to work, could you provide an example of your present code and data if necessary?
>
>
>
> Jim
>
>
>
> On Mon, Apr 27, 2020 at 3:09 AM Blume Christine <christine.blume at sbg.ac.at<mailto:christine.blume at sbg.ac.at>> wrote:
>
>>
>
>> I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?
>
>>
>
>> Kind regards,
>
>> Christine
>
>>
>
>>
>
>>         [[alternative HTML version deleted]]
>
>>
>
>> ______________________________________________
>
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>> PLEASE do read the posting guide
>
>> http://www.R-project.org/posting-guide.html
>
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From |eroy @end|ng |rom |cmpe@cnr@@|r  Wed Apr 29 14:28:55 2020
From: |eroy @end|ng |rom |cmpe@cnr@@|r (Eric Leroy)
Date: Wed, 29 Apr 2020 14:28:55 +0200
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>
References: <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>
Message-ID: <F5F41F99-A6C7-42D8-A197-C4A532C1123B@icmpe.cnrs.fr>

Dear all,
I am sorry to see all the reactions I provoked from a newbie user. Anyway, thank you for the answer I think that the pcf3est function responds to my question. 
Indeed the spatstat is a very impressive library and I am very grateful to the the developers. 
Best regards 

Eric LEROY 
Responsable de la plateforme microscopie ?lectronique 
ICMPE - UMR 7182 
2/8, rue Henri Dunant
94320 THIAIS 
T : 01.49.78.12.09
F : 01.49.78.12.03


> Le 29 avr. 2020 ? 13:04, Ege Rubak <rubak at math.aau.dk> a ?crit :
> 
> ?Dear all,
> 
> I see two issues here:
> 
> 1. A new user has a hard time finding and using a specific function in
> spatstat. As package authors we are always interested in such reports
> and we then try to improve documentation, which is indeed a very
> important part of any software project. The package is **very**
> actively developed and documented by mainly Adrian and to a lesser
> extend by Rolf and I. All the other people listed as
> "authors"/"contributors" have contributed things such as a single new
> function, a bug report, a documentation improvement, etc. Many of them
> might not even be aware that they are mentioned on this list. This list
> has developed over many years, and it is unfortunate if it gives the
> impression that a lot of people are ready to help within 24 hours of a
> question being posted on the general R help list because we cannot give
> such guarantee -- you will have better luck with GitHub, the `spatstat`
> tag on stackoverflow or the R SIG-GEO mail list, but still no 24 hour
> guarantee is provided.
> 
> 2. Abby replies in a very impolite tone towards the spatstat authors
> and suggests that the package isn't fit for CRAN, which I consider a
> direct insult to Adrian and all the hard work he has done to keep a
> very well-documented package on CRAN since 2002. It would have been
> nice to get a constructive suggestion on how to improve documentation
> rather than a message about the alleged poor quality of the spatstat
> package based on the documentation of a single function. If anyone
> (Abby?) has spare time available for going through the documentation
> and suggest improvements, add cross references etc. that's most
> welcome. However, we would like to receive any suggestions in normal
> polite manner via the project's GitHub page or by direct email to the
> authors.
> 
> Regards,
> Ege
> 
>> On Wed, 2020-04-29 at 17:31 +1200, Abby Spurdle wrote:
>> I should have noted that my comments weren't directed towards the
>> main
>> authors, but to all people listed in the description file, which is
>> many, including some R core members.
>> 
>> Also, overall, I'm impressed by the effort here. It's just I strongly
>> feel that good documentation is crucial (especially in open source),
>> and I was somewhat disappointed that, given how many people are/were
>> involved in this package, not one (after approx 24 hours) had tried
>> to
>> help answer the OP's question.
>> 
>>>> *If* it does what it claims ...
>>> 
>>> Why would you doubt that it does what it claims?
>> 
>> Because I didn't test it.
>> 
>>> Wouldn't the first thing that one would try be:
>>>   ??"pp3"
>> 
>> No, because I was reading the PDF version of the documentation.
>> 
>>> Of course I'm biased, but IMHO spatstat is documented not only
>>> "properly", but superbly well! :-)
>> 
>> I started reading the pcf function first.
>> This function has the same problem, it doesn't clearly describe the
>> function arguments.
>> It doesn't say whether it applies to 2d, 3d or higher-dimensional
>> data.
>> After reading it, I had no idea whether the function could be applied
>> to 3d data or not.
>> 
>> In my opinion this is not sufficient.
>> Descriptions of function arguments and return values should be clear.
>> 
>> But here's a bigger problem.
>> The documentation says the pcf function is a generic, but the pcf3est
>> function isn't a method.
>> And the pcf documentation (along with the three methods) don't
>> reference the pcf3est function.
>> 
>> I found the pcf function via Googling the subject.
>> But unless someone goes through a list of all the help topics,
>> they're
>> unlikely to find the pcf3est function.
> -- 
> Ege Rubak, Associate Professor,
> Department of Mathematical Sciences, Aalborg University
> Skjernvej 4A, 9220 Aalborg East, Denmark
> Phone: (+45)99408861
> Mobile: (+45)30230252
> Email: rubak at math.aau.dk


From chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t  Wed Apr 29 14:31:07 2020
From: chr|@t|ne@b|ume @end|ng |rom @bg@@c@@t (Blume Christine)
Date: Wed, 29 Apr 2020 12:31:07 +0000
Subject: [R] Package 'coin' - How to extract rho
In-Reply-To: <alpine.DEB.2.22.394.2004291353350.1154503@paninaro>
References: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
 <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>
 <0bfbe64f1c7f493192d3c46c6c90f5ea@sbg.ac.at>
 <alpine.DEB.2.22.394.2004291353350.1154503@paninaro>
Message-ID: <74225349b6a84fe48f01321ea7c896af@sbg.ac.at>

Dear Achim,

Many thanks indeed. Yes, I had thought about this too and, fortunately, the bootstrapping confirms the results from the "normal" test. However, I was wondering whether it is mathematically acceptable to report the pvals from bootstrapping, but non-bootstrapped correlation coefficients. Does someone have an opinion on this?

Best,
Christine


-----Urspr?ngliche Nachricht-----
Von: Achim Zeileis <Achim.Zeileis at uibk.ac.at> 
Gesendet: Mittwoch, 29. April 2020 13:56
An: Blume Christine <christine.blume at sbg.ac.at>
Cc: Jim Lemon <drjimlemon at gmail.com>; Torsten.Hothorn at uzh.ch; r-help at r-project.org
Betreff: Re: [R] Package 'coin' - How to extract rho

Christine,

thanks for the example. As far as I can see, the "coin" package does not explicitly compute Spearman's rho. This is probably also the reason why it isn't reported in the test output. Thus, you would have to do this "by hand" using cor(..., method = "spearman").

Hope that helps,
Achim


On Wed, 29 Apr 2020, Blume Christine wrote:

> Dear Jim,
>
>
>
> Many thanks for following up on this. Sure, I can provide a sample code. At the end of the code you see that I extract the p-value and the test statistic. However, I cannot find the correlation coefficient rho anywhere in the object ?r?.
>
>
>
> Best,
>
> Christine
>
>
>
> if(!require(pacman)) install.packages("pacman")
>
> pacman::p_load(sn, fGarch, coin)
>
>
>
> # Happiness
>
> central_tendency_sim <- 0
>
> dispersion_sim <- 1
>
> skewness_sim <- 1.5
>
>
>
> N_sim <- 10000
>
>
>
> Happiness <- seq(from = 0,
>
>               to = 10,
>
>               length.out = N_sim)
>
>
>
> # City size
>
> central_tendency_sim <- 3
>
> dispersion_sim <- 1
>
> skewness_sim <- 1.5
>
>
>
> Citysize <- seq(from = 1,
>
>                to = 5,
>
>                length.out = N_sim)
>
>
>
> # create dataframe
>
> datastat <- data.frame(Happiness, Citysize)
>
>
>
> # Bootstrapped correlation
>
> r <- spearman_test(Happiness ~ Citysize, data = datastat, distribution 
> = "approximate", alternative = c("two.sided"))
>
> r
>
> pvalue(r)
>
> statistic(r)
>
>
>
>
>
> -----Urspr?ngliche Nachricht-----
> Von: Jim Lemon <drjimlemon at gmail.com>
> Gesendet: Mittwoch, 29. April 2020 05:53
> An: Blume Christine <christine.blume at sbg.ac.at>
> Cc: r-help at r-project.org
> Betreff: Re: [R] Package 'coin' - How to extract rho
>
>
>
> Hi Christine,
>
> I noticed that your question did not receive a reply. As I don't know exactly what you have tried, it is a bit difficult to suggest a solution. If you are still unable to get this to work, could you provide an example of your present code and data if necessary?
>
>
>
> Jim
>
>
>
> On Mon, Apr 27, 2020 at 3:09 AM Blume Christine <christine.blume at sbg.ac.at<mailto:christine.blume at sbg.ac.at>> wrote:
>
>>
>
>> I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?
>
>>
>
>> Kind regards,
>
>> Christine
>
>>
>
>>
>
>>         [[alternative HTML version deleted]]
>
>>
>
>> ______________________________________________
>
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>
>> https://stat.ethz.ch/mailman/listinfo/r-help
>
>> PLEASE do read the posting guide
>
>> http://www.R-project.org/posting-guide.html
>
>> and provide commented, minimal, self-contained, reproducible code.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Wed Apr 29 14:53:41 2020
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Wed, 29 Apr 2020 14:53:41 +0200 (CEST)
Subject: [R] Package 'coin' - How to extract rho
In-Reply-To: <74225349b6a84fe48f01321ea7c896af@sbg.ac.at>
References: <59d35cc952804772974aa9b66bf4a049@sbg.ac.at>
 <CA+8X3fXN5fa823zjJc6xj8aKzhXsWnDOWvCXsUhgL+b00jVU-Q@mail.gmail.com>
 <0bfbe64f1c7f493192d3c46c6c90f5ea@sbg.ac.at>
 <alpine.DEB.2.22.394.2004291353350.1154503@paninaro>
 <74225349b6a84fe48f01321ea7c896af@sbg.ac.at>
Message-ID: <alpine.DEB.2.22.394.2004291451500.1154503@paninaro>

On Wed, 29 Apr 2020, Blume Christine wrote:

> Dear Achim,
>
> Many thanks indeed. Yes, I had thought about this too and, fortunately, 
> the bootstrapping confirms the results from the "normal" test. However, 
> I was wondering whether it is mathematically acceptable to report the 
> pvals from bootstrapping, but non-bootstrapped correlation coefficients. 
> Does someone have an opinion on this?

First, coin doesn't do bootstrapping tests, it does permutation tests.

Second, reporting the rho coefficient from the original sample is surely 
ok, no matter whether you used a bootstrap test, unconditional asymptotic 
test, or permutation test. At least I wouldn't see any reason, not to do 
so.

Best,
Z

> -----Urspr?ngliche Nachricht-----
> Von: Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> Gesendet: Mittwoch, 29. April 2020 13:56
> An: Blume Christine <christine.blume at sbg.ac.at>
> Cc: Jim Lemon <drjimlemon at gmail.com>; Torsten.Hothorn at uzh.ch; r-help at r-project.org
> Betreff: Re: [R] Package 'coin' - How to extract rho
>
> Christine,
>
> thanks for the example. As far as I can see, the "coin" package does not explicitly compute Spearman's rho. This is probably also the reason why it isn't reported in the test output. Thus, you would have to do this "by hand" using cor(..., method = "spearman").
>
> Hope that helps,
> Achim
>
>
> On Wed, 29 Apr 2020, Blume Christine wrote:
>
>> Dear Jim,
>>
>>
>>
>> Many thanks for following up on this. Sure, I can provide a sample code. At the end of the code you see that I extract the p-value and the test statistic. However, I cannot find the correlation coefficient rho anywhere in the object ?r?.
>>
>>
>>
>> Best,
>>
>> Christine
>>
>>
>>
>> if(!require(pacman)) install.packages("pacman")
>>
>> pacman::p_load(sn, fGarch, coin)
>>
>>
>>
>> # Happiness
>>
>> central_tendency_sim <- 0
>>
>> dispersion_sim <- 1
>>
>> skewness_sim <- 1.5
>>
>>
>>
>> N_sim <- 10000
>>
>>
>>
>> Happiness <- seq(from = 0,
>>
>>               to = 10,
>>
>>               length.out = N_sim)
>>
>>
>>
>> # City size
>>
>> central_tendency_sim <- 3
>>
>> dispersion_sim <- 1
>>
>> skewness_sim <- 1.5
>>
>>
>>
>> Citysize <- seq(from = 1,
>>
>>                to = 5,
>>
>>                length.out = N_sim)
>>
>>
>>
>> # create dataframe
>>
>> datastat <- data.frame(Happiness, Citysize)
>>
>>
>>
>> # Bootstrapped correlation
>>
>> r <- spearman_test(Happiness ~ Citysize, data = datastat, distribution
>> = "approximate", alternative = c("two.sided"))
>>
>> r
>>
>> pvalue(r)
>>
>> statistic(r)
>>
>>
>>
>>
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: Jim Lemon <drjimlemon at gmail.com>
>> Gesendet: Mittwoch, 29. April 2020 05:53
>> An: Blume Christine <christine.blume at sbg.ac.at>
>> Cc: r-help at r-project.org
>> Betreff: Re: [R] Package 'coin' - How to extract rho
>>
>>
>>
>> Hi Christine,
>>
>> I noticed that your question did not receive a reply. As I don't know exactly what you have tried, it is a bit difficult to suggest a solution. If you are still unable to get this to work, could you provide an example of your present code and data if necessary?
>>
>>
>>
>> Jim
>>
>>
>>
>> On Mon, Apr 27, 2020 at 3:09 AM Blume Christine <christine.blume at sbg.ac.at<mailto:christine.blume at sbg.ac.at>> wrote:
>>
>>>
>>
>>> I am using the 'coin' package to compute bootstrapped correlations. I am able to extract the p-value with confidence intervals as well as the test statistic Z. However, I am unable to find rho, i.e. the correlation coefficient. Can someone help?
>>
>>>
>>
>>> Kind regards,
>>
>>> Christine
>>
>>>
>>
>>>
>>
>>>         [[alternative HTML version deleted]]
>>
>>>
>>
>>> ______________________________________________
>>
>>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
>>> UNSUBSCRIBE and more, see
>>
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>
>>> PLEASE do read the posting guide
>>
>>> http://www.R-project.org/posting-guide.html
>>
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

From you@r|@|@nou@ @end|ng |rom gm@||@com  Wed Apr 29 15:09:05 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Wed, 29 Apr 2020 09:09:05 -0400
Subject: [R] what is the expected behavior of layout.show(n)
Message-ID: <CADsEwSf1NGsUYZR5T9WG+hwqgdkPTCMMC-pzFgxO3tZaP6Cd6A@mail.gmail.com>

Hello

Load package: ACSWR
> data(sample)
> layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0),2,6,byrow=T),respect=F)
> hist(sample[,1],main="Hist for sample I",xlab="sample 1",ylab="freq")
> hist(sample[,2],main="Hist for sample II",xlab="sample 2",ylab="freq")
> hist(sample[,3],main="Hist for sample III",xlab="sample 3",ylab="freq")
> hist(sample[,4],main="Hist for sample IV",xlab="sample 4",ylab="freq")
> hist(sample[,5],main="Hist for sample V",xlab="sample 5",ylab="freq")

This works as expected: Histograms 1-3 are displayed on the first row and
histograms 4 and 5 on the second row

However when I use layout.show to check the layout , it appears that
layout.show(3) consumes the first 3 locations

> layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0),2,6,byrow=T),respect=F)
> layout.show(3)
> hist(sample[,1],main="Hist for sample I",xlab="sample 1",ylab="freq")
> hist(sample[,2],main="Hist for sample II",xlab="sample 2",ylab="freq")
> hist(sample[,3],main="Hist for sample III",xlab="sample 3",ylab="freq")
> hist(sample[,4],main="Hist for sample IV",xlab="sample 4",ylab="freq")
> hist(sample[,5],main="Hist for sample V",xlab="sample 5",ylab="freq")

Now the first row shows 3 empty rectangles and histogram 1 and 2 are
displayed on row 2 while histograms 3-5 are displayed on the top row in a
different graph / page

If I use layout.show(5) then each histogram is displayed on a separate
sheet as if the layout was fully consumed

Few questions here:
1) in case of layout.show(3) why the layout was still remembered / recycled
2) with layout.show(5) why was the layout totally dismissed. I expected at
least it would restart over with 3 graphs in first row and 2 graphs in
second row to be consistent in behavior with layout.show(3)
3) layout.show(x) purpose is to check if my layout is correct. It must not
leave any side effect on the main plots.
>From the help of function layout this line relates to layout.show

layout.show(n) plots (part of) the current layout, namely the outlines of
the next n figures.

It does not describe the behavior I am seeing

4) Finally is there a way to undo the effect of layout.show except re-enter
my layout again?

Yousri

Software Developer
IBM Canada

	[[alternative HTML version deleted]]


From v@h|d@borj|65 @end|ng |rom gm@||@com  Wed Apr 29 16:34:21 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Wed, 29 Apr 2020 19:04:21 +0430
Subject: [R] How can I solve an error after installing RStudio
Message-ID: <CAEPHqhaieu+UvGoN5VGGEnta=KKKBxPJA+i7z9Z2eFFLKjY3PQ@mail.gmail.com>

Hi there,

I downloaded Rstudio and installed it on my laptop. When I want to open
Rstudio I see the below message: The program can't start because
api-ms-win-runtime-|1-1-0.dll is missing from your computer. Try
reinstalling the program to fix this problem.

Could you please help me how I can solve this error and work with RStudio?
(I have R on my laptop and work with it without any problem.)

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 29 16:41:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Apr 2020 07:41:13 -0700
Subject: [R] Fwd:  How can I solve an error after installing RStudio
In-Reply-To: <CAGxFJbTMOpNZOJ5X9qE8HH3fRFYV4i-yvs5xZMZ32SoNDPvCFQ@mail.gmail.com>
References: <CAEPHqhaieu+UvGoN5VGGEnta=KKKBxPJA+i7z9Z2eFFLKjY3PQ@mail.gmail.com>
 <CAGxFJbTMOpNZOJ5X9qE8HH3fRFYV4i-yvs5xZMZ32SoNDPvCFQ@mail.gmail.com>
Message-ID: <CAGxFJbRpWt5XKxvPE79nkjD8AjwtEOfjjQu6OiOXv8e8JCOpvA@mail.gmail.com>

Neglected to cc. R-help


---------- Forwarded message ---------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Apr 29, 2020 at 7:40 AM
Subject: Re: [R] How can I solve an error after installing RStudio
To: Vahid Borji <vahid.borji65 at gmail.com>


No. You have to go to the RStudio website/help pages. RStudio is
separate software from R.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 29, 2020 at 7:35 AM Vahid Borji <vahid.borji65 at gmail.com> wrote:
>
> Hi there,
>
> I downloaded Rstudio and installed it on my laptop. When I want to open
> Rstudio I see the below message: The program can't start because
> api-ms-win-runtime-|1-1-0.dll is missing from your computer. Try
> reinstalling the program to fix this problem.
>
> Could you please help me how I can solve this error and work with RStudio?
> (I have R on my laptop and work with it without any problem.)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 29 17:07:01 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 29 Apr 2020 08:07:01 -0700
Subject: [R] How can I solve an error after installing RStudio
In-Reply-To: <CAEPHqhaieu+UvGoN5VGGEnta=KKKBxPJA+i7z9Z2eFFLKjY3PQ@mail.gmail.com>
References: <CAEPHqhaieu+UvGoN5VGGEnta=KKKBxPJA+i7z9Z2eFFLKjY3PQ@mail.gmail.com>
Message-ID: <222E6D70-26AB-443C-8083-B6B5C4A5AE80@dcn.davis.ca.us>

Ah, no, this mailing list is about R, not RStudio. It is _possible_ that your problem could be with R because RStudio requires that R be installed, but you would need to explain how an error appears when you use RGui or R (from the command line) to separate any RStudio issues from R issues. If the error only appears when you use RStudio then you need to ask for help on their help forum.

On April 29, 2020 7:34:21 AM PDT, Vahid Borji <vahid.borji65 at gmail.com> wrote:
>Hi there,
>
>I downloaded Rstudio and installed it on my laptop. When I want to open
>Rstudio I see the below message: The program can't start because
>api-ms-win-runtime-|1-1-0.dll is missing from your computer. Try
>reinstalling the program to fix this problem.
>
>Could you please help me how I can solve this error and work with
>RStudio?
>(I have R on my laptop and work with it without any problem.)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@||@t@ @end|ng |rom gmx@net  Tue Apr 28 19:22:57 2020
From: m@||@t@ @end|ng |rom gmx@net (Andy Spada)
Date: Tue, 28 Apr 2020 19:22:57 +0200
Subject: [R] regular expression, stringr::str_view, grep
In-Reply-To: <5dd4adb3-0844-67d9-66b7-8a9a6d2a3f9b@comcast.net>
References: <1002f7b7-ef2e-4993-967d-0744d874616e@wiwi.hu-berlin.de>
 <5dd4adb3-0844-67d9-66b7-8a9a6d2a3f9b@comcast.net>
Message-ID: <a134abf7-1f31-bca9-1f47-8faabe44d285@gmx.net>

This highlights the literal meaning of the last ] in your correct_brackets:

aff <- c("affgfk]ing", "fgok", "rafgkah]e","a fgk", "bafghk]")

To me, too, the missing_brackets looks more like what was desired, and
returns correct results for a PCRE. Perhaps the regular expression
should have been rewritten:

desired_brackets <- "af+g[^m$][^A-Z]"
grep(desired_brackets, aff, value = TRUE) ### correct result
str_view(aff, desired_brackets) ### correct result

Regards,
Andy


On 28.04.2020 18:41:50, David Winsemius wrote:
>
> On 4/28/20 2:29 AM, Sigbert Klinke wrote:
>> Hi,
>>
>> we gave students the task to construct a regular expression selecting
>> some texts. One send us back a program which gives different results
>> on stringr::str_view and grep.
>>
>> The problem is "[^[A-Z]]" / "[^[A-Z]" at the end of the regular
>> expression. I would have expected that all four calls would give the
>> same result; interpreting [ and ] within [...] as the characters `[`
>> and `]`. Obviously this not the case and moreover stringr::str_view
>> and grep interpret the regular expressions differently.
>>
>> Any ideas?
>>
>> Thanks Sigbert
>>
>> ---
>>
>> aff <- c("affgfking", "fgok", "rafgkahe","a fgk", "bafghk", "affgm",
>> ???????? "baffgkit", "afffhk", "affgfking", "fgok", "rafgkahe", "afg.K",
>> ???????? "bafghk", "aff gm", "baffg kit", "afffhgk")
>
> TL;DR: different versions of regex character class syntax:
>
>
>>
>> correct_brackets <- "af+g[^m$][^[A-Z]]"
> To me that looks "incorrect" because of an unnecessary square-bracket.
>> missing_brackets <- "af+g[^m$][^[A-Z]"
> And that one looks complete. To my mind it looks like the negation of
> a character class with "[" and the range A-Z.
>>
>> library("stringr")
>
>
> I think this is the root of your problem. If you execute ?regex you
> should be given a choice of two different help pages and if you go to
> the one from pkg stringr it says in the Usage section:
>
> regex
> The default. Uses ICU regular expressions.
>
> So that's probably different than the base regex convention which uses
> TRE regular expressions.
>
>
> You should carefully review:
>
>
> help('stringi-search-charclass' , pac=stringi)
>
> ?I think you should also find the adding square brackets around ranges
> is not needed in either type of regex syntax, but that stringi's regex
> (unlike base R's TRE regex) does allow multiple disjoint ranges inside
> the outer square brackets of a character class. I've never seen that
> in base R regex. So I think that this base regex pattern,
> grepl("([a-b]|[r-t])", letters) is the same as this stringi pattern:?
> str_view( letters, "[[a-c][r-t]]").
>
>


From D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u  Wed Apr 29 07:47:44 2020
From: D@v|d@Du||y @end|ng |rom q|mrbergho|er@edu@@u (David Duffy)
Date: Wed, 29 Apr 2020 05:47:44 +0000
Subject: [R] R-help Digest, Vol 206, Issue 25
In-Reply-To: <mailman.358475.1.1587808801.55216.r-help@r-project.org>
References: <mailman.358475.1.1587808801.55216.r-help@r-project.org>
Message-ID: <23b8da5e7dc344a5b1ce24f334a0144f@qimrberghofer.edu.au>

I don't think anyone responded last week.

> Using the mice package, I have created multiple imputed datasets to deal
> with missing data. I am looking for an example of the R code to use in
> order to analyze the set of imputed datasets using tetrachoric correlations
> in such a way that after pooling, I will have a combined tetrachoric
> covariance-variance matrix to use as input for an exploratory factor
> analysis.

Hi Ian.

The mice package requires you to have an appropriate method to extract the individual simulated datasets:

The ?mira? object is generated by the ?with.mids()?...It may happen that you'll see the messages like ?No method for tidying an S3 object of class ...? or ?Error: No glance method for objects of class ...?. The royal way to solve this problem is to write your own ?glance()? and ?tidy()? methods and add these to ?broom? according to the specifications given in
 <URL: https://broom.tidyverse.org/articles/adding-tidiers.html>.

eg
data(gllm::lsat)
idx <- rep(1:32, lsat$Freq)
lsat2 <- lsat[idx,-6]
idx <- cbind(sample(1:1000, size=50, replace=T), sample(1:5, size=50, replace=T))
lsat2[idx] <- NA
library(mice)
s1 <- mice(lsat2)
pool(with(s1, exp=polychor(A,B)))
Error: No glance method for objects of class numeric

 print(with(s1, exp=polychor(A,B)))
call :
with.mids(data = s1, expr = polychor(A, B))
call1 :
mice(data = lsat3)

nmis :
 A  B  C  D  E 
 9 11 13  7 10 

analyses :
[[1]]
[1] 0.1552523

[[2]]
[1] 0.1485645

[[3]]
[1] 0.1584301

[[4]]
[1] 0.1536678

[[5]]
[1] 0.1698725

You can see that "all" you have to do is take the mean of the A-B tetrachoric correlations from in this case, 5, replicates, to get your corrected correlation.

It happens that there is a ?glance.lavaan? routine, and lavaan has the lavCor() function to estimate tetrachoric correlations and
fit structural equation models. So you can probably fit your factor model directly and get correct statistical tests there.

Cheers, David Duffy.


From @dr|@n@b@dde|ey @end|ng |rom curt|n@edu@@u  Wed Apr 29 10:51:12 2020
From: @dr|@n@b@dde|ey @end|ng |rom curt|n@edu@@u (Adrian Baddeley)
Date: Wed, 29 Apr 2020 08:51:12 +0000
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <755C0845-240E-4EDA-8C20-54EAD1CFA295@dcn.davis.ca.us>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>,
 <755C0845-240E-4EDA-8C20-54EAD1CFA295@dcn.davis.ca.us>
Message-ID: <MEAPR01MB2232395E53EC5AD4631C2F7BA4AD0@MEAPR01MB2232.ausprd01.prod.outlook.com>

I am the main author of spatstat, and the author of the code and documentation for pcf3est.

This is the first time in 25 years that I can remember anyone complaining about the documentation for the spatstat package.

The available documentation for spatstat includes:

                 - welcome message on startup which explains where to find help
                 - introductory vignette 'Getting Started in Spatstat'
                 - quick reference guide (in the help file 'spatstat-package' , at the front of the full manual, and on website)
                 - online help files (> 2000 help files)
                 - package manual (> 1700 pages)
                 - project website www.spatstat.org
                 - book 'Spatial Point Patterns: Methodology and Applications with R' (>700 pages)
                 - book companion website book.spatstat.org
                 - technical descriptions in journal articles
                 - ample explanatory comments in the source code

All of these sources (even the Description file) explain that spatstat is mainly focused on *two-dimensional* spatial point patterns but provides limited support for other kinds of data, including three-dimensional point patterns.

Three-dimensional point patterns are a relatively small subset of the current spatstat functionality
(covered in Section 15.3 pages 650-657 of the book, thus approximately 1% of the book).

The full manual PDF is searchable, has an index, and its internal cross-references are hyperlinks that can be followed.
Package manuals can also be accessed interactively in R through a web-like interface.
Package manuals are also available online with a web interface at some websites like rdrr.io

The help entry for 'pcf3est' says that the argument X must be a "three-dimensional point pattern (object of class 'pp3')". Most users would immediately look up 'pp3'. Apparently you were reading this from the full manual PDF and you say that you couldn't look up 'pp3'. The manual is searchable; you could have searched the PDF for keyword 'pp3', or jumped to the index, or the contents page. You could have looked at the first entry in the manual, which is the quick reference guide, which has a section on 'Three-dimensional point patterns' which would have listed all the available functionality for three-dimensional point patterns. You could have searched for 'three dimensional'.

> I was somewhat disappointed that, given how many people are/were
   > involved in this package, not one (after approx 24 hours) had tried to
   > help answer the OP's question.

That's not a complaint about the documentation. It's a complaint that no-one responded
to your query within 24 hours. Seriously? No-one is obliged to provide this level of service.
Twenty-four hours is a pretty short time scale for a response to a question that was not
addressed to anyone in particular. R-help is not a commonly used forum for asking questions about spatstat.
If you wanted a quick answer you could have emailed the package authors directly.

> I should have noted that my comments weren't directed towards the main
> authors, but to all people listed in the description file, which is
 > many, including some R core members.

The Description file says clearly that there are three main authors: Baddeley, Turner and Rubak with email addresses given.
The others are people who have contributed something at some time in the past.
I'm not sure what you hoped to achieve by addressing comments to a wider audience - most of whom are not listening on this frequency.

 > It's just I strongly feel that good documentation is crucial (especially in open source),

So do we; that's why we have put so much effort into documentation, including writing a whole book.

> I started reading the pcf function first.
> This function has the same problem, it doesn't clearly describe the function arguments.
> It doesn't say whether it applies to 2d, 3d or higher-dimensional data.
> After reading it, I had no idea whether the function could be applied to 3d data or not.
> In my opinion this is not sufficient.
> Descriptions of function arguments and return values should be clear.

pcf is generic.
The argument 'X' analysed in 'pcf(X)' could be any kind of spatial data.

The help file for a generic does not go into specific detail about 'X'; that is documented in the help files for the relevant methods.

The help file for the generic usually includes cross-references (under 'See Also') to some of the available methods.
Alternatively, to find out what classes of objects have a 'pcf' method, you can type 'methods(pcf)' in R with the package loaded. If you're reading a PDF, the methods will be listed consecutively in the file.

This would have revealed that there is a 'pcf.ppp' and a couple of other options.
The help for 'pcf.ppp' says that 'X' should be "a point pattern (object of class 'ppp')".
The help for 'ppp' or 'ppp.object' says that this class of object represents a point pattern in the two-dimensional plane.

> But here's a bigger problem.
> The documentation says the pcf function is a generic, but the pcf3est function isn't a method.

That is correct. But this is not a failure of documentation.
'pcf3est' is not a method for the generic 'pcf'.
'pcf3est' has a different, older syntax, and doesn't behave exactly the same way internally,
so it is not suitable to be a method for 'pcf'.

It would of course be logical for 'pcf' to have a method for three-dimensional point patterns,
but that depends on someone implementing it.

The software design for future versions of spatstat specifies that the summary functions such as
pcf.ppp and pcf3est should be modified to have a common syntax, which will be slightly different from
either of the current ones, and at that stage, the rewritten pcf3est will become a method for 'pcf'.

> I found the pcf function via Googling the subject.

I don't want to be rude, but this seems pretty lazy.

> But unless someone goes through a list of all the help topics, they're unlikely to find the pcf3est function.

Try Googling
         'spatstat pair correlation function three dimensions'

or searching the full spatstat manual PDF for
         'pair correlation function' or 'three dimensions'

You could also have jumped to the 'pcf' entry in the full manual, and scrolled up and down to see the other entries that begin with 'pcf'.

You complain that the documentation is insufficient, but at the same time, you complain that the manual is too long (> 1700 pages) and you seem unwilling to search the documentation or follow cross-references.

Before I answered this email, I had to answer an email from CRAN requesting me to please cut down the size of the spatstat package, including the documentation and examples, because the tarball is too large and the examples take too long to run.

So please understand that package authors have to be economical with the provision of documentation and examples. It is simply not feasible or efficient to explain everything in every help file. The user has to make some effort to follow up relevant information.

Finally, you cast doubt on whether the function pcf3est actually does calculate an estimate of the pair correlation function for a three-dimensional point pattern, as we claim in the help file. I'm at a loss to understand what you mean. The help file gives journal paper references, and indicates that the code in pcf3est calculates the estimator described in the paper by Baddeley et al (1993). I am the author of the technical paper, the code, and the documentation. What exactly are you disputing?


Regards



Prof Adrian Baddeley DSc FAA

John Curtin Distinguished Professor

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia


I work Wednesdays, Thursdays and Fridays


	[[alternative HTML version deleted]]


From c@r|o@@un|2 @end|ng |rom gm@||@com  Wed Apr 29 19:01:14 2020
From: c@r|o@@un|2 @end|ng |rom gm@||@com (Carlos H. Mireles)
Date: Wed, 29 Apr 2020 12:01:14 -0500
Subject: [R] upgrade from R 3.6.3 to 4.0.0
Message-ID: <CAB41t0bZwVLJ5DMqeXbyoWVJTVCyT-QiudLcw==nogdyFBvS-Q@mail.gmail.com>

Hello everyone, I'm trying to upgrade R from 3.6.3 to 4.0.0 using the linux
terminal commands (sudo apt upgrade r-base r-base-dev) but I get a message
that says 3.6.3 is still the latest version. Please see the output below.
How could I fix this?

Thanks much for your help!

Carlos

==========================================================
(base) carloshmireles at chm-hp:~$ sudo apt upgrade r-base r-base-dev
[sudo] password for carloshmireles:
Reading package lists... Done
Building dependency tree
Reading state information... Done
r-base-dev is already the newest version (3.6.3-1bionic).
r-base is already the newest version (3.6.3-1bionic).
Calculating upgrade... Done
The following packages were automatically installed and are no longer
required:
  linux-headers-4.15.0-91 linux-headers-4.15.0-91-generic
linux-image-4.15.0-91-generic linux-modules-4.15.0-91-generic
  linux-modules-extra-4.15.0-91-generic
Use 'sudo apt autoremove' to remove them.
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
(base) carloshmireles at chm-hp:~$

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Wed Apr 29 19:05:14 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 29 Apr 2020 13:05:14 -0400
Subject: [R] upgrade from R 3.6.3 to 4.0.0
In-Reply-To: <CAB41t0bZwVLJ5DMqeXbyoWVJTVCyT-QiudLcw==nogdyFBvS-Q@mail.gmail.com>
References: <CAB41t0bZwVLJ5DMqeXbyoWVJTVCyT-QiudLcw==nogdyFBvS-Q@mail.gmail.com>
Message-ID: <9c58810c-75b4-51c1-d315-625ecdba01c9@gmail.com>

Did you update your software sources (/etc/apt/sources.list or entry in /etc/apt/sources.list.d)?

JN

On 2020-04-29 1:01 p.m., Carlos H. Mireles wrote:
> Hello everyone, I'm trying to upgrade R from 3.6.3 to 4.0.0 using the linux
> terminal commands (sudo apt upgrade r-base r-base-dev) but I get a message
> that says 3.6.3 is still the latest version. Please see the output below.
> How could I fix this?
> 
> Thanks much for your help!
> 
> Carlos
> 
> ==========================================================
> (base) carloshmireles at chm-hp:~$ sudo apt upgrade r-base r-base-dev
> [sudo] password for carloshmireles:
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> r-base-dev is already the newest version (3.6.3-1bionic).
> r-base is already the newest version (3.6.3-1bionic).
> Calculating upgrade... Done
> The following packages were automatically installed and are no longer
> required:
>   linux-headers-4.15.0-91 linux-headers-4.15.0-91-generic
> linux-image-4.15.0-91-generic linux-modules-4.15.0-91-generic
>   linux-modules-extra-4.15.0-91-generic
> Use 'sudo apt autoremove' to remove them.
> 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
> (base) carloshmireles at chm-hp:~$
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 29 20:53:37 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 30 Apr 2020 06:53:37 +1200
Subject: [R] [FORGED] Re: pair correlation function of 3D points
In-Reply-To: <MEAPR01MB2232395E53EC5AD4631C2F7BA4AD0@MEAPR01MB2232.ausprd01.prod.outlook.com>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
 <755C0845-240E-4EDA-8C20-54EAD1CFA295@dcn.davis.ca.us>
 <MEAPR01MB2232395E53EC5AD4631C2F7BA4AD0@MEAPR01MB2232.ausprd01.prod.outlook.com>
Message-ID: <CAB8pepx6jwjoxcM7xAsBKJgihgizqL-b4OM958SSdr9e9_GOYQ@mail.gmail.com>

NOTE CITATIONS USE BRIEF EXCERPTS

> It's a complaint that no-one responded to your query within 24 hours.

Correction, it wasn't my query.
I was replying to someone else's query.

> Finally, you cast doubt on whether the function pcf3est actually does calculate...

You've taken what I said out of context.
As I said in my response to Rolf, I didn't run the code.

> email from CRAN requesting me to please cut down the size of the spatstat package

I can't speak on behalf on CRAN.
But reiterating what I said earlier, you'd be better to create smaller
packages, each with a more specific focus.
Each package could have an unofficial co-maintainer to help you out.

> You complain that the documentation is insufficient, but at the same time, you complain that the manual is too long (> 1700 pages) and you seem unwilling to search the documentation or follow cross-references.

Did you read my posts...

The functions DO NOT cross-reference.
The pcf generic/methods DO NOT reference the pcf3est function, at all.
The pcf3est function DOES NOT reference the pp3 function, but rather
references the class of the object.

Also, the seealso sections are minimalist.

If you are not going to create smaller packages, then the least you
could do it improve the standard of the seealso sections and
cross-referencing.

Furthermore, if functions are not cross-referenced, the reader (I this
case me) doesn't necessarily know what package those functions are
defined in.
You assume that readers will assume the functions are defined in your
package, and then do a search for them.

Instead of making assumptions about assumptions, just use hyperlinks...

> > I was somewhat disappointed ... not one (after approx 24 hours) had tried to
> > help answer the OP's question.
> Seriously?

Yes, seriously.
>From my experiences, if people don't reply to an R-help question in
the first 24 hours, chances that they will reply later are low.
Also, I've found a bias on this forum, with few replies to
physics-related questions.

Personally, I like physicists, one of the most under-valued
professions on the planet.

> I found the pcf function via Googling the subject.
> I don't want to be rude, but this seems pretty lazy.

> Try Googling  'spatstat pair correlation function three dimensions'

That sounds like a contradiction.

Also, it's off the mark, given that I was the only one who attempted
to answer the OPs question.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Apr 29 21:19:18 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 29 Apr 2020 14:19:18 -0500
Subject: [R] how to create a new column from two columns with conditions
Message-ID: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>

Hello,

I have a data frame like this:

> head(b)
       FID          IID FLASER PLASER
1: fam1000 G1000      1      1
2: fam1001 G1001      1      1
3: fam1003 G1003      1      2
4: fam1005 G1005      1      1
5: fam1009 G1009      2      1
6: fam1052 G1052      1      1
...

My conditions for creating a new column PHENO would be this:

if FLASER or PLASER =2 then PHENO=2
otherwise PHENO=1

so result would look like this:

> head(b)
       FID          IID FLASER PLASER PHENO
1: fam1000 G1000      1      1            1
2: fam1001 G1001      1      1            1
3: fam1003 G1003      1      2            2
4: fam1005 G1005      1      1            1
5: fam1009 G1009      2      1             2
6: fam1052 G1052      1      1             1
...

Thanks
Ana
...


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Wed Apr 29 21:30:45 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Wed, 29 Apr 2020 15:30:45 -0400
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
Message-ID: <CAJc=yOFu+mfzxVbMj41pvEVC0g7fxdsHKx-XoZCFOzW_4w37vg@mail.gmail.com>

If you don't mind using tidyverse, you can do this easily with if_else.

b$PHENO<-if_else(...



On Wed, Apr 29, 2020 at 3:21 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a data frame like this:
>
> > head(b)
>        FID          IID FLASER PLASER
> 1: fam1000 G1000      1      1
> 2: fam1001 G1001      1      1
> 3: fam1003 G1003      1      2
> 4: fam1005 G1005      1      1
> 5: fam1009 G1009      2      1
> 6: fam1052 G1052      1      1
> ...
>
> My conditions for creating a new column PHENO would be this:
>
> if FLASER or PLASER =2 then PHENO=2
> otherwise PHENO=1
>
> so result would look like this:
>
> > head(b)
>        FID          IID FLASER PLASER PHENO
> 1: fam1000 G1000      1      1            1
> 2: fam1001 G1001      1      1            1
> 3: fam1003 G1003      1      2            2
> 4: fam1005 G1005      1      1            1
> 5: fam1009 G1009      2      1             2
> 6: fam1052 G1052      1      1             1
> ...
>
> Thanks
> Ana
> ...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Apr 29 21:36:34 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 29 Apr 2020 22:36:34 +0300
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
Message-ID: <20200429223634.5923b4f0@Tarkus>

On Wed, 29 Apr 2020 14:19:18 -0500
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> My conditions for creating a new column PHENO would be this:
> 
> if FLASER or PLASER =2 then PHENO=2
> otherwise PHENO=1

On Wed, 29 Apr 2020 15:30:45 -0400
"Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:

> If you don't mind using tidyverse, you can do this easily with
> if_else.

...and if you want to stay with base R, you can use the ifelse
function.

-- 
Best regards,
Ivan


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Apr 29 21:42:20 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 29 Apr 2020 14:42:20 -0500
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <20200429223634.5923b4f0@Tarkus>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
 <20200429223634.5923b4f0@Tarkus>
Message-ID: <CAF9-5jO6cUzOmvPkctJtXu-jYS5gLHnqxx5ngOSYMsFqQgfYfQ@mail.gmail.com>

Thanks, I did this:
b$PHENO<- ifelse(b$FLASER ==2 | b$PLASER ==2, 2, 1)

On Wed, Apr 29, 2020 at 2:36 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Wed, 29 Apr 2020 14:19:18 -0500
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > My conditions for creating a new column PHENO would be this:
> >
> > if FLASER or PLASER =2 then PHENO=2
> > otherwise PHENO=1
>
> On Wed, 29 Apr 2020 15:30:45 -0400
> "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
>
> > If you don't mind using tidyverse, you can do this easily with
> > if_else.
>
> ...and if you want to stay with base R, you can use the ifelse
> function.
>
> --
> Best regards,
> Ivan


From @purd|e@@ @end|ng |rom gm@||@com  Wed Apr 29 22:27:52 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 30 Apr 2020 08:27:52 +1200
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
 <CAB8pepwxV1nyNKA85srFqxw=d5Fzb9k618d9=1tk1PRQdyb42A@mail.gmail.com>
 <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>
Message-ID: <CAB8pepyK3ThAgtjtXM8Xuszs2tv-1TqwSPd16RiQOx_jvVZ+6A@mail.gmail.com>

> suggests that the package isn't fit for CRAN, which I consider a
> direct insult to Adrian and all the hard work he has done

This is my last post on this subject.

I just ran R check on the source package.
After 40 minutes, R check wasn't complete.

And I note the CRAN check results show the package was checked with:

Linux: --no-tests
Windows: --no-examples --no-tests --no-vignettes

I recognize that R-help isn't the right place for this discussion.
And perhaps the last line of my first post was unfair.

But the rest of my comments about the package are objective.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Apr 29 23:10:47 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 29 Apr 2020 22:10:47 +0100
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <CAF9-5jO6cUzOmvPkctJtXu-jYS5gLHnqxx5ngOSYMsFqQgfYfQ@mail.gmail.com>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
 <20200429223634.5923b4f0@Tarkus>
 <CAF9-5jO6cUzOmvPkctJtXu-jYS5gLHnqxx5ngOSYMsFqQgfYfQ@mail.gmail.com>
Message-ID: <1e93298e-2f3f-d280-af2c-fe01dd11b656@sapo.pt>

Hello,

Here is another way. The condition returns FALSE/TRUE or 0/1. Add 1 to 
get the expected result.
It has the advantage of being faster.

b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L


Hope this helps,

Rui Barradas

?s 20:42 de 29/04/20, Ana Marija escreveu:
> Thanks, I did this:
> b$PHENO<- ifelse(b$FLASER ==2 | b$PLASER ==2, 2, 1)
> 
> On Wed, Apr 29, 2020 at 2:36 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>
>> On Wed, 29 Apr 2020 14:19:18 -0500
>> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>>> My conditions for creating a new column PHENO would be this:
>>>
>>> if FLASER or PLASER =2 then PHENO=2
>>> otherwise PHENO=1
>>
>> On Wed, 29 Apr 2020 15:30:45 -0400
>> "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
>>
>>> If you don't mind using tidyverse, you can do this easily with
>>> if_else.
>>
>> ...and if you want to stay with base R, you can use the ifelse
>> function.
>>
>> --
>> Best regards,
>> Ivan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Wed Apr 29 23:12:26 2020
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Thu, 30 Apr 2020 09:12:26 +1200
Subject: [R] [FORGED]  what is the expected behavior of layout.show(n)
In-Reply-To: <CADsEwSf1NGsUYZR5T9WG+hwqgdkPTCMMC-pzFgxO3tZaP6Cd6A@mail.gmail.com>
References: <CADsEwSf1NGsUYZR5T9WG+hwqgdkPTCMMC-pzFgxO3tZaP6Cd6A@mail.gmail.com>
Message-ID: <cead75a0-2ce4-4489-2a14-0d2bee98fcc8@stat.auckland.ac.nz>

Hi

This behaviour is as expected.

The layout.show() function is just there to help visualise what the 
layout will look like.

So for testing purposes, you would do something like ...

layout(...)
layout.show(n)

Then to actually use the layout, you would do something like ...

layout(...)
plot(...)
plot(...)
plot(...)

Paul

On 30/04/20 1:09 am, Yousri Fanous wrote:
> This works as expected: Histograms 1-3 are displayed on the first row and
> histograms 4 and 5 on the second row
> 
> However when I use layout.show to check the layout , it appears that
> layout.show(3) consumes the first 3 locations
> 
>> layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0),2,6,byrow=T),respect=F)
>> layout.show(3)
>> hist(sample[,1],main="Hist for sample I",xlab="sample 1",ylab="freq")
>> hist(sample[,2],main="Hist for sample II",xlab="sample 2",ylab="freq")
>> hist(sample[,3],main="Hist for sample III",xlab="sample 3",ylab="freq")
>> hist(sample[,4],main="Hist for sample IV",xlab="sample 4",ylab="freq")
>> hist(sample[,5],main="Hist for sample V",xlab="sample 5",ylab="freq")
> Now the first row shows 3 empty rectangles and histogram 1 and 2 are
> displayed on row 2 while histograms 3-5 are displayed on the top row in a
> different graph / page
> 
> If I use layout.show(5) then each histogram is displayed on a separate
> sheet as if the layout was fully consumed
> 
> Few questions here:
> 1) in case of layout.show(3) why the layout was still remembered / recycled
> 2) with layout.show(5) why was the layout totally dismissed. I expected at
> least it would restart over with 3 graphs in first row and 2 graphs in
> second row to be consistent in behavior with layout.show(3)
> 3) layout.show(x) purpose is to check if my layout is correct. It must not
> leave any side effect on the main plots.
>  From the help of function layout this line relates to layout.show
> 
> layout.show(n) plots (part of) the current layout, namely the outlines of
> the next n figures.
> 
> It does not describe the behavior I am seeing
> 
> 4) Finally is there a way to undo the effect of layout.show except re-enter
> my layout again?
> 
> Yousri

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From @yen @end|ng |rom hqu@edu@cn  Tue Apr 28 15:30:53 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Tue, 28 Apr 2020 21:30:53 +0800
Subject: [R] Rtools required
In-Reply-To: <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
Message-ID: <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>

Thanks John. Where is file .Renviron located? It must be a hidden file. 
I cannot find it.

On 2020/4/28 ?? 08:29, Fox, John wrote:
> Dear Steven,
>
> Did you follow the instruction on the Rtools webpage to add
>
> 	PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>
> to your .Renviron file?
>
> I hope this helps,
>   John
>
>    -----------------------------
>    John Fox, Professor Emeritus
>    McMaster University
>    Hamilton, Ontario, Canada
>    Web: http::/socserv.mcmaster.ca/jfox
>
>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>
>> Dear All
>>
>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>> the new default folder c:\rtools40). While compiling a package (binary)
>> I received the follow marning message saying Rtools is required. Any
>> clues? Thanks.
>>
>> Steven Yen
>>
>> WARNING: Rtools is required to build R packages but is not currently
>> installed. Please download and install the appropriate version of Rtools
>> before proceeding: https://cran.rstudio.com/bin/windows/Rtools/
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @yen @end|ng |rom hqu@edu@cn  Tue Apr 28 15:49:47 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Tue, 28 Apr 2020 21:49:47 +0800
Subject: [R] Rtools required
In-Reply-To: <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
Message-ID: <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>

Hello John,

Perhaps you can help me. I am an idiot. I visited the Rtools web page 
and learn to run the following lines in R: Still I am getting the same 
warning message.

 > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = 
"~/.Renviron")
 > Sys.which("make")
 ????????????????????????????? make
"C:\\rtools40\\usr\\bin\\make.exe"

On 2020/4/28 ?? 08:29, Fox, John wrote:
> Dear Steven,
>
> Did you follow the instruction on the Rtools webpage to add
>
> 	PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>
> to your .Renviron file?
>
> I hope this helps,
>   John
>
>    -----------------------------
>    John Fox, Professor Emeritus
>    McMaster University
>    Hamilton, Ontario, Canada
>    Web: http::/socserv.mcmaster.ca/jfox
>
>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>
>> Dear All
>>
>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>> the new default folder c:\rtools40). While compiling a package (binary)
>> I received the follow marning message saying Rtools is required. Any
>> clues? Thanks.
>>
>> Steven Yen
>>
>> WARNING: Rtools is required to build R packages but is not currently
>> installed. Please download and install the appropriate version of Rtools
>> before proceeding: https://cran.rstudio.com/bin/windows/Rtools/
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @yen04 @end|ng |rom gm@||@com  Tue Apr 28 15:56:16 2020
From: @yen04 @end|ng |rom gm@||@com (Steven Yen)
Date: Tue, 28 Apr 2020 21:56:16 +0800
Subject: [R] Rtools required
In-Reply-To: <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
Message-ID: <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>

Thanks. I visited the Rtools web page and learned to run the following 
lines. I am still getting the same warning message.

 > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con = 
"~/.Renviron")
 > Sys.which("make")
 ????????????????????????????? make
"C:\\rtools40\\usr\\bin\\make.exe"

On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>> Dear All
>>
>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>> the new default folder c:\rtools40). While compiling a package (binary)
>> I received the follow marning message saying Rtools is required. Any
>> clues? Thanks.
>
> Presumably you didn't put it on your path, or you used a non-standard 
> way to build.? You need to say what command you used.
>
> Duncan Murdoch


From @yen04 @end|ng |rom gm@||@com  Tue Apr 28 17:02:34 2020
From: @yen04 @end|ng |rom gm@||@com (Steven Yen)
Date: Tue, 28 Apr 2020 23:02:34 +0800
Subject: [R] Rtools required
In-Reply-To: <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
Message-ID: <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>

In RStudio, I enter File -> Open Project -> and browse to open a .Rproj 
file. Then, I click Build -> Build Binary Package. Thanks.

On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
> On 28/04/2020 9:56 a.m., Steven Yen wrote:
>> Thanks. I visited the Rtools web page and learned to run the following
>> lines. I am still getting the same warning message.
>
> And you are still not telling us what command you used to trigger that 
> message.
>
> Duncan Murdoch
>
>>
>> ? > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>> "~/.Renviron")
>> ? > Sys.which("make")
>> ? ????????????????????????????? make
>> "C:\\rtools40\\usr\\bin\\make.exe"
>>
>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>>> Dear All
>>>>
>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
>>>> the new default folder c:\rtools40). While compiling a package 
>>>> (binary)
>>>> I received the follow marning message saying Rtools is required. Any
>>>> clues? Thanks.
>>>
>>> Presumably you didn't put it on your path, or you used a non-standard
>>> way to build.? You need to say what command you used.
>>>
>>> Duncan Murdoch
>


From @yen04 @end|ng |rom gm@||@com  Tue Apr 28 17:16:49 2020
From: @yen04 @end|ng |rom gm@||@com (Steven Yen)
Date: Tue, 28 Apr 2020 23:16:49 +0800
Subject: [R] Rtools required
In-Reply-To: <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
 <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
 <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>
Message-ID: <55d211a5-88fc-eaf7-0fb2-8ea556d5e98e@gmail.com>

Thanks. Can you kindly tell me what to read to do it the "standard way"? 
Also, where can I find file .Renviron.

On 2020/4/28 ?? 11:08, Duncan Murdoch wrote:
> On 28/04/2020 11:02 a.m., Steven Yen wrote:
>> In RStudio, I enter File -> Open Project -> and browse to open a .Rproj
>> file. Then, I click Build -> Build Binary Package. Thanks.
>
> Do it the standard way instead of using devtools.
>
> Duncan Murdoch
>
>>
>> On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
>>> On 28/04/2020 9:56 a.m., Steven Yen wrote:
>>>> Thanks. I visited the Rtools web page and learned to run the following
>>>> lines. I am still getting the same warning message.
>>>
>>> And you are still not telling us what command you used to trigger that
>>> message.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> ?? > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>>>> "~/.Renviron")
>>>> ?? > Sys.which("make")
>>>> ?? ????????????????????????????? make
>>>> "C:\\rtools40\\usr\\bin\\make.exe"
>>>>
>>>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>>>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>>>>> Dear All
>>>>>>
>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 
>>>>>> (to now
>>>>>> the new default folder c:\rtools40). While compiling a package
>>>>>> (binary)
>>>>>> I received the follow marning message saying Rtools is required. Any
>>>>>> clues? Thanks.
>>>>>
>>>>> Presumably you didn't put it on your path, or you used a non-standard
>>>>> way to build.? You need to say what command you used.
>>>>>
>>>>> Duncan Murdoch
>>>
>


From @yen04 @end|ng |rom gm@||@com  Tue Apr 28 17:37:57 2020
From: @yen04 @end|ng |rom gm@||@com (Steven Yen)
Date: Tue, 28 Apr 2020 23:37:57 +0800
Subject: [R] Rtools required
In-Reply-To: <9db9b9d0-867b-fa90-146c-f1b7145436c1@gmail.com>
References: <78f43411-97d3-69da-670e-02d9cbe22636@ntu.edu.tw>
 <7e8bd471-9c68-4cc3-2ec7-2b752201f157@gmail.com>
 <f8e820e6-36b7-72bb-c98a-8cecf11365a9@gmail.com>
 <9c075f0e-b4bf-cc07-69ee-80e2ac3e1cc1@gmail.com>
 <97a56470-a5f2-ce2e-dc9c-a15465f45564@gmail.com>
 <87f55507-97e1-8e4e-ca4e-333c48d60e6c@gmail.com>
 <55d211a5-88fc-eaf7-0fb2-8ea556d5e98e@gmail.com>
 <9db9b9d0-867b-fa90-146c-f1b7145436c1@gmail.com>
Message-ID: <358d2733-7646-5e3f-3fcd-b405e6bc877f@gmail.com>

Thanks. Updating RStudio to 1.2.5042 did fix the problem. Thank you!

On 2020/4/28 ?? 11:30, Duncan Murdoch wrote:
> On 28/04/2020 11:16 a.m., Steven Yen wrote:
>> Thanks. Can you kindly tell me what to read to do it the "standard way"?
>
> Start with ?INSTALL, and find more details in the Writing R Extensions 
> manual.? I believe RStudio can be configured to use those tools rather 
> than the devtools ones, but I don't know if it will still run its test 
> for Rtools if you do it that way.
>
> I imagine you can also update RStudio and all of your packages; 
> eventually that will work, if this is really the issue.
>
> Duncan Murdoch
>
>> Also, where can I find file .Renviron.
>>
>> On 2020/4/28 ?? 11:08, Duncan Murdoch wrote:
>>> On 28/04/2020 11:02 a.m., Steven Yen wrote:
>>>> In RStudio, I enter File -> Open Project -> and browse to open a 
>>>> .Rproj
>>>> file. Then, I click Build -> Build Binary Package. Thanks.
>>>
>>> Do it the standard way instead of using devtools.
>>>
>>> Duncan Murdoch
>>>
>>>>
>>>> On 2020/4/28 ?? 10:55, Duncan Murdoch wrote:
>>>>> On 28/04/2020 9:56 a.m., Steven Yen wrote:
>>>>>> Thanks. I visited the Rtools web page and learned to run the 
>>>>>> following
>>>>>> lines. I am still getting the same warning message.
>>>>>
>>>>> And you are still not telling us what command you used to trigger 
>>>>> that
>>>>> message.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> ??? > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>>>>>> "~/.Renviron")
>>>>>> ??? > Sys.which("make")
>>>>>> ??? ????????????????????????????? make
>>>>>> "C:\\rtools40\\usr\\bin\\make.exe"
>>>>>>
>>>>>> On 2020/4/28 ?? 08:39, Duncan Murdoch wrote:
>>>>>>> On 28/04/2020 5:57 a.m., Steven T. Yen wrote:
>>>>>>>> Dear All
>>>>>>>>
>>>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0
>>>>>>>> (to now
>>>>>>>> the new default folder c:\rtools40). While compiling a package
>>>>>>>> (binary)
>>>>>>>> I received the follow marning message saying Rtools is 
>>>>>>>> required. Any
>>>>>>>> clues? Thanks.
>>>>>>>
>>>>>>> Presumably you didn't put it on your path, or you used a 
>>>>>>> non-standard
>>>>>>> way to build.? You need to say what command you used.
>>>>>>>
>>>>>>> Duncan Murdoch
>>>>>
>>>
>


From rub@k @end|ng |rom m@th@@@u@dk  Wed Apr 29 13:04:01 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Wed, 29 Apr 2020 11:04:01 +0000
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <CAB8pepwxV1nyNKA85srFqxw=d5Fzb9k618d9=1tk1PRQdyb42A@mail.gmail.com>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
 <CAB8pepwxV1nyNKA85srFqxw=d5Fzb9k618d9=1tk1PRQdyb42A@mail.gmail.com>
Message-ID: <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>

Dear all,

I see two issues here:

1. A new user has a hard time finding and using a specific function in
spatstat. As package authors we are always interested in such reports
and we then try to improve documentation, which is indeed a very
important part of any software project. The package is **very**
actively developed and documented by mainly Adrian and to a lesser
extend by Rolf and I. All the other people listed as
"authors"/"contributors" have contributed things such as a single new
function, a bug report, a documentation improvement, etc. Many of them
might not even be aware that they are mentioned on this list. This list
has developed over many years, and it is unfortunate if it gives the
impression that a lot of people are ready to help within 24 hours of a
question being posted on the general R help list because we cannot give
such guarantee -- you will have better luck with GitHub, the `spatstat`
tag on stackoverflow or the R SIG-GEO mail list, but still no 24 hour
guarantee is provided.

2. Abby replies in a very impolite tone towards the spatstat authors
and suggests that the package isn't fit for CRAN, which I consider a
direct insult to Adrian and all the hard work he has done to keep a
very well-documented package on CRAN since 2002. It would have been
nice to get a constructive suggestion on how to improve documentation
rather than a message about the alleged poor quality of the spatstat
package based on the documentation of a single function. If anyone
(Abby?) has spare time available for going through the documentation
and suggest improvements, add cross references etc. that's most
welcome. However, we would like to receive any suggestions in normal
polite manner via the project's GitHub page or by direct email to the
authors.

Regards,
Ege

On Wed, 2020-04-29 at 17:31 +1200, Abby Spurdle wrote:
> I should have noted that my comments weren't directed towards the
> main
> authors, but to all people listed in the description file, which is
> many, including some R core members.
> 
> Also, overall, I'm impressed by the effort here. It's just I strongly
> feel that good documentation is crucial (especially in open source),
> and I was somewhat disappointed that, given how many people are/were
> involved in this package, not one (after approx 24 hours) had tried
> to
> help answer the OP's question.
> 
> > > *If* it does what it claims ...
> > 
> > Why would you doubt that it does what it claims?
> 
> Because I didn't test it.
> 
> > Wouldn't the first thing that one would try be:
> >    ??"pp3"
> 
> No, because I was reading the PDF version of the documentation.
> 
> > Of course I'm biased, but IMHO spatstat is documented not only
> > "properly", but superbly well! :-)
> 
> I started reading the pcf function first.
> This function has the same problem, it doesn't clearly describe the
> function arguments.
> It doesn't say whether it applies to 2d, 3d or higher-dimensional
> data.
> After reading it, I had no idea whether the function could be applied
> to 3d data or not.
> 
> In my opinion this is not sufficient.
> Descriptions of function arguments and return values should be clear.
> 
> But here's a bigger problem.
> The documentation says the pcf function is a generic, but the pcf3est
> function isn't a method.
> And the pcf documentation (along with the three methods) don't
> reference the pcf3est function.
> 
> I found the pcf function via Googling the subject.
> But unless someone goes through a list of all the help topics,
> they're
> unlikely to find the pcf3est function.
-- 
Ege Rubak, Associate Professor,
Department of Mathematical Sciences, Aalborg University
Skjernvej 4A, 9220 Aalborg East, Denmark
Phone: (+45)99408861
Mobile: (+45)30230252
Email: rubak at math.aau.dk

From ch@kr@r@hu| @end|ng |rom gm@||@com  Wed Apr 29 21:13:49 2020
From: ch@kr@r@hu| @end|ng |rom gm@||@com (Rahul Chakraborty)
Date: Thu, 30 Apr 2020 00:43:49 +0530
Subject: [R] Designing a Fractional Factorial Design in R
Message-ID: <CAEmZPSmSLXUC3EtJNUZ=_94uEFX6tuEp+f1g+QbxrvfTR=QXXA@mail.gmail.com>

Dear all,

Presently I am working on designing a questionnaire for my discrete choice
experiment. I intend to use R for the "fractional factorial design". I have
the following objective-

The respondent has to choose one out of 4 objects. Each of the 4 objects
are classified by 5 different attributes. However, the levels are not the
same under each of the objects. For example, the table below displays first
three attributes and corresponding values of levels.

                   Object1             Object2                Object3
           Object4
Attribute1       100              80, 100, 120        120, 140, 160
120, 140, 160
Attribute2    100,80,120     100,80,60,40          80,60,40
75, 50, 25
Atrribute3       100                   100                     100,75
           75, 50, 20, 10

In this scenario, as you can see the number and values of levels for each
attribute may vary across different objects. Given this scenario which
package should I use to implement a fractional factorial design? Any help
would be highly appreciated.

Thanking you,

-- Regards,
Rahul Chakraborty
Research Fellow
National Institute of Public Finance and Policy
New Delhi- 110067

	[[alternative HTML version deleted]]


From rub@k @end|ng |rom m@th@@@u@dk  Wed Apr 29 21:35:27 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Wed, 29 Apr 2020 19:35:27 +0000
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <CAJc=yOFu+mfzxVbMj41pvEVC0g7fxdsHKx-XoZCFOzW_4w37vg@mail.gmail.com>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
 <CAJc=yOFu+mfzxVbMj41pvEVC0g7fxdsHKx-XoZCFOzW_4w37vg@mail.gmail.com>
Message-ID: <66b8bbe419ad2cea6e3042bd8217a26d0027f26f.camel@math.aau.dk>

Or if you prefer not to load an entire suite of packages to do such a
simple task you could use

b$PHENO <- ifelse(...)

or in this specific case it seems sufficient to do

b$PHENO <- pmax(b$FLASER, b$PLASER)

/Ege

On Wed, 2020-04-29 at 15:30 -0400, Patrick (Malone Quantitative) wrote:
> If you don't mind using tidyverse, you can do this easily with
> if_else.
> 
> b$PHENO<-if_else(...
> 
> 
> 
> On Wed, Apr 29, 2020 at 3:21 PM Ana Marija <
> sokovic.anamarija at gmail.com>
> wrote:
> 
> > Hello,
> > 
> > I have a data frame like this:
> > 
> > > head(b)
> > 
> >        FID          IID FLASER PLASER
> > 1: fam1000 G1000      1      1
> > 2: fam1001 G1001      1      1
> > 3: fam1003 G1003      1      2
> > 4: fam1005 G1005      1      1
> > 5: fam1009 G1009      2      1
> > 6: fam1052 G1052      1      1
> > ...
> > 
> > My conditions for creating a new column PHENO would be this:
> > 
> > if FLASER or PLASER =2 then PHENO=2
> > otherwise PHENO=1
> > 
> > so result would look like this:
> > 
> > > head(b)
> > 
> >        FID          IID FLASER PLASER PHENO
> > 1: fam1000 G1000      1      1            1
> > 2: fam1001 G1001      1      1            1
> > 3: fam1003 G1003      1      2            2
> > 4: fam1005 G1005      1      1            1
> > 5: fam1009 G1009      2      1             2
> > 6: fam1052 G1052      1      1             1
> > ...
> > 
> > Thanks
> > Ana
> > ...
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > 
> 
> 
-- 
Ege Rubak, Associate Professor,
Department of Mathematical Sciences, Aalborg University
Skjernvej 4A, 9220 Aalborg East, Denmark
Phone: (+45)99408861
Mobile: (+45)30230252
Email: rubak at math.aau.dk

From rub@k @end|ng |rom m@th@@@u@dk  Wed Apr 29 22:30:31 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Wed, 29 Apr 2020 20:30:31 +0000
Subject: [R] [FORGED] Re: pair correlation function of 3D points
In-Reply-To: <CAB8pepx6jwjoxcM7xAsBKJgihgizqL-b4OM958SSdr9e9_GOYQ@mail.gmail.com>
References: <39a11120-d74a-7b12-adb8-2846096066f2@icmpe.cnrs.fr>
 <CAB8pepxiTizYZdE07cKnWu_B32P-1s+M+cOuGo04NNX2wjCN8A@mail.gmail.com>
 <ac8e7e5d-a4e2-849b-59b7-6f7a7b4dc44d@auckland.ac.nz>
 <755C0845-240E-4EDA-8C20-54EAD1CFA295@dcn.davis.ca.us>
 <MEAPR01MB2232395E53EC5AD4631C2F7BA4AD0@MEAPR01MB2232.ausprd01.prod.outlook.com>
 <CAB8pepx6jwjoxcM7xAsBKJgihgizqL-b4OM958SSdr9e9_GOYQ@mail.gmail.com>
Message-ID: <a1443268b7d9ed4da0f7d203a8a794a42a31bc84.camel@math.aau.dk>

Hi Abby,

Once again I must say your form of communication puzzles me. Do you
believe it benefits the open source community to communicate like this?
What about contacting the package maintainer in this way:

"Hi, I was helping someone else using your package to estimate a pair
correlation function. I was really puzzled that the generel help page
for `pcf` said it was a generic, but it doesn't seem to be generic for
the three dimensional case we needed, and no reference was given from
`pcf` to `pcf3est` which I had to search around to find. Maybe you
should consider throwing in a few cross references. Have a nice day."

I think this all would have played out much nicer then. None of us were
ignoring the original poster. We simply weren't aware of the OPs
problem until Rolf discovered it. I think Adrian and I focus on more
spatstat devoted channels to maximize the benefit of our time.

Regarding splitting the package into smaller pieces the thought has
occurred to us without your helpful suggestion. We started the process
of doing so years ago with the introduction of `spatstat.utils` and
`spatstat.data`. This is well documented on the spatstat GitHub page
referenced in the DESCRIPTION file. However, we have to prioritize our
time and it is quite a complex task to split out the relevant parts in
standalone packages due to all the interdependencies of the existing
code.

On a final note, to give you another example of a way to bring
attention to possible improvements of documentation: Let's say I was
looking at the function `marginal.set` in the package `probhat`, then I
would contact the author and say:

"Hi Abby, I was looking at the help for `marginal.set` and I couldn't
quite figure out what the argument constructor was supposed to be. The
help doesn't mention any class and contains no cross references
whatsoever and searching for 'constructor' in the R help system didn't
lead anywhere. Maybe a few cross references and actual usage of the
section 'See Also' would be beneficial for new users of your package.
It would be much better if instead of making assumptions about
assumptions you just use hyperlinks. Have a nice day. Kind regards,
Ege"

Where of course I would never use the sentence about hyperlinks in a
real example. I guess at this point I dug myself into the hole of bad
communication which is so killing for good software projects so
apologies for that. I do wish you a good day and hope you will consider
helping us all improve the state of open source software by
constructive suggestions rather than us claiming that each others
packages are unfit for CRAN.

Kind regards,
Ege

On Thu, 2020-04-30 at 06:53 +1200, Abby Spurdle wrote:
> NOTE CITATIONS USE BRIEF EXCERPTS
> 
> > It's a complaint that no-one responded to your query within 24
> > hours.
> 
> Correction, it wasn't my query.
> I was replying to someone else's query.
> 
> > Finally, you cast doubt on whether the function pcf3est actually
> > does calculate...
> 
> You've taken what I said out of context.
> As I said in my response to Rolf, I didn't run the code.
> 
> > email from CRAN requesting me to please cut down the size of the
> > spatstat package
> 
> I can't speak on behalf on CRAN.
> But reiterating what I said earlier, you'd be better to create
> smaller
> packages, each with a more specific focus.
> Each package could have an unofficial co-maintainer to help you out.
> 
> > You complain that the documentation is insufficient, but at the
> > same time, you complain that the manual is too long (> 1700 pages)
> > and you seem unwilling to search the documentation or follow cross-
> > references.
> 
> Did you read my posts...
> 
> The functions DO NOT cross-reference.
> The pcf generic/methods DO NOT reference the pcf3est function, at
> all.
> The pcf3est function DOES NOT reference the pp3 function, but rather
> references the class of the object.
> 
> Also, the seealso sections are minimalist.
> 
> If you are not going to create smaller packages, then the least you
> could do it improve the standard of the seealso sections and
> cross-referencing.
> 
> Furthermore, if functions are not cross-referenced, the reader (I
> this
> case me) doesn't necessarily know what package those functions are
> defined in.
> You assume that readers will assume the functions are defined in your
> package, and then do a search for them.
> 
> Instead of making assumptions about assumptions, just use
> hyperlinks...
> 
> > > I was somewhat disappointed ... not one (after approx 24 hours)
> > > had tried to
> > > help answer the OP's question.
> > 
> > Seriously?
> 
> Yes, seriously.
> From my experiences, if people don't reply to an R-help question in
> the first 24 hours, chances that they will reply later are low.
> Also, I've found a bias on this forum, with few replies to
> physics-related questions.
> 
> Personally, I like physicists, one of the most under-valued
> professions on the planet.
> 
> > I found the pcf function via Googling the subject.
> > I don't want to be rude, but this seems pretty lazy.
> > Try Googling  'spatstat pair correlation function three dimensions'
> 
> That sounds like a contradiction.
> 
> Also, it's off the mark, given that I was the only one who attempted
> to answer the OPs question.
-- 
Ege Rubak, Associate Professor,
Department of Mathematical Sciences, Aalborg University
Skjernvej 4A, 9220 Aalborg East, Denmark
Phone: (+45)99408861
Mobile: (+45)30230252
Email: rubak at math.aau.dk

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Apr 29 23:44:22 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 29 Apr 2020 16:44:22 -0500
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <1e93298e-2f3f-d280-af2c-fe01dd11b656@sapo.pt>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
 <20200429223634.5923b4f0@Tarkus>
 <CAF9-5jO6cUzOmvPkctJtXu-jYS5gLHnqxx5ngOSYMsFqQgfYfQ@mail.gmail.com>
 <1e93298e-2f3f-d280-af2c-fe01dd11b656@sapo.pt>
Message-ID: <CAF9-5jOx7v_ZW3ngpCY2SW1VNKyAxu=z_ddJkpePSDsapC2nug@mail.gmail.com>

Hi Rui,

thanks for getting back to me
so I tried your method and I got:
> sum(b$PHENO==2, na.rm=T)
[1] 828
> sum(b$PHENO==1, na.rm=T)
[1] 859

Can you please tell me if
b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L

just assigns PHENO=2 if b$FLASER == 2 | b$PLASER == 2 and everything else is 1?

Please see how my data looks like:
> sum(b$FLASER==2, na.rm=T)
[1] 92
> sum(b$FLASER==1, na.rm=T)
[1] 1533
> sum(b$PLASER==1, na.rm=T)
[1] 850
> sum(b$PLASER==2, na.rm=T)
[1] 806
> dim(b)
[1] 1698    5
> unique(b$FLASER)
[1]  1  3  2 NA
> unique(b$PLASER)
[1]  1  2  3 NA

On Wed, Apr 29, 2020 at 4:10 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Here is another way. The condition returns FALSE/TRUE or 0/1. Add 1 to
> get the expected result.
> It has the advantage of being faster.
>
> b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 20:42 de 29/04/20, Ana Marija escreveu:
> > Thanks, I did this:
> > b$PHENO<- ifelse(b$FLASER ==2 | b$PLASER ==2, 2, 1)
> >
> > On Wed, Apr 29, 2020 at 2:36 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> >>
> >> On Wed, 29 Apr 2020 14:19:18 -0500
> >> Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >>
> >>> My conditions for creating a new column PHENO would be this:
> >>>
> >>> if FLASER or PLASER =2 then PHENO=2
> >>> otherwise PHENO=1
> >>
> >> On Wed, 29 Apr 2020 15:30:45 -0400
> >> "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
> >>
> >>> If you don't mind using tidyverse, you can do this easily with
> >>> if_else.
> >>
> >> ...and if you want to stay with base R, you can use the ifelse
> >> function.
> >>
> >> --
> >> Best regards,
> >> Ivan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From you@r|@|@nou@ @end|ng |rom gm@||@com  Wed Apr 29 23:49:20 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Wed, 29 Apr 2020 17:49:20 -0400
Subject: [R] [FORGED]  what is the expected behavior of layout.show(n)
In-Reply-To: <cead75a0-2ce4-4489-2a14-0d2bee98fcc8@stat.auckland.ac.nz>
References: <CADsEwSf1NGsUYZR5T9WG+hwqgdkPTCMMC-pzFgxO3tZaP6Cd6A@mail.gmail.com>
 <cead75a0-2ce4-4489-2a14-0d2bee98fcc8@stat.auckland.ac.nz>
Message-ID: <CADsEwScuG_YywUNs-2H8zc4sf3kywcptzRZHz-23MnJydztAag@mail.gmail.com>

Thank you

Yousri

On Wed, Apr 29, 2020 at 5:12 PM Paul Murrell <paul at stat.auckland.ac.nz>
wrote:

> Hi
>
> This behaviour is as expected.
>
> The layout.show() function is just there to help visualise what the
> layout will look like.
>
> So for testing purposes, you would do something like ...
>
> layout(...)
> layout.show(n)
>
> Then to actually use the layout, you would do something like ...
>
> layout(...)
> plot(...)
> plot(...)
> plot(...)
>
> Paul
>
> On 30/04/20 1:09 am, Yousri Fanous wrote:
> > This works as expected: Histograms 1-3 are displayed on the first row and
> > histograms 4 and 5 on the second row
> >
> > However when I use layout.show to check the layout , it appears that
> > layout.show(3) consumes the first 3 locations
> >
> >> layout(matrix(c(1,1,2,2,3,3,0,4,4,5,5,0),2,6,byrow=T),respect=F)
> >> layout.show(3)
> >> hist(sample[,1],main="Hist for sample I",xlab="sample 1",ylab="freq")
> >> hist(sample[,2],main="Hist for sample II",xlab="sample 2",ylab="freq")
> >> hist(sample[,3],main="Hist for sample III",xlab="sample 3",ylab="freq")
> >> hist(sample[,4],main="Hist for sample IV",xlab="sample 4",ylab="freq")
> >> hist(sample[,5],main="Hist for sample V",xlab="sample 5",ylab="freq")
> > Now the first row shows 3 empty rectangles and histogram 1 and 2 are
> > displayed on row 2 while histograms 3-5 are displayed on the top row in a
> > different graph / page
> >
> > If I use layout.show(5) then each histogram is displayed on a separate
> > sheet as if the layout was fully consumed
> >
> > Few questions here:
> > 1) in case of layout.show(3) why the layout was still remembered /
> recycled
> > 2) with layout.show(5) why was the layout totally dismissed. I expected
> at
> > least it would restart over with 3 graphs in first row and 2 graphs in
> > second row to be consistent in behavior with layout.show(3)
> > 3) layout.show(x) purpose is to check if my layout is correct. It must
> not
> > leave any side effect on the main plots.
> >  From the help of function layout this line relates to layout.show
> >
> > layout.show(n) plots (part of) the current layout, namely the outlines of
> > the next n figures.
> >
> > It does not describe the behavior I am seeing
> >
> > 4) Finally is there a way to undo the effect of layout.show except
> re-enter
> > my layout again?
> >
> > Yousri
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 29 23:49:32 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Apr 2020 14:49:32 -0700
Subject: [R] Rtools required
In-Reply-To: <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
Message-ID: <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>

Type
?.Renviron
?R.home
?"environment variables"

at the R prompt to get what I think should be the info you need (or at
least useful info).


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>
> Thanks John. Where is file .Renviron located? It must be a hidden file.
> I cannot find it.
>
> On 2020/4/28 ?? 08:29, Fox, John wrote:
> > Dear Steven,
> >
> > Did you follow the instruction on the Rtools webpage to add
> >
> >       PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
> >
> > to your .Renviron file?
> >
> > I hope this helps,
> >   John
> >
> >    -----------------------------
> >    John Fox, Professor Emeritus
> >    McMaster University
> >    Hamilton, Ontario, Canada
> >    Web: http::/socserv.mcmaster.ca/jfox
> >
> >> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> >>
> >> Dear All
> >>
> >> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to now
> >> the new default folder c:\rtools40). While compiling a package (binary)
> >> I received the follow marning message saying Rtools is required. Any
> >> clues? Thanks.
> >>
> >> Steven Yen
> >>
> >> WARNING: Rtools is required to build R packages but is not currently
> >> installed. Please download and install the appropriate version of Rtools
> >> before proceeding: https://cran.rstudio.com/bin/windows/Rtools/
> >>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 29 23:51:58 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Apr 2020 14:51:58 -0700
Subject: [R] Designing a Fractional Factorial Design in R
In-Reply-To: <CAEmZPSmSLXUC3EtJNUZ=_94uEFX6tuEp+f1g+QbxrvfTR=QXXA@mail.gmail.com>
References: <CAEmZPSmSLXUC3EtJNUZ=_94uEFX6tuEp+f1g+QbxrvfTR=QXXA@mail.gmail.com>
Message-ID: <CAGxFJbQ4yAckokyaGnGWT=x8Dp8FMOwu8OmDZ=Gthh_7tEqK2A@mail.gmail.com>

https://CRAN.R-project.org/view=ExperimentalDesign

For many R experimental design packages. You might wish to bookmark
the CRAN task view page.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 29, 2020 at 2:39 PM Rahul Chakraborty <chakrarahul at gmail.com> wrote:
>
> Dear all,
>
> Presently I am working on designing a questionnaire for my discrete choice
> experiment. I intend to use R for the "fractional factorial design". I have
> the following objective-
>
> The respondent has to choose one out of 4 objects. Each of the 4 objects
> are classified by 5 different attributes. However, the levels are not the
> same under each of the objects. For example, the table below displays first
> three attributes and corresponding values of levels.
>
>                    Object1             Object2                Object3
>            Object4
> Attribute1       100              80, 100, 120        120, 140, 160
> 120, 140, 160
> Attribute2    100,80,120     100,80,60,40          80,60,40
> 75, 50, 25
> Atrribute3       100                   100                     100,75
>            75, 50, 20, 10
>
> In this scenario, as you can see the number and values of levels for each
> attribute may vary across different objects. Given this scenario which
> package should I use to implement a fractional factorial design? Any help
> would be highly appreciated.
>
> Thanking you,
>
> -- Regards,
> Rahul Chakraborty
> Research Fellow
> National Institute of Public Finance and Policy
> New Delhi- 110067
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Apr 30 00:20:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 29 Apr 2020 17:20:16 -0500
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <11bec6c3-fb14-4399-9c03-67bf11587d0e@email.android.com>
References: <CAF9-5jOx7v_ZW3ngpCY2SW1VNKyAxu=z_ddJkpePSDsapC2nug@mail.gmail.com>
 <11bec6c3-fb14-4399-9c03-67bf11587d0e@email.android.com>
Message-ID: <CAF9-5jPFF6EaEOAq8Ze9BRwnN6vayuUDqaYhsBpfXLF=N-Ui8w@mail.gmail.com>

Thank you so much, numbers add up now!

On Wed, Apr 29, 2020 at 5:09 PM <cpolwart at chemo.org.uk> wrote:
>
> While I've sent you a maths way to do it,
>
> I'd probably take this approach;
>
> # set b$pheno to 1 as default
>
> b$pheno <- 1
>
> # set the flaser
>
> b$pheno[b$flaser == 2] <- 2
>
> #set the plaser
>
> b$pheno[b$plaser == 2] <- 2
>
>
> On 29 Apr 2020 22:44, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Rui,
>
> thanks for getting back to me
> so I tried your method and I got:
> > sum(b$PHENO==2, na.rm=T)
> [1] 828
> > sum(b$PHENO==1, na.rm=T)
> [1] 859
>
> Can you please tell me if
> b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L
>
> just assigns PHENO=2 if b$FLASER == 2 | b$PLASER == 2 and everything else is 1?
>
> Please see how my data looks like:
> > sum(b$FLASER==2, na.rm=T)
> [1] 92
> > sum(b$FLASER==1, na.rm=T)
> [1] 1533
> > sum(b$PLASER==1, na.rm=T)
> [1] 850
> > sum(b$PLASER==2, na.rm=T)
> [1] 806
> > dim(b)
> [1] 1698    5
> > unique(b$FLASER)
> [1]  1  3  2 NA
> > unique(b$PLASER)
> [1]  1  2  3 NA
>
> On Wed, Apr 29, 2020 at 4:10 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Here is another way. The condition returns FALSE/TRUE or 0/1. Add 1 to
> > get the expected result.
> > It has the advantage of being faster.
> >
> > b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 20:42 de 29/04/20, Ana Marija escreveu:
> > > Thanks, I did this:
> > > b$PHENO<- ifelse(b$FLASER ==2 | b$PLASER ==2, 2, 1)
> > >
> > > On Wed, Apr 29, 2020 at 2:36 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
> > >>
> > >> On Wed, 29 Apr 2020 14:19:18 -0500
> > >> Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >>
> > >>> My conditions for creating a new column PHENO would be this:
> > >>>
> > >>> if FLASER or PLASER =2 then PHENO=2
> > >>> otherwise PHENO=1
> > >>
> > >> On Wed, 29 Apr 2020 15:30:45 -0400
> > >> "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
> > >>
> > >>> If you don't mind using tidyverse, you can do this easily with
> > >>> if_else.
> > >>
> > >> ...and if you want to stay with base R, you can use the ifelse
> > >> function.
> > >>
> > >> --
> > >> Best regards,
> > >> Ivan
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 30 00:30:31 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 29 Apr 2020 22:30:31 +0000
Subject: [R] Rtools required
In-Reply-To: <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Steven,

It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).

Best,
 John

> -----Original Message-----
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Wednesday, April 29, 2020 5:50 PM
> To: Steven <syen at hqu.edu.cn>
> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
> project.org>
> Subject: Re: [R] Rtools required
> 
> Type
> ?.Renviron
> ?R.home
> ?"environment variables"
> 
> at the R prompt to get what I think should be the info you need (or at
> least useful info).
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
> >
> > Thanks John. Where is file .Renviron located? It must be a hidden file.
> > I cannot find it.
> >
> > On 2020/4/28 ?? 08:29, Fox, John wrote:
> > > Dear Steven,
> > >
> > > Did you follow the instruction on the Rtools webpage to add
> > >
> > >       PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
> > >
> > > to your .Renviron file?
> > >
> > > I hope this helps,
> > >   John
> > >
> > >    -----------------------------
> > >    John Fox, Professor Emeritus
> > >    McMaster University
> > >    Hamilton, Ontario, Canada
> > >    Web: http::/socserv.mcmaster.ca/jfox
> > >
> > >> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> > >>
> > >> Dear All
> > >>
> > >> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
> > >> now the new default folder c:\rtools40). While compiling a package
> > >> (binary) I received the follow marning message saying Rtools is
> > >> required. Any clues? Thanks.
> > >>
> > >> Steven Yen
> > >>
> > >> WARNING: Rtools is required to build R packages but is not
> > >> currently installed. Please download and install the appropriate
> > >> version of Rtools before proceeding:
> > >> https://cran.rstudio.com/bin/windows/Rtools/
> > >>
> > >>
> > >>      [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Apr 30 00:42:46 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 30 Apr 2020 10:42:46 +1200
Subject: [R] [FORGED] Re:  pair correlation function of 3D points
In-Reply-To: <F5F41F99-A6C7-42D8-A197-C4A532C1123B@icmpe.cnrs.fr>
References: <07f9c7f7f729a3a9bf641fd67fd8a165f7d799e5.camel@math.aau.dk>
 <F5F41F99-A6C7-42D8-A197-C4A532C1123B@icmpe.cnrs.fr>
Message-ID: <e2fdd5e8-2d1e-a07e-e5ed-4163380c0e17@auckland.ac.nz>


On 30/04/20 12:28 am, Eric Leroy wrote:

> Dear all, I am sorry to see all the reactions I provoked from a
> newbie user. Anyway, thank you for the answer I think that the
> pcf3est function responds to my question.
> Indeed the spatstat is a very impressive library and I am very grateful to the the developers.

(1) Not to worry.  Certainly not your fault!

(2) I'm glad that the pcf3est() function was useful to you.

(3) Thank you for your kind words about spatstat.

(4) But *please* --- spatstat is a *package* not a "library"!!!  A 
library is a *collection* of packages; the library() function "checks 
out" a package from a library, like checking a book out of a "real" 
library (biblioth?que en fran?ais, just in case there is any confusion, 
"library" and "libraire" being false cognates).  But I'm sure you knew that.

I know that insisting on this distinction is being pedantic --- but it 
never hurts to get things right!  And saying "library" when you mean 
"package" upsets Martin Maechler!!! :-)

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From henr|k@bengt@@on @end|ng |rom gm@||@com  Thu Apr 30 00:44:59 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Wed, 29 Apr 2020 15:44:59 -0700
Subject: [R] Rtools required
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAFDcVCR+gqEnG6DY1-PJsAc6A_HYxSq=dyxRwq7yoaaGJ3Vm+A@mail.gmail.com>

Careful so you don't overwrite an existing ~/.Renviron file; it's safer to
use something like:

cat('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"\n', file="~/.Renviron"
append=TRUE)

/Henrik




On Wed, Apr 29, 2020, 15:33 Fox, John <jfox at mcmaster.ca> wrote:

> Dear Steven,
>
> It's possible that Windows will hide .Renviron, but it's generally a good
> idea, in my opinion, in Folder Options > View to click "Show hidden files"
> and uncheck "hide extensions". Then .Renviron should show up (once you've
> created it).
>
> Best,
>  John
>
> > -----Original Message-----
> > From: Bert Gunter <bgunter.4567 at gmail.com>
> > Sent: Wednesday, April 29, 2020 5:50 PM
> > To: Steven <syen at hqu.edu.cn>
> > Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
> > project.org>
> > Subject: Re: [R] Rtools required
> >
> > Type
> > ?.Renviron
> > ?R.home
> > ?"environment variables"
> >
> > at the R prompt to get what I think should be the info you need (or at
> > least useful info).
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
> > >
> > > Thanks John. Where is file .Renviron located? It must be a hidden file.
> > > I cannot find it.
> > >
> > > On 2020/4/28 ?? 08:29, Fox, John wrote:
> > > > Dear Steven,
> > > >
> > > > Did you follow the instruction on the Rtools webpage to add
> > > >
> > > >       PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
> > > >
> > > > to your .Renviron file?
> > > >
> > > > I hope this helps,
> > > >   John
> > > >
> > > >    -----------------------------
> > > >    John Fox, Professor Emeritus
> > > >    McMaster University
> > > >    Hamilton, Ontario, Canada
> > > >    Web: http::/socserv.mcmaster.ca/jfox
> > > >
> > > >> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> > > >>
> > > >> Dear All
> > > >>
> > > >> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
> > > >> now the new default folder c:\rtools40). While compiling a package
> > > >> (binary) I received the follow marning message saying Rtools is
> > > >> required. Any clues? Thanks.
> > > >>
> > > >> Steven Yen
> > > >>
> > > >> WARNING: Rtools is required to build R packages but is not
> > > >> currently installed. Please download and install the appropriate
> > > >> version of Rtools before proceeding:
> > > >> https://cran.rstudio.com/bin/windows/Rtools/
> > > >>
> > > >>
> > > >>      [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide
> > > >> http://www.R-project.org/posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Apr 30 01:55:21 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (ProfJCNash)
Date: Wed, 29 Apr 2020 19:55:21 -0400
Subject: [R] repository for ubuntu/linux mint for R 4.0.0
Message-ID: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>

In updating (an older computer with) Linux Mint 18.3 I tried to add
the repository

deb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/

as per the "Download R for Linux" instructions. This gave an error
that there was no Release.key file.

After some investigation, I found that

deb https://cran.r-project.org/bin/linux/ubuntu xenial-cran40/

i.e., CRAN not CLOUD. With this change, I could install R 4.0.

Is this a known glitch?

JN


From jen@r@@mu@ @end|ng |rom gm@||@com  Thu Apr 30 02:27:34 2020
From: jen@r@@mu@ @end|ng |rom gm@||@com (Rasmus Liland)
Date: Thu, 30 Apr 2020 02:27:34 +0200
Subject: [R] repository for ubuntu/linux mint for R 4.0.0
In-Reply-To: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>
References: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>
Message-ID: <20200430002643.GA654972@posteo.no>

On 2020-04-29 19:55 -0400, ProfJCNash wrote:
> In updating (an older computer with) Linux Mint 18.3 I tried to add
> the repository
> 
> deb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/
> 
> as per the "Download R for Linux" instructions. This gave an error
> that there was no Release.key file.
> 
> After some investigation, I found that
> 
> deb https://cran.r-project.org/bin/linux/ubuntu xenial-cran40/
> 
> i.e., CRAN not CLOUD. With this change, I could install R 4.0.
> 
> Is this a known glitch?

Dear JN,

perhaps it is a glitch ... does anyone run mirmon[1] on the R 
mirrors to see which ones are old?

If you open those two addresses in a browser, you see that the 
xenial-cran40 folder is only present in cran case ...  These are 
two different servers, which can also be seen by running curl:

	rasmus at twentyfive ~ % curl -I https://cloud.r-project.org/bin/linux/ubuntu/
	HTTP/2 200 
	content-type: text/html;charset=ISO-8859-1
	date: Thu, 30 Apr 2020 00:05:13 GMT
	server: Apache/2.4.39 (Unix)
	cache-control: max-age=1800
	expires: Thu, 30 Apr 2020 00:35:13 GMT
	x-cache: Miss from cloudfront
	...
	
	rasmus at twentyfive ~ % curl -I https://cran.r-project.org/bin/linux/ubuntu/
	HTTP/1.1 200 OK
	Date: Thu, 30 Apr 2020 00:05:23 GMT
	Server: Apache
	Content-Type: text/html;charset=UTF-8

It is wise to point your package manager to a mirror[2] close to you 
instead of a cdn, e.g. [3] or something ... 

Best,
Rasmus

[1] https://spacehopper.org/mirmon/
[2] https://cran.r-project.org/mirrors.html
[3] https://mirror.las.iastate.edu/CRAN/bin/linux/ubuntu/


From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 30 04:02:25 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 29 Apr 2020 19:02:25 -0700
Subject: [R] Rtools required
In-Reply-To: <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
 <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
Message-ID: <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>

Wouldn't packages that have to be built from source on installation
require Rtools?

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Apr 29, 2020 at 6:48 PM Steven <syen at hqu.edu.cn> wrote:
>
> Thanks to all - very helpful. I search from c:\ and now find file
> .Renviron located in C:\Users\USER\Documents. That does it.
>
> I would like to pose an additional question, since it would also fall
> under the same subject line. This is an RStudio question but since I am
> using the free version the RStudio folks would not help me.
>
> My students simply need to install packages and are not building any
> packages so they have no reason to install Rtools.
>
> When they install (not build) packages (from CRAN or file archive) they
> received the same warning message saying
>
> "Rtools required to build a package".
>
> This is nonsense of course as they are, as I said, simply installing. I
> tell them to user an older RStudio version, specifically 1.1.463 that's
> free of that warning. Any idea?
>
> Steven Yen
>
> On 2020/4/30 ?? 06:30, Fox, John wrote:
> > Dear Steven,
> >
> > It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).
> >
> > Best,
> >   John
> >
> >> -----Original Message-----
> >> From: Bert Gunter <bgunter.4567 at gmail.com>
> >> Sent: Wednesday, April 29, 2020 5:50 PM
> >> To: Steven <syen at hqu.edu.cn>
> >> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
> >> project.org>
> >> Subject: Re: [R] Rtools required
> >>
> >> Type
> >> ?.Renviron
> >> ?R.home
> >> ?"environment variables"
> >>
> >> at the R prompt to get what I think should be the info you need (or at
> >> least useful info).
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
> >>> Thanks John. Where is file .Renviron located? It must be a hidden file.
> >>> I cannot find it.
> >>>
> >>> On 2020/4/28 ?? 08:29, Fox, John wrote:
> >>>> Dear Steven,
> >>>>
> >>>> Did you follow the instruction on the Rtools webpage to add
> >>>>
> >>>>        PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
> >>>>
> >>>> to your .Renviron file?
> >>>>
> >>>> I hope this helps,
> >>>>    John
> >>>>
> >>>>     -----------------------------
> >>>>     John Fox, Professor Emeritus
> >>>>     McMaster University
> >>>>     Hamilton, Ontario, Canada
> >>>>     Web: http::/socserv.mcmaster.ca/jfox
> >>>>
> >>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
> >>>>>
> >>>>> Dear All
> >>>>>
> >>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
> >>>>> now the new default folder c:\rtools40). While compiling a package
> >>>>> (binary) I received the follow marning message saying Rtools is
> >>>>> required. Any clues? Thanks.
> >>>>>
> >>>>> Steven Yen
> >>>>>
> >>>>> WARNING: Rtools is required to build R packages but is not
> >>>>> currently installed. Please download and install the appropriate
> >>>>> version of Rtools before proceeding:
> >>>>> https://cran.rstudio.com/bin/windows/Rtools/
> >>>>>
> >>>>>
> >>>>>       [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Thu Apr 30 04:20:10 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Wed, 29 Apr 2020 21:20:10 -0500
Subject: [R] Rtools required
In-Reply-To: <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
 <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
 <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>
Message-ID: <99f4e613-9063-eadd-0b6a-8dd834303d1e@effectivedefense.org>

 ????? I just encountered something that looks exactly like that with R 
4.0.0 and the latest RStudio AND with Rtools40 installed under Windows 
10 (AND some manual adjustment of the path to delete references to old 
versions of Rtools and make sure Rtools40 was there).


 ????? I got around it by have Rtools40 installed AND running 
"install.packages('xmlw')" inside R 4.0.0 inside a CMD prompt.? That 
worked, even though the same command inside RStudio failed with:


WARNING:? Rtools is required to build an R package but no version of 
Rtools compatible with the currently running version of R was found.? 
Note that the following incompatible version(s) of Rtools were found:

 ????? - Rtools 3.5 (installed at C:\Rtools).


 ????? I got this message after deleting references to C:\Rtools from 
the path and rebooting.


*** I BELIEVE YOU NEED Rtools40 installed, because binaries for some 
packages are not (yet) available for R 4.0.0.


 ????? Hope this helps.
 ????? Spencer Graves


On 2020-04-29 21:02, Bert Gunter wrote:
> Wouldn't packages that have to be built from source on installation
> require Rtools?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Apr 29, 2020 at 6:48 PM Steven <syen at hqu.edu.cn> wrote:
>> Thanks to all - very helpful. I search from c:\ and now find file
>> .Renviron located in C:\Users\USER\Documents. That does it.
>>
>> I would like to pose an additional question, since it would also fall
>> under the same subject line. This is an RStudio question but since I am
>> using the free version the RStudio folks would not help me.
>>
>> My students simply need to install packages and are not building any
>> packages so they have no reason to install Rtools.
>>
>> When they install (not build) packages (from CRAN or file archive) they
>> received the same warning message saying
>>
>> "Rtools required to build a package".
>>
>> This is nonsense of course as they are, as I said, simply installing. I
>> tell them to user an older RStudio version, specifically 1.1.463 that's
>> free of that warning. Any idea?
>>
>> Steven Yen
>>
>> On 2020/4/30 ?? 06:30, Fox, John wrote:
>>> Dear Steven,
>>>
>>> It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).
>>>
>>> Best,
>>>    John
>>>
>>>> -----Original Message-----
>>>> From: Bert Gunter <bgunter.4567 at gmail.com>
>>>> Sent: Wednesday, April 29, 2020 5:50 PM
>>>> To: Steven <syen at hqu.edu.cn>
>>>> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
>>>> project.org>
>>>> Subject: Re: [R] Rtools required
>>>>
>>>> Type
>>>> ?.Renviron
>>>> ?R.home
>>>> ?"environment variables"
>>>>
>>>> at the R prompt to get what I think should be the info you need (or at
>>>> least useful info).
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>>>>> Thanks John. Where is file .Renviron located? It must be a hidden file.
>>>>> I cannot find it.
>>>>>
>>>>> On 2020/4/28 ?? 08:29, Fox, John wrote:
>>>>>> Dear Steven,
>>>>>>
>>>>>> Did you follow the instruction on the Rtools webpage to add
>>>>>>
>>>>>>         PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>>>>>>
>>>>>> to your .Renviron file?
>>>>>>
>>>>>> I hope this helps,
>>>>>>     John
>>>>>>
>>>>>>      -----------------------------
>>>>>>      John Fox, Professor Emeritus
>>>>>>      McMaster University
>>>>>>      Hamilton, Ontario, Canada
>>>>>>      Web: http::/socserv.mcmaster.ca/jfox
>>>>>>
>>>>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>>>>>>
>>>>>>> Dear All
>>>>>>>
>>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
>>>>>>> now the new default folder c:\rtools40). While compiling a package
>>>>>>> (binary) I received the follow marning message saying Rtools is
>>>>>>> required. Any clues? Thanks.
>>>>>>>
>>>>>>> Steven Yen
>>>>>>>
>>>>>>> WARNING: Rtools is required to build R packages but is not
>>>>>>> currently installed. Please download and install the appropriate
>>>>>>> version of Rtools before proceeding:
>>>>>>> https://cran.rstudio.com/bin/windows/Rtools/
>>>>>>>
>>>>>>>
>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Apr 30 07:21:39 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 30 Apr 2020 06:21:39 +0100
Subject: [R] how to create a new column from two columns with conditions
In-Reply-To: <CAF9-5jOx7v_ZW3ngpCY2SW1VNKyAxu=z_ddJkpePSDsapC2nug@mail.gmail.com>
References: <CAF9-5jORf+9HDtrKUeQN+7EE5GuxNjCjdzhcjDeNqmgZxOK5Sg@mail.gmail.com>
 <20200429223634.5923b4f0@Tarkus>
 <CAF9-5jO6cUzOmvPkctJtXu-jYS5gLHnqxx5ngOSYMsFqQgfYfQ@mail.gmail.com>
 <1e93298e-2f3f-d280-af2c-fe01dd11b656@sapo.pt>
 <CAF9-5jOx7v_ZW3ngpCY2SW1VNKyAxu=z_ddJkpePSDsapC2nug@mail.gmail.com>
Message-ID: <4c5de3cd-9147-1c25-8fb3-0c4dfdbdfc23@sapo.pt>

Hello,

Inline.

?s 22:44 de 29/04/20, Ana Marija escreveu:
> Hi Rui,
> 
> thanks for getting back to me
> so I tried your method and I got:
>> sum(b$PHENO==2, na.rm=T)
> [1] 828
>> sum(b$PHENO==1, na.rm=T)
> [1] 859
> 
> Can you please tell me if
> b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L
> 
> just assigns PHENO=2 if b$FLASER == 2 | b$PLASER == 2 and everything else is 1?

Yes, that's it. If b$FLASER == 2 | b$PLASER == 2 returns TRUE then 
adding 1 will give

TRUE + 1 -> 1 + 1 -> 2

This is because logical values are internally coded as integers 0 and 1.
And if the condition returns FALSE it becomes

FALSE + 1 -> 0 + 1 -> 1

In both cases the result is what you want.


> 
> Please see how my data looks like:
>> sum(b$FLASER==2, na.rm=T)
> [1] 92
>> sum(b$FLASER==1, na.rm=T)
> [1] 1533
>> sum(b$PLASER==1, na.rm=T)
> [1] 850
>> sum(b$PLASER==2, na.rm=T)
> [1] 806
>> dim(b)
> [1] 1698    5
>> unique(b$FLASER)
> [1]  1  3  2 NA
>> unique(b$PLASER)
> [1]  1  2  3 NA
> 

What I write above is valid even if your data contains NA's, like it 
does. This is because

(TRUE | x) == (x | TRUE) == TRUE

even if x is NA.

This is an example with some NA values in the data.

set.seed(1234)
b <- rbind(b, b)
i <- sample(nrow(b), 3)
b$FLASER[i] <- NA
i <- sample(nrow(b), 2)
b$PLASER[i] <- NA
b$PLASER[10] <- 2

b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1
b


As you can see,

row 5:

b$FLASER is NA, b$PLASER == 2 evaluates to TRUE -> b$PHENO is TRUE

row 10:

b$FLASER == 2 evaluates to TRUE, b$PLASER is NA -> b$PHENO is TRUE


So the code is not broken by NA's

Hope this helps,

Rui Barradas

> On Wed, Apr 29, 2020 at 4:10 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Hello,
>>
>> Here is another way. The condition returns FALSE/TRUE or 0/1. Add 1 to
>> get the expected result.
>> It has the advantage of being faster.
>>
>> b$PHENO <- (b$FLASER == 2 | b$PLASER == 2) + 1L
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 20:42 de 29/04/20, Ana Marija escreveu:
>>> Thanks, I did this:
>>> b$PHENO<- ifelse(b$FLASER ==2 | b$PLASER ==2, 2, 1)
>>>
>>> On Wed, Apr 29, 2020 at 2:36 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>>>>
>>>> On Wed, 29 Apr 2020 14:19:18 -0500
>>>> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>>>
>>>>> My conditions for creating a new column PHENO would be this:
>>>>>
>>>>> if FLASER or PLASER =2 then PHENO=2
>>>>> otherwise PHENO=1
>>>>
>>>> On Wed, 29 Apr 2020 15:30:45 -0400
>>>> "Patrick (Malone Quantitative)" <malone at malonequantitative.com> wrote:
>>>>
>>>>> If you don't mind using tidyverse, you can do this easily with
>>>>> if_else.
>>>>
>>>> ...and if you want to stay with base R, you can use the ifelse
>>>> function.
>>>>
>>>> --
>>>> Best regards,
>>>> Ivan
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From jeroenoom@ @end|ng |rom gm@||@com  Thu Apr 30 10:38:52 2020
From: jeroenoom@ @end|ng |rom gm@||@com (Jeroen Ooms)
Date: Thu, 30 Apr 2020 10:38:52 +0200
Subject: [R] Rtools required
In-Reply-To: <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>
Message-ID: <CABFfbXsLCB0YSNGTnCR_izYRw1EpjvV9hOJyGJJCNx6BkRrQeA@mail.gmail.com>

On Wed, Apr 29, 2020 at 11:37 PM Steven <syen at hqu.edu.cn> wrote:
>
> Hello John,
>
> Perhaps you can help me. I am an idiot. I visited the Rtools web page
> and learn to run the following lines in R: Still I am getting the same
> warning message.
>
>  > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
> "~/.Renviron")
>  > Sys.which("make")
>                                make
> "C:\\rtools40\\usr\\bin\\make.exe"

That looks OK. Did you restart rstudio?

How exactly are getting this error? Are you using install.packages()
in R? Or using the pkgbuild package?

Also are you running the latest version of rstudio? I think old
versions may have had difficulty finding rtools40.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr 30 12:13:18 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 30 Apr 2020 10:13:18 +0000
Subject: [R] ggplot get rid of unused/empty facets
Message-ID: <ea9a53d7562f407089eda85979fae2bc@SRVEXCHCM1302.precheza.cz>

Dear all

I seek some help how to remove unused facets in ggplot

Here is my code
p <- ggplot(met, aes(x=datum, y=lsp))
p+geom_point(size=5)+geom_line()+facet_grid(.~vzorek)

As you can see, there are some empty facets. Is there any reasonably simple
way how to automatically get rid of empty facets and adjust width of
remaining facets?

I could programmatically remove empty levels of vzorek before invoking
ggplot but before are start with such approach I would like to check if
there is some solution within ggplot.

Here are some toy data.

met <- structure(list(datum = structure(c(18282, 18282, 18282, 18290, 
18290, 18290, 18296, 18296, 18296, 18304, 18304, 18304, 18311, 
18311, 18311, 18317, 18317, 18317, 18317, 18324, 18324, 18324, 
18332, 18332, 18332, 18340, 18340, 18340, 18345, 18345, 18345, 
18352, 18352, 18369, 18369, 18369, 18375, 18375, 18375), class = "Date"), 
    vzorek = structure(c(9L, 8L, 2L, 5L, 9L, 6L, 1L, 7L, 8L, 
    9L, 5L, 1L, 2L, 7L, 8L, 5L, 2L, 1L, 7L, 9L, 7L, 5L, 4L, 2L, 
    1L, 3L, 8L, 5L, 9L, 2L, 1L, 7L, 8L, 9L, 8L, 2L, 1L, 7L, 5L
    ), .Label = c("a", "b", "c", "d", "e", "f", "g", "h", "i"
    ), class = "factor"), lsp = c(55.3, 54.68, 53.15, 54.55, 
    55.17, NA, NA, NA, 54.79, 55.27, 54.44, NA, 53.31, NA, 54.52, 
    54.35, 53.88, NA, NA, 55.21, NA, 54.39, NA, 52.95, NA, NA, 
    54.56, 54.39, 55, 53.2, NA, NA, 54.54, NA, 54.57, 53.31, 
    NA, NA, NA), asp = c(-1.63, -1.47, -1.19, -1.35, -1.62, NA, 
    NA, NA, -1.46, -1.65, -1.4, NA, -1.2, NA, -1.5, -1.36, -1.21, 
    NA, NA, -1.64, NA, -1.36, NA, -1.21, NA, NA, -1.5, -1.42, 
    -1.68, -1.2, NA, NA, -1.47, NA, -1.47, -1.22, NA, NA, NA), 
    bsp = c(-7.19, -5.65, -7.22, -5.31, -7.12, NA, NA, NA, -5.65, 
    -7.14, -5.34, NA, -7.16, NA, -5.68, -5.3, -7.14, NA, NA, 
    -7.14, NA, -5.34, NA, -7.17, NA, NA, -5.65, -5.34, -7.25, 
    -7.19, NA, NA, -5.65, NA, -5.66, -7.14, NA, NA, NA)), row.names = c(NA, 
-39L), class = "data.frame")
>

Cheers
Petr


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Apr 30 12:28:04 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 30 Apr 2020 12:28:04 +0200
Subject: [R] ggplot get rid of unused/empty facets
In-Reply-To: <ea9a53d7562f407089eda85979fae2bc@SRVEXCHCM1302.precheza.cz>
References: <ea9a53d7562f407089eda85979fae2bc@SRVEXCHCM1302.precheza.cz>
Message-ID: <3cf964fe-62da-aae0-d829-e09d8297968b@rgzm.de>

Dear Petr,

This is not a ggplot2 solution, but you could just remove the NA rows
and drop the levels of vzorek:
met2 <- met[complete.cases(met), ]
met2$vzorek <- droplevels(met2$vzorek)

But I guess you already thought about that...!

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 30/04/2020 12:13, PIKAL Petr wrote:
> Dear all
>
> I seek some help how to remove unused facets in ggplot
>
> Here is my code
> p <- ggplot(met, aes(x=datum, y=lsp))
> p+geom_point(size=5)+geom_line()+facet_grid(.~vzorek)
>
> As you can see, there are some empty facets. Is there any reasonably simple
> way how to automatically get rid of empty facets and adjust width of
> remaining facets?
>
> I could programmatically remove empty levels of vzorek before invoking
> ggplot but before are start with such approach I would like to check if
> there is some solution within ggplot.
>
> Here are some toy data.
>
> met <- structure(list(datum = structure(c(18282, 18282, 18282, 18290, 
> 18290, 18290, 18296, 18296, 18296, 18304, 18304, 18304, 18311, 
> 18311, 18311, 18317, 18317, 18317, 18317, 18324, 18324, 18324, 
> 18332, 18332, 18332, 18340, 18340, 18340, 18345, 18345, 18345, 
> 18352, 18352, 18369, 18369, 18369, 18375, 18375, 18375), class = "Date"), 
>     vzorek = structure(c(9L, 8L, 2L, 5L, 9L, 6L, 1L, 7L, 8L, 
>     9L, 5L, 1L, 2L, 7L, 8L, 5L, 2L, 1L, 7L, 9L, 7L, 5L, 4L, 2L, 
>     1L, 3L, 8L, 5L, 9L, 2L, 1L, 7L, 8L, 9L, 8L, 2L, 1L, 7L, 5L
>     ), .Label = c("a", "b", "c", "d", "e", "f", "g", "h", "i"
>     ), class = "factor"), lsp = c(55.3, 54.68, 53.15, 54.55, 
>     55.17, NA, NA, NA, 54.79, 55.27, 54.44, NA, 53.31, NA, 54.52, 
>     54.35, 53.88, NA, NA, 55.21, NA, 54.39, NA, 52.95, NA, NA, 
>     54.56, 54.39, 55, 53.2, NA, NA, 54.54, NA, 54.57, 53.31, 
>     NA, NA, NA), asp = c(-1.63, -1.47, -1.19, -1.35, -1.62, NA, 
>     NA, NA, -1.46, -1.65, -1.4, NA, -1.2, NA, -1.5, -1.36, -1.21, 
>     NA, NA, -1.64, NA, -1.36, NA, -1.21, NA, NA, -1.5, -1.42, 
>     -1.68, -1.2, NA, NA, -1.47, NA, -1.47, -1.22, NA, NA, NA), 
>     bsp = c(-7.19, -5.65, -7.22, -5.31, -7.12, NA, NA, NA, -5.65, 
>     -7.14, -5.34, NA, -7.16, NA, -5.68, -5.3, -7.14, NA, NA, 
>     -7.14, NA, -5.34, NA, -7.17, NA, NA, -5.65, -5.34, -7.25, 
>     -7.19, NA, NA, -5.65, NA, -5.66, -7.14, NA, NA, NA)), row.names = c(NA, 
> -39L), class = "data.frame")
> Cheers
> Petr
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr 30 15:33:40 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 30 Apr 2020 13:33:40 +0000
Subject: [R] deciphering help for `attach`
In-Reply-To: <3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
References: <f45aca15da31ed64e07776c869334bb2.squirrel@webmail.psu.ac.th>
 <51b1d09ab33c4b0bbc97bbe293fac82f@SRVEXCHCM1302.precheza.cz>
 <3755804f995348996db3b45ba20ca858.squirrel@webmail.psu.ac.th>
Message-ID: <2c858674849943a2bb7e2e030b894891@SRVEXCHCM1302.precheza.cz>

Hallo

Sorry for confusion. John explained in technical language what I was trying to explain in plain one. One cannot simply change values in original data frame or call them, however they could be used in functions.

Consider this

attach(cars)
speed <- speed*2
speed
 [1]  8  8 14 14 16 18 20 20 20 22 22 24 24 24 24 26 26 26 26 28 28 28 28 30 30
[26] 30 32 32 34 34 34 36 36 36 36 38 38 38 40 40 40 40 40 44 46 48 48 48 48 50
plot(speed, dist)
fit <- lm(dist~speed, data=cars)
abline(fit)
fit1 <- lm(dist~speed)
abline(fit1, col = 2)

And if you attach something which has speed and dist variable inside, the things could be even more confusing.

mydata <- data.frame(speed="Blue", dist="Black")
attach(mydata)
The following object is masked _by_ .GlobalEnv:

    speed

The following objects are masked from cars:

    dist, speed

> search()
 [1] ".GlobalEnv"        "mydata"            "cars"             
 [4] "package:stats"     "package:datasets"  "package:fun"      
 [7] "package:utils"     "package:grDevices" "package:graphics" 
[10] "package:methods"   "Autoloads"         "package:base"     

So although mydata are attached its speed variable is accessible only by referencing to mydata, but now dist from mydata is used in lm, if cars data frame is not specified.

> fit <- lm(dist~speed)
Error in model.frame.default(formula = dist ~ speed, drop.unused.levels = TRUE) : 
  variable lengths differ (found for 'speed')

> speed
 [1]  8  8 14 14 16 18 20 20 20 22 22 24 24 24 24 26 26 26 26 28 28 28 28 30 30
[26] 30 32 32 34 34 34 36 36 36 36 38 38 38 40 40 40 40 40 44 46 48 48 48 48 50
> dist
[1] "Black"

I used attach myself a lot about 20 years ago but due to unexpected (by myself) behaviour I do not use it now. Of course nobody will prevent you to use or teach attach, but you has to acknowledge that attach is doing what it is doing and not what you or your students expect it is doing. And for me, environments are still something I did not familiarise with.

Cheers
Petr

> -----Original Message-----
> From: Edward McNeil <edward.m at psu.ac.th>
> Sent: Monday, April 27, 2020 3:26 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help at r-project.org
> Subject: RE: [R] deciphering help for `attach`
> 
> Dear Petr,
> Thanks for your quick reply. Much appreciated. However, you haven't really
> answered either of my questions, although I don't quite understand your
> reference to La Gioconda.
> 
> In any case, despite your strong recommendation not to use `attach`, I am
> going to keep using it, as I have done successfully for the past 16 years, and
> keep teaching it, until it either kills me or disappears from R. Unfortunately I
> have to teach R to students and I don't like it when they ask me "tricky"
> questions to which I have no answer. ;)
> --
> Edward McNeil
> 
> On Mon, April 27, 2020 8:00 pm, PIKAL Petr wrote:
> Hi.
> 
> I strongly recommend not to use attach. I agree that mentioned statements
> are rather contradictory and probably others could give you more insightful
> answer. You could consider that by attaching some data, you create
> something like a copy of original data in your system with a feature that you
> can use column names directly. If you change something in the data after
> attachment, you change only attached version and not an original.
> 
> It is similar as if you take a picture of Gioconda an use some creativity to add
> a moustache to this picture. In any circumstances moustache does not
> propagate to the original Louvre painting. Do not perform any tricks,
> preferably do not perform attach.
> 
> Cheers
> Petr
> 
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Edward McNeil
> > Sent: Monday, April 27, 2020 2:07 PM
> > To: r-help at r-project.org
> > Subject: [R] deciphering help for `attach`
> >
> > Hi,
> > I have two related questions.
> >
> > 1. In the help page for `attach` under "Details" it says in paragraph 3:
> > "By default the database is attached ..."
> >
> > But then paragraph 4 starts: "The database is not actually attached."
> >
> > Could somebody explain this contradiction? Is the data(base) attached
> > or not?
> >
> > 2. What is meant by the 5th paragraph: "One useful ?trick? is to use
> > what = NULL (or equivalently a length-zero list) to create a new
> > environment on the search path into which objects can be assigned by
> `assign` ... "?
> >
> > I don't understand what this "trick" is or why a "trick" needs to be
> > performed here.
> >
> > Thanks
> > --
> > Edward McNeil
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> 
> 
> 
> 


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr 30 15:37:15 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 30 Apr 2020 13:37:15 +0000
Subject: [R] ggplot get rid of unused/empty facets
In-Reply-To: <3cf964fe-62da-aae0-d829-e09d8297968b@rgzm.de>
References: <ea9a53d7562f407089eda85979fae2bc@SRVEXCHCM1302.precheza.cz>
 <3cf964fe-62da-aae0-d829-e09d8297968b@rgzm.de>
Message-ID: <9c09c551dcbd4f73a23383a87dbd8ade@SRVEXCHCM1302.precheza.cz>

Yes, thank you Ivan.

I used slightly different approach but with similar idea. I just wondered,
if there is some clever hidden easy command or parameter inside ggplot
environment which could drop panels without data.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ivan Calandra
> Sent: Thursday, April 30, 2020 12:28 PM
> To: r-help at r-project.org
> Subject: Re: [R] ggplot get rid of unused/empty facets
> 
> Dear Petr,
> 
> This is not a ggplot2 solution, but you could just remove the NA rows and
> drop the levels of vzorek:
> met2 <- met[complete.cases(met), ]
> met2$vzorek <- droplevels(met2$vzorek)
> 
> But I guess you already thought about that...!
> 
> Ivan
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments MONREPOS
> Archaeological Research Centre and Museum for Human Behavioural
> Evolution Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> On 30/04/2020 12:13, PIKAL Petr wrote:
> > Dear all
> >
> > I seek some help how to remove unused facets in ggplot
> >
> > Here is my code
> > p <- ggplot(met, aes(x=datum, y=lsp))
> > p+geom_point(size=5)+geom_line()+facet_grid(.~vzorek)
> >
> > As you can see, there are some empty facets. Is there any reasonably
> > simple way how to automatically get rid of empty facets and adjust
> > width of remaining facets?
> >
> > I could programmatically remove empty levels of vzorek before invoking
> > ggplot but before are start with such approach I would like to check
> > if there is some solution within ggplot.
> >
> > Here are some toy data.
> >
> > met <- structure(list(datum = structure(c(18282, 18282, 18282, 18290,
> > 18290, 18290, 18296, 18296, 18296, 18304, 18304, 18304, 18311, 18311,
> > 18311, 18317, 18317, 18317, 18317, 18324, 18324, 18324, 18332, 18332,
> > 18332, 18340, 18340, 18340, 18345, 18345, 18345, 18352, 18352, 18369,
> > 18369, 18369, 18375, 18375, 18375), class = "Date"),
> >     vzorek = structure(c(9L, 8L, 2L, 5L, 9L, 6L, 1L, 7L, 8L,
> >     9L, 5L, 1L, 2L, 7L, 8L, 5L, 2L, 1L, 7L, 9L, 7L, 5L, 4L, 2L,
> >     1L, 3L, 8L, 5L, 9L, 2L, 1L, 7L, 8L, 9L, 8L, 2L, 1L, 7L, 5L
> >     ), .Label = c("a", "b", "c", "d", "e", "f", "g", "h", "i"
> >     ), class = "factor"), lsp = c(55.3, 54.68, 53.15, 54.55,
> >     55.17, NA, NA, NA, 54.79, 55.27, 54.44, NA, 53.31, NA, 54.52,
> >     54.35, 53.88, NA, NA, 55.21, NA, 54.39, NA, 52.95, NA, NA,
> >     54.56, 54.39, 55, 53.2, NA, NA, 54.54, NA, 54.57, 53.31,
> >     NA, NA, NA), asp = c(-1.63, -1.47, -1.19, -1.35, -1.62, NA,
> >     NA, NA, -1.46, -1.65, -1.4, NA, -1.2, NA, -1.5, -1.36, -1.21,
> >     NA, NA, -1.64, NA, -1.36, NA, -1.21, NA, NA, -1.5, -1.42,
> >     -1.68, -1.2, NA, NA, -1.47, NA, -1.47, -1.22, NA, NA, NA),
> >     bsp = c(-7.19, -5.65, -7.22, -5.31, -7.12, NA, NA, NA, -5.65,
> >     -7.14, -5.34, NA, -7.16, NA, -5.68, -5.3, -7.14, NA, NA,
> >     -7.14, NA, -5.34, NA, -7.17, NA, NA, -5.65, -5.34, -7.25,
> >     -7.19, NA, NA, -5.65, NA, -5.66, -7.14, NA, NA, NA)), row.names =
> > c(NA, -39L), class = "data.frame") Cheers Petr
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From Chr|@@W||cox @end|ng |rom c@|ro@@u  Thu Apr 30 01:44:46 2020
From: Chr|@@W||cox @end|ng |rom c@|ro@@u (Wilcox, Chris (O&A, Hobart))
Date: Wed, 29 Apr 2020 23:44:46 +0000
Subject: [R] FW: problem with markov random field smooths in mgcv
In-Reply-To: <13cbad1e-7218-a201-f5d8-0aaed89d305d@bath.edu>
References: <D782BFE1-F78B-47E5-B1B7-838497B45381@csiro.au>
 <13cbad1e-7218-a201-f5d8-0aaed89d305d@bath.edu>
Message-ID: <EBFD6CDD-642B-43D2-825B-1314C0EF3AA6@csiro.au>

Thanks very much Simon, that is super helpful.

Best,

Chris

?On 25/3/20, 9:47 am, "Simon Wood" <simon.wood at bath.edu> wrote:

    Hi Chris,
    
    It's kind of a documentation glitch, a node is not supposed to be listed 
    as its own neighbour (it causes the diagonal entries in the penalty 
    matrix to be over-written by the wrong value). i.e. the neighbour list 
    should be.
    
      NB <- list()
         NB$'East Timor' <- c(2,15)
         NB$Australia <- c(1,15)
         NB$'Sri Lanka' <-c(12,16)
         NB$Bangladesh <-c(12,13,16)
         NB$Philippines <- c(6,11,14,15,17)
         NB$Taiwan <- c(5,11)
         NB$Thailand <- c(8,10,12,13,14,15)
         NB$Vietnam <- c(7,10,11,14,15)
         NB$`South Korea` <- c(11)
         NB$Cambodia <- c(7,8)
         NB$China <- c(5,6,8,9,14)
         NB$India <- c(3,4,7,13,15,16)
         NB$Myanmar <- c(4,7,12,16)
         NB$Malaysia <- c(5,7,8,11,15)
         NB$Indonesia <- c(1,2,5,7,8,12,14)
         NB$HighSeas2 <- c(3,4,12,13)
         NB$HighSeas1 <- c(5)
    
    I've fixed the help page and had the smooth constructor ignore 
    auto-neighbours for the next release.
    
    best,
    Simon
    
       On 18/03/2020 07:44, Wilcox, Chris (O&A, Hobart) wrote:
    > Hi all,
    >      
    >      I am trying to fit a model with a markov random field smooth in mgcv.  I am having some trouble with getting it to run, and in particular I am getting the message
    >      
    >      Error in initial.sp(w * x, S, off) : S[[1]] matrix is not +ve definite.
    >      
    >      After reading everything I could find on mrf, it sounds like there was a bug that was brought up with Simon Wood in 2012, due to differences between windows and linux, with the linus machine stopping due to this error, while windows was not.  I have not been able to find much else on it.  Any suggestions would be much appreciated.
    >      
    >      There is reproducible code below.
    >      
    >      Thanks
    >      
    >      Chris
    >      
    >      
    >      library(mgcv)
    >      
    >      #create data
    >      Country <- as.factor(c("Australia","Australia","Australia","Australia","Australia","Australia","Bangladesh","Bangladesh","Bangladesh",
    >      "Bangladesh","Bangladesh","Bangladesh","Cambodia","Cambodia","Cambodia","Cambodia","Cambodia","Cambodia",
    >      "China","China","China","China","China","China","East Timor","East Timor","East Timor",
    >      "East Timor","East Timor","East Timor","HighSeas1","HighSeas1","HighSeas1","HighSeas1","HighSeas1","HighSeas1",
    >      "HighSeas2","HighSeas2","HighSeas2","HighSeas2","HighSeas2","HighSeas2","China","China","China","China","China","China",
    >      "India","India","India","India","India","India","Indonesia","Indonesia","Indonesia","Indonesia","Indonesia","Indonesia",
    >      "Malaysia","Malaysia","Malaysia","Malaysia","Malaysia","Malaysia","Myanmar","Myanmar","Myanmar","Myanmar","Myanmar",
    >      "Myanmar","Philippines","Philippines","Philippines","Philippines","Philippines","Philippines","South Korea","South Korea",
    >      "South Korea","South Korea","South Korea","South Korea","China","China","China","China","China","China",
    >      "Sri Lanka","Sri Lanka","Sri Lanka","Sri Lanka","Sri Lanka","Sri Lanka","Taiwan","Taiwan","Taiwan","Taiwan",
    >      "Taiwan","Taiwan","Thailand","Thailand","Thailand","Thailand","Thailand","Thailand","Vietnam","Vietnam","Vietnam","Vietnam",
    >      "Vietnam","Vietnam"))
    >      
    >      Count <- c(0,0,3,5,1,5,0,0,0,0,0,1,0,0,0,0,0,3,0,0,2,1,0,6,0,0,0,1,0,0,0,1,0,0,0,0
    >      ,0,0,20,0,1,0,0,0,0,0,0,2,0,0,6,3,3,10,1,1,18,11,8,11,0,1,2,2,1,14,0,0,0,1,0,0
    >      ,0,0,4,3,9,16,0,0,3,0,0,1,0,0,1,0,0,0,0,0,33,18,8,16,0,0,0,0,0,2,0,1,14,6,8,2
    >      ,0,0,0,0,1,1)
    >      
    >      Data <- data.frame(Count,Country)
    >      
    >      #create neighbour matrix
    >      NB <- list()
    >      NB$'East Timor' <- c(1,2,15)
    >      NB$Australia <- c(1,2,15)
    >      NB$'Sri Lanka' <-c(3,12,16)
    >      NB$Bangladesh <-c(4,12,13,16)
    >      NB$Philippines <- c(5,6,11,14,15,17)
    >      NB$Taiwan <- c(5,6,11)
    >      NB$Thailand <- c(7,8,10,12,13,14,15)
    >      NB$Vietnam <- c(7,8,10,11,14,15)
    >      NB$`South Korea` <- c(9,11)
    >      NB$Cambodia <- c(7,8,10)
    >      NB$China <- c(5,6,8,9,11,14)
    >      NB$India <- c(3,4,7,12,13,15,16)
    >      NB$Myanmar <- c(4,7,12,13,16)
    >      NB$Malaysia <- c(5,7,8,11,14,15)
    >      NB$Indonesia <- c(1,2,5,7,8,12,14,15)
    >      NB$HighSeas2 <- c(3,4,12,13,16)
    >      NB$HighSeas1 <- c(5,17)
    >      
    >      #check levels and names match
    >      all.equal(sort(names(NB)), sort(levels(Data$Country)))
    >      
    >      #try fitting GAM
    >      m1 <- gam(Data$Count ~ s(Data$Country, bs = 'mrf', xt = list(nb = NB)))
    >      
    >      
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Simon Wood, School of Mathematics, University of Bristol, BS8 1TW UK
    https://people.maths.bris.ac.uk/~sw15190/
    
    


From @yen @end|ng |rom hqu@edu@cn  Thu Apr 30 03:48:03 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Thu, 30 Apr 2020 09:48:03 +0800
Subject: [R] Rtools required
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>

Thanks to all - very helpful. I search from c:\ and now find file 
.Renviron located in C:\Users\USER\Documents. That does it.

I would like to pose an additional question, since it would also fall 
under the same subject line. This is an RStudio question but since I am 
using the free version the RStudio folks would not help me.

My students simply need to install packages and are not building any 
packages so they have no reason to install Rtools.

When they install (not build) packages (from CRAN or file archive) they 
received the same warning message saying

"Rtools required to build a package".

This is nonsense of course as they are, as I said, simply installing. I 
tell them to user an older RStudio version, specifically 1.1.463 that's 
free of that warning. Any idea?

Steven Yen

On 2020/4/30 ?? 06:30, Fox, John wrote:
> Dear Steven,
>
> It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).
>
> Best,
>   John
>
>> -----Original Message-----
>> From: Bert Gunter <bgunter.4567 at gmail.com>
>> Sent: Wednesday, April 29, 2020 5:50 PM
>> To: Steven <syen at hqu.edu.cn>
>> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
>> project.org>
>> Subject: Re: [R] Rtools required
>>
>> Type
>> ?.Renviron
>> ?R.home
>> ?"environment variables"
>>
>> at the R prompt to get what I think should be the info you need (or at
>> least useful info).
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>>> Thanks John. Where is file .Renviron located? It must be a hidden file.
>>> I cannot find it.
>>>
>>> On 2020/4/28 ?? 08:29, Fox, John wrote:
>>>> Dear Steven,
>>>>
>>>> Did you follow the instruction on the Rtools webpage to add
>>>>
>>>>        PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>>>>
>>>> to your .Renviron file?
>>>>
>>>> I hope this helps,
>>>>    John
>>>>
>>>>     -----------------------------
>>>>     John Fox, Professor Emeritus
>>>>     McMaster University
>>>>     Hamilton, Ontario, Canada
>>>>     Web: http::/socserv.mcmaster.ca/jfox
>>>>
>>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>>>>
>>>>> Dear All
>>>>>
>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
>>>>> now the new default folder c:\rtools40). While compiling a package
>>>>> (binary) I received the follow marning message saying Rtools is
>>>>> required. Any clues? Thanks.
>>>>>
>>>>> Steven Yen
>>>>>
>>>>> WARNING: Rtools is required to build R packages but is not
>>>>> currently installed. Please download and install the appropriate
>>>>> version of Rtools before proceeding:
>>>>> https://cran.rstudio.com/bin/windows/Rtools/
>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From @yen @end|ng |rom hqu@edu@cn  Thu Apr 30 05:00:43 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Thu, 30 Apr 2020 11:00:43 +0800
Subject: [R] Rtools required
In-Reply-To: <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
 <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
 <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>
Message-ID: <f74945a9-6eab-206c-6d34-3893253fedb0@hqu.edu.cn>

Good point, but I am bothered by the non-discrimatory warning message to 
all package installation attempts. My students install mostly binary 
files, and I just hate to have them install Rtools. For one, they have 
not had to do so until after RStudio-1.1.463. The fact that using this 
older RStudio? can avoid the annoying warning message speaks volume.

On 2020/4/30 ?? 10:02, Bert Gunter wrote:
> Wouldn't packages that have to be built from source on installation
> require Rtools?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Apr 29, 2020 at 6:48 PM Steven <syen at hqu.edu.cn> wrote:
>> Thanks to all - very helpful. I search from c:\ and now find file
>> .Renviron located in C:\Users\USER\Documents. That does it.
>>
>> I would like to pose an additional question, since it would also fall
>> under the same subject line. This is an RStudio question but since I am
>> using the free version the RStudio folks would not help me.
>>
>> My students simply need to install packages and are not building any
>> packages so they have no reason to install Rtools.
>>
>> When they install (not build) packages (from CRAN or file archive) they
>> received the same warning message saying
>>
>> "Rtools required to build a package".
>>
>> This is nonsense of course as they are, as I said, simply installing. I
>> tell them to user an older RStudio version, specifically 1.1.463 that's
>> free of that warning. Any idea?
>>
>> Steven Yen
>>
>> On 2020/4/30 ?? 06:30, Fox, John wrote:
>>> Dear Steven,
>>>
>>> It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).
>>>
>>> Best,
>>>    John
>>>
>>>> -----Original Message-----
>>>> From: Bert Gunter <bgunter.4567 at gmail.com>
>>>> Sent: Wednesday, April 29, 2020 5:50 PM
>>>> To: Steven <syen at hqu.edu.cn>
>>>> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
>>>> project.org>
>>>> Subject: Re: [R] Rtools required
>>>>
>>>> Type
>>>> ?.Renviron
>>>> ?R.home
>>>> ?"environment variables"
>>>>
>>>> at the R prompt to get what I think should be the info you need (or at
>>>> least useful info).
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along and
>>>> sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>>>>> Thanks John. Where is file .Renviron located? It must be a hidden file.
>>>>> I cannot find it.
>>>>>
>>>>> On 2020/4/28 ?? 08:29, Fox, John wrote:
>>>>>> Dear Steven,
>>>>>>
>>>>>> Did you follow the instruction on the Rtools webpage to add
>>>>>>
>>>>>>         PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>>>>>>
>>>>>> to your .Renviron file?
>>>>>>
>>>>>> I hope this helps,
>>>>>>     John
>>>>>>
>>>>>>      -----------------------------
>>>>>>      John Fox, Professor Emeritus
>>>>>>      McMaster University
>>>>>>      Hamilton, Ontario, Canada
>>>>>>      Web: http::/socserv.mcmaster.ca/jfox
>>>>>>
>>>>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>>>>>>
>>>>>>> Dear All
>>>>>>>
>>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
>>>>>>> now the new default folder c:\rtools40). While compiling a package
>>>>>>> (binary) I received the follow marning message saying Rtools is
>>>>>>> required. Any clues? Thanks.
>>>>>>>
>>>>>>> Steven Yen
>>>>>>>
>>>>>>> WARNING: Rtools is required to build R packages but is not
>>>>>>> currently installed. Please download and install the appropriate
>>>>>>> version of Rtools before proceeding:
>>>>>>> https://cran.rstudio.com/bin/windows/Rtools/
>>>>>>>
>>>>>>>
>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From @@mue|@gr@nje@ud @end|ng |rom |n@erm@|r  Thu Apr 30 13:47:25 2020
From: @@mue|@gr@nje@ud @end|ng |rom |n@erm@|r (Samuel Granjeaud IR/Inserm)
Date: Thu, 30 Apr 2020 11:47:25 +0000
Subject: [R] stats:: spline's method could not be monoH.FC
Message-ID: <ema4758abf-559f-4e73-90ff-10c2692ea0ce@bioinfo5>

Hi,

I have just noticed that the argument method of the spline function of 
the stats package does not allow to specify monoH.FC although the 
documentation tells it should be possible.

I know how to program a workaround. This post intends to alert the 
maintainers.

Stay safe,
Samuel
	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Apr 30 18:08:22 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 30 Apr 2020 12:08:22 -0400
Subject: [R] repository for ubuntu/linux mint for R 4.0.0
In-Reply-To: <20200430002223.GB645634@posteo.no>
References: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>
 <20200430002223.GB645634@posteo.no>
Message-ID: <10b8114c-c598-4ff1-a9ed-2d368417001a@gmail.com>

Given there's confirmation of some issue with the repositories,
I'm wondering where it should be reported for fixing. It looks like
the repo has been set up but not copied/moved to the appropriate
server or location, i.e., cloud rather than cran. My guess is that
there are some users struggling and thinking that they have made an
error. The msg on my machine concerned the Release.key file, but
the reality is a missing repo. Once I recognized that, it didn't
take too long to get R4.0 running.

JN


On 2020-04-29 8:22 p.m., Rasmus Liland wrote:
> On 2020-04-29 19:55 -0400, ProfJCNash wrote:
>> In updating (an older computer with) Linux Mint 18.3 I tried to add
>> the repository
>>
>> deb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/
>>
>> as per the "Download R for Linux" instructions. This gave an error
>> that there was no Release.key file.
>>
>> After some investigation, I found that
>>
>> deb https://cran.r-project.org/bin/linux/ubuntu xenial-cran40/
>>
>> i.e., CRAN not CLOUD. With this change, I could install R 4.0.
>>
>> Is this a known glitch?
> 
> Dear JN,
> 
> perhaps it is a glitch ... does anyone run mirmon[1] on the R 
> mirrors to see which ones are old?
> 
> If you open those two addresses in a browser, you see that the 
> xenial-cran40 folder is only present in cran case ...  These are 
> two different servers, which can also be seen by running curl:
> 
> 	rasmus at twentyfive ~ % curl -I https://cloud.r-project.org/bin/linux/ubuntu/
> 	HTTP/2 200 
> 	content-type: text/html;charset=ISO-8859-1
> 	date: Thu, 30 Apr 2020 00:05:13 GMT
> 	server: Apache/2.4.39 (Unix)
> 	cache-control: max-age=1800
> 	expires: Thu, 30 Apr 2020 00:35:13 GMT
> 	x-cache: Miss from cloudfront
> 	...
> 	
> 	rasmus at twentyfive ~ % curl -I https://cran.r-project.org/bin/linux/ubuntu/
> 	HTTP/1.1 200 OK
> 	Date: Thu, 30 Apr 2020 00:05:23 GMT
> 	Server: Apache
> 	Content-Type: text/html;charset=UTF-8
> 
> It is wise to point your package manager to a mirror[2] close to you 
> instead of a cdn, e.g. [3] or something ... 
> 
> Best,
> Rasmus
> 
> [1] https://spacehopper.org/mirmon/
> [2] https://cran.r-project.org/mirrors.html
> [3] https://mirror.las.iastate.edu/CRAN/bin/linux/ubuntu/
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 30 18:49:09 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 30 Apr 2020 12:49:09 -0400
Subject: [R] Rtools required
In-Reply-To: <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
 <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
Message-ID: <caf04a36-2450-5e5c-6d12-2ba62cf35721@gmail.com>

I think you probably wrote to the wrong place at RStudio.  You won't get 
help from their help desk without a paid license for the software, but 
they run community forums (similar in aim to this mailing list) where 
community members are often pretty helpful.

In any case, this is the wrong place to ask for help on RStudio.

Duncan Murdoch

On 29/04/2020 9:48 p.m., Steven wrote:
> Thanks to all - very helpful. I search from c:\ and now find file
> .Renviron located in C:\Users\USER\Documents. That does it.
> 
> I would like to pose an additional question, since it would also fall
> under the same subject line. This is an RStudio question but since I am
> using the free version the RStudio folks would not help me.
> 
> My students simply need to install packages and are not building any
> packages so they have no reason to install Rtools.
> 
> When they install (not build) packages (from CRAN or file archive) they
> received the same warning message saying
> 
> "Rtools required to build a package".
> 
> This is nonsense of course as they are, as I said, simply installing. I
> tell them to user an older RStudio version, specifically 1.1.463 that's
> free of that warning. Any idea?
> 
> Steven Yen
> 
> On 2020/4/30 ?? 06:30, Fox, John wrote:
>> Dear Steven,
>>
>> It's possible that Windows will hide .Renviron, but it's generally a good idea, in my opinion, in Folder Options > View to click "Show hidden files" and uncheck "hide extensions". Then .Renviron should show up (once you've created it).
>>
>> Best,
>>    John
>>
>>> -----Original Message-----
>>> From: Bert Gunter <bgunter.4567 at gmail.com>
>>> Sent: Wednesday, April 29, 2020 5:50 PM
>>> To: Steven <syen at hqu.edu.cn>
>>> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
>>> project.org>
>>> Subject: Re: [R] Rtools required
>>>
>>> Type
>>> ?.Renviron
>>> ?R.home
>>> ?"environment variables"
>>>
>>> at the R prompt to get what I think should be the info you need (or at
>>> least useful info).
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>>>> Thanks John. Where is file .Renviron located? It must be a hidden file.
>>>> I cannot find it.
>>>>
>>>> On 2020/4/28 ?? 08:29, Fox, John wrote:
>>>>> Dear Steven,
>>>>>
>>>>> Did you follow the instruction on the Rtools webpage to add
>>>>>
>>>>>         PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>>>>>
>>>>> to your .Renviron file?
>>>>>
>>>>> I hope this helps,
>>>>>     John
>>>>>
>>>>>      -----------------------------
>>>>>      John Fox, Professor Emeritus
>>>>>      McMaster University
>>>>>      Hamilton, Ontario, Canada
>>>>>      Web: http::/socserv.mcmaster.ca/jfox
>>>>>
>>>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>>>>>
>>>>>> Dear All
>>>>>>
>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0 (to
>>>>>> now the new default folder c:\rtools40). While compiling a package
>>>>>> (binary) I received the follow marning message saying Rtools is
>>>>>> required. Any clues? Thanks.
>>>>>>
>>>>>> Steven Yen
>>>>>>
>>>>>> WARNING: Rtools is required to build R packages but is not
>>>>>> currently installed. Please download and install the appropriate
>>>>>> version of Rtools before proceeding:
>>>>>> https://cran.rstudio.com/bin/windows/Rtools/
>>>>>>
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |@t@z@hn @end|ng |rom gm@||@com  Thu Apr 30 18:50:24 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 30 Apr 2020 12:50:24 -0400
Subject: [R] repository for ubuntu/linux mint for R 4.0.0
In-Reply-To: <20200430002643.GA654972@posteo.no>
References: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>
 <20200430002643.GA654972@posteo.no>
Message-ID: <CA+vqiLHRY1D6ZW4Hj4TPRAdrN0FXKh3jxpOTkiWpNNKtTkQ=Nw@mail.gmail.com>

On Wed, Apr 29, 2020 at 8:33 PM Rasmus Liland <jensrasmus at gmail.com> wrote:
>
> On 2020-04-29 19:55 -0400, ProfJCNash wrote:
> > In updating (an older computer with) Linux Mint 18.3 I tried to add
> > the repository
> >
> > deb https://cloud.r-project.org/bin/linux/ubuntu xenial-cran40/
> >
> > as per the "Download R for Linux" instructions. This gave an error
> > that there was no Release.key file.
> >
> > After some investigation, I found that
> >
> > deb https://cran.r-project.org/bin/linux/ubuntu xenial-cran40/
> >
> > i.e., CRAN not CLOUD. With this change, I could install R 4.0.
> >
> > Is this a known glitch?
>
> Dear JN,
>
> perhaps it is a glitch ... does anyone run mirmon[1] on the R
> mirrors to see which ones are old?

https://cran.r-project.org/mirmon_report.html

>
> If you open those two addresses in a browser, you see that the
> xenial-cran40 folder is only present in cran case ...  These are
> two different servers, which can also be seen by running curl:
>
>         rasmus at twentyfive ~ % curl -I https://cloud.r-project.org/bin/linux/ubuntu/
>         HTTP/2 200
>         content-type: text/html;charset=ISO-8859-1
>         date: Thu, 30 Apr 2020 00:05:13 GMT
>         server: Apache/2.4.39 (Unix)
>         cache-control: max-age=1800
>         expires: Thu, 30 Apr 2020 00:35:13 GMT
>         x-cache: Miss from cloudfront
>         ...
>
>         rasmus at twentyfive ~ % curl -I https://cran.r-project.org/bin/linux/ubuntu/
>         HTTP/1.1 200 OK
>         Date: Thu, 30 Apr 2020 00:05:23 GMT
>         Server: Apache
>         Content-Type: text/html;charset=UTF-8
>
> It is wise to point your package manager to a mirror[2] close to you
> instead of a cdn, e.g. [3] or something ...
>
> Best,
> Rasmus
>
> [1] https://spacehopper.org/mirmon/
> [2] https://cran.r-project.org/mirrors.html
> [3] https://mirror.las.iastate.edu/CRAN/bin/linux/ubuntu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 30 19:30:29 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 30 Apr 2020 10:30:29 -0700
Subject: [R] Rtools required
In-Reply-To: <f74945a9-6eab-206c-6d34-3893253fedb0@hqu.edu.cn>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <e54dd038-0419-658b-b8bf-4ebf0395b429@hqu.edu.cn>
 <CAGxFJbQ0=O7=sPCyjDRSyML5V9c2zGpntsYuQ=O02MfvaOf4Qg@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC88CE6935E@FHSDB2D11-2.csu.mcmaster.ca>
 <be4b8320-373e-a1d6-d376-d34c8767ce7a@hqu.edu.cn>
 <CAGxFJbSF25mk4ex7gi0_7-cSCz8JWrnLtaCC+sDBms+5=rCG1Q@mail.gmail.com>
 <f74945a9-6eab-206c-6d34-3893253fedb0@hqu.edu.cn>
Message-ID: <58D6D6C0-DF9E-4F3E-A91F-45F95A9235FA@dcn.davis.ca.us>

Minimize the number of referenced contributed packages, and inform your students that they can (should?) opt to not install from source when prompted.

In fact, this could be a use case where using the checkpoint package could help you manage version conflicts ... once you find a time point for which all of the packages you want them to use seem to play well together, then they can invoke the checkpoint and be on the same page with you.

Of course, you will have to make other sacrifices, like using an older version of R (I don't think the MRAN historical package archive is keeping up) and not having access to some cool stuff from recent advances in package features, but there aren't many options that can keep 15000+ packages all working and bugfixed in sync.


On April 29, 2020 8:00:43 PM PDT, Steven <syen at hqu.edu.cn> wrote:
>Good point, but I am bothered by the non-discrimatory warning message
>to 
>all package installation attempts. My students install mostly binary 
>files, and I just hate to have them install Rtools. For one, they have 
>not had to do so until after RStudio-1.1.463. The fact that using this 
>older RStudio? can avoid the annoying warning message speaks volume.
>
>On 2020/4/30 ?? 10:02, Bert Gunter wrote:
>> Wouldn't packages that have to be built from source on installation
>> require Rtools?
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Apr 29, 2020 at 6:48 PM Steven <syen at hqu.edu.cn> wrote:
>>> Thanks to all - very helpful. I search from c:\ and now find file
>>> .Renviron located in C:\Users\USER\Documents. That does it.
>>>
>>> I would like to pose an additional question, since it would also
>fall
>>> under the same subject line. This is an RStudio question but since I
>am
>>> using the free version the RStudio folks would not help me.
>>>
>>> My students simply need to install packages and are not building any
>>> packages so they have no reason to install Rtools.
>>>
>>> When they install (not build) packages (from CRAN or file archive)
>they
>>> received the same warning message saying
>>>
>>> "Rtools required to build a package".
>>>
>>> This is nonsense of course as they are, as I said, simply
>installing. I
>>> tell them to user an older RStudio version, specifically 1.1.463
>that's
>>> free of that warning. Any idea?
>>>
>>> Steven Yen
>>>
>>> On 2020/4/30 ?? 06:30, Fox, John wrote:
>>>> Dear Steven,
>>>>
>>>> It's possible that Windows will hide .Renviron, but it's generally
>a good idea, in my opinion, in Folder Options > View to click "Show
>hidden files" and uncheck "hide extensions". Then .Renviron should show
>up (once you've created it).
>>>>
>>>> Best,
>>>>    John
>>>>
>>>>> -----Original Message-----
>>>>> From: Bert Gunter <bgunter.4567 at gmail.com>
>>>>> Sent: Wednesday, April 29, 2020 5:50 PM
>>>>> To: Steven <syen at hqu.edu.cn>
>>>>> Cc: Fox, John <jfox at mcmaster.ca>; R-help Mailing List <r-help at r-
>>>>> project.org>
>>>>> Subject: Re: [R] Rtools required
>>>>>
>>>>> Type
>>>>> ?.Renviron
>>>>> ?R.home
>>>>> ?"environment variables"
>>>>>
>>>>> at the R prompt to get what I think should be the info you need
>(or at
>>>>> least useful info).
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming
>along and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>> On Wed, Apr 29, 2020 at 2:37 PM Steven <syen at hqu.edu.cn> wrote:
>>>>>> Thanks John. Where is file .Renviron located? It must be a hidden
>file.
>>>>>> I cannot find it.
>>>>>>
>>>>>> On 2020/4/28 ?? 08:29, Fox, John wrote:
>>>>>>> Dear Steven,
>>>>>>>
>>>>>>> Did you follow the instruction on the Rtools webpage to add
>>>>>>>
>>>>>>>         PATH="${RTOOLS40_HOME}\usr\bin;${PATH}"
>>>>>>>
>>>>>>> to your .Renviron file?
>>>>>>>
>>>>>>> I hope this helps,
>>>>>>>     John
>>>>>>>
>>>>>>>      -----------------------------
>>>>>>>      John Fox, Professor Emeritus
>>>>>>>      McMaster University
>>>>>>>      Hamilton, Ontario, Canada
>>>>>>>      Web: http::/socserv.mcmaster.ca/jfox
>>>>>>>
>>>>>>>> On Apr 28, 2020, at 4:38 AM, Steven <syen at hqu.edu.cn> wrote:
>>>>>>>>
>>>>>>>> Dear All
>>>>>>>>
>>>>>>>> I updated to R-4.0.0. and also installed the latest Rtools 4.0
>(to
>>>>>>>> now the new default folder c:\rtools40). While compiling a
>package
>>>>>>>> (binary) I received the follow marning message saying Rtools is
>>>>>>>> required. Any clues? Thanks.
>>>>>>>>
>>>>>>>> Steven Yen
>>>>>>>>
>>>>>>>> WARNING: Rtools is required to build R packages but is not
>>>>>>>> currently installed. Please download and install the
>appropriate
>>>>>>>> version of Rtools before proceeding:
>>>>>>>> https://cran.rstudio.com/bin/windows/Rtools/
>>>>>>>>
>>>>>>>>
>>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Thu Apr 30 19:21:52 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 30 Apr 2020 19:21:52 +0200
Subject: [R] repository for ubuntu/linux mint for R 4.0.0
In-Reply-To: <CA+vqiLHRY1D6ZW4Hj4TPRAdrN0FXKh3jxpOTkiWpNNKtTkQ=Nw@mail.gmail.com>
References: <9d3f6b5f-1195-896b-6b70-de434cc4af77@gmail.com>
 <20200430002643.GA654972@posteo.no>
 <CA+vqiLHRY1D6ZW4Hj4TPRAdrN0FXKh3jxpOTkiWpNNKtTkQ=Nw@mail.gmail.com>
Message-ID: <20200430172152.GA754594@posteo.no>

On 2020-04-30 12:50 -0400, Ista Zahn wrote:
> https://cran.r-project.org/mirmon_report.html

Wow!  Great!  Someone took the time to test the 
mirror list!

As we can see in this report, many of the mirrors 
are quite old compared to the openbsd mirrors in 
the spacehopper report ...  how this relates to 
the xenial-cran40 directory specifically, I do not 
know.  Only you can find it here too 
https://cran.ma.imperial.ac.uk/bin/linux/ubuntu/xenial-cran40/ 
:) 

Best,
Rasmus


From @yen @end|ng |rom hqu@edu@cn  Thu Apr 30 19:35:09 2020
From: @yen @end|ng |rom hqu@edu@cn (Steven)
Date: Fri, 1 May 2020 01:35:09 +0800
Subject: [R] Rtools required
In-Reply-To: <CABFfbXsLCB0YSNGTnCR_izYRw1EpjvV9hOJyGJJCNx6BkRrQeA@mail.gmail.com>
References: <25564_1588073153_03SBPmZL019568_25565dc8-c426-7745-7f43-89ca3a127450@hqu.edu.cn>
 <1CD3621D-B48B-4265-A82A-8776DB1D3643@mcmaster.ca>
 <34ffe72d-689c-62d3-eee3-4b789a6ca684@hqu.edu.cn>
 <CABFfbXsLCB0YSNGTnCR_izYRw1EpjvV9hOJyGJJCNx6BkRrQeA@mail.gmail.com>
Message-ID: <074defaf-31ab-59a8-3825-7cd7f0b32726@hqu.edu.cn>

Thank you all. In sum, installing packages from RStudio 1.2.5042 without 
Rtools present, I received warnings saying RTools required but 
installation nevertheless was successful.

Installing from R-4.0.0 directly, I have no problem.

This is obviously an RStudio problem but unfortunately they are not 
willing to help free version users. I feel so sorry having to post it here.

===

1. IN RStudio I reun the following to install from CRAC and from local a 
file, respectively:

Tools -> Install Packages -> (Choose Repository CRAN from pull-down menu)

Tools -> Install Packages -> (Packages, Archice, Files (.zip; .tar.gz) 
from pull-down menu)

In both cases, I received warning messages saying Rtools is required... 
but nevertheless the installation is successful.

2. Installing from R-4.0.0 directly, installation were successful 
without warning.

---

Install log listed below.

 > install.packages("A:/R/yenlib1_1.1.0.zip", repos = NULL, type = 
"win.binary")
WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
package ?yenlib1? successfully unpacked and MD5 sums checked

 > install.packages("aod")
WARNING: Rtools is required to build R packages but is not currently 
installed. Please download and install the appropriate version of Rtools 
before proceeding:

https://cran.rstudio.com/bin/windows/Rtools/
?? URL 'https://cran.rstudio.com/bin/windows/contrib/4.0/aod_1.3.1.zip'
Content type 'application/zip' length 382219 bytes (373 KB)
downloaded 373 KB

package ?aod? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\USER\AppData\Local\Temp\Rtmpsf04GM\downloaded_packages


<><><> Install from R4.0.0 directly: Worked fine <><>

Packages -> Install Packages
(Worked fine after selecting a Mirror)

 > utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
?? URL 
'https://mirror.las.iastate.edu/CRAN/bin/windows/contrib/4.0/aod_1.3.1.zip'
Content type 'application/zip' length 382219 bytes (373 KB)
downloaded 373 KB

package ?aod? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\USER\AppData\Local\Temp\RtmpauyB5Q\downloaded_packages

Packages -> Install Packages from local file

 > utils:::menuInstallLocal()
package ?yenlib1? successfully unpacked and MD5 sums checked
 >



On 2020/4/30 ?? 04:38, Jeroen Ooms wrote:
> On Wed, Apr 29, 2020 at 11:37 PM Steven <syen at hqu.edu.cn> wrote:
>> Hello John,
>>
>> Perhaps you can help me. I am an idiot. I visited the Rtools web page
>> and learn to run the following lines in R: Still I am getting the same
>> warning message.
>>
>>   > writeLines('PATH="${RTOOLS40_HOME}\\usr\\bin;${PATH}"', con =
>> "~/.Renviron")
>>   > Sys.which("make")
>>                                 make
>> "C:\\rtools40\\usr\\bin\\make.exe"
> That looks OK. Did you restart rstudio?
>
> How exactly are getting this error? Are you using install.packages()
> in R? Or using the pkgbuild package?
>
> Also are you running the latest version of rstudio? I think old
> versions may have had difficulty finding rtools40.


