From r.turner at auckland.ac.nz  Fri Nov  1 00:01:00 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 01 Nov 2013 12:01:00 +1300
Subject: [R] Efficient way to convert covariance to Euclidian distance
 matrix
In-Reply-To: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
References: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
Message-ID: <5272E12C.9020905@auckland.ac.nz>

On 10/31/13 23:14, Takatsugu Kobayashi wrote:
> Hi RUsers,
>
> I am struggling to come up with an efficient vectorized way to convert
> 20Kx20K covariance matrix to a Euclidian distance matrix as a surrogate for
> dissimilarity matrix. Hopefully I can apply multidimensional scaling for
> mapping these 20K points (commercial products).
>
> I understand that Distance(ij) = sigma(i) + sigma(j) - 2cov(ij). Without
> replying on a slow loop, I appreciate if anyone can help me out with a
> better idea - guess lapply?

As S. Ellison has pointed out, you probably want sigma^2 rather than sigma.

My suspicion is that with a 20K x 20K covariance matrix:

     * nothing will work

     * even if it did, the results would be meaningless numerical noise.

I.e.  Get real.

That being said, for a *reasonable* size of covariance matrix, the 
following might
do what you want:

     DM <- outer(diag(CM),diag(CM),"+") - 2*CM

where "CM" is the covariance matrix.  And then you might want to do

     DM <- sqrt(DM)

to get back to the original units (as S. Ellison indicated).

     cheers,

     Rolf Turner


From taquito2007 at gmail.com  Fri Nov  1 01:52:11 2013
From: taquito2007 at gmail.com (Takatsugu Kobayashi)
Date: Fri, 1 Nov 2013 09:52:11 +0900
Subject: [R] Efficient way to convert covariance to Euclidian distance
	matrix
In-Reply-To: <5272E12C.9020905@auckland.ac.nz>
References: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
	<5272E12C.9020905@auckland.ac.nz>
Message-ID: <CADL0PcjUFYsHYVT-8wNvnPjyytBGNP-beg9S=e1phci15ZZG=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/250b6a0e/attachment.pl>

From ranjanmano167 at gmail.com  Fri Nov  1 02:18:26 2013
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Fri, 1 Nov 2013 02:18:26 +0100
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <5272D158.6090408@sapo.pt>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
	<5272D158.6090408@sapo.pt>
Message-ID: <CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/f13a8f0d/attachment.pl>

From wdunlap at tibco.com  Fri Nov  1 02:48:25 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Nov 2013 01:48:25 +0000
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
	<5272D158.6090408@sapo.pt>
	<CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA11F72@PA-MBX01.na.tibco.com>

> it gives 'NA' (for whatever y value).

What 'y' values were you using?  inf_f maps probabilities (in [0,1]) to
values in the range of the orginal data, x, but it will have problems for
a probability below 1/length(x) because the original data didn't tell
you anything about the ecdf in that region.

   > X <- c(101, 103, 107, 111)
   > f <- ecdf(X)
   > inv_f <- inv_ecdf(f)
   > inv_f(seq(0, 1, by=1/8))
   [1]  NA  NA 101 102 103 105 107 109 111

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Manoranjan Muthusamy
> Sent: Thursday, October 31, 2013 6:18 PM
> To: Rui Barradas
> Cc: r-help at r-project.org
> Subject: Re: [R] Extracting values from a ecdf (empirical cumulative distribution function)
> curve
> 
> Thank you, Barradas. It works when finding y, but when I tried to find x
> using interpolation for a known y it gives 'NA' (for whatever y value). I
> couldn't find out the reason. Any help is really appreciated.
> 
> Thanks,
> Mano
> 
> 
> On Thu, Oct 31, 2013 at 10:53 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> > Hello,
> >
> > As for the problem of finding y given the ecdf and x, it's very easy, just
> > use the ecdf:
> >
> > f <- ecdf(rnorm(100))
> >
> > x <- rnorm(10)
> > y <- f(x)
> >
> > If you want to get the x corresponding to given y, use linear
> > interpolation.
> >
> > inv_ecdf <- function(f){
> >         x <- environment(f)$x
> >         y <- environment(f)$y
> >         approxfun(y, x)
> > }
> >
> > g <- inv_ecdf(f)
> > g(0.5)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 31-10-2013 12:25, Manoranjan Muthusamy escreveu:
> >
> >> Hi R users,
> >>
> >> I am a new user, still learning basics of R. Is there anyway to extract y
> >> (or x) value for a known x (or y) value from ecdf (empirical cumulative
> >> distribution function) curve?
> >>
> >> Thanks in advance.
> >> Mano.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________**________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/**listinfo/r-
> help<https://stat.ethz.ch/mailman/listinfo/r-help>
> >> PLEASE do read the posting guide http://www.R-project.org/**
> >> posting-guide.html <http://www.R-project.org/posting-guide.html>
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Fri Nov  1 03:40:14 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 1 Nov 2013 12:40:14 +1000
Subject: [R] Extracting values from a ecdf (empirical cumulative
	distribution function) curve
In-Reply-To: <CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>	<5272D158.6090408@sapo.pt>
	<CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
Message-ID: <000001ced6ab$b17f6170$147e2450$@bigpond.com>

Hi

There is a print method for ecdf

So print(f) should give you an idea of what is going on

See ?ecdf

HTH

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Manoranjan Muthusamy
Sent: Friday, 1 November 2013 11:18
To: Rui Barradas
Cc: r-help at r-project.org
Subject: Re: [R] Extracting values from a ecdf (empirical cumulative
distribution function) curve

Thank you, Barradas. It works when finding y, but when I tried to find x
using interpolation for a known y it gives 'NA' (for whatever y value). I
couldn't find out the reason. Any help is really appreciated.

Thanks,
Mano


On Thu, Oct 31, 2013 at 10:53 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> As for the problem of finding y given the ecdf and x, it's very easy, 
> just use the ecdf:
>
> f <- ecdf(rnorm(100))
>
> x <- rnorm(10)
> y <- f(x)
>
> If you want to get the x corresponding to given y, use linear 
> interpolation.
>
> inv_ecdf <- function(f){
>         x <- environment(f)$x
>         y <- environment(f)$y
>         approxfun(y, x)
> }
>
> g <- inv_ecdf(f)
> g(0.5)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 31-10-2013 12:25, Manoranjan Muthusamy escreveu:
>
>> Hi R users,
>>
>> I am a new user, still learning basics of R. Is there anyway to 
>> extract y (or x) value for a known x (or y) value from ecdf 
>> (empirical cumulative distribution function) curve?
>>
>> Thanks in advance.
>> Mano.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/m
>> ailman/listinfo/r-help> PLEASE do read the posting guide 
>> http://www.R-project.org/** posting-guide.html 
>> <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bowenli37 at gmail.com  Fri Nov  1 05:34:04 2013
From: bowenli37 at gmail.com (Li Bowen)
Date: Fri, 01 Nov 2013 12:34:04 +0800
Subject: [R] R with openblas and atlas
Message-ID: <87habwbv0j.fsf@nus.edu.sg>

Hi,

I have been trying to build R with optimized BLAS library.

I am using a Ubuntu 13.10 x86_64 desktop, on which I am able to build R
with openblas without any problem:

#BEGIN_SRC sh
./configure --enable-BLAS-shlib --enable-R-shlib LIBnn=lib --disable-nls --with-blas="-L/usr/lib/openblas-base/ -lopenblas" --enable-memory-profiling
make
sudo make install
#END_SRC

However, on redhat 5.9, I am not able to install openblas.
Firstly, there is no pre-built package, even for later version of
redhat.
Secondly, I am not able to build openblas from source, actually not even
able to install newer gcc from source.

I then tried to install ATLAS on redhat and build R with it. -t 2: 2 threads
#BEGIN_SRC sh
../configure --shared -t 2 -b 64 -D c -DPentiumCPS=1600
--with-netlib-lapack-tarfile=/path-to-lapack-3.4.2.tgz
make build
make check
make ptcheck
make time
make install

# R
../configure --enable-BLAS-shlib --enable-R-shlib --disable-nls
--enable-memory-profiling --with-blas="-L/usr/local/atlas/lib
-lptf77blas -lpthread -latlas"
make
sudo make install
#END_SRC

Installation is successful. However when I run the following code, only
one thread is used.

I have looked through lots of manuals and forums and couldn't find an
answer. Please advise. Thanks a lot.

-- 
Sincerely,
Bowen


From szehnder at uni-bonn.de  Fri Nov  1 08:42:11 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 1 Nov 2013 08:42:11 +0100
Subject: [R] R with openblas and atlas
In-Reply-To: <87habwbv0j.fsf@nus.edu.sg>
References: <87habwbv0j.fsf@nus.edu.sg>
Message-ID: <D6323453-9F13-401F-853E-4869324E4405@uni-bonn.de>

There is no R code following


On 01 Nov 2013, at 05:34, Li Bowen <bowenli37 at gmail.com> wrote:

> Hi,
> 
> I have been trying to build R with optimized BLAS library.
> 
> I am using a Ubuntu 13.10 x86_64 desktop, on which I am able to build R
> with openblas without any problem:
> 
> #BEGIN_SRC sh
> ./configure --enable-BLAS-shlib --enable-R-shlib LIBnn=lib --disable-nls --with-blas="-L/usr/lib/openblas-base/ -lopenblas" --enable-memory-profiling
> make
> sudo make install
> #END_SRC
> 
> However, on redhat 5.9, I am not able to install openblas.
> Firstly, there is no pre-built package, even for later version of
> redhat.
> Secondly, I am not able to build openblas from source, actually not even
> able to install newer gcc from source.
> 
> I then tried to install ATLAS on redhat and build R with it. -t 2: 2 threads
> #BEGIN_SRC sh
> ../configure --shared -t 2 -b 64 -D c -DPentiumCPS=1600
> --with-netlib-lapack-tarfile=/path-to-lapack-3.4.2.tgz
> make build
> make check
> make ptcheck
> make time
> make install
> 
> # R
> ../configure --enable-BLAS-shlib --enable-R-shlib --disable-nls
> --enable-memory-profiling --with-blas="-L/usr/local/atlas/lib
> -lptf77blas -lpthread -latlas"
> make
> sudo make install
> #END_SRC
> 
> Installation is successful. However when I run the following code, only
> one thread is used.
> 
> I have looked through lots of manuals and forums and couldn't find an
> answer. Please advise. Thanks a lot.
> 
> -- 
> Sincerely,
> Bowen
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohan.radhakrishnan at polarisft.com  Fri Nov  1 09:09:06 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 1 Nov 2013 13:39:06 +0530
Subject: [R] Replace element with pattern
Message-ID: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/96ecb386/attachment.pl>

From thomas.chesney at nottingham.ac.uk  Fri Nov  1 10:32:09 2013
From: thomas.chesney at nottingham.ac.uk (Thomas)
Date: Fri, 1 Nov 2013 09:32:09 +0000
Subject: [R] Combinations of values in two columns
Message-ID: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>

I have data that looks like this:

Friend1, Friend2
A, B
A, C
B, A
C, D

And I'd like to generate some more rows and another column. In the new  
column I'd like to add a 1 beside all the existing rows. That bit's  
easy enough.

Then I'd like to add rows for all the possible directed combinations  
of rows not included in the existing data. So for the above I think  
that would be:

A, D
D, A
B, C
C, B
B, D
C, A
D, B
D, C

and then put a 0 in the column beside these.

Can anyone suggest how to do this?

I'm using R version 2.15.3.

Thank you,

Thomas Chesney
This message and any attachment are intended solely for the addressee and may contain confidential information. If you have received this message in error, please send it back to me, and immediately delete it.   Please do not use, copy or disclose the information contained in this message or in any attachment.  Any views or opinions expressed by the author of this email do not necessarily reflect the views of the University of Nottingham.

This message has been checked for viruses but the contents of an attachment
may still contain software viruses which could damage your computer system, you are advised to perform your own checks. Email communications with the University of Nottingham may be monitored as permitted by UK legislation.


From petr.pikal at precheza.cz  Fri Nov  1 11:01:52 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 1 Nov 2013 10:01:52 +0000
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
	<CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B86A@SRVEXCHMBX.precheza.cz>

Hi

Another option is sapply/split/sum construction

with(data, sapply(split(x, ID), function(x) sum(x==0)))

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Carlos Nasher
> Sent: Thursday, October 31, 2013 6:46 PM
> To: S Ellison
> Cc: r-help at r-project.org
> Subject: Re: [R] Count number of consecutive zeros by group
> 
> If I apply your function to my test data:
> 
> ID <- c(1,1,1,2,2,3,3,3,3)
> x <- c(1,0,0,0,0,1,1,0,1)
> data <- data.frame(ID=ID,x=x)
> rm(ID,x)
> 
> f2 <-   function(x) {
>   max( rle(x == 0)$lengths )
> }
> with(data, tapply(x, ID, f2))
> 
> the result is
> 1 2 3
> 2 2 2
> 
> which is not what I'm aiming for. It should be
> 1 2 3
> 2 2 1
> 
> I think f2 does not return the max of consecutive zeros, but the max of
> any consecutve number... Any idea how to fix this?
> 
> 
> 2013/10/31 S Ellison <S.Ellison at lgcgroup.com>
> 
> >
> >
> > > -----Original Message-----
> > > So I want to get the max number of consecutive zeros of variable x
> > > for
> > each
> > > ID. I found rle() to be helpful for this task; so I did:
> > >
> > > FUN <- function(x) {
> > >   rles <- rle(x == 0)
> > > }
> > > consec <- lapply(split(df[,2],df[,1]), FUN)
> >
> > You're probably better off with tapply and a function that returns
> > what you want. You're probably also better off with a data frame name
> > that isn't a function name, so I'll use dfr instead of df...
> >
> > dfr<- data.frame(x=rpois(500, 1.5), ID=gl(5,100)) #5 ID groups
> > numbered 1-5, equal size but that doesn't matter for tapply
> >
> > f2 <-   function(x) {
> >         max( rle(x == 0)$lengths )
> > }
> > with(dfr, tapply(x, ID, f2))
> >
> >
> > S Ellison
> >
> >
> > *******************************************************************
> > This email and any attachments are confidential. Any
> > u...{{dropped:24}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Fri Nov  1 11:07:59 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 1 Nov 2013 11:07:59 +0100
Subject: [R] Combinations of values in two columns
In-Reply-To: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
References: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
Message-ID: <0817492A-2804-434E-84DA-803CF1DCC706@uni-bonn.de>

You could use the data.table package
require(data.table)

DT <- data.table(Friend1 = sample(LETTERS, 10, replace = TRUE), Friend2 = sample(LETTERS, 10, replace = TRUE), Indicator = 1)
ALL <- data.table(unique(expand.grid(DT)))
setkey(ALL) 
OTHERS <- ALL[!DT]
OTHERS[, Indicator := 0]

RESULT <- rbind(DT, ALL)

Best

Simon



On 01 Nov 2013, at 10:32, Thomas <Thomas.Chesney at nottingham.ac.uk> wrote:

> I have data that looks like this:
> 
> Friend1, Friend2
> A, B
> A, C
> B, A
> C, D
> 
> And I'd like to generate some more rows and another column. In the new column I'd like to add a 1 beside all the existing rows. That bit's easy enough.
> 
> Then I'd like to add rows for all the possible directed combinations of rows not included in the existing data. So for the above I think that would be:
> 
> A, D
> D, A
> B, C
> C, B
> B, D
> C, A
> D, B
> D, C
> 
> and then put a 0 in the column beside these.
> 
> Can anyone suggest how to do this?
> 
> I'm using R version 2.15.3.
> 
> Thank you,
> 
> Thomas Chesney
> This message and any attachment are intended solely for the addressee and may contain confidential information. If you have received this message in error, please send it back to me, and immediately delete it.   Please do not use, copy or disclose the information contained in this message or in any attachment.  Any views or opinions expressed by the author of this email do not necessarily reflect the views of the University of Nottingham.
> 
> This message has been checked for viruses but the contents of an attachment
> may still contain software viruses which could damage your computer system, you are advised to perform your own checks. Email communications with the University of Nottingham may be monitored as permitted by UK legislation.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccampbell at mango-solutions.com  Fri Nov  1 11:38:20 2013
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Fri, 1 Nov 2013 10:38:20 +0000
Subject: [R] Combinations of values in two columns
In-Reply-To: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
References: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C098D4B1E27@mexchange.Mango.local>

Hi Thomas,    
   
It depends whether you'd like to include all levels of each column in every column. For including all values you could try something like this:    
   
isAllDifferent <- function(z) !any(duplicated(z))   
    
myData <- data.frame(Friend1=c("a", "a", "b", "c"), Friend2=c("b", "c", "a", "d"), stringsAsFactors=FALSE)   
   
friends <- unique(unlist(myData, use.names=FALSE))   
  
allCombs <- do.call(expand.grid, rep(list(friends), ncol(myData)))    
   
colnames(allCombs) <- colnames(myData)   
  
allCombs <- allCombs[apply(allCombs, 1, isAllDifferent),]    
  
output <- cbind(allCombs, included=1*do.call(paste, allCombs)%in%do.call(paste, myData))     
  
output[order(output$included, decreasing=TRUE),]      
   Friend1 Friend2 included   
2        b       a        1   
5        a       b        1   
9        a       c        1   
15       c       d        1   
3        c       a        0   
4        d       a        0   
7        c       b        0   
8        d       b        0   
10       b       c        0   
12       d       c        0   
13       a       d        0   
14       b       d        0   
   
    
If you only want each column to contain its corresponding values, you could try something like this:   
   
myData <- data.frame(Friend1=c("a", "a", "b", "c"),   
    Friend2=c("b", "c", "a", "d"), new = 1)  
   
newData <- expand.grid(Friend1 = unique(myData$Friend1),   
    Friend2 = unique(myData$Friend2))  
   
output <- merge(myData, newData, all = TRUE)  
output$new[is.na(output$new)] <- 0    
  
output   
   Friend1 Friend2 new   
1        a       a   0   
2        a       b   1   
3        a       c   1  
4        a       d   0   
5        b       a   1  
6        b       b   0   
7        b       c   0   
8        b       d   0  
9        c       a   0  
10       c       b   0   
11       c       c   0    
12       c       d   1    
   
I hope this helps.   
   
Best wishes   
  
Chris   

Chris Campbell, PhD   
Tel. +44 (0) 1249 705 450?| Mobile. +44 (0) 7929 628349   
ccampbell at mango-solutions.com?| http://www.mango-solutions.com   
Data Analysis that Delivers   
Mango Solutions     
2 Methuen Park, Chippenham, Wiltshire. SN14 OGB UK    
   
-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
Sent: 01 November 2013 09:32
To: r-help at r-project.org
Subject: [R] Combinations of values in two columns

I have data that looks like this:

Friend1, Friend2
A, B
A, C
B, A
C, D

And I'd like to generate some more rows and another column. In the new column I'd like to add a 1 beside all the existing rows. That bit's easy enough.

Then I'd like to add rows for all the possible directed combinations of rows not included in the existing data. So for the above I think that would be:

A, D
D, A
B, C
C, B
B, D
C, A
D, B
D, C

and then put a 0 in the column beside these.

Can anyone suggest how to do this?

I'm using R version 2.15.3.

Thank you,

Thomas Chesney
This message and any attachment are intended solely for the addressee and may contain confidential information. If you have received this message in error, please send it back to me, and immediately delete it.   Please do not use, copy or disclose the information contained in this message or in any attachment.  Any views or opinions expressed by the author of this email do not necessarily reflect the views of the University of Nottingham.

This message has been checked for viruses but the contents of an attachment may still contain software viruses which could damage your computer system, you are advised to perform your own checks. Email communications with the University of Nottingham may be monitored as permitted by UK legislation.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From istazahn at gmail.com  Fri Nov  1 12:28:30 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 1 Nov 2013 07:28:30 -0400
Subject: [R] help with ggplot legend specification
In-Reply-To: <FB454C9C2759D64BA12708C3073C30BB6A0E63C098@NUEW-EXMBCRB1.gfk.com>
References: <FB454C9C2759D64BA12708C3073C30BB6A0E63C098@NUEW-EXMBCRB1.gfk.com>
Message-ID: <CA+vqiLHnyRcmnRopP=5MGxAsoHVYs02uh92jSE80KV2r=JnNkw@mail.gmail.com>

You can override the legend aesthetics, e.g.,

ggplot(df,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
    geom_point(shape=21,colour="black")+
    scale_size_area(max_size=pointsizefactor) +
    scale_fill_discrete(guide = guide_legend(override.aes = list(size = 4)))

Best,
Ista

On Thu, Oct 31, 2013 at 4:08 PM, Conklin, Mike (GfK)
<Mike.Conklin at gfk.com> wrote:
> I am creating a scatterplot with the following code.
>
>   pl<-ggplot(df,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
>       geom_point(shape=21,colour="black")+scale_size_area(max_size=pointsizefactor)
>
> points are plotted where the size of the point is related to a metric variable gapsize and the fill color on the point is related to the variable PBF which is a 4 level factor.  This works exactly as I want with the points varying in size based on the metric and being color coded.  I get 2 legends on the side of the plot, one related to the size of the dot and the other showing the color coding. The problem is that the dots on the color coding legend are so small that it is impossible to discern what color they are. The dots in the plot are large, so it is clear what colors they are, but the legend is useless.  How can I increase the size of the points in the color legend.
>
> pointsizefactor<-5
>
> df
>
>         Importance Performance gapsize labels       PBF
> q50451   0.7079463  -0.7213622       2      a         W
> q50452   0.4489164  -0.5552116       1      b         G
> q50453   0.7714138  -0.6940144       5      c         F
> q50454   0.6284830  -0.6011352       3      d         S
> q50455   0.7131063  -0.6800826       4      e         G
> q50456   0.7038184  -0.6026832       6      f         S
> q50457   0.5201238  -0.3539732       8      g         G
> q50458   0.9195046  -0.8214654       2      h         F
> q50459   0.3797730  -0.4184727       1      i         W
> q504510  0.8065015  -0.6305470       7      j         G
> q504511  0.6062951  -0.4442724       6      k         S
> q504512  0.6253870  -0.4478844       8      l         G
> q504513  0.3813209  -0.4102167       2      m         W
> q504514  0.3813209  -0.3436533       3      n         F
> q504515  0.5185759  -0.4365325       5      o         G
> q504516  0.5872033  -0.4556244       6      p         S
> q504518  0.5397317  -1.0000000       1      q         S
> q504519  0.5882353  -0.4674923       9      r         S
> q504520  0.4205366  -0.4164087       4      s         W
> q504521  0.7616099  -0.3323013      10      t         F
> q504522  0.7213622  -0.6088751       7      u         G
> q504523  0.6780186  -0.6130031       8      v         G
> q504524  0.6904025  -0.3937049      10      w         W
> q504525  0.4143447  -0.4669763       4      x         W
> q504526  0.5779154  -0.2982456       9      y         F
> q504527  0.6718266  -0.3457172      10      z         G
>
>
> Thanks all
>
> //Mike
>
> W. Michael Conklin
> Executive Vice President | Marketing Science
> GfK Custom Research, LLC | 8401 Golden Valley Road | Minneapolis, MN, 55427
> T +1 763 417 4545 | M +1 612 567 8287
> www.gfk.com<http://www.gfk.com/>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ranjanmano167 at gmail.com  Fri Nov  1 12:37:37 2013
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Fri, 1 Nov 2013 12:37:37 +0100
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA11F72@PA-MBX01.na.tibco.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
	<5272D158.6090408@sapo.pt>
	<CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA11F72@PA-MBX01.na.tibco.com>
Message-ID: <CANqyHbTnVMw10TLEe6Ror-6MFaS2tYzETUmt3KTm6wpCUYXOgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/71b8591e/attachment.pl>

From jholtman at gmail.com  Fri Nov  1 12:47:52 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 1 Nov 2013 07:47:52 -0400
Subject: [R] Replace element with pattern
In-Reply-To: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
Message-ID: <CAAxdm-7Cn62VdzDJTNpFiHnct9Lh6dxg+KFMouYveA70gb9mUw@mail.gmail.com>

try this:

> x <- rbind("Peak Usage    : init:2359296, used:15859328, committed:15892480,max:50331648Current Usage : init:2359296, used:15857920,committed:15892480, max:50331648|-------------------|")
> apply(x, 1, function(a) sub("(Current.*?[/|]).*", "\\1", a))
[1] "Peak Usage    : init:2359296, used:15859328,
committed:15892480,max:50331648Current Usage : init:2359296,
used:15857920,committed:15892480, max:50331648|"
>
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Nov 1, 2013 at 4:09 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
>          I have a data frame with one column and several rows of the form.
>
> "Peak Usage    : init:2359296, used:15859328, committed:15892480,
> max:50331648Current Usage : init:2359296, used:15857920,
> committed:15892480, max:50331648|-------------------|"
>
> I tested the regex
>
>  Current.*?[\|]
>
> in an online tester which greedily matches upto the first 'pipe' character
>
> Current Usage : init:2359296, used:15857920, committed:15892480,
> max:50331648|
>
> This is what I want.
>
> I tried to replace the entire rows using
>
> apply( y, 1, function(x) gsub(x,"Current.*?[/|]",x)) which didn't work.
>
> How is this done ? I also want to recursively apply some more patterns one
> by one on the rows till I reduce it to exactly what I want. Is there a way
> to do this without loops ?
>
> Thanks,
> Mohan
>
>
> This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohan.radhakrishnan at polarisft.com  Fri Nov  1 12:52:01 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 1 Nov 2013 17:22:01 +0530
Subject: [R] Replace element with pattern
In-Reply-To: <CAAxdm-7Cn62VdzDJTNpFiHnct9Lh6dxg+KFMouYveA70gb9mUw@mail.gmail.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
	<CAAxdm-7Cn62VdzDJTNpFiHnct9Lh6dxg+KFMouYveA70gb9mUw@mail.gmail.com>
Message-ID: <OFC76E02B9.E7A6CE3A-ON65257C16.0040FBD6-65257C16.00412ED8@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/7332406e/attachment.pl>

From dimitri.liakhovitski at gmail.com  Fri Nov  1 13:16:53 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 1 Nov 2013 08:16:53 -0400
Subject: [R] ggplot2 - how to get rid of bar boarder lines
In-Reply-To: <4041E51814D.00000973jrkrideau@inbox.com>
References: <CAN2xGJZeEzGqbc9JC=ucM-K8etJMP=xyYtxCgouEUV1oZY=p0w@mail.gmail.com>
	<4041E51814D.00000973jrkrideau@inbox.com>
Message-ID: <CAN2xGJbnfw4BkD91hjLfR1_yeen-FUMQGeFPqYJYUm=dkNwibQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/f40a1151/attachment.pl>

From ishaqbaba at yahoo.com  Fri Nov  1 11:06:38 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Fri, 1 Nov 2013 03:06:38 -0700 (PDT)
Subject: [R] computation of hessian matrix
Message-ID: <1383300398.80446.YahooMailNeo@web142506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/bca2c11f/attachment.pl>

From tstudent at gmail.com  Fri Nov  1 12:10:40 2013
From: tstudent at gmail.com (Tstudent)
Date: Fri, 1 Nov 2013 11:10:40 +0000
Subject: [R] Load Tawny package on R 2.15.3
Message-ID: <loom.20131101T120934-572@post.gmane.org>



I have R version 2.15.3 When i try to load it:

library (tawny)

i receive this response:

package ?parser? could not be loaded

The package Parser in not on Cran anymore, it seems a dead project!
http://cran.r-project.org/web/packages/parser/index.html

If i try to manual install parser_0.1.tar.gz i receive an error and can't
install it.

The question is. Is today impossible to use tawny package? Is there a way to
solve this problem that seems caused by parser package?

Thank you very much


From daniel.fernandes at ine.pt  Fri Nov  1 13:08:56 2013
From: daniel.fernandes at ine.pt (Daniel Fernandes)
Date: Fri, 1 Nov 2013 12:08:56 +0000
Subject: [R] aggregate function output
Message-ID: <H00002fe09c2c514.1383307736.scalix.lx.ine.pt@MHS>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/238ad819/attachment.pl>

From smartpink111 at yahoo.com  Fri Nov  1 14:09:49 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 06:09:49 -0700 (PDT)
Subject: [R] Replace element with pattern
In-Reply-To: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
Message-ID: <1383311389.45470.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,

Try this:

Lines1 <- readLines(textConnection("Peak Usage??? : init:2359296, used:15859328, committed:15892480,max:50331648Current Usage : init:2359296 used:15857920,committed:15892480,max:50331648|-------------------|
Peak Usage??? : init:2359296, used:15859328, committed:15892480,max:50331648Current Usage : init:2359296 used:15857920,committed:15892480,max:50331648|-------------------|"))

data.frame(Col1=as.matrix(gsub("(.*?[/|])","\\1",Lines1))) #Assuming that you want to read it from Peak Usage to the first "|":

#If it is from Current Usage to "|"

data.frame(Col1=as.matrix(gsub("^.*(Current.*?[/|]).*","\\1",Lines1)))


A.K.


On Friday, November 1, 2013 4:11 AM, "mohan.radhakrishnan at polarisft.com" <mohan.radhakrishnan at polarisft.com> wrote:
Hi,
? ? ? ?  I have a data frame with one column and several rows of the form.

"Peak Usage? ? : init:2359296, used:15859328, committed:15892480, 
max:50331648Current Usage : init:2359296, used:15857920, 
committed:15892480, max:50331648|-------------------|"

I tested the regex 

Current.*?[\|]

in an online tester which greedily matches upto the first 'pipe' character

Current Usage : init:2359296, used:15857920, committed:15892480, 
max:50331648|

This is what I want.

I tried to replace the entire rows using 

apply( y, 1, function(x) gsub(x,"Current.*?[/|]",x)) which didn't work.

How is this done ? I also want to recursively apply some more patterns one 
by one on the rows till I reduce it to exactly what I want. Is there a way 
to do this without loops ?

Thanks,
Mohan


This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.? If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Nov  1 14:17:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 06:17:19 -0700 (PDT)
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B86A@SRVEXCHMBX.precheza.cz>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>	<CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B86A@SRVEXCHMBX.precheza.cz>
Message-ID: <1383311839.44020.YahooMailNeo@web142603.mail.bf1.yahoo.com>

I think this gives a different result than the one OP asked for:

df1 <- structure(list(ID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), x = c(1, 0, 
0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0)), .Names = c("ID", 
"x"), row.names = c(NA, -22L), class = "data.frame")

with(df1, sapply(split(x, ID), function(x) sum(x==0)))

with(df1,tapply(x,list(ID),function(y) {rl <- rle(!y); max(c(0,rl$lengths[rl$values]))}))


A.K.


On Friday, November 1, 2013 6:01 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
Hi

Another option is sapply/split/sum construction

with(data, sapply(split(x, ID), function(x) sum(x==0)))

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Carlos Nasher
> Sent: Thursday, October 31, 2013 6:46 PM
> To: S Ellison
> Cc: r-help at r-project.org
> Subject: Re: [R] Count number of consecutive zeros by group
> 
> If I apply your function to my test data:
> 
> ID <- c(1,1,1,2,2,3,3,3,3)
> x <- c(1,0,0,0,0,1,1,0,1)
> data <- data.frame(ID=ID,x=x)
> rm(ID,x)
> 
> f2 <-?  function(x) {
>?  max( rle(x == 0)$lengths )
> }
> with(data, tapply(x, ID, f2))
> 
> the result is
> 1 2 3
> 2 2 2
> 
> which is not what I'm aiming for. It should be
> 1 2 3
> 2 2 1
> 
> I think f2 does not return the max of consecutive zeros, but the max of
> any consecutve number... Any idea how to fix this?
> 
> 
> 2013/10/31 S Ellison <S.Ellison at lgcgroup.com>
> 
> >
> >
> > > -----Original Message-----
> > > So I want to get the max number of consecutive zeros of variable x
> > > for
> > each
> > > ID. I found rle() to be helpful for this task; so I did:
> > >
> > > FUN <- function(x) {
> > >?  rles <- rle(x == 0)
> > > }
> > > consec <- lapply(split(df[,2],df[,1]), FUN)
> >
> > You're probably better off with tapply and a function that returns
> > what you want. You're probably also better off with a data frame name
> > that isn't a function name, so I'll use dfr instead of df...
> >
> > dfr<- data.frame(x=rpois(500, 1.5), ID=gl(5,100)) #5 ID groups
> > numbered 1-5, equal size but that doesn't matter for tapply
> >
> > f2 <-?  function(x) {
> >? ? ? ?  max( rle(x == 0)$lengths )
> > }
> > with(dfr, tapply(x, ID, f2))
> >
> >
> > S Ellison
> >
> >
> > *******************************************************************
> > This email and any attachments are confidential. Any
> > u...{{dropped:24}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jvadams at usgs.gov  Fri Nov  1 14:25:49 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 1 Nov 2013 08:25:49 -0500
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <op.w5tse2qzzqkd1e@bam>
References: <op.w5tse2qzzqkd1e@bam>
Message-ID: <CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/550eed0d/attachment.pl>

From jvadams at usgs.gov  Fri Nov  1 14:31:46 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 1 Nov 2013 08:31:46 -0500
Subject: [R] aggregate function output
In-Reply-To: <H00002fe09c2c514.1383307736.scalix.lx.ine.pt@MHS>
References: <H00002fe09c2c514.1383307736.scalix.lx.ine.pt@MHS>
Message-ID: <CAN5YmCF22ptYY_iQWpGBwsP3oEcwpMZev1+9Q2Y1FbXfiVCvpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/63dea13b/attachment.pl>

From zulutime.net at gmail.com  Fri Nov  1 14:32:46 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Fri, 01 Nov 2013 13:32:46 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
Message-ID: <5273AD7E.6090607@gmail.com>

Pretty much what the subject says:

I used an env as the basis for a Hashtable in R, based on information 
that this is in fact the way environments are implemented under the hood.

I've been experimenting with doubling the number of entries, and so far 
it has seemed to be scaling more or less linearly, as expected.

But as I went from 17 million entries to 34 million entries, the 
completion time has gone from 18 hours, to 5 days and counting.


The keys and values are in all cases strings of equal length.

One might suspect that the slow-down might have to do with the memory 
being swapped to disk, but from what I know about my computing 
environment, that should not be the case.

So my first question:
Is anyone familiar with anything in the implementation of environments 
that would limit their use or slow them down (faster than O(nlog(n)) as 
the number of entries is increased?

And my second question:
I realize that this is not strictly what R environments were designed 
for, but this is what my algorithm requires: I must go through these 
millions of entries, storing them in the hash table and sometimes 
retrieving them along the way, in a more or less random manner, which is 
contingent on the data I am encountering, and on the contents of the 
hash table at each moment.

Does anyone have a good recommendation for alternatives to implement 
huge, fast, table-like structures in R?

Best,
Magnus


From smartpink111 at yahoo.com  Fri Nov  1 14:35:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 06:35:19 -0700 (PDT)
Subject: [R] aggregate function output
Message-ID: <1383312919.42543.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
do.call(data.frame,c(x,check.names=FALSE))
A.K.


Hello, 

? 

I?m using function aggregate in R 3.0.2. ?If I run the instruction 
x<-aggregate(cbind(mpg,hp)~cyl+gear,data=mtcars,quantile) I get the 
result the following data.frame: 

? 

cyl 

gear 

mpg.0% 

mpg.25% 

mpg.50% 

mpg.75% 

mpg.100% 

hp.0% 

hp.25% 

hp.50% 

hp.75% 

hp.100% 

4 

3 

21.5 

21.5 

21.5 

21.5 

21.5 

97 

97 

97 

97 

97 

6 

3 

18.1 

18.925 

19.75 

20.575 

21.4 

105 

106.25 

107.5 

108.75 

110 

8 

3 

10.4 

14.05 

15.2 

16.625 

19.2 

150 

175 

180 

218.75 

245 

4 

4 

21.4 

22.8 

25.85 

30.9 

33.9 

52 

64.25 

66 

93.5 

109 

6 

4 

17.8 

18.85 

20.1 

21 

21 

110 

110 

116.5 

123 

123 

4 

5 

26 

27.1 

28.2 

29.3 

30.4 

91 

96.5 

102 

107.5 

113 

6 

5 

19.7 

19.7 

19.7 

19.7 

19.7 

175 

175 

175 

175 

175 

8 

5 

15 

15.2 

15.4 

15.6 

15.8 

264 

281.75 

299.5 

317.25 

335 

? 

So far so good, however the strange part happens when I run dim(x) or 
names(x), because the results are 8 4 (dim(x)) and "cyl" ?"gear" "mpg" 
"hp" (names(x)). Why this occurs and how do I transform it in a regular 
data.frame with 12 columns? 

? 

Thank you in advance, 

? 

Daniel 

? 

> sessionInfo() 

R version 3.0.2 (2013-09-25) 

Platform: i386-w64-mingw32/i386 (32-bit) 

? 

locale: 

[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252 
LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C ? ? ? ? ? ? ? ? ? ? ? 


[5] LC_TIME=Portuguese_Portugal.1252 ? ? 

? 

attached base packages: 

[1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils ? 
methods ? base ? ? 

? 

other attached packages: 

[1] svSocket_0.9-55 TinnR_1.0-5 ? ? R2HTML_2.2.1 ? ?Hmisc_3.12-2 
Formula_1.1-1 ? survival_2.37-4 

? 

loaded via a namespace (and not attached): 

[1] cluster_1.14.4 ?grid_3.0.2 ? ? ?lattice_0.20-23 rpart_4.1-3 
svMisc_0.9-69 ? tools_3.0.2 ? 

? 



"Confidencialidade: Esta mensagem (e eventuais ficheiros
 anexos) ? destinada exclusivamente ?s pessoas nela indicadas e tem 
natureza confidencial. Se receber esta mensagem por engano, por favor 
contacte o remetente e elimine a mensagem e ficheiros, sem tomar 
conhecimento do respectivo conte?do e sem reproduzi-la ou divulg?-la. 

Confidentiality Warning: This e-mail message (and any attached 
files) is confidential and is intended solely for the use of the 
individual or entity to whom it is addressed. lf you are not the 
intended recipient of this message please notify the sender and delete 
and destroy all copies immediately."


From jholtman at gmail.com  Fri Nov  1 14:49:45 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 1 Nov 2013 09:49:45 -0400
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <5273AD7E.6090607@gmail.com>
References: <5273AD7E.6090607@gmail.com>
Message-ID: <CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>

It would be nice if you followed the posting guidelines and at least
showed the script that was creating your entries now so that we
understand the problem you are trying to solve.  A bit more
explanation of why you want this would be useful.  This gets to the
second part of my tag line:  Tell me what you want to do, not how you
want to do it.  There may be other solutions to your problem.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
<zulutime.net at gmail.com> wrote:
> Pretty much what the subject says:
>
> I used an env as the basis for a Hashtable in R, based on information that
> this is in fact the way environments are implemented under the hood.
>
> I've been experimenting with doubling the number of entries, and so far it
> has seemed to be scaling more or less linearly, as expected.
>
> But as I went from 17 million entries to 34 million entries, the completion
> time has gone from 18 hours, to 5 days and counting.
>
>
> The keys and values are in all cases strings of equal length.
>
> One might suspect that the slow-down might have to do with the memory being
> swapped to disk, but from what I know about my computing environment, that
> should not be the case.
>
> So my first question:
> Is anyone familiar with anything in the implementation of environments that
> would limit their use or slow them down (faster than O(nlog(n)) as the
> number of entries is increased?
>
> And my second question:
> I realize that this is not strictly what R environments were designed for,
> but this is what my algorithm requires: I must go through these millions of
> entries, storing them in the hash table and sometimes retrieving them along
> the way, in a more or less random manner, which is contingent on the data I
> am encountering, and on the contents of the hash table at each moment.
>
> Does anyone have a good recommendation for alternatives to implement huge,
> fast, table-like structures in R?
>
> Best,
> Magnus
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Fri Nov  1 15:13:12 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Fri, 1 Nov 2013 10:13:12 -0400
Subject: [R] Load Tawny package on R 2.15.3
In-Reply-To: <loom.20131101T120934-572@post.gmane.org>
References: <loom.20131101T120934-572@post.gmane.org>
Message-ID: <3A850008-CC66-420D-ADF6-7A2A2A55AD97@gmail.com>

The release version of tawny has no such dependency and builds just fine on CRAN. Try updating that instead. 

Michael

On Nov 1, 2013, at 7:10, Tstudent <tstudent at gmail.com> wrote:

> 
> 
> I have R version 2.15.3 When i try to load it:
> 
> library (tawny)
> 
> i receive this response:
> 
> package ?parser? could not be loaded
> 
> The package Parser in not on Cran anymore, it seems a dead project!
> http://cran.r-project.org/web/packages/parser/index.html
> 
> If i try to manual install parser_0.1.tar.gz i receive an error and can't
> install it.
> 
> The question is. Is today impossible to use tawny package? Is there a way to
> solve this problem that seems caused by parser package?
> 
> Thank you very much
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Fri Nov  1 15:16:35 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 1 Nov 2013 15:16:35 +0100
Subject: [R] Load Tawny package on R 2.15.3
In-Reply-To: <loom.20131101T120934-572@post.gmane.org>
References: <loom.20131101T120934-572@post.gmane.org>
Message-ID: <5273B7C3.4080209@statistik.tu-dortmund.de>

Install a recent version of tawny that does not depend on the other package?

Best,
Uwe Ligges




On 01.11.2013 12:10, Tstudent wrote:
>
>
> I have R version 2.15.3 When i try to load it:
>
> library (tawny)
>
> i receive this response:
>
> package ?parser? could not be loaded
>
> The package Parser in not on Cran anymore, it seems a dead project!
> http://cran.r-project.org/web/packages/parser/index.html
>
> If i try to manual install parser_0.1.tar.gz i receive an error and can't
> install it.
>
> The question is. Is today impossible to use tawny package? Is there a way to
> solve this problem that seems caused by parser package?
>
> Thank you very much
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Fri Nov  1 15:20:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 07:20:58 -0700 (PDT)
Subject: [R] aggregate function output
In-Reply-To: <1383312919.42543.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1383312919.42543.YahooMailNeo@web142606.mail.bf1.yahoo.com> 
Message-ID: <1383315658.9034.YahooMailNeo@web142604.mail.bf1.yahoo.com>

You could also try:
library(plyr)
?newdf <- function(.data, ...) {
?? eval(substitute(data.frame(...)), .data, parent.frame())
?}

x1 <- ddply(mtcars,.(cyl,gear), newdf, mgp=t(quantile(mpg)),hp=t(quantile(hp))) #(found in one of the google group discussions)
#or



library(data.table)
dt1 <- data.table(mtcars,key=c('cyl','gear'))
?dt2 <- dt1[,c(as.list(quantile(mpg)),as.list(quantile(hp))),by=key(dt1)]
?indx <- grep("%",names(dt2))
?x2 <- as.data.frame(dt2)
names(x2)[indx] <- paste(rep(c("mpg", "hp"),each=5), names(x2)[indx],sep=".")
A.K.





On Friday, November 1, 2013 9:35 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
do.call(data.frame,c(x,check.names=FALSE))
A.K.


Hello, 

? 

I?m using function aggregate in R 3.0.2. ?If I run the instruction 
x<-aggregate(cbind(mpg,hp)~cyl+gear,data=mtcars,quantile) I get the 
result the following data.frame: 

? 

cyl 

gear 

mpg.0% 

mpg.25% 

mpg.50% 

mpg.75% 

mpg.100% 

hp.0% 

hp.25% 

hp.50% 

hp.75% 

hp.100% 

4 

3 

21.5 

21.5 

21.5 

21.5 

21.5 

97 

97 

97 

97 

97 

6 

3 

18.1 

18.925 

19.75 

20.575 

21.4 

105 

106.25 

107.5 

108.75 

110 

8 

3 

10.4 

14.05 

15.2 

16.625 

19.2 

150 

175 

180 

218.75 

245 

4 

4 

21.4 

22.8 

25.85 

30.9 

33.9 

52 

64.25 

66 

93.5 

109 

6 

4 

17.8 

18.85 

20.1 

21 

21 

110 

110 

116.5 

123 

123 

4 

5 

26 

27.1 

28.2 

29.3 

30.4 

91 

96.5 

102 

107.5 

113 

6 

5 

19.7 

19.7 

19.7 

19.7 

19.7 

175 

175 

175 

175 

175 

8 

5 

15 

15.2 

15.4 

15.6 

15.8 

264 

281.75 

299.5 

317.25 

335 

? 

So far so good, however the strange part happens when I run dim(x) or 
names(x), because the results are 8 4 (dim(x)) and "cyl" ?"gear" "mpg" 
"hp" (names(x)). Why this occurs and how do I transform it in a regular 
data.frame with 12 columns? 

? 

Thank you in advance, 

? 

Daniel 

? 

> sessionInfo() 

R version 3.0.2 (2013-09-25) 

Platform: i386-w64-mingw32/i386 (32-bit) 

? 

locale: 

[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252 
LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C ? ? ? ? ? ? ? ? ? ? ? 


[5] LC_TIME=Portuguese_Portugal.1252 ? ? 

? 

attached base packages: 

[1] grDevices datasets ?splines ? graphics ?stats ? ? tcltk ? ? utils ? 
methods ? base ? ? 

? 

other attached packages: 

[1] svSocket_0.9-55 TinnR_1.0-5 ? ? R2HTML_2.2.1 ? ?Hmisc_3.12-2 
Formula_1.1-1 ? survival_2.37-4 

? 

loaded via a namespace (and not attached): 

[1] cluster_1.14.4 ?grid_3.0.2 ? ? ?lattice_0.20-23 rpart_4.1-3 
svMisc_0.9-69 ? tools_3.0.2 ? 

? 



"Confidencialidade: Esta mensagem (e eventuais ficheiros
anexos) ? destinada exclusivamente ?s pessoas nela indicadas e tem 
natureza confidencial. Se receber esta mensagem por engano, por favor 
contacte o remetente e elimine a mensagem e ficheiros, sem tomar 
conhecimento do respectivo conte?do e sem reproduzi-la ou divulg?-la. 

Confidentiality Warning: This e-mail message (and any attached 
files) is confidential and is intended solely for the use of the 
individual or entity to whom it is addressed. lf you are not the 
intended recipient of this message please notify the sender and delete 
and destroy all copies immediately."


From tghoward at gw.dec.state.ny.us  Fri Nov  1 15:49:18 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 01 Nov 2013 10:49:18 -0400
Subject: [R] spsurvey analysis
Message-ID: <5273872E020000D500B8180B@gwsmtp.dec.state.ny.us>

All,
I've used the excellent package, spsurvey, to create spatially balanced samples many times in the past. I'm now attempting to use the analysis portion of the package, which compares CDFs among sub-populations to test for differences in sub-population metrics. 
 
- My data (count data) have many zeros, following a negative binomial or even zero-inflated negative binomial distribution.
- Samples are within polygons of varying sizes
- I want to test whether a sample at time 1 is different from a sample at time 2. Essentially the same sample areas and number of samples.

The problem:
- cont.cdftest  throws a warning and does not complete for most (but not all) species sampled. Warning message: "The combined number of values in at least one class is less than five. Action: The user should consider using a smaller number of classes."

- There are plenty of samples in my two time periods (the dummy set below: Yr1=27, Yr2=31 non-zero values). 
 
My Question:
Why is it throwing this error and is there a way to get around it?



Reproduceable example (change path to spsurvey sample data), requires us to use spsurvey to generate sample points:

### R code tweaked from vignettes 'Area_Design' and 'Area_Analysis'
library(spsurvey)
### Analysis set up
setwd("C:/Program Files/R/R-3.0.2/library/spsurvey/doc")
att <- read.dbf("UT_ecoregions")
shp <- read.shape("UT_ecoregions")

set.seed(4447864)

# Create the design list
Stratdsgn <- list("Central Basin and Range"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Colorado Plateaus"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Mojave Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Northern Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Southern Rockies"=list(panel=c(PanelOne=14), seltype="Equal"),
                  "Wasatch and Uinta Mountains"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Wyoming Basin"=list(panel=c(PanelOne=6), seltype="Equal"))

# Select the sample design for each year
Stratsites_Yr1 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

Stratsites_Yr2 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

#extract the core information, add year as a grouping variable, add a plot ID to link with dummy data
Yr1 <- cbind(pltID = 1001:1100, Stratsites_Yr1 at data[,c(1,2,3,5)], grp = "Yr1")
Yr2 <- cbind(pltID = 2001:2100, Stratsites_Yr2 at data[,c(1,2,3,5)], grp = "Yr2")         
sitedat <- rbind(Yr1, Yr2)

# create dummy sampling data. Lots of zeros!
bn.a <- rnbinom(size = 0.06, mu = 19.87, n=100)
bn.b <- rnbinom(size = 0.06, mu = 20.15, n=100)
dat.a <- data.frame(pltID = 1001:1100, grp = "Yr1",count = bn.a)
dat.b <- data.frame(pltID = 2001:2100, grp = "Yr2",count = bn.b)
dat <- rbind(dat.a, dat.b)

####
## Analysis begins here
####
data.cont <- data.frame(siteID = dat$pltID, Density=dat$count)
sites <- data.frame(siteID = dat$pltID, Use=rep(TRUE, nrow(dat)))
subpop <- data.frame(siteID = dat$pltID, 
                        All_years=(rep("allYears",nrow(dat))),
                        Year = dat$grp)
design <- data.frame(siteID = sitedat$pltID,
                        wgt = sitedat$wgt,
                        xcoord = sitedat$xcoord,
                        ycoord = sitedat$ycoord)
framesize <- c("Yr1"=888081202000, "Yr2"=888081202000)                        
                        
## There seem to be pretty good estimates
CDF_Estimates <- cont.analysis(sites, subpop, design, data.cont, 
                        popsize = list(All_years=sum(framesize),
                        Year = as.list(framesize)))

print(CDF_Estimates$Pct)

## this test fails
CDF_Tests <- cont.cdftest(sites, subpop[,c(1,3)], design, data.cont,
   popsize=list(Year=as.list(framesize)))
warnprnt()

## how many records have values greater than zero, by year?   Probably irrelevant!
notZero <- dat[dat$count > 0,]
table(notZero$grp)

### end

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)
 
locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

Thanks in advance.
Tim


From wdunlap at tibco.com  Fri Nov  1 15:54:13 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Nov 2013 14:54:13 +0000
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <CANqyHbTnVMw10TLEe6Ror-6MFaS2tYzETUmt3KTm6wpCUYXOgw@mail.gmail.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
	<5272D158.6090408@sapo.pt>
	<CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA11F72@PA-MBX01.na.tibco.com>
	<CANqyHbTnVMw10TLEe6Ror-6MFaS2tYzETUmt3KTm6wpCUYXOgw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA12083@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/40e1ff30/attachment.pl>

From dimitri.liakhovitski at gmail.com  Fri Nov  1 16:19:55 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 1 Nov 2013 11:19:55 -0400
Subject: [R] ggplot2 - value labels + "adjusting position using y instead"
Message-ID: <CAN2xGJbVu6_WE9xqSjSsbbQOr1bzL=4jy3ZZ1EOHaSYYXbD_PA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/96784cf3/attachment.pl>

From zulutime.net at gmail.com  Fri Nov  1 16:22:37 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Fri, 01 Nov 2013 15:22:37 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
References: <5273AD7E.6090607@gmail.com>
	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
Message-ID: <5273C73D.2090809@gmail.com>

Sure,

I was attempting to be concise and boiling it down to what I saw as the 
root issue, but you are right, I could have taken it a step further. So 
here goes.

I have a set of around around 20M string pairs. A given string (say, A) 
can either be equivalent to another string (B) or not. If A and B occur 
together in the same pair, they are equivalent. But equivalence is 
transitive, so if A and B occur together in one pair, and A and C occur 
together in another pair, then A and C are also equivalent. I need a way 
to quickly determine if any two strings from my data set are equivalent 
or not.

The way I do this currently is to designate the smallest 
(alphabetically) string in each known equivalence set as the "main" 
entry. For each pair, I therefore insert two entries into the hash 
table, both pointing at the mail value. So assuming the input data:

A,B
B,C
D,E

I would then have:

A->A
B->A
C->B
D->D
E->D

Except that I also follow each chain until I reach the end (key==value), 
and insert pointers to the "main" value for every value I find along the 
way. After doing that, I end up with:

A->A
B->A
C->A
D->D
E->D

And I can very quickly check equivalence, either by comparing the hash 
of two strings, or simply by transforming each string into its hash, and 
then I can use simple comparison from then on. The code for generating 
the final hash table is as follows:

h : Empty hash table created with hash.new()
d : Input data
hash.deep.get : Function that iterates through the hash table until it 
finds a key whose value is equal to itself (until hash.get(X)==X), then 
returns all the values in a vector


h = hash.new()
for ( i in 1:nrow(d) )
{
     deep.a      = hash.deep.get(h, d$a[i])
     deep.b      = hash.deep.get(h, d$b[i])
     equivalents = sort(unique(c(deep.a,deep.b)))
     equiv.id    = min(equivalents)
     for ( equivalent in equivalents )
     {
         hash.put(h, equivalent, equiv.id)
     }
}


I would so much appreciate if there was a simpler and faster way to do 
this. Keeping my fingers crossed that one of the R-help geniuses who 
sees this is sufficiently interested to crack the problem

Best,
Magnus

On 11/1/2013 1:49 PM, jim holtman wrote:
> It would be nice if you followed the posting guidelines and at least
> showed the script that was creating your entries now so that we
> understand the problem you are trying to solve.  A bit more
> explanation of why you want this would be useful.  This gets to the
> second part of my tag line:  Tell me what you want to do, not how you
> want to do it.  There may be other solutions to your problem.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
> <zulutime.net at gmail.com> wrote:
>> Pretty much what the subject says:
>>
>> I used an env as the basis for a Hashtable in R, based on information that
>> this is in fact the way environments are implemented under the hood.
>>
>> I've been experimenting with doubling the number of entries, and so far it
>> has seemed to be scaling more or less linearly, as expected.
>>
>> But as I went from 17 million entries to 34 million entries, the completion
>> time has gone from 18 hours, to 5 days and counting.
>>
>>
>> The keys and values are in all cases strings of equal length.
>>
>> One might suspect that the slow-down might have to do with the memory being
>> swapped to disk, but from what I know about my computing environment, that
>> should not be the case.
>>
>> So my first question:
>> Is anyone familiar with anything in the implementation of environments that
>> would limit their use or slow them down (faster than O(nlog(n)) as the
>> number of entries is increased?
>>
>> And my second question:
>> I realize that this is not strictly what R environments were designed for,
>> but this is what my algorithm requires: I must go through these millions of
>> entries, storing them in the hash table and sometimes retrieving them along
>> the way, in a more or less random manner, which is contingent on the data I
>> am encountering, and on the contents of the hash table at each moment.
>>
>> Does anyone have a good recommendation for alternatives to implement huge,
>> fast, table-like structures in R?
>>
>> Best,
>> Magnus
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From ryan at urban-econ.com  Fri Nov  1 14:50:12 2013
From: ryan at urban-econ.com (Ryan)
Date: Fri, 01 Nov 2013 15:50:12 +0200
Subject: [R] forecast.lm() and NEWDATA
Message-ID: <5273B194.6010004@urban-econ.com>

Good day all.

I am hoping you can help me (and I did this right). I've been working in 
R for a week now, and have encountered a problem with forecast.lm().

I have a list of 12 variables, all type = double, with 15 data entries.
(I imported them from tab delimited text files, and then formatted 
as.numeric to change from list to double)
(I understand that this leaves me rather limited in my degrees of 
freedom, but working with what I have, sadly. )

I have a LM model, such that
REGGY = lm(formula=Y~A,B,C,...,I,J)
which I am happy with.

I have
NEWDATA = data.frame(A+B+C+D....+I+J)

When i try to run

forecast.lm(REGGY, h=5)

i receive the following error
"Error in as.data.frame(newdata) :
   argument "newdata" is missing, with no default"

When I run
forecast.lm(REGGY, NEWDATA, h=5)
I receive the confidence intervals of the 15 data entries I already 
possess. I understand that by including NEWDATA, the "h=5" is ignored, 
but without NEWDATA, I receive the error message.

Can anyone help me please?

Regards
Ryan

P.S The forecast is trying to predict the next 5 values for Y from the 
regression model pasted above. I'm a bit rusty with regressions, but I 
think I've covered my bases as well as I can, and from what I understand 
of the R code, I'm following the right steps.


From sartene at voila.fr  Fri Nov  1 16:27:38 2013
From: sartene at voila.fr (sartene at voila.fr)
Date: Fri, 1 Nov 2013 16:27:38 +0100 (CET)
Subject: [R] Irregular time series frequencies
In-Reply-To: <alpine.DEB.2.10.1310310839510.13198@paninaro.uibk.ac.at>
Message-ID: <1718018900.45941383319658233.JavaMail.www@wwinf7139>

Thanks a lot Achim!

This helped a lot. I do not have exactly what I want yet, but I now have promising ideas to gather my data and find what I'm looking for (especially as.numeric(x, 
units = "hours")).

Regards,


Sartene Bel


> Message du 31/10/13 ? 08h48
> De : "Achim Zeileis" 
> A : sartene at voila.fr
> Copie ? : r-help at r-project.org
> Objet : Re: [R] Irregular time series frequencies
> 
> On Wed, 30 Oct 2013, sartene at voila.fr wrote:
> 
> > Hi everyone,
> >
> > I have a data frame with email addresses in the first column and in the second column a list of times (of different lengths) at which an email was sent from 
the 
> > user in the first column.
> >
> > Here is an example of my data:
> >
> > Email Email_sent
> > john at doe.com "2013-09-26 15:59:55" "2013-09-27 09:48:29" "2013-09-27 10:00:02" "2013-09-27 10:12:54" 
> > jane at shoe.com "2013-09-26 09:50:28" "2013-09-26 14:41:24" "2013-09-26 14:51:36" "2013-09-26 17:50:10" "2013-09-27 13:34:02" "2013-09-27 14:41:10" 
> > "2013-09-27 15:37:36"
> > ...
> >
> > I cannot find any way to calculate the frequencies between each email sent for each user:
> > john at doe.com 0.02 email / hour
> > jane at shoe.com 0.15 email / hour
> > ...
> >
> > Can anyone help me on this problem?
> 
> You could do something like this:
> 
> ## scan your data file
> d <- scan(, what = "character")
> 
> ## here I use the data from above
> d <- scan(textConnection('john at doe.com "2013-09-26 15:59:55"
> "2013-09-27 09:48:29" "2013-09-27 10:00:02" "2013-09-27 10:12:54"
> jane at shoe.com "2013-09-26 09:50:28" "2013-09-26 14:41:24"
> "2013-09-26 14:51:36" "2013-09-26 17:50:10" "2013-09-27 13:34:02"
> "2013-09-27 14:41:10" "2013-09-27 15:37:36"'), what = "character")
> 
> ## find position of e-mail addresses
> n <- grep("@", dc, fixed = TRUE)
> 
> ## extract list of dates
> n <- c(n, length(d) + 1)
> x <- lapply(1:(length(n) - 1),
> function(i) as.POSIXct(d[(n[i] + 1):(n[i+1] - 1)]))
> 
> ## add e-mail addresses as names
> names(x) <- d[head(n, -1)]
> 
> ## functions that could extract quantities of interest such as
> ## number of mails per hour or mean time difference etc.
> meantime <- function(timevec)
> mean(as.numeric(diff(timevec), units = "hours"))
> numperhour <- function(timevec)
> length(timevec) / as.numeric(diff(range(timevec)), units = "hours")
> 
> ## apply to full list
> sapply(x, numperhour)
> sapply(x, meantime)
> 
> ## apply to list by date
> sapply(x, function(timevec) tapply(timevec, as.Date(timevec), numperhour))
> sapply(x, function(timevec) tapply(timevec, as.Date(timevec), meantime))
> 
> hth,
> Z
> 
> > The ultimate goal (which seems amibitious at this time) is to calculate, for each user, the frequencies between each mail per day, between the first email sent 
> > and the last email sent each day (to avoid taking nights into account), i.e.:
> >
> > 2013-09-26 2013-09-27
> > john at doe.com 1.32 emails / hour 0.56 emails / hour
> > jane at shoe.com 10.57 emails / hour 2.54 emails / hour
> > ...
> >
> > At this time it seems pretty impossible, but I guess I will eventually find a way :-)
> >
> > Thanks a lot,
> >
> >
> > Sartene Bel
> > R learner
> > ___________________________________________________________
> > Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
___________________________________________________________
Qu'y a-t-il ce soir ? la t?l? ? D'un coup d'?il, visualisez le programme sur Voila.fr http://tv.voila.fr/programmes/chaines-tnt/ce-soir.html


From tstudent at gmail.com  Fri Nov  1 15:33:37 2013
From: tstudent at gmail.com (Tstudent)
Date: Fri, 1 Nov 2013 14:33:37 +0000
Subject: [R] Load Tawny package on R 2.15.3
References: <loom.20131101T120934-572@post.gmane.org>
	<5273B7C3.4080209@statistik.tu-dortmund.de>
Message-ID: <loom.20131101T153217-685@post.gmane.org>


Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:

> 
> Install a recent version of tawny that does not depend on the other package?



The most recent version is this:
http://cran.r-project.org/web/packages/tawny/index.html

I can install, but can't load without parser package.
It seems true for 2.15.3 version of R

Someone says that with R 3.0 no problem.

My question is if there is some possibility to have a working tawny on R 2.15.3

I don't want upgrade to R 3.0 because have one package that doesn't work on
R 3.0


From gunter.berton at gene.com  Fri Nov  1 16:55:18 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 1 Nov 2013 08:55:18 -0700
Subject: [R] Load Tawny package on R 2.15.3
In-Reply-To: <loom.20131101T153217-685@post.gmane.org>
References: <loom.20131101T120934-572@post.gmane.org>
	<5273B7C3.4080209@statistik.tu-dortmund.de>
	<loom.20131101T153217-685@post.gmane.org>
Message-ID: <CACk-te2XhncW5tG5Y=nN2CqTGwM-mrXUjV=yuKxbbSniWu7-aA@mail.gmail.com>

(Inline)

On Fri, Nov 1, 2013 at 7:33 AM, Tstudent <tstudent at gmail.com> wrote:
>
> Uwe Ligges <ligges <at> statistik.tu-dortmund.de> writes:
>
>>
>> Install a recent version of tawny that does not depend on the other package?
>
>
>
> The most recent version is this:
> http://cran.r-project.org/web/packages/tawny/index.html
>
> I can install, but can't load without parser package.
> It seems true for 2.15.3 version of R
>
> Someone says that with R 3.0 no problem.
>
> My question is if there is some possibility to have a working tawny on R 2.15.3
>
> I don't want upgrade to R 3.0 because have one package that doesn't work on
> R 3.0

I have no specific expertise here, but I just wanted to point out that
this sounds like a losing strategy long term: As new packages and
newer versions of packages come out that fix bugs and add features,
you'll be unable to use them because you'll be stuck with 2.15.3 . I
suggest you bite the bullet and follow the experts' advice to get
things working with the current R version now.

Cheers,
Bert

>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From petr.pikal at precheza.cz  Fri Nov  1 17:24:36 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 1 Nov 2013 16:24:36 +0000
Subject: [R] Count number of consecutive zeros by group
In-Reply-To: <1383311839.44020.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAP=BVWPwu7B9WHtmyhCapQby2EX=YXjLnquoZrmqDdLyd=rh-g@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5554EA9DFB@GOLD.corp.lgc-group.com>
	<CAP=BVWN+wD10GCiRFCJiMQRHZ0AA8Y=e+G1i3UGDqkP0w0ixzQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9B86A@SRVEXCHMBX.precheza.cz>
	<1383311839.44020.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9BA9F@SRVEXCHMBX.precheza.cz>

Hi

Yes you are right. This gives number of zeroes not max number of consecutive zeroes.

Regards
Petr


> -----Original Message-----
> From: arun [mailto:smartpink111 at yahoo.com]
> Sent: Friday, November 01, 2013 2:17 PM
> To: R help
> Cc: PIKAL Petr; Carlos Nasher
> Subject: Re: [R] Count number of consecutive zeros by group
> 
> I think this gives a different result than the one OP asked for:
> 
> df1 <- structure(list(ID = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), x = c(1, 0, 0, 1, 0,
> 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0)), .Names = c("ID",
> "x"), row.names = c(NA, -22L), class = "data.frame")
> 
> with(df1, sapply(split(x, ID), function(x) sum(x==0)))
> 
> with(df1,tapply(x,list(ID),function(y) {rl <- rle(!y);
> max(c(0,rl$lengths[rl$values]))}))
> 
> 
> A.K.
> 
> 
> On Friday, November 1, 2013 6:01 AM, PIKAL Petr
> <petr.pikal at precheza.cz> wrote:
> Hi
> 
> Another option is sapply/split/sum construction
> 
> with(data, sapply(split(x, ID), function(x) sum(x==0)))
> 
> Regards
> Petr
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Carlos Nasher
> > Sent: Thursday, October 31, 2013 6:46 PM
> > To: S Ellison
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Count number of consecutive zeros by group
> >
> > If I apply your function to my test data:
> >
> > ID <- c(1,1,1,2,2,3,3,3,3)
> > x <- c(1,0,0,0,0,1,1,0,1)
> > data <- data.frame(ID=ID,x=x)
> > rm(ID,x)
> >
> > f2 <-?  function(x) {
> >?  max( rle(x == 0)$lengths )
> > }
> > with(data, tapply(x, ID, f2))
> >
> > the result is
> > 1 2 3
> > 2 2 2
> >
> > which is not what I'm aiming for. It should be
> > 1 2 3
> > 2 2 1
> >
> > I think f2 does not return the max of consecutive zeros, but the max
> > of any consecutve number... Any idea how to fix this?
> >
> >
> > 2013/10/31 S Ellison <S.Ellison at lgcgroup.com>
> >
> > >
> > >
> > > > -----Original Message-----
> > > > So I want to get the max number of consecutive zeros of variable
> x
> > > > for
> > > each
> > > > ID. I found rle() to be helpful for this task; so I did:
> > > >
> > > > FUN <- function(x) {
> > > >?  rles <- rle(x == 0)
> > > > }
> > > > consec <- lapply(split(df[,2],df[,1]), FUN)
> > >
> > > You're probably better off with tapply and a function that returns
> > > what you want. You're probably also better off with a data frame
> > > name that isn't a function name, so I'll use dfr instead of df...
> > >
> > > dfr<- data.frame(x=rpois(500, 1.5), ID=gl(5,100)) #5 ID groups
> > > numbered 1-5, equal size but that doesn't matter for tapply
> > >
> > > f2 <-?  function(x) {
> > >? ? ? ?  max( rle(x == 0)$lengths )
> > > }
> > > with(dfr, tapply(x, ID, f2))
> > >
> > >
> > > S Ellison
> > >
> > >
> > > *******************************************************************
> > > This email and any attachments are confidential. Any
> > > u...{{dropped:24}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From richardkwock at gmail.com  Fri Nov  1 17:30:44 2013
From: richardkwock at gmail.com (Richard Kwock)
Date: Fri, 1 Nov 2013 09:30:44 -0700
Subject: [R] Lattice Legend/Key by row instead of by column
In-Reply-To: <000001ced68b$39004400$ab00cc00$@bigpond.com>
References: <CAJU8Py06n=EBxAP=HBbiUBcGjyXK7ye=qQCat2L_LvTHP+w2Lg@mail.gmail.com>
	<000001ced68b$39004400$ab00cc00$@bigpond.com>
Message-ID: <CAJU8Py2wzob3OoRSgzZ4QOw4zHg8TpRJfTzLvyvv6PBTJnVAAw@mail.gmail.com>

Hi Duncan,

Thanks for that template. Not quite the solution I was hoping for, but
that works!

Richard

On Thu, Oct 31, 2013 at 3:47 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Richard
>
> If you cannot get a better suggestion this example from Deepayan Sarkar may
> help.
> It is way back in the archives and I do not have a reference for it.
>
> I have used it about a year ago as a template to do a complicated key
>
> fl <- grid.layout(nrow = 2, ncol = 6,
>                   heights = unit(rep(1, 2), "lines"),
>                   widths = unit(c(2, 1, 2, 1, 2, 1),
>
> c("cm","strwidth","cm","strwidth","cm","strwidth"),
>                   data = list(NULL,"John",NULL,"George",NULL,"The
> Beatles")))
>
> foo <- frameGrob(layout = fl)
> foo <- placeGrob(foo,
>                  pointsGrob(.5, .5, pch=19,
>                             gp = gpar(col="red", cex=0.5)),
>                  row = 1, col = 1)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="blue")),
>                  row = 2, col = 1)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="green")),
>                  row = 1, col = 3)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="orange")),
>                  row = 2, col = 3)
> foo <- placeGrob(foo,
>                  rectGrob(width = 0.6,
>                           gp = gpar(col="#FFFFCC",
>                           fill = "#FFFFCC")),
>                  row = 1, col = 5)
> foo <- placeGrob(foo,
>                  textGrob(lab = "John"),
>                  row = 1, col = 2)
> foo <- placeGrob(foo,
>                  textGrob(lab = "Paul"),
>                  row = 2, col = 2)
> foo <- placeGrob(foo,
>                  textGrob(lab = "George"),
>                  row = 1, col = 4)
> foo <- placeGrob(foo,
>                  textGrob(lab = "Ringo"),
>                  row = 2, col = 4)
> foo <- placeGrob(foo,
>                  textGrob(lab = "The Beatles"),
>                  row = 1, col = 6)
>
> xyplot(1 ~ 1, legend = list(top = list(fun = foo)))
>
> In my case I changed  "strwidth" to "cm" for the text as I was cramped for
> space
>
> HTH
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Richard Kwock
> Sent: Friday, 1 November 2013 06:42
> To: R help
> Subject: [R] Lattice Legend/Key by row instead of by column
>
> Hi All,
>
> I am having some trouble getting lattice to display the legend names by row
> instead of by column (default).
>
> Example:
>
> library(lattice)
> set.seed(456846)
> data <- matrix(c(1:10) + runif(50), ncol = 5, nrow = 10) dataset <-
> data.frame(data = as.vector(data), group = rep(1:5, each = 10), time = 1:10)
>
> xyplot(data ~ time, group = group, dataset, t = "l",
>   key = list(text = list(paste("group", unique(dataset$group)) ),
>     lines = list(col = trellis.par.get()$superpose.symbol$col[1:5]),
>     columns = 4
>   )
> )
>
> What I'm hoping for are 4 columns in the legend, like this:
> Legend row 1: "group 1", "group 2", "group 3", "group 4"
> Legend row 2: "group 5"
>
> However, I'm getting:
> Legend row 1: "group 1", "group 3", "group 5"
> Legend row 2: "group 2", "group 4"
>
> I can see how this might work if I include blanks/NULLs in the legend as
> placeholders, but that might get messy in data sets with many groups.
>
> Any ideas on how to get around this?
>
> Thanks,
> Richard
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Fri Nov  1 17:52:53 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Nov 2013 16:52:53 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <5273C73D.2090809@gmail.com>
References: <5273AD7E.6090607@gmail.com>
	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
	<5273C73D.2090809@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA12132@PA-MBX01.na.tibco.com>

Have you looked into the 'igraph' package?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Magnus Thor Torfason
> Sent: Friday, November 01, 2013 8:23 AM
> To: r-help at r-project.org
> Subject: Re: [R] Inserting 17M entries into env took 18h, inserting 34M entries taking 5+
> days
> 
> Sure,
> 
> I was attempting to be concise and boiling it down to what I saw as the
> root issue, but you are right, I could have taken it a step further. So
> here goes.
> 
> I have a set of around around 20M string pairs. A given string (say, A)
> can either be equivalent to another string (B) or not. If A and B occur
> together in the same pair, they are equivalent. But equivalence is
> transitive, so if A and B occur together in one pair, and A and C occur
> together in another pair, then A and C are also equivalent. I need a way
> to quickly determine if any two strings from my data set are equivalent
> or not.
> 
> The way I do this currently is to designate the smallest
> (alphabetically) string in each known equivalence set as the "main"
> entry. For each pair, I therefore insert two entries into the hash
> table, both pointing at the mail value. So assuming the input data:
> 
> A,B
> B,C
> D,E
> 
> I would then have:
> 
> A->A
> B->A
> C->B
> D->D
> E->D
> 
> Except that I also follow each chain until I reach the end (key==value),
> and insert pointers to the "main" value for every value I find along the
> way. After doing that, I end up with:
> 
> A->A
> B->A
> C->A
> D->D
> E->D
> 
> And I can very quickly check equivalence, either by comparing the hash
> of two strings, or simply by transforming each string into its hash, and
> then I can use simple comparison from then on. The code for generating
> the final hash table is as follows:
> 
> h : Empty hash table created with hash.new()
> d : Input data
> hash.deep.get : Function that iterates through the hash table until it
> finds a key whose value is equal to itself (until hash.get(X)==X), then
> returns all the values in a vector
> 
> 
> h = hash.new()
> for ( i in 1:nrow(d) )
> {
>      deep.a      = hash.deep.get(h, d$a[i])
>      deep.b      = hash.deep.get(h, d$b[i])
>      equivalents = sort(unique(c(deep.a,deep.b)))
>      equiv.id    = min(equivalents)
>      for ( equivalent in equivalents )
>      {
>          hash.put(h, equivalent, equiv.id)
>      }
> }
> 
> 
> I would so much appreciate if there was a simpler and faster way to do
> this. Keeping my fingers crossed that one of the R-help geniuses who
> sees this is sufficiently interested to crack the problem
> 
> Best,
> Magnus
> 
> On 11/1/2013 1:49 PM, jim holtman wrote:
> > It would be nice if you followed the posting guidelines and at least
> > showed the script that was creating your entries now so that we
> > understand the problem you are trying to solve.  A bit more
> > explanation of why you want this would be useful.  This gets to the
> > second part of my tag line:  Tell me what you want to do, not how you
> > want to do it.  There may be other solutions to your problem.
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> >
> > On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
> > <zulutime.net at gmail.com> wrote:
> >> Pretty much what the subject says:
> >>
> >> I used an env as the basis for a Hashtable in R, based on information that
> >> this is in fact the way environments are implemented under the hood.
> >>
> >> I've been experimenting with doubling the number of entries, and so far it
> >> has seemed to be scaling more or less linearly, as expected.
> >>
> >> But as I went from 17 million entries to 34 million entries, the completion
> >> time has gone from 18 hours, to 5 days and counting.
> >>
> >>
> >> The keys and values are in all cases strings of equal length.
> >>
> >> One might suspect that the slow-down might have to do with the memory being
> >> swapped to disk, but from what I know about my computing environment, that
> >> should not be the case.
> >>
> >> So my first question:
> >> Is anyone familiar with anything in the implementation of environments that
> >> would limit their use or slow them down (faster than O(nlog(n)) as the
> >> number of entries is increased?
> >>
> >> And my second question:
> >> I realize that this is not strictly what R environments were designed for,
> >> but this is what my algorithm requires: I must go through these millions of
> >> entries, storing them in the hash table and sometimes retrieving them along
> >> the way, in a more or less random manner, which is contingent on the data I
> >> am encountering, and on the contents of the hash table at each moment.
> >>
> >> Does anyone have a good recommendation for alternatives to implement huge,
> >> fast, table-like structures in R?
> >>
> >> Best,
> >> Magnus
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdxgary163 at gmail.com  Fri Nov  1 18:03:52 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Fri, 1 Nov 2013 10:03:52 -0700
Subject: [R] find max value in each row and return column number and column
	name
Message-ID: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/3a74d1c2/attachment.pl>

From dwinsemius at comcast.net  Fri Nov  1 18:28:50 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 Nov 2013 10:28:50 -0700
Subject: [R] forecast.lm() and NEWDATA
In-Reply-To: <5273B194.6010004@urban-econ.com>
References: <5273B194.6010004@urban-econ.com>
Message-ID: <0B8EA941-390C-4C14-B201-395F9ED14F23@comcast.net>


On Nov 1, 2013, at 6:50 AM, Ryan wrote:

> Good day all.
> 
> I am hoping you can help me (and I did this right). I've been working in R for a week now, and have encountered a problem with forecast.lm().
> 
> I have a list of 12 variables, all type = double, with 15 data entries.
> (I imported them from tab delimited text files, and then formatted as.numeric to change from list to double)
> (I understand that this leaves me rather limited in my degrees of freedom, but working with what I have, sadly. )
> 
> I have a LM model, such that
> REGGY = lm(formula=Y~A,B,C,...,I,J)

This looks wrong. Separating independent predictors with commas would be highly unusual.
> which I am happy with.
> 
> I have
> NEWDATA = data.frame(A+B+C+D....+I+J)

This also looks wrong. Separating arguments to data.frame with "+"-signs is surely wrong.
> 
> When i try to run
> 
> forecast.lm(REGGY, h=5)
> 
> i receive the following error
> "Error in as.data.frame(newdata) :
>  argument "newdata" is missing, with no default"

If your code prior to calling forecast on the REGGY-object was really what you showed here, I am not surprised. You should post the output of str() on the data-objects that has the 12 variables and if it was modified the data argument pasted to `lm()` when you made REGGY. (Beginners should name their data arguments.)

> 
> When I run
> forecast.lm(REGGY, NEWDATA, h=5)
> I receive the confidence intervals of the 15 data entries I already possess. I understand that by including NEWDATA, the "h=5" is ignored, but without NEWDATA, I receive the error message.
> 
> Can anyone help me please?
> 
> Regards
> Ryan
> 
> P.S The forecast is trying to predict the next 5 values for Y from the regression model pasted above. I'm a bit rusty with regressions, but I think I've covered my bases as well as I can, and from what I understand of the R code, I'm following the right steps.

Not if what you posted here was your code. I think you missed a few crucials points about R syntax.
> 

-- 

David Winsemius
Alameda, CA, USA


From clint at ecy.wa.gov  Fri Nov  1 18:34:08 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 1 Nov 2013 10:34:08 -0700 (PDT)
Subject: [R] find max value in each row and return column number and
 column name
In-Reply-To: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
References: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1311011033440.5831@ecy.wa.gov>

?which.max should start you down the right path

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 1 Nov 2013, Gary Dong wrote:

> Dear R users,
>
> I wonder how I can use R to identify the max value of each row, the column
> number column name:
>
> For example:
>
> a <- data.frame(x = rnorm(4), y = rnorm(4), z = rnorm(4))
>
>> a
>           x          y          z
> 1 -0.7289964  0.2194702 -2.4674780
> 2  1.0889353  0.3167629 -0.9208548
> 3 -0.6374692 -1.7249049  0.6567313
> 4 -0.1348642  0.4507473 -1.7309010
>
> In this data frame, I compare y and z only.
>
> What I need:
>
>            x                     y                     z
> max                 max.col.num         max.col.name
> 1 -0.7289964  0.2194702 -2.4674780         0.2194702               2
>                     y
> 2  1.0889353  0.3167629 -0.9208548         0.3167629               2
>                     y
> 3 -0.6374692 -1.7249049  0.6567313         0.6567313               3
>                    z
> 4 -0.1348642  0.4507473 -1.7309010         0.4507473               2
>                    y
>
>
> Any suggestion will be greatly appreciated!
>
> Thank you!
>
> Gary
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Fri Nov  1 18:39:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 10:39:06 -0700 (PDT)
Subject: [R] find max value in each row and return column number and
	column	name
In-Reply-To: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
References: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
Message-ID: <1383327546.90486.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:

? cbind(a,do.call(rbind,apply(a,1,function(x) {data.frame(max=max(x), max.col.num=which.max(x), max.col.name=names(a)[which.max(x)],stringsAsFactors=FALSE)}))) ##assuming that unique max for each row.
A.K.


On Friday, November 1, 2013 1:05 PM, Gary Dong <pdxgary163 at gmail.com> wrote:
Dear R users,

I wonder how I can use R to identify the max value of each row, the column
number column name:

For example:

a <- data.frame(x = rnorm(4), y = rnorm(4), z = rnorm(4))

> a
? ? ? ? ?  x? ? ? ? ? y? ? ? ? ? z
1 -0.7289964? 0.2194702 -2.4674780
2? 1.0889353? 0.3167629 -0.9208548
3 -0.6374692 -1.7249049? 0.6567313
4 -0.1348642? 0.4507473 -1.7309010

In this data frame, I compare y and z only.

What I need:

? ? ? ? ? ? x? ? ? ? ? ? ? ? ? ?  y? ? ? ? ? ? ? ? ? ?  z
max? ? ? ? ? ? ? ?  max.col.num? ? ? ?  max.col.name
1 -0.7289964? 0.2194702 -2.4674780? ? ? ?  0.2194702? ? ? ? ? ? ?  2
? ? ? ? ? ? ? ? ? ?  y
2? 1.0889353? 0.3167629 -0.9208548? ? ? ?  0.3167629? ? ? ? ? ? ?  2
? ? ? ? ? ? ? ? ? ?  y
3 -0.6374692 -1.7249049? 0.6567313? ? ? ?  0.6567313? ? ? ? ? ? ?  3
? ? ? ? ? ? ? ? ? ? z
4 -0.1348642? 0.4507473 -1.7309010? ? ? ?  0.4507473? ? ? ? ? ? ?  2
? ? ? ? ? ? ? ? ? ? y


Any suggestion will be greatly appreciated!

Thank you!

Gary

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ranjanmano167 at gmail.com  Fri Nov  1 18:41:45 2013
From: ranjanmano167 at gmail.com (Manoranjan Muthusamy)
Date: Fri, 1 Nov 2013 18:41:45 +0100
Subject: [R] Extracting values from a ecdf (empirical cumulative
 distribution function) curve
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA12083@PA-MBX01.na.tibco.com>
References: <CANqyHbR3PP=My5CfqZANs8Q5aL=sYkrxieZhr7_thdLZpX_J5g@mail.gmail.com>
	<5272D158.6090408@sapo.pt>
	<CANqyHbSz3J9Mksj=BDS8h3T+nvh6kmNLQgHkugxFXXOmkEx2Nw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA11F72@PA-MBX01.na.tibco.com>
	<CANqyHbTnVMw10TLEe6Ror-6MFaS2tYzETUmt3KTm6wpCUYXOgw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA12083@PA-MBX01.na.tibco.com>
Message-ID: <CANqyHbRFq4snbmYVWks8AqdWi1-sbD1AQZ_s-wpK5_0ms5o0jA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/26a270dc/attachment.pl>

From dwinsemius at comcast.net  Fri Nov  1 19:01:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 Nov 2013 11:01:43 -0700
Subject: [R] find max value in each row and return column number and
	column name
In-Reply-To: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
References: <CAEVDvzW4VQ6srbuwQf3gk5myqXo+pbam8cFKuKec2-ZKYpYjkA@mail.gmail.com>
Message-ID: <6736B768-B24E-4183-9006-FDC55A923A63@comcast.net>


On Nov 1, 2013, at 10:03 AM, Gary Dong wrote:

> Dear R users,
> 
> I wonder how I can use R to identify the max value of each row, the column
> number column name:
> 
> For example:
> 
> a <- data.frame(x = rnorm(4), y = rnorm(4), z = rnorm(4))
> 
>> a
>           x          y          z
> 1 -0.7289964  0.2194702 -2.4674780
> 2  1.0889353  0.3167629 -0.9208548
> 3 -0.6374692 -1.7249049  0.6567313
> 4 -0.1348642  0.4507473 -1.7309010
> 
> In this data frame, I compare y and z only.
> 
> What I need:
> 
>          x                     y                 z            max         max.col.num         max.col.name
> 1 	-0.7289964 	 0.2194702 	-2.4674780         0.2194702               2
>                     y
> 2  1.0889353  0.3167629 -0.9208548         0.3167629               2
>                     y
> 3 -0.6374692 -1.7249049  0.6567313         0.6567313               3
>                    z
> 4 -0.1348642  0.4507473 -1.7309010         0.4507473               2
>                    y
> 
> 
> Any suggestion will be greatly appreciated!

cbind(a, max=apply(a,1,max),
         max.col.num =apply(a,1,which.max) ,
         max.col.name= names(a)[apply(a,1,which.max)]  )
> 
> Thank you!
> 
> Gary
> 
> 	[[alternative HTML version deleted]]

You can express your appreciation by posting in plain-text in the future.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdxgary163 at gmail.com  Fri Nov  1 19:11:37 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Fri, 1 Nov 2013 11:11:37 -0700
Subject: [R] extraction of roots in R
Message-ID: <CAEVDvzV88AK_NvvXatb4OWrCxPTfkYwF=AFCo+zR=A1-Wcad=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/bb384603/attachment.pl>

From dmck at u.washington.edu  Fri Nov  1 19:20:58 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 1 Nov 2013 11:20:58 -0700
Subject: [R] extraction of roots in R
In-Reply-To: <CAEVDvzV88AK_NvvXatb4OWrCxPTfkYwF=AFCo+zR=A1-Wcad=w@mail.gmail.com>
References: <CAEVDvzV88AK_NvvXatb4OWrCxPTfkYwF=AFCo+zR=A1-Wcad=w@mail.gmail.com>
Message-ID: <A2D6CB88-8E63-43D0-B7CA-24FCFAFD46BC@u.washington.edu>

If you just want the nth root of X, use X^(1/n)

 > x <- 256
 > x^(1/8)
[1] 2

 > x <- -256
 > x^(1/8)
[1] NaN

It appears that you get the positive real root.

Is this all you wanted?


On 1-Nov-13, at 11:11 AM, Gary Dong wrote:

> Dear R users,
>
> I wonder if R has a default function that I can use to do  
> extraction of
> roots.
>
> Here is an example:
>
> X                  N
> 2.5              5
> 3.4              7
> 8.9              9
> 6.4              1
> 2.1              0
> 1.1             2
>
> I want to calculate Y = root(X)^N, where N represents the power.  
> what is
> the easy way to do this?
>
> Thank you!
>
> Gary
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.





Don McKenzie
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington

dmck at uw.edu


From dmck at u.washington.edu  Fri Nov  1 19:32:05 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 1 Nov 2013 11:32:05 -0700
Subject: [R] extraction of roots in R
In-Reply-To: <A2D6CB88-8E63-43D0-B7CA-24FCFAFD46BC@u.washington.edu>
References: <CAEVDvzV88AK_NvvXatb4OWrCxPTfkYwF=AFCo+zR=A1-Wcad=w@mail.gmail.com>
	<A2D6CB88-8E63-43D0-B7CA-24FCFAFD46BC@u.washington.edu>
Message-ID: <28DD74E0-6B28-4CC9-9FAC-F4FA7998B202@u.washington.edu>

If you want complex roots, there is a post by Ravi Varadhan from  
2010, a reprint of which I found quickly by a google search at

http://r.789695.n4.nabble.com/finding-complex-roots-in-R-td2541514.html


On 1-Nov-13, at 11:20 AM, Don McKenzie wrote:

> If you just want the nth root of X, use X^(1/n)
>
> > x <- 256
> > x^(1/8)
> [1] 2
>
> > x <- -256
> > x^(1/8)
> [1] NaN
>
> It appears that you get the positive real root.
>
> Is this all you wanted?
>
>
> On 1-Nov-13, at 11:11 AM, Gary Dong wrote:
>
>> Dear R users,
>>
>> I wonder if R has a default function that I can use to do  
>> extraction of
>> roots.
>>
>> Here is an example:
>>
>> X                  N
>> 2.5              5
>> 3.4              7
>> 8.9              9
>> 6.4              1
>> 2.1              0
>> 1.1             2
>>
>> I want to calculate Y = root(X)^N, where N represents the power.  
>> what is
>> the easy way to do this?
>>
>> Thank you!
>>
>> Gary
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting- 
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> Don McKenzie
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
>
> dmck at uw.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.





Don McKenzie
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington

dmck at uw.edu


From Jason.Law at portlandoregon.gov  Fri Nov  1 19:47:37 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Fri, 1 Nov 2013 11:47:37 -0700
Subject: [R] spsurvey analysis
In-Reply-To: <5273872E020000D500B8180B@gwsmtp.dec.state.ny.us>
References: <5273872E020000D500B8180B@gwsmtp.dec.state.ny.us>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184EE515598@MAIL2.rose.portland.local>

I use the spsurvey package a decent amount.  The cont.cdftest function bins the cdf in order to perform the test which I think is the root of the problem.  Unfortunately, the default is 3 which is the minimum number of bins.

I would contact Tom Kincaid or Tony Olsen at NHEERL WED directly to ask about this problem.

Another option would be to take a different analytical approach (e.g., a mixed effects model) which would allow you a lot more flexibility.

Jason Law
Statistician
City of Portland
Bureau of Environmental Services
Water Pollution Control Laboratory
6543 N Burlington Avenue
Portland, OR 97203-5452
503-823-1038
jason.law at portlandoregon.gov


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Tim Howard
Sent: Friday, November 01, 2013 7:49 AM
To: r-help at r-project.org
Subject: [R] spsurvey analysis

All,
I've used the excellent package, spsurvey, to create spatially balanced samples many times in the past. I'm now attempting to use the analysis portion of the package, which compares CDFs among sub-populations to test for differences in sub-population metrics. 
 
- My data (count data) have many zeros, following a negative binomial or even zero-inflated negative binomial distribution.
- Samples are within polygons of varying sizes
- I want to test whether a sample at time 1 is different from a sample at time 2. Essentially the same sample areas and number of samples.

The problem:
- cont.cdftest  throws a warning and does not complete for most (but not all) species sampled. Warning message: "The combined number of values in at least one class is less than five. Action: The user should consider using a smaller number of classes."

- There are plenty of samples in my two time periods (the dummy set below: Yr1=27, Yr2=31 non-zero values). 
 
My Question:
Why is it throwing this error and is there a way to get around it?



Reproduceable example (change path to spsurvey sample data), requires us to use spsurvey to generate sample points:

### R code tweaked from vignettes 'Area_Design' and 'Area_Analysis'
library(spsurvey)
### Analysis set up
setwd("C:/Program Files/R/R-3.0.2/library/spsurvey/doc")
att <- read.dbf("UT_ecoregions")
shp <- read.shape("UT_ecoregions")

set.seed(4447864)

# Create the design list
Stratdsgn <- list("Central Basin and Range"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Colorado Plateaus"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Mojave Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Northern Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Southern Rockies"=list(panel=c(PanelOne=14), seltype="Equal"),
                  "Wasatch and Uinta Mountains"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Wyoming Basin"=list(panel=c(PanelOne=6), seltype="Equal"))

# Select the sample design for each year
Stratsites_Yr1 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

Stratsites_Yr2 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

#extract the core information, add year as a grouping variable, add a plot ID to link with dummy data
Yr1 <- cbind(pltID = 1001:1100, Stratsites_Yr1 at data[,c(1,2,3,5)], grp = "Yr1")
Yr2 <- cbind(pltID = 2001:2100, Stratsites_Yr2 at data[,c(1,2,3,5)], grp = "Yr2")         
sitedat <- rbind(Yr1, Yr2)

# create dummy sampling data. Lots of zeros!
bn.a <- rnbinom(size = 0.06, mu = 19.87, n=100) bn.b <- rnbinom(size = 0.06, mu = 20.15, n=100) dat.a <- data.frame(pltID = 1001:1100, grp = "Yr1",count = bn.a) dat.b <- data.frame(pltID = 2001:2100, grp = "Yr2",count = bn.b) dat <- rbind(dat.a, dat.b)

####
## Analysis begins here
####
data.cont <- data.frame(siteID = dat$pltID, Density=dat$count) sites <- data.frame(siteID = dat$pltID, Use=rep(TRUE, nrow(dat))) subpop <- data.frame(siteID = dat$pltID, 
                        All_years=(rep("allYears",nrow(dat))),
                        Year = dat$grp)
design <- data.frame(siteID = sitedat$pltID,
                        wgt = sitedat$wgt,
                        xcoord = sitedat$xcoord,
                        ycoord = sitedat$ycoord)
framesize <- c("Yr1"=888081202000, "Yr2"=888081202000)                        
                        
## There seem to be pretty good estimates CDF_Estimates <- cont.analysis(sites, subpop, design, data.cont, 
                        popsize = list(All_years=sum(framesize),
                        Year = as.list(framesize)))

print(CDF_Estimates$Pct)

## this test fails
CDF_Tests <- cont.cdftest(sites, subpop[,c(1,3)], design, data.cont,
   popsize=list(Year=as.list(framesize)))
warnprnt()

## how many records have values greater than zero, by year?   Probably irrelevant!
notZero <- dat[dat$count > 0,]
table(notZero$grp)

### end

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)
 
locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

Thanks in advance.
Tim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tghoward at gw.dec.state.ny.us  Fri Nov  1 19:57:34 2013
From: tghoward at gw.dec.state.ny.us (Tim Howard)
Date: Fri, 01 Nov 2013 14:57:34 -0400
Subject: [R] spsurvey analysis
In-Reply-To: <0EFBC7C31DB4F24F8CAC48136A1762D70184EE515598@MAIL2.rose.portland.local>
References: <5273872E020000D500B8180B@gwsmtp.dec.state.ny.us>
	<0EFBC7C31DB4F24F8CAC48136A1762D70184EE515598@MAIL2.rose.portland.local>
Message-ID: <5273C15E020000D500B81885@gwsmtp.dec.state.ny.us>

Jason,
Thank you for your reply. Interesting ... so you think the 'classes' in the error message "The combined number of values in at least one class..."  is referring to the CDF bins rather than the sub-population classes that I defined. 
 
That makes sense as I only defined two classes (!). I was worried it was detecting and treating polygons as classes, somehow (ecoregions in example below).
 
I had already reached out to Kincaid and Olsen but had not received an answer yet so I moved on to R-help.   I'll go back to them. 
 
Thanks again.
Best, 
Tim

>>> "Law, Jason" <Jason.Law at portlandoregon.gov> 11/1/2013 2:47 PM >>>
I use the spsurvey package a decent amount.  The cont.cdftest function bins the cdf in order to perform the test which I think is the root of the problem.  Unfortunately, the default is 3 which is the minimum number of bins.

I would contact Tom Kincaid or Tony Olsen at NHEERL WED directly to ask about this problem.

Another option would be to take a different analytical approach (e.g., a mixed effects model) which would allow you a lot more flexibility.

Jason Law
Statistician
City of Portland
Bureau of Environmental Services
Water Pollution Control Laboratory
6543 N Burlington Avenue
Portland, OR 97203-5452
503-823-1038
jason.law at portlandoregon.gov


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Tim Howard
Sent: Friday, November 01, 2013 7:49 AM
To: r-help at r-project.org
Subject: [R] spsurvey analysis

All,
I've used the excellent package, spsurvey, to create spatially balanced samples many times in the past. I'm now attempting to use the analysis portion of the package, which compares CDFs among sub-populations to test for differences in sub-population metrics. 

- My data (count data) have many zeros, following a negative binomial or even zero-inflated negative binomial distribution.
- Samples are within polygons of varying sizes
- I want to test whether a sample at time 1 is different from a sample at time 2. Essentially the same sample areas and number of samples.

The problem:
- cont.cdftest  throws a warning and does not complete for most (but not all) species sampled. Warning message: "The combined number of values in at least one class is less than five. Action: The user should consider using a smaller number of classes."

- There are plenty of samples in my two time periods (the dummy set below: Yr1=27, Yr2=31 non-zero values). 

My Question:
Why is it throwing this error and is there a way to get around it?



Reproduceable example (change path to spsurvey sample data), requires us to use spsurvey to generate sample points:

### R code tweaked from vignettes 'Area_Design' and 'Area_Analysis'
library(spsurvey)
### Analysis set up
setwd("C:/Program Files/R/R-3.0.2/library/spsurvey/doc")
att <- read.dbf("UT_ecoregions")
shp <- read.shape("UT_ecoregions")

set.seed(4447864)

# Create the design list
Stratdsgn <- list("Central Basin and Range"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Colorado Plateaus"=list(panel=c(PanelOne=25), seltype="Equal"),
                  "Mojave Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Northern Basin and Range"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Southern Rockies"=list(panel=c(PanelOne=14), seltype="Equal"),
                  "Wasatch and Uinta Mountains"=list(panel=c(PanelOne=10), seltype="Equal"),
                  "Wyoming Basin"=list(panel=c(PanelOne=6), seltype="Equal"))

# Select the sample design for each year
Stratsites_Yr1 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

Stratsites_Yr2 <- grts(design=Stratdsgn, DesignID="STRATIFIED",
                   type.frame="area", src.frame="sp.object",
                   sp.object=shp, att.frame=att, stratum="Level3_Nam", shapefile=FALSE)

#extract the core information, add year as a grouping variable, add a plot ID to link with dummy data
Yr1 <- cbind(pltID = 1001:1100, Stratsites_Yr1 at data[,c(1,2,3,5)], grp = "Yr1")
Yr2 <- cbind(pltID = 2001:2100, Stratsites_Yr2 at data[,c(1,2,3,5)], grp = "Yr2")         
sitedat <- rbind(Yr1, Yr2)

# create dummy sampling data. Lots of zeros!
bn.a <- rnbinom(size = 0.06, mu = 19.87, n=100) bn.b <- rnbinom(size = 0.06, mu = 20.15, n=100) dat.a <- data.frame(pltID = 1001:1100, grp = "Yr1",count = bn.a) dat.b <- data.frame(pltID = 2001:2100, grp = "Yr2",count = bn.b) dat <- rbind(dat.a, dat.b)

####
## Analysis begins here
####
data.cont <- data.frame(siteID = dat$pltID, Density=dat$count) sites <- data.frame(siteID = dat$pltID, Use=rep(TRUE, nrow(dat))) subpop <- data.frame(siteID = dat$pltID, 
                        All_years=(rep("allYears",nrow(dat))),
                        Year = dat$grp)
design <- data.frame(siteID = sitedat$pltID,
                        wgt = sitedat$wgt,
                        xcoord = sitedat$xcoord,
                        ycoord = sitedat$ycoord)
framesize <- c("Yr1"=888081202000, "Yr2"=888081202000)                        
                        
## There seem to be pretty good estimates CDF_Estimates <- cont.analysis(sites, subpop, design, data.cont, 
                        popsize = list(All_years=sum(framesize),
                        Year = as.list(framesize)))

print(CDF_Estimates$Pct)

## this test fails
CDF_Tests <- cont.cdftest(sites, subpop[,c(1,3)], design, data.cont,
   popsize=list(Year=as.list(framesize)))
warnprnt()

## how many records have values greater than zero, by year?   Probably irrelevant!
notZero <- dat[dat$count > 0,]
table(notZero$grp)

### end

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

Thanks in advance.
Tim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jvadams at usgs.gov  Fri Nov  1 20:18:28 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 1 Nov 2013 14:18:28 -0500
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
	<CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
	<20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>
Message-ID: <CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/55ff48b6/attachment.pl>

From gunter.berton at gene.com  Fri Nov  1 20:45:48 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 1 Nov 2013 12:45:48 -0700
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
	<CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
	<20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>
	<CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>
Message-ID: <CACk-te2=PxWtuNyphBbk9HMwS0zR=FZS+GWGrbPJjrfjtoySOw@mail.gmail.com>

... but you may be interested in this:

http://andywoodruff.com/blog/why-are-choropleth-mercator-maps-bad-because-we-said-so/

Cheers,
Bert

On Fri, Nov 1, 2013 at 12:18 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> Claudia,
>
> I have not worked through the example myself.  Since you seem to be getting
> errors, perhaps a different example would help.  Here are some more
> choropleth maps (although these use US states rather than European
> countries).
>
> http://blog.revolutionanalytics.com/2009/11/choropleth-challenge-result.html
>
> Jean
>
>
>
> On Fri, Nov 1, 2013 at 12:04 PM, <paladini at trustindata.de> wrote:
>
>> Hi Jean,
>> thanks again for your response. As I told you  I did the downloads and
>> double checked if I selected the right directory.
>> But I noticed right now what happend:
>> The command in the example is :
>>
>> eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/Shape/data/NUTS_RG_60M_**
>> 2010")
>>
>> But it should be :
>> eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/data/ggg/NUTS_RG_60M_**
>> 2010")
>>
>> Because if you do the downloads and unzip these data there is no such
>> think as a "Shape" directory.
>>
>> Now eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/data/NUTS_RG_60M_2010")
>> works.
>>
>>
>> What happens now is that after typing:
>> eurEduMapDf <- merge(eurMapDf, eurEdu, by.x="id", by.y="GEO")
>> I get another error message because "eurMapDf" is unknown.
>>
>> So I supposed it should be:
>> eurEduMapDf <- merge(eurMap, eurEdu, by.x="id", by.y="GEO")
>>
>> But this doesn't work either.The error message this time is: undefined
>> column selected.
>>
>> Did I do something wrong?
>>
>>
>>
>> Best regards
>>
>> Claudia
>>
>>
>>
>>
>>
>>
>>
>>
>> Zitat von "Adams, Jean" <jvadams at usgs.gov>:
>>
>>  Claudia,
>>>
>>> You should cc r-help on all correspondence so that others can follow the
>>> thread.
>>>
>>> In the second paragraph of the link I sent you
>>>      http://www.r-bloggers.com/**maps-in-r-choropleth-maps/<http://www.r-bloggers.com/maps-in-r-choropleth-maps/>
>>> a link is provided for the NUTS data,
>>>      "The polygons for drawing the administrative boundaries were obtained
>>> from this link. In particular, the NUTS 2010 shapefile in the 1:60 million
>>> scale was downloaded and used. The other available scales would allow the
>>> drawing of better defined maps, but at a computational cost. The zipped
>>> file has to be extracted in a folder of choice for using it later."
>>>
>>> http://epp.eurostat.ec.europa.**eu/portal/page/portal/gisco_**
>>> Geographical_information_maps/**popups/references/**administrative_units_
>>> **statistical_units_1<http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco_Geographical_information_maps/popups/references/administrative_units_statistical_units_1>
>>>
>>> If you want to follow the example, you will need to download this data to
>>> your computer and then make sure that you refer to the appropriate
>>> directory when using the readShapePoly() function.
>>>
>>> Jean
>>>
>>>
>>>
>>> On Wed, Oct 30, 2013 at 11:14 AM, <paladini at trustindata.de> wrote:
>>>
>>>  Hi Jean,
>>>> thank you for your advice.
>>>> The page looks quite interesting and I tried the example in  GNU R. I did
>>>> all the downloads.
>>>> But
>>>> Just in the beginnig after typing
>>>>
>>>> eurMap <- readShapePoly(fn="NUTS_2010_****60M_SH/Shape/data/NUTS_RG_60M_
>>>> ****
>>>>
>>>> 2010")
>>>> I get the following error message:
>>>>
>>>> Error in getinfo.shape(filen) : Error opening SHP file
>>>>
>>>> To you have an idea what I did wrong?
>>>>
>>>> Thanks a lot and best regards
>>>>
>>>> Claudia
>>>>
>>>>
>>>>
>>>>
>>>> Zitat von "Adams, Jean" <jvadams at usgs.gov>:
>>>>
>>>>  Check out this link for some examples
>>>>
>>>>>     http://www.r-bloggers.com/****maps-in-r-choropleth-maps/<http://www.r-bloggers.com/**maps-in-r-choropleth-maps/>
>>>>> <htt**p://www.r-bloggers.com/maps-**in-r-choropleth-maps/<http://www.r-bloggers.com/maps-in-r-choropleth-maps/>
>>>>> >
>>>>>
>>>>>
>>>>> Jean
>>>>>
>>>>>
>>>>> On Tue, Oct 29, 2013 at 12:02 PM, <paladini at trustindata.de> wrote:
>>>>>
>>>>>  Hello,
>>>>>
>>>>>> I would like to draw a map of Europe. Each country should be colored
>>>>>> depending on how it scores in an index called GPIndex.
>>>>>> Say a dark red for real bad countries a light red for those which are
>>>>>> not
>>>>>> so bad, light blue for the fairly good ones and so on up to the really
>>>>>> good
>>>>>> ones in a dark blue.
>>>>>> I never worked with geographic maps before so I tried library maps but
>>>>>> I
>>>>>> didn't get far,- especially because all examples I found only seem to
>>>>>> work
>>>>>> for the United states. So I'm a bit lost.
>>>>>> I would be nice if somebody could help me.
>>>>>>
>>>>>> Thanking you in anticipation!
>>>>>>
>>>>>> Best regards
>>>>>>
>>>>>> Claudia
>>>>>>
>>>>>> ______________________________******________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/******listinfo/r-help<https://stat.ethz.ch/mailman/****listinfo/r-help>
>>>>>> <https://**stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>>> >
>>>>>> <https://stat.**ethz.ch/**mailman/listinfo/r-**help<http://ethz.ch/mailman/listinfo/r-**help>
>>>>>> <http**s://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> >
>>>>>>
>>>>>> >
>>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>>> posting-guide.html <http://www.R-project.org/****posting-guide.html<http://www.R-project.org/**posting-guide.html>
>>>>>> <http://www.**R-project.org/posting-guide.**html<http://www.R-project.org/posting-guide.html>
>>>>>> >
>>>>>>
>>>>>> >
>>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From jpak3 at umbc.edu  Fri Nov  1 20:05:02 2013
From: jpak3 at umbc.edu (Jinie Pak)
Date: Fri, 1 Nov 2013 15:05:02 -0400
Subject: [R] constucting a sub-network based on time period
Message-ID: <0c30de0999e5ba0435df809b6593b794@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/e65151c4/attachment.pl>

From paladini at trustindata.de  Fri Nov  1 18:04:18 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Fri, 01 Nov 2013 18:04:18 +0100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
	<CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
Message-ID: <20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>

Hi Jean,
thanks again for your response. As I told you  I did the downloads and  
double checked if I selected the right directory.
But I noticed right now what happend:
The command in the example is :
eurMap <- readShapePoly(fn="NUTS_2010_60M_SH/Shape/data/NUTS_RG_60M_2010")

But it should be :
eurMap <- readShapePoly(fn="NUTS_2010_60M_SH/data/ggg/NUTS_RG_60M_2010")

Because if you do the downloads and unzip these data there is no such  
think as a "Shape" directory.

Now eurMap <- readShapePoly(fn="NUTS_2010_60M_SH/data/NUTS_RG_60M_2010")
works.


What happens now is that after typing:
eurEduMapDf <- merge(eurMapDf, eurEdu, by.x="id", by.y="GEO")
I get another error message because "eurMapDf" is unknown.

So I supposed it should be:
eurEduMapDf <- merge(eurMap, eurEdu, by.x="id", by.y="GEO")

But this doesn't work either.The error message this time is: undefined  
column selected.

Did I do something wrong?


Best regards

Claudia








Zitat von "Adams, Jean" <jvadams at usgs.gov>:

> Claudia,
>
> You should cc r-help on all correspondence so that others can follow the
> thread.
>
> In the second paragraph of the link I sent you
>      http://www.r-bloggers.com/maps-in-r-choropleth-maps/
> a link is provided for the NUTS data,
>      "The polygons for drawing the administrative boundaries were obtained
> from this link. In particular, the NUTS 2010 shapefile in the 1:60 million
> scale was downloaded and used. The other available scales would allow the
> drawing of better defined maps, but at a computational cost. The zipped
> file has to be extracted in a folder of choice for using it later."
>
> http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco_Geographical_information_maps/popups/references/administrative_units_statistical_units_1
>
> If you want to follow the example, you will need to download this data to
> your computer and then make sure that you refer to the appropriate
> directory when using the readShapePoly() function.
>
> Jean
>
>
>
> On Wed, Oct 30, 2013 at 11:14 AM, <paladini at trustindata.de> wrote:
>
>> Hi Jean,
>> thank you for your advice.
>> The page looks quite interesting and I tried the example in  GNU R. I did
>> all the downloads.
>> But
>> Just in the beginnig after typing
>>
>> eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/Shape/data/NUTS_RG_60M_**
>> 2010")
>> I get the following error message:
>>
>> Error in getinfo.shape(filen) : Error opening SHP file
>>
>> To you have an idea what I did wrong?
>>
>> Thanks a lot and best regards
>>
>> Claudia
>>
>>
>>
>>
>> Zitat von "Adams, Jean" <jvadams at usgs.gov>:
>>
>>  Check out this link for some examples
>>>      
>>> http://www.r-bloggers.com/**maps-in-r-choropleth-maps/<http://www.r-bloggers.com/maps-in-r-choropleth-maps/>
>>>
>>> Jean
>>>
>>>
>>> On Tue, Oct 29, 2013 at 12:02 PM, <paladini at trustindata.de> wrote:
>>>
>>>  Hello,
>>>> I would like to draw a map of Europe. Each country should be colored
>>>> depending on how it scores in an index called GPIndex.
>>>> Say a dark red for real bad countries a light red for those which are not
>>>> so bad, light blue for the fairly good ones and so on up to the really
>>>> good
>>>> ones in a dark blue.
>>>> I never worked with geographic maps before so I tried library maps but I
>>>> didn't get far,- especially because all examples I found only seem to
>>>> work
>>>> for the United states. So I'm a bit lost.
>>>> I would be nice if somebody could help me.
>>>>
>>>> Thanking you in anticipation!
>>>>
>>>> Best regards
>>>>
>>>> Claudia
>>>>
>>>> ______________________________****________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>> <https://stat.**ethz.ch/mailman/listinfo/r-**help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> >
>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>> posting-guide.html  
>>>> <http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>> >
>>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>>


From paladini at trustindata.de  Fri Nov  1 18:05:43 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Fri, 01 Nov 2013 18:05:43 +0100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <52718136.1080500@bitwrit.com.au>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<52701B42.3090200@bitwrit.com.au>
	<20131030170458.Horde.BRzJMm0tJPM44BSTPT6Ngw7@webmail.df.eu>
	<52718136.1080500@bitwrit.com.au>
Message-ID: <20131101180543.Horde.Rkf802B7HX6z7Op0_Q5J2w4@webmail.df.eu>

Hi Jim,
that works nice.
Thanks again!

Have a nice weekend, best regards

Claudia


Zitat von Jim Lemon <jim at bitwrit.com.au>:

> On 10/31/2013 03:04 AM, paladini at trustindata.de wrote:
>> Hi Jim,
>> thats the second time that you helped me in a short while so thanks a lot!
>>
>> But it seems to me quite laborious and error-prone to first select all
>> the relevant countries in this long list and then to create a color vector.
>> But perhaps I get it all wrong.
>>
>>
>> For the color vector I first did this
>>
>> imagecolors<-color.scale(mydata$GPIndex ,c(1,0,0),0,c(0,0,1))
>>
>> because I wanted the colors to scale from dark red (bad ones) to dark
>> blue (good ones).
>> But it went somehow wrong. By the way can you tell me what I did wrong?
>>
>> Nevertheless I than createt a color vector looking loke this:
>>
>> eurocol=c("#FF0000FF",8,"#710000FF","#390000FF",8,8,"#390000FF",rep(8,10),"#2F0000FF"
>>
>> ,8,"#000000FF",8,"#000000FF","#000000FF" ,"#000055FF",8,"#000064FF",2,
>> "#000083FF",8,8,"#00008BFF" ,"#0000F0FF" ,rep(8,20),"#0000F7FF"
>> ,rep(8,18),"#0000FFFF", rep(8,120))
>>
>>
>> And than
>>
>> world.map<-map('world', fill = TRUE,col =eurocol
>> ,xlim=c(-12,35),ylim=c(37,70))
>>
>> Beside the wrong colors it worked okay.
>> But I am not really happy with this solution.
>>
>> Did I misapprehend you?
>>
> Hi Claudi,
> Maybe. You write that the transformation of GPIndex to colors "went  
> wrong". Let's see:
>
> # make up GPIndex
> GPIndex<-c(sample(1:100,33),rep(NA,165))
> # transform to colors
> eurocol<-color.scale(GPIndex,c(1,0),0,c(0,1))
> world.map<-map('world',fill=TRUE,
>  col=eurocol,xlim=c(-12,35),ylim=c(37,70))
>
> This gives me what I would expect, and checking the colors against  
> the country names (world.map$names) looks like the correct colors  
> have been displayed. Obviously I left a lot of areas out (missed UK  
> and Ireland for example) as I didn't want to overplot individual  
> countries with areas. Does this look okay to you?
>
> Jim


From cesargperezleon at gmail.com  Fri Nov  1 19:16:47 2013
From: cesargperezleon at gmail.com (cesar garcia perez de leon)
Date: Fri, 1 Nov 2013 19:16:47 +0100
Subject: [R] Plot of coxph tt effects
Message-ID: <73C63443-0B13-4373-8B11-E8BD555074C1@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/504e61b2/attachment.pl>

From tstudent at gmail.com  Fri Nov  1 20:46:09 2013
From: tstudent at gmail.com (Tstudent)
Date: Fri, 1 Nov 2013 19:46:09 +0000
Subject: [R] Load Tawny package on R 2.15.3
References: <loom.20131101T120934-572@post.gmane.org>
	<5273B7C3.4080209@statistik.tu-dortmund.de>
	<loom.20131101T153217-685@post.gmane.org>
	<CACk-te2XhncW5tG5Y=nN2CqTGwM-mrXUjV=yuKxbbSniWu7-aA@mail.gmail.com>
Message-ID: <loom.20131101T203738-206@post.gmane.org>


> I have no specific expertise here, but I just wanted to point out that
> this sounds like a losing strategy long term: As new packages and
> newer versions of packages come out that fix bugs and add features,
> you'll be unable to use them because you'll be stuck with 2.15.3 . I
> suggest you bite the bullet and follow the experts' advice to get
> things working with the current R version now.
> 
> Cheers,
> Bert
> 
> >
> > ______________________________________________
> > R-help <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 


It seems that the only possibility for me is to install R 3.0
So i have a question. 
Now i use R 2.15.3 and Rstudio (which is linked to R 2.15.3)
Can i install R 3.0 in another directory but leave R 2.15.3 as default or
primary R  ? Any problems to do this? Something to be careful?


From victor_hyk at yahoo.ca  Fri Nov  1 21:00:51 2013
From: victor_hyk at yahoo.ca (Victor hyk)
Date: Fri, 1 Nov 2013 13:00:51 -0700 (PDT)
Subject: [R] Impose constraint on first order derivative at a point for
	cubic smoothing spline
Message-ID: <1383336051.75528.YahooMailNeo@web125804.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/4540ec30/attachment.pl>

From paladini at trustindata.de  Fri Nov  1 21:53:27 2013
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Fri, 01 Nov 2013 21:53:27 +0100
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
	<CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
	<20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>
	<CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>
Message-ID: <20131101215327.Horde.S_fxKqUMpTXjG4_cO5Xgkw7@webmail.df.eu>

Hi Jean,
nevertheless this page "R-bloggers" looks realy interesting so I'll  
work through the tutorial.
Thanks again for recommanding this web-site.

Best regards

Claudia


Zitat von "Adams, Jean" <jvadams at usgs.gov>:

> Claudia,
>
> I have not worked through the example myself.  Since you seem to be getting
> errors, perhaps a different example would help.  Here are some more
> choropleth maps (although these use US states rather than European
> countries).
>
> http://blog.revolutionanalytics.com/2009/11/choropleth-challenge-result.html
>
> Jean
>
>
>
> On Fri, Nov 1, 2013 at 12:04 PM, <paladini at trustindata.de> wrote:
>
>> Hi Jean,
>> thanks again for your response. As I told you  I did the downloads and
>> double checked if I selected the right directory.
>> But I noticed right now what happend:
>> The command in the example is :
>>
>> eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/Shape/data/NUTS_RG_60M_**
>> 2010")
>>
>> But it should be :
>> eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/data/ggg/NUTS_RG_60M_**
>> 2010")
>>
>> Because if you do the downloads and unzip these data there is no such
>> think as a "Shape" directory.
>>
>> Now eurMap <- readShapePoly(fn="NUTS_2010_**60M_SH/data/NUTS_RG_60M_2010")
>> works.
>>
>>
>> What happens now is that after typing:
>> eurEduMapDf <- merge(eurMapDf, eurEdu, by.x="id", by.y="GEO")
>> I get another error message because "eurMapDf" is unknown.
>>
>> So I supposed it should be:
>> eurEduMapDf <- merge(eurMap, eurEdu, by.x="id", by.y="GEO")
>>
>> But this doesn't work either.The error message this time is: undefined
>> column selected.
>>
>> Did I do something wrong?
>>
>>
>>
>> Best regards
>>
>> Claudia
>>
>>
>>
>>
>>
>>
>>
>>
>> Zitat von "Adams, Jean" <jvadams at usgs.gov>:
>>
>>  Claudia,
>>>
>>> You should cc r-help on all correspondence so that others can follow the
>>> thread.
>>>
>>> In the second paragraph of the link I sent you
>>>       
>>> http://www.r-bloggers.com/**maps-in-r-choropleth-maps/<http://www.r-bloggers.com/maps-in-r-choropleth-maps/>
>>> a link is provided for the NUTS data,
>>>      "The polygons for drawing the administrative boundaries were obtained
>>> from this link. In particular, the NUTS 2010 shapefile in the 1:60 million
>>> scale was downloaded and used. The other available scales would allow the
>>> drawing of better defined maps, but at a computational cost. The zipped
>>> file has to be extracted in a folder of choice for using it later."
>>>
>>> http://epp.eurostat.ec.europa.**eu/portal/page/portal/gisco_**
>>> Geographical_information_maps/**popups/references/**administrative_units_
>>> **statistical_units_1<http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco_Geographical_information_maps/popups/references/administrative_units_statistical_units_1>
>>>
>>> If you want to follow the example, you will need to download this data to
>>> your computer and then make sure that you refer to the appropriate
>>> directory when using the readShapePoly() function.
>>>
>>> Jean
>>>
>>>
>>>
>>> On Wed, Oct 30, 2013 at 11:14 AM, <paladini at trustindata.de> wrote:
>>>
>>>  Hi Jean,
>>>> thank you for your advice.
>>>> The page looks quite interesting and I tried the example in  GNU R. I did
>>>> all the downloads.
>>>> But
>>>> Just in the beginnig after typing
>>>>
>>>> eurMap <- readShapePoly(fn="NUTS_2010_****60M_SH/Shape/data/NUTS_RG_60M_
>>>> ****
>>>>
>>>> 2010")
>>>> I get the following error message:
>>>>
>>>> Error in getinfo.shape(filen) : Error opening SHP file
>>>>
>>>> To you have an idea what I did wrong?
>>>>
>>>> Thanks a lot and best regards
>>>>
>>>> Claudia
>>>>
>>>>
>>>>
>>>>
>>>> Zitat von "Adams, Jean" <jvadams at usgs.gov>:
>>>>
>>>>  Check out this link for some examples
>>>>
>>>>>      
>>>>> http://www.r-bloggers.com/****maps-in-r-choropleth-maps/<http://www.r-bloggers.com/**maps-in-r-choropleth-maps/>
>>>>> <htt**p://www.r-bloggers.com/maps-**in-r-choropleth-maps/<http://www.r-bloggers.com/maps-in-r-choropleth-maps/>
>>>>> >
>>>>>
>>>>>
>>>>> Jean
>>>>>
>>>>>
>>>>> On Tue, Oct 29, 2013 at 12:02 PM, <paladini at trustindata.de> wrote:
>>>>>
>>>>>  Hello,
>>>>>
>>>>>> I would like to draw a map of Europe. Each country should be colored
>>>>>> depending on how it scores in an index called GPIndex.
>>>>>> Say a dark red for real bad countries a light red for those which are
>>>>>> not
>>>>>> so bad, light blue for the fairly good ones and so on up to the really
>>>>>> good
>>>>>> ones in a dark blue.
>>>>>> I never worked with geographic maps before so I tried library maps but
>>>>>> I
>>>>>> didn't get far,- especially because all examples I found only seem to
>>>>>> work
>>>>>> for the United states. So I'm a bit lost.
>>>>>> I would be nice if somebody could help me.
>>>>>>
>>>>>> Thanking you in anticipation!
>>>>>>
>>>>>> Best regards
>>>>>>
>>>>>> Claudia
>>>>>>
>>>>>> ______________________________******________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/******listinfo/r-help<https://stat.ethz.ch/mailman/****listinfo/r-help>
>>>>>> <https://**stat.ethz.ch/mailman/****listinfo/r-help<https://stat.ethz.ch/mailman/**listinfo/r-help>
>>>>>> >
>>>>>> <https://stat.**ethz.ch/**mailman/listinfo/r-**help<http://ethz.ch/mailman/listinfo/r-**help>
>>>>>> <http**s://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>> >
>>>>>>
>>>>>> >
>>>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>>>> posting-guide.html  
>>>>>> <http://www.R-project.org/****posting-guide.html<http://www.R-project.org/**posting-guide.html>
>>>>>> <http://www.**R-project.org/posting-guide.**html<http://www.R-project.org/posting-guide.html>
>>>>>> >
>>>>>>
>>>>>> >
>>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>>>>>
>>>>
>>>>
>>
>>


From dwinsemius at comcast.net  Fri Nov  1 22:18:47 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 1 Nov 2013 14:18:47 -0700
Subject: [R] Plot of coxph tt effects
In-Reply-To: <73C63443-0B13-4373-8B11-E8BD555074C1@gmail.com>
References: <73C63443-0B13-4373-8B11-E8BD555074C1@gmail.com>
Message-ID: <7925BEE0-5911-4B10-A787-327BC530D02B@comcast.net>


On Nov 1, 2013, at 11:16 AM, cesar garcia perez de leon wrote:

> Dear all, 
> 
> We are conducting a study in with a set of covariates and a time to event outcome. 
> Covariates b1 and b3 violate proportionality.

Can you describe the basis for that statement?

> We applied a coxph with a ?tt? term to evaluate the nature of time dependence. 
> 
> Call: 
> coxph(formula = Surv(start - 1, stop, outcome) ~ tt(b1) + 
>    b5 + tt(b3) + b4, data = data, tt = function(x,  t, ...) pspline(x + t/90)) 
> 
> We would like to plot the predicted effects. Following the logic of the tt function, does it make sense to plot the residuals against the results from the model with tt for the upsetting covariates? 
> 
> As far as we know the there has not been updates of survfit for the tt  function. So, we are unsure as to how to plot our curves. 
> 
> I would appreciate if someone can give me an advise or a publication reference that can help us in this matter. 

Is there a reason not to use `cox.zph` and it's `print` and `plot` methods for this purpose? I think it is already offering what you are trying to re0invent.

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Fri Nov  1 22:38:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 14:38:08 -0700 (PDT)
Subject: [R] (no subject)
In-Reply-To: <1383168264.47040.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAFQvP01n8Y+hu5yNw1Fxz9GqYexbSpxbTLhaFnCBVd3eNWShFg@mail.gmail.com>	<1383139020.16224.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAFQvP02xCz3B8MtanYhOG_3cEy0cD08WR7x=6i6TFWpuWKsFtQ@mail.gmail.com>	<1383151171.63745.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAFQvP02r-hD7pfgVu_v=3GAsPCWS+YJhhwXGTzW6a_g6MCY7+Q@mail.gmail.com>	<1383152762.32491.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAFQvP01DEW-sDu__ZZs8VaWBSQtOrQ63GuYdaj6KP4_Am=8jEQ@mail.gmail.com>	<1383159196.60640.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAFQvP02z=pRSMpKAKKc9BvVXjfjcYP9RaA_-Y03L0qcYYSh1hg@mail.gmail.com>
	<1383168264.47040.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1383341888.99418.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

Check whether this works:


vec1 <- c( 'eric', 'JOHN', 'eric', 'JOHN', 'steve', 'scott', 'steve', 'scott', 'JOHN', 'eric')
vec2 <- c( 'eric', 'JOHN', 'eric', 'eric', 'JOHN', 'JOHN', 'steve', 'steve', 'scott', 'scott')
vec3 <- c( 'eric', 'eric', 'JOHN', 'eric', 'JOHN', 'JOHN', 'steve', 'steve', 'scott', 'scott')

vec4 <- c( 'eric', 'eric', 'JOHN', 'eric', 'JOHN', 'steve', 'steve', 'scott', 'scott','JOHN')
vec5 <- c('JOHN', 'JOHN', 'eric', 'eric', 'JOHN', 'eric', 'steve', 'steve', 'scott', 'scott')
vec6 <- c( 'eric', 'eric',? 'eric', 'JOHN','JOHN', 'JOHN', 'steve', 'steve','scott', 'scott')
vec7 <- c( 'eric', 'eric',? 'eric', 'JOHN','JOHN', 'JOHN', 'steve', 'scott', 'scott', 'steve')
fun1 <- function(vec) {
?sum(unlist(sapply(unique(vec),function(x) {x1 <- diff(which(vec %in% x)); ifelse(x1==1, 1, -x1)}),use.names=FALSE))
?}


A.K.






I took a steve and put it at the end of the vector. ?score should be less as the steves are farther apart.

> vec3 <- c( 'eric', 'eric', ?'eric', 'JOHN','JOHN', 'JOHN', 'steve', 'steve','scott', 'scott')
> sum(diff(vec3[-1]!=vec3[-length(vec3)])) + ?sum(vec3[-1]== vec3[-length(vec3)])
[1] 6

> vec4 <- c( 'eric', 'eric', ?'eric', 'JOHN','JOHN', 'JOHN', 'steve', 'scott', 'scott', 'steve')
> sum(diff(vec4[-1]!=vec4[-length(vec4)])) + ?sum(vec4[-1]== vec4[-length(vec4)])
[1] 6

S


From andreas.leha at med.uni-goettingen.de  Fri Nov  1 22:50:19 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Fri, 1 Nov 2013 22:50:19 +0100
Subject: [R] quickly extract response from formula
References: <87ob652njo.fsf@med.uni-goettingen.de>
	<4AF2DBF0-F14B-40B1-97FA-5F64DC9A5A8F@comcast.net>
Message-ID: <87k3gr3i78.fsf@med.uni-goettingen.de>

Hi David,

thanks for your quick answer!

David Winsemius <dwinsemius at comcast.net> writes:

> On Oct 31, 2013, at 1:27 PM, Andreas Leha wrote:
>
>> Hi all,
>> 
>> what is the recommended way to quickly (and without much burden on the
>> memory) extract the response from a formula?
>
> If you want its expression value its just form[[2]]
>
> If you wnat it evaluated in the environment of a dataframe then this should be fairly efficient:
>
> x <- stats::runif(20)
> y <- stats::runif(20)
> dfrm <- data.frame(x=x,y=y)
> extractResponse <- function(frm, dat) { resp <- frm[[2]]; print(resp) # that's optional
>                                          fdat <- eval(resp,
>                                          envir=dat); return(fdat) }

This is what I'll be using.  Thanks again!

[...]

Regards,
Andreas


From wdunlap at tibco.com  Fri Nov  1 23:06:20 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Nov 2013 22:06:20 +0000
Subject: [R] quickly extract response from formula
In-Reply-To: <87k3gr3i78.fsf@med.uni-goettingen.de>
References: <87ob652njo.fsf@med.uni-goettingen.de>
	<4AF2DBF0-F14B-40B1-97FA-5F64DC9A5A8F@comcast.net>
	<87k3gr3i78.fsf@med.uni-goettingen.de>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA123C0@PA-MBX01.na.tibco.com>

You can bullet-proof it a bit by making sure that length(formula)==3
before assuming that formula[[2]] is the response.   If length(formula)==2
then there is no response term, only predictor terms.  E.g., replace
   resp <- frm[[2]]
with
   resp <- if (length(frm)==3) frm[[2]] else NULL
(or call stop(), or warning(), ...)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Andreas Leha
> Sent: Friday, November 01, 2013 2:50 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] quickly extract response from formula
> 
> Hi David,
> 
> thanks for your quick answer!
> 
> David Winsemius <dwinsemius at comcast.net> writes:
> 
> > On Oct 31, 2013, at 1:27 PM, Andreas Leha wrote:
> >
> >> Hi all,
> >>
> >> what is the recommended way to quickly (and without much burden on the
> >> memory) extract the response from a formula?
> >
> > If you want its expression value its just form[[2]]
> >
> > If you wnat it evaluated in the environment of a dataframe then this should be fairly
> efficient:
> >
> > x <- stats::runif(20)
> > y <- stats::runif(20)
> > dfrm <- data.frame(x=x,y=y)
> > extractResponse <- function(frm, dat) { resp <- frm[[2]]; print(resp) # that's optional
> >                                          fdat <- eval(resp,
> >                                          envir=dat); return(fdat) }
> 
> This is what I'll be using.  Thanks again!
> 
> [...]
> 
> Regards,
> Andreas
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fhcrc.org  Fri Nov  1 23:12:07 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 01 Nov 2013 15:12:07 -0700
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <5273C73D.2090809@gmail.com>
References: <5273AD7E.6090607@gmail.com>	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
	<5273C73D.2090809@gmail.com>
Message-ID: <52742737.7020609@fhcrc.org>

On 11/01/2013 08:22 AM, Magnus Thor Torfason wrote:
> Sure,
>
> I was attempting to be concise and boiling it down to what I saw as the root
> issue, but you are right, I could have taken it a step further. So here goes.
>
> I have a set of around around 20M string pairs. A given string (say, A) can
> either be equivalent to another string (B) or not. If A and B occur together in
> the same pair, they are equivalent. But equivalence is transitive, so if A and B
> occur together in one pair, and A and C occur together in another pair, then A
> and C are also equivalent. I need a way to quickly determine if any two strings
> from my data set are equivalent or not.

Do you mean that if A,B occur together and B,C occur together, then A,B and A,C 
are equivalent?

Here's a function that returns a unique identifier (not well tested!), allowing 
for transitive relations but not circularity.

      uid <- function(x, y)
     {
         i <- seq_along(x)                   # global index
         xy <- paste0(x, y)                  # make unique identifiers
         idx <- match(xy, xy)

         repeat {
             ## transitive look-up
             y_idx <- match(y[idx], x)       # look up 'y' in 'x'
             keep <- !is.na(y_idx)
             if (!any(keep))                 # no transitive relations, done!
                 break
             x[idx[keep]] <- x[y_idx[keep]]
             y[idx[keep]] <- y[y_idx[keep]]

             ## create new index of values
             xy <- paste0(x, y)
             idx <- match(xy, xy)
         }
         idx
     }

Values with the same index are identical. Some tests

     > x <- c(1, 2, 3, 4)
     > y <- c(2, 3, 5, 6)
     > uid(x, y)
     [1] 1 1 1 4
     > i <- sample(x); uid(x[i], y[i])
     [1] 1 1 3 1
     > uid(as.character(x), as.character(y))  ## character() ok
     [1] 1 1 1 4
     > uid(1:10, 1 + 1:10)
      [1] 1 1 1 1 1 1 1 1 1 1
     > uid(integer(), integer())
     integer(0)
     > x <- c(1, 2, 3)
     > y <- c(2, 3, 1)
     > uid(x, y)                              ## circular!
       C-c C-c

I think this will scale well enough, but the worst-case scenario can be made to 
be log(longest chain) and copying can be reduced by using an index i and 
subsetting the original vector on each iteration. I think you could test for 
circularity by checking that the updated x are not a permutation of the kept x, 
all(x[y_idx[keep]] %in% x[keep]))

Martin

>
> The way I do this currently is to designate the smallest (alphabetically) string
> in each known equivalence set as the "main" entry. For each pair, I therefore
> insert two entries into the hash table, both pointing at the mail value. So
> assuming the input data:
>
> A,B
> B,C
> D,E
>
> I would then have:
>
> A->A
> B->A
> C->B
> D->D
> E->D
>
> Except that I also follow each chain until I reach the end (key==value), and
> insert pointers to the "main" value for every value I find along the way. After
> doing that, I end up with:
>
> A->A
> B->A
> C->A
> D->D
> E->D
>
> And I can very quickly check equivalence, either by comparing the hash of two
> strings, or simply by transforming each string into its hash, and then I can use
> simple comparison from then on. The code for generating the final hash table is
> as follows:
>
> h : Empty hash table created with hash.new()
> d : Input data
> hash.deep.get : Function that iterates through the hash table until it finds a
> key whose value is equal to itself (until hash.get(X)==X), then returns all the
> values in a vector
>
>
> h = hash.new()
> for ( i in 1:nrow(d) )
> {
>      deep.a      = hash.deep.get(h, d$a[i])
>      deep.b      = hash.deep.get(h, d$b[i])
>      equivalents = sort(unique(c(deep.a,deep.b)))
>      equiv.id    = min(equivalents)
>      for ( equivalent in equivalents )
>      {
>          hash.put(h, equivalent, equiv.id)
>      }
> }
>
>
> I would so much appreciate if there was a simpler and faster way to do this.
> Keeping my fingers crossed that one of the R-help geniuses who sees this is
> sufficiently interested to crack the problem
>
> Best,
> Magnus
>
> On 11/1/2013 1:49 PM, jim holtman wrote:
>> It would be nice if you followed the posting guidelines and at least
>> showed the script that was creating your entries now so that we
>> understand the problem you are trying to solve.  A bit more
>> explanation of why you want this would be useful.  This gets to the
>> second part of my tag line:  Tell me what you want to do, not how you
>> want to do it.  There may be other solutions to your problem.
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
>> <zulutime.net at gmail.com> wrote:
>>> Pretty much what the subject says:
>>>
>>> I used an env as the basis for a Hashtable in R, based on information that
>>> this is in fact the way environments are implemented under the hood.
>>>
>>> I've been experimenting with doubling the number of entries, and so far it
>>> has seemed to be scaling more or less linearly, as expected.
>>>
>>> But as I went from 17 million entries to 34 million entries, the completion
>>> time has gone from 18 hours, to 5 days and counting.
>>>
>>>
>>> The keys and values are in all cases strings of equal length.
>>>
>>> One might suspect that the slow-down might have to do with the memory being
>>> swapped to disk, but from what I know about my computing environment, that
>>> should not be the case.
>>>
>>> So my first question:
>>> Is anyone familiar with anything in the implementation of environments that
>>> would limit their use or slow them down (faster than O(nlog(n)) as the
>>> number of entries is increased?
>>>
>>> And my second question:
>>> I realize that this is not strictly what R environments were designed for,
>>> but this is what my algorithm requires: I must go through these millions of
>>> entries, storing them in the hash table and sometimes retrieving them along
>>> the way, in a more or less random manner, which is contingent on the data I
>>> am encountering, and on the contents of the hash table at each moment.
>>>
>>> Does anyone have a good recommendation for alternatives to implement huge,
>>> fast, table-like structures in R?
>>>
>>> Best,
>>> Magnus
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From dulcalma at bigpond.com  Fri Nov  1 23:27:53 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 2 Nov 2013 08:27:53 +1000
Subject: [R] Lattice Legend/Key by row instead of by column
In-Reply-To: <CAJU8Py2wzob3OoRSgzZ4QOw4zHg8TpRJfTzLvyvv6PBTJnVAAw@mail.gmail.com>
References: <CAJU8Py06n=EBxAP=HBbiUBcGjyXK7ye=qQCat2L_LvTHP+w2Lg@mail.gmail.com>
	<000001ced68b$39004400$ab00cc00$@bigpond.com>
	<CAJU8Py2wzob3OoRSgzZ4QOw4zHg8TpRJfTzLvyvv6PBTJnVAAw@mail.gmail.com>
Message-ID: <003001ced751$9c412180$d4c36480$@bigpond.com>

Hi Richard

Untested Perhaps adding some dummy factors with NA and then have their
labels as " " and color of lines as 0 or "transparent".

I think that I used it partly for the same reason and in addition I was
combining 2 purposes with  the groups and wanted to split them 

Duncan

-----Original Message-----
From: Richard Kwock [mailto:richardkwock at gmail.com] 
Sent: Saturday, 2 November 2013 02:31
To: Duncan Mackay
Cc: R
Subject: Re: [R] Lattice Legend/Key by row instead of by column

Hi Duncan,

Thanks for that template. Not quite the solution I was hoping for, but that
works!

Richard

On Thu, Oct 31, 2013 at 3:47 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Richard
>
> If you cannot get a better suggestion this example from Deepayan 
> Sarkar may help.
> It is way back in the archives and I do not have a reference for it.
>
> I have used it about a year ago as a template to do a complicated key
>
> fl <- grid.layout(nrow = 2, ncol = 6,
>                   heights = unit(rep(1, 2), "lines"),
>                   widths = unit(c(2, 1, 2, 1, 2, 1),
>
> c("cm","strwidth","cm","strwidth","cm","strwidth"),
>                   data = list(NULL,"John",NULL,"George",NULL,"The
> Beatles")))
>
> foo <- frameGrob(layout = fl)
> foo <- placeGrob(foo,
>                  pointsGrob(.5, .5, pch=19,
>                             gp = gpar(col="red", cex=0.5)),
>                  row = 1, col = 1)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="blue")),
>                  row = 2, col = 1)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="green")),
>                  row = 1, col = 3)
> foo <- placeGrob(foo,
>                  linesGrob(c(0.2, 0.8), c(.5, .5),
>                            gp = gpar(col="orange")),
>                  row = 2, col = 3)
> foo <- placeGrob(foo,
>                  rectGrob(width = 0.6,
>                           gp = gpar(col="#FFFFCC",
>                           fill = "#FFFFCC")),
>                  row = 1, col = 5)
> foo <- placeGrob(foo,
>                  textGrob(lab = "John"),
>                  row = 1, col = 2)
> foo <- placeGrob(foo,
>                  textGrob(lab = "Paul"),
>                  row = 2, col = 2)
> foo <- placeGrob(foo,
>                  textGrob(lab = "George"),
>                  row = 1, col = 4)
> foo <- placeGrob(foo,
>                  textGrob(lab = "Ringo"),
>                  row = 2, col = 4)
> foo <- placeGrob(foo,
>                  textGrob(lab = "The Beatles"),
>                  row = 1, col = 6)
>
> xyplot(1 ~ 1, legend = list(top = list(fun = foo)))
>
> In my case I changed  "strwidth" to "cm" for the text as I was cramped 
> for space
>
> HTH
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science University of New England 
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Richard Kwock
> Sent: Friday, 1 November 2013 06:42
> To: R help
> Subject: [R] Lattice Legend/Key by row instead of by column
>
> Hi All,
>
> I am having some trouble getting lattice to display the legend names 
> by row instead of by column (default).
>
> Example:
>
> library(lattice)
> set.seed(456846)
> data <- matrix(c(1:10) + runif(50), ncol = 5, nrow = 10) dataset <- 
> data.frame(data = as.vector(data), group = rep(1:5, each = 10), time = 
> 1:10)
>
> xyplot(data ~ time, group = group, dataset, t = "l",
>   key = list(text = list(paste("group", unique(dataset$group)) ),
>     lines = list(col = trellis.par.get()$superpose.symbol$col[1:5]),
>     columns = 4
>   )
> )
>
> What I'm hoping for are 4 columns in the legend, like this:
> Legend row 1: "group 1", "group 2", "group 3", "group 4"
> Legend row 2: "group 5"
>
> However, I'm getting:
> Legend row 1: "group 1", "group 3", "group 5"
> Legend row 2: "group 2", "group 4"
>
> I can see how this might work if I include blanks/NULLs in the legend 
> as placeholders, but that might get messy in data sets with many groups.
>
> Any ideas on how to get around this?
>
> Thanks,
> Richard
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sat Nov  2 00:22:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Nov 2013 16:22:38 -0700 (PDT)
Subject: [R] Combinations of values in two columns
In-Reply-To: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
References: <68A72B34-5C62-4530-A8DF-9241DC01114B@nottingham.ac.uk>
Message-ID: <1383348158.16880.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
You may try:
dat1 <- read.table(text="
Friend1,Friend2
A,B
A,C
B,A
C,D",sep=",",header=TRUE,stringsAsFactors=FALSE)
indx <- as.vector(outer(unique(dat1[,1]),unique(dat1[,2]),paste))
res <- cbind(setNames(read.table(text=indx,sep="",header=FALSE,stringsAsFactors=FALSE),paste0("Friend",1:2)), New=1*(indx %in% as.character(interaction(dat1,sep=" "))))

A.K.



On Friday, November 1, 2013 5:56 AM, Thomas <thomas.chesney at nottingham.ac.uk> wrote:
I have data that looks like this:

Friend1, Friend2
A, B
A, C
B, A
C, D

And I'd like to generate some more rows and another column. In the new? 
column I'd like to add a 1 beside all the existing rows. That bit's? 
easy enough.

Then I'd like to add rows for all the possible directed combinations? 
of rows not included in the existing data. So for the above I think? 
that would be:

A, D
D, A
B, C
C, B
B, D
C, A
D, B
D, C

and then put a 0 in the column beside these.

Can anyone suggest how to do this?

I'm using R version 2.15.3.

Thank you,

Thomas Chesney
This message and any attachment are intended solely for the addressee and may contain confidential information. If you have received this message in error, please send it back to me, and immediately delete it.?  Please do not use, copy or disclose the information contained in this message or in any attachment.? Any views or opinions expressed by the author of this email do not necessarily reflect the views of the University of Nottingham.

This message has been checked for viruses but the contents of an attachment
may still contain software viruses which could damage your computer system, you are advised to perform your own checks. Email communications with the University of Nottingham may be monitored as permitted by UK legislation.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From zj29 at cornell.edu  Sat Nov  2 00:35:18 2013
From: zj29 at cornell.edu (Zhao Jin)
Date: Fri, 1 Nov 2013 16:35:18 -0700
Subject: [R] Package(s) for making waffle plot-like figures?
Message-ID: <CAGD4NN+jNrmYHywkgvVRMFAd+bauJ3em6pt0+zCdHFwOVAK2tQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/9e4b9dfc/attachment.pl>

From andreas.leha at med.uni-goettingen.de  Sat Nov  2 00:40:48 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Sat, 2 Nov 2013 00:40:48 +0100
Subject: [R] quickly extract response from formula
References: <87ob652njo.fsf@med.uni-goettingen.de>
	<4AF2DBF0-F14B-40B1-97FA-5F64DC9A5A8F@comcast.net>
	<87k3gr3i78.fsf@med.uni-goettingen.de>
	<E66794E69CFDE04D9A70842786030B933FA123C0@PA-MBX01.na.tibco.com>
Message-ID: <87fvrf3d33.fsf@med.uni-goettingen.de>

William Dunlap <wdunlap at tibco.com> writes:

> You can bullet-proof it a bit by making sure that length(formula)==3
> before assuming that formula[[2]] is the response.   If length(formula)==2
> then there is no response term, only predictor terms.  E.g., replace
>    resp <- frm[[2]]
> with
>    resp <- if (length(frm)==3) frm[[2]] else NULL
> (or call stop(), or warning(), ...)

Will do.  Thanks.

- Andreas

>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Andreas Leha
>> Sent: Friday, November 01, 2013 2:50 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] quickly extract response from formula
>> 
>> Hi David,
>> 
>> thanks for your quick answer!
>> 
>> David Winsemius <dwinsemius at comcast.net> writes:
>> 
>> > On Oct 31, 2013, at 1:27 PM, Andreas Leha wrote:
>> >
>> >> Hi all,
>> >>
>> >> what is the recommended way to quickly (and without much burden on the
>> >> memory) extract the response from a formula?
>> >
>> > If you want its expression value its just form[[2]]
>> >
>> > If you wnat it evaluated in the environment of a dataframe then this should be fairly
>> efficient:
>> >
>> > x <- stats::runif(20)
>> > y <- stats::runif(20)
>> > dfrm <- data.frame(x=x,y=y)
>> > extractResponse <- function(frm, dat) { resp <- frm[[2]]; print(resp) # that's optional
>> >                                          fdat <- eval(resp,
>> >                                          envir=dat); return(fdat) }
>> 
>> This is what I'll be using.  Thanks again!
>> 
>> [...]
>> 
>> Regards,
>> Andreas
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdxgary163 at gmail.com  Sat Nov  2 01:08:46 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Fri, 1 Nov 2013 17:08:46 -0700
Subject: [R] plot time series data in wide format
Message-ID: <CAEVDvzUM4SVcVxk8DqWjhzf6_JF6gWfGKh1oaxmNpG91eGECWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/71caecb3/attachment.pl>

From msuzen at gmail.com  Sat Nov  2 01:50:47 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sat, 2 Nov 2013 01:50:47 +0100
Subject: [R] computation of hessian matrix
In-Reply-To: <1383300398.80446.YahooMailNeo@web142506.mail.bf1.yahoo.com>
References: <1383300398.80446.YahooMailNeo@web142506.mail.bf1.yahoo.com>
Message-ID: <CAPtbhHzvTiZyuti+Lg5WL7Xv5HEw2QxnUq=vdXXPnUqAzyDzEQ@mail.gmail.com>

On 1 November 2013 11:06, IZHAK shabsogh <ishaqbaba at yahoo.com> wrote:
> below is a code to compute hessian matrix , which i need to generate 29 number of different matrices for example first

You may consider using Numerical Derivatives package for that instead, see:
http://cran.r-project.org/web/packages/numDeriv/vignettes/Guide.pdf


From Peter.Brecknock at bp.com  Sat Nov  2 02:17:22 2013
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Fri, 1 Nov 2013 18:17:22 -0700 (PDT)
Subject: [R] plot time series data in wide format
In-Reply-To: <CAEVDvzUM4SVcVxk8DqWjhzf6_JF6gWfGKh1oaxmNpG91eGECWA@mail.gmail.com>
References: <CAEVDvzUM4SVcVxk8DqWjhzf6_JF6gWfGKh1oaxmNpG91eGECWA@mail.gmail.com>
Message-ID: <1383355042333-4679591.post@n4.nabble.com>

wudadan wrote
> Dear R users,
> 
> I wonder if there is a way that I can plot a time series data which is in
> a
> wide format like this:
> 
> CITY_NAME       2000Q1    2000Q2      2000Q3        2000Q4     2001Q1
> 2001Q2      2001Q3     2001Q4     2002Q1      2002Q2
> CITY1                100.5210   101.9667  103.24933   104.0506   104.4317
> 105.3921   106.7643   107.5202   107.2561   107.8184
> CITY2                100.0412   100.6146  103.20293   104.0867   104.6612
> 106.6126   109.3514   110.1943   110.9480   113.0071
> CITY3                 99.5895    99.2298   99.26947    99.4101   100.5776
> 101.3719   101.5957   102.2411   103.4390   105.1745
> CITY4                 99.6491   101.5386  104.90953   106.1065   108.1785
> 110.6845   113.3746   114.1254   116.2121   119.1033
> CITY5                100.9828   103.6847  105.04793   106.5925   108.7437
> 110.5549   111.9343   112.6704   113.6201   115.3020
> 
> Ideally, each city of the five city is represented by a line in the plot.
> 
> Any suggestion is appreciated!
> 
> Thanks!
> Gary
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

How about using the zoo package ....

library(zoo)

# Read Data
text <- "CITY_NAME  2000Q1 2000Q2  2000Q3  2000Q4  2001Q1 2001Q2  2001Q3 
2001Q4  2002Q1 2002Q2 
CITY1 100.5210 101.9667 103.24933 104.0506 104.4317 105.3921 106.7643
107.5202 107.2561 107.8184 
CITY2 100.0412 100.6146 103.20293 104.0867 104.6612 106.6126 109.3514
110.1943 110.9480 113.0071 
CITY3  99.5895  99.2298  99.26947  99.4101 100.5776 101.3719 101.5957
102.2411 103.4390 105.1745 
CITY4  99.6491 101.5386 104.90953 106.1065 108.1785 110.6845 113.3746
114.1254 116.2121 119.1033 
CITY5 100.9828 103.6847 105.04793 106.5925 108.7437 110.5549 111.9343
112.6704 113.6201 115.3020"

df <- read.table(textConnection(text), header=TRUE, check.names=FALSE)

#Create zoo object
d <- t(df[,-1])
ind <- as.yearqtr(names(df)[-1]) 
z <- zoo(d,ind)

# Plot
plot(z, plot.type="single", col=1:5, lwd=2)
legend("topleft",legend=c("City1","City2","City3","City4","City5"),lty=1,
lwd=2, col=1:5)

HTH

Pete




--
View this message in context: http://r.789695.n4.nabble.com/plot-time-series-data-in-wide-format-tp4679589p4679591.html
Sent from the R help mailing list archive at Nabble.com.


From Rainer.Schuermann at gmx.net  Sat Nov  2 03:43:10 2013
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 02 Nov 2013 03:43:10 +0100
Subject: [R] Installing RCurl: 'configure' exists but is not executable
Message-ID: <1541278.oqh9e0TbB1@rainer>

I'm trying to install.packages( "RCurl" ) as root but get
ERROR: 'configure' exists but is not executable

I remember having had something like that before on another machine and tried in bash what is described here 
http://mazamascience.com/WorkingWithData/?p=1185
and helped me before:
# mkdir ~/tmp
# export TMPDIR=~/tmp
and added, just in case,
# chmod u+x $TMPDIR

which apparently does what it should
# ls -ld $TMPDIR                                                                                               
drwxrwxrwx 2 root root 4096 Nov  1 08:59 /root/tmp

but it doesn't help, I get the same error.

What else can I try?

Thanks in advance,
Rainer


> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.2


From jmhannon.ucdavis at gmail.com  Sat Nov  2 04:21:36 2013
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Fri, 1 Nov 2013 20:21:36 -0700
Subject: [R] Installing RCurl: 'configure' exists but is not executable
In-Reply-To: <1541278.oqh9e0TbB1@rainer>
References: <1541278.oqh9e0TbB1@rainer>
Message-ID: <CACdH2Za_GSR8j3nX1pNFnckp1EmRfuCDo8V3_BY3MqeHx09nBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131101/ca3970fc/attachment.pl>

From Rainer.Schuermann at gmx.net  Sat Nov  2 04:38:04 2013
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 02 Nov 2013 04:38:04 +0100
Subject: [R] Installing RCurl: 'configure' exists but is not executable
In-Reply-To: <CACdH2Za_GSR8j3nX1pNFnckp1EmRfuCDo8V3_BY3MqeHx09nBg@mail.gmail.com>
References: <1541278.oqh9e0TbB1@rainer>
	<CACdH2Za_GSR8j3nX1pNFnckp1EmRfuCDo8V3_BY3MqeHx09nBg@mail.gmail.com>
Message-ID: <13319325.YRotjPDbHh@rainer>

#  ls -l `which curl-config`
-rwxr-xr-x 1 root root 6327 Oct 20 15:25 /usr/bin/curl-config



On Friday 01 November 2013 20:21:36 Michael Hannon wrote:
> The error message doesn't seem to refer to the tmp directory.  What do you
> get from:
> 
>     ls -l `which curl-config`
> 
> -- Mike
> 
> 
> On Fri, Nov 1, 2013 at 7:43 PM, Rainer Schuermann <Rainer.Schuermann at gmx.net
> > wrote:
> 
> > I'm trying to install.packages( "RCurl" ) as root but get
> > ERROR: 'configure' exists but is not executable
> >
> > I remember having had something like that before on another machine and
> > tried in bash what is described here
> > http://mazamascience.com/WorkingWithData/?p=1185
> > and helped me before:
> > # mkdir ~/tmp
> > # export TMPDIR=~/tmp
> > and added, just in case,
> > # chmod u+x $TMPDIR
> >
> > which apparently does what it should
> > # ls -ld $TMPDIR
> > drwxrwxrwx 2 root root 4096 Nov  1 08:59 /root/tmp
> >
> > but it doesn't help, I get the same error.
> >
> > What else can I try?
> >
> > Thanks in advance,
> > Rainer
> >
> >
> > > sessionInfo()
> > R version 3.0.2 (2013-09-25)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.0.2
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jari.oksanen at oulu.fi  Sat Nov  2 08:07:51 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Sat, 2 Nov 2013 07:07:51 +0000
Subject: [R] Efficient way to convert covariance to Euclidian distance
	matrix
References: <CADL0PchYe4SGAAErKUDqfLi4Z67SUi6xfE4bzMv=Gw8JjTQCFw@mail.gmail.com>
	<5272E12C.9020905@auckland.ac.nz>
Message-ID: <loom.20131102T080203-684@post.gmane.org>

Rolf Turner <r.turner <at> auckland.ac.nz> writes:

> 
> On 10/31/13 23:14, Takatsugu Kobayashi wrote:

> >
> > I am struggling to come up with an efficient vectorized way to convert
> > 20Kx20K covariance matrix to a Euclidian distance matrix as a surrogate for
> > dissimilarity matrix. Hopefully I can apply multidimensional scaling for
> > mapping these 20K points (commercial products).
> >

> 
> My suspicion is that with a 20K x 20K covariance matrix:
> 
>      * nothing will work
> 
>      * even if it did, the results would be meaningless numerical noise.
> 
> I.e.  Get real.

FWIW, I have tried NMDS for 19.2 K observations. It worked. The results looked 
sensible (i.e., they were not meaningless numerical noise). It was not fast, 
though, but it can be done. 

Cheers, Jari Oksanen 

PS. Sorry for excessive pruning, but gmane does not allow me post if I don't
remove some quoted lines.


From enzo.ccc at gmail.com  Sat Nov  2 09:55:23 2013
From: enzo.ccc at gmail.com (Enzo Cocca)
Date: Sat, 2 Nov 2013 09:55:23 +0100
Subject: [R] ascii-grid export
Message-ID: <CAC_+zuqPp7B_ecTS6PCi1EbnDFiOcJR4V6S3WX2FgMGsgudnzA@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/9c7242bf/attachment.pl>

From markuskainu at gmail.com  Sat Nov  2 09:27:00 2013
From: markuskainu at gmail.com (Markus Kainu)
Date: Sat, 2 Nov 2013 10:27:00 +0200
Subject: [R] mapping data to a geographic map of Europe
In-Reply-To: <20131101215327.Horde.S_fxKqUMpTXjG4_cO5Xgkw7@webmail.df.eu>
References: <20131029180252.Horde.8zbcwmvAgWnUOg2ZGLW6RA6@webmail.df.eu>
	<CAN5YmCHnKATgmwohcaHyTbzRSi4vyqcYg-jphxJ7AQ2m-wCbZg@mail.gmail.com>
	<20131030171421.Horde.dPu6YWuryyixwFIzcAFtoQ1@webmail.df.eu>
	<CAN5YmCHRt7+bYz7tFqNEVp9CS0AqCy2=xnBzUa8ERL=eY8QNYQ@mail.gmail.com>
	<20131101180418.Horde.gkeGDMTCJPc7fvpqty_lOg1@webmail.df.eu>
	<CAN5YmCHgLY5_oG3XXVG1LzYuwohFjZkxGAJi7xdi4Rkm3D=1kg@mail.gmail.com>
	<20131101215327.Horde.S_fxKqUMpTXjG4_cO5Xgkw7@webmail.df.eu>
Message-ID: <CANViG7VCRw8cu3oU46AeT8tRatbhnBVAL12CAj2Ujvzgit8DAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/9e2ec5d0/attachment.pl>

From gergely at snowl.net  Sat Nov  2 13:33:55 2013
From: gergely at snowl.net (=?ISO-8859-1?Q?Gergely_Dar=F3czi?=)
Date: Sat, 2 Nov 2013 13:33:55 +0100
Subject: [R] ascii-grid export
In-Reply-To: <CAC_+zuqPp7B_ecTS6PCi1EbnDFiOcJR4V6S3WX2FgMGsgudnzA@mail.gmail.com>
References: <CAC_+zuqPp7B_ecTS6PCi1EbnDFiOcJR4V6S3WX2FgMGsgudnzA@mail.gmail.com>
Message-ID: <CAPvvxJVxBfzMxEm4V=NwJOET95cePA0_bBUExcVGfLCSDSAG_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/0dc7dc96/attachment.pl>

From jim.silverton at gmail.com  Sat Nov  2 18:03:47 2013
From: jim.silverton at gmail.com (Jim Silverton)
Date: Sat, 2 Nov 2013 13:03:47 -0400
Subject: [R] R Packages in Mac
Message-ID: <CAGPwjHxZG2R_JUEHC0TO-8WfjrtVFBV4PuACQ3OR8bTMss-PjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/5a187ada/attachment.pl>

From rogerssarah65 at gmail.com  Sat Nov  2 11:02:31 2013
From: rogerssarah65 at gmail.com (Sarah Rogers)
Date: Sat, 2 Nov 2013 11:02:31 +0100
Subject: [R] Path Analysis
Message-ID: <CAELFSNU6zj3sePqT2pNE3WGtqcc-qu7SnSTY6Et_Dj9K0O4KXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/a8afc7ea/attachment.pl>

From yulya258 at yahoo.com  Sat Nov  2 12:32:39 2013
From: yulya258 at yahoo.com (Yla Savh)
Date: Sat, 2 Nov 2013 04:32:39 -0700 (PDT)
Subject: [R] how to compute correlation between times (with buffer before
	and after times)?
Message-ID: <1383391959.37670.YahooMailNeo@web162703.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/228e367e/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Nov  2 19:29:34 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 02 Nov 2013 18:29:34 +0000
Subject: [R] R Packages in Mac
In-Reply-To: <CAGPwjHxZG2R_JUEHC0TO-8WfjrtVFBV4PuACQ3OR8bTMss-PjA@mail.gmail.com>
References: <CAGPwjHxZG2R_JUEHC0TO-8WfjrtVFBV4PuACQ3OR8bTMss-PjA@mail.gmail.com>
Message-ID: <5275448E.6020707@stats.ox.ac.uk>

On 02/11/2013 17:03, Jim Silverton wrote:
> Hello everyone,
> I am interested in finding out why some packages don't work on Mac like the
> package 'vcd'
> Is there a fix?

What does "don't work" mean?  That one does: see 
http://cran.r-project.org/web/packages/vcd/index.html and the results page.

Vague false accusations are unfair to the package maintainers and CRAN team.

You were asked not to send HTML mail and to ask on the correct list: see 
the posting guide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From istazahn at gmail.com  Sat Nov  2 19:29:54 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 2 Nov 2013 14:29:54 -0400
Subject: [R] R Packages in Mac
In-Reply-To: <CAGPwjHxZG2R_JUEHC0TO-8WfjrtVFBV4PuACQ3OR8bTMss-PjA@mail.gmail.com>
References: <CAGPwjHxZG2R_JUEHC0TO-8WfjrtVFBV4PuACQ3OR8bTMss-PjA@mail.gmail.com>
Message-ID: <CA+vqiLFDtk64p1NDQjdKpLJvp4uvikatsR9cYV+jxH8F7DgQmQ@mail.gmail.com>

The vcd package works for me on a mac. Please be more specific,
describe what you did, and what happened that you found surprising.
Also include the output of sessionInfo()

Best,
Ista

On Sat, Nov 2, 2013 at 1:03 PM, Jim Silverton <jim.silverton at gmail.com> wrote:
> Hello everyone,
> I am interested in finding out why some packages don't work on Mac like the
> package 'vcd'
> Is there a fix?
>
> --
> Thanks,
> Jim.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Nov  2 19:48:38 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 02 Nov 2013 14:48:38 -0400
Subject: [R] Path Analysis
In-Reply-To: <CAELFSNU6zj3sePqT2pNE3WGtqcc-qu7SnSTY6Et_Dj9K0O4KXw@mail.gmail.com>
References: <CAELFSNU6zj3sePqT2pNE3WGtqcc-qu7SnSTY6Et_Dj9K0O4KXw@mail.gmail.com>
Message-ID: <web-481436287@cgpsrv2.cis.mcmaster.ca>

Dear Sarah,

It's generally a good idea to include a reproducible example if you want to get help with a problem, but in this case it's a safe bet that the problem is that the model you specified has no variance or covariance parameters for the variables x1 and x2, which, I assume, you mean to be exogenous. The easiest way to include these variances and covariance in the model is to specify the argument fixed.x=c("x1", "x2") in the call to sem().

In addition:

(1) Your model is fully recursive (guessing that all the x's and y's are observed variables), and so it amounts to four OLS regressions. You could just use lm() to fit the model.

(2) It's generally easier in the sem package to use specifyEquations() than specifyModel() for model specification.

(3) If you have the original data set, as you do, it's generally preferable to use the data argument to sem() than to pass it the covariance matrix for the observed variables.

I hope that this helps,
 John


------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Sat, 2 Nov 2013 11:02:31 +0100
 Sarah Rogers <rogerssarah65 at gmail.com> wrote:
>  Hello,
> 
> I have just started to work on a path analysis (see attached image for the
> diagram), but I have encountered an error message.
> 
> 
> 
> 
> This is the code I have used:
> 
> cov_matrix<-var(xdata)
> 
> library(sem)
> model.xdata<-specifyModel()
> x1 -> y2, xy12, NA
> x2 -> y1, xy21, NA
> y1 -> y2, yy12, NA
> y2 -> y3, yy23, NA
> y2 -> y4, yy24, NA
> y3 -> y4, yy34, NA
> y2 <-> y2, y2error, NA
> y1 <-> y1, y1error, NA
> y3 <-> y3, y3error, NA
> y4 <-> y4, y4error, NA
> 
> model.xdata.sem <- sem(model.xdata, cov_matrix, nrow(xdata))
> 
> and the error message is:
> Error in csem(model = model.description, start, opt.flag = 1, typsize =
> typsize,  :
>   The matrix is non-invertable.
> 
> I fear to have a problem in the data.
> I would be very grateful if you could help me to solve this problem and
> proceed with my analyses.
> 
> thank you in advance for your help!
> Sarah
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yuhanusa at gmail.com  Sat Nov  2 20:24:40 2013
From: yuhanusa at gmail.com (Y)
Date: Sat, 2 Nov 2013 15:24:40 -0400
Subject: [R] How to obtain nonparametric baseline hazard estimates in the
 gamma frailty model?
Message-ID: <CAHJ49whVw=MiwdsW2f4te-t4i3MpjF63EKUjw=s4s1o6Vb4h=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/d4181515/attachment.pl>

From marius.hofert at math.ethz.ch  Sat Nov  2 22:11:10 2013
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Sat, 2 Nov 2013 22:11:10 +0100
Subject: [R] (gam) formula: Why different results for terms being factor
 vs. numeric?
In-Reply-To: <CACk-te1b7v8WXD1Ws9DZjsxjwyewmM8n5nSZXGyO5nGxYUW6VA@mail.gmail.com>
References: <CAM3-Kja0oDJ+koJFPpN404F+uKRWC8iinfVbVhDZH=30atQ2Dg@mail.gmail.com>
	<CACk-te1b7v8WXD1Ws9DZjsxjwyewmM8n5nSZXGyO5nGxYUW6VA@mail.gmail.com>
Message-ID: <CAM3-KjY8Rh1j1rhC=AsxeXLcpMau7Y9im=JdcX8ME=ZQ+uBKzw@mail.gmail.com>

Dear Bert,

Thanks for helping.

Your questions 'answers' why I get the expected behavior if
'group' is a factor. My question was why I don't get the expected
behavior if 'group' is not a factor.

>From a theoretical (non-programming) point of view, there is no
difference in a factor with two levels and a 0-1 (bool/integer)
variable (in my case the 1-2 variable 'group'). gam() interprets
these inputs differently, thus distinguishes these cases (and I
was wondering why; In my opinion, this is a purely R/mgcv related
question and belongs here).

As it turned out, the problem was merely the following: By using
factors and thus specifying a GAM, the intercept was 'hidden' in
the estimated coefficients. When using integers as group
variables, this is a glm and there one needs the intercept. The
examples below provide the details.

With best wishes,

Marius



require(mgcv)
n <- 10
yrs <- 2000+seq_len(n)
loss <- c(seq_len(n)+runif(n), 5+seq_len(n)+runif(n))


## Version 1: gam() with 'group' as factor #####################################

set.seed(271)
dat <- data.frame(year  = rep(yrs, 2),
                  group = as.factor(rep(1:2, each=n)), # could also be "A", "B"
                  resp  = loss)
fit1 <- glm(resp ~ year + group - 1, data=dat)
plot(yrs, fit1$fitted.values[seq_len(n)], type="l", ylim=range(dat$resp),
     xlab="Year", ylab="Response") # fit group A; mean over all
responses in this group
lines (yrs, fit1$fitted.values[n+seq_len(n)], col="blue") # fit group
B; mean over all responses in this group
points(yrs, dat$resp[seq_len(n)]) # actual response group A
points(yrs, dat$resp[n+seq_len(n)], col="blue") # actual response group B


## Version 2: gam() with 'group' as numeric (=> glm) ###########################

set.seed(271)
dat <- data.frame(year  = rep(yrs, 2),
                  group = rep(1:2, each=n), # could also be 0:1
                  resp  = loss)
fit2 <- glm(resp ~ year + group - 1, data=dat) # (*)
plot(yrs, fit2$fitted.values[seq_len(n)], type="l", ylim=range(dat$resp),
     xlab="Year", ylab="Response") # fit group A; mean over all
responses in this group
lines (yrs, fit2$fitted.values[n+seq_len(n)], col="blue") # fit group
B; mean over all responses in this group
points(yrs, dat$resp[seq_len(n)]) # actual response group A
points(yrs, dat$resp[n+seq_len(n)], col="blue") # actual response group B

## Note: without '-1' (intercept) in (*), an unexpected behavior results
## Explanation:
## S. Wiki GAM (without beta_0):
##    g(E(Y)) = f_1(x_1) + f_2(x_2)
## where f_i(x_i) may be functions with a specified parametric form
(for example a
## polynomial, or a coefficient depending on the levels of a factor variable)
## => for f_i's being coefficients (numbers) beta_i, this is a GLM:
##    g(E(Y)) = beta_1 x_1 + beta_2 x_2 (x_1 = year, x_2 = group)
## Problem: (*) does not specify an intercept and thus the lines are
not picked up correctly
fit2$coefficients


## Version 3: Version 2 with intercept #########################################

set.seed(271)
dat <- data.frame(year  = rep(yrs, 2),
                  group = rep(1:2, each=n), # could also be 0:1
                  resp  = loss)
fit3 <- glm(resp ~ year + group, data=dat) # now with intercept
plot(yrs, fit3$fitted.values[seq_len(n)], type="l", ylim=range(dat$resp),
     xlab="Year", ylab="Response") # fit group A; mean over all
responses in this group
lines (yrs, fit3$fitted.values[n+seq_len(n)], col="blue") # fit group
B; mean over all responses in this group
points(yrs, dat$resp[seq_len(n)]) # actual response group A
points(yrs, dat$resp[n+seq_len(n)], col="blue") # actual response group B
## => correct/as expected
fit3$coefficients

## Note: in Version 1, the intercept is already included in the group
coefficients:
fit1$coefficients



On Tue, Oct 29, 2013 at 9:31 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Think about it. How can one define a smooth term with a factor???
>
> Further discussion is probably offtopic. Post on
> stats.stackexchange.com if it still isn't obvious.
>
> Cheers,
> Bert


From b.rowlingson at lancaster.ac.uk  Sun Nov  3 00:59:46 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 2 Nov 2013 23:59:46 +0000
Subject: [R] ascii-grid export
In-Reply-To: <a9f9d52a74ef493c927d218efa052d60@EX-1-HT0.lancs.local>
References: <a9f9d52a74ef493c927d218efa052d60@EX-1-HT0.lancs.local>
Message-ID: <CANVKczMq0L71LMJbiha3iBDxDptwFNNCDCjxcz57iEL-zp9zfw@mail.gmail.com>

Or do you mean you want to write the gridded output of an
interpolation you did (perhaps using kriging) in gstat as an ESRI
ASCII Grid file for reading into a GIS?

If so, you can probably do it with writeGDAL from the rgdal package,
or writeRaster from the raster package.

I don't really know what a 'semivariogram map' is.


On Sat, Nov 2, 2013 at 8:55 AM, Enzo Cocca <enzo.ccc at gmail.com> wrote:
> hi,
>
> I want to export in ascii-grid file a semivariogram map that I have did
> with gstat library.
>
> How can I make it?
>
> Somebody can help me?
>  thanks!
>
> enzo
> --
> Enzo Cocca (PhD Candidate)
> Research Fellow
> Universit? di Napoli "L'Orientale"
> mail: enzo.ccc at gmail.com
> cell: +393495087014
>
>         [[alternative HTML version deleted]]
>


From jmhannon.ucdavis at gmail.com  Sun Nov  3 01:58:43 2013
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Sat, 2 Nov 2013 17:58:43 -0700
Subject: [R] Installing RCurl: 'configure' exists but is not executable
In-Reply-To: <13319325.YRotjPDbHh@rainer>
References: <1541278.oqh9e0TbB1@rainer>
	<CACdH2Za_GSR8j3nX1pNFnckp1EmRfuCDo8V3_BY3MqeHx09nBg@mail.gmail.com>
	<13319325.YRotjPDbHh@rainer>
Message-ID: <CACdH2ZYGCoP91eWO5GZ9g0_ARTQoR=1+Fu1-pNkK=4iJ17dJGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/d387f9f7/attachment.pl>

From jim at bitwrit.com.au  Sun Nov  3 04:30:17 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 03 Nov 2013 14:30:17 +1100
Subject: [R] Package(s) for making waffle plot-like figures?
In-Reply-To: <CAGD4NN+jNrmYHywkgvVRMFAd+bauJ3em6pt0+zCdHFwOVAK2tQ@mail.gmail.com>
References: <CAGD4NN+jNrmYHywkgvVRMFAd+bauJ3em6pt0+zCdHFwOVAK2tQ@mail.gmail.com>
Message-ID: <5275C349.8@bitwrit.com.au>

On 11/02/2013 10:35 AM, Zhao Jin wrote:
> Dear all,
>
> I am trying to make a series of waffle plot-like figures for my data to
> visualize the ratios of amino acid residues at each position. For each one
> of 37 positions, there may be one to four different amino acid residues. So
> the data consist of the positions, what residues are there, and the ratios
> of residues. The ratios of residues at a position add up to 100, or close
> to 100 (more on this soon)*. I am hoping to make a *square* waffle
> plot-like figure for each position, and fill the 10 X 10 grids with colors
> representing each amino acid residue and areas for grids of a certain color
> corresponding to the ratio of that residue. Then I could line up all the
> plots in one row from position 1 to position 37.
> *: if the sum of the ratios is less than 100 at a position, that's because
> of an unknown residue which I did not include in the table.
>
> I am attaching the dput output for my data here:
> structure(list(position = c(1L, 2L, 3L, 4L, 4L, 5L, 6L, 7L, 7L,
> 8L, 9L, 9L, 9L, 10L, 10L, 11L, 11L, 12L, 12L, 13L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 22L, 23L, 24L, 25L, 26L,
> 26L, 27L, 28L, 29L, 29L, 30L, 31L, 32L, 33L, 34L, 34L, 35L, 35L,
> 36L, 36L, 36L, 37L, 37L), residue = structure(c(9L, 4L, 18L,
> 7L, 9L, 7L, 12L, 3L, 4L, 1L, 7L, 9L, 12L, 1L, 4L, 4L, 13L, 5L,
> 14L, 2L, 18L, 3L, 16L, 9L, 17L, 15L, 7L, 5L, 5L, 7L, 17L, 13L,
> 15L, 11L, 6L, 13L, 16L, 14L, 10L, 13L, 17L, 1L, 1L, 17L, 1L,
> 12L, 1L, 5L, 3L, 6L, 8L, 7L, 9L), .Label = c("A", "C", "D", "E",
> "G", "H", "I", "K", "L", "M", "N", "P", "Q", "R", "S", "T", "V",
> "Y"), class = "factor"), ratio = c(99L, 100L, 100L, 1L, 99L,
> 100L, 100L, 1L, 98L, 100L, 10L, 87L, 3L, 79L, 9L, 12L, 84L, 99L,
> 1L, 83L, 13L, 100L, 100L, 100L, 100L, 99L, 100L, 100L, 100L,
> 98L, 2L, 100L, 100L, 100L, 2L, 98L, 100L, 100L, 1L, 99L, 100L,
> 100L, 98L, 100L, 95L, 5L, 98L, 2L, 3L, 95L, 1L, 1L, 98L)), .Names =
> c("position",
> "residue", "ratio"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "10", "11", "12", "13", "14", "15",
> "17", "18", "19", "20", "23", "25", "27", "28", "29", "30", "31",
> "32", "33", "34", "36", "37", "38", "39", "40", "42", "43", "44",
> "45", "46", "47", "48", "50", "51", "52", "53", "54", "56", "57",
> "58", "59", "60", "61", "62", "63", "64", "65"))
>
> Inspired by a statexchange post, I am using these scripts to make the plots
> :
> library(ggplot2)
> col4=c('#E66101','#FDB863','#B2ABD2','#5E3C99')
> dflist=list()
> for (i in 1:37){
> residue_num=length(which(df$position==i))
> dflist[[i]]=df[df$position==i,2:3]
> waffle=expand.grid(y=1:residue_num,x=seq_len(ceiling(sum(dflist[[i]]$ratio)/residue_num)))
> residuevec=rep(dflist[[i]]$residue,dflist[[i]]$ratio)
> waffle$residue=c(as.vector(residuevec),rep(NA,nrow(waffle)-length(residuevec)))
> png(paste('plot',i,'.png',sep=''))
> print(ggplot(waffle, aes(x = x, y = y, fill = residue)) + geom_tile(color =
> "white") + scale_fill_manual("residue",values = col4) + coord_equal() +
> theme(panel.grid.minor=element_blank(),panel.grid.major=element_blank())
> + theme(axis.ticks=element_blank()) +
> theme(axis.text.x=element_blank(),axis.text.y=element_blank()) +
> theme(axis.title.x=element_blank(),axis.title.y=element_blank())
> )
> dev.off()}
>
> With my scripts, I could make a waffle plot, but not a *square* 10 X 10
> waffle plot. Also, the grid size differs for positions with different
> numbers of residues. I am suspecting that I didn't use coord_equal()
> correctly.
>
> So I wonder how I can make the plots like I described above in ggplot2 or
> with some other packages. Also, is there a way to assign a color to
> different residues, say, purple for alanine, blue for glycine, etc, and
> incorporate that information in the for loop?
>
Hi Zhao,
By beginning with a 10x10 matrix of NA values and then replacing some of 
them with a color, I think you can do what you want. First you need a 
function to fill one corner of your matrix with values, leaving the rest 
uncolored (i.e. NA):

fill.corner<-function(x,nrow,ncol) {
  xlen<-length(x)
  if(nrow*ncol > xlen) {
   newmat<-matrix(NA,nrow=nrow,ncol=ncol)
   xside<-1
   while(xside*xside < xlen) xside<-xside+1
   row=1
   col=1
   for(xindex in 1:xlen) {
    newmat[row,col]<-x[xindex]
    if(row == xside) {
     col<-col+1
     row<-1
    }
    else row<-row+1
   }
   return(newmat)
  }
  cat("Too many values in x for",xrow,"by",xcol,"\n")
}

Then you have to massage your data frame into 37 smaller data frames, 
create matrices with the values and colors to display on your 37 waffle 
plots:

library(plotrix)
# get an "alphabet" of colors
alphacol<-rainbow(18)
# the actual values in the plotted matrix don't matter
fakemat<-matrix(1:100,nrow=10)
# pick off the positions one by one
for(pos in 1:37) {
  posdf<-zjdat[zjdat$position == pos,]
  for(res in 1:dim(posdf)[1]) {
   if(res == 1)
    rescol<-rep(alphacol[as.numeric(posdf$residue[res])],
    posdf$ratio[res])
   else
    rescol<-c(rescol,rep(alphacol[as.numeric(posdf$residue[res])],
    posdf$ratio[res]))
  }
  if(!is.null(resmat<-fill.corner(rescol,10,10)))
   color2D.matplot(fakemat,border="lightgray",cellcolors=resmat,
    yrev=FALSE,main=c(pos,length(resmat)))
}

That might get you started. In fact, I might even write a waffle plot 
function for plotrix.

Jim


From jim at bitwrit.com.au  Sun Nov  3 04:47:23 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 03 Nov 2013 14:47:23 +1100
Subject: [R] plot time series data in wide format
In-Reply-To: <CAEVDvzUM4SVcVxk8DqWjhzf6_JF6gWfGKh1oaxmNpG91eGECWA@mail.gmail.com>
References: <CAEVDvzUM4SVcVxk8DqWjhzf6_JF6gWfGKh1oaxmNpG91eGECWA@mail.gmail.com>
Message-ID: <5275C74B.2030609@bitwrit.com.au>

On 11/02/2013 11:08 AM, Gary Dong wrote:
> Dear R users,
>
> I wonder if there is a way that I can plot a time series data which is in a
> wide format like this:
>
> CITY_NAME       2000Q1    2000Q2      2000Q3        2000Q4     2001Q1
> 2001Q2      2001Q3     2001Q4     2002Q1      2002Q2
> CITY1                100.5210   101.9667  103.24933   104.0506   104.4317
> 105.3921   106.7643   107.5202   107.2561   107.8184
> CITY2                100.0412   100.6146  103.20293   104.0867   104.6612
> 106.6126   109.3514   110.1943   110.9480   113.0071
> CITY3                 99.5895    99.2298   99.26947    99.4101   100.5776
> 101.3719   101.5957   102.2411   103.4390   105.1745
> CITY4                 99.6491   101.5386  104.90953   106.1065   108.1785
> 110.6845   113.3746   114.1254   116.2121   119.1033
> CITY5                100.9828   103.6847  105.04793   106.5925   108.7437
> 110.5549   111.9343   112.6704   113.6201   115.3020
>
> Ideally, each city of the five city is represented by a line in the plot.
>
Hi Gary,
I'm not sure that this is exactly what you want, but:

library(plotrix)
# use window() if you are using Windows
x11(width=10,height=5)
bumpchart(garydf[,2:11],rank=FALSE,labels=garydf[,1])

Jim


From lizhen.peng at stonybrook.edu  Sun Nov  3 03:54:53 2013
From: lizhen.peng at stonybrook.edu (Lizkitty)
Date: Sat, 2 Nov 2013 19:54:53 -0700 (PDT)
Subject: [R] Failed to install kernlab package
Message-ID: <1383447292980-4679626.post@n4.nabble.com>

Hi everyone, 

I am trying to install kernlab package, but failed many times by now on
CentOS 6 operating system.

Here is the error message:

trying URL 'http://ftp.ussg.iu.edu/CRAN/src/contrib/kernlab_0.9-18.tar.gz'
Content type 'application/x-gzip' length 1069148 bytes (1.0 Mb)
opened URL
==================================================
downloaded 1.0 Mb

* installing *source* package kernlab ...
** package kernlab successfully unpacked and MD5 sums checked
** libs
g++ 
.
.
.
make: *** [brweight.o] Error 1
ERROR: compilation failed for package kernlab
* removing ~/n/home09/wang/R/x86_64-unknown-linux-gnu-library/3.0/kernlab

The downloaded source packages are in
        ~/scratch/tmp/RtmphA5FF9/downloaded_packages
Warning message:
In install.packages("kernlab") :
  installation of package kernlab had non-zero exit status


I found out online that many others also failed installing kernlab, but no
explicit solutions for this problem. 
What I have tried so far are:
1) change cran mirrors
2) using command line directly: R CMD INSTALL kernlab_0.9-18.tar.gz, after
downloading the package
3) reset working directory
Unfortunately, none of these solved my problem...

Any suggestions are highly appreciated!





--
View this message in context: http://r.789695.n4.nabble.com/Failed-to-install-kernlab-package-tp4679626.html
Sent from the R help mailing list archive at Nabble.com.


From iakub.henschen at gmail.com  Sun Nov  3 02:46:46 2013
From: iakub.henschen at gmail.com (Iakub Henschen)
Date: Sat, 2 Nov 2013 21:46:46 -0400
Subject: [R] Control over character height, width, skew etc.?
Message-ID: <CAOmdYoo-Rw3f+zWpsREcv-eF=OVDB0BLxczC3BDaEeeqhHNO+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131102/c482b32b/attachment.pl>

From zj29 at cornell.edu  Sun Nov  3 08:01:22 2013
From: zj29 at cornell.edu (Zhao Jin)
Date: Sun, 3 Nov 2013 00:01:22 -0700
Subject: [R] Package(s) for making waffle plot-like figures?
In-Reply-To: <5275C349.8@bitwrit.com.au>
References: <CAGD4NN+jNrmYHywkgvVRMFAd+bauJ3em6pt0+zCdHFwOVAK2tQ@mail.gmail.com>
	<5275C349.8@bitwrit.com.au>
Message-ID: <CAGD4NN+tT0UOZU0sW84ESVZ3U1uMp4p6dnnxm9zmwieQWw1u0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131103/8e1d4759/attachment.pl>

From petar.milin at uni-tuebingen.de  Sun Nov  3 10:42:06 2013
From: petar.milin at uni-tuebingen.de (Petar Milin)
Date: Sun, 3 Nov 2013 10:42:06 +0100
Subject: [R] Hierarchical Cluster Analysis with large dataset
Message-ID: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131103/5ffca321/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Nov  3 10:47:32 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 03 Nov 2013 09:47:32 +0000
Subject: [R] Failed to install kernlab package
In-Reply-To: <1383447292980-4679626.post@n4.nabble.com>
References: <1383447292980-4679626.post@n4.nabble.com>
Message-ID: <52761BB4.9070001@stats.ox.ac.uk>

On 03/11/2013 02:54, Lizkitty wrote:
> Hi everyone,
>
> I am trying to install kernlab package, but failed many times by now on
> CentOS 6 operating system.
>
> Here is the error message:
>
> trying URL 'http://ftp.ussg.iu.edu/CRAN/src/contrib/kernlab_0.9-18.tar.gz'
> Content type 'application/x-gzip' length 1069148 bytes (1.0 Mb)
> opened URL
> ==================================================
> downloaded 1.0 Mb
>
> * installing *source* package kernlab ...
> ** package kernlab successfully unpacked and MD5 sums checked
> ** libs
> g++
> .
> .
> .

And the actual error message was here.

Please read the posting guide.  As this is a C error, you should be 
posting to  R-devel, and we cannot help you without the actual error 
message.

> make: *** [brweight.o] Error 1
> ERROR: compilation failed for package kernlab
> * removing ~/n/home09/wang/R/x86_64-unknown-linux-gnu-library/3.0/kernlab
>
> The downloaded source packages are in
>          ~/scratch/tmp/RtmphA5FF9/downloaded_packages
> Warning message:
> In install.packages("kernlab") :
>    installation of package kernlab had non-zero exit status
>
>
> I found out online that many others also failed installing kernlab, but no
> explicit solutions for this problem.

Really?  Who are these 'many others'?  The CRAN check page 
http://cran.r-project.org/web/checks/check_results_kernlab.html shows 
success on several platforms.


> What I have tried so far are:
> 1) change cran mirrors
> 2) using command line directly: R CMD INSTALL kernlab_0.9-18.tar.gz, after
> downloading the package
> 3) reset working directory
> Unfortunately, none of these solved my problem...
>
> Any suggestions are highly appreciated!
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Failed-to-install-kernlab-package-tp4679626.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ishaqbaba at yahoo.com  Sun Nov  3 08:35:20 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Sun, 3 Nov 2013 00:35:20 -0700 (PDT)
Subject: [R] computation of hessian matrix
In-Reply-To: <1383463061.53467.YahooMailNeo@web142505.mail.bf1.yahoo.com>
References: <1383300398.80446.YahooMailNeo@web142506.mail.bf1.yahoo.com>
	<CADv2QyHFj8wOVYHtOem-ZU+YMVc-8-sqcnhJKVi6WNukO9teBQ@mail.gmail.com>
	<1383463061.53467.YahooMailNeo@web142505.mail.bf1.yahoo.com>
Message-ID: <1383464120.6395.YahooMailNeo@web142506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131103/d6a22e70/attachment.pl>

From k.moon at student.unimelb.edu.au  Sun Nov  3 09:32:02 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Sun, 3 Nov 2013 01:32:02 -0700 (PDT)
Subject: [R] Comparison of two weibull distributions
Message-ID: <1383467521821-4679632.post@n4.nabble.com>

Hello,

How can I do a test of two weibull distributions?
I have two weibull distribution sets from two wind datasets in order to
check whether they are same.
I thought 2 sample t-test would be applicable but I couldn't find any ways
to do that on the Internet.
Does anyone know what type of test is applicable to my purpose? and what R
function can you recommend?
Plus, if it turned out that there is a difference between the two datasets,
can I just fit a linear line between the datasets? 

Kind Regards,

Kangmin.



--
View this message in context: http://r.789695.n4.nabble.com/Comparison-of-two-weibull-distributions-tp4679632.html
Sent from the R help mailing list archive at Nabble.com.


From maitra.mbox.ignored at inbox.com  Sun Nov  3 15:01:51 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sun, 3 Nov 2013 08:01:51 -0600
Subject: [R] Hierarchical Cluster Analysis with large dataset
In-Reply-To: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
References: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
Message-ID: <20131103080151.9a9c0121d2dba9c21aa14a0d@inbox.com>

On Sun, 3 Nov 2013 10:42:06 +0100 Petar Milin
<petar.milin at uni-tuebingen.de> wrote:

> Hello!
> Can anyone give me advice on running Hierarchical Cluster Analysis on large
> datasets? For example, 80000x10000. Calculating distances on such a
> dataframe seems impossible even on very powerful computer.
> 
> Also, any other advice that would lead to reduction of dimensionality,
> i.e., cluster/group variables would be more than welcomed.

You have two different issues here: size of dataset (number of
observations which prevents storage in memory of the distance matrix)
and number of variables (which does not, but probably hinders reading
in the dataset.

You need to provide more information here: why do you need/want to do
hierarchical clustering, if so, do you only need to use R. What
hardware you have at your disposal, etc.

Depending on your answers to the above, this may well be a research
problem in its own right.

HTH!

Best wishes,
Ranjan

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From gunter.berton at gene.com  Sun Nov  3 16:34:25 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 3 Nov 2013 07:34:25 -0800
Subject: [R] Hierarchical Cluster Analysis with large dataset
In-Reply-To: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
References: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
Message-ID: <CACk-te3YVi4qLT=PFOmr33YY1qSN0oPRWD92O6QzvEqguDJ49w@mail.gmail.com>

(Offlist, since this is just a personal comment).

I cannot help you -- but it sounds like the sort of thing that you
should look for on the BioconductoR list.

But I wonder how you could possibly interpret the results even if you
could get them. I would think they would be more noise than signal,
and making sense of such a mess would be hopeless. Maybe you need to
rethink your approach.

No need to respond to me, of course.

Cheers,
Bert

On Sun, Nov 3, 2013 at 1:42 AM, Petar Milin
<petar.milin at uni-tuebingen.de> wrote:
> Hello!
> Can anyone give me advice on running Hierarchical Cluster Analysis on large
> datasets? For example, 80000x10000. Calculating distances on such a
> dataframe seems impossible even on very powerful computer.
>
> Also, any other advice that would lead to reduction of dimensionality,
> i.e., cluster/group variables would be more than welcomed.
>
> Many thanks,
> PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From bbolker at gmail.com  Sun Nov  3 14:56:52 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 3 Nov 2013 13:56:52 +0000
Subject: [R] Comparison of two weibull distributions
References: <1383467521821-4679632.post@n4.nabble.com>
Message-ID: <loom.20131103T145352-194@post.gmane.org>

kmmoon100 <k.moon <at> student.unimelb.edu.au> writes:

> 
> Hello,
> 
> How can I do a test of two weibull distributions?
> I have two weibull distribution sets from two wind datasets in order to
> check whether they are same.
> I thought 2 sample t-test would be applicable but I couldn't find any ways
> to do that on the Internet.
> Does anyone know what type of test is applicable to my purpose? and what R
> function can you recommend?
> Plus, if it turned out that there is a difference between the two datasets,
> can I just fit a linear line between the datasets? 
> 
> Kind Regards,
> 
> Kangmin.

  (1) Fit a single model to the combined (pooled data) (e.g. with
MASS::fitdistr()); (2) fit separate models to the individual data
sets; (3) compare the log-likelihood of the pooled model to the
sum of the log-likelihoods of the separate models.  According to
the likelihood ratio test, the p-value of the differences is:

  pchisq(2*(logLik_sum-logLik_pooled),df=2,lower.tail=FALSE)

(2 df because the separate models have a total of 4 parameters,
2 greater than the pooled model)


From giztar2008 at yahoo.com  Sun Nov  3 13:36:25 2013
From: giztar2008 at yahoo.com (GIZACHEW TAREKEGN GETAHUN)
Date: Sun, 3 Nov 2013 04:36:25 -0800 (PST)
Subject: [R] (no subject)
Message-ID: <1383482185.59894.YahooMailNeo@web140601.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131103/319ff7cc/attachment.pl>

From atclark at umn.edu  Sun Nov  3 20:40:54 2013
From: atclark at umn.edu (Adam Clark)
Date: Sun, 3 Nov 2013 13:40:54 -0600
Subject: [R] Rtools for writing packages
Message-ID: <CAL7OOdz_VKmzODN3e+JzHTPcOQOi1UMMqueYPXw1zZFqRyvJKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131103/11953378/attachment.pl>

From murdoch.duncan at gmail.com  Sun Nov  3 21:09:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 03 Nov 2013 15:09:27 -0500
Subject: [R] Rtools for writing packages
In-Reply-To: <CAL7OOdz_VKmzODN3e+JzHTPcOQOi1UMMqueYPXw1zZFqRyvJKw@mail.gmail.com>
References: <CAL7OOdz_VKmzODN3e+JzHTPcOQOi1UMMqueYPXw1zZFqRyvJKw@mail.gmail.com>
Message-ID: <5276AD77.7050000@gmail.com>

On 13-11-03 2:40 PM, Adam Clark wrote:
> I apologize for what is likely a stupid question - I HAVE looked through
> "Writing R Extensions" and HAVE gone through existing help requests, but
> have not yet found an answer. I'm sorry if I've missed something obvious.
>
> I am planning on building a package in the near future. I have a number of
> C programs that I have written to interface with R (compiled using the R
> SHLIB, run using the .C convention).
>
> I now run a Linux system, but seem to remember that for Mac and Windows
> implementations of R, Rtools is required separately in order to run
> compiled C code that interfaces directly with R.
>
> I am wondering whether any packages that I write using such C code will
> require end users of PC and Mac to have Rtools installed, or whether there
> is a way to build the package such that this is not the case.
>
> I ask this because I would like the package to be relatively painlessly
> portable, and know many users who have had trouble installing Rtools on
> their Mac or PC.

Windows users require Rtools to develop packages containing C code, but 
not to run them, as long as someone is producing a "binary" package for 
them.  If you send your package to CRAN that will happen automatically. 
  If you don't, you'll need to find some other way to produce the 
binaries (e.g. WinBuilder).

Mac users are similar, but don't use Rtools, they use a different 
collection of tools.

So you should be fine:  if you write portable C and send your package to 
CRAN, you don't need to worry.

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Sun Nov  3 21:28:39 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 03 Nov 2013 12:28:39 -0800
Subject: [R] (no subject)
In-Reply-To: <1383482185.59894.YahooMailNeo@web140601.mail.bf1.yahoo.com>
References: <1383482185.59894.YahooMailNeo@web140601.mail.bf1.yahoo.com>
Message-ID: <29804b3c-2185-4eaf-912a-f2b1fb53f079@email.android.com>

Kind of difficult to help you if you don't help us do so. Please read the Posting Guide for this mailing list and follow the recommendations there.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

GIZACHEW TAREKEGN GETAHUN <giztar2008 at yahoo.com> wrote:
>Hi,
>I failed to install 'glht' and 'lsmip packages'. I am using R version
>3.0.2
>
>BR,
>Gizachew
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lizhen.peng at stonybrook.edu  Sun Nov  3 22:12:04 2013
From: lizhen.peng at stonybrook.edu (Lizkitty)
Date: Sun, 3 Nov 2013 13:12:04 -0800 (PST)
Subject: [R] Failed to install kernlab package
In-Reply-To: <52761BB4.9070001@stats.ox.ac.uk>
References: <1383447292980-4679626.post@n4.nabble.com>
	<52761BB4.9070001@stats.ox.ac.uk>
Message-ID: <1383513124564-4679651.post@n4.nabble.com>

Thanks for the suggestion, I will re-post it on R-devel.

By others, what I mean is that when I searched for solutions, I found other
people also posted questions with their problems with kernlab installation
on linux platform.  I have no problem with kernlab installation on windows
platform though.

Anyway, I will post it again on R-devel, with more details. Thanks all the
same!



--
View this message in context: http://r.789695.n4.nabble.com/Failed-to-install-kernlab-package-tp4679626p4679651.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Sun Nov  3 23:01:30 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 3 Nov 2013 17:01:30 -0500
Subject: [R] Hierarchical Cluster Analysis with large dataset
In-Reply-To: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
References: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
Message-ID: <CAM_vju=bPOR5HAzPocdLZq7WuhJvgKDAcmCiKVqs0eMRgB=CwA@mail.gmail.com>

Hi,

I think your dataset is too large to be interpretable, but in general
you should check out the cluster package, specifically clara(), which
is intended for use with large data.

Sarah

On Sun, Nov 3, 2013 at 4:42 AM, Petar Milin
<petar.milin at uni-tuebingen.de> wrote:
> Hello!
> Can anyone give me advice on running Hierarchical Cluster Analysis on large
> datasets? For example, 80000x10000. Calculating distances on such a
> dataframe seems impossible even on very powerful computer.
>
> Also, any other advice that would lead to reduction of dimensionality,
> i.e., cluster/group variables would be more than welcomed.
>
> Many thanks,
> PM
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From tlumley at uw.edu  Sun Nov  3 23:47:51 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Mon, 4 Nov 2013 11:47:51 +1300
Subject: [R] Hierarchical Cluster Analysis with large dataset
In-Reply-To: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
References: <CAP0jpe37NMk2RFT-k5tFS1h02WDKZ_u82DMGsiWRcPCa6AX87A@mail.gmail.com>
Message-ID: <CAJ55+d+k8K6X7fwyP4Zv3Na37abjqgazfD9OgF4_duJwRnf3NQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/d2c93701/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Mon Nov  4 07:49:22 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 4 Nov 2013 12:19:22 +0530
Subject: [R] Replace element with pattern
In-Reply-To: <1383311389.45470.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>
	<1383311389.45470.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <OF88E0FCDD.972E91CF-ON65257C19.002524B9-65257C19.00257937@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/ff777b51/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Mon Nov  4 08:22:23 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 4 Nov 2013 12:52:23 +0530
Subject: [R] Replace element with pattern
In-Reply-To: <OF88E0FCDD.972E91CF-ON65257C19.002524B9-65257C19.00257937@polarisft.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>	<1383311389.45470.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<OF88E0FCDD.972E91CF-ON65257C19.002524B9-65257C19.00257937@polarisft.com>
Message-ID: <OF08EAA960.A0D2FFAF-ON65257C19.00286612-65257C19.00287EFF@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/5979e428/attachment.pl>

From enzo.ccc at gmail.com  Mon Nov  4 08:27:54 2013
From: enzo.ccc at gmail.com (Enzo Cocca)
Date: Mon, 4 Nov 2013 08:27:54 +0100
Subject: [R] ascii-grid export
In-Reply-To: <CANVKczMq0L71LMJbiha3iBDxDptwFNNCDCjxcz57iEL-zp9zfw@mail.gmail.com>
References: <a9f9d52a74ef493c927d218efa052d60@EX-1-HT0.lancs.local>
	<CANVKczMq0L71LMJbiha3iBDxDptwFNNCDCjxcz57iEL-zp9zfw@mail.gmail.com>
Message-ID: <CAC_+zuqyZCJkGp4Xc2C92o+G1ucdTqOz1qcLqBNHvcUNTUnjTw@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/c779b2a1/attachment.pl>

From paul at stat.auckland.ac.nz  Mon Nov  4 03:09:48 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 04 Nov 2013 15:09:48 +1300
Subject: [R] Control over character height, width, skew etc.?
In-Reply-To: <CAOmdYoo-Rw3f+zWpsREcv-eF=OVDB0BLxczC3BDaEeeqhHNO+g@mail.gmail.com>
References: <CAOmdYoo-Rw3f+zWpsREcv-eF=OVDB0BLxczC3BDaEeeqhHNO+g@mail.gmail.com>
Message-ID: <527701EC.3030605@stat.auckland.ac.nz>

Hi

R's text-drawing functions, such as text() or grid.text(), do NOT allow 
you to skew or stretch individual characters (like PostScript does). 
Your strategy of using PostScript to produce a result and then import 
the result as a "shape" for R to draw may work (if you can script it).

Paul

On 11/03/13 14:46, Iakub Henschen wrote:
> I would like to add characters to R plots but need separate control over
> height, width, skew, rotation etc. These parameters result from a
> statistical computation within R. Also I need to be able to control stroke
> and fill parameters independently. Finally, I need more than just ASCII
> characters, but symbols and possibly Chinese/Japanese. What I've found so
> far points to a solution where I send the character and scale information
> to an external script that produces what I need in Postscript, then import
> via the grImport package. I assume there is a more direct way via editing R
> sources, such as inserting a transformation into text(), but that's
> probably not a good idea in the long run. Or is there a better strategy?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From pollaroid at gmail.com  Mon Nov  4 08:55:39 2013
From: pollaroid at gmail.com (Kumar Raj)
Date: Mon, 4 Nov 2013 08:55:39 +0100
Subject: [R] Subject: Regress multiple independent variables on multiple
	dependent variables
Message-ID: <CAAC1QdCS5StbTTEOtfF=JBZ2m0=27H2josNcT2_S3BrDW0EcGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/543f6aaa/attachment.pl>

From k.moon at student.unimelb.edu.au  Mon Nov  4 08:50:09 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Sun, 3 Nov 2013 23:50:09 -0800 (PST)
Subject: [R] Formatting time stamps for weibull distribution
Message-ID: <1383551409688-4679666.post@n4.nabble.com>

Hello everyone,

I have been using bReeze package for weibull distribution analysis.
In this package, there is a function called 'formatTS' for converting time
stamps from string to POSIXlt.
(http://rgm3.lab.nig.ac.jp/RGM/R_rdfile?f=bReeze/man/formatTS.Rd&d=R_CC)
This is a part of process to plot and calculate shape and scale of the
distribution. 
However, this function keeps showing an error message.

ts1 <- formatTS(time.stamp = winddata_ballarat[,1])
1  1383549939 
2  1383549939 
3  1383549939 
4  1383549953 
Error in formatTS(time.stamp = winddata_ballarat[, 1]) : No pattern found

The format of the time series (200000 rows) I have is dd.mm.yyyy hh:mm for
12 years.. such as..

Time	                   Wind speed    Wind direction
25.07.2000 0:00:00	15	20
25.07.2000 0:30:00	11	20
25.07.2000 1:00:00	18	10
25.07.2000 1:30:00	17	10
25.07.2000 2:00:00	22	360
25.07.2000 2:30:00	22	360
25.07.2000 3:00:00	26	360
25.07.2000 3:30:00	28	360
.                                         .             .
.                                         .             .
.                                         .             .
.                                         .             .
.                                         .             .


I have no idea why the function cannot find a pattern..

Surprisingly, when the same data and the same function was used in my
colleague's computer, it worked. So I tried processing in other computers
but failed. 

I tried using strftime function too but result is not reliable, which
indicates there is a mismatch between the time stamp I created and wind
speed.

Could anyone know why it keeps happening and how to solve this problem?
All R codes are described below:

winddata_ballarat <- read.csv("ballarat1.csv",header=TRUE,sep=",")
set2 <- createSet(height=10, v.avg=winddata_ballarat$Wind.speed,
dir.avg=winddata_ballarat$Wind.direction)
ts1 <- formatTS(time.stamp = winddata_ballarat[,1])
kangmin.ballarat <- createMast(time.stamp=ts, set2)
kangmin.ballarat.wb <- weibull(mast=kangmin.ballarat, v.set=1, print=FALSE)
plotWeibull(wb=kangmin.ballarat.wb, show.ak =TRUE)
weibull(mast=kangmin.ballarat, v.set=1)

Thank you.





--
View this message in context: http://r.789695.n4.nabble.com/Formatting-time-stamps-for-weibull-distribution-tp4679666.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Mon Nov  4 09:16:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 Nov 2013 00:16:44 -0800
Subject: [R] Formatting time stamps for weibull distribution
In-Reply-To: <1383551409688-4679666.post@n4.nabble.com>
References: <1383551409688-4679666.post@n4.nabble.com>
Message-ID: <006B3E4A-7E8B-4C3E-AC56-192647D52C00@comcast.net>


On Nov 3, 2013, at 11:50 PM, kmmoon100 wrote:

> Hello everyone,
> 
> I have been using bReeze package for weibull distribution analysis.
> In this package, there is a function called 'formatTS' for converting time
> stamps from string to POSIXlt.
> (http://rgm3.lab.nig.ac.jp/RGM/R_rdfile?f=bReeze/man/formatTS.Rd&d=R_CC)
> This is a part of process to plot and calculate shape and scale of the
> distribution. 
> However, this function keeps showing an error message.
> 
> ts1 <- formatTS(time.stamp = winddata_ballarat[,1])
> 1  1383549939 
> 2  1383549939 
> 3  1383549939 
> 4  1383549953 
> Error in formatTS(time.stamp = winddata_ballarat[, 1]) : No pattern found

Shouldn't you after reading that manual page be adding format="%d.%m.%Y %H:%M:%S" ?

.
> 
> The format of the time series (200000 rows) I have is dd.mm.yyyy hh:mm for
> 12 years.. such as..
> 
> Time	                   Wind speed    Wind direction
> 25.07.2000 0:00:00	15	20
> 25.07.2000 0:30:00	11	20
> 25.07.2000 1:00:00	18	10
> 25.07.2000 1:30:00	17	10
> 25.07.2000 2:00:00	22	360
> 25.07.2000 2:30:00	22	360
> 25.07.2000 3:00:00	26	360
> 25.07.2000 3:30:00	28	360
> .                                         .             .
> . 
> 
> 
> I have no idea why the function cannot find a pattern..

Because you didn't offer one?

> 
> Surprisingly, when the same data and the same function was used in my
> colleague's computer, it worked. So I tried processing in other computers
> but failed. 
> 
> I tried using strftime

`strftime` is for output. `strptime` is for input.

> function too but result is not reliable, which
> indicates there is a mismatch between the time stamp I created and wind
> speed.

It only indicates you didn't read the section on the pattern/format arguments.

-- 
David
> 
> Could anyone know why it keeps happening and how to solve this problem?
> All R codes are described below:
> 
> winddata_ballarat <- read.csv("ballarat1.csv",header=TRUE,sep=",")
> set2 <- createSet(height=10, v.avg=winddata_ballarat$Wind.speed,
> dir.avg=winddata_ballarat$Wind.direction)

> ts1 <- formatTS(time.stamp = winddata_ballarat[,1])
> kangmin.ballarat <- createMast(time.stamp=ts, set2)

ts != ts1

> kangmin.ballarat.wb <- weibull(mast=kangmin.ballarat, v.set=1, print=FALSE)
> plotWeibull(wb=kangmin.ballarat.wb, show.ak =TRUE)
> weibull(mast=kangmin.ballarat, v.set=1)
> 
> Thank you.
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Formatting-time-stamps-for-weibull-distribution-tp4679666.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From MSchmidberger at freenet.de  Mon Nov  4 09:22:26 2013
From: MSchmidberger at freenet.de (Markus Schmidberger)
Date: Mon, 4 Nov 2013 09:22:26 +0100
Subject: [R] [R-pkgs] rmongodb 1.1.3 back to CRAN
Message-ID: <897442EE-113C-45B5-A7A7-1873F5D62CAB@freenet.de>

Dear all,

I am pleased to announce that the rmongodb package connecting R with the NoSQL database mongodb is back to CRAN: http://cran.r-project.org/web/packages/rmongodb/index.html
This release is a bug fix release to get the package back to CRAN.

I have overtaken the package maintenance from Gerald Lindsly and looking forward to extend the great work in this package. Planed new features are:
* add high-level functionality to improve usability
* enable JSON queries
* switch to roxygen (already done and on github)
* implement RUnit tests to make the package more stable (work in progress)
* update to the newest C driver (including libBSON and libmongoc)
* improve documentation, write vignettes
(please check github for more details https://github.com/mongosoup/rmongodb/issues)

If you have any ideas or bugs please feel free to contact me.
Furthermore, please feel free to join me in developing the package: https://github.com/mongosoup/rmongodb

Best regards
Markus
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From alaios at yahoo.com  Mon Nov  4 10:09:12 2013
From: alaios at yahoo.com (Alaios)
Date: Mon, 4 Nov 2013 01:09:12 -0800 (PST)
Subject: [R] add a color band
In-Reply-To: <1382947071.31098.YahooMailNeo@web125301.mail.ne1.yahoo.com>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526A3E69.2060103@bitwrit.com.au>	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>	<526AE5FA.3000604@bitwrit.com.au>	<1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526CF7A4.4050709@bitwrit.com.au>
	<1382947071.31098.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <1383556152.90906.YahooMailNeo@web125303.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/15050809/attachment.pl>

From chiaowlet at yahoo.com.tw  Mon Nov  4 09:55:55 2013
From: chiaowlet at yahoo.com.tw (Chia-Chieh Lin)
Date: Mon, 4 Nov 2013 16:55:55 +0800 (CST)
Subject: [R] A warning message generated from 'read.csv'
Message-ID: <1383555355.12212.YahooMailNeo@web75203.mail.tw1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/483a416f/attachment.pl>

From csvirtual at gmx.de  Mon Nov  4 09:34:54 2013
From: csvirtual at gmx.de (csvirtual at gmx.de)
Date: Mon, 4 Nov 2013 09:34:54 +0100
Subject: [R] Newbie Question: Repeatable Tasks
Message-ID: <002201ced938$bdc4f280$394ed780$@gmx.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/4013c460/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Mon Nov  4 10:54:31 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 4 Nov 2013 15:24:31 +0530
Subject: [R] All curves with same y-axis scale
Message-ID: <OFAFDDA7B3.0A5D88DF-ON65257C19.0035CB83-65257C19.00366CA5@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/685d8124/attachment.pl>

From jim at bitwrit.com.au  Mon Nov  4 11:55:17 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 04 Nov 2013 21:55:17 +1100
Subject: [R] add a color band
In-Reply-To: <1383556152.90906.YahooMailNeo@web125303.mail.ne1.yahoo.com>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526A3E69.2060103@bitwrit.com.au>	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>	<526AE5FA.3000604@bitwrit.com.au>	<1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526CF7A4.4050709@bitwrit.com.au>
	<1382947071.31098.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	<1383556152.90906.YahooMailNeo@web125303.mail.ne1.yahoo.com>
Message-ID: <52777D15.6060407@bitwrit.com.au>

On 11/04/2013 08:09 PM, Alaios wrote:
> Hi Jim Lemon,
> thanks for the help, I appreciate this.
>
> right now my code looks like.
>
>
> par(mar=c(5,4,4,5))
> color2D.matplot(data,1,c(0,1),0,xlab="",ylab="Spans",
> main="color.scale",xrange=c(-110,-50),border=NA,axes=F)
> color.legend(357,30,370,100,seq(-110,-50,length.out=13),
> align="rb",rect.col=color.scale(1:13,1,c(0,1),0),
> gradient="y")
>
>
> my major problem now is that the
> a. text in the color bar is squeezed so -50 overlaps with -60 and so on
> b. for some reason the color bar sometimes (the same code is called for
> all the data matrices I have) is misaligned in different positions each time
>
> Could you please also help me with those two?
>
Hi Alex,
For your first question, I would simply extend the color legend vertically:

color.legend(357,30,370,150,seq(-110,-50,length.out=13),
  align="rb",rect.col=color.scale(1:13,1,c(0,1),0),
  gradient="y")

For the second one, you obviously have different dimensions for the data 
matrices. So, let's step through a method for getting the legend 
position and size from the plot itself. As I have written a few times 
previously, par("usr") gives you the dimensions of the plot in user 
units. For the example above, the dimensions were:

x - 0->351
y - 0->200

With a bit of arithmetic, you can work out that the legend positions in 
the above are:

xylim<-par("usr")
# x position of lower left corner of legend
xl<-xylim[2]+diff(xylim[1:2])*0.017
# y position of lower left corner
yb<-xylim[3]+diff(xylim[3:4])*0.15
# x position of upper right corner of legend
xr<-xylim[2]+diff(xylim[1:2])*0.054
# y position of upper right corner
yt<-xylim[3]+diff(xylim[3:4])*0.75

Having these lines means that you can get the position and size of the 
legend about right from the information provided by par("usr") even if 
you change the number of cells in the matrix passed to color2D.matplot. 
Then you would call:

color.legend(xl,yb,xr,yt,seq(-110,-50,length.out=13),
  align="rb",rect.col=color.scale(1:13,1,c(0,1),0),
  gradient="y")

unless of course you wanted to change the values in the scale markings. 
I'll leave that for you to work out.

Jim


From k.moon at student.unimelb.edu.au  Mon Nov  4 12:13:09 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 4 Nov 2013 03:13:09 -0800 (PST)
Subject: [R] Comparison of two weibull distributions
In-Reply-To: <loom.20131103T145352-194@post.gmane.org>
References: <1383467521821-4679632.post@n4.nabble.com>
	<loom.20131103T145352-194@post.gmane.org>
Message-ID: <1383563589396-4679680.post@n4.nabble.com>

Thank you so much for your explanation.
I might be in a trouble again with processing log-likelihood analysis. 
If it happens, may I ask your instuctions next time?




--
View this message in context: http://r.789695.n4.nabble.com/Comparison-of-two-weibull-distributions-tp4679632p4679680.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Mon Nov  4 12:13:11 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 04 Nov 2013 22:13:11 +1100
Subject: [R] All curves with same y-axis scale
In-Reply-To: <OFAFDDA7B3.0A5D88DF-ON65257C19.0035CB83-65257C19.00366CA5@polarisft.com>
References: <OFAFDDA7B3.0A5D88DF-ON65257C19.0035CB83-65257C19.00366CA5@polarisft.com>
Message-ID: <52778147.60009@bitwrit.com.au>

On 11/04/2013 08:54 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi,
>
> When I plot 3 curves with the same x-axis and same y-axis, the first two
> curves honor the y-axis but the last one doesn't. When I remove yaxt="n"
> for the last curve a new scale appears on the y-axis along with the scales
> that the first two curves use. I want all curves to use the same y-axis
> scale.
>
> What is missing ?
>
>         Init             Used        Committed    Max        Time
> 1   2359296 13913536  13959168 50331648   200
> 2   2359296 13915200  13959168 50331648   400
> 3   2359296 13947712  13991936 50331648   600
> 4   2359296 13956224  13991936 50331648   800
> 5   2359296 13968832  14024704 50331648  1000
> 6   2359296 13978048  14024704 50331648  1200
> 7   2359296 14012416  14090240 50331648  1400
> 8   2359296 14450304  14548992 50331648  1600
> 9   2359296 14521024  14548992 50331648  1800
> 10  2359296 14536320  14548992 50331648  2000
> 11  2359296 14553344  14581760 50331648  2200
>
> plot(data$Time,as.numeric(data$Used),col="green",pch=16,type="b",
> ylab="MegaBytes", xlab="",las=2,lwd=2,xaxt="n", cex.lab=1.2,cex.axis=1)
> axis(1,at = seq(min(data$Time), max(data$Time), by=1000),las =
> 2,cex.axis=1)
> title("Time vs Used Code cache,Committed and Maximum Code
> cache",cex.main=1.5,xlab="Time(Seconds)")
>
> par(new=T)
> plot(data$Time,as.numeric(data$Committed),col="orangered",pch=16,type="b",
> ylab="MegaBytes", xlab="",las=2,lwd=2,xaxt="n",
> cex.lab=1.2,cex.axis=1,yaxt="n")
>
> par(new=T)
> plot(data$Time,as.numeric(data$Max),col="palevioletred3",pch=16,type="b",
> ylab="MegaBytes", xlab="",las=2,lwd=2,xaxt="n",
> cex.lab=1.2,cex.axis=1,yaxt="n")
>
Hi Mohan,
This is because the ranges of "Used" and "Committed" are so close that 
you probably didn't notice the difference. "Max" is just a straight line 
way off the two original plots. If you want to show these three widely 
varying values on the same plot, use the lines or points function for 
the second two sets of values and set your ylim in the first plot to 
contain all the values to be plotted.

You might also look at the gap.plot function in plotrix if you want to 
avoid two lines at the bottom of the plot and one line right at the top:

gap.plot(data$Time,data$Used,gap=c(15000000,49000000),
  ylim=c(13500000,50500000),type="b",pch="U")
gap.plot(data$Time,data$Committed,gap=c(15000000,49000000),
  type="b",pch="C",add=TRUE)
gap.plot(data$Time,data$Max,gap=c(15000000,49000000),
  type="b",pch="M",add=TRUE)

Jim


From zulutime.net at gmail.com  Mon Nov  4 12:19:50 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Mon, 04 Nov 2013 11:19:50 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <CAAxdm-5r69f=aNCe+X1AZKh5NHh1z-rqMstCcsK3k7z3s9SqKg@mail.gmail.com>
References: <5273AD7E.6090607@gmail.com>	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>	<5273BD43.7020709@gmail.com>
	<CAAxdm-5r69f=aNCe+X1AZKh5NHh1z-rqMstCcsK3k7z3s9SqKg@mail.gmail.com>
Message-ID: <527782D6.3080104@gmail.com>

There are around 16M unique values. After accounting for equivalence, 
the number is much smaller (I don't know how much smaller, since my 
program has not completed yet :-)

Yes, I meant that "B and C are also equivalent". The original version 
was a typo.

Best,
Magnus

On 11/1/2013 3:45 PM, jim holtman wrote:
> in the 20M pairs, how many unique values are there?  In your statement
> above " But equivalence is transitive, so if A and B occur together in
> one pair, and A and C occur together in another pair, then A and C are
> also equivalent.", did you mean that "B and C are also equivalent"?
>
> Jim Holtman
> Data Munger Guru
>


From mohan.radhakrishnan at polarisft.com  Mon Nov  4 13:04:36 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 4 Nov 2013 17:34:36 +0530
Subject: [R] All curves with same y-axis scale
In-Reply-To: <52778147.60009@bitwrit.com.au>
References: <OFAFDDA7B3.0A5D88DF-ON65257C19.0035CB83-65257C19.00366CA5@polarisft.com>
	<52778147.60009@bitwrit.com.au>
Message-ID: <OF5F9F68F5.52E7A93D-ON65257C19.0041DB57-65257C19.00425596@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/b9c99bb1/attachment.pl>

From carl at witthoft.com  Mon Nov  4 13:19:27 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 4 Nov 2013 04:19:27 -0800 (PST)
Subject: [R] A warning message generated from 'read.csv'
In-Reply-To: <1383555355.12212.YahooMailNeo@web75203.mail.tw1.yahoo.com>
References: <1383555355.12212.YahooMailNeo@web75203.mail.tw1.yahoo.com>
Message-ID: <1383567567657-4679684.post@n4.nabble.com>

Pretty much exactly what it says.  Now, keep in mind that a "warning" message
does not indicate a failure or error.  Presumably you successfully read your
file into "filedata."   What it's saying is that the <EOL> character exists
inside some character string in one of the elements of your file.  Whether
that matters is of course dependent on what your data are and what you're
doing with it.


Chia-Chieh Lin-2 wrote
> I'm using R version 3.0.2. While I executed the following command
> 
> filedata <- read.csv(file, header=TRUE, colClasses="character")
> I got the warning message:
> 
> In scan(file, what, nmax, sep, dec, quote, skip, nlines, ?... :
> EOF within quoted string
> 
> I'd like to know what this means? And how shall I fix the problem?
> 
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/A-warning-message-generated-from-read-csv-tp4679675p4679684.html
Sent from the R help mailing list archive at Nabble.com.


From zulutime.net at gmail.com  Mon Nov  4 13:59:15 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Mon, 04 Nov 2013 12:59:15 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <52742737.7020609@fhcrc.org>
References: <5273AD7E.6090607@gmail.com>	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
	<5273C73D.2090809@gmail.com> <52742737.7020609@fhcrc.org>
Message-ID: <52779A23.2090401@gmail.com>



On 11/1/2013 10:12 PM, Martin Morgan wrote:
> Do you mean that if A,B occur together and B,C occur together, then A,B
> and A,C are equivalent?

Yes, that's what I meant, sorry, typo.

I like your uid() function. It avoids the 20M times loop, and the issue 
of circular references can be solved by ensuring that y is always 
(weakly) smaller than x.

I can see how the log(longest chain) would be the limiting case, since 
each round should always halve the length of the longest chain.

I have yet to test whether that intuition (about running time) works in 
practice.

I did test the program on a different data set, and it does seem that it 
fails to detect equivalence on the following input:

   a b
1 B A
2 C B
3 O G
4 O M
5 Y C
6 Y M

Everything should be equivalent here, but

 > uid(d$a, d$b)
[1] 1 1 3 4 1 6

I'm looking to see what can be about this. The problem seems to be with
entries of the form:

O->G
O->M

Which imply that all of O/M/G are equivalent, but they are not detected 
as such. Will consider whether there is a good way around this.

Best,
Magnus

> Here's a function that returns a unique identifier (not well tested!),
> allowing for transitive relations but not circularity.
>
>       uid <- function(x, y)
>      {
>          i <- seq_along(x)                   # global index
>          xy <- paste0(x, y)                  # make unique identifiers
>          idx <- match(xy, xy)
>
>          repeat {
>              ## transitive look-up
>              y_idx <- match(y[idx], x)       # look up 'y' in 'x'
>              keep <- !is.na(y_idx)
>              if (!any(keep))                 # no transitive relations,
> done!
>                  break
>              x[idx[keep]] <- x[y_idx[keep]]
>              y[idx[keep]] <- y[y_idx[keep]]
>
>              ## create new index of values
>              xy <- paste0(x, y)
>              idx <- match(xy, xy)
>          }
>          idx
>      }
>
> Values with the same index are identical. Some tests
>
>      > x <- c(1, 2, 3, 4)
>      > y <- c(2, 3, 5, 6)
>      > uid(x, y)
>      [1] 1 1 1 4
>      > i <- sample(x); uid(x[i], y[i])
>      [1] 1 1 3 1
>      > uid(as.character(x), as.character(y))  ## character() ok
>      [1] 1 1 1 4
>      > uid(1:10, 1 + 1:10)
>       [1] 1 1 1 1 1 1 1 1 1 1
>      > uid(integer(), integer())
>      integer(0)
>      > x <- c(1, 2, 3)
>      > y <- c(2, 3, 1)
>      > uid(x, y)                              ## circular!
>        C-c C-c
>
> I think this will scale well enough, but the worst-case scenario can be
> made to be log(longest chain) and copying can be reduced by using an
> index i and subsetting the original vector on each iteration. I think
> you could test for circularity by checking that the updated x are not a
> permutation of the kept x, all(x[y_idx[keep]] %in% x[keep]))
>
> Martin
>
>>
>> The way I do this currently is to designate the smallest
>> (alphabetically) string
>> in each known equivalence set as the "main" entry. For each pair, I
>> therefore
>> insert two entries into the hash table, both pointing at the mail
>> value. So
>> assuming the input data:
>>
>> A,B
>> B,C
>> D,E
>>
>> I would then have:
>>
>> A->A
>> B->A
>> C->B
>> D->D
>> E->D
>>
>> Except that I also follow each chain until I reach the end
>> (key==value), and
>> insert pointers to the "main" value for every value I find along the
>> way. After
>> doing that, I end up with:
>>
>> A->A
>> B->A
>> C->A
>> D->D
>> E->D
>>
>> And I can very quickly check equivalence, either by comparing the hash
>> of two
>> strings, or simply by transforming each string into its hash, and then
>> I can use
>> simple comparison from then on. The code for generating the final hash
>> table is
>> as follows:
>>
>> h : Empty hash table created with hash.new()
>> d : Input data
>> hash.deep.get : Function that iterates through the hash table until it
>> finds a
>> key whose value is equal to itself (until hash.get(X)==X), then
>> returns all the
>> values in a vector
>>
>>
>> h = hash.new()
>> for ( i in 1:nrow(d) )
>> {
>>      deep.a      = hash.deep.get(h, d$a[i])
>>      deep.b      = hash.deep.get(h, d$b[i])
>>      equivalents = sort(unique(c(deep.a,deep.b)))
>>      equiv.id    = min(equivalents)
>>      for ( equivalent in equivalents )
>>      {
>>          hash.put(h, equivalent, equiv.id)
>>      }
>> }
>>
>>
>> I would so much appreciate if there was a simpler and faster way to do
>> this.
>> Keeping my fingers crossed that one of the R-help geniuses who sees
>> this is
>> sufficiently interested to crack the problem
>>
>> Best,
>> Magnus
>>
>> On 11/1/2013 1:49 PM, jim holtman wrote:
>>> It would be nice if you followed the posting guidelines and at least
>>> showed the script that was creating your entries now so that we
>>> understand the problem you are trying to solve.  A bit more
>>> explanation of why you want this would be useful.  This gets to the
>>> second part of my tag line:  Tell me what you want to do, not how you
>>> want to do it.  There may be other solutions to your problem.
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>>
>>> On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
>>> <zulutime.net at gmail.com> wrote:
>>>> Pretty much what the subject says:
>>>>
>>>> I used an env as the basis for a Hashtable in R, based on
>>>> information that
>>>> this is in fact the way environments are implemented under the hood.
>>>>
>>>> I've been experimenting with doubling the number of entries, and so
>>>> far it
>>>> has seemed to be scaling more or less linearly, as expected.
>>>>
>>>> But as I went from 17 million entries to 34 million entries, the
>>>> completion
>>>> time has gone from 18 hours, to 5 days and counting.
>>>>
>>>>
>>>> The keys and values are in all cases strings of equal length.
>>>>
>>>> One might suspect that the slow-down might have to do with the
>>>> memory being
>>>> swapped to disk, but from what I know about my computing
>>>> environment, that
>>>> should not be the case.
>>>>
>>>> So my first question:
>>>> Is anyone familiar with anything in the implementation of
>>>> environments that
>>>> would limit their use or slow them down (faster than O(nlog(n)) as the
>>>> number of entries is increased?
>>>>
>>>> And my second question:
>>>> I realize that this is not strictly what R environments were
>>>> designed for,
>>>> but this is what my algorithm requires: I must go through these
>>>> millions of
>>>> entries, storing them in the hash table and sometimes retrieving
>>>> them along
>>>> the way, in a more or less random manner, which is contingent on the
>>>> data I
>>>> am encountering, and on the contents of the hash table at each moment.
>>>>
>>>> Does anyone have a good recommendation for alternatives to implement
>>>> huge,
>>>> fast, table-like structures in R?
>>>>
>>>> Best,
>>>> Magnus
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From zulutime.net at gmail.com  Mon Nov  4 14:05:00 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Mon, 04 Nov 2013 13:05:00 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA12132@PA-MBX01.na.tibco.com>
References: <5273AD7E.6090607@gmail.com>	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
	<5273C73D.2090809@gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA12132@PA-MBX01.na.tibco.com>
Message-ID: <52779B7C.6060901@gmail.com>

Yes, I'm pretty familiar with igraph, but had not thought of using it 
for this. Interesting idea.

So I presume I'd do something like (pseudocode):

:Create igraph object from my data set as an edgelist
:Create a list of connected subgraphs using clusters()
:Loop through that list of clusters to create final data set

That might work ...

Thanks!

Magnus

On 11/1/2013 4:52 PM, William Dunlap wrote:
> Have you looked into the 'igraph' package?
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Magnus Thor Torfason
>> Sent: Friday, November 01, 2013 8:23 AM
>> To: r-help at r-project.org
>> Subject: Re: [R] Inserting 17M entries into env took 18h, inserting 34M entries taking 5+
>> days
>>
>> Sure,
>>
>> I was attempting to be concise and boiling it down to what I saw as the
>> root issue, but you are right, I could have taken it a step further. So
>> here goes.
>>
>> I have a set of around around 20M string pairs. A given string (say, A)
>> can either be equivalent to another string (B) or not. If A and B occur
>> together in the same pair, they are equivalent. But equivalence is
>> transitive, so if A and B occur together in one pair, and A and C occur
>> together in another pair, then A and C are also equivalent. I need a way
>> to quickly determine if any two strings from my data set are equivalent
>> or not.
>>
>> The way I do this currently is to designate the smallest
>> (alphabetically) string in each known equivalence set as the "main"
>> entry. For each pair, I therefore insert two entries into the hash
>> table, both pointing at the mail value. So assuming the input data:
>>
>> A,B
>> B,C
>> D,E
>>
>> I would then have:
>>
>> A->A
>> B->A
>> C->B
>> D->D
>> E->D
>>
>> Except that I also follow each chain until I reach the end (key==value),
>> and insert pointers to the "main" value for every value I find along the
>> way. After doing that, I end up with:
>>
>> A->A
>> B->A
>> C->A
>> D->D
>> E->D
>>
>> And I can very quickly check equivalence, either by comparing the hash
>> of two strings, or simply by transforming each string into its hash, and
>> then I can use simple comparison from then on. The code for generating
>> the final hash table is as follows:
>>
>> h : Empty hash table created with hash.new()
>> d : Input data
>> hash.deep.get : Function that iterates through the hash table until it
>> finds a key whose value is equal to itself (until hash.get(X)==X), then
>> returns all the values in a vector
>>
>>
>> h = hash.new()
>> for ( i in 1:nrow(d) )
>> {
>>       deep.a      = hash.deep.get(h, d$a[i])
>>       deep.b      = hash.deep.get(h, d$b[i])
>>       equivalents = sort(unique(c(deep.a,deep.b)))
>>       equiv.id    = min(equivalents)
>>       for ( equivalent in equivalents )
>>       {
>>           hash.put(h, equivalent, equiv.id)
>>       }
>> }
>>
>>
>> I would so much appreciate if there was a simpler and faster way to do
>> this. Keeping my fingers crossed that one of the R-help geniuses who
>> sees this is sufficiently interested to crack the problem
>>
>> Best,
>> Magnus
>>
>> On 11/1/2013 1:49 PM, jim holtman wrote:
>>> It would be nice if you followed the posting guidelines and at least
>>> showed the script that was creating your entries now so that we
>>> understand the problem you are trying to solve.  A bit more
>>> explanation of why you want this would be useful.  This gets to the
>>> second part of my tag line:  Tell me what you want to do, not how you
>>> want to do it.  There may be other solutions to your problem.
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>>
>>> On Fri, Nov 1, 2013 at 9:32 AM, Magnus Thor Torfason
>>> <zulutime.net at gmail.com> wrote:
>>>> Pretty much what the subject says:
>>>>
>>>> I used an env as the basis for a Hashtable in R, based on information that
>>>> this is in fact the way environments are implemented under the hood.
>>>>
>>>> I've been experimenting with doubling the number of entries, and so far it
>>>> has seemed to be scaling more or less linearly, as expected.
>>>>
>>>> But as I went from 17 million entries to 34 million entries, the completion
>>>> time has gone from 18 hours, to 5 days and counting.
>>>>
>>>>
>>>> The keys and values are in all cases strings of equal length.
>>>>
>>>> One might suspect that the slow-down might have to do with the memory being
>>>> swapped to disk, but from what I know about my computing environment, that
>>>> should not be the case.
>>>>
>>>> So my first question:
>>>> Is anyone familiar with anything in the implementation of environments that
>>>> would limit their use or slow them down (faster than O(nlog(n)) as the
>>>> number of entries is increased?
>>>>
>>>> And my second question:
>>>> I realize that this is not strictly what R environments were designed for,
>>>> but this is what my algorithm requires: I must go through these millions of
>>>> entries, storing them in the hash table and sometimes retrieving them along
>>>> the way, in a more or less random manner, which is contingent on the data I
>>>> am encountering, and on the contents of the hash table at each moment.
>>>>
>>>> Does anyone have a good recommendation for alternatives to implement huge,
>>>> fast, table-like structures in R?
>>>>
>>>> Best,
>>>> Magnus
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> .
>


From jrkrideau at inbox.com  Mon Nov  4 14:09:26 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 4 Nov 2013 05:09:26 -0800
Subject: [R] Newbie Question: Repeatable Tasks
In-Reply-To: <002201ced938$bdc4f280$394ed780$@gmx.de>
Message-ID: <7332AC7070F.000002D4jrkrideau@inbox.com>

Just type the commands in the Source window of RStudioo, debug,  save as a .r file and source it.  

I don't see any particular reason to have three scripts once everything is running correctly but you may find it useful.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: csvirtual at gmx.de
> Sent: Mon, 4 Nov 2013 09:34:54 +0100
> To: r-help at r-project.org
> Subject: [R] Newbie Question: Repeatable Tasks
> 
> Hello mailing list,
> 
> 
> 
> I am new to R using RStudio in Windows and I just want to have repeated
> tasks each day but could not find an answer to that reading a lot of
> intros,
> scrolling through even more and reading on S.O.
> 
> 
> 
> I connect to a database, load data, do calculation, write results to the
> database and close connection.
> 
> 
> Can I save what I typed into the console as a script (I just figured how
> to
> type into the Source window)? My idea is to have three scripts (if
> scripts
> are the right way to do it): one for connection, second for calculation,
> third to close connection. Would I then call them by "source(..R)" or is
> there a click-button-solution?
> 
> 
> 
> I would really appreciate if someone guides me in the right direction
> (link,
> tutorial, example would be sufficient).
> 
> 
> 
> Thanks for your help
> 
> Chris
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Mon Nov  4 14:25:55 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 4 Nov 2013 05:25:55 -0800
Subject: [R] help with ggplot legend specification
In-Reply-To: <FB454C9C2759D64BA12708C3073C30BB6A0E63C098@NUEW-EXMBCRB1.gfk.com>
Message-ID: <735784B6A7B.00000308jrkrideau@inbox.com>

As a starting point perhaps have a look at legend.key.size (unit)
in ?theme.  It may do something like what you want with some tweaking.  My quick and dirty example just applies the command to both legends.

  pl<-ggplot(dat1,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
      geom_point(shape=21,colour="black") 
pl + theme(legend.key.size = unit(2, "cm"))

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mike.conklin at gfk.com
> Sent: Thu, 31 Oct 2013 21:08:02 +0100
> To: r-help at r-project.org
> Subject: [R] help with ggplot legend specification
> 
> I am creating a scatterplot with the following code.
> 
>   pl<-ggplot(df,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
> 
> geom_point(shape=21,colour="black")+scale_size_area(max_size=pointsizefactor)
> 
> points are plotted where the size of the point is related to a metric
> variable gapsize and the fill color on the point is related to the
> variable PBF which is a 4 level factor.  This works exactly as I want
> with the points varying in size based on the metric and being color
> coded.  I get 2 legends on the side of the plot, one related to the size
> of the dot and the other showing the color coding. The problem is that
> the dots on the color coding legend are so small that it is impossible to
> discern what color they are. The dots in the plot are large, so it is
> clear what colors they are, but the legend is useless.  How can I
> increase the size of the points in the color legend.
> 
> pointsizefactor<-5
> 
> df
> 
>         Importance Performance gapsize labels       PBF
> q50451   0.7079463  -0.7213622       2      a         W
> q50452   0.4489164  -0.5552116       1      b         G
> q50453   0.7714138  -0.6940144       5      c         F
> q50454   0.6284830  -0.6011352       3      d         S
> q50455   0.7131063  -0.6800826       4      e         G
> q50456   0.7038184  -0.6026832       6      f         S
> q50457   0.5201238  -0.3539732       8      g         G
> q50458   0.9195046  -0.8214654       2      h         F
> q50459   0.3797730  -0.4184727       1      i         W
> q504510  0.8065015  -0.6305470       7      j         G
> q504511  0.6062951  -0.4442724       6      k         S
> q504512  0.6253870  -0.4478844       8      l         G
> q504513  0.3813209  -0.4102167       2      m         W
> q504514  0.3813209  -0.3436533       3      n         F
> q504515  0.5185759  -0.4365325       5      o         G
> q504516  0.5872033  -0.4556244       6      p         S
> q504518  0.5397317  -1.0000000       1      q         S
> q504519  0.5882353  -0.4674923       9      r         S
> q504520  0.4205366  -0.4164087       4      s         W
> q504521  0.7616099  -0.3323013      10      t         F
> q504522  0.7213622  -0.6088751       7      u         G
> q504523  0.6780186  -0.6130031       8      v         G
> q504524  0.6904025  -0.3937049      10      w         W
> q504525  0.4143447  -0.4669763       4      x         W
> q504526  0.5779154  -0.2982456       9      y         F
> q504527  0.6718266  -0.3457172      10      z         G
> 
> 
> Thanks all
> 
> //Mike
> 
> W. Michael Conklin
> Executive Vice President | Marketing Science
> GfK Custom Research, LLC | 8401 Golden Valley Road | Minneapolis, MN,
> 55427
> T +1 763 417 4545 | M +1 612 567 8287
> www.gfk.com<http://www.gfk.com/>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From babakbsn at gmail.com  Mon Nov  4 14:47:23 2013
From: babakbsn at gmail.com (Baro)
Date: Mon, 4 Nov 2013 05:47:23 -0800
Subject: [R] Reading data from Excel file in r
Message-ID: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/3ce9d0ee/attachment.pl>

From friendly at yorku.ca  Mon Nov  4 14:54:00 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 04 Nov 2013 08:54:00 -0500
Subject: [R] Subject: Regress multiple independent variables on multiple
 dependent variables
In-Reply-To: <CAAC1QdCS5StbTTEOtfF=JBZ2m0=27H2josNcT2_S3BrDW0EcGA@mail.gmail.com>
References: <CAAC1QdCS5StbTTEOtfF=JBZ2m0=27H2josNcT2_S3BrDW0EcGA@mail.gmail.com>
Message-ID: <5277A6F8.9000108@yorku.ca>

It's not clear exactly what you mean by 'automate' but you can simplify
a bit by fitting a multivariate linear model to all the responses 
together, and using . on the RHS of the formula to represent all
other variables in the data set as independent variables,

m.all <- glm(cbind(O3, temp) ~ ., data=ozone)

(assuming that only humidity, ibh and ibt remain; otherwise, use
data=subset(ozone, ...))

-Michael

On 11/4/2013 2:55 AM, Kumar Raj wrote:
> I want to estimate the effect of several independent variables on several
> dependent
> variables. In the example below I wanted to estimate the
> effect of three independent variables on ozone and temperature.  My aim is
> to create a list of dependent and independent variables and automate the
> process rather than writing every dependent and independent variable in
> each model as I have done below.
>
> Example data is provided by the following library:
> library(faraway)
>
> data(ozone)
>
> mo3 <- glm(O3 ~ humidity + ibh + ibt, data=ozone)
>
> mtemp<- glm(temp ~  humidity + ibh + ibt, data=ozone)
>
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jvadams at usgs.gov  Mon Nov  4 14:56:09 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 4 Nov 2013 07:56:09 -0600
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <op.w50q3raozqkd1e@bam>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam>
Message-ID: <CAN5YmCHCEALxdDaV5XVLyM2dhxj_-tsjWi18i31AjEpqpMwUsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/854841be/attachment.pl>

From jholtman at gmail.com  Mon Nov  4 15:01:14 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 4 Nov 2013 09:01:14 -0500
Subject: [R] Reading data from Excel file in r
In-Reply-To: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
References: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
Message-ID: <CAAxdm-7MyFEBFLKgaCmyW6M+f8ASC_zJ0prjyTNY9v-5nxrx7A@mail.gmail.com>

Take a look at the "XLConnect" package.  I use it for all the
reading/writing for Excel files.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Nov 4, 2013 at 8:47 AM, Baro <babakbsn at gmail.com> wrote:
> Hi experts,
>
> I want to read data from an excel data  like this:
>
>  for the fifth column, from first row until 140 but only 1,3,5,7,.....139
> (only 70 values),
>
> How can I do it in R?
>
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thomasfoxley at aol.com  Mon Nov  4 15:13:04 2013
From: thomasfoxley at aol.com (thomas)
Date: Mon, 04 Nov 2013 14:13:04 +0000
Subject: [R] How to plot results of clmm()?
Message-ID: <5277AB70.1030301@aol.com>

Dear list,

I'd like to create a visual plot of a clmm() I've fitted using the 
'ordinal' package in R. It's possible to do this with a glm() by using 
the 'effects' package. For example:

    library(effects)
    data(BEPS)
    mod <- lm(political.knowledge ~ age + gender + vote, data=BEPS)
    eff <- effect("age", mod, default.levels=100)
    plot(eff, colors=c("black", "red"))

Produces: http://i.stack.imgur.com/elo4p.png

The 'effects' package does not support clmm:

    mod <- clmm(as.factor(political.knowledge) ~ age + gender + 
(1|vote), data=BEPS)
    eff <- effect("age", mod, default.levels=100)
    > Error in UseMethod("effect", mod) :
    no applicable method for 'effect' applied to an object of class "clmm"

How would I go about doing this? I can't find any examples with clm() or 
clmm() online. Any suggestions would be much appreciated.

Tom


From jvadams at usgs.gov  Mon Nov  4 15:13:09 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 4 Nov 2013 08:13:09 -0600
Subject: [R] Reading data from Excel file in r
In-Reply-To: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
References: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
Message-ID: <CAN5YmCGHUPBLekTSf6rP5WbCsEeUJ=cN6RVAoT54Bxb0AZy2xQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/0f4d1c03/attachment.pl>

From alaios at yahoo.com  Mon Nov  4 15:18:55 2013
From: alaios at yahoo.com (Alaios)
Date: Mon, 4 Nov 2013 06:18:55 -0800 (PST)
Subject: [R] add a color band
In-Reply-To: <52777D15.6060407@bitwrit.com.au>
References: <1382693891.44547.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526A3E69.2060103@bitwrit.com.au>	<1382703414.34947.YahooMailNeo@web125305.mail.ne1.yahoo.com>	<526AE5FA.3000604@bitwrit.com.au>	<1382823551.43934.YahooMailNeo@web125302.mail.ne1.yahoo.com>	<526CF7A4.4050709@bitwrit.com.au>
	<1382947071.31098.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	<1383556152.90906.YahooMailNeo@web125303.mail.ne1.yahoo.com>
	<52777D15.6060407@bitwrit.com.au>
Message-ID: <1383574735.57478.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/ff38935a/attachment.pl>

From istazahn at gmail.com  Mon Nov  4 15:18:50 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 4 Nov 2013 09:18:50 -0500
Subject: [R] help with ggplot legend specification
In-Reply-To: <735784B6A7B.00000308jrkrideau@inbox.com>
References: <FB454C9C2759D64BA12708C3073C30BB6A0E63C098@NUEW-EXMBCRB1.gfk.com>
	<735784B6A7B.00000308jrkrideau@inbox.com>
Message-ID: <CA+vqiLF1+btKcYrZxBAwgiVSjGZREeHmouTQQgOK-7NLhhsVGg@mail.gmail.com>

Hi John,

On Mon, Nov 4, 2013 at 8:25 AM, John Kane <jrkrideau at inbox.com> wrote:
> As a starting point perhaps have a look at legend.key.size (unit)
> in ?theme.

That will change the size of the legend key, not the size of the
aesthetics inside the legend. For that you need to use override.aes in
guide_legend, as I previously suggested.

Best,
Ista

 It may do something like what you want with some tweaking.  My quick
and dirty example just applies the command to both legends.
>
>   pl<-ggplot(dat1,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
>       geom_point(shape=21,colour="black")
> pl + theme(legend.key.size = unit(2, "cm"))
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: mike.conklin at gfk.com
>> Sent: Thu, 31 Oct 2013 21:08:02 +0100
>> To: r-help at r-project.org
>> Subject: [R] help with ggplot legend specification
>>
>> I am creating a scatterplot with the following code.
>>
>>   pl<-ggplot(df,aes(x=Importance,y=Performance,fill=PBF,size=gapsize))+
>>
>> geom_point(shape=21,colour="black")+scale_size_area(max_size=pointsizefactor)
>>
>> points are plotted where the size of the point is related to a metric
>> variable gapsize and the fill color on the point is related to the
>> variable PBF which is a 4 level factor.  This works exactly as I want
>> with the points varying in size based on the metric and being color
>> coded.  I get 2 legends on the side of the plot, one related to the size
>> of the dot and the other showing the color coding. The problem is that
>> the dots on the color coding legend are so small that it is impossible to
>> discern what color they are. The dots in the plot are large, so it is
>> clear what colors they are, but the legend is useless.  How can I
>> increase the size of the points in the color legend.
>>
>> pointsizefactor<-5
>>
>> df
>>
>>         Importance Performance gapsize labels       PBF
>> q50451   0.7079463  -0.7213622       2      a         W
>> q50452   0.4489164  -0.5552116       1      b         G
>> q50453   0.7714138  -0.6940144       5      c         F
>> q50454   0.6284830  -0.6011352       3      d         S
>> q50455   0.7131063  -0.6800826       4      e         G
>> q50456   0.7038184  -0.6026832       6      f         S
>> q50457   0.5201238  -0.3539732       8      g         G
>> q50458   0.9195046  -0.8214654       2      h         F
>> q50459   0.3797730  -0.4184727       1      i         W
>> q504510  0.8065015  -0.6305470       7      j         G
>> q504511  0.6062951  -0.4442724       6      k         S
>> q504512  0.6253870  -0.4478844       8      l         G
>> q504513  0.3813209  -0.4102167       2      m         W
>> q504514  0.3813209  -0.3436533       3      n         F
>> q504515  0.5185759  -0.4365325       5      o         G
>> q504516  0.5872033  -0.4556244       6      p         S
>> q504518  0.5397317  -1.0000000       1      q         S
>> q504519  0.5882353  -0.4674923       9      r         S
>> q504520  0.4205366  -0.4164087       4      s         W
>> q504521  0.7616099  -0.3323013      10      t         F
>> q504522  0.7213622  -0.6088751       7      u         G
>> q504523  0.6780186  -0.6130031       8      v         G
>> q504524  0.6904025  -0.3937049      10      w         W
>> q504525  0.4143447  -0.4669763       4      x         W
>> q504526  0.5779154  -0.2982456       9      y         F
>> q504527  0.6718266  -0.3457172      10      z         G
>>
>>
>> Thanks all
>>
>> //Mike
>>
>> W. Michael Conklin
>> Executive Vice President | Marketing Science
>> GfK Custom Research, LLC | 8401 Golden Valley Road | Minneapolis, MN,
>> 55427
>> T +1 763 417 4545 | M +1 612 567 8287
>> www.gfk.com<http://www.gfk.com/>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From babakbsn at gmail.com  Mon Nov  4 15:26:22 2013
From: babakbsn at gmail.com (Baro)
Date: Mon, 4 Nov 2013 06:26:22 -0800
Subject: [R] Reading data from Excel file in r
In-Reply-To: <CAN5YmCGHUPBLekTSf6rP5WbCsEeUJ=cN6RVAoT54Bxb0AZy2xQ@mail.gmail.com>
References: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
	<CAN5YmCGHUPBLekTSf6rP5WbCsEeUJ=cN6RVAoT54Bxb0AZy2xQ@mail.gmail.com>
Message-ID: <CAF-JZQtArb7XwXDOg6VYXtUNuGj+ZVvxnnKPvKuKnDunb=bAGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/bd286faa/attachment.pl>

From csvirtual at gmx.de  Mon Nov  4 15:27:32 2013
From: csvirtual at gmx.de (csvirtual at gmx.de)
Date: Mon, 4 Nov 2013 15:27:32 +0100
Subject: [R] Newbie Question: Repeatable Tasks
In-Reply-To: <7332AC7070F.000002D4jrkrideau@inbox.com>
References: <002201ced938$bdc4f280$394ed780$@gmx.de>
	<7332AC7070F.000002D4jrkrideau@inbox.com>
Message-ID: <006d01ced969$ffb5efb0$ff21cf10$@gmx.de>

Thanks John,

It works. (just saved source and clicked "Source" to run it, without
debug(?)).
Best
Chris

-----Urspr?ngliche Nachricht-----
Von: John Kane [mailto:jrkrideau at inbox.com] 
Gesendet: Montag, 4. November 2013 14:09
An: csvirtual at gmx.de; r-help at r-project.org
Betreff: RE: [R] Newbie Question: Repeatable Tasks

Just type the commands in the Source window of RStudioo, debug,  save as a
.r file and source it.  

I don't see any particular reason to have three scripts once everything is
running correctly but you may find it useful.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: csvirtual at gmx.de
> Sent: Mon, 4 Nov 2013 09:34:54 +0100
> To: r-help at r-project.org
> Subject: [R] Newbie Question: Repeatable Tasks
> 
> Hello mailing list,
> 
> 
> 
> I am new to R using RStudio in Windows and I just want to have 
> repeated tasks each day but could not find an answer to that reading a 
> lot of intros, scrolling through even more and reading on S.O.
> 
> 
> 
> I connect to a database, load data, do calculation, write results to 
> the database and close connection.
> 
> 
> Can I save what I typed into the console as a script (I just figured 
> how to type into the Source window)? My idea is to have three scripts 
> (if scripts are the right way to do it): one for connection, second 
> for calculation, third to close connection. Would I then call them by 
> "source(..R)" or is there a click-button-solution?
> 
> 
> 
> I would really appreciate if someone guides me in the right direction 
> (link, tutorial, example would be sufficient).
> 
> 
> 
> Thanks for your help
> 
> Chris
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your
desktop!


From jvadams at usgs.gov  Mon Nov  4 15:49:11 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 4 Nov 2013 08:49:11 -0600
Subject: [R] Reading data from Excel file in r
In-Reply-To: <CAF-JZQtArb7XwXDOg6VYXtUNuGj+ZVvxnnKPvKuKnDunb=bAGw@mail.gmail.com>
References: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
	<CAN5YmCGHUPBLekTSf6rP5WbCsEeUJ=cN6RVAoT54Bxb0AZy2xQ@mail.gmail.com>
	<CAF-JZQtArb7XwXDOg6VYXtUNuGj+ZVvxnnKPvKuKnDunb=bAGw@mail.gmail.com>
Message-ID: <CAN5YmCFYU9VjrVs4TFQ+ab82kqFSiZBSu8kKvp6RtYTJ3r0MHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/2e7a3509/attachment.pl>

From babakbsn at gmail.com  Mon Nov  4 15:58:38 2013
From: babakbsn at gmail.com (Baro)
Date: Mon, 4 Nov 2013 06:58:38 -0800
Subject: [R] Reading data from Excel file in r
In-Reply-To: <CAN5YmCFYU9VjrVs4TFQ+ab82kqFSiZBSu8kKvp6RtYTJ3r0MHw@mail.gmail.com>
References: <CAF-JZQsb=HzVhCN11RCfmnh-apoB0T6n+So7f=PeQ+XsPdCr6Q@mail.gmail.com>
	<CAN5YmCGHUPBLekTSf6rP5WbCsEeUJ=cN6RVAoT54Bxb0AZy2xQ@mail.gmail.com>
	<CAF-JZQtArb7XwXDOg6VYXtUNuGj+ZVvxnnKPvKuKnDunb=bAGw@mail.gmail.com>
	<CAN5YmCFYU9VjrVs4TFQ+ab82kqFSiZBSu8kKvp6RtYTJ3r0MHw@mail.gmail.com>
Message-ID: <CAF-JZQv_vsoOuUWVUNQJwhWxTRewxeeXjQWqNbnQXch4AHz-ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/552f1b56/attachment.pl>

From anders.tisell at liu.se  Mon Nov  4 15:10:47 2013
From: anders.tisell at liu.se (Anders Tisell)
Date: Mon, 4 Nov 2013 14:10:47 +0000
Subject: [R] Save P values calculated with anova
Message-ID: <E192948D-889F-422A-AFD5-6ED42079DEA9@liu.se>

Hi,

I have created a mixed linear model with one fixed factor and two
random factors then I would like to test if there is a significant
difference between the two groups.

To do this I calculate the model with the lmer function:

> MyModel <- lmer(...)

and do a anova of the model to estimate if the F value is significant.

> MyAnova <- anova(MyModel)

And I get a summary table of the anova with F values, Pr(>F) when i
try to extract this values using the $ function:

> MyAnova$Pr(>F)

I get the error message:

Error: unexpected symbol '>' in "MyAnova$Pr(>

I also get this message if I try to extract F value, Mean Sq etc But
not for DF, Denom etc, so I guess it is the white space and >
characters that is the problem. What should I do to get the P values
so I can write them in to a file?

I am using R 3.0.2 GUI 1.62 Snow Lepard build (6558) on a Mac Mini OS X 10.9

Best regards
/Anders


Sent from Anders iPad


From lorenzo.isella at gmail.com  Mon Nov  4 10:53:41 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 4 Nov 2013 10:53:41 +0100
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
Message-ID: <op.w50q3raozqkd1e@bam>

Hello,
And thanks a lot.
This is indeed very close to what I need.
I am trying to figure out how not to "lose" the headers and how to avoid  
downloading labels like "(p)" together with the numerical data I am  
interested in.
If anyone on the list knows how to make this minor modifications, s/he  
will make my life much easier.
Cheers

Lorenzo


On Fri, 01 Nov 2013 14:25:49 +0100, Adams, Jean <jvadams at usgs.gov> wrote:

> Lorenzo,
>
> I may be able to help you get started.  You can use the XML package to  
> grab the information >off the internet.
>
> library(XML)
>
> mylines <- readLines(url("http://bit.ly/1coCohq"))
> closeAllConnections()mylist <- readHTMLTable(mylines, asText=TRUE) 
> mytable <- mylist1$xTable
>
> However, when I look at the resulting object, mytable, it doesn't have  
> informative row or >column headings.  Perhaps someone else can figure  
> out how to get that information.
>
> Jean
>
>
>
>
>
> On Thu, Oct 31, 2013 at 10:38 AM, Lorenzo Isella  
> <lorenzo.isella at gmail.com> wrote:
>> Dear All,
>> I often need to do some work on some data which is publicly available  
>> on the EUROSTAT >>website.
>> I saw several ways to download automatically mainly the bulk data from  
>> EUROSTAT to later on >>postprocess it with R, for instance
>>
>> http://bit.ly/HrDICj
>> http://bit.ly/HrDL10
>> http://bit.ly/HrDTgT
>>
>> However, what I would like to do is to be able to download directly the  
>> csv file >>corresponding to a properly formatted dataset (typically a  
>> dynamic dataset) from EUROSTAT.
>> To fix the ideas, please consider the dataset at the following link
>>
>> http://bit.ly/1coCohq
>>
>> what I would like to do is to automatically read its content into R, or  
>> at least to >>automatically download it as a csv file (full extraction,  
>> single file, no flags and >>footnotes) which I can then manipulate  
>> easily.
>> Any suggestion is appreciated.
>> Cheers
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide  
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From miroslav.kutal at hnutiduha.cz  Mon Nov  4 12:10:41 2013
From: miroslav.kutal at hnutiduha.cz (Miroslav Kutal)
Date: Mon, 04 Nov 2013 12:10:41 +0100
Subject: [R] Error message in SPACECAP package
Message-ID: <527780B1.5010407@hnutiduha.cz>

Dear all

I've tried a spatial capture-recapture in SPACECAP package but got stuck 
after uploading the input data files:

"Error in animal capture details file - non-integer or missing values"
Error in if (locso[loc, so + 3] == 0) { :
missing value where TRUE/FALSE needed

I prepared the input capture file according to the manual and the file 
should consist from three columns: LOC_ID, ANIMAL_ID, SO (sampling 
occasion) so actually no TRUE/FALSE type of data..

I am attaching also the input capture file. Because I am not familiar 
with all R functions I would appreciate any suggestion for solving this 
problem.

Thank you,

Miroslav Kutal


From smartpink111 at yahoo.com  Mon Nov  4 15:18:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 4 Nov 2013 06:18:25 -0800 (PST)
Subject: [R] Subject: Regress multiple independent variables on multiple
	dependent variables
In-Reply-To: <5277A6F8.9000108@yorku.ca>
References: <CAAC1QdCS5StbTTEOtfF=JBZ2m0=27H2josNcT2_S3BrDW0EcGA@mail.gmail.com>
	<5277A6F8.9000108@yorku.ca>
Message-ID: <1383574705.32826.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

This gives an error.? 

glm(cbind(O3, temp) ~ ., data=ozone)
Error in x[good, , drop = FALSE] : (subscript) logical subscript too long


?lm(cbind(O3, temp) ~ ., data=ozone) #works



R version 3.0.2 (2013-09-25)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=en_CA.UTF-8?????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] faraway_1.0.5?? ggplot2_0.9.3.1 plotrix_3.5-1?? stringr_0.6.2? 
[5] reshape2_1.2.2 

loaded via a namespace (and not attached):
?[1] colorspace_1.2-3?? dichromat_2.0-0??? digest_0.6.3?????? grid_3.0.2??????? 
?[5] gtable_0.1.2?????? labeling_0.2?????? MASS_7.3-29??????? munsell_0.4.2???? 
?[9] plyr_1.8?????????? proto_0.3-10?????? RColorBrewer_1.0-5 scales_0.2.3????? 
[13] tcltk_3.0.2??????? tools_3.0.2?????? 



On Monday, November 4, 2013 8:55 AM, Michael Friendly <friendly at yorku.ca> wrote:
It's not clear exactly what you mean by 'automate' but you can simplify
a bit by fitting a multivariate linear model to all the responses 
together, and using . on the RHS of the formula to represent all
other variables in the data set as independent variables,

m.all <- glm(cbind(O3, temp) ~ ., data=ozone)

(assuming that only humidity, ibh and ibt remain; otherwise, use
data=subset(ozone, ...))

-Michael

On 11/4/2013 2:55 AM, Kumar Raj wrote:
> I want to estimate the effect of several independent variables on several
> dependent
> variables. In the example below I wanted to estimate the
> effect of three independent variables on ozone and temperature.? My aim is
> to create a list of dependent and independent variables and automate the
> process rather than writing every dependent and independent variable in
> each model as I have done below.
>
> Example data is provided by the following library:
> library(faraway)
>
> data(ozone)
>
> mo3 <- glm(O3 ~ humidity + ibh + ibt, data=ozone)
>
> mtemp<- glm(temp ~? humidity + ibh + ibt, data=ozone)
>
>
> Thanks
>
> ??? [[alternative HTML version deleted]]
>


-- 
Michael Friendly? ?  Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University? ? ? Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street? ? Web:? http://www.datavis.ca
Toronto, ONT? M3J 1P3 CANADA


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Nov  4 15:43:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 4 Nov 2013 06:43:23 -0800 (PST)
Subject: [R] Replace element with pattern
In-Reply-To: <OF08EAA960.A0D2FFAF-ON65257C19.00286612-65257C19.00287EFF@polarisft.com>
References: <OF82954872.301E1D6A-ON65257C16.002C15DC-65257C16.002CC65B@polarisft.com>	<1383311389.45470.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<OF88E0FCDD.972E91CF-ON65257C19.002524B9-65257C19.00257937@polarisft.com>
	<OF08EAA960.A0D2FFAF-ON65257C19.00286612-65257C19.00287EFF@polarisft.com>
Message-ID: <1383576203.93806.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Using ?gsub()
gsub("[^0-9]+"," ",a$Col1)

#or
?gsub("[^0-9]+(,|/|)"," ",a$Col1) 

library(stringr)
dat <- read.table(text=str_trim(gsub("[^0-9]+(,|/|)"," ",a$Col1)),sep="")


A.K.







On Monday, November 4, 2013 2:22 AM, "mohan.radhakrishnan at polarisFT.com" <mohan.radhakrishnan at polarisFT.com> wrote:

Please ignore. This works. 

str_extract_all(a$Col1,"[0-9]+(,|/|)") 

Mohan 



From: ? ? ?
?mohan.radhakrishnan at polarisft.com 
To: ? ? ?
?arun <smartpink111 at yahoo.com> 
Cc: ? ? ?
?R help <r-help at r-project.org> 
Date: ? ? ?
?11/04/2013 12:22 PM 
Subject: ? ?
? ?Re: [R] Replace
element with pattern 
Sent by: ? ?
? ?r-help-bounces at r-project.org 
________________________________



Hi,

? ?How do we extract the numbers into an array or data frame
assuming the 
rows of text is in a data frame ?

> head(a)
Col1
1 Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|
2 Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|
> 

The working pattern is this [0-9]*(,|\|)

I tried

gsub("[0-9]*(,|/|)","",a$Col1)

> grep("[0-9]*(,|/|)",a$Col1,value=TRUE)
[1] "Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|"
[2] "Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|"
>

> str_extract(a$Col1,"[0-9]*(,|/|)")
[1] "" ""


Thanks



From: ? arun <smartpink111 at yahoo.com>
To: ? ? R help <r-help at r-project.org>
Cc: ? ? "mohan.radhakrishnan at polarisft.com" 
<mohan.radhakrishnan at polarisft.com>
Date: ? 11/01/2013 06:40 PM
Subject: ? ? ? ?Re: [R] Replace element with pattern





Hi,

Try this:

Lines1 <- readLines(textConnection("Peak Usage ? ?: init:2359296, 
used:15859328, committed:15892480,max:50331648Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|-------------------|
Peak Usage ? ?: init:2359296, used:15859328, 
committed:15892480,max:50331648Current Usage : init:2359296 
used:15857920,committed:15892480,max:50331648|-------------------|"))

data.frame(Col1=as.matrix(gsub("(.*?[/|])","\\1",Lines1)))
#Assuming that 
you want to read it from Peak Usage to the first "|":

#If it is from Current Usage to "|"

data.frame(Col1=as.matrix(gsub("^.*(Current.*?[/|]).*","\\1",Lines1)))


A.K.


On Friday, November 1, 2013 4:11 AM, "mohan.radhakrishnan at polarisft.com" 
<mohan.radhakrishnan at polarisft.com> wrote:
Hi,
? ? ? ? I have a data frame with one column and several
rows of the form.

"Peak Usage ? ?: init:2359296, used:15859328, committed:15892480, 
max:50331648Current Usage : init:2359296, used:15857920, 
committed:15892480, max:50331648|-------------------|"

I tested the regex 

Current.*?[\|]

in an online tester which greedily matches upto the first 'pipe' character

Current Usage : init:2359296, used:15857920, committed:15892480, 
max:50331648|

This is what I want.

I tried to replace the entire rows using 

apply( y, 1, function(x) gsub(x,"Current.*?[/|]",x)) which didn't
work.

How is this done ? I also want to recursively apply some more patterns
one 

by one on the rows till I reduce it to exactly what I want. Is there a
way 

to do this without loops ?

Thanks,
Mohan


This e-Mail may contain proprietary and confidential information and is 
sent for the intended recipient(s) only. ?If by an addressing or 
transmission error this mail has been misdirected to you, you are 
requested to delete this mail immediately. You are also hereby notified 
that any use, any form of reproduction, dissemination, copying, 
disclosure, modification, distribution and/or publication of this e-mail 
message, contents or its attachment other than by its intended recipient/s 
is strictly prohibited.

Visit us at http://www.polarisFT.com

? ?[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






This e-Mail may contain proprietary and confidential information and is
sent for the intended recipient(s) only. ?If by an addressing or transmission
error this mail has been misdirected to you, you are requested to delete
this mail immediately. You are also hereby notified that any use, any form
of reproduction, dissemination, copying, disclosure, modification, distribution
and/or publication of this e-mail message, contents or its attachment other
than by its intended recipient/s is strictly prohibited.

Visit us at 
http://www.polarisFT.com


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



________________________________
This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.??If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited. Visit us at http://www.polarisFT.com

________

From Thierry.ONKELINX at inbo.be  Mon Nov  4 16:13:06 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 4 Nov 2013 15:13:06 +0000
Subject: [R] Save P values calculated with anova
In-Reply-To: <E192948D-889F-422A-AFD5-6ED42079DEA9@liu.se>
References: <E192948D-889F-422A-AFD5-6ED42079DEA9@liu.se>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFAFBDC8@inbomail.inbo.be>

You'll need to add quotes

MyAnova$"Pr(>F)"

Or use the bracket notation

MyAnova[, "Pr(>F)"]



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Anders Tisell
Verzonden: maandag 4 november 2013 15:11
Aan: r-help at r-project.org
Onderwerp: [R] Save P values calculated with anova

Hi,

I have created a mixed linear model with one fixed factor and two random factors then I would like to test if there is a significant difference between the two groups.

To do this I calculate the model with the lmer function:

> MyModel <- lmer(...)

and do a anova of the model to estimate if the F value is significant.

> MyAnova <- anova(MyModel)

And I get a summary table of the anova with F values, Pr(>F) when i try to extract this values using the $ function:

> MyAnova$Pr(>F)

I get the error message:

Error: unexpected symbol '>' in "MyAnova$Pr(>

I also get this message if I try to extract F value, Mean Sq etc But not for DF, Denom etc, so I guess it is the white space and > characters that is the problem. What should I do to get the P values so I can write them in to a file?

I am using R 3.0.2 GUI 1.62 Snow Lepard build (6558) on a Mac Mini OS X 10.9

Best regards
/Anders


Sent from Anders iPad

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From dusa.adrian at unibuc.ro  Mon Nov  4 16:16:10 2013
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Mon, 4 Nov 2013 17:16:10 +0200
Subject: [R] Save P values calculated with anova
In-Reply-To: <E192948D-889F-422A-AFD5-6ED42079DEA9@liu.se>
References: <E192948D-889F-422A-AFD5-6ED42079DEA9@liu.se>
Message-ID: <CAJ=0CtBMwdguaD7bVesqk2NipWBox94zx1oFrzyq1b122dQO=A@mail.gmail.com>

That would be:
MyAnova$"Pr(>F)"

and since that is an Anova table, you actually only need the first value:
MyAnova$"Pr(>F)"[1]

Hope this helps,
Adrian


On Mon, Nov 4, 2013 at 4:10 PM, Anders Tisell <anders.tisell at liu.se> wrote:
>
> Hi,
>
> I have created a mixed linear model with one fixed factor and two
> random factors then I would like to test if there is a significant
> difference between the two groups.
>
> To do this I calculate the model with the lmer function:
>
> > MyModel <- lmer(...)
>
> and do a anova of the model to estimate if the F value is significant.
>
> > MyAnova <- anova(MyModel)
>
> And I get a summary table of the anova with F values, Pr(>F) when i
> try to extract this values using the $ function:
>
> > MyAnova$Pr(>F)
>
> I get the error message:
>
> Error: unexpected symbol '>' in "MyAnova$Pr(>
>
> I also get this message if I try to extract F value, Mean Sq etc But
> not for DF, Denom etc, so I guess it is the white space and >
> characters that is the problem. What should I do to get the P values
> so I can write them in to a file?
>
> I am using R 3.0.2 GUI 1.62 Snow Lepard build (6558) on a Mac Mini OS X 10.9
>
> Best regards
> /Anders
>
>
> Sent from Anders iPad
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
1, Schitu Magureanu Bd.
050025 Bucharest sector 5
Romania
Tel.:+40 21 3126618 \
        +40 21 3120210 / int.101
Fax: +40 21 3158391


From ryan at urban-econ.com  Mon Nov  4 16:19:22 2013
From: ryan at urban-econ.com (Ryan)
Date: Mon, 04 Nov 2013 17:19:22 +0200
Subject: [R] forecast.lm() and NEWDATA
In-Reply-To: <0B8EA941-390C-4C14-B201-395F9ED14F23@comcast.net>
References: <5273B194.6010004@urban-econ.com>
	<0B8EA941-390C-4C14-B201-395F9ED14F23@comcast.net>
Message-ID: <5277BAFA.8050708@urban-econ.com>

Hi David (and everyone)

Thank you for your reply.

I see I copied down the code wrong for the regression. I was using the 
"+" seperator, and not ",".  The regression was working.

I made a mistake with the NEWDATA, where I also used "+", instead of 
",", however I see both work but return very different results. I have 
corrected the mistake.

However, I am still receiving the same error when I try to run the 
forecast.lm.
"

forecast.lm(REGGY, h=5)

i receive the following error
"Error in as.data.frame(newdata) :
  argument "newdata" is missing, with no default""



I am sorry to say, I don't understand your reference to the string 
output when you mentioned

"

You should post the output of str() on the data-objects that has the 12 variables and if it was modified the data argument pasted to `lm()` when you made REGGY.

"
  As of right now, NEWDATA includes all the independent variables from 
the REGGY Regression.


Should the NEWDATA data.frame include the dependent variable?

Also, is it necessary to reformat all variables as time series? (I have 
not currently done so)

Regards
Ryan

On 2013-11-01 07:28 PM, David Winsemius wrote:
> On Nov 1, 2013, at 6:50 AM, Ryan wrote:
>
>> Good day all.
>>
>> I am hoping you can help me (and I did this right). I've been working in R for a week now, and have encountered a problem with forecast.lm().
>>
>> I have a list of 12 variables, all type = double, with 15 data entries.
>> (I imported them from tab delimited text files, and then formatted as.numeric to change from list to double)
>> (I understand that this leaves me rather limited in my degrees of freedom, but working with what I have, sadly. )
>>
>> I have a LM model, such that
>> REGGY = lm(formula=Y~A,B,C,...,I,J)
> This looks wrong. Separating independent predictors with commas would be highly unusual.
>> which I am happy with.
>>
>> I have
>> NEWDATA = data.frame(A+B+C+D....+I+J)
> This also looks wrong. Separating arguments to data.frame with "+"-signs is surely wrong.
>> When i try to run
>>
>> forecast.lm(REGGY, h=5)
>>
>> i receive the following error
>> "Error in as.data.frame(newdata) :
>>   argument "newdata" is missing, with no default"
> If your code prior to calling forecast on the REGGY-object was really what you showed here, I am not surprised. You should post the output of str() on the data-objects that has the 12 variables and if it was modified the data argument pasted to `lm()` when you made REGGY. (Beginners should name their data arguments.)
>
>> When I run
>> forecast.lm(REGGY, NEWDATA, h=5)
>> I receive the confidence intervals of the 15 data entries I already possess. I understand that by including NEWDATA, the "h=5" is ignored, but without NEWDATA, I receive the error message.
>>
>> Can anyone help me please?
>>
>> Regards
>> Ryan
>>
>> P.S The forecast is trying to predict the next 5 values for Y from the regression model pasted above. I'm a bit rusty with regressions, but I think I've covered my bases as well as I can, and from what I understand of the R code, I'm following the right steps.
> Not if what you posted here was your code. I think you missed a few crucials points about R syntax.


From cof at qualityexcellence.es  Mon Nov  4 16:19:51 2013
From: cof at qualityexcellence.es (Carlos Ortega)
Date: Mon, 4 Nov 2013 16:19:51 +0100
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <CAN5YmCHCEALxdDaV5XVLyM2dhxj_-tsjWi18i31AjEpqpMwUsQ@mail.gmail.com>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam>
	<CAN5YmCHCEALxdDaV5XVLyM2dhxj_-tsjWi18i31AjEpqpMwUsQ@mail.gmail.com>
Message-ID: <CAOKbq8h-yW9SxZbnGKErQFzSzHUmOCrLFO32PDgKg313zkyOpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/cc10d3a3/attachment.pl>

From jholtman at gmail.com  Mon Nov  4 16:34:02 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 04 Nov 2013 10:34:02 -0500
Subject: [R] Reading data from Excel file in r
Message-ID: <xgk11b3kt16i5wraey2dyt21.1383579242041@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/88dccad2/attachment.pl>

From babakbsn at gmail.com  Mon Nov  4 16:58:18 2013
From: babakbsn at gmail.com (Baro)
Date: Mon, 4 Nov 2013 07:58:18 -0800
Subject: [R] Reading data from Excel file in r
In-Reply-To: <xgk11b3kt16i5wraey2dyt21.1383579242041@email.android.com>
References: <xgk11b3kt16i5wraey2dyt21.1383579242041@email.android.com>
Message-ID: <CAF-JZQt2neV_FtpypNqO+9-8VE6CH2ToZ73Cn0XZ64kxpn_iZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/7331a548/attachment.pl>

From pburns at pburns.seanet.com  Mon Nov  4 17:03:10 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 04 Nov 2013 16:03:10 +0000
Subject: [R] Newbie Question: Repeatable Tasks
In-Reply-To: <7332AC7070F.000002D4jrkrideau@inbox.com>
References: <7332AC7070F.000002D4jrkrideau@inbox.com>
Message-ID: <5277C53E.6010006@pburns.seanet.com>

Breaking up the task is an excellent way
of thinking.

John's solution is probably simplest in the
short run but not necessarily best in the
long run.

How I'd do it is write a function for each
of your three tasks and then have a script
to call the functions.  There would be two
source files: one with the function definitions
and one with the script.

The advantage of functions is that they tend
to encourage breaking up tasks, and they are
more likely to be useful in more than one
instance.  They help achieve long-term laziness.

Pat

On 04/11/2013 13:09, John Kane wrote:
> Just type the commands in the Source window of RStudioo, debug,  save as a .r file and source it.
>
> I don't see any particular reason to have three scripts once everything is running correctly but you may find it useful.
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: csvirtual at gmx.de
>> Sent: Mon, 4 Nov 2013 09:34:54 +0100
>> To: r-help at r-project.org
>> Subject: [R] Newbie Question: Repeatable Tasks
>>
>> Hello mailing list,
>>
>>
>>
>> I am new to R using RStudio in Windows and I just want to have repeated
>> tasks each day but could not find an answer to that reading a lot of
>> intros,
>> scrolling through even more and reading on S.O.
>>
>>
>>
>> I connect to a database, load data, do calculation, write results to the
>> database and close connection.
>>
>>
>> Can I save what I typed into the console as a script (I just figured how
>> to
>> type into the Source window)? My idea is to have three scripts (if
>> scripts
>> are the right way to do it): one for connection, second for calculation,
>> third to close connection. Would I then call them by "source(..R)" or is
>> there a click-button-solution?
>>
>>
>>
>> I would really appreciate if someone guides me in the right direction
>> (link,
>> tutorial, example would be sufficient).
>>
>>
>>
>> Thanks for your help
>>
>> Chris
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From friendly at yorku.ca  Mon Nov  4 17:32:30 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 04 Nov 2013 11:32:30 -0500
Subject: [R] Subject: Regress multiple independent variables on multiple
 dependent variables
In-Reply-To: <1383574705.32826.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAAC1QdCS5StbTTEOtfF=JBZ2m0=27H2josNcT2_S3BrDW0EcGA@mail.gmail.com>
	<5277A6F8.9000108@yorku.ca>
	<1383574705.32826.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <5277CC1E.7080402@yorku.ca>

On 11/4/2013 9:18 AM, arun wrote:
> Hi,
>
> This gives an error.
>
> glm(cbind(O3, temp) ~ ., data=ozone)
> Error in x[good, , drop = FALSE] : (subscript) logical subscript too long
>
>
>   lm(cbind(O3, temp) ~ ., data=ozone) #works
>
Right.  With no family= specified, lm() is equivalent to what I meant. 
If this case was trapped,
the error message might have read
Error: glm() does not handle multiple responses with family=gaussian.  
Perhaps you meant to use lm()?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From sergio.fonda99 at gmail.com  Mon Nov  4 16:45:37 2013
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Mon, 4 Nov 2013 16:45:37 +0100
Subject: [R] variable standardization in manova() call
Message-ID: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>

Hi,
I'm not able to get information about the following question:

is the variables standardization a default option in manova() (stats package)?
Or if you want to compare variables with different units or scales and
rather different variances, you have to previously standardize the
variables ?

Thanks a lot for any help,

Sergio Fonda
www.unimore.it


From steorini at gmail.com  Mon Nov  4 17:49:40 2013
From: steorini at gmail.com (Stefania Orini)
Date: Mon, 4 Nov 2013 17:49:40 +0100
Subject: [R] Fwd: mediation analysis with R
In-Reply-To: <CABTAppY4WPZXKU-pA8i2mAk5cpGUoSFLPoFqqJHJREt_PG-+og@mail.gmail.com>
References: <CABTAppY4WPZXKU-pA8i2mAk5cpGUoSFLPoFqqJHJREt_PG-+og@mail.gmail.com>
Message-ID: <CABTAppbD5-0y3Xc79LZFo0waLOz9xgLVnEh+7Z3Gb=+x+F0rGg@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/739bd002/attachment.pl>

From timo_schmid at hotmail.com  Mon Nov  4 19:29:42 2013
From: timo_schmid at hotmail.com (Timo Schmid)
Date: Mon, 4 Nov 2013 19:29:42 +0100
Subject: [R] Strange results using match and which function
Message-ID: <DUB115-W3418373EFF2DB6EF842C5397F60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/d6ad9e3c/attachment.pl>

From gunter.berton at gene.com  Mon Nov  4 19:34:28 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 4 Nov 2013 10:34:28 -0800
Subject: [R] Strange results using match and which function
In-Reply-To: <DUB115-W3418373EFF2DB6EF842C5397F60@phx.gbl>
References: <DUB115-W3418373EFF2DB6EF842C5397F60@phx.gbl>
Message-ID: <CACk-te1Yezm=4iU55xC7uDJbq0T=ZOYsVaZ2V=hkU5umDuXUTA@mail.gmail.com>

R FAQ 7.31 .

-- Bert

On Mon, Nov 4, 2013 at 10:29 AM, Timo Schmid <timo_schmid at hotmail.com> wrote:
> Hello,
> I want to match specific numbers and a vector. Therefore I use the match or which function but I get unreasonable results. Has anybody an idea why I got a NA inmatch(0.12, tau)Please see the code below:
>
>> tau<-seq(0.02,0.98,0.02)
>> tau
>  [1] 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 0.38 0.40
> [21] 0.42 0.44 0.46 0.48 0.50 0.52 0.54 0.56 0.58 0.60 0.62 0.64 0.66 0.68 0.70 0.72 0.74 0.76 0.78 0.80
> [41] 0.82 0.84 0.86 0.88 0.90 0.92 0.94 0.96 0.98
>> match(0.02, tau)
> [1] 1
>> match(0.12, tau)
> [1] NA
>> match(0.16, tau)
> [1] 8
>>
>> which(0.12==tau)
> integer(0)
>> which(0.16==tau)
> [1] 8
>>
>> 0.14%in%tau
> [1] FALSE
>> 0.16%in%tau
> [1] TRUE
>
>
>
> Thanks in advance
> Timo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From nicolas.gutierrez at msc.org  Mon Nov  4 18:52:02 2013
From: nicolas.gutierrez at msc.org (Nicolas Gutierrez)
Date: Mon, 4 Nov 2013 17:52:02 +0000
Subject: [R] alternative for shell() in Mac
Message-ID: <AF61DB59-903C-42CF-AE14-4856F612AA89@msc.org>

Hi All,

I'm trying to run an ADMB function on R for Mac and need to find a substitute for the Windows command shell(). I tried system() but I get the following message:

> system(ADMBFile)
/bin/sh: /Users/nicolas/Desktop/SPE/LBSPR_ADMB/L_AFun.exe: cannot execute binary file

Any hints please?

Cheers,

N
This e-mail and any accompanying documents contain confidential information intended for a specific individual or company. This information is private and protected by law. If you are not the intended recipient, you are hereby notified that any disclosure, copying or distribution, or the taking of any action based on the contents of this information, is strictly prohibited. You are also requested to advise us immediately if you receive information not addressed to you.


From dwinsemius at comcast.net  Mon Nov  4 19:49:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 Nov 2013 10:49:28 -0800
Subject: [R] alternative for shell() in Mac
In-Reply-To: <AF61DB59-903C-42CF-AE14-4856F612AA89@msc.org>
References: <AF61DB59-903C-42CF-AE14-4856F612AA89@msc.org>
Message-ID: <96539262-82DE-4551-9E69-A67672B76C67@comcast.net>


On Nov 4, 2013, at 9:52 AM, Nicolas Gutierrez wrote:

> Hi All,
> 
> I'm trying to run an ADMB function on R for Mac and need to find a substitute for the Windows command shell(). I tried system() but I get the following message:
> 
>> system(ADMBFile)
> /bin/sh: /Users/nicolas/Desktop/SPE/LBSPR_ADMB/L_AFun.exe: cannot execute binary file
> 
> Any hints please?
> 

Generally one would enclose system commands in quotes. Is ADMBFile a character object? If so what is its value?
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Mon Nov  4 19:52:51 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 4 Nov 2013 18:52:51 +0000
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <op.w50q3raozqkd1e@bam>
References: <op.w5tse2qzzqkd1e@bam>	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam>
Message-ID: <5277ED03.20302@sapo.pt>

Hello,

If you want to get rid of the (bp) stuff, you can use lapply/gsub. Using 
Jean's code a bit changed,

library(XML)

mylines <- readLines(url("http://bit.ly/1coCohq"))
closeAllConnections()
mytable <- readHTMLTable(mylines, which = 2, asText=TRUE, 
stringsAsFactors = FALSE)

str(mytable)

mytable[] <- lapply(mytable, function(x) gsub("\\(.*\\)", "", x))
mytable[] <- lapply(mytable, function(x) gsub(",", "", x))
mytable[] <- lapply(mytable, as.numeric)

colnames(mytable) <- 2000:2013


Hope this helps,

Rui Barradas

Em 04-11-2013 09:53, Lorenzo Isella escreveu:
> Hello,
> And thanks a lot.
> This is indeed very close to what I need.
> I am trying to figure out how not to "lose" the headers and how to avoid
> downloading labels like "(p)" together with the numerical data I am
> interested in.
> If anyone on the list knows how to make this minor modifications, s/he
> will make my life much easier.
> Cheers
>
> Lorenzo
>
>
> On Fri, 01 Nov 2013 14:25:49 +0100, Adams, Jean <jvadams at usgs.gov> wrote:
>
>> Lorenzo,
>>
>> I may be able to help you get started.  You can use the XML package to
>> grab the information >off the internet.
>>
>> library(XML)
>>
>> mylines <- readLines(url("http://bit.ly/1coCohq"))
>> closeAllConnections()mylist <- readHTMLTable(mylines,
>> asText=TRUE)mytable <- mylist1$xTable
>>
>> However, when I look at the resulting object, mytable, it doesn't have
>> informative row or >column headings.  Perhaps someone else can figure
>> out how to get that information.
>>
>> Jean
>>
>>
>>
>>
>>
>> On Thu, Oct 31, 2013 at 10:38 AM, Lorenzo Isella
>> <lorenzo.isella at gmail.com> wrote:
>>> Dear All,
>>> I often need to do some work on some data which is publicly available
>>> on the EUROSTAT >>website.
>>> I saw several ways to download automatically mainly the bulk data
>>> from EUROSTAT to later on >>postprocess it with R, for instance
>>>
>>> http://bit.ly/HrDICj
>>> http://bit.ly/HrDL10
>>> http://bit.ly/HrDTgT
>>>
>>> However, what I would like to do is to be able to download directly
>>> the csv file >>corresponding to a properly formatted dataset
>>> (typically a dynamic dataset) from EUROSTAT.
>>> To fix the ideas, please consider the dataset at the following link
>>>
>>> http://bit.ly/1coCohq
>>>
>>> what I would like to do is to automatically read its content into R,
>>> or at least to >>automatically download it as a csv file (full
>>> extraction, single file, no flags and >>footnotes) which I can then
>>> manipulate easily.
>>> Any suggestion is appreciated.
>>> Cheers
>>>
>>> Lorenzo
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Nov  4 19:52:58 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 4 Nov 2013 13:52:58 -0500
Subject: [R] Strange results using match and which function
In-Reply-To: <DUB115-W3418373EFF2DB6EF842C5397F60@phx.gbl>
References: <DUB115-W3418373EFF2DB6EF842C5397F60@phx.gbl>
Message-ID: <CAM_vjumqPG-QONPqWjLx7wRaGydsK8YXgPVv+gbS9gFeQ2MqjA@mail.gmail.com>

This looks like R FAQ 7.31, the one so commonly asked that regulars on
this list have its number memorized!

>  tau<-seq(0.02,0.98,0.02)
> match(round(0.12, 2), round(tau, 2))
[1] 6
> match(round(0.16, 2), round(tau, 2))
[1] 8

See also ?all.equal

Sarah

On Mon, Nov 4, 2013 at 1:29 PM, Timo Schmid <timo_schmid at hotmail.com> wrote:
> Hello,
> I want to match specific numbers and a vector. Therefore I use the match or which function but I get unreasonable results. Has anybody an idea why I got a NA inmatch(0.12, tau)Please see the code below:
>
>> tau<-seq(0.02,0.98,0.02)
>> tau
>  [1] 0.02 0.04 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.22 0.24 0.26 0.28 0.30 0.32 0.34 0.36 0.38 0.40
> [21] 0.42 0.44 0.46 0.48 0.50 0.52 0.54 0.56 0.58 0.60 0.62 0.64 0.66 0.68 0.70 0.72 0.74 0.76 0.78 0.80
> [41] 0.82 0.84 0.86 0.88 0.90 0.92 0.94 0.96 0.98
>> match(0.02, tau)
> [1] 1
>> match(0.12, tau)
> [1] NA
>> match(0.16, tau)
> [1] 8
>>
>> which(0.12==tau)
> integer(0)
>> which(0.16==tau)
> [1] 8
>>
>> 0.14%in%tau
> [1] FALSE
>> 0.16%in%tau
> [1] TRUE
>
>
>
> Thanks in advance
> Timo
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Mon Nov  4 19:57:52 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 04 Nov 2013 12:57:52 -0600
Subject: [R] alternative for shell() in Mac
In-Reply-To: <AF61DB59-903C-42CF-AE14-4856F612AA89@msc.org>
References: <AF61DB59-903C-42CF-AE14-4856F612AA89@msc.org>
Message-ID: <E613EC95-8114-4D87-B6FE-DE4F12FA9A9C@me.com>

On Nov 4, 2013, at 11:52 AM, Nicolas Gutierrez <nicolas.gutierrez at msc.org> wrote:

> Hi All,
> 
> I'm trying to run an ADMB function on R for Mac and need to find a substitute for the Windows command shell(). I tried system() but I get the following message:
> 
>> system(ADMBFile)
> /bin/sh: /Users/nicolas/Desktop/SPE/LBSPR_ADMB/L_AFun.exe: cannot execute binary file
> 
> Any hints please?
> 
> Cheers,
> 
> N


Why would you expect a Windows executable file (L_AFun.exe) to run on a non-Windows operating system?

This is not related to the system call, but that you are trying to run the wrong executable.

ADMB is presumably associated with AD Model Builder and you may be better off posting to the r-sig-mixed-models list:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models


Regards,

Marc Schwartz


From lorenzo.isella at gmail.com  Mon Nov  4 20:03:39 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 4 Nov 2013 20:03:39 +0100
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <5277ED03.20302@sapo.pt>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam> <5277ED03.20302@sapo.pt>
Message-ID: <op.w51gkdmdzqkd1e@nirvana>

Thanks.
I had already introduced this minor adjustments in the code, but the real  
problem (to me) is the information that gets lost: the informative name of  
the columns, the indicator type and the units.
Cheers

Lorenzo

On Mon, 04 Nov 2013 19:52:51 +0100, Rui Barradas <ruipbarradas at sapo.pt>  
wrote:

> Hello,
>
> If you want to get rid of the (bp) stuff, you can use lapply/gsub. Using  
> Jean's code a bit changed,
>
> library(XML)
>
> mylines <- readLines(url("http://bit.ly/1coCohq"))
> closeAllConnections()
> mytable <- readHTMLTable(mylines, which = 2, asText=TRUE,  
> stringsAsFactors = FALSE)
>
> str(mytable)
>
> mytable[] <- lapply(mytable, function(x) gsub("\\(.*\\)", "", x))
> mytable[] <- lapply(mytable, function(x) gsub(",", "", x))
> mytable[] <- lapply(mytable, as.numeric)
>
> colnames(mytable) <- 2000:2013
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 04-11-2013 09:53, Lorenzo Isella escreveu:
>> Hello,
>> And thanks a lot.
>> This is indeed very close to what I need.
>> I am trying to figure out how not to "lose" the headers and how to avoid
>> downloading labels like "(p)" together with the numerical data I am
>> interested in.
>> If anyone on the list knows how to make this minor modifications, s/he
>> will make my life much easier.
>> Cheers
>>
>> Lorenzo
>>
>>
>> On Fri, 01 Nov 2013 14:25:49 +0100, Adams, Jean <jvadams at usgs.gov>  
>> wrote:
>>
>>> Lorenzo,
>>>
>>> I may be able to help you get started.  You can use the XML package to
>>> grab the information >off the internet.
>>>
>>> library(XML)
>>>
>>> mylines <- readLines(url("http://bit.ly/1coCohq"))
>>> closeAllConnections()mylist <- readHTMLTable(mylines,
>>> asText=TRUE)mytable <- mylist1$xTable
>>>
>>> However, when I look at the resulting object, mytable, it doesn't have
>>> informative row or >column headings.  Perhaps someone else can figure
>>> out how to get that information.
>>>
>>> Jean
>>>
>>>
>>>
>>>
>>>
>>> On Thu, Oct 31, 2013 at 10:38 AM, Lorenzo Isella
>>> <lorenzo.isella at gmail.com> wrote:
>>>> Dear All,
>>>> I often need to do some work on some data which is publicly available
>>>> on the EUROSTAT >>website.
>>>> I saw several ways to download automatically mainly the bulk data
>>>> from EUROSTAT to later on >>postprocess it with R, for instance
>>>>
>>>> http://bit.ly/HrDICj
>>>> http://bit.ly/HrDL10
>>>> http://bit.ly/HrDTgT
>>>>
>>>> However, what I would like to do is to be able to download directly
>>>> the csv file >>corresponding to a properly formatted dataset
>>>> (typically a dynamic dataset) from EUROSTAT.
>>>> To fix the ideas, please consider the dataset at the following link
>>>>
>>>> http://bit.ly/1coCohq
>>>>
>>>> what I would like to do is to automatically read its content into R,
>>>> or at least to >>automatically download it as a csv file (full
>>>> extraction, single file, no flags and >>footnotes) which I can then
>>>> manipulate easily.
>>>> Any suggestion is appreciated.
>>>> Cheers
>>>>
>>>> Lorenzo
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Nov  4 20:26:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 Nov 2013 11:26:46 -0800
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <op.w51gkdmdzqkd1e@nirvana>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam> <5277ED03.20302@sapo.pt>
	<op.w51gkdmdzqkd1e@nirvana>
Message-ID: <AA43EB7E-4719-4BD6-B4BD-48CEAB224ECF@comcast.net>


On Nov 4, 2013, at 11:03 AM, Lorenzo Isella wrote:

> Thanks.
> I had already introduced this minor adjustments in the code, but the real problem (to me) is the information that gets lost: the informative name of the columns, the indicator type and the units.

Maybe you should use their "download" facility rather than trying to deparse a complex webpage with lots of special user interaction "features":

http://appsso.eurostat.ec.europa.eu/nui/setupDownloads.do

-- 
David.

> Cheers
> 
> Lorenzo
> 
> On Mon, 04 Nov 2013 19:52:51 +0100, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
>> Hello,
>> 
>> If you want to get rid of the (bp) stuff, you can use lapply/gsub. Using Jean's code a bit changed,
>> 
>> library(XML)
>> 
>> mylines <- readLines(url("http://bit.ly/1coCohq"))
>> closeAllConnections()
>> mytable <- readHTMLTable(mylines, which = 2, asText=TRUE, stringsAsFactors = FALSE)
>> 
>> str(mytable)
>> 
>> mytable[] <- lapply(mytable, function(x) gsub("\\(.*\\)", "", x))
>> mytable[] <- lapply(mytable, function(x) gsub(",", "", x))
>> mytable[] <- lapply(mytable, as.numeric)
>> 
>> colnames(mytable) <- 2000:2013
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 04-11-2013 09:53, Lorenzo Isella escreveu:
>>> Hello,
>>> And thanks a lot.
>>> This is indeed very close to what I need.
>>> I am trying to figure out how not to "lose" the headers and how to avoid
>>> downloading labels like "(p)" together with the numerical data I am
>>> interested in.
>>> If anyone on the list knows how to make this minor modifications, s/he
>>> will make my life much easier.
>>> Cheers
>>> 
>>> Lorenzo
>>> 
>>> 
>>> On Fri, 01 Nov 2013 14:25:49 +0100, Adams, Jean <jvadams at usgs.gov> wrote:
>>> 
>>>> Lorenzo,
>>>> 
>>>> I may be able to help you get started.  You can use the XML package to
>>>> grab the information >off the internet.
>>>> 
>>>> library(XML)
>>>> 
>>>> mylines <- readLines(url("http://bit.ly/1coCohq"))
>>>> closeAllConnections()mylist <- readHTMLTable(mylines,
>>>> asText=TRUE)mytable <- mylist1$xTable
>>>> 
>>>> However, when I look at the resulting object, mytable, it doesn't have
>>>> informative row or >column headings.  Perhaps someone else can figure
>>>> out how to get that information.
>>>> 
>>>> Jean
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On Thu, Oct 31, 2013 at 10:38 AM, Lorenzo Isella
>>>> <lorenzo.isella at gmail.com> wrote:
>>>>> Dear All,
>>>>> I often need to do some work on some data which is publicly available
>>>>> on the EUROSTAT >>website.
>>>>> I saw several ways to download automatically mainly the bulk data
>>>>> from EUROSTAT to later on >>postprocess it with R, for instance
>>>>> 
>>>>> http://bit.ly/HrDICj
>>>>> http://bit.ly/HrDL10
>>>>> http://bit.ly/HrDTgT
>>>>> 
>>>>> However, what I would like to do is to be able to download directly
>>>>> the csv file >>corresponding to a properly formatted dataset
>>>>> (typically a dynamic dataset) from EUROSTAT.
>>>>> To fix the ideas, please consider the dataset at the following link
>>>>> 
>>>>> http://bit.ly/1coCohq
>>>>> 
>>>>> what I would like to do is to automatically read its content into R,
>>>>> or at least to >>automatically download it as a csv file (full
>>>>> extraction, single file, no flags and >>footnotes) which I can then
>>>>> manipulate easily.
>>>>> Any suggestion is appreciated.
>>>>> Cheers
>>>>> 
>>>>> Lorenzo
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cs_2002 at hotmail.com  Mon Nov  4 20:14:52 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Mon, 4 Nov 2013 19:14:52 +0000
Subject: [R] transform one probability distribution into another
Message-ID: <DUB406-EAS179788A29CD405E8C3F2FAA80F60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/29f3cc42/attachment.pl>

From ruipbarradas at sapo.pt  Mon Nov  4 20:54:27 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 4 Nov 2013 19:54:27 +0000
Subject: [R] transform one probability distribution into another
In-Reply-To: <DUB406-EAS179788A29CD405E8C3F2FAA80F60@phx.gbl>
References: <DUB406-EAS179788A29CD405E8C3F2FAA80F60@phx.gbl>
Message-ID: <5277FB73.1070200@sapo.pt>

Hello,

At an R prompt type

?rexp

Also, read An Introduction to R, file R-intro.pdf that comes with your 
distribution of R, namely, chapter 8 Probability distributions.

Hope this helps,

Rui Barradas

Em 04-11-2013 19:14, b. alzahrani escreveu:
>
> Hi guys
>
> Given a exponential curve, is there any function on r that can generate exponential distributed random numbers?
>
> in General I want an function that can transform one probability distribution into another??
>
> Regards
> ******************************************************************
> Bander
>   *************************************
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tlumley at uw.edu  Mon Nov  4 21:20:59 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Tue, 5 Nov 2013 09:20:59 +1300
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <52742737.7020609@fhcrc.org>
References: <5273AD7E.6090607@gmail.com>
	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>
	<5273C73D.2090809@gmail.com> <52742737.7020609@fhcrc.org>
Message-ID: <CAJ55+dLPe5uqyYVzi7qHh2w6GzfWBV6sm398qv7UENEPNmnALA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/b63eebf9/attachment.pl>

From 538280 at gmail.com  Mon Nov  4 21:35:10 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 4 Nov 2013 13:35:10 -0700
Subject: [R] transform one probability distribution into another
In-Reply-To: <DUB406-EAS179788A29CD405E8C3F2FAA80F60@phx.gbl>
References: <DUB406-EAS179788A29CD405E8C3F2FAA80F60@phx.gbl>
Message-ID: <CAFEqCdzMhic5q3R5ZFFhtg5ZkU_Z3eND7eQXyJ3rcztrOrPmSw@mail.gmail.com>

As a general rule, the distribution functions that start with p (e.g.
pnorm, pexp, pgamma, ...) will transform a random variable from the
corresponding distribution to a uniformly distributed random variable.
 The functions that start with q (e.g. qnorm, qexp, qgamma, ...) will
transform a uniform random variable to the corresponding distribution.
 So going via the uniform distribution you can convert any
distribution to another one (provided the functions exist and you have
the correct one to begin with).  If there is not a built in function
for your distribution then you can create the appropriate
distributions from the cumulative distribution function and the
inverse cumulative distribution function  (the distr package and
friends could be of help).

But in practice if you just want to generate data from a distribution
you should look at the r functions (rnorm, rexp, regamma, ...).

On Mon, Nov 4, 2013 at 12:14 PM, b. alzahrani <cs_2002 at hotmail.com> wrote:
>
> Hi guys
>
> Given a exponential curve, is there any function on r that can generate exponential distributed random numbers?
>
> in General I want an function that can transform one probability distribution into another??
>
> Regards
> ******************************************************************
> Bander
>  *************************************
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From lorenzo.isella at gmail.com  Mon Nov  4 21:52:21 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Mon, 4 Nov 2013 21:52:21 +0100
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <AA43EB7E-4719-4BD6-B4BD-48CEAB224ECF@comcast.net>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam> <5277ED03.20302@sapo.pt>
	<op.w51gkdmdzqkd1e@nirvana>
	<AA43EB7E-4719-4BD6-B4BD-48CEAB224ECF@comcast.net>
Message-ID: <op.w51lljpmzqkd1e@nirvana>

On Mon, 04 Nov 2013 20:26:46 +0100, David Winsemius  
<dwinsemius at comcast.net> wrote:

>
> On Nov 4, 2013, at 11:03 AM, Lorenzo Isella wrote:
>
>> Thanks.
>> I had already introduced this minor adjustments in the code, but the  
>> real problem (to me) is the information that gets lost: the informative  
>> name of the columns, the indicator type and the units.
>
> Maybe you should use their "download" facility rather than trying to  
> deparse a complex webpage with lots of special user interaction  
> "features":
>
> http://appsso.eurostat.ec.europa.eu/nui/setupDownloads.do
>


Of course, for a single data set, I agree.
In my case, I need to download and analyze several tens of data sets and I  
need to be able to do this at regular time intervals, hence the need to  
automate also the download.
Cheers

Lorenzo


From yuhanusa at gmail.com  Mon Nov  4 22:05:37 2013
From: yuhanusa at gmail.com (Y)
Date: Mon, 4 Nov 2013 16:05:37 -0500
Subject: [R] Can I obtain baseline hazard estimates in the gamma frailty
 model by using coxph()?
Message-ID: <CAHJ49wiHS+vO=wAJ3PVjpNYW2AiRAs3fOYxD8GhjnrOaFx9MEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/beac0304/attachment.pl>

From smartpink111 at yahoo.com  Mon Nov  4 21:04:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 4 Nov 2013 12:04:34 -0800 (PST)
Subject: [R] R loop for applying an equation to each unique category
Message-ID: <1383595474.50700.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,You could use:
dat1 <- structure(list(Haplotype = c("H1", "H1", "H1", "H2", "H2", "H2", 
"H3", "H3", "H3", "H4", "H4", "H4", "H4", "H4", "H4"), Frequency = c(0.8278, 
0.02248, 0.1494, 0.8238, 0.02248, 0.1497, 0.1497, 0.02248, 0.8244, 
0.628, 0.02248, 0.1483, 0.1637, 0.01081, 0.01798)), .Names = c("Haplotype", 
"Frequency"), class = "data.frame", row.names = c(NA, -15L))

with(dat1,tapply(Frequency,list(Haplotype),function(x) sum(pi*x*log2(1/(pi*x)))))
?#with(dat1,tapply(Frequency,list(Haplotype),function(x) sum(pi*x*log(1/(pi*x)))))
#or
sapply(split(dat1[,-1],dat1$Haplotype),function(x) sum(pi*x*log2(1/(pi*x))))
A.K.




Hi all. I am seeking help in writing an R loop to calculate the shannon's information content (SIC) 
for every unique haplotype. The data includes the haplotypes in 
column 1 and frequency of haplotypes in column 2. As you can see in the 
example data with just 4 unique haplotypes, there are different numbers 
of each haplotype, with a frequency corresponding to each one. The 
frequency for all haplotype H* sums up to 1. The equation for SIC is 

?i (?hi*log(1/(?hi))) 

where ??hi is the frequency of the hi haplotype. 



Haplotype	Frequency 
H1	0.8278 
H1	0.02248 
H1	0.1494 
H2	0.8238 
H2	0.02248 
H2	0.1497 
H3	0.1497 
H3	0.02248 
H3	0.8244 
H4	0.628 
H4	0.02248 
H4	0.1483 
H4	0.1637 
H4	0.01081 
H4	0.01798 

In this example, the SIC for H1 would be 

(?*0.8278*log(1/(?*0.8278))) + (?*0.02248*log(1/(?*0.02248))) + (?*0.1494*log(1/(?*0.1494))) 

and the final output should give 4 SIC values, one corresponding to each unique haplotype. 

I believe using lappy() is the correct method of going foward, 
but my R skills are very elementary to know what to do next. Thank you 
for any help.

From therneau at mayo.edu  Mon Nov  4 23:29:59 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 04 Nov 2013 16:29:59 -0600
Subject: [R] How to obtain nonparametric baseline hazard estimates in
 the gamma frailty model?
In-Reply-To: <mailman.15.1383476406.25317.r-help@r-project.org>
References: <mailman.15.1383476406.25317.r-help@r-project.org>
Message-ID: <52781FE7.8050504@mayo.edu>



On 11/03/2013 05:00 AM, r-help-request at r-project.org wrote:
> I can easily get the other parameter estimates by using coxph() but don't
> know how to get the baseline hazard estimates from it. Does anyone know how
> to obtain nonparametric baseline hazard estimates in the gamma frailty
> model?
>
> Thanks,
> YH
>

I don't see what the problem is.

  fit1 <- coxph(Surv(time, status) ~ age + ph.ecog + frailty(inst), data=lung)
  sfit <- survfit(fit1)
  plot(sfit)


Please give an actual example of the problem.

Terry Therneau


From yuhanusa at gmail.com  Mon Nov  4 23:47:51 2013
From: yuhanusa at gmail.com (Y)
Date: Mon, 4 Nov 2013 17:47:51 -0500
Subject: [R] How to obtain nonparametric baseline hazard estimates in
 the gamma frailty model?
In-Reply-To: <52781FE7.8050504@mayo.edu>
References: <mailman.15.1383476406.25317.r-help@r-project.org>
	<52781FE7.8050504@mayo.edu>
Message-ID: <CAHJ49wgPAfJQ_w49nfjvTp3pdFaDqQ4LMi4eePx6oNB_5P2SOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/dd2a0d6c/attachment.pl>

From therneau at mayo.edu  Tue Nov  5 00:29:48 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 04 Nov 2013 17:29:48 -0600
Subject: [R] Fwd: Re: How to obtain nonparametric baseline hazard estimates
 in the gamma frailty model?
In-Reply-To: <52782D48.3020703@mayo.edu>
References: <52782D48.3020703@mayo.edu>
Message-ID: <52782DEC.4000602@mayo.edu>



-------- Original Message --------
Subject: Re: How to obtain nonparametric baseline hazard estimates in the gamma frailty model?
Date: Mon, 04 Nov 2013 17:27:04 -0600
From: Terry Therneau <therneau.terry at mayo.edu>
To: Y <yuhanusa at gmail.com>

The cumulative hazard is just -log(sfit$surv).
The hazard is essentially a density estimate, and that is much harder.  You'll notice that
everyone does CDF curves for survival data ( Kaplan-Meier = estimate of 1-CDF), but no one
does histograms, which estimate a density.  That isn't because we wouldn't like density
estimates.

Terry T.


On 11/04/2013 04:47 PM, Y wrote:
> Hi Dr. Therneau,
>
> Thanks very much for your kind help! Does survfit() just give me the survival curve? What
> I wanted is the baseline hazard estimates, i.e., lambda_{0} (t). How can I obtain this
> estimate from coxph()? Or using basehaz()?
>
> Thanks,
> YH
>
>
>
>
>
>
>
>
>
>
> On Mon, Nov 4, 2013 at 5:29 PM, Terry Therneau <therneau at mayo.edu
> <mailto:therneau at mayo.edu>> wrote:
>
>
>
>     On 11/03/2013 05:00 AM, r-help-request at r-project.org
>     <mailto:r-help-request at r-project.org> wrote:
>
>         I can easily get the other parameter estimates by using coxph() but don't
>         know how to get the baseline hazard estimates from it. Does anyone know how
>         to obtain nonparametric baseline hazard estimates in the gamma frailty
>         model?
>
>         Thanks,
>         YH
>
>
>     I don't see what the problem is.
>
>     fit1 <- coxph(Surv(time, status) ~ age + ph.ecog + frailty(inst), data=lung)
>     sfit <- survfit(fit1)
>     plot(sfit)
>
>
>     Please give an actual example of the problem.
>
>     Terry Therneau
>
>


From yuhanusa at gmail.com  Tue Nov  5 03:48:07 2013
From: yuhanusa at gmail.com (Y)
Date: Mon, 4 Nov 2013 21:48:07 -0500
Subject: [R] How to obtain nonparametric baseline hazard estimates in
 the gamma frailty model?
In-Reply-To: <52782D48.3020703@mayo.edu>
References: <mailman.15.1383476406.25317.r-help@r-project.org>
	<52781FE7.8050504@mayo.edu>
	<CAHJ49wgPAfJQ_w49nfjvTp3pdFaDqQ4LMi4eePx6oNB_5P2SOw@mail.gmail.com>
	<52782D48.3020703@mayo.edu>
Message-ID: <CAHJ49wgy0manbQV-argUKSp_Yt5erx8A7p5CC8EUpcLbbj7W2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131104/c1b931d8/attachment.pl>

From simon.pickert at t-online.de  Mon Nov  4 23:57:10 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Mon, 4 Nov 2013 23:57:10 +0100
Subject: [R] speed issue: gsub on large data frame
Message-ID: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>

Hi R?lers,

I?m running into speeding issues, performing a bunch of 

?gsub(patternvector, [token],dataframe$text_column)"

on a data frame containing >4millionentries.

(The ?patternvectors? contain up to 500 elements) 

Is there any better/faster way than performing like 20 gsub commands in a row?


Thanks!
Simon


From jdnewmil at dcn.davis.CA.us  Tue Nov  5 06:59:31 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 04 Nov 2013 21:59:31 -0800
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
Message-ID: <5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>

Example not reproducible. Communication fail. Please refer to Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Simon Pickert <simon.pickert at t-online.de> wrote:
>Hi R?lers,
>
>I?m running into speeding issues, performing a bunch of 
>
>?gsub(patternvector, [token],dataframe$text_column)"
>
>on a data frame containing >4millionentries.
>
>(The ?patternvectors? contain up to 500 elements) 
>
>Is there any better/faster way than performing like 20 gsub commands in
>a row?
>
>
>Thanks!
>Simon
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Nov  5 09:31:16 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 05 Nov 2013 00:31:16 -0800
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
Message-ID: <e6ccc3b3-ea29-4809-be85-7d998abe3cb2@email.android.com>

It is not reproducible [1] because I cannot run your (representative) example. The type of regex pattern,  token, and even the character of the data you are searching can affect possible optimizations. Note that a non-memory-resident tool such as sed or perl may be an appropriate tool for a problem like this.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Simon Pickert <simon.pickert at t-online.de> wrote:
>How?s that not reproducible?
>
>1. Data frame, one column with text strings
>2. Size of data frame= 4million observations
>3. A bunch of gsubs in a row (  gsub(patternvector,
>?[token]?,dataframe$text_column)  )
>4. General question: How to speed up string operations on ?large' data
>sets?
>
>
>Please let me know what more information you need in order to reproduce
>this example? 
>It?s more a general type of question, while I think the description
>above gives you a specific picture of what I?m doing right now.
>
>
>
>
>
>
>General question: 
>Am 05.11.2013 um 06:59 schrieb Jeff Newmiller
><jdnewmil at dcn.davis.CA.us>:
>
>> Example not reproducible. Communication fail. Please refer to Posting
>Guide.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> Simon Pickert <simon.pickert at t-online.de> wrote:
>>> Hi R?lers,
>>> 
>>> I?m running into speeding issues, performing a bunch of 
>>> 
>>> ?gsub(patternvector, [token],dataframe$text_column)"
>>> 
>>> on a data frame containing >4millionentries.
>>> 
>>> (The ?patternvectors? contain up to 500 elements) 
>>> 
>>> Is there any better/faster way than performing like 20 gsub commands
>in
>>> a row?
>>> 
>>> 
>>> Thanks!
>>> Simon
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From simon.pickert at t-online.de  Tue Nov  5 09:13:12 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Tue, 5 Nov 2013 09:13:12 +0100
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
Message-ID: <2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>

How?s that not reproducible?

1. Data frame, one column with text strings
2. Size of data frame= 4million observations
3. A bunch of gsubs in a row (  gsub(patternvector, ?[token]?,dataframe$text_column)  )
4. General question: How to speed up string operations on ?large' data sets?


Please let me know what more information you need in order to reproduce this example? 
It?s more a general type of question, while I think the description above gives you a specific picture of what I?m doing right now.






General question: 
Am 05.11.2013 um 06:59 schrieb Jeff Newmiller <jdnewmil at dcn.davis.CA.us>:

> Example not reproducible. Communication fail. Please refer to Posting Guide.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Simon Pickert <simon.pickert at t-online.de> wrote:
>> Hi R?lers,
>> 
>> I?m running into speeding issues, performing a bunch of 
>> 
>> ?gsub(patternvector, [token],dataframe$text_column)"
>> 
>> on a data frame containing >4millionentries.
>> 
>> (The ?patternvectors? contain up to 500 elements) 
>> 
>> Is there any better/faster way than performing like 20 gsub commands in
>> a row?
>> 
>> 
>> Thanks!
>> Simon
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jholtman at gmail.com  Tue Nov  5 10:06:26 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Tue, 5 Nov 2013 04:06:26 -0500
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
Message-ID: <50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>

what is missing is any idea of what the 'patterns' are that you are searching for.  Regular expressions are very sensitive to how you specify the pattern.  you indicated that you have up to 500 elements in the pattern, so what does it look like?  alternation and backtracking can be very expensive.  so a lot more specificity is required.  there are whole books written on how pattern matching works and what is hard and what is easy.  this is true for wherever regular expressions are used, not just in R.  also some idea of what the timing is; are you talking about 1-10-100 seconds/minutes/hours.

Sent from my iPad

On Nov 5, 2013, at 3:13, Simon Pickert <simon.pickert at t-online.de> wrote:

> How?s that not reproducible?
> 
> 1. Data frame, one column with text strings
> 2. Size of data frame= 4million observations
> 3. A bunch of gsubs in a row (  gsub(patternvector, ?[token]?,dataframe$text_column)  )
> 4. General question: How to speed up string operations on ?large' data sets?
> 
> 
> Please let me know what more information you need in order to reproduce this example? 
> It?s more a general type of question, while I think the description above gives you a specific picture of what I?m doing right now.
> 
> 
> 
> 
> 
> 
> General question: 
> Am 05.11.2013 um 06:59 schrieb Jeff Newmiller <jdnewmil at dcn.davis.CA.us>:
> 
>> Example not reproducible. Communication fail. Please refer to Posting Guide.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                     Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> --------------------------------------------------------------------------- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> Simon Pickert <simon.pickert at t-online.de> wrote:
>>> Hi R?lers,
>>> 
>>> I?m running into speeding issues, performing a bunch of 
>>> 
>>> ?gsub(patternvector, [token],dataframe$text_column)"
>>> 
>>> on a data frame containing >4millionentries.
>>> 
>>> (The ?patternvectors? contain up to 500 elements) 
>>> 
>>> Is there any better/faster way than performing like 20 gsub commands in
>>> a row?
>>> 
>>> 
>>> Thanks!
>>> Simon
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From babakbsn at gmail.com  Tue Nov  5 10:18:49 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 01:18:49 -0800
Subject: [R] Reading only one Column of an excel file using RODBC
Message-ID: <CAF-JZQt4hDOpQc8U7mBNDo9rsRcPGuYtwCq510vHQLGUhbOrJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/cc564dc3/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Nov  5 11:31:31 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 05 Nov 2013 10:31:31 +0000
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
Message-ID: <5278C903.8080805@stats.ox.ac.uk>

But note too what the help says:

Performance considerations:

      If you are doing a lot of regular expression matching, including
      on very long strings, you will want to consider the options used.
      Generally PCRE will be faster than the default regular expression
      engine, and ?fixed = TRUE? faster still (especially when each
      pattern is matched only a few times).

(and there is more).  I don't see perl=TRUE here.

On 05/11/2013 09:06, Jim Holtman wrote:
> what is missing is any idea of what the 'patterns' are that you are searching for.  Regular expressions are very sensitive to how you specify the pattern.  you indicated that you have up to 500 elements in the pattern, so what does it look like?  alternation and backtracking can be very expensive.  so a lot more specificity is required.  there are whole books written on how pattern matching works and what is hard and what is easy.  this is true for wherever regular expressions are used, not just in R.  also some idea of what the timing is; are you talking about 1-10-100 seconds/minutes/hours.
>
> Sent from my iPad
>
> On Nov 5, 2013, at 3:13, Simon Pickert <simon.pickert at t-online.de> wrote:
>
>> How?s that not reproducible?
>>
>> 1. Data frame, one column with text strings
>> 2. Size of data frame= 4million observations
>> 3. A bunch of gsubs in a row (  gsub(patternvector, ?[token]?,dataframe$text_column)  )
>> 4. General question: How to speed up string operations on ?large' data sets?
>>
>>
>> Please let me know what more information you need in order to reproduce this example?
>> It?s more a general type of question, while I think the description above gives you a specific picture of what I?m doing right now.
>>
>>
>>
>>
>>
>>
>> General question:
>> Am 05.11.2013 um 06:59 schrieb Jeff Newmiller <jdnewmil at dcn.davis.CA.us>:
>>
>>> Example not reproducible. Communication fail. Please refer to Posting Guide.
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> Simon Pickert <simon.pickert at t-online.de> wrote:
>>>> Hi R?lers,
>>>>
>>>> I?m running into speeding issues, performing a bunch of
>>>>
>>>> ?gsub(patternvector, [token],dataframe$text_column)"
>>>>
>>>> on a data frame containing >4millionentries.
>>>>
>>>> (The ?patternvectors? contain up to 500 elements)
>>>>
>>>> Is there any better/faster way than performing like 20 gsub commands in
>>>> a row?
>>>>
>>>>
>>>> Thanks!
>>>> Simon
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mohan.radhakrishnan at polarisft.com  Tue Nov  5 11:31:44 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 5 Nov 2013 16:01:44 +0530
Subject: [R] All curves with same y-axis scale
In-Reply-To: <52781C57.5000705@bitwrit.com.au>
References: <OFAFDDA7B3.0A5D88DF-ON65257C19.0035CB83-65257C19.00366CA5@polarisft.com>
	<52778147.60009@bitwrit.com.au>
	<OF5F9F68F5.52E7A93D-ON65257C19.0041DB57-65257C19.00425596@polarisft.com>
	<52781C57.5000705@bitwrit.com.au>
Message-ID: <OFBB39C0D5.B704B1F4-ON65257C1A.00398690-65257C1A.0039D244@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/cf6548dd/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Nov  5 11:33:11 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 05 Nov 2013 10:33:11 +0000
Subject: [R] Reading only one Column of an excel file using RODBC
In-Reply-To: <CAF-JZQt4hDOpQc8U7mBNDo9rsRcPGuYtwCq510vHQLGUhbOrJg@mail.gmail.com>
References: <CAF-JZQt4hDOpQc8U7mBNDo9rsRcPGuYtwCq510vHQLGUhbOrJg@mail.gmail.com>
Message-ID: <5278C967.6030209@stats.ox.ac.uk>

On 05/11/2013 09:18, Baro wrote:
> Hi experts
>
> How can I read only one column of an excel file using RODBC in r?

The same way as for any other ODBC client: by selecting it in SQL.

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do (no HTML, a reproducible example and tell us what you tried).



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From babakbsn at gmail.com  Tue Nov  5 11:41:04 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 02:41:04 -0800
Subject: [R] Reading only one Column of an excel file using RODBC
In-Reply-To: <5278C967.6030209@stats.ox.ac.uk>
References: <CAF-JZQt4hDOpQc8U7mBNDo9rsRcPGuYtwCq510vHQLGUhbOrJg@mail.gmail.com>
	<5278C967.6030209@stats.ox.ac.uk>
Message-ID: <CAF-JZQvTZk4bk4OvtQAZ2uwB-ZCzpdMZfHX9n==ix6GTe_2Q3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/a2bf9ff5/attachment.pl>

From zhyuanzh at gmail.com  Tue Nov  5 11:42:22 2013
From: zhyuanzh at gmail.com (Zhong-Yuan Zhang)
Date: Tue, 5 Nov 2013 18:42:22 +0800
Subject: [R]  Function does not see variables outside the function
Message-ID: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/27061d07/attachment.pl>

From jianfeng.mao at gmail.com  Tue Nov  5 11:38:59 2013
From: jianfeng.mao at gmail.com (Mao Jianfeng)
Date: Tue, 5 Nov 2013 02:38:59 -0800
Subject: [R] fail to install packages in R3.0.2 running in Redhat linux
Message-ID: <CAAU6gard5uGbNXv85meDAjuMoHSYdN_2qBBDQh6jX5uC5Kb1cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/0522a760/attachment.pl>

From ishaqbaba at yahoo.com  Tue Nov  5 11:56:39 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Tue, 5 Nov 2013 02:56:39 -0800 (PST)
Subject: [R] regession code
Message-ID: <1383648999.92680.YahooMailNeo@web142503.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/34b8d190/attachment.pl>

From simon.pickert at t-online.de  Tue Nov  5 13:18:10 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Tue, 5 Nov 2013 13:18:10 +0100
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <5278C903.8080805@stats.ox.ac.uk>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
	<5278C903.8080805@stats.ox.ac.uk>
Message-ID: <80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>

Thanks everybody! Now I understand the need for more details:

the patterns for the gsubs are of different kinds.First, I have character strings, I need to replace. Therefore, I have around 5000 stock ticker symbols (e.g. c(?AAPL?, ?EBAY?,?) distributed across 10 vectors. 
Second, I have four vectors with regular expressions, all similar to this on: replace_url <- c(?https?://.*\\s|www.*\\s?) 

The text strings I perform the gsub commands on, look like this (no string is longer than 200 characters):

'GOOGL announced new partnership www.url.com. Stock price is up +5%?

After performing several gsubs in a row, like

gsub(replace_url, ?[url]?,dataframe$text_column) 
gsub(replace_ticker_sp500, ?[sp500_ticker]?,dataframe$text_column) 
etc. 

this string will look like this:

'[sp500_ticker] announced new partnership [url]. Stock price is up [positive_percentage]?


The dataset contains 4 million entries. The code works, but I I cancelled the process after 1 day (my whole system was blocked while R was running). Performing the code on a smaller chunck of data (1 million) took about 12hrs. As far as I can say, replacing the ticker symbols takes the longest, while the regular expressions went quite fast

Thanks!



Am 05.11.2013 um 11:31 schrieb Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> But note too what the help says:
> 
> Performance considerations:
> 
>     If you are doing a lot of regular expression matching, including
>     on very long strings, you will want to consider the options used.
>     Generally PCRE will be faster than the default regular expression
>     engine, and ?fixed = TRUE? faster still (especially when each
>     pattern is matched only a few times).
> 
> (and there is more).  I don't see perl=TRUE here.
> 
> On 05/11/2013 09:06, Jim Holtman wrote:
>> what is missing is any idea of what the 'patterns' are that you are searching for.  Regular expressions are very sensitive to how you specify the pattern.  you indicated that you have up to 500 elements in the pattern, so what does it look like?  alternation and backtracking can be very expensive.  so a lot more specificity is required.  there are whole books written on how pattern matching works and what is hard and what is easy.  this is true for wherever regular expressions are used, not just in R.  also some idea of what the timing is; are you talking about 1-10-100 seconds/minutes/hours.
>> 
>> Sent from my iPad
>> 
>> On Nov 5, 2013, at 3:13, Simon Pickert <simon.pickert at t-online.de> wrote:
>> 
>>> How?s that not reproducible?
>>> 
>>> 1. Data frame, one column with text strings
>>> 2. Size of data frame= 4million observations
>>> 3. A bunch of gsubs in a row (  gsub(patternvector, ?[token]?,dataframe$text_column)  )
>>> 4. General question: How to speed up string operations on ?large' data sets?
>>> 
>>> 
>>> Please let me know what more information you need in order to reproduce this example?
>>> It?s more a general type of question, while I think the description above gives you a specific picture of what I?m doing right now.
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> General question:
>>> Am 05.11.2013 um 06:59 schrieb Jeff Newmiller <jdnewmil at dcn.davis.CA.us>:
>>> 
>>>> Example not reproducible. Communication fail. Please refer to Posting Guide.
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>                                     Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> Simon Pickert <simon.pickert at t-online.de> wrote:
>>>>> Hi R?lers,
>>>>> 
>>>>> I?m running into speeding issues, performing a bunch of
>>>>> 
>>>>> ?gsub(patternvector, [token],dataframe$text_column)"
>>>>> 
>>>>> on a data frame containing >4millionentries.
>>>>> 
>>>>> (The ?patternvectors? contain up to 500 elements)
>>>>> 
>>>>> Is there any better/faster way than performing like 20 gsub commands in
>>>>> a row?
>>>>> 
>>>>> 
>>>>> Thanks!
>>>>> Simon
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Tue Nov  5 13:22:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 05 Nov 2013 12:22:38 +0000
Subject: [R] regession code
In-Reply-To: <1383648999.92680.YahooMailNeo@web142503.mail.bf1.yahoo.com>
References: <1383648999.92680.YahooMailNeo@web142503.mail.bf1.yahoo.com>
Message-ID: <5278E30E.2090305@sapo.pt>

Hello,

You are trying to get the coefficients of the function, nt of that 
function's result. Also, your function returns nothing. Try instead


fn <- function(x,y){
	lreg <- lm(y ~ x)
	lreg
}

fit <- fn(x,y)
b <- coef(fit)
b

Hope this helps,

Rui Barradas

Em 05-11-2013 10:56, IZHAK shabsogh escreveu:
>> y <- c(5.5199668,  1.5234525,  3.3557000,  6.7211704,  7.4237955,  1.9703127,
> +        4.3939336, -1.4380091,  3.2650180,  3.5760906,  0.2947972,  1.0569417)
>> x <- c(1,   0,   0,   4,   3,   5,  12,  10,  12, 100, 100, 100)
>>
>> fn<-function(x,y){
> + lreg<-lm(y ~ x)
> + }
>> fn(x,y)
>>
>> b<-coef(fn)
> Error: object of type 'closure' is not subsettable
>
> can you please correct this error and explain to me what is the problem with this code,that i am get the above error
>
>
> thankx
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Nov  5 13:25:10 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 05 Nov 2013 12:25:10 +0000
Subject: [R] Function does not see variables outside the function
In-Reply-To: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
Message-ID: <5278E3A6.4070809@sapo.pt>

Hello,

I believe the answer is no. Functions will first look in their 
environment, and then in the parent frame, i.e., outside the function.

Hope this helps,

Rui Barradas

Em 05-11-2013 10:42, Zhong-Yuan Zhang escreveu:
> Dear experts:
>
>       In MATLAB, functions cannot see variables outside the
>
> functions.  However, in R, the functions can do that. Is there
>
> any settings that can disable this ability of functions?
>
>       Many thanks for your kind help.
>
>       Best Regards Always.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Tue Nov  5 13:46:12 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 05 Nov 2013 06:46:12 -0600
Subject: [R] fail to install packages in R3.0.2 running in Redhat linux
In-Reply-To: <CAAU6gard5uGbNXv85meDAjuMoHSYdN_2qBBDQh6jX5uC5Kb1cA@mail.gmail.com>
References: <CAAU6gard5uGbNXv85meDAjuMoHSYdN_2qBBDQh6jX5uC5Kb1cA@mail.gmail.com>
Message-ID: <1D49A4C1-23AD-45A0-B8C5-0AEBEF6CA0E5@me.com>


On Nov 5, 2013, at 4:38 AM, Mao Jianfeng <jianfeng.mao at gmail.com> wrote:

> Dear R-helpers,
> 
> Glad to write to you.
> 
> I would like to have your helps to install packages through internet, in a
> linux computer. Could you please share any of your expertise with me on
> this problem?
> 
> Thanks in advance.
> 
> Best
> Jian-Feng,
> 
> ########################################
> # check the problem here.
>> install.packages(pkgs="ggplot2", repos='http://ftp.ctex.org/mirrors/CRAN/
> ')
> Installing package into ?/checkpoints/home/jfmao/bin/R_library?
> (as ?lib? is unspecified)
> Error: Line starting '<html> ...' is malformed!


The error suggests that there is a problem with the CRAN mirror that you have specified. I would try a different CRAN mirror and see if that resolves the problem.

Regards,

Marc Schwartz


From ripley at stats.ox.ac.uk  Tue Nov  5 13:59:29 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 05 Nov 2013 12:59:29 +0000
Subject: [R] Function does not see variables outside the function
In-Reply-To: <5278E3A6.4070809@sapo.pt>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
	<5278E3A6.4070809@sapo.pt>
Message-ID: <5278EBB1.2030801@stats.ox.ac.uk>

On 05/11/2013 12:25, Rui Barradas wrote:
> Hello,
>
> I believe the answer is no. Functions will first look in their
> environment, and then in the parent frame, i.e., outside the function.

That is not correct.  The scoping rule when evaluatiing a function is to 
look first in the evaluation frame, then the function's environment (see 
?environment).  The parent frame is not part of the scope (unless part 
of the environment).

You can set a function's environment to emptyenv(): then there will be 
no search outside the function.  As that includes no search for any of 
the functions implementing R itself, only very simple functions will be 
self-contained.

You can control the search by setting a function's environment.  Most 
likely that will achieve what you want to do (but have not told us).

>
> Hope this helps,
>
> Rui Barradas
>
> Em 05-11-2013 10:42, Zhong-Yuan Zhang escreveu:
>> Dear experts:
>>
>>       In MATLAB, functions cannot see variables outside the
>>
>> functions.  However, in R, the functions can do that. Is there
>>
>> any settings that can disable this ability of functions?
>>
>>       Many thanks for your kind help.
>>
>>       Best Regards Always.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From carl at witthoft.com  Tue Nov  5 14:00:59 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 5 Nov 2013 05:00:59 -0800 (PST)
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
	<5278C903.8080805@stats.ox.ac.uk>
	<80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>
Message-ID: <1383656459847-4679769.post@n4.nabble.com>

My feeling is that the **result** you want is far more easily achievable via
a substitution table or a hash table.  Someone better versed in those areas
may want to chime in.  I'm thinking more or less of splitting your character
strings into vectors (separate elements at whitespace) and chunking away.

Something like  charvec[charvec==dataframe$text_column[k]] <-
dataframe$replace_column[k]




Simon Pickert wrote
> Thanks everybody! Now I understand the need for more details:
> 
> the patterns for the gsubs are of different kinds.First, I have character
> strings, I need to replace. Therefore, I have around 5000 stock ticker
> symbols (e.g. c(?AAPL?, ?EBAY?,?) distributed across 10 vectors. 
> Second, I have four vectors with regular expressions, all similar to this
> on: replace_url <- c(?https?://.*\\s|www.*\\s?) 
> 
> The text strings I perform the gsub commands on, look like this (no string
> is longer than 200 characters):
> 
> 'GOOGL announced new partnership www.url.com. Stock price is up +5%?
> 
> After performing several gsubs in a row, like
> 
> gsub(replace_url, ?[url]?,dataframe$text_column) 
> gsub(replace_ticker_sp500, ?[sp500_ticker]?,dataframe$text_column) 
> etc. 
> 
> this string will look like this:
> 
> '[sp500_ticker] announced new partnership [url]. Stock price is up
> [positive_percentage]?





--
View this message in context: http://r.789695.n4.nabble.com/speed-issue-gsub-on-large-data-frame-tp4679747p4679769.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Tue Nov  5 14:06:43 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 13:06:43 +0000
Subject: [R] Error message in SPACECAP package
In-Reply-To: <527780B1.5010407@hnutiduha.cz>
References: <527780B1.5010407@hnutiduha.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D238@SRVEXCHMBX.precheza.cz>

Hi

Although I do not know about SPACECAP here are few hints.

Usually attachment does not go through, use dput instead.
Copy output of

dput(head(yourdata))

to the mail.

str(yourdata)

Gives you (and us if you show the output) some info about your data mode.

My opinion is that some column is not the correct type for used function.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Miroslav Kutal
> Sent: Monday, November 04, 2013 12:11 PM
> To: r-help at r-project.org
> Subject: [R] Error message in SPACECAP package
> 
> Dear all
> 
> I've tried a spatial capture-recapture in SPACECAP package but got
> stuck after uploading the input data files:
> 
> "Error in animal capture details file - non-integer or missing values"
> Error in if (locso[loc, so + 3] == 0) { :
> missing value where TRUE/FALSE needed
> 
> I prepared the input capture file according to the manual and the file
> should consist from three columns: LOC_ID, ANIMAL_ID, SO (sampling
> occasion) so actually no TRUE/FALSE type of data..
> 
> I am attaching also the input capture file. Because I am not familiar
> with all R functions I would appreciate any suggestion for solving this
> problem.
> 
> Thank you,
> 
> Miroslav Kutal


From petr.pikal at precheza.cz  Tue Nov  5 14:12:03 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 13:12:03 +0000
Subject: [R] forecast.lm() and NEWDATA
In-Reply-To: <5277BAFA.8050708@urban-econ.com>
References: <5273B194.6010004@urban-econ.com>
	<0B8EA941-390C-4C14-B201-395F9ED14F23@comcast.net>
	<5277BAFA.8050708@urban-econ.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D251@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ryan
> Sent: Monday, November 04, 2013 4:19 PM
> To: David Winsemius
> Cc: r-help at r-project.org
> Subject: Re: [R] forecast.lm() and NEWDATA
> 
> Hi David (and everyone)
> 
> Thank you for your reply.
> 
> I see I copied down the code wrong for the regression. I was using the
> "+" seperator, and not ",".  The regression was working.
> 
> I made a mistake with the NEWDATA, where I also used "+", instead of
> ",", however I see both work but return very different results. I have
> corrected the mistake.
> 
> However, I am still receiving the same error when I try to run the
> forecast.lm.
> "
> 
> forecast.lm(REGGY, h=5)
> 
> i receive the following error
> "Error in as.data.frame(newdata) :
>   argument "newdata" is missing, with no default""
> 

Where is forecast.lm from? Anyway, it probably requires an argument for newdata so maybe

forecast.lm(REGGY, newdata=somedata, h=5)

will work.

Regards
Petr

> 
> 
> I am sorry to say, I don't understand your reference to the string
> output when you mentioned
> 
> "
> 
> You should post the output of str() on the data-objects that has the 12
> variables and if it was modified the data argument pasted to `lm()`
> when you made REGGY.
> 
> "
>   As of right now, NEWDATA includes all the independent variables from
> the REGGY Regression.
> 
> 
> Should the NEWDATA data.frame include the dependent variable?
> 
> Also, is it necessary to reformat all variables as time series? (I have
> not currently done so)
> 
> Regards
> Ryan
> 
> On 2013-11-01 07:28 PM, David Winsemius wrote:
> > On Nov 1, 2013, at 6:50 AM, Ryan wrote:
> >
> >> Good day all.
> >>
> >> I am hoping you can help me (and I did this right). I've been
> working in R for a week now, and have encountered a problem with
> forecast.lm().
> >>
> >> I have a list of 12 variables, all type = double, with 15 data
> entries.
> >> (I imported them from tab delimited text files, and then formatted
> as.numeric to change from list to double)
> >> (I understand that this leaves me rather limited in my degrees of
> freedom, but working with what I have, sadly. )
> >>
> >> I have a LM model, such that
> >> REGGY = lm(formula=Y~A,B,C,...,I,J)
> > This looks wrong. Separating independent predictors with commas would
> be highly unusual.
> >> which I am happy with.
> >>
> >> I have
> >> NEWDATA = data.frame(A+B+C+D....+I+J)
> > This also looks wrong. Separating arguments to data.frame with "+"-
> signs is surely wrong.
> >> When i try to run
> >>
> >> forecast.lm(REGGY, h=5)
> >>
> >> i receive the following error
> >> "Error in as.data.frame(newdata) :
> >>   argument "newdata" is missing, with no default"
> > If your code prior to calling forecast on the REGGY-object was really
> what you showed here, I am not surprised. You should post the output of
> str() on the data-objects that has the 12 variables and if it was
> modified the data argument pasted to `lm()` when you made REGGY.
> (Beginners should name their data arguments.)
> >
> >> When I run
> >> forecast.lm(REGGY, NEWDATA, h=5)
> >> I receive the confidence intervals of the 15 data entries I already
> possess. I understand that by including NEWDATA, the "h=5" is ignored,
> but without NEWDATA, I receive the error message.
> >>
> >> Can anyone help me please?
> >>
> >> Regards
> >> Ryan
> >>
> >> P.S The forecast is trying to predict the next 5 values for Y from
> the regression model pasted above. I'm a bit rusty with regressions,
> but I think I've covered my bases as well as I can, and from what I
> understand of the R code, I'm following the right steps.
> > Not if what you posted here was your code. I think you missed a few
> crucials points about R syntax.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Tue Nov  5 13:54:29 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 5 Nov 2013 04:54:29 -0800 (PST)
Subject: [R] Function does not see variables outside the function
In-Reply-To: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
Message-ID: <1383656069289-4679768.post@n4.nabble.com>

Why would you want to impose this restriction?  Perhaps if you explain what
you are trying to do, we can suggest approaches that will satisfy your
specific needs.
(note- one can always redefine whatever variables are to be "excluded." E.g.
to keep the body of a function from referring to 'foo' in the calling
environment, just add the line 'foo<-NA' inside the function)


Zhong-Yuan Zhang wrote
>      In MATLAB, functions cannot see variables outside the
> 
> functions.  However, in R, the functions can do that. Is there
> 
> any settings that can disable this ability of functions?
> 
>     
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Function-does-not-see-variables-outside-the-function-tp4679762p4679768.html
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at me.com  Tue Nov  5 14:29:29 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 05 Nov 2013 07:29:29 -0600
Subject: [R] fail to install packages in R3.0.2 running in Redhat linux
In-Reply-To: <CAAU6gaqsRwn2pU-ZfGPo+xOzVP2oOUAh084BR8WUpV8CM+uLmw@mail.gmail.com>
References: <CAAU6gard5uGbNXv85meDAjuMoHSYdN_2qBBDQh6jX5uC5Kb1cA@mail.gmail.com>
	<1D49A4C1-23AD-45A0-B8C5-0AEBEF6CA0E5@me.com>
	<CAAU6gaqsRwn2pU-ZfGPo+xOzVP2oOUAh084BR8WUpV8CM+uLmw@mail.gmail.com>
Message-ID: <4DE9A103-E26F-4B58-9DA3-1E2CA3B56034@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/a4970e44/attachment.pl>

From jianfeng.mao at gmail.com  Tue Nov  5 13:59:20 2013
From: jianfeng.mao at gmail.com (Mao Jianfeng)
Date: Tue, 5 Nov 2013 04:59:20 -0800
Subject: [R] fail to install packages in R3.0.2 running in Redhat linux
In-Reply-To: <1D49A4C1-23AD-45A0-B8C5-0AEBEF6CA0E5@me.com>
References: <CAAU6gard5uGbNXv85meDAjuMoHSYdN_2qBBDQh6jX5uC5Kb1cA@mail.gmail.com>
	<1D49A4C1-23AD-45A0-B8C5-0AEBEF6CA0E5@me.com>
Message-ID: <CAAU6gaqsRwn2pU-ZfGPo+xOzVP2oOUAh084BR8WUpV8CM+uLmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/9ba6e3a0/attachment.pl>

From rogerssarah65 at gmail.com  Tue Nov  5 14:44:34 2013
From: rogerssarah65 at gmail.com (Sarah Rogers)
Date: Tue, 5 Nov 2013 14:44:34 +0100
Subject: [R] Path Analysis
In-Reply-To: <web-481436287@cgpsrv2.cis.mcmaster.ca>
References: <CAELFSNU6zj3sePqT2pNE3WGtqcc-qu7SnSTY6Et_Dj9K0O4KXw@mail.gmail.com>
	<web-481436287@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAELFSNXpRRm5e4j78wtj5Fnx8ctKLa_7NBzxSLLavYbsjeJkVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/e65fe1d8/attachment.pl>

From therneau at mayo.edu  Tue Nov  5 15:02:31 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 05 Nov 2013 08:02:31 -0600
Subject: [R] How to obtain nonparametric baseline hazard estimates in
 the gamma frailty model?
In-Reply-To: <mailman.25.1383649208.21437.r-help@r-project.org>
References: <mailman.25.1383649208.21437.r-help@r-project.org>
Message-ID: <5278FA77.1010407@mayo.edu>

I have responded to this particular misconception so often I begin to grow grumpy about it 
(not the particular fault of YH).  The cumulative hazard function from
	fit <- coxph( some model)
         sfit <- survfit(fit, newdata=  set of covariate values)

gives the survival curve and cumulative hazard for that particular set of covariate values.

There is nothing special about a "baseline hazard".  Any cumulative hazard is for some 
particular set of covariate values, including "all values =0" which is what most textbooks 
refer to as the baseline.  The survfit routine will by default return one centered at the 
means of the predictor variables, simply because there is less round off error if one 
stays near the center.  Any baseline is as good as any other.

   cum haz at covariate values "z" = cumulative haz for values "x" * exp(beta * (z-x))

Note that for a random effect, the survfit routine uses 0 as the centering value.

Terry Therneau


On 11/05/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hi Dr. Therneau,
>
> Yes, -log(sfit$surv) gives me the cumulative hazard but not the baseline
> cumulative hazard. I know that Nielsen and Klein have SAS Macros to get
> such estimates by using EM approach. I'm wondering if I can obtain the
> baseline hazard estimates from coxph() for gamma frailty model since I
> think coxph() is a very powerful function. I feel there may be some way
> that I don't know.
>
> Thanks,
> YH


From babakbsn at gmail.com  Tue Nov  5 15:41:52 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 06:41:52 -0800
Subject: [R] Problem while reading Data from a data frame
Message-ID: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/25283850/attachment.pl>

From Yan_Li at ibi.com  Tue Nov  5 15:47:25 2013
From: Yan_Li at ibi.com (Li, Yan)
Date: Tue, 5 Nov 2013 09:47:25 -0500
Subject: [R] Sample size for clustering analysis?
Message-ID: <A29EC196EE32C64389369F6BF03B66C8769310E530@IBIUSMBSB.ibi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/b3d3827e/attachment.pl>

From prudentxavier at gmail.com  Tue Nov  5 15:36:16 2013
From: prudentxavier at gmail.com (Xavier Prudent)
Date: Tue, 5 Nov 2013 15:36:16 +0100
Subject: [R] Regression of the sum of distributions on an histogram with R
Message-ID: <CAF7OBP_fsV_3=3Sb8cMA2GXUNFVC8NjaQ40xuP3t3qURvaDXpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/71305e07/attachment.pl>

From aljehani-k at hotmail.com  Tue Nov  5 15:42:13 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Tue, 5 Nov 2013 17:42:13 +0300
Subject: [R] Nadaraya-Watson kernel
Message-ID: <DUB122-W253DBDF28232A9FBD6C47585F10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/5f795938/attachment.pl>

From Thierry.ONKELINX at inbo.be  Tue Nov  5 15:51:15 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 5 Nov 2013 14:51:15 +0000
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFAFC521@inbomail.inbo.be>

You don't need a loop nor a growing object.

data(mtcars)
mtcars
mtcars[seq(1, nrow(mtcars), by = 2), ]

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Baro
Verzonden: dinsdag 5 november 2013 15:42
Aan: R help
Onderwerp: [R] Problem while reading Data from a data frame

Hi experts,

I want to read only the half of my data frame, which I read it from clip board, and save it in a list. I wrote this code but it doesnt work:

ck<-read.table("clipboard")
datalist<-list()
d<-dim(ck)[1]
i<-1

repeat
{
  datalist<-c(datalist,ck[i,])
  i<-i+2
  if(i>d)
  {break}
}
datalist

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From petr.pikal at precheza.cz  Tue Nov  5 15:55:44 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 14:55:44 +0000
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>

Hi

You shall probably use C or similar program for such task.

As I understand you want only odd rows. If yes, this will do it for you

odd<-seq(1,d,2)
datalist<-cd[odd,]

If not please explain better your real intention.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Baro
> Sent: Tuesday, November 05, 2013 3:42 PM
> To: R help
> Subject: [R] Problem while reading Data from a data frame
> 
> Hi experts,
> 
> I want to read only the half of my data frame, which I read it from
> clip board, and save it in a list. I wrote this code but it doesnt
> work:
> 
> ck<-read.table("clipboard")
> datalist<-list()
> d<-dim(ck)[1]
> i<-1
> 
> repeat
> {
>   datalist<-c(datalist,ck[i,])
>   i<-i+2
>   if(i>d)
>   {break}
> }
> datalist
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Nov  5 16:01:30 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 15:01:30 +0000
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D341@SRVEXCHMBX.precheza.cz>

Sorry

shall be
datalist<-ck[odd,]

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of PIKAL Petr
> Sent: Tuesday, November 05, 2013 3:56 PM
> To: Baro; R help
> Subject: Re: [R] Problem while reading Data from a data frame
> 
> Hi
> 
> You shall probably use C or similar program for such task.
> 
> As I understand you want only odd rows. If yes, this will do it for you
> 
> odd<-seq(1,d,2)
> datalist<-cd[odd,]
> 
> If not please explain better your real intention.
> 
> Regards
> Petr
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Baro
> > Sent: Tuesday, November 05, 2013 3:42 PM
> > To: R help
> > Subject: [R] Problem while reading Data from a data frame
> >
> > Hi experts,
> >
> > I want to read only the half of my data frame, which I read it from
> > clip board, and save it in a list. I wrote this code but it doesnt
> > work:
> >
> > ck<-read.table("clipboard")
> > datalist<-list()
> > d<-dim(ck)[1]
> > i<-1
> >
> > repeat
> > {
> >   datalist<-c(datalist,ck[i,])
> >   i<-i+2
> >   if(i>d)
> >   {break}
> > }
> > datalist
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From babakbsn at gmail.com  Tue Nov  5 16:01:45 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 07:01:45 -0800
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/fd2bfde2/attachment.pl>

From friendly at yorku.ca  Tue Nov  5 16:08:21 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 05 Nov 2013 10:08:21 -0500
Subject: [R] How to plot results of clmm()?
In-Reply-To: <5277AB70.1030301@aol.com>
References: <5277AB70.1030301@aol.com>
Message-ID: <527909E5.9050307@yorku.ca>

On 11/4/2013 9:13 AM, thomas wrote:
> Dear list,
>
> I'd like to create a visual plot of a clmm() I've fitted using the
> 'ordinal' package in R. It's possible to do this with a glm() by using
> the 'effects' package. For example:
>
>     library(effects)
>     data(BEPS)
>     mod <- lm(political.knowledge ~ age + gender + vote, data=BEPS)
>     eff <- effect("age", mod, default.levels=100)
>     plot(eff, colors=c("black", "red"))
>
> Produces: http://i.stack.imgur.com/elo4p.png
>
> The 'effects' package does not support clmm:
>
>     mod <- clmm(as.factor(political.knowledge) ~ age + gender +
> (1|vote), data=BEPS)
>     eff <- effect("age", mod, default.levels=100)
>     > Error in UseMethod("effect", mod) :
>     no applicable method for 'effect' applied to an object of class "clmm"
>
> How would I go about doing this? I can't find any examples with clm() or
> clmm() online. Any suggestions would be much appreciated.
>

You're right that clm() and clmm() models are not supported by the 
effects package.  In principle, this would not be too difficult to add, 
*if* the ordinal package contained the standard collection of methods for
'clm' and 'clmm' objects --- coef(), vcov(), and importantly, predict().
Unfortunately, there is no predict method, and clmm objects don't 
inherit from anything else:

 > methods(class="clmm")
  [1] anova.clmm*      condVar.clmm*    extractAIC.clmm* logLik.clmm*
  [5] nobs.clmm*       print.clmm*      ranef.clmm       summary.clmm*
  [9] VarCorr.clmm     vcov.clmm*
 > class(modc)
[1] "clmm"
 >

If there were, you could simply do what effects does yourself --
obtain predicted values (and CIs) over a grid of values, and plot them,

xlevels <- expand.grid(list(age=seq(20,90,10),
               gender=levels(BEPS$gender), vote=levels(BEPS$vote)))

You can, of course, obtain all the fitted values, and plot those,
but that lacks the simplicity of effect plots in averaging over factors
not shown in a given plot.

library(ordinal)
  modc <- clmm(as.factor(political.knowledge) ~ age + gender +
(1|vote), data=BEPS)

BEPS$fitted <- fitted(modc)
plot(fitted~age, data=BEPS, col=c("red", "blue")[gender])



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From wewolski at gmail.com  Tue Nov  5 16:21:07 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 5 Nov 2013 16:21:07 +0100
Subject: [R] writing blobs with RDBI
Message-ID: <CAAjnpdiR6BQVaUz5fTpLrdowa9w2q-ReaagGCduWJ_ReWtj2CA@mail.gmail.com>

How to write a blob with RDBI?

assuming I have
x <- 1:10 * 0.1

How do I store it in a sql table as an blob?

regards




-- 
Witold Eryk Wolski


From aljehani-k at hotmail.com  Tue Nov  5 15:48:46 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Tue, 5 Nov 2013 17:48:46 +0300
Subject: [R] FW: Nadaraya-Watson kernel
In-Reply-To: <DUB122-W253DBDF28232A9FBD6C47585F10@phx.gbl>
References: <DUB122-W253DBDF28232A9FBD6C47585F10@phx.gbl>
Message-ID: <DUB122-W16799739806241A7A7ADB385F10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/a8be586f/attachment.pl>

From petr.pikal at precheza.cz  Tue Nov  5 16:31:24 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 15:31:24 +0000
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
	<CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/c65433f7/attachment.pl>

From babakbsn at gmail.com  Tue Nov  5 16:35:21 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 07:35:21 -0800
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
	<CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/b061d3bf/attachment.pl>

From gunter.berton at gene.com  Tue Nov  5 16:43:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 5 Nov 2013 07:43:16 -0800
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
	<CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>
	<CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>
Message-ID: <CACk-te0yt7=2neMu7mHDGq4y6z73=ZJbU367d1oKCfw9MygNhQ@mail.gmail.com>

Please follow Petr's advice and read the Introduction to R or other R
online tutorial (there are many) before posting further basic
questions here. You need to make an effort to learn the basics of R
before pestering this list with questions such as these.

Cheers,
Bert

On Tue, Nov 5, 2013 at 7:35 AM, Baro <babakbsn at gmail.com> wrote:
> I exactly jump over this values and only have the integer values, henc I
> want to read only odd rows
>
>
> On Tue, Nov 5, 2013 at 7:31 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>>  Hi
>>
>>
>>
>> It means that what you read is a factor. Most probably the values are
>> formated in scientific notation which is not read properly as numbers. You
>> shall format numbers in your Excel file so that it does not have comma but
>> dot.
>>
>>
>>
>> Or you can transfer those values to numbers in R.
>>
>>
>>
>> see
>>
>> ?factor
>>
>> ?as.character
>>
>> ?gsub
>>
>>
>>
>> And if you are in reading some docs you can try to locate R-intro and go
>> through it. It can help you greatly in beginning.
>>
>>
>>
>> Regards
>>
>> Petr
>>
>>
>>
>> *From:* Baro [mailto:babakbsn at gmail.com]
>> *Sent:* Tuesday, November 05, 2013 4:02 PM
>> *To:* PIKAL Petr
>> *Cc:* R help
>> *Subject:* Re: [R] Problem while reading Data from a data frame
>>
>>
>>
>> thank you for your answers. It works and I have such an output:
>>
>>
>>
>> [1] 491 492 494 492 493 492 494 493 493 492 491 491 493 494 492 493 494
>> 492 493 492 491 494 492 491 493 495
>>
>> [27] 492 492 491 493 492 493 495 493 492 491 494 493 492 491 491 494 492
>> 493 492 492 492 492 494 492 491 493
>>
>> [53] 493 493 494 493 491 495 495 492 493 494 492 490 491 494 492 495 491
>> 495
>>
>> Levels: 1,09E+13 1,14E+13 1,24E+13 2,21E+12 490 491 492 493 494 495
>> 7,06E+12 7,50E+11 8,03E+12
>>
>>
>>
>> what does levels mean? how can I have only the numbers?
>>
>>
>>
>> On Tue, Nov 5, 2013 at 6:55 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>
>> Hi
>>
>> You shall probably use C or similar program for such task.
>>
>> As I understand you want only odd rows. If yes, this will do it for you
>>
>> odd<-seq(1,d,2)
>> datalist<-cd[odd,]
>>
>> If not please explain better your real intention.
>>
>> Regards
>> Petr
>>
>>
>>
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> > project.org] On Behalf Of Baro
>> > Sent: Tuesday, November 05, 2013 3:42 PM
>> > To: R help
>> > Subject: [R] Problem while reading Data from a data frame
>> >
>> > Hi experts,
>> >
>> > I want to read only the half of my data frame, which I read it from
>> > clip board, and save it in a list. I wrote this code but it doesnt
>> > work:
>> >
>> > ck<-read.table("clipboard")
>> > datalist<-list()
>> > d<-dim(ck)[1]
>> > i<-1
>> >
>> > repeat
>> > {
>> >   datalist<-c(datalist,ck[i,])
>> >   i<-i+2
>> >   if(i>d)
>> >   {break}
>> > }
>> > datalist
>> >
>>
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-
>> > guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From petr.pikal at precheza.cz  Tue Nov  5 16:45:02 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 5 Nov 2013 15:45:02 +0000
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
	<CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>
	<CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D3CC@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/d2e67a68/attachment.pl>

From babakbsn at gmail.com  Tue Nov  5 16:56:14 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 5 Nov 2013 07:56:14 -0800
Subject: [R] Problem while reading Data from a data frame
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D3CC@SRVEXCHMBX.precheza.cz>
References: <CAF-JZQskVyUrpHv=Kwf5ASEod2i=penz_jL6VTTPV5WBeX9qzA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D32B@SRVEXCHMBX.precheza.cz>
	<CAF-JZQt_p1Uo3LoZ-S=H3U8xVKmpR-48d_hgAJ+BMwQ817_1gQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D390@SRVEXCHMBX.precheza.cz>
	<CAF-JZQsw3xKqUrYu7AVttwGRnqoD+JGihLnWCY2igdAhbYJ9HA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9D3CC@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF-JZQuHr1P-Q=0di3t6KVkW0pu7DvU8MxUBmMORgGAse0-dPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/77338bf0/attachment.pl>

From jfox at mcmaster.ca  Tue Nov  5 16:57:19 2013
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 5 Nov 2013 10:57:19 -0500
Subject: [R] How to plot results of clmm()?
In-Reply-To: <527909E5.9050307@yorku.ca>
References: <5277AB70.1030301@aol.com> <527909E5.9050307@yorku.ca>
Message-ID: <008101ceda3f$b5fdb160$21f91420$@mcmaster.ca>

Dear Thomas and Michael,

As Michael knows, there is a default Effect() method in the development
version of the effects package on R-Forge. This should work with almost all
model objects that produce a single fitted value and that respond to coef(),
model.frame(), formula(), and vcov(). 

This might cover plotting the latent response in clm() or clmm() models but
not plots of fitted response-category probabilities such as the effects
package can make for models fit by multinom() in the nnet package or polr()
in the MASS package. 

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Michael Friendly
> Sent: Tuesday, November 05, 2013 10:08 AM
> To: thomas; r-help at r-project.org
> Cc: John Fox
> Subject: Re: [R] How to plot results of clmm()?
> 
> On 11/4/2013 9:13 AM, thomas wrote:
> > Dear list,
> >
> > I'd like to create a visual plot of a clmm() I've fitted using the
> > 'ordinal' package in R. It's possible to do this with a glm() by
> using
> > the 'effects' package. For example:
> >
> >     library(effects)
> >     data(BEPS)
> >     mod <- lm(political.knowledge ~ age + gender + vote, data=BEPS)
> >     eff <- effect("age", mod, default.levels=100)
> >     plot(eff, colors=c("black", "red"))
> >
> > Produces: http://i.stack.imgur.com/elo4p.png
> >
> > The 'effects' package does not support clmm:
> >
> >     mod <- clmm(as.factor(political.knowledge) ~ age + gender +
> > (1|vote), data=BEPS)
> >     eff <- effect("age", mod, default.levels=100)
> >     > Error in UseMethod("effect", mod) :
> >     no applicable method for 'effect' applied to an object of class
> "clmm"
> >
> > How would I go about doing this? I can't find any examples with clm()
> or
> > clmm() online. Any suggestions would be much appreciated.
> >
> 
> You're right that clm() and clmm() models are not supported by the
> effects package.  In principle, this would not be too difficult to add,
> *if* the ordinal package contained the standard collection of methods
> for
> 'clm' and 'clmm' objects --- coef(), vcov(), and importantly,
> predict().
> Unfortunately, there is no predict method, and clmm objects don't
> inherit from anything else:
> 
>  > methods(class="clmm")
>   [1] anova.clmm*      condVar.clmm*    extractAIC.clmm* logLik.clmm*
>   [5] nobs.clmm*       print.clmm*      ranef.clmm       summary.clmm*
>   [9] VarCorr.clmm     vcov.clmm*
>  > class(modc)
> [1] "clmm"
>  >
> 
> If there were, you could simply do what effects does yourself --
> obtain predicted values (and CIs) over a grid of values, and plot them,
> 
> xlevels <- expand.grid(list(age=seq(20,90,10),
>                gender=levels(BEPS$gender), vote=levels(BEPS$vote)))
> 
> You can, of course, obtain all the fitted values, and plot those,
> but that lacks the simplicity of effect plots in averaging over factors
> not shown in a given plot.
> 
> library(ordinal)
>   modc <- clmm(as.factor(political.knowledge) ~ age + gender +
> (1|vote), data=BEPS)
> 
> BEPS$fitted <- fitted(modc)
> plot(fitted~age, data=BEPS, col=c("red", "blue")[gender])
> 
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abmathewks at gmail.com  Tue Nov  5 17:00:26 2013
From: abmathewks at gmail.com (Abraham Mathew)
Date: Tue, 5 Nov 2013 10:00:26 -0600
Subject: [R] Convert date column with two different structures
Message-ID: <CAJ-4XAoOM2gN56SUtjs0Uk=PoiKMvnkwNsi-9qB8i=jj5jxzEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/710728ee/attachment.pl>

From ishaqbaba at yahoo.com  Tue Nov  5 18:40:07 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Tue, 5 Nov 2013 09:40:07 -0800 (PST)
Subject: [R] multi
Message-ID: <1383673207.801.YahooMailNeo@web142502.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/29ef1a41/attachment.pl>

From ruipbarradas at sapo.pt  Tue Nov  5 19:39:30 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 05 Nov 2013 18:39:30 +0000
Subject: [R] Convert date column with two different structures
In-Reply-To: <CAJ-4XAoOM2gN56SUtjs0Uk=PoiKMvnkwNsi-9qB8i=jj5jxzEA@mail.gmail.com>
References: <CAJ-4XAoOM2gN56SUtjs0Uk=PoiKMvnkwNsi-9qB8i=jj5jxzEA@mail.gmail.com>
Message-ID: <52793B62.7030300@sapo.pt>

Hello,

Try the following.


idx <- grep("[[:alpha:]]", df$Date)

Date <- as.Date(df$Date, "%m/%d/%y")
Date[idx] <- as.Date(paste("01", df$Date[idx]), "%d %b-%y")


Hope this helps,

Rui Barradas

Em 05-11-2013 16:00, Abraham Mathew escreveu:
> Let's say I have the following data frame and the date column has two
> different ways in which date is presented. How can I use as.Date or the
> lubridate package to have one date structure for the entire colum
>
> df = data.frame(Date=c("5/1/13","8/1/13","9/1/13","Apr-10",
>
>                "Apr-11","Apr-12","Apr-13"))
> It's "month/date/year" and "month-year".
>
> An alternative approach would be to perform some conditional statements
> where if the date is "Apr-11", then populate it with "04/01/2011".
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From b.rowlingson at lancaster.ac.uk  Tue Nov  5 19:44:24 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 5 Nov 2013 18:44:24 +0000
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <19fc603f1c0046a1a6d0e4dd10dbcf50@EX-0-HT0.lancs.local>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam> <5277ED03.20302@sapo.pt>
	<op.w51gkdmdzqkd1e@nirvana>
	<19fc603f1c0046a1a6d0e4dd10dbcf50@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPR42Ak7GxL3L=nYHsVgkzn_dEtjo=jag3jJj9qdNDmow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/de51679d/attachment.pl>

From jfox at mcmaster.ca  Tue Nov  5 21:16:58 2013
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 5 Nov 2013 15:16:58 -0500
Subject: [R] Path Analysis
In-Reply-To: <CAELFSNXpRRm5e4j78wtj5Fnx8ctKLa_7NBzxSLLavYbsjeJkVQ@mail.gmail.com>
References: <CAELFSNU6zj3sePqT2pNE3WGtqcc-qu7SnSTY6Et_Dj9K0O4KXw@mail.gmail.com>	<web-481436287@cgpsrv2.cis.mcmaster.ca>
	<CAELFSNXpRRm5e4j78wtj5Fnx8ctKLa_7NBzxSLLavYbsjeJkVQ@mail.gmail.com>
Message-ID: <00ba01ceda63$fbadec60$f309c520$@mcmaster.ca>

Dear Sarah,

As you know, our discussion continued off-list, and I'm glad that you were
able to get the software to work.

I'll address your question briefly, but what I have to say probably isn't
what you want to hear:

Most fundamentally, the information you've provided is entirely without
content. That is, variable names like x1 and y1 convey no information about
the substance of the data. It's therefore impossible to know whether the
model that you specified is sensible. I think that you'd do much better to
seek competent statistical help locally than to ask questions on an email
list devoted to statistical software.

That said, you've specified a very restrictive model for the data. You could
add 8 paths to the model and still have a fully recursive model. For
example, your model specifies that x2 can only influence y4 indirectly
through y1. If you've carefully specified the model and believe, for
example, that the missing paths are implausible, that x1 and x2 are really
exogenous, and that all of the disturbances are uncorrelated, then the
correct conclusion is that your model is wrong. You could try adding the
missing paths to the model, but if you're willing to do this that would
suggest that you didn't think carefully enough about the specification in
the first place. In my opinion, structural-equation modeling shouldn't be
regarded as an exploratory method.

Of course, in a very large sample, an overidentified model that's trivially
wrong can be rejected when tested as a hypothesis. I don't know how large
your sample is, but the various "fit indices" are not encouraging. Your
model isn't just trivially wrong. Moreover, the R^2s for the endogenous
variable are very small -- two are effectively 0.

I can't judge whether your model makes any sense, but it's my impression
that most structural equation models don't. People often think that SEMs are
magic wands that can be waved over observational data to draw causal
inferences, even when the assumptions underlying the model, such as
exogeneity, are implausible, and without attending to aspects of the model,
such as potential nonlinearity, that should be part of careful regression
modeling.

My two cents,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Sarah Rogers
> Sent: Tuesday, November 05, 2013 8:45 AM
> To: r-help at r-project.org
> Cc: John Fox
> Subject: Re: [R] Path Analysis
> 
> Dear John,
> Thanks for your help. I run the path analysis but the model does not
> fit
> the data. I am in doubt if this reflects the model construction et al.
> (too
> many variables or more needed, more paths or change in direction of
> paths,
> sample size, etc) or it could be that there is an error-variance
> I have all observed data (fully recursive model), two exogenous
> variables
> (with no variance or covariance parameters), four exogenous variables,
> and
> for the final sem() model I used data argument instead of a moment
> matrix
> with the covariance symmetric matrix. What would you suggest to be the
> best
> way to investigate this in R?
> Here attached the script and results:
> 
> library(sem)
> model.xdata<-specifyEquations()
> 
> y1=xy21*x2
> y2=xy12*x1 + yy12*y1
> y3=yy23*y2
> y4=yy24*y2+yy34*y3
> 
> model.xdata.sem <- sem(model.xdata, data=xdata, fixed.x=c("x1", "x2") )
> summary(model.xdata.sem,fit.indices=c("CFI","NFI", "GFI", "RMSEA",
> "AGFI",
> "NNFI", "SRMR"))
> 
> Model Chisquare =  41.03029   Df =  8 Pr(>Chisq) = 2.057595e-06
> Goodness-of-fit index =  0.8604332
>  Adjusted goodness-of-fit index =  0.6336373
>  RMSEA index =  0.2330797   90% CI: (0.1654494, 0.3060134)
> Bentler-Bonett NFI =  0.4290901
>  Tucker-Lewis NNFI =  -0.08903999
>  Bentler CFI =  0.4191787
>  SRMR =  0.1472905
> 
>  Normalized Residuals
>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
> -3.91600 -0.60120  0.00000 -0.09444  0.13940  2.71400
> 
>  R-square for Endogenous Variables
>     y1     y2     y3     y4
> 0.0009 0.1890 0.0019 0.1558
> 
>  Parameter Estimates
>       Estimate      Std Error    z value     Pr(>|z|)
> xy21    0.017817121  0.066762981  0.26687127 7.895683e-01 y1 <--- x2
> xy12   -0.030928721  0.007447431 -4.15293810 3.282335e-05 y2 <--- x1
> yy12    0.311216816  0.475353649  0.65470585 5.126572e-01 y2 <--- y1
> yy23   -0.077701789  0.203130269 -0.38252196 7.020742e-01 y3 <--- y2
> yy24    0.002539283  0.031323241  0.08106706 9.353886e-01 y4 <--- y2
> yy34    0.066168523  0.017671263  3.74441396 1.808153e-04 y4 <--- y3
> V[y1]   1.945406949  0.315586680  6.16441400 7.074463e-10 y1 <--> y1
> V[y2]  33.438573159  5.424452858  6.16441400 7.074463e-10 y2 <--> y2
> V[y3] 129.295382082 20.974480627  6.16441400 7.074463e-10 y3 <--> y3
> V[y4]   3.068539923  0.497782907  6.16441400 7.074463e-10 y4 <--> y4
> 
> 
> 
> 
> On 2 November 2013 19:48, John Fox <jfox at mcmaster.ca> wrote:
> 
> > Dear Sarah,
> >
> > It's generally a good idea to include a reproducible example if you
> want
> > to get help with a problem, but in this case it's a safe bet that the
> > problem is that the model you specified has no variance or covariance
> > parameters for the variables x1 and x2, which, I assume, you mean to
> be
> > exogenous. The easiest way to include these variances and covariance
> in the
> > model is to specify the argument fixed.x=c("x1", "x2") in the call to
> sem().
> >
> > In addition:
> >
> > (1) Your model is fully recursive (guessing that all the x's and y's
> are
> > observed variables), and so it amounts to four OLS regressions. You
> could
> > just use lm() to fit the model.
> >
> > (2) It's generally easier in the sem package to use
> specifyEquations()
> > than specifyModel() for model specification.
> >
> > (3) If you have the original data set, as you do, it's generally
> > preferable to use the data argument to sem() than to pass it the
> covariance
> > matrix for the observed variables.
> >
> > I hope that this helps,
> >  John
> >
> >
> > ------------------------------------------------
> > John Fox
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> > On Sat, 2 Nov 2013 11:02:31 +0100
> >  Sarah Rogers <rogerssarah65 at gmail.com> wrote:
> > >  Hello,
> > >
> > > I have just started to work on a path analysis (see attached image
> for
> > the
> > > diagram), but I have encountered an error message.
> > >
> > >
> > >
> > >
> > > This is the code I have used:
> > >
> > > cov_matrix<-var(xdata)
> > >
> > > library(sem)
> > > model.xdata<-specifyModel()
> > > x1 -> y2, xy12, NA
> > > x2 -> y1, xy21, NA
> > > y1 -> y2, yy12, NA
> > > y2 -> y3, yy23, NA
> > > y2 -> y4, yy24, NA
> > > y3 -> y4, yy34, NA
> > > y2 <-> y2, y2error, NA
> > > y1 <-> y1, y1error, NA
> > > y3 <-> y3, y3error, NA
> > > y4 <-> y4, y4error, NA
> > >
> > > model.xdata.sem <- sem(model.xdata, cov_matrix, nrow(xdata))
> > >
> > > and the error message is:
> > > Error in csem(model = model.description, start, opt.flag = 1,
> typsize =
> > > typsize,  :
> > >   The matrix is non-invertable.
> > >
> > > I fear to have a problem in the data.
> > > I would be very grateful if you could help me to solve this problem
> and
> > > proceed with my analyses.
> > >
> > > thank you in advance for your help!
> > > Sarah
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Nov  5 19:40:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 5 Nov 2013 10:40:13 -0800 (PST)
Subject: [R] multi
In-Reply-To: <1383673207.801.YahooMailNeo@web142502.mail.bf1.yahoo.com>
References: <1383673207.801.YahooMailNeo@web142502.mail.bf1.yahoo.com>
Message-ID: <1383676813.37524.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(42)
?list1 <- lapply(1:3, function(i) matrix(rnorm(4),2,2))
g <- c(1,2,3)

fun1 <- function(g,hessianList){
? mat1 <- vector(mode="list",length=length(g))
?? for(i in seq_along(g)){
???????? mat1[[i]] <- g[i]*hessianList[[i]]
??? ????????????????? }
Reduce(`+`,mat1)
? 
}

#or
fun2 <- function(g,hessianList){
lst1 <- lapply(seq_along(g),function(i) g[i]*hessianList[[i]])
Reduce(`+`,lst1)
}
identical(fun1(g,list1),fun2(g,list1))
#[1] TRUE
A.K.



On Tuesday, November 5, 2013 1:02 PM, IZHAK shabsogh <ishaqbaba at yahoo.com> wrote:


[[1]]
???????????? [,1]????? [,2]
[1,]? 0.003632559 0.2190629
[2,] -2.090772847 0.2190629

[[2]]
??????????? [,1]?????? [,2]
[1,] 0.004278991 0.04337005
[2,] 0.190723602 0.04337005

[[3]]
?????????? [,1]??????? [,2]
[1,] 0.01237827 -0.01544811
[2,] 0.06452200 -0.01544811

g<-c(1,2,3)

function(g,hessianList){
?? for(i in 1:3){
?? ??? ? ft1<-g[2]*hessianList[[2]]
?? ??? ? ft2<-sum(ft1)
?? ??? ? ft2
?? }
}

can u please help me find out what is the problem with this code

i want to multiply matrix 1-3 by a vector g and sum the result.


thanks
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Nov  5 20:03:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 5 Nov 2013 11:03:53 -0800 (PST)
Subject: [R] Convert date column with two different structures
In-Reply-To: <CAJ-4XAoOM2gN56SUtjs0Uk=PoiKMvnkwNsi-9qB8i=jj5jxzEA@mail.gmail.com>
References: <CAJ-4XAoOM2gN56SUtjs0Uk=PoiKMvnkwNsi-9qB8i=jj5jxzEA@mail.gmail.com>
Message-ID: <1383678233.16326.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
You could try:
library(lubridate)

Date1 <- mdy(as.character(df[,1]))
?Date1[is.na(Date1)] <- parse_date_time(paste(1,as.character(df[,1][is.na(Date1)]),sep="-"),"%d-%b-%y")

A.K.




On Tuesday, November 5, 2013 12:38 PM, Abraham Mathew <abmathewks at gmail.com> wrote:
Let's say I have the following data frame and the date column has two
different ways in which date is presented. How can I use as.Date or the
lubridate package to have one date structure for the entire colum

df = data.frame(Date=c("5/1/13","8/1/13","9/1/13","Apr-10",

? ? ? ? ? ? ? "Apr-11","Apr-12","Apr-13"))
It's "month/date/year" and "month-year".

An alternative approach would be to perform some conditional statements
where if the date is "Apr-11", then populate it with "04/01/2011".

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jvadams at usgs.gov  Tue Nov  5 21:46:23 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 5 Nov 2013 14:46:23 -0600
Subject: [R] multi
In-Reply-To: <1383673207.801.YahooMailNeo@web142502.mail.bf1.yahoo.com>
References: <1383673207.801.YahooMailNeo@web142502.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCFu3xEGY8WQLedixDe9Kz+X3un5CQ10CtHwc2d6=b_FTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/a79947da/attachment.pl>

From smartpink111 at yahoo.com  Tue Nov  5 21:59:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 5 Nov 2013 12:59:31 -0800 (PST)
Subject: [R] Sampling question
Message-ID: <1383685171.69416.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

You may try:
dat1 <- structure(list(SubID = 1:8, CSE1 = c(6L, 6L, 5L, 5L, 5L, 5L, 
3L, 3L), CSE2 = c(5L, 4L, 5L, 4L, 6L, 4L, 6L, 6L), CSE3 = c(6L, 
7L, 5L, 3L, 7L, 3L, 6L, 6L), CSE4 = c(2L, 2L, 5L, 4L, 5L, 6L, 
3L, 3L), WSE1 = c(6L, 6L, 5L, 4L, 6L, 4L, 6L, 6L), WSE2 = c(2L, 
6L, 5L, 4L, 4L, 3L, 5L, 5L), WSE3 = c(2L, 2L, 4L, 5L, 4L, 7L, 
2L, 4L), WSE4 = c(4L, 3L, 5L, 2L, 1L, 3L, 1L, 7L)), .Names = c("SubID", 
"CSE1", "CSE2", "CSE3", "CSE4", "WSE1", "WSE2", "WSE3", "WSE4"
), class = "data.frame", row.names = c(NA, -8L))


fun1 <- function(dat, rep){
res <- replicate(rep,{
?lst1 <-lapply(sample(nrow(dat),nrow(dat)),function(x) sample(dat[x,2:5],4))
names(lst1) <- sapply(lst1,row.names)

lst1[-c(1:2)] <- lapply(names(lst1)[-c(1:2)],function(i) {
??? ??? ??? x1 <- dat[i,6:9][is.na(match(gsub("^.","",names(dat[i,6:9])),gsub("^.","",names(lst1[[i]][1]))))]
??? ??? ??? ?cbind(lst1[[i]][1], sample(x1,3))
??? ??? ??? 
??? ??? ??? ??? }
??? ??? ??? ??? )


?do.call(rbind,lapply(lst1,function(x) {datNew <- cbind(SubID= as.numeric(row.names(x)), x); names(datNew)[-1] <- "var"; datNew}))
})
res
}

?res1 <- fun1(dat1,5)
lst2 <- lapply(split(res1,col(res1)), function(x) {dat <- do.call(cbind,x); colnames(dat) <- c("SubID", rep("var",4));dat})

do.call(cbind,res1[,1])
do.call(cbind,res1[,2])
A.K.




I have a question about drawing samples from a data frame. This might 
sound really tricky. Let me use a data frame I have posted earlier as an example: 

? ? SubID ? ?CSE1 CSE2 CSE3 CSE4 WSE1 WSE2 WSE3 WSE4 
? ? ? 1 ? ? ? ? ?6 ? ? ?5 ? ? ? 6 ? ? ? 2 ? ? ?6 ? ? ?2 ? ? ? ?2 ? ? ? 4 
? ? ? 2 ? ? ? ? ?6 ? ? ?4 ? ? ? 7 ? ? ? 2 ? ? ?6 ? ? ?6 ? ? ? ?2 ? ? ? 3 
? ? ? 3 ? ? ? ? ?5 ? ? ?5 ? ? ? 5 ? ? ? 5 ? ? ?5 ? ? ?5 ? ? ? ?4 ? ? ? 5 
? ? ? 4 ? ? ? ? ?5 ? ? ?4 ? ? ? 3 ? ? ? 4 ? ? ?4 ? ? ?4 ? ? ? ?5 ? ? ? 2 
? ? ? 5 ? ? ? ? ?5 ? ? ?6 ? ? ? 7 ? ? ? 5 ? ? ?6 ? ? ?4 ? ? ? ?4 ? ? ? 1 
? ? ? 6 ? ? ? ? ?5 ? ? ?4 ? ? ? 3 ? ? ? 6 ? ? ?4 ? ? ?3 ? ? ? ?7 ? ? ? 3 
? ? ? 7 ? ? ? ? ?3 ? ? ?6 ? ? ? 6 ? ? ? 3 ? ? ?6 ? ? ?5 ? ? ? ?2 ? ? ? 1 
? ? ? 8 ? ? ? ? ?3 ? ? ?6 ? ? ? 6 ? ? ? 3 ? ? ?6 ? ? ?5 ? ? ? ?4 ? ? ? 7 

this data frame have two sets of variables. each set simply 
represent one scale. as shown above, the first scale, say CSE, consists 
of four items: CSE1, CSE2, CSE3, and CSE4, whereas the second scale, say
 WSE, also has four items: WSE1, WSE2, WSE3, WSE4. 
the leftmost column lists the subjects' ID. 

I wanna create a new data frame through sampling random numbers 
from the data frame above. Below is the structure of the new data frame. 

? ? SubID ? ?var ? ?var ? var ? ? var 
? ? ? s ? ? ? ? ?c ? ? ?c ? ? ?c ? ? ? c ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?c ? ? ?c ? ? ? c ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w ? ? ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w ? ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w ? ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w ? ? ? ? 
? ? ? s ? ? ? ? ?c ? ? ?w ? ? w ? ? ? w 

in the new data frame: 
? 
s= SubID range from 1 to 8 
var= variables 
c=CSE numbers 
w=WSE numbers 

some rules to construct the new data frame: 

1. the top two rows have to be filled with CSE numbers; the 
numbers in the cells of each row should be randomized. for example, if 
the first row is an array of numbers from subject 4, they can follow the
 order: 4(CSE2), 5(CSE1), 3(CSE3), and 4(CSE4). Also, the numbers in the
 second row does not have to follow the order of the first row. for 
example, similarly, if the first row is an array of numbers from subject
 4 in the order: 4(CSE2), 5(CSE1), 3(CSE3), and 4(CSE4), numbers in the 
second row (assuming it is from subject 8) does not have to be 6(CSE2), 
3(CSE1), 6(CSE3), and 3(CSE4). numbers in these two rows should be drawn
 without replacement. 

2. each of the rest of the rows should include a CSE number in 
the leftmost cell and three WSE numbers on the right. At the same time, 
in each row, the three WSE numbers on the right have to be only those 
numbers that are not corresponding to the CSE number in the leftmost 
cell. For example, if the CSE number in the leftmost cell is 4, a CSE2 
number from subject 6, the three WSE numbers on the right side can only 
be 4(WSE1), 7(WSE3), and 3(WSE4) from subject 6. 

3. the numbers in each row can only be drawn from the same 
subject. Also, Subjects should be randomized. Specifically, they does 
have to be in the following order: 

?SubID ? ? 
? ? ? 1 ? ? ? ? 
? ? ? 2 ? ? ? ? ? 
? ? ? 3 ? ? ? ? 
? ? ? 4 ? ? ? ? ? 
? ? ? 5 ? ? ? ? ? 
? ? ? 6 ? ? ? ? ? 
? ? ? 7 ? ? ? ? ? 
? ? ? 8 ? ? 
? ? ? 
they can be: 

?SubID ? ? 
? ? ? 2 ? ? ? ? 
? ? ? 8 ? ? ? ? ? 
? ? ? 5 ? ? ? ? 
? ? ? 4 ? ? ? ? ? 
? ? ? 1 ? ? ? ? ? 
? ? ? 6 ? ? ? ? ? 
? ? ? 7 ? ? ? ? ? 
? ? ? 3 
4. repeat the whole process 1000 times to draw 1000 random samples 

Any ideas? ?Thanks in advance!! :)


From agony_jah at yahoo.com  Wed Nov  6 00:01:51 2013
From: agony_jah at yahoo.com (Agony)
Date: Tue, 5 Nov 2013 15:01:51 -0800 (PST)
Subject: [R] How can I use muliple cores of CPU in Windows or OS X?
Message-ID: <1383692511.50798.YahooMailBasic@web161501.mail.bf1.yahoo.com>

Dear all,

I have about 50 pages of R codes and ran it in both OS X and Windows.
It takes at least haft a day to have the results. The running time is not very different in both Systems.
I found that R does not use all cores of CPU by default.
Can anybody help me to use all cores of CPU in my programming from the beginning or through programming in both OS X and Windows?

Many thanks your attention and help in advance.

Best,
Amir


From simon.pickert at t-online.de  Wed Nov  6 00:26:29 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Wed, 6 Nov 2013 00:26:29 +0100
Subject: [R] How can I use muliple cores of CPU in Windows or OS X?
In-Reply-To: <1383692511.50798.YahooMailBasic@web161501.mail.bf1.yahoo.com>
References: <1383692511.50798.YahooMailBasic@web161501.mail.bf1.yahoo.com>
Message-ID: <52C80D53-90C1-4E70-8A52-55F136B9E435@t-online.de>

Mcapply from package 'parallel'. Also see package 'multicore'


> Am 06.11.2013 um 00:01 schrieb Agony <agony_jah at yahoo.com>:
> 
> Dear all,
> 
> I have about 50 pages of R codes and ran it in both OS X and Windows.
> It takes at least haft a day to have the results. The running time is not very different in both Systems.
> I found that R does not use all cores of CPU by default.
> Can anybody help me to use all cores of CPU in my programming from the beginning or through programming in both OS X and Windows?
> 
> Many thanks your attention and help in advance.
> 
> Best,
> Amir
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul.bivand at gmail.com  Wed Nov  6 00:31:27 2013
From: paul.bivand at gmail.com (Paul Bivand)
Date: Tue, 5 Nov 2013 23:31:27 +0000
Subject: [R] Download CSV Files from EUROSTAT Website
In-Reply-To: <CANVKczPR42Ak7GxL3L=nYHsVgkzn_dEtjo=jag3jJj9qdNDmow@mail.gmail.com>
References: <op.w5tse2qzzqkd1e@bam>
	<CAN5YmCFoU_Zvvj-j_S76Y+O-yD8Stxf7YVDcnEu_ic4Bc-Zj9w@mail.gmail.com>
	<op.w50q3raozqkd1e@bam> <5277ED03.20302@sapo.pt>
	<op.w51gkdmdzqkd1e@nirvana>
	<19fc603f1c0046a1a6d0e4dd10dbcf50@EX-0-HT0.lancs.local>
	<CANVKczPR42Ak7GxL3L=nYHsVgkzn_dEtjo=jag3jJj9qdNDmow@mail.gmail.com>
Message-ID: <CAC=KSNgBw-=y0qYycRf7vaPoakgksmcG8gZm3nJwuUG=_j0A0g@mail.gmail.com>

This looks as though you need to be a little XML old-school.
readHTMLTable is a summary function drawing on:

?htmlTreeParse() turns the table into xml
?xpathApply()
and more.

#xpathApply(doc, , "//td", function(x)xmlValue(x)) breaks each line at
the end of a table cell and extracts the value

# The "//th" picks out the table headings without distinction as to
whether they are rows or columns

Followed by various gsub()  and turning it into a matrix (as this
comes out with a list of values without columns. I couldn't identify
the headings, but the table body is definitely doable.

readHTMLTable seems to assume that the column headings are a single
row, which isn't always the case.

Paul Bivand


On 5 November 2013 18:44, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:
> On 4 Nov 2013 19:30, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>> Maybe you should use their "download" facility rather than trying to
> deparse a complex webpage with lots of special user interaction "features":
>>
>> http://appsso.eurostat.ec.europa.eu/nui/setupDownloads.do
>>
>
> That web page depends on the user already having been to the previous page
> to set up a session and so directly downloading a dataset requires setting
> up cookies and making sure the request has all the right parameters. Looks
> like a right pain.
>
> --
>> David.
>> >
>>
>> On Nov 4, 2013, at 11:03 AM, Lorenzo Isella wrote:
>>
>> > Thanks.
>> > I had already introduced this minor adjustments in the code, but the
> real problem (to me) is the information that gets lost: the informative
> name of the columns, the indicator type and the units.
>>
>> > Cheers
>> >
>> > Lorenzo
>> >
>> > On Mon, 04 Nov 2013 19:52:51 +0100, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>> >
>> >> Hello,
>> >>
>> >> If you want to get rid of the (bp) stuff, you can use lapply/gsub.
> Using Jean's code a bit changed,
>> >>
>> >> library(XML)
>> >>
>> >> mylines <- readLines(url("http://bit.ly/1coCohq"))
>> >> closeAllConnections()
>> >> mytable <- readHTMLTable(mylines, which = 2, asText=TRUE,
> stringsAsFactors = FALSE)
>> >>
>> >> str(mytable)
>> >>
>> >> mytable[] <- lapply(mytable, function(x) gsub("\\(.*\\)", "", x))
>> >> mytable[] <- lapply(mytable, function(x) gsub(",", "", x))
>> >> mytable[] <- lapply(mytable, as.numeric)
>> >>
>> >> colnames(mytable) <- 2000:2013
>> >>
>> >>
>> >> Hope this helps,
>> >>
>> >> Rui Barradas
>> >>
>> >> Em 04-11-2013 09:53, Lorenzo Isella escreveu:
>> >>> Hello,
>> >>> And thanks a lot.
>> >>> This is indeed very close to what I need.
>> >>> I am trying to figure out how not to "lose" the headers and how to
> avoid
>> >>> downloading labels like "(p)" together with the numerical data I am
>> >>> interested in.
>> >>> If anyone on the list knows how to make this minor modifications, s/he
>> >>> will make my life much easier.
>> >>> Cheers
>> >>>
>> >>> Lorenzo
>> >>>
>> >>>
>> >>> On Fri, 01 Nov 2013 14:25:49 +0100, Adams, Jean <jvadams at usgs.gov>
> wrote:
>> >>>
>> >>>> Lorenzo,
>> >>>>
>> >>>> I may be able to help you get started.  You can use the XML package
> to
>> >>>> grab the information >off the internet.
>> >>>>
>> >>>> library(XML)
>> >>>>
>> >>>> mylines <- readLines(url("http://bit.ly/1coCohq"))
>> >>>> closeAllConnections()mylist <- readHTMLTable(mylines,
>> >>>> asText=TRUE)mytable <- mylist1$xTable
>> >>>>
>> >>>> However, when I look at the resulting object, mytable, it doesn't
> have
>> >>>> informative row or >column headings.  Perhaps someone else can figure
>> >>>> out how to get that information.
>> >>>>
>> >>>> Jean
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>> On Thu, Oct 31, 2013 at 10:38 AM, Lorenzo Isella
>> >>>> <lorenzo.isella at gmail.com> wrote:
>> >>>>> Dear All,
>> >>>>> I often need to do some work on some data which is publicly
> available
>> >>>>> on the EUROSTAT >>website.
>> >>>>> I saw several ways to download automatically mainly the bulk data
>> >>>>> from EUROSTAT to later on >>postprocess it with R, for instance
>> >>>>>
>> >>>>> http://bit.ly/HrDICj
>> >>>>> http://bit.ly/HrDL10
>> >>>>> http://bit.ly/HrDTgT
>> >>>>>
>> >>>>> However, what I would like to do is to be able to download directly
>> >>>>> the csv file >>corresponding to a properly formatted dataset
>> >>>>> (typically a dynamic dataset) from EUROSTAT.
>> >>>>> To fix the ideas, please consider the dataset at the following link
>> >>>>>
>> >>>>> http://bit.ly/1coCohq
>> >>>>>
>> >>>>> what I would like to do is to automatically read its content into R,
>> >>>>> or at least to >>automatically download it as a csv file (full
>> >>>>> extraction, single file, no flags and >>footnotes) which I can then
>> >>>>> manipulate easily.
>> >>>>> Any suggestion is appreciated.
>> >>>>> Cheers
>> >>>>>
>> >>>>> Lorenzo
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Wed Nov  6 00:36:37 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 06 Nov 2013 00:36:37 +0100
Subject: [R] How can I use muliple cores of CPU in Windows or OS X?
In-Reply-To: <52C80D53-90C1-4E70-8A52-55F136B9E435@t-online.de>
References: <1383692511.50798.YahooMailBasic@web161501.mail.bf1.yahoo.com>
	<52C80D53-90C1-4E70-8A52-55F136B9E435@t-online.de>
Message-ID: <52798105.2060307@statistik.tu-dortmund.de>



On 06.11.2013 00:26, Simon Pickert wrote:
> Mcapply from package 'parallel'. Also see package 'multicore'

Not mcapply: it won't work under Windows that the OP asked for.

But package parallel is the right hint. It also provides other 
parallelization techniques that will work under Windows.

Best,
Uwe Ligges



>
>
>> Am 06.11.2013 um 00:01 schrieb Agony <agony_jah at yahoo.com>:
>>
>> Dear all,
>>
>> I have about 50 pages of R codes and ran it in both OS X and Windows.
>> It takes at least haft a day to have the results. The running time is not very different in both Systems.
>> I found that R does not use all cores of CPU by default.
>> Can anybody help me to use all cores of CPU in my programming from the beginning or through programming in both OS X and Windows?
>>
>> Many thanks your attention and help in advance.
>>
>> Best,
>> Amir
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peter.langfelder at gmail.com  Wed Nov  6 00:42:40 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 5 Nov 2013 15:42:40 -0800
Subject: [R] How can I use muliple cores of CPU in Windows or OS X?
In-Reply-To: <52798105.2060307@statistik.tu-dortmund.de>
References: <1383692511.50798.YahooMailBasic@web161501.mail.bf1.yahoo.com>
	<52C80D53-90C1-4E70-8A52-55F136B9E435@t-online.de>
	<52798105.2060307@statistik.tu-dortmund.de>
Message-ID: <CA+hbrhW-1KwdyV_Ko-PJarWG1vj42DAE+ysth_u9fOcQ5v=oUQ@mail.gmail.com>

On Tue, Nov 5, 2013 at 3:36 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 06.11.2013 00:26, Simon Pickert wrote:
>>
>> Mcapply from package 'parallel'. Also see package 'multicore'
>
>
> Not mcapply: it won't work under Windows that the OP asked for.
>
> But package parallel is the right hint. It also provides other
> parallelization techniques that will work under Windows.

Packages foreach and doParallel provide ways of writing parallel code
that will run on all systems, without having to worry about details of
parallel computation on each platform.

HTH,

Peter


From angela.dwyer at rmbo.org  Wed Nov  6 00:22:26 2013
From: angela.dwyer at rmbo.org (Angela Dwyer)
Date: Tue, 5 Nov 2013 16:22:26 -0700
Subject: [R] Help on error  (Error: could not find function "kernelUD")
Message-ID: <016501ceda7d$e51b6cb0$af524610$@rmbo.org>

Hello,

I am working through examples of generating Home Range using the
adehabitatHR package. Everything is going fine until I load the code for the
kernelUD function, it looks like this;

> data(puechabonsp)
> kud <- kernelUD(puechabonsp$relocs[,1], h="href")
> kud

I then get an error of;     Error: could not find function "kernelUD"

Any thoughts on what I am doing wrong to get this error, should that
function be built into the package?

Thanks!

Angela (aka very new to R)


From e.beard at ucl.ac.uk  Wed Nov  6 00:36:47 2013
From: e.beard at ucl.ac.uk (EmmaB)
Date: Tue, 5 Nov 2013 15:36:47 -0800 (PST)
Subject: [R] =?utf-8?q?Error_message_glmer_using_R=3A_=E2=80=9C_=27what=27?=
 =?utf-8?q?_must_be_a_character_string_or_a_function=E2=80=9D?=
Message-ID: <1383694607649-4679829.post@n4.nabble.com>

I am running a multi-level model. I use the following commands with
validatedRS6 as the outcome, random as the predictor and clustno as the
random effects variable.

new<-as.data.frame(read.delim("BABEX.dat", header=TRUE))
install.packages("lme4")
library(lme4)
model1<- glmer(validatedRS6 ~ random + (1|clustno), data=new,
family=binomial("logit"), nAGQ)

However, I get the following error

Error in do.call(new, c(list(Class = "glmResp", family = family),
ll[setdiff(names(ll), : 'what' must be a character string or a function

I have absolutely no idea what has gone wrong and have searched the
internet. I am sorry but I cannot provide the data as it is from an
intervention which has yet to be published.

Many thanks

Emma




--
View this message in context: http://r.789695.n4.nabble.com/Error-message-glmer-using-R-what-must-be-a-character-string-or-a-function-tp4679829.html
Sent from the R help mailing list archive at Nabble.com.


From cyril.auburtin at gmail.com  Wed Nov  6 01:02:38 2013
From: cyril.auburtin at gmail.com (Cyril Auburtin)
Date: Wed, 6 Nov 2013 01:02:38 +0100
Subject: [R] grnn issue
Message-ID: <CAKteAhEGu4MWOMHDezUTXjCdO+a4J9VYc0Oh9_ib6JBGb0dVhA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/ab929eeb/attachment.pl>

From price_ja at hotmail.com  Wed Nov  6 01:35:34 2013
From: price_ja at hotmail.com (James Price)
Date: Tue, 5 Nov 2013 16:35:34 -0800
Subject: [R] Finding absolute viewport location in grid / lattice
Message-ID: <BAY175-W41B9F0644AE64FE2C660A8F6F00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131105/e1944c61/attachment.pl>

From dwinsemius at comcast.net  Wed Nov  6 01:42:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Nov 2013 16:42:31 -0800
Subject: [R]
 =?windows-1252?q?Error_message_glmer_using_R=3A_=93_=27what?=
 =?windows-1252?q?=27_must_be_a_character_string_or_a_function=94?=
In-Reply-To: <1383694607649-4679829.post@n4.nabble.com>
References: <1383694607649-4679829.post@n4.nabble.com>
Message-ID: <41691CFF-1263-42DB-B975-4574CB6A13EB@comcast.net>


On Nov 5, 2013, at 3:36 PM, EmmaB wrote:

> I am running a multi-level model. I use the following commands with
> validatedRS6 as the outcome, random as the predictor and clustno as the
> random effects variable.
> 
> new<-as.data.frame(read.delim("BABEX.dat", header=TRUE))
> install.packages("lme4")
> library(lme4)
> model1<- glmer(validatedRS6 ~ random + (1|clustno), data=new,
> family=binomial("logit"), nAGQ)
> 
> However, I get the following error
> 
> Error in do.call(new, c(list(Class = "glmResp", family = family),
> ll[setdiff(names(ll), : 'what' must be a character string or a function
> 
> I have absolutely no idea what has gone wrong and have searched the
> internet. I am sorry but I cannot provide the data as it is from an
> intervention which has yet to be published.

You at least need to post the output of str(new).


> --
> View this message in context: http://r.789695.n4.nabble.com/Error-message-glmer-using-R-what-must-be-a-character-string-or-a-function-tp4679829.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From e.beard at ucl.ac.uk  Wed Nov  6 01:47:56 2013
From: e.beard at ucl.ac.uk (EmmaB)
Date: Tue, 5 Nov 2013 16:47:56 -0800 (PST)
Subject: [R]
 =?utf-8?q?Error_message_glmer_using_R=3A_=E2=80=9C_=27what=27?=
 =?utf-8?q?_must_be_a_character_string_or_a_function=E2=80=9D?=
In-Reply-To: <1383694607649-4679829.post@n4.nabble.com>
References: <1383694607649-4679829.post@n4.nabble.com>
Message-ID: <1383698876009-4679836.post@n4.nabble.com>

> str(new)
'data.frame':   1214 obs. of  4 variables:
 $ ?..VAR00001 : logi  NA NA NA NA NA NA ...
 $ random      : int  1 1 1 1 1 1 1 1 1 1 ...
 $ clustno     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ validatedRS6: int  0 0 0 0 0 0 0 0 0 0 ...



--
View this message in context: http://r.789695.n4.nabble.com/Error-message-glmer-using-R-what-must-be-a-character-string-or-a-function-tp4679829p4679836.html
Sent from the R help mailing list archive at Nabble.com.


From qaisfayyad at gmail.com  Wed Nov  6 06:14:46 2013
From: qaisfayyad at gmail.com (Cahaya Iman)
Date: Wed, 6 Nov 2013 16:14:46 +1100
Subject: [R] Goodness Of Fit for Nonparametric Copulas
Message-ID: <CAMZD=bf=dY6ejgF_Agk-EBTt0xEuWx=v++T5XtLH1pmA5OYBbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/fe32206f/attachment.pl>

From 20282734 at student.uwa.edu.au  Wed Nov  6 06:27:53 2013
From: 20282734 at student.uwa.edu.au (Scottyfromaussie)
Date: Tue, 5 Nov 2013 21:27:53 -0800 (PST)
Subject: [R] Rugarch issue. Any help would be great!
Message-ID: <1383715673882-4679841.post@n4.nabble.com>

Hi there

I'm having a bit of trouble with my code that I'm writing.

Essentially I'm trying to do a rolling eGARCH forecast for a dataset, namely
DataExplorers which is a portfolio of gold exploration stocks.

I'm hoping to get it so that it calculates the eGARCH for each day and
refits itself each day.

The error message I keep getting is

/"Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf"/


I've been googling this issue and trying to adjust the parameters in
ugarchroll. When I do this I get other errors such as 

/"Warning message:
In .makefitmodel(garchmodel = "eGARCH", f = .egarchLLH, T = T, m = m,  : 
rugarch-->warning: failed to invert hessian"/


and

/"Warning message:
In .rollfdensity(spec = spec, data = data, n.ahead = n.ahead,
forecast.length = forecast.length,  :
  
non-converged estimation windows present...resubsmit object with different
solver parameters..."/

Has anyone got an idea whats going wrong? Thanks to anyone who replies, I'm
sure you've got better things to go than answer my questions :)

Scotty

My code is as follows:

library(rugarch)
setwd("C:/Users/Scott/Dropbox/Stat 7444 Project/")

##Data Bank##

goldstockdata = read.csv("DataExplorers.csv", header = TRUE)  

t = log(goldstockdata)[1:2500,"Adj.Close"]
goldstockreturns <- diff(log(t))

## Specify GARCH Parameters ##

model=ugarchspec (
variance.model = list(model = "eGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(1, 1)),
distribution.model = "std"
)

stockmodelroll=ugarchroll (
spec=model, data=goldstockreturns, n.ahead = 1,
n.start = 1, refit.every = 1, refit.window = c("recursive"),
window.size = 1, solver = "hybrid", fit.control = list(),
solver.control = list(), calculate.VaR = FALSE, VaR.alpha = c(0.01,
0.05),
cluster = NULL, keep.coef = TRUE
)

str(stockmodelroll at forecast)
stockgarch=stockmodelroll at forecast$density[,"Sigma"]

plot(stockgarch)



--
View this message in context: http://r.789695.n4.nabble.com/Rugarch-issue-Any-help-would-be-great-tp4679841.html
Sent from the R help mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Wed Nov  6 11:04:06 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 6 Nov 2013 10:04:06 +0000
Subject: [R] ascii-grid export
In-Reply-To: <6f693057937b44eba6bf89a4d0569fa6@EX-0-HT0.lancs.local>
References: <a9f9d52a74ef493c927d218efa052d60@EX-1-HT0.lancs.local>
	<CANVKczMq0L71LMJbiha3iBDxDptwFNNCDCjxcz57iEL-zp9zfw@mail.gmail.com>
	<6f693057937b44eba6bf89a4d0569fa6@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPuRbS-E7Y4ZpDTPW0xnZdU3vXw4B33qSxno+fEUQ=sSg@mail.gmail.com>

On Mon, Nov 4, 2013 at 7:27 AM, Enzo Cocca <enzo.ccc at gmail.com> wrote:
> yes barry I really need this.
>
> I tried to use raster or rgdal but with poor results.
>
> I have this function:
>
> VGM_PARAM_A3 <- gstat(id="bos_bison",
> formula=combusto~1,locations=~coord_x+coord_y, data=archezoology_table,
> nmax = 10)
>
> VGM_PARAM_A3 <- gstat(VGM_PARAM_A3, model=vgm(1, "Sph", 5, 0),
> fill.all=TRUE)
>
> ESV_A3 <- variogram(VGM_PARAM_A3, map=True, with=0.1, cutoff=9)
>
> VARMODEL_A3 = fit.lmc(ESV_A3, VGM_PARAM_A3)
>
> plot(ESV_A3, threshold = 5, col.regions = bpy.colors(), xlab=, ylab=,
> main="Map - A3")
> png("C:\Users\User\pyarchinit_R_folder\A3 semivariogram_map.png",
> width=10000, height=10000, res=400)
>
> I make a png file but how can I convert it in ascii-grid?

Why do you want to make an ascii-grid out of this? The variogram map
isn't in geographical coordinates, its in coordinate differences in x
and y

The return value when map=TRUE doesn't seem to be too well documented,
but looks like it is a list with a 'map' element that is a spatial
pixels data frame. Here's an example using the demo data (I can't run
your code because I don't have your data, please try and make your
problems easily reproducible):

require(sp)
require(gstat)
data(meuse)
coordinates(meuse)=~x+y
v=variogram(log(zinc)~1, meuse,map=TRUE,cutoff=900,width=10)
class(v$map)
[1] "SpatialPixelsDataFrame"
attr(,"package")
[1] "sp"

Now that can be written using rgdal's writeGDAL function.

However, you need the AAIGrid driver to work properly:

> writeGDAL(v$map,"vmap.ag",driver="AAIGrid")
Error in .local(.Object, ...) : Dataset copy failed

raster package to the rescue:

> require(raster)
> writeRaster(raster(v$map),"v.asc","ascii")
class       : RasterLayer

[etc]

When I look at the file, I have an ESRI grid file:

$ head -5 v.asc
NCOLS 181
NROWS 181
XLLCORNER -905
YLLCORNER -905
CELLSIZE 10
[+ data]

Now, that's assuming you wanted to write the data, not a pretty image
picture like you get when you plot the variogram map. And there's
still the mystery of why you want to write a non-geographic
coordinate-based dataset to a geographic data format...

 And you should probably have asked this on R-sig-geo where the
geographRs (including the authors of gstat) hang out.

 Hope this helps anyway.

Barry


From c-w.hoffmann at sunrise.ch  Wed Nov  6 11:08:00 2013
From: c-w.hoffmann at sunrise.ch (hoffmann)
Date: Wed, 06 Nov 2013 11:08:00 +0100
Subject: [R] help.start hangs
Message-ID: <527A1500.9050805@echoffmann.ch>

Hi,

After helpstart() and the first jump into a package, the nest jump will 
keep trying endlessly Then I go back to the R window, where '> Making 
'packages.html' ... done' is being displayed but no prompt. So I bring 
back the prompt by ^C^C. Then, o wonder, the prompt comes back and in 
the browser (Thunderbird) the desired package display is shown.

Is there a remedy for this?

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] C

attached base packages:
  [1] tools     tcltk     stats4    splines   parallel  datasets  compiler
  [8] graphics  grDevices stats     grid      utils     methods   base

other attached packages:
  [1] survival_2.37-4    spatial_7.3-7      rpart_4.1-3 
nnet_7.3-7
  [5] mgcv_1.7-26        nlme_3.1-111       foreign_0.8-55 
codetools_0.2-8
  [9] cluster_1.14.4     class_7.3-9        boot_1.3-9 
Matrix_1.0-14
[13] MASS_7.3-29        KernSmooth_2.23-10 cwhmisc_4.2 
lattice_0.20-23



Who is willing to give me advice?

TIA  -- Christian

-- 
Christian W. Hoffmann,
CH - 8915 Hausen am Albis, Switzerland
Rigiblickstrasse 15 b, Tel.+41-44-7640853
christian at echoffmann.ch,
www.echoffmann.ch


-- 
Christian W. Hoffmann,
CH - 8915 Hausen am Albis, Switzerland
Rigiblickstrasse 15 b, Tel.+41-44-7640853
(!! c-w.hoffmann at sunrise.ch, <will be eliminated in the near future,
instead Bitte nicht mehr benutzen !!, stattdessen: >)
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From jwd at surewest.net  Wed Nov  6 07:17:40 2013
From: jwd at surewest.net (jwd)
Date: Tue, 5 Nov 2013 22:17:40 -0800
Subject: [R] Help on error  (Error: could not find function "kernelUD")
In-Reply-To: <016501ceda7d$e51b6cb0$af524610$@rmbo.org>
References: <016501ceda7d$e51b6cb0$af524610$@rmbo.org>
Message-ID: <20131105221740.70f60e24@draco.site>

On Tue, 5 Nov 2013 16:22:26 -0700
"Angela Dwyer" <angela.dwyer at rmbo.org> wrote:

You didn't forget to load the library did you?  The bit of output you
provide doesn't show a "library(adehabitat)" line.  That needs to be run
before the function can be found.

JWDougherty


From d.stasinopoulos at londonmet.ac.uk  Wed Nov  6 12:29:25 2013
From: d.stasinopoulos at londonmet.ac.uk (Mikis Stasinopoulos)
Date: Wed, 6 Nov 2013 11:29:25 +0000
Subject: [R] hidden functions
Message-ID: <6ED6C84C-543B-4F9E-9976-F93EC60C17DE@staff.londonmet.ac.uk>

Is there a way which I can use a hidden function say f() of a package say "foo", (that is, f()is non exported in the NAMESPACE of "foo")  within the package "foo" without using foo:::f()

Mikis
   
Prof Mikis Stasinopoulos
d.stasinopoulos at londonmet.ac.uk



Companies Act 2006 : http://www.londonmet.ac.uk/companyinfo



From Nina.Schoenfelder at FernUni-Hagen.de  Wed Nov  6 12:44:48 2013
From: Nina.Schoenfelder at FernUni-Hagen.de (=?ISO-8859-15?Q?Nina_Sch=F6nfelder?=)
Date: Wed, 6 Nov 2013 12:44:48 +0100
Subject: [R] Problem with the collapse option in pgmm function in the plm
 package
Message-ID: <527A2BB0.7080207@fernuni-hagen.de>

Hi all,
I am working with the "Wages" data from plm package to learn something 
about the pgmm function (Arellano&Bond estimator, Blundell&Bond estimator).
In the following regression, I assume that the variable lwage is the 
lagged dependent regressor and the variable wks is weak exogenous, so I 
can use the lags 1 and up as instruments for wks.
Everything is fine, as long as I set the option "collapse = FALSE" for 
collapsing the instruments.

 > library(plm)
 > ## with Wages data from plm-package
 > data("Wages", package = "plm")
 > Wag <- pdata.frame(Wages, 595)

 > ## No collapsing of instruments
 > z1<-pgmm(lwage~lag(lwage,1) + wks     | lag(lwage,2:99)+ lag(wks,1:99),
     data=Wag, effect="twoway", collapse = FALSE, 
model="onestep",transformation = "d")
 >tail(z1$W,1)

 >## With collapsing the instruments
 > z1<-pgmm(lwage~lag(lwage,1) + wks   | lag(lwage,2:99)+ lag(wks,1:99),
     data=Wag, effect="twoway", collapse = TRUE, 
model="onestep",transformation = "d")
 >tail(z1$W,1)
Es gab 50 oder mehr Warnungen (Anzeige der ersten 50 mit warnings())
 > warnings()
Warnmeldungen:
1: In matrix(unlist(u), nrow = nrow(u[[1]])) :
   Datenl?nge [61] ist kein Teiler oder Vielfaches der Anzahl der Zeilen [5]
2: In matrix(unlist(u), nrow = nrow(u[[1]])) :
   Datenl?nge [61] ist kein Teiler oder Vielfaches der Anzahl der Zeilen [5]

 > tail(z1$W,1)
$`595`
         [,1]    [,2]    [,3]    [,4]    [,5] [,6] [,7] [,8] [,9] [,10] 
[,11] [,12]
[1,] 5.68698 0.00000 0.00000 0.00000 0.00000   52   50   49   50 0     
0     0
[2,] 5.85793 5.68698 0.00000 0.00000 0.00000   50    0   50   50 52     
0     0
[3,] 5.95324 5.85793 5.68698 0.00000 0.00000   50   52    0   49 50     
0     0
[4,] 6.06379 5.95324 5.85793 5.68698 0.00000   49   50    0    0 50    
52     0
[5,] 6.21461 6.06379 5.95324 5.85793 5.68698   50   50   52    0 0    
50     0
         [,13] [,14] [,15] [,16] [,17] [,18]
[1,] 52.00000     1     0     0     0     0
[2,]  5.68698    -1     1     0     0     0
[3,]  5.85793     0    -1     1     0     0
[4,]  5.95324     0     0    -1     1     0
[5,]  6.06379     0     0     0    -1     1



As you can see, the instrument matrix looks very strange for the weak 
exogenous variable, i.e. the columns 6 to 13. Is that a bug in pgmm, or 
did I miss something?

Thanks for suggestions!

Nina Sch?nfelder

-----
FernUniversit?t in Hagen
Fakult?t f?r Wirtschaftswissenschaft
Lehrstuhl f?r Volkswirtschaftslehre,
insbes. Makro?konomik
58084 Hagen
E-Mail: Nina.Schoenfelder at FernUni-Hagen.de


From kh_harut at yahoo.com  Wed Nov  6 09:35:27 2013
From: kh_harut at yahoo.com (Harutyun Khachatryan)
Date: Wed, 6 Nov 2013 00:35:27 -0800 (PST)
Subject: [R] WriteBin problem
Message-ID: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>

Dear R project officials,

I have found that in R 3.0.1 version "writeBin" function of "base" package might not work correctly. For command writeBin("100",raw()) it answers "31 30 30 00" the last double 0 is differs from http://www.branah.com/ascii-converter there ascii codes are "31 30 30". So is it normal having double 0-s after ascii codes and what it means? 

Thank you in advance.
Regards, Harutyun Khachatryan.


From hossam.hassanien at gmail.com  Wed Nov  6 12:00:29 2013
From: hossam.hassanien at gmail.com (Hossam Hassanien)
Date: Wed, 6 Nov 2013 15:00:29 +0400
Subject: [R] Fraud and Anomaly detection packages in R...
Message-ID: <CAGUsVcfZ04Si96i2zS+fRdkjn3CKUu=4qRRh9N2R5JgkzP55Jw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/649fa960/attachment.pl>

From babakbsn at gmail.com  Wed Nov  6 13:15:12 2013
From: babakbsn at gmail.com (Baro)
Date: Wed, 6 Nov 2013 04:15:12 -0800
Subject: [R] Fraud and Anomaly detection packages in R...
In-Reply-To: <CAGUsVcfZ04Si96i2zS+fRdkjn3CKUu=4qRRh9N2R5JgkzP55Jw@mail.gmail.com>
References: <CAGUsVcfZ04Si96i2zS+fRdkjn3CKUu=4qRRh9N2R5JgkzP55Jw@mail.gmail.com>
Message-ID: <CAF-JZQts1MuiqeofwA_FgzcRGGxWtQF8ty7oSJ8cKiEAPizvBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/73c980db/attachment.pl>

From zhyuanzh at gmail.com  Wed Nov  6 13:32:10 2013
From: zhyuanzh at gmail.com (Zhong-Yuan Zhang)
Date: Wed, 6 Nov 2013 20:32:10 +0800
Subject: [R] Function does not see variables outside the function
In-Reply-To: <1383656069289-4679768.post@n4.nabble.com>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
	<1383656069289-4679768.post@n4.nabble.com>
Message-ID: <CAApZs+HCZ4KAt=D+anxrV4Fg4XMwNoHRTosQL=LjsRjVYdi+8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/0058c24c/attachment.pl>

From abhinavk698 at gmail.com  Wed Nov  6 13:34:03 2013
From: abhinavk698 at gmail.com (Abhinav Kashyap)
Date: Wed, 6 Nov 2013 18:04:03 +0530
Subject: [R]  CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
Message-ID: <CACkB_X3gi5oHCuatVBNjXm0vwtWaZmjpusMKWwVF5YxPmjtE9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/58a26140/attachment.pl>

From murdoch.duncan at gmail.com  Wed Nov  6 14:12:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 Nov 2013 08:12:30 -0500
Subject: [R] WriteBin problem
In-Reply-To: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>
References: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>
Message-ID: <527A403E.80704@gmail.com>

On 06/11/2013 3:35 AM, Harutyun Khachatryan wrote:
> Dear R project officials,
>
> I have found that in R 3.0.1 version "writeBin" function of "base" package might not work correctly. For command writeBin("100",raw()) it answers "31 30 30 00" the last double 0 is differs from http://www.branah.com/ascii-converter there ascii codes are "31 30 30". So is it normal having double 0-s after ascii codes and what it means?
>

 From ?writeBin:

"|readBin| and |writeBin| read and write C-style zero-terminated 
character strings."

Duncan Murdoch


From cyril.auburtin at gmail.com  Wed Nov  6 14:19:41 2013
From: cyril.auburtin at gmail.com (Cyril Auburtin)
Date: Wed, 6 Nov 2013 14:19:41 +0100
Subject: [R] grnn issue
In-Reply-To: <CAKteAhEGu4MWOMHDezUTXjCdO+a4J9VYc0Oh9_ib6JBGb0dVhA@mail.gmail.com>
References: <CAKteAhEGu4MWOMHDezUTXjCdO+a4J9VYc0Oh9_ib6JBGb0dVhA@mail.gmail.com>
Message-ID: <CAKteAhHh0-xPMpFUSSB6AOiiU60Xfnv7UFk-BmF2K2JU4nw7vQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/a468e352/attachment.pl>

From friendly at yorku.ca  Wed Nov  6 14:45:11 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 06 Nov 2013 08:45:11 -0500
Subject: [R] variable standardization in manova() call
In-Reply-To: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
References: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
Message-ID: <527A47E7.7080606@yorku.ca>

On 11/4/2013 10:45 AM, Sergio Fonda wrote:
> Hi,
> I'm not able to get information about the following question:
>
> is the variables standardization a default option in manova() (stats package)?
> Or if you want to compare variables with different units or scales and
> rather different variances, you have to previously standardize the
> variables ?
>

If you mean the response variables, manova() does not require equal
variances and does not standardize.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From friendly at yorku.ca  Wed Nov  6 14:45:11 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 6 Nov 2013 08:45:11 -0500
Subject: [R] variable standardization in manova() call
In-Reply-To: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
References: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
Message-ID: <527A47E7.7080606@yorku.ca>

On 11/4/2013 10:45 AM, Sergio Fonda wrote:
> Hi,
> I'm not able to get information about the following question:
>
> is the variables standardization a default option in manova() (stats package)?
> Or if you want to compare variables with different units or scales and
> rather different variances, you have to previously standardize the
> variables ?
>

If you mean the response variables, manova() does not require equal
variances and does not standardize.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jfox at mcmaster.ca  Wed Nov  6 14:57:13 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 6 Nov 2013 08:57:13 -0500
Subject: [R] Function does not see variables outside the function
In-Reply-To: <CAApZs+HCZ4KAt=D+anxrV4Fg4XMwNoHRTosQL=LjsRjVYdi+8Q@mail.gmail.com>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>	<1383656069289-4679768.post@n4.nabble.com>
	<CAApZs+HCZ4KAt=D+anxrV4Fg4XMwNoHRTosQL=LjsRjVYdi+8Q@mail.gmail.com>
Message-ID: <000a01cedaf8$18f420c0$4adc6240$@mcmaster.ca>

Dear Zhong-Yuan Zhang,

R is lexically scoped. Pretending that you're using a different programming
language is probably a bad idea. 

The findGlobals() function in the codetools package, which is part of the
standard R distribution, can help you locate references to global variables
(and functions) in a function. For example,

> f <- function() g(a)

> findGlobals(f)
[1] "a" "g"

> ff <- function() {a <- 10; g(a)}

> findGlobals(ff)
[1] "{"  "<-" "g"

> fff <- function(a) g(a)

> findGlobals(fff)
[1] "g"

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Zhong-Yuan Zhang
> Sent: Wednesday, November 06, 2013 7:32 AM
> To: r-help at r-project.org
> Subject: Re: [R] Function does not see variables outside the function
> 
> Dear Experts:
> 
>     I am very appreciate your comments and help!
> 
>     Actually I am a new comer from MATLAB. If the function
> 
> can see global variables, then it may output wrong results without
> 
> any error messages. For example, there is a gloabl variable named
> 
> v, and I write one funciton with one local variable x. However, in some
> line,
> 
> I misspelled x to v, which would results in unexpected errors without
> warning.
> 
>     In summary, I want to disable the ability to make debugging easier.
> 
>     Best.
> 
> 
> 2013/11/5 Carl Witthoft <carl at witthoft.com>
> 
> > Why would you want to impose this restriction?  Perhaps if you
> explain what
> > you are trying to do, we can suggest approaches that will satisfy
> your
> > specific needs.
> > (note- one can always redefine whatever variables are to be
> "excluded."
> > E.g.
> > to keep the body of a function from referring to 'foo' in the calling
> > environment, just add the line 'foo<-NA' inside the function)
> >
> >
> > Zhong-Yuan Zhang wrote
> > >      In MATLAB, functions cannot see variables outside the
> > >
> > > functions.  However, in R, the functions can do that. Is there
> > >
> > > any settings that can disable this ability of functions?
> > >
> > >
> > > ______________________________________________
> >
> > > R-help@
> >
> > >  mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/Function-does-not-see-variables-
> outside-the-function-tp4679762p4679768.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> 
> --
> Zhong-Yuan Zhang (PhD.)
> Associate Professor
> School of Statistics
> Central University of Finance and Economics
> 39 South College Road, Haidian District, Beijing, P.R.China 100081
> Email: zhyuanzh at gmail.com
> Homepage: http://en.stat.cufe.edu.cn/zhongyuanzhang/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Wed Nov  6 14:30:14 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 6 Nov 2013 05:30:14 -0800 (PST)
Subject: [R] WriteBin problem
In-Reply-To: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>
References: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>
Message-ID: <1383744614555-4679855.post@n4.nabble.com>


First of all,  use "readBin" to verify you get the desired data back.  
Second, that '00' is, I believe the <EOF> character you'll find at the end
of any file.


Harutyun Khachatryan wrote
> Dear R project officials,
> 
> I have found that in R 3.0.1 version "writeBin" function of "base" package
> might not work correctly. For command writeBin("100",raw()) it answers "31
> 30 30 00" the last double 0 is differs from
> http://www.branah.com/ascii-converter there ascii codes are "31 30 30". So
> is it normal having double 0-s after ascii codes and what it means? 





--
View this message in context: http://r.789695.n4.nabble.com/WriteBin-problem-tp4679853p4679855.html
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Wed Nov  6 16:30:52 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 06 Nov 2013 16:30:52 +0100
Subject: [R] CRAN mirror for R in India: new one at WBUT,
 how do we get listed in the CRAN website?
In-Reply-To: <CACkB_X3gi5oHCuatVBNjXm0vwtWaZmjpusMKWwVF5YxPmjtE9w@mail.gmail.com>
References: <CACkB_X3gi5oHCuatVBNjXm0vwtWaZmjpusMKWwVF5YxPmjtE9w@mail.gmail.com>
Message-ID: <527A60AC.6010107@statistik.tu-dortmund.de>

See

http://cran.r-project.org/mirror-howto.html

Best,
Uwe Ligges

On 06.11.2013 13:34, Abhinav Kashyap wrote:
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Wed Nov  6 17:04:07 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 Nov 2013 16:04:07 +0000
Subject: [R]
 =?utf-8?q?Error_message_glmer_using_R=3A_=E2=80=9C_=27what=27?=
 =?utf-8?q?_must_be_a_character_string_or_a_function=E2=80=9D?=
In-Reply-To: <1383698876009-4679836.post@n4.nabble.com>
References: <1383694607649-4679829.post@n4.nabble.com>
	<1383698876009-4679836.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA130F3@PA-MBX01.na.tibco.com>

You can reproduce the problem by having a data.frame (or anything else) in your
environment:

new <- data.frame(?..VAR00001 = rep(c(TRUE,NA,FALSE), c(10,2,8)), random=rep(1:3,len=20), clustno=rep(c(1:5),len=20), validatedRS6=rep(0:1,len=20))
model1<- glmer(validatedRS6 ~ random + (1|clustno), data=new, family=binomial(), nAGQ=3)
# Error in do.call(new, c(list(Class = "glmResp", family = family), ll[setdiff(names(ll),  : 
#  'what' must be a character string or a function

The problem is in the call
   do.call(new, list())
It finds your dataset 'new' (in .GlobalEnv), which is not a function or the name of a function,
not the function 'new' from the 'methods' package.  Rename your dataset, so you do not
have anything called 'new' masking the one in package:methods, and things should work.

Write to the maintainer of the package (use maintainer("lme4") for the address) about the
problem.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of EmmaB
> Sent: Tuesday, November 05, 2013 4:48 PM
> To: r-help at r-project.org
> Subject: Re: [R] Error message glmer using R: ? 'what' must be a character string or a
> function?
> 
> > str(new)
> 'data.frame':   1214 obs. of  4 variables:
>  $ ?..VAR00001 : logi  NA NA NA NA NA NA ...
>  $ random      : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ clustno     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ validatedRS6: int  0 0 0 0 0 0 0 0 0 0 ...
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-message-glmer-
> using-R-what-must-be-a-character-string-or-a-function-tp4679829p4679836.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.CA.us  Wed Nov  6 17:05:27 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 06 Nov 2013 08:05:27 -0800
Subject: [R] WriteBin problem
In-Reply-To: <1383744614555-4679855.post@n4.nabble.com>
References: <1383726927.82489.YahooMailBasic@web121304.mail.ne1.yahoo.com>
	<1383744614555-4679855.post@n4.nabble.com>
Message-ID: <7b577d5c-10ad-444a-9ed7-8e13da702440@email.android.com>

Sorry, Carl, but you missed the boat on both responses.

Using readBin to read what they wrote won't help the OP if they don't understand what they are writing.  Nor is byte 0 the EOF marker on any operating system I have ever used. (It does happen to be the string terminator for in-memory strings in the C language, and it is actually not unusual to find NUL-termination used in strings that are stored in binary files. The OP does seem to be confused about the difference between binary files and text files, both of which can be affected by the disk format, CPU type, and operating system that are in use.)

I recommend that the OP use raw vectors (see ?raw) if they want to read and write binary data. I also recommend using the hexView package to manipulate the contents of raw vectors.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Carl Witthoft <carl at witthoft.com> wrote:
>
>First of all,  use "readBin" to verify you get the desired data back.  
>Second, that '00' is, I believe the <EOF> character you'll find at the
>end
>of any file.
>
>
>Harutyun Khachatryan wrote
>> Dear R project officials,
>> 
>> I have found that in R 3.0.1 version "writeBin" function of "base"
>package
>> might not work correctly. For command writeBin("100",raw()) it
>answers "31
>> 30 30 00" the last double 0 is differs from
>> http://www.branah.com/ascii-converter there ascii codes are "31 30
>30". So
>> is it normal having double 0-s after ascii codes and what it means? 
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/WriteBin-problem-tp4679853p4679855.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Wed Nov  6 17:25:23 2013
From: alaios at yahoo.com (Alaios)
Date: Wed, 6 Nov 2013 08:25:23 -0800 (PST)
Subject: [R] convert one digit numbers to two digits one
Message-ID: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/173bd37d/attachment.pl>

From dwinsemius at comcast.net  Wed Nov  6 17:32:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 08:32:13 -0800
Subject: [R] convert one digit numbers to two digits one
In-Reply-To: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
References: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
Message-ID: <24678416-74AE-4475-A92C-24071EAEDC0B@comcast.net>


On Nov 6, 2013, at 8:25 AM, Alaios wrote:

> Hi all,
> the following returns the hour and the minutes
> 
> paste(DataSet$TimeStamps[selectedInterval$start,4], DataSet$TimeStamps[selectedInterval$start,5],sep=":")
> [1] "12:3"
> 
> the problem is that from these two I want to create a time stamp so 12:03. The problem is that the number 3 is not converted to 03. Is there an easy way when I have one digit integer to add a zero in the front? Two digits integers are working fine so far, 12:19, or 12:45 would appear correctly
> 

?sprintf  # other options are linked from that page.

> 
> 	[[alternative HTML version deleted]]
Sigh.
-- 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Wed Nov  6 17:33:47 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 6 Nov 2013 08:33:47 -0800
Subject: [R] convert one digit numbers to two digits one
In-Reply-To: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
References: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
Message-ID: <CACk-te2J4+ozXRHj7c1wqEmp3+sMgyLwNtXmhhu58e=c3_1+Fg@mail.gmail.com>

(Assuming I understand) tons of ways of doing this.

So I'll just point out the
?nchar
function, which you can use to count characters in your tail end and
paste a "0" if there's only one, e.g. via ifelse() .

-- Bert

On Wed, Nov 6, 2013 at 8:25 AM, Alaios <alaios at yahoo.com> wrote:
> Hi all,
> the following returns the hour and the minutes
>
> paste(DataSet$TimeStamps[selectedInterval$start,4], DataSet$TimeStamps[selectedInterval$start,5],sep=":")
> [1] "12:3"
>
> the problem is that from these two I want to create a time stamp so 12:03. The problem is that the number 3 is not converted to 03. Is there an easy way when I have one digit integer to add a zero in the front? Two digits integers are working fine so far, 12:19, or 12:45 would appear correctly
>
> I would like to thank you in advance for your help
>
> Regards
> Alex
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gaiarrido at usal.es  Wed Nov  6 17:33:52 2013
From: gaiarrido at usal.es (Mario Garrido)
Date: Wed, 6 Nov 2013 17:33:52 +0100
Subject: [R] Remove from the mailing list
Message-ID: <CABi7Y8Y9PLfXsQxj64uZQKYyanAMaPbkeskoX8cwBcL7QL5oRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/59775e53/attachment.pl>

From marc_schwartz at me.com  Wed Nov  6 17:34:03 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 06 Nov 2013 10:34:03 -0600
Subject: [R] convert one digit numbers to two digits one
In-Reply-To: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
References: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
Message-ID: <A518F2CE-82AB-462E-8044-5201608386BC@me.com>

On Nov 6, 2013, at 10:25 AM, Alaios <alaios at yahoo.com> wrote:

> Hi all,
> the following returns the hour and the minutes
> 
> paste(DataSet$TimeStamps[selectedInterval$start,4], DataSet$TimeStamps[selectedInterval$start,5],sep=":")
> [1] "12:3"
> 
> the problem is that from these two I want to create a time stamp so 12:03. The problem is that the number 3 is not converted to 03. Is there an easy way when I have one digit integer to add a zero in the front? Two digits integers are working fine so far, 12:19, or 12:45 would appear correctly
> 
> I would like to thank you in advance for your help
> 
> Regards
> Alex


This is an example where using ?sprintf gives you more control:

> sprintf("%02d:%02d", 12, 3)
[1] "12:03"

> sprintf("%02d:%02d", 9, 3)
[1] "09:03"


The syntax '%02d' tells sprintf to print the integer and pad with leading zeroes to two characters where needed.

Regards,

Marc Schwartz


From alfonso.carfora at uniparthenope.it  Wed Nov  6 17:30:01 2013
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Wed, 06 Nov 2013 17:30:01 +0100
Subject: [R] resdiuals of random model estimated by plm function
Message-ID: <20131106173001.1587192psdnkhjt5@webmail.uniparthenope.it>

Hi all,


I have estimated a random panel model using plm function.

I have a question about the vector of resduals obtained with the  
object $residuals.

example:

data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,  
model="random", data = Produc, index = c("state","year"))

res<-zz$residuals # vector of the residuals.

the vector res is the sum of the idyosiyncratic (eit) and individual  
(ui) component or is only the idyosiyncratic (eit) component?

Thanks
Alfonso


From tal.galili at gmail.com  Wed Nov  6 17:40:21 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Wed, 6 Nov 2013 18:40:21 +0200
Subject: [R] Basic question: why does a scatter plot of a variable against
 itself works like this?
Message-ID: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/cfb7fcff/attachment.pl>

From wdunlap at tibco.com  Wed Nov  6 17:41:32 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 Nov 2013 16:41:32 +0000
Subject: [R]
 =?utf-8?q?Error_message_glmer_using_R=3A_=E2=80=9C_=27what=27?=
 =?utf-8?q?_must_be_a_character_string_or_a_function=E2=80=9D?=
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA130F3@PA-MBX01.na.tibco.com>
References: <1383694607649-4679829.post@n4.nabble.com>
	<1383698876009-4679836.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA130F3@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA13146@PA-MBX01.na.tibco.com>

> You can reproduce the problem by having a data.frame (or anything else) in your
> environment:

I left out "called 'new'" in the above statement.  The example is correct.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Wednesday, November 06, 2013 8:04 AM
> To: EmmaB; r-help at r-project.org
> Subject: Re: [R] Error message glmer using R: ? 'what' must be a character string or a
> function?
> 
> You can reproduce the problem by having a data.frame (or anything else) in your
> environment:
> 
> new <- data.frame(?..VAR00001 = rep(c(TRUE,NA,FALSE), c(10,2,8)),
> random=rep(1:3,len=20), clustno=rep(c(1:5),len=20), validatedRS6=rep(0:1,len=20))
> model1<- glmer(validatedRS6 ~ random + (1|clustno), data=new, family=binomial(),
> nAGQ=3)
> # Error in do.call(new, c(list(Class = "glmResp", family = family), ll[setdiff(names(ll),  :
> #  'what' must be a character string or a function
> 
> The problem is in the call
>    do.call(new, list())
> It finds your dataset 'new' (in .GlobalEnv), which is not a function or the name of a
> function,
> not the function 'new' from the 'methods' package.  Rename your dataset, so you do not
> have anything called 'new' masking the one in package:methods, and things should work.
> 
> Write to the maintainer of the package (use maintainer("lme4") for the address) about
> the
> problem.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of EmmaB
> > Sent: Tuesday, November 05, 2013 4:48 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] Error message glmer using R: ? 'what' must be a character string or a
> > function?
> >
> > > str(new)
> > 'data.frame':   1214 obs. of  4 variables:
> >  $ ?..VAR00001 : logi  NA NA NA NA NA NA ...
> >  $ random      : int  1 1 1 1 1 1 1 1 1 1 ...
> >  $ clustno     : int  1 1 1 1 1 1 1 1 1 1 ...
> >  $ validatedRS6: int  0 0 0 0 0 0 0 0 0 0 ...
> >
> >
> >
> > --
> > View this message in context: http://r.789695.n4.nabble.com/Error-message-glmer-
> > using-R-what-must-be-a-character-string-or-a-function-tp4679829p4679836.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From marc_schwartz at me.com  Wed Nov  6 17:52:22 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 06 Nov 2013 10:52:22 -0600
Subject: [R] Basic question: why does a scatter plot of a variable
 against itself works like this?
In-Reply-To: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>
References: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>
Message-ID: <0836935D-106F-4662-B747-C55AD85F5212@me.com>


On Nov 6, 2013, at 10:40 AM, Tal Galili <tal.galili at gmail.com> wrote:

> Hello all,
> 
> I just noticed the following behavior of plot:
> x <- c(1,2,9)
> plot(x ~ x) # this is just like doing:
> plot(x)
> # when maybe we would like it to give this:
> plot(x ~ c(x))
> # the same as:
> plot(x ~ I(x))
> 
> I was wondering if there is some reason for this behavior.
> 
> 
> Thanks,
> Tal


Hi Tal,

In your example:

  plot(x ~ x)

the formula method of plot() is called, which essentially does the following internally:

> model.frame(x ~ x)
  x
1 1
2 2
3 9

Note that there is only a single column in the result. Thus, the plot is based upon 'y' = c(1, 2, 9), while 'x' = 1:3, which is NOT the row names for the resultant data frame, but the indices of the vector elements in the 'x' column. 

This is just like:

  plot(c(1, 2, 9))


On the other hand:

> model.frame(x ~ c(x))
  x c(x)
1 1    1
2 2    2
3 9    9

> model.frame(x ~ I(x))
  x I(x)
1 1    1
2 2    2
3 9    9


In both of the above cases, you get two columns of data back, thus the result is essentially:

  plot(c(1, 2, 9), c(1, 2, 9))


Regards,

Marc Schwartz


From wdunlap at tibco.com  Wed Nov  6 17:59:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 Nov 2013 16:59:09 +0000
Subject: [R] Basic question: why does a scatter plot of a variable
 against itself works like this?
In-Reply-To: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>
References: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA13173@PA-MBX01.na.tibco.com>

It probably happens because plot(formula) makes one call to terms(formula) to
analyze the formula.  terms() says there is one variable in the formula,
the response, so plot(x~x) is the same a plot(seq_along(x), x).
If you give it plot(~x) , terms() also says there is one variable, but
no response, so you get the same plot as plot(x, rep(1,length(x))).
This is also the reason that plot(y1+y2 ~ x1+x2) makes one plot of the sum of y1 and y2
for each term on the right side instead of 4 plots, plot(x1,y1), plot(x1,y2),plot(x2,y1),
and plot(x2,y2).

One could write a plot function that called terms separately on the left and
right sides of the formula.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Tal Galili
> Sent: Wednesday, November 06, 2013 8:40 AM
> To: r-help at r-project.org
> Subject: [R] Basic question: why does a scatter plot of a variable against itself works like
> this?
> 
> Hello all,
> 
> I just noticed the following behavior of plot:
> x <- c(1,2,9)
> plot(x ~ x) # this is just like doing:
> plot(x)
> # when maybe we would like it to give this:
> plot(x ~ c(x))
> # the same as:
> plot(x ~ I(x))
> 
> I was wondering if there is some reason for this behavior.
> 
> 
> Thanks,
> Tal
> 
> 
> 
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From danica_714 at hotmail.com  Wed Nov  6 13:41:41 2013
From: danica_714 at hotmail.com (Danica Fabrigar)
Date: Wed, 6 Nov 2013 12:41:41 +0000
Subject: [R] SNPRelate- problem performing PCA
Message-ID: <DUB124-W198E48CA1F4160667FC396A2F00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/cb925373/attachment.pl>

From simon.pickert at t-online.de  Wed Nov  6 14:11:49 2013
From: simon.pickert at t-online.de (Simon Pickert)
Date: Wed, 6 Nov 2013 14:11:49 +0100
Subject: [R] Multiple String word replacements: Performance Issue
Message-ID: <7DF0A2FB-F412-4035-8C91-E3DD4172C3C7@t-online.de>

Dear experts,
I?ve been on this for weeks now, and couldn?t find a solution..Sorry for the long description. I figured I post many details, so you get the problem entirely, although it?s not hard to grasp.

**Situation:**
Data frame consisting of 4 million entries (total size: 250 MB). Two columns: `ID` and `TEXT`. Text strings are each up to 200 characters.


**Task:**
Preprocessing the text strings

Example Data:


    +??????+?????????????????+
    |  ID    |                     Text                                                 |  
    +??+?????????????????????+
    | 123  | $AAPL is up +5%                                                |  
    | 456  | $MSFT , $EBAY doing great.  www.url.com       |
                                              ..
    +??+?????????????????????+

Should become

    +??????+??????????????????????????????????-??+
    |  ID    |                     Text clean                                        |  First Ticker  |  All Ticker       |   Ticker Count      
    +??+????????????????????+??????+???? +???????-?+
    | 123  | [ticker] is up [positive_percentage]                       |       $aapl       |   $aapl            |          1
    | 456  | [ticker] [ticker] doing great [url] [pos_emotion]     |       $msft       |   $msft,$ebay  |          2
                                              ..
    +??+????????????????????+??????-+??????+??????+



**Problem:**
It takes too long. On my 8GB RAM Dual-Core machine: Cancelled after 1 day. On a 70GB 8-Core Amazon EC2 instance: Cancelled after 1 day.


**Details:**
I am basically 

 - Counting how often certain words appear in one string
 - Write this number into a new column (COUNT)
 - Replace this (counted) word
 - Replace other words (which I don't need to count before)
 - Replace some regular expressions

The vectors which are used as patterns look like this:

    "\\bWORD1\\b|\\bWORD2\\b|\\bWORD3\\b|\\bWORD4\\b..."

Thus, those 'replacement vectors' are character vectors of length 1, each containing up to 800 words



**Main code:**

    library("parallel")
    library("stringr")

    preprocessText<-function(x){
      
      # Replace the 'html-and'
      arguments<-list(pattern="\\&amp\\;",replacement="and",x=x, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      # Remove some special characters
       arguments<-list(pattern="[^-[:alnum:]\\'\\:\\/\\$\\%\\.\\,\\+\\-\\#\\@\\_\\!\\?+[:space:]]",replacement="",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      # Lowercase 
      arguments<-list(string=y,pattern=tolower(rep_ticker))
      first<-do.call(str_match,arguments)  
      
      # Identify signal words and count them
      # Need to be done in parts, because otherwise R can't handle this many at once
      arguments<-list(string=x, pattern=rep_words_part1)
      t1<-do.call(str_extract_all,arguments)
   
      arguments<-list(string=x, pattern=rep_words_part2)
      t2<-do.call(str_extract_all,arguments)
      
      arguments<-list(string=x, pattern=rep_words_part3)
      t3<-do.call(str_extract_all,arguments)
      
      arguments<-list(string=x, pattern=rep_words_part4)
      t4<-do.call(str_extract_all,arguments)
      
      count=length(t1[[1]])+length(t2[[1]])+length(t3[[1]])+length(t4[[1]])
      signal_words=c(t1[[1]],t2[[1]],t3[[1]],t4[[1]])
      

      # Replacements
      
      arguments<-list(pattern=rep_wordsA,replacement="[ticker]",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments) 
       
      arguments<-list(pattern=rep_wordB_part1,replacement="[ticker] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   

      arguments<-list(pattern=rep_wordB_part2,replacement="[ticker] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   

      arguments<-list(pattern=rep_wordB_part3,replacement="[ticker2] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   

      arguments<-list(pattern=rep_wordB_part4,replacement=?[ticker2] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern=rep_email,replacement=" [email_address] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern=rep_url,replacement=" [url] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
         
      arguments<-list(pattern=rep_wordC,replacement=" [wordC] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      # Some regular expressions
      arguments<-list(pattern="\\+[[:digit:]]*.?[[:digit:]]+%",replacement=" [positive_percentage] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="-[[:digit:]]*.?[[:digit:]]+%",replacement=" [negative_percentage] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="[[:digit:]]*.?[[:digit:]]+%",replacement=" [percentage] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="\\$[[:digit:]]*.?[[:digit:]]+",replacement=" [dollar_value] ",x=y,ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="\\+[[:digit:]]*.?[[:digit:]]+",replacement=" [pos_number] ",x=y, ignore.case=TRUE)# remaining numbers 
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="\\-[[:digit:]]*.?[[:digit:]]+",replacement=" [neg_number] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern="[[:digit:]]*.?[[:digit:]]+",replacement=" [number] ",x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)   
      
      arguments<-list(pattern=rep_question,replacement=" [question] ", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)    
      
      
      # Unify synonyms
      arguments<-list(pattern=rep_syno1,replacement="happy", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rep_syno2,replacement="sad", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rep_syno3,replacement="people", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rep_syno4,replacement="father", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rep_syno5,replacement="mother", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rep_syno6,replacement="money", x=y, ignore.case=TRUE)
      y<-do.call(gsub, arguments)  
      
      # Remove words
      # Punctuation (I know there a pre-defined R commands for this, but I need to customize this
      arguments<-list(pattern=rem_punct,replacement="", x=y, ignore.case=TRUE) 
      y<-do.call(gsub, arguments)  
      
      arguments<-list(pattern=rem_linebreak,replacement=" ", x=y, ignore.case=TRUE) #Remove line breaks
      y<-do.call(gsub, arguments) 
     
      #Append Positive or Negative Emotion  
      arguments<-list(x=y)
      y<-do.call(appendEmotion, arguments)  
      
 
      # Output
      result<-list(
        textclean=y,
        first_ticker=first,
        all_ticker=signal_words,
        ticker_count=count)
      
      return(result)
    }
   
    resultList<-mclapply(dataframe$text_column,preprocessText)

** end main code **

(The return would be a list, which I plan to convert to a data.frame. Don?t get that far though).


Before, I also tried to call each `gsub` seperately, thus performing the first `gsub` on every text string, then the second `gsub` and so on.. but I guess that this was even less efficient.

The code itself works, but for me it seems that this can be speeded up. Unfortunately I'm not familiar with hash tables, which is what I heard could be a solution.

Appreciate your ideas and help very much!




*Definition of the one function called inside `preprocessText`*

    appendEmotion<-function(x){
      
      if (grepl(app_pos,x)){
        x<-paste(x," [pos_emotion] ")
      } 
      if(grepl(app_neg,x)){
        x<-paste(x," [neg_emotion] ")
      }  
      #Output
      return(x)
    }


From umairdurrani at outlook.com  Wed Nov  6 16:48:51 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Wed, 6 Nov 2013 20:48:51 +0500
Subject: [R] R 3.0.2 - How to create intervals and group another variable in
 those intervals?
Message-ID: <BLU170-W4648C53FDA08C46BA17E97C9F00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/8c53d4e0/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Wed Nov  6 18:18:10 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 6 Nov 2013 17:18:10 +0000
Subject: [R] convert one digit numbers to two digits one
In-Reply-To: <2256079a78fc4c26afe74561651ec321@EX-0-HT0.lancs.local>
References: <1383755123.64417.YahooMailNeo@web125304.mail.ne1.yahoo.com>
	<2256079a78fc4c26afe74561651ec321@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNTAb6rfs-6mGJoQS+bx1tiGUDOpTc76sC6MX1SNWsTkQ@mail.gmail.com>

All these suggestions of using 'sprintf' might be right but you might
be doing it wrong...

If you are working with times, then use the date/time classes and the
handy functions for working on them. Which means the lubridate
package, most likely.

Are these times part of a calendar time, or are they just clock times
without reference to any day, or are they durations in hours and
minutes?



On Wed, Nov 6, 2013 at 4:34 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Nov 6, 2013, at 10:25 AM, Alaios <alaios at yahoo.com> wrote:
>
>> Hi all,
>> the following returns the hour and the minutes
>>
>> paste(DataSet$TimeStamps[selectedInterval$start,4], DataSet$TimeStamps[selectedInterval$start,5],sep=":")
>> [1] "12:3"
>>
>> the problem is that from these two I want to create a time stamp so 12:03. The problem is that the number 3 is not converted to 03. Is there an easy way when I have one digit integer to add a zero in the front? Two digits integers are working fine so far, 12:19, or 12:45 would appear correctly
>>
>> I would like to thank you in advance for your help
>>
>> Regards
>> Alex
>
>
> This is an example where using ?sprintf gives you more control:
>
>> sprintf("%02d:%02d", 12, 3)
> [1] "12:03"
>
>> sprintf("%02d:%02d", 9, 3)
> [1] "09:03"
>
>
> The syntax '%02d' tells sprintf to print the integer and pad with leading zeroes to two characters where needed.
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Wed Nov  6 18:19:13 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Nov 2013 12:19:13 -0500
Subject: [R] R 3.0.2 - How to create intervals and group another
 variable in those intervals?
In-Reply-To: <BLU170-W4648C53FDA08C46BA17E97C9F00@phx.gbl>
References: <BLU170-W4648C53FDA08C46BA17E97C9F00@phx.gbl>
Message-ID: <CAAxdm-5kayoTfX_4dcD9Hpo4JzooN6jKu-sQE5EP2=cww6nHxQ@mail.gmail.com>

Is this what you are after:


> n <- 1000
> x <- data.frame(speed = runif(n, 0, 85.53)
+             , spacing = rnorm(n)
+             )
> # create interval for speed
> int <- seq(0, max(x) + 4.5, by = 4.5)
> # split the data and find average of spacing
> tapply(x$spacing, cut(x$speed, int), mean)
    (0,4.5]     (4.5,9]    (9,13.5]   (13.5,18]   (18,22.5]
(22.5,27]   (27,31.5]   (31.5,36]
 0.27840783 -0.08349567 -0.10659408 -0.01476840 -0.08773255
-0.06643826  0.21873016  0.17627232
  (36,40.5]   (40.5,45]   (45,49.5]   (49.5,54]   (54,58.5]
(58.5,63]   (63,67.5]   (67.5,72]
-0.16568350 -0.15458191 -0.04909331 -0.01179396  0.25022296
-0.27553812 -0.14927483 -0.21000177
  (72,76.5]   (76.5,81]   (81,85.5]
-0.09884137 -0.08459709  0.02864456
>
>

plotting is left as an exercise for the reader, but given the averages
above, you can find the midpoints easily.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Nov 6, 2013 at 10:48 AM, umair durrani <umairdurrani at outlook.com> wrote:
> I have two columns for speed ('Smoothed velocity') and Spacing. What I want to do is to first create the intervals of speed (minimum value=0, max value= 85.53), group the Spacing values falling in a particular Speed interval, find the average of the Spacing for an interval and finally plot the average spacing of each interval against the mid-point of the Speed interval. I want to have fixed intervals of 4.5 feet per second, i.e. 0-4.5, 4.5-9,......xx-85.53.After hours of search I found a function for creating intervals called classIntervals() but I can't figure out how to create fixed intervals of 4.5. Here is what I tried:classIntervals(s21[,'Smoothed velocity'], style='fixed', fixedBreaks=4.5)But the results were unexpected and there was a Warning message:In classIntervals(s21[, "Smoothed velocity"], style = "fixed", fixedBreaks = 4.5) :
>   variable range greater than fixedBreaksEven after intervals are created, I need to group spacing and find the avg. for every interval. How can I do this? I have tried what I could, please help
>
> Umair Durrani
>
> email: umairdurrani at outlook.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From atclark at umn.edu  Wed Nov  6 18:20:41 2013
From: atclark at umn.edu (Adam Clark)
Date: Wed, 6 Nov 2013 11:20:41 -0600
Subject: [R] deSolve, unresolved namespace error
Message-ID: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/66cb8a2e/attachment.pl>

From jholtman at gmail.com  Wed Nov  6 18:22:50 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Nov 2013 12:22:50 -0500
Subject: [R] R 3.0.2 - How to create intervals and group another
 variable in those intervals?
In-Reply-To: <CAAxdm-5kayoTfX_4dcD9Hpo4JzooN6jKu-sQE5EP2=cww6nHxQ@mail.gmail.com>
References: <BLU170-W4648C53FDA08C46BA17E97C9F00@phx.gbl>
	<CAAxdm-5kayoTfX_4dcD9Hpo4JzooN6jKu-sQE5EP2=cww6nHxQ@mail.gmail.com>
Message-ID: <CAAxdm-5UWHL1GBd3erk7VCnT+3QSDtKzsJzfFjEtRMqo577xxQ@mail.gmail.com>

should of had in the script:


int <- seq(0, max(x$speed) + 4.5, by = 4.5)



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Nov 6, 2013 at 12:19 PM, jim holtman <jholtman at gmail.com> wrote:
> Is this what you are after:
>
>
>> n <- 1000
>> x <- data.frame(speed = runif(n, 0, 85.53)
> +             , spacing = rnorm(n)
> +             )
>> # create interval for speed
>> int <- seq(0, max(x) + 4.5, by = 4.5)
>> # split the data and find average of spacing
>> tapply(x$spacing, cut(x$speed, int), mean)
>     (0,4.5]     (4.5,9]    (9,13.5]   (13.5,18]   (18,22.5]
> (22.5,27]   (27,31.5]   (31.5,36]
>  0.27840783 -0.08349567 -0.10659408 -0.01476840 -0.08773255
> -0.06643826  0.21873016  0.17627232
>   (36,40.5]   (40.5,45]   (45,49.5]   (49.5,54]   (54,58.5]
> (58.5,63]   (63,67.5]   (67.5,72]
> -0.16568350 -0.15458191 -0.04909331 -0.01179396  0.25022296
> -0.27553812 -0.14927483 -0.21000177
>   (72,76.5]   (76.5,81]   (81,85.5]
> -0.09884137 -0.08459709  0.02864456
>>
>>
>
> plotting is left as an exercise for the reader, but given the averages
> above, you can find the midpoints easily.
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Wed, Nov 6, 2013 at 10:48 AM, umair durrani <umairdurrani at outlook.com> wrote:
>> I have two columns for speed ('Smoothed velocity') and Spacing. What I want to do is to first create the intervals of speed (minimum value=0, max value= 85.53), group the Spacing values falling in a particular Speed interval, find the average of the Spacing for an interval and finally plot the average spacing of each interval against the mid-point of the Speed interval. I want to have fixed intervals of 4.5 feet per second, i.e. 0-4.5, 4.5-9,......xx-85.53.After hours of search I found a function for creating intervals called classIntervals() but I can't figure out how to create fixed intervals of 4.5. Here is what I tried:classIntervals(s21[,'Smoothed velocity'], style='fixed', fixedBreaks=4.5)But the results were unexpected and there was a Warning message:In classIntervals(s21[, "Smoothed velocity"], style = "fixed", fixedBreaks = 4.5) :
>>   variable range greater than fixedBreaksEven after intervals are created, I need to group spacing and find the avg. for every interval. How can I do this? I have tried what I could, please help
>>
>> Umair Durrani
>>
>> email: umairdurrani at outlook.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From sashikanth.chandrasekaran at gmail.com  Wed Nov  6 18:19:33 2013
From: sashikanth.chandrasekaran at gmail.com (Sashikanth Chandrasekaran)
Date: Wed, 6 Nov 2013 09:19:33 -0800
Subject: [R] Fitting multiple horizontal lines to data
Message-ID: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/f244a7be/attachment.pl>

From silesmek at gmail.com  Wed Nov  6 18:09:14 2013
From: silesmek at gmail.com (Silvia Espinoza)
Date: Wed, 6 Nov 2013 11:09:14 -0600
Subject: [R] Questions about R
Message-ID: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/a40c109d/attachment.pl>

From matthias.salvisberg at gmail.com  Wed Nov  6 18:09:37 2013
From: matthias.salvisberg at gmail.com (Matthias Salvisberg)
Date: Wed, 6 Nov 2013 18:09:37 +0100
Subject: [R] MPICH2 Rmpi and doSNOW
Message-ID: <000001cedb12$fa508bc0$eef1a340$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/f7e745c7/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Wed Nov  6 18:38:22 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 6 Nov 2013 17:38:22 +0000
Subject: [R] Basic question: why does a scatter plot of a variable
 against itself works like this?
In-Reply-To: <f9c7d03650944ec2a7925da1e760bd52@EX-1-HT0.lancs.local>
References: <CANdJ3dUC7gEOtoqQc__BoagPXPykfB-w0hgKwBvpPcGOnYS6Rw@mail.gmail.com>
	<f9c7d03650944ec2a7925da1e760bd52@EX-1-HT0.lancs.local>
Message-ID: <CANVKczP-2UOfDAZp8zoZGiDg5ibevJRb_2-0AOPgJEVwPJDoNw@mail.gmail.com>

Interestingly, fitting an LM with x on both sides gives a warning, and
then drops it from the RHS, leaving you with just an intercept:

> lm(x~x,data=d)

Call:
lm(formula = x ~ x, data = d)

Coefficients:
(Intercept)
          4

Warning messages:
1: In model.matrix.default(mt, mf, contrasts) :
  the response appeared on the right-hand side and was dropped
2: In model.matrix.default(mt, mf, contrasts) :
  problem with term 1 in model.matrix: no columns are assigned

there's no numerical problem fitting a line through the points:

 > d$xx=d$x
 > lm(x~xx,data=d)

Call:
lm(formula = x ~ xx, data = d)

Coefficients:
(Intercept)           xx
  5.128e-16    1.000e+00

It seems to be R saying "Ummm did you really mean to do this? It's kinda dumb".

I suppose this could occur if you had a nested loop over all columns
in a data frame, fitting an LM with every column, and didn't skip if
i==j

Except of course it doesn't:

 - fit with two indexes set to one:

> i=1;j=1
> lm(d[,i]~d[,j])

Call:
lm(formula = d[, i] ~ d[, j])

Coefficients:
(Intercept)       d[, j]
  5.128e-16    1.000e+00

- fit with two ones:

> lm(d[,1]~d[,1])

Call:
lm(formula = d[, 1] ~ d[, 1])

Coefficients:
(Intercept)
          4

Warning messages:
1: In model.matrix.default(mt, mf, contrasts) :
  the response appeared on the right-hand side and was dropped
2: In model.matrix.default(mt, mf, contrasts) :
  problem with term 1 in model.matrix: no columns are assigned

Obviously this can all be explained in terms of R (or lm's, or
model.matrix's) evaluation schemes, but it seems far from intuitive.

Barry



On Wed, Nov 6, 2013 at 4:59 PM, William Dunlap <wdunlap at tibco.com> wrote:
> It probably happens because plot(formula) makes one call to terms(formula) to
> analyze the formula.  terms() says there is one variable in the formula,
> the response, so plot(x~x) is the same a plot(seq_along(x), x).
> If you give it plot(~x) , terms() also says there is one variable, but
> no response, so you get the same plot as plot(x, rep(1,length(x))).
> This is also the reason that plot(y1+y2 ~ x1+x2) makes one plot of the sum of y1 and y2
> for each term on the right side instead of 4 plots, plot(x1,y1), plot(x1,y2),plot(x2,y1),
> and plot(x2,y2).
>
> One could write a plot function that called terms separately on the left and
> right sides of the formula.
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Tal Galili
>> Sent: Wednesday, November 06, 2013 8:40 AM
>> To: r-help at r-project.org
>> Subject: [R] Basic question: why does a scatter plot of a variable against itself works like
>> this?
>>
>> Hello all,
>>
>> I just noticed the following behavior of plot:
>> x <- c(1,2,9)
>> plot(x ~ x) # this is just like doing:
>> plot(x)
>> # when maybe we would like it to give this:
>> plot(x ~ c(x))
>> # the same as:
>> plot(x ~ I(x))
>>
>> I was wondering if there is some reason for this behavior.
>>
>>
>> Thanks,
>> Tal
>>
>>
>>
>> ----------------Contact
>> Details:-------------------------------------------------------
>> Contact me: Tal.Galili at gmail.com |
>> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
>> www.r-statistics.com (English)
>> ----------------------------------------------------------------------------------------------
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Wed Nov  6 18:40:54 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 06 Nov 2013 17:40:54 +0000
Subject: [R] deSolve, unresolved namespace error
In-Reply-To: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>
References: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>
Message-ID: <527A7F26.3030003@stats.ox.ac.uk>

On 06/11/2013 17:20, Adam Clark wrote:
> I'm having trouble running the "ode" function from the "deSolve" package.
>
> I am running RStudio under Ubuntu 13.1
>
> I am running ode() on compiled code that returns delta values using the .C
> convention. While I can include an example of the code, I suspect that it
> will not be helpful, since the problem is not replicable among systems
> (e.g. Solaris or Mac).
>
> When I call ode() on my compiled code, it occasionally will return:
>
> Error in .C("unlock_solver") :
>    "unlock_solver" not resolved from current namespace (deSolve)
>
>
> All subsequent calls to ode() return the same error message, regardless of
> what I run. The problem is resolved only if I restart RStudio. However,
> since I am running many iterations of this command, I would like to find a
> way to resolve this without restarting RStudio.
>
> If I call: is.loaded("unlock_solver", PACKAGE="deSolve"), R returns TRUE.
>
> If I call: .C("unlock_solver"), R returns:
> list()
>
> If I first unload "deSolve" using
> detach("package:deSolve", unload=TRUE), deSolve disappears from my search()
> space, but  is.loaded("unlock_solver", PACKAGE="deSolve") still returns
> TRUE. If I reload deSolve, the problem persists.
>
> Based on what I have read in the help files on namespace conventions in
> packages,  I suspect that the problem is that the .C function
> "unlock_solver" is not corrected loaded, or was unloaded but not marked as
> unloaded.
>
> I have two guesses for what is going on:
> 1) "unlock_solver" was loaded using the library.dynam() function, but
> unloaded using the dyn.unload() function. As I understand it, this would

Who said it was unloaded?  That it is not by default is explicit in ?detach.

> leave a blank entry in the namespace, leading R to think that
> "unlock_solver" is loaded, even though the function no longer does
> anything. However, even when deSolve is working correctly,
> .C("unlock_solver") returns a blank list, so this may not be the case.
>
> 2) Some call deep in deSolve is not pointed towards the right package, and
> therefore cannot find "unlock_solver".
>
>>From the source code for deSolve, posted at
> https://r-forge.r-project.org/scm/viewvc.php/pkg/deSolve/src/deSolve_utils.c?view=log&root=desolve&pathrev=344,
> "unlock_solver"
> seems to be a pretty simple function, inside the deSolve_utils.c file:
>
> void unlock_solver(void) {solver_locked = 0;}
>
> This command is a pretty recent addition to deSolve (it appeared
> somewhere between revision 319 and 324), and is meant to "prevent
> nesting of solvers that have global variables", according to the
> change annotation.
>
>
> In any case, I'd like to find a way to specifically unload "unlock_solver"
> and reload it, or barring that, unload as many of the DLL's associated with
> deSolve as possible and reload them. I suspect that this will solve my
> problems.

I am not sure why you think it is reasonable to do that.  Clearly the 
designers of deSolve did not think so, as it does not have an .onUnload 
action.

 > library(deSolve)
 > names(getLoadedDLLs())
[1] "base"      "utils"     "methods"   "grDevices" "graphics"  "stats"
[7] "deSolve"   "tools"
 > detach("package:deSolve", unload=TRUE)
 > names(getLoadedDLLs())
[1] "base"      "utils"     "methods"   "grDevices" "graphics"  "stats"
[7] "deSolve"   "tools"

> Many thanks, and sorry if this is a silly question,

It is really an R-devel question: see the posting guide.  In particular 
OSes differ in how (or even if) they can reload DLLs, and the details 
are way too technical for R-help.

In any case, there are no reproduction instructions here: see the 
posting guide.

> Adam
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From yelin at lbl.gov  Wed Nov  6 18:44:13 2013
From: yelin at lbl.gov (Ye Lin)
Date: Wed, 6 Nov 2013 09:44:13 -0800
Subject: [R] Questions about R
In-Reply-To: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>
References: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>
Message-ID: <CAAvu=bk1tVh2bhi6Jam+yKa4geS6hGP+_iUm7NbzD_=5DxWMZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/61f38815/attachment.pl>

From atclark at umn.edu  Wed Nov  6 18:50:37 2013
From: atclark at umn.edu (Adam Clark)
Date: Wed, 6 Nov 2013 11:50:37 -0600
Subject: [R] deSolve, unresolved namespace error
In-Reply-To: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>
References: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>
Message-ID: <CAL7OOdwZN2X852acyHHNNvYZUghx19jR-E1XcT53LqC9vgTS3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/7c9b3c8f/attachment.pl>

From stefano.sofia at regione.marche.it  Wed Nov  6 18:56:02 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 6 Nov 2013 17:56:02 +0000
Subject: [R] plot a single frequency of a ts object
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0DA2FFE9@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/63e987da/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Wed Nov  6 18:58:02 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 6 Nov 2013 17:58:02 +0000
Subject: [R] Questions about R
In-Reply-To: <f2a7dcbc257b4e1fa80a2c09964b139a@EX-0-HT0.lancs.local>
References: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>
	<f2a7dcbc257b4e1fa80a2c09964b139a@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMDXEkVYXrziPaqgqhdWNC_4VTGo6-p_jTjbMrP6zvonw@mail.gmail.com>

On Wed, Nov 6, 2013 at 5:44 PM, Ye Lin <yelin at lbl.gov> wrote:
> You can get details at http://www.r-project.org/
>
> But to answer your question: Yes it is free

 But there is also a paid version. Send me $1000 and I will send you R
on a USB stick, complete with all the source code.

 Seriously, other companies do supply support and extensions for R at
a cost, and although I can legally sell you a copy of R for $1000
nobody bothers charging for R because the license can't stop you
giving your copy away.

 As for your security/data safety question, well your operating system
is probably the weaker link in that chain. However if you are running
R in a client-server fashion then you should make sure the data is
encrypted - and then the weakest link is possession of the private
half of the encryption key, which is your responsibility.

Barry


From dwinsemius at comcast.net  Wed Nov  6 19:00:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 10:00:06 -0800
Subject: [R] Remove from the mailing list
In-Reply-To: <CABi7Y8Y9PLfXsQxj64uZQKYyanAMaPbkeskoX8cwBcL7QL5oRA@mail.gmail.com>
References: <CABi7Y8Y9PLfXsQxj64uZQKYyanAMaPbkeskoX8cwBcL7QL5oRA@mail.gmail.com>
Message-ID: <D7578EE4-9523-44CC-AA5C-E76D04F5EE51@comcast.net>


On Nov 6, 2013, at 8:33 AM, Mario Garrido wrote:

> Dear administrators,
> I tried to stop receving mails from your webpage to my current mail (
> gaiarrido at usal.es). I try to do it through your webpage but i was not
> able. I would appreciate to be removed from the mailing list.

If you were unable to login with your current addres it might have been because there was not an exact match for the domain name. This happens when an institution changes their domain name and forwards mail for a time to a new address. In this case, however, you are subscribed with that address. The moderators do not have delete rights to subscriptions, nor can they generate password reminders. Your password should be sent on a regular basis. (From the web page where you subscribed: "Once a month, your password will be emailed to you as a reminder.")


> 
> Thanks in advance.
> 
> 
> -- 
> Mario Garrido Escudero

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Wed Nov  6 19:02:26 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 06 Nov 2013 12:02:26 -0600
Subject: [R] Questions about R
In-Reply-To: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>
References: <CAFeWiKC3Qt5MjGgmeJD6ZOt6VxTCDWy-7SBAyCtT8w7ZHZnqeA@mail.gmail.com>
Message-ID: <F7174145-3D2A-4C32-A601-12B764C0CB66@me.com>

On Nov 6, 2013, at 11:09 AM, Silvia Espinoza <silesmek at gmail.com> wrote:

> Good morning. I am interested in downloading R.  I would appreciate if you
> can help me with the following questions, please.
> 
> 1.       Is R free, or I have to pay for support/maintenance, or it depends
> on the version? Is there a paid version?
> 


Yes, it is free, although there are commercial versions of R available, if you decide that you do need/want commercial support.

Some additional info on commercial versions here:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_002dplus_003f


None of this has any effect on your ability to use R in a commercial setting, though there are some CRAN packages that do have such limitations: 

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f



> 2.       How safe is it to work with data using R? Is there any risk that
> someone else can have access to the information?


That is outside of the scope of R and is dependent upon the security of the computer system(s) and possibly networks, upon and over which R is running and where your data is stored and managed.

Regards,

Marc Schwartz


> Thanks in advance for your attention and for any help you can provide me.
> 
> Silvia Espinoza


From jholtman at gmail.com  Wed Nov  6 19:03:11 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 6 Nov 2013 13:03:11 -0500
Subject: [R] R 3.0.2 - How to create intervals and group another
 variable in those intervals?
In-Reply-To: <BLU170-W855622BE0D5FEE46EABB1CC9F00@phx.gbl>
References: <BLU170-W4648C53FDA08C46BA17E97C9F00@phx.gbl>
	<CAAxdm-5kayoTfX_4dcD9Hpo4JzooN6jKu-sQE5EP2=cww6nHxQ@mail.gmail.com>
	<CAAxdm-5UWHL1GBd3erk7VCnT+3QSDtKzsJzfFjEtRMqo577xxQ@mail.gmail.com>
	<BLU170-W855622BE0D5FEE46EABB1CC9F00@phx.gbl>
Message-ID: <CAAxdm-4yG7PYZR2JJwUCRTzyeyiCcK-BP4SnFBPhHKs4ywKb1Q@mail.gmail.com>

You need to read up on the use of the "apply" functions: this is just
another 'tapply' call with the 'speed' in it.

> n <- 1000
> x <- data.frame(speed = runif(n, 0, 85.53)
+  , spacing = rnorm(n)
+  )
> # create interval for speed
> int <- seq(0, max(x) + 4.5, by = 4.5)
> # split the data and find average of spacing
> tapply(x$spacing, cut(x$speed, int), mean)
     (0,4.5]      (4.5,9]     (9,13.5]    (13.5,18]    (18,22.5]
(22.5,27]    (27,31.5]    (31.5,36]
-0.260755737 -0.017766405 -0.097255963  0.234719308 -0.038908267
-0.004559798 -0.065556109 -0.144327936
   (36,40.5]    (40.5,45]    (45,49.5]    (49.5,54]    (54,58.5]
(58.5,63]    (63,67.5]    (67.5,72]
-0.135491878 -0.120387573  0.033821289 -0.110058896 -0.107173009
-0.091258106 -0.198911676 -0.138334909
   (72,76.5]    (76.5,81]    (81,85.5]
-0.127941501  0.198943106  0.136345405
>
> # find the average speed
> tapply(x$speed, cut(x$speed, int), mean)
  (0,4.5]   (4.5,9]  (9,13.5] (13.5,18] (18,22.5] (22.5,27] (27,31.5]
(31.5,36] (36,40.5] (40.5,45]
 2.276792  6.804097 11.024388 15.699358 20.184667 24.644743 29.050843
34.017265 38.288514 42.617572
(45,49.5] (49.5,54] (54,58.5] (58.5,63] (63,67.5] (67.5,72] (72,76.5]
(76.5,81] (81,85.5]
47.357247 51.808874 56.162820 60.719576 65.202813 70.055034 74.147431
79.070495 83.376027
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Nov 6, 2013 at 12:36 PM, umair durrani <umairdurrani at outlook.com> wrote:
> Thanks Jim. You now provided me with the average of spacing but how can I
> find the average of speed for every speed interval? I am a newbie in R,
> sorry for my stupid questions
>
>
> Umair Durrani
> email: umairdurrani at outlook.com
>
>
>> Date: Wed, 6 Nov 2013 12:22:50 -0500
>> Subject: Re: [R] R 3.0.2 - How to create intervals and group another
>> variable in those intervals?
>> From: jholtman at gmail.com
>> To: umairdurrani at outlook.com
>> CC: r-help at r-project.org
>>
>> should of had in the script:
>>
>>
>> int <- seq(0, max(x$speed) + 4.5, by = 4.5)
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Wed, Nov 6, 2013 at 12:19 PM, jim holtman <jholtman at gmail.com> wrote:
>> > Is this what you are after:
>> >
>> >
>> >> n <- 1000
>> >> x <- data.frame(speed = runif(n, 0, 85.53)
>> > + , spacing = rnorm(n)
>> > + )
>> >> # create interval for speed
>> >> int <- seq(0, max(x) + 4.5, by = 4.5)
>> >> # split the data and find average of spacing
>> >> tapply(x$spacing, cut(x$speed, int), mean)
>> > (0,4.5] (4.5,9] (9,13.5] (13.5,18] (18,22.5]
>> > (22.5,27] (27,31.5] (31.5,36]
>> > 0.27840783 -0.08349567 -0.10659408 -0.01476840 -0.08773255
>> > -0.06643826 0.21873016 0.17627232
>> > (36,40.5] (40.5,45] (45,49.5] (49.5,54] (54,58.5]
>> > (58.5,63] (63,67.5] (67.5,72]
>> > -0.16568350 -0.15458191 -0.04909331 -0.01179396 0.25022296
>> > -0.27553812 -0.14927483 -0.21000177
>> > (72,76.5] (76.5,81] (81,85.5]
>> > -0.09884137 -0.08459709 0.02864456
>> >>
>> >>
>> >
>> > plotting is left as an exercise for the reader, but given the averages
>> > above, you can find the midpoints easily.
>> >
>> > Jim Holtman
>> > Data Munger Guru
>> >
>> > What is the problem that you are trying to solve?
>> > Tell me what you want to do, not how you want to do it.
>> >
>> >
>> > On Wed, Nov 6, 2013 at 10:48 AM, umair durrani
>> > <umairdurrani at outlook.com> wrote:
>> >> I have two columns for speed ('Smoothed velocity') and Spacing. What I
>> >> want to do is to first create the intervals of speed (minimum value=0, max
>> >> value= 85.53), group the Spacing values falling in a particular Speed
>> >> interval, find the average of the Spacing for an interval and finally plot
>> >> the average spacing of each interval against the mid-point of the Speed
>> >> interval. I want to have fixed intervals of 4.5 feet per second, i.e. 0-4.5,
>> >> 4.5-9,......xx-85.53.After hours of search I found a function for creating
>> >> intervals called classIntervals() but I can't figure out how to create fixed
>> >> intervals of 4.5. Here is what I tried:classIntervals(s21[,'Smoothed
>> >> velocity'], style='fixed', fixedBreaks=4.5)But the results were unexpected
>> >> and there was a Warning message:In classIntervals(s21[, "Smoothed
>> >> velocity"], style = "fixed", fixedBreaks = 4.5) :
>> >> variable range greater than fixedBreaksEven after intervals are
>> >> created, I need to group spacing and find the avg. for every interval. How
>> >> can I do this? I have tried what I could, please help
>> >>
>> >> Umair Durrani
>> >>
>> >> email: umairdurrani at outlook.com
>> >>
>> >> [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.


From simon.pickert at t-online.de  Wed Nov  6 19:57:46 2013
From: simon.pickert at t-online.de (SPi)
Date: Wed, 6 Nov 2013 10:57:46 -0800 (PST)
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <1383656459847-4679769.post@n4.nabble.com>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
	<5278C903.8080805@stats.ox.ac.uk>
	<80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>
	<1383656459847-4679769.post@n4.nabble.com>
Message-ID: <1383764266267-4679904.post@n4.nabble.com>

Good idea! 

I'm trying your approach right now, but I am wondering if using str_split
(package: 'stringr') or strsplit is the right way to go in terms of speed? I
ran str_split over the text column of the data frame and it's processing for
2 hours now..? 

I did: 
splittedStrings<-str_split(dataframe$text, " ")

The $text column already contains cleaned text, so no double blanks etc or
unnecessary symbols. Just full words.




--
View this message in context: http://r.789695.n4.nabble.com/speed-issue-gsub-on-large-data-frame-tp4679747p4679904.html
Sent from the R help mailing list archive at Nabble.com.


From simon.pickert at t-online.de  Wed Nov  6 20:06:48 2013
From: simon.pickert at t-online.de (SPi)
Date: Wed, 6 Nov 2013 11:06:48 -0800 (PST)
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <1383764266267-4679904.post@n4.nabble.com>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
	<5278C903.8080805@stats.ox.ac.uk>
	<80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>
	<1383656459847-4679769.post@n4.nabble.com>
	<1383764266267-4679904.post@n4.nabble.com>
Message-ID: <1383764808294-4679905.post@n4.nabble.com>

I'll answer myself:
using strsplit with fixed=true took like 2minutes!



--
View this message in context: http://r.789695.n4.nabble.com/speed-issue-gsub-on-large-data-frame-tp4679747p4679905.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Wed Nov  6 20:25:53 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 6 Nov 2013 19:25:53 +0000
Subject: [R]
	=?utf-8?q?Error_message_glmer_using_R=3A_=E2=80=9C_=27what=27?=
	=?utf-8?q?_must_be_a_character_string_or_a_function=E2=80=9D?=
References: <1383694607649-4679829.post@n4.nabble.com>
	<1383698876009-4679836.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA130F3@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B933FA13146@PA-MBX01.na.tibco.com>
Message-ID: <loom.20131106T193817-690@post.gmane.org>

William Dunlap <wdunlap <at> tibco.com> writes:

 
> > You can reproduce the problem by having a data.frame (or anything
> > else) in your environment: > > I left out "called 'new'" in the
> > above statement.  The example is correct.
 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> > -----Original Message-----

[snip]

> > You can reproduce the problem by having a data.frame (or anything
> > else) in your environment: new <- data.frame(?..VAR00001 =
> > rep(c(TRUE,NA,FALSE), c(10,2,8)), random=rep(1:3,len=20),
> > clustno=rep(c(1:5),len=20), validatedRS6=rep(0:1,len=20)) model1<-
> > glmer(validatedRS6 ~ random + (1|clustno), data=new,
> > family=binomial(), nAGQ=3) # Error in do.call(new, c(list(Class =
> > "glmResp", family = family), ll[setdiff(names(ll), : # 'what' must
> > be a character string or a function The problem is in the call
> > do.call(new, list()) It finds your dataset 'new' (in .GlobalEnv),
> > which is not a function or the name of a function, not the
> > function 'new' from the 'methods' package.  Rename your dataset,
> > so you do not have anything called 'new' masking the one in
> > package:methods, and things should work.  Write to the maintainer
> > of the package (use maintainer("lme4") for the address) about the
> > problem.

For what it's worth, I saw this on StackOverflow:

[broken URL]
http://stackoverflow.com/questions/19801070/
  error-message-glmer-using-r-what-must-be-a-character-string-or-a-function

answered it there, and have fixed it on Github: 

https://github.com/lme4/lme4/commit/9c12f002821f9567d5454e2ce3b78076dabffb54

While it is not officially forbidden in 
http://www.r-project.org/posting-guide.html (to my surprise, I can't
even find any proscription against cross-posting to R mailing lists,
although there is a section about "which list to post to"), posting
to both r-help and Stack Overflow tends to lead to duplicated effort/
frustration.  Please choose one or the other (in my opinion it's
OK to cross-post after a few days if you don't get any responses
in one place, provided that you say that you've cross-posted and
ideally provide a reference link to the cross-post).

  Ben Bolker


From carl at witthoft.com  Wed Nov  6 20:29:59 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 6 Nov 2013 11:29:59 -0800 (PST)
Subject: [R] speed issue: gsub on large data frame
In-Reply-To: <1383764808294-4679905.post@n4.nabble.com>
References: <D315E966-EC2F-4AB5-B818-0D7F8B9B7AF2@t-online.de>
	<5c17fc2c-78f1-409e-9150-2b7379108d07@email.android.com>
	<2925DAD9-CD46-4303-973A-A8C5A5F12B9A@t-online.de>
	<50049578-9195-4F5D-A04F-2DE52A6740F3@gmail.com>
	<5278C903.8080805@stats.ox.ac.uk>
	<80466F08-16F5-4E56-B53C-9A4DE89CEC80@t-online.de>
	<1383656459847-4679769.post@n4.nabble.com>
	<1383764266267-4679904.post@n4.nabble.com>
	<1383764808294-4679905.post@n4.nabble.com>
Message-ID: <1383766199991-4679906.post@n4.nabble.com>

If you could, please identify which responder's idea you used, as well as the
"strsplit" -- related code you ended up with.
That may help someone who browses the mail archives in the future.

Carl


SPi wrote
> I'll answer myself:
> using strsplit with fixed=true took like 2minutes!





--
View this message in context: http://r.789695.n4.nabble.com/speed-issue-gsub-on-large-data-frame-tp4679747p4679906.html
Sent from the R help mailing list archive at Nabble.com.


From robin.henderson at email.wsu.edu  Wed Nov  6 19:07:43 2013
From: robin.henderson at email.wsu.edu (Henderson, Robin Michelle)
Date: Wed, 6 Nov 2013 18:07:43 +0000
Subject: [R] R help-classification accuracy of DFA and RF using caret
Message-ID: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/fd03094b/attachment.pl>

From rissa_r at gmx.ch  Wed Nov  6 20:59:01 2013
From: rissa_r at gmx.ch (rissa)
Date: Wed, 6 Nov 2013 11:59:01 -0800 (PST)
Subject: [R] Matrix Question, calculate with 3 different matrices
Message-ID: <1383767941158-4679907.post@n4.nabble.com>

Hi there

I've got a (I think) simple problem, but I just can't figure it out.

I've got 3 dataset (datasets attached below).
In 'Value' there is the measured mean value for every unit (SFZN, SGKN,
SGSN, SHLTN, SIK) and for every treatment (1 to 10).
In 'SE' is the Standard Error for every unit and every treatment.
In 'DF' is the degrees of freedom for every unit and every treatment.

First, I want to calculate the t-value for every unit and treatment based on
the null hypothesis Value= 0 and safe it in a new matrix that has the same
form like SE etc (value names in first column and Treatments in the header).
That means something like...

tvalue<-as.matrix(Value)/as.matrix(SE)

Next I want to calculate the critical t value (p=0.05, two-sided) in a
separate matrix (same form as SE etc). That means something like...

critical<-qf(0.05/2,as.matrix(DF))

And last. I want to compare 'tvalue' with 'critical' and give out
'significant' if abs(critical) > 
abs(critical) or 'not' if it is not true and safe the results in a matrix
(same form as SE).

I know it's just a matrix question, but I'm a bit stuck.

P.S. Another question (not related to the above)

As far as I know in R the command var() calculates the sample variance (that
means 1/(N-1) ??x-x ? ? ). Is there a way to tell R to calculate the
Population Variance (that means divided through N instead of N-1)



Kind regards

DF.txt <http://r.789695.n4.nabble.com/file/n4679907/DF.txt>  
SE.txt <http://r.789695.n4.nabble.com/file/n4679907/SE.txt>  
Value.txt <http://r.789695.n4.nabble.com/file/n4679907/Value.txt>  




--
View this message in context: http://r.789695.n4.nabble.com/Matrix-Question-calculate-with-3-different-matrices-tp4679907.html
Sent from the R help mailing list archive at Nabble.com.


From jonsleepy at gmail.com  Wed Nov  6 21:09:09 2013
From: jonsleepy at gmail.com (Jon BR)
Date: Wed, 6 Nov 2013 15:09:09 -0500
Subject: [R] ggplot2 beginner question
Message-ID: <CA+d7zeSj0nbfAb3oGN3ieCLBquPCheo_U4j65ezc=mcR73K3vA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/efdb1ca9/attachment.pl>

From dcarlson at tamu.edu  Wed Nov  6 21:45:47 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 6 Nov 2013 14:45:47 -0600
Subject: [R] Fitting multiple horizontal lines to data
In-Reply-To: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
References: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
Message-ID: <010101cedb31$2bec9b10$83c5d130$@tamu.edu>

The changepoint package might give you a way to do this.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Sashikanth
Chandrasekaran
Sent: Wednesday, November 6, 2013 11:20 AM
To: r-help at r-project.org
Subject: [R] Fitting multiple horizontal lines to data

I am not trying to fit a horizontal line at every unique value
of y. I am
trying fit the y values with as few horizontal lines by trading
off the
number of horizontal lines with the error. The actual problem I
am trying
to solve is to smooth data in a time series. Here is a realistic
example of
y

y=c(134.45,141.82,143.81,141.81,145,141.61,143.72,145.71,200,175
,140,200,148.77,71.64,111.57,118.15,119.15,112.8,111.64,111.64,1
57.26,143.8,40.19,64.99,64.99,129.98,64.99,65,64.98,64.99)

An example fit for y using multiple horizontal lines (may not be
the best
fit in terms of squared error or another error metric, but I
have included
the y value for concreteness)

1. A horizontal line at approximately y=140 (to fit the first 13
values -
134.45 to 148.77)
2. A horizontal line at approximately y=110 (to fit the next 7
values -
71.64 to 111.64)
3. A horizontal line at approximately y=150 (to fit the next 2
values -
157.26 to 143.8)
4. A horizontal line at approximately y=65 (to fit the last 8
values -
40.19 to 64.99)
-sashi.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From collinl at cs.pitt.edu  Wed Nov  6 21:46:31 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Wed, 06 Nov 2013 15:46:31 -0500 (EST)
Subject: [R] Nonnormal Residuals and GAMs
Message-ID: <Pine.LNX.4.44.1311061531180.27153-100000@aluminum.cs.pitt.edu>

Greetings, My question is more algorithmic than prectical.  What I am
trying to determine is, are the GAM algorithms used in the mgcv package
affected by nonnormally-distributed residuals?

As I understand the theory of linear models the Gauss-Markov theorem
guarantees that least-squares regression is optimal over all unbiased
estimators iff the data meet the conditions linearity, homoscedasticity,
independence, and normally-distributed residuals.  Absent the last
requirement it is optimal but only over unbiased linear estimators.

What I am trying to determine is whether or not it is necessary to check
for normally-distributed errors in a GAM from mgcv.  I know that the
unsmoothed terms, if any, will be fitted by ordinary least-squares but I
am unsure whether the default Penalized Iteratively Reweighted Least
Squares method used in the package is also based upon this assumption or
falls under any analogue to the Gauss-Markov Theorem.

Thank you in advance for any help.

	Sincrely,
	Collin Lynch.


From babakbsn at gmail.com  Wed Nov  6 21:58:53 2013
From: babakbsn at gmail.com (Baro)
Date: Wed, 6 Nov 2013 12:58:53 -0800
Subject: [R] Hanning window in r
Message-ID: <CAF-JZQvFWFntgaDvEiFxdr4Thi3eBeZJMH0vOVn7AGnQR9k0KA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131106/06bf74f0/attachment.pl>

From cressler at queensu.ca  Wed Nov  6 21:46:57 2013
From: cressler at queensu.ca (c_e_cressler)
Date: Wed, 6 Nov 2013 12:46:57 -0800 (PST)
Subject: [R] Treatment effects on measurements through time: how to tell
 when (in time) treatment has a significant effect?
Message-ID: <1383770817307-4679911.post@n4.nabble.com>

Hi, 

The data (attached) I am looking at consists of measurements of growth rate
at different ages, for individuals in two treatments (control and infected).
What I want to know is whether and when (what age) the growth rate of
infected individuals is higher than the growth rate for control individuals.

The simplest way to approach this question is to just do a t-test at each
age, but because the growth rates at a given age depend on the growth rates
at previous ages before, that seems statistically invalid. I have looked at
some of the time series literature, but most of that seems more complicated
than what I am trying to do. What I would like to be able to say is
something like, "The growth rate of infected individuals is higher than
control individuals for ages 18-30."

Any help or insight would be greatly appreciated.

Thanks!
Clay

P.S. The data is provided as two matrices: the first column are the ages at
which data was collected, and subsequent columns are the growth rate
trajectories for different individuals.  cntl.grates.rda
<http://r.789695.n4.nabble.com/file/n4679911/cntl.grates.rda>  
inf.grates.rda <http://r.789695.n4.nabble.com/file/n4679911/inf.grates.rda>  



--
View this message in context: http://r.789695.n4.nabble.com/Treatment-effects-on-measurements-through-time-how-to-tell-when-in-time-treatment-has-a-significant--tp4679911.html
Sent from the R help mailing list archive at Nabble.com.


From ealaca at ucdavis.edu  Wed Nov  6 22:06:25 2013
From: ealaca at ucdavis.edu (Emilio A. Laca)
Date: Wed, 6 Nov 2013 13:06:25 -0800
Subject: [R] multistate data w/out individual ID
Message-ID: <1FBCA329-F2F8-426B-8F5E-79F4EC74BA89@ucdavis.edu>

Dear R help community,

I have a version of the data below generated by counting the number of individuals in each state every 2-3 time units for a series of cohorts (sets).
States are A, B, C, E and T.
It is known that the following transitions are possible A->B, B->C, C->E, B->T, C->T and E->T. 
The identity of the individuals in each set was not recorded.
I am interested in estimating the transition rates or probabilities and sojourn times as a function of covariates.
We assume that rates (probabilities) are independent of time.

Is there a package to estimate those quantities?
Is there a method to estimate those quantities?
Do you think a Bayesian approach integrating over all possible paths might work?
Everything I read about multi-state modeling packages seems to indicate that it is necessary to know the identity of individuals.

time,N,A,B,C,E,T,set,cov1,cov2
199,24,22,2,0,0,0,s1,1,4.65816667
201,24,22,2,0,0,0,s1,3,0.29922222
203,24,22,1,1,0,0,s1,10,9.570125
205,24,21,2,1,0,0,s1,6,9.94370139
207,24,20,3,1,0,0,s1,4,1.34693056
209,24,15,8,1,0,0,s1,2,1.20429167
212,24,14,9,1,0,0,s1,9,8.3008125
214,24,12,10,2,0,0,s1,15,9.14613194
216,24,10,11,3,0,0,s1,8,8.94250694
219,24,4,12,8,0,0,s1,5,0.97334722
221,24,3,12,9,0,0,s1,7,7.29372917
223,24,3,6,12,2,1,s1,17,1.28570139
225,24,1,7,8,5,3,s1,16,1.41599306
227,24,1,4,5,11,3,s1,18,7.07947222
229,24,1,3,2,15,3,s1,14,6.09359028
231,24,0,4,0,17,3,s1,12,4.70666667
233,24,0,4,0,17,3,s1,13,5.31577083
235,24,0,2,0,19,3,s1,11,4.62228472
199,24,19,5,0,0,0,s2,1,4.65816667
201,24,23,1,0,0,0,s2,3,0.29922222
203,24,22,2,0,0,0,s2,10,9.570125
205,24,22,2,0,0,0,s2,6,9.94370139
207,23,21,2,0,0,0,s2,4,1.34693056
209,23,19,3,1,0,0,s2,2,1.20429167
212,23,12,10,1,0,0,s2,9,8.3008125
214,23,10,12,1,0,0,s2,15,9.14613194
216,23,3,18,2,0,0,s2,8,8.94250694
219,23,0,16,7,0,0,s2,5,0.97334722
221,23,0,14,8,0,1,s2,7,7.29372917
223,23,0,5,14,2,2,s2,17,1.28570139
225,23,0,0,18,2,3,s2,16,1.41599306
227,23,0,2,13,2,6,s2,18,7.07947222
229,23,0,0,6,7,10,s2,14,6.09359028
231,23,0,0,3,8,12,s2,12,4.70666667
233,26,0,0,1,13,12,s2,13,5.31577083
235,28,0,0,0,16,12,s2,11,4.62228472
199,24,20,4,0,0,0,s3,1,4.65816667
201,24,22,2,0,0,0,s3,3,0.29922222
203,24,18,5,1,0,0,s3,10,9.570125
205,24,16,7,1,0,0,s3,6,9.94370139
207,24,13,10,1,0,0,s3,4,1.34693056
209,24,8,12,4,0,0,s3,2,1.20429167
212,24,5,14,5,0,0,s3,9,8.3008125
214,24,4,10,10,0,0,s3,15,9.14613194
216,24,2,9,12,1,0,s3,8,8.94250694
219,24,0,8,13,3,0,s3,5,0.97334722
221,24,2,6,5,11,0,s3,7,7.29372917
223,22,0,5,4,12,1,s3,17,1.28570139
225,24,1,3,1,17,2,s3,16,1.41599306
227,24,0,2,1,18,3,s3,18,7.07947222
229,25,0,2,0,20,3,s3,14,6.09359028
231,24,0,2,0,19,3,s3,12,4.70666667
233,24,0,1,1,19,3,s3,13,5.31577083
235,24,0,1,0,20,3,s3,11,4.62228472

Any comment will be appreciated.
Regards,

Emilio A. Laca, Professor                                                
One Shields Avenue, 2306 PES Bldg.            
Plant Sciences  Mail Stop 1                        ealaca at ucdavis.edu 
University of California                                 fax: (530) 752-4361     
Davis, California  95616                              voice: (530) 754-4083
						 		          mobile: (530) 220-5315
Include the Mail stop in the address or mail will be delayed.


From matthias.salvisberg at gmail.com  Wed Nov  6 22:18:05 2013
From: matthias.salvisberg at gmail.com (Matthias Salvisberg)
Date: Wed, 6 Nov 2013 22:18:05 +0100
Subject: [R] MPICH2 Rmpi and doSNOW
Message-ID: <000101cedb35$b03f9670$10bec350$@gmail.com>

Hi

I have managed to install MPICH2 and Rmpi on my Windows 7 machine. I can
also run the following code

> library(Rmpi)
> mpi.spawn.Rslaves()
        4 slaves are spawned successfully. 0 failed.
master (rank 0, comm 1) of size 5 is running on: MyMaster 
slave1 (rank 1, comm 1) of size 5 is running on: MyMaster 
slave2 (rank 2, comm 1) of size 5 is running on: MyMaster 
slave3 (rank 3, comm 1) of size 5 is running on: MyMaster 
slave4 (rank 4, comm 1) of size 5 is running on: MyMaster 
> mpichhosts()
     master      slave1      slave2      slave3      slave4 
"localhost" "localhost" "localhost" "localhost" "localhost" 
> mpi.universe.size()
[1] 4
> mpi.close.Rslaves()
[1] 1

library(doSNOW)

But every time I try to set up a cluster via

cluster <- makeCluster(4, type = "MPI")

My computer hangs up and I have to close the R session.

Any advice how I get this running?
Thanks in advance

> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)


From thpe at simecol.de  Wed Nov  6 22:56:59 2013
From: thpe at simecol.de (Thomas Petzoldt)
Date: Wed, 06 Nov 2013 22:56:59 +0100
Subject: [R] deSolve, unresolved namespace error
In-Reply-To: <CAL7OOdwZN2X852acyHHNNvYZUghx19jR-E1XcT53LqC9vgTS3w@mail.gmail.com>
References: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>
	<CAL7OOdwZN2X852acyHHNNvYZUghx19jR-E1XcT53LqC9vgTS3w@mail.gmail.com>
Message-ID: <527ABB2B.9080702@simecol.de>

On 11/6/2013 6:50 PM, Adam Clark wrote:> Addendum:
> unloading and reloading deSolve.so does indeed fix the problem:
>
> library.dynam.unload("deSolve", libpath=paste(.libPaths()[1],
> "//deSolve", sep=""))
> library.dynam("deSolve", package="deSolve", lib.loc=.libPaths()[1])
>
> However, this is a little clunky, and seems like overkill. Does
> anybody have an idea for a more elegant workaround?


Adam,

the solver lock is used for the ODEPACK solvers to prevent simultaneous
(i.e. nested) calls of the solver within R session, because the ODEPACK
algorithms use some global variables. The RK solvers do not use
global variables, so they have no lock.

If you use the ode solvers in the intended way, an internal call of:

  on.exit(.C("unlock_solver"))

should always unlock the solver, even if the function is exited due to
an error. However, your example may point to another problem in the
code, for which we need a minimal reproducible example.


As a first workaround, you may try to call:

.C("unlock_solver")

... but calling an internal .C package function outside a package is
generally not recommended, so you should definitely try to find the real
cause of your problem.

Thomas



PS: please move this thread to either R-Devel or (preferred) to the
specialised mailing list:

mailto:R-sig-dynamic-models at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-dynamic-models


From dwinsemius at comcast.net  Wed Nov  6 22:57:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 13:57:06 -0800
Subject: [R] R help-classification accuracy of DFA and RF using caret
In-Reply-To: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
Message-ID: <59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>


On Nov 6, 2013, at 10:07 AM, Henderson, Robin Michelle wrote:

> Hi,
> 
> I am a graduate student applying published R scripts to compare the classification accuracy of 2 predictive models, one built using discriminant function analysis and one using random forests (webpage link for these scripts is provided below).  The purpose of these models is to predict the biotic integrity of streams.  Specifically, I am trying to compare the classification accuracy (i.e., prediction of group membership)of both the DFA and RF models using k-fold crossvalidation for the following metrics: AUC ROC, percent correctly classified, specificity, sensitivity, and Kappa.

Sensitivity, "accuracy" (= percent correct), and specificity are only defined when you establish a particular threshold for decision. The is no "sensitivity" or "specificity" that will accrue to a classification model. AUC is an effort at presenting such an overall value, but it has deficiencies and is insensitive to statistically significant differences in models.

> I would also like to obtain the F statistic, Wilks lambda, MSE or RMSE for the random forest models as the script does not contain code to get this data.

I doubt very much that is by accident or oversight on the part of the randomForest developers.

>  I think I need to use the caret package to obtain the classification accuracy, but I keep getting error messages when I apply the train function to my data.  As I am relatively new to R and my thesis committee is unable to help as they are also unfamiliar with R, I thought it best to ask for help.

I think you need to add a statistician to your committee. The difficulties you are facing (of which you appear to be unaware) are not just related to being new to R.


>  Would someone be willing to help me?
> 
> 
> Thanks,
> Robin
> 
> http://www.epa.gov/wed/pages/models/rivpacs/rivpacs.htm
> 
> 
>> TrainDataDFAgrps2 <-predcal
>> TrainClassesDFAgrps2 <-grp.2;
>> DFAgrps2Fit1 <- train(TrainDataDFAgrps2, TrainClassesDFAgrps2,
> +  method = "lda",
> + tuneLength = 10,
> + trControl = trainControl(method = "cv"));
> Error in train.default(TrainDataDFAgrps2, TrainClassesDFAgrps2, method = "lda",  :
>  wrong model type for regression

That error is pointing out that you are choosing a method that expects a particular form of outcome (continuous) and does not accept a categorical (possibly an R factor?) outcome. I suspect you may be using the `caret` package, but it's unclear. I think this is further evidence of the need for competent statistical consultation. You would be advised to study further in Venables and Ripley's MASS(v4) or in Hastie, Tibshirani, and Freidmans ESL(v2).

This link, found with a simple google search, suggests that the author of the cited code is at an academic institution only one state away from you: fw.oregonstate.edu/system/files/Van%20Sickle%20CV%20consult.pdf?. He may be willing to offer assistance.

-- 
David.

> 
>> RFgrps2Fit1 <- train(TrainDataRFgrps2, TrainClassesRFgrps2,
> +  method = "rf",
> + tuneLength = 10,
> + trControl = trainControl(method = "cv"));
> There were 50 or more warnings (use warnings() to see the first 50)
> 
> Clip of predcal (same length as grp.2, but too much data to display all):
>> predcal
>          Reference_Test HUC12_AREA_HA_log10 ELEV_m M_Slp_sqt Precip_mm Temp_CX10
> 2370                   R                 3.7  588.0       2.2      1751       148
> 559                    R                 4.0  643.1       1.8      1674       141
> 2062                   R                 4.0  643.1       1.8      1674       141
> 2467                   R                 4.0  643.1       1.8      1674       141
> 1176                   R                 3.9  694.3       2.4      1534       131
> 1840                   R                 3.9  694.3       2.4      1534       131
> 2052                   R                 3.9  694.3       2.4      1534       131
> 1174                   R                 4.1  605.0       2.1      1382       138
> 1841                   R                 4.1  605.0       2.1      1382       138
> 2051                   R                 4.1  605.0       2.1      1382       138
> 1831                   R                 4.1  363.9       1.7       937       156
> 
> 
> Grps.2:
> grp.2
>  [1] 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 1 1
> [45] 2 2 1 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 1 1 1 2 2 2 2 2 2 1 1 1 2 2 2 1 2 2 2 2 2 2 2 2 1
> [89] 1 2 2 2 2 2 1 1 2 2 2 1 2 1 2 2 1 2 1 1 2
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov  6 23:00:14 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 14:00:14 -0800
Subject: [R] Fitting multiple horizontal lines to data
In-Reply-To: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
References: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
Message-ID: <E28183FB-613D-4047-A0A8-C4A8279AB466@comcast.net>


On Nov 6, 2013, at 9:19 AM, Sashikanth Chandrasekaran wrote:

> I am not trying to fit a horizontal line at every unique value of y. I am
> trying fit the y values with as few horizontal lines by trading off the
> number of horizontal lines with the error. The actual problem I am trying
> to solve is to smooth data in a time series. Here is a realistic example of
> y
> 
> y=c(134.45,141.82,143.81,141.81,145,141.61,143.72,145.71,200,175,140,200,148.77,71.64,111.57,118.15,119.15,112.8,111.64,111.64,157.26,143.8,40.19,64.99,64.99,129.98,64.99,65,64.98,64.99)
> 
> An example fit for y using multiple horizontal lines (may not be the best
> fit in terms of squared error or another error metric, but I have included
> the y value for concreteness)
> 

The human brain searches for patterns and often finds them where there is no underlying mechanism. If you are asking for a regime-change method that is statistically based and will replicate your brain-driven pencil-and-paper methods you will probably be disappointed.

> plot(y)
> abline(h=c(140,110,150,65) )
> abline(v=c(13,20,22,30) ,col="red")


> 1. A horizontal line at approximately y=140 (to fit the first 13 values -
> 134.45 to 148.77)
> 2. A horizontal line at approximately y=110 (to fit the next 7 values -
> 71.64 to 111.64)
> 3. A horizontal line at approximately y=150 (to fit the next 2 values -
> 157.26 to 143.8)
> 4. A horizontal line at approximately y=65 (to fit the last 8 values -
> 40.19 to 64.99)
> -sashi.

If you want a method that is driven by the magnitude of the shift in adjacent values, then this would find some but not all of your proposed breakpoints:

> which( abs(diff(y)) >55)
[1] 11 13 22 25 26

You could perhaps refine that set of candidates by requiring that the next value have some other defining feature but I was unable to come up with a simple rule-set that agreed with your candidates . There are packages that do segmented regression but hey are not generall set up to assume all regression coefficients are 0 and that you are only interested in


> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Wed Nov  6 23:08:31 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 07 Nov 2013 11:08:31 +1300
Subject: [R] R help-classification accuracy of DFA and RF using caret
In-Reply-To: <59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
	<59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
Message-ID: <527ABDDF.1010307@auckland.ac.nz>

On 11/07/13 10:57, David Winsemius wrote:

     <SNIP>
> I think you need to add a statistician to your committee. The 
> difficulties you are facing (of which you appear to be unaware) are 
> not just related to being new to R.
     <SNIP>

Fortune?

     cheers,

     Rolf


From dwinsemius at comcast.net  Wed Nov  6 23:10:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 14:10:53 -0800
Subject: [R] Nonnormal Residuals and GAMs
In-Reply-To: <Pine.LNX.4.44.1311061531180.27153-100000@aluminum.cs.pitt.edu>
References: <Pine.LNX.4.44.1311061531180.27153-100000@aluminum.cs.pitt.edu>
Message-ID: <C1304CAA-0190-4E85-869D-AA9B4317ADAE@comcast.net>


On Nov 6, 2013, at 12:46 PM, Collin Lynch wrote:

> Greetings, My question is more algorithmic than prectical.  What I am
> trying to determine is, are the GAM algorithms used in the mgcv package
> affected by nonnormally-distributed residuals?
> 
> As I understand the theory of linear models the Gauss-Markov theorem
> guarantees that least-squares regression is optimal over all unbiased
> estimators iff the data meet the conditions linearity, homoscedasticity,
> independence, and normally-distributed residuals.  Absent the last
> requirement it is optimal but only over unbiased linear estimators.
> 
> What I am trying to determine is whether or not it is necessary to check
> for normally-distributed errors in a GAM from mgcv.  I know that the
> unsmoothed terms, if any, will be fitted by ordinary least-squares but I
> am unsure whether the default Penalized Iteratively Reweighted Least
> Squares method used in the package is also based upon this assumption or
> falls under any analogue to the Gauss-Markov Theorem.

The default functional link for mgcv::gam is "log", so I doubt that your theoretical understanding applies to GAM's in general. When Simon Wood wrote his book on GAMs his first chapter was on linear models, his second chapter was on generalized lienar models at which point he had written over 100 pages, and only then did he "introduce" GAMs. I think you need to follow the same progression, and this forum is not the correct one for statistics education. Perhaps pose your follow-up questions to CrossValidated.com

-- 
David Winsemius
Alameda, CA, USA


From carl at witthoft.com  Wed Nov  6 14:31:24 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 6 Nov 2013 05:31:24 -0800 (PST)
Subject: [R] hidden functions
In-Reply-To: <6ED6C84C-543B-4F9E-9976-F93EC60C17DE@staff.londonmet.ac.uk>
References: <6ED6C84C-543B-4F9E-9976-F93EC60C17DE@staff.londonmet.ac.uk>
Message-ID: <1383744684753-4679856.post@n4.nabble.com>

Why would you need to?  The whole point of "::" and ":::" is to specify the
origin of a function.




--
View this message in context: http://r.789695.n4.nabble.com/hidden-functions-tp4679849p4679856.html
Sent from the R help mailing list archive at Nabble.com.


From gunter.berton at gene.com  Wed Nov  6 23:28:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 6 Nov 2013 14:28:41 -0800
Subject: [R] R help-classification accuracy of DFA and RF using caret
In-Reply-To: <527ABDDF.1010307@auckland.ac.nz>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
	<59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
	<527ABDDF.1010307@auckland.ac.nz>
Message-ID: <CACk-te1DNf_D2_hDBjdmci+DOgRU9ddQr6adsOrK4-PyMPV8ig@mail.gmail.com>

Second (perhaps with the slight addition indicated)

-- Bert

... And **amen!** to the sentiment expressed.


On Wed, Nov 6, 2013 at 2:08 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 11/07/13 10:57, David Winsemius wrote:
>
>     <SNIP>
>>
>> I think you need to add a statistician to your [PhD] committee. The difficulties
>> you are facing (of which you appear to be unaware) are not just related to
>> being new to R.
>
>     <SNIP>
>
> Fortune?
>
>     cheers,
>
>     Rolf
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From email8889 at gmail.com  Wed Nov  6 22:24:03 2013
From: email8889 at gmail.com (email)
Date: Wed, 6 Nov 2013 23:24:03 +0200
Subject: [R] =?utf-8?q?cannot_load_MagAct96-98_-_Extracurricular_af?=
	=?utf-8?b?76yBbGlhdGlvbiBkYXRh?=
Message-ID: <CAJMZ3cdzahpE0bFtWwrjLyJ9mk21iJvSx2hWMjmqSLefGHcdwA@mail.gmail.com>

Hi:

I have installed the NetData package, and want to use the  MagAct96-98
- Extracurricular af?liation data. But while loading the data, its
giving an error. Any help?


install.packages("NetData")
library(NetData)
data('studentnets.magact96.97.98', package = "NetData")

Warning message:
In data("studentnets.magact96.97.98", package = "NetData") :
  data set ?studentnets.magact96.97.98? not found

Thanks:
John


From dwinsemius at comcast.net  Wed Nov  6 23:38:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 14:38:44 -0800
Subject: [R] =?utf-8?q?cannot_load_MagAct96-98_-_Extracurricular_af?=
 =?utf-8?b?76yBbGlhdGlvbiBkYXRh?=
In-Reply-To: <CAJMZ3cdzahpE0bFtWwrjLyJ9mk21iJvSx2hWMjmqSLefGHcdwA@mail.gmail.com>
References: <CAJMZ3cdzahpE0bFtWwrjLyJ9mk21iJvSx2hWMjmqSLefGHcdwA@mail.gmail.com>
Message-ID: <7B0D44C2-F405-4F19-B6FE-735C4BF98888@comcast.net>


On Nov 6, 2013, at 1:24 PM, email wrote:

> Hi:
> 
> I have installed the NetData package, and want to use the  MagAct96-98
> - Extracurricular af?liation data. But while loading the data, its
> giving an error. Any help?
> 
> 
> install.packages("NetData")
> library(NetData)
> data('studentnets.magact96.97.98', package = "NetData")
> 
> Warning message:
> In data("studentnets.magact96.97.98", package = "NetData") :
>  data set ?studentnets.magact96.97.98? not found

I just loaded that package and looked at its Index. I don't see any item with that name. I see three items that appear as though they could be descendents or predecessors of such a file:

magact96	MagAct96-98 - Extracurricular affiliation data by year (1996-1998)
magact97	MagAct96-98 - Extracurricular affiliation data by year (1996-1998)
magact98	MagAct96-98 - Extracurricular affiliation data by year (1996-1998)


-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Nov  7 01:19:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 16:19:09 -0800
Subject: [R] New fortune nomination ... was Re: R help-classification
	accuracy of DFA and RF using caret
In-Reply-To: <CACk-te1DNf_D2_hDBjdmci+DOgRU9ddQr6adsOrK4-PyMPV8ig@mail.gmail.com>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
	<59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
	<527ABDDF.1010307@auckland.ac.nz>
	<CACk-te1DNf_D2_hDBjdmci+DOgRU9ddQr6adsOrK4-PyMPV8ig@mail.gmail.com>
Message-ID: <198FF735-3329-4215-B31D-A5538C688FB2@comcast.net>

Seen on StackOverflow. Any seconds?


"I would heed the warnings and diagnostics. They are there for a reason. The Ostrich algorithm does not help you."

  -- Dirk Eddelbuettel commenting on StackOverflow when a questioner said he had not run R CMD check because he suspected other problems would be found (Nov 2013)



Achim: I also have a fortunes spelling correction (at least for v 1.5-0):
Looking at:  fortune("calibration")  == fortune(277),  The author's last name needs to be Beleites.

-- 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Thu Nov  7 01:18:25 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 07 Nov 2013 11:18:25 +1100
Subject: [R] Treatment effects on measurements through time: how to tell
 when (in time) treatment has a significant effect?
In-Reply-To: <1383770817307-4679911.post@n4.nabble.com>
References: <1383770817307-4679911.post@n4.nabble.com>
Message-ID: <527ADC51.4020006@bitwrit.com.au>

On 11/07/2013 07:46 AM, c_e_cressler wrote:
> Hi,
>
> The data (attached) I am looking at consists of measurements of growth rate
> at different ages, for individuals in two treatments (control and infected).
> What I want to know is whether and when (what age) the growth rate of
> infected individuals is higher than the growth rate for control individuals.
>
> The simplest way to approach this question is to just do a t-test at each
> age, but because the growth rates at a given age depend on the growth rates
> at previous ages before, that seems statistically invalid. I have looked at
> some of the time series literature, but most of that seems more complicated
> than what I am trying to do. What I would like to be able to say is
> something like, "The growth rate of infected individuals is higher than
> control individuals for ages 18-30."
>
Hi Clay,
If you calculate the mean growth rates:

inf_mean<-apply(as.matrix(inf.grates),1,
  mean,na.rm=TRUE)
cntl_mean<-apply(as.matrix(cntl.grates),1,
  mean,na.rm=TRUE)

and plot them:

plot(cntl_mean,col=3)
points(inf_mean,col=2)

It looks like the growth rate in the infected group is consistently 
greater. Testing the linear models:

summary(lm(cntl_mean~I(1:length(cnf_mean))))
summary(lm(inf_mean~I(1:length(inf_mean))))

looks like there is a significant effect. The proper comparison would be 
a mixed model with the individual scores, I think.

Jim


From r.turner at auckland.ac.nz  Thu Nov  7 01:31:02 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 07 Nov 2013 13:31:02 +1300
Subject: [R] New fortune nomination ... was Re: R help-classification
 accuracy of DFA and RF using caret
In-Reply-To: <198FF735-3329-4215-B31D-A5538C688FB2@comcast.net>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
	<59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
	<527ABDDF.1010307@auckland.ac.nz>
	<CACk-te1DNf_D2_hDBjdmci+DOgRU9ddQr6adsOrK4-PyMPV8ig@mail.gmail.com>
	<198FF735-3329-4215-B31D-A5538C688FB2@comcast.net>
Message-ID: <527ADF46.2030100@auckland.ac.nz>

On 11/07/13 13:19, David Winsemius wrote:
> Seen on StackOverflow. Any seconds?
>
>
> "I would heed the warnings and diagnostics. They are there for a reason. The Ostrich algorithm does not help you."
>
>    -- Dirk Eddelbuettel commenting on StackOverflow when a questioner said he had not run R CMD check because he suspected other problems would be found (Nov 2013)

Right on!!!

     cheers,

     Rolf


From Achim.Zeileis at uibk.ac.at  Thu Nov  7 01:33:44 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 7 Nov 2013 01:33:44 +0100 (CET)
Subject: [R] New fortune nomination ... was Re: R help-classification
 accuracy of DFA and RF using caret
In-Reply-To: <527ADF46.2030100@auckland.ac.nz>
References: <B74A2964EA6D7D4A8FD2B7786FB07006287EEDA4@CO1PRD0112MB619.prod.exchangelabs.com>
	<59F67ED5-E846-4E06-B159-CD9922D3E00B@comcast.net>
	<527ABDDF.1010307@auckland.ac.nz>
	<CACk-te1DNf_D2_hDBjdmci+DOgRU9ddQr6adsOrK4-PyMPV8ig@mail.gmail.com>
	<198FF735-3329-4215-B31D-A5538C688FB2@comcast.net>
	<527ADF46.2030100@auckland.ac.nz>
Message-ID: <alpine.DEB.2.10.1311070133060.21083@paninaro.uibk.ac.at>

On Thu, 7 Nov 2013, Rolf Turner wrote:

> On 11/07/13 13:19, David Winsemius wrote:
>> Seen on StackOverflow. Any seconds?
>> 
>> 
>> "I would heed the warnings and diagnostics. They are there for a reason. 
>> The Ostrich algorithm does not help you."
>>
>>    -- Dirk Eddelbuettel commenting on StackOverflow when a questioner said 
>> he had not run R CMD check because he suspected other problems would be 
>> found (Nov 2013)
>
> Right on!!!

Yes! :-)

Now also in the devel-version on R-Forge.

Thanks,
Z

>    cheers,
>
>    Rolf
>


From zhyuanzh at gmail.com  Thu Nov  7 00:44:11 2013
From: zhyuanzh at gmail.com (Zhong-Yuan Zhang)
Date: Thu, 7 Nov 2013 07:44:11 +0800
Subject: [R] Function does not see variables outside the function
In-Reply-To: <000a01cedaf8$18f420c0$4adc6240$@mcmaster.ca>
References: <CAApZs+HuWo2zuKjjEfpjsYY7E21nUEpHVgpqRimyZOReO=AVAg@mail.gmail.com>
	<1383656069289-4679768.post@n4.nabble.com>
	<CAApZs+HCZ4KAt=D+anxrV4Fg4XMwNoHRTosQL=LjsRjVYdi+8Q@mail.gmail.com>
	<000a01cedaf8$18f420c0$4adc6240$@mcmaster.ca>
Message-ID: <CAApZs+GoSSwbAkMJ6T80A5zVv+TtJF6OqykhAN+1kCYE5sWd4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/b4f100ee/attachment.pl>

From macqueen1 at llnl.gov  Thu Nov  7 02:43:18 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 7 Nov 2013 01:43:18 +0000
Subject: [R] Fitting multiple horizontal lines to data
In-Reply-To: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D53C6BF@PRDEXMBX-08.the-lab.llnl.gov>

Possibly see the
   strucchange
package

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/6/13 9:19 AM, "Sashikanth Chandrasekaran"
<sashikanth.chandrasekaran at gmail.com> wrote:

>I am not trying to fit a horizontal line at every unique value of y. I am
>trying fit the y values with as few horizontal lines by trading off the
>number of horizontal lines with the error. The actual problem I am trying
>to solve is to smooth data in a time series. Here is a realistic example
>of
>y
>
>y=c(134.45,141.82,143.81,141.81,145,141.61,143.72,145.71,200,175,140,200,1
>48.77,71.64,111.57,118.15,119.15,112.8,111.64,111.64,157.26,143.8,40.19,64
>.99,64.99,129.98,64.99,65,64.98,64.99)
>
>An example fit for y using multiple horizontal lines (may not be the best
>fit in terms of squared error or another error metric, but I have included
>the y value for concreteness)
>
>1. A horizontal line at approximately y=140 (to fit the first 13 values -
>134.45 to 148.77)
>2. A horizontal line at approximately y=110 (to fit the next 7 values -
>71.64 to 111.64)
>3. A horizontal line at approximately y=150 (to fit the next 2 values -
>157.26 to 143.8)
>4. A horizontal line at approximately y=65 (to fit the last 8 values -
>40.19 to 64.99)
>-sashi.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From collinl at cs.pitt.edu  Thu Nov  7 02:44:26 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Wed, 06 Nov 2013 20:44:26 -0500 (EST)
Subject: [R] Nonnormal Residuals and GAMs
In-Reply-To: <C1304CAA-0190-4E85-869D-AA9B4317ADAE@comcast.net>
Message-ID: <Pine.LNX.4.44.1311062012430.9206-100000@neptunium.cs.pitt.edu>

> The default functional link for mgcv::gam is "log", so I doubt that
 your theoretical understanding applies to GAM's in general. When Simon
 Wood wrote his book on GAMs his first chapter was on linear models, his
 second chapter was on generalized lienar models at which point he had
 written over 100 pages, and only then did he "introduce" GAMs. I think
 you need to follow the same progression, and this forum is not the
 correct one for statistics education. Perhaps pose your follow-up
 questions to CrossValidated.com

David, thank you for your advice, has the default changed for mgcv::gam?
Based upon the help pages for the version I have (1.7-27) I had thought
that the default family was gaussian() with link "identity".

In any event I will look again at Simon Woods' book and consider
CrossValidated in the future.

	Best,
	Collin.


From jim at bitwrit.com.au  Thu Nov  7 02:53:47 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 07 Nov 2013 12:53:47 +1100
Subject: [R] plot a single frequency of a ts object
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F0DA2FFE9@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F0DA2FFE9@ESINO.regionemarche.intra>
Message-ID: <527AF2AB.5070906@bitwrit.com.au>

On 11/07/2013 04:56 AM, Stefano Sofia wrote:
> Dear list users,
> I transformed two vectors of seasonal data in ts objects of frequency 4:
>
> y1<- ts(x1, frequency=4, start=c(1952,1))
> y2<- ts(x2, frequency=4, start=c(1952,1))
>
> In this way Qtr1 corresponds to Winters, Qtr2 corresponds to Springs and so on.
> I would like to plot on the same graph both y1 and all the Winters of y2.
> I am not able to find an easy and straightforward way to do that.
> Could somebody please help me in this?

Hi Stefano,
This may do what you want:

x1<-runif(64,1,4)
x2<-runif(64,2,5)
y1 <- ts(x1, frequency=4, start=c(1952,1))
y2 <- ts(x2, frequency=4, start=c(1952,1))
plot(y1,ylim=c(1,5))
y2w<-ts(y2[seq(1,61,by=4)],frequency=1,start=1952)
lines(y2w)

Jim


From wdunlap at tibco.com  Thu Nov  7 03:13:20 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 Nov 2013 02:13:20 +0000
Subject: [R] plot a single frequency of a ts object
In-Reply-To: <527AF2AB.5070906@bitwrit.com.au>
References: <8B435C9568170B469AE31E8891E8CC4F0DA2FFE9@ESINO.regionemarche.intra>
	<527AF2AB.5070906@bitwrit.com.au>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA13529@PA-MBX01.na.tibco.com>

> y2 <- ts(x2, frequency=4, start=c(1952,1))
> y2w<-ts(y2[seq(1,61,by=4)],frequency=1,start=1952)

I think it is simpler to compute y2w using the window() function, which
figures out the right call to seq() for you:
    window(y2, frequency=1, start=c(1952,1)) # use c(1952,2) for springs, etc.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jim Lemon
> Sent: Wednesday, November 06, 2013 5:54 PM
> To: Stefano Sofia
> Cc: r-help at r-project.org
> Subject: Re: [R] plot a single frequency of a ts object
> 
> On 11/07/2013 04:56 AM, Stefano Sofia wrote:
> > Dear list users,
> > I transformed two vectors of seasonal data in ts objects of frequency 4:
> >
> > y1<- ts(x1, frequency=4, start=c(1952,1))
> > y2<- ts(x2, frequency=4, start=c(1952,1))
> >
> > In this way Qtr1 corresponds to Winters, Qtr2 corresponds to Springs and so on.
> > I would like to plot on the same graph both y1 and all the Winters of y2.
> > I am not able to find an easy and straightforward way to do that.
> > Could somebody please help me in this?
> 
> Hi Stefano,
> This may do what you want:
> 
> x1<-runif(64,1,4)
> x2<-runif(64,2,5)
> y1 <- ts(x1, frequency=4, start=c(1952,1))
> y2 <- ts(x2, frequency=4, start=c(1952,1))
> plot(y1,ylim=c(1,5))
> y2w<-ts(y2[seq(1,61,by=4)],frequency=1,start=1952)
> lines(y2w)
> 
> Jim
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Nov  7 04:11:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Nov 2013 19:11:28 -0800
Subject: [R] Nonnormal Residuals and GAMs
In-Reply-To: <Pine.LNX.4.44.1311062012430.9206-100000@neptunium.cs.pitt.edu>
References: <Pine.LNX.4.44.1311062012430.9206-100000@neptunium.cs.pitt.edu>
Message-ID: <E93459B1-BBB8-4585-A8DD-56D7E6B47C48@comcast.net>


On Nov 6, 2013, at 5:44 PM, Collin Lynch wrote:

>> The default functional link for mgcv::gam is "log", so I doubt that
> your theoretical understanding applies to GAM's in general. When Simon
> Wood wrote his book on GAMs his first chapter was on linear models, his
> second chapter was on generalized lienar models at which point he had
> written over 100 pages, and only then did he "introduce" GAMs. I think
> you need to follow the same progression, and this forum is not the
> correct one for statistics education. Perhaps pose your follow-up
> questions to CrossValidated.com
> 
> David, thank you for your advice, has the default changed for mgcv::gam?
> Based upon the help pages for the version I have (1.7-27) I had thought
> that the default family was gaussian() with link "identity".
> 
> In any event I will look again at Simon Woods' book and consider
> CrossValidated in the future.

I may have gotten this wrong by only referring to my memory. I'm not able to tell by looking at either         ?mgcv::gam or ?gam::gam pages where I picked up this notion.

-- 
David Winsemius
Alameda, CA, USA


From COLLINL at pitt.edu  Thu Nov  7 05:37:29 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Wed, 06 Nov 2013 23:37:29 -0500
Subject: [R] Nonnormal Residuals and GAMs
In-Reply-To: <E93459B1-BBB8-4585-A8DD-56D7E6B47C48@comcast.net>
References: <Pine.LNX.4.44.1311062012430.9206-100000@neptunium.cs.pitt.edu>
	<E93459B1-BBB8-4585-A8DD-56D7E6B47C48@comcast.net>
Message-ID: <1550acd781c2713b1ee39129c04385d3.squirrel@webmail.pitt.edu>

>>> The default functional link for mgcv::gam is "log", so I doubt that
>> your theoretical understanding applies to GAM's in general. When Simon
>> Wood wrote his book on GAMs his first chapter was on linear models, his
>> second chapter was on generalized lienar models at which point he had
>> written over 100 pages, and only then did he "introduce" GAMs. I think
>> you need to follow the same progression, and this forum is not the
>> correct one for statistics education. Perhaps pose your follow-up
>> questions to CrossValidated.com
>>
>> David, thank you for your advice, has the default changed for mgcv::gam?
>> Based upon the help pages for the version I have (1.7-27) I had thought
>> that the default family was gaussian() with link "identity".
>>
>> In any event I will look again at Simon Woods' book and consider
>> CrossValidated in the future.
>
> I may have gotten this wrong by only referring to my memory. I'm not able
> to tell by looking at either         ?mgcv::gam or ?gam::gam pages where I
> picked up this notion.

Ok, thanks.


From Giovanni_Millo at Generali.com  Thu Nov  7 09:47:02 2013
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Thu, 7 Nov 2013 09:47:02 +0100
Subject: [R] R: resdiuals of random model estimated by plm function
In-Reply-To: <20131106173001.1587192psdnkhjt5@webmail.uniparthenope.it>
References: <20131106173001.1587192psdnkhjt5@webmail.uniparthenope.it>
Message-ID: <D41D66AB93B9E04BBA5378B621FFDACB045814B5@BEMAILEXPD01.corp.generali.net>

Dear Alfonso,

in a RE model you do not explicitly estimate every single individual effect, but only the variance of the distribution they have been "drawn from". Hence the only (pointwise) residual you can estimate ex-post is the composite one: i.e., the sum.

Best,
Giovanni 

Giovanni Millo, PhD
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 3,
34132 Trieste (Italy)
tel. +39 040 671184
fax  +39 040 671160

-----Messaggio originale-----
Da: alfonso.carfora at uniparthenope.it [mailto:alfonso.carfora at uniparthenope.it] 
Inviato: mercoled? 6 novembre 2013 17.30
A: r-help at r-project.org
Cc: Millo Giovanni
Oggetto: resdiuals of random model estimated by plm function

Hi all,


I have estimated a random panel model using plm function.

I have a question about the vector of resduals obtained with the object $residuals.

example:

data("Produc", package = "plm")
zz <- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, model="random", data = Produc, index = c("state","year"))

res<-zz$residuals # vector of the residuals.

the vector res is the sum of the idyosiyncratic (eit) and individual
(ui) component or is only the idyosiyncratic (eit) component?

Thanks
Alfonso





?
Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From anna.lampei-bucharova at uni-tuebingen.de  Thu Nov  7 12:15:31 2013
From: anna.lampei-bucharova at uni-tuebingen.de (a_lampei)
Date: Thu, 7 Nov 2013 03:15:31 -0800 (PST)
Subject: [R] problem with interaction in lmer even after creating an
 "interaction variable"
Message-ID: <1383822931873-4679951.post@n4.nabble.com>

Dear all,
I have a problem with interactions in lmer. I have 2 factors (garden and
gebiet) which interact, plus one other variable (home), dataframe arr. When
I put:
/
lmer (biomass ~ home + garden:gebiet +  ( 1|Block), data = arr)/

it writes:
/Error in lme4::lFormula(formula = biomass ~ home + garden:gebiet + (1 |  : 
  rank of X = 28 < ncol(X) = 30/

In the lmer help I found out that if not all combination of the interaction
are realized, lmer has problems and one should do new variable using
"interaction", which I did:
/
arr$agg <- interaction (arr$gebiet, arr$garden, drop = TRUE)/

when I fit the interaction term now:
 /
lmer (biomass ~ home + agg+  ( 1|Block), data = arr)/

The error does not change:
/
Error in lme4::lFormula(formula = biomass ~ home + agg + (1 | Block),  : 
  rank of X = 28 < ncol(X) = 29/

No NAs are in the given variables in the dataset.

Interestingly it works when I put only given interaction like

/lmer (biomass ~ agg +  ( 1|Block), data = arr)/

Even following models work:
/lmer (biomass ~ gebiet*garden +  ( 1|Block), data = arr)
lmer (biomass ~ garden + garden:gebiet  +( 1|Block), data = arr)/

But if I add the interaction term in th enew formate of the new fariable, it
reports again the same error.

/lmer (biomass ~ garden + agg  +( 1|Block), data = arr)/

If I put any other variable from the very same dataframe (not only variable
"home"), the error is reported again.

I do not understand it, the new variable is just another factor now, or? And
it is in the same dataframe, it has the same length.

Does anyone have any idea?

Thanks a lot, Anna


 









--
View this message in context: http://r.789695.n4.nabble.com/problem-with-interaction-in-lmer-even-after-creating-an-interaction-variable-tp4679951.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Thu Nov  7 13:20:14 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 7 Nov 2013 04:20:14 -0800 (PST)
Subject: [R] Fitting multiple horizontal lines to data
In-Reply-To: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
References: <CAO-ZAA5Ht4u6y0XXxvseK4bywU9AzPfrm8Eiaf8KzLvNRvXs-Q@mail.gmail.com>
Message-ID: <1383826814929-4679952.post@n4.nabble.com>

You already asked this on StackOverflow.
The answer remains the same,  pretty much what David W.  wrote:   this is
not a question about fitting lines to data.  You need to step back and think
about what message you want to deliver to those who will view your graph,
and what the meaning of your dataset is in the first place.




--
View this message in context: http://r.789695.n4.nabble.com/Fitting-multiple-horizontal-lines-to-data-tp4679891p4679952.html
Sent from the R help mailing list archive at Nabble.com.


From jholtman at gmail.com  Thu Nov  7 14:19:35 2013
From: jholtman at gmail.com (jim holtman)
Date: Thu, 7 Nov 2013 08:19:35 -0500
Subject: [R] Multiple String word replacements: Performance Issue
In-Reply-To: <7DF0A2FB-F412-4035-8C91-E3DD4172C3C7@t-online.de>
References: <7DF0A2FB-F412-4035-8C91-E3DD4172C3C7@t-online.de>
Message-ID: <CAAxdm-7CDLM8jhMNrWSYkLKS9DOGwCLBcBaidHLe2NutF9cdPQ@mail.gmail.com>

Here is a start.  I was wondering how long it would take to at least
substitute 800 different patterns into 4M vectors.  Here is my test.
It took longer (99 sec) to create the test data than to do the
substitutes (52 secs).  Now some variations on this can provide the
other information that you are probably after in less than a day ( I
would guess less than an hour)


> n <- 1000
> x <- paste0("$"
+         , sample(LETTERS, n, TRUE)
+         , sample(LETTERS, n, TRUE)
+         , sample(LETTERS, n, TRUE)
+         , sample(LETTERS, n, TRUE)
+ )
> x <- x[!duplicated(x)][1:800]
>
> n <- 4000000
> system.time({
+ output <- replicate(n, paste(sample(x,2), collapse = ' '))
+ })
   user  system elapsed
  99.85    0.22  100.37
>
> system.time({
+ pattern <- paste0("\\", x, collapse = "|")
+ z <- gsub(pattern, "[ticker]", output, perl = TRUE)
+ })
   user  system elapsed
  52.05    0.00   52.21
>
>
> str(output)
 chr [1:4000000] "$JHVN $VKOL" "$GTEU $CEGL" "$LOEY $ETQK" "$AFDO
$SDLH" "$MOIN $WEVR" ...
> str(z)
 chr [1:4000000] "[ticker] [ticker]" "[ticker] [ticker]" "[ticker] [ticker]" ...
> str(pattern)
 chr "\\$MATF|\\$GFGC|\\$SRYC|\\$HLWS|\\$GHFB|\\$BGVU|\\$GFDW|\\$PSFN|\\$ONDY|\\$SXUH|\\$EBDJ|\\$YNQY|\\$NDBT|\\$TOQK|\\$IUBN|\\$VSMT"|
__truncated__
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Nov 6, 2013 at 8:11 AM, Simon Pickert <simon.pickert at t-online.de> wrote:
> Dear experts,
> I?ve been on this for weeks now, and couldn?t find a solution..Sorry for the long description. I figured I post many details, so you get the problem entirely, although it?s not hard to grasp.
>
> **Situation:**
> Data frame consisting of 4 million entries (total size: 250 MB). Two columns: `ID` and `TEXT`. Text strings are each up to 200 characters.
>
>
> **Task:**
> Preprocessing the text strings
>
> Example Data:
>
>
>     +??????+?????????????????+
>     |  ID    |                     Text                                                 |
>     +??+?????????????????????+
>     | 123  | $AAPL is up +5%                                                |
>     | 456  | $MSFT , $EBAY doing great.  www.url.com       |
>                                               ..
>     +??+?????????????????????+
>
> Should become
>
>     +??????+??????????????????????????????????-??+
>     |  ID    |                     Text clean                                        |  First Ticker  |  All Ticker       |   Ticker Count
>     +??+????????????????????+??????+???? +???????-?+
>     | 123  | [ticker] is up [positive_percentage]                       |       $aapl       |   $aapl            |          1
>     | 456  | [ticker] [ticker] doing great [url] [pos_emotion]     |       $msft       |   $msft,$ebay  |          2
>                                               ..
>     +??+????????????????????+??????-+??????+??????+
>
>
>
> **Problem:**
> It takes too long. On my 8GB RAM Dual-Core machine: Cancelled after 1 day. On a 70GB 8-Core Amazon EC2 instance: Cancelled after 1 day.
>
>
> **Details:**
> I am basically
>
>  - Counting how often certain words appear in one string
>  - Write this number into a new column (COUNT)
>  - Replace this (counted) word
>  - Replace other words (which I don't need to count before)
>  - Replace some regular expressions
>
> The vectors which are used as patterns look like this:
>
>     "\\bWORD1\\b|\\bWORD2\\b|\\bWORD3\\b|\\bWORD4\\b..."
>
> Thus, those 'replacement vectors' are character vectors of length 1, each containing up to 800 words
>
>
>
> **Main code:**
>
>     library("parallel")
>     library("stringr")
>
>     preprocessText<-function(x){
>
>       # Replace the 'html-and'
>       arguments<-list(pattern="\\&amp\\;",replacement="and",x=x, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       # Remove some special characters
>        arguments<-list(pattern="[^-[:alnum:]\\'\\:\\/\\$\\%\\.\\,\\+\\-\\#\\@\\_\\!\\?+[:space:]]",replacement="",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       # Lowercase
>       arguments<-list(string=y,pattern=tolower(rep_ticker))
>       first<-do.call(str_match,arguments)
>
>       # Identify signal words and count them
>       # Need to be done in parts, because otherwise R can't handle this many at once
>       arguments<-list(string=x, pattern=rep_words_part1)
>       t1<-do.call(str_extract_all,arguments)
>
>       arguments<-list(string=x, pattern=rep_words_part2)
>       t2<-do.call(str_extract_all,arguments)
>
>       arguments<-list(string=x, pattern=rep_words_part3)
>       t3<-do.call(str_extract_all,arguments)
>
>       arguments<-list(string=x, pattern=rep_words_part4)
>       t4<-do.call(str_extract_all,arguments)
>
>       count=length(t1[[1]])+length(t2[[1]])+length(t3[[1]])+length(t4[[1]])
>       signal_words=c(t1[[1]],t2[[1]],t3[[1]],t4[[1]])
>
>
>       # Replacements
>
>       arguments<-list(pattern=rep_wordsA,replacement="[ticker]",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_wordB_part1,replacement="[ticker] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_wordB_part2,replacement="[ticker] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_wordB_part3,replacement="[ticker2] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_wordB_part4,replacement=?[ticker2] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_email,replacement=" [email_address] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_url,replacement=" [url] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_wordC,replacement=" [wordC] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       # Some regular expressions
>       arguments<-list(pattern="\\+[[:digit:]]*.?[[:digit:]]+%",replacement=" [positive_percentage] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="-[[:digit:]]*.?[[:digit:]]+%",replacement=" [negative_percentage] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="[[:digit:]]*.?[[:digit:]]+%",replacement=" [percentage] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="\\$[[:digit:]]*.?[[:digit:]]+",replacement=" [dollar_value] ",x=y,ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="\\+[[:digit:]]*.?[[:digit:]]+",replacement=" [pos_number] ",x=y, ignore.case=TRUE)# remaining numbers
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="\\-[[:digit:]]*.?[[:digit:]]+",replacement=" [neg_number] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern="[[:digit:]]*.?[[:digit:]]+",replacement=" [number] ",x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_question,replacement=" [question] ", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>
>       # Unify synonyms
>       arguments<-list(pattern=rep_syno1,replacement="happy", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_syno2,replacement="sad", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_syno3,replacement="people", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_syno4,replacement="father", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_syno5,replacement="mother", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rep_syno6,replacement="money", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       # Remove words
>       # Punctuation (I know there a pre-defined R commands for this, but I need to customize this
>       arguments<-list(pattern=rem_punct,replacement="", x=y, ignore.case=TRUE)
>       y<-do.call(gsub, arguments)
>
>       arguments<-list(pattern=rem_linebreak,replacement=" ", x=y, ignore.case=TRUE) #Remove line breaks
>       y<-do.call(gsub, arguments)
>
>       #Append Positive or Negative Emotion
>       arguments<-list(x=y)
>       y<-do.call(appendEmotion, arguments)
>
>
>       # Output
>       result<-list(
>         textclean=y,
>         first_ticker=first,
>         all_ticker=signal_words,
>         ticker_count=count)
>
>       return(result)
>     }
>
>     resultList<-mclapply(dataframe$text_column,preprocessText)
>
> ** end main code **
>
> (The return would be a list, which I plan to convert to a data.frame. Don?t get that far though).
>
>
> Before, I also tried to call each `gsub` seperately, thus performing the first `gsub` on every text string, then the second `gsub` and so on.. but I guess that this was even less efficient.
>
> The code itself works, but for me it seems that this can be speeded up. Unfortunately I'm not familiar with hash tables, which is what I heard could be a solution.
>
> Appreciate your ideas and help very much!
>
>
>
>
> *Definition of the one function called inside `preprocessText`*
>
>     appendEmotion<-function(x){
>
>       if (grepl(app_pos,x)){
>         x<-paste(x," [pos_emotion] ")
>       }
>       if(grepl(app_neg,x)){
>         x<-paste(x," [neg_emotion] ")
>       }
>       #Output
>       return(x)
>     }
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Thu Nov  7 14:40:30 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 7 Nov 2013 08:40:30 -0500
Subject: [R] reading in stata file with read.dta works in R x64 3.0.1 and
 crashes R x64 3.0.2
Message-ID: <CAOwvMDwQopNCFM9Oh=xHM9Zx3L-CV9s_OhmUQPRMjYq1WjrzMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/eeafc8bb/attachment.pl>

From bbolker at gmail.com  Thu Nov  7 15:03:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 7 Nov 2013 14:03:22 +0000
Subject: [R] problem with interaction in lmer even after creating an
	"interaction variable"
References: <1383822931873-4679951.post@n4.nabble.com>
Message-ID: <loom.20131107T145540-295@post.gmane.org>

a_lampei <anna.lampei-bucharova <at> uni-tuebingen.de> writes:

> 
> Dear all,
> I have a problem with interactions in lmer. I have 2 factors (garden and
> gebiet) which interact, plus one other variable (home), 
> dataframe arr. When
> I put:
> /
> lmer (biomass ~ home + garden:gebiet +  ( 1|Block), data = arr)/
> 
> it writes:
> /Error in lme4::lFormula(formula = biomass ~ home + garden:gebiet 
> + (1 |  : 
>   rank of X = 28 < ncol(X) = 30/
> 
> In the lmer help I found out that if not all combination of
>  the interaction
> are realized, lmer has problems and one should do new variable using
> "interaction", which I did:
> /
> arr$agg <- interaction (arr$gebiet, arr$garden, drop = TRUE)/
> 
> when I fit the interaction term now:
>  /
> lmer (biomass ~ home + agg+  ( 1|Block), data = arr)/
> 
> The error does not change:
> /
> Error in lme4::lFormula(formula = biomass ~ home + agg + (1 | Block),  : 
>   rank of X = 28 < ncol(X) = 29/
> 
> No NAs are in the given variables in the dataset.
> 
> Interestingly it works when I put only given interaction like
> 
> /lmer (biomass ~ agg +  ( 1|Block), data = arr)/
> 
> Even following models work:
> /lmer (biomass ~ gebiet*garden +  ( 1|Block), data = arr)
> lmer (biomass ~ garden + garden:gebiet  +( 1|Block), data = arr)/
> 
> But if I add the interaction term in th enew formate of 
> the new fariable, it
> reports again the same error.
> 
> /lmer (biomass ~ garden + agg  +( 1|Block), data = arr)/
> 
> If I put any other variable from the very same dataframe 
> (not only variable
> "home"), the error is reported again.
> 
> I do not understand it, the new variable is just another 
> factor now, or? And
> it is in the same dataframe, it has the same length.
> 
> Does anyone have any idea?
> 
> Thanks a lot, Anna
> 

  This probably belongs on r-sig-mixed-models.

  Presumably 'home' is still correlated with one of the
columns of 'garden:gebiet'.

  Here's an example of how you can use svd() to find out which
of your columns are collinear:

set.seed(101)
d <- data.frame(x=runif(100),y=1:100,z=2:101)
m <- model.matrix(~x+y+z,data=d)
s <- svd(m)
zapsmall(s$d)
## [1] 828.8452   6.6989   2.6735   0.0000
## this tells us there is one collinear component
zapsmall(s$v)
##            [,1]       [,2]       [,3]       [,4]
## [1,] -0.0105005 -0.7187260  0.3872847  0.5773503
## [2,] -0.0054954 -0.4742947 -0.8803490  0.0000000
## [3,] -0.7017874  0.3692117 -0.1945349  0.5773503
## [4,] -0.7122879 -0.3495142  0.1927498 -0.5773503
## this tells us that the first (intercept), third (y),
## and fourth (z) column of the model matrix are
## involved in the collinear term, i.e.
## 1+y-z is zero


From andy_liaw at merck.com  Thu Nov  7 15:06:49 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 7 Nov 2013 09:06:49 -0500
Subject: [R] FW: Nadaraya-Watson kernel
In-Reply-To: <DUB122-W16799739806241A7A7ADB385F10@phx.gbl>
References: <DUB122-W253DBDF28232A9FBD6C47585F10@phx.gbl>
	<DUB122-W16799739806241A7A7ADB385F10@phx.gbl>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B857FC0B@USCTMXP51012.merck.com>

Use KernSmooth (one of the recommended packages that are included in R distribution).  E.g.,

> library(KernSmooth)
KernSmooth 2.23 loaded
Copyright M. P. Wand 1997-2009
> x <- seq(0, 1, length=201)
> y <- 4 * cos(2*pi*x) + rnorm(x)
> f <- locpoly(x, y, degree=0, kernel="epan", bandwidth=.1)
> plot(x, y)
> lines(f, lwd=2)

Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ms khulood aljehani
Sent: Tuesday, November 05, 2013 9:49 AM
To: r-help at stat.math.ethz.ch
Subject: [R] FW: Nadaraya-Watson kernel

From: aljehani-k at hotmail.com
To: r-help at r-project.org
Subject: Nadaraya-Watson kernel
Date: Tue, 5 Nov 2013 17:42:13 +0300




Hello
 
i want to compute the Nadaraya-Watson kernel estimation when the kernel function is Epanchincov kernel
i use the command
ksmooth(x, y, kernel="normal", bandwidth ,....)
 
the argmunt ( kernel="normal" ) accept normal and box kernels
i want to compute it if the kerenl = Epanchincov
 
 
thank you
 
                       		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From andreas-winterhalder at web.de  Thu Nov  7 15:17:10 2013
From: andreas-winterhalder at web.de (wintwin111)
Date: Thu, 7 Nov 2013 06:17:10 -0800 (PST)
Subject: [R] loop for backtesting
Message-ID: <1383833830071-4679962.post@n4.nabble.com>

First of all sorry for my bad english but its not my native language.

I am working on a paper on Portfolio Optimization with Markowitz and Lower
Partial Moments. 

I want to compare the returns of the minimum variance portfolios from booth
methods. First of all i have an in-sample multivariate timeseries from 4
stocks reaching from 1.october.2011 to 1.october 2012 (log-returns, daily
data, 257 observations for each stock).

I start to optimize my portfolio using the package tseries as follow:

portfolio.optim(x,pm=mean(x),riskless=F,rf=0,shorts=F,reslow=NULL,reshigh=NULL,covmat=cov(x))

with this i get the weights, the mean return of the whole period, the
standard deviation and the returns on each day for my in-sample optimal
portfolio Markowitz portfolio. 

The out of sample data reaches from 2.october.2012 to 1.october.2013
(log-returns,daily data, 253 observations for each stock, again a
multivariate time series). Now i want to optimize the Portfolio 253 times.
Each time the log-returns for one day should be added to the original
in-sample timeseries (first optimization 257 in-sample data plus the first
from the out of sample data and so on). Now i should get new weights for
every of the 253 periods and therefor new returns for the portfolio every
period. 

My advisor at the university told me i cant use backtest packages cause they
cant handle the Lower Partial Moments part of my analysis. The problem is
just for the markowitz portfolio optimization. 

I hope you can help me with my problem

greetings wintwin111



--
View this message in context: http://r.789695.n4.nabble.com/loop-for-backtesting-tp4679962.html
Sent from the R help mailing list archive at Nabble.com.


From elisabeth.eckstaedt at tu-dresden.de  Thu Nov  7 14:36:41 2013
From: elisabeth.eckstaedt at tu-dresden.de (=?iso-8859-1?Q?Eckst=E4dt=2C_Elisabeth?=)
Date: Thu, 7 Nov 2013 13:36:41 +0000
Subject: [R] strange behaviour when subsetting a data.frame
Message-ID: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>

Hello everyone,
I am experiencing a unfathomable benaviour of "subset" on a data.frame. This is a minimal reproducable example. The data.frame cosists only of one column, which contains 10 ascending values (from 0.1 to 1). Subsetting for 0.1 is working (gives me one row), subsetting for 0.3 gives me zero rows? Doing the same with values from 1 to 10 is working out well (as expected). 

Beimischung=seq(0.1,1,0.1)
man2=data.frame(Beimischung)
subset(man2, Beimischung==0.3)
#---> gives 0 rows
subset(man2, Beimischung==0.1)
---> gives one row (as expected)#

#also not working:

man2$Beimischung3=man2$Beimischung*10
subset(man2, Beimischung3==3)
--> gives 0 rows

Does anybody have a clue for me?
Thanks in advance
Regards
Elisabeth
_______________
Dipl.-Ing. Elisabeth Eckst?dt
Member of Academic Staff & PhD Student
Technische Universit?t Dresden
Faculty of Mechanical Engineering
Institue of Power Engineering
Chair of Building Energy Systems and Heat Supply

Phone +49 351 463 34709
Fax +49 351 463 37076
Web http://tu-dresden.de/mw/iet/ew


From helene.huber at univ-paris1.fr  Thu Nov  7 13:48:48 2013
From: helene.huber at univ-paris1.fr (=?ISO-8859-1?Q?H=E9l=E8ne_Huber=2DYahi?=)
Date: Thu, 7 Nov 2013 13:48:48 +0100
Subject: [R] AER ivreg diagnostics: question on DF of Sargan test
Message-ID: <CAA40SnePyJMH7PmCnGL97E-hYiqjuo5W95BD7vcwrKKrt-YS7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/a43ff9cc/attachment.pl>

From roland.deutsch at tuwien.ac.at  Thu Nov  7 14:07:12 2013
From: roland.deutsch at tuwien.ac.at (Roland Deutsch)
Date: Thu, 7 Nov 2013 14:07:12 +0100
Subject: [R] Adding the complementary log-link to binomial() and make.link()
Message-ID: <527B9080.9070906@tuwien.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/6a957506/attachment.pl>

From tretiakov.k at gmail.com  Thu Nov  7 14:38:29 2013
From: tretiakov.k at gmail.com (Konstantin Tretiakov)
Date: Thu, 7 Nov 2013 13:38:29 +0000
Subject: [R] all combinations with replacement not ordered
Message-ID: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/3ae815e7/attachment.pl>

From vikrant.shimpi at tcs.com  Thu Nov  7 15:27:34 2013
From: vikrant.shimpi at tcs.com (vikrant)
Date: Thu, 7 Nov 2013 06:27:34 -0800 (PST)
Subject: [R] Checking datetime value
Message-ID: <1383834454305-4679963.post@n4.nabble.com>

Hi ,
I would like to check if a column contains datetime values. (column may
contain any datetime format or just numbers or string). Request your help 




--
View this message in context: http://r.789695.n4.nabble.com/Checking-datetime-value-tp4679963.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Thu Nov  7 16:16:33 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 7 Nov 2013 10:16:33 -0500
Subject: [R] strange behaviour when subsetting a data.frame
In-Reply-To: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
References: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
Message-ID: <CAM_vjukP9v05z77x=-S0wYWD3cfw0iGp7tgMTj6pSR6kenbH6Q@mail.gmail.com>

R FAQ 7.31.

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

On Thu, Nov 7, 2013 at 8:36 AM, Eckst?dt, Elisabeth
<elisabeth.eckstaedt at tu-dresden.de> wrote:
> Hello everyone,
> I am experiencing a unfathomable benaviour of "subset" on a data.frame. This is a minimal reproducable example. The data.frame cosists only of one column, which contains 10 ascending values (from 0.1 to 1). Subsetting for 0.1 is working (gives me one row), subsetting for 0.3 gives me zero rows? Doing the same with values from 1 to 10 is working out well (as expected).
>
> Beimischung=seq(0.1,1,0.1)
> man2=data.frame(Beimischung)
> subset(man2, Beimischung==0.3)
> #---> gives 0 rows
> subset(man2, Beimischung==0.1)
> ---> gives one row (as expected)#
>
> #also not working:
>
> man2$Beimischung3=man2$Beimischung*10
> subset(man2, Beimischung3==3)
> --> gives 0 rows
>
> Does anybody have a clue for me?
> Thanks in advance
> Regards
> Elisabeth


From ripley at stats.ox.ac.uk  Thu Nov  7 16:41:00 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 07 Nov 2013 15:41:00 +0000
Subject: [R] reading in stata file with read.dta works in R x64 3.0.1
 and crashes R x64 3.0.2
In-Reply-To: <CAOwvMDwQopNCFM9Oh=xHM9Zx3L-CV9s_OhmUQPRMjYq1WjrzMQ@mail.gmail.com>
References: <CAOwvMDwQopNCFM9Oh=xHM9Zx3L-CV9s_OhmUQPRMjYq1WjrzMQ@mail.gmail.com>
Message-ID: <527BB48C.5070008@stats.ox.ac.uk>

See the posting guide: your version of 'foreign' is not current: 
http://cran.r-project.org/web/packages/foreign/index.html .

Please update your packages and try again.  (This looks very like a bug 
in recently contributed code that has already been fixed.)

On 07/11/2013 13:40, Anthony Damico wrote:
> this file
>
>
> http://www.electionstudies.org/studypages/data/anes_mergedfile_1992to1997/anes_mergedfile_1992to1997_dta.zip
>
> can be downloaded after free registration on this page
>
>      http://electionstudies.org/studypages/download/registration_form.php
>
>
> imports properly in windows R x64 3.0.1 but causes R x64 3.0.2 to crash
>
>
> the crash occurs at the line
>
> rval <- .External(do_readStata, file)
>
>
> at the bottom of this e-mail, i have included code that will reproduce the
> problem exactly in 3.0.2 but not 3.0.1
>
>
> and if i don't load the memisc and Hmisc packages, i get an error instead
> of a crash..
>
>
>> x <- read.dta( fp , convert.factors = FALSE )
> Error in read.dta(fp, convert.factors = FALSE) :
>    Value of SET_STRING_ELT() must be a 'CHARSXP' not a 'NULL'
>
>
> ..but if i load both (as shown in the script below), R just dies.
>
>
> =================
>
>
> sessionInfo for 3.0.1 (the version that works)
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] grid      splines   stats     graphics  grDevices utils     datasets
> methods   base
>
> other attached packages:
> [1] memisc_0.96-6   MASS_7.3-26     lattice_0.20-15 Hmisc_3.12-2
> Formula_1.1-1   survival_2.37-4 httr_0.2        stringr_0.6.2
> foreign_0.8-53
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.4 digest_0.6.3   RCurl_1.95-4.1 rpart_4.1-1
> tools_3.0.1
>
>
> =================
>
> sessionInfo in 3.0.2 right before the crash --
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] grid      splines   stats     graphics  grDevices utils     datasets
> [8] methods   base
>
> other attached packages:
> [1] memisc_0.96-6   MASS_7.3-29     lattice_0.20-23 Hmisc_3.12-2
> [5] Formula_1.1-1   survival_2.37-4 httr_0.2        stringr_0.6.2
> [9] foreign_0.8-55
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.4 digest_0.6.3   RCurl_1.95-4.1 rpart_4.1-3
> tools_3.0.2
>
>
>
>
> =================
>
>
> # code that works in 3.0.1 and crashes in 3.0.2 --
>
>
> setwd( "C:/my directory/anes")
> your.username <- "email at address.com"
> your.password <- "your.password"
>
>
>
>
> require(foreign)     # load foreign package (converts data files into R)
> require(stringr)    # load stringr package (manipulates character strings
> easily)
> require(httr)        # load httr package (downloads files from the web,
> with SSL and cookies)
> require(Hmisc)         # load Hmisc package (loads spss.get function)
> require(memisc)        # load memisc package (loads spss portable table
> import functions)
>
> # construct a list containing the pre-specified login information
> values <-
>      list(
>          "email" = your.username ,
>          "pass" = your.password
>      )
>
> # contact the anes website to log in
> POST( "http://www.electionstudies.org/studypages/download/login-process.php"
> , body = values )
>
> # download the `all_datasets` page to figure out what needs to be downloaded
> z <- GET( "
> http://www.electionstudies.org/studypages/download/datacenter_all_datasets.php"
> )
>
> # create a temporary file and a temporary directory
> tf <- tempfile() ; td <- tempdir()
>
> # download the damn file
> z <- GET( "
> http://www.electionstudies.org/studypages/data/anes_mergedfile_1992to1997/anes_mergedfile_1992to1997_dta.zip"
> )
>
> # save the result to a temporary file on the local disk
> writeBin( z$content , tf )
>
> # unzip that temporary file to an equally-temporary directory
> z <- unzip( tf , exdir = td )
>
> # find which one it is from among everything zipped up together..
> fp <- z[ grep( 'dta' , z ) ]
>
> # ..import that puppy
> x <- read.dta( fp , convert.factors = FALSE )
> # crash.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ajdamico at gmail.com  Thu Nov  7 16:59:38 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 7 Nov 2013 10:59:38 -0500
Subject: [R] reading in stata file with read.dta works in R x64 3.0.1
 and crashes R x64 3.0.2
In-Reply-To: <527BB48C.5070008@stats.ox.ac.uk>
References: <CAOwvMDwQopNCFM9Oh=xHM9Zx3L-CV9s_OhmUQPRMjYq1WjrzMQ@mail.gmail.com>
	<527BB48C.5070008@stats.ox.ac.uk>
Message-ID: <CAOwvMDwDwgRr0U=fjU641d2E1=qz_9L056EzgE4B7HuOUVCHig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/695fb016/attachment.pl>

From ken.knoblauch at inserm.fr  Thu Nov  7 17:04:28 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Thu, 7 Nov 2013 16:04:28 +0000
Subject: [R] Adding the complementary log-link to binomial() and
	make.link()
References: <527B9080.9070906@tuwien.ac.at>
Message-ID: <loom.20131107T170117-942@post.gmane.org>

Roland Deutsch <roland.deutsch <at> tuwien.ac.at> writes:
> in my research I frequently work with binomial 
response models, which 
> are of course part of the generalized linear 
models. While I do use 
> common link functions such as the logit, probit 
and cloglog, I often 
> have the need of invoking the lesser-known 
Complementary Log link 
> (Walter W. Piegorsch, 1992, "Complementary Log 
Regression for 
> Generalized Linear Models ", The American 
Statistician , Vol. 46, No. 2, 
> pp. 94-99 ) which is based on the exponential 
distribution.
> 
> Before the release of R 3.0, I simply could 
do so by adding the 
> following lines to the long switch command 
in make.link(...):
> 
> clog = {
>          linkfun <- function(mu) qexp(mu)
>          linkinv <- function(eta) pmax(.Machine$double.eps,pexp(eta))
>          mu.eta <- function(eta) pmax(dexp(eta), .Machine$double.eps)
>          valideta <- function(eta) all(eta > 0)
>      },
> 
> and then add "clog" to the okLinks vector in 
binomial(). However, I 

I wouldn't mess with make.link.  Why don't you just
define your own custom link, for example following the
example under help(family)?  This is what I did in
the psyphy package and I just checked and
they all still work under the current version of R.

> Thanks a lot,
> Roland Deutsch

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From j.a.balbuena at uv.es  Thu Nov  7 17:31:47 2013
From: j.a.balbuena at uv.es (Juan Antonio Balbuena)
Date: Thu, 07 Nov 2013 17:31:47 +0100
Subject: [R] Same code - error in one PC but not in other
Message-ID: <527BC073.2080406@uv.es>


   Hello
   I am running exactly the same code on two different computers. In PC1 of the
   the code is working fine, whereas in PC2 I get this error
   Error in HP.LUT[, 1] : incorrect number of dimensions
   HP.LUT is an object within a function computed as HP.LUT <- which(HP ==1,
   arr.in=TRUE), where HP is a binary matrix.
   HP.LUT is not returned for further use. I have made sure that no object with
   the name HP.LUT is present in either PC1 and 2, and I have used both RStudio
   and R 3.01.
   So I am puzzled and wonder what the reason for this might be.
   Any hint will be much appreciated.
   Thank you very much for your attention
   Juan A. Balbuena

   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary Biology
   University of
   Valencia
   [1]http://www.uv.es/~balbuena
   P.O. Box 22085
   [2]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [3]http://cetus.uv.es/mullpardb/index.html
   e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following street address:
   C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/%7Ebalbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:j.a.balbuena at uv.es

From wdunlap at tibco.com  Thu Nov  7 17:33:22 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 Nov 2013 16:33:22 +0000
Subject: [R] all combinations with replacement not ordered
In-Reply-To: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>
References: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA13645@PA-MBX01.na.tibco.com>

Is this what you want?
   f <- function (x, m)  combn(x + m - 1, m) - seq_len(m) + 1

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Konstantin Tretiakov
> Sent: Thursday, November 07, 2013 5:38 AM
> To: r-help at r-project.org
> Subject: [R] all combinations with replacement not ordered
> 
> Hello!
> 
> I need to obtain all possible combinations with replacement when order is
> not important.
> E.g. I have a population x{1,2,3}.
> So I can get (choose(3+3-1,3)=) 10 combinations from this population with
> 'size=3'.
> How can I get a list of all that combinations?
> 
> I have tried 'expand.grid()' and managed to get only samples where order is
> important.
> 'combn()' gave me samples without replacement.
> 
> Best regards,
> Konstantin Tretyakov.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Thu Nov  7 17:52:00 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 7 Nov 2013 16:52:00 +0000
Subject: [R] strange behaviour when subsetting a data.frame
In-Reply-To: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
References: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6866443ED7A@DC1VEX10MB001.air.org>

Yes, but notice that

man2[3,] == .3
[1] FALSE

This is because of issues of machine precision when dealing with floating points, not a problem in R.  Comparisons for nearly equivalent numbers are done using all.equal() as shown below.

> all.equal(man2[3,], .3)
[1] TRUE




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Eckst?dt, Elisabeth
Sent: Thursday, November 07, 2013 8:37 AM
To: r-help at R-project.org
Subject: [R] strange behaviour when subsetting a data.frame

Hello everyone,
I am experiencing a unfathomable benaviour of "subset" on a data.frame. This is a minimal reproducable example. The data.frame cosists only of one column, which contains 10 ascending values (from 0.1 to 1). Subsetting for 0.1 is working (gives me one row), subsetting for 0.3 gives me zero rows? Doing the same with values from 1 to 10 is working out well (as expected). 

Beimischung=seq(0.1,1,0.1)
man2=data.frame(Beimischung)
subset(man2, Beimischung==0.3)
#---> gives 0 rows
subset(man2, Beimischung==0.1)
---> gives one row (as expected)#

#also not working:

man2$Beimischung3=man2$Beimischung*10
subset(man2, Beimischung3==3)
--> gives 0 rows

Does anybody have a clue for me?
Thanks in advance
Regards
Elisabeth
_______________
Dipl.-Ing. Elisabeth Eckst?dt
Member of Academic Staff & PhD Student
Technische Universit?t Dresden
Faculty of Mechanical Engineering
Institue of Power Engineering
Chair of Building Energy Systems and Heat Supply

Phone +49 351 463 34709
Fax +49 351 463 37076
Web http://tu-dresden.de/mw/iet/ew

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Thu Nov  7 18:00:53 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 7 Nov 2013 17:00:53 +0000
Subject: [R] strange behaviour when subsetting a data.frame
In-Reply-To: <3eddfb7ab4114c0cb7becdf677ee656f@AMXPR07MB071.eurprd07.prod.outlook.com>
References: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
	<B08B6AF0CF8CA44F81B9983EEBDCD6866443ED7A@DC1VEX10MB001.air.org>
	<3eddfb7ab4114c0cb7becdf677ee656f@AMXPR07MB071.eurprd07.prod.outlook.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6866443EDAE@DC1VEX10MB001.air.org>

Yes, what I would do is write a function around the all.equal() comparisons on the data to see which values are "nearly" identical to the ones desired I the subset. If TRUE, I would retain those values and discard the others.


-----Original Message-----
From: Simon Hayward [mailto:simon.hayward at infinitycloud.com] 
Sent: Thursday, November 07, 2013 11:59 AM
To: Doran, Harold; 'Eckst?dt, Elisabeth'; r-help at R-project.org
Subject: RE: strange behaviour when subsetting a data.frame

So is there a way to make the subsetting behave as expected?



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: 07 November 2013 16:52
To: 'Eckst?dt, Elisabeth'; r-help at R-project.org
Subject: Re: [R] strange behaviour when subsetting a data.frame

Yes, but notice that

man2[3,] == .3
[1] FALSE

This is because of issues of machine precision when dealing with floating points, not a problem in R.  Comparisons for nearly equivalent numbers are done using all.equal() as shown below.

> all.equal(man2[3,], .3)
[1] TRUE




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Eckst?dt, Elisabeth
Sent: Thursday, November 07, 2013 8:37 AM
To: r-help at R-project.org
Subject: [R] strange behaviour when subsetting a data.frame

Hello everyone,
I am experiencing a unfathomable benaviour of "subset" on a data.frame. This is a minimal reproducable example. The data.frame cosists only of one column, which contains 10 ascending values (from 0.1 to 1). Subsetting for 0.1 is working (gives me one row), subsetting for 0.3 gives me zero rows? Doing the same with values from 1 to 10 is working out well (as expected). 

Beimischung=seq(0.1,1,0.1)
man2=data.frame(Beimischung)
subset(man2, Beimischung==0.3)
#---> gives 0 rows
subset(man2, Beimischung==0.1)
---> gives one row (as expected)#

#also not working:

man2$Beimischung3=man2$Beimischung*10
subset(man2, Beimischung3==3)
--> gives 0 rows

Does anybody have a clue for me?
Thanks in advance
Regards
Elisabeth
_______________
Dipl.-Ing. Elisabeth Eckst?dt
Member of Academic Staff & PhD Student
Technische Universit?t Dresden
Faculty of Mechanical Engineering
Institue of Power Engineering
Chair of Building Energy Systems and Heat Supply

Phone +49 351 463 34709
Fax +49 351 463 37076
Web http://tu-dresden.de/mw/iet/ew

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Thu Nov  7 18:04:54 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 07 Nov 2013 17:04:54 -0000 (GMT)
Subject: [R] all combinations with replacement not ordered
In-Reply-To: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>
Message-ID: <XFMail.20131107170454.Ted.Harding@wlandres.net>

On 07-Nov-2013 13:38:29 Konstantin Tretiakov wrote:
> Hello!
> 
> I need to obtain all possible combinations with replacement when
> order is not important.
> E.g. I have a population x{1,2,3}.
> So I can get (choose(3+3-1,3)=) 10 combinations from this population
> with 'size=3'.
> How can I get a list of all that combinations?
> 
> I have tried 'expand.grid()' and managed to get only samples where
> order is important.
> 'combn()' gave me samples without replacement.
> 
> Best regards,
> Konstantin Tretyakov.

>From your description I infer that, from {1,2,3}, you want the result:

  1 1 1
  1 1 2
  1 1 3
  1 2 2
  1 2 3
  1 3 3
  2 2 2
  2 2 3
  2 3 3
  3 3 3

The following will do that:

u <- c(1,2,3)
unique(t(unique(apply(expand.grid(u,u,u),1,sort),margin=1)))

#      [,1] [,2] [,3]
# [1,]    1    1    1
# [2,]    1    1    2
# [3,]    1    1    3
# [4,]    1    2    2
# [5,]    1    2    3
# [6,]    1    3    3
# [7,]    2    2    2
# [9,]    2    3    3
#[10,]    3    3    3

There may be a simpler way!
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 07-Nov-2013  Time: 17:04:50
This message was sent by XFMail


From bbolker at gmail.com  Thu Nov  7 18:29:39 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 7 Nov 2013 17:29:39 +0000
Subject: [R]
	=?utf-8?q?Adding_the_complementary_log-link_to_binomial=28=29?=
	=?utf-8?q?_and=09make=2Elink=28=29?=
References: <527B9080.9070906@tuwien.ac.at>
	<loom.20131107T170117-942@post.gmane.org>
Message-ID: <loom.20131107T182231-412@post.gmane.org>

Ken Knoblauch <ken.knoblauch <at> inserm.fr> writes:

> 
> Roland Deutsch <roland.deutsch <at> tuwien.ac.at> writes:
> > in my research I frequently work with binomial 
> response models, which 
> > are of course part of the generalized linear 
> models. While I do use 
> > common link functions such as the logit, probit 
> and cloglog, I often 
> > have the need of invoking the lesser-known 
> Complementary Log link 
> > (Walter W. Piegorsch, 1992, "Complementary Log 
> Regression for 
> > Generalized Linear Models ", The American 
> Statistician , Vol. 46, No. 2, 
> > pp. 94-99 ) which is based on the exponential 
> distribution.
> > 
> > Before the release of R 3.0, I simply could 
> do so by adding the 
> > following lines to the long switch command 
> in make.link(...):
> > 
> > clog = {
> >          linkfun <- function(mu) qexp(mu)
> >          linkinv <- function(eta) pmax(.Machine$double.eps,pexp(eta))
> >          mu.eta <- function(eta) pmax(dexp(eta), .Machine$double.eps)
> >          valideta <- function(eta) all(eta > 0)
> >      },
> > 
> > and then add "clog" to the okLinks vector in 
> binomial(). However, I 
> 
> I wouldn't mess with make.link.  Why don't you just
> define your own custom link, for example following the
> example under help(family)?  This is what I did in
> the psyphy package and I just checked and
> they all still work under the current version of R.
> 
> > Thanks a lot,
> > Roland Deutsch
> 

This seems to work:

linkinfo <- list(link="clog",
                 linkfun=function(mu) qexp(mu),
                 linkinv=function(eta) pmax(.Machine$double.eps,pexp(eta)),
                 mu.eta=function(eta) pmax(dexp(eta), .Machine$double.eps),
                 valideta=function(eta) all(eta > 0))
binomClog <- binomial()
for (i in names(linkinfo))
    binomClog[[i]] <- linkinfo[[i]]

set.seed(101)
d <- data.frame(x=runif(1000))
d$y <- rbinom(1000,prob=binomClog$linkinv(1+2*d$x),size=1)
library(lattice)
xyplot(y~x,data=d,type=c("p","smooth"))
g1 <- glm(y~x,data=d,family=binomClog)
library(MASS)
confint(g1)


From sergio.fonda99 at gmail.com  Thu Nov  7 18:37:50 2013
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Thu, 7 Nov 2013 18:37:50 +0100
Subject: [R] variable standardization in manova() call
In-Reply-To: <527A47E7.7080606@yorku.ca>
References: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
	<527A47E7.7080606@yorku.ca>
Message-ID: <CAJRuHooiGo2fLiTPAOdDhjZuD-d5-SzXbm+qc2SXTw6RjunOSg@mail.gmail.com>

2013/11/6 Michael Friendly <friendly at yorku.ca>:
> On 11/4/2013 10:45 AM, Sergio Fonda wrote:
>>
>> Hi,
>> I'm not able to get information about the following question:
>>
>> is the variables standardization a default option in manova() (stats
>> package)?
>> Or if you want to compare variables with different units or scales and
>> rather different variances, you have to previously standardize the
>> variables ?
>>
>
> If you mean the response variables, manova() does not require equal
> variances and does not standardize.
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA

Hi Michael,
thank you for your reply. However, your remark was not so clear to me
so I attach a short script I tried to launch. The comparison between
results got from MANOVA() call with the non-standardized and
standardized version of the same data frame, convinced me that it is
not necessary to standardize data before calling MANOVA. The only
difference you get is in the residuals values, of course.
Could you kindly confirm my conclusion?

All the best,
Sergio Fonda
______________________
set.seed(1234)
# non- standardized series
x1 =  rnorm(n=10, mean=50, sd=11)
x2 =  rnorm(n=10, mean=93, sd=23)
x1 =  rnorm(n=10, mean=217, sd=52)
fact= rep(1:2,20)
glob1=data.frame(cbind(x1,x2,x3,fact))
fitta1=manova(cbind(x1,x2,x3)~fact, data=glob1)
fitta1.wilks=summary(fitta1, test="Wilks")
summary.aov(fitta1)

#after standardization
x.stand=scale(glob1[,-4])
glob2=data.frame(x.stand,fact)
fitta2=manova(cbind(x1,x2,x3)~fact, data=glob2)
fitta2.wilks=summary(fitta2, test="Wilks")
summary.aov(fitta2)

-- 
Sergio Fonda
Associate Professor of Bioengineering
Department of Life Sciences
University of Modena and Reggio Emilia
Modena, Italy


From gunter.berton at gene.com  Thu Nov  7 19:06:01 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 7 Nov 2013 10:06:01 -0800
Subject: [R] all combinations with replacement not ordered
In-Reply-To: <XFMail.20131107170454.Ted.Harding@wlandres.net>
References: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>
	<XFMail.20131107170454.Ted.Harding@wlandres.net>
Message-ID: <CACk-te36RZ0iUtjftb+XaP7U3z2YbwfdWXF9PjYdi-TCxH=SPw@mail.gmail.com>

Well, you can create the expand.grid data frame programmatically via:

u <- 1:3
len <- length(u)
v <-do.call(expand.grid, split(rep(u,len),rep(seq_len(len),e=len)))

And then you can use unique.array to get the unique rows after the sort:

unique(t(apply(v,1,sort)))

However, I agree with your sentiments. Not only does this seem
inelegant, but it will not scale well.

I would imagine a recursive approach would be more efficient -- as
then only the sets you need would be produced and there'd be no
sorting, etc. -- but I have neither the time nor interest to work it
out.

... and I bet someone already has done this in some R package anyway.

Cheers,
Bert

On Thu, Nov 7, 2013 at 9:04 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
> On 07-Nov-2013 13:38:29 Konstantin Tretiakov wrote:
>> Hello!
>>
>> I need to obtain all possible combinations with replacement when
>> order is not important.
>> E.g. I have a population x{1,2,3}.
>> So I can get (choose(3+3-1,3)=) 10 combinations from this population
>> with 'size=3'.
>> How can I get a list of all that combinations?
>>
>> I have tried 'expand.grid()' and managed to get only samples where
>> order is important.
>> 'combn()' gave me samples without replacement.
>>
>> Best regards,
>> Konstantin Tretyakov.
>
> >From your description I infer that, from {1,2,3}, you want the result:
>
>   1 1 1
>   1 1 2
>   1 1 3
>   1 2 2
>   1 2 3
>   1 3 3
>   2 2 2
>   2 2 3
>   2 3 3
>   3 3 3
>
> The following will do that:
>
> u <- c(1,2,3)
> unique(t(unique(apply(expand.grid(u,u,u),1,sort),margin=1)))
>
> #      [,1] [,2] [,3]
> # [1,]    1    1    1
> # [2,]    1    1    2
> # [3,]    1    1    3
> # [4,]    1    2    2
> # [5,]    1    2    3
> # [6,]    1    3    3
> # [7,]    2    2    2
> # [9,]    2    3    3
> #[10,]    3    3    3
>
> There may be a simpler way!
> Ted.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 07-Nov-2013  Time: 17:04:50
> This message was sent by XFMail
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From Achim.Zeileis at uibk.ac.at  Thu Nov  7 19:07:21 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 7 Nov 2013 19:07:21 +0100 (CET)
Subject: [R] AER ivreg diagnostics: question on DF of Sargan test
In-Reply-To: <CAA40SnePyJMH7PmCnGL97E-hYiqjuo5W95BD7vcwrKKrt-YS7Q@mail.gmail.com>
References: <CAA40SnePyJMH7PmCnGL97E-hYiqjuo5W95BD7vcwrKKrt-YS7Q@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1311071903330.13854@paninaro.uibk.ac.at>

H?l?ne,

thanks for spotting this! This is a bug in "AER". I had just tested the 
new diagnostics for regressions with 1 endogenous variable and hence 
never noticed the problem. But if there are > 1 endogenous variables, the 
df used in ivreg() (and hence the associated p-values) are too large.

I've fixed the problem in AER's devel-version and will release it on CRAN 
in the next days.

Thanks & best regards,
Z

On Thu, 7 Nov 2013, H?l?ne Huber-Yahi wrote:

> Hello,
> I'm new to R and I'm currently learning to use package AER, which is
> extremely comprehensive and useful. I have one question related to the
> diagnostics after ivreg: if I understood well, the Sargan test provided
> states that the statistic should follow a Chi squared of degrees of freedom
> equal to the number of excluded instruments minus one. But I read many
> times that the degrees of freedom of this statistic is supposed to equal
> the number of overidentifying restrictions, i.e. the number of excluded
> instruments minus the number of endogenous variables tested. When comparing
> with Stata results (estat overid after ivreg, same with ivreg2 output), the
> statistic is the same as the one provided by R, only the p-value changes
> because the distribution chosen is different. Is this command using a
> different flavor of the Sargan test ? I did not find the details in the AER
> pdf.
> I'm using Rstudio with R 3.0.2 (Windows 7) and AER is up to date. The
> output I get from R is the following, where the Sargan DF is equal to 5,
> while I thought it would be equal to 6-3=3. The data comes from Verbeek's
> econometrics textbook and the example replicates the one in the book.
> Dependent variable is log of wage, endogenous variables are education,
> experience and its square (3 of them), excluded instruments are parents'
> education etc (6 of them).
>
>> ivmodel <- ivreg(lwage76 ~ ed76 + exp76 + exp762 + black + smsa76 + south76 | daded + momed + libcrd14 + age76 + age762 + nearc4 + black + smsa76 + south76,+             data = school)> > summary(ivmodel,diagnostics=TRUE)
> Call:
> ivreg(formula = lwage76 ~ ed76 + exp76 + exp762 + black + smsa76 +
>    south76 | daded + momed + libcrd14 + age76 + age762 + nearc4 +
>    black + smsa76 + south76, data = school)
>
> Residuals:
>     Min       1Q   Median       3Q      Max
> -1.63375 -0.22253  0.02403  0.24350  1.32911
>
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  4.6064811  0.1126195  40.903  < 2e-16 ***
> ed76         0.0848507  0.0066061  12.844  < 2e-16 ***
> exp76        0.0796432  0.0164406   4.844 1.34e-06 ***
> exp762      -0.0020376  0.0008257  -2.468   0.0136 *
> black       -0.1726723  0.0195231  -8.845  < 2e-16 ***
> smsa76       0.1521693  0.0165207   9.211  < 2e-16 ***
> south76     -0.1204765  0.0154904  -7.778 1.01e-14 ***
>
> Diagnostic tests:
>                  df1  df2 statistic p-value
> Weak instruments    6 2987   965.450  <2e-16 ***
> Wu-Hausman          2 2988     1.949   0.143
> Sargan              5   NA     3.868   0.569
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.3753 on 2990 degrees of freedom
> Multiple R-Squared: 0.2868,	Adjusted R-squared: 0.2854
> Wald test: 178.6 on 6 and 2990 DF,  p-value: < 2.2e-16
>
>
> Would this be caused by the fact that I'm using 2SLS and not GMM (at least
> I suppose) to estimate the IV model ? I apologize if this comes from a
> misunderstanding from my part, and I thank you in advance for your help.
>
> Best,
>
> H. Huber
>
> 	[[alternative HTML version deleted]]
>
>

From mart.turcotte at gmail.com  Thu Nov  7 17:55:50 2013
From: mart.turcotte at gmail.com (Martin Turcotte)
Date: Thu, 7 Nov 2013 11:55:50 -0500
Subject: [R] Error running MuMIn dredge function using glmer models
Message-ID: <1E4F5497-CCB4-4E8B-A23A-8AA5E1136DAE@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/5a5c33ac/attachment.pl>

From gunter.berton at gene.com  Thu Nov  7 19:09:35 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 7 Nov 2013 10:09:35 -0800
Subject: [R] all combinations with replacement not ordered
In-Reply-To: <CACk-te36RZ0iUtjftb+XaP7U3z2YbwfdWXF9PjYdi-TCxH=SPw@mail.gmail.com>
References: <CAOWRPpHzev+FYY9uhsqQNCxT-kPmkcNbJ+Apaq8Yqms2j5LPeQ@mail.gmail.com>
	<XFMail.20131107170454.Ted.Harding@wlandres.net>
	<CACk-te36RZ0iUtjftb+XaP7U3z2YbwfdWXF9PjYdi-TCxH=SPw@mail.gmail.com>
Message-ID: <CACk-te1zazVqgOUaiZRoJcWdcOnk1r1cHGpvAp_S2fgE6Ro7gA@mail.gmail.com>

... and actually, since u can be assumed to be of the form shown,

v <-do.call(expand.grid, split(rep(u,len),rep(u,e=len)))


should do.

-- Bert

On Thu, Nov 7, 2013 at 10:06 AM, Bert Gunter <bgunter at gene.com> wrote:
> Well, you can create the expand.grid data frame programmatically via:
>
> u <- 1:3
> len <- length(u)
> v <-do.call(expand.grid, split(rep(u,len),rep(seq_len(len),e=len)))
>
> And then you can use unique.array to get the unique rows after the sort:
>
> unique(t(apply(v,1,sort)))
>
> However, I agree with your sentiments. Not only does this seem
> inelegant, but it will not scale well.
>
> I would imagine a recursive approach would be more efficient -- as
> then only the sets you need would be produced and there'd be no
> sorting, etc. -- but I have neither the time nor interest to work it
> out.
>
> ... and I bet someone already has done this in some R package anyway.
>
> Cheers,
> Bert
>
> On Thu, Nov 7, 2013 at 9:04 AM, Ted Harding <Ted.Harding at wlandres.net> wrote:
>> On 07-Nov-2013 13:38:29 Konstantin Tretiakov wrote:
>>> Hello!
>>>
>>> I need to obtain all possible combinations with replacement when
>>> order is not important.
>>> E.g. I have a population x{1,2,3}.
>>> So I can get (choose(3+3-1,3)=) 10 combinations from this population
>>> with 'size=3'.
>>> How can I get a list of all that combinations?
>>>
>>> I have tried 'expand.grid()' and managed to get only samples where
>>> order is important.
>>> 'combn()' gave me samples without replacement.
>>>
>>> Best regards,
>>> Konstantin Tretyakov.
>>
>> >From your description I infer that, from {1,2,3}, you want the result:
>>
>>   1 1 1
>>   1 1 2
>>   1 1 3
>>   1 2 2
>>   1 2 3
>>   1 3 3
>>   2 2 2
>>   2 2 3
>>   2 3 3
>>   3 3 3
>>
>> The following will do that:
>>
>> u <- c(1,2,3)
>> unique(t(unique(apply(expand.grid(u,u,u),1,sort),margin=1)))
>>
>> #      [,1] [,2] [,3]
>> # [1,]    1    1    1
>> # [2,]    1    1    2
>> # [3,]    1    1    3
>> # [4,]    1    2    2
>> # [5,]    1    2    3
>> # [6,]    1    3    3
>> # [7,]    2    2    2
>> # [9,]    2    3    3
>> #[10,]    3    3    3
>>
>> There may be a simpler way!
>> Ted.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 07-Nov-2013  Time: 17:04:50
>> This message was sent by XFMail
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From simon.hayward at infinitycloud.com  Thu Nov  7 17:59:13 2013
From: simon.hayward at infinitycloud.com (Simon Hayward)
Date: Thu, 7 Nov 2013 16:59:13 +0000
Subject: [R] strange behaviour when subsetting a data.frame
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6866443ED7A@DC1VEX10MB001.air.org>
References: <8143A255DE0826499FB1C7CD935FF6930616B9E4@msxmb01.msx.tu-dresden.de>
	<B08B6AF0CF8CA44F81B9983EEBDCD6866443ED7A@DC1VEX10MB001.air.org>
Message-ID: <3eddfb7ab4114c0cb7becdf677ee656f@AMXPR07MB071.eurprd07.prod.outlook.com>

So is there a way to make the subsetting behave as expected?



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: 07 November 2013 16:52
To: 'Eckst?dt, Elisabeth'; r-help at R-project.org
Subject: Re: [R] strange behaviour when subsetting a data.frame

Yes, but notice that

man2[3,] == .3
[1] FALSE

This is because of issues of machine precision when dealing with floating points, not a problem in R.  Comparisons for nearly equivalent numbers are done using all.equal() as shown below.

> all.equal(man2[3,], .3)
[1] TRUE




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Eckst?dt, Elisabeth
Sent: Thursday, November 07, 2013 8:37 AM
To: r-help at R-project.org
Subject: [R] strange behaviour when subsetting a data.frame

Hello everyone,
I am experiencing a unfathomable benaviour of "subset" on a data.frame. This is a minimal reproducable example. The data.frame cosists only of one column, which contains 10 ascending values (from 0.1 to 1). Subsetting for 0.1 is working (gives me one row), subsetting for 0.3 gives me zero rows? Doing the same with values from 1 to 10 is working out well (as expected). 

Beimischung=seq(0.1,1,0.1)
man2=data.frame(Beimischung)
subset(man2, Beimischung==0.3)
#---> gives 0 rows
subset(man2, Beimischung==0.1)
---> gives one row (as expected)#

#also not working:

man2$Beimischung3=man2$Beimischung*10
subset(man2, Beimischung3==3)
--> gives 0 rows

Does anybody have a clue for me?
Thanks in advance
Regards
Elisabeth
_______________
Dipl.-Ing. Elisabeth Eckst?dt
Member of Academic Staff & PhD Student
Technische Universit?t Dresden
Faculty of Mechanical Engineering
Institue of Power Engineering
Chair of Building Energy Systems and Heat Supply

Phone +49 351 463 34709
Fax +49 351 463 37076
Web http://tu-dresden.de/mw/iet/ew

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Thu Nov  7 20:01:13 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 7 Nov 2013 11:01:13 -0800 (PST)
Subject: [R] Same code - error in one PC but not in other
In-Reply-To: <527BC073.2080406@uv.es>
References: <527BC073.2080406@uv.es>
Message-ID: <1383850873463-4679992.post@n4.nabble.com>

In the absence of any description of the computers themselves, it's hard to
say,  but there's a good chance that there is some object in your working
environment that's being accessed by your function -- and that object exists
on only one of the machines.

I would suggest you use debug() or browser()  to see what the value of HP
and HP.LUT are in each case.


Tursiops wrote
> Hello
>    I am running exactly the same code on two different computers. In PC1
> of the
>    the code is working fine, whereas in PC2 I get this error
>    Error in HP.LUT[, 1] : incorrect number of dimensions
>    HP.LUT is an object within a function computed as HP.LUT <- which(HP
> ==1,
>    arr.in=TRUE), where HP is a binary matrix.
>    HP.LUT is not returned for further use. I have made sure that no object
> with
>    the name HP.LUT is present in either PC1 and 2, and I have used both
> RStudio
>    and R 3.01.
>    So I am puzzled and wonder what the reason for this might be.
>    Any hint will be much appreciated.
>    Thank you very much for your attention
>    Juan A. Balbuena
> 
>    --
> 
>    Dr. Juan A. Balbuena
>    Marine Zoology Unit
>    Cavanilles Institute of Biodiversity and Evolutionary Biology
>    University of
>    Valencia
>    [1]http://www.uv.es/~balbuena
>    P.O. Box 22085
>    [2]http://www.uv.es/cavanilles/zoomarin/index.htm
>    46071 Valencia, Spain
>    [3]http://cetus.uv.es/mullpardb/index.html
>    e-mail: [4]

> j.a.balbuena@

>     tel. +34 963 543 658    fax +34 963 543 733
>    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>    NOTE! For shipments by EXPRESS COURIER use the following street
> address:
>    C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
>    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> 
> References
> 
>    1. http://www.uv.es/%7Ebalbuena
>    2. http://www.uv.es/cavanilles/zoomarin/index.htm
>    3. http://cetus.uv.es/mullpardb/index.html
>    4. mailto:

> j.a.balbuena@

> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Same-code-error-in-one-PC-but-not-in-other-tp4679980p4679992.html
Sent from the R help mailing list archive at Nabble.com.


From s.wood at bath.ac.uk  Thu Nov  7 20:06:12 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Thu, 07 Nov 2013 20:06:12 +0100
Subject: [R] Nonnormal Residuals and GAMs
In-Reply-To: <527B4770.4060100@bath.ac.uk>
References: <527B4770.4060100@bath.ac.uk>
Message-ID: <527BE4A4.5020508@bath.ac.uk>

If you use GCV smoothness selection then, in the Gaussian case, the key
assumptions are constant variance and independence. As with linear
modelling, the normality assumption only comes in when you want to find
confidence intervals or p-values. (The GM Thm does not require normality 
btw. but I don't know if it has a penalized analogue).

With REML smoothness selection it's less clear (at least to me).

Beyond Gaussian the situation is much as it is with GLMs. The key
assumptions are independence and that the mean variance relationship is
correct. The theory of quasi-likelihood tells you that you can make
valid inference based only on specifying the mean-variance relationship
for the response, rather than the whole distribution, with the price
being a small loss of efficiency. It follows that getting the
distribution exactly right is of secondary importance.

It's also quite easy to be misled by normal qq plots of the deviance
residuals when you have low count data. For example, section 4 of
   http://opus.bath.ac.uk/27091/1/qq_gam_resub.pdf
shows a real example where the usual qq plots look awful, suggesting
massive zero inflation, but if you compute the correct reference
quantiles for the qq plot you find that there is nothing wrong and no
evidence of zero inflation.

best,
Simon

ps. in response to the follow up discussion: The default link depends on 
the family, rather than being a  gam (or glm) default. Eg the default is 
log for the Poisson, but identity for the Gaussian.


On 06/11/13 21:46, Collin Lynch wrote:
> Greetings, My question is more algorithmic than prectical.  What I am
> trying to determine is, are the GAM algorithms used in the mgcv package
> affected by nonnormally-distributed residuals?
>
> As I understand the theory of linear models the Gauss-Markov theorem
> guarantees that least-squares regression is optimal over all unbiased
> estimators iff the data meet the conditions linearity, homoscedasticity,
> independence, and normally-distributed residuals.  Absent the last
> requirement it is optimal but only over unbiased linear estimators.
>
> What I am trying to determine is whether or not it is necessary to check
> for normally-distributed errors in a GAM from mgcv.  I know that the
> unsmoothed terms, if any, will be fitted by ordinary least-squares but I
> am unsure whether the default Penalized Iteratively Reweighted Least
> Squares method used in the package is also based upon this assumption or
> falls under any analogue to the Gauss-Markov Theorem.
>
> Thank you in advance for any help.
>
> 	Sincrely,
> 	Collin Lynch.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From smartpink111 at yahoo.com  Thu Nov  7 20:10:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 7 Nov 2013 11:10:32 -0800 (PST)
Subject: [R] Checking datetime value
In-Reply-To: <1383834454305-4679963.post@n4.nabble.com>
References: <1383834454305-4679963.post@n4.nabble.com>
Message-ID: <1383851432.82953.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
You can check the dataset for any patterns that are unique for the datetime values. 
For example:
vec1 <-? c(as.character(Sys.time()), format(Sys.time(), "%a %b %d %X %Y %Z"),4324343,format(Sys.time(),"%m-%d-%Y %H:%M:%S"),"aZZCRDDS")
?vec1[grepl(":",vec1)]
#[1] "2013-11-07 15:04:27"???????????? "Thu Nov 07 03:04:27 PM 2013 EST"
#[3] "11-07-2013 15:04:27"??? 

A.K.


On Thursday, November 7, 2013 10:12 AM, vikrant <vikrant.shimpi at tcs.com> wrote:
Hi ,
I would like to check if a column contains datetime values. (column may
contain any datetime format or just numbers or string). Request your help 




--
View this message in context: http://r.789695.n4.nabble.com/Checking-datetime-value-tp4679963.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From karl.schelhammer at gmail.com  Thu Nov  7 20:20:21 2013
From: karl.schelhammer at gmail.com (Karl Schelhammer)
Date: Thu, 7 Nov 2013 11:20:21 -0800
Subject: [R] R newbie - loop questions
In-Reply-To: <1383847293.9702.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <29748344.137627.1383842516427.JavaMail.nabble@joe.nabble.com>
	<314D7575-A64B-4227-96A6-7C383C41A9BD@gmail.com>
	<1383847293.9702.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <719B13A0-BD02-4D35-B9D8-95BBA3EF23FD@gmail.com>

Yep, that solves the problem and is much cleaner than what I was trying to do.

KWS

On Nov 7, 2013, at 10:01 AM, arun <smartpink111 at yahoo.com> wrote:

> Hi,
> 
> May be this is what you wanted:
> mat1 <- matrix(1:4,2,2)
> results.norm <- mat1/rowSums(mat1)
> 
> A.K.
> 
> 
> 
> 
> On Thursday, November 7, 2013 12:27 PM, Karl Schelhammer <karl.schelhammer at gmail.com> wrote:
> Sorry for the confusion.  results is a 2 x 2 matrix containing real positive values.  The goal is to divide each element of the matrix by the sum of the elements in a row and store the result in results.norm.  However, the loop returns an error that I don't understand.  Any thoughts?
> 
> KWS
> 
> On Nov 7, 2013, at 8:42 AM, smartpink111 at yahoo.com wrote:
> 
>> 
>> This is not clear.
>> For example, 
>> v1 <- 24 #value
>> r1 <- c(2,3) # vector with 2 elements
>> my.function(v1,r1)
>> #[1] 4.8
>> 
>> There is no reference to "results".  If it is the output of my.function(), then there is only one element.  Anyway, please show a reproducible example.
>> 
>> 
>> 
>> <quote author='Sledge'>
>> Greetings all, I am attempting to run the following code:
>> 
>> 
>> I recieve the following error:
>> 
>> The function runs fine when I explicitly enter the subscripts in results and
>> pass to my.function.  Can someone else see what is wrong with this approach?
>> </quote>
>> Quoted from: 
>> http://r.789695.n4.nabble.com/R-newbie-loop-questions-tp4679975.html
>> 
>> 
>> _____________________________________
>> Sent from http://r.789695.n4.nabble.com
>> 


From drgady at outlook.com  Thu Nov  7 21:55:47 2013
From: drgady at outlook.com (Barrett Gady)
Date: Thu, 7 Nov 2013 20:55:47 +0000
Subject: [R] =?utf-8?q?_Problems_loading_xlsx?=
Message-ID: <BAY404-EAS10884859BD70EE36AC864ADD1F30@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/61076e6e/attachment.pl>

From bbolker at gmail.com  Fri Nov  8 00:10:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 7 Nov 2013 23:10:20 +0000
Subject: [R] Error running MuMIn dredge function using glmer models
References: <1E4F5497-CCB4-4E8B-A23A-8AA5E1136DAE@gmail.com>
Message-ID: <loom.20131108T000358-446@post.gmane.org>

Martin Turcotte <mart.turcotte <at> gmail.com> writes:

> Dear list, 
> I am trying to use MuMIn to compare all possible mixed models 
> using the dredge function on binomial data but I
> am getting an error message that I cannot decode. This error 
> only occurs when I use glmer. When I use an lmer
> analysis on a different response variable every works great. 
> 
> Example using a simplified glmer model
> global model: 
> mod<- glmer(cbind(st$X2.REP.LIVE, st$X2.REP.DEAD) ~ 
> DOMESTICATION*GLUC + (1|PAIR), data=st,
> na.action=na.omit , family=binomial) 
> 
> The response variables are the number of survival and dead insects
> (successes and failures)
> DOMESTICATION is a 2 level factor.
> GLUC is a continuous variable.
> PAIR is coded as a factor or character (both ways fail).
> 
> This model functions correctly but when I try it with dredge()
> I get an error. 
> 
> g<- dredge(mod, beta=F, evaluate=F, rank='AIC')
> Error in sprintf(gettext(fmt, domain = domain), ...) : 
>   invalid type of argument[1]: 'symbol'
> 
> When I try with another rank the same thing happens:
> chat<- deviance(mod)/58
> g<- dredge(mod, beta=F, evaluate=F, rank='QAIC', chat=chat)
> Error in sprintf(gettext(fmt, domain = domain), ...) : 
>   invalid type of argument[1]: 'symbol'
> 
> Any suggestions would be greatly appreciated
> 
> thanks
> 
> Martin Turcotte, Ph. D.
> mart.turcotte <at> gmail.com

* Please send follow-ups to r-sig-mixed-models at r-project.org
* I think we need a reproducible example: it works OK for the
first two binomial GLMMs I tried:

library(lme4)
library(MuMIn)
gm1 <- glmer(cbind(incidence, size - incidence) ~ period + (1 | herd),
                   data = cbpp, family = binomial)
dredge(gm1)
dredge(gm1,beta=FALSE,evaluate=FALSE)

library(mlmRev)
gm2 <- glmer(use ~ urban+age+livch+(1|district), Contraception, binomial)
dredge(gm2)
dredge(gm2,beta=FALSE,evaluate=FALSE)

* It might be worth removing the 'st$' from  your response variable,
e.g.

mod<- glmer(cbind(X2.REP.LIVE, X2.REP.DEAD) ~  DOMESTICATION*GLUC + (1|PAIR),
            data=st,family=binomial) 

* What are the results of traceback()?  sessionInfo() ?


From ingfimo at gmail.com  Fri Nov  8 00:39:54 2013
From: ingfimo at gmail.com (Filippo)
Date: Thu, 07 Nov 2013 23:39:54 +0000
Subject: [R] prod and F90 product
Message-ID: <527C24CA.5060101@gmail.com>

Hi,
I'm having strange differences between the R function prod ad the F90 
function product.
Processing the same vector C (see attachment). I get 2 different results:
prod(C) = 1.069678e-307
testProduct(C) = 0

where testProd is the following wrapping function:

testProd <- function(x) {
     return(.Fortran('testProd', as.double(x), as.double(0), 
as.double(0), as.integer(length(x))))
}

subroutine testProd(x, p, q,  n)
     implicit none
     integer, intent (in) :: n
     double precision, intent (in) :: x(n)
     double precision, intent (out) :: p
     double precision, intent (out) :: q
     integer :: i

     p = product(x)
     q=1
     do i = 1, n
         q = q*x(i)
     end do
end subroutine testProd

I check the lowest possible number and seems to be the same for both R 
and F90.
Can anyone help me understanding this behaviour?
Thank you in advance
Regards,
Filippo

-------------- next part --------------
c(0.126667774727727, 0.126778508335206, 0.126889731437094, 0.127001445486345, 
0.127113651944097, 0.127226352279715, 0.127339547970833, 0.127453240503398, 
0.127567431371714, 0.127682122078482, 0.127797314134848, 0.127913009060448, 
0.128029208383447, 0.128145913640589, 0.128263126377241, 0.128380848147438, 
0.128499080513928, 0.128617825048222, 0.128737083330636, 0.128856856950339, 
0.128977147505404, 0.129097956602849, 0.129219285858691, 0.129341136897992, 
0.129463511354905, 0.129586410872726, 0.129709837103945, 0.12983379171029, 
0.129958276362782, 0.130083292741782, 0.130208842537045, 0.130334927447768, 
0.130461549182643, 0.130588709459909, 0.130716410007402, 0.130844652562612, 
0.130973438872731, 0.13110277069471, 0.131232649795309, 0.131363077951156, 
0.131494056948797, 0.131625588584752, 0.131757674665574, 0.131890317007896, 
0.132023517438499, 0.132157277794358, 0.132291599922703, 0.132426485681077, 
0.132561936937394, 0.132697955569994, 0.132834543467704, 0.132971702529897, 
0.133109434666551, 0.133247741798307, 0.133386625856532, 0.13352608878338, 
0.133666132531848, 0.133806759065846, 0.133947970360249, 0.134089768400969, 
0.134232155185011, 0.134375132720541, 0.134518703026945, 0.1346628681349, 
0.13480763008643, 0.134952990934981, 0.135098952745478, 0.135245517594397, 
0.13539268756983, 0.13554046477155, 0.135688851311081, 0.135837849311768, 
0.13598746090884, 0.136137688249485, 0.136288533492915, 0.13643999881044, 
0.136592086385536, 0.136744798413917, 0.136898137103608, 0.137052104675016, 
0.137206703361001, 0.137361935406953, 0.137517803070863, 0.137674308623401, 
0.137831454347986, 0.137989242540865, 0.138147675511187, 0.138306755581082, 
0.138466485085736, 0.13862686637347, 0.13878790180582, 0.138949593757609, 
0.139111944617036, 0.13927495678575, 0.139438632678933, 0.139602974725378, 
0.139767985367577, 0.139933667061797, 0.140100022278169, 0.140267053500766, 
0.140434763227692, 0.140603153971164, 0.140772228257601, 0.140941988627706, 
0.141112437636557, 0.14128357785369, 0.141455411863193, 0.141627942263791, 
0.141801171668934, 0.141975102706893, 0.142149738020846, 0.142325080268972, 
0.14250113212454, 0.142677896276008, 0.14285537542711, 0.143033572296957, 
0.143212489620126, 0.143392130146759, 0.14357249664266, 0.143753591889391, 
0.14393541868437, 0.144117979840971, 0.144301278188622, 0.144485316572906, 
0.144670097855664, 0.144855624915093, 0.14504190064585, 0.145228927959158, 
0.145416709782907, 0.145605249061759, 0.145794548757257, 0.145984611847927, 
0.146175441329391, 0.146367040214468, 0.14655941153329, 0.146752558333409, 
0.146946483679905, 0.147141190655504, 0.147336682360684, 0.147532961913792, 
0.147730032451156, 0.147927897127204, 0.148126559114576, 0.148326021604241, 
0.148526287805616, 0.148727360946687, 0.148929244274124, 0.149131941053405, 
0.149335454568934, 0.149539788124169, 0.149744945041738, 0.149950928663571, 
0.150157742351019, 0.150365389484985, 0.150573873466047, 0.150783197714589, 
0.150993365670932, 0.151204380795458, 0.151416246568747, 0.15162896649171, 
0.151842544085717, 0.152056982892734, 0.15227228647546, 0.152488458417464, 
0.152705502323319, 0.152923421818742, 0.153142220550736, 0.153361902187731, 
0.15358247041972, 0.153803928958412, 0.154026281537366, 0.154249531912146, 
0.15447368386046, 0.154698741182311, 0.154924707700148, 0.15515158725901, 
0.155379383726686, 0.155608100993858, 0.155837742974264, 0.156068313604844, 
0.156299816845904, 0.15653225668127, 0.156765637118446, 0.156999962188775, 
0.157235235947601, 0.15747146247443, 0.157708645873097, 0.157946790271927, 
0.158185899823904, 0.158425978706841, 0.158667031123545, 0.158909061301989, 
0.159152073495486, 0.159396071982862, 0.159641061068628, 0.15988704508316, 
0.160134028382875, 0.160382015350409, 0.160631010394801, 0.16088101795167, 
0.161132042483405, 0.161384088479345, 0.161637160455966, 0.161891262957074, 
0.162146400553988, 0.162402577845737, 0.162659799459248, 0.162918070049544, 
0.163177394299939, 0.163437776922235, 0.163699222656923, 0.16396173627338, 
0.164225322570076, 0.164489986374778, 0.164755732544751, 0.165022565966972, 
0.165290491558336, 0.165559514265867, 0.165829639066933, 0.166100870969459, 
0.166373215012143, 0.166646676264676, 0.166921259827962, 0.167196970834337, 
0.167473814447798, 0.167751795864226, 0.16803092031161, 0.168311193050283, 
0.16859261937315, 0.168875204605922, 0.169158954107351, 0.169443873269469, 
0.169729967517823, 0.170017242311723, 0.17030570314448, 0.170595355543656, 
0.170886205071306, 0.171178257324233, 0.171471517934237, 0.171765992568371, 
0.172061686929194, 0.172358606755035, 0.172656757820246, 0.172956145935471, 
0.173256776947909, 0.17355865674158, 0.173861791237597, 0.174166186394438, 
0.174471848208216, 0.174778782712961, 0.175086995980898, 0.175396494122726, 
0.175707283287904, 0.176019369664935, 0.17633275948166, 0.176647459005543, 
0.17696347454397, 0.177280812444543, 0.177599479095379, 0.177919480925412, 
0.178240824404697, 0.178563516044721, 0.178887562398705, 0.179212970061922, 
0.17953974567201, 0.179867895909293, 0.180197427497096, 0.180528347202073, 
0.180860661834532, 0.181194378248764, 0.181529503343377, 0.181866044061627, 
0.18220400739176, 0.182543400367351, 0.18288423006765, 0.183226503617925, 
0.183570228189819, 0.183915411001696, 0.184262059319004, 0.184610180454628, 
0.184959781769258, 0.185310870671757, 0.185663454619521, 0.186017541118863, 
0.18637313772538, 0.186730252044341, 0.187088891731061, 0.187449064491294, 
0.187810778081621, 0.188174040309841, 0.18853885903537, 0.188905242169644, 
0.189273197676518, 0.189642733572677, 0.190013857928047, 0.19038657886621, 
0.190760904564824, 0.191136843256045, 0.191514403226953, 0.191893592819983, 
0.192274420433363, 0.192656894521548, 0.193041023595664, 0.193426816223955, 
0.193814281032235, 0.194203426704341, 0.194594261982594, 0.19498679566826, 
0.195381036622021, 0.195776993764442, 0.196174676076453, 0.196574092599828, 
0.196975252437666, 0.197378164754889, 0.197782838778727, 0.198189283799226, 
0.198597509169745, 0.199007524307466, 0.199419338693909, 0.19983296187545, 
0.20024840346384, 0.200665673136737, 0.201084780638235, 0.201505735779406, 
0.201928548438839, 0.202353228563188, 0.202779786167727, 0.20320823133691, 
0.203638574224928, 0.204070825056284, 0.204504994126367, 0.204941091802027, 
0.205379128522166, 0.205819114798326, 0.206261061215286, 0.206704978431663, 
0.207150877180523, 0.207598768269993, 0.208048662583881, 0.208500571082301, 
0.208954504802308, 0.20941047485853, 0.209868492443818, 0.210328568829893, 
0.210790715368003, 0.211254943489586, 0.211721264706939, 0.212189690613896, 
0.212660232886506, 0.213132903283727, 0.213607713648118, 0.214084675906544, 
0.214563802070883, 0.215045104238746, 0.215528594594196, 0.216014285408481, 
0.216502189040772, 0.216992317938908, 0.217484684640145, 0.217979301771921, 
0.218476182052619, 0.218975338292343, 0.219476783393702, 0.219980530352596, 
0.220486592259021, 0.220994982297869, 0.221505713749742, 0.222018799991779, 
0.222534254498484, 0.223052090842561, 0.223572322695767, 0.224094963829763, 
0.224620028116982, 0.225147529531498, 0.22567748214991, 0.226209900152233, 
0.226744797822793, 0.227282189551141, 0.227822089832971, 0.22836451327104, 
0.228909474576113, 0.229456988567903, 0.230007070176029, 0.230559734440981, 
0.231114996515097, 0.231672871663545, 0.232233375265318, 0.232796522814244, 
0.233362329919996, 0.233930812309122, 0.234501985826082, 0.23507586643429, 
0.23565247021718, 0.236231813379268, 0.236813912247239, 0.23739878327103, 
0.23798644302494, 0.238576908208741, 0.239170195648803, 0.239766322299235, 
0.240365305243027, 0.24096716169322, 0.241571908994073, 0.242179564622251, 
0.242790146188023, 0.243403671436474, 0.244020158248724, 0.244639624643169, 
0.245262088776728, 0.245887568946107, 0.246516083589072, 0.24714765128574, 
0.247782290759884, 0.248420020880245, 0.249060860661866, 0.24970482926744, 
0.25035194600866, 0.251002230347604, 0.251655701898113, 0.252312380427204, 
0.252972285856481, 0.253635438263571, 0.254301857883574, 0.254971565110527, 
0.255644580498884, 0.256320924765013, 0.257000618788707, 0.257683683614715, 
0.258370140454285, 0.259060010686729, 0.259753315861001, 0.260450077697291, 
0.261150318088643, 0.261854059102583, 0.262561322982772, 0.263272132150668, 
0.263986509207217, 0.264704476934552, 0.265426058297719, 0.26615127644642, 
0.266880154716771, 0.267612716633081, 0.268348985909659, 0.269088986452625, 
0.269832742361758, 0.270580277932351, 0.271331617657098, 0.272086786227989, 
0.27284580853824, 0.273608709684234, 0.27437551496749, 0.275146249896651, 
0.275920940189494, 0.276699611774965, 0.277482290795235, 0.27826900360778, 
0.279059776787482, 0.279854637128761, 0.28065361164772, 0.281456727584324, 
0.2822640124046, 0.283075493802859, 0.283891199703951, 0.284711158265537, 
0.285535397880392, 0.286363947178735, 0.287196835030582, 0.288034090548129, 
0.28887574308816, 0.289721822254486, 0.290572357900409, 0.291427380131215, 
0.292286919306696, 0.293151006043704, 0.29401967121873, 0.294892945970514, 
0.295770861702688, 0.296653450086448, 0.297540743063257, 0.298432772847579, 
0.299329571929646, 0.300231173078257, 0.301137609343611, 0.302048914060171, 
0.302965120849563, 0.303886263623507, 0.30481237658679, 0.305743494240263, 
0.306679651383881, 0.307620883119779, 0.308567224855379, 0.30951871230654, 
0.310475381500742, 0.311437268780311, 0.312404410805677, 0.313376844558676, 
0.314354607345891, 0.31533773680203, 0.316326270893349, 0.31732024792111, 
0.318319706525089, 0.319324685687116, 0.32033522473467, 0.321351363344506, 
0.322373141546331, 0.323400599726529, 0.324433778631921, 0.32547271937358, 
0.326517463430689, 0.327568052654445, 0.328624529272012, 0.329686935890525, 
0.330755315501134, 0.331829711483112, 0.332910167608, 0.333996728043813, 
0.335089437359289, 0.3361883405282, 0.337293482933706, 0.338404910372776, 
0.339522669060651, 0.340646805635367, 0.34177736716234, 0.342914401139002, 
0.344057955499495, 0.345208078619425, 0.346364819320679, 0.347528226876294, 
0.3486983510154, 0.34987524192821, 0.351058950271085, 0.352249527171659, 
0.353447024234028, 0.354651493544003, 0.355862987674435, 0.357081559690603, 
0.358307263155673, 0.359540152136224, 0.360780281207853, 0.362027705460834, 
0.363282480505872, 0.36454466247991, 0.36581430805203, 0.367091474429409, 
0.368376219363373, 0.369668601155511, 0.370968678663882, 0.372276511309294, 
0.373592159081667, 0.374915682546477, 0.37624714285129, 0.377586601732372, 
0.378934121521393, 0.380289765152215, 0.381653596167768, 0.38302567872702, 
0.384406077612035, 0.385794858235125, 0.387192086646097, 0.388597829539595, 
0.390012154262539, 0.391435128821664, 0.392866821891156, 0.39430730282039, 
0.395756641641775, 0.3972149090787, 0.398682176553587, 0.400158516196047, 
0.401644000851155, 0.403138704087829, 0.404642700207322, 0.40615606425183, 
0.407678872013214, 0.409211200041844, 0.410753125655557, 0.41230472694874, 
0.413866082801535, 0.415437272889168, 0.417018377691408, 0.418609478502151, 
0.420210657439137, 0.421821997453802, 0.423443582341258, 0.425075496750418, 
0.426717826194254, 0.428370657060202, 0.4300340766207, 0.431708173043885, 
0.433393035404428, 0.435088753694524, 0.436795418835027, 0.438513122686754, 
0.440241958061929, 0.4419820187358, 0.44373339945841, 0.445496195966538, 
0.447270504995803, 0.449056424292939, 0.450854052628244, 0.452663489808202, 
0.454484836688283, 0.456318195185927, 0.458163668293704, 0.460021360092671, 
0.461891375765908, 0.463773821612251, 0.465668805060223, 0.467576434682156, 
0.469496820208524, 0.471430072542472, 0.473376303774557, 0.475335627197701, 
0.477308157322358, 0.4792940098919, 0.48129330189822, 0.483306151597566, 
0.4853326785266, 0.487373003518694, 0.489427248720454, 0.491495537608494, 
0.493577995006444, 0.495674747102214, 0.497785921465505, 0.499911647065577, 
0.502052054289276, 0.504207274959328, 0.506377442352901, 0.508562691220433, 
0.510763157804749, 0.51297897986045, 0.515210296673594, 0.517457249081665, 
0.519719979493837, 0.521998631911548, 0.524293351949361, 0.526604286856157, 
0.528931585536629, 0.531275398573102, 0.533635878247678, 0.536013178564717, 
0.538407455273648, 0.540818865892126, 0.54324756972954, 0.545693727910873, 
0.548157503400918, 0.550639061028867, 0.553138567513267, 0.555656191487358, 
0.558192103524792, 0.560746476165743, 0.563319483943419, 0.565911303410975, 
0.568522113168835, 0.571152093892437, 0.573801428360398, 0.576470301483111, 
0.579158900331789, 0.581867414167945, 0.584596034473331, 0.587344954980342, 
0.590114371702885, 0.592904482967725, 0.595715489446323, 0.59854759418716, 
0.601401002648568, 0.604275922732072, 0.607172564816249, 0.610091141791118, 
0.613031869093063, 0.615994964740309, 0.618980649368945, 0.621989146269524, 
0.625020681424225, 0.62807548354461, 0.63115378410997, 0.634255817406277, 
0.637381820565754, 0.640532033607065, 0.64370669947615, 0.646906064087698, 
0.650130376367288, 0.653379888294188, 0.656654854944852, 0.659955534537093, 
0.663282188474974, 0.666635081394407, 0.670014481209488, 0.673420659159574, 
0.676853889857108, 0.680314451336222, 0.683802625102113, 0.68731869618122, 
0.690862953172205, 0.694435688297756, 0.698037197457236, 0.70166778028017, 
0.705327740180606, 0.709017384412357, 0.712737024125137, 0.716486974421608, 
0.720267554415357, 0.724079087289815, 0.727921900358139, 0.731796325124065, 
0.73570269734376, 0.739641357088679, 0.743612648809459, 0.747616921400851, 
0.751654528267718, 0.755725827392119, 0.75983118140149, 0.76397095763795, 
0.768145528228741, 0.772355270157834, 0.776600565338707, 0.780881800688335, 
0.785199368202383, 0.78955366503166, 0.793945093559819, 0.798374061482355, 
0.802840981886904, 0.807346273334868, 0.811890359944402, 0.816473671474767, 
0.821096643412089, 0.825759717056535, 0.830463339610946, 0.835207964270926, 
0.839994050316449, 0.844822063204971, 0.849692474666098, 0.854605762797835, 
0.85956241216442, 0.864562913895808, 0.869607765788795, 0.874697472409829, 
0.879832545199546, 0.885013502579025, 0.890240870057837, 0.895515180343878, 
0.900836973455035, 0.906206796832719, 0.911625205457281, 0.917092761965356, 
0.922610036769158, 0.928177608177759, 0.933796062520393, 0.939465994271806, 
0.945188006179693, 0.950962709394249, 0.956790723599879, 0.962672677149092, 
0.968609207198612, 0.974600959847752, 0.98064859027908, 0.986752762901407, 
0.992914151495149, 0.999133439360083, 1.00541131946554, 1.0117484946031, 
1.01814567754173, 1.02460359118558, 1.03112296873426, 1.03770455384584, 
1.04434910080242, 1.05105737467852, 1.05783015151208, 1.06466821847839, 
1.07157237406671, 1.07854342825986, 1.08558220271664, 1.09268953095722, 
1.09986625855153, 1.10711324331065, 1.11443135548128, 1.12182147794325, 
1.12928450641032, 1.13682134963396, 1.14443292961054, 1.15212018179164, 
1.15988405529777, 1.16772551313532, 1.17564553241696, 1.18364510458546, 
1.19172523564088, 1.19988694637132, 1.20813127258717, 1.21645926535893, 
1.22487199125854, 1.23337053260447, 1.24195598771034, 1.25062947113729, 
1.25939211395004, 1.2682450639767, 1.27718948607235, 1.28622656238638, 
1.29535749263372, 1.3045834943698, 1.31390580326946, 1.32332567340966, 
1.33284437755611, 1.34246320745381, 1.35218347412142, 1.36200650814963, 
1.37193366000337, 1.38196630032797, 1.39210582025918, 1.40235363173713, 
1.41271116782414, 1.4231798830264, 1.43376125361948, 1.44445677797766, 
1.45526797690703, 1.46619639398233, 1.47724359588748, 1.48841117275974, 
1.49970073853747, 1.51111393131137, 1.5226524136792, 1.53431787310381, 
1.54611202227448, 1.55803659947138, 1.57009336893313, 1.58228412122724, 
1.59461067362338, 1.60707487046933, 1.61967858356934, 1.63242371256497, 
1.64531218531793, 1.65834595829495, 1.67152701695441, 1.68485737613442, 
1.69833908044218, 1.71197420464445, 1.72576485405856, 1.73971316494402, 
1.7538213048941, 1.76809147322728, 1.78252590137798, 1.79712685328638, 
1.8118966257868, 1.82683754899417, 1.84195198668824, 1.85724233669495, 
1.87271103126437, 1.88836053744482, 1.90419335745236, 1.92021202903522, 
1.93641912583231, 1.95281725772524, 1.96940907118308, 1.9861972495989, 
2.00318451361754, 2.02037362145344, 2.03776736919778, 2.0553685911138, 
2.07318015991939, 2.09120498705573, 2.10944602294091, 2.12790625720719, 
2.14658871892075, 2.16549647678244, 2.18463263930821, 2.20400035498756, 
2.22360281241868, 2.24344324041827, 2.26352490810464, 2.28385112495197, 
2.30442524081398, 2.32525064591489, 2.34633077080554, 2.36766908628253, 
2.38926910326789, 2.41113437264693, 2.43326848506172, 2.45567507065736, 
2.47835779877839, 2.50132037761223, 2.52456655377673, 2.54810011184839, 
2.57192487382806, 2.59604469854048, 2.62046348096394, 2.64518515148636, 
2.67021367508358, 2.69555305041579, 2.72120730883764, 2.74718051331758, 
2.77347675726154, 2.80010016323613, 2.82705488158604, 2.85434508894054, 
2.88197498660324, 2.90994879881949, 2.93827077091539, 2.96694516730204, 
2.99597626933882, 3.02536837304872, 3.05512578667895, 3.08525282809956, 
3.1157538220327, 3.1466330971048, 3.17789498271367, 3.20954380570253, 
3.24158388683228, 3.27401953704356, 3.30685505349945, 3.34009471539983, 
3.37374277955779, 3.40780347572854, 3.44228100168088, 3.47717951800111, 
3.51250314261899, 3.54825594504538, 3.58444194031052, 3.62106508259244, 
3.65812925852402, 3.69563828016792, 3.73359587764766, 3.77200569142381, 
3.81087126420363, 3.85019603247277, 3.88998331763749, 3.93023631676615, 
3.9709580929185, 4.01215156505172, 4.05381949749217, 4.09596448896233, 
4.13858896115228, 4.18169514682602, 4.225285077453, 4.26936057035584, 
4.31392321536612, 4.35897436098048, 4.40451510001032, 4.45054625471939, 
4.49706836144439, 4.54408165469509, 4.59158605073174, 4.63958113061874, 
4.68806612275574, 4.73703988488826, 4.78650088560256, 4.83644718531116, 
4.88687641673778, 4.93778576491282, 4.9891719466933, 5.04103118982387, 
5.09335921155849, 5.14615119686566, 5.19940177624365, 5.25310500317552, 
5.30725433125797, 5.36184259104187, 5.41686196662666, 5.47230397205558, 
5.5281594275631, 5.58441843573103, 5.64107035761498, 5.69810378890798, 
5.75550653621385, 5.81326559350816, 5.87136711887098, 5.92979641158084, 
5.98853788966604, 6.04757506801486, 6.10689053715278, 6.16646594280064, 
6.22628196633371, 6.28631830626767, 6.34655366090301, 6.40696571226526, 
6.46753111148334, 6.52822546575354, 6.58902332704112, 6.6498981826754, 
6.71082244799802, 6.7717674612266, 6.83270348069849, 6.89359968466034, 
6.95442417377007, 7.01514397647684, 7.0757250574436, 7.13613232917356, 
7.19632966699837, 7.25627992758037, 7.31594497107456, 7.37528568708809, 
7.43426202456508, 7.49283302571387, 7.55095686408033, 7.60859088685726, 
7.66569166150283, 7.72221502672414, 7.77811614786189, 7.83334957669142, 
7.88786931563279, 7.94162888633836, 7.99458140260103, 8.04667964749941, 
8.09787615466862, 8.14812329355627, 8.19737335849394, 8.2455786613843, 
8.29269162777338, 8.33866489604749, 8.38345141946338, 8.42700457069126, 
8.46927824852053, 8.51022698635093, 8.54980606206488, 8.58797160885252, 
8.62468072653814, 8.65989159293669, 8.69356357475138, 8.7256573375091, 
8.75613495401908, 8.7849600108323, 8.8120977121755, 8.83751498083311, 
8.86118055545461, 8.88306508377275, 8.90314121123023, 8.92138366452907, 
8.93776932963719, 8.95227732381165, 8.96488906122628, 8.97558831182403, 
8.98436125304979, 8.99119651415869, 8.99608521283661, 8.99902098391393
)

From r.turner at auckland.ac.nz  Fri Nov  8 00:48:57 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 08 Nov 2013 12:48:57 +1300
Subject: [R] prod and F90 product
In-Reply-To: <527C24CA.5060101@gmail.com>
References: <527C24CA.5060101@gmail.com>
Message-ID: <527C26E9.4000700@auckland.ac.nz>

On 11/08/13 12:39, Filippo wrote:
> Hi,
> I'm having strange differences between the R function prod ad the F90 
> function product.
> Processing the same vector C (see attachment). I get 2 different results:
> prod(C) = 1.069678e-307
> testProduct(C) = 0

<SNIP>

If you are worried about the difference between 0 and 1.069678e-307 then 
you probably
shouldn't be using computers.

     cheers,

     Rolf Turner


From marceivissa at gmail.com  Fri Nov  8 01:01:47 2013
From: marceivissa at gmail.com (=?ISO-8859-1?Q?Marc_Mar=ED_Dell=27Olmo?=)
Date: Fri, 8 Nov 2013 01:01:47 +0100
Subject: [R] Merging two dataframes with a condition involving variables of
	both dataframes
Message-ID: <CAAZSCQ5Yf9fK+aYfK3WkUtyvySzi1vcXZHqrNZadn+up7pMYFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/45d3db91/attachment.pl>

From gunter.berton at gene.com  Fri Nov  8 01:10:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 7 Nov 2013 16:10:00 -0800
Subject: [R] prod and F90 product
In-Reply-To: <527C26E9.4000700@auckland.ac.nz>
References: <527C24CA.5060101@gmail.com> <527C26E9.4000700@auckland.ac.nz>
Message-ID: <AE8A64A4-63BB-483E-9B93-AFC4E8BEE656@gene.com>

Fortune !

Bert

Sent from my iPhone -- please excuse typos.

> On Nov 7, 2013, at 3:48 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> On 11/08/13 12:39, Filippo wrote:
>> Hi,
>> I'm having strange differences between the R function prod ad the F90 function product.
>> Processing the same vector C (see attachment). I get 2 different results:
>> prod(C) = 1.069678e-307
>> testProduct(C) = 0
> 
> <SNIP>
> 
> If you are worried about the difference between 0 and 1.069678e-307 then you probably
> shouldn't be using computers.
> 
>    cheers,
> 
>    Rolf Turner
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Nov  8 01:28:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 07 Nov 2013 19:28:38 -0500
Subject: [R] prod and F90 product
In-Reply-To: <527C24CA.5060101@gmail.com>
References: <527C24CA.5060101@gmail.com>
Message-ID: <527C3036.3010707@gmail.com>

On 13-11-07 6:39 PM, Filippo wrote:
> Hi,
> I'm having strange differences between the R function prod ad the F90
> function product.
> Processing the same vector C (see attachment). I get 2 different results:
> prod(C) = 1.069678e-307
> testProduct(C) = 0
>
> where testProd is the following wrapping function:
>
> testProd <- function(x) {
>       return(.Fortran('testProd', as.double(x), as.double(0),
> as.double(0), as.integer(length(x))))
> }
>
> subroutine testProd(x, p, q,  n)
>       implicit none
>       integer, intent (in) :: n
>       double precision, intent (in) :: x(n)
>       double precision, intent (out) :: p
>       double precision, intent (out) :: q
>       integer :: i
>
>       p = product(x)
>       q=1
>       do i = 1, n
>           q = q*x(i)
>       end do
> end subroutine testProd
>
> I check the lowest possible number and seems to be the same for both R
> and F90.
> Can anyone help me understanding this behaviour?

Some intermediate results may be stored with 80 bit precision in R, 64 
bit precision in Fortran.

Duncan Murdoch


From dwinsemius at comcast.net  Fri Nov  8 01:47:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Nov 2013 16:47:03 -0800
Subject: [R] Problems loading xlsx
In-Reply-To: <BAY404-EAS10884859BD70EE36AC864ADD1F30@phx.gbl>
References: <BAY404-EAS10884859BD70EE36AC864ADD1F30@phx.gbl>
Message-ID: <E0437CAB-C5B5-447C-8209-870208E61EED@comcast.net>


On Nov 7, 2013, at 12:55 PM, Barrett Gady wrote:

> does anyone know how to resolve Error:  .onLoad failed in loadNamespace() for ?xlsxjars?  
> 
> I can?t seem to get this package to load on my windows 7 install of R3.02

It appears that you did not install all  the depndencies for package xlsx.

http://cran.r-project.org/web/packages/xlsx/index.html


-- 

David Winsemius
Alameda, CA, USA


From collinl at cs.pitt.edu  Fri Nov  8 03:37:29 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Thu, 07 Nov 2013 21:37:29 -0500 (EST)
Subject: [R] Merging two dataframes with a condition involving variables
 of both dataframes
In-Reply-To: <CAAZSCQ5Yf9fK+aYfK3WkUtyvySzi1vcXZHqrNZadn+up7pMYFQ@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1311072134390.5651-100000@neodymium.cs.pitt.edu>

You might need to implement it as a nested pair of for loops using rbind.
In essence iterate over the rows in df1 and each time find the matching
row in df2.  If none is found then add the df1 row by itself to the
result.  If one is then remove it from df2 and rbind both of them.  Once
done just merge in all rows that remain in df2.

This would likely be slower than a sql-based method but is essentially the
same algorithm.

You can find advice on for-loops in R here:
http://paleocave.sciencesortof.com/2013/03/writing-a-for-loop-in-r/

	Best,
	Collin.


From kinsham at verizon.net  Fri Nov  8 05:16:18 2013
From: kinsham at verizon.net (Chris Wilkinson)
Date: Thu, 07 Nov 2013 23:16:18 -0500
Subject: [R] Earth (MARS) package with categorical predictors
Message-ID: <ml99syxejec3ep0u4h0je78h.1383884178002@email.android.com>

It appears to be legitimate to include multi-level categorical and continuous variables in defining the model for earth (e.g. y ~ cat + cont1 + cont2) but is it also then possible use categoricals in the predict method using the earth result? I tried but it returns an error which is not very informative.

Thanks

Chris

From blaturnu at ualberta.ca  Thu Nov  7 23:17:59 2013
From: blaturnu at ualberta.ca (Breanne Tidemann)
Date: Thu, 7 Nov 2013 15:17:59 -0700
Subject: [R] Loglogistic 4-parameter model,
 fitting multiple curves specific estimates give NaNS,
 when fit alone all parameters estimated
Message-ID: <CAENkib58sO7s32CEdPBxj63L5jaK+xhwLnZbhTDFSNBgYPNLrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/5b4bd271/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov  7 23:47:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 7 Nov 2013 14:47:39 -0800 (PST)
Subject: [R] Sorting Data Frames in R by multiple columns with a custom
	order
Message-ID: <1383864459.40742.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

Not sure whether this helps:
dat1 <- as.data.frame(mat,stringsAsFactors=FALSE)
dat1$c4 <- factor(dat1$c4,levels=c("OF","ON"))
?dat1$c1 <- factor(dat1$c1,levels=c("US","UK","WW","BO","BR","CA"))
?dat1$c2 <- factor(dat1$c2, levels=c("P2","P3","P1"))
?dat1$c3 <- factor(dat1$c3, levels=c("S2","S1","S3"))
?dat1[with(dat1,order(c4,c1,c2,c3)),]

A.K.




Thank you guys for the help here and my apologies if this has been answered in the post's already somewhere which I just was not able to 
find. 

I am trying to sort a data frame by multiple 
columns. ?Each column has different values of interest for which I am 
trying to sort. ?I have been able to do this alphebetically in both 
ascending and decending order using the order function. ?However, for 
the document I am trying to create it is crutcial that the order is not 
alphebetically. ?In fact it is by a specific ordering, on each of the 
columns, which I need to specify. 

I could do this via a nasty convolution of creating sort order variables for each of the columns and then merging on to the data frame by the cols, then ordering on the new sort order cols, then 
remove them...however, I was hoping that there would be a nice and easy 
automated way to handle this in case the order changes at another time. 

so, here's an example 
c1 = c('CA', 'CA', 'CA', 'BR', 'BR', 'UK', 'UK', 'BO', 'BO', 'BO', 'WW', 'WW', 'WW', 'US', 'US') 
c2 = c('P3', 'P2', 'P1', 'P1', 'P2', 'P2', 'P1', 'P1', 'P3', 'P2', 'P1', 'P2', 'P3', 'P3', 'P2') 
c3 = c('S1', 'S1', 'S2', 'S2', 'S2', 'S1', 'S2', 'S1', 'S1', 'S1', 'S1', 'S2', 'S3', 'S1', 'S1') 
c4 = c('ON', 'ON', 'OF', 'ON', 'OF', 'OF', 'OF', 'ON', 'ON', 'ON', 'OF', 'ON', 'ON', 'ON', 'ON') 

mat = cbind(c4, c1, c2, c3) 

if we sort as usual we'd get 
"OF"	"BR"	"P2"	"S2" 
"OF"	"CA"	"P1"	"S2" 
"OF"	"UK"	"P1"	"S2" 
"OF"	"UK"	"P2"	"S1" 
"OF"	"WW"	"P1"	"S1" 
"ON"	"BO"	"P1"	"S1" 
"ON"	"BO"	"P2"	"S1" 
"ON"	"BO"	"P3"	"S1" 
"ON"	"BR"	"P1"	"S2" 
"ON"	"CA"	"P2"	"S1" 
"ON"	"CA"	"P3"	"S1" 
"ON"	"US"	"P2"	"S1" 
"ON"	"US"	"P3"	"S1" 
"ON"	"WW"	"P2"	"S2" 
"ON"	"WW"	"P3"	"S3" 


however I want OF in col 1 to come first...then in the col2 i want US, UK, WW, BO, BR, and then CA. ?then col 3 we need P2, then P3, then P1, and finally in col 4 i need S2, then S1, and then finally S3. ?As such 

"OF"	"UK"	"P2"	"S1" 
"OF"	"UK"	"P1"	"S2" 
"OF"	"WW"	"P1"	"S1" 
"OF"	"BR"	"P2"	"S2" 
"OF"	"CA"	"P1"	"S2" 
"ON"	"US"	"P2"	"S1" 
"ON"	"US"	"P3"	"S1" 
"ON"	"WW"	"P2"	"S2" 
"ON"	"WW"	"P3"	"S3" 
"ON"	"BO"	"P2"	"S1" 
"ON"	"BO"	"P3"	"S1" 
"ON"	"BO"	"P1"	"S1" 
"ON"	"BR"	"P1"	"S2" 
"ON"	"CA"	"P2"	"S1" 
"ON"	"CA"	"P3"	"S1" 

i've tried nesting orders in orders, the match 
function looks like it might work if it wasn't for the fact that in my 
actual data each col can have multiple records for each value and match 
only looks for the first matching case....that said, the sort order is 
unique. 

Furthermore, these are not the real data, just an example. 

anything might be able to get me further along the way than I am now. 

Thanks


From smartpink111 at yahoo.com  Fri Nov  8 00:07:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 7 Nov 2013 15:07:46 -0800 (PST)
Subject: [R] Sorting Data Frames in R by multiple columns with a custom
	order
In-Reply-To: <1383864459.40742.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1383864459.40742.YahooMailNeo@web142603.mail.bf1.yahoo.com> 
Message-ID: <1383865666.68271.YahooMailNeo@web142605.mail.bf1.yahoo.com>

If you already have the order stored in a list or so:
For example:
dat1 <- as.data.frame(mat,stringsAsFactors=FALSE)

lst1 <- list(c("OF","ON"), c("US","UK", "WW","BO","BR","CA"), c("P2","P3","P1"),c("S2","S1","S3"))
?dat1[] <- lapply(seq_along(lst1),function(i) factor(dat1[,i],levels=lst1[[i]])) 
?dat1[with(dat1,order(c4,c1,c2,c3)),]

A.K.


On Thursday, November 7, 2013 5:47 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,

Not sure whether this helps:
dat1 <- as.data.frame(mat,stringsAsFactors=FALSE)
dat1$c4 <- factor(dat1$c4,levels=c("OF","ON"))
?dat1$c1 <- factor(dat1$c1,levels=c("US","UK","WW","BO","BR","CA"))
?dat1$c2 <- factor(dat1$c2, levels=c("P2","P3","P1"))
?dat1$c3 <- factor(dat1$c3, levels=c("S2","S1","S3"))
?dat1[with(dat1,order(c4,c1,c2,c3)),]

A.K.




Thank you guys for the help here and my apologies if this has been answered in the post's already somewhere which I just was not able to 
find. 

I am trying to sort a data frame by multiple 
columns. ?Each column has different values of interest for which I am 
trying to sort. ?I have been able to do this alphebetically in both 
ascending and decending order using the order function. ?However, for 
the document I am trying to create it is crutcial that the order is not 
alphebetically. ?In fact it is by a specific ordering, on each of the 
columns, which I need to specify. 

I could do this via a nasty convolution of creating sort order variables for each of the columns and then merging on to the data frame by the cols, then ordering on the new sort order cols, then 
remove them...however, I was hoping that there would be a nice and easy 
automated way to handle this in case the order changes at another time. 

so, here's an example 
c1 = c('CA', 'CA', 'CA', 'BR', 'BR', 'UK', 'UK', 'BO', 'BO', 'BO', 'WW', 'WW', 'WW', 'US', 'US') 
c2 = c('P3', 'P2', 'P1', 'P1', 'P2', 'P2', 'P1', 'P1', 'P3', 'P2', 'P1', 'P2', 'P3', 'P3', 'P2') 
c3 = c('S1', 'S1', 'S2', 'S2', 'S2', 'S1', 'S2', 'S1', 'S1', 'S1', 'S1', 'S2', 'S3', 'S1', 'S1') 
c4 = c('ON', 'ON', 'OF', 'ON', 'OF', 'OF', 'OF', 'ON', 'ON', 'ON', 'OF', 'ON', 'ON', 'ON', 'ON') 

mat = cbind(c4, c1, c2, c3) 

if we sort as usual we'd get 
"OF"??? "BR"??? "P2"??? "S2" 
"OF"??? "CA"??? "P1"??? "S2" 
"OF"??? "UK"??? "P1"??? "S2" 
"OF"??? "UK"??? "P2"??? "S1" 
"OF"??? "WW"??? "P1"??? "S1" 
"ON"??? "BO"??? "P1"??? "S1" 
"ON"??? "BO"??? "P2"??? "S1" 
"ON"??? "BO"??? "P3"??? "S1" 
"ON"??? "BR"??? "P1"??? "S2" 
"ON"??? "CA"??? "P2"??? "S1" 
"ON"??? "CA"??? "P3"??? "S1" 
"ON"??? "US"??? "P2"??? "S1" 
"ON"??? "US"??? "P3"??? "S1" 
"ON"??? "WW"??? "P2"??? "S2" 
"ON"??? "WW"??? "P3"??? "S3" 


however I want OF in col 1 to come first...then in the col2 i want US, UK, WW, BO, BR, and then CA. ?then col 3 we need P2, then P3, then P1, and finally in col 4 i need S2, then S1, and then finally S3. ?As such 

"OF"??? "UK"??? "P2"??? "S1" 
"OF"??? "UK"??? "P1"??? "S2" 
"OF"??? "WW"??? "P1"??? "S1" 
"OF"??? "BR"??? "P2"??? "S2" 
"OF"??? "CA"??? "P1"??? "S2" 
"ON"??? "US"??? "P2"??? "S1" 
"ON"??? "US"??? "P3"??? "S1" 
"ON"??? "WW"??? "P2"??? "S2" 
"ON"??? "WW"??? "P3"??? "S3" 
"ON"??? "BO"??? "P2"??? "S1" 
"ON"??? "BO"??? "P3"??? "S1" 
"ON"??? "BO"??? "P1"??? "S1" 
"ON"??? "BR"??? "P1"??? "S2" 
"ON"??? "CA"??? "P2"??? "S1" 
"ON"??? "CA"??? "P3"??? "S1" 

i've tried nesting orders in orders, the match 
function looks like it might work if it wasn't for the fact that in my 
actual data each col can have multiple records for each value and match 
only looks for the first matching case....that said, the sort order is 
unique. 

Furthermore, these are not the real data, just an example. 

anything might be able to get me further along the way than I am now. 

Thanks


From paul at stat.auckland.ac.nz  Fri Nov  8 01:51:18 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 08 Nov 2013 13:51:18 +1300
Subject: [R] Finding absolute viewport location in grid / lattice
In-Reply-To: <BAY175-W41B9F0644AE64FE2C660A8F6F00@phx.gbl>
References: <BAY175-W41B9F0644AE64FE2C660A8F6F00@phx.gbl>
Message-ID: <527C3586.6030105@stat.auckland.ac.nz>

Hi

Take a look at current.transform() (the grid.locator() function shows an 
example use)

Paul

On 11/06/13 13:35, James Price wrote:
> I'm trying to do some post-plot manipulation of some lattice
> graphics, in which I need to get the absolute viewport locations on
> the plotting device. So for example:
>
> library(lattice) print(xyplot(Petal.Length ~ Sepal.Length | Species,
> iris, layout = c(2, 2))) trellis.focus('panel', 1, 1)
>
> This shows the item I want to identify. I need to know, for example,
> that the lower left corner of the highlighted panel is at (0.1, 0.1)
> of the plotting device. Hopefully there's some grid shenanigans I can
> use to do so.
>
> To put the question into context (in case there's an alternative
> way): I'm constructing PDF reports that are an amalgam of PDF
> figures, constructed through LaTeX programmatically constructed in R,
> and I'd like to be able to add tooltips to some of the data points on
> the graphs. To do so, I'm overlaying a tikz (empty) image that uses
> the pdfcomment package to add the tooltips. Hence I need to be able
> to calculate where some of the points are on the screen so I can
> calculate where to put the tooltip 'hit-zones'. This would be fairly
> trivial using javascript / actionscript and mouseover hooks, but I'm
> constrained by PDF.
>
> Thanks, Jim Price. Strength in Numbers.
>
>  [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ebowles at ucalgary.ca  Fri Nov  8 05:41:04 2013
From: ebowles at ucalgary.ca (Ella Bowles)
Date: Thu, 7 Nov 2013 21:41:04 -0700
Subject: [R] help plotting two-dimensional ADMIXTURE data in R
Message-ID: <CAHpKFdBD8AfP9x2cxrtt3-pjnqqDFvuTirCSTwjPbCM7swYqWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/7aca866f/attachment.pl>

From sv.june at yahoo.ca  Fri Nov  8 06:06:06 2013
From: sv.june at yahoo.ca (sv.june at yahoo.ca)
Date: Thu, 7 Nov 2013 21:06:06 -0800 (PST)
Subject: [R] Underdispersion and count data
Message-ID: <1383887166.3917.YahooMailNeo@web120406.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131107/d6a9fb24/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Fri Nov  8 07:55:41 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 8 Nov 2013 07:55:41 +0100 (CET)
Subject: [R] Underdispersion and count data
In-Reply-To: <1383887166.3917.YahooMailNeo@web120406.mail.ne1.yahoo.com>
References: <1383887166.3917.YahooMailNeo@web120406.mail.ne1.yahoo.com>
Message-ID: <alpine.DEB.2.10.1311080750050.23610@paninaro.uibk.ac.at>

On Thu, 7 Nov 2013, sv.june at yahoo.ca wrote:

> Hello,
>
> I have count data for 4 groups, 2 of which have a large number of zeroes 
> and are overdispersed, and the other 2 underdispersed with no zeroes.

Are you sure that it's really underdispersion in addition to the lack of 
zeros? It could also be that due to the missing zeros, there is less 
dispersion.

> I have two questions about model fitting, which I am quite new to, and 
> have been using mostly the pscl package.
>
> 1 - How do I deal with underdispersion? Almost all the published and 
> online advice is regarding overdispersion, and neither the Poisson nor 
> negative binomial distribution seem appropriate. The COM Poisson comes 
> up sometimes as a suggestion, but it's not clear to me how I can use 
> this, explain my choice of it, or what information I would report for 
> publication purposes.

There are (at least) two packages on CRAN: compoisson and ComPoissonReg 
which support this.

However, I would check first whether this is really needed or maybe a 
zero-truncated Poisson model is already sufficient.

The package "countreg" on R-Forge 
(https://R-Forge.R-project.org/R/?group_id=522) has a function zerotrunc() 
which is essentially the same code that hurdle() in "pscl" uses. So it 
should be easy to use for you.

> 2 - For the overdispersed data with lots of zeroes, I've tried 
> zero-inflated Poisson and NegBin and hurdle models, and used the Vuong 
> test to compare. However, I get equal fit for two candidate models that 
> produce quite different coefficient estimates for my predictor 
> variables, and hence different p values. I am unsure how to proceed in 
> choosing one of these models, and how I would justify one over the other 
> given that the Vuong test seems not to discriminate.

Is it just zero-inflated vs. hurdle or also differences in the regressors? 
If the former: zero-inflated and hurdle models are parametrized 
differently but often lead to similar fits. But the former has a count 
part plus a zero-inlation part whereas the latter as a zero-truncated 
count part and a zero hurdle.

If the regressors are different, then it's probably a subject-matter 
decision.

hth,
Z

> Thank you and any advice would be much appreciated.
>
> Mo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thpe at simecol.de  Fri Nov  8 07:59:50 2013
From: thpe at simecol.de (Thomas Petzoldt)
Date: Fri, 08 Nov 2013 07:59:50 +0100
Subject: [R] deSolve, unresolved namespace error -- solved
In-Reply-To: <527ABB2B.9080702@simecol.de>
References: <CAL7OOdxV2MOsV_Nvt3A1y1JdcTfGt0=VkAnhAYvMr=1JkSCSdQ@mail.gmail.com>	<CAL7OOdwZN2X852acyHHNNvYZUghx19jR-E1XcT53LqC9vgTS3w@mail.gmail.com>
	<527ABB2B.9080702@simecol.de>
Message-ID: <527C8BE6.80707@simecol.de>

We have been able to reproduce the reported issue on another Linux
system: Fedora 19, and the solution was quite simple:

The deSolve package must always to be loaded *before* loading the shared
library of the compiled model.

Thomas


From lucam1968 at gmail.com  Fri Nov  8 08:32:48 2013
From: lucam1968 at gmail.com (Luca Meyer)
Date: Fri, 8 Nov 2013 08:32:48 +0100
Subject: [R] Uploading Google Spreadsheet data into R
Message-ID: <CABQyo87ON_6fuhYfEfuK2DZ0isJRxPyOskqGZzwOokSnSQOAqw@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/ce7d2d1a/attachment.pl>

From aloboaleu at gmail.com  Fri Nov  8 09:35:00 2013
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Fri, 8 Nov 2013 09:35:00 +0100
Subject: [R] Different output from lm() and lmPerm lmp() if categorical
 variables are included in the analysis
Message-ID: <CALPC6DO2aR+y9sVs1z8edPe1uacee13jY+40QzTTHdUbjRRdjQ@mail.gmail.com>

I've found a problem when using
categorical variables in lmp() from package lmPerm

According to help(lmp): "This function will behave identically to lm()
if the following parameters are set: perm="", seq=TRUE,
center=FALSE.")
But not in the case of including categorical variables:

require(lmPerm)
set.seed(42)
testx1 <- rnorm(100,10,5)
testx2 <- c(rep("a",50),rep("b",50))
testy <- 5*testx1 + 3 + runif(100,-20,20)
test <- data.frame(x1=testx1,x2=
testx2,y=testy)
atest <- lm(y ~ x1*x2,data=test)
aptest <- lmp(y ~ x1*x2,data=test,perm = "", seqs = TRUE, center = FALSE)
summary(atest)

Call:
lm(formula = y ~ x1 * x2, data = test)
Residuals:
    Min       1Q   Median       3Q      Max
-17.1777  -9.5306  -0.9733   7.6840  22.2728

Coefficients:
        Estimate Std. Error t value Pr(>|t|)
(Intercept)  -2.0036     3.2488  -0.617    0.539
x1            5.3346     0.2861  18.646   <2e-16 ***
x2b           2.4952     5.2160   0.478    0.633
x1:x2b       -0.3833     0.4568  -0.839    0.404

summary(aptest)

Call:
lmp(formula = y ~ x1 * x2, data = test, perm = "", seqs = TRUE,
center = FALSE)

Residuals:
    Min       1Q   Median       3Q      Max
-17.1777  -9.5306  -0.9733   7.6840  22.2728

Coefficients:
   Estimate Std. Error t value Pr(>|t|)
x1       5.1429     0.2284  22.516   <2e-16 ***
x21     -1.2476     2.6080  -0.478    0.633
x1:x21   0.1917     0.2284   0.839    0.404

It looks like lmp() is internally coding dummy variables in a different way, so
lmp results are for "a" (named "1" by lmp) while lm results are for
"b" ?

 Agus


From anna.lampei-bucharova at uni-tuebingen.de  Fri Nov  8 09:48:59 2013
From: anna.lampei-bucharova at uni-tuebingen.de (a_lampei)
Date: Fri, 8 Nov 2013 00:48:59 -0800 (PST)
Subject: [R] problem with interaction in lmer even after creating an
 "interaction variable"
In-Reply-To: <loom.20131107T145540-295@post.gmane.org>
References: <1383822931873-4679951.post@n4.nabble.com>
	<loom.20131107T145540-295@post.gmane.org>
Message-ID: <527CA563.1020607@uni-tuebingen.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/db5cdd4e/attachment.pl>

From cyrus.shaoul at ualberta.ca  Thu Nov  7 13:46:38 2013
From: cyrus.shaoul at ualberta.ca (Cyrus Shaoul)
Date: Thu, 7 Nov 2013 13:46:38 +0100
Subject: [R] [R-pkgs] ndl 0.2.13 released today.
Message-ID: <CABtDUsT=Eu6UrYTo0g=5E2BUjw4y=3pnu1enzk7dorz7wty6hw@mail.gmail.com>

Dear R-package Folk,

I am pleased to announce the release of a new version of the ndl package (
http://cran.r-project.org/web/packages/ndl/)

What is NDL? It is a simple learning model based on the Rescorla-Wagner
model of discrimination learning.

I have become the new maintainer, replacing Dr. Antti Arppe (thank you for
all your hard work, Antti!)

This release is a major update. In particular the following items are new
since the last CRAN version (v 0.1.6 from Dec. 2012)

* improved speed in counting co-occurrence counts through the use of Rcpp
and C++ functions.
* improved scalability: it can process many millions of events, with much
larger numbers of cues and outcomes.
* support for Unicode text
* new ability to count background rates (optional)
* new method for converting counts to probabilities
-- and many other small improvements.

For access to the development branch, to join development,  or to submit
issues, please go to: https://bitbucket.org/cyrusshaoul/ndl/

Best regards,

Cyrus

-- 
Cyrus Shaoul, PhD
http://www.sfs.uni-tuebingen.de/~cshaoul/

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From mohan.radhakrishnan at polarisft.com  Fri Nov  8 10:01:19 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Fri, 8 Nov 2013 14:31:19 +0530
Subject: [R] Graph dashboard
Message-ID: <OF7558FE74.6FDE1D06-ON65257C1D.00311358-65257C1D.00318C1A@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/c5cdff41/attachment.pl>

From zulutime.net at gmail.com  Fri Nov  8 10:34:23 2013
From: zulutime.net at gmail.com (Magnus Thor Torfason)
Date: Fri, 08 Nov 2013 09:34:23 +0000
Subject: [R] Inserting 17M entries into env took 18h,
 inserting 34M entries taking 5+ days
In-Reply-To: <CAJ55+dLPe5uqyYVzi7qHh2w6GzfWBV6sm398qv7UENEPNmnALA@mail.gmail.com>
References: <5273AD7E.6090607@gmail.com>	<CAAxdm-6OV5U+CRC1=pGG9+CNkHig0bwRQe5D2tm+vzsN_f1Amg@mail.gmail.com>	<5273C73D.2090809@gmail.com>	<52742737.7020609@fhcrc.org>
	<CAJ55+dLPe5uqyYVzi7qHh2w6GzfWBV6sm398qv7UENEPNmnALA@mail.gmail.com>
Message-ID: <527CB01F.5000702@gmail.com>

Thanks to Thomas, Martin, Jim and William,

Your input was very informative, and thanks for the reference to Sedgwick.

In the end, it does seem to me that all these algorithms require fast 
lookup by ID of nodes to access data, and that conditional on such fast 
lookup, algorithms are possible with efficiency O(n) or O(n*log(n)) 
(depending on whether lookup time is constant or logarithmic). I believe 
my original algorithm achieves that.

We come back to the fact that I assumed that R environments, implemented 
as hash tables, would give me that fast lookup. But on my systems, their 
efficiency (for insert and lookup) seems to degrade fast at several 
million entries. Certainly much faster than either O(1) or O(log(n)). I 
believe this does not have to do with disk access time. For example, I 
tested this on my desktop computer, running a pure hash insert loop. I 
observe 100% processor use but no disk access, as the size of the hash 
table approaches millions of entries.

I have tested this on two systems, but have not gone into the 
implementation of the hashed environments to look at this in details. If 
others have the same (or different) experiences with using hashed 
environments with millions of entries, it would be very useful to know.

Barring a solution to the hashed environment speed, it seems the way to 
speed this algorithm up (within the confines of R) would be to move away 
from hash tables and towards a numerically indexed array.

Thanks again for all of the help,
Magnus

On 11/4/2013 8:20 PM, Thomas Lumley wrote:
> On Sat, Nov 2, 2013 at 11:12 AM, Martin Morgan <mtmorgan at fhcrc.org
> <mailto:mtmorgan at fhcrc.org>> wrote:
>
>     On 11/01/2013 08:22 AM, Magnus Thor Torfason wrote:
>
>         Sure,
>
>         I was attempting to be concise and boiling it down to what I saw
>         as the root
>         issue, but you are right, I could have taken it a step further.
>         So here goes.
>
>         I have a set of around around 20M string pairs. A given string
>         (say, A) can
>         either be equivalent to another string (B) or not. If A and B
>         occur together in
>         the same pair, they are equivalent. But equivalence is
>         transitive, so if A and B
>         occur together in one pair, and A and C occur together in
>         another pair, then A
>         and C are also equivalent. I need a way to quickly determine if
>         any two strings
>         from my data set are equivalent or not.
>
>
>     Do you mean that if A,B occur together and B,C occur together, then
>     A,B and A,C are equivalent?
>
>     Here's a function that returns a unique identifier (not well
>     tested!), allowing for transitive relations but not circularity.
>
>           uid <- function(x, y)
>          {
>              i <- seq_along(x)                   # global index
>              xy <- paste0(x, y)                  # make unique identifiers
>              idx <- match(xy, xy)
>
>              repeat {
>                  ## transitive look-up
>                  y_idx <- match(y[idx], x)       # look up 'y' in 'x'
>                  keep <- !is.na <http://is.na>(y_idx)
>                  if (!any(keep))                 # no transitive
>     relations, done!
>                      break
>                  x[idx[keep]] <- x[y_idx[keep]]
>                  y[idx[keep]] <- y[y_idx[keep]]
>
>                  ## create new index of values
>                  xy <- paste0(x, y)
>                  idx <- match(xy, xy)
>              }
>              idx
>          }
>
>     Values with the same index are identical. Some tests
>
>          > x <- c(1, 2, 3, 4)
>          > y <- c(2, 3, 5, 6)
>          > uid(x, y)
>          [1] 1 1 1 4
>          > i <- sample(x); uid(x[i], y[i])
>          [1] 1 1 3 1
>          > uid(as.character(x), as.character(y))  ## character() ok
>          [1] 1 1 1 4
>          > uid(1:10, 1 + 1:10)
>           [1] 1 1 1 1 1 1 1 1 1 1
>          > uid(integer(), integer())
>          integer(0)
>          > x <- c(1, 2, 3)
>          > y <- c(2, 3, 1)
>          > uid(x, y)                              ## circular!
>            C-c C-c
>
>     I think this will scale well enough, but the worst-case scenario can
>     be made to be log(longest chain) and copying can be reduced by using
>     an index i and subsetting the original vector on each iteration. I
>     think you could test for circularity by checking that the updated x
>     are not a permutation of the kept x, all(x[y_idx[keep]] %in% x[keep]))
>
>     Martin
>
>
>
> This problem (union-find) is discussed in Chapter 1 of Sedgwick's
> "Algorithms".  There's an algorithm given that takes linear time to
> build the structure, worst-case logarithmic time to query, and
> effectively constant average time to query (inverse-Ackerman amortized
> complexity).
>
>     -thomas
>
> --
> Thomas Lumley
> Professor of Biostatistics
> University of Auckland


From pollaroid at gmail.com  Fri Nov  8 10:40:53 2013
From: pollaroid at gmail.com (Kuma Raj)
Date: Fri, 8 Nov 2013 10:40:53 +0100
Subject: [R] Remove a column of a matrix with unnamed column header
Message-ID: <CAAC1QdAA-8s4sUCwm7cp2n4kJjktMDL3wHMA08vhGQ+H8Oo5ig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/2748619a/attachment.pl>

From studerov at gmail.com  Fri Nov  8 11:10:27 2013
From: studerov at gmail.com (David Studer)
Date: Fri, 8 Nov 2013 11:10:27 +0100
Subject: [R] Crime hotspot maps (kernel density)
Message-ID: <CAA1twZSAtO8yP4-Ma0VWaofmUbrAeD1c1u=1xDtKJvc1ka+nBQ@mail.gmail.com>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/d061e55c/attachment.pl>

From jholtman at gmail.com  Fri Nov  8 11:29:45 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Fri, 8 Nov 2013 05:29:45 -0500
Subject: [R] prod and F90 product
In-Reply-To: <527C24CA.5060101@gmail.com>
References: <527C24CA.5060101@gmail.com>
Message-ID: <AA2EE19E-FDAB-4537-9804-29FAA965B78F@gmail.com>

sounds like FAQ 7.31

Sent from my iPad

On Nov 7, 2013, at 18:39, Filippo <ingfimo at gmail.com> wrote:

> Hi,
> I'm having strange differences between the R function prod ad the F90 function product.
> Processing the same vector C (see attachment). I get 2 different results:
> prod(C) = 1.069678e-307
> testProduct(C) = 0
> 
> where testProd is the following wrapping function:
> 
> testProd <- function(x) {
>    return(.Fortran('testProd', as.double(x), as.double(0), as.double(0), as.integer(length(x))))
> }
> 
> subroutine testProd(x, p, q,  n)
>    implicit none
>    integer, intent (in) :: n
>    double precision, intent (in) :: x(n)
>    double precision, intent (out) :: p
>    double precision, intent (out) :: q
>    integer :: i
> 
>    p = product(x)
>    q=1
>    do i = 1, n
>        q = q*x(i)
>    end do
> end subroutine testProd
> 
> I check the lowest possible number and seems to be the same for both R and F90.
> Can anyone help me understanding this behaviour?
> Thank you in advance
> Regards,
> Filippo
> 
> <C>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Fri Nov  8 11:31:57 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 8 Nov 2013 11:31:57 +0100
Subject: [R] Remove a column of a matrix with unnamed column header
In-Reply-To: <CAAC1QdAA-8s4sUCwm7cp2n4kJjktMDL3wHMA08vhGQ+H8Oo5ig@mail.gmail.com>
References: <CAAC1QdAA-8s4sUCwm7cp2n4kJjktMDL3wHMA08vhGQ+H8Oo5ig@mail.gmail.com>
Message-ID: <70FEE293-FBF5-48B6-A98D-5B7B8E3BB83E@xs4all.nl>


On 08-11-2013, at 10:40, Kuma Raj <pollaroid at gmail.com> wrote:

> I have a matrix names test which I want to convert to a data frame. When I
> use a command  test2<-as.data.frame(test) it is executed without a problem.
> But when I want to browse the content I receive an error message "Error in
> data.frame(outcome = c("cardva", "respir", "cereb", "neoplasm",  :
> duplicate row.names: Estimate" . The problem is clearly due to a duplicate
> in  row name . But I am unable to remove this column. I need help on how to
> remove this specific column that has essentially no column header name.
> dput of the matrix is here:
> 
>> dput(test)
> structure(c("cardva", "respir", "cereb", "neoplasm", "ami", "ischem",
> "heartf", "pneumo", "copd", "asthma", "dysrhy", "diabet",
> "0.00259492159959046",
> "0.00979775441709427", "0.00103414632535868", "0.00486468139227382",
> "0.0164825543879707", "0.0116647168053943", "-0.0012137908515233",
> "0.00730433232907741", "0.00355583994565985", "0.000712387285735019",
> "-0.00103763671307935", "0.00981500221106926", "0.00325476724733837",
> "0.0049232113728293", "0.00520118026087645", "0.00386848394426742",
> "0.00688121694253705", "0.00585772614064902", "0.00564983058883797",
> "0.0061328202328586", "0.0108212194251692", "0.0173804438930357",
> "0.00867931407250442", "0.0106638104533486", "0.425323120845664",
> "0.0466180768654915", "0.842402292743715", "0.208609687427072",
> "0.0166336682608816", "0.0464833846710956", "0.8299010611324",
> "0.233685747699204", "0.742469001175026", "0.967306766450795",
> "0.904840885401235", "0.357394700741248"), .Dim = c(12L, 4L), .Dimnames =
> list(
>    c("Estimate", "Estimate", "Estimate", "Estimate", "Estimate",
>    "Estimate", "Estimate", "Estimate", "Estimate", "Estimate",
>    "Estimate", "Estimate"), c("outcome", "beta", "se", "pval"
>    )))
> 
>> test2<-as.data.frame(test)
>> test2
> Error in data.frame(outcome = c("cardva", "respir", "cereb", "neoplasm",  :
>  duplicate row.names: Estimate

rownames(test) <- NULL

Berend


From pollaroid at gmail.com  Fri Nov  8 12:22:11 2013
From: pollaroid at gmail.com (Kuma Raj)
Date: Fri, 8 Nov 2013 12:22:11 +0100
Subject: [R] Remove a column of a matrix with unnamed column header
In-Reply-To: <70FEE293-FBF5-48B6-A98D-5B7B8E3BB83E@xs4all.nl>
References: <CAAC1QdAA-8s4sUCwm7cp2n4kJjktMDL3wHMA08vhGQ+H8Oo5ig@mail.gmail.com>
	<70FEE293-FBF5-48B6-A98D-5B7B8E3BB83E@xs4all.nl>
Message-ID: <CAAC1QdCXaNwOFJNwKiPDGFNrUfTywbUbqgGszS_6_G7D-SYQzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/b3dc2ea8/attachment.pl>

From k.barton at abdn.ac.uk  Fri Nov  8 12:35:21 2013
From: k.barton at abdn.ac.uk (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Fri, 8 Nov 2013 11:35:21 +0000
Subject: [R] Error running MuMIn dredge function using glmer models
In-Reply-To: <mailman.29.1383908408.8209.r-help@r-project.org>
References: <mailman.29.1383908408.8209.r-help@r-project.org>
Message-ID: <527CCC79.8010407@abdn.ac.uk>

There is indeed a glitch in 'dredge' that prevents you from seeing the
actual error message. It is explained in "?dredge", in section "Missing
values". (it's been corrected now in 1.9.14, on R-forge)

kamil



On 2013-11-08 11:00, r-help-request at r-project.org wrote:
> ------------------------------
>
> Message: 26
> Date: Thu, 7 Nov 2013 11:55:50 -0500
> From: Martin Turcotte<mart.turcotte at gmail.com>
> To:r-help at r-project.org
> Subject: [R] Error running MuMIn dredge function using glmer models
> Message-ID:<1E4F5497-CCB4-4E8B-A23A-8AA5E1136DAE at gmail.com>
> Content-Type: text/plain
>
> Dear list,
> I am trying to use MuMIn to compare all possible mixed models using the dredge function on binomial data but I am getting an error message that I cannot decode. This error only occurs when I use glmer. When I use an lmer analysis on a different response variable every works great.
>
> Example using a simplified glmer model
> global model:
> mod<- glmer(cbind(st$X2.REP.LIVE, st$X2.REP.DEAD) ~ DOMESTICATION*GLUC + (1|PAIR), data=st, na.action=na.omit , family=binomial)
>
> The response variables are the number of survival and dead insects (successes and failures)
> DOMESTICATION is a 2 level factor.
> GLUC is a continuous variable.
> PAIR is coded as a factor or character (both ways fail).
>
> This model functions correctly but when I try it with dredge() I get an error.
>
> g<- dredge(mod, beta=F, evaluate=F, rank='AIC')
> Error in sprintf(gettext(fmt, domain = domain), ...) :
>    invalid type of argument[1]: 'symbol'
>
> When I try with another rank the same thing happens:
> chat<- deviance(mod)/58
> g<- dredge(mod, beta=F, evaluate=F, rank='QAIC', chat=chat)
> Error in sprintf(gettext(fmt, domain = domain), ...) :
>    invalid type of argument[1]: 'symbol'
>
> Any suggestions would be greatly appreciated
>
> thanks
>
> Martin Turcotte, Ph. D.
> mart.turcotte at gmail.com





The University of Aberdeen is a charity registered in Scotland, No SC013683.


From veedeehjay at googlemail.com  Fri Nov  8 12:49:14 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Fri, 08 Nov 2013 12:49:14 +0100
Subject: [R] how to derive true surface area from `computeContour3d' (misc3d
 package)
Message-ID: <op.w58a4cs3p7eajd@marco.fz-rossendorf.de>

I want to compute the total surface area of an isosurface in 3D space as  
approximated with
`computeContour3d' by adding up the areas of the triangles making up the
contour surface.

problem:
the vertex matrix returned by `computeContour3d' in general seems to  
provide the vertices
not in the frame of reference in which the original data are given but  
apparently rather
after some linear transformation (scaling + translation (+ rotation?) -- or
I am having some fundamental misconception of what is going on.

I'm interested in the simplest case where the input data are provided as a  
3D array
on an equidistant grid (i.e. leaving the x,y,z arguments at their  
defaults).

e.g. (slight modification of `example(computeContour3d)'):

library(misc3d)
x <- seq(-1,1,len=11)
g <- expand.grid(x = x, y = x, z = x)
v <- array(g$x^4 + g$y^4 + g$z^4, rep(length(x),3))
con <- computeContour3d(v, max(v), 1)
drawScene(makeTriangles(con))

this is (approximately) a cube with edge length 10 (taking the grid  
spacing as the unit of length).
so the expected (approximate) surface area is 600.

indeed,

apply(con, 2, range) yields

      [,1] [,2] [,3]
[1,]    1    1    1
[2,]   11   11   11

which might be interpreted as providing the vertices in coordinates
where the grid spacing is used as unit of length. however
I get an area of only about 430 instead of approx. 600 which is already a  
much much larger deviation
 from the ideal cube surface than I would have expected given the small  
amount of smoothing at the
box edges and corners (but I have to double-check whether my triangle area  
computation is right, although I believe it is).

choosing instead

x <- seq(-2,2,len=50)

however, the corresponding range of `con' is

       [,1]   [,2]   [,3]
[1,] 13.274 13.274 13.274
[2,] 37.726 37.726 37.726

which cannot be the "grid coordinates" (which should be in the range  
[1,50]). adopting this interpretation nevertheless
(vertices are given in grid coordinates)
the sum of the triangle areas only amounts to about 2600 instead of the  
expected approx. 49^2*6 = 14406

question 1:
am I making a stupid error (if so which one...)?

if not so:

question 2:
is there a linear transformation from the original grid coordinates (with  
range from 1 to dim(v)[n], n=1:3)
involved which yields the reported vertex coordinates?

question 3:
could someone please explain where to find this information (even if  
hidden in the source code of the package)
how to convert the vertex coordinates as delivered by `computeContour3D'  
to 'grid coordinates' (or true world coordinates
in general (if the x,y,z arguments are specified, too)?

for the wishlist: it would of course be nice if `computeContour3d' would  
indeed return the total surface area itself,
e.g. as an attribute of the triangles matrix.

for the devs: there is a typo in the manpage of this function:
Value:

      A matrix of three columns representing the triangles making up the
      contour surface. Each row represents a vertex and goups of three
      rows represent a triangle.

(should be `groups' instead of `goups')

--


From veedeehjay at googlemail.com  Fri Nov  8 14:01:23 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Fri, 08 Nov 2013 14:01:23 +0100
Subject: [R] how to derive true surface area from `computeContour3d' (misc3d
 package) -- follow up
Message-ID: <op.w58eglz6p7eajd@marco.fz-rossendorf.de>

regarding my previous mail for this topic, I have in the meantime  
identified my misconception.


actually, `computeContour3d' returns the vertices just fine in the correct  
coordinate frame.

the misconception was caused basically by assuming that the `level'  
argument was a fractional
threshold relative to the maximum of the array. so I believed that the  
rendered cube actually
is the "outer surface" of the defined object in the example provided in  
the manpage.

I know understandt it's an absolute level and `example(computeContour3d)'  
consequently displays
some "interior" isocontour. this explains all my apparent errors.

I believe the manpage would benefit from a slight clarification that  
`level' actually is
an absolute, not a relative/fractional threshold.

apologies for the noise.

j.

ps: it of course would still be nice, if the surface area (or a vector  
containing the individual triangle areas)
were returned to the caller as well ...


From bbolker at gmail.com  Fri Nov  8 15:26:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 8 Nov 2013 14:26:54 +0000
Subject: [R] problem with interaction in lmer even after creating an
	"interaction variable"
References: <1383822931873-4679951.post@n4.nabble.com>
	<loom.20131107T145540-295@post.gmane.org>
	<527CA563.1020607@uni-tuebingen.de>
Message-ID: <loom.20131108T152555-868@post.gmane.org>

a_lampei <anna.lampei-bucharova <at> uni-tuebingen.de> writes:

> 
> Thank you very much,
> First, sorry for posting on wrong mailing list, I did not know that 
> there exists a special one for lmer.
> Yes, there are collinearities in the data.
> Still, I would like to have the variables in one model to compare 
> explained variability. Is there some option, or it is simply impossible?
> Thank you, Anna

  The development version of lme4 has an (experimental) feature
that automatically removes collinear columns of the model matrix;
you could try that.

  Further discussion on r-sig-mixed-models ...

  Ben Bolker


From b.rowlingson at lancaster.ac.uk  Fri Nov  8 15:32:00 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 8 Nov 2013 14:32:00 +0000
Subject: [R] how to derive true surface area from `computeContour3d'
 (misc3d package) -- follow up
In-Reply-To: <e2beb18b22534675afed3a8109d66e5d@EX-0-HT0.lancs.local>
References: <e2beb18b22534675afed3a8109d66e5d@EX-0-HT0.lancs.local>
Message-ID: <CANVKczOnoniLMqNy=hjpw-Uh_Evk0dBiQ3jMnv4gBO34NTdSxw@mail.gmail.com>

On Fri, Nov 8, 2013 at 1:01 PM, j. van den hoff
<veedeehjay at googlemail.com> wrote:


> ps: it of course would still be nice, if the surface area (or a vector
> containing the individual triangle areas)
> were returned to the caller as well ...

 Does the 'surfaceArea' function in the sp package do what you want?
It's Edzer's integration of an R function that I wrote that calls some
C code that someone else wrote that implements an algorithm from 2004.

 You just need to coerce your grid data into the right form.

 Barry


From veedeehjay at googlemail.com  Fri Nov  8 16:11:08 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Fri, 08 Nov 2013 16:11:08 +0100
Subject: [R] how to derive true surface area from `computeContour3d'
 (misc3d package) -- follow up
In-Reply-To: <CANVKczOnoniLMqNy=hjpw-Uh_Evk0dBiQ3jMnv4gBO34NTdSxw@mail.gmail.com>
References: <e2beb18b22534675afed3a8109d66e5d@EX-0-HT0.lancs.local>
	<CANVKczOnoniLMqNy=hjpw-Uh_Evk0dBiQ3jMnv4gBO34NTdSxw@mail.gmail.com>
Message-ID: <op.w58kguwlp7eajd@marco.fz-rossendorf.de>

On Fri, 08 Nov 2013 15:32:00 +0100, Barry Rowlingson  
<b.rowlingson at lancaster.ac.uk> wrote:

> On Fri, Nov 8, 2013 at 1:01 PM, j. van den hoff
> <veedeehjay at googlemail.com> wrote:
>
>
>> ps: it of course would still be nice, if the surface area (or a vector
>> containing the individual triangle areas)
>> were returned to the caller as well ...
>
>  Does the 'surfaceArea' function in the sp package do what you want?
> It's Edzer's integration of an R function that I wrote that calls some
> C code that someone else wrote that implements an algorithm from 2004.
>
>  You just need to coerce your grid data into the right form.

not quite, I believe: I need to compute the area of a (closed) iso-surface  
of a 3D object
defined by samples on a discrete 3D grid.
if I understand correctly from a quick view on `sp', `surfaceArea' does  
compute
the surface integral of some function  z = f(x,y), instead.

but thanks for the pointer anyway, this might still be useful in a  
different context.

joerg


>
>  Barry


--


From smartpink111 at yahoo.com  Fri Nov  8 14:09:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 8 Nov 2013 05:09:53 -0800 (PST)
Subject: [R] Remove a column of a matrix with unnamed column header
In-Reply-To: <CAAC1QdCXaNwOFJNwKiPDGFNrUfTywbUbqgGszS_6_G7D-SYQzQ@mail.gmail.com>
References: <CAAC1QdAA-8s4sUCwm7cp2n4kJjktMDL3wHMA08vhGQ+H8Oo5ig@mail.gmail.com>	<70FEE293-FBF5-48B6-A98D-5B7B8E3BB83E@xs4all.nl>
	<CAAC1QdCXaNwOFJNwKiPDGFNrUfTywbUbqgGszS_6_G7D-SYQzQ@mail.gmail.com>
Message-ID: <1383916193.59215.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
?test2 <- as.data.frame(test,stringsAsFactors=FALSE)
test2[,c(2:4)] <- lapply(test2[,c(2:4)],as.numeric)
A.K.




On Friday, November 8, 2013 6:24 AM, Kuma Raj <pollaroid at gmail.com> wrote:
Beend, Thanks for that. Conversion of test to a data frame resulted in a
factor. Is there a possibility to selectively convert to numeric??  I have
tried this code and that has not produced the intended result.
test[, c(2:4)] <- sapply(test[, c(2:4)], as.numeric)



On 8 November 2013 11:31, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> On 08-11-2013, at 10:40, Kuma Raj <pollaroid at gmail.com> wrote:
>
> > I have a matrix names test which I want to convert to a data frame. When
> I
> > use a command? test2<-as.data.frame(test) it is executed without a
> problem.
> > But when I want to browse the content I receive an error message "Error
> in
> > data.frame(outcome = c("cardva", "respir", "cereb", "neoplasm",? :
> > duplicate row.names: Estimate" . The problem is clearly due to a
> duplicate
> > in? row name . But I am unable to remove this column. I need help on how
> to
> > remove this specific column that has essentially no column header name.
> > dput of the matrix is here:
> >
> >> dput(test)
> > structure(c("cardva", "respir", "cereb", "neoplasm", "ami", "ischem",
> > "heartf", "pneumo", "copd", "asthma", "dysrhy", "diabet",
> > "0.00259492159959046",
> > "0.00979775441709427", "0.00103414632535868", "0.00486468139227382",
> > "0.0164825543879707", "0.0116647168053943", "-0.0012137908515233",
> > "0.00730433232907741", "0.00355583994565985", "0.000712387285735019",
> > "-0.00103763671307935", "0.00981500221106926", "0.00325476724733837",
> > "0.0049232113728293", "0.00520118026087645", "0.00386848394426742",
> > "0.00688121694253705", "0.00585772614064902", "0.00564983058883797",
> > "0.0061328202328586", "0.0108212194251692", "0.0173804438930357",
> > "0.00867931407250442", "0.0106638104533486", "0.425323120845664",
> > "0.0466180768654915", "0.842402292743715", "0.208609687427072",
> > "0.0166336682608816", "0.0464833846710956", "0.8299010611324",
> > "0.233685747699204", "0.742469001175026", "0.967306766450795",
> > "0.904840885401235", "0.357394700741248"), .Dim = c(12L, 4L), .Dimnames =
> > list(
> >? ? c("Estimate", "Estimate", "Estimate", "Estimate", "Estimate",
> >? ? "Estimate", "Estimate", "Estimate", "Estimate", "Estimate",
> >? ? "Estimate", "Estimate"), c("outcome", "beta", "se", "pval"
> >? ? )))
> >
> >> test2<-as.data.frame(test)
> >> test2
> > Error in data.frame(outcome = c("cardva", "respir", "cereb", "neoplasm",
>? :
> >? duplicate row.names: Estimate
>
> rownames(test) <- NULL
>
> Berend
>
>

??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From danica_714 at hotmail.com  Fri Nov  8 15:04:00 2013
From: danica_714 at hotmail.com (Danica Fabrigar)
Date: Fri, 8 Nov 2013 14:04:00 +0000
Subject: [R] SNPRelate: Plink conversion
Message-ID: <DUB124-W51FF67BC4475AC2109D9BA2F20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/726cfc8a/attachment.pl>

From gunter.berton at gene.com  Fri Nov  8 17:14:03 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Nov 2013 08:14:03 -0800
Subject: [R] SNPRelate: Plink conversion
In-Reply-To: <DUB124-W51FF67BC4475AC2109D9BA2F20@phx.gbl>
References: <DUB124-W51FF67BC4475AC2109D9BA2F20@phx.gbl>
Message-ID: <CACk-te07B3AgP_pVd91ax=a9ve5x4nk4QQPobL29+_TrNNGraA@mail.gmail.com>

Doesn't this belong on Bioconductor rather than here?

-- Bert

On Fri, Nov 8, 2013 at 6:04 AM, Danica Fabrigar <danica_714 at hotmail.com> wrote:
> Hi,
>
> Following my earlier posts about having problems performing a PCA, I have
> worked out what the problem is. The problem lies within the PLINK to gds
> conversion.
>
> It seems as though the SNPs are imported as "samples" and in turn, the
> samples are recognised as SNPs:
>
>>snpsgdsSummary("chr2L")
> Some values of snp.position are invalid (should be > 0)!
> Some values of snp.chromosome are invalid (should be finite and >=1)!
> Some of snp.allele are not standard! E.g, 2/-9
> The file name: chr2L
> The total number of samples: 2638506
> The total number of SNPs: 67
> SNP genotypes are stored in SNP-major mode.
> The number of valid samples: 2638506
> The number of valid SNPs: 0
>
>
> Anyone have any ideas on how to fix this?
>
> Thanks,
> Danica
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From mart.turcotte at gmail.com  Fri Nov  8 17:41:59 2013
From: mart.turcotte at gmail.com (Martin Turcotte)
Date: Fri, 8 Nov 2013 11:41:59 -0500
Subject: [R] Error running MuMIn dredge function using glmer models
In-Reply-To: <527CCC79.8010407@abdn.ac.uk>
References: <mailman.29.1383908408.8209.r-help@r-project.org>
	<527CCC79.8010407@abdn.ac.uk>
Message-ID: <0EB834FB-1ABA-4031-897B-580F27F231FD@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/f26ab407/attachment.pl>

From dcarlson at tamu.edu  Fri Nov  8 18:16:59 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 8 Nov 2013 11:16:59 -0600
Subject: [R] Uploading Google Spreadsheet data into R
In-Reply-To: <CABQyo87ON_6fuhYfEfuK2DZ0isJRxPyOskqGZzwOokSnSQOAqw@mail.gmail.com>
References: <CABQyo87ON_6fuhYfEfuK2DZ0isJRxPyOskqGZzwOokSnSQOAqw@mail.gmail.com>
Message-ID: <03db01cedca6$5563aa80$002aff80$@tamu.edu>

Stripping down to the bare essentials seems to get it. In
particular making the query just "select *" instead of "select *
where B!=''" works. You don't need the processing that the more
complicated Guardian web page requires. After loading the RCurl
package and creating the gsqAPI function:

>
tmp=gsqAPI("0AkvLBhzbLcz5dHljNGhUdmNJZ0dOdGJLTVRjTkRhTkE","selec
t *", 0)
> str(tmp)
'data.frame':   9 obs. of  3 variables:
 $ COL1: chr  "25/10/2013" "25/10/2013" "31/10/2013"
"31/10/2013" ...
 $ COL2: int  50 10 16 18 25 34 56 47 50
 $ COL3: chr  "TEXT" "TEXT TEXT" "TEXT" "TEXT" ...
> tmp
        COL1 COL2      COL3
1 25/10/2013   50      TEXT
2 25/10/2013   10 TEXT TEXT
3 31/10/2013   16      TEXT
4 31/10/2013   18      TEXT
5 31/10/2013   25 TEXT TEXT
6 31/10/2013   34      TEXT
7 31/10/2013   56      TEXT
8 31/10/2013   47      TEXT
9 31/10/2013   50      TEXT

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Luca Meyer
Sent: Friday, November 8, 2013 1:33 AM
To: r-help at r-project.org
Subject: [R] Uploading Google Spreadsheet data into R

Hello,

I am trying to upload data I have on a Google Spreadsheet within
R to
perform some analysis. I regularly update such data and need to
perform
data analysis in the quickiest possible way - i.e. without need
to publish
the data, so I was wondering how to make work this piece of code
(source
http://www.r-bloggers.com/datagrabbing-commonly-formatted-sheets
-from-a-google-spreadsheet-guardian-2014-university-guide-data/)
with my dataset (see
https://docs.google.com/spreadsheet/ccc?key=0AkvLBhzbLcz5dHljNGh
UdmNJZ0dOdGJLTVRjTkRhTkE#gid=0
):

library(RCurl)
gsqAPI = function(key,query,gid=0){
  tmp=getURL( paste(
sep="",'https://spreadsheets.google.com/tq?',
'tqx=out:csv','&tq=', curlEscape(query), '&key=', key, '&gid=',
gid),
ssl.verifypeer = FALSE )
  return( read.csv( textConnection( tmp ),  stringsAsFactors=F )
)
}
handler=function(key,i){
  tmp=gsqAPI(key,"select * where B!=''", i)
  subject=sub(".Rank",'',colnames(tmp)[1])
  colnames(tmp)[1]="Subject.Rank"
  tmp$subject=subject
  tmp
}
key='0AkvLBhzbLcz5dHljNGhUdmNJZ0dOdGJLTVRjTkRhTkE'
gdata=handler(key,0)

The code is currently returning  the following:

Error in `$<-.data.frame`(`*tmp*`, "subject", value = "COL1") :
  replacement has 1 row, data has 0

Thank you in advance,
Luca

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From lucam1968 at gmail.com  Fri Nov  8 18:24:14 2013
From: lucam1968 at gmail.com (Luca Meyer)
Date: Fri, 8 Nov 2013 18:24:14 +0100
Subject: [R] Uploading Google Spreadsheet data into R
In-Reply-To: <03db01cedca6$5563aa80$002aff80$@tamu.edu>
References: <CABQyo87ON_6fuhYfEfuK2DZ0isJRxPyOskqGZzwOokSnSQOAqw@mail.gmail.com>
	<03db01cedca6$5563aa80$002aff80$@tamu.edu>
Message-ID: <CABQyo84tZYA1w=ecoO-4VAWfTG9h2p90zuzTzr3Er3QTD70JOg@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/24c7c4cd/attachment.pl>

From zilefacelvis at yahoo.com  Fri Nov  8 18:33:35 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 8 Nov 2013 09:33:35 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
Message-ID: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/2cc37122/attachment.pl>

From r.rigby at londonmet.ac.uk  Fri Nov  8 18:34:50 2013
From: r.rigby at londonmet.ac.uk (Robert Rigby)
Date: Fri, 8 Nov 2013 17:34:50 +0000
Subject: [R] Nonnormal Residuals and GAMs
Message-ID: <CAKmh6oGrtw1NKzveN5bKgQorjADmZjjFA7HTUaouFJDEGiGoHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/da3b85a0/attachment.pl>

From sarah.goslee at gmail.com  Fri Nov  8 18:40:46 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Nov 2013 12:40:46 -0500
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <CAM_vjummj-OY5MSGkVKrEaxsaAwEQ8Tp-GkVtUmn4vBbM_71mA@mail.gmail.com>

How do you decide which ones you need?

Is there some pattern that lets you distinguish needing df.txt from
not needing ds.txt?

You say you "have the names" - how do you have them? In a text file?

What are you trying to do with the text files?

Sarah

On Fri, Nov 8, 2013 at 12:33 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Hi,
> I have 300 .txt files in a directory. Out of this 300, I need just 100 of the files.
> I have the names of the 100 .txt files which are also found in the 300 .txt files.
> How can I extract only the 100 .txt files from the 300 ,txt files?
>
> e.g given d1.txt, ds.txt, dx.txt, df.txt...d300.txt, how can I select only d1.txt and df.txt? Remember, I have 300 of such and want to extract 100 of them with names known.
>
> Thanks for your great help.
> Atem.

-- 
Sarah Goslee
http://www.functionaldiversity.org


From szehnder at uni-bonn.de  Fri Nov  8 18:44:55 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 8 Nov 2013 18:44:55 +0100
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>

I do not understand the question. If you already know the names what is the problem to select the files by names? 

If you have the names but not inside of R you have to find a name pattern to avoid typing them in. Is there a pattern, e.g. da.txt, db.txt, dc.txt? 


On 08 Nov 2013, at 18:33, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

> Hi,
> I have 300 .txt files in a directory. Out of this 300, I need just 100 of the files.
> I have the names of the 100 .txt files which are also found in the 300 .txt files.
> How can I extract only the 100 .txt files from the 300 ,txt files?
> 
> e.g given d1.txt, ds.txt, dx.txt, df.txt...d300.txt, how can I select only d1.txt and df.txt? Remember, I have 300 of such and want to extract 100 of them with names known.
> 
> Thanks for your great help.
> Atem.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Fri Nov  8 18:50:43 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Nov 2013 09:50:43 -0800
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <CACk-te2DBejkdrKFko3-orV-7sFKk2oWzwaF6iqr9wxHBkhfXw@mail.gmail.com>

1. Please don't post in HTML (see posting guide).

2. What do you mean by "extract?"

3. Your qiestion sounds very basic. Have you read "An Introduction to
R" or other online R tutorial? If not please do so before posting
further. All of R's file input functions allow you to specify the
directory path and/or filename, so if I understand you correctly, it's
just a matter of giving them to the appropriate function in some sort
of loop. e.g. something like

alldat <- lapply(filenameList, function(x)InputFunction(x,...))

4. If you need something fancier than is described in the tutorials,
consult the "R data Import/Export manual,"  please.

-- Bert

On Fri, Nov 8, 2013 at 9:33 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Hi,
> I have 300 .txt files in a directory. Out of this 300, I need just 100 of the files.
> I have the names of the 100 .txt files which are also found in the 300 .txt files.
> How can I extract only the 100 .txt files from the 300 ,txt files?
>
> e.g given d1.txt, ds.txt, dx.txt, df.txt...d300.txt, how can I select only d1.txt and df.txt? Remember, I have 300 of such and want to extract 100 of them with names known.
>
> Thanks for your great help.
> Atem.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From zilefacelvis at yahoo.com  Fri Nov  8 18:51:24 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 8 Nov 2013 09:51:24 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
Message-ID: <1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/04525c02/attachment.pl>

From szehnder at uni-bonn.de  Fri Nov  8 18:54:22 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 8 Nov 2013 18:54:22 +0100
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
Message-ID: <40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>

If you want to type in the names by hand, you can simply use read.table to load them into R ? I still don?t get the aim of your text file handling


On 08 Nov 2013, at 18:51, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

> All files are text files. They are found in a folder on my computer. 
> Assume that I know the names of some of the files I want to select from the 300 txt files.
> How can I do this in R.
> Atem.
> 
> 
> On Friday, November 8, 2013 11:44 AM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
> I do not understand the question. If you already know the names what is the problem to select the files by names? 
> 
> If you have the names but not inside of R you have to find a name pattern to avoid typing them in. Is there a pattern, e.g. da.txt, db.txt, dc.txt? 
> 
> 
> On 08 Nov 2013, at 18:33, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> 
> > Hi,
> > I have 300 .txt files in a directory. Out of this 300, I need just 100 of the files.
> > I have the names of the 100 .txt files which are also found in the 300 .txt files.
> > How can I extract only the 100 .txt files from the 300 ,txt files?
> > 
> > e.g given d1.txt, ds.txt, dx.txt, df.txt...d300.txt, how can I select only d1.txt and df.txt? Remember, I have 300 of such and want to extract 100 of them with names known.
> > 
> > Thanks for your great help.
> > Atem.
> 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From domszi at gmail.com  Fri Nov  8 17:04:12 2013
From: domszi at gmail.com (=?ISO-8859-1?Q?Domokos_P=E9ter?=)
Date: Fri, 8 Nov 2013 17:04:12 +0100
Subject: [R] How to show the second abline ?
Message-ID: <CA+kXM-nScW_tAUU29GgXCpQcxYP=+0JE=PJW5PCyFo+ex1dhyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/6bf7b6a6/attachment.pl>

From danica_714 at hotmail.com  Fri Nov  8 17:31:27 2013
From: danica_714 at hotmail.com (Danica Fabrigar)
Date: Fri, 8 Nov 2013 16:31:27 +0000
Subject: [R] SNPRelate: Plink conversion
In-Reply-To: <CACk-te07B3AgP_pVd91ax=a9ve5x4nk4QQPobL29+_TrNNGraA@mail.gmail.com>
References: <DUB124-W51FF67BC4475AC2109D9BA2F20@phx.gbl>,
	<CACk-te07B3AgP_pVd91ax=a9ve5x4nk4QQPobL29+_TrNNGraA@mail.gmail.com>
Message-ID: <DUB124-W43DE27A98CE870A5EEFC57A2F20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/1dad2961/attachment.pl>

From jose.batista at nb.com  Fri Nov  8 18:10:38 2013
From: jose.batista at nb.com (Batista, Jose)
Date: Fri, 8 Nov 2013 17:10:38 +0000
Subject: [R] Adding Proxy information in 'R' application
Message-ID: <34E80CBD3A1FFB4096F09931DFFFA58F35C6356F@PIPWXCM212.nb.com>

R-Help Mailing List,

I'm currently working with a user who is actively trying to download & install libraries for 'R' on her office PC. While using install.packages("packageName", dependencies = TRUE) works without a problem on our home PCs, we use a proxy at the firm and therefore it doesn't let the application go directly out of the network on port 80.  Is there a way to manually set proxy information within the application so that it can, indeed, reach the internet when we're trying to download and install libraries (and necessary dependencies) from within the application?  I've gone through some of the options but there's nothing there for it.

Regards,
Jos? Emmanuel Batista



 
 
--------
If you are not an intended recipient of this e-mail, you are not authorized to duplicate, copy, retransmit or redistribute it by any means. Please delete it and any attachments immediately and notify the sender that you have received it in error. Unless specifically indicated, this e-mail is not an offer to buy or sell or a solicitation to buy or sell any securities, investment products or other financial product or service, an official confirmation of any transaction, or an official statement of Neuberger Berman. Any views or opinions presented are solely those of the author and do not necessarily represent those of Neuberger Berman. This e-mail is subject to terms available at the following link: www.nb.com/disclaimer/usa.html. By messaging with Neuberger Berman you consent to the foregoing.


From sarah.goslee at gmail.com  Fri Nov  8 19:20:29 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Nov 2013 13:20:29 -0500
Subject: [R] How to show the second abline ?
In-Reply-To: <CA+kXM-nScW_tAUU29GgXCpQcxYP=+0JE=PJW5PCyFo+ex1dhyg@mail.gmail.com>
References: <CA+kXM-nScW_tAUU29GgXCpQcxYP=+0JE=PJW5PCyFo+ex1dhyg@mail.gmail.com>
Message-ID: <CAM_vju=QQ+mM=aEJ_Dk9KPhj_W7hMF8FeRNexydb5o_gRTJ91A@mail.gmail.com>

I have no idea where gap.plot() came from, so I can't reproduce this,
but you almost certainly need

y ~ x

in your formula.

abline(coef(lm(y ~ x)),col=1)

Sarah

On Fri, Nov 8, 2013 at 11:04 AM, Domokos P?ter <domszi at gmail.com> wrote:
> Hi,
>
> I have the next script in R:
>
> x=c(8.0,17.5,23.5,32.0,38.5,48.5,58.5,68.5)
> y=c(267,246,290,294,302,301,301,298)
>
> gap.plot(x,y,ylim=c(8,310),pch=8,cex=0.5,
> xlab=c('Time'),ylab=c('uS'),
> gap=c(30,240),gap.axis='y',
> ytics=c(10,20,30,270,280,290,300))
> abline(h=31,col='white',lwd=20)
> axis.break(axis=2,31)
> axis.break(axis=4,31)
>
> abline(coef(lm(x~y)),col=1)#Why don't show this???
>
> Thank's for Your help,
> P?ter
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Fri Nov  8 19:39:47 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Nov 2013 13:39:47 -0500
Subject: [R] Fw:  select .txt from .txt in a directory
In-Reply-To: <1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <CAM_vju=4_5ZOtyENayrQk6aSrybV0fkxEmkn-P+0vndR2XpzKw@mail.gmail.com>

Hi,

I'm not particularly interested in opening unsolicited binary attachments.

Why don't you use dput() to provide part of your data to the R-help
list (copied on this email; emailing just me not being that useful).

You still haven't told us what you want to do with the named text
files - read them into R?

In general, you would read the file with the list of names into R,
then use a loop or a *apply construct to import each of those named
files. Based on what you've said, the fact that your desired list has
only 100 of the 300 total files is a red herring.

Sarah


On Fri, Nov 8, 2013 at 1:30 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Hi Sarah
> Attached are my data files.
> Btemperature_Stations is my main file.
> Temperature inventory is my 'wanted' file and is a subset of
> Btemperature_Stations.
> Using column 3 in both files, select the files in Temperature inventory from
> Btemperature_Stations.
> The .zip file contains the .txt files which you will extract to a folder and
> do the selection in R.
>
> Thanks,
> Atem.
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From david at revolutionanalytics.com  Fri Nov  8 19:52:47 2013
From: david at revolutionanalytics.com (David Smith)
Date: Fri, 8 Nov 2013 10:52:47 -0800
Subject: [R] Revolutions blog: October roundup
Message-ID: <CABgvEC-fH3bNKo8QzUGA-ARrAxctqc7NAU=KF2GD3VUaVWy8GA@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of October:

Joe Rickert recounts the R presence at the Strata + Hadoop World
conference, including slides from the R and Hadoop tutorial:
http://bit.ly/1acPavl

Hadley Wickham's favorite tools, gadgets and software (including of
course R): http://bit.ly/1acPavm

Revolution R Enterprise 7 is announced, including R 3.0.2: http://bit.ly/1acP8DM

I was interviewed on camera by theCUBE about R, data science, and
Revolution R Enterprise 7: http://bit.ly/1acP8DO

Patrick Burns shares some good reasons for switching from spreadsheets
to R for data analysis: http://bit.ly/1acP8DN

R is used for several sports-related analyses at the The New England
Symposium of Statistics in Sport: http://bit.ly/1acPavk

Some tips for using the .Rprofile file to customize your R session at
startup: http://bit.ly/1acP8DP

Quandl?s introduction to econometrics using R: http://bit.ly/1acPavr

Video replay of a recent webinar by DataSong on implementing
time-to-event models with Revolution R Enterprise:
http://bit.ly/1acP8DQ

Revolution R Enterprise is now integrated with Alteryx to provide a
drag-and-drop GUI workflow for R: http://bit.ly/1acPavt

An article in Forbes discusses using R from the Alteryx drag-and-drop
workflow interface: http://bit.ly/1acPavs

Joe Rickert reviews the sessions at the ACM 2013 Big Data Camp:
http://bit.ly/1acP8DR

The New York Times published an article on fantasy football analysis
with R: http://bit.ly/1acPaLG

The latest Rexer poll shows the use of R continues to skyrocket. It?s
the most popular data mining tool by a wide margin:
http://bit.ly/1acPaLH

Replays of two recent webinar presentations on using R on Hadoop,
presented by Cloudera http://bit.ly/1acPaLI and Hortonworks
http://bit.ly/1acP8U8 in conjunction with Revolution Analytics.

Tips and resources for using R for signal processing and time series
analysis: http://bit.ly/1acP8U7

The popular data-visualization software Tableau adds integration with
R: http://bit.ly/1acP8U5

An interactive web tool explains Simpson?s paradox: http://bit.ly/1acPaLJ

R-related presentations from the DataWeek 2013 conference, including
how an IBM division replaced SAS with R: http://bit.ly/1acP8U9

Some non-R stories in the past month included: remembering video
stores (http://bit.ly/1acP8Ub), some optical illusion trickery
(http://bit.ly/1acPaLK), better voting systems
(http://bit.ly/1acPaLL), a funny interpretation of air safety videos
(http://bit.ly/1acP8Ua) and a discussion on how to get ROT from
analytics (http://bit.ly/1acPaLM).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://bit.ly/MH2I2Q to be alerted to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From szehnder at uni-bonn.de  Fri Nov  8 19:59:59 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 8 Nov 2013 19:59:59 +0100
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <1D862CEF-7F88-461E-AFE3-20AF88F2494C@uni-bonn.de>

Elvis,

first, keep things on the list - so others can learn and comment. Second, as Sarah already commented: We do not like to open unsolicited binary attachments on the list. Sarah gives a good hint how to post data to the list.

What I would do so far is use the matching columns to get the names you need from BTemperature: 

temp_inv <- read.table("Temperature Inventory", ? ) (here I would change the .xlsx to a .csv and use read.csv instead of read.table)
btemp <- read.table(?BTemperature_Stations.txt?, ? ) (again think about converting via Excel to .csv - it makes things far more easy) 

Check ?read.table for options - you gonna need them.

Then match
mynames <- btemp[(temp_inv[,3] %in% btemp[, 3]), 2]

Now you have the names of the stations and if your .txt files are named by the stations you can do something like:

for (name in mynames) {
tmp.table <- read.table(paste(?path/to/your/Homog_daily_min_temp/?, name, ?.txt?, sep = ??), ? )
?. do things with the data
}



Best

Simon
 
On 08 Nov 2013, at 19:26, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

> Hi Simon,
> Attached are my data files.
> Btemperature_Stations is my main file.
> Temperature inventory is my 'wanted' file and is a subset of Btemperature_Stations.
> Using column 3 in both files, select the files in Temperature inventory from Btemperature_Stations.
> The .zip file contains the .txt files which you will extract to a folder and do the selection in R.
> 
> Thanks,
> Atem.
>  
> 
> 
> 
> 
> On Friday, November 8, 2013 11:54 AM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
> If you want to type in the names by hand, you can simply use read.table to load them into R ? I still don?t get the aim of your text file handling
> 
> 
> On 08 Nov 2013, at 18:51, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> 
> > All files are text files. They are found in a folder on my computer. 
> > Assume that I know the names of some of the files I want to select from the 300 txt files.
> > How can I do this in R.
> > Atem.
> > 
> > 
> > On Friday, November 8, 2013 11:44 AM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
> > I do not understand the question. If you already know the names what is the problem to select the files by names? 
> > 
> > If you have the names but not inside of R you have to find a name pattern to avoid typing them in. Is there a pattern, e.g. da.txt, db.txt, dc.txt? 
> > 
> > 
> > On 08 Nov 2013, at 18:33, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> > 
> > > Hi,
> > > I have 300 .txt files in a directory. Out of this 300, I need just 100 of the files.
> > > I have the names of the 100 .txt files which are also found in the 300 .txt files.
> > > How can I extract only the 100 .txt files from the 300 ,txt files?
> > > 
> > > e.g given d1.txt, ds.txt, dx.txt, df.txt...d300.txt, how can I select only d1.txt and df.txt? Remember, I have 300 of such and want to extract 100 of them with names known.
> > > 
> > > Thanks for your great help.
> > > Atem.
> > 
> > >    [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> > 
> 
> 
> <BTemperature_Stations.txt><Tempearture inventory.xlsx><Homog_daily_min_temp.zip>


From alemu.tadesse at gmail.com  Fri Nov  8 20:41:29 2013
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Fri, 8 Nov 2013 12:41:29 -0700
Subject: [R] Date handling in R is hard to understand
Message-ID: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/74969de4/attachment.pl>

From dwinsemius at comcast.net  Fri Nov  8 20:53:48 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Nov 2013 11:53:48 -0800
Subject: [R] C50 Node Assignment
Message-ID: <958B1386-C121-4084-95AE-038A5168918D@comcast.net>

In my role as a moderator I am attempting to bypass the automatic mail filters that are blocking this posting. Please reply to the list and to:
=========================
Kevin Shaney <kevin.shaney at rosetta.com>

C50 Node Assignment

I am using C50 to classify individuals into 5 groups / categories (factor variable).  The tree / set of rules has 10 rules for classification.  I am trying to extract the RULE for which each individual qualifies (a number between 1 and 10), and cannot figure out how to do so.  I can extract the predicted group and predicted group probability, but not the RULE to which an individual qualifies.  Please let me know if you can help!

Kevin
=========================


-- 
David Winsemius
Alameda, CA, USA


From carina.salt at googlemail.com  Fri Nov  8 21:10:51 2013
From: carina.salt at googlemail.com (Carina Salt)
Date: Fri, 8 Nov 2013 20:10:51 +0000
Subject: [R] Adding Proxy information in 'R' application
In-Reply-To: <34E80CBD3A1FFB4096F09931DFFFA58F35C6356F@PIPWXCM212.nb.com>
References: <34E80CBD3A1FFB4096F09931DFFFA58F35C6356F@PIPWXCM212.nb.com>
Message-ID: <CAB+PZ6DamfDCYD1Xp3iJLV5LTbFgzZnpyXBF4J+wd=XPg6221Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/3829dd29/attachment.pl>

From gunter.berton at gene.com  Fri Nov  8 21:12:25 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 8 Nov 2013 12:12:25 -0800
Subject: [R] Date handling in R is hard to understand
In-Reply-To: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
References: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
Message-ID: <CACk-te3Un0nKQPPM7SqsUbhD63EZX-_GbSjUTWTk-rM-ZDi15Q@mail.gmail.com>

Have a look at the "lubridate" package. It claims to try to make
dealing with dates easier.


-- Bert

On Fri, Nov 8, 2013 at 11:41 AM, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
> Dear All,
>
> I usually work with time series data. The data may come in AM/PM date
> format or on 24 hour time basis. R can not recognize the two differences
> automatically - at least for me. I have to specifically tell R in which
> time format the data is. It seems that Pandas knows how to handle date
> without being told the format. The problem arises when I try to shift time
> by a certain time. Say adding 3600 to shift it forward, that case I have to
> use something like:
> Measured_data$Date <- as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %I:%M %p")+3600
> or Measured_data$Date <- as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %H:%M")+3600  depending on the format. The date
> also attaches MDT or MST and so on. When merging two data frames  with
> dates of different format that may create a problem (I think). When I get
> data from excel it could be in any/random format and I needed to customize
> the date to use in R in one of the above formats. Any TIPS - for automatic
> processing with no need to specifically tell the data format ?
>
> Another problem I saw was that when using r bind to bind data frames, if
> one column of one of the data frames is a character data (say for example
> none - coming from mysql) format R doesn't know how to concatenate numeric
> column from the other data frame to it. I needed to change the numeric to
> character and later after binding takes place I had to re-convert it to
> numeric. But, this causes problem in an automated environment. Any
> suggestion ?
>
> Thanks
> Mihretu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From r.turner at auckland.ac.nz  Fri Nov  8 22:49:48 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 09 Nov 2013 10:49:48 +1300
Subject: [R] Crime hotspot maps (kernel density)
In-Reply-To: <CAA1twZSAtO8yP4-Ma0VWaofmUbrAeD1c1u=1xDtKJvc1ka+nBQ@mail.gmail.com>
References: <CAA1twZSAtO8yP4-Ma0VWaofmUbrAeD1c1u=1xDtKJvc1ka+nBQ@mail.gmail.com>
Message-ID: <527D5C7C.6000802@auckland.ac.nz>



It is not clear to me what you want/need to do, but it is possible that
the "spatstat" package (in particular the function density.ppp()) might
help you.

     cheers,

     Rolf Turner

On 11/08/13 23:10, David Studer wrote:
> Hi everybody,
>
> does anyone of you know how to create a (crime) hotspot map using R?
> Are there any packages or do you know any ressources?
>
> It should be something like this:
> http://www.caliper.com/Maptitude/Crime/MotorVehicleTheft2.png
> (but it doesnt necessarely have to be a map)


From jim at bitwrit.com.au  Sat Nov  9 00:01:26 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 09 Nov 2013 10:01:26 +1100
Subject: [R] How to show the second abline ?
In-Reply-To: <CA+kXM-nScW_tAUU29GgXCpQcxYP=+0JE=PJW5PCyFo+ex1dhyg@mail.gmail.com>
References: <CA+kXM-nScW_tAUU29GgXCpQcxYP=+0JE=PJW5PCyFo+ex1dhyg@mail.gmail.com>
Message-ID: <527D6D46.7080900@bitwrit.com.au>

On 11/09/2013 03:04 AM, Domokos P?ter wrote:
> Hi,
>
> I have the next script in R:
>
> x=c(8.0,17.5,23.5,32.0,38.5,48.5,58.5,68.5)
> y=c(267,246,290,294,302,301,301,298)
>
> gap.plot(x,y,ylim=c(8,310),pch=8,cex=0.5,
> xlab=c('Time'),ylab=c('uS'),
> gap=c(30,240),gap.axis='y',
> ytics=c(10,20,30,270,280,290,300))
> abline(h=31,col='white',lwd=20)
> axis.break(axis=2,31)
> axis.break(axis=4,31)
>
> abline(coef(lm(x~y)),col=1)#Why don't show this???
>
Hi Peter,
Perhaps because both of these numbers:

coef(lm(x~y))
  (Intercept)            y
-176.5047160    0.7425131

are off the scale of your plot. Do you really want:

lmcoef<-coef(lm(y~x))
abline(lmcoef[1]-210,lmcoef[2],col=1)

Jim


From jim at bitwrit.com.au  Sat Nov  9 00:05:59 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 09 Nov 2013 10:05:59 +1100
Subject: [R] Date handling in R is hard to understand
In-Reply-To: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
References: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
Message-ID: <527D6E57.2050903@bitwrit.com.au>

Hi Mihretu,
Can you grep for "AM" or "PM"? If so build your format string depending 
upon whether one of these exists in the date string.

Jim

On 11/09/2013 06:41 AM, Alemu Tadesse wrote:
> Dear All,
>
> I usually work with time series data. The data may come in AM/PM date
> format or on 24 hour time basis. R can not recognize the two differences
> automatically - at least for me. I have to specifically tell R in which
> time format the data is. It seems that Pandas knows how to handle date
> without being told the format. The problem arises when I try to shift time
> by a certain time. Say adding 3600 to shift it forward, that case I have to
> use something like:
> Measured_data$Date<- as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %I:%M %p")+3600
> or Measured_data$Date<- as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %H:%M")+3600  depending on the format. The date
> also attaches MDT or MST and so on. When merging two data frames  with
> dates of different format that may create a problem (I think). When I get
> data from excel it could be in any/random format and I needed to customize
> the date to use in R in one of the above formats. Any TIPS - for automatic
> processing with no need to specifically tell the data format ?
>
> Another problem I saw was that when using r bind to bind data frames, if
> one column of one of the data frames is a character data (say for example
> none - coming from mysql) format R doesn't know how to concatenate numeric
> column from the other data frame to it. I needed to change the numeric to
> character and later after binding takes place I had to re-convert it to
> numeric. But, this causes problem in an automated environment. Any
> suggestion ?
>
> Thanks
> Mihretu
>


From davidmarino838 at gmail.com  Sat Nov  9 01:53:34 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Fri, 8 Nov 2013 16:53:34 -0800
Subject: [R] Geweke Diagnostic in CODA package
Message-ID: <CABmD0bH07k-0OOyWY=naujB4-DoWiN_02Q8JrvLEZrNabsvM1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/04dd5c21/attachment.pl>

From smartpink111 at yahoo.com  Fri Nov  8 21:18:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 8 Nov 2013 12:18:03 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383936055.76561.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383936055.76561.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <1383941883.12484.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi Atem,

It is not clear what you wanted to do.? If you want to transfer the subset of files from the main folder to a new location, then you may try: (make sure you create a copy of the original .txt folder before doing this)
I created three sub folders and two files (BTemperature_Stations.txt and Tempearture inventory.csv) in my working directory.


list.files()
#[1] "BTemperature_Stations.txt" "Files1"????????? ## Files1 folder contains all the .txt files; #SubsetFiles: created to subset the files that match the condition???????????????? 
#[3] "FilesCopy"???????????????? "SubsetFiles1"????????? #FilesCopy. A copy of the Files1 folder?? 
#[5] "Tempearture inventory.csv"


?

list.files(pattern="\\.")
#[1] "BTemperature_Stations.txt" "Tempearture inventory.csv"
fl1 <- list.files(pattern="\\.")
?dat1 <- read.table(fl1[1],header=TRUE,sep="",stringsAsFactors=FALSE,fill=TRUE,check.names=FALSE)
?dat2 <- read.csv(fl1[2],header=TRUE,sep=",",stringsAsFactors=FALSE,check.names=FALSE)
vec1 <- dat1[,3][dat1[,3]%in% dat2[,3]]
vec2 <- list.files(path="/home/arunksa111/Zl/Files1",recursive=TRUE)
?sum(gsub(".txt","",vec2) %in% vec1)
#[1] 98
vec3 <-? vec2[gsub(".txt","",vec2) %in% vec1]
lapply(vec3, function(x) file.rename(paste("/home/arunksa111/Zl/Files1",x,sep="/"), paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"))) #change the path accordingly. 
length(list.files(path="/home/arunksa111/Zl/SubsetFiles1"))
#[1] 98

fileDim <- sapply(vec3,function(x) {x1 <-read.delim(paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"),header=TRUE,stringsAsFactors=FALSE,sep=",",check.names=FALSE); dim(x1)})
fileDim[,1:3]
#???? dn3011120.txt dn3011240.txt dn3011887.txt
#[1,]????????? 1151?????????? 791????????? 1054
#[2,]???????????? 7???????????? 7???????????? 7


A.K.





On Friday, November 8, 2013 1:41 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi AK,


I want to select some files from a list of files. All are text files. The index for selection is found in column 3 of both files.


Attached are my data files.
Btemperature_Stations is my main file.
Temperature inventory is my 'wanted' file and is a subset of Btemperature_Stations.
Using column 3 in both files, select the files in?Temperature inventory from?Btemperature_Stations.
The .zip file contains the .txt files which you will extract to a folder and do the selection in R.

Thanks,
Atem.


From hnorpois at gmail.com  Fri Nov  8 19:56:53 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Fri, 8 Nov 2013 19:56:53 +0100
Subject: [R] making chains from pairs
Message-ID: <CAKyZeBs4qMiBY=3yZ6W30x+imgL+LSxKNtPxW_hm=rzNF9B4=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/ff4e82d4/attachment.pl>

From hnorpois at gmail.com  Fri Nov  8 20:13:36 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Fri, 8 Nov 2013 20:13:36 +0100
Subject: [R] SNPRelate: Plink conversion
In-Reply-To: <DUB124-W43DE27A98CE870A5EEFC57A2F20@phx.gbl>
References: <DUB124-W51FF67BC4475AC2109D9BA2F20@phx.gbl>
	<CACk-te07B3AgP_pVd91ax=a9ve5x4nk4QQPobL29+_TrNNGraA@mail.gmail.com>
	<DUB124-W43DE27A98CE870A5EEFC57A2F20@phx.gbl>
Message-ID: <CAKyZeBtBAB2qPROuu2w_EtD0vjBfe=6YmoZs3aEAuwTRGoWZxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131108/d856cbe4/attachment.pl>

From smartpink111 at yahoo.com  Sat Nov  9 07:05:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 8 Nov 2013 22:05:56 -0800 (PST)
Subject: [R] Please help me to short my code
Message-ID: <1383977156.9454.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try either:
Ceramic <- read.table("ceramic.dat",header=TRUE)
Ceramic1 <- Ceramic
Ceramic$indx <- ((seq_len(nrow(Ceramic))-1)%/%60)+1
library(plyr)
DF1 <- data.frame(M=as.vector(t(ddply(Ceramic,.(indx), colwise(mean))[,-1])), S=as.vector(t(ddply(Ceramic,.(indx),colwise(sd))[,-1])),Rep = 60)
?colnames(DF)[3] <- colnames(DF1)[3]
?identical(DF,DF1)
#[1] TRUE


#or
?indx <- ((seq_len(nrow(Ceramic))-1)%/%60)+1
Ceramic2 <-? do.call(data.frame, c(aggregate(.~indx,data=Ceramic1,function(x) c(mean(x),sd(x))), check.names=FALSE))[,-1]
?DF2 <- data.frame(M= as.vector(t(Ceramic2[,seq(1,ncol(Ceramic2),by=2)])), S= as.vector(t(Ceramic2[,seq(2,ncol(Ceramic2),by=2)])),Rep =60)
identical(DF,DF2)
#[1] TRUE



A.K.


please help me to short the code 

#To import data onto R 
Ceramic<-read.table("D:/ceramic.dat",header=T) 
#to obtain mean, standard deviation and number of observations- 
LAB1<-Ceramic[1:60,] 
LAB2<-Ceramic[61:120,] 
LAB3<-Ceramic[121:180,] 
LAB4<-Ceramic[181:240,] 
LAB5<-Ceramic[241:300,] 
LAB6<-Ceramic[301:360,] 
LAB7<-Ceramic[361:420,] 
LAB8<-Ceramic[421:480,] 
M1<-sapply(LAB1,mean) 
M2<-sapply(LAB2,mean) 
M3<-sapply(LAB3,mean) 
M4<-sapply(LAB4,mean) 
M5<-sapply(LAB5,mean) 
M6<-sapply(LAB6,mean) 
M7<-sapply(LAB7,mean) 
M8<-sapply(LAB8,mean) 
S1<-sapply(LAB1,sd) 
S2<-sapply(LAB2,sd) 
S3<-sapply(LAB3,sd) 
S4<-sapply(LAB4,sd) 
S5<-sapply(LAB5,sd) 
S6<-sapply(LAB6,sd) 
S7<-sapply(LAB7,sd) 
S8<-sapply(LAB8,sd) 
#tabulating results- 
M<-c(M1,M2,M3,M4,M5,M6,M7,M8) 
S<-c(S1,S2,S3,S4,S5,S6,S7,S8) 
DF<-data.frame(M,S,c(rep(60)))


From dwinsemius at comcast.net  Sat Nov  9 09:55:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Nov 2013 00:55:25 -0800
Subject: [R] making chains from pairs
In-Reply-To: <CAKyZeBs4qMiBY=3yZ6W30x+imgL+LSxKNtPxW_hm=rzNF9B4=w@mail.gmail.com>
References: <CAKyZeBs4qMiBY=3yZ6W30x+imgL+LSxKNtPxW_hm=rzNF9B4=w@mail.gmail.com>
Message-ID: <459FDE38-00A3-45BB-8EFD-C64683798C49@comcast.net>


On Nov 8, 2013, at 10:56 AM, Hermann Norpois wrote:

> Hello,
> 
> having a data frame like test with pairs of characters I would like to
> create chains. For instance from the pairs A/B and B/I you get the vector A
> B I. It is like jumping from one pair to the next related pair. So for my
> example test you should get:
> A B F G H I
> C F I K
> D L M N O P

> second <- with(test, tapply(V2, V1, FUN=function(x) test[test$V2==x, ] ) )
Warning messages:
1: In test$V2 == x :
  longer object length is not a multiple of shorter object length
2: In test$V2 == x :
  longer object length is not a multiple of shorter object length
3: In test$V2 == x :
  longer object length is not a multiple of shorter object length

> third <- sapply(names(second) , function(df) c(df, second[[df]][ , "V2" ]) )
> third
$A
[1] "A" "B" "F" "G" "H"

$B
[1] "B" "F" "I" "F" "I"

$C
[1] "C" "F" "I" "K"

$D
[1] "D" "L" "M" "N"

$L
[1] "L" "O" "P"

> fourth <- sapply(names(third), function(d) unique( c(third[[d]], 
                                       unlist(third[ sapply( third[[d]], "[" ) ]) ) ) )
> fourth
$A
[1] "A" "B" "F" "G" "H" "I"

$B
[1] "B" "F" "I"

$C
[1] "C" "F" "I" "K"

$D
[1] "D" "L" "M" "N" "O" "P"

$L
[1] "L" "O" "P"



> 
> 
>> test
>   V1 V2
> 1   A  B
> 2   A  F
> 3   A  G
> 4   A  H
> 5   B  F
> 6   B  I
> 7   C  F
> 8   C  I
> 9   C  K
> 10  D  L
> 11  D  M
> 12  D  N
> 13  L  O
> 14  L  P
> 
> Thanks
> Hermann
> 
>> dput (test)
> structure(list(V1 = c("A", "A", "A", "A", "B", "B", "C", "C",
> "C", "D", "D", "D", "L", "L"), V2 = c("B", "F", "G", "H", "F",
> "I", "F", "I", "K", "L", "M", "N", "O", "P")), .Names = c("V1",
> "V2"), row.names = c(NA, -14L), class = "data.frame")
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rm at wippies.se  Sat Nov  9 13:43:25 2013
From: rm at wippies.se (rm)
Date: Sat, 9 Nov 2013 04:43:25 -0800 (PST)
Subject: [R] Standard errors in regression models with interactions terms
Message-ID: <1384001005904-4680104.post@n4.nabble.com>

In a rather simple regression, I?d like to ask the question, for high trees,
whether it makes a difference (for volume) whether a three is thick.

If my interpretation is correct, for low trees, i.e. for which trees$isHigh
== FALSE, the answer is yes. 

The problem is how to "merge" the standard errors. Code follows.

data(trees)
trees$isHigh <- trees$Height > 76
trees$isThick <- trees$Girth > 13
m <- lm(trees$Volume ~ trees$isHigh + trees$isThick +
trees$isHigh:trees$isThick)
summary(m)

I might be mistaken, but a workaround is to rewrite the model as follows,
which shows that the answer is yes. However, I would very much like to know
how to answer the question with the original model.

data(trees)
trees$isLow <- trees$Height <= 76
trees$isThick <- trees$Girth > 13
m <- lm(trees$Volume ~ trees$isLow + trees$isThick +
trees$isLow:trees$isThick)
summary(m)








--
View this message in context: http://r.789695.n4.nabble.com/Standard-errors-in-regression-models-with-interactions-terms-tp4680104.html
Sent from the R help mailing list archive at Nabble.com.


From veedeehjay at googlemail.com  Sat Nov  9 14:50:29 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Sat, 09 Nov 2013 14:50:29 +0100
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
Message-ID: <op.w6abefn4p7eajd@muck.fritz.box>

I'd very much appreciate some help here: I'm in the process of clarifying  
whether I can use `computeContour3d' to derive estimates of the surface  
area of a single closed isosurface (and prospectively the enclosed  
volume). getting the surface area from the list of triangles returned by  
`computeContour3d' is straightforward but I've stumbled over the precise  
meaning of `level' here. looking into the package, ultimately the level is  
used in the namespace function `faceType' which reads:

function (v, nx, ny, level, maxvol)
{
     if (level == maxvol)
         p <- v >= level
     else p <- v > level
     v[p] <- 1
     v[!p] <- 0
     v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
         -1]
}

my question: is the discrimination of the special case `level == maxvol'  
(or rather of everything else) really desirable? I would argue
that always testing for `v >= level' would be better. if I feed data with  
discrete values (e.g. integer-valued) defined
on a coarse grid into `computeContour3d' it presently makes a big  
difference whether there is a single data point (e.g.) with a value larger
than `level' or not. consider the 1D example:

data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)

and level = 1

this defines the isocontour `level = 1' to lie at pos 3 and 7 in for data1  
but as lying at pos 4 in data2. actually I would like (and expect) to get  
the same isosurface for `data2' with this `level' setting. in short: the  
meaning/definition of `level' changes depending on whether or not it is  
equal to `maxvol'. this is neither stated in the manpage nor is this  
desirable in my view. but maybe I miss something here. any clarification  
would be appreciated.

j.



--


From dschnaider at gmail.com  Sat Nov  9 15:31:09 2013
From: dschnaider at gmail.com (daniel schnaider)
Date: Sat, 9 Nov 2013 12:31:09 -0200
Subject: [R] S4; Setter function is not chaning slot value as expected
Message-ID: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/e15a4377/attachment.pl>

From dschnaider at gmail.com  Sat Nov  9 16:22:03 2013
From: dschnaider at gmail.com (daniel schnaider)
Date: Sat, 9 Nov 2013 13:22:03 -0200
Subject: [R] S4 vs S3. New Package
Message-ID: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/74495ac1/attachment.pl>

From murdoch.duncan at gmail.com  Sat Nov  9 17:16:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 11:16:28 -0500
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
In-Reply-To: <op.w6abefn4p7eajd@muck.fritz.box>
References: <op.w6abefn4p7eajd@muck.fritz.box>
Message-ID: <527E5FDC.4070409@gmail.com>

On 13-11-09 8:50 AM, j. van den hoff wrote:
> I'd very much appreciate some help here: I'm in the process of clarifying
> whether I can use `computeContour3d' to derive estimates of the surface
> area of a single closed isosurface (and prospectively the enclosed
> volume). getting the surface area from the list of triangles returned by
> `computeContour3d' is straightforward but I've stumbled over the precise
> meaning of `level' here. looking into the package, ultimately the level is
> used in the namespace function `faceType' which reads:
>
> function (v, nx, ny, level, maxvol)
> {
>       if (level == maxvol)
>           p <- v >= level
>       else p <- v > level
>       v[p] <- 1
>       v[!p] <- 0
>       v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
>           -1]
> }
>
> my question: is the discrimination of the special case `level == maxvol'
> (or rather of everything else) really desirable? I would argue
> that always testing for `v >= level' would be better. if I feed data with
> discrete values (e.g. integer-valued) defined
> on a coarse grid into `computeContour3d' it presently makes a big
> difference whether there is a single data point (e.g.) with a value larger
> than `level' or not. consider the 1D example:
>
> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
> data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)
>
> and level = 1
>
> this defines the isocontour `level = 1' to lie at pos 3 and 7 in for data1
> but as lying at pos 4 in data2. actually I would like (and expect) to get
> the same isosurface for `data2' with this `level' setting. in short: the
> meaning/definition of `level' changes depending on whether or not it is
> equal to `maxvol'. this is neither stated in the manpage nor is this
> desirable in my view. but maybe I miss something here. any clarification
> would be appreciated.

I don't see why you'd expect the same output from those vectors, but 
since they aren't legal input to computeContour3d, maybe I don't know 
what you mean by them.  Could you put together a reproducible example 
that shows bad contours?

Duncan Murdoch

>
> j.
>
>
>
> --
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From szehnder at uni-bonn.de  Sat Nov  9 17:22:29 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 9 Nov 2013 17:22:29 +0100
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
Message-ID: <1448CFEE-C7B6-4BE8-9999-D9C77F0E7615@uni-bonn.de>

If you want to set a slot you have to refer to it:

ac at CustomerID <- ?54321? 

or you use your setter:

ac <- CustomerID(ac, ?54321?)

What you did was creating a new symbol CustomerID referring to the String ?54321?
CustomerID <- ?54321?
CustomerID
[1] ?54321?

Best

Simon

On 09 Nov 2013, at 15:31, daniel schnaider <dschnaider at gmail.com> wrote:

> It is my first time programming with S4 and I can't get the setter fuction
> to actually change the value of the slot created by the constructor.
> 
> I guess it has to do with local copy, global copy, etc. of the variable -
> but, I could't find anything relevant in documentation.
> 
> Tried to copy examples from the internet, but they had the same problem.
> 
> # The code
>    setClass ("Account" ,
>               representation (
>               customer_id = "character",
>               transactions = "matrix")
>    )
> 
> 
>    Account <- function(id, t) {
>            new("Account", customer_id = id, transactions = t)
>            }
> 
> 
>    setGeneric ("CustomerID<-", function(obj,
> id){standardGeneric("CustomerID<-")})
>    setReplaceMethod("CustomerID", "Account", function(obj, id){
>        obj at customer_id <- id
>        obj
>        })
> 
>        ac <- Account("12345", matrix(c(1,2,3,4,5,6), ncol=2))
>        ac
>        CustomerID <- "54321"
>        ac
> 
> #Output
>> ac
>        An object of class "Account"
>        Slot "customer_id":
>        [1] "12345"
> 
>        Slot "transactions":
>             [,1] [,2]
>        [1,]    1    4
>        [2,]    2    5
>        [3,]    3    6
> 
> # CustomerID is value has changed to 54321, but as you can see it does't
>> CustomerID <- "54321"
>> ac
>        An object of class "Account"
>        Slot "customer_id":
>        [1] "12345"
> 
>        Slot "transactions":
>             [,1] [,2]
>        [1,]    1    4
>        [2,]    2    5
>        [3,]    3    6
> 
> 
> Help!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Sat Nov  9 17:30:45 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 9 Nov 2013 17:30:45 +0100
Subject: [R] S4 vs S3. New Package
In-Reply-To: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
References: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
Message-ID: <37DF2865-28FC-40EB-B247-DAC9CD404981@uni-bonn.de>

This depends very often of on the developer and what he is comfortable with. I like S4 classes, as I come from C++ and S4 classes approximate C++ classes at least more than S3 classes do (Reference Classes would do so even more and I know very good R programmers liking these most).

1) I wrote a package for MCMC simulation with S4 classes carrying all simulated values - fast enough for me: in less than 1.5 secs I have my sample of 100.000 values together with several other 100T values like log-likelihoods, posterior hyper parameters, etc. I watch out for not copying too often an object but sometimes it is not avoidable. 

2) That is not true: 
    
Books:
http://www.amazon.de/Software-Data-Analysis-Programming-Statistics/dp/0387759352/ref=sr_1_1?ie=UTF8&qid=1384014486&sr=8-1&keywords=John+chambers+data
http://www.amazon.de/Programming-Data-Language-John-Chambers/dp/0387985034/ref=sr_1_4?ie=UTF8&qid=1384014486&sr=8-4&keywords=John+chambers+data

Online:
https://www.rmetrics.org/files/Meielisalp2009/Presentations/Chalabi1.pdf
https://www.stat.auckland.ac.nz/S-Workshop/Gentleman/S4Objects.pdf

And for a bunch of packages look into the Bioconductor packages.

Best

Simon

On 09 Nov 2013, at 16:22, daniel schnaider <dschnaider at gmail.com> wrote:

> Hi,
> 
> I am working on a new credit portfolio optimization package. My question is
> if it is more recommended to develop in S4 object oriented or S3.
> 
> It would be more naturally to develop in object oriented paradigm, but
> there is many concerns regarding S4.
> 
> 1) Performance of S4 could be an issue as a setter function, actually
> changes the whole object behind the scenes.
> 
> 2) Documentation. It has been really hard to find examples in S4. Most
> books and articles consider straightforward S3 examples.
> 
> Thanks,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From veedeehjay at googlemail.com  Sat Nov  9 17:57:37 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Sat, 09 Nov 2013 17:57:37 +0100
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
In-Reply-To: <527E5FDC.4070409@gmail.com>
References: <op.w6abefn4p7eajd@muck.fritz.box> <527E5FDC.4070409@gmail.com>
Message-ID: <op.w6aj2brsp7eajd@muck.fritz.box>

On Sat, 09 Nov 2013 17:16:28 +0100, Duncan Murdoch  
<murdoch.duncan at gmail.com> wrote:

> On 13-11-09 8:50 AM, j. van den hoff wrote:
>> I'd very much appreciate some help here: I'm in the process of  
>> clarifying
>> whether I can use `computeContour3d' to derive estimates of the surface
>> area of a single closed isosurface (and prospectively the enclosed
>> volume). getting the surface area from the list of triangles returned by
>> `computeContour3d' is straightforward but I've stumbled over the precise
>> meaning of `level' here. looking into the package, ultimately the level  
>> is
>> used in the namespace function `faceType' which reads:
>>
>> function (v, nx, ny, level, maxvol)
>> {
>>       if (level == maxvol)
>>           p <- v >= level
>>       else p <- v > level
>>       v[p] <- 1
>>       v[!p] <- 0
>>       v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
>>           -1]
>> }
>>
>> my question: is the discrimination of the special case `level == maxvol'
>> (or rather of everything else) really desirable? I would argue
>> that always testing for `v >= level' would be better. if I feed data  
>> with
>> discrete values (e.g. integer-valued) defined
>> on a coarse grid into `computeContour3d' it presently makes a big
>> difference whether there is a single data point (e.g.) with a value  
>> larger
>> than `level' or not. consider the 1D example:
>>
>> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>> data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)
>>
>> and level = 1
>>
>> this defines the isocontour `level = 1' to lie at pos 3 and 7 in for  
>> data1
>> but as lying at pos 4 in data2. actually I would like (and expect) to  
>> get
>> the same isosurface for `data2' with this `level' setting. in short: the
>> meaning/definition of `level' changes depending on whether or not it is
>> equal to `maxvol'. this is neither stated in the manpage nor is this
>> desirable in my view. but maybe I miss something here. any clarification
>> would be appreciated.
>
> I don't see why you'd expect the same output from those vectors, but  
> since they aren't legal input to computeContour3d, maybe I don't know  
> what you mean by them.  Could you put together a reproducible example  
> that shows bad contours?

it's not "bad" contours, actually. my question only concerns the different  
meaning
of `level' depending on whether `level = maxvol' or not.

here is a real example:

8<------------------------------------------------
library(misc3d)

dim <- 21
cnt <- (dim+1)/2
wid1 <- 5
wid2 <- 1
rng1 <- (cnt-wid1):(cnt+wid1)
rng2 <- (cnt-wid2):(cnt+wid2)

v <- array(0, rep (dim, 3))

#put 11x11x11 box of ones at center
v[rng1, rng1, rng1] <- 1

con1 <- computeContour3d(v, level = 1)
drawScene(makeTriangles(con1))
dum <- readline("CR for next plot")

#put an additional  3x3x3 box of twos at center
v[rng2, rng2, rng2] <- 2
con2 <- computeContour3d(v, level = 1)
drawScene(makeTriangles(con2))
8<------------------------------------------------

this first puts a 11x11x11 box one Ones at the center of the  
zero-initalized array and computes `con1' for `level=1'. in the 2. step
it puts a further, 3x3x3 box of Twos at the center and computes the  
`level=1' contour again which this time does not delineate
the box of Ones but lies somewhere between the two non-zero boxes since  
now the test in `faceType' is for `> level'. this is not immediately  
obvious from the plots (no scale) but obvious from looking at `con1' and  
`con2': the `con2' isosurface is shrunk by 3 voxels at each
side relative to `con1' (so my initial mail was wrong here: `con2' does  
not "jump" to the next "discrete" isocontour but rather to
a point about halfway between both plateaus ). I also (for my own problem  
at hand) computed the total surface area which is
(not surprisingly...) 600 for `con1' and 64.87 for `con2'. so if one is  
interested in such surfaces (I am) this makes a big difference in such  
data.

the present behavior is not "wrong" per se but I would much prefer if the  
test where always for `>= level' (so that in the present example the
resulting isosurface would in both cases delineate the box of Ones -- as  
is the case when using `level = 1-e-6' instead of `level=1').

I believe the isosurface for a given value of `level' should have an  
unambiguous meaning independent of what the data further "inside" are  
looking like.

is this clearer now?

>
> Duncan Murdoch
>
>>
>> j.
>>
>>
>>
>> --
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide  
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


--


From murdoch.duncan at gmail.com  Sat Nov  9 18:18:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 12:18:23 -0500
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
In-Reply-To: <op.w6aj2brsp7eajd@muck.fritz.box>
References: <op.w6abefn4p7eajd@muck.fritz.box> <527E5FDC.4070409@gmail.com>
	<op.w6aj2brsp7eajd@muck.fritz.box>
Message-ID: <527E6E5F.4040409@gmail.com>

On 13-11-09 11:57 AM, j. van den hoff wrote:
> On Sat, 09 Nov 2013 17:16:28 +0100, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>
>> On 13-11-09 8:50 AM, j. van den hoff wrote:
>>> I'd very much appreciate some help here: I'm in the process of
>>> clarifying
>>> whether I can use `computeContour3d' to derive estimates of the surface
>>> area of a single closed isosurface (and prospectively the enclosed
>>> volume). getting the surface area from the list of triangles returned by
>>> `computeContour3d' is straightforward but I've stumbled over the precise
>>> meaning of `level' here. looking into the package, ultimately the level
>>> is
>>> used in the namespace function `faceType' which reads:
>>>
>>> function (v, nx, ny, level, maxvol)
>>> {
>>>        if (level == maxvol)
>>>            p <- v >= level
>>>        else p <- v > level
>>>        v[p] <- 1
>>>        v[!p] <- 0
>>>        v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
>>>            -1]
>>> }
>>>
>>> my question: is the discrimination of the special case `level == maxvol'
>>> (or rather of everything else) really desirable? I would argue
>>> that always testing for `v >= level' would be better. if I feed data
>>> with
>>> discrete values (e.g. integer-valued) defined
>>> on a coarse grid into `computeContour3d' it presently makes a big
>>> difference whether there is a single data point (e.g.) with a value
>>> larger
>>> than `level' or not. consider the 1D example:
>>>
>>> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>>> data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)
>>>
>>> and level = 1
>>>
>>> this defines the isocontour `level = 1' to lie at pos 3 and 7 in for
>>> data1
>>> but as lying at pos 4 in data2. actually I would like (and expect) to
>>> get
>>> the same isosurface for `data2' with this `level' setting. in short: the
>>> meaning/definition of `level' changes depending on whether or not it is
>>> equal to `maxvol'. this is neither stated in the manpage nor is this
>>> desirable in my view. but maybe I miss something here. any clarification
>>> would be appreciated.
>>
>> I don't see why you'd expect the same output from those vectors, but
>> since they aren't legal input to computeContour3d, maybe I don't know
>> what you mean by them.  Could you put together a reproducible example
>> that shows bad contours?
>
> it's not "bad" contours, actually. my question only concerns the different
> meaning
> of `level' depending on whether `level = maxvol' or not.
>
> here is a real example:
>
> 8<------------------------------------------------
> library(misc3d)
>
> dim <- 21
> cnt <- (dim+1)/2
> wid1 <- 5
> wid2 <- 1
> rng1 <- (cnt-wid1):(cnt+wid1)
> rng2 <- (cnt-wid2):(cnt+wid2)
>
> v <- array(0, rep (dim, 3))
>
> #put 11x11x11 box of ones at center
> v[rng1, rng1, rng1] <- 1
>
> con1 <- computeContour3d(v, level = 1)
> drawScene(makeTriangles(con1))
> dum <- readline("CR for next plot")
>
> #put an additional  3x3x3 box of twos at center
> v[rng2, rng2, rng2] <- 2
> con2 <- computeContour3d(v, level = 1)
> drawScene(makeTriangles(con2))
> 8<------------------------------------------------
>
> this first puts a 11x11x11 box one Ones at the center of the
> zero-initalized array and computes `con1' for `level=1'. in the 2. step
> it puts a further, 3x3x3 box of Twos at the center and computes the
> `level=1' contour again which this time does not delineate
> the box of Ones but lies somewhere between the two non-zero boxes since
> now the test in `faceType' is for `> level'. this is not immediately
> obvious from the plots (no scale) but obvious from looking at `con1' and
> `con2': the `con2' isosurface is shrunk by 3 voxels at each
> side relative to `con1' (so my initial mail was wrong here: `con2' does
> not "jump" to the next "discrete" isocontour but rather to
> a point about halfway between both plateaus ). I also (for my own problem
> at hand) computed the total surface area which is
> (not surprisingly...) 600 for `con1' and 64.87 for `con2'. so if one is
> interested in such surfaces (I am) this makes a big difference in such
> data.
>
> the present behavior is not "wrong" per se but I would much prefer if the
> test where always for `>= level' (so that in the present example the
> resulting isosurface would in both cases delineate the box of Ones -- as
> is the case when using `level = 1-e-6' instead of `level=1').
>
> I believe the isosurface for a given value of `level' should have an
> unambiguous meaning independent of what the data further "inside" are
> looking like.
>

I think it does, but your data make the determination of its location 
ambiguous.

The definition is the estimated location where the continuous field 
sampled at v crosses level.

You have a field with a discontinuity (or two).  You have whole volumes 
of space where the field is equal to the level.  The marching cubes 
algorithm is designed to detect crossings, not solid regions.

For example, going back to one dimension, if your data looked like your 
original vector

data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)

then it is ambiguous where it crosses 1:  it could be at 3 and 7, or 
there could be multiple crossings in that range.  I believe the 
analogous situation in misc3d would treat this as a crossing at 3 and 7.

Duncan Murdoch


From veedeehjay at googlemail.com  Sat Nov  9 18:53:57 2013
From: veedeehjay at googlemail.com (j. van den hoff)
Date: Sat, 09 Nov 2013 18:53:57 +0100
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
In-Reply-To: <527E6E5F.4040409@gmail.com>
References: <op.w6abefn4p7eajd@muck.fritz.box> <527E5FDC.4070409@gmail.com>
	<op.w6aj2brsp7eajd@muck.fritz.box> <527E6E5F.4040409@gmail.com>
Message-ID: <op.w6amn7ycp7eajd@muck.fritz.box>

On Sat, 09 Nov 2013 18:18:23 +0100, Duncan Murdoch  
<murdoch.duncan at gmail.com> wrote:

> On 13-11-09 11:57 AM, j. van den hoff wrote:
>> On Sat, 09 Nov 2013 17:16:28 +0100, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>
>>> On 13-11-09 8:50 AM, j. van den hoff wrote:
>>>> I'd very much appreciate some help here: I'm in the process of
>>>> clarifying
>>>> whether I can use `computeContour3d' to derive estimates of the  
>>>> surface
>>>> area of a single closed isosurface (and prospectively the enclosed
>>>> volume). getting the surface area from the list of triangles returned  
>>>> by
>>>> `computeContour3d' is straightforward but I've stumbled over the  
>>>> precise
>>>> meaning of `level' here. looking into the package, ultimately the  
>>>> level
>>>> is
>>>> used in the namespace function `faceType' which reads:
>>>>
>>>> function (v, nx, ny, level, maxvol)
>>>> {
>>>>        if (level == maxvol)
>>>>            p <- v >= level
>>>>        else p <- v > level
>>>>        v[p] <- 1
>>>>        v[!p] <- 0
>>>>        v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
>>>>            -1]
>>>> }
>>>>
>>>> my question: is the discrimination of the special case `level ==  
>>>> maxvol'
>>>> (or rather of everything else) really desirable? I would argue
>>>> that always testing for `v >= level' would be better. if I feed data
>>>> with
>>>> discrete values (e.g. integer-valued) defined
>>>> on a coarse grid into `computeContour3d' it presently makes a big
>>>> difference whether there is a single data point (e.g.) with a value
>>>> larger
>>>> than `level' or not. consider the 1D example:
>>>>
>>>> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>>>> data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)
>>>>
>>>> and level = 1
>>>>
>>>> this defines the isocontour `level = 1' to lie at pos 3 and 7 in for
>>>> data1
>>>> but as lying at pos 4 in data2. actually I would like (and expect) to
>>>> get
>>>> the same isosurface for `data2' with this `level' setting. in short:  
>>>> the
>>>> meaning/definition of `level' changes depending on whether or not it  
>>>> is
>>>> equal to `maxvol'. this is neither stated in the manpage nor is this
>>>> desirable in my view. but maybe I miss something here. any  
>>>> clarification
>>>> would be appreciated.
>>>
>>> I don't see why you'd expect the same output from those vectors, but
>>> since they aren't legal input to computeContour3d, maybe I don't know
>>> what you mean by them.  Could you put together a reproducible example
>>> that shows bad contours?
>>
>> it's not "bad" contours, actually. my question only concerns the  
>> different
>> meaning
>> of `level' depending on whether `level = maxvol' or not.
>>
>> here is a real example:
>>
>> 8<------------------------------------------------
>> library(misc3d)
>>
>> dim <- 21
>> cnt <- (dim+1)/2
>> wid1 <- 5
>> wid2 <- 1
>> rng1 <- (cnt-wid1):(cnt+wid1)
>> rng2 <- (cnt-wid2):(cnt+wid2)
>>
>> v <- array(0, rep (dim, 3))
>>
>> #put 11x11x11 box of ones at center
>> v[rng1, rng1, rng1] <- 1
>>
>> con1 <- computeContour3d(v, level = 1)
>> drawScene(makeTriangles(con1))
>> dum <- readline("CR for next plot")
>>
>> #put an additional  3x3x3 box of twos at center
>> v[rng2, rng2, rng2] <- 2
>> con2 <- computeContour3d(v, level = 1)
>> drawScene(makeTriangles(con2))
>> 8<------------------------------------------------
>>
>> this first puts a 11x11x11 box one Ones at the center of the
>> zero-initalized array and computes `con1' for `level=1'. in the 2. step
>> it puts a further, 3x3x3 box of Twos at the center and computes the
>> `level=1' contour again which this time does not delineate
>> the box of Ones but lies somewhere between the two non-zero boxes since
>> now the test in `faceType' is for `> level'. this is not immediately
>> obvious from the plots (no scale) but obvious from looking at `con1' and
>> `con2': the `con2' isosurface is shrunk by 3 voxels at each
>> side relative to `con1' (so my initial mail was wrong here: `con2' does
>> not "jump" to the next "discrete" isocontour but rather to
>> a point about halfway between both plateaus ). I also (for my own  
>> problem
>> at hand) computed the total surface area which is
>> (not surprisingly...) 600 for `con1' and 64.87 for `con2'. so if one is
>> interested in such surfaces (I am) this makes a big difference in such
>> data.
>>
>> the present behavior is not "wrong" per se but I would much prefer if  
>> the
>> test where always for `>= level' (so that in the present example the
>> resulting isosurface would in both cases delineate the box of Ones -- as
>> is the case when using `level = 1-e-6' instead of `level=1').
>>
>> I believe the isosurface for a given value of `level' should have an
>> unambiguous meaning independent of what the data further "inside" are
>> looking like.
>>
>
> I think it does, but your data make the determination of its location  
> ambiguous.

I was imprecise: what I meant is: the isosurface should not change in my  
example between both cases.

>
> The definition is the estimated location where the continuous field  
> sampled at v crosses level.

understood/agreed.

>
> You have a field with a discontinuity (or two).  You have whole volumes  
> of space where the field is equal to the level.  The marching cubes  
> algorithm is designed to detect crossings, not solid regions.
>
> For example, going back to one dimension, if your data looked like your  
> original vector
>
> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>
> then it is ambiguous where it crosses 1:  it could be at 3 and 7, or  
> there could be multiple crossings in that range.  I believe the  
> analogous situation in misc3d would treat this as a crossing at 3 and 7.

yes, it does that. and it is clear that due to your interpretation it  
selects
about point 3.5 and 6.5 (?) for

data2 <- c(0, 0, 1, 1, 2, 1, 1, 0, 0).

still, depending on application I would maintain that it can make (more)  
sense
to keep the isosurface at 3,7 in this case.

I believe the problem maybe is not so much "discrete vs. continuous" but  
whether there is
a constant "plateau" in the data: even for the underlying continuous field  
it is a matter
of convention, then, where to put the level=1 contour: at the first  
crossing, in the middle
of the plateau, or at the second crossing. I understand `computeContour3d'  
essentially puts
the contour in the middle of the plateau.

I do not want to claim present behavior is a bug. it just is not  
necessarily what
is needed. an additional argument/flag to `computeContour3d', e.g., to  
select behaviour in this
sort of "degenerate" cases (exhibiting strictly constant plateaus) would  
be great.

 from a purely practical point of view: as explained I want to get the  
"outer isosurface" of such
preprocessed discretized data and quantify the surface area. the question  
here is "when do the data
first cross the threshold" and that's where the present behaviour causes a  
problem for me.

but anyway thanks for bothering. if it is deemed undesirable to change  
present behaviour (or to add
a further flag for controling the behaviour of `level') I can fix it  
locally for my needs by
just changing the test in `faceType' (or so I presume).

joerg

>
> Duncan Murdoch


--


From carl at witthoft.com  Sat Nov  9 19:06:35 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Sat, 9 Nov 2013 10:06:35 -0800 (PST)
Subject: [R] Date handling in R is hard to understand
In-Reply-To: <CACk-te3Un0nKQPPM7SqsUbhD63EZX-_GbSjUTWTk-rM-ZDi15Q@mail.gmail.com>
References: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
	<CACk-te3Un0nKQPPM7SqsUbhD63EZX-_GbSjUTWTk-rM-ZDi15Q@mail.gmail.com>
Message-ID: <1384020395624-4680125.post@n4.nabble.com>

I agree w/ lubridate.    I also would like to mention that   "date handling" 
is amazingly difficult in ALL computer languages, not just R.  Take a stroll
through sites like thedailywtf.com to see how quickly people get into
tarpits full of thorns when trying to deal with leap years, weeks vs month
ends, etc.   



Bert Gunter wrote
> Have a look at the "lubridate" package. It claims to try to make
> dealing with dates easier.
> 
> 
> -- Bert
> 
> On Fri, Nov 8, 2013 at 11:41 AM, Alemu Tadesse &lt;

> alemu.tadesse@

> &gt; wrote:
>> Dear All,
>>
>> I usually work with time series data. The data may come in AM/PM date
>> format or on 24 hour time basis. R can not recognize the two differences
>> automatically - at least for me. I have to specifically tell R in which
>> time format the data is. It seems that Pandas knows how to handle date
>> without being told the format. The problem arises when I try to shift
>> time
>> by a certain time. Say adding 3600 to shift it forward, that case I have
>> to
>> use something like:
>> Measured_data$Date <- as.POSIXct(as.character(Measured_data$Date),
>> tz="",format = "%m/%d/%Y %I:%M %p")+3600
>> or Measured_data$Date <- as.POSIXct(as.character(Measured_data$Date),
>> tz="",format = "%m/%d/%Y %H:%M")+3600  depending on the format. The date
>> also attaches MDT or MST and so on. When merging two data frames  with
>> dates of different format that may create a problem (I think). When I get
>> data from excel it could be in any/random format and I needed to
>> customize
>> the date to use in R in one of the above formats. Any TIPS - for
>> automatic
>> processing with no need to specifically tell the data format ?
>>
>> Another problem I saw was that when using r bind to bind data frames, if
>> one column of one of the data frames is a character data (say for example
>> none - coming from mysql) format R doesn't know how to concatenate
>> numeric
>> column from the other data frame to it. I needed to change the numeric to
>> character and later after binding takes place I had to re-convert it to
>> numeric. But, this causes problem in an automated environment. Any
>> suggestion ?
>>
>> Thanks
>> Mihretu
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Date-handling-in-R-is-hard-to-understand-tp4680070p4680125.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Sat Nov  9 19:11:45 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Sat, 9 Nov 2013 10:11:45 -0800 (PST)
Subject: [R] C50 Node Assignment
In-Reply-To: <958B1386-C121-4084-95AE-038A5168918D@comcast.net>
References: <958B1386-C121-4084-95AE-038A5168918D@comcast.net>
Message-ID: <1384020705260-4680127.post@n4.nabble.com>


Just to clarify:  I'm guessing the OP is referring to the CRAN package C50
here.   A quick skim suggests the rules are a list element of a C5.0-class
object, so maybe that's where to start?


David Winsemius wrote
> In my role as a moderator I am attempting to bypass the automatic mail
> filters that are blocking this posting. Please reply to the list and to:
> =========================
> Kevin Shaney &lt;

> kevin.shaney@

> &gt;
> 
> C50 Node Assignment
> 
> I am using C50 to classify individuals into 5 groups / categories (factor
> variable).  The tree / set of rules has 10 rules for classification.  I am
> trying to extract the RULE for which each individual qualifies (a number
> between 1 and 10), and cannot figure out how to do so.  I can extract the
> predicted group and predicted group probability, but not the RULE to which
> an individual qualifies.  Please let me know if you can help!
> 
> Kevin
> =========================
> 
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/C50-Node-Assignment-tp4680071p4680127.html
Sent from the R help mailing list archive at Nabble.com.


From mtmorgan at fhcrc.org  Sat Nov  9 19:20:04 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 09 Nov 2013 10:20:04 -0800
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
Message-ID: <527E7CD4.1030701@fhcrc.org>

On 11/09/2013 06:31 AM, daniel schnaider wrote:
> It is my first time programming with S4 and I can't get the setter fuction
> to actually change the value of the slot created by the constructor.
>
> I guess it has to do with local copy, global copy, etc. of the variable -
> but, I could't find anything relevant in documentation.
>
> Tried to copy examples from the internet, but they had the same problem.
>
> # The code
>      setClass ("Account" ,
>                 representation (
>                 customer_id = "character",
>                 transactions = "matrix")
>      )
>
>
>      Account <- function(id, t) {
>              new("Account", customer_id = id, transactions = t)
>              }
>
>
>      setGeneric ("CustomerID<-", function(obj,
> id){standardGeneric("CustomerID<-")})

Replacement methods (in R in general) require that the final argument (the 
replacement value) be named 'value', so

     setGeneric("CustomerID<-",
         function(x, ..., value) standardGeneric("CustomerID"))

     setReplaceMethod("CustomerID", c("Account", "character"),
         function(x, ...., value)
     {
         x at customer_id <- value
         x
     })

use this as

    CustomerID(ac) <- "54321"


>      setReplaceMethod("CustomerID", "Account", function(obj, id){
>          obj at customer_id <- id
>          obj
>          })
>
>          ac <- Account("12345", matrix(c(1,2,3,4,5,6), ncol=2))
>          ac
>          CustomerID <- "54321"
>          ac
>
> #Output
>          > ac
>          An object of class "Account"
>          Slot "customer_id":
>          [1] "12345"
>
>          Slot "transactions":
>               [,1] [,2]
>          [1,]    1    4
>          [2,]    2    5
>          [3,]    3    6
>
> # CustomerID is value has changed to 54321, but as you can see it does't
>          > CustomerID <- "54321"

>          > ac
>          An object of class "Account"
>          Slot "customer_id":
>          [1] "12345"
>
>          Slot "transactions":
>               [,1] [,2]
>          [1,]    1    4
>          [2,]    2    5
>          [3,]    3    6
>
>
> Help!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From jdnewmil at dcn.davis.ca.us  Sat Nov  9 19:23:26 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 9 Nov 2013 10:23:26 -0800 (PST)
Subject: [R] Tables Package Grouping Factors
Message-ID: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>

Visually, the elimination of duplicates in hierarchical tables in the 
tabular function from the tables package is very nice. I would like to do 
the same thing with non-crossed factors, but am perhaps missing some 
conceptual element of how this package is used. The following code 
illustrates my goal (I hope):

library(tables)
sampledf <- data.frame( Sex=rep(c("M","F"),each=6)
            , Name=rep(c("John","Joe","Mark","Alice","Beth","Jane"),each=2)
            , When=rep(c("Before","After"),times=6)
            , Weight=c(180,190,190,180,200,200,140,145,150,140,135,135)
            )
sampledf$SexName <- factor( paste( sampledf$Sex, sampledf$Name ) )

# logically, this is the layout
tabular( Name ~ Heading()* When * Weight * Heading()*identity, 
data=sampledf )

# but I want to augment the Name with the Sex but visually group the
# Sex like
#   tabular( Sex*Name ~ Heading()*When * Weight * Heading()*identity, 
data=sampledf )
# would except that there really is no crossing between sexes.
tabular( SexName ~ Heading()*When * Weight * Heading()*identity, 
data=sampledf )
# this repeats the Sex category excessively.


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From murdoch.duncan at gmail.com  Sat Nov  9 19:40:26 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 13:40:26 -0500
Subject: [R] `level' definition in `computeContour3d' (misc3d package)
In-Reply-To: <op.w6amn7ycp7eajd@muck.fritz.box>
References: <op.w6abefn4p7eajd@muck.fritz.box> <527E5FDC.4070409@gmail.com>
	<op.w6aj2brsp7eajd@muck.fritz.box> <527E6E5F.4040409@gmail.com>
	<op.w6amn7ycp7eajd@muck.fritz.box>
Message-ID: <527E819A.60201@gmail.com>

On 13-11-09 12:53 PM, j. van den hoff wrote:
> On Sat, 09 Nov 2013 18:18:23 +0100, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>
>> On 13-11-09 11:57 AM, j. van den hoff wrote:
>>> On Sat, 09 Nov 2013 17:16:28 +0100, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>
>>>> On 13-11-09 8:50 AM, j. van den hoff wrote:
>>>>> I'd very much appreciate some help here: I'm in the process of
>>>>> clarifying
>>>>> whether I can use `computeContour3d' to derive estimates of the
>>>>> surface
>>>>> area of a single closed isosurface (and prospectively the enclosed
>>>>> volume). getting the surface area from the list of triangles returned
>>>>> by
>>>>> `computeContour3d' is straightforward but I've stumbled over the
>>>>> precise
>>>>> meaning of `level' here. looking into the package, ultimately the
>>>>> level
>>>>> is
>>>>> used in the namespace function `faceType' which reads:
>>>>>
>>>>> function (v, nx, ny, level, maxvol)
>>>>> {
>>>>>         if (level == maxvol)
>>>>>             p <- v >= level
>>>>>         else p <- v > level
>>>>>         v[p] <- 1
>>>>>         v[!p] <- 0
>>>>>         v[-nx, -ny] + 2 * v[-1, -ny] + 4 * v[-1, -1] + 8 * v[-nx,
>>>>>             -1]
>>>>> }
>>>>>
>>>>> my question: is the discrimination of the special case `level ==
>>>>> maxvol'
>>>>> (or rather of everything else) really desirable? I would argue
>>>>> that always testing for `v >= level' would be better. if I feed data
>>>>> with
>>>>> discrete values (e.g. integer-valued) defined
>>>>> on a coarse grid into `computeContour3d' it presently makes a big
>>>>> difference whether there is a single data point (e.g.) with a value
>>>>> larger
>>>>> than `level' or not. consider the 1D example:
>>>>>
>>>>> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>>>>> data2 <- c(0, 0, 1, 2, 1, 1, 1, 0, 0)
>>>>>
>>>>> and level = 1
>>>>>
>>>>> this defines the isocontour `level = 1' to lie at pos 3 and 7 in for
>>>>> data1
>>>>> but as lying at pos 4 in data2. actually I would like (and expect) to
>>>>> get
>>>>> the same isosurface for `data2' with this `level' setting. in short:
>>>>> the
>>>>> meaning/definition of `level' changes depending on whether or not it
>>>>> is
>>>>> equal to `maxvol'. this is neither stated in the manpage nor is this
>>>>> desirable in my view. but maybe I miss something here. any
>>>>> clarification
>>>>> would be appreciated.
>>>>
>>>> I don't see why you'd expect the same output from those vectors, but
>>>> since they aren't legal input to computeContour3d, maybe I don't know
>>>> what you mean by them.  Could you put together a reproducible example
>>>> that shows bad contours?
>>>
>>> it's not "bad" contours, actually. my question only concerns the
>>> different
>>> meaning
>>> of `level' depending on whether `level = maxvol' or not.
>>>
>>> here is a real example:
>>>
>>> 8<------------------------------------------------
>>> library(misc3d)
>>>
>>> dim <- 21
>>> cnt <- (dim+1)/2
>>> wid1 <- 5
>>> wid2 <- 1
>>> rng1 <- (cnt-wid1):(cnt+wid1)
>>> rng2 <- (cnt-wid2):(cnt+wid2)
>>>
>>> v <- array(0, rep (dim, 3))
>>>
>>> #put 11x11x11 box of ones at center
>>> v[rng1, rng1, rng1] <- 1
>>>
>>> con1 <- computeContour3d(v, level = 1)
>>> drawScene(makeTriangles(con1))
>>> dum <- readline("CR for next plot")
>>>
>>> #put an additional  3x3x3 box of twos at center
>>> v[rng2, rng2, rng2] <- 2
>>> con2 <- computeContour3d(v, level = 1)
>>> drawScene(makeTriangles(con2))
>>> 8<------------------------------------------------
>>>
>>> this first puts a 11x11x11 box one Ones at the center of the
>>> zero-initalized array and computes `con1' for `level=1'. in the 2. step
>>> it puts a further, 3x3x3 box of Twos at the center and computes the
>>> `level=1' contour again which this time does not delineate
>>> the box of Ones but lies somewhere between the two non-zero boxes since
>>> now the test in `faceType' is for `> level'. this is not immediately
>>> obvious from the plots (no scale) but obvious from looking at `con1' and
>>> `con2': the `con2' isosurface is shrunk by 3 voxels at each
>>> side relative to `con1' (so my initial mail was wrong here: `con2' does
>>> not "jump" to the next "discrete" isocontour but rather to
>>> a point about halfway between both plateaus ). I also (for my own
>>> problem
>>> at hand) computed the total surface area which is
>>> (not surprisingly...) 600 for `con1' and 64.87 for `con2'. so if one is
>>> interested in such surfaces (I am) this makes a big difference in such
>>> data.
>>>
>>> the present behavior is not "wrong" per se but I would much prefer if
>>> the
>>> test where always for `>= level' (so that in the present example the
>>> resulting isosurface would in both cases delineate the box of Ones -- as
>>> is the case when using `level = 1-e-6' instead of `level=1').
>>>
>>> I believe the isosurface for a given value of `level' should have an
>>> unambiguous meaning independent of what the data further "inside" are
>>> looking like.
>>>
>>
>> I think it does, but your data make the determination of its location
>> ambiguous.
>
> I was imprecise: what I meant is: the isosurface should not change in my
> example between both cases.
>
>>
>> The definition is the estimated location where the continuous field
>> sampled at v crosses level.
>
> understood/agreed.
>
>>
>> You have a field with a discontinuity (or two).  You have whole volumes
>> of space where the field is equal to the level.  The marching cubes
>> algorithm is designed to detect crossings, not solid regions.
>>
>> For example, going back to one dimension, if your data looked like your
>> original vector
>>
>> data1 <- c(0, 0, 1, 1, 1, 1, 1, 0, 0)
>>
>> then it is ambiguous where it crosses 1:  it could be at 3 and 7, or
>> there could be multiple crossings in that range.  I believe the
>> analogous situation in misc3d would treat this as a crossing at 3 and 7.
>
> yes, it does that. and it is clear that due to your interpretation it
> selects
> about point 3.5 and 6.5 (?) for
>
> data2 <- c(0, 0, 1, 1, 2, 1, 1, 0, 0).

I don't think it does.  I think it picks 4 and 6.  In your 3d example, 
the smaller cube runs from 9 to 13 in each coordinate (though it misses 
the corners).  You can see this if you plot it using the "rgl" engine, 
then call rgl::decorate3d() to add axes.

>
> still, depending on application I would maintain that it can make (more)
> sense
> to keep the isosurface at 3,7 in this case.

That makes just as much sense, but not more.  Anywhere from 3 to 4 is a 
sensible left end, anywhere from 6 to 7 is fine for the right end.
>
> I believe the problem maybe is not so much "discrete vs. continuous" but
> whether there is
> a constant "plateau" in the data: even for the underlying continuous field
> it is a matter
> of convention, then, where to put the level=1 contour: at the first
> crossing, in the middle
> of the plateau, or at the second crossing. I understand `computeContour3d'
> essentially puts
> the contour in the middle of the plateau.

No, it doesn't.  As you've seen, it handles plateaus inconsistently 
depending on whether they are the max of the field or not.  For the case 
where it is an interior plateau, you get your contour at height 
level+epsilon in an approximation to the field.  For the max of the 
field, you get level.

Try comparing the contour you get at level 1 with v and at level -1 with 
-v.  They are not the same.


>
> I do not want to claim present behavior is a bug. it just is not
> necessarily what
> is needed. an additional argument/flag to `computeContour3d', e.g., to
> select behaviour in this
> sort of "degenerate" cases (exhibiting strictly constant plateaus) would
> be great.

You can suggest this to the maintainer of the package (I am not author 
or maintainer of it).
>
>   from a purely practical point of view: as explained I want to get the
> "outer isosurface" of such
> preprocessed discretized data and quantify the surface area. the question
> here is "when do the data
> first cross the threshold" and that's where the present behaviour causes a
> problem for me.

You may need to write your own function for this.

Duncan Murdoch

>
> but anyway thanks for bothering. if it is deemed undesirable to change
> present behaviour (or to add
> a further flag for controling the behaviour of `level') I can fix it
> locally for my needs by
> just changing the test in `faceType' (or so I presume).
>
> joerg
>
>>
>> Duncan Murdoch
>
>


From murdoch.duncan at gmail.com  Sat Nov  9 20:03:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 14:03:23 -0500
Subject: [R] Tables Package Grouping Factors
In-Reply-To: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
References: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
Message-ID: <527E86FB.5050003@gmail.com>

On 13-11-09 1:23 PM, Jeff Newmiller wrote:
> Visually, the elimination of duplicates in hierarchical tables in the
> tabular function from the tables package is very nice. I would like to do
> the same thing with non-crossed factors, but am perhaps missing some
> conceptual element of how this package is used. The following code
> illustrates my goal (I hope):
>
> library(tables)
> sampledf <- data.frame( Sex=rep(c("M","F"),each=6)
>              , Name=rep(c("John","Joe","Mark","Alice","Beth","Jane"),each=2)
>              , When=rep(c("Before","After"),times=6)
>              , Weight=c(180,190,190,180,200,200,140,145,150,140,135,135)
>              )
> sampledf$SexName <- factor( paste( sampledf$Sex, sampledf$Name ) )
>
> # logically, this is the layout
> tabular( Name ~ Heading()* When * Weight * Heading()*identity,
> data=sampledf )
>
> # but I want to augment the Name with the Sex but visually group the
> # Sex like
> #   tabular( Sex*Name ~ Heading()*When * Weight * Heading()*identity,
> data=sampledf )
> # would except that there really is no crossing between sexes.
> tabular( SexName ~ Heading()*When * Weight * Heading()*identity,
> data=sampledf )
> # this repeats the Sex category excessively.

I don't think it's easy to get what you want.  The basic assumption is 
that factors are crossed.

One hack that would get you what you want in this case is to make up a 
new variable representing person within sex (running from 1 to 3), then 
treating the Name as a statistic.  Of course, this won't work if you 
don't have equal numbers of each sex.

A better solution is more cumbersome, and only works in LaTeX (and maybe 
HTML).  Draw two tables, first for the female subset, then for the male 
subset.  Put out the headers only on the first one and the footer only 
on the second, and it will be typeset as one big table.
You'll have to fight with the fact that the factors Sex and Name 
remember their levels whether they are present or not, but it should 
work.  For example,

sampledf$Sex <- as.character(sampledf$Sex)
sampledf$Name <- as.character(sampledf$Name)
females <- subset(sampledf, Sex == "F")
males <- subset(sampledf, Sex == "M")

latex( tabular( Factor(Sex)*Factor(Name) ~ Heading()*When * Weight * 
Heading()*identity, data=females),
options = list(doFooter=FALSE, doEnd=FALSE) )

latex( tabular( Factor(Sex)*Factor(Name) ~ Heading()*When * Weight * 
Heading()*identity, data=males),
options = list(doBegin=FALSE, doHeader=FALSE) )

It would probably make sense to support nested factor notation using 
%in% to make this easier, but currently tables doesn't do that.

Duncan Murdoch


From bogaso.christofer at gmail.com  Sat Nov  9 20:21:43 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 10 Nov 2013 01:06:43 +0545
Subject: [R] Custom Numeric type in R
Message-ID: <CA+dpOJkZ496s95G69+qZiO=7U8sgU1SmLPKko=Gy5xJxX9sakg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/e1dd3b77/attachment.pl>

From murdoch.duncan at gmail.com  Sat Nov  9 20:30:10 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 14:30:10 -0500
Subject: [R] Tables Package Grouping Factors
In-Reply-To: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
References: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
Message-ID: <527E8D42.2030405@gmail.com>

On 13-11-09 1:23 PM, Jeff Newmiller wrote:
> Visually, the elimination of duplicates in hierarchical tables in the
> tabular function from the tables package is very nice. I would like to do
> the same thing with non-crossed factors, but am perhaps missing some
> conceptual element of how this package is used. The following code
> illustrates my goal (I hope):
>
> library(tables)
> sampledf <- data.frame( Sex=rep(c("M","F"),each=6)
>              , Name=rep(c("John","Joe","Mark","Alice","Beth","Jane"),each=2)
>              , When=rep(c("Before","After"),times=6)
>              , Weight=c(180,190,190,180,200,200,140,145,150,140,135,135)
>              )
> sampledf$SexName <- factor( paste( sampledf$Sex, sampledf$Name ) )
>
> # logically, this is the layout
> tabular( Name ~ Heading()* When * Weight * Heading()*identity,
> data=sampledf )
>
> # but I want to augment the Name with the Sex but visually group the
> # Sex like
> #   tabular( Sex*Name ~ Heading()*When * Weight * Heading()*identity,
> data=sampledf )
> # would except that there really is no crossing between sexes.
> tabular( SexName ~ Heading()*When * Weight * Heading()*identity,
> data=sampledf )
> # this repeats the Sex category excessively.

I forgot, there's a simpler way to do this.  Build the full table with 
the junk values, then take a subset:

full <- tabular( Sex*Name ~ Heading()*When * Weight * 
Heading()*identity, data=sampledf )

full[c(1:3, 10:12), ]

Figuring out which rows you want to keep can be a little tricky, but 
doing something like this might be good:

counts <- tabular( Sex*Name ~ 1, data=sampledf )
full[ as.logical(counts), ]

Duncan Murdoch


From r.turner at auckland.ac.nz  Sat Nov  9 20:59:22 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 10 Nov 2013 08:59:22 +1300
Subject: [R] S4 vs S3. New Package
In-Reply-To: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
References: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
Message-ID: <527E941A.9050100@auckland.ac.nz>



For my take on the issue see fortune("strait jacket").

     cheers,

     Rolf Turner

P. S.  I said that quite some time ago and I have seen nothing
in the intervening years to change my views.

     R. T.


On 11/10/13 04:22, daniel schnaider wrote:
> Hi,
>
> I am working on a new credit portfolio optimization package. My question is
> if it is more recommended to develop in S4 object oriented or S3.
>
> It would be more naturally to develop in object oriented paradigm, but
> there is many concerns regarding S4.
>
> 1) Performance of S4 could be an issue as a setter function, actually
> changes the whole object behind the scenes.
>
> 2) Documentation. It has been really hard to find examples in S4. Most
> books and articles consider straightforward S3 examples.


From mxkuhn at gmail.com  Sat Nov  9 22:38:28 2013
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sat, 9 Nov 2013 16:38:28 -0500
Subject: [R] C50 Node Assignment
In-Reply-To: <1384020705260-4680127.post@n4.nabble.com>
References: <958B1386-C121-4084-95AE-038A5168918D@comcast.net>
	<1384020705260-4680127.post@n4.nabble.com>
Message-ID: <CAJ9CoWkAGTF7EHa0zrRyuZVfVjKi==VoMt1WE1Pu4eQz3dWTLw@mail.gmail.com>

There is a sub-object called 'rules' that has the output of C5.0 for this model:

> library(C50)
> mod <- C5.0(Species ~ ., data = iris, rules = TRUE)
> cat(mod$rules)
id="See5/C5.0 2.07 GPL Edition 2013-11-09"
entries="1"
rules="4" default="setosa"
conds="1" cover="50" ok="50" lift="2.94231" class="setosa"
type="2" att="Petal.Length" cut="1.9" result="<"
conds="3" cover="48" ok="47" lift="2.88" class="versicolor"
type="2" att="Petal.Length" cut="1.9" result=">"
type="2" att="Petal.Length" cut="4.9000001" result="<"
type="2" att="Petal.Width" cut="1.7" result="<"
conds="1" cover="46" ok="45" lift="2.875" class="virginica"
type="2" att="Petal.Width" cut="1.7" result=">"
conds="1" cover="46" ok="44" lift="2.8125" class="virginica"
type="2" att="Petal.Length" cut="4.9000001" result=">"

You would either have to parse this or parse the summary results:

> summary(mod)

Call:
C5.0.formula(formula = Species ~ ., data = iris, rules = TRUE)

<snip>
Rules:

Rule 1: (50, lift 2.9)
Petal.Length <= 1.9
->  class setosa  [0.981]

Rule 2: (48/1, lift 2.9)
Petal.Length > 1.9
Petal.Length <= 4.9
Petal.Width <= 1.7
->  class versicolor  [0.960]
<snip>

Max

On Sat, Nov 9, 2013 at 1:11 PM, Carl Witthoft <carl at witthoft.com> wrote:
>
> Just to clarify:  I'm guessing the OP is referring to the CRAN package C50
> here.   A quick skim suggests the rules are a list element of a C5.0-class
> object, so maybe that's where to start?
>
>
> David Winsemius wrote
>> In my role as a moderator I am attempting to bypass the automatic mail
>> filters that are blocking this posting. Please reply to the list and to:
>> =========================
>> Kevin Shaney &lt;
>
>> kevin.shaney@
>
>> &gt;
>>
>> C50 Node Assignment
>>
>> I am using C50 to classify individuals into 5 groups / categories (factor
>> variable).  The tree / set of rules has 10 rules for classification.  I am
>> trying to extract the RULE for which each individual qualifies (a number
>> between 1 and 10), and cannot figure out how to do so.  I can extract the
>> predicted group and predicted group probability, but not the RULE to which
>> an individual qualifies.  Please let me know if you can help!
>>
>> Kevin
>> =========================
>>
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>
>> R-help@
>
>>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/C50-Node-Assignment-tp4680071p4680127.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Max


From mtmorgan at fhcrc.org  Sat Nov  9 23:54:14 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sat, 09 Nov 2013 14:54:14 -0800
Subject: [R] S4 vs S3. New Package
In-Reply-To: <527E941A.9050100@auckland.ac.nz>
References: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
	<527E941A.9050100@auckland.ac.nz>
Message-ID: <527EBD16.2030005@fhcrc.org>

On 11/09/2013 11:59 AM, Rolf Turner wrote:
>
>
> For my take on the issue see fortune("strait jacket").
>
>      cheers,
>
>      Rolf Turner
>
> P. S.  I said that quite some time ago and I have seen nothing
> in the intervening years to change my views.

Mileage varies; the Bioconductor project attains a level of interoperability and 
re-use (http://www.nature.com/nbt/journal/v31/n10/full/nbt.2721.html) that would 
be difficult with a less formal class system.

>
>      R. T.
>
>
> On 11/10/13 04:22, daniel schnaider wrote:
>> Hi,
>>
>> I am working on a new credit portfolio optimization package. My question is
>> if it is more recommended to develop in S4 object oriented or S3.
>>
>> It would be more naturally to develop in object oriented paradigm, but
>> there is many concerns regarding S4.
>>
>> 1) Performance of S4 could be an issue as a setter function, actually
>> changes the whole object behind the scenes.

Depending on implementation, updating S3 objects could as easily trigger copies; 
this is a fact of life in R. Mitigate by modelling objects in a vector 
(column)-oriented approach rather than the row-oriented paradigm of Java / C++ / 
etc.

Martin Morgan

>> 2) Documentation. It has been really hard to find examples in S4. Most
>> books and articles consider straightforward S3 examples.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From jdnewmil at dcn.davis.CA.us  Sat Nov  9 23:56:28 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 09 Nov 2013 14:56:28 -0800
Subject: [R] Tables Package Grouping Factors
In-Reply-To: <527E8D42.2030405@gmail.com>
References: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
	<527E8D42.2030405@gmail.com>
Message-ID: <835b11e2-322e-48d2-9de8-a8fe082663d5@email.android.com>

The problem that prompted this question involved manufacturers and their model numbers, so I think the cross everything and throw away most of it will get out of hand quickly. The number of models per manufacturer definitely varies. I think I will work on the print segments of the table successively approach. Thanks for the ideas.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 13-11-09 1:23 PM, Jeff Newmiller wrote:
>> Visually, the elimination of duplicates in hierarchical tables in the
>> tabular function from the tables package is very nice. I would like
>to do
>> the same thing with non-crossed factors, but am perhaps missing some
>> conceptual element of how this package is used. The following code
>> illustrates my goal (I hope):
>>
>> library(tables)
>> sampledf <- data.frame( Sex=rep(c("M","F"),each=6)
>>              ,
>Name=rep(c("John","Joe","Mark","Alice","Beth","Jane"),each=2)
>>              , When=rep(c("Before","After"),times=6)
>>              ,
>Weight=c(180,190,190,180,200,200,140,145,150,140,135,135)
>>              )
>> sampledf$SexName <- factor( paste( sampledf$Sex, sampledf$Name ) )
>>
>> # logically, this is the layout
>> tabular( Name ~ Heading()* When * Weight * Heading()*identity,
>> data=sampledf )
>>
>> # but I want to augment the Name with the Sex but visually group the
>> # Sex like
>> #   tabular( Sex*Name ~ Heading()*When * Weight * Heading()*identity,
>> data=sampledf )
>> # would except that there really is no crossing between sexes.
>> tabular( SexName ~ Heading()*When * Weight * Heading()*identity,
>> data=sampledf )
>> # this repeats the Sex category excessively.
>
>I forgot, there's a simpler way to do this.  Build the full table with 
>the junk values, then take a subset:
>
>full <- tabular( Sex*Name ~ Heading()*When * Weight * 
>Heading()*identity, data=sampledf )
>
>full[c(1:3, 10:12), ]
>
>Figuring out which rows you want to keep can be a little tricky, but 
>doing something like this might be good:
>
>counts <- tabular( Sex*Name ~ 1, data=sampledf )
>full[ as.logical(counts), ]
>
>Duncan Murdoch


From dschnaider at gmail.com  Sat Nov  9 23:02:36 2013
From: dschnaider at gmail.com (daniel schnaider)
Date: Sat, 9 Nov 2013 20:02:36 -0200
Subject: [R] S4 vs S3. New Package
In-Reply-To: <37DF2865-28FC-40EB-B247-DAC9CD404981@uni-bonn.de>
References: <CAPOwdSqL4RgzQRMHczfB70s4_WGEmZkO588Fk0UnO6z2tbEiWg@mail.gmail.com>
	<37DF2865-28FC-40EB-B247-DAC9CD404981@uni-bonn.de>
Message-ID: <CAPOwdSoQ9XfPXE-MaPamMZZKiSFSLNsRRuvMhjJ7eDn9ZPtxMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/0420650e/attachment.pl>

From ameekdgn90 at gmail.com  Sat Nov  9 19:08:29 2013
From: ameekdgn90 at gmail.com (Ameek Singh)
Date: Sat, 9 Nov 2013 23:38:29 +0530
Subject: [R] Problem while using "searchTwitter" function in TwitteR package
Message-ID: <CAGhMYJW1_sZ37zs-EzPGTCW7PJXaVjfxN95zrj8CiqcM24KRSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/a191b53e/attachment.pl>

From stausland.johnsen at iln.uio.no  Sat Nov  9 20:01:27 2013
From: stausland.johnsen at iln.uio.no (Sverre Stausland)
Date: Sat, 9 Nov 2013 20:01:27 +0100
Subject: [R] Using Unicode inside R's expression() command
Message-ID: <CACtaF7whDrV+UVDWabibUZfX9KMYfKt-EeYq2tdJJ=AoAk-NcQ@mail.gmail.com>

I'm using 'expression()' in R plots in order to get italicized text.
But it appears as if I cannot use Unicode symbols inside 'expression'
outside of ASCII characters. Is there some way I can work around this?
My goal is to get the '?' ligature in various labels in my R barplots
(together with italicized text). I think I could work around this if
there was another way of italicizing selected characters in a string
than using 'expression()'.

I'm using R for Windows version 3.0.2.

    CairoPDF(file = "Ligature1.pdf")
    plot.new()
    text(x =.5, y = .5, labels = "?", family = "Times New Roman")
    dev.off()

    CairoPDF(file = "Ligature2.pdf")
    plot.new()
    text(x =.5, y = .5, labels = expression(paste(italic(m), "u", "?",
italic(m), sep = "")), family = "Times New Roman")
    dev.off()
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lig1.png
Type: image/png
Size: 680 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/5ed05b75/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: lig2.png
Type: image/png
Size: 4409 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/5ed05b75/attachment-0001.png>

From hnorpois at gmail.com  Sat Nov  9 21:45:36 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Sat, 9 Nov 2013 21:45:36 +0100
Subject: [R] union of list objects if objects intersect
Message-ID: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/f7cf5516/attachment.pl>

From smartpink111 at yahoo.com  Sat Nov  9 23:46:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 9 Nov 2013 14:46:54 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1383951262.61119.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383936055.76561.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1383941883.12484.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1383951262.61119.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1384037214.39832.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
Try:
library(stringr)
##### Created the selected files (98) in a separate working? folder (SubsetFiles1) (refer to my previous mail)
filelst <- list.files()
#Sublst <- filelst[1:2]
res <- lapply(filelst,function(x) {con <- file(x)
??? ?Lines1 <- readLines(con) close(con)
??? ?Lines2 <- Lines1[-1]
??? ?Lines3 <- str_split(Lines2,"-9999.9M")
??? ?Lines4 <- str_trim(unlist(lapply(Lines3,function(x) {x[x==""] <- NA
??? ?paste(x,collapse=" ")})))
??? ?Lines5 <- gsub("(\\d+)[A-Za-z]","\\1",Lines4)
??? ?res1 <- read.table(text=Lines5,sep="",header=FALSE,fill=TRUE)
??? ?res1})

##Created another folder "Modified" to store the "res" files
lapply(seq_along(res),function(i) write.table(res[[i]],paste("/home/arunksa111/Zl/Modified",paste0("Mod_",filelst[i]),sep="/"),row.names=FALSE,quote=FALSE))

?lstf1 <- list.files(path="/home/arunksa111/Zl/Modified")? 

lst1 <- lapply(lstf1,function(x) readLines(paste("/home/arunksa111/Zl/Modified",x,sep="/")))
?which(lapply(lst1,function(x) length(grep("\\d+-9999.9",x)))>0 )
?#[1]? 7 11 14 15 30 32 39 40 42 45 46 53 60 65 66 68 69 70 73 74 75 78 80 82 83
#[26] 86 87 90 91 93

lst2 <- lapply(lst1,function(x) gsub("(\\d+)(-9999.9)","\\1 \\2",x))
?#lapply(lst2,function(x) x[grep("\\d+-9999.9",x)]) ##checking for the pattern

lst3 <- lapply(lst2,function(x) {x<-gsub("(-9999.9)(-9999.9)","\\1 \\2",x)})#
#lapply(lst3,function(x) x[grep("\\d+-9999.9",x)])? ##checking for the pattern
# lapply(lst3,function(x) x[grep("-9999.9",x)]) ###second check
lst4 <- lapply(lst3,function(x) gsub("(Day) (\\d+)","\\1_\\2", x[-1]))? #removed the additional header "V1", "V2", etc.

#sapply(lst4,function(x) length(strsplit(x[1]," ")[[1]])) #checking the number of columns that should be present
lst5 <- lapply(lst4,function(x) unlist(lapply(x, function(y) word(y,1,33))))
lst6 <- lapply(lst5,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
# head(lst6[[94]],3)
lst7 <- lapply(lst6,function(x) x[x$Year >=1961 & x$Year <=2005,])
#head(lst7[[45]],3)
?lst8 <- lapply(lst7,function(x) x[!is.na(x$Year),])


lst9 <- lapply(lst8,function(x) {
??? if((min(x$Year)>1961)|(max(x$Year)<2005)){
????? n1<- (min(x$Year)-1961)*12
????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
????? n2<- (2005-max(x$Year))*12
????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
?????? colnames(x1) <- colnames(x)
?????? colnames(x2) <- colnames(x)??? ??? 
????? x3<- rbind(x1,x,x2)
??? }
?? else if((min(x$Year)==1961) & (max(x$Year)==2005)) {
??? ????? if((min(x$Mo[x$Year==1961])>1)|(max(x$Mo[x$Year==2005])<12)){
??? ?? n1 <- min(x$Mo[x$Year==1961])-1
??? ?? x1 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
??? ?? n2 <- (12-max(x$Mo[x$Year==2005])) ??? ???? 
??? ?? x2 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
??? ?? colnames(x1) <- colnames(x)
??? ?? colnames(x2) <- colnames(x)
??? ?? x3 <- rbind(x1,x,x2)
??? ? }
??? ??? else {??? 
??? ??? x
??? }
???? 
??? } })

which(sapply(lst9,nrow)!=540)
#[1] 45 46 54 64 65 66 70 75 97
lst10 <- lapply(lst9,function(x) {x1 <- x[!is.na(x$Year),]
??? ??? ??? ?hx1 <- head(x1,1)
??? ??? ??? ?tx1 <- tail(x1,1)
??? ??? ??? ?x2 <- as.data.frame(matrix(NA, ncol=ncol(x), nrow=hx1$Mo-1))
??? ??? ??? ?x3 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=12-tx1$Mo))
??? ??? ??? ?colnames(x2) <- colnames(x)
??? ??? ??? ?colnames(x3) <- colnames(x)
??? ??? ??? ?if(nrow(x) < 540) rbind(x2,x,x3) else x? })
which(sapply(lst10,nrow)!=540)
#integer(0)



lst11 <-lapply(lst10,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) 
? lst12<- lapply(seq_along(lst10),function(i){
??? x<- lst11[[i]]
??? colnames(x)<- lstf1[i]
??? row.names(x)<- 1:nrow(x)
??? x
? })
res2 <-? do.call(cbind,lst11)
?dim(res2)
#[1] 16740??? 98
?
res2[res2==-9999.9]<-NA # change missing value identifier as in your data set
which(res2==-9999.9)
#integer(0)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst12<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst12,function(x) any(lapply(x,length)!=31)))
#[1] FALSE

lst22<-lapply(lst12,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res3 <- data.frame(dates=dates3,res2,stringsAsFactors=FALSE)
str(res3)
res3$dates<-as.Date(res3$dates)
res4 <- res3[!is.na(res3$dates),]
res4[1:3,1:3]
dim(res4)
?#[1] 16436??? 99


A.K.




On Friday, November 8, 2013 5:54 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi Ak,

I think I figured out how to do the sub-setting. All I needed was to use column 3 in Temperature_inventory and select matching .txt files in the .zip file. The final result would be a subset of files whose IDs are in column 3 of temp_inventory.
*************************************************************************
I also have this script which you developed for managing precipitation files. Now I want to use the same code for the temperature files I sent to you. I tried doing it with some errors.
Please try these scripts on my temperature data. If you need further information let me know.
Note here that -9999.99M is -9999.9M in the temperature files.

library(stringr)# load it
res<-lapply(temp,function(x) {con <- file(x);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines1<- readLines(con);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?close(con);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines2<-Lines1[-1];# myfiles contain headers in row 2, so I removed the headers
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines3<- str_split(Lines2,"-9999.99M");
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines4<- str_trim(unlist(lapply(Lines3,function(x){x[x==""]<-NA;#replace missing identifier with NA
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? paste(x,collapse=" ")})));
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines5<- gsub("(\\d+)[A-Za-z]","\\1",Lines4);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?res<- read.table(text=Lines5,sep="",header=FALSE,fill=TRUE)})
lapply(res,head,2)# take a look at first two rows of res.
lapply(seq_along(res),function(i) write.table(res[[i]],paste0(gsub(".txt","",temp[i]),".txt"),row.names=FALSE,quote=FALSE))
#********************************************************************************************************
# Then use the following as a continuation from the one above

lstf1<- list.files(pattern=".txt")
length(lstf1)
fun2<- function(lstf){
? lst1<-lapply(lstf,function(x) readLines(x))
? lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})#change missing value identifier as in your data set
? lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})#change missing value identifier as in your data set
? lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
? lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
? lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
? lst7<- lapply(lst6,function(x) {
? ? if((min(x$V1)>1961)|(max(x$V1)<2005)){
? ? ? n1<- (min(x$V1)-1961)*12
? ? ? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
? ? ? n2<- (2005-max(x$V1))*12
? ? ? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
? ? ? x3<- rbind(x1,x,x2)
? ? }
? ? else {
? ? ? x
? ? } })
? lst8<-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) ####changed
? lst9<- lapply(seq_along(lst8),function(i){
? ? x<- lst8[[i]]
? ? colnames(x)<- lstf1[i]
? ? row.names(x)<- 1:nrow(x)
? ? x
? })
? do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
res[res==-9999.99]<-NA # change missing value identifier as in your data set
which(res==-9999.99)#change missing value identifier as in your data set
dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst11<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst1,function(x) any(lapply(x,length)!=31)))
lst22<-lapply(lst11,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res1<- data.frame(dates=dates3,res,stringsAsFactors=FALSE)
str(res1)
res1$dates<-as.Date(res1$dates)
res2<-res1[!is.na(res1$dates),]
res2[1:3,1:3]
dim(res2)
write.csv(res2, file = "TemperatureAllstations.csv")#
#***********************************************************************************

Waiting for your useful input.

Thanks so much,
Atem.




On Friday, November 8, 2013 2:18 PM, arun <sm
you wanted to do.? If you want to transfer the subset of files from the main folder to a new location, then you may try: (make sure you create a copy of the original .txt folder before doing this)
I created three sub folders and two files (BTemperature_Stations.txt and Tempearture inventory.csv) in my working directory.


list.files()
#[1] "BTemperature_Stations.txt" "Files1"????????? ## Files1 folder contains all the .txt files; #SubsetFiles: created to subset the files that match the condition???????????????? 
#[3]
"FilesCopy"???????????????? "SubsetFiles1"????????? #FilesCopy. A copy of the Files1 folder?? 
#[5] "Tempearture inventory.csv"




list.files(pattern="\\.")
#[1] "BTemperature_Stations.txt" "Tempearture inventory.csv"
fl1 <- list.files(pattern="\\.")
?dat1 <- read.table(fl1[1],header=TRUE,sep="",stringsAsFactors=FALSE,fill=TRUE,check.names=FALSE)
?dat2 <- read.csv(fl1[2],header=TRUE,sep=",",stringsAsFactors=FALSE,check.names=FALSE)
vec1 <- dat1[,3][dat1[,3]%in% dat2[,3]]
vec2 <- list.files(path="/home/arunksa111/Zl/Files1",recursive=TRUE)
?sum(gsub(".txt","",vec2) %in% vec1)
#[1] 98
vec3 <-? vec2[gsub(".txt","",vec2) %in% vec1]
lapply(vec3, function(x) file.rename(paste("/home/arunksa111/Zl/Files1",x,sep="/"), paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"))) #change the path accordingly. 
length(list.files(path="/home/arunksa111/Zl/SubsetFiles1"))
#[1] 98

fileDim <- sapply(vec3,function(x) {x1 <-read.delim(paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"),header=TRUE,stringsAsFactors=FALSE,sep=",",check.names=FALSE); dim(x1)})
fileDim[,1:3]
#???? dn3011120.txt dn3011240.txt dn3011887.txt
#[1,]????????? 1151?????????? 791????????? 1054
#[2,]???????????? 7???????????? 7???????????? 7


A.K.






On Friday, November 8, 2013 1:41 PM, Zilefac Elvis <
les from a list of files. All are text files. The index for selection is found in column 3 of both files.


Attached are my data files.
Btemperature_Stations is my
main file.
Temperature inventory is my 'wanted' file and is a subset of Btemperature_Stations.
Using column 3 in both files, select the files in?Temperature inventory from?Btemperature_Stations.
The .zip file contains the .txt files which you will extract to a folder and do the selection in R.

Thanks,
Atem.


From smartpink111 at yahoo.com  Sun Nov 10 01:27:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 9 Nov 2013 16:27:03 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1384037214.39832.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383936055.76561.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1383941883.12484.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1383951262.61119.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1384037214.39832.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1384043223.37448.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,

The code could be shortened by using ?merge or ?join().
library(plyr)
##Using the output from `lst6`


lst7 <- lapply(lst6,function(x) {x1 <- data.frame(Year=rep(1961:2005,each=12),Mo=rep(1:12,45)); x2 <-join(x1,x,type="left",by=c("Year","Mo"))})

##rest are the same (only change in object names)

?sapply(lst7,nrow)
?lst8 <-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) 
? lst9<- lapply(seq_along(lst8),function(i){
??? x<- lst11[[i]]
??? colnames(x)<- lstf1[i]
??? row.names(x)<- 1:nrow(x)
??? x
? })?
sapply(lst9,nrow)
res2New <- do.call(cbind,lst9)
?dim(res2New)
#[1] 16740??? 98
res2New[res2New ==-9999.9]<-NA # change missing value identifier as in your data set
which(res2New==-9999.9)
#integer(0)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst12<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst12,function(x) any(lapply(x,length)!=31)))
#[1] FALSE

lst22<-lapply(lst12,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res3New <- data.frame(dates=dates3,res2New,stringsAsFactors=FALSE)
str(res3New)
res3New$dates<-as.Date(res3New$dates)
res4New <- res3New[!is.na(res3New$dates),]
res4New[1:3,1:3]
dim(res4New)
colnames(res4) <- colnames(res4New)
?identical(res4,res4New)
#[1] TRUE

A.K.





On Saturday, November 9, 2013 5:46 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Try:
library(stringr)
##### Created the selected files (98) in a separate working? folder (SubsetFiles1) (refer to my previous mail)
filelst <- list.files()
#Sublst <- filelst[1:2]
res <- lapply(filelst,function(x) {con <- file(x)
??? ?Lines1 <- readLines(con) close(con)
??? ?Lines2 <- Lines1[-1]
??? ?Lines3 <- str_split(Lines2,"-9999.9M")
??? ?Lines4 <- str_trim(unlist(lapply(Lines3,function(x) {x[x==""] <- NA
??? ?paste(x,collapse=" ")})))
??? ?Lines5 <- gsub("(\\d+)[A-Za-z]","\\1",Lines4)
??? ?res1 <- read.table(text=Lines5,sep="",header=FALSE,fill=TRUE)
??? ?res1})

##Created another folder "Modified" to store the "res" files
lapply(seq_along(res),function(i) write.table(res[[i]],paste("/home/arunksa111/Zl/Modified",paste0("Mod_",filelst[i]),sep="/"),row.names=FALSE,quote=FALSE))

?lstf1 <- list.files(path="/home/arunksa111/Zl/Modified")? 

lst1 <- lapply(lstf1,function(x) readLines(paste("/home/arunksa111/Zl/Modified",x,sep="/")))
?which(lapply(lst1,function(x) length(grep("\\d+-9999.9",x)))>0 )
?#[1]? 7 11 14 15 30 32 39 40 42 45 46 53 60 65 66 68 69 70 73 74 75 78 80 82 83
#[26] 86 87 90 91 93

lst2 <- lapply(lst1,function(x) gsub("(\\d+)(-9999.9)","\\1 \\2",x))
?#lapply(lst2,function(x) x[grep("\\d+-9999.9",x)]) ##checking for the pattern

lst3 <- lapply(lst2,function(x) {x<-gsub("(-9999.9)(-9999.9)","\\1 \\2",x)})#
#lapply(lst3,function(x) x[grep("\\d+-9999.9",x)])? ##checking for the pattern
# lapply(lst3,function(x) x[grep("-9999.9",x)]) ###second check
lst4 <- lapply(lst3,function(x) gsub("(Day) (\\d+)","\\1_\\2", x[-1]))? #removed the additional header "V1", "V2", etc.

#sapply(lst4,function(x) length(strsplit(x[1]," ")[[1]])) #checking the number of columns that should be present
lst5 <- lapply(lst4,function(x) unlist(lapply(x, function(y) word(y,1,33))))
lst6 <- lapply(lst5,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
# head(lst6[[94]],3)
lst7 <- lapply(lst6,function(x) x[x$Year >=1961 & x$Year <=2005,])
#head(lst7[[45]],3)
?lst8 <- lapply(lst7,function(x) x[!is.na(x$Year),])


lst9 <- lapply(lst8,function(x) {
??? if((min(x$Year)>1961)|(max(x$Year)<2005)){
????? n1<- (min(x$Year)-1961)*12
????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
????? n2<- (2005-max(x$Year))*12
????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
?????? colnames(x1) <- colnames(x)
?????? colnames(x2) <- colnames(x)??? ??? 
????? x3<- rbind(x1,x,x2)
??? }
?? else if((min(x$Year)==1961) & (max(x$Year)==2005)) {
??? ????? if((min(x$Mo[x$Year==1961])>1)|(max(x$Mo[x$Year==2005])<12)){
??? ?? n1 <- min(x$Mo[x$Year==1961])-1
??? ?? x1 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
??? ?? n2 <- (12-max(x$Mo[x$Year==2005])) ??? ???? 
??? ?? x2 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
??? ?? colnames(x1) <- colnames(x)
??? ?? colnames(x2) <- colnames(x)
??? ?? x3 <- rbind(x1,x,x2)
??? ? }
??? ??? else {??? 
??? ??? x
??? }
???? 
??? } })

which(sapply(lst9,nrow)!=540)
#[1] 45 46 54 64 65 66 70 75 97
lst10 <- lapply(lst9,function(x) {x1 <- x[!is.na(x$Year),]
??? ??? ??? ?hx1 <- head(x1,1)
??? ??? ??? ?tx1 <- tail(x1,1)
??? ??? ??? ?x2 <- as.data.frame(matrix(NA, ncol=ncol(x), nrow=hx1$Mo-1))
??? ??? ??? ?x3 <- as.data.frame(matrix(NA,ncol=ncol(x),nrow=12-tx1$Mo))
??? ??? ??? ?colnames(x2) <- colnames(x)
??? ??? ??? ?colnames(x3) <- colnames(x)
??? ??? ??? ?if(nrow(x) < 540) rbind(x2,x,x3) else x? })
which(sapply(lst10,nrow)!=540)
#integer(0)



lst11 <-lapply(lst10,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) 
? lst12<- lapply(seq_along(lst10),function(i){
??? x<- lst11[[i]]
??? colnames(x)<- lstf1[i]
??? row.names(x)<- 1:nrow(x)
??? x
? })
res2 <-? do.call(cbind,lst11)
?dim(res2)
#[1] 16740??? 98
?
res2[res2==-9999.9]<-NA # change missing value identifier as in your data set
which(res2==-9999.9)
#integer(0)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst12<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst12,function(x) any(lapply(x,length)!=31)))
#[1] FALSE

lst22<-lapply(lst12,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res3 <- data.frame(dates=dates3,res2,stringsAsFactors=FALSE)
str(res3)
res3$dates<-as.Date(res3$dates)
res4 <- res3[!is.na(res3$dates),]
res4[1:3,1:3]
dim(res4)
?#[1] 16436??? 99


A.K.





On Friday, November 8, 2013 5:54 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hi Ak,

I think I figured out how to do the sub-setting. All I needed was to use column 3 in Temperature_inventory and select matching .txt files in the .zip file. The final result would be a subset of files whose IDs are in column 3 of temp_inventory.
*************************************************************************
I also have this script which you developed for managing precipitation files. Now I want to use the same code for the temperature files I sent to you. I tried doing it with some errors.
Please try these scripts on my temperature data. If you need further information let me know.
Note here that -9999.99M is -9999.9M in the temperature files.

library(stringr)# load it
res<-lapply(temp,function(x) {con <- file(x);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines1<- readLines(con);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?close(con);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines2<-Lines1[-1];# myfiles contain headers in row 2, so I removed the headers
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines3<- str_split(Lines2,"-9999.99M");
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines4<- str_trim(unlist(lapply(Lines3,function(x){x[x==""]<-NA;#replace missing identifier with NA
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? paste(x,collapse=" ")})));
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Lines5<- gsub("(\\d+)[A-Za-z]","\\1",Lines4);
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?res<- read.table(text=Lines5,sep="",header=FALSE,fill=TRUE)})
lapply(res,head,2)# take a look at first two rows of res.
lapply(seq_along(res),function(i) write.table(res[[i]],paste0(gsub(".txt","",temp[i]),".txt"),row.names=FALSE,quote=FALSE))
#********************************************************************************************************
# Then use the following as a continuation from the one above

lstf1<- list.files(pattern=".txt")
length(lstf1)
fun2<- function(lstf){
? lst1<-lapply(lstf,function(x) readLines(x))
? lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})#change missing value identifier as in your data set
? lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})#change missing value identifier as in your data set
? lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
? lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
? lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
? lst7<- lapply(lst6,function(x) {
? ? if((min(x$V1)>1961)|(max(x$V1)<2005)){
? ? ? n1<- (min(x$V1)-1961)*12
? ? ? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
? ? ? n2<- (2005-max(x$V1))*12
? ? ? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
? ? ? x3<- rbind(x1,x,x2)
? ? }
? ? else {
? ? ? x
? ? } })
? lst8<-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) ####changed
? lst9<- lapply(seq_along(lst8),function(i){
? ? x<- lst8[[i]]
? ? colnames(x)<- lstf1[i]
? ? row.names(x)<- 1:nrow(x)
? ? x
? })
? do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
res[res==-9999.99]<-NA # change missing value identifier as in your data set
which(res==-9999.99)#change missing value identifier as in your data set
dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst11<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst1,function(x) any(lapply(x,length)!=31)))
lst22<-lapply(lst11,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res1<- data.frame(dates=dates3,res,stringsAsFactors=FALSE)
str(res1)
res1$dates<-as.Date(res1$dates)
res2<-res1[!is.na(res1$dates),]
res2[1:3,1:3]
dim(res2)
write.csv(res2, file = "TemperatureAllstations.csv")#
#***********************************************************************************

Waiting for your useful input.

Thanks so much,
Atem.




On Friday, November 8, 2013 2:18 PM, arun
hat you wanted to do.? If you want to transfer the subset of files from the main folder to a new location, then you may try: (make sure you create a copy of the original .txt folder before doing this)
I created three sub folders and two files (BTemperature_Stations.txt and Tempearture inventory.csv) in my working directory.


list.files()
#[1] "BTemperature_Stations.txt" "Files1"????????? ## Files1 folder contains all the .txt files; #SubsetFiles: created to subset the files that match the condition???????????????? 
#[3]
"FilesCopy"???????????????? "SubsetFiles1"????????? #FilesCopy. A copy of the Files1 folder?? 
#[5] "Tempearture inventory.csv"




list.files(pattern="\\.")
#[1] "BTemperature_Stations.txt" "Tempearture inventory.csv"
fl1 <- list.files(pattern="\\.")
?dat1 <- read.table(fl1[1],header=TRUE,sep="",stringsAsFactors=FALSE,fill=TRUE,check.names=FALSE)
?dat2 <- read.csv(fl1[2],header=TRUE,sep=",",stringsAsFactors=FALSE,check.names=FALSE)
vec1 <- dat1[,3][dat1[,3]%in% dat2[,3]]
vec2 <- list.files(path="/home/arunksa111/Zl/Files1",recursive=TRUE)
?sum(gsub(".txt","",vec2) %in% vec1)
#[1] 98
vec3 <-? vec2[gsub(".txt","",vec2) %in% vec1]
lapply(vec3, function(x) file.rename(paste("/home/arunksa111/Zl/Files1",x,sep="/"), paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"))) #change the path accordingly. 
length(list.files(path="/home/arunksa111/Zl/SubsetFiles1"))
#[1] 98

fileDim <- sapply(vec3,function(x) {x1 <-read.delim(paste("/home/arunksa111/Zl/SubsetFiles1",x,sep="/"),header=TRUE,stringsAsFactors=FALSE,sep=",",check.names=FALSE); dim(x1)})
fileDim[,1:3]
#???? dn3011120.txt dn3011240.txt dn3011887.txt
#[1,]????????? 1151?????????? 791????????? 1054
#[2,]???????????? 7???????????? 7???????????? 7


A.K.






On Friday, November 8, 2013 1:41 PM, Zilefac
 some files from a list of files. All are text files. The index for selection is found in column 3 of both files.


Attached are my data files.
Btemperature_Stations is my
main file.
Temperature inventory is my 'wanted' file and is a subset of Btemperature_Stations.
Using column 3 in both files, select the files in?Temperature inventory from?Btemperature_Stations.
The .zip file contains the .txt files which you will extract to a folder and do the selection in R.

Thanks,
Atem.


From murdoch.duncan at gmail.com  Sun Nov 10 02:29:52 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 09 Nov 2013 20:29:52 -0500
Subject: [R] Tables Package Grouping Factors
In-Reply-To: <835b11e2-322e-48d2-9de8-a8fe082663d5@email.android.com>
References: <alpine.BSF.2.00.1311091010120.52177@pedal.dcn.davis.ca.us>
	<527E8D42.2030405@gmail.com>
	<835b11e2-322e-48d2-9de8-a8fe082663d5@email.android.com>
Message-ID: <527EE190.1040804@gmail.com>

On 13-11-09 5:56 PM, Jeff Newmiller wrote:
> The problem that prompted this question involved manufacturers and their model numbers, so I think the cross everything and throw away most of it will get out of hand quickly. The number of models per manufacturer definitely varies. I think I will work on the print segments of the table successively approach. Thanks for the ideas.

I've just added cbind() and rbind() methods for tabular objects, so that 
approach will be a lot easier.  Just do the table of the first subset, 
then rbind on the subsets for the rest.  Will commit to R-forge after a 
bit more testing and documentation.

Duncan Murdoch

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-11-09 1:23 PM, Jeff Newmiller wrote:
>>> Visually, the elimination of duplicates in hierarchical tables in the
>>> tabular function from the tables package is very nice. I would like
>> to do
>>> the same thing with non-crossed factors, but am perhaps missing some
>>> conceptual element of how this package is used. The following code
>>> illustrates my goal (I hope):
>>>
>>> library(tables)
>>> sampledf <- data.frame( Sex=rep(c("M","F"),each=6)
>>>               ,
>> Name=rep(c("John","Joe","Mark","Alice","Beth","Jane"),each=2)
>>>               , When=rep(c("Before","After"),times=6)
>>>               ,
>> Weight=c(180,190,190,180,200,200,140,145,150,140,135,135)
>>>               )
>>> sampledf$SexName <- factor( paste( sampledf$Sex, sampledf$Name ) )
>>>
>>> # logically, this is the layout
>>> tabular( Name ~ Heading()* When * Weight * Heading()*identity,
>>> data=sampledf )
>>>
>>> # but I want to augment the Name with the Sex but visually group the
>>> # Sex like
>>> #   tabular( Sex*Name ~ Heading()*When * Weight * Heading()*identity,
>>> data=sampledf )
>>> # would except that there really is no crossing between sexes.
>>> tabular( SexName ~ Heading()*When * Weight * Heading()*identity,
>>> data=sampledf )
>>> # this repeats the Sex category excessively.
>>
>> I forgot, there's a simpler way to do this.  Build the full table with
>> the junk values, then take a subset:
>>
>> full <- tabular( Sex*Name ~ Heading()*When * Weight *
>> Heading()*identity, data=sampledf )
>>
>> full[c(1:3, 10:12), ]
>>
>> Figuring out which rows you want to keep can be a little tricky, but
>> doing something like this might be good:
>>
>> counts <- tabular( Sex*Name ~ 1, data=sampledf )
>> full[ as.logical(counts), ]
>>
>> Duncan Murdoch
>


From h.wickham at gmail.com  Sun Nov 10 08:31:35 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sun, 10 Nov 2013 02:31:35 -0500
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
Message-ID: <CABdHhvE+CDzdq+0C6_9YW6vgDUUy0SFu8vjT7xNhf-h=X83+RA@mail.gmail.com>

Modelling a mutable entity, i.e. an account, is really a perfect
example of when to use reference classes.  You might find the examples
on http://adv-r.had.co.nz/OO-essentials.html give you a better feel
for the strengths and weaknesses of R's different OO systems.

Hadley

On Sat, Nov 9, 2013 at 9:31 AM, daniel schnaider <dschnaider at gmail.com> wrote:
> It is my first time programming with S4 and I can't get the setter fuction
> to actually change the value of the slot created by the constructor.
>
> I guess it has to do with local copy, global copy, etc. of the variable -
> but, I could't find anything relevant in documentation.
>
> Tried to copy examples from the internet, but they had the same problem.
>
> # The code
>     setClass ("Account" ,
>                representation (
>                customer_id = "character",
>                transactions = "matrix")
>     )
>
>
>     Account <- function(id, t) {
>             new("Account", customer_id = id, transactions = t)
>             }
>
>
>     setGeneric ("CustomerID<-", function(obj,
> id){standardGeneric("CustomerID<-")})
>     setReplaceMethod("CustomerID", "Account", function(obj, id){
>         obj at customer_id <- id
>         obj
>         })
>
>         ac <- Account("12345", matrix(c(1,2,3,4,5,6), ncol=2))
>         ac
>         CustomerID <- "54321"
>         ac
>
> #Output
>         > ac
>         An object of class "Account"
>         Slot "customer_id":
>         [1] "12345"
>
>         Slot "transactions":
>              [,1] [,2]
>         [1,]    1    4
>         [2,]    2    5
>         [3,]    3    6
>
> # CustomerID is value has changed to 54321, but as you can see it does't
>         > CustomerID <- "54321"
>         > ac
>         An object of class "Account"
>         Slot "customer_id":
>         [1] "12345"
>
>         Slot "transactions":
>              [,1] [,2]
>         [1,]    1    4
>         [2,]    2    5
>         [3,]    3    6
>
>
> Help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Chief Scientist, RStudio
http://had.co.nz/


From smartpink111 at yahoo.com  Sun Nov 10 04:32:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 9 Nov 2013 19:32:39 -0800 (PST)
Subject: [R] making chains from pairs
In-Reply-To: <CAKyZeBs4qMiBY=3yZ6W30x+imgL+LSxKNtPxW_hm=rzNF9B4=w@mail.gmail.com>
References: <CAKyZeBs4qMiBY=3yZ6W30x+imgL+LSxKNtPxW_hm=rzNF9B4=w@mail.gmail.com>
Message-ID: <1384054359.90629.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

May be this helps.? But, the conditions are not very clear.
lst1 <- lapply(split(test,test$V1),function(x) unique(as.vector(t(x))))

indx <- unlist(lapply(lst1,function(x) which(names(lst1) %in% x)))
lst2 <- split(gsub("\\d+","",names(indx)),indx)
indx1 <- duplicated(lapply(lst2,`[`,1))|!(duplicated(lapply(lst2,`[`,1))|duplicated(lapply(lst2,`[`,1),fromLast=TRUE))
lapply(lst2[indx1],function(x) unique(unlist(lst1[x])))

A.K.





On Friday, November 8, 2013 10:50 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
Hello,

having a data frame like test with pairs of characters I would like to
create chains. For instance from the pairs A/B and B/I you get the vector A
B I. It is like jumping from one pair to the next related pair. So for my
example test you should get:
A B F G H I
C F I K
D L M N O P


> test
?  V1 V2
1?  A? B
2?  A? F
3?  A? G
4?  A? H
5?  B? F
6?  B? I
7?  C? F
8?  C? I
9?  C? K
10? D? L
11? D? M
12? D? N
13? L? O
14? L? P

Thanks
Hermann

> dput (test)
structure(list(V1 = c("A", "A", "A", "A", "B", "B", "C", "C",
"C", "D", "D", "D", "L", "L"), V2 = c("B", "F", "G", "H", "F",
"I", "F", "I", "K", "L", "M", "N", "O", "P")), .Names = c("V1",
"V2"), row.names = c(NA, -14L), class = "data.frame")
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Nov 10 06:11:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 9 Nov 2013 21:11:56 -0800 (PST)
Subject: [R] finding a min against an id in a column
In-Reply-To: <1384050357.81616.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1384050357.81616.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1384060316.65561.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
Try:
?df <- data.frame(ID=c("ID1","ID1","ID2","ID3","ID1","ID2"), date=c("Mar03","Mar01","Mar05","Mar02","Mar02","Mar01"),stringsAsFactors=FALSE)
?#as.Date(paste0(1,df[,2]),"%d%b%y") #assuming that year represents the digits
#as.Date(paste0(2001,df[,2]),"%Y%b%d")# if the digits represent days


#or
#strptime(df[,2],"%b%d")



#Either
aggregate(date~ID,data=df,function(x) format(min(as.Date(paste0(2001,x),"%Y%b%d")),"%b%d"))

#or

library(plyr)
ddply(df,.(ID),summarize, date=format(min(as.Date(paste0(2001,date),"%Y%b%d")),"%b%d"))

#or

?df1 <- df[with(df,order(ID,as.Date(paste0(2001,date),"%Y%b%d"))),]
df1[c(1,diff(as.numeric(gsub("[^0-9]","",df1$ID)))) !=0,]

#or
?df1[c(TRUE,df1$ID[-1] != df1$ID[-length(df1$ID)]),]


A.K.




I need some help to do something in r that is done using pivots in excel. 

I have a data frame with IDs and dates against these ids. I need to get the minimum date against each id. 
eg. 
my datra frame is 
df[,1]=c(ID1,ID1,ID2,ID3,ID1,ID2) 
df[,2]=c(Mar03,Mar01. Mar 05,Mar02,Mar02,Mar01) 

I need the result to show 
ndf[,1] = ID1 ID2 ID3 
ndf[,2] = Mar01 Mar 02 Mar 05 

thanks...


From pmaclean2011 at yahoo.com  Sun Nov 10 07:05:42 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Sat, 9 Nov 2013 22:05:42 -0800 (PST)
Subject: [R] Cross Tabulation
Message-ID: <1384063542.77900.YahooMailNeo@web121702.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131109/45b4f401/attachment.pl>

From mtmorgan at fhcrc.org  Sun Nov 10 15:33:25 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 10 Nov 2013 06:33:25 -0800
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <CAPOwdSoH7y4QAPmEfbBc-DOKwo9NxE68odj3Au5rmipnJowCuw@mail.gmail.com>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
	<527E7CD4.1030701@fhcrc.org>
	<CAPOwdSoH7y4QAPmEfbBc-DOKwo9NxE68odj3Au5rmipnJowCuw@mail.gmail.com>
Message-ID: <527F9935.9020304@fhcrc.org>

On 11/10/2013 03:54 AM, daniel schnaider wrote:
> Thanks Martin. It worked well.
> Two new questions related to the same subject.
>
> 1) Why create this semantic of a final argument name specifically names value?

I do not know. It is a requirement of replacement methods in R in general, not 
just S4 methods. See section 3.4.4 of RShowDoc("R-lang").

> 2) Regarding performance. When CustomerID(ac) <- "54321" runs, does it only
> change the slot from whatever it was to 54321, or it really create another
> object and change all the value of all slots, keeping technically all the other
> values equal and changing 54321?

Copying is tricky in R. It behaves as though a copy has been made of the entire 
object. Whether a copy is actually made, or just marked as necessary on 
subsequent modification, requires deep consideration of the code. This is the 
way R works, not just the way S4 classes work.

If instead of a single account you modelled 'Accounts', i.e., all accounts, then 
updating 1000 account id's would only make one copy, whereas if you model each 
account separately this would require 1000 copies.

Martin

>
> thanks..
>
>
> On Sat, Nov 9, 2013 at 4:20 PM, Martin Morgan <mtmorgan at fhcrc.org
> <mailto:mtmorgan at fhcrc.org>> wrote:
>
>     On 11/09/2013 06:31 AM, daniel schnaider wrote:
>
>         It is my first time programming with S4 and I can't get the setter fuction
>         to actually change the value of the slot created by the constructor.
>
>         I guess it has to do with local copy, global copy, etc. of the variable -
>         but, I could't find anything relevant in documentation.
>
>         Tried to copy examples from the internet, but they had the same problem.
>
>         # The code
>               setClass ("Account" ,
>                          representation (
>                          customer_id = "character",
>                          transactions = "matrix")
>               )
>
>
>               Account <- function(id, t) {
>                       new("Account", customer_id = id, transactions = t)
>                       }
>
>
>               setGeneric ("CustomerID<-", function(obj,
>         id){standardGeneric("__CustomerID<-")})
>
>
>     Replacement methods (in R in general) require that the final argument (the
>     replacement value) be named 'value', so
>
>          setGeneric("CustomerID<-",
>              function(x, ..., value) standardGeneric("CustomerID"))
>
>          setReplaceMethod("CustomerID", c("Account", "character"),
>              function(x, ...., value)
>          {
>              x at customer_id <- value
>              x
>          })
>
>     use this as
>
>         CustomerID(ac) <- "54321"
>
>
>
>               setReplaceMethod("CustomerID", "Account", function(obj, id){
>                   obj at customer_id <- id
>                   obj
>                   })
>
>                   ac <- Account("12345", matrix(c(1,2,3,4,5,6), ncol=2))
>                   ac
>                   CustomerID <- "54321"
>                   ac
>
>         #Output
>                   > ac
>                   An object of class "Account"
>                   Slot "customer_id":
>                   [1] "12345"
>
>                   Slot "transactions":
>                        [,1] [,2]
>                   [1,]    1    4
>                   [2,]    2    5
>                   [3,]    3    6
>
>         # CustomerID is value has changed to 54321, but as you can see it does't
>                   > CustomerID <- "54321"
>
>
>                   > ac
>                   An object of class "Account"
>                   Slot "customer_id":
>                   [1] "12345"
>
>                   Slot "transactions":
>                        [,1] [,2]
>                   [1,]    1    4
>                   [2,]    2    5
>                   [3,]    3    6
>
>
>         Help!
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     --
>     Computational Biology / Fred Hutchinson Cancer Research Center
>     1100 Fairview Ave. N.
>     PO Box 19024 Seattle, WA 98109
>
>     Location: Arnold Building M1 B861
>     Phone: (206) 667-2793
>
>
>
>
> --
> Daniel Schnaider
>
> SP Phone:  +55-11-9.7575.0822
>
>
> ds at scaigroup.com <mailto:ds at scaigroup.com>
> skype dschnaider
> Linked In: http://www.linkedin.com/in/danielschnaider
>
> w <http://www.arkiagroup.com/>ww.scaigroup.com <http://ww.scaigroup.com/>
>
> Depoimentos de clientes <http://www.scaigroup.com/Projetos/depoimentos>
>
> Casos de Sucesso & Refer?ncias <http://www.scaigroup.com/Projetos>
>
> SCAI Group no Facebook <http://facebook.scaigroup.com/>
>
> SCAI Group no Twitter <http://twitter.scaigroup.com/>
>
> SCAI Group no Google Plus <http://plus.scaigroup.com/>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From mtmorgan at fhcrc.org  Sun Nov 10 15:49:34 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 10 Nov 2013 06:49:34 -0800
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <CABdHhvE+CDzdq+0C6_9YW6vgDUUy0SFu8vjT7xNhf-h=X83+RA@mail.gmail.com>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
	<CABdHhvE+CDzdq+0C6_9YW6vgDUUy0SFu8vjT7xNhf-h=X83+RA@mail.gmail.com>
Message-ID: <527F9CFE.4050102@fhcrc.org>

On 11/09/2013 11:31 PM, Hadley Wickham wrote:
> Modelling a mutable entity, i.e. an account, is really a perfect
> example of when to use reference classes.  You might find the examples
> on http://adv-r.had.co.nz/OO-essentials.html give you a better feel
> for the strengths and weaknesses of R's different OO systems.

Reference classes provide less memory copying and a more familiar programming 
paradigm but not necessarily fantastic performance, as illustrated here

http://stackoverflow.com/questions/18677696/stack-class-in-r-something-more-concise/18678440#18678440

and I think elsewhere on this or the R-devel list (sorry not to be able to 
provide a more precise recollection).

Martin


>
> Hadley
>
> On Sat, Nov 9, 2013 at 9:31 AM, daniel schnaider <dschnaider at gmail.com> wrote:
>> It is my first time programming with S4 and I can't get the setter fuction
>> to actually change the value of the slot created by the constructor.
>>
>> I guess it has to do with local copy, global copy, etc. of the variable -
>> but, I could't find anything relevant in documentation.
>>
>> Tried to copy examples from the internet, but they had the same problem.
>>
>> # The code
>>      setClass ("Account" ,
>>                 representation (
>>                 customer_id = "character",
>>                 transactions = "matrix")
>>      )
>>
>>
>>      Account <- function(id, t) {
>>              new("Account", customer_id = id, transactions = t)
>>              }
>>
>>
>>      setGeneric ("CustomerID<-", function(obj,
>> id){standardGeneric("CustomerID<-")})
>>      setReplaceMethod("CustomerID", "Account", function(obj, id){
>>          obj at customer_id <- id
>>          obj
>>          })
>>
>>          ac <- Account("12345", matrix(c(1,2,3,4,5,6), ncol=2))
>>          ac
>>          CustomerID <- "54321"
>>          ac
>>
>> #Output
>>          > ac
>>          An object of class "Account"
>>          Slot "customer_id":
>>          [1] "12345"
>>
>>          Slot "transactions":
>>               [,1] [,2]
>>          [1,]    1    4
>>          [2,]    2    5
>>          [3,]    3    6
>>
>> # CustomerID is value has changed to 54321, but as you can see it does't
>>          > CustomerID <- "54321"
>>          > ac
>>          An object of class "Account"
>>          Slot "customer_id":
>>          [1] "12345"
>>
>>          Slot "transactions":
>>               [,1] [,2]
>>          [1,]    1    4
>>          [2,]    2    5
>>          [3,]    3    6
>>
>>
>> Help!
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From gunter.berton at gene.com  Sun Nov 10 16:10:43 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 10 Nov 2013 07:10:43 -0800
Subject: [R] union of list objects if objects intersect
In-Reply-To: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
References: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
Message-ID: <CACk-te2OJ4X6ALrCgLjOUcS1w3rdE0NMbpnZpnFp-oR9kP08Pg@mail.gmail.com>

Your specification is a unclear (to me anyway): What do you want to
return if the intersection is empty? What if intersect(ja[[i]],
ja[[i+1]]) is empty for all i? What if  length(intersect( ja[[i]],
ja[[i+1]] )) ==0 but intersect(ja[[i]],ja[[i+2]]) is nonempty?  Your
example isn't -- you did not specify what the return should be on your
list.

Note also that your example test  is wrong: the length of the
intersection must =0 not the intersection.

-- Bert



On Sat, Nov 9, 2013 at 12:45 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> I have a list called ja and I wish to unify list objects if there is some
> overlap.
> For instance something like
>
> if (length (intersect (ja[[1]], ja[[2]]) !=0) { union (ja[[1]], ja[[2]] }
>
> but of course it should work cumulatively (for larger data sets).
>
> Could you please give me a hint.
>
> Thanks
> Hermann
>
>> ja
> $A
> [1] "A" "B" "F" "G" "H"
>
> $B
> [1] "B" "F" "I"
>
> $C
> [1] "C" "F" "I" "K"
>
> $D
> [1] "D" "L" "M" "N"
>
> $L
> [1] "L" "O" "P"
>
>
> dput (ja)
> structure(list(A = c("A", "B", "F", "G", "H"), B = c("B", "F",
> "I"), C = c("C", "F", "I", "K"), D = c("D", "L", "M", "N"), L = c("L",
> "O", "P")), .Names = c("A", "B", "C", "D", "L"))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Sun Nov 10 16:47:33 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 10 Nov 2013 07:47:33 -0800
Subject: [R] union of list objects if objects intersect
In-Reply-To: <CAKyZeBsZANpEthQV-prAEGD44fEi7JzkvLXCzFQfhQGUA6tpeg@mail.gmail.com>
References: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
	<CACk-te2OJ4X6ALrCgLjOUcS1w3rdE0NMbpnZpnFp-oR9kP08Pg@mail.gmail.com>
	<CAKyZeBsZANpEthQV-prAEGD44fEi7JzkvLXCzFQfhQGUA6tpeg@mail.gmail.com>
Message-ID: <CACk-te220VXkMcY9NtYXsXC=--oDaEFB7BDEgGy9um3P6RAjPA@mail.gmail.com>

I'll leave it to others to muddle through your code. It appears to
refer to an earlier post that you did not include.  Note also that you
still have not specified what you want to get from your example ja
list.  Doing so might help you get a useful response, which mine
clearly is not.

Cheers,
Bert

On Sun, Nov 10, 2013 at 7:38 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> My purpose is to create chains of list objects if elements of the object
> overlap. If there is no overlap the object remains as it is. My plan is to
> identify snps that are in ld. The letters in each list object represent snps
> that are in ld in respect to the first snp (or letter). The first snp (or
> letter) is identical with names (list), respectively.
> Yes, (@Bert) my example was wrong. But the function I posted is correct, I
> hope. At least it does what I want for some sets I tested.
>
> snp.block <- function (huz)
>     {
>         for (i in names (huz))
>              {
>                  chain1 <- huz[[i]]
>                  for (k in names (huz))
>                      {
>                          chain2 <- huz[[k]]
>                          if (k==i)
>                              {
>
>    next
>                              }
>                          else if (length (intersect (chain1, chain2))!=0)
>                              {
>                                  chain3 <- union (chain1, chain2)
>                                  chain1 <- chain3
>                                  huz[[i]] <- sort (chain3)
>                              }
>                          else if (length (intersect (chain1, chain2)) == 0)
>                              {
>                                  chain3 <- chain1
>                                  huz[[i]] <- sort (chain3)
>                                  next
>                              }
>                      }
>              }
>         huz <- unique (huz)
>         return (huz)
>     }
>
>
>
> 2013/11/10 Bert Gunter <gunter.berton at gene.com>
>>
>> Your specification is a unclear (to me anyway): What do you want to
>> return if the intersection is empty? What if intersect(ja[[i]],
>> ja[[i+1]]) is empty for all i? What if  length(intersect( ja[[i]],
>> ja[[i+1]] )) ==0 but intersect(ja[[i]],ja[[i+2]]) is nonempty?  Your
>> example isn't -- you did not specify what the return should be on your
>> list.
>>
>> Note also that your example test  is wrong: the length of the
>> intersection must =0 not the intersection.
>>
>> -- Bert
>>
>>
>>
>> On Sat, Nov 9, 2013 at 12:45 PM, Hermann Norpois <hnorpois at gmail.com>
>> wrote:
>> > Hello,
>> >
>> > I have a list called ja and I wish to unify list objects if there is
>> > some
>> > overlap.
>> > For instance something like
>> >
>> > if (length (intersect (ja[[1]], ja[[2]]) !=0) { union (ja[[1]], ja[[2]]
>> > }
>> >
>> > but of course it should work cumulatively (for larger data sets).
>> >
>> > Could you please give me a hint.
>> >
>> > Thanks
>> > Hermann
>> >
>> >> ja
>> > $A
>> > [1] "A" "B" "F" "G" "H"
>> >
>> > $B
>> > [1] "B" "F" "I"
>> >
>> > $C
>> > [1] "C" "F" "I" "K"
>> >
>> > $D
>> > [1] "D" "L" "M" "N"
>> >
>> > $L
>> > [1] "L" "O" "P"
>> >
>> >
>> > dput (ja)
>> > structure(list(A = c("A", "B", "F", "G", "H"), B = c("B", "F",
>> > "I"), C = c("C", "F", "I", "K"), D = c("D", "L", "M", "N"), L = c("L",
>> > "O", "P")), .Names = c("A", "B", "C", "D", "L"))
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From alaios at yahoo.com  Sun Nov 10 18:57:16 2013
From: alaios at yahoo.com (Alaios)
Date: Sun, 10 Nov 2013 09:57:16 -0800 (PST)
Subject: [R] Colour Legend text, in a print color2D.matplot
In-Reply-To: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>
References: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <1384106236.75116.YahooMailNeo@web125301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/5662a59d/attachment.pl>

From jdnewmil at dcn.davis.ca.us  Sun Nov 10 19:16:49 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 10 Nov 2013 10:16:49 -0800 (PST)
Subject: [R] Tables Package Ampersand Quoting
Message-ID: <alpine.BSF.2.00.1311100945500.11074@pedal.dcn.davis.ca.us>

There seems to be some inappropriate quoting in the tabular function from 
the tables package. Consider this example:

library(tables)
sampledf <- data.frame( Manufacturer=c(rep("Joe & Co.",6)
                                       ,rep("\\tabular, Inc.",4))
                       , Tool=rep(c("Shovel","Screwdriver","Harpoon"
                                 ,"Items","Stuff"),each=2)
                       , When=rep(c("List","After"),times=5)
                       , Price=c(180,190,190,180,200,200,140,145,150,140)
                       )
sampledf$MfrTool <- with( sampledf
                         , factor( paste( Manufacturer, "-", Tool ) ) )
tabular( MfrTool ~ When * Price * identity, data=sampledf )

which produces for me:

                                           When
                                           After    List
                                           Price    Price
  MfrTool                                  identity identity
  \\textbackslash{}tabular, Inc. - Items   145      140
  \\textbackslash{}tabular, Inc. - Stuff   140      150
  Joe \\textbackslash{}& Co. - Harpoon     200      200
  Joe \\textbackslash{}& Co. - Screwdriver 180      190
  Joe \\textbackslash{}& Co. - Shovel      190      180

Although I do intend to pass this through the latex() function, I think
that in this representation the substitution of '\textbackslash{}' for
'\' is premature, and I am not sure why the backslash is getting doubled 
here.  In any event, the ampersand in 'Joe & Co.' is getting a '\' added 
to it (which it shouldn't here), and then when I pass this through the
latex function I get:

> latex(tabular( MfrTool ~ When * Price * identity, data=sampledf ))

\begin{tabular}{lcc}
\hline
  & \multicolumn{2}{c}{When} \\
  & After & \multicolumn{1}{c}{List} \\
  & Price & \multicolumn{1}{c}{Price} \\
MfrTool  & identity & \multicolumn{1}{c}{identity} \\
\hline
\textbackslash{}tabular, Inc. - Items  & $145$ & $140$ \\
\textbackslash{}tabular, Inc. - Stuff  & $140$ & $150$ \\
Joe \textbackslash{}& Co. - Harpoon  & $200$ & $200$ \\
Joe \textbackslash{}& Co. - Screwdriver  & $180$ & $190$ \\
Joe \textbackslash{}& Co. - Shovel  & $190$ & $180$ \\
\hline
\end{tabular}

where 'Joe & Co.' has become illegal TeX.

For reference,, my session:

> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] tables_0.7      Hmisc_3.12-2    Formula_1.1-1   survival_2.37-4

loaded via a namespace (and not attached):
[1] cluster_1.14.4  grid_2.15.3     lattice_0.20-24 rpart_4.1-3


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dcarlson at tamu.edu  Sun Nov 10 19:32:45 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Sun, 10 Nov 2013 12:32:45 -0600
Subject: [R] Cross Tabulation
In-Reply-To: <1384063542.77900.YahooMailNeo@web121702.mail.ne1.yahoo.com>
References: <1384063542.77900.YahooMailNeo@web121702.mail.ne1.yahoo.com>
Message-ID: <050501cede43$3f9ea620$bedbf260$@tamu.edu>

The simplest would be to create a variable combining region and
district:

> data$region_district <- with(data, paste(region, district))
> prop.table(xtabs(~region_district+response, data), 1)
               response
region_district  no yes
            A d 0.5 0.5
            A e 0.0 1.0
            B f 0.5 0.5
            B g 0.5 0.5
            C h 0.5 0.5
            C i 0.0 1.0
            C j 1.0 0.0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Peter Maclean
Sent: Sunday, November 10, 2013 12:06 AM
To: r-help at r-project.org
Subject: Re: [R] Cross Tabulation


#Would like to create a cross-table (Region, district, response)
and 
#(Region, district, cost. The flat table function does not look
so good 
region   <- c("A","A","A","A","B","B", "B", "B", "C","C", "C",
"C") 
district <- c("d","d","e","e","f","f", "g", "g", "h","h", "i",
"j") 
response <- c("yes", "no", "yes", "yes", "no", "yes", "yes",
"no", "yes", "no", "yes","no")
cost  <-  runif(12, 5.0, 9)
var <- c("region", "response", "district")
data <- data.frame(region, district, response, cost)
var1 <- c("region", "district", "response")
var2 <- c("region", "district", "cost")
data1 <- data[var1]
#This look okay
with(data, aggregate(x=cost, by=list(region, district),
FUN="mean"))
#This does not look good 
#How do i remove the NaN or create a better one
prop.table(ftable(data1, exclude = c(NA, NaN)), 1)
prop.table(ftable(xtabs(~region + district+ response,
data=data)),1)


Peter Maclean
Department of Economics
UDSM
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From kinsham at verizon.net  Sun Nov 10 15:41:49 2013
From: kinsham at verizon.net (Chris Wilkinson)
Date: Sun, 10 Nov 2013 09:41:49 -0500
Subject: [R] Earth (MARS) package with categorical predictors
Message-ID: <s2v3bapsrvnitj0tocp4wy15.1384094103074@email.android.com>


It appears to be legitimate to include multi-level categorical and continuous variables in defining the model for earth (e.g. y ~ cat + cont1 + cont2) but is it also then possible use categoricals in the predict method using the earth result?

Chris

From hnorpois at gmail.com  Sun Nov 10 12:14:15 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Sun, 10 Nov 2013 12:14:15 +0100
Subject: [R] union of list objects if objects intersect
In-Reply-To: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
References: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
Message-ID: <CAKyZeBvY5jpqPAKrnu3mTNJZPFwNB38oY5jZ+UR-kz1KxghLwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/274ec4f0/attachment.pl>

From dschnaider at gmail.com  Sun Nov 10 12:54:58 2013
From: dschnaider at gmail.com (daniel schnaider)
Date: Sun, 10 Nov 2013 09:54:58 -0200
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <527E7CD4.1030701@fhcrc.org>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
	<527E7CD4.1030701@fhcrc.org>
Message-ID: <CAPOwdSoH7y4QAPmEfbBc-DOKwo9NxE68odj3Au5rmipnJowCuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/cfed9da7/attachment.pl>

From alaios at yahoo.com  Sun Nov 10 14:21:10 2013
From: alaios at yahoo.com (Alaios)
Date: Sun, 10 Nov 2013 05:21:10 -0800 (PST)
Subject: [R] Plotrix: Add text below the color- legend.
Message-ID: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/5893ef25/attachment.pl>

From stausland.johnsen at iln.uio.no  Sun Nov 10 15:30:50 2013
From: stausland.johnsen at iln.uio.no (Sverre Stausland)
Date: Sun, 10 Nov 2013 15:30:50 +0100
Subject: [R] Set system font in R package Cairo in Mac OS X
Message-ID: <CACtaF7zD2kCQZgmzofrb3ym_9+uio9v_EjDx3hP-0NDWL-37LQ@mail.gmail.com>

Because of the issue raised in
https://stat.ethz.ch/pipermail/r-help/2013-November/362896.html, I am
switching to R on Mac OS X (10.6.8) to create some plots. Using
CairoPDF(), however, the commands I use in Windows (7) to select my
fonts don't have any effect on Mac OS X, where the output .pdf file
always has the Helvetica font.

library(package = "Cairo")
CairoPDF("test.pdf")
plot.new()
text(x=.5,y=.5,labels="\u0260",family="Times New Roman")
dev.off()

The outputs are attached. The Times New Roman font is exactly the same
on both systems. I'm using R 3.0.2 on both systems.

Sverre
-------------- next part --------------
A non-text attachment was scrubbed...
Name: windows.png
Type: image/png
Size: 896 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/bd0c8ae7/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mac.png
Type: image/png
Size: 1028 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/bd0c8ae7/attachment-0001.png>

From ashz at walla.co.il  Sun Nov 10 15:31:19 2013
From: ashz at walla.co.il (ashz)
Date: Sun, 10 Nov 2013 06:31:19 -0800 (PST)
Subject: [R] Mark each group centroid in a linear discriminant analysis plot
Message-ID: <1384093879664-4680159.post@n4.nabble.com>

Hi,

How can I calculate and mark each group centroid in a linear discriminant
analysis plot (using ggplot2)? 


Script:
## originate from
http://r.789695.n4.nabble.com/LDA-and-confidence-ellipse-td4671308.html
require(MASS)
require(ggplot2)
iris.lda<-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width,  data = iris)
LD1<-predict(iris.lda)$x[,1]
LD2<-predict(iris.lda)$x[,2]
ggplot(iris, aes(x=LD1, y=LD2, col=iris$Species) ) + geom_point( size = 4,
aes(color = iris$Species))+theme_bw()   




--
View this message in context: http://r.789695.n4.nabble.com/Mark-each-group-centroid-in-a-linear-discriminant-analysis-plot-tp4680159.html
Sent from the R help mailing list archive at Nabble.com.


From dschnaider at gmail.com  Sun Nov 10 15:57:46 2013
From: dschnaider at gmail.com (daniel schnaider)
Date: Sun, 10 Nov 2013 12:57:46 -0200
Subject: [R] S4; Setter function is not chaning slot value as expected
In-Reply-To: <527F9CFE.4050102@fhcrc.org>
References: <CAPOwdSq6bUg4qDKbGmtk3EFFDFLvu16c6XtasCaWVwV7wLPgng@mail.gmail.com>
	<CABdHhvE+CDzdq+0C6_9YW6vgDUUy0SFu8vjT7xNhf-h=X83+RA@mail.gmail.com>
	<527F9CFE.4050102@fhcrc.org>
Message-ID: <CAPOwdSp35CNvKhfVNtj=ryfZoodxQYk-hu-PgKhpE3GnW64yWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/8c993c8b/attachment.pl>

From hnorpois at gmail.com  Sun Nov 10 16:38:36 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Sun, 10 Nov 2013 16:38:36 +0100
Subject: [R] union of list objects if objects intersect
In-Reply-To: <CACk-te2OJ4X6ALrCgLjOUcS1w3rdE0NMbpnZpnFp-oR9kP08Pg@mail.gmail.com>
References: <CAKyZeBuBFZ6o7Athk2+adDKCuS8eQLMhZmyR3vY6o-iNY2FNkA@mail.gmail.com>
	<CACk-te2OJ4X6ALrCgLjOUcS1w3rdE0NMbpnZpnFp-oR9kP08Pg@mail.gmail.com>
Message-ID: <CAKyZeBsZANpEthQV-prAEGD44fEi7JzkvLXCzFQfhQGUA6tpeg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/333a9070/attachment.pl>

From ccberry at ucsd.edu  Sun Nov 10 18:49:14 2013
From: ccberry at ucsd.edu (Charles Berry)
Date: Sun, 10 Nov 2013 17:49:14 +0000
Subject: [R] Custom Numeric type in R
References: <CA+dpOJkZ496s95G69+qZiO=7U8sgU1SmLPKko=Gy5xJxX9sakg@mail.gmail.com>
Message-ID: <loom.20131110T181820-595@post.gmane.org>

Christofer Bogaso <bogaso.christofer <at> gmail.com> writes:

> 
> Hi again,
> 
> In R, there are various numerics like, NA, Inf, or simple integers etc.
> However I want to include one custom type: "TBD", which R should treat as
> numeric, not character.
> 
> That "TBD" should have same property like Inf, however except this: TBD -
> TBD = 0
> 
> In future, I am planning to add few more properties to TBD.
> 
> Can somebody guide me if this is possible in R, ans also some pointer on
> how can be done in R
> 

Possible? Yes.

Your question might be framed as 

"How do I create a class and write a method for '-' that does ... ?"

The answer is "learn about methods and classes in R".

To get started, see

 ?methods
 ?class
 ?groupGenericFunction-class
 ?groupGeneric

and follow the links therein.


Check the posting guide. If you need to follow up, you should consider
whether the question you have fits better on R-devel.


From gunter.berton at gene.com  Sun Nov 10 22:07:40 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 10 Nov 2013 13:07:40 -0800
Subject: [R] Custom Numeric type in R
In-Reply-To: <loom.20131110T181820-595@post.gmane.org>
References: <CA+dpOJkZ496s95G69+qZiO=7U8sgU1SmLPKko=Gy5xJxX9sakg@mail.gmail.com>
	<loom.20131110T181820-595@post.gmane.org>
Message-ID: <CACk-te2nKzr3DryjihWYJQYvrtnbaiPfZ=t5ZdThG9ruoqJAPg@mail.gmail.com>

Charles:

That was my initial thought, too. But then I wondered whether what was
meant was to use "TBD" as an alternative kind of numeric value that
would be part of numeric vectors, lists, etc.  in the same way that NA
or Inf is. It is not clear to me that a new object class provides a
way to do this, at least not without a large amount of recreating
standard R objects and the operations on them to include a "TBD" type
numeric. My understanding is that NA and Inf are built into R's
internals as part of IEEE floating point standards. I do not know how
or if one can add new numeric types to these.

I would appreciate correction of any misunderstanding that I have and
further details as to how one would do this.

Best,
Bert

On Sun, Nov 10, 2013 at 9:49 AM, Charles Berry <ccberry at ucsd.edu> wrote:
> Christofer Bogaso <bogaso.christofer <at> gmail.com> writes:
>
>>
>> Hi again,
>>
>> In R, there are various numerics like, NA, Inf, or simple integers etc.
>> However I want to include one custom type: "TBD", which R should treat as
>> numeric, not character.
>>
>> That "TBD" should have same property like Inf, however except this: TBD -
>> TBD = 0
>>
>> In future, I am planning to add few more properties to TBD.
>>
>> Can somebody guide me if this is possible in R, ans also some pointer on
>> how can be done in R
>>
>
> Possible? Yes.
>
> Your question might be framed as
>
> "How do I create a class and write a method for '-' that does ... ?"
>
> The answer is "learn about methods and classes in R".
>
> To get started, see
>
>  ?methods
>  ?class
>  ?groupGenericFunction-class
>  ?groupGeneric
>
> and follow the links therein.
>
>
> Check the posting guide. If you need to follow up, you should consider
> whether the question you have fits better on R-devel.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Sun Nov 10 22:10:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Nov 2013 13:10:56 -0800
Subject: [R] Using Unicode inside R's expression() command
In-Reply-To: <CACtaF7whDrV+UVDWabibUZfX9KMYfKt-EeYq2tdJJ=AoAk-NcQ@mail.gmail.com>
References: <CACtaF7whDrV+UVDWabibUZfX9KMYfKt-EeYq2tdJJ=AoAk-NcQ@mail.gmail.com>
Message-ID: <C77D1594-752A-4527-AC70-225FB23A6557@comcast.net>


On Nov 9, 2013, at 11:01 AM, Sverre Stausland wrote:

> I'm using 'expression()' in R plots in order to get italicized text.
> But it appears as if I cannot use Unicode symbols inside 'expression'
> outside of ASCII characters. Is there some way I can work around this?
> My goal is to get the '?' ligature in various labels in my R barplots
> (together with italicized text). I think I could work around this if
> there was another way of italicizing selected characters in a string
> than using 'expression()'.
> 
> I'm using R for Windows version 3.0.2.
> 
>    CairoPDF(file = "Ligature1.pdf")
>    plot.new()
>    text(x =.5, y = .5, labels = "?", family = "Times New Roman")
>    dev.off()
> 
>    CairoPDF(file = "Ligature2.pdf")
>    plot.new()
>    text(x =.5, y = .5, labels = expression(paste(italic(m), "u", "?",
> italic(m), sep = "")), family = "Times New Roman")
>    dev.off()
> <lig1.png><lig2.png>

To the list readers: I posted a comment to the identical SO question that changing the font with CairoFonts before the CairoPDF call might be more effective. (I used a font name of "TimesNewRoman" rather than "Times New Roman" but testing with 

 CairoFontMatch(fontpattern="Times New Roman",sort=FALSE,verbose=TRUE)

... proved that the spaces were not causing problems. I happen to have a copy of Times New Roman since I have purchased MS Office, but I do not know if everyone would have that font installed. )

This succeeded
CairoFonts(
	regular="Roman-12:normal", italic="Roman-12:italic" 
)
# The default family is Helvetica on my machine running OSX 10.7.5
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Nov 10 22:52:28 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 10 Nov 2013 21:52:28 +0000
Subject: [R] Custom Numeric type in R
In-Reply-To: <CACk-te2nKzr3DryjihWYJQYvrtnbaiPfZ=t5ZdThG9ruoqJAPg@mail.gmail.com>
References: <CA+dpOJkZ496s95G69+qZiO=7U8sgU1SmLPKko=Gy5xJxX9sakg@mail.gmail.com>	<loom.20131110T181820-595@post.gmane.org>
	<CACk-te2nKzr3DryjihWYJQYvrtnbaiPfZ=t5ZdThG9ruoqJAPg@mail.gmail.com>
Message-ID: <5280001C.9010909@sapo.pt>

Hello,

Try the following.

 > class(NA)
[1] "logical"
 > class(NaN)
[1] "numeric"
 > class(Inf)
[1] "numeric"


So my guess is that what the op wants is not possible. And that to 
declare a new class shouldn't solve the problem.

Rui Barradas

Em 10-11-2013 21:07, Bert Gunter escreveu:
> Charles:
>
> That was my initial thought, too. But then I wondered whether what was
> meant was to use "TBD" as an alternative kind of numeric value that
> would be part of numeric vectors, lists, etc.  in the same way that NA
> or Inf is. It is not clear to me that a new object class provides a
> way to do this, at least not without a large amount of recreating
> standard R objects and the operations on them to include a "TBD" type
> numeric. My understanding is that NA and Inf are built into R's
> internals as part of IEEE floating point standards. I do not know how
> or if one can add new numeric types to these.
>
> I would appreciate correction of any misunderstanding that I have and
> further details as to how one would do this.
>
> Best,
> Bert
>
> On Sun, Nov 10, 2013 at 9:49 AM, Charles Berry <ccberry at ucsd.edu> wrote:
>> Christofer Bogaso <bogaso.christofer <at> gmail.com> writes:
>>
>>>
>>> Hi again,
>>>
>>> In R, there are various numerics like, NA, Inf, or simple integers etc.
>>> However I want to include one custom type: "TBD", which R should treat as
>>> numeric, not character.
>>>
>>> That "TBD" should have same property like Inf, however except this: TBD -
>>> TBD = 0
>>>
>>> In future, I am planning to add few more properties to TBD.
>>>
>>> Can somebody guide me if this is possible in R, ans also some pointer on
>>> how can be done in R
>>>
>>
>> Possible? Yes.
>>
>> Your question might be framed as
>>
>> "How do I create a class and write a method for '-' that does ... ?"
>>
>> The answer is "learn about methods and classes in R".
>>
>> To get started, see
>>
>>   ?methods
>>   ?class
>>   ?groupGenericFunction-class
>>   ?groupGeneric
>>
>> and follow the links therein.
>>
>>
>> Check the posting guide. If you need to follow up, you should consider
>> whether the question you have fits better on R-devel.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From murdoch.duncan at gmail.com  Sun Nov 10 23:04:01 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Nov 2013 17:04:01 -0500
Subject: [R] Custom Numeric type in R
In-Reply-To: <5280001C.9010909@sapo.pt>
References: <CA+dpOJkZ496s95G69+qZiO=7U8sgU1SmLPKko=Gy5xJxX9sakg@mail.gmail.com>	<loom.20131110T181820-595@post.gmane.org>	<CACk-te2nKzr3DryjihWYJQYvrtnbaiPfZ=t5ZdThG9ruoqJAPg@mail.gmail.com>
	<5280001C.9010909@sapo.pt>
Message-ID: <528002D1.6080601@gmail.com>

On 13-11-10 4:52 PM, Rui Barradas wrote:
> Hello,
>
> Try the following.
>
>   > class(NA)
> [1] "logical"

This doesn't actually prove anything, since there are multiple different 
objects that display as NA.  For example:

 > 1+NA
[1] NA
 > class(1+NA)
[1] "numeric"

See ?"NA" for other ways to represent the other NA values.


>   > class(NaN)
> [1] "numeric"
>   > class(Inf)
> [1] "numeric"
>
>
> So my guess is that what the op wants is not possible. And that to
> declare a new class shouldn't solve the problem.

I don't think it is impossible, but I think it would be hard to get it 
working well.

Duncan Murdoch

>
> Rui Barradas
>
> Em 10-11-2013 21:07, Bert Gunter escreveu:
>> Charles:
>>
>> That was my initial thought, too. But then I wondered whether what was
>> meant was to use "TBD" as an alternative kind of numeric value that
>> would be part of numeric vectors, lists, etc.  in the same way that NA
>> or Inf is. It is not clear to me that a new object class provides a
>> way to do this, at least not without a large amount of recreating
>> standard R objects and the operations on them to include a "TBD" type
>> numeric. My understanding is that NA and Inf are built into R's
>> internals as part of IEEE floating point standards. I do not know how
>> or if one can add new numeric types to these.
>>
>> I would appreciate correction of any misunderstanding that I have and
>> further details as to how one would do this.
>>
>> Best,
>> Bert
>>
>> On Sun, Nov 10, 2013 at 9:49 AM, Charles Berry <ccberry at ucsd.edu> wrote:
>>> Christofer Bogaso <bogaso.christofer <at> gmail.com> writes:
>>>
>>>>
>>>> Hi again,
>>>>
>>>> In R, there are various numerics like, NA, Inf, or simple integers etc.
>>>> However I want to include one custom type: "TBD", which R should treat as
>>>> numeric, not character.
>>>>
>>>> That "TBD" should have same property like Inf, however except this: TBD -
>>>> TBD = 0
>>>>
>>>> In future, I am planning to add few more properties to TBD.
>>>>
>>>> Can somebody guide me if this is possible in R, ans also some pointer on
>>>> how can be done in R
>>>>
>>>
>>> Possible? Yes.
>>>
>>> Your question might be framed as
>>>
>>> "How do I create a class and write a method for '-' that does ... ?"
>>>
>>> The answer is "learn about methods and classes in R".
>>>
>>> To get started, see
>>>
>>>    ?methods
>>>    ?class
>>>    ?groupGenericFunction-class
>>>    ?groupGeneric
>>>
>>> and follow the links therein.
>>>
>>>
>>> Check the posting guide. If you need to follow up, you should consider
>>> whether the question you have fits better on R-devel.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Sun Nov 10 23:59:41 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 11 Nov 2013 09:59:41 +1100
Subject: [R] Colour Legend text, in a print color2D.matplot
In-Reply-To: <1384106236.75116.YahooMailNeo@web125301.mail.ne1.yahoo.com>
References: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	<1384106236.75116.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <52800FDD.4010206@bitwrit.com.au>

On 11/11/2013 04:57 AM, Alaios wrote:
> Hi all,
>
> I am plotting very nice looking mattrices with  plotrin...
>
> so far so good, I would like though to ask you if it would be possible to add at the bottom of the color.legend (this lovely color bar that maps colors to numbers).
> Would that be possible to do that?
>
Hi Alex,
It is not too difficult:

# first allow printing outside the plot
par(xpd=TRUE)
# get the x component of the label
# from the values passed to color.legend
# see the help page
labelx<-(xl+xr)/2
# get the y coordinate from the y value
labely<-yb-strheight("M")
# display the label
text(labelx,labely,mylabel)
# restore the clipping
par(xpd=FALSE)

Jim


From aljehani-k at hotmail.com  Sun Nov 10 23:53:05 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Mon, 11 Nov 2013 01:53:05 +0300
Subject: [R] Nadaraya-Watson kernel estimation 2
Message-ID: <DUB122-W3383B661ABBD3F7516E68785FC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/cf949cb9/attachment.pl>

From murdoch.duncan at gmail.com  Mon Nov 11 01:15:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Nov 2013 19:15:06 -0500
Subject: [R] Tables Package Ampersand Quoting
In-Reply-To: <alpine.BSF.2.00.1311100945500.11074@pedal.dcn.davis.ca.us>
References: <alpine.BSF.2.00.1311100945500.11074@pedal.dcn.davis.ca.us>
Message-ID: <5280218A.4040701@gmail.com>

On 13-11-10 1:16 PM, Jeff Newmiller wrote:> There seems to be some 
inappropriate quoting in the tabular function from
 > the tables package. Consider this example:
 >
 > library(tables)
 > sampledf <- data.frame( Manufacturer=c(rep("Joe & Co.",6)
 >                                         ,rep("\\tabular, Inc.",4))
 >                         , Tool=rep(c("Shovel","Screwdriver","Harpoon"
 >                                   ,"Items","Stuff"),each=2)
 >                         , When=rep(c("List","After"),times=5)
 >                         , 
Price=c(180,190,190,180,200,200,140,145,150,140)
 >                         )
 > sampledf$MfrTool <- with( sampledf
 >                           , factor( paste( Manufacturer, "-", Tool ) ) )
 > tabular( MfrTool ~ When * Price * identity, data=sampledf )
 >
 > which produces for me:
 >
 >                                             When
 >                                             After    List
 >                                             Price    Price
 >    MfrTool                                  identity identity
 >    \\textbackslash{}tabular, Inc. - Items   145      140
 >    \\textbackslash{}tabular, Inc. - Stuff   140      150
 >    Joe \\textbackslash{}& Co. - Harpoon     200      200
 >    Joe \\textbackslash{}& Co. - Screwdriver 180      190
 >    Joe \\textbackslash{}& Co. - Shovel      190      180
 >
 > Although I do intend to pass this through the latex() function, I think
 > that in this representation the substitution of '\textbackslash{}' for
 > '\' is premature,

Yes, that's a bug.  I have just fixed it.


  and I am not sure why the backslash is getting doubled

That's just the way R prints matrix entries that contain single 
backslashes.  print.tabular just converts the table + labels to a matrix 
and then prints it without quotes.

 > here.  In any event, the ampersand in 'Joe & Co.' is getting a '\' added
 > to it (which it shouldn't here), and then when I pass this through the
 > latex function I get:

The & backslash is the same bug as the first one.

 >
 >> latex(tabular( MfrTool ~ When * Price * identity, data=sampledf ))
 >
 > \begin{tabular}{lcc}
 > \hline
 >    & \multicolumn{2}{c}{When} \\
 >    & After & \multicolumn{1}{c}{List} \\
 >    & Price & \multicolumn{1}{c}{Price} \\
 > MfrTool  & identity & \multicolumn{1}{c}{identity} \\
 > \hline
 > \textbackslash{}tabular, Inc. - Items  & $145$ & $140$ \\
 > \textbackslash{}tabular, Inc. - Stuff  & $140$ & $150$ \\
 > Joe \textbackslash{}& Co. - Harpoon  & $200$ & $200$ \\
 > Joe \textbackslash{}& Co. - Screwdriver  & $180$ & $190$ \\
 > Joe \textbackslash{}& Co. - Shovel  & $190$ & $180$ \\
 > \hline
 > \end{tabular}
 >
 > where 'Joe & Co.' has become illegal TeX.

After the fix, this appears as

 > latex(tabular( MfrTool ~ When * Price * identity, data=sampledf ))
\begin{tabular}{lcc}
\hline
  & \multicolumn{2}{c}{When} \\
  & After & \multicolumn{1}{c}{List} \\
  & Price & \multicolumn{1}{c}{Price} \\
MfrTool  & identity & \multicolumn{1}{c}{identity} \\
\hline
\tabular, Inc. - Items  & $145$ & $140$ \\
\tabular, Inc. - Stuff  & $140$ & $150$ \\
Joe & Co. - Harpoon  & $200$ & $200$ \\
Joe & Co. - Screwdriver  & $180$ & $190$ \\
Joe & Co. - Shovel  & $190$ & $180$ \\
\hline
\end{tabular}

which is probably still not what you want:  here you'd want the & in the 
company name to be escaped.  I'll have to think about this a bit to find 
the best solution, but in the meantime, if you use the R-forge version, 
you can get the right behaviour by including the escape in the original 
factor level.  (What I may do is include some information about whether 
something has been texified or not, so that it only happens once.  Or 
perhaps I will just never do it unless you explicitly ask for it.  We'll 
see.)

Duncan Murdoch

 >
 > For reference,, my session:
 >
 >> sessionInfo()
 > R version 2.15.3 (2013-03-01)
 > Platform: i386-w64-mingw32/i386 (32-bit)
 >
 > locale:
 > [1] LC_COLLATE=English_United States.1252
 > [2] LC_CTYPE=English_United States.1252
 > [3] LC_MONETARY=English_United States.1252
 > [4] LC_NUMERIC=C
 > [5] LC_TIME=English_United States.1252
 >
 > attached base packages:
 > [1] splines   stats     graphics  grDevices utils     datasets  methods
 > [8] base
 >
 > other attached packages:
 > [1] tables_0.7      Hmisc_3.12-2    Formula_1.1-1   survival_2.37-4
 >
 > loaded via a namespace (and not attached):
 > [1] cluster_1.14.4  grid_2.15.3     lattice_0.20-24 rpart_4.1-3
 >
 >
 > 
---------------------------------------------------------------------------
 > Jeff Newmiller                        The     .....       .....  Go 
Live...
 > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live 
Go...
 >                                         Live:   OO#.. Dead: OO#.. 
Playing
 > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
 > /Software/Embedded Controllers)               .OO#.       .OO#. 
rocks...1k
 >
 > ______________________________________________
 > R-help at r-project.org mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
 > and provide commented, minimal, self-contained, reproducible code.
 >


From murdoch.duncan at gmail.com  Mon Nov 11 02:25:52 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Nov 2013 20:25:52 -0500
Subject: [R] Tables Package Ampersand Quoting
In-Reply-To: <alpine.BSF.2.00.1311100945500.11074@pedal.dcn.davis.ca.us>
References: <alpine.BSF.2.00.1311100945500.11074@pedal.dcn.davis.ca.us>
Message-ID: <52803220.7010701@gmail.com>

On 13-11-10 1:16 PM, Jeff Newmiller wrote:
> There seems to be some inappropriate quoting in the tabular function from
> the tables package. Consider this example:

This turned out to be different than I thought at first.  It was simply 
that I mis-used the latexTranslate function from the Hmisc package.

I'll be committing some different changes soon.

Duncan Murdoch

>
> library(tables)
> sampledf <- data.frame( Manufacturer=c(rep("Joe & Co.",6)
>                                         ,rep("\\tabular, Inc.",4))
>                         , Tool=rep(c("Shovel","Screwdriver","Harpoon"
>                                   ,"Items","Stuff"),each=2)
>                         , When=rep(c("List","After"),times=5)
>                         , Price=c(180,190,190,180,200,200,140,145,150,140)
>                         )
> sampledf$MfrTool <- with( sampledf
>                           , factor( paste( Manufacturer, "-", Tool ) ) )
> tabular( MfrTool ~ When * Price * identity, data=sampledf )
>
> which produces for me:
>
>                                             When
>                                             After    List
>                                             Price    Price
>    MfrTool                                  identity identity
>    \\textbackslash{}tabular, Inc. - Items   145      140
>    \\textbackslash{}tabular, Inc. - Stuff   140      150
>    Joe \\textbackslash{}& Co. - Harpoon     200      200
>    Joe \\textbackslash{}& Co. - Screwdriver 180      190
>    Joe \\textbackslash{}& Co. - Shovel      190      180
>
> Although I do intend to pass this through the latex() function, I think
> that in this representation the substitution of '\textbackslash{}' for
> '\' is premature, and I am not sure why the backslash is getting doubled
> here.  In any event, the ampersand in 'Joe & Co.' is getting a '\' added
> to it (which it shouldn't here), and then when I pass this through the
> latex function I get:
>
>> latex(tabular( MfrTool ~ When * Price * identity, data=sampledf ))
>
> \begin{tabular}{lcc}
> \hline
>    & \multicolumn{2}{c}{When} \\
>    & After & \multicolumn{1}{c}{List} \\
>    & Price & \multicolumn{1}{c}{Price} \\
> MfrTool  & identity & \multicolumn{1}{c}{identity} \\
> \hline
> \textbackslash{}tabular, Inc. - Items  & $145$ & $140$ \\
> \textbackslash{}tabular, Inc. - Stuff  & $140$ & $150$ \\
> Joe \textbackslash{}& Co. - Harpoon  & $200$ & $200$ \\
> Joe \textbackslash{}& Co. - Screwdriver  & $180$ & $190$ \\
> Joe \textbackslash{}& Co. - Shovel  & $190$ & $180$ \\
> \hline
> \end{tabular}
>
> where 'Joe & Co.' has become illegal TeX.
>
> For reference,, my session:
>
>> sessionInfo()
> R version 2.15.3 (2013-03-01)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
>
> other attached packages:
> [1] tables_0.7      Hmisc_3.12-2    Formula_1.1-1   survival_2.37-4
>
> loaded via a namespace (and not attached):
> [1] cluster_1.14.4  grid_2.15.3     lattice_0.20-24 rpart_4.1-3
>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                         Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alaios at yahoo.com  Mon Nov 11 03:04:57 2013
From: alaios at yahoo.com (Alaios)
Date: Sun, 10 Nov 2013 18:04:57 -0800 (PST)
Subject: [R] Colour Legend text, in a print color2D.matplot
In-Reply-To: <52800FDD.4010206@bitwrit.com.au>
References: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	<1384106236.75116.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	<52800FDD.4010206@bitwrit.com.au>
Message-ID: <1384135497.89085.YahooMailNeo@web125306.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/e60e8393/attachment.pl>

From agony_jah at yahoo.com  Mon Nov 11 02:39:25 2013
From: agony_jah at yahoo.com (Agony)
Date: Sun, 10 Nov 2013 17:39:25 -0800 (PST)
Subject: [R] decode and annotate
Message-ID: <1384133965.39543.YahooMailNeo@web161506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/abde0298/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Nov 11 04:33:44 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 10 Nov 2013 19:33:44 -0800
Subject: [R] decode and annotate
In-Reply-To: <1384133965.39543.YahooMailNeo@web161506.mail.bf1.yahoo.com>
References: <1384133965.39543.YahooMailNeo@web161506.mail.bf1.yahoo.com>
Message-ID: <46dd5a86-9616-4d24-8701-0754f1c42a0b@email.android.com>

This is not a homework assistance forum. You really need to use the resources provided by your educational institution for that. Please read the Posting Guide, and note for future reference that HTML email distorts your R code so it is not appropriate on this list.

As regards your question, you may need to review the Introduction to R document that comes with R. Then you might as well get started learning how to use the help system, paying close attention to the first argument and (return) value for the rainbow function.

?rainbow
?"["

Also, the str function can help you decipher bits of code:

str(rainbow)
str(rainbow(50))
str(rainbow (50)[46])
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Agony <agony_jah at yahoo.com> wrote:
>Dear all, 
>
>
>Could anyone help me annotate and decode the below codes?
>Many thanks in advance.
>Best,
>
>
>coverage.col <- rep(0, length(mean))
>coverage.col[coverage=="a"] <-? rainbow(50)[30]
>coverage.col[coverage=="b"] <-? rainbow(50)[15]
>coverage.col[coverage=="c"] <- rainbow(50)[8]
>coverage.col[coverage=="d"] <-? rainbow(50)[46]
>
>?
>what does it mean by (50)[30] et al.?
>what will be happend after using these codes?
>
>Based on what they could be selected?
>
>
>and also:
>if(variable=="a" & fOnly==0){
>? NF? <- length(unique(uid[fasting==1]))
>? NnF <- length(unique(uid[fasting==0]))
>}
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dilaradi21 at gmail.com  Mon Nov 11 07:31:28 2013
From: dilaradi21 at gmail.com (dila radi)
Date: Sun, 10 Nov 2013 22:31:28 -0800
Subject: [R] how to introduce missing data for complete data
Message-ID: <CAMgoKBKj0EQ0MVJzKkFyGFewv64Hfv1-GVc9iz=nbfpnWmoWwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131110/4174d0db/attachment.pl>

From katherine_gobin at yahoo.com  Mon Nov 11 10:55:36 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Mon, 11 Nov 2013 17:55:36 +0800 (SGT)
Subject: [R] Readjusting frequencies
Message-ID: <1384163736.56933.YahooMailNeo@web193306.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/a9ace161/attachment.pl>

From l.hilger at ku.de  Mon Nov 11 11:00:52 2013
From: l.hilger at ku.de (Ludwig Hilger)
Date: Mon, 11 Nov 2013 02:00:52 -0800 (PST)
Subject: [R] create Geotiff
In-Reply-To: <1384125025991-4680188.post@n4.nabble.com>
References: <1384125025991-4680188.post@n4.nabble.com>
Message-ID: <1384164052855-4680203.post@n4.nabble.com>

Hi Karren,

not sure if this is a problem of the software you are using to view the
image after writing? I would first check the color scaling of the image in
this software. I would interpret the black background as "no data".

regards,
Ludwig


Karren wrote
> Hi
> 
> I am trying to export a raster as a Geotiff using -
> 
> writeRaster(grazedmasstot, paste(pad, "grazedmass_total.tif"), "GTiff",
> overwrite=TRUE) -
> 
> But the resulting image is incorrect, the image is tiny and shows up as a
> white object with a black background. 
> 
> Does anyone have any suggestions how I can rectify this?
> 
> Thanks





-----
Dipl. Geogr. Ludwig Hilger
Wiss. MA
Lehrstuhl f?r Physische Geographie
Katholische Universit?t Eichst?tt-Ingolstadt
Ostenstra?e 18
85072 Eichst?tt
--
View this message in context: http://r.789695.n4.nabble.com/create-Geotiff-tp4680188p4680203.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Mon Nov 11 11:06:23 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 11 Nov 2013 10:06:23 +0000
Subject: [R] Date handling in R is hard to understand
In-Reply-To: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
References: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9E03E@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Alemu Tadesse
> Sent: Friday, November 08, 2013 8:41 PM
> To: r-help at r-project.org
> Subject: [R] Date handling in R is hard to understand
> 
> Dear All,
> 
> I usually work with time series data. The data may come in AM/PM date
> format or on 24 hour time basis. R can not recognize the two
> differences automatically - at least for me. I have to specifically
> tell R in which time format the data is. It seems that Pandas knows how
> to handle date without being told the format. The problem arises when I
> try to shift time by a certain time. Say adding 3600 to shift it
> forward, that case I have to use something like:
> Measured_data$Date <- as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %I:%M %p")+3600 or Measured_data$Date <-
> as.POSIXct(as.character(Measured_data$Date),
> tz="",format = "%m/%d/%Y %H:%M")+3600  depending on the format. The
> date also attaches MDT or MST and so on. When merging two data frames
> with dates of different format that may create a problem (I think).
> When I get data from excel it could be in any/random format and I
> needed to customize the date to use in R in one of the above formats.
> Any TIPS - for automatic processing with no need to specifically tell
> the data format ?
> 
> Another problem I saw was that when using r bind to bind data frames,
> if one column of one of the data frames is a character data (say for
> example none - coming from mysql) format R doesn't know how to
> concatenate numeric column from the other data frame to it. I needed to

rbind/cbind can use data.frame method which add any column specific format. However with "normal" method, it results in matrix which has to have common type of data in all columns (actually matrix is only vector with dimensions).

> str(cbind(airquality, 1:153))
'data.frame':   153 obs. of  7 variables:
 $ ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...
 $ solar.r: int  190 118 149 313 NA NA 299 99 19 194 ...
 $ wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...
 $ temp   : int  67 72 74 62 56 66 65 59 61 69 ...
 $ month  : int  5 5 5 5 5 5 5 5 5 5 ...
 $ day    : int  1 2 3 4 5 6 7 8 9 10 ...
 $ 1:153  : int  1 2 3 4 5 6 7 8 9 10 ...

Regards
Petr


> change the numeric to character and later after binding takes place I
> had to re-convert it to numeric. But, this causes problem in an
> automated environment. Any suggestion ?
> 
> Thanks
> Mihretu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohan.radhakrishnan at polarisft.com  Mon Nov 11 11:07:44 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Mon, 11 Nov 2013 15:37:44 +0530
Subject: [R] Show  time in x-axis
Message-ID: <OFC7C56160.F9B72EEB-ON65257C20.00331D4D-65257C20.0037A1F5@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/3cdb950f/attachment.pl>

From ishaqbaba at yahoo.com  Mon Nov 11 11:13:31 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Mon, 11 Nov 2013 02:13:31 -0800 (PST)
Subject: [R] MM robust
Message-ID: <1384164811.96407.YahooMailNeo@web142503.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/9e4d9ded/attachment.pl>

From cevans at chyden.net  Mon Nov 11 12:02:57 2013
From: cevans at chyden.net (Charles Evans)
Date: Mon, 11 Nov 2013 06:02:57 -0500
Subject: [R] =?windows-1252?q?package_=91build-essential=92_is_not_availab?=
 =?windows-1252?q?le_=28for_R_version_3=2E0=2E2=29?=
Message-ID: <5280B961.2030607@chyden.net>

Hello,

I have searched on the R-Project site, R-Help archives, and the Internet
at large, and I cannot find a solution to my problem.

I am running R version 3.0.2 (2013-09-25) -- "Frisbee Sailing" on Ubuntu
13.04.

When I try to install several packages, including quantmod, with
dependencies=T set, and I keep getting long lists of packages that
result in "installation of package 'X' had non-zero exit status".  When
I try to install X, I get another list of packages that failed to install.

After a few iterations of this, the package that I am trying to install
is listed among the packages that have failed to install.

I found a reference online to build-essential, but when I tried to
install that, I got "package ?build-essential? is not available (for R
version 3.0.2)".

Any hints or follow-up questions would be greatly appreciated.

C.Evans


From jim at bitwrit.com.au  Mon Nov 11 12:44:58 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 11 Nov 2013 22:44:58 +1100
Subject: [R] Show  time in x-axis
In-Reply-To: <OFC7C56160.F9B72EEB-ON65257C20.00331D4D-65257C20.0037A1F5@polarisft.com>
References: <OFC7C56160.F9B72EEB-ON65257C20.00331D4D-65257C20.0037A1F5@polarisft.com>
Message-ID: <5280C33A.5060304@bitwrit.com.au>

On 11/11/2013 09:07 PM, mohan.radhakrishnan at polarisft.com wrote:
> Hi,
>              I am trying to show time( HH:MM:SS) in my x-axis. I have these
> two questions.
>
> 1. The error in the code is
>
> Error in axis(1, at = data$Time, labels = data$Time, las = 2, cex.axis =
> 1.2) :
>    (list) object cannot be coerced to type 'double'
>
> Should I use 'POSIXCt' or 'strptime' ?
>
> 2. I have times that are repeated because it is the next or previous day.
> But I want to show the times and data points in sequence - as they are in
> the data frame - along the axis.
>
> Thanks,
> Mohan
>
>          X1       X2             X3                      X4
> OldGenAfterFullGC      X6               X7      PermGenAfterFullGC  Time
> 1        0              3285    873856          3456              3285
> 1256128         12862              12862                19:36:16
> 2     3285      30437   873856          31324             30437 1256128
> 39212              39212                19:36:26
> 3   312755      313565   873856         313843            313565  1214080
> 182327             182327               20:36:27
> 4   313565      281379  873856          313789            281379 1213248
> 182338             147729               21:36:29
> 5        0              3285    873856          3456              3285
> 1256128         12862              12862                19:36:16
>
> plot(data$Time,levels(data$PermGenAfterFullGC)[data$PermGenAfterFullGC],col="darkblue",pch=2,type="b",
> ylab="Megabytes", xlab="Time",las=2,lwd=2, cex.lab=1,cex.axis=1,xaxt="n")
>
> axis(1, at = data$Time, labels = data$Time, las = 2,cex.axis=1.2)
> text(data$Time,data$Time, data$Time, 2, cex=1.45)
>
>
Hi Mohan,
Yes, you probably want to convert the "Time" variable. However, to 
answer both questions in one, you also probably want to stick a starting 
date on your times, incrementing this whenever a time is less than the 
previous one:

# this will produce times for the current date
data$Time1<-strptime(data$Time,"%H:%M:%S")
offset<-0
lasttime<-0
for(timedate in 1:length(data$Time1)) {
  if(as.numeric(data$Time1[timedate]) < lasttime) offset<-offset + 86400
  data$Time1[timedate]<-data$Time1[timedate]+offset
  lasttime<-data$Time1[timedate]
}

Then you can use "Time1" as the "at" argument, and "Time" as the 
"labels" argument to axis.

Jim


From f.calboli at imperial.ac.uk  Mon Nov 11 13:11:48 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 11 Nov 2013 12:11:48 +0000
Subject: [R] repeating values in an index two by two
Message-ID: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>

Hi All,

I am trying to create an index that returns something like

1,2,1,2,3,4,3,4,5,6,5,6,7,8,7,8

and so on and so forth until a predetermined value (which is obviously even).  I am trying very hard to avoid for loops or for loops front ends.

I'd be obliged if anybody could offer a suggestion.

BW

F
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 881 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/7bc5cbcb/attachment.bin>

From enzo.ccc at gmail.com  Mon Nov 11 13:13:28 2013
From: enzo.ccc at gmail.com (Enzo Cocca)
Date: Mon, 11 Nov 2013 13:13:28 +0100
Subject: [R] graphics or table
Message-ID: <CAC_+zuqsfnXi3COVHsZBLc4gc75UkDkoBddyxOf3pCN7QeT0Pw@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/2cb12fdb/attachment.pl>

From cyril.auburtin at gmail.com  Mon Nov 11 13:19:34 2013
From: cyril.auburtin at gmail.com (Cyril Auburtin)
Date: Mon, 11 Nov 2013 13:19:34 +0100
Subject: [R] grnn input format usage?
Message-ID: <CAKteAhGRmVEK4nWfgO8tg2rWro6FMm=A2yR9bPD61BFENDmGGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/f8a41ce6/attachment.pl>

From mashranga at yahoo.com  Mon Nov 11 13:31:27 2013
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Mon, 11 Nov 2013 04:31:27 -0800 (PST)
Subject: [R] Apply a function with multiple argument on each column of matrix
Message-ID: <1384173087.36768.YahooMailNeo@web142605.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/dd937a59/attachment.pl>

From djandrija at gmail.com  Mon Nov 11 13:35:17 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Mon, 11 Nov 2013 13:35:17 +0100
Subject: [R] repeating values in an index two by two
In-Reply-To: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
Message-ID: <CABcwgRQaB56EeGZF1_FpK-Dv1LToK3-WA6UshdTL+3Q8f1QjLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/658f52cb/attachment.pl>

From S.Ellison at LGCGroup.com  Mon Nov 11 13:42:10 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 11 Nov 2013 12:42:10 +0000
Subject: [R] MM robust
In-Reply-To: <1384164811.96407.YahooMailNeo@web142503.mail.bf1.yahoo.com>
References: <1384164811.96407.YahooMailNeo@web142503.mail.bf1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5554FF2AB4@GOLD.corp.lgc-group.com>

> given the model
> 
> y = x1 / 1+ b1x2^b2
>...
> i am able to find the parameter of the above model usingnls method, can u
> please give hint on how i can solve the same model as above using MM
> robust?estimate to obtain the parameter. i mean u can illustrate using the
> above information to enable me extend to what i am doing

have a look at ?nlrob in the robustbase package.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ligges at statistik.tu-dortmund.de  Mon Nov 11 13:49:13 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 11 Nov 2013 13:49:13 +0100
Subject: [R] Apply a function with multiple argument on each column of
 matrix
In-Reply-To: <1384173087.36768.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1384173087.36768.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <5280D249.9070000@statistik.tu-dortmund.de>



On 11.11.2013 13:31, Mohammad Tanvir Ahamed wrote:
> Hi there !!
> I have a function like
> fun <- function(x,y)
> {
> loe<-loess(y ~ x,span=0.9,family="gaussian")
> pre<-predict(loe,data.frame(x=x))
> return(pre)
> }
>
> Now i have defined :
> x<-1:500
>
> y<-matrix(rnorm(1000,3),ncol=2)
>
> I can manipulate fun(x,y[,1]) .
> But i want to apply the function on each column of matrix y .

apply(y, 2, function(i) fun(x, i))

Uwe Ligges


> Any suggestion will be appreciated .
> Thanks .
>
>
> Best regards
>
>
> ...........................
> Tanvir Ahamed
> G?teborg, Sweden
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mashranga at yahoo.com  Mon Nov 11 13:54:25 2013
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Mon, 11 Nov 2013 04:54:25 -0800 (PST)
Subject: [R] Apply a function with multiple argument on each column of
	matrix
In-Reply-To: <5280D249.9070000@statistik.tu-dortmund.de>
References: <1384173087.36768.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<5280D249.9070000@statistik.tu-dortmund.de>
Message-ID: <1384174465.96738.YahooMailNeo@web142604.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/21a0c02d/attachment.pl>

From f.calboli at imperial.ac.uk  Mon Nov 11 14:01:03 2013
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Mon, 11 Nov 2013 13:01:03 +0000
Subject: [R] repeating values in an index two by two
In-Reply-To: <CABcwgRQaB56EeGZF1_FpK-Dv1LToK3-WA6UshdTL+3Q8f1QjLA@mail.gmail.com>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
	<CABcwgRQaB56EeGZF1_FpK-Dv1LToK3-WA6UshdTL+3Q8f1QjLA@mail.gmail.com>
Message-ID: <3C1B003A-E038-40A1-B46C-8EA02FD7A6E1@imperial.ac.uk>

Hi,

first off, thanks for the suggestion.  I managed to solve it by doing:

IND = rep(c(T,T,F,F), 5)
X = rep(NA, 20)
X[IND] = 1:10
X[!IND] = 1:10

which avoids any function -- I think mapply, apply etc call a for loop internally, which I'd rather avoid.

BW

F



On 11 Nov 2013, at 12:35, andrija djurovic <djandrija at gmail.com> wrote:

> Hi. Here are two approaches:
> 
> c(mapply(function(x,y) rep(c(x,y), 2), (1:10)[c(T,F)], (1:10)[c(F,T)]))
> 
> c(tapply(1:10, rep(1:(10/2), each=2), rep, 2), recursive=T)
> 
> Andrija
> 
> 
> 
> 
> 
> On Mon, Nov 11, 2013 at 1:11 PM, Federico Calboli <f.calboli at imperial.ac.uk> wrote:
> Hi All,
> 
> I am trying to create an index that returns something like
> 
> 1,2,1,2,3,4,3,4,5,6,5,6,7,8,7,8
> 
> and so on and so forth until a predetermined value (which is obviously even).  I am trying very hard to avoid for loops or for loops front ends.
> 
> I'd be obliged if anybody could offer a suggestion.
> 
> BW
> 
> F
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 881 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/094d9112/attachment.bin>

From josh.m.ulrich at gmail.com  Mon Nov 11 14:12:10 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Mon, 11 Nov 2013 07:12:10 -0600
Subject: [R]
	=?windows-1252?q?package_=91build-essential=92_is_not_availab?=
	=?windows-1252?q?le_=28for_R_version_3=2E0=2E2=29?=
In-Reply-To: <5280B961.2030607@chyden.net>
References: <5280B961.2030607@chyden.net>
Message-ID: <CAPPM_gTvqP82Atr6ui2eCkdy29NRqL=bMK=TO45mz19T68d8Og@mail.gmail.com>

Have you read these instructions?
http://cran.r-project.org/bin/linux/ubuntu/README.html

They say to run
sudo apt-get install r-base-dev

which should install 'build-essential' (which is an Ubuntu package,
not an R package).
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Mon, Nov 11, 2013 at 5:02 AM, Charles Evans <cevans at chyden.net> wrote:
> Hello,
>
> I have searched on the R-Project site, R-Help archives, and the Internet
> at large, and I cannot find a solution to my problem.
>
> I am running R version 3.0.2 (2013-09-25) -- "Frisbee Sailing" on Ubuntu
> 13.04.
>
> When I try to install several packages, including quantmod, with
> dependencies=T set, and I keep getting long lists of packages that
> result in "installation of package 'X' had non-zero exit status".  When
> I try to install X, I get another list of packages that failed to install.
>
> After a few iterations of this, the package that I am trying to install
> is listed among the packages that have failed to install.
>
> I found a reference online to build-essential, but when I tried to
> install that, I got "package ?build-essential? is not available (for R
> version 3.0.2)".
>
> Any hints or follow-up questions would be greatly appreciated.
>
> C.Evans
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From derex.fen at gmail.com  Mon Nov 11 14:49:14 2013
From: derex.fen at gmail.com (Dereje Fentie)
Date: Mon, 11 Nov 2013 14:49:14 +0100
Subject: [R] r package to solve for Nash equilibrium
Message-ID: <CAEqV=wdmACAB9PrsRHx4M9R889Q4LiabegkEMdAioZP8J9nS1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/5c2eb746/attachment.pl>

From gunter.berton at gene.com  Mon Nov 11 15:59:20 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 11 Nov 2013 06:59:20 -0800
Subject: [R] how to introduce missing data for complete data
In-Reply-To: <CAMgoKBKj0EQ0MVJzKkFyGFewv64Hfv1-GVc9iz=nbfpnWmoWwQ@mail.gmail.com>
References: <CAMgoKBKj0EQ0MVJzKkFyGFewv64Hfv1-GVc9iz=nbfpnWmoWwQ@mail.gmail.com>
Message-ID: <CACk-te3J5AFz0nefSqdBcpn9pnhhx5TWD_drtWVYzJ2UomnXbA@mail.gmail.com>

1. You need to define more explicitly exactly what you mean by "randomly."

2. You need to make an honest effort to learn basic R, e.g. by
spending time with the "Introduction to R" document that ships with R
or an online tutorial (there are many good ones).

Cheers,
Bert

On Sun, Nov 10, 2013 at 10:31 PM, dila radi <dilaradi21 at gmail.com> wrote:
> Hi,
>
> Im new R users. In my research I use rainfall data and Im interested in
> estimating missing data. I would like to use Normal Ratio Method to
> estimate missing data. My problem is, how do I introduce missing data
> randomly within my complete set of data?
>
>
> Stn ID      Year  Mth   Day   Amount
> 48603 71 1 1 1
> 48603 71 1 2 0.5
> 48603 71 1 3 1.3
> 48603 71 1 4 0.8
> 48603 71 1 5 0
> 48603 71 1 6 0
> 48603 71 1 7 0
> ...
>
> Thank you so much for your attention and help.
>
> Regards,
> Dila
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From pburns at pburns.seanet.com  Mon Nov 11 16:14:39 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 11 Nov 2013 15:14:39 +0000
Subject: [R] repeating values in an index two by two
In-Reply-To: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
Message-ID: <5280F45F.3050707@pburns.seanet.com>

 > f1
function(x) {
     one <- matrix(1:x, nrow=2)
     as.vector(rbind(one, one))
}
<environment: 0x000000000daaf1c0>
 > f1(8)
  [1] 1 2 1 2 3 4 3 4 5 6 5 6 7 8 7 8

Pat


On 11/11/2013 12:11, Federico Calboli wrote:
> Hi All,
>
> I am trying to create an index that returns something like
>
> 1,2,1,2,3,4,3,4,5,6,5,6,7,8,7,8
>
> and so on and so forth until a predetermined value (which is obviously even).  I am trying very hard to avoid for loops or for loops front ends.
>
> I'd be obliged if anybody could offer a suggestion.
>
> BW
>
> F
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From dcarlson at tamu.edu  Mon Nov 11 16:32:33 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 11 Nov 2013 09:32:33 -0600
Subject: [R] Cross Tabulation
Message-ID: <067601cedef3$3d815b70$b8841250$@tamu.edu>

OK. Then using aggregate():

> data$yes <- ifelse(data$response=="yes", 1, 0)
> data$no <- ifelse(data$response=="no", 1, 0)
> dataresp <- aggregate(cbind(no, yes)~region+district, data,
sum)
> dataresp[,3:4] <- dataresp[,3:4]/rowSums(dataresp[,3:4])
> # or dataresp[,3:4] <- prop.table(as.matrix(dataresp[,3:4]),
1)
> dataresp
  region district  no yes
1      A        d 0.5 0.5
2      A        e 0.0 1.0
3      B        f 0.5 0.5
4      B        g 0.5 0.5
5      C        h 0.5 0.5
6      C        i 0.0 1.0
7      C        j 1.0 0.0

David

From: Peter Maclean [mailto:pmaclean2011 at yahoo.com] 
Sent: Sunday, November 10, 2013 12:52 PM
To: dcarlson at tamu.edu
Subject: Re: [R] Cross Tabulation

Thanks. But I am creating?lots of tables and I need Regions and
Districts to appear so as to avoid to much editing.
?
Peter Maclean
Department of Economics
UDSM

On Sunday, November 10, 2013 12:32 PM, David Carlson
<dcarlson at tamu.edu> wrote:
The simplest would be to create a variable combining region and
district:

> data$region_district <- with(data, paste(region, district))
> prop.table(xtabs(~region_district+response, data), 1)
? ? ? ? ? ? ? response
region_district? no yes
? ? ? ? ? ? A d 0.5 0.5
? ? ? ? ? ? A e 0.0 1.0
? ? ? ? ? ? B f 0.5 0.5
? ? ? ? ? ? B g 0.5 0.5
? ? ? ? ? ? C h 0.5 0.5
? ? ? ? ? ? C i 0.0 1.0
? ? ? ? ? ? C j 1.0 0.0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Peter Maclean
Sent: Sunday, November 10, 2013 12:06 AM
To: r-help at r-project.org
Subject: Re: [R] Cross Tabulation


#Would like to create a cross-table (Region, district, response)
and 
#(Region, district, cost. The flat table function does not look
so good 
region? <- c("A","A","A","A","B","B", "B", "B", "C","C", "C",
"C") 
district <- c("d","d","e","e","f","f", "g", "g", "h","h", "i",
"j") 
response <- c("yes", "no", "yes", "yes", "no", "yes", "yes",
"no", "yes", "no", "yes","no")
cost? <-? runif(12, 5.0, 9)
var <- c("region", "response", "district")
data <- data.frame(region, district, response, cost)
var1 <- c("region", "district", "response")
var2 <- c("region", "district", "cost")
data1 <- data[var1]
#This look okay
with(data, aggregate(x=cost, by=list(region, district),
FUN="mean"))
#This does not look good 
#How do i remove the NaN or create a better one
prop.table(ftable(data1, exclude = c(NA, NaN)), 1)
prop.table(ftable(xtabs(~region + district+ response,
data=data)),1)


Peter Maclean
Department of Economics
UDSM

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From carl at witthoft.com  Mon Nov 11 17:16:06 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 11 Nov 2013 08:16:06 -0800 (PST)
Subject: [R] repeating values in an index two by two
In-Reply-To: <5280F45F.3050707@pburns.seanet.com>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
	<5280F45F.3050707@pburns.seanet.com>
Message-ID: <1384186566678-4680234.post@n4.nabble.com>

Here's a rather extreme solution:

 foo<-rep(1:6,each=2)
Rgames> foo
 [1] 1 1 2 2 3 3 4 4 5 5 6 6

Rgames> foo[rep(c(1,3,2,4),3)+rep(c(0,4,8),each=4)]
 [1] 1 2 1 2 3 4 3 4 5 6 5 6

In the general case, then, it would be something like

foo<- rep(1:N, each = 2)  # foo is of length(2*N)

foo[rep(c(1,3,2,4),2*N/4 + rep( seq(0, 3*N/4,by=4),each=4)]

Note that the refolding requires the sequence to have length a multiple of
4.




Patrick Burns wrote
>> f1
> function(x) {
>      one <- matrix(1:x, nrow=2)
>      as.vector(rbind(one, one))
> }
> <environment: 0x000000000daaf1c0>
>  > f1(8)
>   [1] 1 2 1 2 3 4 3 4 5 6 5 6 7 8 7 8
> 
> Pat
> 
> 
> On 11/11/2013 12:11, Federico Calboli wrote:
>> Hi All,
>>
>> I am trying to create an index that returns something like
>>
>> 1,2,1,2,3,4,3,4,5,6,5,6,7,8,7,8
>>
>> and so on and so forth until a predetermined value (which is obviously
>> even).  I am trying very hard to avoid for loops or for loops front ends.
>>
>> I'd be obliged if anybody could offer a suggestion.
>>
>> BW
>>
>> F
>>
>>
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> -- 
> Patrick Burns

> pburns at .seanet

> twitter: @burnsstat @portfolioprobe
> http://www.portfolioprobe.com/blog
> http://www.burns-stat.com
> (home of:
>   'Impatient R'
>   'The R Inferno'
>   'Tao Te Programming')
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/repeating-values-in-an-index-two-by-two-tp4680210p4680234.html
Sent from the R help mailing list archive at Nabble.com.


From deter088 at umn.edu  Mon Nov 11 17:40:26 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 11 Nov 2013 10:40:26 -0600
Subject: [R] repeating values in an index two by two
In-Reply-To: <1384186566678-4680234.post@n4.nabble.com>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
	<5280F45F.3050707@pburns.seanet.com>
	<1384186566678-4680234.post@n4.nabble.com>
Message-ID: <CAOLJphkqSDQvLcd5BQFUwQ6X2+7MCDYD4Vsv1CBLZTGs6uC9EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/00d68a42/attachment.pl>

From iakub.henschen at gmail.com  Mon Nov 11 17:41:31 2013
From: iakub.henschen at gmail.com (Iakub Henschen)
Date: Mon, 11 Nov 2013 11:41:31 -0500
Subject: [R] repeating values in an index two by two
In-Reply-To: <1384186566678-4680234.post@n4.nabble.com>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
	<5280F45F.3050707@pburns.seanet.com>
	<1384186566678-4680234.post@n4.nabble.com>
Message-ID: <CAOmdYorVFCP6Yeb0ixazD2T68WPt+XrNWx7uSh0yta17kr4Zhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/e6054f4d/attachment.pl>

From wdunlap at tibco.com  Mon Nov 11 18:04:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Nov 2013 17:04:09 +0000
Subject: [R] repeating values in an index two by two
In-Reply-To: <CAOmdYorVFCP6Yeb0ixazD2T68WPt+XrNWx7uSh0yta17kr4Zhg@mail.gmail.com>
References: <80B3917B-7502-4859-9EEC-62AE991C939B@imperial.ac.uk>
	<5280F45F.3050707@pburns.seanet.com>
	<1384186566678-4680234.post@n4.nabble.com>
	<CAOmdYorVFCP6Yeb0ixazD2T68WPt+XrNWx7uSh0yta17kr4Zhg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA14867@PA-MBX01.na.tibco.com>

Or you can use the integer divide and remainder operators:
   > n <- 30
   > x <- seq(0, len=n)
   > + (x %% 2) + (x %/% 4)*2 + 1 # period 2 oscillator + jump by 2 every fourth
    [1]  1  2  1  2  3  4  3  4  5  6  5  6  7  8  7
   [16]  8  9 10  9 10 11 12 11 12 13 14 13 14 15 16

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Iakub Henschen
> Sent: Monday, November 11, 2013 8:42 AM
> To: r-help at r-project.org
> Subject: Re: [R] repeating values in an index two by two
> 
> > n<-7
> > rep(seq(1,n,2), each=4)+c(0,1,0,1)
>  [1] 1 2 1 2 3 4 3 4 5 6 5 6 7 8 7 8
> 
> rep(), seq(), rbind(), apply() ... whatever: internally there will always
> be iteration via some loop :-)
> 
> Ia.
> 
> 
> On Mon, Nov 11, 2013 at 11:16 AM, Carl Witthoft <carl at witthoft.com> wrote:
> 
> > Here's a rather extreme solution:
> >
> >  foo<-rep(1:6,each=2)
> > Rgames> foo
> >  [1] 1 1 2 2 3 3 4 4 5 5 6 6
> >
> > Rgames> foo[rep(c(1,3,2,4),3)+rep(c(0,4,8),each=4)]
> >  [1] 1 2 1 2 3 4 3 4 5 6 5 6
> >
> > In the general case, then, it would be something like
> >
> > foo<- rep(1:N, each = 2)  # foo is of length(2*N)
> >
> > foo[rep(c(1,3,2,4),2*N/4 + rep( seq(0, 3*N/4,by=4),each=4)]
> >
> > Note that the refolding requires the sequence to have length a multiple of
> > 4.
> >
> >
> >
> >
> > Patrick Burns wrote
> > >> f1
> > > function(x) {
> > >      one <- matrix(1:x, nrow=2)
> > >      as.vector(rbind(one, one))
> > > }
> > > <environment: 0x000000000daaf1c0>
> > >  > f1(8)
> > >   [1] 1 2 1 2 3 4 3 4 5 6 5 6 7 8 7 8
> > >
> > > Pat
> > >
> > >
> > > On 11/11/2013 12:11, Federico Calboli wrote:
> > >> Hi All,
> > >>
> > >> I am trying to create an index that returns something like
> > >>
> > >> 1,2,1,2,3,4,3,4,5,6,5,6,7,8,7,8
> > >>
> > >> and so on and so forth until a predetermined value (which is obviously
> > >> even).  I am trying very hard to avoid for loops or for loops front
> > ends.
> > >>
> > >> I'd be obliged if anybody could offer a suggestion.
> > >>
> > >> BW
> > >>
> > >> F
> > >>
> > >>
> > >>
> > >> ______________________________________________
> > >>
> >
> > > R-help@
> >
> > >  mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > > --
> > > Patrick Burns
> >
> > > pburns at .seanet
> >
> > > twitter: @burnsstat @portfolioprobe
> > > http://www.portfolioprobe.com/blog
> > > http://www.burns-stat.com
> > > (home of:
> > >   'Impatient R'
> > >   'The R Inferno'
> > >   'Tao Te Programming')
> > >
> > > ______________________________________________
> >
> > > R-help@
> >
> > >  mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/repeating-values-in-an-index-two-by-two-
> tp4680210p4680234.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Nov 11 18:05:57 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 11 Nov 2013 09:05:57 -0800
Subject: [R] graphics or table
In-Reply-To: <CAC_+zuqsfnXi3COVHsZBLc4gc75UkDkoBddyxOf3pCN7QeT0Pw@mail.gmail.com>
References: <CAC_+zuqsfnXi3COVHsZBLc4gc75UkDkoBddyxOf3pCN7QeT0Pw@mail.gmail.com>
Message-ID: <f828fa0d-379f-4119-b6da-592f5e63d2fd@email.android.com>

Your code is messed up because you posted in HTML. Also, it is not reproducible (e.g. no sample data, incomplete analysis code). (See http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for more on reproducibility.) Also, this looks very much like homework and the Posting Guide (mentioned in the footer of this email) indicates that homework is off topic here, and that you should rely on resources provided by your educational institution.

If you want to put all of these various values in one table, you will need to write code to do so, since you have to specify how you want that table laid out. E.g.

resultdf <- data.frame( Mean=mean(res), StdDev=SD(res))

but mixing single valued measures such as mean with vector valued measures such as residuals in a single table usually requires repeating the SVM in many rows, which is why this often is avoided.

Your unnecessary and inappropriate use of as.data.frame also suggests that you need to spend some time studying the Introduction to R document that comes with the software learning the difference between vectors, lists and data frames.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Enzo Cocca <enzo.ccc at gmail.com> wrote:
>hi
>
>I have this code for a cross validation:
>
>>res <- as.data.frame(CV_Pb_var)$residual>      sqrt(mean(res^2))>     
>mean(res)>      mean(res^2/as.data.frame(CV_Pb_var)$var1.var)
>
>
>I can not seem to export everything in one table
>
>
> also  can I to be exported it graphically?
>
>
>thanks
>
>
>enzo


From derex.fen at gmail.com  Mon Nov 11 18:11:47 2013
From: derex.fen at gmail.com (Dereje Fentie)
Date: Mon, 11 Nov 2013 18:11:47 +0100
Subject: [R] Generating bootstrap samples from a panel data frame
Message-ID: <CAEqV=wfHkQ2H-3t_tL_Z60WurWZZk_mQEAdaXDc0nwkLENeZvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/1c220945/attachment.pl>

From kiangati at gmail.com  Mon Nov 11 16:02:19 2013
From: kiangati at gmail.com (Keniajin Wambui)
Date: Mon, 11 Nov 2013 18:02:19 +0300
Subject: [R] Bar Graph
Message-ID: <CAE=fH8H0f554HZJNwx9xvn_ydHtDmkWXXybJ5JEarDYTkNcr4g@mail.gmail.com>

I am using R 3.0.2 on a 64 bit machine

I have a data set from 1989-2002. The data has four variables
serialno, date, admission ward, temperature and bcg scar.

serialno admin_ward date_admn bcg_scar temp_axilla yr
70162    Ward2         11-Oct-89       y           38.9 1989
70163     Ward1        11-Oct-91       y             37.2 1991
70164     Ward2       11-Oct-92        n               37.3 1992
70165     Ward1        11-Oct-93        y                38.9 1993
70166     Ward1       11-Oct-94          y              37.7 1994
70167      Ward1       11-Oct-95          y              40 1995


I want to do a bar graph of total data (serialno) vs *(data of one of
the variables) to show the available data vs total data over the years

i am using

gplot(dta, aes(temp_axilla, fill=admin_ward)) + geom_bar() +
  facet_grid(. ~ yr, scales = "free",margins=F) + geom_histogram(binwidth=300)

But can include the serialno which shows the data. how can I achieve this

-- 
Mega Six Solutions
Web Designer and Research Consultant
Kennedy Mwai


From kinsham at verizon.net  Mon Nov 11 17:58:38 2013
From: kinsham at verizon.net (Chris Wilkinson)
Date: Mon, 11 Nov 2013 11:58:38 -0500
Subject: [R] Earth (MARS) package with categorical predictors
In-Reply-To: <489C2C765C874A17AEE42FBECE781996@Studio17>
References: <489C2C765C874A17AEE42FBECE781996@Studio17>
Message-ID: <000501cedeff$44e702a0$ceb507e0$@net>

Steve, thanks for your reply. Here is what I get.

pkg is a 4-level categorical vector.

> is.factor(pkg)
[1] TRUE>
> summary(pkg)
BGA PGA QCC QFP 
225  36  19 178 
>
> dat <- earth(lifetime ~ pkg+pins+volts+temp+doi+logspd, degree=3) ## The
other vars are continuous.
> s <- 243
> pr <- c(pkg[s],pins[s],volts[s],temp[s],doi[s],logspd[s])
> pkg[s]
[1] BGA
Levels: BGA PGA QCC QFP
> pr
[1]    1.000000  256.000000    3.300000  125.000000 2002.258105    4.890349
> pred <- predict(dat, newdata=pr)
Error : variable 'pkg' was fitted with type "factor" but type "numeric" was
supplied
Forging on regardless, first few rows of x are
  pkg pins volts temp      doi   logspd
1   1  256   3.3  125 2002.258 4.890349
Error: get.earth.x from model.matrix.earth from predict.earth: the number 6
of columns of x
(after factor expansion) does not match the number 8 of columns of the earth
object
    expanded x:  pkg pins volts temp doi logspd
    object$dirs: pkgPGA pkgQCC pkgQFP pins volts temp doi logspd
Possible remedy: check factors in the input data
>

Pkg is being passed as numeric 1. I'm unsure how to correctly specify pkg
for predict. In the example you gave, does the data include a categorical?

Chris

-----Original Message-----
From: Stephen Milborrow [mailto:milbo at sonic.net] 
Sent: Monday, November 11, 2013 7:21 AM
To: kinsham at verizon.net
Subject: [R] Earth (MARS) package with categorical predictors

See if you can provide a simple reproducible example.  It's not clear 
exactly what the issue is from your question.  The following simple example 
gives the correct response:

data(etitanic)
a <- earth(survived~., data=etitanic)
predict(a, newdata=etitanic[1,])

Regards,
Steve

Message: 42
Date: Thu, 07 Nov 2013 23:16:18 -0500
From: Chris Wilkinson <kinsham at verizon.net>
To: r-help at r-project.org, Chris Wilkinson <kinsham at verizon.net>
Subject: [R] Earth (MARS) package with categorical predictors
Message-ID: <ml99syxejec3ep0u4h0je78h.1383884178002 at email.android.com>
Content-Type: text/plain; charset=utf-8

It appears to be legitimate to include multi-level categorical and
continuous variables in defining the model for earth (e.g. y ~ cat +
cont1 + cont2) but is it also then possible use categoricals in the
predict method using the earth result? I tried but it returns an error
which is not very informative.

Thanks

Chris


From phiartea.emn at gmail.com  Mon Nov 11 15:36:18 2013
From: phiartea.emn at gmail.com (Viarti Eminita)
Date: Mon, 11 Nov 2013 21:36:18 +0700
Subject: [R] (no subject)
Message-ID: <CAMtTxviHWMx0ZVAEPY34Qw7SCoLKCaLMJGobCKQO-uLGBXaGZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/a4774b41/attachment.pl>

From carlos.nasher at googlemail.com  Mon Nov 11 18:49:08 2013
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Mon, 11 Nov 2013 18:49:08 +0100
Subject: [R] SOLVED: Count number of consecutive zeros by group
Message-ID: <CAP=BVWMvnOk-227WMZh4ZQzTNJsd=iTtdxeSxP-7a+-FDW2viA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/a7b6cb6e/attachment.pl>

From COLLINL at pitt.edu  Mon Nov 11 18:50:36 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Mon, 11 Nov 2013 12:50:36 -0500
Subject: [R] (no subject)
In-Reply-To: <CAMtTxviHWMx0ZVAEPY34Qw7SCoLKCaLMJGobCKQO-uLGBXaGZA@mail.gmail.com>
References: <CAMtTxviHWMx0ZVAEPY34Qw7SCoLKCaLMJGobCKQO-uLGBXaGZA@mail.gmail.com>
Message-ID: <b719344a35c7c3ee49608a6f4ff42108.squirrel@webmail.pitt.edu>

Hi Viarti, can you clarify your question slightly?
(1) When you say "the predict value still on pattern scale" what do you
mean?  It sounds like you are saying that the prediction values are on the
Ytraining values specifically or do you mean that you expect the scale to
differ.
(2) When you say how "to change the predict value to the real data value"
do you mean change the scale.

Perhaps if you gave some examples of the desired outputs it would be eaiser.

    Best,
    Collin.


> Dear Mr/Mrs.
>
> I am Viarti Eminita, student from magister fifth level of Statistics in
> Bogor Agriculture University. Mr/ Mrs, now I'm analyzing ANN on time
> series
> data, I am learning kohonen package for series data, but when I want to
> predict, the predict value still on pattern scale. I wanna ask how to
> change the predict value to real data value?
>
> example:
> data <- read.table("D:/THESIS/Data/data.txt",head=T)
> Ytraining <- scale(data[1:168,3])
> Xtraining <- scale(data[1:168,4:6])
> Xtest <- scale(data[168:180,4:6])
> xyf <- xyf(Xtraining,Ytraining,grid = somgrid(5, 5, "hexagonal"))
> xyf.prediction <- predict(xyf,newdata=Xtest)
>
> thank's Mr/Mrs.
>
> best regard,
>
> viarti
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From triutami.iut at gmail.com  Mon Nov 11 19:04:06 2013
From: triutami.iut at gmail.com (Iut Tri Utami)
Date: Tue, 12 Nov 2013 01:04:06 +0700
Subject: [R] ensemble methods
Message-ID: <CANpQC0kit1p7cYaAo8dewifZx2PUAbn6ExthwcZx+uy6etoe5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/24e8df7d/attachment.pl>

From gunter.berton at gene.com  Mon Nov 11 19:49:21 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 11 Nov 2013 10:49:21 -0800
Subject: [R] ensemble methods
In-Reply-To: <CANpQC0kit1p7cYaAo8dewifZx2PUAbn6ExthwcZx+uy6etoe5Q@mail.gmail.com>
References: <CANpQC0kit1p7cYaAo8dewifZx2PUAbn6ExthwcZx+uy6etoe5Q@mail.gmail.com>
Message-ID: <CACk-te3LeoHXFWyuGE+Xgp057Z6qwcjZvndMgqVfS9aVxT5yCQ@mail.gmail.com>

See the R randomForest package.

This already does ensemble classification and regression.

-- Bert

On Mon, Nov 11, 2013 at 10:04 AM, Iut Tri Utami <triutami.iut at gmail.com> wrote:
> Dear Mr/Mrs
>
> I am Iut, student of graduate student in Bogor Agriculture Institur
> I read a book on ensemble methods in data mining by Seni and Elder and find
> R code about bagging.
> I am confused how to call these functions and and how to agregate it with
> the majority votes?
> I think there is missing code in here.What if the function is replaced with
> SVM?
>
> Example :
> genPredictors <- function(seed = 123, N = 30) {
> # Load package with random number generation
> # for the multivariate normal distribution
> library(mnormt)
> # 5 "features" each having a "standard" Normal
> # distribution with pairwise correlation 0.95
> Rho <- matrix(c(1,.95,.95,.95,.95,
> + .95, 1,.95,.95,.95,
> + .95,.95,1,.95,.95,
> + .95,.95,.95,1,.95,
> + .95,.95,.95,.95,1), 5, 5)
> mu <- c(rep(0,5))
> set.seed(seed);
> x <- rmnorm(N, mu, Rho)
> colnames(x) <- c("x1", "x2", "x3", "x4", "x5")
> return(x)
> }
> genTarget <- function(x, N, seed = 123) {
> # Response Y is generated according to:
> # Pr(Y = 1 | x1 <= 0.5) = 0.2,
> # Pr(Y = 1 | x1 > 0.5) = 0.8
> y <- c(rep(-1, N))
> set.seed(seed);
> for (i in 1:N) {
> if ( x[i,1] <= 0.5 ) {
> if ( runif(1) <= 0.2 ) {
> y[i] <- 1
> } else {
> y[i] <- 0
> }
> } else {
> if ( runif(1) <= 0.8 ) {
> y[i] <- 1
> } else {
> y[i] <- 0
> }
> }
> }
> return(y)
> }
> genBStrapSamp <- function(seed = 123, N = 200, Size = 30) {
> set.seed(seed)
> sampleList <- vector(mode = "list", length = N)
> for (i in 1:N) {
> sampleList[[i]] <- sample(1:Size, replace=TRUE)
> }
> return(sampleList)
> }
> fitBStrapTrees <- function(data, sampleList, N) {
> treeList <- vector(mode = "list", length = N)
> for (i in 1:N) {
> tree.params=list(minsplit = 4, minbucket = 2, maxdepth = 7)
> treeList[[i]] <- fitClassTree(data[sampleList[[i]],],
> tree.params)
> }
> return(treeList)
> }
> fitClassTree <- function(x, params, w = NULL,
> seed = 123) {
> library(rpart)
> set.seed(seed)
> tree <- rpart(y ~ ., method = "class",
> data = x, weights = w, cp = 0,
> minsplit = params.minsplit,
> minbucket = params.minbucket,
> maxdepth = params.maxdepth)
> return(tree)
> }
>
> thankyou very much
>
> best regard,
>
> Iut
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From alemu.tadesse at gmail.com  Mon Nov 11 20:01:21 2013
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Mon, 11 Nov 2013 12:01:21 -0700
Subject: [R] Date handling in R is hard to understand
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9E03E@SRVEXCHMBX.precheza.cz>
References: <CACGkHRN8uSY4Z+Bf597NBCv9UdLOnUpAgLdWmZBBLaiNgM76Xg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9E03E@SRVEXCHMBX.precheza.cz>
Message-ID: <CACGkHRMMhzVNuw46D=5ge0P3vd0DVOHdery7aL2Ckh_qcFoEyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/038b5d47/attachment.pl>

From macqueen1 at llnl.gov  Mon Nov 11 21:02:31 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 11 Nov 2013 20:02:31 +0000
Subject: [R] how to introduce missing data for complete data
In-Reply-To: <CAMgoKBKj0EQ0MVJzKkFyGFewv64Hfv1-GVc9iz=nbfpnWmoWwQ@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D551074@PRDEXMBX-08.the-lab.llnl.gov>

Here's a suggestion.

The sample() function takes random samples of sets. See
  ?sample
The set you want to take a random sample from is the rows of your data.
Represent the rows by their row numbers.
To get a vector of row numbers, you can use the seq() function. See
  ?seq

Let's suppose your data is in a data frame named 'mydat', and you want to
introduce 10 instances of missing data.

nr <- nrow(mydat)
set.to.missing <- sample( seq(nr) , 10)
mydat$Amount[set.to.missing] <- NA


A simplified example of the core idea is:

> foo <-seq(10)
> foo
 [1]  1  2  3  4  5  6  7  8  9 10
> foo[3] <- NA> foo
 [1]  1  2 NA  4  5  6  7  8  9 10


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/10/13 10:31 PM, "dila radi" <dilaradi21 at gmail.com> wrote:

>Hi,
>
>Im new R users. In my research I use rainfall data and Im interested in
>estimating missing data. I would like to use Normal Ratio Method to
>estimate missing data. My problem is, how do I introduce missing data
>randomly within my complete set of data?
>
>
>Stn ID      Year  Mth   Day   Amount
>48603 71 1 1 1
>48603 71 1 2 0.5
>48603 71 1 3 1.3
>48603 71 1 4 0.8
>48603 71 1 5 0
>48603 71 1 6 0
>48603 71 1 7 0
>...
>
>Thank you so much for your attention and help.
>
>Regards,
>Dila
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Mon Nov 11 21:50:11 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Mon, 11 Nov 2013 20:50:11 +0000
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/270c8742/attachment.pl>

From zilefacelvis at yahoo.com  Mon Nov 11 21:56:24 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 11 Nov 2013 12:56:24 -0800 (PST)
Subject: [R] select .txt from .txt in a directory
In-Reply-To: <1384043223.37448.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1383932015.59227.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<23B10D03-95AC-493D-8F26-8D2AF18AF4FE@uni-bonn.de>
	<1383933084.60740.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<40BA7A91-3B12-434D-8615-C7519D16451C@uni-bonn.de>
	<1383935182.41321.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383935434.56654.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1383936055.76561.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1383941883.12484.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1383951262.61119.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1384037214.39832.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1384043223.37448.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1384203384.72168.YahooMailNeo@web160605.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/f4130c61/attachment.pl>

From wdunlap at tibco.com  Mon Nov 11 22:18:04 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Nov 2013 21:18:04 +0000
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA149A3@PA-MBX01.na.tibco.com>

If you have an algorithm that only works on sorted data, it is easy to
write a function that sorts [a copy of] the data, applies the algorithm,
then puts the result back in the order of the original data.  E.g.,

f <- function (data)  {
    ord <- with(data, order(TT, ID, FY)) # data[ord,] will be sorted in your required order
    data$EXCL3 <- 1 * duplicated(data[ord, 1:2], fromLast = TRUE)[order(ord)] # [order(ord)] puts it back in original order
    data
}

E.g.,
> i <- c(12, 5, 10, 6, 4, 2, 1, 3, 7, 11, 9, 8)
> scrambled <- HTDF[i,]
> f(scrambled)
     FY ID  TT EXCL3
12 FY13  2 TER     0
5  FY12  1 TER     0
10 FY12  2  HC     0
6  FY09  2  HC     0
4  FY12  1  HC     1
2  FY10  1  HC     0
1  FY09  1  HC     0
3  FY11  1  HC     0
7  FY10  2  HC     1
11 FY13  2  HC     1
9  FY11  2  HC     0
8  FY10  2 TER     0

Or is your dataset so large that this sorting and unsorting would take too
long or too much space?

(There are faster ways of doing this than duplicated(), but the details depend
on some details like whether or not there may be more than 2 FY/ID duplicates.]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Lopez, Dan
> Sent: Monday, November 11, 2013 12:50 PM
> To: R help (r-help at r-project.org)
> Subject: [R] How do I derive a logical variable in a dataframe based on another row in the
> same dataframe?
> 
> Hi R Experts,
> 
> How do I mark rows in dataframe based on a condition that's based off another row in
> the same dataframe?
> 
> I want to mark any combination of FY,ID, TT=='HC' rows that have a FY,ID,TT=='TER' row
> with a 1.  In my example below this is rows 4, 7 and 11.
> My data looks something like this:
>     FY ID  TT
> 1  FY09  1  HC
> 2  FY10  1  HC
> 3  FY11  1  HC
> 4  FY12  1  HC
> 5  FY12  1 TER
> 6  FY09  2  HC
> 7  FY10  2  HC
> 8  FY10  2 TER
> 9  FY11  2  HC
> 10 FY12  2  HC
> 11 FY13  2  HC
> 12 FY13  2 TER
> 
> I know for this specific example I can use:
> HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)
> 
> However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable.
> I want to know if there is another way of doing the same thing without sorting the data.
> I tried the last line of code below but it gave me unexpected results. It marks the first
> three rows with 0 and everything else with 1.  Based on the warning messages looks like
> it has something to do with longer object length is not a multiple of shorter object
> length. But I am now stumped.
> 
> #REPRODUCIBLE EXAMPLE
> FY<-
> factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","FY11","FY12","FY13
> ","FY13"))
> ID<-c(rep(1,5),rep(2,7))
> TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
> HTDF<-data.frame(FY,ID,TT)
> 
> #Summarize data and get max TT. TT is a binary factor variable
> library(sqldf)
> HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY ID,FY')
> 
> # Initiate new variable and assign 0 or 1
> HTDF$EXCL<-0
> 
> # THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
> HTDF$EXCL<-
> ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==HTDF.MAX$MAX
> TT,0,1)
> 
> 
> Dan Lopez
> Workforce Analyst
> LLNL
> HRIM - Workforce Analytics & Metrics
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From seanstclair at verizon.net  Mon Nov 11 23:01:06 2013
From: seanstclair at verizon.net (seanstclair at verizon.net)
Date: Mon, 11 Nov 2013 16:01:06 -0600 (CST)
Subject: [R] Data Security when using R
Message-ID: <13433027.310180.1384207266078.JavaMail.root@vznit170080>


   Hello.  At the company I work for, I recently requested having R loaded onto
   my desktop and some of my colleagues.

   My company's IT/Security groups are having trouble assessing whether R
   software meets their standards.

   Can anyone point me to a source where i can read about how R uses data? does
   it store the data somewhere?  Does data ever actually leave the company's
   environment?  etc...?

   Thanks.
   Sean

From smartpink111 at yahoo.com  Mon Nov 11 23:25:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 11 Nov 2013 14:25:44 -0800 (PST)
Subject: [R] How do I derive a logical variable in a dataframe based on
	another row in the same dataframe?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <1384208744.26484.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
You may try:

fun1 <- function(dat){
dat$EXCL3 <- 0
dat$EXCL3[dat$TT=="HC"] <- 1*as.character(interaction(dat[,1:2]))[dat$TT=="HC"] %in% as.character(interaction(dat[,1:2]))[dat$TT=="TER"]
dat
}

fun1(HTDF)

set.seed(14)
?indx <- sample(1:nrow(HTDF),12)
?HTDF1 <- HTDF[indx,]

fun1(HTDF1)

A.K.




On Monday, November 11, 2013 4:49 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

How do I mark rows in dataframe based on a condition that's based off another row in the same dataframe?

I want to mark any combination of FY,ID, TT=='HC' rows that have a FY,ID,TT=='TER' row with a 1.? In my example below this is rows 4, 7 and 11.
My data looks something like this:
? ? FY ID? TT
1? FY09? 1? HC
2? FY10? 1? HC
3? FY11? 1? HC
4? FY12? 1? HC
5? FY12? 1 TER
6? FY09? 2? HC
7? FY10? 2? HC
8? FY10? 2 TER
9? FY11? 2? HC
10 FY12? 2? HC
11 FY13? 2? HC
12 FY13? 2 TER

I know for this specific example I can use:
HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)

However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable. I want to know if there is another way of doing the same thing without sorting the data.
I tried the last line of code below but it gave me unexpected results. It marks the first three rows with 0 and everything else with 1.? Based on the warning messages looks like it has something to do with longer object length is not a multiple of shorter object length. But I am now stumped.

#REPRODUCIBLE EXAMPLE
FY<-factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","FY11","FY12","FY13","FY13"))
ID<-c(rep(1,5),rep(2,7))
TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
HTDF<-data.frame(FY,ID,TT)

#Summarize data and get max TT. TT is a binary factor variable
library(sqldf)
HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY ID,FY')

# Initiate new variable and assign 0 or 1
HTDF$EXCL<-0

# THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
HTDF$EXCL<-ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==HTDF.MAX$MAXTT,0,1)


Dan Lopez
Workforce Analyst
LLNL
HRIM - Workforce Analytics & Metrics

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From teresamarso at hotmail.com  Mon Nov 11 23:52:16 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Mon, 11 Nov 2013 22:52:16 +0000
Subject: [R] colours legend, for loop,density plot
Message-ID: <DUB125-W1108F7613E140D206A8FC6B9FF0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/36a34507/attachment.pl>

From ggrothendieck at gmail.com  Tue Nov 12 00:01:44 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 11 Nov 2013 18:01:44 -0500
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CAP01uRmuFti2FhmxNOpK4AOezyueQVfXz+MDZFdnG9XFWEGcMw@mail.gmail.com>

On Mon, Nov 11, 2013 at 3:50 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Hi R Experts,
>
> How do I mark rows in dataframe based on a condition that's based off another row in the same dataframe?
>
> I want to mark any combination of FY,ID, TT=='HC' rows that have a FY,ID,TT=='TER' row with a 1.  In my example below this is rows 4, 7 and 11.
> My data looks something like this:
>     FY ID  TT
> 1  FY09  1  HC
> 2  FY10  1  HC
> 3  FY11  1  HC
> 4  FY12  1  HC
> 5  FY12  1 TER
> 6  FY09  2  HC
> 7  FY10  2  HC
> 8  FY10  2 TER
> 9  FY11  2  HC
> 10 FY12  2  HC
> 11 FY13  2  HC
> 12 FY13  2 TER
>
> I know for this specific example I can use:
> HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)
>
> However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable. I want to know if there is another way of doing the same thing without sorting the data.
> I tried the last line of code below but it gave me unexpected results. It marks the first three rows with 0 and everything else with 1.  Based on the warning messages looks like it has something to do with longer object length is not a multiple of shorter object length. But I am now stumped.
>
> #REPRODUCIBLE EXAMPLE
> FY<-factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","FY11","FY12","FY13","FY13"))
> ID<-c(rep(1,5),rep(2,7))
> TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
> HTDF<-data.frame(FY,ID,TT)
>
> #Summarize data and get max TT. TT is a binary factor variable
> library(sqldf)
> HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY ID,FY')
>
> # Initiate new variable and assign 0 or 1
> HTDF$EXCL<-0
>
> # THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
> HTDF$EXCL<-ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==HTDF.MAX$MAXTT,0,1)

For each FY, ID group ave applies f to TT == 'TER' returning
a logical vector that is TRUE for each HC if TER is in the group
ad otherwise FALSE.   Finally we add 0 to convert from
TRUE/FALSE to 1/0.

The rows of HTDF need not be in any specific order and their
oreder will be preserved.

> f <- function(x) any(x) & !x
> transform(HTDF, EXCL = ave(TT == 'TER', FY, ID, FUN = f) + 0)
     FY ID  TT EXCL
1  FY09  1  HC    0
2  FY10  1  HC    0
3  FY11  1  HC    0
4  FY12  1  HC    1
5  FY12  1 TER    0
6  FY09  2  HC    0
7  FY10  2  HC    1
8  FY10  2 TER    0
9  FY11  2  HC    0
10 FY12  2  HC    0
11 FY13  2  HC    1
12 FY13  2 TER    0


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jim at bitwrit.com.au  Mon Nov 11 23:59:58 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 12 Nov 2013 09:59:58 +1100
Subject: [R] colours legend, for loop,density plot
In-Reply-To: <DUB125-W1108F7613E140D206A8FC6B9FF0@phx.gbl>
References: <DUB125-W1108F7613E140D206A8FC6B9FF0@phx.gbl>
Message-ID: <5281616E.7070003@bitwrit.com.au>

On 11/12/2013 09:52 AM, M? Teresa Martinez Soriano wrote:
> normal<-sort(rnorm(1000))	cauchy<-sort(rcauchy(1000))	t3<-sort(rt(1000,3))	t10<-sort(rt(1000, 10))
> 	col<-c("green","blue","orange","purple")	v<-list(normal,cauchy,t3,t10)	names(v)<-c("Normal", "Cauchy", "T-stud 3 df", "T-stud 10 df")
> 	par(mfrow=c(1,2))		plot(density(normal),col=col[[1]],main="Funciones de densidad")	for ( i in 2:4)	{	lines(density(v[[i]]),col=col[[i]],lty=i+2)	}
> 	legend(x=-4,y=0.3,names(v),col=col,cex=0.6)
>
Hi Tere,
Try this:

legend(x=-2,y=0.04,names(v),col=col,cex=0.6,lty=c(1,4:6))

Jim


From kw.stat at gmail.com  Tue Nov 12 00:35:41 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 11 Nov 2013 17:35:41 -0600
Subject: [R] Data Security when using R
In-Reply-To: <13433027.310180.1384207266078.JavaMail.root@vznit170080>
References: <13433027.310180.1384207266078.JavaMail.root@vznit170080>
Message-ID: <CAKFxdiRrxD-=tLGRfmc8jiJkseR09itavsqnb_eHZcd6FAmF9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/52eb9df4/attachment.pl>

From macqueen1 at llnl.gov  Tue Nov 12 00:35:46 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 11 Nov 2013 23:35:46 +0000
Subject: [R] Data Security when using R
In-Reply-To: <13433027.310180.1384207266078.JavaMail.root@vznit170080>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D5548DA@PRDEXMBX-08.the-lab.llnl.gov>

See below

-- 
Don MacQueen

Lawrence Livermore National Laboratory


On 11/11/13 2:01 PM, "seanstclair at verizon.net" <seanstclair at verizon.net>
wrote:

>
>   Hello.  At the company I work for, I recently requested having R
>loaded onto
>   my desktop and some of my colleagues.
>
>   My company's IT/Security groups are having trouble assessing whether R
>   software meets their standards.
>
>   Can anyone point me to a source where i can read about how R uses data?

I would start by downloading  "An Introduction to R" from CRAN and
searching on "save" and ".RData".


> does
>   it store the data somewhere?

Yes. In memory to start, and optionally to disk, normally somewhere in the
user's home directory or working directory.

>  Does data ever actually leave the company's
>   environment? 

Not unless the user does something explicit to make it happen.

> etc...?

No less secure than, say, MS Excel, I would think.

Others with a deeper understanding than I may point out exceptions or
special cases worth knowing about ... I hope.

>
>   Thanks.
>   Sean
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Tue Nov 12 01:02:20 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 12 Nov 2013 00:02:20 +0000
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
In-Reply-To: <1384208744.26484.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
	<1384208744.26484.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAF0BF@PRDEXMBX-05.the-lab.llnl.gov>



Thanks.
Dan

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, November 11, 2013 2:26 PM
To: R help (r-help at r-project.org)
Cc: Lopez, Dan
Subject: Re: [R] How do I derive a logical variable in a dataframe based on another row in the same dataframe?

Hi,
You may try:

fun1 <- function(dat){
dat$EXCL3 <- 0
dat$EXCL3[dat$TT=="HC"] <- 1*as.character(interaction(dat[,1:2]))[dat$TT=="HC"] %in% as.character(interaction(dat[,1:2]))[dat$TT=="TER"]
dat
}

fun1(HTDF)

set.seed(14)
?indx <- sample(1:nrow(HTDF),12)
?HTDF1 <- HTDF[indx,]

fun1(HTDF1)

A.K.




On Monday, November 11, 2013 4:49 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

How do I mark rows in dataframe based on a condition that's based off another row in the same dataframe?

I want to mark any combination of FY,ID, TT=='HC' rows that have a FY,ID,TT=='TER' row with a 1.? In my example below this is rows 4, 7 and 11.
My data looks something like this:
? ? FY ID? TT
1? FY09? 1? HC
2? FY10? 1? HC
3? FY11? 1? HC
4? FY12? 1? HC
5? FY12? 1 TER
6? FY09? 2? HC
7? FY10? 2? HC
8? FY10? 2 TER
9? FY11? 2? HC
10 FY12? 2? HC
11 FY13? 2? HC
12 FY13? 2 TER

I know for this specific example I can use:
HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)

However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable. I want to know if there is another way of doing the same thing without sorting the data.
I tried the last line of code below but it gave me unexpected results. It marks the first three rows with 0 and everything else with 1.? Based on the warning messages looks like it has something to do with longer object length is not a multiple of shorter object length. But I am now stumped.

#REPRODUCIBLE EXAMPLE
FY<-factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","FY11","FY12","FY13","FY13"))
ID<-c(rep(1,5),rep(2,7))
TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
HTDF<-data.frame(FY,ID,TT)

#Summarize data and get max TT. TT is a binary factor variable
library(sqldf)
HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY ID,FY')

# Initiate new variable and assign 0 or 1
HTDF$EXCL<-0

# THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
HTDF$EXCL<-ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==HTDF.MAX$MAXTT,0,1)


Dan Lopez
Workforce Analyst
LLNL
HRIM - Workforce Analytics & Metrics

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Tue Nov 12 01:02:40 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 12 Nov 2013 00:02:40 +0000
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA149A3@PA-MBX01.na.tibco.com>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
	<E66794E69CFDE04D9A70842786030B933FA149A3@PA-MBX01.na.tibco.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAF0C6@PRDEXMBX-05.the-lab.llnl.gov>

Great advice!
Thank you.

Dan


-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com] 
Sent: Monday, November 11, 2013 1:18 PM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: RE: [R] How do I derive a logical variable in a dataframe based on another row in the same dataframe?

If you have an algorithm that only works on sorted data, it is easy to write a function that sorts [a copy of] the data, applies the algorithm, then puts the result back in the order of the original data.  E.g.,

f <- function (data)  {
    ord <- with(data, order(TT, ID, FY)) # data[ord,] will be sorted in your required order
    data$EXCL3 <- 1 * duplicated(data[ord, 1:2], fromLast = TRUE)[order(ord)] # [order(ord)] puts it back in original order
    data
}

E.g.,
> i <- c(12, 5, 10, 6, 4, 2, 1, 3, 7, 11, 9, 8) scrambled <- HTDF[i,]
> f(scrambled)
     FY ID  TT EXCL3
12 FY13  2 TER     0
5  FY12  1 TER     0
10 FY12  2  HC     0
6  FY09  2  HC     0
4  FY12  1  HC     1
2  FY10  1  HC     0
1  FY09  1  HC     0
3  FY11  1  HC     0
7  FY10  2  HC     1
11 FY13  2  HC     1
9  FY11  2  HC     0
8  FY10  2 TER     0

Or is your dataset so large that this sorting and unsorting would take too long or too much space?

(There are faster ways of doing this than duplicated(), but the details depend on some details like whether or not there may be more than 2 FY/ID duplicates.]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Lopez, Dan
> Sent: Monday, November 11, 2013 12:50 PM
> To: R help (r-help at r-project.org)
> Subject: [R] How do I derive a logical variable in a dataframe based 
> on another row in the same dataframe?
> 
> Hi R Experts,
> 
> How do I mark rows in dataframe based on a condition that's based off 
> another row in the same dataframe?
> 
> I want to mark any combination of FY,ID, TT=='HC' rows that have a 
> FY,ID,TT=='TER' row with a 1.  In my example below this is rows 4, 7 and 11.
> My data looks something like this:
>     FY ID  TT
> 1  FY09  1  HC
> 2  FY10  1  HC
> 3  FY11  1  HC
> 4  FY12  1  HC
> 5  FY12  1 TER
> 6  FY09  2  HC
> 7  FY10  2  HC
> 8  FY10  2 TER
> 9  FY11  2  HC
> 10 FY12  2  HC
> 11 FY13  2  HC
> 12 FY13  2 TER
> 
> I know for this specific example I can use:
> HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)
> 
> However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable.
> I want to know if there is another way of doing the same thing without sorting the data.
> I tried the last line of code below but it gave me unexpected results. 
> It marks the first three rows with 0 and everything else with 1.  
> Based on the warning messages looks like it has something to do with 
> longer object length is not a multiple of shorter object length. But I am now stumped.
> 
> #REPRODUCIBLE EXAMPLE
> FY<-
> factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","FY11
> ","FY12","FY13
> ","FY13"))
> ID<-c(rep(1,5),rep(2,7))
> TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
> HTDF<-data.frame(FY,ID,TT)
> 
> #Summarize data and get max TT. TT is a binary factor variable
> library(sqldf)
> HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY 
> ID,FY')
> 
> # Initiate new variable and assign 0 or 1
> HTDF$EXCL<-0
> 
> # THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
> HTDF$EXCL<-
> ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==HTDF.MAX$MAX
> TT,0,1)
> 
> 
> Dan Lopez
> Workforce Analyst
> LLNL
> HRIM - Workforce Analytics & Metrics
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lopez235 at llnl.gov  Tue Nov 12 01:41:28 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 12 Nov 2013 00:41:28 +0000
Subject: [R] How do I derive a logical variable in a dataframe based on
 another row in the same dataframe?
In-Reply-To: <CAP01uRmuFti2FhmxNOpK4AOezyueQVfXz+MDZFdnG9XFWEGcMw@mail.gmail.com>
References: <56180B40A4F72A4083C75B30DA86297333DAEFA0@PRDEXMBX-05.the-lab.llnl.gov>
	<CAP01uRmuFti2FhmxNOpK4AOezyueQVfXz+MDZFdnG9XFWEGcMw@mail.gmail.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAF117@PRDEXMBX-05.the-lab.llnl.gov>

Hi Gabor,

This is a great solution!  I will use it.

Thank you!

Dan


-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Monday, November 11, 2013 3:02 PM
To: Lopez, Dan
Cc: R help (r-help at r-project.org)
Subject: Re: [R] How do I derive a logical variable in a dataframe based on another row in the same dataframe?

On Mon, Nov 11, 2013 at 3:50 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Hi R Experts,
>
> How do I mark rows in dataframe based on a condition that's based off another row in the same dataframe?
>
> I want to mark any combination of FY,ID, TT=='HC' rows that have a FY,ID,TT=='TER' row with a 1.  In my example below this is rows 4, 7 and 11.
> My data looks something like this:
>     FY ID  TT
> 1  FY09  1  HC
> 2  FY10  1  HC
> 3  FY11  1  HC
> 4  FY12  1  HC
> 5  FY12  1 TER
> 6  FY09  2  HC
> 7  FY10  2  HC
> 8  FY10  2 TER
> 9  FY11  2  HC
> 10 FY12  2  HC
> 11 FY13  2  HC
> 12 FY13  2 TER
>
> I know for this specific example I can use:
> HTDF$EXCL3<-1*duplicated(HTDF[,1:2],fromLast=T)
>
> However my actual data set is NOT sorted by FY, ID and TT. TT is a binary factor variable. I want to know if there is another way of doing the same thing without sorting the data.
> I tried the last line of code below but it gave me unexpected results. It marks the first three rows with 0 and everything else with 1.  Based on the warning messages looks like it has something to do with longer object length is not a multiple of shorter object length. But I am now stumped.
>
> #REPRODUCIBLE EXAMPLE
> FY<-factor(c("FY09","FY10","FY11","FY12","FY12","FY09","FY10","FY10","
> FY11","FY12","FY13","FY13"))
> ID<-c(rep(1,5),rep(2,7))
> TT<-factor(c(rep("HC",4),"TER","HC","HC","TER","HC","HC","HC","TER"))
> HTDF<-data.frame(FY,ID,TT)
>
> #Summarize data and get max TT. TT is a binary factor variable
> library(sqldf)
> HTDF.MAX<-sqldf('SELECT ID,FY,Max(TT) "MAXTT" FROM HTDF GROUP BY 
> ID,FY')
>
> # Initiate new variable and assign 0 or 1
> HTDF$EXCL<-0
>
> # THIS IS WHERE I AM GETTING UNEXPECTE RESULTS
> HTDF$EXCL<-ifelse(HTDF$FY==HTDF.MAX$FY&HTDF$ID==HTDF.MAX$ID&HTDF$TT==H
> TDF.MAX$MAXTT,0,1)

For each FY, ID group ave applies f to TT == 'TER' returning a logical vector that is TRUE for each HC if TER is in the group
ad otherwise FALSE.   Finally we add 0 to convert from
TRUE/FALSE to 1/0.

The rows of HTDF need not be in any specific order and their oreder will be preserved.

> f <- function(x) any(x) & !x
> transform(HTDF, EXCL = ave(TT == 'TER', FY, ID, FUN = f) + 0)
     FY ID  TT EXCL
1  FY09  1  HC    0
2  FY10  1  HC    0
3  FY11  1  HC    0
4  FY12  1  HC    1
5  FY12  1 TER    0
6  FY09  2  HC    0
7  FY10  2  HC    1
8  FY10  2 TER    0
9  FY11  2  HC    0
10 FY12  2  HC    0
11 FY13  2  HC    1
12 FY13  2 TER    0


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From lopez235 at llnl.gov  Tue Nov 12 02:04:03 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 12 Nov 2013 01:04:03 +0000
Subject: [R] Update a variable in a dataframe based on variables in another
 dataframe of a different size
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAF137@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/1ba849e6/attachment.pl>

From ggrothendieck at gmail.com  Tue Nov 12 02:20:38 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 11 Nov 2013 20:20:38 -0500
Subject: [R] Update a variable in a dataframe based on variables in
 another dataframe of a different size
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DAF137@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DAF137@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CAP01uRnBoRAWm_GFGfg6BJ5yVNFkxRSNYFEBgqzuxfXQRqwOYA@mail.gmail.com>

On Mon, Nov 11, 2013 at 8:04 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Below is how I am currently doing this. Is there a more efficient way to do this?
> The scenario is that I have two dataframes of different sizes. I need to update one binary factor variable in one of those dataframes by matching on two variables. If there is no match keep as is otherwise update. Also the variable being update, TT in this case should remain a binary factor variable (levels='HC','TER')
>
> HTDF2<-merge(H_DF,T_DF,by=c("FY","ID"),all.x=T)
> HTDF2$TT<-factor(ifelse(is.na(HTDF2$TT.y),HTDF2$TT.x,HTDF2$TT.y),labels=c("HC","TER"))
> HTDF2<-HTDF2[,-(3:4)]
>
>
> # REPRODUCIBLE EXAMPLE DATA FOR ABOVE..
>> dput(H_DF)
> structure(list(FY = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,
> 5L), .Label = c("FY09", "FY10", "FY11", "FY12", "FY13"), class = "factor"),
>     ID = c(1, 1, 1, 1, 2, 2, 2, 2, 2), TT = structure(c(1L, 1L,
>     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("HC", "TER"), class = "factor")), .Names = c("FY",
> "ID", "TT"), class = "data.frame", row.names = c(1L, 2L, 3L,
> 4L, 6L, 7L, 9L, 10L, 11L))
>> dput(T_DF)
> structure(list(FY = structure(c(4L, 2L, 5L), .Label = c("FY09",
> "FY10", "FY11", "FY12", "FY13"), class = "factor"), ID = c(1,
> 2, 2), TT = structure(c(2L, 2L, 2L), .Label = c("HC", "TER"), class = "factor")), .Names = c("FY",
> "ID", "TT"), row.names = c(5L, 8L, 12L), class = "data.frame")
>

Here is an sqldf solution:

> library(sqldf)
> sqldf("select FY, ID, coalesce(t.TT, h.TT) TT from H_DF h left join T_DF t using(FY, ID)")
    FY ID  TT
1 FY09  1  HC
2 FY10  1  HC
3 FY11  1  HC
4 FY12  1 TER
5 FY09  2  HC
6 FY10  2 TER
7 FY11  2  HC
8 FY12  2  HC
9 FY13  2 TER


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From lopez235 at llnl.gov  Tue Nov 12 02:57:38 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 12 Nov 2013 01:57:38 +0000
Subject: [R] Saving then Loading Objects/Models into existing workspace.
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAF1BF@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/95fee76a/attachment.pl>

From rayd at liondatasystems.com  Tue Nov 12 05:05:05 2013
From: rayd at liondatasystems.com (Ray DiGiacomo, Jr.)
Date: Mon, 11 Nov 2013 20:05:05 -0800
Subject: [R] Elastic-R Webinar Invite
Message-ID: <CACT39NYc-48CnPwaD6Oskjet9syFC1Ua_pVqa83Yafi8fg_PYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131111/31fd6f4b/attachment.pl>

From wchongyang at gmail.com  Tue Nov 12 05:40:57 2013
From: wchongyang at gmail.com (Wang Chongyang)
Date: Tue, 12 Nov 2013 12:40:57 +0800
Subject: [R] unable to install package xts
Message-ID: <CAEJ3vw8Xx_ctdjFHGnJqjSyJt36qUMKN4BjxwkD1SVWtC3BM7w@mail.gmail.com>

I am using Ubuntu 12.04 and unable to install xts. Here are the info:

usr/bin/ld: cannot find -lgfortran
collect2: error: ld returned 1 exit status
make: *** [xts.so] Error 1
ERROR: compilation failed for package ?xts?
* removing ?/home/jasom/R/x86_64-pc-linux-gnu-library/3.0/xts?
Warning in install.packages :
  installation of package ?xts? had non-zero exit status

The downloaded source packages are in
    ?/tmp/RtmpVH1i1S/downloaded_packages?
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.2

Thanks in advance.

CY


From aline.frank at wsl.ch  Tue Nov 12 06:01:30 2013
From: aline.frank at wsl.ch (aline.frank at wsl.ch)
Date: Tue, 12 Nov 2013 06:01:30 +0100
Subject: [R] Getting residual term out of lmer summary table
Message-ID: <OF1141438F.C08FED98-ONC1257C21.001B9A7E-C1257C21.001B9A85@wsl.ch>

Hello

I'm working with mixed effects models using lmer() and have some problems to get all variance components of the model's random effects. I can get the variance of the random effect out of the summary and use it for further calculations, but not the variance component of the residual term. Could somebody help me with that problem? Thanks a lot! Below an example.

Aline



## EXAMPLE
#----------

require(lme4)

## Simulate data for the example
set.seed(6)
x1 <- runif(n=100, min=10, max=100) ## a continuos variable
x2 <- runif(n=100, min=10, max=100) ## a continuos variable

treat <- rep(letters[1:4], times=25) ## a fixed factor with 4 levels
treat.effect <- 20*rep(1:4, times=25) 

group.label <- rep(LETTERS[1:5], each=20)  ## the random effect
group.effect <- 10*rep(1:5, each=20)       ## there are 5 groups

## Response variable:
y <- 2*x1 + (-5)*x2 + treat.effect + group.effect + rnorm(100)

## Dataframe
d.ex <- data.frame(y, x1, x2, "Group"=group.label, treat)

## Apply model
mod1 <- lmer(y~x1+x2+treat+x1:treat+ (1|Group), data=d.ex)
output <- summary(mod1); output # ok, there is the variance component of the random effect group and the residual term

## Now I'd like to get the variance components of the random effect "Group" and of the residual term "Residual" in order 
# to do further calculations with these numbers
output$varcor[1] ## reveals the variance of the random effect "Group"
output$varcor[2] ## does not reveal the residual term! what other command do I need to use then?


From smartpink111 at yahoo.com  Tue Nov 12 04:01:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 11 Nov 2013 19:01:08 -0800 (PST)
Subject: [R] Apply function to every 20 rows between pairs of columns in
	a matrix
Message-ID: <1384225268.68199.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,

It's not very clear.
set.seed(25)
dat1 <- as.data.frame(matrix(sample(c("A","T","G","C"),46482*56,replace=TRUE),ncol=56,nrow=46482),stringsAsFactors=FALSE)
?lst1 <- split(dat1,as.character(gl(nrow(dat1),20,nrow(dat1))))
res <- lapply(lst1,function(x) sapply(x[,1:8],function(y) sapply(x[,9:56], function(z) sum(y==z)/20)))

?length(res)
#[1] 2325? ### check here
?dim(res[[1]])
#[1] 48? 8

A.K.



Hi all, I have a set of genetic SNP data that looks like 

Founder1 Founder2 Founder3 Founder4 Founder5 Founder6 Founder7 Founder8 Sample1 Sample2 Sample3 Sample... 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 

The size of the matrix is 56 columns by 46482 rows. I need to 
first bin the matrix by every 20 rows, then compare each of the first 8 
columns (founders) to each columns 9-56, and divide the total number of 
matching letters/alleles by the total number of rows (20). Ultimately I 
need 48 8 column by 2342 row matrices, which are essentially similarity 
matrices. I have tried to extract each pair separately by something like 

"length(cbind(odd[,9],odd[,1])[cbind(odd[,9],cbind(odd[,9],odd[,1])[,1])[,1]=="T"
 & cbind(odd[,9],odd[,1])[,2]=="T",])/nrow(cbind(odd[,9],odd[,1]))" 

but this is no where near efficient, and I do not know of a 
faster way of applying the function to every 20 rows and across multiple
 pairs. 

In the example given above, if the rows were all identical like 
shown across 20 rows, then the first row of the matrix for Sample1 would
 be 

1 1 1 0 0 0 0


From smartpink111 at yahoo.com  Tue Nov 12 04:40:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 11 Nov 2013 19:40:05 -0800 (PST)
Subject: [R] Apply function to every 20 rows between pairs of columns in
	a matrix
In-Reply-To: <CAF8+O=paB=UAoa53B0S09-twV=auMe_i7mzqQ_59QvXdcR1QXw@mail.gmail.com>
References: <18076153.250645.1384223858497.JavaMail.nabble@joe.nabble.com>	<CAF8+O=pqt-56Uvn8QiA6qzRPczV9TuDPv26Kvs-gOTgL-hX4aA@mail.gmail.com>	<1384225359.29411.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAF8+O=paB=UAoa53B0S09-twV=auMe_i7mzqQ_59QvXdcR1QXw@mail.gmail.com>
Message-ID: <1384227605.74172.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
May be this what you wanted.
res2 <- lapply(row.names(res[[1]]),function(x) do.call(rbind,lapply(res,function(y) y[match(x, row.names(y)),])))
?length(res2)
#[1] 48
?dim(res2[[1]])
#[1] 2325??? 8

A.K.


On Monday, November 11, 2013 10:20 PM, Yu-yu Ren <renyangsu at gmail.com> wrote:

Thank you so much for that script, it works great. One additional request; how can I go about binding each of the 2325 matrices for each sample, resulting in 48 matrices of 8 column by 2325 row?




On Mon, Nov 11, 2013 at 10:02 PM, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>I already sent a reply to R-help.? I am not sure about the "2342".
>
>set.seed(25)
>dat1 <- as.data.frame(matrix(sample(c("A","T","G","C"),46482*56,replace=TRUE),ncol=56,nrow=46482),stringsAsFactors=FALSE)
>?lst1 <- split(dat1,as.character(gl(nrow(dat1),20,nrow(dat1))))
>res <- lapply(lst1,function(x) sapply(x[,1:8],function(y) sapply(x[,9:56], function(z) sum(y==z)/20)))
>
>?length(res)
>#[1] 2325? ### check here
>?dim(res[[1]])
>#[1] 48? 8
>
>A.K.
>
>
>
>
>On Monday, November 11, 2013 10:00 PM, Yu-yu Ren <renyangsu at gmail.com> wrote:
>
>Thank you, I have uploaded several example files, with intermediate outputs of what I have done and the logic flow.
>
>
>
>
>On Mon, Nov 11, 2013 at 9:37 PM, <smartpink111 at yahoo.com> wrote:
>
>
>>Hi,
>>
>>Comparing the first 8 columns separately with 9-56 columns is not clear. ?Also, please provide a reproducible example (using ?dput) for others to work on.
>>
>>A.K.
>><quote author='Renyulb28'>
>>Hi all, I have a set of genetic SNP data that looks like
>>
>>Founder1 Founder2 Founder3 Founder4 Founder5 Founder6 Founder7 Founder8
>>Sample1 Sample2 Sample3 Sample...
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>A A A T T T T T A T A T
>>
>>The size of the matrix is 56 columns by 46482 rows. I need to first bin the
>>matrix by every 20 rows, then compare each of the first 8 columns (founders)
>>to each columns 9-56, and divide the total number of matching
>>letters/alleles by the total number of rows (20). Ultimately I need 48 8
>>column by 2342 row matrices, which are essentially similarity matrices. I
>>have tried to extract each pair separately by something like
>>
>>"length(cbind(odd[,9],odd[,1])[cbind(odd[,9],cbind(odd[,9],odd[,1])[,1])[,1]=="T"
>>& cbind(odd[,9],odd[,1])[,2]=="T",])/nrow(cbind(odd[,9],odd[,1]))"
>>
>>but this is no where near efficient, and I do not know of a faster way of
>>applying the function to every 20 rows and across multiple pairs.
>>
>>In the example given above, if the rows were all identical like shown across
>>20 rows, then the first row of the matrix for Sample1 would be
>>
>>1 1 1 0 0 0 0
>>
>></quote>
>>Quoted from:
>>http://r.789695.n4.nabble.com/Apply-function-to-every-20-rows-between-pairs-of-columns-in-a-matrix-tp4680272.html
>>
>>
>>_____________________________________
>>Sent from http://r.789695.n4.nabble.com
>>
>>
>


From smartpink111 at yahoo.com  Tue Nov 12 04:43:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 11 Nov 2013 19:43:35 -0800 (PST)
Subject: [R] Apply function to every 20 rows between pairs of columns in
	a matrix
In-Reply-To: <1384225268.68199.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1384225268.68199.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1384227815.65960.YahooMailNeo@web142601.mail.bf1.yahoo.com>







HI,


set.seed(25)
dat1 <- as.data.frame(matrix(sample(c("A","T","G","C"),46482*56,replace=TRUE),ncol=56,nrow=46482),stringsAsFactors=FALSE)
?lst1 <- split(dat1,as.character(gl(nrow(dat1),20,nrow(dat1))))
res <- lapply(lst1,function(x) sapply(x[,1:8],function(y) sapply(x[,9:56], function(z) sum(y==z)/20)))

?length(res)
#[1] 2325? ### check here
?dim(res[[1]])
#[1] 48? 8

A.K.



Hi all, I have a set of genetic SNP data that looks like 

Founder1 Founder2 Founder3 Founder4 Founder5 Founder6 Founder7 Founder8 Sample1 Sample2 Sample3 Sample... 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 
A A A T T T T T A T A T 

The size of the matrix is 56 columns by 46482 rows. I need to 
first bin the matrix by every 20 rows, then compare each of the first 8 
columns (founders) to each columns 9-56, and divide the total number of 
matching letters/alleles by the total number of rows (20). Ultimately I 
need 48 8 column by 2342 row matrices, which are essentially similarity 
matrices. I have tried to extract each pair separately by something like 

"length(cbind(odd[,9],odd[,1])[cbind(odd[,9],cbind(odd[,9],odd[,1])[,1])[,1]=="T"
& cbind(odd[,9],odd[,1])[,2]=="T",])/nrow(cbind(odd[,9],odd[,1]))" 

but this is no where near efficient, and I do not know of a 
faster way of applying the function to every 20 rows and across multiple
pairs. 

In the example given above, if the rows were all identical like 
shown across 20 rows, then the first row of the matrix for Sample1 would
be 

1 1 1 0 0 0 0


From edd at debian.org  Tue Nov 12 06:20:29 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 12 Nov 2013 05:20:29 +0000
Subject: [R] unable to install package xts
References: <CAEJ3vw8Xx_ctdjFHGnJqjSyJt36qUMKN4BjxwkD1SVWtC3BM7w@mail.gmail.com>
Message-ID: <loom.20131112T061933-44@post.gmane.org>

Wang Chongyang <wchongyang <at> gmail.com> writes:
> I am using Ubuntu 12.04 and unable to install xts. Here are the info:
> 
> usr/bin/ld: cannot find -lgfortran

Do 'sudo apt-get install r-base-dev' to install a set of requirement 
for building packages, which includes among other things the Fortran
library you are missing here.

Dirk


From miaojpm at gmail.com  Tue Nov 12 06:37:49 2013
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 12 Nov 2013 13:37:49 +0800
Subject: [R] Test for exogeneity
Message-ID: <CABcx46AfRxxGE9BrSMrCje_mER5yF1NZLvEeWoOuwvPrmAFEHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/89ca7ed7/attachment.pl>

From lucam1968 at gmail.com  Tue Nov 12 07:13:12 2013
From: lucam1968 at gmail.com (Luca Meyer)
Date: Tue, 12 Nov 2013 07:13:12 +0100
Subject: [R] sourcing from 2 different computers R code
Message-ID: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/62d85070/attachment.pl>

From kridox at ymail.com  Tue Nov 12 07:46:26 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 12 Nov 2013 15:46:26 +0900
Subject: [R] unable to install package xts
In-Reply-To: <CAEJ3vw8Xx_ctdjFHGnJqjSyJt36qUMKN4BjxwkD1SVWtC3BM7w@mail.gmail.com>
References: <CAEJ3vw8Xx_ctdjFHGnJqjSyJt36qUMKN4BjxwkD1SVWtC3BM7w@mail.gmail.com>
Message-ID: <CAAcyNCw2CGa_WQcgchV14UZkUw+ccs4-BzhqarzGspUKX+U1Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/6dd6261f/attachment.pl>

From kridox at ymail.com  Tue Nov 12 07:47:08 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 12 Nov 2013 15:47:08 +0900
Subject: [R] sourcing from 2 different computers R code
In-Reply-To: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>
References: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>
Message-ID: <CAAcyNCy1uoq+J=ObuNi49Dwt4s_Cf9UEUG9yOSq-=gkU-sbdNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/74033638/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Nov 12 07:51:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Nov 2013 06:51:43 +0000
Subject: [R] sourcing from 2 different computers R code
In-Reply-To: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>
References: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>
Message-ID: <5281CFFF.8090203@stats.ox.ac.uk>

This is not one but two FAQs:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-file-names-work-in-Windows_003f

http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file

See the posting guide and the footer of this message.

On 12/11/2013 06:13, Luca Meyer wrote:
> Hi,
>
> I have a piece of code sitting on a dropbox directory and haev installed R
> 3.0.2 on 2 machines: one MacBook Pro and one Sony Vaio pc.
>
> Now, when I use
>
> source("/Users/....R")
>
> to call the script from the Mac no problems, but when I use
>
> source("C:\Users\...R")
>
> to call the script from the Sony Vaio I get the following:
>
> Error: '\U' used without hex digits in character string starting "'C:\U"
>
> What am I doing wrong?
>
> Thanks in advance,
>
> Luca
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jwd at surewest.net  Tue Nov 12 09:53:58 2013
From: jwd at surewest.net (jwd)
Date: Tue, 12 Nov 2013 00:53:58 -0800
Subject: [R] Bar Graph
In-Reply-To: <CAE=fH8H0f554HZJNwx9xvn_ydHtDmkWXXybJ5JEarDYTkNcr4g@mail.gmail.com>
References: <CAE=fH8H0f554HZJNwx9xvn_ydHtDmkWXXybJ5JEarDYTkNcr4g@mail.gmail.com>
Message-ID: <20131112005358.37675698@draco.site>

On Mon, 11 Nov 2013 18:02:19 +0300
Keniajin Wambui <kiangati at gmail.com> wrote:

> I am using R 3.0.2 on a 64 bit machine
> 
> I have a data set from 1989-2002. The data has four variables
> serialno, date, admission ward, temperature and bcg scar.
> 
> serialno admin_ward date_admn bcg_scar temp_axilla yr
> 70162    Ward2         11-Oct-89       y           38.9 1989
> 70163     Ward1        11-Oct-91       y             37.2 1991
> 70164     Ward2       11-Oct-92        n               37.3 1992
> 70165     Ward1        11-Oct-93        y                38.9 1993
> 70166     Ward1       11-Oct-94          y              37.7 1994
> 70167      Ward1       11-Oct-95          y              40 1995
> 
> 
> I want to do a bar graph of total data (serialno) vs *(data of one of
> the variables) to show the available data vs total data over the years
> 
> i am using
> 
> gplot(dta, aes(temp_axilla, fill=admin_ward)) + geom_bar() +
>   facet_grid(. ~ yr, scales = "free",margins=F) +
> geom_histogram(binwidth=300)
> 
> But can include the serialno which shows the data. how can I achieve
> this
> 

You really need to pay better attention somewhere.  There are six
variables in your example table for instance, not four.  You state you
want to do something with the serialno variable, but it is not used 
in your bit of code.  Also, given that serialno appears to be
unique in your example, a bar graph would be singularly uninformative.

You need to provide a better example of the data, and an actual example
of the code you are trying to use, including the libraries you've
loaded.  

jwdougherty


From pollaroid at gmail.com  Tue Nov 12 10:53:23 2013
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 12 Nov 2013 10:53:23 +0100
Subject: [R] Loop through columns of outcomes
Message-ID: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/abcf2e53/attachment.pl>

From ii54250 at msn.com  Tue Nov 12 11:41:26 2013
From: ii54250 at msn.com (IOANNA)
Date: Tue, 12 Nov 2013 10:41:26 +0000
Subject: [R] Error in grf using geoR
Message-ID: <DUB126-DS155BBB1A3B597216D0F4EEF3FE0@phx.gbl>

Hello all, 

I cant find a thread with a problem similar to mine. I am trying to create a
random fields and I get the same error:

library(geoR)
N<-10
nslon<-250
nslat<-250
range<-10
sim2 <- grf(nslon*nslat, grid="reg", nx=nslon, ny=nslat,cov.pars=c(1,
range), 
              nsim=N, cov.model = "exponential",
              xlims=c(30.02,35.00),ylims=c(30.02,35.00) )

Error in FUN(X[[1L]], ...) : 
  different grid distances detected, but the grid must have equal distances
in each direction -- try gridtriple=TRUE that avoids numerical errors.

 I can't understand why as the code seems to run if I change the limits of
the grid:

sim2 <- grf(nslon*nslat, grid="reg", nx=nslon, ny=nslat,cov.pars=c(1,
range), 
              nsim=N, cov.model = "exponential",
              xlims=c(0.02,5.00),ylims=c(0.02,5.00) )

Any ideas?

Best 
Ioanna


From lucam1968 at gmail.com  Tue Nov 12 11:52:12 2013
From: lucam1968 at gmail.com (Luca Meyer)
Date: Tue, 12 Nov 2013 11:52:12 +0100
Subject: [R] sourcing from 2 different computers R code
In-Reply-To: <CAAcyNCy1uoq+J=ObuNi49Dwt4s_Cf9UEUG9yOSq-=gkU-sbdNA@mail.gmail.com>
References: <CABQyo84XXOgkw771LF9E8es2mrQjzNvZ3dNrkLOLJ9y8sxp84w@mail.gmail.com>
	<CAAcyNCy1uoq+J=ObuNi49Dwt4s_Cf9UEUG9yOSq-=gkU-sbdNA@mail.gmail.com>
Message-ID: <CABQyo863U0=mA7CKfHg3v6UzgJfVFYayL7rVCYa1N3ecOnZQvw@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/8e53f947/attachment.pl>

From ruipbarradas at sapo.pt  Tue Nov 12 12:32:42 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 12 Nov 2013 11:32:42 +0000
Subject: [R] Loop through columns of outcomes
In-Reply-To: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>
References: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>
Message-ID: <528211DA.2080302@sapo.pt>

Hello,

Use nested lapply(). Like this:



m1 <- lapply(varlist0,function(v) {
	lapply(outcomes, function(o){
		f <- sprintf("%s~ s(time,bs='cr',k=200)+s(temp,bs='cr') + 
Lag(%s,0:6)", o, v)
		gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
       })})

m1 <- unlist(m1, recursive = FALSE)
m1


Hope this helps,

Rui Barradas


Em 12-11-2013 09:53, Kuma Raj escreveu:
> I have asked this question on SO, but it attracted no response, thus I am
> cross- posting it here with the hope that someone would help.
>
> I want to estimate the effect of  pm10 and o3 on three outcome(death, cvd
> and resp). What I want to do is run one model for each of the main
> predictors  (pm10 and o3) and each outcome(death, cvd and resp). Thus I
> expect to obtain 6 models. The script below works for one outcome (death)
> and I wish to use it for more dependent variables.
>
>
>
> library(quantmod)
> library(mgcv)
> library(dlnm)
> df <- chicagoNMMAPS
> outcomes<- c("death", "cvd", "resp ")
> varlist0 <- c("pm10", "o3")
>
>      m1 <- lapply(varlist0,function(v) {
>          f <- sprintf("death~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
> Lag(%s,0:6)",v)
>          gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>        })
>
> Thanks
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alaios at yahoo.com  Tue Nov 12 13:15:36 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 12 Nov 2013 04:15:36 -0800 (PST)
Subject: [R] Colour Legend text, in a print color2D.matplot
In-Reply-To: <1384135497.89085.YahooMailNeo@web125306.mail.ne1.yahoo.com>
References: <1384089670.64248.YahooMailNeo@web125301.mail.ne1.yahoo.com>	<1384106236.75116.YahooMailNeo@web125301.mail.ne1.yahoo.com>	<52800FDD.4010206@bitwrit.com.au>
	<1384135497.89085.YahooMailNeo@web125306.mail.ne1.yahoo.com>
Message-ID: <1384258536.6576.YahooMailNeo@web125302.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/369d2ae1/attachment.pl>

From carl at witthoft.com  Tue Nov 12 13:31:56 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 12 Nov 2013 04:31:56 -0800 (PST)
Subject: [R] Ant Colony Optimization Algorithm
In-Reply-To: <1384250144598-4680292.post@n4.nabble.com>
References: <1384250144598-4680292.post@n4.nabble.com>
Message-ID: <1384259516486-4680300.post@n4.nabble.com>

We would need to see the contents of the "mplus" file that is read in.  Quite
possibly it's overwriting either "iter" or "count" with an incompatible data
type.

I would also recommend contactingWalter Leite directly to verify you have a
proper mplus source file.


/* partial quote follows   */

The error message I keep receiving is:
Read 107 items 
Error in count <= iter : 
  comparison (4) is possible only for atomic and list types 


The code I use comes from Walter Leite's webpage: 

http://education.ufl.edu/leite/code/

The syntax I use is the following:
#Last updated: 11/27/07 
#Function (in R language) that performs item selection for the development
of 
#short-forms of scales using an Ant Colony Optmization (ACO) Algorithm. 

#Author: Walter Leite, Assitant Professor, Department of Educational
Psychology 
#University of Florida 
#Contact Information: walter.leite at coe.ufl.edu 

#The paper "Item selection for the development of short-forms of scales
using 
#an Ant Colony Optimization algorithm" can be obtained by e-mailing the
author. 



--
View this message in context: http://r.789695.n4.nabble.com/Ant-Colony-Optimization-Algorithm-tp4680292p4680300.html
Sent from the R help mailing list archive at Nabble.com.


From pollaroid at gmail.com  Tue Nov 12 14:28:59 2013
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 12 Nov 2013 14:28:59 +0100
Subject: [R] Loop through columns of outcomes
In-Reply-To: <528211DA.2080302@sapo.pt>
References: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>
	<528211DA.2080302@sapo.pt>
Message-ID: <CAAC1QdCY3K9WiJy-0gqKg+DSTuoD10tPQY282RC6D7uep3GVkA@mail.gmail.com>

Thanks for the script which works perfectly. I am interested to do
model checking and also interested to extract the coefficients for
linear and spline terms. For model checkup I could run this script
which will give different plots to test model fit: gam.check(m2[[1]]).
Thanks to mnel from SO I could also extract the linear terms with the
following script:

m2 <- unlist(m1, recursive = FALSE)   ## unlist

First extract the model elements:

mod1<-m2[[1]]
mod2<-m2[[2]]
mod3<-m2[[3]]
mod4<-m2[[4]]
mod5<-m2[[5]]
mod6<-m2[[6]]

And run the following:

mlist <- list(mod1, mod2, mod3,mod4,mod5,mod6)  ##  Creates a list of models
names(mlist) <- list("mod1", "mod2", "mod3","mod4","mod5","mod6")

 slist <- lapply(mlist, summary)   ## obtain summaries

plist <- lapply(slist, `[[`, 'p.table')   ## list of the coefficients
linear terms

For 6 models this is relatively easy to do, but how could I shorten
the process if I have large number of models?

Thanks


On 12 November 2013 12:32, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Use nested lapply(). Like this:
>
>
>
> m1 <- lapply(varlist0,function(v) {
>         lapply(outcomes, function(o){
>                 f <- sprintf("%s~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
> Lag(%s,0:6)", o, v)
>
> gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>       })})
>
> m1 <- unlist(m1, recursive = FALSE)
> m1
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 12-11-2013 09:53, Kuma Raj escreveu:
>>
>> I have asked this question on SO, but it attracted no response, thus I am
>> cross- posting it here with the hope that someone would help.
>>
>> I want to estimate the effect of  pm10 and o3 on three outcome(death, cvd
>> and resp). What I want to do is run one model for each of the main
>> predictors  (pm10 and o3) and each outcome(death, cvd and resp). Thus I
>> expect to obtain 6 models. The script below works for one outcome (death)
>> and I wish to use it for more dependent variables.
>>
>>
>>
>> library(quantmod)
>> library(mgcv)
>> library(dlnm)
>> df <- chicagoNMMAPS
>> outcomes<- c("death", "cvd", "resp ")
>> varlist0 <- c("pm10", "o3")
>>
>>      m1 <- lapply(varlist0,function(v) {
>>          f <- sprintf("death~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
>> Lag(%s,0:6)",v)
>>          gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>>        })
>>
>> Thanks
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ishaqbaba at yahoo.com  Tue Nov 12 15:01:56 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Tue, 12 Nov 2013 06:01:56 -0800 (PST)
Subject: [R] (no subject)
Message-ID: <1384264916.91743.YahooMailNeo@web142505.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/830d61fd/attachment.pl>

From ishaqbaba at yahoo.com  Tue Nov 12 15:03:02 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Tue, 12 Nov 2013 06:03:02 -0800 (PST)
Subject: [R] codenls
In-Reply-To: <1384264916.91743.YahooMailNeo@web142505.mail.bf1.yahoo.com>
References: <1384264916.91743.YahooMailNeo@web142505.mail.bf1.yahoo.com>
Message-ID: <1384264982.50617.YahooMailNeo@web142502.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/0af971fb/attachment.pl>

From alaios at yahoo.com  Tue Nov 12 15:34:44 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 12 Nov 2013 06:34:44 -0800 (PST)
Subject: [R] Handle Gps coordinates
Message-ID: <1384266884.5102.YahooMailNeo@web125305.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/deccbc72/attachment.pl>

From babakbsn at gmail.com  Tue Nov 12 15:59:53 2013
From: babakbsn at gmail.com (Baro)
Date: Tue, 12 Nov 2013 06:59:53 -0800
Subject: [R] Having a relative x-axis in a plot
Message-ID: <CAF-JZQupPPoyGfd-1k0ztn7bHmFTxdXUjtMGHub9D3TYLh=2uQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/c800b393/attachment.pl>

From ruipbarradas at sapo.pt  Tue Nov 12 16:09:02 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 12 Nov 2013 15:09:02 +0000
Subject: [R] Loop through columns of outcomes
In-Reply-To: <CAAC1QdCY3K9WiJy-0gqKg+DSTuoD10tPQY282RC6D7uep3GVkA@mail.gmail.com>
References: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>	<528211DA.2080302@sapo.pt>
	<CAAC1QdCY3K9WiJy-0gqKg+DSTuoD10tPQY282RC6D7uep3GVkA@mail.gmail.com>
Message-ID: <5282448E.4020102@sapo.pt>

Hello,

Once again, use lapply.

mlist <- lapply(seq_along(m2), function(i) m2[[i]])
names(mlist) <- paste0("mod", seq_along(mlist))

slist <- lapply(mlist, summary)

plist <- lapply(slist, `[[`, 'p.table')


Hope this helps,

Rui Barradas

Em 12-11-2013 13:28, Kuma Raj escreveu:
> Thanks for the script which works perfectly. I am interested to do
> model checking and also interested to extract the coefficients for
> linear and spline terms. For model checkup I could run this script
> which will give different plots to test model fit: gam.check(m2[[1]]).
> Thanks to mnel from SO I could also extract the linear terms with the
> following script:
>
> m2 <- unlist(m1, recursive = FALSE)   ## unlist
>
> First extract the model elements:
>
> mod1<-m2[[1]]
> mod2<-m2[[2]]
> mod3<-m2[[3]]
> mod4<-m2[[4]]
> mod5<-m2[[5]]
> mod6<-m2[[6]]
>
> And run the following:
>
> mlist <- list(mod1, mod2, mod3,mod4,mod5,mod6)  ##  Creates a list of models
> names(mlist) <- list("mod1", "mod2", "mod3","mod4","mod5","mod6")
>
>   slist <- lapply(mlist, summary)   ## obtain summaries
>
> plist <- lapply(slist, `[[`, 'p.table')   ## list of the coefficients
> linear terms
>
> For 6 models this is relatively easy to do, but how could I shorten
> the process if I have large number of models?
>
> Thanks
>
>
> On 12 November 2013 12:32, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Use nested lapply(). Like this:
>>
>>
>>
>> m1 <- lapply(varlist0,function(v) {
>>          lapply(outcomes, function(o){
>>                  f <- sprintf("%s~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
>> Lag(%s,0:6)", o, v)
>>
>> gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>>        })})
>>
>> m1 <- unlist(m1, recursive = FALSE)
>> m1
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Em 12-11-2013 09:53, Kuma Raj escreveu:
>>>
>>> I have asked this question on SO, but it attracted no response, thus I am
>>> cross- posting it here with the hope that someone would help.
>>>
>>> I want to estimate the effect of  pm10 and o3 on three outcome(death, cvd
>>> and resp). What I want to do is run one model for each of the main
>>> predictors  (pm10 and o3) and each outcome(death, cvd and resp). Thus I
>>> expect to obtain 6 models. The script below works for one outcome (death)
>>> and I wish to use it for more dependent variables.
>>>
>>>
>>>
>>> library(quantmod)
>>> library(mgcv)
>>> library(dlnm)
>>> df <- chicagoNMMAPS
>>> outcomes<- c("death", "cvd", "resp ")
>>> varlist0 <- c("pm10", "o3")
>>>
>>>       m1 <- lapply(varlist0,function(v) {
>>>           f <- sprintf("death~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
>>> Lag(%s,0:6)",v)
>>>           gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>>>         })
>>>
>>> Thanks
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>


From pollaroid at gmail.com  Tue Nov 12 16:26:53 2013
From: pollaroid at gmail.com (Kuma Raj)
Date: Tue, 12 Nov 2013 16:26:53 +0100
Subject: [R] Loop through columns of outcomes
In-Reply-To: <5282448E.4020102@sapo.pt>
References: <CAAC1QdBYMSbFya1BNAsTHTJ7iVKE=DXE2bT3As_Vkj74oiP=AA@mail.gmail.com>
	<528211DA.2080302@sapo.pt>
	<CAAC1QdCY3K9WiJy-0gqKg+DSTuoD10tPQY282RC6D7uep3GVkA@mail.gmail.com>
	<5282448E.4020102@sapo.pt>
Message-ID: <CAAC1QdDfFofZ3swbRXKnSjTm-ab5YK3LQPFrkcXmjcwHw6RWig@mail.gmail.com>

Very helpful, many thanks.

On 12 November 2013 16:09, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Once again, use lapply.
>
> mlist <- lapply(seq_along(m2), function(i) m2[[i]])
> names(mlist) <- paste0("mod", seq_along(mlist))
>
> slist <- lapply(mlist, summary)
>
>
> plist <- lapply(slist, `[[`, 'p.table')
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 12-11-2013 13:28, Kuma Raj escreveu:
>
>> Thanks for the script which works perfectly. I am interested to do
>> model checking and also interested to extract the coefficients for
>> linear and spline terms. For model checkup I could run this script
>> which will give different plots to test model fit: gam.check(m2[[1]]).
>> Thanks to mnel from SO I could also extract the linear terms with the
>> following script:
>>
>> m2 <- unlist(m1, recursive = FALSE)   ## unlist
>>
>> First extract the model elements:
>>
>> mod1<-m2[[1]]
>> mod2<-m2[[2]]
>> mod3<-m2[[3]]
>> mod4<-m2[[4]]
>> mod5<-m2[[5]]
>> mod6<-m2[[6]]
>>
>> And run the following:
>>
>> mlist <- list(mod1, mod2, mod3,mod4,mod5,mod6)  ##  Creates a list of
>> models
>> names(mlist) <- list("mod1", "mod2", "mod3","mod4","mod5","mod6")
>>
>>   slist <- lapply(mlist, summary)   ## obtain summaries
>>
>> plist <- lapply(slist, `[[`, 'p.table')   ## list of the coefficients
>> linear terms
>>
>> For 6 models this is relatively easy to do, but how could I shorten
>> the process if I have large number of models?
>>
>> Thanks
>>
>>
>> On 12 November 2013 12:32, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>
>>> Hello,
>>>
>>> Use nested lapply(). Like this:
>>>
>>>
>>>
>>> m1 <- lapply(varlist0,function(v) {
>>>          lapply(outcomes, function(o){
>>>                  f <- sprintf("%s~ s(time,bs='cr',k=200)+s(temp,bs='cr')
>>> +
>>> Lag(%s,0:6)", o, v)
>>>
>>> gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>>>        })})
>>>
>>> m1 <- unlist(m1, recursive = FALSE)
>>> m1
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> Em 12-11-2013 09:53, Kuma Raj escreveu:
>>>>
>>>>
>>>> I have asked this question on SO, but it attracted no response, thus I
>>>> am
>>>> cross- posting it here with the hope that someone would help.
>>>>
>>>> I want to estimate the effect of  pm10 and o3 on three outcome(death,
>>>> cvd
>>>> and resp). What I want to do is run one model for each of the main
>>>> predictors  (pm10 and o3) and each outcome(death, cvd and resp). Thus I
>>>> expect to obtain 6 models. The script below works for one outcome
>>>> (death)
>>>> and I wish to use it for more dependent variables.
>>>>
>>>>
>>>>
>>>> library(quantmod)
>>>> library(mgcv)
>>>> library(dlnm)
>>>> df <- chicagoNMMAPS
>>>> outcomes<- c("death", "cvd", "resp ")
>>>> varlist0 <- c("pm10", "o3")
>>>>
>>>>       m1 <- lapply(varlist0,function(v) {
>>>>           f <- sprintf("death~ s(time,bs='cr',k=200)+s(temp,bs='cr') +
>>>> Lag(%s,0:6)",v)
>>>>
>>>> gam(as.formula(f),family=quasipoisson,na.action=na.omit,data=df)
>>>>         })
>>>>
>>>> Thanks
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>


From bbolker at gmail.com  Tue Nov 12 16:34:34 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Nov 2013 15:34:34 +0000
Subject: [R] Getting residual term out of lmer summary table
References: <OF1141438F.C08FED98-ONC1257C21.001B9A7E-C1257C21.001B9A85@wsl.ch>
Message-ID: <loom.20131112T163036-424@post.gmane.org>

 <aline.frank <at> wsl.ch> writes:

> 
> Hello
 
> I'm working with mixed effects models using lmer() and have some
> problems to get all variance components of the model's random
> effects. I can get the variance of the random effect out of the
> summary and use it for further calculations, but not the variance
> component of the residual term. Could somebody help me with that
> problem? Thanks a lot! Below an example.

  There's an r-sig-mixed-models at r-project.org mailing list that
is specifically for mixed-models (especially lme4) questions.
 
> Aline
 
> ## EXAMPLE
> #----------
> 
require(lme4)

## Simulate data for the example
set.seed(6)
x1 <- runif(n=100, min=10, max=100) ## a continuos variable
x2 <- runif(n=100, min=10, max=100) ## a continuos variable

treat <- rep(letters[1:4], times=25) ## a fixed factor with 4 levels
treat.effect <- 20*rep(1:4, times=25) 

group.label <- rep(LETTERS[1:5], each=20)  ## the random effect
group.effect <- 10*rep(1:5, each=20)       ## there are 5 groups

## Response variable:
y <- 2*x1 + (-5)*x2 + treat.effect + group.effect + rnorm(100)

## Dataframe
d.ex <- data.frame(y, x1, x2, "Group"=group.label, treat)

## Apply model
mod1 <- lmer(y~x1+x2+treat+x1:treat+ (1|Group), data=d.ex)
output <- summary(mod1); output
## # ok, there is the variance component of the random effect group and the
residual term
> 
## Now I'd like to get the variance components of the random effect "Group"
and of the residual term
"Residual" in order 
## to do further calculations with these numbers
output$varcor[1] ## reveals the variance of the random effect "Group"
output$varcor[2] ## does not reveal the residual term! what other command do
I need to use then?

VarCorr(mod1)  ## prints standard dev by default in latest lme4
## print both var and std dev
print(VarCorr(mod1),comp=c("Variance","Std.Dev."))
unlist(VarCorr(mod1))  ## group variance (as raw number)
sigma(mod1)   ## std. dev. of residual variance


From cs_2002 at hotmail.com  Tue Nov 12 16:47:59 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Tue, 12 Nov 2013 18:47:59 +0300
Subject: [R] Double Pareto Log Normal Distribution
Message-ID: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/bf430831/attachment.pl>

From pdalgd at gmail.com  Tue Nov 12 17:26:32 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Nov 2013 17:26:32 +0100
Subject: [R] Double Pareto Log Normal Distribution
In-Reply-To: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
Message-ID: <F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>

There's a recipe involving two exponentials and a normal deviate as formula (6) in (1st hit on Google for "dpln distribution").

http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf

It should be a no-brainer to code it up in R.

-pd


On 12 Nov 2013, at 16:47 , b. alzahrani <cs_2002 at hotmail.com> wrote:

> Hi guys
> I would like to generate random number Double Pareto Log Normal Distribution (DPLN). does anyone know how to do this in R or if there is any built-in function.
> 
> Thanks
> 
> ******************************************************************
> Bander 
> *************************************
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From COLLINL at pitt.edu  Tue Nov 12 17:33:21 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Tue, 12 Nov 2013 11:33:21 -0500
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
Message-ID: <eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>

Greetings, I'm working on a project where I want to hand-tailor an lm. 
Specifically I want to construct an lm with an existing formula and then
hand tailor the coefficients myself.  Is there an established method for
that other than manipulating the $coefficients values?

     Thank you,
    Collin.


From gunter.berton at gene.com  Tue Nov 12 17:44:46 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Nov 2013 08:44:46 -0800
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
	<eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
Message-ID: <CACk-te1-cTF5koC2gzbNPNNQvZ0x9JcYyMANtT5ts34_Ao5-gg@mail.gmail.com>

Think you're going to have to explicitly define "hand tailor." I
haven't a clue what you mean. (Someone else might of course).

-- Bert

On Tue, Nov 12, 2013 at 8:33 AM,  <COLLINL at pitt.edu> wrote:
> Greetings, I'm working on a project where I want to hand-tailor an lm.
> Specifically I want to construct an lm with an existing formula and then
> hand tailor the coefficients myself.  Is there an established method for
> that other than manipulating the $coefficients values?
>
>      Thank you,
>     Collin.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From COLLINL at pitt.edu  Tue Nov 12 17:59:16 2013
From: COLLINL at pitt.edu (COLLINL at pitt.edu)
Date: Tue, 12 Nov 2013 11:59:16 -0500
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <CACk-te1-cTF5koC2gzbNPNNQvZ0x9JcYyMANtT5ts34_Ao5-gg@mail.gmail.com>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
	<eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
	<CACk-te1-cTF5koC2gzbNPNNQvZ0x9JcYyMANtT5ts34_Ao5-gg@mail.gmail.com>
Message-ID: <bc9d78117aafbe105f4413d73552a2a7.squirrel@webmail.pitt.edu>

> Think you're going to have to explicitly define "hand tailor." I
> haven't a clue what you mean. (Someone else might of course).

Ah, I want to set a specific coefficient value for each of the terms
rather than rely on training.  Thus given:

   y ~ x0 + x1 + x2 + a

I would like to set:

    a = 10
    b0 = 20
    b2 = 90,
    etc.

I'm trying out my own training model and I would like to use the machinery
of the lm for evaluation and reporting but I would like to fix the beta
coefficients and other trained values independently of least-squares
regression.

    Collin.


From jvadams at usgs.gov  Tue Nov 12 18:13:31 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 12 Nov 2013 11:13:31 -0600
Subject: [R] Having a relative x-axis in a plot
In-Reply-To: <CAF-JZQupPPoyGfd-1k0ztn7bHmFTxdXUjtMGHub9D3TYLh=2uQ@mail.gmail.com>
References: <CAF-JZQupPPoyGfd-1k0ztn7bHmFTxdXUjtMGHub9D3TYLh=2uQ@mail.gmail.com>
Message-ID: <CAN5YmCHyMx85oqk5E1B=9zYngu9EezTvJF80iAH0v2ABSL+6rQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/b0d4f6bb/attachment.pl>

From ishaqbaba at yahoo.com  Tue Nov 12 18:14:57 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Tue, 12 Nov 2013 09:14:57 -0800 (PST)
Subject: [R] robust MM
Message-ID: <1384276497.81391.YahooMailNeo@web142506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/8a000b17/attachment.pl>

From HDoran at air.org  Tue Nov 12 18:20:36 2013
From: HDoran at air.org (Doran, Harold)
Date: Tue, 12 Nov 2013 17:20:36 +0000
Subject: [R] cbind2() in Matrix
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD686725832F5@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/1ddbe344/attachment.pl>

From davismcc at gmail.com  Tue Nov 12 16:31:58 2013
From: davismcc at gmail.com (DavisMcCrthy)
Date: Tue, 12 Nov 2013 07:31:58 -0800 (PST)
Subject: [R] Error: X11 fatal IO error: please save work and shut down R
 when ssh connection broken
In-Reply-To: <ED07A7DD-33CD-4770-82B0-06BE97CD7C69@channing.harvard.edu>
References: <ED07A7DD-33CD-4770-82B0-06BE97CD7C69@channing.harvard.edu>
Message-ID: <a0e5fb27-70a9-4793-8a7c-7c2590e15dca@googlegroups.com>

I also see this behaviour and would also love to hear about a work-around 
for it. 

Best
Davis


On Wednesday, April 18, 2012 8:35:06 PM UTC+1, regcl wrote:
>
> I ues R on a Linux server running under Screen or Emacs server from a Mac 
> desktop.
>
> I use Screen and/or Emacs server so that I can reattach to long running 
> sessions, and this works well except...
>
> If X11 server on my desktop is shut down, or my ssh connection is broken, 
> I get this error on the next plot() call:
>
> Error: X11 fatal IO error: please save work and shut down R
>
> Is there a work around for this?
>
> Thanks,
> regcl
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From dilaradi21 at gmail.com  Tue Nov 12 09:20:56 2013
From: dilaradi21 at gmail.com (dila radi)
Date: Tue, 12 Nov 2013 00:20:56 -0800
Subject: [R] How to replace NA's data with some value
Message-ID: <CAMgoKBLtT154cgNgWcoTBQQm2m0tDjY6y-xp1y0mNBup5XEY8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/d1fc2973/attachment.pl>

From dominic.roye at gmail.com  Tue Nov 12 14:01:28 2013
From: dominic.roye at gmail.com (Dominic Roye)
Date: Tue, 12 Nov 2013 14:01:28 +0100
Subject: [R] Kriging
Message-ID: <CALvVS-FAw2M8R3Ry4zccw3jfeMXXvVxSynKyLdK-Mcw+mB8qYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/55359350/attachment.pl>

From drf at vims.edu  Tue Nov 12 17:51:22 2013
From: drf at vims.edu (David R Forrest)
Date: Tue, 12 Nov 2013 16:51:22 +0000
Subject: [R] Double Pareto Log Normal Distribution
In-Reply-To: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
Message-ID: <FE020833-70FD-459B-A606-94FC66668C64@vims.edu>


http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf is the original ref and has the equations.

library(VGAM) for *pareto() and library(stats) for *lnorm() should get you most of the way there.

On Nov 12, 2013, at 10:47 AM, "b. alzahrani" <cs_2002 at hotmail.com>
 wrote:

> Hi guys
> I would like to generate random number Double Pareto Log Normal Distribution (DPLN). does anyone know how to do this in R or if there is any built-in function.
> 
> Thanks
> 
> ******************************************************************
> Bander 
> *************************************
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Dr. David Forrest
drf at vims.edu





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/7f70e6e7/attachment.bin>

From michael.weylandt at gmail.com  Tue Nov 12 18:44:41 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Tue, 12 Nov 2013 12:44:41 -0500
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <bc9d78117aafbe105f4413d73552a2a7.squirrel@webmail.pitt.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
	<eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
	<CACk-te1-cTF5koC2gzbNPNNQvZ0x9JcYyMANtT5ts34_Ao5-gg@mail.gmail.com>
	<bc9d78117aafbe105f4413d73552a2a7.squirrel@webmail.pitt.edu>
Message-ID: <F056C722-BD66-477D-8BBF-26951E1276FA@gmail.com>



On Nov 12, 2013, at 11:59, <COLLINL at pitt.edu> wrote:

>> Think you're going to have to explicitly define "hand tailor." I
>> haven't a clue what you mean. (Someone else might of course).
> 
> Ah, I want to set a specific coefficient value for each of the terms
> rather than rely on training.  Thus given:
> 
>   y ~ x0 + x1 + x2 + a
> 
> I would like to set:
> 
>    a = 10
>    b0 = 20
>    b2 = 90,
>    etc.
> 
> I'm trying out my own training model and I would like to use the machinery
> of the lm for evaluation and reporting but I would like to fix the beta
> coefficients and other trained values independently of least-squares
> regression.
> 

I'm quite confused: if you set all the coefficients in advance, in what sense are you doing a linear regression? 

Even if this is possible, won't all the other estimates (i.e., standard error of betas) produced be junk since they aren't derived from the associated estimators?

Michael

>    Collin.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Nov 12 18:50:15 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 12 Nov 2013 10:50:15 -0700
Subject: [R] Handle Gps coordinates
In-Reply-To: <1384266884.5102.YahooMailNeo@web125305.mail.ne1.yahoo.com>
References: <1384266884.5102.YahooMailNeo@web125305.mail.ne1.yahoo.com>
Message-ID: <CAFEqCdxFDC1jqT4_ZCGWk9uOEcUe4Ly0EjmE75U+OLnPWhctiw@mail.gmail.com>

I don't know of any packages specifically for gps coordinates, but
more generally there are packages for spatial statistics (of which the
gps coordinates would be a special case).

Check the CRAN Taskviews Spatial and SpatialTemporal for descriptions
of packages that will do what you ask (and a lot more).

On Tue, Nov 12, 2013 at 7:34 AM, Alaios <alaios at yahoo.com> wrote:
> Dear all,
> I would like to ask you if there are any gps libraries.
>
>
> I would like to be able to handle them,
> -like calculate distances in meters between gps locations,
> -or find which gps location is closer to a list of gps locations.
>
> Is there something like that in R?
>
> I would like to tthank you in advance for your reply
>
> Regards
> Alex
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 at gmail.com  Tue Nov 12 18:54:25 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 12 Nov 2013 10:54:25 -0700
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<F5C4FF03-8BFE-4487-8F80-4F95B5CB440D@gmail.com>
	<eb1838c01b3d23fdc8eea7893e773dcb.squirrel@webmail.pitt.edu>
Message-ID: <CAFEqCdwfmbW2RnrLrGVTfLPKEZXyQ7aeqED9btt=wne7WmPG2w@mail.gmail.com>

You can use the "offset" function as part of a formula in "lm" (and
other model fitting functions) to set a specific slope or set of
slopes.  Using this up front will give you the correct residuals,
standard errors, etc.  This is better than trying to modify a fitted
regression object.

On Tue, Nov 12, 2013 at 9:33 AM,  <COLLINL at pitt.edu> wrote:
> Greetings, I'm working on a project where I want to hand-tailor an lm.
> Specifically I want to construct an lm with an existing formula and then
> hand tailor the coefficients myself.  Is there an established method for
> that other than manipulating the $coefficients values?
>
>      Thank you,
>     Collin.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From collinl at cs.pitt.edu  Tue Nov 12 19:15:40 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Tue, 12 Nov 2013 13:15:40 -0500 (EST)
Subject: [R] How to replace NA's data with some value
In-Reply-To: <CAMgoKBLtT154cgNgWcoTBQQm2m0tDjY6y-xp1y0mNBup5XEY8g@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1311121315160.20392-100000@rhenium.cs.pitt.edu>

Dila, take a look at this:

http://r.789695.n4.nabble.com/How-to-replace-all-lt-NA-gt-values-in-a-data-frame-with-another-not-0-value-td2125458.html

	Does that help?
	Best,
	Collin.

On Tue, 12 Nov 2013, dila radi wrote:

> Hi all,
>
> I have a data set with missing value. I would like to estimate those
> missing value by using normal ratio method.
> Below is part of my data:
>
>       AS   BL Serdang  Jhr   Phg  Target station
>        0    0.0    12.8      0.0  23.7  0.0
>        6    0.0    81.7      0.2  0.0   NA
>        0    1.5    60.9      0.0  0.0   15.5
>        1   13.0    56.8     17.5 32.8  6.4
>        4     3.0    66.4      2.0  0.3   NA
>
> Now I want to replace those NA's,  with the estimation values by using this
> formula:
> weight$v6
> <-(weight1*AS)+(weight2*BL)+(weight3*Serdang)+(weight4*Jhr)+(weight5*Phg);
> Targetstation
>
> but I still could not replace the NA's. My problem is, how do I replace
> those NA's with another value?
>
> Thank you so much for your help and attention.
>
> Regards,
> Dila
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From collinl at cs.pitt.edu  Tue Nov 12 19:18:02 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Tue, 12 Nov 2013 13:18:02 -0500
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <F056C722-BD66-477D-8BBF-26951E1276FA@gmail.com>
Message-ID: <Pine.LNX.4.44.1311121316540.20392-100000@rhenium.cs.pitt.edu>

> Even if this is possible, won't all the other estimates (i.e., standard error of betas) produced be junk since they aren't derived from the associated estimators?

That was actually my primary concern.  It looks like the offset is the
solution.

	Thanks.
	Collin.
>
> Michael
>
> >    Collin.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From collinl at cs.pitt.edu  Tue Nov 12 19:23:14 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Tue, 12 Nov 2013 13:23:14 -0500
Subject: [R] Manually setting coefficients in an lm.
In-Reply-To: <CAFEqCdwfmbW2RnrLrGVTfLPKEZXyQ7aeqED9btt=wne7WmPG2w@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1311121318110.20392-100000@rhenium.cs.pitt.edu>

> You can use the "offset" function as part of a formula in "lm" (and
> other model fitting functions) to set a specific slope or set of
> slopes.  Using this up front will give you the correct residuals,
> standard errors, etc.  This is better than trying to modify a fitted
> regression object.

Great, I'll try that out.  Thanks.

	Collin.

>
> On Tue, Nov 12, 2013 at 9:33 AM,  <COLLINL at pitt.edu> wrote:
> > Greetings, I'm working on a project where I want to hand-tailor an lm.
> > Specifically I want to construct an lm with an existing formula and then
> > hand tailor the coefficients myself.  Is there an established method for
> > that other than manipulating the $coefficients values?
> >
> >      Thank you,
> >     Collin.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>


From ruipbarradas at sapo.pt  Tue Nov 12 19:52:31 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 12 Nov 2013 18:52:31 +0000
Subject: [R] cbind2() in Matrix
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD686725832F5@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686725832F5@DC1VEX10MB001.air.org>
Message-ID: <528278EF.6000407@sapo.pt>

Hello,

Maybe using ?Reduce:


Zlist <- c(mat1, mat2, mat3)
Z <- Reduce(cbind2, Zlist)

Ztmp <- cbind2(mat1, mat2)
Z2 <- cbind2(Ztmp, mat3)

identical(Z, Z2)  # TRUE


Also, I prefer list(mat1, mat2, mat3), not c().

Hope this helps,

Rui Barradas

Em 12-11-2013 17:20, Doran, Harold escreveu:
> Suppose I have three matrices, such as the following:
>
> mat1 <- Matrix(rnorm(9), 3)
> mat2 <- Matrix(rnorm(9), 3)
> mat3 <- Matrix(rnorm(9), 3)
>
> I now need to column bind these and I could do the following if there were only two of those matrices because cbind2() has an x and y argument
>
> Zlist <- c(mat1, mat2)
> Z <- do.call(cbind2, Zlist)
>
> The following would not work as noted in the help page for cbind2() and I don't think I want to activate cbind() here.
>
> Zlist <- c(mat1, mat2, mat3)
> Z <- do.call(cbind2, Zlist)
>
> So, the object I would want in the end would be
> Ztmp <- cbind2(mat1, mat2)
> Z <- cbind2(Ztmp, mat3)
>
> I never have a large number of these things to combine, so I have solved the problem with a simple loop over the list.
>
> I'm curious though if there is a better (and perhaps) more reliable way to do this?
>
> Thanks,
> Harold
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From umairdurrani at outlook.com  Tue Nov 12 18:45:51 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Tue, 12 Nov 2013 22:45:51 +0500
Subject: [R] How to sum a function over a specific range in R?
Message-ID: <BLU170-W30E13D8AEFB69C46F3D6A9C9FE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/281a09e4/attachment.pl>

From jared.f.duquette at gmail.com  Tue Nov 12 18:43:12 2013
From: jared.f.duquette at gmail.com (Jared Duquette)
Date: Tue, 12 Nov 2013 11:43:12 -0600
Subject: [R] Change x-axis intervals and labels on cox.zph plot
Message-ID: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/77e8f75c/attachment.pl>

From livingstone.sam at gmail.com  Tue Nov 12 18:36:49 2013
From: livingstone.sam at gmail.com (Sam Livingstone)
Date: Tue, 12 Nov 2013 17:36:49 +0000
Subject: [R] Vol calculations
Message-ID: <CAOcy1qkiNW++oxaA+nyxhc25qPayT39rUWmTBrP_fNdzsLeZuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/9bd584fd/attachment.pl>

From smartpink111 at yahoo.com  Tue Nov 12 18:51:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 09:51:32 -0800 (PST)
Subject: [R] cbind2() in Matrix
Message-ID: <1384278692.80880.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:

Reduce(function(...) cbind2(...),Zlist)

A.K.


Suppose I have three matrices, such as the following: 

mat1 <- Matrix(rnorm(9), 3) 
mat2 <- Matrix(rnorm(9), 3) 
mat3 <- Matrix(rnorm(9), 3) 

I now need to column bind these and I could do the following if 
there were only two of those matrices because cbind2() has an x and y 
argument 

Zlist <- c(mat1, mat2) 
Z <- do.call(cbind2, Zlist) 

The following would not work as noted in the help page for cbind2() and I don't think I want to activate cbind() here. 

Zlist <- c(mat1, mat2, mat3) 
Z <- do.call(cbind2, Zlist) 

So, the object I would want in the end would be 
Ztmp <- cbind2(mat1, mat2) 
Z <- cbind2(Ztmp, mat3) 

I never have a large number of these things to combine, so I have solved the problem with a simple loop over the list. 

I'm curious though if there is a better (and perhaps) more reliable way to do this? 

Thanks, 
Harold


From smartpink111 at yahoo.com  Tue Nov 12 21:02:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 12:02:00 -0800 (PST)
Subject: [R] using scan function
Message-ID: <1384286520.77902.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You may try:
op <- options(digits=12)
r1 <- 4; c1 <- 4
?A <- matrix(scan("file1.txt",n=r1*c1),r1,c1,byrow=TRUE)

options(op) #reset

A.K.





Dear all, 
I?m using 'scan' function to import data into a matrix from a .txt 
file. The data are numbers with 12 significant digits (e.g. 
471773.309872). ? 
When I give the command: 

A <- matrix(scan(file_name, n=r*c), r, c, byrow=TRUE) 

numbers are stored in the matrix with only 7 significant digits 
(e.g. 471773.3). How can I increase the number of significant digits? 

Thank you for your reply. 
Eleonora


From smartpink111 at yahoo.com  Tue Nov 12 21:22:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 12:22:16 -0800 (PST)
Subject: [R] using scan function
In-Reply-To: <1384286520.77902.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1384286520.77902.YahooMailNeo@web142603.mail.bf1.yahoo.com> 
Message-ID: <1384287736.40920.YahooMailNeo@web142606.mail.bf1.yahoo.com>




Hi,
You may try:
op <- options(digits=12)
r1 <- 4; c1 <- 4
?A <- matrix(scan("file1.txt",n=r1*c1),r1,c1,byrow=TRUE)

options(op) #reset

A.K.





Dear all, 
I?m using 'scan' function to import data into a matrix from a .txt 
file. The data are numbers with 12 significant digits (e.g. 
471773.309872). ? 
When I give the command: 

A <- matrix(scan(file_name, n=r*c), r, c, byrow=TRUE) 

numbers are stored in the matrix with only 7 significant digits 
(e.g. 471773.3). How can I increase the number of significant digits? 

Thank you for your reply. 
Eleonora


From anindya55 at gmail.com  Tue Nov 12 21:53:23 2013
From: anindya55 at gmail.com (Anindya Sankar Dey)
Date: Tue, 12 Nov 2013 14:53:23 -0600
Subject: [R] Data transformation to list for event occurence
Message-ID: <CAKC+_z84GCiQjb7GgyoyQnAqGZ8GiPrAh3do7yrw9CRs3Hbn0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/f89e3711/attachment.pl>

From kripa777 at hotmail.com  Tue Nov 12 22:07:39 2013
From: kripa777 at hotmail.com (Kripa R)
Date: Tue, 12 Nov 2013 21:07:39 +0000
Subject: [R] GLMNET warning msg
Message-ID: <BAY179-W31C1BD2C3A5678E6C91D5B99FE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/8623fcb0/attachment.pl>

From f.harrell at Vanderbilt.Edu  Tue Nov 12 22:30:58 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Tue, 12 Nov 2013 15:30:58 -0600
Subject: [R] A problem about nomogram
Message-ID: <52829E12.2040100@vanderbilt.edu>

You did not follow the posting guide, did you use pure ascii email, and 
used illegal characters in your source code.  This caused extra work. 
Once I cleaned up your characters and made the example self-contained, 
the labels worked fine for me.  Here's the cleaned-up code:

library(rms)
x1 <- runif(20)
x2 <- runif(20)
y <- sample(0:1, 20, TRUE)
label(x1) <- 'A'
label(x2) <- 'B'

ddist <- datadist(x1,x2)
options(datadist='ddist')
f <- lrm(y~x1+x2)
x<-nomogram(f, fun=function(x)1/(1+exp(-x)), 
fun.at=c(.001,.01,.05,seq(0,1,by=.1),.95,.99,.999),vnames="labels")

plot(x)

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From kw.stat at gmail.com  Tue Nov 12 22:45:42 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Tue, 12 Nov 2013 15:45:42 -0600
Subject: [R] What graphics device settings are used by Rcmd check ?
Message-ID: <CAKFxdiSCX51e3XpYTsmHefVm8RnoPQPQsnnRYf9Kz_ev+H6=OQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/1d992682/attachment.pl>

From gunter.berton at gene.com  Tue Nov 12 23:29:54 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Nov 2013 14:29:54 -0800
Subject: [R] GLMNET warning msg
In-Reply-To: <BAY179-W31C1BD2C3A5678E6C91D5B99FE0@phx.gbl>
References: <BAY179-W31C1BD2C3A5678E6C91D5B99FE0@phx.gbl>
Message-ID: <CACk-te3TOOBwDK49ONdNfW86aMk=3TixoYyinPBvc+Ce3Yyv_A@mail.gmail.com>

It means that 10/10 = 1 < 3.

It also means that what you're trying to do (fitting 10 cases to 12000
variables) is ridiculous (assuming I understand your message
correctly).


Cheers,
Bert


On Tue, Nov 12, 2013 at 1:07 PM, Kripa R <kripa777 at hotmail.com> wrote:
> Hi I'm getting the following warning msg after ?cv.glmnet and I'm wondering what it means...
>
> dim(x) 10   12000;
> dim(y) 10; #two groups case=1 and control=0
> cv.glmnet(x, y)
>
> Warning message:
> Option grouped=FALSE enforced in cv.glmnet, since < 3 observations per fold
>
>
> Thanks,
>
>
>
> .kripa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Wed Nov 13 02:44:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 Nov 2013 17:44:43 -0800
Subject: [R] Change x-axis intervals and labels on cox.zph plot
In-Reply-To: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
Message-ID: <5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>


On Nov 12, 2013, at 9:43 AM, Jared Duquette wrote:

> Hi all,
> The plot.cox.zph function automatically plots the x-axis, but I would like
> to change the intervals and labels of my cox.zph plots to 0, 50,100,150,
> 200. However, I cannot get the function to do so. I tried using the
> "axis(..." function, but that did not override the existing plot labels.
> Below is my code and attached example plots which I am trying to modify.
> Thank you in advance for your consideration and assistance.
> #plot.cox.zph code
> iw.zph=cox.zph(idealweather);
> par(mfrow=c(2,1),ann=F,mar=c(3.2,3.5,1.2,0.5),mgp=c(1.7, 0.6,
> 0),cex.axis=1.1,cex.lab=1.2,cex=0.9,pch=16,family="serif",col.axis=1);
> plot.cox.zph(iw.zph);
> title(ylab="scaled Schoenfeld",xlab="Time (days)");

survival:::plot.cox.zph is not a particularly large or complicated function. Why not make a copy and modify it? There are only 3 possible plot() calls to modify.
-- 

David Winsemius
Alameda, CA, USA


From arrayprofile at yahoo.com  Wed Nov 13 03:10:20 2013
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 12 Nov 2013 18:10:20 -0800 (PST)
Subject: [R] power analysis is applicable or not
In-Reply-To: <5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
	<5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>
Message-ID: <1384308620.80700.YahooMailNeo@web122904.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/79a2d07f/attachment.pl>

From dwinsemius at comcast.net  Wed Nov 13 03:50:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 Nov 2013 18:50:20 -0800
Subject: [R] power analysis is applicable or not
In-Reply-To: <1384308620.80700.YahooMailNeo@web122904.mail.ne1.yahoo.com>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
	<5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>
	<1384308620.80700.YahooMailNeo@web122904.mail.ne1.yahoo.com>
Message-ID: <EC17064E-350C-465E-996F-C46A09372469@comcast.net>


On Nov 12, 2013, at 6:10 PM, array chip wrote:

> Hi, this is a statistical question rather than a pure R question. I have got many help from R mailing list in the past, so would like to try here and appreciate any input:
> 
> I conducted Mantel-Haenszel test to show that the performance of a diagnostic test did not show heterogeneity among 4 study sites, i.e. Mantel Haenszel test p value > 0.05,  so that I could conduct a meta-analysis by combining data of all 4 study sites. 
> 
> Now one of the reviewers for the manuscript did a powering analysis for Mantel Haneszel test showing that with the sample sizes I have, the power for Mantel Haeszel test was only 50%. So he argued that I did not have enough power for Mantel Haenszel test.
> 
> My usage of Mantel Haenszel was NOT to show a significant p value, instead a non-sginificant p value was what I was looking for because non-significant p value indicate NO heterogeneity among study sites. Powering analysis in general is to show whether you have enough sample size to ensure a statistical significant difference can be seen with certain likelihood. But this is not how I used Mantel Haenszel test. So I think in my scenario, the power analysis is NOT applicable because I am simply using the test to demonstrate a non-significant p value.
> 
> Am I correct on this view?

I think not. If you need a p > 0.05 to argue for lumping categories together then you should have sufficient power for the test. Now since you havetoldus almost nothing about the science or the analysis, this is a very general opinion that could get modified if there were further specifics presented. In particular it is often the case that MH tests are done on ordered categories but the ordinary MH tests fail to account for that aspect.

-- 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Wed Nov 13 04:38:09 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 13 Nov 2013 14:38:09 +1100
Subject: [R] Change x-axis intervals and labels on cox.zph plot
In-Reply-To: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
Message-ID: <5282F421.3040903@bitwrit.com.au>

On 11/13/2013 04:43 AM, Jared Duquette wrote:
> Hi all,
> The plot.cox.zph function automatically plots the x-axis, but I would like
> to change the intervals and labels of my cox.zph plots to 0, 50,100,150,
> 200. However, I cannot get the function to do so. I tried using the
> "axis(..." function, but that did not override the existing plot labels.
> Below is my code and attached example plots which I am trying to modify.
> Thank you in advance for your consideration and assistance.
> #plot.cox.zph code
> iw.zph=cox.zph(idealweather);
> par(mfrow=c(2,1),ann=F,mar=c(3.2,3.5,1.2,0.5),mgp=c(1.7, 0.6,
> 0),cex.axis=1.1,cex.lab=1.2,cex=0.9,pch=16,family="serif",col.axis=1);
> plot.cox.zph(iw.zph);
> title(ylab="scaled Schoenfeld",xlab="Time (days)");
>
Hi Jared,
Try this:

plot.cox.zph(iw.zph,xaxt="n")
axis(...)

Untested.

Jim


From arrayprofile at yahoo.com  Wed Nov 13 04:42:37 2013
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 12 Nov 2013 19:42:37 -0800 (PST)
Subject: [R] power analysis is applicable or not
In-Reply-To: <5282E9B0.4060206@binghamton.edu>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
	<5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>
	<1384308620.80700.YahooMailNeo@web122904.mail.ne1.yahoo.com>
	<5282E9B0.4060206@binghamton.edu>
Message-ID: <1384314157.89884.YahooMailNeo@web122901.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/338d8566/attachment.pl>

From jlhoward.2015 at gmail.com  Tue Nov 12 22:18:45 2013
From: jlhoward.2015 at gmail.com (jlhoward.2015 at gmail.com)
Date: Tue, 12 Nov 2013 16:18:45 -0500
Subject: [R] geom_abline does not seem to respect groups in facet_grid
	[ggplot2]
Message-ID: <003701cedfec$ca352700$5e9f7500$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131112/78f4c93b/attachment.pl>

From smartpink111 at yahoo.com  Tue Nov 12 23:05:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 14:05:08 -0800 (PST)
Subject: [R] Apply a function to a list
Message-ID: <1384293908.42713.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

You may try:

(Please provide a reproducible example.)
lst1 <- list(list(list(c(14L, 13L, 5L, 4L, 9L), c(14L, 16L, 13L, 2L)), 
??? list(c(3L, 2L, 7L, 1L, 8L), c(1L, 9L, 4L, 8L, 7L, 3L, 5L, 
??? 2L), c(4L, 2L, 1L))), list(list(c(7L, 14L, 15L, 4L, 3L), 
??? c(10L, 12L, 6L, 1L)), list(c(5L, 8L, 10L, 3L, 4L), c(9L, 
4L, 2L, 8L, 5L, 7L, 3L, 1L), c(1L, 4L, 3L))))

lapply(lst1,function(x) lapply(x,function(y) lapply(y,function(z) sum(z))))


A.K.

I have a list that has a header with the following information. 
List of 6 
?$ :List of 3 
? ..$ :List of 48 

The structure of the list from the 1st to 4th looks like this. 
[[1]] 
[[1]][[1]] 

[[2]] 
[[2]][[2]] 

[[3]] 
[[3]][[3]] 

[[4]] 
[[4]][[4]] 

I want to apply a function to the entire list but am unable to do it. How can one apply such a function to the list?


From smartpink111 at yahoo.com  Tue Nov 12 23:13:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 14:13:08 -0800 (PST)
Subject: [R] Data transformation to list for event occurence
In-Reply-To: <CAKC+_z84GCiQjb7GgyoyQnAqGZ8GiPrAh3do7yrw9CRs3Hbn0A@mail.gmail.com>
References: <CAKC+_z84GCiQjb7GgyoyQnAqGZ8GiPrAh3do7yrw9CRs3Hbn0A@mail.gmail.com>
Message-ID: <1384294388.63306.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi Anindya,

You may try:
dat1 <- read.table(text="ID?? Week??? Event_Occurence
A 1 0
A 2 0
A 3 1
A 4 0
B 1 1
B 2 0
B 3 0
B 4 1",sep="",header=TRUE,stringsAsFactors=FALSE)

?with(dat1,tapply(as.logical(Event_Occurence),ID,FUN=which ))
#or
lapply(split(dat1,dat1$ID),function(x) which(!!x[,3]))
A.K.





On Tuesday, November 12, 2013 4:58 PM, Anindya Sankar Dey <anindya55 at gmail.com> wrote:
Hi,

Say I have a following data

ID?  Week? ? Event_Occurence
A 1 0
A 2 0
A 3 1
A 4 0
B 1 1
B 2 0
B 3 0
B 4 1

that whether an individual experienced an event in a particular week.

I wish to create list such as the first element of the list will be a
vector listing the week number when the event has occurred for A, followed
by that of B.

Can you help creating this?

-- 
Anindya Sankar Dey

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Nov 13 00:06:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Nov 2013 15:06:05 -0800 (PST)
Subject: [R] Apply a function to a list
In-Reply-To: <1384293908.42713.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1384293908.42713.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1384297565.39182.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You may also flatten the list of lists and apply the function. In the example I provided,
lapply(do.call(c,unlist(lst1,recursive=FALSE)),sum) 


#or
use one of the functions from this link
http://stackoverflow.com/questions/8139677/how-to-flatten-a-list-to-a-list-without-coercion

lapply(flatten2(lst1),sum)
A.K.





On Tuesday, November 12, 2013 5:05 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,

You may try:

(Please provide a reproducible example.)
lst1 <- list(list(list(c(14L, 13L, 5L, 4L, 9L), c(14L, 16L, 13L, 2L)), 
??? list(c(3L, 2L, 7L, 1L, 8L), c(1L, 9L, 4L, 8L, 7L, 3L, 5L, 
??? 2L), c(4L, 2L, 1L))), list(list(c(7L, 14L, 15L, 4L, 3L), 
??? c(10L, 12L, 6L, 1L)), list(c(5L, 8L, 10L, 3L, 4L), c(9L, 
4L, 2L, 8L, 5L, 7L, 3L, 1L), c(1L, 4L, 3L))))

lapply(lst1,function(x) lapply(x,function(y) lapply(y,function(z) sum(z))))


A.K.

I have a list that has a header with the following information. 
List of 6 
?$ :List of 3 
? ..$ :List of 48 

The structure of the list from the 1st to 4th looks like this. 
[[1]] 
[[1]][[1]] 

[[2]] 
[[2]][[2]] 

[[3]] 
[[3]][[3]] 

[[4]] 
[[4]][[4]] 

I want to apply a function to the entire list but am unable to do it. How can one apply such a function to the list?


From babuawara at gmail.com  Wed Nov 13 04:22:29 2013
From: babuawara at gmail.com (vikram ranga)
Date: Wed, 13 Nov 2013 08:52:29 +0530
Subject: [R] Handle Gps coordinates
In-Reply-To: <CAFEqCdxFDC1jqT4_ZCGWk9uOEcUe4Ly0EjmE75U+OLnPWhctiw@mail.gmail.com>
References: <1384266884.5102.YahooMailNeo@web125305.mail.ne1.yahoo.com>
	<CAFEqCdxFDC1jqT4_ZCGWk9uOEcUe4Ly0EjmE75U+OLnPWhctiw@mail.gmail.com>
Message-ID: <CAL-ALVHPLT5uJmJhH8VqiTcH0zBmhYhpTAOCPCH_iif8pkfwsw@mail.gmail.com>

Hi,

You would like to have a look at library(maptools) & library(rgeos)
they have amazingly lot of function for such analysis.
You can also read GPS data directly in R using maptools.

This question is more suitable for r-sig-geo list.


On Tue, Nov 12, 2013 at 11:20 PM, Greg Snow <538280 at gmail.com> wrote:
> I don't know of any packages specifically for gps coordinates, but
> more generally there are packages for spatial statistics (of which the
> gps coordinates would be a special case).
>
> Check the CRAN Taskviews Spatial and SpatialTemporal for descriptions
> of packages that will do what you ask (and a lot more).
>
> On Tue, Nov 12, 2013 at 7:34 AM, Alaios <alaios at yahoo.com> wrote:
>> Dear all,
>> I would like to ask you if there are any gps libraries.
>>
>>
>> I would like to be able to handle them,
>> -like calculate distances in meters between gps locations,
>> -or find which gps location is closer to a list of gps locations.
>>
>> Is there something like that in R?
>>
>> I would like to tthank you in advance for your reply
>>
>> Regards
>> Alex
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k.moon at student.unimelb.edu.au  Wed Nov 13 06:44:56 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Tue, 12 Nov 2013 21:44:56 -0800 (PST)
Subject: [R] Plotting multiple weibull distributions in one graph
Message-ID: <1384321496424-4680355.post@n4.nabble.com>

Hello,

I am trying to plot multiple weibull distributions in one graph.
Does anyone know how to produce?
I already have different parameters for weibull distributions (shape and
scale)

Here are examples.

	Shape	Scale
2011	2.455	21.657
2010	2.328	21.486
2009	2.336	22.642
2008	2.404	22.193
2007	2.447	23.378
2006	2.385	22.194
2005	2.382	22.153
2004	2.53	22.081
2003	2.451	23.408
2002	2.482	23.135
2001	2.44	22.204
2000	2.449	22.011

Regards, 

Kangmin.



--
View this message in context: http://r.789695.n4.nabble.com/Plotting-multiple-weibull-distributions-in-one-graph-tp4680355.html
Sent from the R help mailing list archive at Nabble.com.


From ripley at stats.ox.ac.uk  Wed Nov 13 07:25:44 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Nov 2013 06:25:44 +0000
Subject: [R] What graphics device settings are used by Rcmd check ?
In-Reply-To: <CAKFxdiSCX51e3XpYTsmHefVm8RnoPQPQsnnRYf9Kz_ev+H6=OQ@mail.gmail.com>
References: <CAKFxdiSCX51e3XpYTsmHefVm8RnoPQPQsnnRYf9Kz_ev+H6=OQ@mail.gmail.com>
Message-ID: <52831B68.9060307@stats.ox.ac.uk>

On 12/11/2013 21:45, Kevin Wright wrote:
> I'm on Windows 7.
>
> When I do Rcmd check pkg, I get this error from a .Rd file:
> Error in plot.new() : plot region too large
>
> Using the windows() and pdf() devices in interactive mode, the code in the
> .Rd file works just fine.
>
> I'm wondering if the graphics device settings are the culprit and am trying
> to find the settings used by Rcmd check.

No settings are used.  So the default device on your system for 
non-interactive session is used.
>
> Where do I look for these?
>
'check' is R code in the tools package.

This really was an R-devel question: see the posting guide.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Wed Nov 13 07:46:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 Nov 2013 22:46:09 -0800
Subject: [R] power analysis is applicable or not
In-Reply-To: <1384314157.89884.YahooMailNeo@web122901.mail.ne1.yahoo.com>
References: <CAH18Qe2FmD2r0srvH1WzbKa9hvnmn1_CDw95BGF=k5VyZ78Lxw@mail.gmail.com>
	<5FA17042-BA26-444D-AC50-5C4544CAE9B6@comcast.net>
	<1384308620.80700.YahooMailNeo@web122904.mail.ne1.yahoo.com>
	<5282E9B0.4060206@binghamton.edu>
	<1384314157.89884.YahooMailNeo@web122901.mail.ne1.yahoo.com>
Message-ID: <C3B73C93-BEBE-4C04-AF4F-795D492BB1D6@comcast.net>


On Nov 12, 2013, at 7:42 PM, array chip wrote:

> Hi Chris,
> 
> Thanks for sharing your thoughts.
> 
> The reviewer used the heterogeneity that I observed in my study for the power analysis. I understand what you have descried. And I agree that with the sample size I have, I do not have enough power to detect the heterogeneity that I observed with significance.

You said that: "Now one of the reviewers for the manuscript did a powering analysis for Mantel Haneszel test showing that with the sample sizes I have, the power for Mantel Haeszel test was only 50%. So he argued that I did not have enough power for Mantel Haenszel test."

This is rather interesting in its own right. Generally if you find that the p-value is 0.05 then you are exactly at the point where the post-hoc power (the power calculated on the basis of the observed differences and variances)  will be 0.50. In other words if you are right at the tipping point then a small perturbation in the data will tip you either way. And yet you said the p value was > 0.05 (although you didn't say how much greater.)  So I would say your power was certainly less and possibly materially less than 0.50. (This is dodging the question of power to detect exactly "what?". So far we have neither a discssion of the underlying scientific question nor any specifics.)

> 
> But if let's say I have enough sample size as calculated by the power analysis, then I will have 80% power to detect the heterogeneity, would it be true that I will almost very unlikely to declare homogeneity among study sites, so that I would almost never be able to combine study sites?

(That was incoherent.)

> This goes to the general thinking that if you have a sample size large enough, you will always be able to make any difference statistically significant...
> 
> On the the hand, making a statistical inference using any statistical test (including Mantel Haenszel test), I though, is always valid regardless of sample size.

That is just wrong.

> For the heterogeneity test, I am just doing that -- making a statistical inference with the p value from Mantel Haenszel test.  I am not sure if it is correct that it is mandatory to perform a power analysis before attempting a statistical test.

The question is whether you are justified in ignoring (or leaving out of the analysis) covariates that you thought a priori had a good chance of confounding the relationship of the predictors of interest on the outcome of interest. It appears that you have insufficient such justication. (And some statsiticians of excelletn repute would say you never have justification to do so regardless of any testing.)

-- 
David.
> 
> Please share your thoughts...
> 
> Thanks
> 
> John
> From: Christopher W. Ryan <cryan at binghamton.edu>
> To: array chip <arrayprofile at yahoo.com> 
> Sent: Tuesday, November 12, 2013 6:53 PM
> Subject: Re: [R] power analysis is applicable or not
> 
> John--
> 
> Well, my simple-minded way of thinking about these issues goes something
> like this:
> 
> You want to know if there is heterogeneity. You gather some data and do
> your MH analysis. You never know *for sure* whether there is *really*
> heterogeneity in your population; all you know is whether there is any
> in your sample--you concluded there was not. Your reviewer calculated
> that with the sample size you used, *even if there was heterogeneity in
> your population* (unknowable by you or anyone else) then your sample
> size only had a 50% probability of detecting it (a 50% probability of
> coming up with a p < 0.05).  Meaning there *could have been*
> heterogeneity there, at a 0.05 signficance level, and you *would* have
> seen it, *if* your sample size was larger.
> 
> It's when you come up with a "non-significant result" that the issue of
> power is most relevant. If you already have a "significant" result, then
> yes, your sample size was large enough to show a significant result.
> 
> An important question is: what *magnitude* of heterogeneity did your
> reviewer assume he/she was looking for when he/she did the power
> calculation?  And is that magnitude meaningful?
> 
> All this being said, power calculations are best done before recruiting
> subjects or gathering data.
> 
> --Chris Ryan
> SUNY Upstate Medical University
> Binghamton, NY
> 
> array chip wrote:
> > Hi, this is a statistical question rather than a pure R question. I have got many help from R mailing list in the past, so would like to try here and appreciate any input:
> > 
> > I conducted Mantel-Haenszel test to show that the performance of a diagnostic test did not show heterogeneity among 4 study sites, i.e. Mantel Haenszel test p value > 0.05,  so that I could conduct a meta-analysis by combining data of all 4 study sites. 
> > 
> > Now one of the reviewers for the manuscript did a powering analysis for Mantel Haneszel test showing that with the sample sizes I have, the power for Mantel Haeszel test was only 50%. So he argued that I did not have enough power for Mantel Haenszel test.
> > 
> > My usage of Mantel Haenszel was NOT to show a significant p value, instead a non-sginificant p value was what I was looking for because non-significant p value indicate NO heterogeneity among study sites. Powering analysis in general is to show whether you have enough sample size to ensure a statistical significant difference can be seen with certain likelihood. But this is not how I used Mantel Haenszel test. So I think in my scenario, the power analysis is NOT applicable because I am simply using the test to demonstrate a non-significant p value.
> > 
> > Am I correct on this view?
> > 
> > Thanks and appreciate any thoughts.
> > 
> > John
> >     [[alternative HTML version deleted]]
> > 
> > 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> > 
> 
> 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Wed Nov 13 08:45:41 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 13 Nov 2013 20:45:41 +1300
Subject: [R] Plotting multiple weibull distributions in one graph
In-Reply-To: <1384321496424-4680355.post@n4.nabble.com>
References: <1384321496424-4680355.post@n4.nabble.com>
Message-ID: <52832E25.2030104@auckland.ac.nz>


Read the help for plot.function, and note the argument "add".
After plotting your first function, you'll want to set "add=TRUE".

Note that the plotting interval defaults to [0,1] which is toadally out
to luntch for the functions you are interested in.  You'll want to set
from=0 and to=100 or thereabouts.

You will probably want to plot each trace in a different colour;
plot.function() takes a "col" argument.

     cheers,

     Rolf Turner

On 11/13/13 18:44, kmmoon100 wrote:
> Hello,
>
> I am trying to plot multiple weibull distributions in one graph.
> Does anyone know how to produce?
> I already have different parameters for weibull distributions (shape and
> scale)
>
> Here are examples.
>
> 	Shape	Scale
> 2011	2.455	21.657
> 2010	2.328	21.486
> 2009	2.336	22.642
> 2008	2.404	22.193
> 2007	2.447	23.378
> 2006	2.385	22.194
> 2005	2.382	22.153
> 2004	2.53	22.081
> 2003	2.451	23.408
> 2002	2.482	23.135
> 2001	2.44	22.204
> 2000	2.449	22.011


From r.turner at auckland.ac.nz  Wed Nov 13 09:06:46 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 13 Nov 2013 21:06:46 +1300
Subject: [R] r package to solve for Nash equilibrium
In-Reply-To: <CAEqV=wdmACAB9PrsRHx4M9R889Q4LiabegkEMdAioZP8J9nS1A@mail.gmail.com>
References: <CAEqV=wdmACAB9PrsRHx4M9R889Q4LiabegkEMdAioZP8J9nS1A@mail.gmail.com>
Message-ID: <52833316.1030006@auckland.ac.nz>

On 11/12/13 02:49, Dereje Fentie wrote:
> Is there an r package out there that solves for pure strategy* Nash
> equilibrium of a two-person game*? A search for Nash equilibrium in r
> provides a link to the *GNE* package which solves for the Generalized Nash
> equilibrium. But what I would like to solve is a pure strategy Nash
> equilibrium.

Please be aware that "R" is spelt with an upper case "R"!!!

I can't answer your question, but you should note two things (of which 
you may
not be aware).

(1) There may not *be* a pure strategy Nash equilibrium.

(2) There may be more than one Nash equilibrium.

If the GNE package finds *all* Nash equilibria for a given game
(I don't know whether it does, or if it stops with the first equilibrium
it comes to) and *if* there is a pure strategy equilibrium, then this
will be amongst the solutions found, and you just have to pick it out.

     cheers,

     Rolf Turner


From kiangati at gmail.com  Wed Nov 13 09:20:51 2013
From: kiangati at gmail.com (Keniajin Wambui)
Date: Wed, 13 Nov 2013 11:20:51 +0300
Subject: [R] Bar Graph
In-Reply-To: <20131112005358.37675698@draco.site>
References: <CAE=fH8H0f554HZJNwx9xvn_ydHtDmkWXXybJ5JEarDYTkNcr4g@mail.gmail.com>
	<20131112005358.37675698@draco.site>
Message-ID: <CAE=fH8FV7Rk7TWVReUmW5jFCy2bJny8BCifzys1Ctiq7M7bfnQ@mail.gmail.com>

The serialno represents each individual in the data set.The total
count of the serialno will represent the whole sample

 I want to do a graph to compare the total data (serialno) vs each of
the remaining five variables yearly. i.e to show the total data
(serialno) vs available data for one of the variables in the above
case temp axilla.

The above code plot count of temp_axilla yearly,how can I include
serialno to be part of the plot?

I have used
library(ggplot2)
library(foreign)
utils package

On Tue, Nov 12, 2013 at 11:53 AM, jwd <jwd at surewest.net> wrote:
> On Mon, 11 Nov 2013 18:02:19 +0300
> Keniajin Wambui <kiangati at gmail.com> wrote:
>
>> I am using R 3.0.2 on a 64 bit machine
>>
>> I have a data set from 1989-2002. The data has four variables
>> serialno, date, admission ward, temperature and bcg scar.
>>
>> serialno admin_ward date_admn bcg_scar temp_axilla yr
>> 70162    Ward2         11-Oct-89       y           38.9 1989
>> 70163     Ward1        11-Oct-91       y             37.2 1991
>> 70164     Ward2       11-Oct-92        n               37.3 1992
>> 70165     Ward1        11-Oct-93        y                38.9 1993
>> 70166     Ward1       11-Oct-94          y              37.7 1994
>> 70167      Ward1       11-Oct-95          y              40 1995
>>
>>
>> I want to do a bar graph of total data (serialno) vs *(data of one of
>> the variables) to show the available data vs total data over the years
>>
>> i am using
>>
>> gplot(dta, aes(temp_axilla, fill=admin_ward)) + geom_bar() +
>>   facet_grid(. ~ yr, scales = "free",margins=F) +
>> geom_histogram(binwidth=300)
>>
>> But can include the serialno which shows the data. how can I achieve
>> this
>>
>
> You really need to pay better attention somewhere.  There are six
> variables in your example table for instance, not four.  You state you
> want to do something with the serialno variable, but it is not used
> in your bit of code.  Also, given that serialno appears to be
> unique in your example, a bar graph would be singularly uninformative.
>
> You need to provide a better example of the data, and an actual example
> of the code you are trying to use, including the libraries you've
> loaded.
>
> jwdougherty
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Mega Six Solutions
Web Designer and Research Consultant
Kennedy Mwai
25475211786


From babakbsn at gmail.com  Wed Nov 13 09:24:02 2013
From: babakbsn at gmail.com (Baro)
Date: Wed, 13 Nov 2013 00:24:02 -0800
Subject: [R] Setting x-axis of a plot on each loop
Message-ID: <CAF-JZQsQoAS7OWjrzOEchprb8qtdN-9eFgfsD4C8BOaUdMUyRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/79b1a5a5/attachment.pl>

From r.turner at auckland.ac.nz  Wed Nov 13 09:27:28 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 13 Nov 2013 21:27:28 +1300
Subject: [R] Different output from lm() and lmPerm lmp() if categorical
 variables are included in the analysis
In-Reply-To: <CALPC6DO2aR+y9sVs1z8edPe1uacee13jY+40QzTTHdUbjRRdjQ@mail.gmail.com>
References: <CALPC6DO2aR+y9sVs1z8edPe1uacee13jY+40QzTTHdUbjRRdjQ@mail.gmail.com>
Message-ID: <528337F0.5000403@auckland.ac.nz>


RTFM!!! :-)

The help explicitly says "The default contrasts are set internally to 
(contr.sum, contr.poly) ....".

Set

     options(contrasts=c("contr.sum","contr.poly"))

before your call to lm() and "atest" will agree with "aptest" all down 
the line.

     cheers,

     Rolf Turner

On 11/08/13 21:35, Agustin Lobo wrote:
> I've found a problem when using
> categorical variables in lmp() from package lmPerm
>
> According to help(lmp): "This function will behave identically to lm()
> if the following parameters are set: perm="", seq=TRUE,
> center=FALSE.")
> But not in the case of including categorical variables:
>
> require(lmPerm)
> set.seed(42)
> testx1 <- rnorm(100,10,5)
> testx2 <- c(rep("a",50),rep("b",50))
> testy <- 5*testx1 + 3 + runif(100,-20,20)
> test <- data.frame(x1=testx1,x2=
> testx2,y=testy)
> atest <- lm(y ~ x1*x2,data=test)
> aptest <- lmp(y ~ x1*x2,data=test,perm = "", seqs = TRUE, center = FALSE)
> summary(atest)
>
> Call:
> lm(formula = y ~ x1 * x2, data = test)
> Residuals:
>      Min       1Q   Median       3Q      Max
> -17.1777  -9.5306  -0.9733   7.6840  22.2728
>
> Coefficients:
>          Estimate Std. Error t value Pr(>|t|)
> (Intercept)  -2.0036     3.2488  -0.617    0.539
> x1            5.3346     0.2861  18.646   <2e-16 ***
> x2b           2.4952     5.2160   0.478    0.633
> x1:x2b       -0.3833     0.4568  -0.839    0.404
>
> summary(aptest)
>
> Call:
> lmp(formula = y ~ x1 * x2, data = test, perm = "", seqs = TRUE,
> center = FALSE)
>
> Residuals:
>      Min       1Q   Median       3Q      Max
> -17.1777  -9.5306  -0.9733   7.6840  22.2728
>
> Coefficients:
>     Estimate Std. Error t value Pr(>|t|)
> x1       5.1429     0.2284  22.516   <2e-16 ***
> x21     -1.2476     2.6080  -0.478    0.633
> x1:x21   0.1917     0.2284   0.839    0.404
>
> It looks like lmp() is internally coding dummy variables in a different way, so
> lmp results are for "a" (named "1" by lmp) while lm results are for
> "b" ?


From jim at bitwrit.com.au  Wed Nov 13 09:30:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 13 Nov 2013 19:30:19 +1100
Subject: [R] Bar Graph
In-Reply-To: <CAE=fH8FV7Rk7TWVReUmW5jFCy2bJny8BCifzys1Ctiq7M7bfnQ@mail.gmail.com>
References: <CAE=fH8H0f554HZJNwx9xvn_ydHtDmkWXXybJ5JEarDYTkNcr4g@mail.gmail.com>	<20131112005358.37675698@draco.site>
	<CAE=fH8FV7Rk7TWVReUmW5jFCy2bJny8BCifzys1Ctiq7M7bfnQ@mail.gmail.com>
Message-ID: <5283389B.9050609@bitwrit.com.au>

On 11/13/2013 07:20 PM, Keniajin Wambui wrote:
> The serialno represents each individual in the data set.The total
> count of the serialno will represent the whole sample
>
>   I want to do a graph to compare the total data (serialno) vs each of
> the remaining five variables yearly. i.e to show the total data
> (serialno) vs available data for one of the variables in the above
> case temp axilla.
>
> The above code plot count of temp_axilla yearly,how can I include
> serialno to be part of the plot?
>
> I have used
> library(ggplot2)
> library(foreign)
> utils package

Hi Keniajim,
It is not easy to work out what you want. If each serial number is an 
individual and you want the total number of individuals (dataset is 
"mydata"):

length(unique(mydata$serialno))

If you want the total number of individuals per year:

nind<-function(x) return(length(unique(x)))
year<-as.numeric(format(as.Date(mydata$date_admn,"%d-%b-%y"),"%Y"))
by(mydata$serialno,mydata$year,nind)

Perhaps this will give you a start.

Jim


From michael.lang at tum.de  Wed Nov 13 10:03:07 2013
From: michael.lang at tum.de (Mike.lang)
Date: Wed, 13 Nov 2013 01:03:07 -0800 (PST)
Subject: [R] Generalized Additive Models - gamma against overfitting
Message-ID: <1384333387866-4680364.post@n4.nabble.com>

Dear listeners, 

in order to analyze a dataset, which includes more than 30k records, I'm
using a general GAMM like y~s(x)+s(y)+z+e with a underlying normal
distribution. Unfortunately, I have some problems with over- and
underfittings in smooth-functions at the same time. 
In general there is the possibility to set up a gamma like gamma=1.4 in
order to avoid overfitting in the smooth-functions. In my case I would need
different gammas for different smooth-functions, because s(x) is overfitted
and s(y) underfitted currently. 
So, is there any possibility to set up a gamma for each smooth-function
separately? 

I really would appreciate your responses! 

Thanks a lot!
Best 
Mike



--
View this message in context: http://r.789695.n4.nabble.com/Generalized-Additive-Models-gamma-against-overfitting-tp4680364.html
Sent from the R help mailing list archive at Nabble.com.


From markpayneatwork at gmail.com  Wed Nov 13 10:38:33 2013
From: markpayneatwork at gmail.com (Mark Payne)
Date: Wed, 13 Nov 2013 10:38:33 +0100
Subject: [R] Negative binomial parameterisation in mgcv
Message-ID: <CAGBzUO9Ur=aGj-GpTXY4fyW4hBUJs=MJaz6EN6Q67TH4OBnCAQ@mail.gmail.com>

Dear R-help,

The negative binomial distribution has several different
parameterisations, but I can't seem to figure out what the exact one
used in mgcv's negbin family is? negbin() requires a theta argument,
but its not clear anywhere in the documentation (that I can find), how
this parameter should be interpreted - for example, can it be less
than 1?

Best wishes,

MArk


From ripley at stats.ox.ac.uk  Wed Nov 13 10:54:21 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 13 Nov 2013 09:54:21 +0000
Subject: [R] Negative binomial parameterisation in mgcv
In-Reply-To: <CAGBzUO9Ur=aGj-GpTXY4fyW4hBUJs=MJaz6EN6Q67TH4OBnCAQ@mail.gmail.com>
References: <CAGBzUO9Ur=aGj-GpTXY4fyW4hBUJs=MJaz6EN6Q67TH4OBnCAQ@mail.gmail.com>
Message-ID: <52834C4D.70702@stats.ox.ac.uk>

On 13/11/2013 09:38, Mark Payne wrote:
> Dear R-help,
>
> The negative binomial distribution has several different
> parameterisations, but I can't seem to figure out what the exact one
> used in mgcv's negbin family is? negbin() requires a theta argument,
> but its not clear anywhere in the documentation (that I can find), how
> this parameter should be interpreted - for example, can it be less
> than 1?

I believe it is the same as MASS (the package) explained in MASS (the 
book).  As its help says ....

>
> Best wishes,
>
> MArk
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From alaios at yahoo.com  Wed Nov 13 11:36:32 2013
From: alaios at yahoo.com (Alaios)
Date: Wed, 13 Nov 2013 02:36:32 -0800 (PST)
Subject: [R] Grid type of sampling in geodata
Message-ID: <1384338992.27448.YahooMailNeo@web125304.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/bfb87be9/attachment.pl>

From N.Hubner at ncmls.ru.nl  Wed Nov 13 15:24:28 2013
From: N.Hubner at ncmls.ru.nl (N.Hubner at ncmls.ru.nl)
Date: Wed, 13 Nov 2013 14:24:28 +0000
Subject: [R] making a barplot with table of experimental conditions
 underneath (preferably ggplot2)
Message-ID: <5FF7898BAD1B4A4A809F4C51902634847344670E@UMCEXMBX11.umcn.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/275493a7/attachment.pl>

From julian.bothe at elitepartner.de  Wed Nov 13 15:46:03 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Wed, 13 Nov 2013 15:46:03 +0100 (CET)
Subject: [R] issues with calling predict.coxph.penal (survival) inside a
	function - subset-vector not found. Because of NextMethod?
Message-ID: <111e0e45.00000f98.00000008@FIW7PC12.ELITEMEDIANET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/8b72383e/attachment.pl>

From szehnder at uni-bonn.de  Wed Nov 13 16:35:54 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 13 Nov 2013 16:35:54 +0100
Subject: [R] issues with calling predict.coxph.penal (survival) inside a
	function - subset-vector not found. Because of NextMethod?
In-Reply-To: <111e0e45.00000f98.00000008@FIW7PC12.ELITEMEDIANET>
References: <111e0e45.00000f98.00000008@FIW7PC12.ELITEMEDIANET>
Message-ID: <826E7466-60AF-47C9-A554-6E8DC1945172@uni-bonn.de>

Works for me:

predicting_function(fit2,test1)
         1          2          3          4          5          6          7
-1.0481141  0.1495946  0.4492597  0.4492597  0.9982492 -0.4991246 -0.4991246

Best

Simon

On 13 Nov 2013, at 15:46, julian.bothe at elitepartner.de wrote:

> Hello everyone, 
> 
> 
> 
> I got an issue with calling predict.coxph.penal inside a function. 
> 
> 
> 
> Regarding the context: My original problem is that I wrote a function that
> uses predict.coxph and survfit(model) to predict
> 
> a lot of survival-curves using only the basis-curves for the strata (as
> delivered by survfit(model) ) and then adapts them with 
> 
> the predicted risk-scores. Because there are cases where my new data has
> strata which didn't exist in the original model I exclude 
> 
> them, using a Boolean vector inside the function.
> 
> I end up with a call like this: predict (coxph_model,
> newdata[subscript_vector,] ) 
> 
> 
> 
> This works fine for coxph.model, but when I fit a model with a spline
> (class coxph.penal), I get an error: 
> 
> "Error in `[.data.frame`(newdata, [subscript_vector, ) : object
> '[subscript_vector ' not found"
> 
> 
> 
> I suppose this is because of NextMethod, but I am not sure how to work
> around it. I also read a little bit about all those
> matching-and-frame-issues, 
> 
> But must confess I am not really into it. 
> 
> 
> 
> I attach a reproducible example. 
> 
> Any help or suggestions of work-arounds will be appreciated. 
> 
> 
> 
> Thanks 
> 
> Julian
> 
> 
> 
>> version
> 
>               _                           
> 
> platform       x86_64-w64-mingw32          
> 
> arch           x86_64                      
> 
> os             mingw32                     
> 
> system         x86_64, mingw32             
> 
> status                                     
> 
> major          3                           
> 
> minor          0.1                         
> 
> year           2013                        
> 
> month          05                          
> 
> day            16                          
> 
> svn rev        62743                       
> 
> language       R                           
> 
> version.string R version 3.0.1 (2013-05-16)
> 
> nickname       Good Sport    
> 
> 
> 
> 
> 
> ##TEST-DATA
> 
> 
> 
> # Create the simplest test data set 
> 
> test1 <- data.frame(time=c(4,3,1,1,2,2,3), 
> 
>              status=c(1,1,1,0,1,1,0), 
> 
>              x=c(0,2,1,1,1,0,0), 
> 
>              sex=c(0,0,0,0,1,1,1)) 
> 
> 
> 
> # Fit a stratified model 
> 
> fit1 <- coxph(Surv(time, status) ~ x + strata(sex), test1) 
> 
> summary(fit1)
> 
> 
> 
> #fit stratified wih spline
> 
> fit2 <- coxph(Surv(time, status) ~ pspline(x, df=2) + strata(sex), test1) 
> 
> summary(fit2)
> 
> 
> 
> #function to predict within
> 
> 
> 
> predicting_function <- function(model, newdata){
> 
>  subs <-vector(mode='logical', length=nrow(newdata))
> 
>  subs[1:length(subs)]<- TRUE
> 
> 
> 
>  ret <- predict (model, newdata=newdata[subs,])
> 
>  return(ret)
> 
> }
> 
> 
> 
> predicting_function(fit1, test1) # works
> 
> 
> 
> predicting_function(fit2,test1) #doesnt work - Error in
> `[.data.frame`(newdata, subs, ) : object 'subs' not found
> 
>                                # probably because of NextMethod
> 
> 
> 
> #--------
> 
>> traceback()
> 
> #12: `[.data.frame`(newdata, subs, )
> 
> #11: newdata[subs, ]
> 
> #10: is.data.frame(data)
> 
> #9: model.frame.default(data = newdata[subs, ], formula = ~pspline(x, 
> 
> #       df = 2) + strata(sex), na.action = function (object, ...) 
> 
> #   object)
> 
> #8: model.frame(data = newdata[subs, ], formula = ~pspline(x, df = 2) + 
> 
> #       strata(sex), na.action = function (object, ...) 
> 
> #   object)
> 
> #7: eval(expr, envir, enclos)
> 
> #6: eval(tcall, parent.frame())
> 
> #5: predict.coxph(model, newdata = newdata[subs, ])
> 
> #4: NextMethod("predict", object, ...)
> 
> #3: predict.coxph.penal(model, newdata = newdata[subs, ])
> 
> #2: predict(model, newdata = newdata[subs, ]) at #5
> 
> #1: predicting_function(fit2, test1)
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Nov 13 17:13:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Nov 2013 16:13:18 +0000
Subject: [R] Data transformation to list for event occurence
In-Reply-To: <1384294388.63306.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAKC+_z84GCiQjb7GgyoyQnAqGZ8GiPrAh3do7yrw9CRs3Hbn0A@mail.gmail.com>
	<1384294388.63306.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA14F78@PA-MBX01.na.tibco.com>

Or,

f3 <- function (dat1)  {
    i <- dat1$Event_Occurence == 1
    split(dat1$Week[i], dat1$ID[i])
}

in addition to the previously mentioned
f1 <- function(dat1) {
    with(dat1,tapply(as.logical(Event_Occurence),ID,FUN=which ))
}
f2 <- function(dat1){
     lapply(split(dat1,dat1$ID),function(x) which(!!x[,3]))
}

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Tuesday, November 12, 2013 2:13 PM
> To: R help
> Subject: Re: [R] Data transformation to list for event occurence
> 
> 
> 
> Hi Anindya,
> 
> You may try:
> dat1 <- read.table(text="ID?? Week??? Event_Occurence
> A 1 0
> A 2 0
> A 3 1
> A 4 0
> B 1 1
> B 2 0
> B 3 0
> B 4 1",sep="",header=TRUE,stringsAsFactors=FALSE)
> 
> ?with(dat1,tapply(as.logical(Event_Occurence),ID,FUN=which ))
> #or
> lapply(split(dat1,dat1$ID),function(x) which(!!x[,3]))
> A.K.
> 
> 
> 
> 
> 
> On Tuesday, November 12, 2013 4:58 PM, Anindya Sankar Dey <anindya55 at gmail.com>
> wrote:
> Hi,
> 
> Say I have a following data
> 
> ID?  Week? ? Event_Occurence
> A 1 0
> A 2 0
> A 3 1
> A 4 0
> B 1 1
> B 2 0
> B 3 0
> B 4 1
> 
> that whether an individual experienced an event in a particular week.
> 
> I wish to create list such as the first element of the list will be a
> vector listing the week number when the event has occurred for A, followed
> by that of B.
> 
> Can you help creating this?
> 
> --
> Anindya Sankar Dey
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From s.wood at bath.ac.uk  Wed Nov 13 17:20:36 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 13 Nov 2013 17:20:36 +0100
Subject: [R] Negative binomial parameterisation in mgcv
In-Reply-To: <52836013.2050403@bath.ac.uk>
References: <52836013.2050403@bath.ac.uk>
Message-ID: <5283A6D4.806@bath.ac.uk>

var(y) = mu + mu^2/theta where E(y) = mu.

best,
Simon

On 13/11/13 10:38, Mark Payne wrote:
> Dear R-help,
>
> The negative binomial distribution has several different
> parameterisations, but I can't seem to figure out what the exact one
> used in mgcv's negbin family is? negbin() requires a theta argument,
> but its not clear anywhere in the documentation (that I can find), how
> this parameter should be interpreted - for example, can it be less
> than 1?
>
> Best wishes,
>
> MArk
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From cs_2002 at hotmail.com  Wed Nov 13 17:43:04 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Wed, 13 Nov 2013 19:43:04 +0300
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>,
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
Message-ID: <DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/5d42ff96/attachment.pl>

From dwinsemius at comcast.net  Wed Nov 13 18:01:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 13 Nov 2013 09:01:25 -0800
Subject: [R] Setting x-axis of a plot on each loop
In-Reply-To: <CAF-JZQsQoAS7OWjrzOEchprb8qtdN-9eFgfsD4C8BOaUdMUyRg@mail.gmail.com>
References: <CAF-JZQsQoAS7OWjrzOEchprb8qtdN-9eFgfsD4C8BOaUdMUyRg@mail.gmail.com>
Message-ID: <19DA29E1-4E8F-437F-8D18-23E0C0A423DE@comcast.net>


On Nov 13, 2013, at 12:24 AM, Baro wrote:

> I have a block of code:
> 
> window<-5
> start<-3
> n<-1
> 
> seq1 <- seq(1:40)
> mat<-matrix(seq1,40)
> 
> 
> while(1+window<=length(mat[,1]))
> {
>  kd<-matrix(as.integer(mat[n:(n+window-1),1]))
>  Sys.sleep(0.2)
> 
> plot(kd,col="blue",xlab="Rohdaten",ylab="values",xlim=c(start+n,start+n+window-1)
> )
> 
>  n<-n+1
> }
> 
> I have this expectation, that on each loop two x-axis and y-axis are
> changed and see the values on the plot. but I cant see the value.What
> should I do to have values too?. If I am changing this my code to
> 
> plot(kd,col="blue",xlab="Rohdaten",ylab="values")
> 
> I can see the values but on the x-axis I have no the correct values

You "see nothing" (except perhaps in the first few plots where I suspect points are being plotted within the plot area) because by offdering only one unnamed numeric  argument to plot you implicitly use 1:5 as your x value in all plots. You say you have qn expectation that the and y values are changing but you don't change the x-values in your code. You have not described what you are trying to do so giving further advice is not possible. I take that back; further advice:  It's always a good idea to name your arguments.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lopez235 at llnl.gov  Wed Nov 13 18:15:55 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Wed, 13 Nov 2013 17:15:55 +0000
Subject: [R] What is the difference between Mean Decrease Accuracy produced
 by importance(foo) vs foo$importance in a Random Forest Model?
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAFC7A@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/80fa33c0/attachment.pl>

From nashjc at uottawa.ca  Wed Nov 13 18:50:44 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 13 Nov 2013 12:50:44 -0500
Subject: [R] codenls
In-Reply-To: <mailman.25.1384340410.32061.r-help@r-project.org>
References: <mailman.25.1384340410.32061.r-help@r-project.org>
Message-ID: <5283BBF4.7090706@uottawa.ca>

The expression has b[1] and b[2] while start has b[2] and b[3].

The expression needs a different form, for example:

#   fit<-nlrob(y ~ x1 / (1+ b[1]*x2^b[2]),data = xx, start =
#   list(b[2],b[3]))
   fit<-nlrob(y ~ x1 / (1+ b1*x2^b2),data = xx, start =
   list(b1=b[2],b2=b[3]))

This "works", though I have no idea if the results make sense.

JN

On 13-11-13 06:00 AM, r-help-request at r-project.org wrote:
> Message: 6
> Date: Tue, 12 Nov 2013 06:03:02 -0800 (PST)
> From: IZHAK shabsogh <ishaqbaba at yahoo.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] codenls
> Message-ID:
> 	<1384264982.50617.YahooMailNeo at web142502.mail.bf1.yahoo.com>
> Content-Type: text/plain
> 
>  kindly help correct this program as given below i run and run is given me some error
> 
> rm(list=ls())
>  require(stats)
>  require(robustbase) 
>  x1<-as.matrix(c(5.548,4.896,1.964,3.586,3.824,3.111,3.607,3.557,2.989))
>  y<-as.matrix(c(2.590,3.770,1.270,1.445,3.290,0.930,1.600,1.250,3.450))
>  x2<-as.matrix(c(0.137,2.499,0.419,1.699,0.605,0.677,0.159,1.699,0.340))
>  k<-rep(1,9)
>  x<-data.frame(k,x1,x2)
>  xx<-data.frame(y,x1,x2)
>  
>  
>  freg<-function(y,x1,x2){
>    reg<- lm(y ~ x1 + x2 , data=x)
>   
>  return(reg)
>  }
>  
>  fit<-freg(y,x1,x2)
>  b<-as.matrix((coef(fit)))
>  
> 
>  f<-function(b,x1,x2){
>    fit<-nlrob(y ~ x1 / (1+ b[1]*x2^b[2]),data = xx, start =
>    list(b[2],b[3]))
>    return(fit)
>  }
>  fit1<-f(b,x1,x2)
> Error in nlrob(y ~ x1/(1 + b[1] * x2^b[2]), data = xx, start = list(b[2],  : 
>   'start' must be fully named (list or numeric vector)
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 7
> Date: Tue, 12 Nov 2013 06:34:44 -0800 (PST)
> From: Alaios <alaios at yahoo.com>
> To: "R-help at r-project.org" <R-help at r-project.org>
> Subject: [R] Handle Gps coordinates
> Message-ID:
> 	<1384266884.5102.YahooMailNeo at web125305.mail.ne1.yahoo.com>
> Content-Type: text/plain
> 
> Dear all,
> I would like to ask you if there are any gps libraries.
> 
> 
> I would like to be able to handle them,
> -like calculate distances in meters between gps locations,
> -or find which gps location is closer to a list of gps locations.
> 
> Is there something like that in R?
> 
> I would like to tthank you in advance for your reply
> 
> Regards
> Alex
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------
> 
> Message: 8
> Date: Tue, 12 Nov 2013 06:59:53 -0800
> From: Baro <babakbsn at gmail.com>
> To: R help <r-help at r-project.org>
> Subject: [R] Having a relative x-axis in a plot
> Message-ID:
> 	<CAF-JZQupPPoyGfd-1k0ztn7bHmFTxdXUjtMGHub9D3TYLh=2uQ at mail.gmail.com>
> Content-Type: text/plain
> 
> I would like to have a relative x-axis in r. I am reading time seris from
> an excel file and I want to show in a plot and also I want to have a window
> which moves over the values.
> 
> My aim ist to see which point belongs to which time(row number in excel
> file). i.e I am reading from 401th row in 1100th column in excel file and
> my window length is 256. here is my code:
> 
> #which column in excel filespalte<-1100
> #start row and end row
> start<-401end<-600
> 
> window<-256
> n<-1
> 
> wb <- loadWorkbook("D:\\MA\\excel_mix_1100.xls")
> dat <-readWorksheet(wb, sheet=getSheets(wb)[1], startRow=start,
> endRow=end, startCol=spalte, endCol=spalte,header=FALSE)
> datalist<-dat[seq(1, length(dat[,1]), by = 2),]
> datalist<-matrix(datalist)while(1+window<=length(datalist)){
>   kd<-matrix(as.integer(datalist[n:(n+window-1),1]))
>   Sys.sleep(0.2)
>   plot(kd,type="l",col="blue",xlab="Rohdaten",ylab="values",xlim=c(start+n,start+n+window-1))
>   n<-n+1}
> 
> 	[[alternative HTML version deleted]]


From anna.zakrisson at su.se  Wed Nov 13 11:05:42 2013
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Wed, 13 Nov 2013 10:05:42 +0000
Subject: [R] ggplot2: geom_boxplot. Mapping aes factor but with different
 color scale and hatching
Message-ID: <11019DCE9B47004F90B2D9C62FF1579218D19F90@ebox-prod-srv04.win.su.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/050e47b1/attachment.pl>

From balu555 at gmx.de  Wed Nov 13 11:22:00 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Wed, 13 Nov 2013 11:22:00 +0100 (CET)
Subject: [R] Linux Java and R not working together
Message-ID: <trinity-add01646-32d0-4eb2-84c5-72572e54d883-1384338120448@3capp-gmx-bs15>


   Dear community,

   I almost tried for 3 days now to install rJava and package FSelector on my
   Linux machine but couldn't do so.
   I  searched all the forums and tried some tricks ... but unfortunately
   couldn't find any solution.
   First of all I did try to install rJava in my rkward without any changes ,
   that gave me the following error :

   configure: error: One or more JNI types differ from the corresponding native
   type.  You  may need to use non-standard compiler flags or a different
   compiler in order to fix this.

   ERROR: configuration failed for package ?rJava?

   * removing ?/home/uwe/.rkward/library/rJava?

   Warnmeldung:

   In install.packages(pkgs = c("rJava"), lib = "/home/uwe/.rkward/library", :

   Installation des Pakets ?rJava? hatte Exit-Status ungleich 0


   So then I started searching and found a tip. I did run the following;



   uwe at linux-k2a8:~> sudo R CMD javareconf
   Java interpreter : /usr/bin/java
   Java version     : 1.7.0_45
   Java home path   : /usr/lib/jdk1.7.0_45/jre
   Java compiler    : /usr/bin/javac
   Java headers gen.: /usr/bin/javah
   Java archive tool: /usr/bin/jar
   NOTE: Your JVM has a bogus java.library.path system property!
         Trying a heuristic via sun.boot.library.path to find jvm library...
   Java library path: $(JAVA_HOME)/lib/i386/client
   JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
   JNI cpp flags    : -I$(JAVA_HOME)/../include -I$(JAVA_HOME)/../include/linux
   Updating Java configuration in /usr/lib/R
   Done.



   And also did check 


   uwe at linux-k2a8:~> java -version
   java version "1.7.0_45"
   Java(TM) SE Runtime Environment (build 1.7.0_45-b18)
   Java HotSpot(TM) Server VM (build 24.45-b08, mixed mode)
   uwe at linux-k2a8:~> sudo /usr/sbin/update-alternatives --config java
   There are 4 choices for the alternative java (providing /usr/bin/java).
     Selection    Path                                     Priority   Status
   ------------------------------------------------------------
     0            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     auto mode
     1            /usr/java/latest/bin/java                 1         manual
   mode
   * 2            /usr/lib/jdk_Oracle/bin/java              3         manual
   mode
     3            /usr/lib/jvm/jre-1.5.0-gcj/bin/java       1500      manual
   mode
     4            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     manual
   mode
   Press enter to keep the current choice[*], or type selection number:



   I absolutely don't know what is wrong with that setup since my Java seems to
   have JDK and all the other things needed for R.

   For your Information here my system:
   uwe at linux-k2a8:~> uname -rm
   3.4.63-2.44-desktop i686

   uwe at linux-k2a8:~> cat /proc/version
   Linux version 3.4.63-2.44-desktop (geeko at buildhost) (gcc version 4.7.1
   20120723 [gcc-4_7-branch revision 189773] (S Linux) ) #1 SMP PREEMPT Wed Oct
   2 11:18:32 UTC 2013 (d91a619)



   I would be really thankful for any advise to get rJava (and FSelector)
   running soon.

   Best wishes

   Uwe

From erkcan at hotmail.com  Wed Nov 13 12:36:44 2013
From: erkcan at hotmail.com (=?iso-8859-1?Q?Erkcan_=D6zcan?=)
Date: Wed, 13 Nov 2013 13:36:44 +0200
Subject: [R] Fitting arbitrary curve to 1D data with error bars
Message-ID: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/b3106b54/attachment.pl>

From smartpink111 at yahoo.com  Wed Nov 13 14:19:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 13 Nov 2013 05:19:00 -0800 (PST)
Subject: [R] simplex
Message-ID: <1384348740.21960.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi Sven,
May be this helps:

If you look into ?simplex.object 

"

solved This indicates whether the problem was solved.? A value of
????????? ?-1? indicates that no feasible solution could be found.? A
????????? value of ?0? that the maximum number of iterations was
????????? reached without termination of the second stage.? This may
????????? indicate an unbounded function or simply that more iterations
????????? are needed. A value of ?1? indicates that an optimal solution
????????? has been found.
"


?s1 <- simplex(a=price * -1, A1=A, b1=b, A2=A, b2=b2, maxi=T) # This cant find a solution
s1$solved
#[1] -1

A.K.




Dear All, 

I do have a problem with a linear optimisation I am trying to achieve: 

library(boot) 
price <- c(26.93, 26.23, 25.64, 25.97, 26.12, 26.18, 26.49, 27, 27.32, 27.93, 27.72, 27.23) 
A <- matrix(0, nrow=length(price)+1, ncol=length(price)) 
A[1,] <- 1 
for(i in 1:length(price)) A[i+1,i] <- 1 
b <- c(864000.01, 288000, 288000, 288000, 288000, 288000, 288000, 288000, 288000, 288000, 288000, 288000, 288000) 
b2 <- c(864000, 216000, 216000, 216000, 216000, 216000, 216000, 216000, 216000, 216000, 216000, 216000, 216000) 


simplex(a=price, A1=A, b1=b) # This works 
simplex(a=price, A1=A, b1=b, maxi=T) # This is the maxing function and works as well 
simplex(a=price * -1, A1=A, b1=b, A2=A, b2=b2, maxi=T) # This cant find a solution 


The result I would expect is that it picks the 4 
highest(note I multiplied "price" with -1) numbers and multiplies them 
with constraint in b2. 

For example this works: 


library(boot) 
price <- c(1, 2, 3 , 4) 
A <- matrix(0, nrow=length(price)+1, ncol=length(price)) 
A[1,] <- 1 
for(i in 1:length(price)) A[i+1,i] <- 1 
b <- c(8.01, 2.5, 2.5, 2.5, 2.5) 
b2 <- c(8, 2, 2, 2, 2) 

simplex(a=price, A1=A, b1=b) 
simplex(a=price, A1=A, b1=b, maxi=T) 
simplex(a=price * -1, A1=A, b1=b, A2=A, b2=b2, maxi=T) 


I cant see a logical difference between the two, why would it not find a solution for the first problem? 

Thank you. 


Sven


From zfeinstein at isgmn.com  Wed Nov 13 14:57:17 2013
From: zfeinstein at isgmn.com (Zach Feinstein)
Date: Wed, 13 Nov 2013 13:57:17 +0000
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
	Learn Few Basics
Message-ID: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/454b914c/attachment.pl>

From nicolas.palix at imag.fr  Wed Nov 13 15:48:32 2013
From: nicolas.palix at imag.fr (Nicolas Palix)
Date: Wed, 13 Nov 2013 15:48:32 +0100
Subject: [R] Survival analysis with truncated data.
Message-ID: <CAAxaTiPcgObfJFK6OkXzeM-5ipZK8C94NSL+6B05k3LYxn77jg@mail.gmail.com>

Hi,

I would like to know how to handle truncated data.
My intend is to have the survival curve of a software fault in order
to have some information
about fault lifespan.

I have some observations of a software system between 2004 and 2010.
The system was first released in 1994.
The event considered is the disappearance of a software fault. The
faults can have been
introduced at any time, between 1994 and 2010. But for fault
introduced before 2004,
there is not mean to know their age.

I used the Surv and survfit functions with type interval2.
For the faults that are first observed in 2004, I set the lower bound
to the lifespan
observed between 2004 and 2010.

How could I set the upper bound ? Using 1994 as a starting point to not seems
to be meaningful. Neither is using only the lower bound.

Should I consider another survival estimator ?

Thanks in advance.
-- 
Nicolas Palix
Tel: +33 4 76 51 46 27
http://membres-liglab.imag.fr/palix/


From saporta at scarletmail.rutgers.edu  Wed Nov 13 16:31:43 2013
From: saporta at scarletmail.rutgers.edu (Ricardo Saporta)
Date: Wed, 13 Nov 2013 10:31:43 -0500
Subject: [R] .First in R.app (on Mac) vs R in Terminal
Message-ID: <CAE7Aa4TfAmiJYXDPE+V-T0L4ocqDTfPE1v9Ue5TygWz6xGXwuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/20b9b3bf/attachment.pl>

From smartpink111 at yahoo.com  Wed Nov 13 17:00:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 13 Nov 2013 08:00:37 -0800 (PST)
Subject: [R] Readjusting frequencies
Message-ID: <1384358437.66986.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Katherine,

Check if this works:
fraud_data = data.frame(no_of_frauds = c(1, 2, 4, 6, 7, 9, 10), frequency = c(3, 1, 7, 11, 13, 1, 4))
fraud_data1 <- rbind(fraud_data,c(11,10))

fun1 <- function(dat) {
?sum1 <- 0
?for(i in 1:nrow(dat)){
?sum1 <- sum1 + dat[i, "frequency"]
?dat[i,"frequency"] <- sum1
?if(sum1> 5){
?sum1 <- 0
?}
?}
indx <- which(dat$frequency >5)
if(max(indx)==nrow(dat))
{res <- dat[dat$frequency >5,]
}
else{
dat[max(indx),"frequency"] <- sum(dat[c(max(indx),nrow(dat)),"frequency"])
res <- dat[dat$frequency > 5,]
}
res
}
fun1(fraud_data)
#? no_of_frauds frequency
#3??????????? 4??????? 11
#4??????????? 6??????? 11
#5??????????? 7??????? 18
?fun1(fraud_data1)
#? no_of_frauds frequency
#3??????????? 4??????? 11
#4??????????? 6??????? 11
#5??????????? 7??????? 13
#8?????????? 11??????? 15


A.K.

On Tuesday, November 12, 2013 5:12 AM, Katherine Gobin <katherine_gobin at yahoo.com> wrote:

Dear Mr Arun,

Hi!
 Sorry to bother you. Yesterday I had raised one query to the forum but 
haven't received any response. If the time permits, will it be possible 
for you to at least have a look at it?


I have
following data.frame as

fraud_data
= data.frame(no_of_frauds = c(1, 2, 4, 6, 7, 9, 10), frequency = c(3, 1, 7, 11,
13, 1, 4))

>
fraud_data

no_of_frauds frequency
1
? ? ? ? ? ?1 ? ? ? ? 3
2
? ? ? ? ? ?2 ? ? ? ? 1
3
? ? ? ? ? ?4 ? ? ? ? 7
4
? ? ? ? ? ?6 ? ? ? ?11
5
? ? ? ? ? ?7 ? ? ? ?13
6
? ? ? ? ? ?9 ? ? ? ? 1
7
? ? ? ? ? 10 ? ? ? ? 4

I need
to regroup the data in such a way that if the frequency is less than 5, the
corresponding class data gets merged to next class (or at times with previous class too) i.e. the frequencies get
added till the added frequencies exceed 5.?

Thus, in above data.frame
since frequencies pertaining to no_of_frauds 1 and 2 are 3 and 1 respectively,
these get added to class 4 and the frequency of this class now becomes 3+1+7 =
11. Likewise, frequency of classes 9 and 10 are 1 and 4 and when these are
added still it is 5 i.e. doesn't exceed 5. Thus, these should get added to the
previous class i.e. 7.

Thus I
need to have

no_of_frauds
? ? ? frequency

? ? ? 4 ? ? ? ? ? ? ? ?
? 11 ? ? ? ? ? ?# ?( 3 + 1 + 7)

? ? ? 6 ? ? ? ? ? ? ? ?
? 11 ? ? ? ? ??

? ? ? 7 ? ? ? ? ? ? ? ?
? 18 ? ? ? ? ? ?# ?(13 + 1 + 4)


If possible, pl go through it. Sorry to bother you.

Regards

Katherine



From drf at vims.edu  Wed Nov 13 18:56:10 2013
From: drf at vims.edu (David R Forrest)
Date: Wed, 13 Nov 2013 17:56:10 +0000
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>,
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
	<DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
Message-ID: <E143F773-7734-43EE-BE5F-4015867EAAF6@vims.edu>


Looks like there are typos in equation 8 of http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf  (expo2 doesn't depend on 'v') or equation 9 of http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf ('a' is not specified).

Dave

On Nov 13, 2013, at 11:43 AM, "b. alzahrani" <cs_2002 at hotmail.com>
 wrote:

> 
> Hi
> 
> I found this paper http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf that models the DPLN distribution as in equation 8. I implemented this in R but cannot get the same curve as in Figure 4. can you please check if my code below is correct: e.g. is the use of pnorm() correct here?
> 
> ddlpn <- function(x){
>  a=2.8
>  b=0.01
>  v=0.45
>  t=6.5
>  j <- (a * b /(a+b))
> 
>  norm1<-pnorm((log(x)-v-(a*t^2))/t)
>  expo1<- a*v+(a^2*t^2/2)
> 
>  z<-exp(expo1)*(x^(-a-1))*(norm1)
> 
>  norm2<-pnorm((log(x)-v+(b*t^2))/t)
> expo2<- -b*t+(b^2*t^2/2)
> 
>  y<- x^(b-1)*exp(expo2)*(1-norm2)  # 1-norm is the complementary CDF of N(0,1)
>  j*(z+y)
> }
> ******************************************************************
> Bander Alzahrani, Teacher Assistant
> Information Systems Department
> Faculty of Computing & Information Technology
> King Abdulaziz University
> 
> *************************************
> 
> 
> 
>> From: drf at vims.edu
>> To: cs_2002 at hotmail.com
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Double Pareto Log Normal Distribution
>> Date: Tue, 12 Nov 2013 16:51:22 +0000
>> 
>> 
>> http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf is the original ref and has the equations.
>> 
>> library(VGAM) for *pareto() and library(stats) for *lnorm() should get you most of the way there.
>> 
>> On Nov 12, 2013, at 10:47 AM, "b. alzahrani" <cs_2002 at hotmail.com>
>> wrote:
>> 
>>> Hi guys
>>> I would like to generate random number Double Pareto Log Normal Distribution (DPLN). does anyone know how to do this in R or if there is any built-in function.
>>> 
>>> Thanks
>>> 
>>> ******************************************************************
>>> Bander 
>>> *************************************
>>> 
>>> 
>>> 		 	   		  
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Dr. David Forrest
>> drf at vims.edu
>> 
>> 
>> 
>> 
>> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Dr. David Forrest
drf at vims.edu


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/e3595bb0/attachment.bin>

From liamroche at yahoo.com  Wed Nov 13 19:23:13 2013
From: liamroche at yahoo.com (Liam Roche)
Date: Wed, 13 Nov 2013 18:23:13 +0000 (GMT)
Subject: [R] kernlab multicore usage
Message-ID: <1384366993.22526.YahooMailNeo@web172004.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/6aa00c21/attachment.pl>

From gunter.berton at gene.com  Wed Nov 13 20:08:44 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 13 Nov 2013 11:08:44 -0800
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
 Learn Few Basics
In-Reply-To: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
References: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
Message-ID: <CACk-te3ANwkBNAbeFqCU5aZJOqkA4ZVOb3cPSwAOVbNp7fiZkQ@mail.gmail.com>

Type the following into your console window:

install.packages("fortunes")
library(fortunes)
fortune("brain surgery")

(It's not quite apposite, but close enough).

Cheers,
Bert


On Wed, Nov 13, 2013 at 5:57 AM, Zach Feinstein <zfeinstein at isgmn.com> wrote:
> I have finally decided that I will learn R and learn it very well. For now I am using a program that a friend of mine developed to do some advanced statistical analyses. I downloaded RStudio to my machine. [Perhaps RStudio is not the best platform to work from -  I have heard that Rattle is sort of the new standard.] I have so far been able to highlight the rows of the code that I wish to run, but then I somehow turned off seeing the output. I also cannot find where I would locate the output window. Yes, frustrated.
>
> Would any kind soul be interested in helping kickstart my R learning? I have JoinMe installed on my machine so I figure we can do it interactively. It should not take more than a few minutes. I am already very experienced with both C and VBA languages as well as SPSS syntax so there is not much need to worry about me being too much of a novice.
>
> Thank you very much in advance.
>
> Zach Feinstein
> zfeinstein at isgmn.com<mailto:zfeinstein at isgmn.com>
> (952) 277-0162
> (612) 590-4813 (mobile)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From mmalten at gmail.com  Wed Nov 13 20:41:50 2013
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Wed, 13 Nov 2013 14:41:50 -0500
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
 Learn Few Basics
In-Reply-To: <CACk-te3ANwkBNAbeFqCU5aZJOqkA4ZVOb3cPSwAOVbNp7fiZkQ@mail.gmail.com>
References: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
	<CACk-te3ANwkBNAbeFqCU5aZJOqkA4ZVOb3cPSwAOVbNp7fiZkQ@mail.gmail.com>
Message-ID: <CANOgrHYj2Ta=ffEdPRcK1=hR4qbyuZhCctxorHkHLaHX2BVVbg@mail.gmail.com>

Bert:

 Yet another reason I'm a fan of Frank Harrell. Does anyone know when
I get to buy the next edition of Regression Modeling Strategies?

Zach: Check www.coursera.org. They have some nice R-centric classes.
I signed up myself since my own R skills are self-taught.  Also
consider investing in some of the excellent R texts available such as
"The R Book" or "The R Primer"




____________________________
Ersatzistician and Chutzpahthologist
I can answer any question.  "I don't know" is an answer. "I don't know
yet" is a better answer.


On Wed, Nov 13, 2013 at 2:08 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Type the following into your console window:
>
> install.packages("fortunes")
> library(fortunes)
> fortune("brain surgery")
>
> (It's not quite apposite, but close enough).
>
> Cheers,
> Bert
>
>
> On Wed, Nov 13, 2013 at 5:57 AM, Zach Feinstein <zfeinstein at isgmn.com> wrote:
>> I have finally decided that I will learn R and learn it very well. For now I am using a program that a friend of mine developed to do some advanced statistical analyses. I downloaded RStudio to my machine. [Perhaps RStudio is not the best platform to work from -  I have heard that Rattle is sort of the new standard.] I have so far been able to highlight the rows of the code that I wish to run, but then I somehow turned off seeing the output. I also cannot find where I would locate the output window. Yes, frustrated.
>>
>> Would any kind soul be interested in helping kickstart my R learning? I have JoinMe installed on my machine so I figure we can do it interactively. It should not take more than a few minutes. I am already very experienced with both C and VBA languages as well as SPSS syntax so there is not much need to worry about me being too much of a novice.
>>
>> Thank you very much in advance.
>>
>> Zach Feinstein
>> zfeinstein at isgmn.com<mailto:zfeinstein at isgmn.com>
>> (952) 277-0162
>> (612) 590-4813 (mobile)
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drf at vims.edu  Wed Nov 13 20:09:34 2013
From: drf at vims.edu (David R Forrest)
Date: Wed, 13 Nov 2013 19:09:34 +0000
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>,
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
	<DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
Message-ID: <DBD8C8ED-98B0-41DE-9927-FF34C6BE3BD7@vims.edu>

...Additionally...your set of parameters match none of the curves in figure 4.

I think the ordering of the parameters as listed on the graphs is different than in the text of the article.

The 'v' parameter controls the location of the 'elbow' and should be near log(x) in each graph, while the 't' parameter is the sharpness of the elbow.  So eyeballing the elbows:

   log(c(80,150,300))= 4.382027 5.010635 5.703782

These appear to match positional parameter #4 in the legends, which you apply as parameter t in your function.  


# editing your function a bit:

ddpln <- function(x, a=2.5, b=0.01, v=log(100), t=v/10){
  # Density of Double Pareto LogNormal distribution
  # from "b. alzahrani" <cs_2002 at hotmail.com> email of 2013-11-13
  # per formula 8 from http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf

   c <- (a * b /(a+b))

   norm1<-pnorm((log(x)-v-(a*t^2))/t)
   norm2<-pnorm((log(x)-v+(b*t^2))/t)
   expo1<-  a*v+(a^2*t^2/2)
   expo2<- -b*v+(b^2*t^2/2)  # edited from the paper's eqn 8  with: s/t/v/

   z<- (x^(-a-1)) * exp(expo1)*(norm1)
   y<- (x^(b-1))  * exp(expo2)*(1-norm2)  # 1-norm is the complementary CDF of N(0,1)

   c*(z+y)
}

x<-10^seq(0,5,by=0.1) # 0-10k

plot(x,ddpln(x,a=2.8,b=.01,v=3.8,t=0.35),log='xy',type='l')  # Similar to fig 4 left.

plot(x,ddpln(x,a=2.5,b=.01,v=log(2)),log='xy',type='l')
plot(x,ddpln(x,a=2.5,b=.01,v=log(10)),log='xy',type='l')
plot(x,ddpln(x,a=2.5,b=.01,v=log(100)),log='xy',type='l')
plot(x,ddpln(x,a=2.5,b=.01,v=log(1000)),log='xy',type='l')
plot(x,ddpln(x,a=2.5,b=.01,v=log(10000)),log='xy',type='l')

Dave

On Nov 13, 2013, at 11:43 AM, "b. alzahrani" <cs_2002 at hotmail.com>
 wrote:

> 
> Hi
> 
> I found this paper http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf that models the DPLN distribution as in equation 8. I implemented this in R but cannot get the same curve as in Figure 4. can you please check if my code below is correct: e.g. is the use of pnorm() correct here?
> 
> ddlpn <- function(x){
>  a=2.8
>  b=0.01
>  v=0.45
>  t=6.5
>  j <- (a * b /(a+b))
> 
>  norm1<-pnorm((log(x)-v-(a*t^2))/t)
>  expo1<- a*v+(a^2*t^2/2)
> 
>  z<-exp(expo1)*(x^(-a-1))*(norm1)
> 
>  norm2<-pnorm((log(x)-v+(b*t^2))/t)
> expo2<- -b*t+(b^2*t^2/2)
> 
>  y<- x^(b-1)*exp(expo2)*(1-norm2)  # 1-norm is the complementary CDF of N(0,1)
>  j*(z+y)
> }
> ******************************************************************
> Bander Alzahrani, Teacher Assistant
> Information Systems Department
> Faculty of Computing & Information Technology
> King Abdulaziz University
> 
> *************************************
> 
> 
> 
>> From: drf at vims.edu
>> To: cs_2002 at hotmail.com
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Double Pareto Log Normal Distribution
>> Date: Tue, 12 Nov 2013 16:51:22 +0000
>> 
>> 
>> http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf is the original ref and has the equations.
>> 
>> library(VGAM) for *pareto() and library(stats) for *lnorm() should get you most of the way there.
>> 
>> On Nov 12, 2013, at 10:47 AM, "b. alzahrani" <cs_2002 at hotmail.com>
>> wrote:
>> 
>>> Hi guys
>>> I would like to generate random number Double Pareto Log Normal Distribution (DPLN). does anyone know how to do this in R or if there is any built-in function.
>>> 
>>> Thanks
>>> 
>>> ******************************************************************
>>> Bander 
>>> *************************************
>>> 
>>> 
>>> 		 	   		  
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Dr. David Forrest
>> drf at vims.edu
>> 
>> 
>> 
>> 
>> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Dr. David Forrest
drf at vims.edu




-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/37731731/attachment.bin>

From jvadams at usgs.gov  Wed Nov 13 22:10:07 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 13 Nov 2013 15:10:07 -0600
Subject: [R] How to sum a function over a specific range in R?
In-Reply-To: <BLU170-W30E13D8AEFB69C46F3D6A9C9FE0@phx.gbl>
References: <BLU170-W30E13D8AEFB69C46F3D6A9C9FE0@phx.gbl>
Message-ID: <CAN5YmCGP8VmZm5bzWSCXo+jv4yxhBB7m5OgHEAPAuFPWckocNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/147ea4ca/attachment.pl>

From lopez235 at llnl.gov  Wed Nov 13 22:29:35 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Wed, 13 Nov 2013 21:29:35 +0000
Subject: [R] Update a variable in a dataframe based on variables in
 another dataframe of a different size
In-Reply-To: <1384223441.18430.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <56180B40A4F72A4083C75B30DA86297333DAF137@PRDEXMBX-05.the-lab.llnl.gov>
	<1384223441.18430.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DAFE8E@PRDEXMBX-05.the-lab.llnl.gov>

This is a great solution! Love the conciseness of your solution. And easy to understand.

Thanks again.
Dan


-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, November 11, 2013 6:31 PM
To: Lopez, Dan
Subject: Re: [R] Update a variable in a dataframe based on variables in another dataframe of a different size

Hi,
You could use:
H_DF[match(with(T_DF,paste(FY,ID,sep="_")), with(H_DF,paste(FY,ID,sep="_"))),3]<- "TER"
A.K.




On Monday, November 11, 2013 8:51 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Below is how I am currently doing this. Is there a more efficient way to do this?
The scenario is that I have two dataframes of different sizes. I need to update one binary factor variable in one of those dataframes by matching on two variables. If there is no match keep as is otherwise update. Also the variable being update, TT in this case should remain a binary factor variable (levels='HC','TER')

HTDF2<-merge(H_DF,T_DF,by=c("FY","ID"),all.x=T)
HTDF2$TT<-factor(ifelse(is.na(HTDF2$TT.y),HTDF2$TT.x,HTDF2$TT.y),labels=c("HC","TER"))
HTDF2<-HTDF2[,-(3:4)]


# REPRODUCIBLE EXAMPLE DATA FOR ABOVE..
> dput(H_DF)
structure(list(FY = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L, 5L), .Label = c("FY09", "FY10", "FY11", "FY12", "FY13"), class = "factor"),
? ? ID = c(1, 1, 1, 1, 2, 2, 2, 2, 2), TT = structure(c(1L, 1L,
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("HC", "TER"), class = "factor")), .Names = c("FY", "ID", "TT"), class = "data.frame", row.names = c(1L, 2L, 3L, 4L, 6L, 7L, 9L, 10L, 11L))
> dput(T_DF)
structure(list(FY = structure(c(4L, 2L, 5L), .Label = c("FY09", "FY10", "FY11", "FY12", "FY13"), class = "factor"), ID = c(1, 2, 2), TT = structure(c(2L, 2L, 2L), .Label = c("HC", "TER"), class = "factor")), .Names = c("FY", "ID", "TT"), row.names = c(5L, 8L, 12L), class = "data.frame")

Dan Lopez
LLNL, HRIM - Workforce Analytics & Metrics

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From stefan at inizio.se  Wed Nov 13 22:35:35 2013
From: stefan at inizio.se (Stefan Petersson)
Date: Wed, 13 Nov 2013 22:35:35 +0100
Subject: [R] Real frequencies in a 'set' problem
Message-ID: <CAFy6Y8WjP6iOPD7vnDuSgo4VtWGDm5kM0uXPnVG4zu+ggRhU=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/4a726b1a/attachment.pl>

From jim at bitwrit.com.au  Wed Nov 13 22:43:52 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 14 Nov 2013 08:43:52 +1100
Subject: [R] making a barplot with table of experimental conditions
 underneath (preferably ggplot2)
In-Reply-To: <5FF7898BAD1B4A4A809F4C51902634847344670E@UMCEXMBX11.umcn.nl>
References: <5FF7898BAD1B4A4A809F4C51902634847344670E@UMCEXMBX11.umcn.nl>
Message-ID: <5283F298.6090804@bitwrit.com.au>

On 11/14/2013 01:24 AM, N.Hubner at ncmls.ru.nl wrote:
> Dear all,
>
>
>
> my data looks the following:
>
>
>
> df<- data.frame (experiment=c("E1","E2","E3","E4"), mean = c(3,4,5,6), stdev=c(0.1,0.1,0.05,0.2), method = c("STD","STD", "FP", "FP"), enzyme =c ("T","T/L","T","T/L"), denaturation=c("U","U","0.05%RG", "0.1%RG"))
>
>
>
> I would like to make a bar plot with standard deviation which I solved the following way:
>
>
>
> x<- df$experiment
> y<- df$mean
> sd<- df$stdev
>
>
>
> df.plot<- qplot(x,y,xlab="", ylab="# peptides identified")+
>    geom_bar(colour="black", fill="darkgrey")+
>    geom_errorbar(aes(x=x, ymin=y-sd, ymax=y+sd), width=0.25)
>
> df.plot
>
>
>
> However, as the labels for the x-axis (the bars) I do not want the experiment number, as now, but instead a table containing the other columns of my data.frame (method, enzyme, denaturation) with the description in the front and the certain 'value' below the bars.
>
>
>
> I am looking forward to your suggestions!
>
>
>
Hi Nina,
This isn't in ggplot2, but it might help:

library(plotrix)
plotbg<-"rect(0,0,5,7,col=\"lightgray\");grid(col=\"white\",lty=1)"
exp_con<-paste(df$method,df$enzyme,df$denaturation,sep="\n")
barp(df$mean,names.arg=rep("",4),col="darkgray",
  ylab="# peptides identified",do.first=plotbg)
mtext(exp_con,side=1,at=1:4,line=3)
dispersion(1:4,df$mean,df$stdev)

Jim


From dwinsemius at comcast.net  Thu Nov 14 00:09:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 13 Nov 2013 15:09:05 -0800
Subject: [R] Real frequencies in a 'set' problem
In-Reply-To: <CAFy6Y8WjP6iOPD7vnDuSgo4VtWGDm5kM0uXPnVG4zu+ggRhU=g@mail.gmail.com>
References: <CAFy6Y8WjP6iOPD7vnDuSgo4VtWGDm5kM0uXPnVG4zu+ggRhU=g@mail.gmail.com>
Message-ID: <7453FB0B-269A-4B1F-B721-231FAC91F984@comcast.net>


On Nov 13, 2013, at 1:35 PM, Stefan Petersson wrote:

> I have three media channels where I can push public health information (tv,
> radio and newspaper). Any given citizen can be touched by the information
> from one, two or three channels (let's ignore for the moment that citizens
> might miss the information all together). Hence these sets:
> 
> library(sets)
> 
> tv <- set(1, 4, 7, 6)
> radio <- set(6, 7, 5, 2)
> newspaper <- set(4, 7, 5, 3)
> 
> Now I want to know how many citizens that newspapers bring to the complete
> body of informed citizens. E.g. how many people gets the information ONLY
> from a newspaper:
> 
> (tv | radio | t) - (tv | radio)
> 
> But how do I solve this if I know that
> 
> 220 people is reached via tv
> 349 people is reached vi radio
> 384 people is reached via newspaper
> 
> 97 people is reached via tv and radio
> 173 people is reached via radio and newspaper
> 134 people is reached via newspaper and tv
> 
> It's the grey area of the (dummy) plot below that I would like to put a
> frequency in
> 
> library(VennDiagram)
> 
> draw.triple.venn(area1 = 10,
>   area2 = 10,
>   area3 = 10,
>   n12 = 3,
>   n13 = 3,
>   n23 = 3,
>   n123 = 1,
>   category = c('TV', 'Radio', 'Newspaper'),
>   fill = c('white', 'white', 'grey'),
>   alpha = c(1, 1, 0)
> )
> 
> I don't understand how the frequencies that I know is supposed to be used
> in the 'sets' notation. Or am I completely misunderstanding something here?
> Wouldn't be the first time if I did...
> 

Is there any reason for us to think this isn't homework? Have you read the Posting Guide?


> TIA
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Thu Nov 14 00:10:34 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 13 Nov 2013 15:10:34 -0800
Subject: [R] How to sum a function over a specific range in R?
In-Reply-To: <CAN5YmCGP8VmZm5bzWSCXo+jv4yxhBB7m5OgHEAPAuFPWckocNw@mail.gmail.com>
References: <BLU170-W30E13D8AEFB69C46F3D6A9C9FE0@phx.gbl>
	<CAN5YmCGP8VmZm5bzWSCXo+jv4yxhBB7m5OgHEAPAuFPWckocNw@mail.gmail.com>
Message-ID: <CACk-te1J0on=WC1AY71YjGzD6zO1_MuLMWL73aVT-o3VhupwXA@mail.gmail.com>

?filter

perhaps.

-- Bert

On Wed, Nov 13, 2013 at 1:10 PM, Adams, Jean <jvadams at usgs.gov> wrote:
> On Tue, Nov 12, 2013 at 11:45 AM, umair durrani <umairdurrani at outlook.com>wrote:
>
>> I am new to R and have already posted this question on stack overflow. The
>> problem is that I did not understand the answers as the R documentation
>> about the discussed functions (e.g. 'convolve') is quite complicated for a
>> newbie like me. Here's the question:
>> I have a big text file with more than 3 million rows. The following is the
>> example of the three columns I want to use:
>> indx    vehID   LocalY
>> 1   2   35.381
>> 2   2   39.381
>> 3   2   43.381
>> 4   2   47.38
>> 5   2   51.381
>> 6   2   55.381
>> 7   2   59.381
>> 8   2   63.379
>> 9   2   67.383
>> 10  2   71.398
>> where,indx = IndexvehID = Vehicle ID (Here only '2' is shown but infact
>> there are 2169 vehicle IDs and each one repeats several times because the
>> data was collected at every 0.1 seconds)LocalY = The y coordinate of the
>> vehicle at a particular time (The time column is not shown here)
>> What I want to do is to create a new column of 'SmoothedY' using the
>> following formula:
>> SmoothedY = 1/Z * Summation from (i-15) to (i+15) (LocalY *
>> exp(-abs(i-k))/5))
>> where,i = indxZ = Summation from (k =i-15) to (k = i+15) (
>> exp(-abs(i-k))/5))
>> How can I apply this formula to create the new column 'SmoothedY'? This is
>> actually a data smoothing problem but default smoothing algorithms in R are
>> not suitable for my data and I have to use this custom formula.
>> Thanks in advance.
>>
>> Umair Durrani
>>
>
> I have never tried this myself, but it appears as if you can define your
> own smoothing function using Simon Wood's mgcv package.  Check out
> http://www.maths.bath.ac.uk/~sw283/talks/snw-R-talk.pdf for more
> information.
>
> Jean
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From aragorn168b at gmail.com  Thu Nov 14 00:00:00 2013
From: aragorn168b at gmail.com (Arunkumar Srinivasan)
Date: Thu, 14 Nov 2013 00:00:00 +0100
Subject: [R] On "^" returning a matrix when operated on a data.frame
Message-ID: <F8EB6FB495BF4C30912ECBF0E3A53D9C@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/998498e5/attachment.pl>

From Yuanzhi.Li at USherbrooke.ca  Wed Nov 13 23:31:06 2013
From: Yuanzhi.Li at USherbrooke.ca (Yuanzhi Li)
Date: Wed, 13 Nov 2013 17:31:06 -0500
Subject: [R] volume of ellipsoid
Message-ID: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>

Hi, everyone!

I have a matrix X(n*p) which is n samples from a p-dimensional normal  
distribution. Now I want to make the ellipsoid containing (1-?)% of  
the probability in the distribution based on Mahalanobis distance:

?:(x-?)'?^(-1)(x-?)??2p(?)

where x and ? is the mean and variance-covariance matrix of X. Are  
there some functions in R which can plot the ellipsoid and calculate  
the volume (area for p=2, hypervolume for p>3) of the ellipsoid? I  
only find the "ellipsoidhull" function in "cluster" package, but it  
deal with ellipsoid hull containing X, which obvious not the one I want.

After that, a more difficult is the following. If we have a series of  
matrix X1, X2, X3,? Xm which follow different p-dimensional normal  
distributions. And we make m ellipsoids (E1, E2, ? Em) for each matrix  
like the before. How can we calculate the volume of union of the m  
ellipsoids? One possible solution for this problem is the  
inclusion-exclusion principle:

V(?Ei)(1?i?m)=
V(Ei)(1?i?m)-?V(Ei?Ej)(1?i<j?m)+?V(Ei?Ej?Ek)(1?i<j<k?m)+(-1)^(m-1)V(E1???Em)

But the problem is how to calculate the volume of intersection between  
2, 3 or more ellipsoids. Are there some functions which can calculate  
the volume of intersection between two region or functions which  
directly calculate the volume of a union of two region(the region here  
is ellipsoid). OR yo you have any good ideas solving this problem in  
R? Thank you all in advance!

Yuanzhi


From efb at usal.es  Wed Nov 13 22:45:31 2013
From: efb at usal.es (Elisa Frutos Bernal)
Date: Wed, 13 Nov 2013 22:45:31 +0100
Subject: [R] (sin asunto)
Message-ID: <cf75e11ca19d0502c028f2ac0c2ad1c2.squirrel@correo.usal.es>

Hi!

I need to print a graph that I have in a window. Previously I used:

try(win.print(), silent = TRUE)
        if (geterrmessage() != "Error in win.print() : unable to start
device devWindows\n") {
            plotFunctiond(screen = FALSE)
            dev.off()

but now it is not possible.
Can you help me?


-- 
Elisa.


From murdoch.duncan at gmail.com  Thu Nov 14 00:32:34 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Nov 2013 18:32:34 -0500
Subject: [R] On "^" returning a matrix when operated on a data.frame
In-Reply-To: <F8EB6FB495BF4C30912ECBF0E3A53D9C@gmail.com>
References: <F8EB6FB495BF4C30912ECBF0E3A53D9C@gmail.com>
Message-ID: <52840C12.2010604@gmail.com>

On 13-11-13 6:00 PM, Arunkumar Srinivasan wrote:
> Dear R-users,
>
> I am wondering why "^" operator alone returns a matrix, when operated on a data.frame (as opposed to all other arithmetic operators). Here's an example:
>
> DF <- data.frame(x=1:5, y=6:10)
> class(DF*DF) # [1] data.frame
> class(DF^2) # [1] matrix
>
> I posted here on SO: http://stackoverflow.com/questions/19964897/why-does-on-a-data-frame-return-a-matrix-instead-of-a-data-frame-like-do and got a very nice answer - it happens because a matrix is returned (obvious by looking at `Ops.data.frame`). However, what I'd like to understand is, *why* a matrix is returned for "^" alone? Here's an excerpt from Ops.data.frame (Thanks to Neal Fultz):
>
> if (.Generic %in% c("+", "-", "*", "/", "%%", "%/%")) {
>      names(value) <- cn
>      data.frame(value, row.names = rn, check.names = FALSE,
>          check.rows = FALSE)
> }
> else matrix(unlist(value, recursive = FALSE, use.names = FALSE),
>      nrow = nr, dimnames = list(rn, cn))
>
>
> It's clear that a matrix will be returned unless `.Generic` is one of those arithmetic operators. My question therefore is, is there any particular reason why "^" operator is being missed in the if-statement here? I can't think of a reason where this would break. Also ?`^` doesn't seem to mention anything about this coercion.

It's not just ^ that is missing, the logical relations like <, ==, etc 
also return matrices.  This is very old code (I think from 1999), but I 
would guess that the reason is that the ^ and < operators always return 
values of a single type (numeric and logical respectively), whereas the 
other operators can take mixed type inputs and return mixed type outputs.

Duncan Murdoch

> Please let me know if I should be posting this to R-devel list instead.
>
> Thank you very much,
> Arun
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aragorn168b at gmail.com  Thu Nov 14 00:52:32 2013
From: aragorn168b at gmail.com (Arunkumar Srinivasan)
Date: Thu, 14 Nov 2013 00:52:32 +0100
Subject: [R] On "^" returning a matrix when operated on a data.frame
In-Reply-To: <52840C12.2010604@gmail.com>
References: <F8EB6FB495BF4C30912ECBF0E3A53D9C@gmail.com>
	<52840C12.2010604@gmail.com>
Message-ID: <D0C9926AC53C4DCB98A8AEC5915BE0DB@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/de3c5b7c/attachment.pl>

From murdoch.duncan at gmail.com  Thu Nov 14 01:17:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Nov 2013 19:17:23 -0500
Subject: [R] On "^" returning a matrix when operated on a data.frame
In-Reply-To: <D0C9926AC53C4DCB98A8AEC5915BE0DB@gmail.com>
References: <F8EB6FB495BF4C30912ECBF0E3A53D9C@gmail.com>
	<52840C12.2010604@gmail.com>
	<D0C9926AC53C4DCB98A8AEC5915BE0DB@gmail.com>
Message-ID: <52841693.6060304@gmail.com>

On 13-11-13 6:52 PM, Arunkumar Srinivasan wrote:
> Duncan,
> Thank you. What I meant was that "^" is the only *arithmetic operator*
> to result in a matrix on operating in a data.frame. I understand it's
> quite old code. Also, your explanation makes sense, with the exception
> of "/" operator, I suppose (I could be wrong here).

You're right, "/", "%/%" and "%%" also return consistent types.  So my 
explanation is wrong.  The NEWS entry for this change appears to be in 
the 0.63 release,

     o	Ops.data.frame :  things like  d.fr < a	  now return a matrix

That doesn't give much of a hint for why "^" is handled differently than 
"/".

Duncan Murdoch

> Arun
>
> On Thursday, November 14, 2013 at 12:32 AM, Duncan Murdoch wrote:
>
>>
>> It's not just ^ that is missing, the logical relations like <, ==, etc
>> also return matrices. This is very old code (I think from 1999), but I
>> would guess that the reason is that the ^ and < operators always return
>> values of a single type (numeric and logical respectively), whereas the
>> other operators can take mixed type inputs and return mixed type outputs.
>>
>> Duncan Murdoch
>>
>>> Please let me know if I should be posting this to R-devel list instead.
>>>
>>> Thank you very much,
>>> Arun
>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Thu Nov 14 01:58:04 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 14 Nov 2013 00:58:04 +0000
Subject: [R] Update a variable in a dataframe based on variables in
 another dataframe of a different size
In-Reply-To: <CAP01uRnBoRAWm_GFGfg6BJ5yVNFkxRSNYFEBgqzuxfXQRqwOYA@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D560EA2@PRDEXMBX-08.the-lab.llnl.gov>

Dan,

Gabor's solution is of course good, but here's a solution that uses only
base R capabilities, and doesn't sort as merge() does. Essentially the
same as A.K.'s, but slightly more general.

tmp1 <- match( paste(T_DF$FY,T_DF$ID) , paste(H_DF$FY,H_DF$ID) )
H_DF$TT[tmp1] <- T_DF$TT

gg <- sqldf("select FY, ID, coalesce(t.TT, h.TT) TT from H_DF h left join
T_DF t using(FY, ID)")

> for (nm in names(H_DF)) print(all.equal(H_DF[[nm]], gg[[nm]]))
[1] TRUE
[1] TRUE
[1] TRUE


It could be made into a one-liner.It would probably break if TT doesn't
have the same factor levels in both H_DF and T_DF.

As an aside, I suspect that nowadays match() is generally
under-appreciated among R users as a whole.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/11/13 5:20 PM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:

>On Mon, Nov 11, 2013 at 8:04 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
>> Below is how I am currently doing this. Is there a more efficient way
>>to do this?
>> The scenario is that I have two dataframes of different sizes. I need
>>to update one binary factor variable in one of those dataframes by
>>matching on two variables. If there is no match keep as is otherwise
>>update. Also the variable being update, TT in this case should remain a
>>binary factor variable (levels='HC','TER')
>>
>> HTDF2<-merge(H_DF,T_DF,by=c("FY","ID"),all.x=T)
>> 
>>HTDF2$TT<-factor(ifelse(is.na(HTDF2$TT.y),HTDF2$TT.x,HTDF2$TT.y),labels=c
>>("HC","TER"))
>> HTDF2<-HTDF2[,-(3:4)]
>>
>>
>> # REPRODUCIBLE EXAMPLE DATA FOR ABOVE..
>>> dput(H_DF)
>> structure(list(FY = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,
>> 5L), .Label = c("FY09", "FY10", "FY11", "FY12", "FY13"), class =
>>"factor"),
>>     ID = c(1, 1, 1, 1, 2, 2, 2, 2, 2), TT = structure(c(1L, 1L,
>>     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("HC", "TER"), class =
>>"factor")), .Names = c("FY",
>> "ID", "TT"), class = "data.frame", row.names = c(1L, 2L, 3L,
>> 4L, 6L, 7L, 9L, 10L, 11L))
>>> dput(T_DF)
>> structure(list(FY = structure(c(4L, 2L, 5L), .Label = c("FY09",
>> "FY10", "FY11", "FY12", "FY13"), class = "factor"), ID = c(1,
>> 2, 2), TT = structure(c(2L, 2L, 2L), .Label = c("HC", "TER"), class =
>>"factor")), .Names = c("FY",
>> "ID", "TT"), row.names = c(5L, 8L, 12L), class = "data.frame")
>>
>
>Here is an sqldf solution:
>
>> library(sqldf)
>> sqldf("select FY, ID, coalesce(t.TT, h.TT) TT from H_DF h left join
>>T_DF t using(FY, ID)")
>    FY ID  TT
>1 FY09  1  HC
>2 FY10  1  HC
>3 FY11  1  HC
>4 FY12  1 TER
>5 FY09  2  HC
>6 FY10  2 TER
>7 FY11  2  HC
>8 FY12  2  HC
>9 FY13  2 TER
>
>
>-- 
>Statistics & Software Consulting
>GKX Group, GKX Associates Inc.
>tel: 1-877-GKX-GROUP
>email: ggrothendieck at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim.silverton at gmail.com  Thu Nov 14 01:58:30 2013
From: jim.silverton at gmail.com (Jim Silverton)
Date: Wed, 13 Nov 2013 20:58:30 -0400
Subject: [R] Analysis
Message-ID: <CAGPwjHyWAH+UWhhsfJFT_Yvz6tmg7Ssh_5m-BsmLCr9RYoPWPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/39853ccd/attachment.pl>

From markseeto at gmail.com  Thu Nov 14 03:11:42 2013
From: markseeto at gmail.com (Mark Seeto)
Date: Thu, 14 Nov 2013 13:11:42 +1100
Subject: [R] oblique.scores argument for fa function in psych package
Message-ID: <CAK2mLtMqTE-XNEqc2OOAtX23RUVhJXhAbSm0JuKEixWMXznk-A@mail.gmail.com>

Dear R help,

I'm using version 1.3.10.12 of the psych package. The help page for fa
says that when calculating factor scores, oblique.scores=FALSE causes
the pattern matrix to be used, and oblique.scores=TRUE causes the
structure matrix to be used. However, when I try it, it seems to be
the other way around.

Example:

###############################################################################
library(psych)

set.seed(1)

n <- 100

Y <- data.frame(y1 = rnorm(n),
                y2 = rnorm(n),
                y3 = rnorm(n),
                y4 = rnorm(n),
                y5 = rnorm(n),
                y6 = rnorm(n))

fa1 <- fa(Y, nfactors=2, rotate="oblimin", fm="minres", oblique.scores=FALSE)
fa2 <- fa(Y, nfactors=2, rotate="oblimin", fm="minres", oblique.scores=TRUE)

fa1$scores[1:3, ]
fa2$scores[1:3, ]

(scale(Y) %*% solve(cor(Y)) %*% fa1$loadings)[1:3, ]   # not the same
as fa1$scores[1:3, ]
(scale(Y) %*% solve(cor(Y)) %*% fa1$Structure)[1:3, ]  # same as
fa1$scores[1:3, ]

(scale(Y) %*% solve(cor(Y)) %*% fa2$loadings)[1:3, ]   # same as
fa2$scores[1:3, ]
(scale(Y) %*% solve(cor(Y)) %*% fa2$Structure)[1:3, ]  # not the same
as fa2$scores[1:3, ]

###############################################################################

Have I misunderstood something?

Thanks,
Mark Seeto


From msuzen at gmail.com  Thu Nov 14 03:21:07 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 14 Nov 2013 03:21:07 +0100
Subject: [R] Fitting arbitrary curve to 1D data with error bars
In-Reply-To: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>
References: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>
Message-ID: <CAPtbhHyCzMfHGPhM1awnTo7s5EQOJg9B68n6=YUh4Wog+i07Ww@mail.gmail.com>

If you are after adding error bars in a scatter plot; one example is
given below :

#some example data
set.seed(42)
df <- data.frame(x = rep(1:10,each=5), y = rnorm(50))

#calculate mean, min and max for each x-value
library(plyr)
df2 <- ddply(df,.(x),function(df)
c(mean=mean(df$y),min=min(df$y),max=max(df$y)))

#plot error bars
library(Hmisc)
with(df2,errbar(x,mean,max,min))
grid(nx=NA,ny=NULL)

(From: http://stackoverflow.com/questions/13032777/scatter-plot-with-error-bars)


From maitra.mbox.ignored at inbox.com  Thu Nov 14 03:40:00 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Wed, 13 Nov 2013 20:40:00 -0600
Subject: [R] Analysis
In-Reply-To: <CAGPwjHyWAH+UWhhsfJFT_Yvz6tmg7Ssh_5m-BsmLCr9RYoPWPQ@mail.gmail.com>
References: <CAGPwjHyWAH+UWhhsfJFT_Yvz6tmg7Ssh_5m-BsmLCr9RYoPWPQ@mail.gmail.com>
Message-ID: <20131113204000.5df9e638054552c739b545ff@inbox.com>

Don't know if the data will support the result that you want but the
only way to get some sort of answer is to hire a statistician.

ranjan

On Wed, 13 Nov 2013 20:58:30 -0400 Jim Silverton
<jim.silverton at gmail.com> wrote:

> Hi,
> 
> 
> 
> I have 187 urine cultures which were subjected to culture and microscopy
> methods. Video were used to 'verify' the findings. Culture is considered
> the gold method. But Microscopy is another method which may be cheaper. I
> checked the videos to determine whether bacteria was growing on both the
> culture and microscopy readings to ' verify' what was really happening.
> 
> My question is this...How can I show that Microscopy is superior?
> Is there a special test available?
> 
> 
> 
>      *Microscopy*        *Positive* *Negative*    *Culture Positive* *Video
> Positive* *47* *5* *52*  Video Negative 0 *2* *2*  *Culture Negative* Video
> Positive  18 *0* *18*  *Video Negative* *5* *110* *115*      *70* *117*
> *187*
> 
> 
> 
> 
> 
> 
> 
> 
> 
> -- 
> Thanks,
> Jim.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From smartpink111 at yahoo.com  Thu Nov 14 04:11:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 13 Nov 2013 19:11:35 -0800 (PST)
Subject: [R] Update a variable in a dataframe based on variables in
	another dataframe of a different size
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D560EA2@PRDEXMBX-08.the-lab.llnl.gov>
References: <CAP01uRnBoRAWm_GFGfg6BJ5yVNFkxRSNYFEBgqzuxfXQRqwOYA@mail.gmail.com>
	<5E1B812FAC2C4A49B3D99593B5A521910D560EA2@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <1384398695.28645.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Don,

In cases like:
H_DF <- H_DF[-4,]
tmp1 <- match( paste(T_DF$FY,T_DF$ID) , paste(H_DF$FY,H_DF$ID) )

?H_DF$TT[tmp1] <- T_DF$TT 
#Error in `[<-.factor`(`*tmp*`, tmp1, value = c(2L, 2L, 2L)) : 

Probably, this works:
H_DF$TT[tmp1[!is.na(tmp1)]] <- unique(T_DF$TT) 
A.K.




On Wednesday, November 13, 2013 7:59 PM, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
Dan,

Gabor's solution is of course good, but here's a solution that uses only
base R capabilities, and doesn't sort as merge() does. Essentially the
same as A.K.'s, but slightly more general.

tmp1 <- match( paste(T_DF$FY,T_DF$ID) , paste(H_DF$FY,H_DF$ID) )
H_DF$TT[tmp1] <- T_DF$TT

gg <- sqldf("select FY, ID, coalesce(t.TT, h.TT) TT from H_DF h left join
T_DF t using(FY, ID)")

> for (nm in names(H_DF)) print(all.equal(H_DF[[nm]], gg[[nm]]))
[1] TRUE
[1] TRUE
[1] TRUE


It could be made into a one-liner.It would probably break if TT doesn't
have the same factor levels in both H_DF and T_DF.

As an aside, I suspect that nowadays match() is generally
under-appreciated among R users as a whole.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/11/13 5:20 PM, "Gabor Grothendieck" <ggrothendieck at gmail.com> wrote:

>On Mon, Nov 11, 2013 at 8:04 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
>> Below is how I am currently doing this. Is there a more efficient way
>>to do this?
>> The scenario is that I have two dataframes of different sizes. I need
>>to update one binary factor variable in one of those dataframes by
>>matching on two variables. If there is no match keep as is otherwise
>>update. Also the variable being update, TT in this case should remain a
>>binary factor variable (levels='HC','TER')
>>
>> HTDF2<-merge(H_DF,T_DF,by=c("FY","ID"),all.x=T)
>> 
>>HTDF2$TT<-factor(ifelse(is.na(HTDF2$TT.y),HTDF2$TT.x,HTDF2$TT.y),labels=c
>>("HC","TER"))
>> HTDF2<-HTDF2[,-(3:4)]
>>
>>
>> # REPRODUCIBLE EXAMPLE DATA FOR ABOVE..
>>> dput(H_DF)
>> structure(list(FY = structure(c(1L, 2L, 3L, 4L, 1L, 2L, 3L, 4L,
>> 5L), .Label = c("FY09", "FY10", "FY11", "FY12", "FY13"), class =
>>"factor"),
>>? ?  ID = c(1, 1, 1, 1, 2, 2, 2, 2, 2), TT = structure(c(1L, 1L,
>>? ?  1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("HC", "TER"), class =
>>"factor")), .Names = c("FY",
>> "ID", "TT"), class = "data.frame", row.names = c(1L, 2L, 3L,
>> 4L, 6L, 7L, 9L, 10L, 11L))
>>> dput(T_DF)
>> structure(list(FY = structure(c(4L, 2L, 5L), .Label = c("FY09",
>> "FY10", "FY11", "FY12", "FY13"), class = "factor"), ID = c(1,
>> 2, 2), TT = structure(c(2L, 2L, 2L), .Label = c("HC", "TER"), class =
>>"factor")), .Names = c("FY",
>> "ID", "TT"), row.names = c(5L, 8L, 12L), class = "data.frame")
>>
>
>Here is an sqldf solution:
>
>> library(sqldf)
>> sqldf("select FY, ID, coalesce(t.TT, h.TT) TT from H_DF h left join
>>T_DF t using(FY, ID)")
>? ? FY ID? TT
>1 FY09? 1? HC
>2 FY10? 1? HC
>3 FY11? 1? HC
>4 FY12? 1 TER
>5 FY09? 2? HC
>6 FY10? 2 TER
>7 FY11? 2? HC
>8 FY12? 2? HC
>9 FY13? 2 TER
>
>
>-- 
>Statistics & Software Consulting
>GKX Group, GKX Associates Inc.
>tel: 1-877-GKX-GROUP
>email: ggrothendieck at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ishaqbaba at yahoo.com  Thu Nov 14 04:37:22 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Wed, 13 Nov 2013 19:37:22 -0800 (PST)
Subject: [R] MM estmator
Message-ID: <1384400242.93139.YahooMailNeo@web142501.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/087862d0/attachment.pl>

From dilaradi21 at gmail.com  Thu Nov 14 06:02:31 2013
From: dilaradi21 at gmail.com (dila radi)
Date: Wed, 13 Nov 2013 21:02:31 -0800
Subject: [R] Replace NA's with value in the next row
Message-ID: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131113/09a22f44/attachment.pl>

From szehnder at uni-bonn.de  Thu Nov 14 08:52:16 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 14 Nov 2013 08:52:16 +0100
Subject: [R] MM estmator
In-Reply-To: <1384400242.93139.YahooMailNeo@web142501.mail.bf1.yahoo.com>
References: <1384400242.93139.YahooMailNeo@web142501.mail.bf1.yahoo.com>
Message-ID: <8B2389BC-48CA-45D5-A834-C8C1C845C6B5@uni-bonn.de>

Check the gmm package with a weighting matrix equal to the identity.

Best

Simon
 
On 14 Nov 2013, at 04:37, IZHAK shabsogh <ishaqbaba at yahoo.com> wrote:

> hi
> 
> I have a nonlinear regression model with two parameter, i have estimated using nls in R
> and i want to also find the estimate using MM, someone refer me to this function nlrob
> but this is main for only M estimate. can you please help me findout  a function in R for MM nonlinear regression
> 
> thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Thu Nov 14 09:02:06 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 14 Nov 2013 19:02:06 +1100
Subject: [R] Replace NA's with value in the next row
In-Reply-To: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>
References: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>
Message-ID: <5284837E.2080805@bitwrit.com.au>

On 11/14/2013 04:02 PM, dila radi wrote:
> Hi all,
>
> I have a data set which treat missing value as NA and now I need to replace
> all these NA's by using number in the same row but different column.
>
> Here is the part of my data:
>   V1 V2 V3 V4 V5 V6 V7  0 0 0 1.2 0 0 0.259  0 0 12.8 0 23.7 0 8.495  6 0
> 81.7 0.2 0 20 19.937  0 1.5 60.9 0 0 15.5 13.900  1 13 56.8 17.5 32.8 6.4
> 27.654  4 3 66.4 2 0.3 NA 17.145
>
>
> I want to replace (V6, 6) with (V7, 6). I have about 1000 NA's in V6 which
> I want to replace  with the same row in V7. The other values in V6, I want
> to keep remain the same.
>
> How to achieve this? Assuming my data is called "Targetstation",  I have
> tried this:
>
> Targetstation<- within(Targetstation, v6<- replace(v6, is.na(v6), v7[is.na
> (v6)]))
>
> But R gives me this:
>
> Warning messages:
>
> 1: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'
>
> 2: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'
>
>
Hi Dila,
You could do this like this:

V6NA<-is.na(Targetstation$V6)
Targetstation$V6[V6NA]<-Targetstation$V7[V6NA]

but if you want to use the above, I think you will have to replace the 
is.na(V6) with is.na(Targetstation$V6) or use the method above.

Jim


From erkcan at hotmail.com  Thu Nov 14 10:01:41 2013
From: erkcan at hotmail.com (=?iso-8859-1?Q?Erkcan_=D6zcan?=)
Date: Thu, 14 Nov 2013 11:01:41 +0200
Subject: [R] Fitting arbitrary curve to 1D data with error bars
In-Reply-To: <CAPtbhHyCzMfHGPhM1awnTo7s5EQOJg9B68n6=YUh4Wog+i07Ww@mail.gmail.com>
References: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>
	<CAPtbhHyCzMfHGPhM1awnTo7s5EQOJg9B68n6=YUh4Wog+i07Ww@mail.gmail.com>
Message-ID: <BLU0-SMTP18773F73AC0865EBCE0E4AEDFF80@phx.gbl>

Thanks, but if you have another closer look to my post, you will see that my question has nothing to do with drawing error bars on a plot.

What I want is to do a curve fit to a data with error bars.

Best,
e.

On 14 Nov 2013, at 04:21, Suzen, Mehmet wrote:

> If you are after adding error bars in a scatter plot; one example is
> given below :
> 
> #some example data
> set.seed(42)
> df <- data.frame(x = rep(1:10,each=5), y = rnorm(50))
> 
> #calculate mean, min and max for each x-value
> library(plyr)
> df2 <- ddply(df,.(x),function(df)
> c(mean=mean(df$y),min=min(df$y),max=max(df$y)))
> 
> #plot error bars
> library(Hmisc)
> with(df2,errbar(x,mean,max,min))
> grid(nx=NA,ny=NULL)
> 
> (From: http://stackoverflow.com/questions/13032777/scatter-plot-with-error-bars)
> 


From msuzen at gmail.com  Thu Nov 14 10:34:22 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 14 Nov 2013 10:34:22 +0100
Subject: [R] Fitting arbitrary curve to 1D data with error bars
In-Reply-To: <BLU0-SMTP18773F73AC0865EBCE0E4AEDFF80@phx.gbl>
References: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>
	<CAPtbhHyCzMfHGPhM1awnTo7s5EQOJg9B68n6=YUh4Wog+i07Ww@mail.gmail.com>
	<BLU0-SMTP18773F73AC0865EBCE0E4AEDFF80@phx.gbl>
Message-ID: <CAPtbhHwTzpnD-jVksDJROYraLOpqDw3tWta88M-+_d=DMTf7ag@mail.gmail.com>

Maybe you are after "weights" option given by 'lm' or 'glm'

See: http://stackoverflow.com/questions/6375650/function-for-weighted-least-squares-estimates

On 14 November 2013 10:01, Erkcan ?zcan <erkcan at hotmail.com> wrote:
> Thanks, but if you have another closer look to my post, you will see that my question has nothing to do with drawing error bars on a plot.
>
> What I want is to do a curve fit to a data with error bars.
>
> Best,
> e.
>
> On 14 Nov 2013, at 04:21, Suzen, Mehmet wrote:
>
>> If you are after adding error bars in a scatter plot; one example is
>> given below :
>>
>> #some example data
>> set.seed(42)
>> df <- data.frame(x = rep(1:10,each=5), y = rnorm(50))
>>
>> #calculate mean, min and max for each x-value
>> library(plyr)
>> df2 <- ddply(df,.(x),function(df)
>> c(mean=mean(df$y),min=min(df$y),max=max(df$y)))
>>
>> #plot error bars
>> library(Hmisc)
>> with(df2,errbar(x,mean,max,min))
>> grid(nx=NA,ny=NULL)
>>
>> (From: http://stackoverflow.com/questions/13032777/scatter-plot-with-error-bars)
>>
>


From olivier.peron at univ-pau.fr  Thu Nov 14 11:28:23 2013
From: olivier.peron at univ-pau.fr (peron)
Date: Thu, 14 Nov 2013 11:28:23 +0100
Subject: [R] Transform aggregated data to individual data
Message-ID: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/5d9e3238/attachment.pl>

From jim at bitwrit.com.au  Thu Nov 14 12:03:37 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 14 Nov 2013 22:03:37 +1100
Subject: [R] Transform aggregated data to individual data
In-Reply-To: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>
References: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>
Message-ID: <5284AE09.4060901@bitwrit.com.au>

On 11/14/2013 09:28 PM, peron wrote:
> Hello
>
>
>
> I have data in following form : 100 ind describe by two variables x and y.
>
>
>
> D<-data .frame( x=rnorm(3), y=rnorm(3), size=c(50,10,40))
>
>
>
> I want data for individual, i.e, 100 observations for my 100 ind.
>
Hi Olivier,
 From the above, it seems you have three values for the three groups. If 
you try:

df100<-data.frame(x=rep(D$x,D$size),y=rep(D$y,D$size))

You will get what you request, if the values are the same for all 
members of each group. I suspect that those three values may be means or 
some other summary measure.

Jim


From ligges at statistik.tu-dortmund.de  Thu Nov 14 12:26:08 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 14 Nov 2013 12:26:08 +0100
Subject: [R] Printing from windows device; was:  (sin asunto)
In-Reply-To: <cf75e11ca19d0502c028f2ac0c2ad1c2.squirrel@correo.usal.es>
References: <cf75e11ca19d0502c028f2ac0c2ad1c2.squirrel@correo.usal.es>
Message-ID: <5284B350.7070505@statistik.tu-dortmund.de>



On 13.11.2013 22:45, Elisa Frutos Bernal wrote:
> Hi!
>
> I need to print a graph that I have in a window. Previously I used:
>
> try(win.print(), silent = TRUE)
>          if (geterrmessage() != "Error in win.print() : unable to start
> device devWindows\n") {
>              plotFunctiond(screen = FALSE)
>              dev.off()
>
> but now it is not possible.
> Can you help me?

No, since I do not know what
plotFunctiond()
does.

Please use a sensible subject line.

Best,
Uwe Ligges


From carl at witthoft.com  Thu Nov 14 13:25:26 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 14 Nov 2013 04:25:26 -0800 (PST)
Subject: [R] volume of ellipsoid
In-Reply-To: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>
Message-ID: <1384431926676-4680435.post@n4.nabble.com>

Well, given that an upvoted question on math.stackexchange got no answers,
I'd say you're asking a very difficult question.   Perhaps this paper  
http://www.geometrictools.com/Documentation/IntersectionOfEllipsoids.pdf

will be of some help.   It's possible that you could do:
1) find the ellipse of intersection of the two ellipsoids
2) find some formula for the equivalent of the "spherical cap" volume
3) apply that formula to each ellipsoid, using the intersection ellipse as
the base of the caps.

All this, btw, is math,  not really related to R or to software programming
in general.


yuanzhi wrote
> Hi, everyone!
> 
> I have a matrix X(n*p) which is n samples from a p-dimensional normal  
> distribution. Now I want to make the ellipsoid containing (1-?)% of  
> the probability in the distribution based on Mahalanobis distance:
> 
> ?:(x-?)'?^(-1)(x-?)??2p(?)
> 
> where x and ? is the mean and variance-covariance matrix of X. Are  
> there some functions in R which can plot the ellipsoid and calculate  
> the volume (area for p=2, hypervolume for p>3) of the ellipsoid? I  
> only find the "ellipsoidhull" function in "cluster" package, but it  
> deal with ellipsoid hull containing X, which obvious not the one I want.
> 
> After that, a more difficult is the following. If we have a series of  
> matrix X1, X2, X3,? Xm which follow different p-dimensional normal  
> distributions. And we make m ellipsoids (E1, E2, ? Em) for each matrix  
> like the before. How can we calculate the volume of union of the m  
> ellipsoids? One possible solution for this problem is the  
> inclusion-exclusion principle:
> 
> V(?Ei)(1?i?m)=
> V(Ei)(1?i?m)-?V(Ei?Ej)(1?i&lt;j?m)+?V(Ei?Ej?Ek)(1?i&lt;j&lt;k?m)+(-1)^(m-1)V(E1???Em)
> 
> But the problem is how to calculate the volume of intersection between  
> 2, 3 or more ellipsoids. Are there some functions which can calculate  
> the volume of intersection between two region or functions which  
> directly calculate the volume of a union of two region(the region here  
> is ellipsoid). OR yo you have any good ideas solving this problem in  
> R? Thank you all in advance!
> 
> Yuanzhi
> 
> ______________________________________________
> &lt;email&gt;R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/volume-of-ellipsoid-tp4680409p4680435.html
Sent from the R help mailing list archive at Nabble.com.


From frans.marcelissen at digipsy.nl  Thu Nov 14 10:13:05 2013
From: frans.marcelissen at digipsy.nl (Frans Marcelissen)
Date: Thu, 14 Nov 2013 10:13:05 +0100
Subject: [R] Replace NA's with value in the next row
In-Reply-To: <5284837E.2080805@bitwrit.com.au>
References: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>
	<5284837E.2080805@bitwrit.com.au>
Message-ID: <CAFFQM6ayLxTY5zJnsyEdizUizfXt6taa3+Gm7=ptEXRWo=N-hQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/01c710c1/attachment.pl>

From hnorpois at gmail.com  Thu Nov 14 09:41:36 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 14 Nov 2013 09:41:36 +0100
Subject: [R] From list to dataframe
Message-ID: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/8a4ecb8c/attachment.pl>

From tstudent at gmail.com  Thu Nov 14 09:26:10 2013
From: tstudent at gmail.com (Tstudent)
Date: Thu, 14 Nov 2013 08:26:10 +0000
Subject: [R] xts objects comparison
Message-ID: <loom.20131114T091602-703@post.gmane.org>

I have the following two xts object:

https://dl.dropboxusercontent.com/u/102669/series1.rdata

https://dl.dropboxusercontent.com/u/102669/series2.rdata

With str i see that they are both xts objects

I can't understand why it's impossible to compare each element.

For example: series1 > series2
Why i don't get an xts object with a sequence of true and false?


From master at iaas.msu.ru  Thu Nov 14 12:24:49 2013
From: master at iaas.msu.ru (Michail Vidiassov)
Date: Thu, 14 Nov 2013 15:24:49 +0400
Subject: [R] beta package for 3D PDF output
Message-ID: <CALDha9PCwYQUEWV_wWiKq5q8BYAqfJgDpVG02v9v7cmt-dd79A@mail.gmail.com>

Dear All,

recent desktop versions of Adobe Acrobat and Adobe Reader have
built-in support for 3D models in PDF.

You can take a look at http://www.pdf3d.com/gallery.php for a gallery
of professional results achieved with a commercial tool.

For an overview of what 3D PDF can be used for I (naturally) suggest the article
http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0069446 .

To bring together 3D PDF and R, I have enhanced "rgl" package with
necessary output routine, so you draw something in 3D using rgl and
after that say "save it as 3D PDF".
The resulting 3D PDF model can be used standalone or in your LaTeX document.

The source code of the package and demo output are at
http://www2.iaas.msu.ru/tmp/u3d/rgl/

I have successfully compiled and run my package on Mac OS 10.9 64bit,
Windows XP 32 bit, Ubuntu 13.04 i686  and 13.10 ppc, Fedora 18 64bit,
but received a crash report in undisclosed Linux environment on some
CRAN test platform.

Testers welcome, feel free to e-mail me if necessary (by the time
search finds you this post I may be off the list).

Sincerely, Michail


From rsjreddy1341946 at yahoo.co.in  Thu Nov 14 14:15:42 2013
From: rsjreddy1341946 at yahoo.co.in (sarvajannnadha reddy)
Date: Thu, 14 Nov 2013 21:15:42 +0800 (SGT)
Subject: [R] Fw: Lower 'Pi' 3.1415926... and Exact 'Pi' and Squaring of
	Circle
In-Reply-To: <1384410180.88054.YahooMailNeo@web192801.mail.sg3.yahoo.com>
References: <1384267308.60765.YahooMailNeo@web192805.mail.sg3.yahoo.com>
	<1384267420.94249.YahooMailNeo@web192801.mail.sg3.yahoo.com>
	<1384321763.36346.YahooMailNeo@web192802.mail.sg3.yahoo.com>
	<1384324477.18307.YahooMailNeo@web192805.mail.sg3.yahoo.com>
	<1384350489.22779.YahooMailNeo@web192803.mail.sg3.yahoo.com>
	<1384410180.88054.YahooMailNeo@web192801.mail.sg3.yahoo.com>
Message-ID: <1384434942.14820.YahooMailNeo@web192802.mail.sg3.yahoo.com>


From djandrija at gmail.com  Thu Nov 14 14:30:21 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Thu, 14 Nov 2013 14:30:21 +0100
Subject: [R] From list to dataframe
In-Reply-To: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>
References: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>
Message-ID: <CABcwgRROheoCS33xDarV5oNHGiPk1ybZ68ru=hCKqiDB3DEJ6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/6ff3d8fb/attachment.pl>

From jvadams at usgs.gov  Thu Nov 14 15:16:04 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 14 Nov 2013 08:16:04 -0600
Subject: [R] How to sum a function over a specific range in R?
In-Reply-To: <BLU170-W4090CFB19D56D1B1330E9DC9F90@phx.gbl>
References: <BLU170-W30E13D8AEFB69C46F3D6A9C9FE0@phx.gbl>
	<CAN5YmCGP8VmZm5bzWSCXo+jv4yxhBB7m5OgHEAPAuFPWckocNw@mail.gmail.com>
	<BLU170-W4090CFB19D56D1B1330E9DC9F90@phx.gbl>
Message-ID: <CAN5YmCGJuoY0S-28AXCsM0hOXTOJ-8M9WikDkXdT0Zma_ieJzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/59904ccf/attachment.pl>

From josh.m.ulrich at gmail.com  Thu Nov 14 15:26:46 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 14 Nov 2013 08:26:46 -0600
Subject: [R] xts objects comparison
In-Reply-To: <loom.20131114T091602-703@post.gmane.org>
References: <loom.20131114T091602-703@post.gmane.org>
Message-ID: <CAPPM_gT9BCnz+RZ0d8JYHCTQabuw46Oo9uM=pNFPJ2k4BxWrYA@mail.gmail.com>

On Thu, Nov 14, 2013 at 2:26 AM, Tstudent <tstudent at gmail.com> wrote:
> I have the following two xts object:
>
> https://dl.dropboxusercontent.com/u/102669/series1.rdata
>
> https://dl.dropboxusercontent.com/u/102669/series2.rdata
>
> With str i see that they are both xts objects
>
> I can't understand why it's impossible to compare each element.
>
> For example: series1 > series2
> Why i don't get an xts object with a sequence of true and false?
>
Because series1 has a POSIXct index and series2 has a yearmon index.
The two objects have no index values in common, so there's nothing to
compare.

Convert series1's index to yearmon, and the comparison works.

> index(series1) <- as.yearmon(index(series1))
> tail(series1 > series2)
           GSPC
2013-06-01 TRUE
2013-07-01 TRUE
2013-08-01 TRUE
2013-09-01 TRUE
2013-10-01 TRUE
2013-11-01 TRUE

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From gunter.berton at gene.com  Thu Nov 14 15:26:53 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 14 Nov 2013 06:26:53 -0800
Subject: [R] Replace NA's with value in the next row
In-Reply-To: <CAFFQM6ayLxTY5zJnsyEdizUizfXt6taa3+Gm7=ptEXRWo=N-hQ@mail.gmail.com>
References: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>
	<5284837E.2080805@bitwrit.com.au>
	<CAFFQM6ayLxTY5zJnsyEdizUizfXt6taa3+Gm7=ptEXRWo=N-hQ@mail.gmail.com>
Message-ID: <CACk-te20T7ybsLhyVHCWxu_Jjn7q-tBi_Fkkftf=mvSZM_Oczw@mail.gmail.com>

On Thu, Nov 14, 2013 at 1:13 AM, Frans Marcelissen
<frans.marcelissen at digipsy.nl> wrote:
> R purists forbid the use of the for loop,

That is utter nonsense. Please do not make such statements when you
have no idea what you're talking about. It just promulgates confusion.

-- Bert

> simple solution:
>
> for (i in 1:(length(V6)-1)) if(is.na(V6[i])) V6[i]<-V6[i+1]
>
>
>
>
> 2013/11/14 Jim Lemon <jim at bitwrit.com.au>
>
>> On 11/14/2013 04:02 PM, dila radi wrote:
>>
>>> Hi all,
>>>
>>> I have a data set which treat missing value as NA and now I need to
>>> replace
>>> all these NA's by using number in the same row but different column.
>>>
>>> Here is the part of my data:
>>>   V1 V2 V3 V4 V5 V6 V7  0 0 0 1.2 0 0 0.259  0 0 12.8 0 23.7 0 8.495  6 0
>>> 81.7 0.2 0 20 19.937  0 1.5 60.9 0 0 15.5 13.900  1 13 56.8 17.5 32.8 6.4
>>> 27.654  4 3 66.4 2 0.3 NA 17.145
>>>
>>>
>>> I want to replace (V6, 6) with (V7, 6). I have about 1000 NA's in V6 which
>>> I want to replace  with the same row in V7. The other values in V6, I want
>>> to keep remain the same.
>>>
>>> How to achieve this? Assuming my data is called "Targetstation",  I have
>>> tried this:
>>>
>>> Targetstation<- within(Targetstation, v6<- replace(v6, is.na(v6), v7[
>>> is.na
>>> (v6)]))
>>>
>>> But R gives me this:
>>>
>>> Warning messages:
>>>
>>> 1: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>> 2: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'
>>>
>>>
>>>  Hi Dila,
>> You could do this like this:
>>
>> V6NA<-is.na(Targetstation$V6)
>> Targetstation$V6[V6NA]<-Targetstation$V7[V6NA]
>>
>> but if you want to use the above, I think you will have to replace the
>> is.na(V6) with is.na(Targetstation$V6) or use the method above.
>>
>> Jim
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
>
> -------------------
> dr F.H.G. (Frans) Marcelissen
> DigiPsy (www.DigiPsy.nl <http://www.digipsy.nl/>)
> Pomperschans 26
> 5595 AV Leende
> tel: 040 2065030/06 2325 06 53
> skype adres: frans.marcelissen
> email: frans.marcelissen at digipsy.nl
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From jrkrideau at inbox.com  Thu Nov 14 16:00:00 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 14 Nov 2013 07:00:00 -0800
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
 Learn Few Basics
In-Reply-To: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
Message-ID: <F1E452F6EBD.00000288jrkrideau@inbox.com>

This is not an R question per se.  It really seems like an RStudio question.  They have their own help forum and it is probably best to ask there.  

My first thought was that you had just closed the output window in RStudio but in my version, 0.97.449 under Ubuntu 13.10 the window automatically opens when you send a command to R.

You have not said what operating system you are using. If in Windows, IIRC, you can just open an RGui or RTerminal and work there.  Just open the script in a text editor and paste it (preferably line-by-line) and see what happens.  Actually just type in something like 1 + 1 and see what happens

In Linux open a terminal window, start R and do the same. No idea about Macs

This way you will get an idea if the R installation or the RStudio installation is likely the culprit.

It sounds like a faulty RStudio installation to me but who knows. An RStudio session should look more or less like this http://www.rstudio.com/ide/ . If you don't have those four panels then you have an RStudio problem.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: zfeinstein at isgmn.com
> Sent: Wed, 13 Nov 2013 13:57:17 +0000
> To: r-help at r-project.org
> Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
> Learn Few Basics
> 
> I have finally decided that I will learn R and learn it very well. For
> now I am using a program that a friend of mine developed to do some
> advanced statistical analyses. I downloaded RStudio to my machine.
> [Perhaps RStudio is not the best platform to work from -  I have heard
> that Rattle is sort of the new standard.] I have so far been able to
> highlight the rows of the code that I wish to run, but then I somehow
> turned off seeing the output. I also cannot find where I would locate the
> output window. Yes, frustrated.
> 
> Would any kind soul be interested in helping kickstart my R learning? I
> have JoinMe installed on my machine so I figure we can do it
> interactively. It should not take more than a few minutes. I am already
> very experienced with both C and VBA languages as well as SPSS syntax so
> there is not much need to worry about me being too much of a novice.
> 
> Thank you very much in advance.
> 
> Zach Feinstein
> zfeinstein at isgmn.com<mailto:zfeinstein at isgmn.com>
> (952) 277-0162
> (612) 590-4813 (mobile)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From maechler at stat.math.ethz.ch  Thu Nov 14 16:08:07 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 14 Nov 2013 16:08:07 +0100
Subject: [R] MM estimator
In-Reply-To: <8B2389BC-48CA-45D5-A834-C8C1C845C6B5@uni-bonn.de>
References: <1384400242.93139.YahooMailNeo@web142501.mail.bf1.yahoo.com>
	<8B2389BC-48CA-45D5-A834-C8C1C845C6B5@uni-bonn.de>
Message-ID: <21124.59223.496612.628512@stat.math.ethz.ch>

>>>>> "SZ" == Simon Zehnder <szehnder at uni-bonn.de>
>>>>>     on Thu, 14 Nov 2013 08:52:16 +0100 writes:

    SZ> Check the gmm package with a weighting matrix equal to
    SZ> the identity.  Best

    SZ> Simon

No.    "MM" is ambigous: The  gmm package is about
       "Generalized Method of Moments"

but Izhak is really asking about MM estimation in the field of
robust statistics, where an MM estimator is a special kind of 
"M-Estimator" (and these, introduced by Peter Huber (1964), Annals,
	       fortunately are well known unambigously,
	       as a generalization of ML estimators (= MLE)),
namely an M-estimator with redescending psi (==> non-convex
problem ==> solution typically depends on starting value),
started with a high-breakdown point initial estimate.

Izhak mentioned  nlrob() from package robustbase, and he is
right that this does not provide an MM estimator, but only an M
estimate started by Least Squares.

Fortunately, we have had contributions to the robustbase
package from Eduardo Concei??o since last summer.
He provided alternative versions of  nlrob(),
notably a  nlrob.MM()  
currently *hidden* {and undocumented}.

I.e. you need

 install.packages("robustbase", repos="http://R-Forge.R-project.org")

 library(robustbase)

and then use  robustbase:::nlrob.MM(....)

The reason for all this is that I plan to have one nlrob()
function  but with  a new argument  'method'
and so eventually

    nlrob.MM(...., method="MM")

will correspond to current to the R-forge version

    robustbase:::nlrob.MM(....)

-------
Please for all more, use the dedicated mailing list
R-SIG-robust only (i.e. do *not* just reply-all to this
e-mail!).

Martin Maechler,
ETH Zurich

 
    SZ> On 14 Nov 2013, at 04:37, IZHAK shabsogh
    SZ> <ishaqbaba at yahoo.com> wrote:

    >> hi
    >> 
    >> I have a nonlinear regression model with two parameter, i
    >> have estimated using nls in R and i want to also find the
    >> estimate using MM, someone refer me to this function
    >> nlrob but this is main for only M estimate. can you
    >> please help me findout a function in R for MM nonlinear
    >> regression
    >> 
    >> thanks
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    >> read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    SZ> ______________________________________________
    SZ> R-help at r-project.org mailing list
    SZ> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    SZ> read the posting guide
    SZ> http://www.R-project.org/posting-guide.html and provide
    SZ> commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Thu Nov 14 16:20:58 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Thu, 14 Nov 2013 10:20:58 -0500
Subject: [R] lapply?
Message-ID: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/86c14612/attachment.pl>

From therneau at mayo.edu  Thu Nov 14 16:30:52 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 14 Nov 2013 09:30:52 -0600
Subject: [R] issues with calling predict.coxph.penal (survival) inside a
	function
In-Reply-To: <mailman.25.1384426808.2137.r-help@r-project.org>
References: <mailman.25.1384426808.2137.r-help@r-project.org>
Message-ID: <5284ECAC.5040504@mayo.edu>

Thanks for the reproducable example.  I can confirm that it fails on my machine using 
survival 2-37.5, the next soon-to-be-released version,

The issue is with NextMethod, and my assumption that the called routine inherited 
everything from the parent, including the environment chain.  A simple test this AM showed 
me that the assumption is false.  It might have been true for Splus.  Working this out may 
take some time -- every other one of my wrestling matches with predict inside a function 
has -- and there is a reasonable chance that it won't make this already overdue release.

In the meantime, here is a workaround that I have sometimes used in other situations. 
Inside your function do the following: fit a new coxph model with fixed coefficients, and 
do prediction on that.

myfun <- function(oldfit, subset) {
    newX <- model.matrix(oldfit)[subset,]
    newY <- oldfit$y[subset]
    newfit <- coxph(newY ~ newX, iter=0, init=coef(oldfit))
    newfit$var <- oldfit$var
    predict(newfit)
    }

If the subset is all of a particular strata, as you indicated, then all of the predictions 
will be correct.  If not, then those that make use of the the baseline hazard (type= 
expect) will be incorrect but all others are ok.

Terry Therneau


On 11/14/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hello everyone,
>
>
>
> I got an issue with calling predict.coxph.penal inside a function.
>
>
>
> Regarding the context: My original problem is that I wrote a function that
> uses predict.coxph and survfit(model) to predict
>
> a lot of survival-curves using only the basis-curves for the strata (as
> delivered by survfit(model) ) and then adapts them with
>
> the predicted risk-scores. Because there are cases where my new data has
> strata which didn't exist in the original model I exclude
>
> them, using a Boolean vector inside the function.
>
> I end up with a call like this: predict (coxph_model,
> newdata[subscript_vector,] )
>
>
>
> This works fine for coxph.model, but when I fit a model with a spline
> (class coxph.penal), I get an error:
>
> "Error in `[.data.frame`(newdata, [subscript_vector, ) : object
> '[subscript_vector ' not found"
>
>
>
> I suppose this is because of NextMethod, but I am not sure how to work
> around it. I also read a little bit about all those
> matching-and-frame-issues,
>
> But must confess I am not really into it.
>


From bhh at xs4all.nl  Thu Nov 14 16:34:58 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 14 Nov 2013 16:34:58 +0100
Subject: [R] lapply?
In-Reply-To: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
References: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
Message-ID: <161EBFC0-48E5-4D66-BB89-ECD120A227D6@xs4all.nl>


On 14-11-2013, at 16:20, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi,
> 
> I was trying to use lapply to create a matrix from a list:
> 
> uu <- list()
> uu[[1]] <- c(1,2,3)
> uu[[2]] <- c(3,4,5)
> 
> The output I desire is a matrix with 2 rows and 3 columns, so I try:
> 
> xx <- lapply(uu,rbind)
> 
> Obviously, I'm not doing something right, but what!?


do.call(rbind,uu) 

Berend


From ruipbarradas at sapo.pt  Thu Nov 14 16:35:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 14 Nov 2013 15:35:00 +0000
Subject: [R] lapply?
In-Reply-To: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
References: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
Message-ID: <5284EDA4.302@sapo.pt>

Hello,

You are applying rbind to each element of the list, not rbinding it with 
the others. Try instead

do.call(rbind, uu)

Hope this helps,

Rui Barradas

Em 14-11-2013 15:20, Brian Smith escreveu:
> Hi,
>
> I was trying to use lapply to create a matrix from a list:
>
> uu <- list()
> uu[[1]] <- c(1,2,3)
> uu[[2]] <- c(3,4,5)
>
> The output I desire is a matrix with 2 rows and 3 columns, so I try:
>
> xx <- lapply(uu,rbind)
>
> Obviously, I'm not doing something right, but what!?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From therneau at mayo.edu  Thu Nov 14 16:44:46 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 14 Nov 2013 09:44:46 -0600
Subject: [R] Survival analysis with truncated data
In-Reply-To: <mailman.25.1384426808.2137.r-help@r-project.org>
References: <mailman.25.1384426808.2137.r-help@r-project.org>
Message-ID: <5284EFEE.7030608@mayo.edu>

I think that your data is censored, not truncated.
   For a fault introduced 1/2005 and erased 2/2006, duration = 13 months
   For a fault introduced 4/2010 and still in existence at the last observation 12/2010, 
duration> 8 months.
   For a fault introduced before 2004, erased  3/2005, in a machine installed 2/1998, the 
duration is somewhere between 15 and 87 months.
   For a fault introduced before 2004, smachine installed 5/2000, still present 11/2010 at 
last check, the duration is > 126 months.

For type=interval2 the data would be (13,13), (8,NA), (15,87), (126, NA).

Terry T.


On 11/14/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hi,
>
> I would like to know how to handle truncated data.
> My intend is to have the survival curve of a software fault in order
> to have some information
> about fault lifespan.
>
> I have some observations of a software system between 2004 and 2010.
> The system was first released in 1994.
> The event considered is the disappearance of a software fault. The
> faults can have been
> introduced at any time, between 1994 and 2010. But for fault
> introduced before 2004,
> there is not mean to know their age.
>
> I used the Surv and survfit functions with type interval2.
> For the faults that are first observed in 2004, I set the lower bound
> to the lifespan
> observed between 2004 and 2010.
>
> How could I set the upper bound ? Using 1994 as a starting point to not seems
> to be meaningful. Neither is using only the lower bound.
>
> Should I consider another survival estimator ?
>
> Thanks in advance.


From derex.fen at gmail.com  Thu Nov 14 16:52:17 2013
From: derex.fen at gmail.com (Dereje Fentie)
Date: Thu, 14 Nov 2013 16:52:17 +0100
Subject: [R] Generating bootstrap samples from a panel data frame
In-Reply-To: <CAEqV=wfHkQ2H-3t_tL_Z60WurWZZk_mQEAdaXDc0nwkLENeZvQ@mail.gmail.com>
References: <CAEqV=wfHkQ2H-3t_tL_Z60WurWZZk_mQEAdaXDc0nwkLENeZvQ@mail.gmail.com>
Message-ID: <CAEqV=wcYKtC4NGmCAfh12Ht=-uUfzQzER-Ps4G6kdX7s27d8yA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/304636e6/attachment.pl>

From bsmith030465 at gmail.com  Thu Nov 14 17:02:04 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Thu, 14 Nov 2013 11:02:04 -0500
Subject: [R] lapply?
In-Reply-To: <5284EDA4.302@sapo.pt>
References: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
	<5284EDA4.302@sapo.pt>
Message-ID: <CAEQKoCEH-OOoxHXR_CwKaEcSQRJDg19fwPB6AaPbgtxAzorPZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/b4e45bb8/attachment.pl>

From szehnder at uni-bonn.de  Thu Nov 14 17:03:39 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 14 Nov 2013 17:03:39 +0100
Subject: [R] MM estimator
In-Reply-To: <21124.59223.496612.628512@stat.math.ethz.ch>
References: <1384400242.93139.YahooMailNeo@web142501.mail.bf1.yahoo.com>
	<8B2389BC-48CA-45D5-A834-C8C1C845C6B5@uni-bonn.de>
	<21124.59223.496612.628512@stat.math.ethz.ch>
Message-ID: <2F7E7DC4-C4F3-459F-BBCE-FAA0DBFC6A03@uni-bonn.de>

Thanks Martin, for making this clear to me, I thought of Pearson?s Method-of-Moments.
On 14 Nov 2013, at 16:08, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> "SZ" == Simon Zehnder <szehnder at uni-bonn.de>
>>>>>>    on Thu, 14 Nov 2013 08:52:16 +0100 writes:
> 
>    SZ> Check the gmm package with a weighting matrix equal to
>    SZ> the identity.  Best
> 
>    SZ> Simon
> 
> No.    "MM" is ambigous: The  gmm package is about
>       "Generalized Method of Moments"
> 
> but Izhak is really asking about MM estimation in the field of
> robust statistics, where an MM estimator is a special kind of 
> "M-Estimator" (and these, introduced by Peter Huber (1964), Annals,
> 	       fortunately are well known unambigously,
> 	       as a generalization of ML estimators (= MLE)),
> namely an M-estimator with redescending psi (==> non-convex
> problem ==> solution typically depends on starting value),
> started with a high-breakdown point initial estimate.
> 
> Izhak mentioned  nlrob() from package robustbase, and he is
> right that this does not provide an MM estimator, but only an M
> estimate started by Least Squares.
> 
> Fortunately, we have had contributions to the robustbase
> package from Eduardo Concei??o since last summer.
> He provided alternative versions of  nlrob(),
> notably a  nlrob.MM()  
> currently *hidden* {and undocumented}.
> 
> I.e. you need
> 
> install.packages("robustbase", repos="http://R-Forge.R-project.org")
> 
> library(robustbase)
> 
> and then use  robustbase:::nlrob.MM(....)
> 
> The reason for all this is that I plan to have one nlrob()
> function  but with  a new argument  'method'
> and so eventually
> 
>    nlrob.MM(...., method="MM")
> 
> will correspond to current to the R-forge version
> 
>    robustbase:::nlrob.MM(....)
> 
> -------
> Please for all more, use the dedicated mailing list
> R-SIG-robust only (i.e. do *not* just reply-all to this
> e-mail!).
> 
> Martin Maechler,
> ETH Zurich
> 
> 
>    SZ> On 14 Nov 2013, at 04:37, IZHAK shabsogh
>    SZ> <ishaqbaba at yahoo.com> wrote:
> 
>>> hi
>>> 
>>> I have a nonlinear regression model with two parameter, i
>>> have estimated using nls in R and i want to also find the
>>> estimate using MM, someone refer me to this function
>>> nlrob but this is main for only M estimate. can you
>>> please help me findout a function in R for MM nonlinear
>>> regression
>>> 
>>> thanks
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>>> read the posting guide
>>> http://www.R-project.org/posting-guide.html and provide
>>> commented, minimal, self-contained, reproducible code.
> 
>    SZ> ______________________________________________
>    SZ> R-help at r-project.org mailing list
>    SZ> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>    SZ> read the posting guide
>    SZ> http://www.R-project.org/posting-guide.html and provide
>    SZ> commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Thu Nov 14 18:02:19 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 14 Nov 2013 09:02:19 -0800
Subject: [R] making a barplot with table of experimental conditions
 underneath (preferably ggplot2)
In-Reply-To: <5FF7898BAD1B4A4A809F4C51902634847344670E@UMCEXMBX11.umcn.nl>
Message-ID: <F2F5B8302DC.000004A3jrkrideau@inbox.com>

Hi Nina, 
I think the following code does what you want (thanks to Jim Lemon for showing me what you wanted in terms of x-axis tick labels)

However I  think that barcharts are generally evil  so I changed your geom_bar to geom_point.  Feel free to change it back if your discipline requires it but I think it shows your data better

Also you were doing some unnecessary extraction of dat from the data.frame so I just included a "data =" statement in qplot and changed the variable names in it to the original df names. This makes for cleaner and more readable code.

df <- data.frame (experiment=c("E1","E2","E3","E4"), mean = c(3,4,5,6),
stdev=c(0.1,0.1,0.05,0.2), method = c("STD","STD", "FP", "FP"), enzyme =c
("T","T/L","T","T/L"), denaturation=c("U","U","0.05%RG", "0.1%RG"))

df$labs  <-  paste(df[,4],"\n ",df[,5], "\n ",df[,6]) # create labels

df.plot <- qplot(experiment,mean,data = df, xlab="", ylab="# peptides identified")+
  geom_point(fill="grey")+
  geom_errorbar(aes(x=experiment, ymin=mean-stdev, ymax=mean+stdev), width=0.25)

p + scale_x_discrete( labels = df$labs)

I hop
John Kane
Kingston ON Canada


> -----Original Message-----
> From: n.hubner at ncmls.ru.nl
> Sent: Wed, 13 Nov 2013 14:24:28 +0000
> To: r-help at r-project.org
> Subject: [R] making a barplot with table of experimental conditions
> underneath (preferably ggplot2)
> 
> Dear all,
>
> my data looks the following:
> 
> df <- data.frame (experiment=c("E1","E2","E3","E4"), mean = c(3,4,5,6),
> stdev=c(0.1,0.1,0.05,0.2), method = c("STD","STD", "FP", "FP"), enzyme =c
> ("T","T/L","T","T/L"), denaturation=c("U","U","0.05%RG", "0.1%RG"))

> I would like to make a bar plot with standard deviation which I solved
> the following way:
> 
> x <- df$experiment
> y <- df$mean
> sd <- df$stdev
> 
> df.plot <- qplot(x,y,xlab="", ylab="# peptides identified")+
>   geom_bar(colour="black", fill="darkgrey")+
>   geom_errorbar(aes(x=x, ymin=y-sd, ymax=y+sd), width=0.25)
> 
> df.plot
> 

> However, as the labels for the x-axis (the bars) I do not want the
> experiment number, as now, but instead a table containing the other
> columns of my data.frame (method, enzyme, denaturation) with the
> description in the front and the certain 'value' below the bars.
> 
> I am looking forward to your suggestions!
>
> With best wishes,
> 
> Nina
> ______________________________________________
> 
> Dr. Nina C. Hubner
> scientist quantitative proteomics
> 
> Dep. of Molecular Biology, Radboud University Nijmegen, The Netherlands
> e-mail: n.hubner at ncmls.ru.nl
> tel: +31-24-3613655
> 
> Visiting address:
> NCMLS, Dept of Molecular Biology (route 274)
> Geert Grooteplein 26/28
> 6525 GA Nijmegen
> The Netherlands
> 
> 
> 
> 
> The Radboud University Medical Centre is listed in the Commercial
> Register of the Chamber of Commerce under file number 41055629.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From nicolas.palix at imag.fr  Thu Nov 14 18:11:49 2013
From: nicolas.palix at imag.fr (Nicolas Palix)
Date: Thu, 14 Nov 2013 18:11:49 +0100
Subject: [R] Survival analysis with truncated data
In-Reply-To: <5284EFEE.7030608@mayo.edu>
References: <mailman.25.1384426808.2137.r-help@r-project.org>
	<5284EFEE.7030608@mayo.edu>
Message-ID: <CAAxaTiP7MUKBLpex_w8meC2D_eXKay5KejOf-YVzL0F1YcjzsQ@mail.gmail.com>

Hi,

Thanks for your response.

On Thu, Nov 14, 2013 at 4:44 PM, Terry Therneau <therneau at mayo.edu> wrote:
> I think that your data is censored, not truncated.
>   For a fault introduced 1/2005 and erased 2/2006, duration = 13 months
>   For a fault introduced 4/2010 and still in existence at the last
> observation 12/2010, duration> 8 months.
>   For a fault introduced before 2004, erased  3/2005, in a machine installed
> 2/1998, the duration is somewhere between 15 and 87 months.
>   For a fault introduced before 2004, smachine installed 5/2000, still
> present 11/2010 at last check, the duration is > 126 months.
>
> For type=interval2 the data would be (13,13), (8,NA), (15,87), (126, NA).

I have done this that way. My problem is that I have no information
when a fault is introduced before 2004. Indeed, this is about the lifespan
of software faults in the code.

In your example, this means I could not set the upper bound to 87 months.
As I know for sure that the first software release was in 1994. For a fault
which is observed from 2004 up to 2005 I set the range to (12, 120+12). That is
12 observed + 10 years from 1994 to 2004. The estimation is almost
similar if I use (12, NA) and gives me an upper bound.
I tried (12, 12) to have the lower bound.


I tried with 5 years instead of 10. This seems to give an
over-estimation too.

Could I use some properties of the data from ]2004;2010] to give
an average extension to these faults ? The average or median
for instance.

Thanks in advance.


>
> Terry T.
>
>
> On 11/14/2013 05:00 AM, r-help-request at r-project.org wrote:
>>
>> Hi,
>>
>> I would like to know how to handle truncated data.
>> My intend is to have the survival curve of a software fault in order
>> to have some information
>> about fault lifespan.
>>
>> I have some observations of a software system between 2004 and 2010.
>> The system was first released in 1994.
>> The event considered is the disappearance of a software fault. The
>> faults can have been
>> introduced at any time, between 1994 and 2010. But for fault
>> introduced before 2004,
>> there is not mean to know their age.
>>
>> I used the Surv and survfit functions with type interval2.
>> For the faults that are first observed in 2004, I set the lower bound
>> to the lifespan
>> observed between 2004 and 2010.
>>
>> How could I set the upper bound ? Using 1994 as a starting point to not
>> seems
>> to be meaningful. Neither is using only the lower bound.
>>
>> Should I consider another survival estimator ?
>>
>> Thanks in advance.



-- 
Nicolas Palix
Tel: +33 4 76 51 46 27
http://membres-liglab.imag.fr/palix/


From yuanzhi.li at usherbrooke.ca  Thu Nov 14 15:35:09 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Thu, 14 Nov 2013 06:35:09 -0800 (PST)
Subject: [R] volume of ellipsoid
In-Reply-To: <1384431926676-4680435.post@n4.nabble.com>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>
	<1384431926676-4680435.post@n4.nabble.com>
Message-ID: <1384439709454-4680445.post@n4.nabble.com>

Hi, Carl Witthoft

yes, it looks like a mathematical question. I will try based on your
suggestion to calculate the volume of the intersection. But I still want to
know whether there are some functions in R which can calculate the volume of
an ellipsoid(area for p=2, hypervolume for p>3) containing X, just like the
"convhulln" function in "geometry" package which can calculate the volume of
convex hull containing X. 



--
View this message in context: http://r.789695.n4.nabble.com/volume-of-ellipsoid-tp4680409p4680445.html
Sent from the R help mailing list archive at Nabble.com.


From yuanzhi.li at usherbrooke.ca  Thu Nov 14 15:44:33 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Thu, 14 Nov 2013 06:44:33 -0800 (PST)
Subject: [R] volume of ellipsoid
In-Reply-To: <1384431926676-4680435.post@n4.nabble.com>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>
	<1384431926676-4680435.post@n4.nabble.com>
Message-ID: <1384440273272-4680446.post@n4.nabble.com>

Carl Witthoft wrote
> Well, given that an upvoted question on math.stackexchange got no answers,
> I'd say you're asking a very difficult question.   Perhaps this paper  
> http://www.geometrictools.com/Documentation/IntersectionOfEllipsoids.pdf
> 
> will be of some help.   It's possible that you could do:
> 1) find the ellipse of intersection of the two ellipsoids
> 2) find some formula for the equivalent of the "spherical cap" volume
> 3) apply that formula to each ellipsoid, using the intersection ellipse as
> the base of the caps.
> 
> All this, btw, is math,  not really related to R or to software
> programming in general.
> yuanzhi wrote
>> Hi, everyone!
>> 
>> I have a matrix X(n*p) which is n samples from a p-dimensional normal  
>> distribution. Now I want to make the ellipsoid containing (1-?)% of  
>> the probability in the distribution based on Mahalanobis distance:
>> 
>> ?:(x-?)'?^(-1)(x-?)??2p(?)
>> 
>> where x and ? is the mean and variance-covariance matrix of X. Are  
>> there some functions in R which can plot the ellipsoid and calculate  
>> the volume (area for p=2, hypervolume for p>3) of the ellipsoid? I  
>> only find the "ellipsoidhull" function in "cluster" package, but it  
>> deal with ellipsoid hull containing X, which obvious not the one I want.
>> 
>> After that, a more difficult is the following. If we have a series of  
>> matrix X1, X2, X3,? Xm which follow different p-dimensional normal  
>> distributions. And we make m ellipsoids (E1, E2, ? Em) for each matrix  
>> like the before. How can we calculate the volume of union of the m  
>> ellipsoids? One possible solution for this problem is the  
>> inclusion-exclusion principle:
>> 
>> V(?Ei)(1?i?m)=
>> V(Ei)(1?i?m)-?V(Ei?Ej)(1?i&lt;j?m)+?V(Ei?Ej?Ek)(1?i&lt;j&lt;k?m)+(-1)^(m-1)V(E1???Em)
>> 
>> But the problem is how to calculate the volume of intersection between  
>> 2, 3 or more ellipsoids. Are there some functions which can calculate  
>> the volume of intersection between two region or functions which  
>> directly calculate the volume of a union of two region(the region here  
>> is ellipsoid). OR yo you have any good ideas solving this problem in  
>> R? Thank you all in advance!
>> 
>> Yuanzhi
>> 
>> ______________________________________________
>> &lt;email&gt;R-help@

>>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

Hi, Carl Witthoft 

yes, it looks like a mathematical question. I will try based on your
suggestion to calculate the volume of the intersection. But I still want to
know whether there are some functions in R which can calculate the volume of
an ellipsoid(area for p=2, hypervolume for p>3) containing X, just like the
"convhulln" function in "geometry" package which can calculate the volume of
convex hull containing X.
thanks!



--
View this message in context: http://r.789695.n4.nabble.com/volume-of-ellipsoid-tp4680409p4680446.html
Sent from the R help mailing list archive at Nabble.com.


From chanita.holmes at gmail.com  Thu Nov 14 17:12:33 2013
From: chanita.holmes at gmail.com (Chanita Holmes)
Date: Thu, 14 Nov 2013 08:12:33 -0800
Subject: [R] 2SLS for panel data, re
Message-ID: <CAEaD0=6SkDOTODbPZZ19LE2ca6YxByXWp+q-GiL1g+8eFB22DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/c5cdca63/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 14 14:51:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 05:51:42 -0800 (PST)
Subject: [R] From list to dataframe
In-Reply-To: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>
References: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>
Message-ID: <1384437102.33665.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi Hermann,

You may try:
do.call(rbind,testlist)
#or
Reduce(rbind,testlist)
#or
library(plyr)
?ldply(testlist)
A.K.




On Thursday, November 14, 2013 8:27 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
Hello,

having a list like testlist I would like to transform it in dataframe. How
does it work?

Thanks
Hermann

> testlist
[[1]]
? ? ? BP_A? ?? SNP_A? ?? BP_B? ?? SNP_B? ? ?? R2
2 27001689 rs4822747 27002392 rs4820690 0.695642
3 27001689 rs4822747 27004298 rs5761627 0.695642
4 27001689 rs4822747 27004902 rs5752355 0.687861
5 27001689 rs4822747 27004964 rs4822748 0.682715
6 27001689 rs4822747 27005122 rs4820691 0.695642
7 27001689 rs4822747 27005158 rs4822749 0.695642

[[2]]
? ? ?? BP_A? ?? SNP_A? ?? BP_B? ?? SNP_B? ? ?? R2
9? 27002392 rs4820690 27001689 rs4822747 0.695642
11 27002392 rs4820690 27004298 rs5761627 1.000000
12 27002392 rs4820690 27004902 rs5752355 0.988681
13 27002392 rs4820690 27004964 rs4822748 0.988655
14 27002392 rs4820690 27005122 rs4820691 1.000000
15 27002392 rs4820690 27005158 rs4822749 1.000000
16 27002392 rs4820690 27005194 rs4822750 0.988655
17 27002392 rs4820690 27005470 rs5761629 0.695642

[[3]]
? ? ?? BP_A? ?? SNP_A? ?? BP_B? ?? SNP_B? ? ?? R2
19 27004298 rs5761627 27001689 rs4822747 0.695642
20 27004298 rs5761627 27002392 rs4820690 1.000000
22 27004298 rs5761627 27004902 rs5752355 0.988681
23 27004298 rs5761627 27004964 rs4822748 0.988655
24 27004298 rs5761627 27005122 rs4820691 1.000000
25 27004298 rs5761627 27005158 rs4822749 1.000000

#The aim is the dataframe
? ? ?? BP_A? ?? SNP_A? ?? BP_B? ?? SNP_B? ? ?? R2
2? 27001689 rs4822747 27002392 rs4820690 0.695642
3? 27001689 rs4822747 27004298 rs5761627 0.695642
4? 27001689 rs4822747 27004902 rs5752355 0.687861
5? 27001689 rs4822747 27004964 rs4822748 0.682715
6? 27001689 rs4822747 27005122 rs4820691 0.695642
7? 27001689 rs4822747 27005158 rs4822749 0.695642
9? 27002392 rs4820690 27001689 rs4822747 0.695642
11 27002392 rs4820690 27004298 rs5761627 1.000000
12 27002392 rs4820690 27004902 rs5752355 0.988681
13 27002392 rs4820690 27004964 rs4822748 0.988655
14 27002392 rs4820690 27005122 rs4820691 1.000000
15 27002392 rs4820690 27005158 rs4822749 1.000000
16 27002392 rs4820690 27005194 rs4822750 0.988655
17 27002392 rs4820690 27005470 rs5761629 0.695642
19 27004298 rs5761627 27001689 rs4822747 0.695642
20 27004298 rs5761627 27002392 rs4820690 1.000000
22 27004298 rs5761627 27004902 rs5752355 0.988681
23 27004298 rs5761627 27004964 rs4822748 0.988655
24 27004298 rs5761627 27005122 rs4820691 1.000000
25 27004298 rs5761627 27005158 rs4822749 1.000000
>
> dput (testlist)
list(structure(list(BP_A = c(27001689L, 27001689L, 27001689L,
27001689L, 27001689L, 27001689L), SNP_A = c("rs4822747", "rs4822747",
"rs4822747", "rs4822747", "rs4822747", "rs4822747"), BP_B = c(27002392L,
27004298L, 27004902L, 27004964L, 27005122L, 27005158L), SNP_B =
c("rs4820690",
"rs5761627", "rs5752355", "rs4822748", "rs4820691", "rs4822749"
), R2 = c(0.695642, 0.695642, 0.687861, 0.682715, 0.695642, 0.695642
)), .Names = c("BP_A", "SNP_A", "BP_B", "SNP_B", "R2"), row.names = 2:7,
class = "data.frame"),
? ? structure(list(BP_A = c(27002392L, 27002392L, 27002392L,
? ? 27002392L, 27002392L, 27002392L, 27002392L, 27002392L), SNP_A =
c("rs4820690",
? ? "rs4820690", "rs4820690", "rs4820690", "rs4820690", "rs4820690",
? ? "rs4820690", "rs4820690"), BP_B = c(27001689L, 27004298L,
? ? 27004902L, 27004964L, 27005122L, 27005158L, 27005194L, 27005470L
? ? ), SNP_B = c("rs4822747", "rs5761627", "rs5752355", "rs4822748",
? ? "rs4820691", "rs4822749", "rs4822750", "rs5761629"), R2 = c(0.695642,
? ? 1, 0.988681, 0.988655, 1, 1, 0.988655, 0.695642)), .Names = c("BP_A",
? ? "SNP_A", "BP_B", "SNP_B", "R2"), row.names = c(9L, 11L, 12L,
? ? 13L, 14L, 15L, 16L, 17L), class = "data.frame"), structure(list(
? ? ? ? BP_A = c(27004298L, 27004298L, 27004298L, 27004298L,
? ? ? ? 27004298L, 27004298L), SNP_A = c("rs5761627", "rs5761627",
? ? ? ? "rs5761627", "rs5761627", "rs5761627", "rs5761627"),
? ? ? ? BP_B = c(27001689L, 27002392L, 27004902L, 27004964L,
? ? ? ? 27005122L, 27005158L), SNP_B = c("rs4822747", "rs4820690",
? ? ? ? "rs5752355", "rs4822748", "rs4820691", "rs4822749"),
? ? ? ? R2 = c(0.695642, 1, 0.988681, 0.988655, 1, 1)), .Names = c("BP_A",
? ? "SNP_A", "BP_B", "SNP_B", "R2"), row.names = c(19L, 20L,
? ? 22L, 23L, 24L, 25L), class = "data.frame"))

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Nov 14 15:33:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 06:33:10 -0800 (PST)
Subject: [R] Replace NA's with value in the next row
In-Reply-To: <1384438845.22570.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAMgoKBKpmCa5EB3UK5YgO=HCCGo3xHYo786wFyCZEwpz-_9Z8g@mail.gmail.com>
	<1384438845.22570.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1384439590.51178.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,

I think you used a column that doesn't exist in the dataset.

Targetstation <- read.table(text="V1 V2 V3 V4 V5 V6 V7? 
0 0 0 1.2 0 0 0.259
0 0 12.8 0 23.7 0 8.495
?6 0 81.7 0.2 0 20 19.937
?0 1.5 60.9 0 0 15.5 13.900
?1 13 56.8 17.5 32.8 6.4 27.654
? 4 3 66.4 2 0.3 NA 17.145",sep="",header=TRUE)


within(Targetstation, V6 <- replace(V6,is.na(V6),V7[is.na(V6)]))
? V1?? V2?? V3?? V4?? V5???? V6???? V7
1? 0? 0.0? 0.0? 1.2? 0.0? 0.000? 0.259
2? 0? 0.0 12.8? 0.0 23.7? 0.000? 8.495
3? 6? 0.0 81.7? 0.2? 0.0 20.000 19.937
4? 0? 1.5 60.9? 0.0? 0.0 15.500 13.900
5? 1 13.0 56.8 17.5 32.8? 6.400 27.654
6? 4? 3.0 66.4? 2.0? 0.3 17.145 17.145

#if you use:
?!is.na(Targetstation$v6) #'v6' and 'V6' are different
logical(0)
Warning message:
In is.na(Targetstation$v6) :
? is.na() applied to non-(list or vector) of type 'NULL'



A.K.









On Thursday, November 14, 2013 2:26 AM, dila radi <dilaradi21 at gmail.com> wrote:
Hi all,

I have a data set which treat missing value as NA and now I need to replace
all these NA's by using number in the same row but different column.

Here is the part of my data:
V1 V2 V3 V4 V5 V6 V7? 0 0 0 1.2 0 0 0.259? 0 0 12.8 0 23.7 0 8.495? 6 0
81.7 0.2 0 20 19.937? 0 1.5 60.9 0 0 15.5 13.900? 1 13 56.8 17.5 32.8 6.4
27.654? 4 3 66.4 2 0.3 NA 17.145


I want to replace (V6, 6) with (V7, 6). I have about 1000 NA's in V6 which
I want to replace? with the same row in V7. The other values in V6, I want
to keep remain the same.

How to achieve this? Assuming my data is called "Targetstation",? I have
tried this:

Targetstation <- within(Targetstation, v6 <- replace(v6, is.na(v6), v7[is.na
(v6)]))

But R gives me this:

Warning messages:

1: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'

2: In is.na(v6) : is.na() applied to non-(list or vector) of type 'NULL'


How to solve this?

Thank you in advance.

Regards,

Dila.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From toth.denes at ttk.mta.hu  Thu Nov 14 16:34:19 2013
From: toth.denes at ttk.mta.hu (Toth, Denes)
Date: Thu, 14 Nov 2013 16:34:19 +0100
Subject: [R] lapply?
In-Reply-To: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
References: <CAEQKoCEGDps0kzBE-YdsmYpy4+Bw5uQQ6uTf6oKgXiUhToanvA@mail.gmail.com>
Message-ID: <27d4f90dc7e63fc18c87a8069b9c9e7b.squirrel@webmail.cogpsyphy.hu>


Hi,

the output of lapply() is a list; see ?lapply and ?sapply.

# if you know the length of your list in advance,
# this definition is better:
uu <- vector("list", 2)

# list elements
uu[[1]] <- c(1,2,3)
uu[[2]] <- c(3,4,5)


# some options to achieve what you want:
matrix(unlist(uu), 2, 3, T)
do.call(rbind, uu)
t(sapply(uu, I))


HTH,
  Denes


> Hi,
>
> I was trying to use lapply to create a matrix from a list:
>
> uu <- list()
> uu[[1]] <- c(1,2,3)
> uu[[2]] <- c(3,4,5)
>
> The output I desire is a matrix with 2 rows and 3 columns, so I try:
>
> xx <- lapply(uu,rbind)
>
> Obviously, I'm not doing something right, but what!?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Thu Nov 14 16:36:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 07:36:30 -0800 (PST)
Subject: [R] Transform aggregated data to individual data
In-Reply-To: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>
References: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>
Message-ID: <1384443390.12620.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
Try:
?D1 <- D[rep(row.names(D),D[,3]),-3] ##assuming rownames(D) are from 1:nrow(D)
?row.names(D1) <- 1:nrow(D1)
A.K.


On Thursday, November 14, 2013 5:32 AM, peron <olivier.peron at univ-pau.fr> wrote:
Hello 



I have data in following form : 100 ind describe by two variables x and y.



D<-data .frame( x=rnorm(3), y=rnorm(3), size=c(50,10,40))



I want data for individual, i.e, 100 observations for my 100 ind.



Thank for your help



Olivier Peron


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Nov 14 16:50:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 07:50:21 -0800 (PST)
Subject: [R] Substring and extract a certain number of characters
Message-ID: <1384444221.45391.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Try:
s1 <- "hello.world"
s2 <- c("GLEm0045", "GLEn0042", "GLEz0048")

?substr(s1,1,5)
#or
gsub("\\..*","",s1)

n <- 5
substr(s2,nchar(s2)-n +1,nchar(s2))


A.K.



If I have a column that has "hello.world" ?how ? could I extract hello? 
?In addition in a column how can I extract the last 5 characters? ? ?For example from character ?G1Em0017 ?I wish to extract m0017 .


From smartpink111 at yahoo.com  Thu Nov 14 17:02:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 08:02:38 -0800 (PST)
Subject: [R] Substring and extract a certain number of characters
In-Reply-To: <1384444221.45391.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1384444221.45391.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1384444958.58860.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Also,
library(stringr)
str_sub(s2,-5,-1)

str_extract(s1,"[[:alpha:]]+")

A.K.





On Thursday, November 14, 2013 10:50 AM, arun <smartpink111 at yahoo.com> wrote:
Try:
s1 <- "hello.world"
s2 <- c("GLEm0045", "GLEn0042", "GLEz0048")

?substr(s1,1,5)
#or
gsub("\\..*","",s1)

n <- 5
substr(s2,nchar(s2)-n +1,nchar(s2))


A.K.



If I have a column that has "hello.world" ?how ? could I extract hello? 
?In addition in a column how can I extract the last 5 characters? ? ?For example from character ?G1Em0017 ?I wish to extract m0017 .


From hnorpois at gmail.com  Thu Nov 14 17:45:44 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 14 Nov 2013 17:45:44 +0100
Subject: [R] From list to dataframe
In-Reply-To: <1384437102.33665.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAKyZeBub-4HkyhvgxBu7xjmBqZEnxHiJjgZej5HSrK=GtUUZ5Q@mail.gmail.com>
	<1384437102.33665.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAKyZeBsRhoV4Z+=m_VcDtrG3WbDFMGgbcFMb3iUikJRYjRFAzQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/3d6d05ef/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 14 18:35:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 09:35:53 -0800 (PST)
Subject: [R] Transform aggregated data to individual data
In-Reply-To: <1384443390.12620.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <001b01cee124$3f227c60$bd677520$@peron@univ-pau.fr>
	<1384443390.12620.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1384450553.18685.YahooMailNeo@web142601.mail.bf1.yahoo.com>



HI,

A more general form would be:
?D[rep(1:nrow(D),D[,3]),-3]

A.K.


On Thursday, November 14, 2013 12:27 PM, arun <smartpink111 at yahoo.com> wrote:


Hi,
Try:
?D1 <- D[rep(row.names(D),D[,3]),-3] ##assuming rownames(D) are from 1:nrow(D)
?row.names(D1) <- 1:nrow(D1)
A.K.


On Thursday, November 14, 2013 5:32 AM, peron <olivier.peron at univ-pau.fr> wrote:
Hello 



I have data in following form : 100 ind describe by two variables x and y.



D<-data .frame( x=rnorm(3), y=rnorm(3), size=c(50,10,40))



I want data for individual, i.e, 100 observations for my 100 ind.



Thank for your help



Olivier Peron


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From plalehzari at platinumlp.com  Thu Nov 14 19:06:07 2013
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Thu, 14 Nov 2013 18:06:07 +0000
Subject: [R] Column Name Matching in xts Objects
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB0B00772D@EX02.platinum.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/04b1664d/attachment.pl>

From email8889 at gmail.com  Thu Nov 14 19:03:35 2013
From: email8889 at gmail.com (email)
Date: Thu, 14 Nov 2013 20:03:35 +0200
Subject: [R] polygon circling a graph
Message-ID: <CAJMZ3ceBmehpyMUMTiKYGaG97OT2-Q=nBs3X7uiAg4zNfx896g@mail.gmail.com>

Hi:

I want to create a polygon encircling a graph. For this i use convex
hull  to get the coordinate points for polygon.

g <- barabasi.game(10)
L<-layout.fruchterman.reingold(g)
temp1 <- chull(L)
temp1 <- c(temp1, temp1[1])
plot(g, layout=layout.fruchterman.reingold)


But when i plot the polygon with the code below, the polygon dosen't
encircle the graph.

polygon(L[temp1, ], col = "#0000FFAA")

How can I plot a polygon circling a graph?

Regards:
John


From Jean-Francois.Chevalier at bisnode.com  Thu Nov 14 19:24:56 2013
From: Jean-Francois.Chevalier at bisnode.com (Jean-Francois Chevalier)
Date: Thu, 14 Nov 2013 18:24:56 +0000
Subject: [R] optimization: multiple assignment problem
Message-ID: <5107C4330AFCF145AD7E53EE2282964D32012A3A@EEL.pcs.sopres.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/e7a50191/attachment.pl>

From szehnder at uni-bonn.de  Thu Nov 14 19:50:23 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 14 Nov 2013 19:50:23 +0100
Subject: [R] optimization: multiple assignment problem
In-Reply-To: <5107C4330AFCF145AD7E53EE2282964D32012A3A@EEL.pcs.sopres.be>
References: <5107C4330AFCF145AD7E53EE2282964D32012A3A@EEL.pcs.sopres.be>
Message-ID: <98E8D91F-F51D-44CA-9718-A7DDE4C0DDA3@uni-bonn.de>

It would be more clear if you tell, what you want to do instead of what you do not want to do. 

If you start with a usual cost matrix (whatever cost function you have) and you have to assign N to N this reduces to the well-known Munkre?s algorithm (see for example: http://gallery.rcpp.org/articles/minimal-assignment/). If you have to assign M to N, it is an extended version of the Munkre?s algorithm which has been covered by Bourgeois and Lassalle (1971). All this is graph theory. 

Best 

Simon
 
On 14 Nov 2013, at 19:24, Jean-Francois Chevalier <Jean-Francois.Chevalier at bisnode.com> wrote:

> Hello,
> I'm trying to solve a multiple assignment problem.
> I found a package Adagio and its function mknapsack which
> 
> maximize vstar = p(1)*(x(1,1) + ... + x(m,1)) + ... ... + p(n)*(x(1,n) + ... + x(m,n))
> 
> subject to w(1)*x(i,1) + ... + w(n)*x(i,n) <= k(i) for i=1,...,m
> 
> x(1,j) + ... + x(m,j) <= 1 for j=1,...,n x(i,j) = 0 or 1 for i=1,...,m , j=1,...,n ,
> It's close to what I'm trying to do except that
> 1)k(i) = k for any I (not an issue)
> 2)p is dependent of the item AND the knapsack
> 3)each item must be assigned
> 
> maximize vstar = p(1,1)*x(1,1) + ... + p(m,1)*x(m,1) + ... ... + p(1,n)*x(1,n) + ... + p(m,n)*x(m,n)
> 
> with p(j,i) profit of assigning item i to knapsack j
> 
> subject to w(1)*x(i,1) + ... + w(n)*x(i,n) <= k for i=1,...,m
> 
> x(1,j) + ... + x(m,j) = 1 for j=1,...,n x(i,j) = 0 or 1 for i=1,...,m , j=1,...,n ,
> It would be really helpful if you could indicate me any package, function that would solve my problem?
> Thanks in advance,
> Best regards,
> 
> Jean-Fran?ois
> 
> 
> 
> **** DISCLAIMER ****\ "This e-mail and any attachments t...{{dropped:13}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Thu Nov 14 19:57:48 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 14 Nov 2013 12:57:48 -0600
Subject: [R] Column Name Matching in xts Objects
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB0B00772D@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0B00772D@EX02.platinum.com>
Message-ID: <CAPPM_gSj_YC2paqigUQdz_YGZv8-_ykgwiB-taEpbHWf-2iaaw@mail.gmail.com>

On Thu, Nov 14, 2013 at 12:06 PM, Pooya Lalehzari
<plalehzari at platinumlp.com> wrote:
> Hello,
> I noticed an unexpected behavior when using the xts object and I was wondering if anyone knows why that happens. I have a code to create a new column and copy one of the columns to the new column (please see below):
>
> library(xts)
> df = data.frame(stringsAsFactors=FALSE)
> df[1:3,"date"] = c("2001-1-1","2001-1-2","2001-1-3")
> df[1:3,"col1"] = c(1:3)
> df[1:3,"col2"] = c(-1:-3)
> df[1:3,"col3"] = c(101:103)
> rownames(df)= df$date
> df2 = as.xts(df)
> View(df2)
> Col_To_Copy = "col1"
> df2$NewCol = df2[,colnames(df2)==Col_To_Copy]
> View(df2)
>
> This code works, expect, I noticed that when the Col_To_Copy is not found, the last column is renamed to "NewCol". For example:
> library(xts)
> df = data.frame(stringsAsFactors=FALSE)
> df[1:3,"date"] = c("2001-1-1","2001-1-2","2001-1-3")
> df[1:3,"col1"] = c(1:3)
> df[1:3,"col2"] = c(-1:-3)
> df[1:3,"col3"] = c(101:103)
> rownames(df)= df$date
> df2 = as.xts(df)
> View(df2)
> Col_To_Copy = "col5"  # the only line changed
> df2$NewCol = df2[,colnames(df2)==Col_To_Copy]
> View(df2)
>
> In this case, the last column's name is changed to "NewCol". Is that behavior expected for xts objects?
>
xts doesn't have a $<- method, so $<-.zoo is dispatched.  I'm not
familiar with the function, but the behavior you found is explicitly
defined, so that seems to suggest it was intended.

>From "$<-.zoo":

  wi <- match(x, colnames(object))
  if(is.na(wi)) {
    object <- cbind(object, value)
    if(is.null(dim(object))) dim(object) <- c(length(object), 1)
    colnames(object)[NCOL(object)] <- x
  } else {
    ...

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From wdunlap at tibco.com  Thu Nov 14 20:30:55 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 Nov 2013 19:30:55 +0000
Subject: [R] polygon circling a graph
In-Reply-To: <CAJMZ3ceBmehpyMUMTiKYGaG97OT2-Q=nBs3X7uiAg4zNfx896g@mail.gmail.com>
References: <CAJMZ3ceBmehpyMUMTiKYGaG97OT2-Q=nBs3X7uiAg4zNfx896g@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1545D@PA-MBX01.na.tibco.com>

layout.fruchterman.reingold(g) returns a random result, so you
want to call it once and use the one return value.  Also, I think
you need to avoid the rescaling that plot.igraph does.  It looks
like you need to explicitly specify xlim and ylim if you do that,
but I may not have looked long enough at it.

   plot(g, layout=L, rescale=FALSE, xlim=range(L[,1]), ylim=range(L[,2]))
   polygon(L[temp1, ], col = "#0000FFAA")


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of email
> Sent: Thursday, November 14, 2013 10:04 AM
> To: r-help at r-project.org
> Subject: [R] polygon circling a graph
> 
> Hi:
> 
> I want to create a polygon encircling a graph. For this i use convex
> hull  to get the coordinate points for polygon.
> 
> g <- barabasi.game(10)
> L<-layout.fruchterman.reingold(g)
> temp1 <- chull(L)
> temp1 <- c(temp1, temp1[1])
> plot(g, layout=layout.fruchterman.reingold)
> 
> 
> But when i plot the polygon with the code below, the polygon dosen't
> encircle the graph.
> 
> polygon(L[temp1, ], col = "#0000FFAA")
> 
> How can I plot a polygon circling a graph?
> 
> Regards:
> John
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Thu Nov 14 20:34:32 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 14 Nov 2013 11:34:32 -0800 (PST)
Subject: [R] polygon circling a graph
In-Reply-To: <CAJMZ3ceBmehpyMUMTiKYGaG97OT2-Q=nBs3X7uiAg4zNfx896g@mail.gmail.com>
References: <CAJMZ3ceBmehpyMUMTiKYGaG97OT2-Q=nBs3X7uiAg4zNfx896g@mail.gmail.com>
Message-ID: <1384457672515-4680484.post@n4.nabble.com>

Please post the packages from which 'barabasi' and 'layout.fruch....'
originate (not to mention whatever the plot() method is for whatever class
your 'g' is).  Further, without seeing what your data look like we have no
way of knowing whether you've fed the appropriate elements of "L" to chull.


email mail wrote
> Hi:
> 
> I want to create a polygon encircling a graph. For this i use convex
> hull  to get the coordinate points for polygon.
> 
> g <- barabasi.game(10)
> L<-layout.fruchterman.reingold(g)
> temp1 <- chull(L)
> temp1 <- c(temp1, temp1[1])
> plot(g, layout=layout.fruchterman.reingold)
> 
> 
> But when i plot the polygon with the code below, the polygon dosen't
> encircle the graph.
> 
> polygon(L[temp1, ], col = "#0000FFAA")
> 
> How can I plot a polygon circling a graph?
> 
> Regards:
> John
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/polygon-circling-a-graph-tp4680479p4680484.html
Sent from the R help mailing list archive at Nabble.com.


From erkcan at hotmail.com  Thu Nov 14 20:46:17 2013
From: erkcan at hotmail.com (=?iso-8859-1?Q?Erkcan_=D6zcan?=)
Date: Thu, 14 Nov 2013 21:46:17 +0200
Subject: [R] Fitting arbitrary curve to 1D data with error bars
In-Reply-To: <CAPtbhHwTzpnD-jVksDJROYraLOpqDw3tWta88M-+_d=DMTf7ag@mail.gmail.com>
References: <BLU0-SMTP1192B108F21D95125ED90CADFF90@phx.gbl>
	<CAPtbhHyCzMfHGPhM1awnTo7s5EQOJg9B68n6=YUh4Wog+i07Ww@mail.gmail.com>
	<BLU0-SMTP18773F73AC0865EBCE0E4AEDFF80@phx.gbl>
	<CAPtbhHwTzpnD-jVksDJROYraLOpqDw3tWta88M-+_d=DMTf7ag@mail.gmail.com>
Message-ID: <BLU0-SMTP868567246B3BFC59B5F40DDFF80@phx.gbl>

Thanks, this was a useful pointer. Since the function I am trying to fit is exponential, I decided to use nls. And I was able to reproduce exactly the results and the plot in the URL I had posted. For future reference, here is the R code I wrote:


require("gplots")
xx <- 1:10
yy <- c(1.56,1.20,1.10,0.74,0.57,0.55,0.31,0.27,0.28,0.11)
dy <- c(0.02,0.02,0.20,0.03,0.03,0.10,0.05,0.02,0.10,0.05)
plotCI(xx,yy,uiw=dy,gap=0)
nlmod <- nls(yy ~ Alpha * exp(Beta * xx), start=list(Alpha=1, Beta=-1))
lines(xx, predict(nlmod), col = "blue")
wnlmod <- nls(yy ~ Alpha * exp(Beta * xx), start=list(Alpha=1, Beta=-1), weights=dy^-2)
lines(xx, predict(wnlmod), col = "red")


Thanks to everybody who responded,

e.

On 14 Nov 2013, at 11:34, Suzen, Mehmet wrote:

> Maybe you are after "weights" option given by 'lm' or 'glm'
> 
> See: http://stackoverflow.com/questions/6375650/function-for-weighted-least-squares-estimates
> 
> On 14 November 2013 10:01, Erkcan ?zcan <erkcan at hotmail.com> wrote:
>> Thanks, but if you have another closer look to my post, you will see that my question has nothing to do with drawing error bars on a plot.
>> 
>> What I want is to do a curve fit to a data with error bars.
>> 
>> Best,
>> e.
>> 
>> On 14 Nov 2013, at 04:21, Suzen, Mehmet wrote:
>> 
>>> If you are after adding error bars in a scatter plot; one example is
>>> given below :
>>> 
>>> #some example data
>>> set.seed(42)
>>> df <- data.frame(x = rep(1:10,each=5), y = rnorm(50))
>>> 
>>> #calculate mean, min and max for each x-value
>>> library(plyr)
>>> df2 <- ddply(df,.(x),function(df)
>>> c(mean=mean(df$y),min=min(df$y),max=max(df$y)))
>>> 
>>> #plot error bars
>>> library(Hmisc)
>>> with(df2,errbar(x,mean,max,min))
>>> grid(nx=NA,ny=NULL)
>>> 
>>> (From: http://stackoverflow.com/questions/13032777/scatter-plot-with-error-bars)
>>> 
>> 
> 


From lopez235 at llnl.gov  Thu Nov 14 21:50:09 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 14 Nov 2013 20:50:09 +0000
Subject: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to abort
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB06F2@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/bb364fa4/attachment.pl>

From drf at vims.edu  Thu Nov 14 22:29:08 2013
From: drf at vims.edu (David R Forrest)
Date: Thu, 14 Nov 2013 21:29:08 +0000
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <CDE7CA8F-0062-4E71-BFB7-3C9FDA0B068B@vims.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>, ,
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>,
	<DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>,
	<DBD8C8ED-98B0-41DE-9927-FF34C6BE3BD7@vims.edu>,
	<DUB126-W16A28AE7FD65F5F5B0FC3E80F90@phx.gbl>,
	<0FF0603C-A50E-47E8-8AA8-7407AA7F5715@vims.edu>
	<DUB126-W6986A26A21D3556F92864480F90@phx.gbl>
	<CDE7CA8F-0062-4E71-BFB7-3C9FDA0B068B@vims.edu>
Message-ID: <8EC78533-C239-4F0C-9089-7DE5C4F06394@vims.edu>

Hi Bander,

I'm pushing this discussion back to the list, because I'm not sure of the shape/rate parameters for rpareto and rexp and how they'd be applied across this mix of typo'd papers.

# Reed Equation 6 http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf exponentiated per end of sec 3:
rdpln<-function(n,a=1,b=1,t=1,v=0){exp(v+t*rnorm(n,sd=t)+rexp(n,rate=1/a)-rexp(n,rate=1/b))}

# Reed Equation 10:
library(VGAM)
rdpln2<-function(n,a,b,v,t){ rlnorm(n,meanlog=v,sdlog=t)*
                               rpareto(n,location=1,shape=1/a)/
                               rpareto(n,location=1,shape=1/b)}
 
boxplot(data.frame(x1= log(rdpln(a=2.5,b=.01,t=0.45,v=6.5,n=100000)), x2= log(rdpln2(a=2.5,b=.01,t=0.45,v=6.5,n=100000))))  

# Reed equation 8 http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf 
# with S1 errata #1 from http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048964 

ddpln <- function(x, a=1, b=1, v=0, t=1){
 # Density of Double Pareto LogNormal distribution
 # from "b. alzahrani" <cs_2002 at hotmail.com> email of 2013-11-13
 # per formula 8 from http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf

  c <- (a * b /(a+b))

  norm1<-pnorm((log(x)-v-(a*t^2))/t)
  norm2<-pnorm((log(x)-v+(b*t^2))/t)
  expo1<-  a*v+(a^2*t^2/2)
  expo2<- -b*v+(b^2*t^2/2)  # edited from the paper's eqn 8  with: s/t/v/

  z<- (x^(-a-1)) * exp(expo1)*(  norm1)
  y<- (x^( b-1)) * exp(expo2)*(1-norm2)  # 1-norm is the complementary CDF of N(0,1)

  c*(z+y)
}


Dave



On Nov 14, 2013, at 9:12 AM, David Forrest <drf at vims.edu>
 wrote:

> 
> I think exponentiation of eqn 6 from the Reed paper generates DPLN variates directly, so maybe:
> 
> rdpln=function(n,a=1,b=1,t=1,v=0){exp(v+t*rnorm(n,sd=t)+rexp(n,rate=1/a)-rexp(n,rate=1/b))}
> 
> 
> Dave
> 
> 
> On Nov 13, 2013, at 4:34 PM, "b. alzahrani" <cs_2002 at hotmail.com>
> wrote:
> 
>> You help is much appreciated. Just one last point if you could help, Now I want to pass this curve to a function that can generate random numbers distributed according to DPLN ( right curve).
>> 
>> I found the package Runuran can do that http://cran.r-project.org/web/packages/Runuran/Runuran.pdf  but I do not know how to do it I think it would be something similar to page 8 and 9.
>> 
>> Regards
>> ******************************************************************
>> Bander 
>> *************************************
>> 
>> 
>> 
>> From: drf at vims.edu
>> To: cs_2002 at hotmail.com
>> Subject: Re: [R] Double Pareto Log Normal Distribution DPLN
>> Date: Wed, 13 Nov 2013 21:13:43 +0000
>> 
>> 
>> I read the parameters in Fig 4, right as "DPLN[2.5,0.1,0.45,6.5]", so:
>> 
>> x<- 10^seq(0,4,by=.1)
>> plot(x,ddpln(x,a=2.5,b=.01,v=6.5,t=0.45),log='xy',type='l')
>> 
>> ... and the attached graph does not look dissimilar the figure--It starts at 10^-2, goes through 10^-4 at x=100, and elbows down around 900 and passes through 10^-6 at about 2000.
>> 
>> The correction of Reed helps -- The uncorrected Reed Eq9 equation suggests that the the 't' in Sehshadri Eq9 should be a 'v' , but it doesn't exactly make sense with the extra 'a' in there.  If the errata clears that up, then your expo2 term looks just like the expo1 term, but with a=-b.
>> 
>> 
>> 
>> 
>> 
>> On Nov 13, 2013, at 3:43 PM, "b. alzahrani" wrote: > Thank you very much for the help and the change you suggested in my code, I also found a correction on equation 9 that has been published by Reed ( here http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf i.e. the original paper on Double Pareto Log Normal Distribution ). > > can you please see the correction in this linkhttp://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0048964 (in Supporting Information section, appendix S1), does your suggested code coincide with the correction on this link? as I can see > > Actually, I am interested in the most right curve in figure 4. and if we plot the curve with same order of the paper's parameters you suggests: plot(x,ddpln(x,a=2.8,b=.01,v=6.5,t=0.45),log='xy',type='l') the curve is different from the one in the paper?? > > Thanks > > ****************************************************************** > Bander Alzahrani, > ************************************* > > > > > From: drf at vims.edu > > To: cs_2002 at hotmail.com > > CC: r-help at stat.math.ethz.ch > > Subject: Re: [R] Double Pareto Log Normal Distribution DPLN > > Date: Wed, 13 Nov 2013 19:09:34 +0000 > > > > ...Additionally...your set of parameters match none of the curves in figure 4. > > > > I think the ordering of the parameters as listed on the graphs is different than in the text of the article. > > > > The 'v' parameter controls the location of the 'elbow' and should be near log(x) in each graph, while the 't' parameter is the sharpness of the elbow. So eyeballing the elbows: > > > > log(c(80,150,300))= 4.382027 5.010635 5.703782 > > > > These appear to match positional parameter #4 in the legends, which you apply as parameter t in your function. > > > > > > # editing your function a bit: > > > > ddpln <- function(x, a=2.5, b=0.01, v=log(100), t=v/10){ > > # Density of Double Pareto LogNormal distribution > > # from "b. alzahrani" email of 2013-11-13 > > # per formula 8 from http://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf > > > > c <- (a * b /(a+b)) > > > > norm1<-pnorm((log(x)-v-(a*t^2))/t) > > norm2<-pnorm((log(x)-v+(b*t^2))/t) > > expo1<- a*v+(a^2*t^2/2) > > expo2<- -b*v+(b^2*t^2/2) # edited from the paper's eqn 8 with: s/t/v/ > > > > z<- (x^(-a-1)) * exp(expo1)*(norm1) > > y<- (x^(b-1)) * exp(expo2)*(1-norm2) # 1-norm is the complementary CDF of N(0,1) > > > > c*(z+y) > > } > > > > x<-10^seq(0,5,by=0.1) # 0-10k > > > > plot(x,ddpln(x,a=2.8,b=.01,v=3.8,t=0.35),log='xy',type='l') # Similar to fig 4 left. > > > > plot(x,ddpln(x,a=2.5,b=.01,v=log(2)),log='xy',type='l') > > plot(x,ddpln(x,a=2.5,b=.01,v=log(10)),log='xy',type='l') > > plot(x,ddpln(x,a=2.5,b=.01,v=log(100)),log='xy',type='l') > > plot(x,ddpln(x,a=2.5,b=.01,v=log(1000)),log='xy',type='l') > > plot(x,ddpln(x,a=2.5,b=.01,v=log(10000)),log='xy',type='l') > > > > Dave > > > > On Nov 13, 2013, at 11:43 AM, "b. alzahrani" > > wrote: > > > > > > > > Hi > > > > > > I found this paperhttp://cs.stanford.edu/people/jure/pubs/dpln-kdd08.pdf that models the DPLN distribution as in equation 8. I implemented this in R but cannot get the same curve as in Figure 4. can you please check if my code below is correct: e.g. is the use of pnorm() correct here? > > > > > > ddlpn <- function(x){ > > > a=2.8 > > > b=0.01 > > > v=0.45 > > > t=6.5 > > > j <- (a * b /(a+b)) > > > > > > norm1<-pnorm((log(x)-v-(a*t^2))/t) > > > expo1<- a*v+(a^2*t^2/2) > > > > > > z<-exp(expo1)*(x^(-a-1))*(norm1) > > > > > > norm2<-pnorm((log(x)-v+(b*t^2))/t) > > > expo2<- -b*t+(b^2*t^2/2) > > > > > > y<- x^(b-1)*exp(expo2)*(1-norm2) # 1-norm is the complementary CDF of N(0,1) > > > j*(z+y) > > > } > > > ****************************************************************** > > > Bander Alzahrani, Teacher Assistant > > > Information Systems Department > > > Faculty of Computing & Information Technology > > > King Abdulaziz University > > > > > > ************************************* > > > > > > > > > > > >> From: drf at vims.edu > > >> To: cs_2002 at hotmail.com > > >> CC: r-help at stat.math.ethz.ch > > >> Subject: Re: [R] Double Pareto Log Normal Distribution > > >> Date: Tue, 12 Nov 2013 16:51:22 +0000 > > >> > > >> > > >> http://www.math.uvic.ca/faculty/reed/dPlN.3.pdf is the original ref and has the equations. > > >> > > >> library(VGAM) for *pareto() and library(stats) for *lnorm() should get you most of the way there. > > >> > > >> On Nov 12, 2013, at 10:47 AM, "b. alzahrani" > > >> wrote: > > >> > > >>> Hi guys > > >>> I would like to generate random number Double Pareto Log Normal Distribution (DPLN). does anyone know how to do this in R or if there is any built-in function. > > >>> > > >>> Thanks > > >>> > > >>> ****************************************************************** > > >>> Bander > > >>> ************************************* > > >>> > > >>> > > >>> > > >>> [[alternative HTML version deleted]] > > >>> > > >>> ______________________________________________ > > >>> R-help at r-project.org mailing list > > >>>https://stat.ethz.ch/mailman/listinfo/r-help > > >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html > > >>> and provide commented, minimal, self-contained, reproducible code. > > >> > > >> -- > > >> Dr. David Forrest > > >> drf at vims.edu > > >> > > >> > > >> > > >> > > >> > > > > > > [[alternative HTML version deleted]] > > > > > > ______________________________________________ > > > R-help at r-project.org mailing list > > > https://stat.ethz.ch/mailman/listinfo/r-help > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html > > > and provide commented, minimal, self-contained, reproducible code. > > > > -- > > Dr. David Forrest > >drf at vims.edu > > > > > > > > -- Dr. David Forrest drf at vims.edu 804-684-7900w 757-968-5509h 804-413-7125c 104 Three Point Ct Yorktown, VA, 23692-4325
> 
> --
> Dr. David Forrest
> drf at vims.edu
> 

--
Dr. David Forrest
drf at vims.edu



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 455 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/354f988a/attachment.bin>

From murdoch.duncan at gmail.com  Thu Nov 14 22:38:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 14 Nov 2013 16:38:06 -0500
Subject: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to
	abort
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB06F2@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB06F2@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <528542BE.4020801@gmail.com>

On 13-11-14 3:50 PM, Lopez, Dan wrote:> Windows 7, R 2.15.1 64bit, 
RStudio 0.97.312, Rattle 2.6.26
 >
 > Hi,
 > Please help.
 >
 > I removed rattle then reinstalled then loaded then attempted to open 
rattle with rattle(). But each time I do that My R session in R studio 
aborts and restarts.
 >
 > remove.packages("rattle")
 > install.packages("rattle")
 > library(rattle)
 >
 > How can I fix this? I saw something in rattle-users but that applied 
to Mac.

Do you have problems running rattle in the plain Rgui.exe?  If not, then 
this sounds like an RStudio problem, and you should use one of their 
support sites.

Duncan Murdoch


From lopez235 at llnl.gov  Thu Nov 14 22:41:00 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 14 Nov 2013 21:41:00 +0000
Subject: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to
 abort
In-Reply-To: <528542BE.4020801@gmail.com>
References: <56180B40A4F72A4083C75B30DA86297333DB06F2@PRDEXMBX-05.the-lab.llnl.gov>
	<528542BE.4020801@gmail.com>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB0777@PRDEXMBX-05.the-lab.llnl.gov>

It's happening in the 64bit installation of R I have too (w/o Rstudio). This is R version 2.15.1

Dan


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Thursday, November 14, 2013 1:38 PM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: Re: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to abort

On 13-11-14 3:50 PM, Lopez, Dan wrote:> Windows 7, R 2.15.1 64bit, RStudio 0.97.312, Rattle 2.6.26  >  > Hi,  > Please help.
 >
 > I removed rattle then reinstalled then loaded then attempted to open rattle with rattle(). But each time I do that My R session in R studio aborts and restarts.
 >
 > remove.packages("rattle")
 > install.packages("rattle")
 > library(rattle)
 >
 > How can I fix this? I saw something in rattle-users but that applied to Mac.

Do you have problems running rattle in the plain Rgui.exe?  If not, then this sounds like an RStudio problem, and you should use one of their support sites.

Duncan Murdoch


From murdoch.duncan at gmail.com  Thu Nov 14 22:46:58 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 14 Nov 2013 16:46:58 -0500
Subject: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to
	abort
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB0777@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB06F2@PRDEXMBX-05.the-lab.llnl.gov>
	<528542BE.4020801@gmail.com>
	<56180B40A4F72A4083C75B30DA86297333DB0777@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <528544D2.6080600@gmail.com>

On 13-11-14 4:41 PM, Lopez, Dan wrote:
> It's happening in the 64bit installation of R I have too (w/o Rstudio). This is R version 2.15.1

That's kind of an old R version (from June 2012); there were two more 
releases in the 2.15.x series.  The current release is 3.0.2.  Can you 
upgrade?

Duncan Murdoch

>
> Dan
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Thursday, November 14, 2013 1:38 PM
> To: Lopez, Dan; R help (r-help at r-project.org)
> Subject: Re: [R] Windows 7/Rstudio/Rattle - rattle() Causes R Session to abort
>
> On 13-11-14 3:50 PM, Lopez, Dan wrote:> Windows 7, R 2.15.1 64bit, RStudio 0.97.312, Rattle 2.6.26  >  > Hi,  > Please help.
>   >
>   > I removed rattle then reinstalled then loaded then attempted to open rattle with rattle(). But each time I do that My R session in R studio aborts and restarts.
>   >
>   > remove.packages("rattle")
>   > install.packages("rattle")
>   > library(rattle)
>   >
>   > How can I fix this? I saw something in rattle-users but that applied to Mac.
>
> Do you have problems running rattle in the plain Rgui.exe?  If not, then this sounds like an RStudio problem, and you should use one of their support sites.
>
> Duncan Murdoch
>


From derex.fen at gmail.com  Thu Nov 14 22:46:26 2013
From: derex.fen at gmail.com (Dereje Fentie)
Date: Thu, 14 Nov 2013 22:46:26 +0100
Subject: [R] Warning message during starts up
Message-ID: <CAEqV=werMz7Sb2w1QHS=oDuvZpVyLYnU5QJ=bU0LTEwK1573bQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/258e17d3/attachment.pl>

From cs_2002 at hotmail.com  Thu Nov 14 22:51:25 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Thu, 14 Nov 2013 21:51:25 +0000
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <8EC78533-C239-4F0C-9089-7DE5C4F06394@vims.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
	<DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
	<DBD8C8ED-98B0-41DE-9927-FF34C6BE3BD7@vims.edu>
	<DUB126-W16A28AE7FD65F5F5B0FC3E80F90@phx.gbl>
	<0FF0603C-A50E-47E8-8AA8-7407AA7F5715@vims.edu>
	<DUB126-W6986A26A21D3556F92864480F90@phx.gbl>
	<CDE7CA8F-0062-4E71-BFB7-3C9FDA0B068B@vims.edu>
	<8EC78533-C239-4F0C-9089-7DE5C4F06394@vims.edu>
Message-ID: <DUB405-EAS9DBB6C281163408B0CF1E80F80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/b683964a/attachment.pl>

From hwborchers at googlemail.com  Thu Nov 14 23:03:41 2013
From: hwborchers at googlemail.com (Hans W.Borchers)
Date: Thu, 14 Nov 2013 22:03:41 +0000
Subject: [R] optimization: multiple assignment problem
References: <5107C4330AFCF145AD7E53EE2282964D32012A3A@EEL.pcs.sopres.be>
Message-ID: <loom.20131114T225429-368@post.gmane.org>

Jean-Francois Chevalier <Jean-Francois.Chevalier <at> bisnode.com> writes:
> 

You have already given the answer yourself. You have binary variables x(j, i),
you need to set up the inequalities, and then apply one of the mixed-integer
linear programming solvers in R, for instance 'lpSolve', 'Rglpk', 'Rsymphony'.

Setting up the inequalities may be slightly involved. You have not provided
reproducible code, so no concrete answer possible.

Hans Werner

> Hello,
> I'm trying to solve a multiple assignment problem.
> I found a package Adagio and its function mknapsack which
> maximize vstar = p(1)*(x(1,1) + ... + x(m,1)) + ... ... + 
>                  p(n)*(x(1,n) + ... + x(m,n))
> subject to w(1)*x(i,1) + ... + w(n)*x(i,n) <= k(i) for i=1,...,m
> x(1,j) + ... + x(m,j) <= 1 for j=1,...,n x(i,j) = 0 or 1 
>     for i=1,...,m , j=1,...,n ,
> It's close to what I'm trying to do except that
> 1)k(i) = k for any I (not an issue)
> 2)p is dependent of the item AND the knapsack
> 3)each item must be assigned
> maximize vstar = p(1,1)*x(1,1) + ... + p(m,1)*x(m,1) + ... ... + 
>                             p(1,n)*x(1,n) + ... + p(m,n)*x(m,n)
> with p(j,i) profit of assigning item i to knapsack j
> subject to w(1)*x(i,1) + ... + w(n)*x(i,n) <= k for i=1,...,m
> x(1,j) + ... + x(m,j) = 1 for j=1,...,n x(i,j) = 0 or 1 
>      for i=1,...,m , j=1,...,n ,
> It would be really helpful if you could indicate me any package, 
> function that would solve my problem?
> Thanks in advance,
> Best regards,
> Jean-Fran?ois


From andrewdigby at mac.com  Fri Nov 15 01:31:40 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Fri, 15 Nov 2013 13:31:40 +1300
Subject: [R] Inconsistent results between caret+kernlab versions
Message-ID: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>


I'm using caret to assess classifier performance (and it's great!). However, I've found that my results differ between R2.* and R3.* - reported accuracies are reduced dramatically. I suspect that a code change to kernlab ksvm may be responsible (see version 5.16-24 here: http://cran.r-project.org/web/packages/caret/news.html). I get very different results between caret_5.15-61 + kernlab_0.9-17 and caret_5.17-7 + kernlab_0.9-19 (see below).

Can anyone please shed any light on this?

Thanks very much!


### To replicate:

require(repmis)  # For downloading from https
df <- source_data('https://dl.dropboxusercontent.com/u/47973221/data.csv', sep=',')
require(caret)
svm.m1 <- train(df[,-1],df[,1],method='svmRadial',metric='Kappa',tunelength=5,trControl=trainControl(method='repeatedcv', number=10, repeats=10, classProbs=TRUE))
svm.m1
sessionInfo()

### Results - R2.15.2

> svm.m1
1241 samples
   7 predictors
  10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676? 

No pre-processing
Resampling: Cross-Validation (10 fold, repeated 10 times) 

Summary of sample sizes: 1116, 1116, 1114, 1118, 1118, 1119, ... 

Resampling results across tuning parameters:

  C     Accuracy  Kappa  Accuracy SD  Kappa SD
  0.25  0.684     0.63   0.0353       0.0416  
  0.5   0.729     0.685  0.0379       0.0445  
  1     0.756     0.716  0.0357       0.0418  

Tuning parameter ?sigma? was held constant at a value of 0.247
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were C = 1 and sigma = 0.247. 
> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] e1071_1.6-1     class_7.3-5     kernlab_0.9-17  repmis_0.2.4    caret_5.15-61   reshape2_1.2.2  plyr_1.8        lattice_0.20-10 foreach_1.4.0   cluster_1.14.3 

loaded via a namespace (and not attached):
 [1] codetools_0.2-8 compiler_2.15.2 digest_0.6.0    evaluate_0.4.3  formatR_0.7     grid_2.15.2     httr_0.2        iterators_1.0.6 knitr_1.1       RCurl_1.95-4.1  stringr_0.6.2   tools_2.15.2  

### Results - R3.0.2

> require(caret)
> svm.m1 <- train(df[,-1],df[,1],method=?svmRadial?,metric=?Kappa?,tunelength=5,trControl=trainControl(method=?repeatedcv?, number=10, repeats=10, classProbs=TRUE))
Loading required package: class
Warning messages:
1: closing unused connection 4 (https://dl.dropboxusercontent.com/u/47973221/df.Rdata) 
2: executing %dopar% sequentially: no parallel backend registered 
> svm.m1
1241 samples
   7 predictors
  10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676? 

No pre-processing
Resampling: Cross-Validation (10 fold, repeated 10 times) 

Summary of sample sizes: 1118, 1117, 1115, 1117, 1116, 1118, ... 

Resampling results across tuning parameters:

  C     Accuracy  Kappa  Accuracy SD  Kappa SD
  0.25  0.372     0.278  0.033        0.0371  
  0.5   0.39      0.297  0.0317       0.0358  
  1     0.399     0.307  0.0289       0.0323  

Tuning parameter ?sigma? was held constant at a value of 0.2148907
Kappa was used to select the optimal model using  the largest value.
The final values used for the model were C = 1 and sigma = 0.215. 
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] e1071_1.6-1     class_7.3-9     kernlab_0.9-19  repmis_0.2.6.2  caret_5.17-7    reshape2_1.2.2  plyr_1.8        lattice_0.20-24 foreach_1.4.1   cluster_1.14.4 

loaded via a namespace (and not attached):
[1] codetools_0.2-8 compiler_3.0.2  digest_0.6.3    grid_3.0.2      httr_0.2        iterators_1.0.6 RCurl_1.95-4.1  stringr_0.6.2   tools_3.0.2  


From miaojpm at gmail.com  Fri Nov 15 02:53:39 2013
From: miaojpm at gmail.com (jpm miao)
Date: Fri, 15 Nov 2013 09:53:39 +0800
Subject: [R] Find the cutoff correlation value for Pearson correlation test
Message-ID: <CABcx46AyRePpnMTHswNw9B1Ey6n3FyONGp76Hik1D-p59f+nyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/8f53884e/attachment.pl>

From jim at bitwrit.com.au  Fri Nov 15 04:44:13 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 15 Nov 2013 14:44:13 +1100
Subject: [R] Find the cutoff correlation value for Pearson correlation
 test
In-Reply-To: <CABcx46AyRePpnMTHswNw9B1Ey6n3FyONGp76Hik1D-p59f+nyA@mail.gmail.com>
References: <CABcx46AyRePpnMTHswNw9B1Ey6n3FyONGp76Hik1D-p59f+nyA@mail.gmail.com>
Message-ID: <5285988D.6010509@bitwrit.com.au>

On 11/15/2013 12:53 PM, jpm miao wrote:
> Hi,
>
>     I find a few Pearson correlation test functions like
>
>     fBasics::correlationTest or stats::cor.test
>
> which give the p-value of the test result. Is there a function that
> calculate the cutoff correlation value for a specific p-value , e.g., p =
> 0.05?
>
> I have a plot for the cross correlations between two time series, and I
> would like to add a horizontal line that marks the significance of the
> correlations.

Hi Miao,
Perhaps you could use the confidence interval.

Jim


From smartpink111 at yahoo.com  Fri Nov 15 01:21:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 14 Nov 2013 16:21:25 -0800 (PST)
Subject: [R] getting the results of tapply into a single matrix
Message-ID: <1384474885.8064.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
example <- read.table(text="ID Sex Location CL
1?? F??? lake1?? 40
1?? F??? lake1??? 
1?? F??? lake1???? 43
2?? M??? lake1??? 30
3?? M??? lake2??? 22
4?? F??? lake2???? 25
4?? F??? lake2???? 27",sep="",header=TRUE,stringsAsFactors=FALSE,fill=TRUE) 


aggregate(CL~.,example,mean,na.rm=TRUE)

#or
library(plyr)
ddply(example,.(ID,Sex,Location),summarize,CL=mean(CL,na.rm=TRUE))


#or from `result`
?res <- setNames(cbind(expand.grid(dimnames(result),stringsAsFactors=FALSE),as.data.frame(as.matrix(result))),c("Location","Sex","ID","CL"))
?res[!is.na(res$CL),c(3,2,1,4)]

###It would be better to store the results in a data.frame than in a matrix for this case.

A.K.



I have a table with three categorical columns (ID, Sex, Location) and a 
measurement column (CL). These are measurements from individuals in a 
study. Some individuals were measured more than once and thus have 
multiple rows. For those individuals, I need to take an average of all 
of their measurements so that I can run statistical tests without having pseudoreplication. Below is an example table with the code that I am 
using, the results that I am getting, and the results that I want (I am 
calling the table "example"). 
? 
ID Sex Location CL 
1 ? F ? ?lake1 ? ? 40 
1 ? F ? ?lake1 ? ? 
1 ? F ? ?lake1 ? ? 43 
2 ? M ? ?lake1 ? ?30 
3 ? M ? ?lake2 ? ?22 
4 ? F ? ?lake2 ? ? 25 
4 ? F ? ?lake2 ? ? 27 

> result <- with(example, tapply(CL, list(Location, Sex, ID), mean, na.rm=T)) 

this almost does what I want. I takes the mean for each ID, and 
retains its relationship to the categorical variables, the problem is 
the output looks like this: 

, , 1 

? ? ? ? ? ? ?F M 
lake1 41.66667 ? 
lake2 ? ? ? ? ? 

, , 2 

? ? ? F ? ? ? ?M 
lake1 ? 30.00000 
lake2 ? ? ? ? ? 

, , 3 

? ? ? F ? ? ? ?M 
lake1 ? ? ? ? ? 
lake2 ? 22.00000 

, , 4 

? ? ? ? ? ? ?F M 
lake1 ? ? ? ? ? 
lake2 26.00000 ? 

How do I get those results back into a single table like I 
originally had. In other words, I want a table that looks like this: ? 

ID Sex Location CL 
1 ? F ? ?lake1 ? ? 41.66667 
2 ? M ? ?lake1 ? ?30 
3 ? M ? ?lake2 ? ?22 
4 ? F ? ?lake2 ? ? 26.00000 
? 

Thanks for the help!


From lillydethier at gmail.com  Fri Nov 15 03:01:27 2013
From: lillydethier at gmail.com (Lilly Dethier)
Date: Thu, 14 Nov 2013 18:01:27 -0800
Subject: [R] Error in MuMIn "models are not all fitted to the same data"
Message-ID: <CAOK+e=Z_0pMEFKdPxZ5Eub+DYhHFjzGk3Lcqczsa9TimAP4n_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131114/4a328d75/attachment.pl>

From jrkrideau at inbox.com  Fri Nov 15 14:58:34 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 15 Nov 2013 05:58:34 -0800
Subject: [R] making a barplot with table of experimental conditions
 underneath (preferably ggplot2)
In-Reply-To: <F2F5B8302DC.000004A3jrkrideau@inbox.com>
References: <5ff7898bad1b4a4a809f4c51902634847344670e@umcexmbx11.umcn.nl>
Message-ID: <FDEDAC99D78.00001019jrkrideau@inbox.com>

Oops, that last line  of code should read
df.plot + scale_x_discrete( labels = df$labs)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jrkrideau at inbox.com
> Sent: Thu, 14 Nov 2013 09:02:19 -0800
> To: n.hubner at ncmls.ru.nl, r-help at r-project.org
> Subject: RE: [R] making a barplot with table of experimental conditions
> underneath (preferably ggplot2)
> 
> Hi Nina,
> I think the following code does what you want (thanks to Jim Lemon for
> showing me what you wanted in terms of x-axis tick labels)
> 
> However I  think that barcharts are generally evil  so I changed your
> geom_bar to geom_point.  Feel free to change it back if your discipline
> requires it but I think it shows your data better
> 
> Also you were doing some unnecessary extraction of dat from the
> data.frame so I just included a "data =" statement in qplot and changed
> the variable names in it to the original df names. This makes for cleaner
> and more readable code.
> 
> df <- data.frame (experiment=c("E1","E2","E3","E4"), mean = c(3,4,5,6),
> stdev=c(0.1,0.1,0.05,0.2), method = c("STD","STD", "FP", "FP"), enzyme =c
> ("T","T/L","T","T/L"), denaturation=c("U","U","0.05%RG", "0.1%RG"))
> 
> df$labs  <-  paste(df[,4],"\n ",df[,5], "\n ",df[,6]) # create labels
> 
> df.plot <- qplot(experiment,mean,data = df, xlab="", ylab="# peptides
> identified")+
>   geom_point(fill="grey")+
>   geom_errorbar(aes(x=experiment, ymin=mean-stdev, ymax=mean+stdev),
> width=0.25)
> 
> p + scale_x_discrete( labels = df$labs)
> 
> I hop
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: n.hubner at ncmls.ru.nl
>> Sent: Wed, 13 Nov 2013 14:24:28 +0000
>> To: r-help at r-project.org
>> Subject: [R] making a barplot with table of experimental conditions
>> underneath (preferably ggplot2)
>> 
>> Dear all,
>> 
>> my data looks the following:
>> 
>> df <- data.frame (experiment=c("E1","E2","E3","E4"), mean = c(3,4,5,6),
>> stdev=c(0.1,0.1,0.05,0.2), method = c("STD","STD", "FP", "FP"), enzyme
>> =c
>> ("T","T/L","T","T/L"), denaturation=c("U","U","0.05%RG", "0.1%RG"))
> 
>> I would like to make a bar plot with standard deviation which I solved
>> the following way:
>> 
>> x <- df$experiment
>> y <- df$mean
>> sd <- df$stdev
>> 
>> df.plot <- qplot(x,y,xlab="", ylab="# peptides identified")+
>>   geom_bar(colour="black", fill="darkgrey")+
>>   geom_errorbar(aes(x=x, ymin=y-sd, ymax=y+sd), width=0.25)
>> 
>> df.plot
>> 
> 
>> However, as the labels for the x-axis (the bars) I do not want the
>> experiment number, as now, but instead a table containing the other
>> columns of my data.frame (method, enzyme, denaturation) with the
>> description in the front and the certain 'value' below the bars.
>> 
>> I am looking forward to your suggestions!
>> 
>> With best wishes,
>> 
>> Nina
>> ______________________________________________
>> 
>> Dr. Nina C. Hubner
>> scientist quantitative proteomics
>> 
>> Dep. of Molecular Biology, Radboud University Nijmegen, The Netherlands
>> e-mail: n.hubner at ncmls.ru.nl
>> tel: +31-24-3613655
>> 
>> Visiting address:
>> NCMLS, Dept of Molecular Biology (route 274)
>> Geert Grooteplein 26/28
>> 6525 GA Nijmegen
>> The Netherlands
>> 
>> 
>> 
>> 
>> The Radboud University Medical Centre is listed in the Commercial
>> Register of the Chamber of Commerce under file number 41055629.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
> Check it out at http://www.inbox.com/earth

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From matteo.tiratelli at mindshareworld.com  Fri Nov 15 14:22:52 2013
From: matteo.tiratelli at mindshareworld.com (matira)
Date: Fri, 15 Nov 2013 05:22:52 -0800 (PST)
Subject: [R] R for loop
Message-ID: <1384521772459-4680515.post@n4.nabble.com>

Hi
I'm quite new to R and I am having trouble with this code:

names(Mindreader_2012_vars)
varlist<-names(Mindreader_2012_vars)
for (i in 688:696) {
  for (j in 673:685) {
 
assign(paste("Uk_Cluster_",i-687,sep=""),cbind(get(varlist[j],pos=Mindreader_2012_vars)[get(varlist[i],
pos=Mindreader_2012_vars)>0]))
}
}

I want this code to output 9 matrixes (which are the variables 'i' is
getting) which have 13 columns (one for each of the variables that 'j' is
getting.
At the moment I get 9 matrixes with only 1 column. I guess the issue is the
way I am nesting the loops but i can't work out how to make it take all the
values of 'j' in each matrix.

Thanks



--
View this message in context: http://r.789695.n4.nabble.com/R-for-loop-tp4680515.html
Sent from the R help mailing list archive at Nabble.com.


From simone.medori at me.com  Fri Nov 15 13:32:23 2013
From: simone.medori at me.com (Simone Medori)
Date: Fri, 15 Nov 2013 13:32:23 +0100
Subject: [R] Merge xts and Return.portfolio
References: <65B9B514AB6BD74E9781BFC23028D87218AF18EA@MUN2WSP05021.global.pioneer.com>
Message-ID: <5E50A4E7-5A86-4E86-B0AD-72F0F107B7A4@me.com>

Hi,
I'm triyng to merge two xts time series objects, one of them is from Return.portfolio (PerformanceAnalytics).

Despite the merging xts objects have the same indexes, the merged object shows extra lines at the day before of every entry.

I noticed that indexes of merging objects have different classes ("POSIXct" and "Date"): might be this the reason? Why do I get different extra dates anyway?

Kind regards,

Simone


> require(PerformanceAnalytics)
> require(quantmod)
>  
> benchmark<-c("^STOXX50E","^NDX")
> downloaded<-getSymbols(benchmark,from=as.Date(Sys.Date()-15))
> prices <- merge.xts(na.locf(do.call(merge,lapply(downloaded, function(x) Cl(get(x))))))
> returns <- Return.calculate(prices)[-1,] #get rid of first NA
>  
> returns
> #STOXX50E.Close     NDX.Close
> #2013-11-01   -0.005153278  0.0006009953
> #2013-11-04    0.000000000  0.0014764362
> #2013-11-05   -0.005314304  0.0012024522
> #2013-11-06    0.006745896 -0.0010151026
> #2013-11-07   -0.004390787 -0.0188959585
> #2013-11-08    0.000000000  0.0136779259
> #2013-11-11    0.003236959 -0.0011464756
> #2013-11-12   -0.005945303  0.0006690495
> #2013-11-13   -0.004451870  0.0119843220
> #2013-11-14    0.010764042  0.0028130469
>  
> Return.portfolio(returns)
> #             portfolio.returns
> #2013-11-01     -0.0022761415
> #2013-11-04      0.0007403469
> #2013-11-05     -0.0020441262
> #2013-11-06      0.0028386740
> #2013-11-07     -0.0116652539
> #2013-11-08      0.0068094113
> #2013-11-11      0.0010398246
> #2013-11-12     -0.0026371940
> #2013-11-13      0.0037957949
> #2013-11-14      0.0067416934
> #Warning message:
> #  In Return.portfolio(returns) :
> #  weighting vector is null, calulating an equal weighted portfolio
>  
> merge(returns,Return.portfolio(returns))
>  
> #STOXX50E.Close     NDX.Close portfolio.returns
> #2013-10-31             NA            NA     -0.0022761415 # Return.portfolio merges into extra lines!
> #2013-11-01   -0.005153278  0.0006009953                NA
> #2013-11-03             NA            NA      0.0007403469
> #2013-11-04    0.000000000  0.0014764362                NA
> #2013-11-04             NA            NA     -0.0020441262
> #2013-11-05   -0.005314304  0.0012024522                NA
> #2013-11-05             NA            NA      0.0028386740
> #2013-11-06    0.006745896 -0.0010151026                NA
> #2013-11-06             NA            NA     -0.0116652539
> #2013-11-07   -0.004390787 -0.0188959585                NA
> #2013-11-07             NA            NA      0.0068094113
> #2013-11-08    0.000000000  0.0136779259                NA
> #2013-11-10             NA            NA      0.0010398246
> #2013-11-11    0.003236959 -0.0011464756                NA
> #2013-11-11             NA            NA     -0.0026371940
> #2013-11-12   -0.005945303  0.0006690495                NA
> #2013-11-12             NA            NA      0.0037957949
> #2013-11-13   -0.004451870  0.0119843220                NA
> #2013-11-13             NA            NA      0.0067416934
> #2013-11-14    0.010764042  0.0028130469                NA

From friendly at yorku.ca  Fri Nov 15 15:16:01 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 15 Nov 2013 09:16:01 -0500
Subject: [R] volume of ellipsoid
In-Reply-To: <1384439709454-4680445.post@n4.nabble.com>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>	<1384431926676-4680435.post@n4.nabble.com>
	<1384439709454-4680445.post@n4.nabble.com>
Message-ID: <52862CA1.8090001@yorku.ca>

On 11/14/2013 9:35 AM, yuanzhi wrote:
> Hi, Carl Witthoft
>
> yes, it looks like a mathematical question. I will try based on your
> suggestion to calculate the volume of the intersection. But I still want to
> know whether there are some functions in R which can calculate the volume of
> an ellipsoid(area for p=2, hypervolume for p>3) containing X, just like the
> "convhulln" function in "geometry" package which can calculate the volume of
> convex hull containing X.
>

See the Appendix A.2 in my paper on Elliptical Insights ...
http://www.datavis.ca/papers/ellipses-STS402.pdf

for the properties of ellipsoids and calculation of (hyper)volumes
based on a spectral decomposition.

The intersection of general ellipsoids is mathematically extremely 
complex.  You can approximate it by acceptance sampling -- finding the
proportion of random points in R^p in the bounding box of the ellipsoids 
which are contained in both.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From josh.m.ulrich at gmail.com  Fri Nov 15 15:30:02 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 15 Nov 2013 08:30:02 -0600
Subject: [R] Merge xts and Return.portfolio
In-Reply-To: <5E50A4E7-5A86-4E86-B0AD-72F0F107B7A4@me.com>
References: <65B9B514AB6BD74E9781BFC23028D87218AF18EA@MUN2WSP05021.global.pioneer.com>
	<5E50A4E7-5A86-4E86-B0AD-72F0F107B7A4@me.com>
Message-ID: <CAPPM_gQGjhu3jobFUjquGhtH9+H8sY+y3N1s+dwVBt1Ys1sXDg@mail.gmail.com>

On Fri, Nov 15, 2013 at 6:32 AM, Simone Medori <simone.medori at me.com> wrote:
> Hi,
> I'm triyng to merge two xts time series objects, one of them is from Return.portfolio (PerformanceAnalytics).
>
> Despite the merging xts objects have the same indexes, the merged object shows extra lines at the day before of every entry.
>
> I noticed that indexes of merging objects have different classes ("POSIXct" and "Date"): might be this the reason? Why do I get different extra dates anyway?
>
Yes, this is the reason.  Specifically, the cause is the difference in
timezone between the POSIXct index and the Date index.

For some reason, Return.portfolio returns a xts object with a POSIXct
index.  Convert it to Date and your merge will work.
rp <- Return.portfolio(returns)
index(rp) <- as.Date(index(rp))
merge(returns,rp)

> Kind regards,
>
> Simone
>
>
>> require(PerformanceAnalytics)
>> require(quantmod)
>>
>> benchmark<-c("^STOXX50E","^NDX")
>> downloaded<-getSymbols(benchmark,from=as.Date(Sys.Date()-15))
>> prices <- merge.xts(na.locf(do.call(merge,lapply(downloaded, function(x) Cl(get(x))))))
>> returns <- Return.calculate(prices)[-1,] #get rid of first NA
>>
>> returns
>> #STOXX50E.Close     NDX.Close
>> #2013-11-01   -0.005153278  0.0006009953
>> #2013-11-04    0.000000000  0.0014764362
>> #2013-11-05   -0.005314304  0.0012024522
>> #2013-11-06    0.006745896 -0.0010151026
>> #2013-11-07   -0.004390787 -0.0188959585
>> #2013-11-08    0.000000000  0.0136779259
>> #2013-11-11    0.003236959 -0.0011464756
>> #2013-11-12   -0.005945303  0.0006690495
>> #2013-11-13   -0.004451870  0.0119843220
>> #2013-11-14    0.010764042  0.0028130469
>>
>> Return.portfolio(returns)
>> #             portfolio.returns
>> #2013-11-01     -0.0022761415
>> #2013-11-04      0.0007403469
>> #2013-11-05     -0.0020441262
>> #2013-11-06      0.0028386740
>> #2013-11-07     -0.0116652539
>> #2013-11-08      0.0068094113
>> #2013-11-11      0.0010398246
>> #2013-11-12     -0.0026371940
>> #2013-11-13      0.0037957949
>> #2013-11-14      0.0067416934
>> #Warning message:
>> #  In Return.portfolio(returns) :
>> #  weighting vector is null, calulating an equal weighted portfolio
>>
>> merge(returns,Return.portfolio(returns))
>>
>> #STOXX50E.Close     NDX.Close portfolio.returns
>> #2013-10-31             NA            NA     -0.0022761415 # Return.portfolio merges into extra lines!
>> #2013-11-01   -0.005153278  0.0006009953                NA
>> #2013-11-03             NA            NA      0.0007403469
>> #2013-11-04    0.000000000  0.0014764362                NA
>> #2013-11-04             NA            NA     -0.0020441262
>> #2013-11-05   -0.005314304  0.0012024522                NA
>> #2013-11-05             NA            NA      0.0028386740
>> #2013-11-06    0.006745896 -0.0010151026                NA
>> #2013-11-06             NA            NA     -0.0116652539
>> #2013-11-07   -0.004390787 -0.0188959585                NA
>> #2013-11-07             NA            NA      0.0068094113
>> #2013-11-08    0.000000000  0.0136779259                NA
>> #2013-11-10             NA            NA      0.0010398246
>> #2013-11-11    0.003236959 -0.0011464756                NA
>> #2013-11-11             NA            NA     -0.0026371940
>> #2013-11-12   -0.005945303  0.0006690495                NA
>> #2013-11-12             NA            NA      0.0037957949
>> #2013-11-13   -0.004451870  0.0119843220                NA
>> #2013-11-13             NA            NA      0.0067416934
>> #2013-11-14    0.010764042  0.0028130469                NA

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From wangdan412 at gmail.com  Fri Nov 15 15:34:47 2013
From: wangdan412 at gmail.com (dan wang)
Date: Fri, 15 Nov 2013 09:34:47 -0500
Subject: [R] modify functions in "stats", but .Call(C_BinDist,
	...) couldn't load C function
Message-ID: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/3c6a8398/attachment.pl>

From simone.medori at me.com  Fri Nov 15 16:01:17 2013
From: simone.medori at me.com (Simone Medori)
Date: Fri, 15 Nov 2013 16:01:17 +0100
Subject: [R] Merge xts and Return.portfolio
In-Reply-To: <CAPPM_gQGjhu3jobFUjquGhtH9+H8sY+y3N1s+dwVBt1Ys1sXDg@mail.gmail.com>
References: <65B9B514AB6BD74E9781BFC23028D87218AF18EA@MUN2WSP05021.global.pioneer.com>
	<5E50A4E7-5A86-4E86-B0AD-72F0F107B7A4@me.com>
	<CAPPM_gQGjhu3jobFUjquGhtH9+H8sY+y3N1s+dwVBt1Ys1sXDg@mail.gmail.com>
Message-ID: <2C464E61-899D-4E32-92A7-3D5D83649FD9@me.com>

Thanks

Simone

> Il giorno 15/nov/2013, alle ore 15:30, Joshua Ulrich <josh.m.ulrich at gmail.com> ha scritto:
> 
>> On Fri, Nov 15, 2013 at 6:32 AM, Simone Medori <simone.medori at me.com> wrote:
>> Hi,
>> I'm triyng to merge two xts time series objects, one of them is from Return.portfolio (PerformanceAnalytics).
>> 
>> Despite the merging xts objects have the same indexes, the merged object shows extra lines at the day before of every entry.
>> 
>> I noticed that indexes of merging objects have different classes ("POSIXct" and "Date"): might be this the reason? Why do I get different extra dates anyway?
> Yes, this is the reason.  Specifically, the cause is the difference in
> timezone between the POSIXct index and the Date index.
> 
> For some reason, Return.portfolio returns a xts object with a POSIXct
> index.  Convert it to Date and your merge will work.
> rp <- Return.portfolio(returns)
> index(rp) <- as.Date(index(rp))
> merge(returns,rp)
> 
>> Kind regards,
>> 
>> Simone
>> 
>> 
>>> require(PerformanceAnalytics)
>>> require(quantmod)
>>> 
>>> benchmark<-c("^STOXX50E","^NDX")
>>> downloaded<-getSymbols(benchmark,from=as.Date(Sys.Date()-15))
>>> prices <- merge.xts(na.locf(do.call(merge,lapply(downloaded, function(x) Cl(get(x))))))
>>> returns <- Return.calculate(prices)[-1,] #get rid of first NA
>>> 
>>> returns
>>> #STOXX50E.Close     NDX.Close
>>> #2013-11-01   -0.005153278  0.0006009953
>>> #2013-11-04    0.000000000  0.0014764362
>>> #2013-11-05   -0.005314304  0.0012024522
>>> #2013-11-06    0.006745896 -0.0010151026
>>> #2013-11-07   -0.004390787 -0.0188959585
>>> #2013-11-08    0.000000000  0.0136779259
>>> #2013-11-11    0.003236959 -0.0011464756
>>> #2013-11-12   -0.005945303  0.0006690495
>>> #2013-11-13   -0.004451870  0.0119843220
>>> #2013-11-14    0.010764042  0.0028130469
>>> 
>>> Return.portfolio(returns)
>>> #             portfolio.returns
>>> #2013-11-01     -0.0022761415
>>> #2013-11-04      0.0007403469
>>> #2013-11-05     -0.0020441262
>>> #2013-11-06      0.0028386740
>>> #2013-11-07     -0.0116652539
>>> #2013-11-08      0.0068094113
>>> #2013-11-11      0.0010398246
>>> #2013-11-12     -0.0026371940
>>> #2013-11-13      0.0037957949
>>> #2013-11-14      0.0067416934
>>> #Warning message:
>>> #  In Return.portfolio(returns) :
>>> #  weighting vector is null, calulating an equal weighted portfolio
>>> 
>>> merge(returns,Return.portfolio(returns))
>>> 
>>> #STOXX50E.Close     NDX.Close portfolio.returns
>>> #2013-10-31             NA            NA     -0.0022761415 # Return.portfolio merges into extra lines!
>>> #2013-11-01   -0.005153278  0.0006009953                NA
>>> #2013-11-03             NA            NA      0.0007403469
>>> #2013-11-04    0.000000000  0.0014764362                NA
>>> #2013-11-04             NA            NA     -0.0020441262
>>> #2013-11-05   -0.005314304  0.0012024522                NA
>>> #2013-11-05             NA            NA      0.0028386740
>>> #2013-11-06    0.006745896 -0.0010151026                NA
>>> #2013-11-06             NA            NA     -0.0116652539
>>> #2013-11-07   -0.004390787 -0.0188959585                NA
>>> #2013-11-07             NA            NA      0.0068094113
>>> #2013-11-08    0.000000000  0.0136779259                NA
>>> #2013-11-10             NA            NA      0.0010398246
>>> #2013-11-11    0.003236959 -0.0011464756                NA
>>> #2013-11-11             NA            NA     -0.0026371940
>>> #2013-11-12   -0.005945303  0.0006690495                NA
>>> #2013-11-12             NA            NA      0.0037957949
>>> #2013-11-13   -0.004451870  0.0119843220                NA
>>> #2013-11-13             NA            NA      0.0067416934
>>> #2013-11-14    0.010764042  0.0028130469                NA
> 
> Best,
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Nov 15 16:41:51 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 15 Nov 2013 09:41:51 -0600
Subject: [R] Find the cutoff correlation value for Pearson correlation
	test
In-Reply-To: <5285988D.6010509@bitwrit.com.au>
References: <CABcx46AyRePpnMTHswNw9B1Ey6n3FyONGp76Hik1D-p59f+nyA@mail.gmail.com>
	<5285988D.6010509@bitwrit.com.au>
Message-ID: <00e501cee219$33e812b0$9bb83810$@tamu.edu>

I haven't looked at fBasics::correlationTest, but cor.test uses
the t distribution to evaluate significance:

t = sqrt(df) * r/sqrt(1 - r^2)

where df=n-2

If you solve that for r, you get

r = t/sqrt(t^2+100-2)

If you choose t as qt(.975, df) for a two-tailed test at p<.05
you can plug in t and place your limits at +/- of that value. Eg
for 100 observations:

> t <- qt(.975, 98)
> t
[1] 1.984467
> rlim <- t/sqrt(t^2+100-2)
> rlim
[1] 0.1965512
> rs <- replicate(1000, cor(rnorm(100), rnorm(100)))
> hist(rs)
> abline(v=c(-rlim, rlim))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, November 14, 2013 9:44 PM
To: jpm miao
Cc: r-help
Subject: Re: [R] Find the cutoff correlation value for Pearson
correlation test

On 11/15/2013 12:53 PM, jpm miao wrote:
> Hi,
>
>     I find a few Pearson correlation test functions like
>
>     fBasics::correlationTest or stats::cor.test
>
> which give the p-value of the test result. Is there a function
that
> calculate the cutoff correlation value for a specific p-value
, e.g., p =
> 0.05?
>
> I have a plot for the cross correlations between two time
series, and I
> would like to add a horizontal line that marks the
significance of the
> correlations.

Hi Miao,
Perhaps you could use the confidence interval.

Jim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From ruipbarradas at sapo.pt  Fri Nov 15 16:48:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 15 Nov 2013 15:48:20 +0000
Subject: [R] modify functions in "stats", but .Call(C_BinDist,
 ...) couldn't load C function
In-Reply-To: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
References: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
Message-ID: <52864244.6000400@sapo.pt>

Hello,

If your C function is in a shared library, take a look at ?dyn.load.

Hope this helps,

Rui Barradas

Em 15-11-2013 14:34, dan wang escreveu:
> Hi all,
>
> I am trying to write a new function based on an existing function in
> "stats".
>
> This function requires to call a c program "C_BinDist". The new function
> couldn't work without load this c script.
>
> How can I find this "C_BinDist" function and load it to make my new
> function work through?
>
> Thanks,
>
> Dan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wangdan412 at gmail.com  Fri Nov 15 16:53:31 2013
From: wangdan412 at gmail.com (dan wang)
Date: Fri, 15 Nov 2013 10:53:31 -0500
Subject: [R] modify functions in "stats", but .Call(C_BinDist,
 ...) couldn't load C function
In-Reply-To: <52864244.6000400@sapo.pt>
References: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
	<52864244.6000400@sapo.pt>
Message-ID: <CA+1Z_YvBjY=X16ZUPZR_dB_7Avp_j=FAnC6EmTzRA5pYGnm7UA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/96809846/attachment.pl>

From dcarlson at tamu.edu  Fri Nov 15 16:56:57 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 15 Nov 2013 09:56:57 -0600
Subject: [R] R for loop
In-Reply-To: <1384521772459-4680515.post@n4.nabble.com>
References: <1384521772459-4680515.post@n4.nabble.com>
Message-ID: <00e701cee21b$50500960$f0f01c20$@tamu.edu>

I would be easier to respond if we had some idea what
Mindreader_2012_vars is, data.frame, list, matrix?

Give us a small, reproducible version of what you are trying to
accomplish. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of matira
Sent: Friday, November 15, 2013 7:23 AM
To: r-help at r-project.org
Subject: [R] R for loop

Hi
I'm quite new to R and I am having trouble with this code:

names(Mindreader_2012_vars)
varlist<-names(Mindreader_2012_vars)
for (i in 688:696) {
  for (j in 673:685) {
 
assign(paste("Uk_Cluster_",i-687,sep=""),cbind(get(varlist[j],po
s=Mindreader_2012_vars)[get(varlist[i],
pos=Mindreader_2012_vars)>0]))
}
}

I want this code to output 9 matrixes (which are the variables
'i' is
getting) which have 13 columns (one for each of the variables
that 'j' is
getting.
At the moment I get 9 matrixes with only 1 column. I guess the
issue is the
way I am nesting the loops but i can't work out how to make it
take all the
values of 'j' in each matrix.

Thanks



--
View this message in context:
http://r.789695.n4.nabble.com/R-for-loop-tp4680515.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From dcarlson at tamu.edu  Fri Nov 15 17:03:55 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 15 Nov 2013 10:03:55 -0600
Subject: [R] Find the cutoff correlation value for Pearson
	correlation	test
In-Reply-To: <00e501cee219$33e812b0$9bb83810$@tamu.edu>
References: <CABcx46AyRePpnMTHswNw9B1Ey6n3FyONGp76Hik1D-p59f+nyA@mail.gmail.com>	<5285988D.6010509@bitwrit.com.au>
	<00e501cee219$33e812b0$9bb83810$@tamu.edu>
Message-ID: <010e01cee21c$492adab0$db809010$@tamu.edu>

I should have added, that these limits are not been corrected
for multiple comparisons. With 1000 tests, we expect about 50 to
be outside the limits. So you might want to use p.adjust() to
take multiple comparisons into account.

David

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David Carlson
Sent: Friday, November 15, 2013 9:42 AM
To: 'Jim Lemon'; 'jpm miao'
Cc: 'r-help'
Subject: Re: [R] Find the cutoff correlation value for Pearson
correlation test

I haven't looked at fBasics::correlationTest, but cor.test uses
the t distribution to evaluate significance:

t = sqrt(df) * r/sqrt(1 - r^2)

where df=n-2

If you solve that for r, you get

r = t/sqrt(t^2+100-2)

If you choose t as qt(.975, df) for a two-tailed test at p<.05
you can plug in t and place your limits at +/- of that value. Eg
for 100 observations:

> t <- qt(.975, 98)
> t
[1] 1.984467
> rlim <- t/sqrt(t^2+100-2)
> rlim
[1] 0.1965512
> rs <- replicate(1000, cor(rnorm(100), rnorm(100)))
> hist(rs)
> abline(v=c(-rlim, rlim))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Thursday, November 14, 2013 9:44 PM
To: jpm miao
Cc: r-help
Subject: Re: [R] Find the cutoff correlation value for Pearson
correlation test

On 11/15/2013 12:53 PM, jpm miao wrote:
> Hi,
>
>     I find a few Pearson correlation test functions like
>
>     fBasics::correlationTest or stats::cor.test
>
> which give the p-value of the test result. Is there a function
that
> calculate the cutoff correlation value for a specific p-value
, e.g., p =
> 0.05?
>
> I have a plot for the cross correlations between two time
series, and I
> would like to add a horizontal line that marks the
significance of the
> correlations.

Hi Miao,
Perhaps you could use the confidence interval.

Jim

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From ripley at stats.ox.ac.uk  Fri Nov 15 17:04:17 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Nov 2013 16:04:17 +0000
Subject: [R] modify functions in "stats", but .Call(C_BinDist,
 ...) couldn't load C function
In-Reply-To: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
References: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
Message-ID: <52864601.70407@stats.ox.ac.uk>

On 15/11/2013 14:34, dan wang wrote:
> Hi all,
>
> I am trying to write a new function based on an existing function in
> "stats".
>
> This function requires to call a c program "C_BinDist". The new function
> couldn't work without load this c script.
>
> How can I find this "C_BinDist" function and load it to make my new
> function work through?

You are confused:  C_BinDist is not a C program and not a function.  It 
is an R object in the stats namespace, so access it as you would any 
other unexported object in a namespace.

>
> Thanks,
>
> Dan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do: no HTML as requested, and this seems to indicate that the 
correct list was R-devel.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Fri Nov 15 17:15:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Nov 2013 10:15:52 -0600
Subject: [R] volume of ellipsoid
In-Reply-To: <52862CA1.8090001@yorku.ca>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>	<1384431926676-4680435.post@n4.nabble.com>
	<1384439709454-4680445.post@n4.nabble.com>
	<52862CA1.8090001@yorku.ca>
Message-ID: <F4D16F2F-C743-4A28-86BC-F9DD126B6C15@comcast.net>


On Nov 15, 2013, at 8:16 AM, Michael Friendly wrote:

> On 11/14/2013 9:35 AM, yuanzhi wrote:
>> Hi, Carl Witthoft
>>
>> yes, it looks like a mathematical question. I will try based on your
>> suggestion to calculate the volume of the intersection. But I still  
>> want to
>> know whether there are some functions in R which can calculate the  
>> volume of
>> an ellipsoid(area for p=2, hypervolume for p>3) containing X, just  
>> like the
>> "convhulln" function in "geometry" package which can calculate the  
>> volume of
>> convex hull containing X.
>>
>
> See the Appendix A.2 in my paper on Elliptical Insights ...
> http://www.datavis.ca/papers/ellipses-STS402.pdf

Thank you so much for that reference, Michael, as well as the  
programming supplements that you constructed and linked in that  
encyclopedic review.

>
> for the properties of ellipsoids and calculation of (hyper)volumes
> based on a spectral decomposition.
>

Copying back the omitted text from the OP who probably is under the  
misapprehension that we are all using Nabble:

>>> But the problem is how to calculate the volume of intersection  
>>> between 2, 3 or more ellipsoids. Are there some functions which  
>>> can calculate the volume of intersection between two region or  
>>> functions which directly calculate the volume of a union of two  
>>> region(the region here is ellipsoid). OR yo you have any good  
>>> ideas solving this problem in R? Thank you all in advance!

> The intersection of general ellipsoids is mathematically extremely  
> complex.  You can approximate it by acceptance sampling -- finding the
> proportion of random points in R^p in the bounding box of the  
> ellipsoids which are contained in both.

So that reduces the problem to defining a function that returns TRUE  
for a point when it is in the interior of an ellipse. So reading your  
section on statistical ellipsoids, I think an intersection test for  
n=2 could require that the squared Mahalanobis distance from the  
centroids be less than the c_1^2 and c_2^2 values for the two  
ellipsoids under consideration.

> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
-- 

David Winsemius, MD
Alameda, CA, USA


From wangdan412 at gmail.com  Fri Nov 15 17:22:51 2013
From: wangdan412 at gmail.com (dan wang)
Date: Fri, 15 Nov 2013 11:22:51 -0500
Subject: [R] modify functions in "stats", but .Call(C_BinDist,
 ...) couldn't load C function
In-Reply-To: <528648C0.2040109@stats.ox.ac.uk>
References: <CA+1Z_Yvap8PKWzaLuhHAXfdLJU4w6nnAkCJCngsRHWdWLygoPQ@mail.gmail.com>
	<52864601.70407@stats.ox.ac.uk>
	<CA+1Z_YvBwXDxXGapRA3CCPwLfvh8XJo9VtScQP6pATR4+4R-UA@mail.gmail.com>
	<528648C0.2040109@stats.ox.ac.uk>
Message-ID: <CA+1Z_Yuwazv=ywK=LL_pDUzO2j97bi6K+5CXEJYA6KHchWR8ZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/2615d21b/attachment.pl>

From Giovanni_Millo at Generali.com  Fri Nov 15 17:31:28 2013
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Fri, 15 Nov 2013 17:31:28 +0100
Subject: [R]  2SLS for panel data, re
Message-ID: <D41D66AB93B9E04BBA5378B621FFDACB04802F7E@BEMAILEXPD01.corp.generali.net>

Dear Chanita,

impossible to tell without a reproducible example. You do not even
include your Stata call.

Assuming you meant 'ivreg2' w/o "t", there are four rows of possible
arguments to it in the help page, but I don't seem to find any switch
for random effects. Are you sure you are not comparing a RE model with a
pooled one?

Best wishes,
Giovanni

Giovanni Millo, PhD
Research Dept.,
Assicurazioni Generali SpA
Via Machiavelli 3,
34132 Trieste (Italy)
tel. +39 040 671184
fax  +39 040 671160


-------------- original message ------------------

Date: Thu, 14 Nov 2013 08:12:33 -0800
From: Chanita Holmes <chanita.holmes at gmail.com>
To: r-help at r-project.org
Subject: [R] 2SLS for panel data, re
Message-ID:
	
<CAEaD0=6SkDOTODbPZZ19LE2ca6YxByXWp+q-GiL1g+8eFB22DA at mail.gmail.com>
Content-Type: text/plain

Hi,

I am trying to estimate a 2sls using panel data (random effect model). I
tried the same estimation in STATA using the ivtreg2 command. However
STATA
and R are giving me two different results. I figure there is something
with
my R code:

iv=plm(formula=wecon~fdistockgdp +trade + polrightsreversed +lnrgdpch +
execleft + muslim2+c100rat +c111rat +yeardum|
polrightsreversed+lnrgdpch+
execleft+muslim2+c100rat+c111rat+yeardum
+lnpop+lnarea+devcountrycomlanguage+bitcum,
data = women, index = c("country", "year"), random.method = c("swar"),
inst.method = c("bvk"), model="random")
summary(iv)

Coefficients :
                    Estimate Std. Error t-value  Pr(>|t|)
(Intercept)       -0.2258528  0.2951301 -0.7653 0.4441954
fdistockgdp       -0.0067207  0.0077315 -0.8693 0.3847993
trade              0.0068462  0.0023687  2.8903 0.0038863 **
polrightsreversed  0.0092366  0.0106174  0.8699 0.3844229
lnrgdpch           0.1246679  0.0389043  3.2045 0.0013724 **
execleft           0.1118046  0.0340817  3.2805 0.0010524 **
muslim2           -0.0044742  0.0012433 -3.5986 0.0003270 ***
c100rat            0.0226208  0.0595134  0.3801 0.7039114
c111rat            0.0165951  0.0618339  0.2684 0.7884310
yeardum1982        0.1479947  0.0588824  2.5134 0.0120282 *
yeardum1983        0.1783255  0.0606153  2.9419 0.0032958 **
yeardum1984        0.0344572  0.0597167  0.5770 0.5639907
yeardum1985        0.2206961  0.0610344  3.6159 0.0003060 ***
yeardum1986        0.2428015  0.0649779  3.7367 0.0001912 ***
yeardum1987        0.0489043  0.0615708  0.7943 0.4271186
yeardum1988        0.2243599  0.0605343  3.7063 0.0002155 ***
yeardum1989        0.2215060  0.0624042  3.5495 0.0003940 ***
yeardum1990        0.0688333  0.0607056  1.1339 0.2569648
yeardum1991        0.1370871  0.0638830  2.1459 0.0319892 *
yeardum1992        0.1851857  0.0630868  2.9354 0.0033655 **
yeardum1993        0.0904620  0.0698526  1.2950 0.1954420
yeardum1994        0.1003735  0.0737431  1.3611 0.1736137
yeardum1995        0.1164818  0.0721240  1.6150 0.1064494
yeardum1996        0.0482520  0.0787232  0.6129 0.5399837
yeardum1997        0.1049161  0.0895001  1.1722 0.2412247
yeardum1998        0.2191887  0.1109757  1.9751 0.0483807 *
yeardum1999        0.1573342  0.1397150  1.1261 0.2602422
yeardum2000        0.1532796  0.1627206  0.9420 0.3463059
---
 However STATA gives me
------------------------------------------------------------
-----------------------
            wecon |      Coef.   Std. Err.      z    P>|z|     [95%
Conf.
Interval]
------------------+-----------------------------------------
-----------------------
            trade |   .0093915   .0027483     3.42   0.001      .004005
.014778
      fdistockgdp |  -.0169171   .0092405    -1.83   0.067    -.0350281
.0011938
polrightsreversed |   .0165855   .0119176     1.39   0.164    -.0067726
.0399436
         lnrgdpch |   .1045675   .0431179     2.43   0.015     .0200579
.189077
         execleft |   .1373652   .0384442     3.57   0.000     .0620159
.2127145
          muslim2 |  -.0043645   .0013551    -3.22   0.001    -.0070205
-.0017085
          c100rat |   .0480539   .0657304     0.73   0.465    -.0807752
.1768831
          c111rat |   .0170048   .0676272     0.25   0.801    -.1155421
.1495516

Really would appreciate any help explaining why the results are so
different

	[[alternative HTML version deleted]]



--------------------- end original message ---------

?
Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From k.barton at abdn.ac.uk  Fri Nov 15 17:14:13 2013
From: k.barton at abdn.ac.uk (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Fri, 15 Nov 2013 16:14:13 +0000
Subject: [R] R-help Digest, Vol 129, Issue 15
In-Reply-To: <mailman.19.1384513206.32212.r-help@r-project.org>
References: <mailman.19.1384513206.32212.r-help@r-project.org>
Message-ID: <52864855.7000300@abdn.ac.uk>

works ok with mock-up data. Can you give some code to reproduce this error?

kamil



On 2013-11-15 11:00, r-help-request at r-project.org wrote:
> Message: 56
> Date: Thu, 14 Nov 2013 18:01:27 -0800
> From: Lilly Dethier<lillydethier at gmail.com>
> To:r-help at r-project.org
> Subject: [R] Error in MuMIn "models are not all fitted to the same
>       data"
> Message-ID:
>       <CAOK+e=Z_0pMEFKdPxZ5Eub+DYhHFjzGk3Lcqczsa9TimAP4n_w at mail.gmail.com>
> Content-Type: text/plain
>
> I'm pretty new to GLMMs and model averaging, but think I'm getting some
> understanding of it all through lots of reading. However, I keep receiving
> an error message when trying to average models that I don't understand and
> can't find any resources about. I'm doing science education research trying
> to evaluate population demographic factors that predict biology student
> math performance. I have a lot of factors and so I tested a lot of models.
> 6 of my models had pretty similar AIC values (and evidence ratios of less
> than 2.7) so I'm trying to average them. I keep receiving an error message
> that says the models are not fitted to the same data, but I have no idea
> how this is possible because all the models are from the same set of data
> (same file and same variables)...strangely it seems to work when I try to
> average MEx7, MEx10, & MEx22 only OR MEx24, MEx29, and MEx47 only. My code
> is below. Any ideas? Thanks for any advice you can offer!!
>
> library(MuMIn)
> MEx7=lmer(cbind(c.score, w.score) ~ year + transfer + gender + p.math +
> (1|section) + (1|quarter), family=binomial, data=survey.full, REML=F)
> MEx10=lmer(cbind(c.score, w.score) ~ transfer + gender + p.math + Pmajor +
> (1|section) + (1|quarter), family=binomial, data=survey.full, REML=F)
> MEx22=lmer(cbind(c.score, w.score) ~ year + transfer + p.math + (1|section)
> + (1|quarter), family=binomial, data=survey.full, REML=F)
> MEx24=lmer(cbind(c.score, w.score) ~ transfer + gender + p.math +
> (1|section) + (1|quarter), family=binomial, data=survey.full, REML=F)
> MEx29=lmer(cbind(c.score, w.score) ~ transfer + p.math + Pmajor +
> (1|section) + (1|quarter), family=binomial, data=survey.full, REML=F)
> MEx47=lmer(cbind(c.score, w.score) ~ transfer + p.math + (1|section) +
> (1|quarter), family=binomial, data=survey.full, REML=F)
> MExAvg=model.avg(rank=AIC, MEx24, MEx7, MEx10, MEx47, MEx29, MEx22)
>
> Error in model.avg.default(rank = AIC, MEx24, MEx7, MEx10, MEx47, MEx29,  :
>    models are not all fitted to the same data
> Lilly Dethier





The University of Aberdeen is a charity registered in Scotland, No SC013683.


From gunter.berton at gene.com  Fri Nov 15 17:57:12 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 15 Nov 2013 08:57:12 -0800
Subject: [R] Bug in predict.lm?
Message-ID: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>

Yes, I realize that it is more likely  a misunderstanding on my part.
Suitable humility will be tendered if this is pointed out.

The claimed "bug" is that predict.lm throws an error when the scale
argument is specified with interval = "conf" (and in some other
cases):

> z <- lm(rnorm(10)~I(1:10))

> predict(z,int="conf",scale=1)
Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found


R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)


Cheers,
Bert




-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ishaqbaba at yahoo.com  Fri Nov 15 18:17:47 2013
From: ishaqbaba at yahoo.com (IZHAK shabsogh)
Date: Fri, 15 Nov 2013 09:17:47 -0800 (PST)
Subject: [R] optimization
Message-ID: <1384535867.58595.YahooMailNeo@web142506.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/4470038b/attachment.pl>

From maechler at stat.math.ethz.ch  Fri Nov 15 18:59:06 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 15 Nov 2013 18:59:06 +0100
Subject: [R] cbind2() in Matrix
In-Reply-To: <528278EF.6000407@sapo.pt>
References: <B08B6AF0CF8CA44F81B9983EEBDCD686725832F5@DC1VEX10MB001.air.org>
	<528278EF.6000407@sapo.pt>
Message-ID: <21126.24810.951767.264858@stat.math.ethz.ch>

>>>>> "RB" == Rui Barradas <ruipbarradas at sapo.pt>
>>>>>     on Tue, 12 Nov 2013 18:52:31 +0000 writes:

    RB> Hello,

    RB> Maybe using ?Reduce:

    RB> Zlist <- c(mat1, mat2, mat3)
    RB> Z <- Reduce(cbind2, Zlist)

    RB> Ztmp <- cbind2(mat1, mat2)
    RB> Z2 <- cbind2(Ztmp, mat3)

    RB> identical(Z, Z2)  # TRUE

    RB> Also, I prefer list(mat1, mat2, mat3), not c().
(me too)

    RB> Hope this helps,
    RB> Rui Barradas

Well... I'm a bit disappointed that nobody took up and made the
matter a bit more clear :

1) cbind2() is not from package Matrix, but from standard R,
   package 'methods'.
   It is true (and necessary!) that Matrix defines many (S4)
   methods for cbind2(), indeed.

2) The help page for cbind2() {and rbind2()} mentions that their
   main use is to be used as building blocks for more than two
   arguments, and then mentions the possibility of
     methods:::bind_activation(TRUE)
   which makes  cbind() and rbind()  being "S4" aware and using
   cbind2() and rbind2() for column and row binding.

   The help page then has a "link" to  cBind() and rBind()  in
   the Matrix package, and these actually *are* cbind and rbind
   version that work with an arbitrary number of matrices
   (Matrix package or other; it will work whenever cbind2() /
   rbind2() methods are defined).

So, where as you can use cbind with  Reduce()   and that is nice functional
programming {not available at the time  cBind / rBind
were created},
actually the whole idea was that you would simply
use
	cBind(mat1, mat2, mat3)

Maybe we have to review this matter, or at least add something
to the help pages.

Martin Maechler, 
ETH Zurich


    RB> Em 12-11-2013 17:20, Doran, Harold escreveu:
    >> Suppose I have three matrices, such as the following:
    >> 
    >> mat1 <- Matrix(rnorm(9), 3)
    >> mat2 <- Matrix(rnorm(9), 3)
    >> mat3 <- Matrix(rnorm(9), 3)
    >> 
    >> I now need to column bind these and I could do the following if there were only two of those matrices because cbind2() has an x and y argument
    >> 
    >> Zlist <- c(mat1, mat2)
    >> Z <- do.call(cbind2, Zlist)
    >> 
    >> The following would not work as noted in the help page for cbind2() and I don't think I want to activate cbind() here.
    >> 
    >> Zlist <- c(mat1, mat2, mat3)
    >> Z <- do.call(cbind2, Zlist)
    >> 
    >> So, the object I would want in the end would be
    >> Ztmp <- cbind2(mat1, mat2)
    >> Z <- cbind2(Ztmp, mat3)
    >> 
    >> I never have a large number of these things to combine, so I have solved the problem with a simple loop over the list.
    >> 
    >> I'm curious though if there is a better (and perhaps) more reliable way to do this?
    >> 
    >> Thanks,
    >> Harold
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    RB> ______________________________________________
    RB> R-help at r-project.org mailing list
    RB> https://stat.ethz.ch/mailman/listinfo/r-help
    RB> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    RB> and provide commented, minimal, self-contained, reproducible code.


From mxkuhn at gmail.com  Fri Nov 15 21:59:51 2013
From: mxkuhn at gmail.com (Max Kuhn)
Date: Fri, 15 Nov 2013 15:59:51 -0500
Subject: [R] Inconsistent results between caret+kernlab versions
In-Reply-To: <CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
References: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>
	<CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
Message-ID: <CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>

Or not!

The issue with with kernlab.

Background: SVM models do not naturally produce class probabilities. A
secondary model (via Platt) is fit to the raw model output and a
logistic function is used to translate the raw SVM output to
probability-like numbers (i.e. sum to zero, between 0 and 1). In
ksvm(), you need to use the option prob.model = TRUE to get that
second model.

I discovered some time ago that there can be a discrepancy in the
predicted classes that naturally come from the SVM model and those
derived by using the class associated with the largest class
probability. This is most likely do to natural error in the secondary
probability model and should not be unexpected.

That is the case for your data. In you use the same tuning parameters
as those suggested by train() and go straight to ksvm():

> newSVM <- ksvm(x = as.matrix(df[,-1]),
+                y = df[,1],
+                kernel = rbfdot(sigma = svm.m1$bestTune$.sigma),
+                C = svm.m1$bestTune$.C,
+                prob.model = TRUE)
>
> predict(newSVM, df[43,-1])
[1] O32078
10 Levels: O27479 O31403 O32057 O32059 O32060 O32078 ... O32676
> predict(newSVM, df[43,-1], type = "probabilities")
         O27479     O31403    O32057    O32059     O32060    O32078
[1,] 0.08791826 0.05911645 0.2424997 0.1036943 0.06968587 0.1648394
         O32089     O32663     O32668     O32676
[1,] 0.04890477 0.05210836 0.09838892 0.07284396

Note that, based on the probability model, the class with the largest
probability is O32057 (p = 0.24) while the basic SVM model predicts
O32078 (p = 0.16).

Somebody (maybe me) saw this discrepancy and that led to me to follow this rule:

if(prob.model = TRUE) use the class with the maximum probability
   else use the class prediction from ksvm().

Therefore:

> predict(svm.m1, df[43,-1])
[1] O32057
10 Levels: O27479 O31403 O32057 O32059 O32060 O32078 ... O32676

That change occurred between the two caret versions that you tested with.

(On a side note, can also occur with ksvm() and rpart() if
cost-sensitive training is used because the class designation takes
into account the costs but the class probability predictions do not. I
alerted both package maintainers to the issue some time ago.)

HTH,

Max

On Fri, Nov 15, 2013 at 1:56 PM, Max Kuhn <mxkuhn at gmail.com> wrote:
> I've looked into this a bit and the issue seems to be with caret. I've
> been looking at the svn check-ins and nothing stands out to me as the
> issue so far. The final models that are generated are the same and
> I'll try to figure out the difference.
>
> Two small notes:
>
> 1) you should set the seed to ensure reproducibility.
> 2) you really shouldn't use character stings with all numbers as
> factor levels with caret when you want class probabilities. It should
> give you a warning about this
>
> Max
>
> On Thu, Nov 14, 2013 at 7:31 PM, Andrew Digby <andrewdigby at mac.com> wrote:
>>
>> I'm using caret to assess classifier performance (and it's great!). However, I've found that my results differ between R2.* and R3.* - reported accuracies are reduced dramatically. I suspect that a code change to kernlab ksvm may be responsible (see version 5.16-24 here: http://cran.r-project.org/web/packages/caret/news.html). I get very different results between caret_5.15-61 + kernlab_0.9-17 and caret_5.17-7 + kernlab_0.9-19 (see below).
>>
>> Can anyone please shed any light on this?
>>
>> Thanks very much!
>>
>>
>> ### To replicate:
>>
>> require(repmis)  # For downloading from https
>> df <- source_data('https://dl.dropboxusercontent.com/u/47973221/data.csv', sep=',')
>> require(caret)
>> svm.m1 <- train(df[,-1],df[,1],method='svmRadial',metric='Kappa',tunelength=5,trControl=trainControl(method='repeatedcv', number=10, repeats=10, classProbs=TRUE))
>> svm.m1
>> sessionInfo()
>>
>> ### Results - R2.15.2
>>
>>> svm.m1
>> 1241 samples
>>    7 predictors
>>   10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676?
>>
>> No pre-processing
>> Resampling: Cross-Validation (10 fold, repeated 10 times)
>>
>> Summary of sample sizes: 1116, 1116, 1114, 1118, 1118, 1119, ...
>>
>> Resampling results across tuning parameters:
>>
>>   C     Accuracy  Kappa  Accuracy SD  Kappa SD
>>   0.25  0.684     0.63   0.0353       0.0416
>>   0.5   0.729     0.685  0.0379       0.0445
>>   1     0.756     0.716  0.0357       0.0418
>>
>> Tuning parameter ?sigma? was held constant at a value of 0.247
>> Kappa was used to select the optimal model using  the largest value.
>> The final values used for the model were C = 1 and sigma = 0.247.
>>> sessionInfo()
>> R version 2.15.2 (2012-10-26)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>
>> locale:
>> [1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>  [1] e1071_1.6-1     class_7.3-5     kernlab_0.9-17  repmis_0.2.4    caret_5.15-61   reshape2_1.2.2  plyr_1.8        lattice_0.20-10 foreach_1.4.0   cluster_1.14.3
>>
>> loaded via a namespace (and not attached):
>>  [1] codetools_0.2-8 compiler_2.15.2 digest_0.6.0    evaluate_0.4.3  formatR_0.7     grid_2.15.2     httr_0.2        iterators_1.0.6 knitr_1.1       RCurl_1.95-4.1  stringr_0.6.2   tools_2.15.2
>>
>> ### Results - R3.0.2
>>
>>> require(caret)
>>> svm.m1 <- train(df[,-1],df[,1],method=?svmRadial?,metric=?Kappa?,tunelength=5,trControl=trainControl(method=?repeatedcv?, number=10, repeats=10, classProbs=TRUE))
>> Loading required package: class
>> Warning messages:
>> 1: closing unused connection 4 (https://dl.dropboxusercontent.com/u/47973221/df.Rdata)
>> 2: executing %dopar% sequentially: no parallel backend registered
>>> svm.m1
>> 1241 samples
>>    7 predictors
>>   10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676?
>>
>> No pre-processing
>> Resampling: Cross-Validation (10 fold, repeated 10 times)
>>
>> Summary of sample sizes: 1118, 1117, 1115, 1117, 1116, 1118, ...
>>
>> Resampling results across tuning parameters:
>>
>>   C     Accuracy  Kappa  Accuracy SD  Kappa SD
>>   0.25  0.372     0.278  0.033        0.0371
>>   0.5   0.39      0.297  0.0317       0.0358
>>   1     0.399     0.307  0.0289       0.0323
>>
>> Tuning parameter ?sigma? was held constant at a value of 0.2148907
>> Kappa was used to select the optimal model using  the largest value.
>> The final values used for the model were C = 1 and sigma = 0.215.
>>> sessionInfo()
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>
>> locale:
>> [1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>  [1] e1071_1.6-1     class_7.3-9     kernlab_0.9-19  repmis_0.2.6.2  caret_5.17-7    reshape2_1.2.2  plyr_1.8        lattice_0.20-24 foreach_1.4.1   cluster_1.14.4
>>
>> loaded via a namespace (and not attached):
>> [1] codetools_0.2-8 compiler_3.0.2  digest_0.6.3    grid_3.0.2      httr_0.2        iterators_1.0.6 RCurl_1.95-4.1  stringr_0.6.2   tools_3.0.2
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Max



-- 

Max


From hnorpois at gmail.com  Fri Nov 15 22:26:04 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Fri, 15 Nov 2013 22:26:04 +0100
Subject: [R] Find backward duplicates in a data frame
Message-ID: <CAKyZeBuBGNOyx0zsBOGBnPSMR0B+LWWf9BnKFXAV6FFTT8Ts=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/44dc8034/attachment.pl>

From ccberry at ucsd.edu  Fri Nov 15 22:55:45 2013
From: ccberry at ucsd.edu (Charles Berry)
Date: Fri, 15 Nov 2013 21:55:45 +0000
Subject: [R] Bug in predict.lm?
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
Message-ID: <loom.20131115T225210-168@post.gmane.org>

Bert Gunter <gunter.berton <at> gene.com> writes:

> 
> Yes, I realize that it is more likely  a misunderstanding on my part.
> Suitable humility will be tendered if this is pointed out.
> 
> The claimed "bug" is that predict.lm throws an error when the scale
> argument is specified with interval = "conf" (and in some other
> cases):
> 
> > z <- lm(rnorm(10)~I(1:10))
> 
> > predict(z,int="conf",scale=1)
> Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found
> 
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
> 
> Cheers,
> Bert
> 

I do not see this (see below). 

Maybe traceback() or options(recover=browser) to get
to the bottom??



> z <- lm(rnorm(10)~I(1:10))
> predict(z,int="conf",scale=1)
          fit        lwr       upr
1  0.02491723 -1.1270591 1.1768935
2  0.06402057 -0.9129873 1.0410284
3  0.10312392 -0.7185606 0.9248085
4  0.14222726 -0.5569958 0.8414504
5  0.18133060 -0.4477852 0.8104464
6  0.22043395 -0.4086818 0.8495497
7  0.25953729 -0.4396858 0.9587604
8  0.29864063 -0.5230439 1.1203252
9  0.33774398 -0.6392639 1.3147518
10 0.37684732 -0.7751290 1.5288236
> version
               _                           
platform       x86_64-apple-darwin10.8.0   
arch           x86_64                      
os             darwin10.8.0                
system         x86_64, darwin10.8.0        
status                                     
major          3                           
minor          0.2                         
year           2013                        
month          09                          
day            25                          
svn rev        63987                       
language       R                           
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing             
>


From lordpreetam at gmail.com  Fri Nov 15 23:08:47 2013
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sat, 16 Nov 2013 03:38:47 +0530
Subject: [R] CHAID in R
Message-ID: <CAHVFrXGKr4z0n4-q2rHBP9Ev4P1NGO5AmSzt4idL1F2gtMFa6A@mail.gmail.com>

Hi,

I have a data set on credit rating for customers in a bank (Rating is 1 for
defaulter, 0 = non-defaulter). I have 10 predictor variables
(C1,C2,.....,C10) . I want to build a CHAID Tree using R for
classification. How do I do this? For your perusal, the data set is
attached. Thanks in advance.

-Preetam

-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.
-------------- next part --------------
C1	C2	C3	C4	C5	C6	C7	C8	C9	C10	Rating
-24	-12	-1108	-4	5	12	-29	-109	-225	178	0
-150	-118	-5628	-7	15	83	-75	-303	-1167	859	1
-50	-31	-1984	-4	7	25	-36	-139	-409	308	0
-196	-135	-7454	-10	19	104	-105	-416	-1547	1139	0
-119	-78	-4607	-8	13	63	-70	-277	-955	707	1
-226	-146	-8563	-12	21	119	-116	-465	-1780	1305	0
-69	-52	-2684	-5	9	37	-46	-178	-553	416	0
-173	-119	-6571	-9	17	92	-90	-363	-1365	1004	0
-73	-43	-2895	-5	8	37	-50	-195	-598	449	0
-130	-92	-4950	-7	13	69	-69	-274	-1028	757	1
-31	-24	-1225	-2	4	17	-22	-81	-252	190	1
-109	-96	-4075	-5	12	62	-57	-224	-843	624	1
-38	-28	-1482	-3	4	21	-23	-93	-306	229	0
-27	-29	-1137	-3	5	16	-28	-103	-231	183	1
-34	-28	-1328	-3	4	19	-22	-89	-273	206	0
-31	-34	-1215	-3	4	19	-21	-85	-249	190	1
-59	-46	-2295	-5	8	32	-41	-157	-472	357	0
-201	-129	-7633	-10	19	106	-103	-410	-1586	1163	0
-312	-181	-11894	-17	29	160	-162	-646	-2475	1813	1
-85	-62	-3245	-5	10	46	-48	-189	-671	497	0
-51	-30	-2019	-4	6	26	-36	-141	-417	314	0
-63	-35	-2504	-5	8	32	-41	-163	-518	386	0
-52	-32	-2121	-4	7	27	-38	-145	-439	329	0
-42	-29	-1708	-5	5	23	-32	-121	-351	266	0
-51	-33	-1957	-3	5	27	-30	-120	-405	301	0
-31	-18	-1300	-3	4	16	-24	-94	-269	203	0
-8	-6	-404	-2	2	4	-14	-50	-82	68	0
-9	-10	-389	-1	2	6	-14	-52	-76	65	0
-58	-34	-2284	-4	6	30	-36	-144	-473	352	0
-170	-135	-6467	-10	18	94	-96	-377	-1338	994	1
-46	-36	-1811	-3	5	26	-32	-119	-373	280	0
-100	-71	-3802	-6	10	54	-54	-215	-788	582	0
-145	-89	-5547	-9	14	76	-77	-308	-1152	847	0
-28	-20	-1198	-4	5	15	-28	-105	-245	191	0
-36	-25	-1395	-3	5	19	-25	-96	-288	217	0
-120	-99	-4489	-6	13	67	-63	-246	-930	687	1
-154	-119	-5779	-8	15	85	-79	-318	-1198	884	0
-52	-38	-1987	-4	6	28	-33	-130	-410	308	1
-29	-19	-1160	-3	4	15	-22	-88	-238	182	0
-10	-11	-434	-1	2	6	-10	-40	-88	70	0
-59	-53	-2208	-3	8	34	-35	-134	-456	340	0
-27	-23	-1096	-2	5	16	-19	-76	-225	170	0
-152	-92	-5867	-9	15	79	-84	-335	-1219	897	0
-154	-105	-5851	-9	15	82	-80	-318	-1214	892	0
-152	-115	-5812	-9	17	83	-87	-340	-1203	893	1
-33	-23	-1318	-3	4	18	-25	-93	-272	206	0
-58	-57	-2177	-3	8	34	-36	-139	-447	337	0
-32	-20	-1279	-2	5	16	-22	-84	-265	197	0
-178	-100	-6835	-10	17	91	-95	-382	-1422	1044	0
-51	-34	-1961	-4	5	27	-30	-122	-405	302	0
-57	-48	-2208	-3	7	32	-35	-133	-456	340	0
-148	-98	-5641	-8	14	79	-78	-312	-1172	862	0
-31	-24	-1194	-2	4	17	-20	-80	-246	185	0
-84	-56	-3195	-5	9	44	-47	-187	-662	490	0
-54	-54	-2107	-4	8	32	-39	-150	-432	330	1
-18	-12	-742	-2	3	9	-14	-58	-152	115	0
-158	-89	-6117	-10	15	80	-90	-355	-1271	936	1
-240	-154	-9045	-12	22	126	-121	-488	-1880	1379	0
-49	-38	-1855	-3	6	27	-29	-112	-384	285	0
-156	-110	-5891	-8	15	84	-80	-317	-1224	899	1
-33	-23	-1316	-3	4	18	-22	-88	-272	204	0
-35	-27	-1456	-4	5	19	-30	-113	-298	229	0
-47	-50	-1850	-4	7	28	-37	-139	-379	291	1
-361	-229	-13635	-18	33	189	-178	-718	-2836	2075	1
-80	-60	-3009	-4	8	43	-44	-172	-623	461	0
-128	-86	-4910	-8	13	68	-73	-288	-1017	752	0
-53	-35	-2053	-4	6	28	-33	-127	-425	317	0
-24	-21	-953	-1	3	14	-16	-65	-195	148	0
-46	-51	-1722	-3	6	28	-29	-114	-353	268	1
-61	-60	-2266	-3	7	36	-33	-133	-466	348	0
-204	-135	-7691	-10	19	108	-104	-417	-1598	1173	0
-15	-10	-693	-3	3	8	-19	-71	-141	112	0
-25	-16	-1102	-3	4	13	-25	-96	-226	174	0
-148	-110	-5632	-8	15	80	-80	-318	-1167	863	0
-49	-52	-1872	-3	7	30	-32	-124	-384	291	1
-34	-22	-1446	-4	6	18	-33	-125	-297	230	0
-99	-85	-3751	-5	11	56	-55	-215	-775	576	1
-115	-66	-4512	-7	12	59	-69	-272	-936	693	0
-237	-166	-8924	-12	23	127	-121	-485	-1853	1361	0
-96	-74	-3624	-5	10	53	-51	-200	-751	554	0
-147	-94	-5621	-9	15	77	-82	-321	-1166	860	1
-28	-23	-1150	-3	5	16	-25	-95	-234	182	0
-39	-33	-1484	-3	5	22	-23	-93	-306	229	0
-41	-36	-1662	-4	7	23	-34	-128	-341	262	0
-54	-32	-2191	-5	7	28	-39	-152	-453	341	0
-34	-25	-1336	-3	4	18	-22	-90	-276	207	0
-31	-29	-1226	-2	4	18	-22	-82	-252	191	0
-313	-192	-11926	-17	29	163	-162	-649	-2480	1817	1
-55	-41	-2128	-4	6	30	-33	-131	-440	327	0
-26	-21	-1048	-2	4	14	-19	-75	-215	164	1
-13	-12	-587	-3	3	7	-20	-73	-117	98	0
-32	-22	-1334	-4	5	17	-29	-110	-273	211	0
-19	-16	-756	-2	3	10	-17	-63	-154	119	1
-91	-65	-3421	-5	9	49	-48	-190	-709	522	0
-29	-21	-1249	-3	4	16	-28	-105	-255	198	0
-397	-250	-15078	-21	37	208	-206	-817	-3134	2300	1
-47	-29	-1905	-4	7	23	-38	-145	-391	298	0
-64	-46	-2481	-5	7	35	-38	-153	-513	382	0
-58	-58	-2212	-3	7	35	-36	-139	-455	342	0
-174	-106	-6674	-9	17	90	-93	-370	-1387	1018	0
-36	-35	-1392	-4	5	21	-26	-101	-285	218	0
-58	-59	-2198	-3	7	35	-33	-129	-452	338	0
-22	-15	-882	-2	3	12	-16	-64	-181	138	0
-45	-29	-1815	-3	5	23	-31	-120	-375	281	0
-60	-39	-2313	-4	6	32	-36	-138	-479	355	0
-296	-173	-11287	-16	27	153	-152	-610	-2350	1719	1
-160	-96	-6107	-9	15	82	-87	-344	-1270	933	1
-149	-86	-5747	-8	14	76	-80	-320	-1195	878	0
-192	-119	-7301	-10	18	100	-100	-397	-1517	1113	0
-33	-27	-1335	-3	5	19	-25	-95	-274	208	0
-34	-20	-1371	-4	4	18	-25	-94	-283	212	0
-10	-14	-372	-1	2	7	-10	-35	-74	60	0
-155	-94	-5919	-8	15	80	-81	-325	-1231	903	0
-197	-132	-7428	-10	18	104	-99	-399	-1543	1133	1
-40	-28	-1590	-3	6	22	-28	-108	-327	247	0
-90	-83	-3387	-5	11	52	-53	-207	-697	522	0
-179	-127	-6785	-9	18	96	-93	-369	-1408	1035	1
-51	-33	-2017	-4	6	27	-32	-123	-417	310	0
-107	-82	-4049	-5	12	59	-56	-224	-839	619	1
-57	-37	-2239	-4	7	30	-36	-142	-463	345	0
-45	-39	-1736	-3	5	26	-27	-107	-358	268	1
-96	-67	-3659	-6	10	51	-56	-218	-758	562	0
-43	-30	-1672	-3	5	23	-26	-104	-346	258	0
-16	-10	-741	-3	4	8	-24	-87	-149	122	0
-47	-38	-1821	-3	5	26	-30	-112	-375	281	1
-51	-35	-2006	-4	6	27	-31	-126	-415	309	0
-15	-14	-665	-2	3	9	-16	-64	-135	107	0
-14	-15	-605	-2	3	9	-13	-54	-123	97	1
-44	-31	-1760	-3	5	23	-30	-116	-364	273	0
-85	-53	-3309	-5	9	45	-48	-192	-687	507	1
-213	-151	-8026	-10	20	114	-107	-428	-1666	1223	0
-172	-119	-6513	-9	17	92	-88	-355	-1352	994	1
-67	-45	-2561	-4	7	35	-39	-151	-531	393	0
-48	-36	-1878	-4	6	26	-33	-132	-386	293	0
-257	-183	-9593	-13	24	138	-126	-505	-1992	1461	0
-29	-22	-1174	-3	4	16	-23	-89	-240	184	0
-215	-134	-8144	-10	19	112	-109	-439	-1693	1241	0
-15	-12	-728	-3	5	8	-23	-88	-146	121	1
-66	-45	-2581	-4	7	35	-41	-159	-533	397	0
-45	-28	-1780	-4	6	24	-31	-125	-368	277	0
-16	-10	-672	-1	2	9	-15	-54	-138	106	0
-120	-91	-4535	-6	12	66	-65	-253	-941	694	0
-85	-65	-3231	-5	9	47	-46	-185	-670	495	0
-61	-45	-2328	-4	6	33	-34	-136	-482	357	1
-57	-46	-2164	-3	6	32	-33	-127	-447	333	0
-90	-85	-3375	-5	10	52	-49	-193	-696	518	0
-18	-12	-814	-3	3	10	-19	-72	-166	130	0
-14	-13	-648	-3	3	8	-19	-72	-129	106	0
-134	-99	-5080	-7	13	73	-70	-281	-1053	777	0
-38	-31	-1498	-3	5	21	-29	-112	-307	235	0
-31	-18	-1275	-4	4	16	-26	-98	-262	199	0
-46	-29	-1820	-4	6	24	-31	-123	-376	282	0
-147	-105	-5530	-7	14	80	-75	-301	-1148	844	0
-193	-120	-7336	-10	17	101	-100	-399	-1525	1118	0
-172	-108	-6589	-10	16	90	-92	-366	-1369	1006	0
-31	-25	-1213	-2	4	17	-19	-77	-250	187	1
-29	-19	-1220	-4	4	15	-26	-100	-250	191	0
-5	-9	-323	-2	3	4	-14	-50	-63	56	0
-86	-62	-3323	-6	9	46	-50	-199	-687	510	0
-45	-26	-1796	-4	5	23	-30	-118	-372	277	0
-71	-54	-2718	-5	8	39	-43	-166	-561	417	0
-26	-26	-999	-2	4	15	-20	-72	-204	157	0
-30	-25	-1195	-2	5	16	-23	-88	-244	187	0
-177	-96	-6912	-12	18	89	-104	-410	-1436	1060	0
-23	-39	-863	-2	5	17	-19	-69	-173	137	0
-73	-40	-2817	-5	8	37	-42	-170	-584	432	0
-27	-27	-1071	-2	4	15	-21	-79	-219	168	1
-38	-28	-1492	-2	4	21	-24	-91	-308	229	0
-99	-70	-3756	-5	10	53	-53	-211	-779	575	0
-47	-43	-1831	-3	6	27	-30	-116	-377	283	1
-22	-21	-900	-2	4	13	-19	-71	-184	141	1
-18	-17	-722	-2	3	11	-14	-56	-147	114	0
-50	-44	-1953	-3	6	28	-32	-125	-403	302	1
-33	-22	-1338	-3	4	18	-24	-94	-276	208	0
-84	-60	-3229	-5	9	45	-47	-184	-669	495	1
-185	-118	-7080	-11	18	96	-102	-404	-1470	1083	1
-62	-39	-2438	-5	7	32	-40	-158	-504	377	0
-4	-3	-322	-2	3	2	-16	-57	-62	57	0
-48	-32	-1857	-3	6	25	-30	-119	-384	286	0
-11	-18	-543	-3	4	7	-21	-77	-106	93	0
-240	-154	-9051	-12	22	126	-122	-485	-1882	1379	1
-111	-86	-4214	-6	12	61	-59	-237	-874	645	1
-39	-35	-1560	-3	6	22	-28	-109	-321	242	1
-93	-64	-3574	-6	10	50	-56	-221	-739	551	0
-20	-23	-837	-2	4	13	-19	-70	-170	132	1
-33	-27	-1287	-3	4	18	-22	-89	-265	201	0
-123	-66	-4852	-9	13	62	-79	-307	-1007	747	1
-25	-21	-1114	-4	5	13	-29	-109	-227	180	0
-16	-17	-638	-2	2	9	-12	-47	-130	100	1
-79	-54	-3068	-5	8	43	-46	-182	-636	471	0
-113	-75	-4344	-7	12	60	-66	-264	-900	668	1
-97	-88	-3638	-6	11	55	-53	-209	-751	558	1
-97	-71	-3703	-6	10	53	-54	-217	-767	568	1
-51	-29	-1994	-3	6	25	-32	-125	-413	307	0
-77	-77	-2868	-4	8	46	-40	-160	-591	440	1
-35	-23	-1420	-3	5	19	-26	-99	-294	221	1
-33	-20	-1307	-3	4	17	-22	-89	-270	203	0
-22	-20	-901	-3	3	13	-18	-66	-184	141	1
-67	-53	-2612	-4	8	37	-41	-161	-539	402	0
-105	-67	-4064	-6	11	55	-61	-239	-844	624	1
-20	-14	-888	-3	5	11	-23	-86	-180	142	0
-27	-22	-1105	-2	4	15	-19	-77	-228	172	0
-128	-88	-4839	-6	13	68	-67	-267	-1004	739	0
-21	-20	-853	-1	3	12	-15	-59	-175	133	1
-36	-25	-1415	-3	5	19	-26	-101	-292	220	0
-264	-161	-10045	-14	24	137	-137	-545	-2090	1531	0
-46	-31	-1831	-4	6	24	-33	-127	-377	285	0
-34	-26	-1347	-2	4	18	-23	-89	-277	209	0
-163	-105	-6210	-8	15	86	-83	-334	-1292	947	0
-32	-22	-1339	-3	4	17	-29	-111	-273	212	0
-75	-44	-2908	-5	8	39	-44	-175	-603	445	0
-95	-76	-3629	-6	11	53	-56	-218	-750	559	0
-130	-87	-5006	-8	13	68	-75	-295	-1038	769	1
-46	-42	-1808	-4	7	26	-37	-142	-370	286	1
-83	-69	-3163	-5	10	46	-51	-200	-652	489	0
-20	-12	-883	-2	4	10	-20	-75	-181	140	0
-76	-53	-2936	-4	8	40	-44	-174	-608	451	0
-99	-79	-3701	-5	10	55	-51	-206	-766	566	0
-75	-57	-2857	-4	8	41	-41	-164	-592	438	0
-30	-19	-1292	-4	5	15	-30	-116	-264	206	0
-14	-15	-592	-2	3	9	-14	-48	-121	94	0
-29	-23	-1136	-2	4	16	-19	-76	-233	176	0
-17	-16	-670	-2	3	10	-14	-57	-136	107	0
-74	-56	-2818	-4	8	40	-42	-168	-582	432	0
-115	-71	-4404	-7	11	60	-62	-249	-915	674	0
-66	-63	-2472	-4	8	38	-36	-145	-510	381	0
-275	-183	-10365	-13	25	146	-138	-551	-2154	1579	1
-192	-107	-7437	-11	18	98	-107	-424	-1547	1137	1
-36	-24	-1398	-2	4	19	-23	-88	-289	216	1
-78	-60	-2978	-4	8	43	-43	-168	-617	456	0
-107	-83	-3982	-5	11	59	-55	-222	-825	610	1
-60	-34	-2373	-5	8	30	-42	-161	-491	368	0
-52	-34	-2026	-5	6	27	-33	-131	-418	313	0
-21	-24	-820	-2	3	13	-15	-60	-168	129	0
-36	-18	-1461	-3	5	17	-28	-107	-302	227	0
-45	-41	-1725	-3	6	25	-29	-110	-356	266	1
-361	-194	-13760	-19	31	182	-181	-727	-2868	2092	1
-66	-47	-2620	-6	8	35	-47	-180	-540	407	1
-31	-23	-1222	-3	4	17	-22	-89	-251	191	0
-62	-54	-2387	-4	8	35	-39	-151	-492	368	0
-22	-29	-867	-2	4	15	-17	-65	-176	136	1
-37	-20	-1510	-4	5	18	-31	-117	-310	236	0
-116	-100	-4356	-5	12	66	-61	-239	-901	666	1
-29	-23	-1121	-2	4	16	-19	-78	-231	175	0
-85	-51	-3261	-5	10	44	-48	-194	-677	499	0
-32	-34	-1191	-2	4	19	-20	-79	-244	185	0
-15	-13	-680	-3	4	8	-20	-75	-137	112	0
-28	-17	-1140	-4	4	14	-21	-86	-234	178	0
-49	-42	-1821	-3	6	28	-28	-112	-375	281	0
-11	-19	-410	-1	2	7	-10	-37	-82	66	1
-13	-9	-632	-1	2	7	-16	-62	-128	102	0
-54	-33	-2130	-4	7	28	-36	-144	-440	331	0
-54	-52	-2034	-3	6	32	-30	-121	-419	313	1
-103	-71	-3927	-7	10	55	-57	-228	-813	602	0
-49	-32	-1920	-3	5	25	-30	-117	-397	295	0
-187	-147	-7017	-9	19	104	-94	-377	-1455	1071	0
-67	-52	-2539	-4	8	36	-39	-156	-525	392	0
-52	-35	-2033	-4	6	28	-32	-127	-421	313	1
-95	-60	-3605	-6	9	50	-51	-202	-748	551	0
-26	-17	-1094	-4	4	12	-27	-100	-223	175	0
-40	-29	-1567	-3	5	22	-25	-101	-324	242	0
-37	-35	-1518	-4	6	22	-32	-119	-310	240	0
-130	-81	-5014	-8	13	68	-72	-285	-1042	767	0
-65	-39	-2601	-5	8	33	-46	-177	-538	404	0
-29	-20	-1165	-2	4	16	-22	-84	-240	181	0
-18	-19	-760	-2	3	11	-18	-67	-154	120	1
-158	-110	-5963	-8	16	84	-84	-332	-1236	911	0
-38	-36	-1451	-3	5	22	-27	-101	-297	227	0
-221	-125	-8489	-12	21	113	-118	-472	-1766	1296	1
-25	-31	-947	-2	4	16	-17	-66	-192	148	0
-66	-47	-2519	-4	7	35	-39	-153	-520	387	0
-33	-24	-1328	-3	5	17	-25	-96	-272	207	0
-304	-198	-11508	-15	28	159	-155	-617	-2393	1753	0
-78	-79	-2895	-4	9	46	-42	-166	-596	445	1
-298	-180	-11344	-15	27	154	-153	-608	-2361	1728	1
-66	-39	-2551	-4	7	34	-39	-156	-529	391	0
-60	-44	-2274	-4	6	32	-34	-136	-470	350	0
-28	-21	-1196	-3	5	15	-26	-98	-245	189	0
-113	-62	-4360	-7	11	57	-63	-249	-906	667	1
-47	-42	-1800	-4	6	27	-28	-113	-371	278	0
-84	-55	-3186	-4	8	44	-46	-181	-660	487	0
-37	-25	-1490	-4	5	19	-29	-115	-306	234	0
-34	-27	-1369	-3	5	18	-28	-107	-280	215	0
-35	-25	-1441	-4	6	18	-32	-122	-294	228	0
-95	-67	-3669	-7	10	52	-55	-215	-759	563	0
-268	-178	-10139	-13	25	142	-137	-545	-2108	1546	0
-121	-102	-4529	-6	13	68	-63	-249	-937	692	0
-190	-138	-7171	-10	18	102	-98	-390	-1489	1094	0
-24	-19	-1034	-3	4	13	-23	-91	-211	165	0
-23	-28	-971	-3	4	15	-23	-85	-197	156	1
-26	-21	-1018	-2	3	14	-18	-72	-209	159	0
-235	-152	-8886	-12	22	124	-120	-476	-1848	1354	1
-158	-100	-6070	-9	16	83	-87	-345	-1261	928	0
-119	-92	-4538	-7	13	65	-70	-274	-938	699	0
-191	-137	-7216	-10	19	103	-102	-403	-1497	1103	0
-250	-170	-9418	-12	23	133	-126	-501	-1957	1435	1
-116	-70	-4421	-6	11	60	-61	-242	-919	674	0
-30	-20	-1219	-3	5	15	-25	-97	-250	192	0
-61	-43	-2380	-4	7	33	-39	-155	-491	368	0
-67	-50	-2597	-3	7	37	-40	-157	-536	399	0
-14	-7	-638	-3	3	6	-20	-75	-130	105	0
-94	-76	-3599	-6	11	53	-54	-215	-744	554	1
-33	-33	-1273	-2	5	19	-24	-92	-260	198	1
-22	-16	-983	-3	4	12	-23	-88	-200	157	0
-254	-170	-9577	-13	25	134	-131	-524	-1989	1462	1
-37	-21	-1460	-3	4	19	-25	-101	-301	226	0
-121	-86	-4551	-6	12	64	-63	-250	-944	695	0
-16	-16	-689	-3	3	10	-16	-59	-140	110	1
-29	-20	-1170	-2	4	16	-19	-78	-241	181	1
-5	-9	-262	-1	2	4	-7	-29	-53	43	0
-135	-108	-5091	-7	14	74	-74	-289	-1054	780	0
-138	-90	-5212	-8	13	73	-71	-286	-1082	795	0
-94	-66	-3546	-5	9	51	-51	-200	-735	543	0
-15	-16	-649	-1	3	9	-13	-51	-133	103	1
-36	-18	-1414	-3	4	18	-25	-94	-293	218	0
-69	-64	-2598	-4	8	40	-40	-155	-536	400	1
-15	-15	-671	-2	3	9	-16	-63	-137	107	0
-106	-72	-4117	-7	12	57	-62	-247	-853	633	0
-16	-16	-664	-2	3	9	-15	-58	-135	106	0
-89	-57	-3445	-5	9	47	-50	-197	-715	528	0
-106	-79	-4019	-6	11	57	-57	-226	-834	615	1
-47	-42	-1834	-3	6	27	-31	-117	-378	284	1
-71	-55	-2753	-4	8	39	-42	-166	-570	424	0
-65	-47	-2516	-3	6	36	-37	-150	-520	386	0
-25	-25	-974	-2	4	14	-19	-77	-199	154	0
-82	-46	-3214	-5	9	41	-49	-195	-667	494	0
-142	-81	-5487	-9	14	72	-81	-320	-1139	840	0
-38	-37	-1444	-2	5	22	-26	-99	-295	224	0
-113	-86	-4231	-6	12	62	-61	-239	-876	648	0
-24	-16	-1010	-2	3	13	-19	-73	-208	157	0
-161	-99	-6257	-11	17	82	-97	-379	-1298	962	0
-46	-37	-1764	-4	5	25	-28	-113	-363	272	1
-187	-147	-7007	-10	18	104	-94	-374	-1453	1069	1
-291	-191	-10960	-15	27	154	-144	-579	-2279	1669	1
-102	-72	-3887	-5	10	55	-55	-216	-806	593	1
-81	-44	-3201	-6	9	41	-50	-199	-665	493	1
-51	-36	-1987	-3	6	28	-31	-118	-412	306	0
-31	-27	-1207	-2	4	18	-20	-80	-248	187	1
-103	-72	-3943	-6	10	56	-56	-223	-818	604	0
-36	-25	-1439	-3	5	19	-24	-97	-298	224	0
-143	-94	-5430	-8	14	76	-75	-296	-1128	829	0
-89	-62	-3404	-5	9	47	-49	-193	-706	521	0
-79	-55	-3039	-4	9	43	-45	-174	-630	465	0
-109	-70	-4198	-6	11	57	-61	-241	-872	643	0
-97	-55	-3735	-6	10	50	-56	-219	-776	572	0
-35	-27	-1381	-3	5	19	-26	-103	-284	217	0
-21	-20	-835	-2	3	12	-16	-59	-171	131	0
-93	-68	-3555	-5	10	50	-51	-199	-738	543	0
-42	-24	-1650	-4	5	21	-28	-111	-341	255	0
-26	-19	-1076	-2	3	15	-21	-80	-221	167	1
-30	-21	-1169	-2	4	16	-20	-77	-241	181	0
-22	-17	-908	-2	3	12	-17	-69	-186	142	1
-79	-53	-3055	-5	9	41	-47	-186	-633	470	0
-153	-89	-5861	-9	14	79	-80	-323	-1219	894	1
-16	-13	-690	-2	4	9	-19	-71	-139	111	0
-31	-34	-1179	-2	4	19	-20	-75	-242	183	1
-56	-35	-2206	-5	7	29	-39	-151	-455	342	0
-113	-87	-4221	-6	11	62	-58	-235	-875	646	1
-19	-17	-735	-2	3	11	-15	-59	-150	116	0
-60	-55	-2276	-3	7	34	-34	-132	-469	350	1
-27	-24	-1175	-4	5	16	-28	-107	-238	188	0
-83	-50	-3215	-5	9	43	-49	-194	-667	493	0
-55	-35	-2126	-4	6	29	-34	-137	-439	329	0
-43	-26	-1670	-3	5	22	-25	-102	-346	257	0
-61	-45	-2339	-4	7	32	-35	-139	-485	359	1
-37	-26	-1459	-3	5	19	-26	-102	-300	227	0
-96	-63	-3641	-5	10	50	-52	-207	-755	557	0
-90	-61	-3451	-5	9	48	-49	-193	-716	528	0
-85	-72	-3260	-5	10	48	-51	-198	-673	502	1
-73	-50	-2839	-5	8	38	-45	-176	-587	438	0
-77	-68	-2914	-4	9	44	-44	-175	-601	449	0
-151	-91	-5740	-8	14	78	-81	-320	-1193	877	0
-53	-34	-2029	-3	6	28	-31	-121	-420	312	0
-344	-226	-13010	-18	33	181	-180	-715	-2703	1986	0
-368	-240	-13979	-20	35	194	-191	-762	-2905	2133	1
-192	-138	-7268	-10	19	103	-100	-399	-1508	1111	1
-57	-42	-2195	-4	6	30	-36	-138	-453	339	0
-19	-13	-802	-2	3	10	-18	-69	-163	127	0
-355	-213	-13539	-19	33	184	-185	-740	-2816	2065	1
-6	-3	-345	-3	3	3	-15	-57	-68	60	0
-53	-42	-2094	-4	7	29	-35	-137	-431	324	0
-322	-182	-12268	-17	29	163	-165	-661	-2555	1869	1
-32	-33	-1215	-2	4	18	-21	-80	-248	188	0
-33	-24	-1258	-3	4	18	-22	-83	-259	195	0
-107	-79	-4041	-6	11	58	-56	-226	-838	618	0
-56	-42	-2117	-3	6	30	-32	-127	-438	326	0
-28	-28	-1066	-2	4	16	-19	-69	-218	165	0
-182	-108	-6973	-10	17	93	-98	-389	-1450	1065	0
-57	-41	-2201	-3	7	31	-33	-133	-455	338	0
-35	-23	-1371	-2	4	18	-23	-91	-283	212	0
-45	-36	-1722	-3	5	25	-28	-111	-356	266	0
-23	-21	-931	-1	3	14	-16	-61	-192	144	0
-80	-69	-3074	-4	9	45	-47	-185	-635	473	0
-46	-27	-1851	-3	5	23	-30	-119	-383	286	0
-59	-36	-2276	-4	6	29	-36	-141	-472	350	0
-293	-185	-11120	-16	27	153	-149	-595	-2312	1694	0
-61	-37	-2440	-5	7	31	-44	-168	-505	379	0
-58	-57	-2223	-4	8	34	-37	-147	-456	346	0
-27	-21	-1158	-3	4	15	-25	-95	-237	183	1
-37	-35	-1436	-2	5	22	-27	-105	-294	225	0
-36	-30	-1394	-3	5	20	-27	-100	-286	218	0
-46	-37	-1786	-3	5	26	-28	-112	-368	275	0
-216	-131	-8177	-11	20	112	-111	-440	-1701	1246	1
-19	-19	-760	-2	3	11	-15	-59	-156	120	0
-70	-49	-2743	-5	8	38	-45	-173	-567	422	0
-51	-45	-1929	-3	6	29	-30	-114	-398	297	1
-54	-44	-2080	-4	7	29	-36	-138	-427	322	0
-25	-24	-997	-2	4	15	-19	-70	-204	156	0
-81	-60	-3060	-4	9	44	-45	-176	-634	469	0
-23	-18	-889	-2	4	12	-17	-67	-181	139	1
-49	-44	-1861	-3	6	28	-28	-109	-384	286	0
-181	-120	-6859	-9	18	95	-95	-378	-1425	1048	0
-55	-35	-2169	-4	6	28	-37	-144	-449	336	1
-38	-24	-1512	-3	6	20	-27	-108	-312	235	0
-33	-35	-1308	-3	5	20	-23	-93	-267	204	1
-146	-104	-5525	-8	15	78	-78	-309	-1146	844	0
-62	-40	-2439	-4	7	33	-39	-149	-506	375	1
-210	-124	-8010	-11	19	109	-107	-430	-1666	1219	0
-69	-51	-2632	-4	9	37	-40	-158	-545	404	0
-24	-25	-987	-2	4	15	-19	-75	-201	155	1
-79	-52	-3013	-4	7	42	-43	-170	-624	460	0
-49	-34	-1919	-3	6	26	-30	-121	-396	296	0
-21	-17	-908	-2	4	11	-22	-82	-185	144	0
-39	-35	-1507	-4	5	22	-26	-102	-310	234	0
-67	-44	-2613	-4	7	36	-39	-153	-541	400	1
-69	-50	-2628	-4	7	37	-37	-150	-545	403	0
-69	-57	-2595	-4	8	38	-39	-154	-536	399	0
-27	-25	-1089	-2	4	16	-23	-90	-222	172	0
-32	-23	-1242	-2	4	17	-20	-79	-256	192	0
-27	-24	-1128	-3	5	14	-27	-99	-231	179	1
-81	-40	-3263	-7	10	39	-58	-225	-675	507	0
-282	-166	-10710	-15	25	145	-142	-573	-2230	1631	1
-44	-25	-1771	-4	5	22	-31	-119	-367	274	0
-51	-44	-1947	-3	6	29	-31	-124	-401	301	0
-52	-33	-2020	-3	5	27	-31	-123	-418	311	0
-35	-27	-1404	-3	4	20	-23	-91	-289	217	1
-15	-11	-625	-1	3	8	-13	-49	-128	98	0
-32	-33	-1219	-2	4	19	-24	-90	-249	191	0
-83	-73	-3213	-6	11	46	-55	-212	-662	499	0
-15	-14	-577	-2	3	9	-13	-48	-118	92	1
-45	-30	-1783	-4	6	24	-31	-121	-369	277	0
-39	-28	-1533	-3	5	21	-25	-101	-316	238	0
-64	-49	-2487	-4	7	35	-37	-149	-514	383	0
-16	-14	-682	-2	3	9	-18	-66	-139	109	1
-128	-105	-4820	-6	13	72	-67	-267	-999	738	1
-29	-19	-1179	-3	4	15	-24	-92	-242	185	0
-46	-51	-1744	-3	6	28	-30	-112	-357	271	1
-62	-36	-2436	-4	7	32	-38	-152	-505	375	0
-33	-21	-1349	-4	5	17	-29	-111	-277	213	0
-34	-25	-1433	-3	5	19	-31	-120	-293	227	1
-277	-173	-10453	-14	25	144	-139	-559	-2174	1592	0
-12	-8	-491	-2	2	6	-12	-47	-100	79	0
-68	-43	-2610	-4	7	35	-41	-160	-540	402	0
-66	-52	-2526	-4	8	36	-40	-155	-523	389	0
-119	-80	-4555	-6	12	63	-65	-257	-945	697	1
-67	-53	-2534	-4	7	37	-39	-150	-525	390	0
-95	-56	-3693	-6	10	49	-54	-218	-766	565	0
-82	-51	-3202	-5	9	43	-49	-192	-664	492	1
-6	-6	-325	-1	2	4	-11	-37	-65	54	0
-114	-72	-4344	-7	11	59	-63	-247	-902	665	0
-90	-74	-3425	-5	10	50	-51	-202	-708	526	0
-41	-31	-1628	-3	5	22	-29	-110	-335	253	0
-73	-46	-2853	-5	8	38	-44	-172	-592	439	0
-16	-16	-715	-2	3	10	-18	-65	-145	114	0
-48	-37	-1845	-3	6	26	-31	-120	-380	286	0
-70	-51	-2767	-6	9	38	-48	-190	-570	430	0
-40	-39	-1570	-3	5	24	-27	-100	-324	244	1
-182	-133	-6846	-9	18	99	-94	-374	-1420	1044	0
-70	-62	-2615	-4	8	40	-38	-152	-540	402	0
-116	-78	-4425	-6	12	61	-64	-253	-918	678	0
-77	-59	-2925	-5	8	43	-42	-165	-605	448	1
-9	-8	-424	-1	2	5	-11	-39	-86	68	1
-14	-13	-619	-2	3	8	-13	-53	-127	99	1
-29	-17	-1172	-3	4	14	-23	-88	-242	182	0
-30	-28	-1179	-3	4	17	-21	-85	-242	185	1
-77	-53	-2945	-5	8	41	-44	-170	-610	452	1
-66	-65	-2431	-3	8	39	-35	-141	-501	373	0
-129	-85	-4872	-7	12	68	-67	-269	-1011	744	0
-23	-19	-983	-3	4	13	-21	-79	-201	155	0
-34	-27	-1399	-3	5	19	-28	-105	-287	219	0
-88	-54	-3379	-5	9	46	-47	-191	-702	517	0
-29	-34	-1137	-2	4	18	-20	-76	-233	177	0
-88	-67	-3428	-5	10	48	-56	-219	-707	530	0
-23	-22	-909	-1	3	13	-18	-69	-185	143	0
-27	-20	-1102	-3	5	15	-23	-90	-225	174	0
-27	-15	-1145	-3	4	13	-25	-95	-236	181	1
-74	-44	-2911	-6	8	38	-48	-190	-602	450	0
-91	-63	-3555	-7	11	48	-59	-230	-734	550	0
-34	-23	-1343	-4	4	18	-24	-95	-277	209	0
-87	-48	-3326	-5	8	44	-47	-191	-691	509	0
-48	-33	-1829	-3	5	25	-29	-114	-378	282	0
-206	-128	-7866	-11	20	107	-110	-436	-1635	1201	1
-30	-18	-1171	-3	3	15	-20	-81	-241	181	0
-6	-5	-350	-2	2	4	-13	-47	-69	58	0
-50	-33	-2008	-4	6	27	-33	-133	-415	310	0
-75	-58	-2834	-4	8	41	-40	-160	-586	433	1
-225	-147	-8543	-12	21	119	-116	-459	-1776	1302	1
-39	-37	-1501	-3	6	22	-28	-106	-307	235	0
-31	-29	-1232	-2	5	18	-23	-86	-253	192	0
-32	-18	-1252	-4	4	17	-22	-86	-258	193	0
-77	-59	-2954	-4	8	42	-44	-170	-611	453	1
-136	-98	-5196	-8	14	74	-75	-297	-1077	795	0
-26	-16	-1067	-4	4	13	-25	-92	-218	169	0
-29	-32	-1152	-3	4	18	-23	-86	-235	180	1
-30	-34	-1142	-2	4	18	-20	-75	-234	178	1
-32	-22	-1239	-2	4	17	-21	-84	-256	192	1
-58	-39	-2233	-4	7	31	-36	-142	-461	344	0
-169	-99	-6478	-10	16	86	-90	-359	-1347	987	1
-35	-36	-1337	-2	5	21	-22	-89	-274	208	0
-214	-141	-8122	-12	21	113	-113	-450	-1687	1241	0
-17	-17	-718	-2	3	10	-15	-56	-146	113	1
-118	-89	-4432	-6	12	64	-62	-250	-919	679	0
-67	-44	-2541	-4	7	35	-38	-150	-526	390	0
-13	-16	-554	-1	2	9	-11	-43	-113	87	0
-55	-44	-2135	-4	7	30	-40	-149	-439	333	0
-12	-8	-577	-2	3	6	-15	-58	-117	93	0
-31	-18	-1288	-3	4	16	-26	-96	-266	201	0
-179	-122	-6739	-9	17	95	-91	-361	-1400	1028	1
-27	-16	-1139	-4	4	14	-24	-92	-233	179	0
-15	-10	-664	-2	3	8	-17	-62	-135	106	0
-136	-88	-5208	-8	14	71	-76	-301	-1080	798	0
-79	-55	-3017	-5	8	42	-43	-173	-625	462	1
-177	-129	-6734	-10	18	96	-97	-384	-1396	1031	1
-87	-64	-3299	-5	9	47	-47	-186	-683	505	0
-27	-27	-1054	-2	4	16	-18	-73	-217	164	0
-198	-124	-7532	-10	18	104	-103	-409	-1566	1149	0
-37	-29	-1450	-4	4	21	-24	-98	-298	225	0
-35	-17	-1422	-3	5	17	-27	-105	-294	221	0
-58	-58	-2179	-3	7	34	-33	-133	-448	337	1
-13	-8	-627	-2	3	7	-17	-63	-128	101	0
-57	-57	-2151	-3	7	33	-34	-132	-442	332	0
-64	-44	-2489	-5	7	35	-37	-149	-515	382	1
-36	-25	-1423	-3	5	19	-26	-104	-292	223	0
-33	-35	-1242	-3	4	19	-21	-82	-254	193	0
-78	-59	-2937	-4	8	42	-43	-168	-608	450	0
-58	-44	-2194	-4	7	32	-36	-136	-453	339	1
-29	-14	-1303	-5	5	13	-34	-125	-266	209	0
-88	-59	-3416	-6	9	47	-52	-203	-708	525	0
-194	-139	-7342	-10	19	104	-103	-407	-1524	1123	1
-75	-49	-2885	-5	9	39	-47	-181	-597	446	0
-37	-28	-1451	-3	4	20	-24	-91	-300	224	1
-49	-40	-1924	-4	7	27	-38	-144	-394	302	0
-158	-106	-6006	-8	15	84	-83	-331	-1246	917	1
-71	-48	-2709	-4	8	38	-41	-164	-561	416	1
-28	-19	-1189	-4	5	14	-29	-107	-243	190	0
-32	-33	-1263	-3	5	18	-26	-97	-258	198	1
-50	-43	-1914	-3	6	28	-32	-125	-394	297	0
-39	-37	-1469	-2	5	22	-25	-98	-301	228	0
-14	-15	-593	-1	3	9	-12	-48	-121	94	1
-222	-154	-8377	-11	21	118	-114	-455	-1739	1278	0
-24	-21	-943	-2	3	13	-17	-65	-193	146	0
-41	-22	-1657	-4	6	21	-31	-120	-342	257	0
-175	-130	-6619	-9	17	95	-91	-363	-1372	1012	1
-48	-33	-1888	-4	5	26	-30	-117	-390	291	0
-25	-15	-1136	-4	5	12	-29	-110	-232	183	0
-32	-25	-1259	-2	4	18	-21	-80	-260	195	1
-56	-42	-2155	-5	6	31	-34	-131	-445	332	1
-125	-81	-4732	-7	12	65	-66	-265	-982	723	1
-88	-64	-3359	-5	9	47	-49	-192	-696	515	1
-47	-37	-1824	-3	6	26	-30	-115	-377	282	1
-72	-54	-2805	-5	9	39	-47	-181	-579	433	0
-38	-38	-1463	-2	5	22	-23	-91	-301	227	1
-16	-10	-647	-2	2	8	-15	-55	-132	103	0
-309	-190	-11715	-16	28	161	-157	-630	-2436	1785	1
-116	-78	-4457	-7	12	62	-64	-257	-925	682	0
-38	-38	-1470	-3	5	23	-23	-91	-301	227	0
-32	-24	-1298	-3	4	17	-24	-94	-267	203	1
-64	-51	-2440	-3	7	36	-39	-150	-503	376	0
-100	-89	-3765	-5	11	57	-57	-221	-777	578	0
-170	-127	-6391	-8	17	93	-87	-349	-1326	977	1
-80	-60	-3059	-4	8	44	-44	-172	-634	469	1
-148	-100	-5631	-8	15	78	-80	-317	-1168	862	0
-136	-89	-5138	-7	13	71	-71	-283	-1068	784	0
-19	-21	-763	-1	3	12	-13	-55	-157	120	0
-25	-18	-1024	-2	4	14	-19	-73	-211	160	0
-69	-47	-2637	-4	7	36	-39	-153	-546	404	0
-71	-46	-2771	-4	7	37	-41	-163	-574	425	0
-48	-42	-1824	-3	6	27	-30	-118	-375	282	0
-71	-65	-2668	-4	8	41	-40	-154	-551	410	1
-24	-30	-888	-2	4	15	-17	-63	-181	140	0
-25	-26	-1000	-2	4	15	-19	-73	-204	157	1
-75	-45	-2955	-5	9	39	-49	-188	-612	456	0
-34	-23	-1313	-3	4	18	-22	-87	-271	203	0
-59	-59	-2256	-3	8	35	-36	-137	-465	349	1
-51	-32	-2019	-4	7	26	-37	-144	-417	314	0
-50	-40	-1929	-3	5	28	-28	-114	-399	296	1
-67	-40	-2647	-5	7	35	-41	-164	-549	407	0
-31	-24	-1219	-2	4	17	-19	-78	-252	189	0
-28	-26	-1153	-3	5	16	-24	-94	-236	183	1
-52	-32	-2126	-5	7	27	-41	-155	-438	332	1
-6	-8	-367	-2	3	3	-17	-63	-72	65	0
-47	-42	-1861	-4	6	27	-32	-127	-382	289	0
-38	-34	-1489	-2	5	22	-27	-103	-306	232	0
-68	-54	-2571	-4	7	38	-36	-146	-533	394	1
-32	-34	-1287	-3	5	19	-25	-95	-263	202	1
-21	-13	-882	-3	3	11	-19	-69	-181	138	1
-36	-37	-1365	-2	5	21	-22	-86	-280	211	1
-104	-72	-4011	-6	11	56	-58	-232	-832	615	1
-69	-48	-2625	-4	7	36	-40	-158	-543	404	1
-96	-68	-3654	-6	10	51	-53	-211	-757	560	0
-55	-31	-2203	-5	6	28	-39	-147	-456	342	0
-21	-16	-869	-2	3	12	-17	-67	-178	137	1
-45	-40	-1739	-3	6	25	-29	-113	-358	270	1
-85	-72	-3168	-4	9	48	-45	-182	-656	486	1
-31	-22	-1206	-2	4	17	-21	-78	-249	187	0
-70	-56	-2675	-4	8	39	-38	-153	-553	410	0
-110	-71	-4283	-8	13	57	-70	-276	-886	662	0
-65	-60	-2529	-5	8	38	-42	-166	-520	392	1
-50	-39	-1940	-4	6	27	-32	-123	-400	300	0
-31	-25	-1232	-3	5	17	-26	-97	-252	193	0
-17	-17	-702	-2	2	10	-14	-52	-143	110	1
-28	-18	-1175	-4	4	15	-26	-97	-241	185	1
-83	-59	-3176	-4	8	45	-47	-184	-657	487	0
-90	-66	-3435	-5	9	49	-48	-192	-712	526	0
-45	-37	-1710	-2	5	24	-26	-104	-353	263	1
-304	-197	-11541	-16	29	160	-157	-628	-2399	1760	0
-231	-170	-8660	-11	22	125	-115	-462	-1798	1320	0
-89	-49	-3476	-6	9	45	-52	-208	-722	533	0
-86	-69	-3255	-5	9	48	-45	-181	-674	498	1
-14	-12	-607	-2	3	7	-18	-68	-123	100	0
-90	-63	-3454	-5	9	48	-50	-197	-716	529	0
-38	-32	-1448	-3	5	21	-25	-98	-298	225	1
-99	-89	-3704	-5	11	57	-54	-216	-764	569	1
-45	-32	-1757	-3	5	24	-28	-106	-364	270	0
-61	-42	-2461	-5	8	32	-45	-176	-507	384	1
-48	-35	-1873	-4	6	26	-32	-123	-386	290	0
-51	-27	-2002	-4	6	26	-34	-135	-414	310	0
-34	-23	-1360	-3	4	18	-24	-92	-280	211	1
-102	-86	-3825	-5	12	57	-56	-221	-790	587	0
-92	-50	-3626	-7	10	46	-61	-236	-751	560	0
-91	-66	-3462	-5	9	49	-49	-198	-717	531	0
-36	-31	-1470	-3	5	21	-28	-109	-302	231	1
-35	-29	-1367	-2	4	20	-23	-86	-281	211	0
-49	-32	-1872	-3	5	26	-29	-110	-388	287	1
-33	-35	-1283	-2	5	20	-22	-82	-264	199	1
-33	-23	-1319	-3	5	17	-27	-104	-270	207	0
-34	-36	-1303	-2	6	20	-23	-87	-266	202	0
-394	-256	-14800	-18	36	207	-193	-774	-3078	2252	0
-36	-26	-1413	-3	5	19	-26	-97	-291	219	0
-110	-91	-4133	-5	12	61	-58	-229	-855	632	1
-18	-22	-710	-2	3	10	-15	-56	-145	112	1
-30	-25	-1238	-3	5	17	-24	-92	-255	194	0
-114	-69	-4373	-8	11	59	-64	-255	-908	670	1
-46	-41	-1752	-3	6	26	-29	-114	-360	272	0
-45	-36	-1779	-3	6	25	-29	-115	-367	275	0
-200	-133	-7546	-10	19	106	-103	-406	-1567	1150	1
-114	-83	-4335	-6	12	62	-61	-246	-898	664	0
-34	-26	-1312	-2	5	19	-22	-87	-270	203	1
-23	-28	-897	-2	4	14	-20	-74	-182	142	1
-14	-14	-648	-2	3	9	-16	-63	-132	104	1
-186	-134	-7071	-10	19	100	-101	-399	-1467	1083	0
-45	-31	-1819	-4	6	24	-30	-121	-376	282	1
-55	-46	-2180	-4	7	31	-38	-145	-449	339	1
-201	-133	-7648	-12	19	106	-107	-424	-1588	1168	1
-58	-47	-2220	-4	7	32	-36	-139	-457	343	0
-98	-62	-3757	-5	9	51	-53	-210	-780	574	0
-19	-17	-841	-2	4	11	-20	-74	-172	133	1
-256	-172	-9667	-13	24	135	-131	-523	-2007	1474	0
-105	-78	-3992	-6	11	58	-56	-225	-827	611	0
-156	-94	-6015	-9	15	81	-86	-341	-1250	920	0
-32	-24	-1227	-2	4	18	-20	-80	-253	190	0
-21	-19	-852	-2	3	12	-15	-61	-174	133	1
-54	-42	-2121	-4	7	29	-38	-146	-436	330	0
-23	-15	-994	-3	3	12	-21	-78	-205	156	0
-23	-11	-992	-3	4	12	-23	-89	-203	158	0
-158	-101	-5970	-8	15	82	-82	-327	-1241	911	0
-87	-68	-3308	-4	9	48	-49	-194	-684	507	0
-92	-86	-3414	-4	10	53	-48	-193	-705	524	0
-118	-69	-4580	-7	12	61	-68	-269	-951	702	1
-75	-59	-2855	-5	9	41	-47	-181	-589	442	0
-103	-72	-3915	-6	10	55	-55	-220	-812	599	0
-144	-103	-5431	-8	14	77	-76	-301	-1126	830	0
-261	-184	-9803	-13	25	140	-134	-533	-2036	1497	0
-51	-30	-1968	-3	6	26	-30	-120	-407	302	0
-63	-47	-2442	-4	8	34	-41	-155	-504	376	1
-114	-82	-4284	-6	11	61	-60	-238	-889	655	0
-128	-85	-4870	-7	13	68	-69	-275	-1011	745	0
-143	-134	-5293	-7	15	84	-71	-285	-1094	809	1
-56	-44	-2257	-5	8	31	-43	-164	-464	353	0
-36	-32	-1375	-2	4	20	-24	-89	-283	213	0
-35	-18	-1456	-4	5	17	-32	-118	-299	230	0
-55	-36	-2157	-4	6	29	-35	-139	-445	333	0
-36	-28	-1399	-3	5	20	-24	-97	-288	218	0
-126	-82	-4827	-8	13	66	-72	-283	-1001	741	0
-246	-157	-9321	-13	23	129	-125	-501	-1938	1419	0
-166	-134	-6174	-8	17	92	-85	-339	-1278	943	0
-33	-22	-1275	-2	4	17	-22	-86	-262	197	0
-71	-65	-2709	-5	8	42	-41	-160	-558	416	0
-67	-40	-2604	-6	7	34	-41	-161	-539	400	0
-89	-55	-3453	-5	8	47	-50	-201	-716	528	0
-23	-23	-923	-2	3	14	-16	-66	-189	144	0
-64	-44	-2489	-5	7	35	-36	-146	-516	382	0
-71	-56	-2740	-5	8	40	-42	-161	-566	421	0
-114	-61	-4460	-7	11	58	-67	-263	-927	683	0
-57	-47	-2161	-3	7	31	-33	-131	-446	333	0
-28	-15	-1171	-3	5	14	-25	-99	-240	185	0
-26	-21	-1044	-2	4	14	-20	-75	-214	163	0
-22	-18	-877	-2	4	11	-20	-74	-180	139	0
-45	-36	-1703	-3	5	25	-26	-105	-351	263	0
-46	-32	-1803	-4	6	25	-32	-123	-372	280	0
-27	-21	-1064	-2	5	15	-19	-76	-219	166	1
-158	-120	-5989	-8	16	86	-86	-340	-1240	918	1
-33	-32	-1305	-4	5	20	-27	-102	-266	206	0
-61	-54	-2369	-5	7	35	-39	-151	-487	366	0
-62	-53	-2392	-4	7	35	-38	-145	-494	368	0
-132	-79	-5035	-7	14	68	-72	-286	-1045	770	0
-165	-125	-6205	-9	16	90	-84	-334	-1286	947	1
-73	-46	-2808	-4	7	38	-42	-162	-582	430	1
-28	-21	-1141	-2	4	16	-20	-78	-235	177	0
-50	-31	-2004	-4	6	26	-33	-131	-415	309	0
-15	-20	-597	-1	4	10	-15	-54	-121	95	0
-27	-17	-1134	-3	4	14	-22	-85	-233	178	1
-60	-45	-2344	-4	7	32	-40	-155	-484	363	0
-27	-19	-1077	-2	4	15	-18	-74	-222	168	0
-352	-234	-13263	-17	32	186	-175	-699	-2758	2019	1
-188	-118	-7185	-11	19	98	-106	-417	-1490	1101	0
-77	-62	-2912	-5	9	42	-46	-179	-601	448	0
-37	-31	-1424	-3	5	21	-24	-97	-294	222	0
-79	-58	-2978	-5	8	43	-44	-176	-616	457	0
-152	-95	-5814	-9	14	80	-81	-322	-1207	887	0
-32	-20	-1265	-3	4	17	-24	-90	-261	197	1
-9	-8	-411	-1	1	6	-11	-39	-83	65	1
-29	-23	-1162	-2	4	16	-19	-77	-240	180	1
-15	-10	-751	-3	5	8	-23	-89	-151	124	0
-65	-55	-2431	-3	7	37	-35	-139	-502	373	1
-4	-3	-239	-1	1	2	-11	-43	-47	42	0
-31	-24	-1247	-3	6	17	-25	-99	-255	197	0
-46	-37	-1780	-3	5	26	-27	-110	-368	275	1
-159	-119	-6070	-9	17	87	-90	-355	-1256	932	1
-32	-32	-1208	-2	4	19	-22	-88	-246	189	0
-159	-101	-6055	-9	15	83	-85	-335	-1258	925	0
-49	-44	-1880	-3	6	28	-27	-111	-389	288	1
-16	-11	-720	-2	3	8	-19	-70	-147	116	0
-65	-52	-2463	-3	7	36	-37	-147	-509	378	0
-82	-43	-3196	-5	8	41	-49	-193	-663	490	0
-100	-80	-3775	-5	11	56	-55	-213	-782	578	0
-288	-170	-10929	-15	26	149	-144	-580	-2276	1663	1
-107	-69	-4143	-7	11	57	-60	-239	-860	633	0
-166	-88	-6393	-10	16	83	-92	-364	-1330	976	0
-107	-79	-4049	-6	11	58	-56	-226	-839	619	1
-57	-47	-2200	-4	7	32	-35	-136	-453	339	0
-25	-19	-992	-2	3	14	-17	-68	-205	154	0
-78	-55	-2990	-5	9	41	-47	-184	-618	460	0
-62	-51	-2349	-3	8	35	-34	-136	-485	360	0
-354	-217	-13407	-17	32	183	-177	-711	-2790	2040	0
-43	-31	-1700	-3	5	23	-28	-107	-352	263	0
-62	-43	-2375	-4	6	32	-36	-139	-492	364	0
-29	-22	-1206	-3	4	16	-24	-89	-248	189	1
-131	-84	-4963	-7	12	69	-68	-274	-1030	757	0
-75	-49	-2865	-5	8	39	-44	-172	-593	440	0
-7	-5	-406	-2	3	4	-16	-59	-81	69	0
-23	-25	-924	-2	4	14	-17	-63	-190	144	1
-19	-18	-797	-2	3	11	-15	-57	-163	124	0
-145	-99	-5457	-7	14	76	-75	-298	-1133	833	0
-36	-24	-1473	-3	5	19	-31	-118	-302	231	1
-31	-34	-1217	-2	5	18	-22	-85	-248	190	1
-28	-12	-1231	-5	5	13	-31	-121	-252	197	0
-30	-24	-1204	-3	4	17	-23	-91	-246	189	1
-35	-35	-1319	-2	5	21	-23	-90	-270	206	0
-15	-15	-655	-2	3	9	-16	-60	-133	105	1
-123	-72	-4773	-8	13	63	-74	-291	-989	734	0
-52	-41	-2009	-3	6	29	-30	-121	-415	309	1
-54	-36	-2094	-3	6	29	-31	-125	-434	322	0
-316	-181	-11989	-16	28	162	-160	-640	-2496	1825	1
-62	-50	-2331	-4	7	34	-35	-139	-481	358	0
-26	-20	-1094	-3	4	15	-23	-86	-225	173	0
-77	-63	-2940	-4	9	43	-44	-172	-608	452	1
-71	-43	-2744	-5	7	37	-42	-164	-568	421	0
-88	-55	-3420	-5	9	46	-50	-197	-710	524	0
-38	-24	-1568	-4	6	19	-34	-129	-322	248	0
-69	-55	-2660	-4	8	39	-40	-155	-550	408	0
-202	-134	-7626	-10	19	107	-102	-410	-1586	1163	1
-81	-57	-3098	-5	9	43	-47	-186	-642	476	0
-54	-44	-2105	-5	7	30	-38	-147	-432	328	0
-33	-21	-1403	-4	6	17	-33	-123	-287	223	0
-34	-36	-1298	-2	4	21	-21	-84	-266	201	1
-89	-73	-3344	-5	10	49	-50	-198	-691	515	0
-86	-59	-3318	-5	9	46	-48	-189	-688	508	0
-143	-102	-5402	-7	14	77	-77	-305	-1120	826	0
-93	-58	-3664	-7	11	47	-62	-240	-758	567	0
-124	-96	-4665	-6	13	68	-65	-256	-967	713	1
-46	-39	-1838	-4	6	26	-37	-139	-376	289	0
-33	-25	-1334	-3	4	18	-23	-92	-275	208	0
-19	-18	-792	-3	3	12	-15	-56	-162	124	1
-158	-95	-6118	-10	16	81	-92	-361	-1270	938	0
-47	-37	-1837	-3	5	26	-30	-120	-379	284	0
-66	-49	-2532	-4	9	36	-41	-160	-522	391	0
-70	-73	-2605	-4	9	42	-41	-159	-535	401	0
-155	-118	-5888	-9	16	85	-86	-338	-1219	903	1
-150	-111	-5672	-8	15	82	-77	-310	-1177	867	1
-28	-29	-1125	-3	5	17	-23	-86	-230	176	1
-157	-99	-5971	-9	15	82	-85	-338	-1240	912	0
-29	-18	-1156	-3	4	15	-20	-80	-238	179	0
-71	-52	-2737	-5	9	38	-46	-179	-565	424	0
-76	-57	-2897	-4	9	42	-44	-172	-599	445	0
-57	-35	-2176	-5	6	30	-33	-128	-451	333	0
-184	-108	-7103	-11	18	95	-102	-405	-1475	1085	1
-31	-24	-1190	-2	4	17	-20	-76	-246	184	0
-16	-24	-681	-3	4	11	-21	-75	-135	112	0
-36	-24	-1466	-3	5	19	-27	-101	-303	228	0

From r.turner at auckland.ac.nz  Fri Nov 15 23:23:06 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Nov 2013 11:23:06 +1300
Subject: [R] Bug in predict.lm?
In-Reply-To: <loom.20131115T225210-168@post.gmane.org>
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
	<loom.20131115T225210-168@post.gmane.org>
Message-ID: <52869ECA.6050802@auckland.ac.nz>


I *do* see the same phenomenon that Bert describes and the code of 
predict.lm()
*does* appear to contain a bug.  There is a line:

> XRinv <- if (missing(newdata) && is.null(w))

But "w" gets assigned (as object$weights) only if (is.null(scale)).

If that assignment is moved outside of the applicable "if field" (e.g. 
and is put
just after the line:

> if (se.fit || interval != "none") {

then predict.lm() throws no error.

> > sessionInfo()
> R version 3.0.2 Patched (2013-09-26 r64005)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> other attached packages:
> [1] fortunes_1.5-0 misc_0.0-15
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2

The operative difference between my set-up and Chuck's is that I am using
version 3.0.2 Patched.  So I am very puzzled as to why Chuck does *not* get
an error thrown!

BTW traceback() was not helpful:

> > predict(z,int="conf",scale=1)
> Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found
> > traceback()
> 2: predict.lm(z, int = "conf", scale = 1)
> 1: predict(z, int = "conf", scale = 1)

     cheers,

     Rolf


On 11/16/13 10:55, Charles Berry wrote:
> Bert Gunter <gunter.berton <at> gene.com> writes:
>
>> Yes, I realize that it is more likely  a misunderstanding on my part.
>> Suitable humility will be tendered if this is pointed out.
>>
>> The claimed "bug" is that predict.lm throws an error when the scale
>> argument is specified with interval = "conf" (and in some other
>> cases):
>>
>>> z <- lm(rnorm(10)~I(1:10))
>>> predict(z,int="conf",scale=1)
>> Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found
>>
>> R version 3.0.2 (2013-09-25)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> Cheers,
>> Bert
>>
> I do not see this (see below).
>
> Maybe traceback() or options(recover=browser) to get
> to the bottom??
>
>
>
>> z <- lm(rnorm(10)~I(1:10))
>> predict(z,int="conf",scale=1)
>            fit        lwr       upr
> 1  0.02491723 -1.1270591 1.1768935
> 2  0.06402057 -0.9129873 1.0410284
> 3  0.10312392 -0.7185606 0.9248085
> 4  0.14222726 -0.5569958 0.8414504
> 5  0.18133060 -0.4477852 0.8104464
> 6  0.22043395 -0.4086818 0.8495497
> 7  0.25953729 -0.4396858 0.9587604
> 8  0.29864063 -0.5230439 1.1203252
> 9  0.33774398 -0.6392639 1.3147518
> 10 0.37684732 -0.7751290 1.5288236
>> version
>                 _
> platform       x86_64-apple-darwin10.8.0
> arch           x86_64
> os             darwin10.8.0
> system         x86_64, darwin10.8.0
> status
> major          3
> minor          0.2
> year           2013
> month          09
> day            25
> svn rev        63987
> language       R
> version.string R version 3.0.2 (2013-09-25)
> nickname       Frisbee Sailing
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tdenes at cogpsyphy.hu  Fri Nov 15 23:32:34 2013
From: tdenes at cogpsyphy.hu (Toth, Denes)
Date: Fri, 15 Nov 2013 23:32:34 +0100
Subject: [R] Bug in predict.lm?
In-Reply-To: <loom.20131115T225210-168@post.gmane.org>
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
	<loom.20131115T225210-168@post.gmane.org>
Message-ID: <7a007cc050153b2ba6554e43a7fe6b04.squirrel@webmail.cogpsyphy.hu>


The same problem appears on a 64-bit linux:
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          0.2
year           2013
month          09
day            25
svn rev        63987
language       R
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing

After dputting the predict.lm function (traceback etc. did not give a hint
on the source of the error message) I could locate the invalid call at
around the 70-80th rows of the function:

...
        if (type != "terms") {
            if (p > 0) {
                XRinv <- if (missing(newdata) && is.null(w))
                    qr.Q(qr.lm(object))[, p1, drop = FALSE]
                else X[, piv] %*% qr.solve(qr.R(qr.lm(object))[p1,
                                                               p1])
                ip <- drop(XRinv^2 %*% rep(res.var, p))
            }  else ip <- rep(0, n)
        }
...

Here ...&& is.null(w)... causes the troubles.




> Bert Gunter <gunter.berton <at> gene.com> writes:
>
>>
>> Yes, I realize that it is more likely  a misunderstanding on my part.
>> Suitable humility will be tendered if this is pointed out.
>>
>> The claimed "bug" is that predict.lm throws an error when the scale
>> argument is specified with interval = "conf" (and in some other
>> cases):
>>
>> > z <- lm(rnorm(10)~I(1:10))
>>
>> > predict(z,int="conf",scale=1)
>> Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found
>>
>> R version 3.0.2 (2013-09-25)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> Cheers,
>> Bert
>>
>
> I do not see this (see below).
>
> Maybe traceback() or options(recover=browser) to get
> to the bottom??
>
>
>
>> z <- lm(rnorm(10)~I(1:10))
>> predict(z,int="conf",scale=1)
>           fit        lwr       upr
> 1  0.02491723 -1.1270591 1.1768935
> 2  0.06402057 -0.9129873 1.0410284
> 3  0.10312392 -0.7185606 0.9248085
> 4  0.14222726 -0.5569958 0.8414504
> 5  0.18133060 -0.4477852 0.8104464
> 6  0.22043395 -0.4086818 0.8495497
> 7  0.25953729 -0.4396858 0.9587604
> 8  0.29864063 -0.5230439 1.1203252
> 9  0.33774398 -0.6392639 1.3147518
> 10 0.37684732 -0.7751290 1.5288236
>> version
>                _
> platform       x86_64-apple-darwin10.8.0
> arch           x86_64
> os             darwin10.8.0
> system         x86_64, darwin10.8.0
> status
> major          3
> minor          0.2
> year           2013
> month          09
> day            25
> svn rev        63987
> language       R
> version.string R version 3.0.2 (2013-09-25)
> nickname       Frisbee Sailing
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Fri Nov 15 23:38:11 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 15 Nov 2013 23:38:11 +0100 (CET)
Subject: [R] CHAID in R
In-Reply-To: <CAHVFrXGKr4z0n4-q2rHBP9Ev4P1NGO5AmSzt4idL1F2gtMFa6A@mail.gmail.com>
References: <CAHVFrXGKr4z0n4-q2rHBP9Ev4P1NGO5AmSzt4idL1F2gtMFa6A@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1311152325030.23296@paninaro.uibk.ac.at>

On Sat, 16 Nov 2013, Preetam Pal wrote:

> Hi,
>
> I have a data set on credit rating for customers in a bank (Rating is 1 
> for defaulter, 0 = non-defaulter). I have 10 predictor variables 
> (C1,C2,.....,C10) . I want to build a CHAID Tree using R for 
> classification. How do I do this? For your perusal, the data set is 
> attached. Thanks in advance.

The classical CHAID algorithm is implemented in a package on R-Forge:
https://R-Forge.R-project.org/R/?group_id=343
However, this only supports categorical covariates and hence is not useful 
for your data.

Alternatively, you might want to try out other packages for learning 
classification trees, e.g., partykit or rpart. See also
http://CRAN.R-project.org/view=MachineLearning

For your data you could do:

## read data with factor response
d <- read.table("text.txt", header = TRUE)
d$Rating <- factor(d$Rating)

## ctree
library("partykit")
ct <- ctree(Rating ~ ., data = d)
plot(ct)

## rpart
library("rpart")
rp <- rpart(Rating ~ ., data = d, control = list(cp = 0.02))
plot(as.party(rp))

## evtree
library("evtree")
set.seed(1)
ev <- evtree(Rating ~ ., data = d, maxdepth = 5)
plot(ev)

All methods agree that the decisive split is in C2 at about -110. And 
possibly you might be able to infer some more splits for the < -110 
subsample but there the methods disagree somewhat.

Best,
Z

> -Preetam
>
> -- 
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>


From macqueen1 at llnl.gov  Sat Nov 16 00:43:11 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 15 Nov 2013 23:43:11 +0000
Subject: [R] Find backward duplicates in a data frame
In-Reply-To: <CAKyZeBuBGNOyx0zsBOGBnPSMR0B+LWWf9BnKFXAV6FFTT8Ts=w@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D57640D@PRDEXMBX-08.the-lab.llnl.gov>

So rows are considered duplicated if they have the same two characters,
regardless of which column they're in?

If the B A row came first is it ok to keep that row, or would you want to
keep the A B row?

This appears to work, at least for this example.

  foo <- t(apply(test,1, function(x) sort(format(x)) ))
  test[ !duplicated(foo),]

  a u
1 A B
2 A C
4 B F
6 D W


Note that the function sorts the formatted value, in case the factor
levels are such that they don't sort alphabetically.

Notice also that in the result, the second column ('u') is still a factor,
and its levels still include 'A', even though A no longer is present in
the column. Whether or not that's wanted, I couldn't say.

-Don



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/15/13 1:26 PM, "Hermann Norpois" <hnorpois at gmail.com> wrote:

>Hello,
>
>I am looking for a method to eliminate rows dupblicates in a backwards
>manner, for instance:
>I want to keep A B but not B A (see my data.frame test).
>Thanks
>Hermann
>
>> test
>  a u
>1 A B
>2 A C
>3 B A
>4 B F
>5 C A
>6 D W
>> dput (test)
>structure(list(a = structure(c(1L, 1L, 2L, 2L, 3L, 4L), .Label = c("A",
>"B", "C", "D"), class = "factor"), u = structure(c(2L, 3L, 1L,
>4L, 1L, 5L), .Label = c("A", "B", "C", "F", "W"), class = "factor")),
>.Names = c("a",
>"u"), row.names = c(NA, -6L), class = "data.frame")
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Nov 16 01:05:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Nov 2013 19:05:36 -0500
Subject: [R] Bug in predict.lm?
In-Reply-To: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
Message-ID: <5286B6D0.1070608@gmail.com>

On 13-11-15 11:57 AM, Bert Gunter wrote:
> Yes, I realize that it is more likely  a misunderstanding on my part.
> Suitable humility will be tendered if this is pointed out.
>
> The claimed "bug" is that predict.lm throws an error when the scale
> argument is specified with interval = "conf" (and in some other
> cases):
>
>> z <- lm(rnorm(10)~I(1:10))
>
>> predict(z,int="conf",scale=1)
> Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found
>
>
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
>
> Cheers,
> Bert
>
>
>
>

Looks more like a bug than a misunderstanding.  Please report via 
bug.report() or on bugs.r-project.org.

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Sat Nov 16 02:34:36 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 Nov 2013 17:34:36 -0800
Subject: [R] R for loop
In-Reply-To: <00e701cee21b$50500960$f0f01c20$@tamu.edu>
References: <1384521772459-4680515.post@n4.nabble.com>
	<00e701cee21b$50500960$f0f01c20$@tamu.edu>
Message-ID: <000616ea-fb25-491d-8e65-ebb6f8da6444@email.android.com>

You seem to have a problem with your Mindreader skills today, David!
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

David Carlson <dcarlson at tamu.edu> wrote:
>I would be easier to respond if we had some idea what
>Mindreader_2012_vars is, data.frame, list, matrix?
>
>Give us a small, reproducible version of what you are trying to
>accomplish. 
>
>-------------------------------------
>David L Carlson
>Department of Anthropology
>Texas A&M University
>College Station, TX 77840-4352
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of matira
>Sent: Friday, November 15, 2013 7:23 AM
>To: r-help at r-project.org
>Subject: [R] R for loop
>
>Hi
>I'm quite new to R and I am having trouble with this code:
>
>names(Mindreader_2012_vars)
>varlist<-names(Mindreader_2012_vars)
>for (i in 688:696) {
>  for (j in 673:685) {
> 
>assign(paste("Uk_Cluster_",i-687,sep=""),cbind(get(varlist[j],po
>s=Mindreader_2012_vars)[get(varlist[i],
>pos=Mindreader_2012_vars)>0]))
>}
>}
>
>I want this code to output 9 matrixes (which are the variables
>'i' is
>getting) which have 13 columns (one for each of the variables
>that 'j' is
>getting.
>At the moment I get 9 matrixes with only 1 column. I guess the
>issue is the
>way I am nesting the loops but i can't work out how to make it
>take all the
>values of 'j' in each matrix.
>
>Thanks
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/R-for-loop-tp4680515.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible
>code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Nov 16 00:08:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 15 Nov 2013 15:08:39 -0800 (PST)
Subject: [R] Find backward duplicates in a data frame
In-Reply-To: <CAKyZeBuBGNOyx0zsBOGBnPSMR0B+LWWf9BnKFXAV6FFTT8Ts=w@mail.gmail.com>
References: <CAKyZeBuBGNOyx0zsBOGBnPSMR0B+LWWf9BnKFXAV6FFTT8Ts=w@mail.gmail.com>
Message-ID: <1384556919.2992.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,May be:

fun1 <- function(dat){
indx <- apply(dat,1,function(x) {
??? ??? any(x==sort(x))| !any(as.character(interaction(dat,sep="")) %in% paste(sort(x),collapse=""))
??? ??? })
dat[indx,]
}

test1 <- rbind(test,data.frame(a="F",u="E"))
fun1(test)
fun1(test1)




A.K.




On Friday, November 15, 2013 4:58 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
Hello,

I am looking for a method to eliminate rows dupblicates in a backwards
manner, for instance:
I want to keep A B but not B A (see my data.frame test).
Thanks
Hermann

> test
? a u
1 A B
2 A C
3 B A
4 B F
5 C A
6 D W
> dput (test)
structure(list(a = structure(c(1L, 1L, 2L, 2L, 3L, 4L), .Label = c("A",
"B", "C", "D"), class = "factor"), u = structure(c(2L, 3L, 1L,
4L, 1L, 5L), .Label = c("A", "B", "C", "F", "W"), class = "factor")),
.Names = c("a",
"u"), row.names = c(NA, -6L), class = "data.frame")

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ccberry at ucsd.edu  Fri Nov 15 23:20:27 2013
From: ccberry at ucsd.edu (Charles Berry)
Date: Fri, 15 Nov 2013 22:20:27 +0000
Subject: [R] Bug in predict.lm?
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
	<loom.20131115T225210-168@post.gmane.org>
Message-ID: <loom.20131115T231920-697@post.gmane.org>

Charles Berry <ccberry <at> ucsd.edu> writes:

> 
> Bert Gunter <gunter.berton <at> gene.com> writes:
> 

[snip]

> 
> I do not see this (see below). 
> 
> Maybe traceback() or options(recover=browser) to get
> to the bottom??

Argh! I meant:

options(error = recover) 


[rest deleted]


From smartpink111 at yahoo.com  Sat Nov 16 00:32:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 15 Nov 2013 15:32:00 -0800 (PST)
Subject: [R] delete rows with duplicate numbers of opposite signs in the
	same column
Message-ID: <1384558320.54471.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:


library(plyr)
?fun1 <- function(dat){
?fun2 <- function(x) {indx <- x <0
? x1 <- x[!indx] %in% abs(x[indx])
? x2 <- abs(x[indx]) %in% x[!indx]
? x3 <- rbind(x[!indx][x1],x[indx][x2])
? x[!x %in% x3]}
?if(length(colnames(dat)) > 2) {
? lapply(colnames(dat)[-1], function(x) {
? dat1 <- cbind(dat[1],dat[x])
?ddply(dat1,.(Customer),colwise(fun2))
?})
?}
?else {
?ddply(dat,.(Customer),colwise(fun2))
?}
?}

dat1 <- structure(list(Customer = c("A", "A", "A", "B", "B", "B"), Consumption = c(100L, 
-100L, 150L, 20L, 30L, -30L)), .Names = c("Customer", "Consumption"
), class = "data.frame", row.names = c(NA, -6L))

dat2 <- structure(list(Customer = c("A", "A", "A", "B", "B", "B"), Consumption = c(100L, 
-100L, 150L, 20L, 30L, -30L), Column2 = c(30, -30, 40, 80, -40, 
40)), .Names = c("Customer", "Consumption", "Column2"), row.names = c(NA, 
-6L), class = "data.frame")

dat3 <- structure(list(Customer = c("A", "A", "A", "B", "B", "B", "B", 
"B"), Consumption = c(100, -100, 150, 20, 30, -30, 20, -40), 
??? Column2 = c(30, 40, -30, -40, 80, 40, 20, -60)), .Names = c("Customer", 
"Consumption", "Column2"), row.names = c(NA, 8L), class = "data.frame")



fun1(dat1)
fun1(dat2)
fun1(dat3)

A.K.



Hi guys 

I am working on the dataset that there are some duplicates with 
opposite signs in the same column. But those pairs of opposites are 
errors, I have to delete them. For example: 

Customer ? ?Consumption 
A ? ? ? ? ? ? ? ? ?100 
A ? ? ? ? ? ? ? ? -100 
A ? ? ? ? ? ? ? ? ?150 
B ? ? ? ? ? ? ? ? ? 20 
B ? ? ? ? ? ? ? ? ? 30 
B ? ? ? ? ? ? ? ? ?-30 

I have to get rid of those opposites for each 
customer(Consumption is one of the 13 variables in the dataset). This 
question troubles me for a long time, I really have no idea. 
Can anyone help me out or give me some hint? I really appreciate.


From smartpink111 at yahoo.com  Sat Nov 16 00:56:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 15 Nov 2013 15:56:59 -0800 (PST)
Subject: [R] reshape data frame
Message-ID: <1384559819.65236.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

Try:
var1 <- load("reshape_data.frame.RData")
##It is better not to name the objects with function names.
dat1 <- data
?reshape1 <- reshape
names(dat1)[grep("X\\d+",names(dat1))] <- gsub("[[:alpha:]]","X_",names(dat1)[grep("X\\d+",names(dat1))])
res1 <- reshape(dat1,direction="long",varying=7:ncol(dat1),sep="_")
res2 <- res1[with(res1,order(Yr,Seas,Flt.Svy,Gender,Part,NSAMP)),-9]
row.names(res2) <- 1:nrow(res2)
colnames(res2) <- colnames(reshape1)
all.equal(res2,reshape1)
#[1] TRUE

A.K.


Some advice on transforming my data would be appreciated. ?Attached is 
an .Rdata image with my examples (reshape_data.frame.Rdata). Within the 
image are 2 objects: 

1) The "data" object contains an example of my original data 
format. The columns "X20" : "X50" are histogram bins, and the rows 
beneath are the number of observations (ie. counts) within those bins. 
The other columns; "Yr", "Seas", "Flt.Svy", "Gender", "Part", "NSAMP" 
are observation associated with each bin count. ? 

2) The "reshape" object is the format I need to transform the "data" object into. 

I think the reshape() function is designed for this, and my 
"data" object is in wide format, and my "resphape" object would be in 
long format. ?If indeed reshape() is the best way to do this, I'm 
looking for help in calling the function to transform my data. ? 

Many thanks, 

Tim


From ccberry at ucsd.edu  Sat Nov 16 03:06:13 2013
From: ccberry at ucsd.edu (Charles Berry)
Date: Sat, 16 Nov 2013 02:06:13 +0000
Subject: [R] Bug in predict.lm?
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
	<loom.20131115T225210-168@post.gmane.org>
	<52869ECA.6050802@auckland.ac.nz>
Message-ID: <loom.20131116T024955-582@post.gmane.org>

Rolf Turner <r.turner <at> auckland.ac.nz> writes:

> 
> 
> I *do* see the same phenomenon that Bert describes and the code of 
> predict.lm()
> *does* appear to contain a bug.  There is a line:
> 
[snip]

> 
> The operative difference between my set-up and Chuck's is that I am using
> version 3.0.2 Patched.  So I am very puzzled as to why Chuck does *not* get
> an error thrown!
> 

[rest deleted]

The answer is that I made a rookie error.

I ran

  example(predict.lm)

before trying Bert's ECM.

And then I did not bother to see what example(predict.lm) left lying
around in R_GlobalEnv ...

As you can probably guess, there was an object called 'w'.

So predict.lm finds it and is.null(w) is FALSE.

Mea culpa!


From dalal.e.hanna at gmail.com  Sat Nov 16 00:30:13 2013
From: dalal.e.hanna at gmail.com (Dalal Hanna)
Date: Fri, 15 Nov 2013 18:30:13 -0500
Subject: [R] Help
Message-ID: <CAA3K1Kz-wfsv6c17V6XGTboqCNzxdOBmAvz4DCNCBpDvc5Zo9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131115/7434135c/attachment.pl>

From pdalgd at gmail.com  Sat Nov 16 10:35:46 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 16 Nov 2013 10:35:46 +0100
Subject: [R] Bug in predict.lm?
In-Reply-To: <loom.20131116T024955-582@post.gmane.org>
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>
	<loom.20131115T225210-168@post.gmane.org>
	<52869ECA.6050802@auckland.ac.nz>
	<loom.20131116T024955-582@post.gmane.org>
Message-ID: <944273B4-FC14-43F5-81A7-27AB87C9EB8C@gmail.com>


On 16 Nov 2013, at 03:06 , Charles Berry <ccberry at ucsd.edu> wrote:

> Rolf Turner <r.turner <at> auckland.ac.nz> writes:
> 
>> 
>> 
>> I *do* see the same phenomenon that Bert describes and the code of 
>> predict.lm()
>> *does* appear to contain a bug.  There is a line:
>> 
> [snip]
> 
>> 
>> The operative difference between my set-up and Chuck's is that I am using
>> version 3.0.2 Patched.  So I am very puzzled as to why Chuck does *not* get
>> an error thrown!
>> 
> 
> [rest deleted]
> 
> The answer is that I made a rookie error.
> 
> I ran
> 
>  example(predict.lm)
> 
> before trying Bert's ECM.
> 
> And then I did not bother to see what example(predict.lm) left lying
> around in R_GlobalEnv ...
> 
> As you can probably guess, there was an object called 'w'.
> 
> So predict.lm finds it and is.null(w) is FALSE.
> 
> Mea culpa!

Hmm, maybe, but this is the sort of thing that code analysis tries to catch (as in "no visible binding for global variable 'w'"). Apparently, the code checker is not smart enough to detect cases where a local variable is _sometimes_ not defined.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hwborchers at googlemail.com  Sat Nov 16 13:11:49 2013
From: hwborchers at googlemail.com (Hans W.Borchers)
Date: Sat, 16 Nov 2013 12:11:49 +0000
Subject: [R] The smallest enclosing ball problem
Message-ID: <loom.20131116T130416-500@post.gmane.org>

I wanted to solve the following geometric optimization problem, sometimes 
called the "enclosing ball problem":

    Given a set P = {p_1, ..., p_n} of n points in R^d, find a point p_0 such 
    that max ||p_i - p_0|| is minimized.

A known algorithm to solve this as a Qudratic Programming task is as follows:

    Define matrix C = (p_1, ..., p_n), i.e. coordinates of points in columns,
    and minimize
                    x' C' C x - \sum (p_i' p_i) x_i
    subject to
                    \sum x_1 = 1, x_i >= 0 .

Let x0 = (x0_1, ..., x0_n) be an optimal solution, then the linear combination

    p0 = \sum x0_i p_i

is the center of the smallest enclosing ball, and the negative value of the 
objective function at x0 is the squared radius of the ball.

As an example, find the smallest ball enclosing the points (1,0,0), (0,1,0), 
and (0.5, 0.5, 0.1) in 3-dim. space. We would expect the center of the ball to 
be at (0.5, 0.5, 0), and with radius 1/sqrt(2).

    C <- matrix( c(1, 0, 0.5,
                   0, 1, 0.5,
                   0, 0, 0.1), ncol = 3, byrow = TRUE)

    # We need to define D = 2    C' C, d = (p_i' p_i), A = c(1,1,1), and b = 1
    D <- 2 * t(C) %*% C
    d <- apply(C^2, 2, sum)
    A <- matrix(1, nrow = 1, ncol = 3)
    b <- 1

    # Now solve with solve.QP() in package quadprog ...
    require(quadprog)
    sol1 <- solve.QP(D, d, t(A), b, meq = 1)

    # ... and check the result
    sum(sol1$solution)                  # 1
    p0 <- c(C %*% sol1$solution)        # 0.50  0.50 -2.45
    r0 <- sqrt(-sol1$value)             # 2.55

    # distance of all points to the center
    sqrt(colSums((C - p0)^2))           # 2.55 2.55 2.55

As a result we get a ball such that all points lie on the boundary.
The same happens for 100 points in 100-dim. space (to keep D positive 
definite, n = d is required).
That is a very nice, even astounding result, but not what I had hoped for!

Compare this with another quadratic programming solver in R, for example 
LowRankQP() in the package of the same name.

    require(LowRankQP)
    sol2 <- LowRankQP(D, -d, A, b, u = rep(3, 3), method="LU")

    p2 <- c(C %*% sol2$alpha)   # 5.000000e-01 5.000000e-01 1.032019e-12
    sqrt(colSums((C - p2)^2))   # 0.7071068 0.7071068 0.1000000

The correct result, and we get correct solutions in higher dimensions, too. 
LowRankQP works also if we apply it with n > d, e.g., 100 points in 2- 
or 3-dimensional space, when matrix D is not positive definite -- solve.QP( ) 
does not work in these cases.

*** What do I do wrong in calling solve.QP()? ***

My apologies for this overly long request. I am sending it through the weekend
hoping that someone may have a bit of time to look at it more closely.

Hans Werner


From gunter.berton at gene.com  Sat Nov 16 16:28:36 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 16 Nov 2013 07:28:36 -0800
Subject: [R] Help
In-Reply-To: <CAA3K1Kz-wfsv6c17V6XGTboqCNzxdOBmAvz4DCNCBpDvc5Zo9Q@mail.gmail.com>
References: <CAA3K1Kz-wfsv6c17V6XGTboqCNzxdOBmAvz4DCNCBpDvc5Zo9Q@mail.gmail.com>
Message-ID: <CACk-te0m1CX=+cF0vpc8c4sC2tiMvHspNOWk_YRZfwW--9HdMw@mail.gmail.com>

Sorry to do this to you, but questions about mixed models(especially
lmer) are better handled on the mixed models list, r-sig-mixed-models
. So subscribe and post this there.

Cheers,
Bert

On Fri, Nov 15, 2013 at 3:30 PM, Dalal Hanna <dalal.e.hanna at gmail.com> wrote:
> Hi,
>
> I tried to post the below message and it was rejected because I hadn't yet
> received my subscription to the group.
>
> Can it be posted now?
>
> Cheers,
> Thanks very much for all your dedication to this project!
> Dalal
>
>
> MESSAGE I ATTEMPTED TO POST BELOW
>
> I am trying to code the following idea using lmer (package lme4) and
> running into problems. I am also unsure that I am coding this properly and
> wanted to double check, as there are not enough people in my entourage that
> can do this for me.
>
> For individual fish i of species j in lake k,
> Hgijk ~ b0j[i] + b1k[i] + b2j[i]*lengthi + ei
> ei ~ N(0,s2e)
> b0j ~ N(mb0,s2b0)
> b1k ~ go + g1*chlorophyll-ak + eb1
> eb1 ~ N(0,s2b1)
> b2j ~ N(mb2,s2b2)
>
> This model says that the Hg for fish i of species j from lake k is a
> function of the species, the lake, and the length of the fish. The species
> effects are like intercepts ? the average Hg for a particular species at
> average length (if the length data are centered) in an average lake ? and
> they come from a normal distribution. The lake effect is itself a linear
> function of chlorophyll concentration, so that lakes with higher
> chlorophyll can potentially have higher or lower average Hg concentrations.
> The length effects vary by species, on the assumption that Hg concentration
> may change with size differently in different species (which is the case in
> the systems I am working in). These length effects come from a normal
> distribution.
>
> *Problems:*
> 1. My original idea was to code this as such:
>
> M.A4<-lmer(LogTHg~ Chlorophyll + Length+ (1 + Length|SpeciesCode)
> +(1|Location), data=mercury.subset)
>
> -Does this function really represent the ideas I explained above?  I am not
> sure if Length is supposed to be included in 2 places as it is here
> -When I run this model, the se.ceof() of Length always comes out to 0,
> which doesn't really make sense.  Any ideas why this might be happening?
>
> Thank you very much for taking the time to read this and providing input.
>  I appreciate it.
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From yael.inbar.new at gmail.com  Sat Nov 16 09:36:07 2013
From: yael.inbar.new at gmail.com (Yael Inbar)
Date: Sat, 16 Nov 2013 10:36:07 +0200
Subject: [R] R 2.14.2 - Installation problem - could not load lattice
Message-ID: <001501cee2a6$e5e239e0$b1a6ada0$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131116/45de3903/attachment.pl>

From ronjaq at gmx.net  Sat Nov 16 16:30:29 2013
From: ronjaq at gmx.net (Stageexp)
Date: Sat, 16 Nov 2013 07:30:29 -0800 (PST)
Subject: [R] Apply function to one specific column / Alternative to for loop
Message-ID: <1384615829390-4680566.post@n4.nabble.com>

Hi guys, I am a total newbie to R, so I hope this isn't a totally dumb
question. I have a dataframe with a title in one row and the corresponding
values in the next rows. Let's take this example: 

test_df <- data.frame(cbind(titel = "", x = 4:5, y = 1:2))
test_df = rbind(cbind(titel="1.Test", x="", y=""), test_df,
cbind(titel="2.Test", x="", y=""), test_df, cbind(titel="3.Test", x="",
y=""), test_df)

test_df
   titel x y
1 1.Test    
2        4 1
3        5 2
4 2.Test    
5        4 1
6        5 2
7 3.Test    
8        4 1
9        5 2

What I want to have is:
   titel x y
2 1.Test 4 1
3 1.Test 5 2
5 2.Test 4 1
6 2.Test 5 2
8 3.Test 4 1
9 3.Test 5 2

In my example, the title is in every third line, but in my real data there
is no pattern. Each title has at least one line but can have x lines.

I was able to solve my problem in a for loop with the following code:
test_df$titel <- as.character(test_df$titel)
for (i in 1:nrow(test_df))
{
  if (nchar(test_df$titel[i])==0){
    test_df$titel[i]=test_df$titel[i-1]
  }
}
test_df <- subset(test_df,test_df$x!="")


The problem is, I have a lot of data and the for loop is obviously very
slow. Is there a more elegant way to achieve the same? I think I have to use
the apply function, but I don't know how to use it with just one column.




--
View this message in context: http://r.789695.n4.nabble.com/Apply-function-to-one-specific-column-Alternative-to-for-loop-tp4680566.html
Sent from the R help mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Sat Nov 16 17:26:29 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 16 Nov 2013 17:26:29 +0100
Subject: [R] R 2.14.2 - Installation problem - could not load lattice
In-Reply-To: <001501cee2a6$e5e239e0$b1a6ada0$@gmail.com>
References: <001501cee2a6$e5e239e0$b1a6ada0$@gmail.com>
Message-ID: <52879CB5.2070202@statistik.tu-dortmund.de>



On 16.11.2013 09:36, Yael Inbar wrote:
> Hello,
>
> I'm new to R, and have a problem related to spss integration with R (but is
> actually related to the R installation):
> I have windows 8, 64bit, and installed R 2.14.2, and then the R plug in for
> spss (spss version 21).
> When I tried to run somthing in spss, I got the following error messgae:
> Error in loadNamespace(i, c(lib.loc, .libPaths())) :
> there is no package called 'lattice'
> Installing package(s) into 'C:/Program
> Files/IBM/SPSS/Statistics/21/extensions'
> (as 'lib' is unspecified)
>
> I unserstood that lattice should come with the default installation, and
> that this messgae indicates that something went wrong with the installation,
> but after uninstalling and re-installing I got the same thing... I have some
> suspicion that this might be related to 32/64 bit. When I downloaded R I
> took the default installation suggestion and this downloaded both 32 and 64.
> Could it be the case?


Probably not, but version R-2.14.2 is ancient and hence unsupported.
If SPSS requires it, please contact your SPSS support for help.

Best,
Uwe Ligges



> Any help would be very much appreciated!!!!
>
>
> Yael
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Nov 16 17:38:22 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 16 Nov 2013 17:38:22 +0100
Subject: [R] there is no package called 'boot'
In-Reply-To: <525C4D2B.4070708@sunrise.ch>
References: <525C4D2B.4070708@sunrise.ch>
Message-ID: <52879F7E.4090209@statistik.tu-dortmund.de>



On 14.10.2013 21:59, Christian Hoffmann wrote:
> Hi,
>
> R CMD  mypackage  /Users/hoffmann/R/cwhmisc  check --as-cran
>
> gives me
>
> * checking Rd cross-references ... WARNING
> Error in find.package(package, lib.loc) :
>    there is no package called 'boot'
>
> although there is no textual reference to 'boot' in my /R and /man
> within /cwhmisc nor any file of that name.
>
> How could I possibly find the culprit?

I do not know your current version of the package, but probably you 
forgot to declare it as a dependency level (e.g. Suggests) in the 
DESCRIPTION file?

Best,
Uwe Ligges





>
> TIA
>
> C.
>
> sessionInfo() > R version 3.0.1 (2013-05-16)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] C
>
> attached base packages:
>   [1] tools     tcltk     stats4    splines   parallel  datasets compiler
>   [8] graphics  grDevices stats     grid      utils     methods base
>
> other attached packages:
>   [1] survival_2.37-4    spatial_7.3-6      rpart_4.1-1 nnet_7.3-6
>   [5] nlme_3.1-109       foreign_0.8-53     codetools_0.2-8 cluster_1.14.4
>   [9] class_7.3-7        Matrix_1.0-12      MASS_7.3-26 KernSmooth_2.23-10
> [13] cwhmisc_4.1        lattice_0.20-15
>


From cs_2002 at hotmail.com  Sat Nov 16 18:04:30 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Sat, 16 Nov 2013 17:04:30 +0000
Subject: [R] Double Pareto Log Normal Distribution DPLN
In-Reply-To: <8EC78533-C239-4F0C-9089-7DE5C4F06394@vims.edu>
References: <DUB126-W38DD34AD9F9A9E2061A6C180FE0@phx.gbl>
	<FE020833-70FD-459B-A606-94FC66668C64@vims.edu>
	<DUB126-W518FF58D1C9702049074AF80F90@phx.gbl>
	<DBD8C8ED-98B0-41DE-9927-FF34C6BE3BD7@vims.edu>
	<DUB126-W16A28AE7FD65F5F5B0FC3E80F90@phx.gbl>
	<0FF0603C-A50E-47E8-8AA8-7407AA7F5715@vims.edu>
	<DUB126-W6986A26A21D3556F92864480F90@phx.gbl>
	<CDE7CA8F-0062-4E71-BFB7-3C9FDA0B068B@vims.edu>
	<8EC78533-C239-4F0C-9089-7DE5C4F06394@vims.edu>
Message-ID: <DUB404-EAS24179E552594887D6519D7C80FA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131116/b1fd80d8/attachment.pl>

From sergio.fonda99 at gmail.com  Sat Nov 16 18:19:56 2013
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sat, 16 Nov 2013 18:19:56 +0100
Subject: [R] variable standardization in manova() call
In-Reply-To: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
References: <CAJRuHoo6Ptv1-8gRmyZMjSXo00TegoGWghBTRrAEFJ0bC+BchA@mail.gmail.com>
Message-ID: <CAJRuHoqf418Xo=9-HuSFvtNB4mBf9r9VEUBTEvM3wW7pAjqsmA@mail.gmail.com>

 thank you for your reply.
However, your remark was not so clear to me
so I attach a short script I tried to launch. The comparison between
results got from MANOVA() call with the non-standardized and
standardized version of the same data frame, convinced me that it is
not necessary to standardize data before calling MANOVA. The only
difference you get is in the residuals values, of course.
Could you kindly confirm my conclusion?

All the best,
Sergio Fonda
______________________
set.seed(1234)
# non- standardized series
x1 =  rnorm(n=10, mean=50, sd=11)
x2 =  rnorm(n=10, mean=93, sd=23)
x1 =  rnorm(n=10, mean=217, sd=52)
fact= rep(1:2,20)
glob1=data.frame(cbind(x1,x2,x3,fact))
fitta1=manova(cbind(x1,x2,x3)~fact, data=glob1)
fitta1.wilks=summary(fitta1, test="Wilks")
summary.aov(fitta1)

#after standardization
x.stand=scale(glob1[,-4])
glob2=data.frame(x.stand,fact)
fitta2=manova(cbind(x1,x2,x3)~fact, data=glob2)
fitta2.wilks=summary(fitta2, test="Wilks")
summary.aov(fitta2)

2013/11/4 Sergio Fonda <sergio.fonda99 at gmail.com>:
> Hi,
> I'm not able to get information about the following question:
>
> is the variables standardization a default option in manova() (stats package)?
> Or if you want to compare variables with different units or scales and
> rather different variances, you have to previously standardize the
> variables ?
>
> Thanks a lot for any help,
>
> Sergio Fonda
> www.unimore.it


From batholdy at googlemail.com  Sat Nov 16 20:20:01 2013
From: batholdy at googlemail.com (Martin Batholdy)
Date: Sat, 16 Nov 2013 20:20:01 +0100
Subject: [R] export vector with write() introduces line breaks
Message-ID: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>

Hi,

I have a long vector which I want to export as a simple ascii text file via
write(1:600, file='test.txt', sep=',')

When I open the text file with my text editor I see that the data is structured in columns.
So it seems that line breaks are introduced.

How can I prevent this?


Thank you!


From gunter.berton at gene.com  Sat Nov 16 20:30:51 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 16 Nov 2013 11:30:51 -0800
Subject: [R] export vector with write() introduces line breaks
In-Reply-To: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
References: <3FC1DBA3-2908-4487-BC15-FBB49640D9DF@googlemail.com>
Message-ID: <CACk-te3seZLHEaTwc5VgurB=K7dVNS8u8qcCf63SMq6xQRvN2w@mail.gmail.com>

1. Read ?write carefully. Note what it says about write() writing to
columns and the link to cat().

2. Use cat() with appropriate arguments to write your file instead.

e.g.

cat(1:600, file=yourfile,fill=FALSE)

Cheers,
Bert

On Sat, Nov 16, 2013 at 11:20 AM, Martin Batholdy
<batholdy at googlemail.com> wrote:
> Hi,
>
> I have a long vector which I want to export as a simple ascii text file via
> write(1:600, file='test.txt', sep=',')
>
> When I open the text file with my text editor I see that the data is structured in columns.
> So it seems that line breaks are introduced.
>
> How can I prevent this?
>
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From ivo.welch at anderson.ucla.edu  Sat Nov 16 20:39:36 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Sat, 16 Nov 2013 11:39:36 -0800
Subject: [R] contour plot axis correspondence
Message-ID: <CAPr7RtWCzemUE5DkXjBFJT4Rznw77hvBJcTo5nuA_ytUO+MTEg@mail.gmail.com>

I am struggling with a contour plot.  I want to place a cross over the
minimum.  alas, I don't seem to be able to map axes appropriately.
here is what I mean:

N <- 1000

rm <- rnorm(N, mean=0.0, sd=0.4)
rx <- rnorm(N, mean=0.0, sd=0.4)
rt <- rnorm(N, mean=0.0, sd=0.4)

exploss <- function(hdgM,hdgX) {
    ## this could be any function that is not vectorized
    losscosts <- function(FirmV) { D <- 50; ifelse( FirmV<D, 0.2*(D-FirmV), 0) }
    FirmV <- 100*(1+rt)*(1+rm)*(1+rx) + 100*(hdgM*(1+rm)-hdgM) +
100*(hdgX*(1+rx)-hdgX)
    mean( losscosts( FirmV ) )
}

ss <- seq(-2,0.5,0.1)
MX <- expand.grid( hdgM= ss, hdgX= ss )
MX$z <- unlist(lapply( 1:nrow(MX), function(i) with(MX,
exploss(hdgM[i],hdgX[i])) ))

M <- matrix(MX$z, nrow=length(ss), ncol=length(ss))
rownames(M) <- colnames(M) <- ss

filled.contour( x=ss, y=ss, M )

vline <- function(x, y=c(-99,99), ...) lines(c(x,x), y, ...)
vline(-0.5, col="blue", lwd=3 )


how do I map the -0.5 in the vline() to the true -0.5?  it is drawn .

as a sidenote, it was not easy to figure out how I could plot an z
function for an x-axis and y-axis.  plot(x,y) is very intuitive.  it
would have been nice to have analogous plot3d(x,y,z) and
contour(x,y,z) functions.  as with everything in R, it probably
exists, but I did not find it.  my above code had to map MX (with
x,y,z columns) into a matrix first.

advice appreciated.

best,

/iaw

----
Ivo Welch (ivo.welch at gmail.com)


From wdunlap at tibco.com  Sat Nov 16 21:28:46 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 16 Nov 2013 20:28:46 +0000
Subject: [R] contour plot axis correspondence
In-Reply-To: <CAPr7RtWCzemUE5DkXjBFJT4Rznw77hvBJcTo5nuA_ytUO+MTEg@mail.gmail.com>
References: <CAPr7RtWCzemUE5DkXjBFJT4Rznw77hvBJcTo5nuA_ytUO+MTEg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA159AD@PA-MBX01.na.tibco.com>

filled.contour() makes two plots (the contour plot and the legend) and
must adjust some par() parameters to do that.  It appears to set them back
to a state where you cannot easily add things to the plot.  There is a trick
mentioned in Stackoverflow a while back about how to use the plot.title
argument to fiddle with filled.contour() plots.  In your case you could do something
like

   > x <- 11:15
   > y <- 101:108
   > z <- outer(x,y,function(x,y)sin(x^2.5+y^.9/1.2))
   > filled.contour(x,y,z, plot.title=abline(v=12, h=103))

If you call abline() after filled.contour you can see how it the horizontal
margin settings do not correspond to the plot you are trying to add to.

   > abline(v=12, h=103, lwd=3, col="red", lty=2)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of ivo welch
> Sent: Saturday, November 16, 2013 11:40 AM
> To: r-help
> Subject: [R] contour plot axis correspondence
> 
> I am struggling with a contour plot.  I want to place a cross over the
> minimum.  alas, I don't seem to be able to map axes appropriately.
> here is what I mean:
> 
> N <- 1000
> 
> rm <- rnorm(N, mean=0.0, sd=0.4)
> rx <- rnorm(N, mean=0.0, sd=0.4)
> rt <- rnorm(N, mean=0.0, sd=0.4)
> 
> exploss <- function(hdgM,hdgX) {
>     ## this could be any function that is not vectorized
>     losscosts <- function(FirmV) { D <- 50; ifelse( FirmV<D, 0.2*(D-FirmV), 0) }
>     FirmV <- 100*(1+rt)*(1+rm)*(1+rx) + 100*(hdgM*(1+rm)-hdgM) +
> 100*(hdgX*(1+rx)-hdgX)
>     mean( losscosts( FirmV ) )
> }
> 
> ss <- seq(-2,0.5,0.1)
> MX <- expand.grid( hdgM= ss, hdgX= ss )
> MX$z <- unlist(lapply( 1:nrow(MX), function(i) with(MX,
> exploss(hdgM[i],hdgX[i])) ))
> 
> M <- matrix(MX$z, nrow=length(ss), ncol=length(ss))
> rownames(M) <- colnames(M) <- ss
> 
> filled.contour( x=ss, y=ss, M )
> 
> vline <- function(x, y=c(-99,99), ...) lines(c(x,x), y, ...)
> vline(-0.5, col="blue", lwd=3 )
> 
> 
> how do I map the -0.5 in the vline() to the true -0.5?  it is drawn .
> 
> as a sidenote, it was not easy to figure out how I could plot an z
> function for an x-axis and y-axis.  plot(x,y) is very intuitive.  it
> would have been nice to have analogous plot3d(x,y,z) and
> contour(x,y,z) functions.  as with everything in R, it probably
> exists, but I did not find it.  my above code had to map MX (with
> x,y,z columns) into a matrix first.
> 
> advice appreciated.
> 
> best,
> 
> /iaw
> 
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Sat Nov 16 22:26:30 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 16 Nov 2013 16:26:30 -0500
Subject: [R] optimization
In-Reply-To: <mailman.29.1384599608.13725.r-help@r-project.org>
References: <mailman.29.1384599608.13725.r-help@r-project.org>
Message-ID: <5287E306.3090400@uottawa.ca>

There are lots of errors in your code. In particular, the optimization
routines do not like functions that ignore the parameters.

And you have not provided out or out1 to the optimizer -- they are
returned as elements of func(), but not correctly.

Please try some of the examples for optim or optimx to learn how to
structure your problem.

JN


On 13-11-16 06:00 AM, r-help-request at r-project.org wrote:
> Message: 19
> Date: Fri, 15 Nov 2013 09:17:47 -0800 (PST)
> From: IZHAK shabsogh <ishaqbaba at yahoo.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Subject: [R] optimization
> Message-ID:
> 	<1384535867.58595.YahooMailNeo at web142506.mail.bf1.yahoo.com>
> Content-Type: text/plain
> 
> x1<-c(5.548,4.896,1.964,3.586,3.824,3.111,3.607,3.557,2.989,18.053,3.773,1.253,2.094,2.726,1.758,5.011,2.455,0.913,0.890,2.468,4.168,4.810,34.319,1.531,1.481,2.239,4.204,3.463,1.727)
> y<-c(2.590,3.770,1.270,1.445,3.290,0.930,1.600,1.250,3.450,1.096,1.745,1.060,0.890,2.755,1.515,4.770,2.220,0.590,0.530,1.910,4.010,1.745,1.965,2.555,0.770,0.720,1.730,2.860,0.760)
> x2<-c(0.137,2.499,0.419,1.699,0.605,0.677,0.159,1.699,0.340,2.899,0.082,0.425,0.444,0.225,0.241,0.099,0.644,0.266,0.351,0.027,0.030,3.400,1.499,0.351,0.082,0.518,0.471,0.036,0.721)
> k<-rep(1,29)
> x<-data.frame(k,x1,x2)
> 
> freg<-function(y,x1,x2){
>   reg<- rlm(y ~ x1 + x2 , data=x)
>   return(reg)
> }
> 
> 
>  func <- function(x1,x2,b){
>       fit<-freg(y,x1,x2)
>         b<-c(coef(fit))
>       dv<-1+ b[2]*x2^b[3]
>         dv1<-b[2]*x2^b[3]*log(x2)
>       out <- ( x1/(1+ b[2]*x2^b[3]))
>       out1<-  c(-x1*x2^b[3]/dv^2,-x1* dv1/dv^2)
>         return(list( out,out1))
>        }>
> optim(par=c(b[2],b[3]), fn=out, gr =out1,
>         method = c("BFGS"),
>         lower = -Inf, upper = Inf,
>         control = list(), hessian = T)
> can someone help me try running this code because i try many occasion but prove  abortive. the aim is
> to optimize the parameter of the model that is parameter estimates using optimization 
> 
> 	[[alternative HTML version deleted]]


From djmuser at gmail.com  Sat Nov 16 23:49:29 2013
From: djmuser at gmail.com (Dennis Murphy)
Date: Sat, 16 Nov 2013 14:49:29 -0800
Subject: [R] optimization
In-Reply-To: <5287E306.3090400@uottawa.ca>
References: <mailman.29.1384599608.13725.r-help@r-project.org>
	<5287E306.3090400@uottawa.ca>
Message-ID: <CADv2QyFXp2vpokPxpOnZhRLd9QXhXeGRGX-TxLxYZjcybVzx_w@mail.gmail.com>

> There are lots of errors in your code. In particular, the optimization
> routines do not like functions that ignore the parameters.

I would like to nominate this delicious riposte as a fortune
candidate. Anyone to second the motion?

Dennis

On Sat, Nov 16, 2013 at 1:26 PM, Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
> There are lots of errors in your code. In particular, the optimization
> routines do not like functions that ignore the parameters.
>
> And you have not provided out or out1 to the optimizer -- they are
> returned as elements of func(), but not correctly.
>
> Please try some of the examples for optim or optimx to learn how to
> structure your problem.
>
> JN
>
>
> On 13-11-16 06:00 AM, r-help-request at r-project.org wrote:
>> Message: 19
>> Date: Fri, 15 Nov 2013 09:17:47 -0800 (PST)
>> From: IZHAK shabsogh <ishaqbaba at yahoo.com>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: [R] optimization
>> Message-ID:
>>       <1384535867.58595.YahooMailNeo at web142506.mail.bf1.yahoo.com>
>> Content-Type: text/plain
>>
>> x1<-c(5.548,4.896,1.964,3.586,3.824,3.111,3.607,3.557,2.989,18.053,3.773,1.253,2.094,2.726,1.758,5.011,2.455,0.913,0.890,2.468,4.168,4.810,34.319,1.531,1.481,2.239,4.204,3.463,1.727)
>> y<-c(2.590,3.770,1.270,1.445,3.290,0.930,1.600,1.250,3.450,1.096,1.745,1.060,0.890,2.755,1.515,4.770,2.220,0.590,0.530,1.910,4.010,1.745,1.965,2.555,0.770,0.720,1.730,2.860,0.760)
>> x2<-c(0.137,2.499,0.419,1.699,0.605,0.677,0.159,1.699,0.340,2.899,0.082,0.425,0.444,0.225,0.241,0.099,0.644,0.266,0.351,0.027,0.030,3.400,1.499,0.351,0.082,0.518,0.471,0.036,0.721)
>> k<-rep(1,29)
>> x<-data.frame(k,x1,x2)
>>
>> freg<-function(y,x1,x2){
>>   reg<- rlm(y ~ x1 + x2 , data=x)
>>   return(reg)
>> }
>>
>>
>>  func <- function(x1,x2,b){
>>       fit<-freg(y,x1,x2)
>>         b<-c(coef(fit))
>>       dv<-1+ b[2]*x2^b[3]
>>         dv1<-b[2]*x2^b[3]*log(x2)
>>       out <- ( x1/(1+ b[2]*x2^b[3]))
>>       out1<-  c(-x1*x2^b[3]/dv^2,-x1* dv1/dv^2)
>>         return(list( out,out1))
>>        }>
>> optim(par=c(b[2],b[3]), fn=out, gr =out1,
>>         method = c("BFGS"),
>>         lower = -Inf, upper = Inf,
>>         control = list(), hessian = T)
>> can someone help me try running this code because i try many occasion but prove  abortive. the aim is
>> to optimize the parameter of the model that is parameter estimates using optimization
>>
>>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Nov 17 00:12:10 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 17 Nov 2013 12:12:10 +1300
Subject: [R] optimization
In-Reply-To: <CADv2QyFXp2vpokPxpOnZhRLd9QXhXeGRGX-TxLxYZjcybVzx_w@mail.gmail.com>
References: <mailman.29.1384599608.13725.r-help@r-project.org>
	<5287E306.3090400@uottawa.ca>
	<CADv2QyFXp2vpokPxpOnZhRLd9QXhXeGRGX-TxLxYZjcybVzx_w@mail.gmail.com>
Message-ID: <5287FBCA.10402@auckland.ac.nz>

On 11/17/13 11:49, Dennis Murphy wrote:
>> There are lots of errors in your code. In particular, the optimization
>> routines do not like functions that ignore the parameters.
> I would like to nominate this delicious riposte as a fortune
> candidate. Anyone to second the motion?

Indeed.  I so second!

     cheers,

     Rolf Turner


From vksingh.iiitb at gmail.com  Sun Nov 17 03:46:37 2013
From: vksingh.iiitb at gmail.com (vivek kumar singh)
Date: Sun, 17 Nov 2013 10:46:37 +0800
Subject: [R] Change date time to epoch time
Message-ID: <52882E0D.8060104@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/c97a5ee1/attachment.pl>

From dwinsemius at comcast.net  Sun Nov 17 04:15:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 16 Nov 2013 21:15:15 -0600
Subject: [R] Change date time to epoch time
In-Reply-To: <52882E0D.8060104@gmail.com>
References: <52882E0D.8060104@gmail.com>
Message-ID: <C0D73129-0DA7-4DAA-9166-B4F89B427885@comcast.net>


On Nov 16, 2013, at 8:46 PM, vivek kumar singh wrote:

> Hi All,
>
> I have time series data in (Year-month-date-hour-minute-second) format
> and i want to convert it to epoch time.
>
> I have tried the following:
> *> Sys.time()**
> **[1] "2013-11-17 10:39:46 MYT"**
> **> as.numeric(Sys.time())**
> **[1] 1384656006**

Should we assume this is "epoch time"?

> **> as.numeric("2013-11-17 10:39:46 MYT")**
> **[1] NA**
> **Warning message:**
> **NAs introduced by coercion **
> **> as.numeric("2013-11-17 10:39:46 MYT")**
> **[1] NA**

If it is then this is close:

as.numeric(as.POSIXct("2013-11-17 10:39:46 MYT"))

(You may need to supply an appropriate TZ offset in seconds

?POSIXct


--  
David.

> **Warning message:**
> **NAs introduced by coercion **
> *
> Please let me know which function in R converts date-time to epoch  
> time.
>
> Regards,
> Vivek
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Sun Nov 17 04:21:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 16 Nov 2013 19:21:24 -0800
Subject: [R] Change date time to epoch time
In-Reply-To: <52882E0D.8060104@gmail.com>
References: <52882E0D.8060104@gmail.com>
Message-ID: <da27e57d-97da-4b7a-8540-e1e28165533a@email.android.com>

There are many epochs. Which one are you interested in? If you are interested in the POSIX time_t epoch, then you could look at ?DateTimeClasses to find out about ?as.POSIXct. You might also find my email on inputting zones informative [1].

Also, per the Posting Guide, please don't post in html format... it messes up your R code.

[1] https://www.stat.math.ethz.ch/pipermail/r-help/2013-August/357939.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

vivek kumar singh <vksingh.iiitb at gmail.com> wrote:
>Hi All,
>
>I have time series data in (Year-month-date-hour-minute-second) format 
>and i want to convert it to epoch time.
>
>I have tried the following:
>*> Sys.time()**
>**[1] "2013-11-17 10:39:46 MYT"**
>**> as.numeric(Sys.time())**
>**[1] 1384656006**
>**> as.numeric("2013-11-17 10:39:46 MYT")**
>**[1] NA**
>**Warning message:**
>**NAs introduced by coercion **
>**> as.numeric("2013-11-17 10:39:46 MYT")**
>**[1] NA**
>**Warning message:**
>**NAs introduced by coercion **
>*
>Please let me know which function in R converts date-time to epoch
>time.
>
>Regards,
>Vivek
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jakub.szewczyk at gmail.com  Sat Nov 16 17:45:10 2013
From: jakub.szewczyk at gmail.com (Jakub Szewczyk)
Date: Sat, 16 Nov 2013 17:45:10 +0100
Subject: [R] repeated-measures multiple regression/ANCOVA/MANCOVA
Message-ID: <CAKw8OYz=P5wEKiXZQ+MC8UKnE=bkQwK7ANorT4d4ript_hN5+Q@mail.gmail.com>

Dear List,

I am trying to analyze a dataset where I have 1 continuous
between-item variable (C), and 2 factorial within-item variables (3-
and 2-level: F3, F2). I'm interested in whether slope of C is
different from 0 at different combinations of F3 and F2, and whether
it varies between these combinations.

And unfortunately I need a decent anova-like table with p-values. The
reason is that 1) this analysis is going to be repeated 9 times for
different parts of the data (not comparable), so such an omnibus table
will give a good overview of which places need a follow up with
simpler models; 2) this is the norm in my field of reseach, although
usually with factorial variables only.

I'm wondering how to do it properly in R without falling into any
pitfalls, avoiding violations of any assumptions (like sphericity) and
what is the most apropriate type of sum of squares for this analysis.


The 2 solutions I found so far are:

based on nlme::lme():
> res.lme = nlme::lme(data=d, y ~ C * F3 * F2, random = ~ 1|item/F3/F2)
> anova(res.lme) for type I SS
> Anova(res.lme, type="II/III") # for type II/III SS

based on lmerTest package:
> res.lmertest = lmerTest::lmer(data=d, y ~ C * F3 * F2 + (1|item))
> anova(res.lmertest) # for type III SS


I also considered running repeated-measures ANCOVA using aov() with
nested error terms, but that wouldn't protect me against sphericity
assumption violations.

I also considered using car::Anova() for running a repeated-measures
MANCOVA analysis, but if I got this thread right
(http://thread.gmane.org/gmane.comp.lang.r.general/270271/focus=270275),
this is (at present) not possible to do.

Are these ways of analyzing data valid?

Concerning the type of SS: I tried to read all discussions in this
list on this topic. If I got it right, since I'm interested in
interactions of C with other factors in the first place, in my case
using SS type III would make sense - is this a good logic?

Many thanks for help,
Jakub


From umairdurrani at outlook.com  Sat Nov 16 18:58:41 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Sat, 16 Nov 2013 22:58:41 +0500
Subject: [R] Apply function to one specific column / Alternative to for
 loop
In-Reply-To: <1384615829390-4680566.post@n4.nabble.com>
References: <1384615829390-4680566.post@n4.nabble.com>
Message-ID: <BLU170-W40B1598B76E9FC50D47800C9FA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131116/a8225f5f/attachment.pl>

From chanita.holmes at gmail.com  Sat Nov 16 19:25:14 2013
From: chanita.holmes at gmail.com (Phdstudent2)
Date: Sat, 16 Nov 2013 10:25:14 -0800 (PST)
Subject: [R] 2SLS for panel data, re
In-Reply-To: <CAEaD0=6SkDOTODbPZZ19LE2ca6YxByXWp+q-GiL1g+8eFB22DA@mail.gmail.com>
References: <CAEaD0=6SkDOTODbPZZ19LE2ca6YxByXWp+q-GiL1g+8eFB22DA@mail.gmail.com>
Message-ID: <93de0220-f4c9-4222-a0f9-053a7fcdac0e@googlegroups.com>

Hi Millo Giovanni,

Thanks for your response.  In regards to my STATA code it would be:

xi:xtiverg wecon polrightsreversed lnrgdpch execleft mulim2 c100rat 
c1100rat i.year
(trade fdistockgdp = lnpop lnarea devcountrycomlanguage bitcum), re.

Any suggestions will help so much......
Regards




On Thursday, November 14, 2013 8:12:33 AM UTC-8, Phdstudent2 wrote:
>
> Hi, 
>
> I am trying to estimate a 2sls using panel data (random effect model). I 
> tried the same estimation in STATA using the ivtreg2 command. However 
> STATA 
> and R are giving me two different results. I figure there is something 
> with 
> my R code: 
>
> iv=plm(formula=wecon~fdistockgdp +trade + polrightsreversed +lnrgdpch + 
> execleft + muslim2+c100rat +c111rat +yeardum| polrightsreversed+lnrgdpch+ 
> execleft+muslim2+c100rat+c111rat+yeardum 
> +lnpop+lnarea+devcountrycomlanguage+bitcum, 
> data = women, index = c("country", "year"), random.method = c("swar"), 
> inst.method = c("bvk"), model="random") 
> summary(iv) 
>
> Coefficients : 
>                     Estimate Std. Error t-value  Pr(>|t|) 
> (Intercept)       -0.2258528  0.2951301 -0.7653 0.4441954 
> fdistockgdp       -0.0067207  0.0077315 -0.8693 0.3847993 
> trade              0.0068462  0.0023687  2.8903 0.0038863 ** 
> polrightsreversed  0.0092366  0.0106174  0.8699 0.3844229 
> lnrgdpch           0.1246679  0.0389043  3.2045 0.0013724 ** 
> execleft           0.1118046  0.0340817  3.2805 0.0010524 ** 
> muslim2           -0.0044742  0.0012433 -3.5986 0.0003270 *** 
> c100rat            0.0226208  0.0595134  0.3801 0.7039114 
> c111rat            0.0165951  0.0618339  0.2684 0.7884310 
> yeardum1982        0.1479947  0.0588824  2.5134 0.0120282 * 
> yeardum1983        0.1783255  0.0606153  2.9419 0.0032958 ** 
> yeardum1984        0.0344572  0.0597167  0.5770 0.5639907 
> yeardum1985        0.2206961  0.0610344  3.6159 0.0003060 *** 
> yeardum1986        0.2428015  0.0649779  3.7367 0.0001912 *** 
> yeardum1987        0.0489043  0.0615708  0.7943 0.4271186 
> yeardum1988        0.2243599  0.0605343  3.7063 0.0002155 *** 
> yeardum1989        0.2215060  0.0624042  3.5495 0.0003940 *** 
> yeardum1990        0.0688333  0.0607056  1.1339 0.2569648 
> yeardum1991        0.1370871  0.0638830  2.1459 0.0319892 * 
> yeardum1992        0.1851857  0.0630868  2.9354 0.0033655 ** 
> yeardum1993        0.0904620  0.0698526  1.2950 0.1954420 
> yeardum1994        0.1003735  0.0737431  1.3611 0.1736137 
> yeardum1995        0.1164818  0.0721240  1.6150 0.1064494 
> yeardum1996        0.0482520  0.0787232  0.6129 0.5399837 
> yeardum1997        0.1049161  0.0895001  1.1722 0.2412247 
> yeardum1998        0.2191887  0.1109757  1.9751 0.0483807 * 
> yeardum1999        0.1573342  0.1397150  1.1261 0.2602422 
> yeardum2000        0.1532796  0.1627206  0.9420 0.3463059 
> --- 
>  However STATA gives me 
> ------------------------------------------------------------ 
> ----------------------- 
>             wecon |      Coef.   Std. Err.      z    P>|z|     [95% Conf. 
> Interval] 
> ------------------+----------------------------------------- 
> ----------------------- 
>             trade |   .0093915   .0027483     3.42   0.001      .004005 
> .014778 
>       fdistockgdp |  -.0169171   .0092405    -1.83   0.067    -.0350281 
> .0011938 
> polrightsreversed |   .0165855   .0119176     1.39   0.164    -.0067726 
> .0399436 
>          lnrgdpch |   .1045675   .0431179     2.43   0.015     .0200579 
> .189077 
>          execleft |   .1373652   .0384442     3.57   0.000     .0620159 
> .2127145 
>           muslim2 |  -.0043645   .0013551    -3.22   0.001    -.0070205 
> -.0017085 
>           c100rat |   .0480539   .0657304     0.73   0.465    -.0807752 
> .1768831 
>           c111rat |   .0170048   .0676272     0.25   0.801    -.1155421 
> .1495516 
>
> Really would appreciate any help explaining why the results are so 
> different 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-help at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From jlh.membership at gmail.com  Sat Nov 16 19:27:04 2013
From: jlh.membership at gmail.com (jlh.membership)
Date: Sat, 16 Nov 2013 13:27:04 -0500
Subject: [R] Bug in predict.lm?
In-Reply-To: <944273B4-FC14-43F5-81A7-27AB87C9EB8C@gmail.com>
References: <CACk-te3+GX2SFzzhD08MD01MJdAZb4OGEhzebCSS=7sVDSUO5Q@mail.gmail.com>	<loom.20131115T225210-168@post.gmane.org>	<52869ECA.6050802@auckland.ac.nz>	<loom.20131116T024955-582@post.gmane.org>
	<944273B4-FC14-43F5-81A7-27AB87C9EB8C@gmail.com>
Message-ID: <000c01cee2f9$779a0640$66ce12c0$@gmail.com>

This definitely looks like a bug and should really be reported. Denes' diagnosis is right on.

I get the bug here: 
> z <- lm(rnorm(10)~I(1:10))
> 
> predict(z, int="conf", scale=1)
Error in predict.lm(z, int = "conf", scale = 1) : object 'w' not found

And also here:
> z <- lm(rnorm(10)~I(1:10))
> 
> predict(z, se.fit=T, scale=1)
Error in predict.lm(z, se.fit = T, scale = 1) : object 'w' not found

**
platform       x86_64-w64-mingw32          
arch           x86_64                      
os             mingw32                     
system         x86_64, mingw32             
status                                     
major          3                           
minor          0.2                         
year           2013                        
month          09                          
day            25                          
svn rev        63987                       
language       R                           
version.string R version 3.0.2 (2013-09-25)
nickname       Frisbee Sailing    
**

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Saturday, November 16, 2013 4:36 AM
To: Charles Berry
Cc: r-help
Subject: Re: [R] Bug in predict.lm?


On 16 Nov 2013, at 03:06 , Charles Berry <ccberry at ucsd.edu> wrote:

> Rolf Turner <r.turner <at> auckland.ac.nz> writes:
> 
>> 
>> 
>> I *do* see the same phenomenon that Bert describes and the code of
>> predict.lm()
>> *does* appear to contain a bug.  There is a line:
>> 
> [snip]
> 
>> 
>> The operative difference between my set-up and Chuck's is that I am 
>> using version 3.0.2 Patched.  So I am very puzzled as to why Chuck 
>> does *not* get an error thrown!
>> 
> 
> [rest deleted]
> 
> The answer is that I made a rookie error.
> 
> I ran
> 
>  example(predict.lm)
> 
> before trying Bert's ECM.
> 
> And then I did not bother to see what example(predict.lm) left lying 
> around in R_GlobalEnv ...
> 
> As you can probably guess, there was an object called 'w'.
> 
> So predict.lm finds it and is.null(w) is FALSE.
> 
> Mea culpa!

Hmm, maybe, but this is the sort of thing that code analysis tries to catch (as in "no visible binding for global variable 'w'").
Apparently, the code checker is not smart enough to detect cases where a local variable is _sometimes_ not defined.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Sat Nov 16 19:24:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 16 Nov 2013 10:24:27 -0800 (PST)
Subject: [R] Apply function to one specific column / Alternative to for
	loop
In-Reply-To: <1384615829390-4680566.post@n4.nabble.com>
References: <1384615829390-4680566.post@n4.nabble.com>
Message-ID: <1384626267.51320.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
indx <- grep("Test",test_df[,1])? ##assuming that there is some pattern
?res <- within(test_df[-indx,],titel <- rep(test_df$titel[indx], diff(c(indx,nrow(test_df)+1))-1))

## If you need to change the class

res[] <- lapply(res,function(x) if(any(grepl("[[:alpha:]]",x))) as.character(x) else as.numeric(as.character(x)))


##Using data.frame(cbind()), etc. creates 


A.K.




On Saturday, November 16, 2013 11:14 AM, Stageexp <ronjaq at gmx.net> wrote:
Hi guys, I am a total newbie to R, so I hope this isn't a totally dumb
question. I have a dataframe with a title in one row and the corresponding
values in the next rows. Let's take this example: 

test_df <- data.frame(cbind(titel = "", x = 4:5, y = 1:2))
test_df = rbind(cbind(titel="1.Test", x="", y=""), test_df,
cbind(titel="2.Test", x="", y=""), test_df, cbind(titel="3.Test", x="",
y=""), test_df)

test_df
?  titel x y
1 1.Test? ? 
2? ? ? ? 4 1
3? ? ? ? 5 2
4 2.Test? ? 
5? ? ? ? 4 1
6? ? ? ? 5 2
7 3.Test? ? 
8? ? ? ? 4 1
9? ? ? ? 5 2

What I want to have is:
?  titel x y
2 1.Test 4 1
3 1.Test 5 2
5 2.Test 4 1
6 2.Test 5 2
8 3.Test 4 1
9 3.Test 5 2

In my example, the title is in every third line, but in my real data there
is no pattern. Each title has at least one line but can have x lines.

I was able to solve my problem in a for loop with the following code:
test_df$titel <- as.character(test_df$titel)
for (i in 1:nrow(test_df))
{
? if (nchar(test_df$titel[i])==0){
? ? test_df$titel[i]=test_df$titel[i-1]
? }
}
test_df <- subset(test_df,test_df$x!="")


The problem is, I have a lot of data and the for loop is obviously very
slow. Is there a more elegant way to achieve the same? I think I have to use
the apply function, but I don't know how to use it with just one column.




--
View this message in context: http://r.789695.n4.nabble.com/Apply-function-to-one-specific-column-Alternative-to-for-loop-tp4680566.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From JML at CWAZY.CO.UK  Sat Nov 16 22:49:49 2013
From: JML at CWAZY.CO.UK (SCRIPTHAM)
Date: Sat, 16 Nov 2013 13:49:49 -0800 (PST)
Subject: [R] Calculate Range
Message-ID: <1384638589297-4680579.post@n4.nabble.com>

Hi

My R version is the current version as at 15 Nov 2013.

I have tried to calculate range using tapply() with FUN=range.
tapply() returns two fields, the ID field and a field of two text items one
is the maximum and the other is the minimum.
I take as the difference max - min, does R use a different term for range in
tapply?

I have also tried
aggregate() with Fun=range, with Fun=min and FUN=max 
and they also gave problems.

What is the best route to calculate ranges for groups within a data frame.

Thanks.
Scriptham.






--
View this message in context: http://r.789695.n4.nabble.com/Calculate-Range-tp4680579.html
Sent from the R help mailing list archive at Nabble.com.


From joh.mo at web.de  Sat Nov 16 23:49:28 2013
From: joh.mo at web.de (randomsamson)
Date: Sat, 16 Nov 2013 14:49:28 -0800 (PST)
Subject: [R] r documentation rugarch egarch
Message-ID: <1384642168140-4680580.post@n4.nabble.com>

Hi,

I`m about to switch from STATA to R and have serious troubles to find proper
documentations on the internet.
Right now I try to find a proper documentation of the eGARCH model being
part of the rugarch package.

Neither here
http://cran.r-project.org/web/packages/rugarch/vignettes/Introduction_to_the_rugarch_package.pdf
nor here
http://cran.r-project.org/web/packages/rugarch/rugarch.pdf
could i find some information that was helping.

In this post
http://r.789695.n4.nabble.com/RUGARCH-eGARCH-and-variance-targeting-td4634896.html
someone proposes to read the "vignette on how the unconditional variance is
calculated for the eGARCH
model"
I don`t know what is meant by vignette. 

The R-built-in help function tells me about eGARCH: "assymetry term: gamma1"
Thanks a lot R-help. This is relly a lot of information.

I`d like to find out about the eGARCH model notation used in R, the settings
and estimation techniques that are used and/or can be configured in this
case, ...

When searching the internet I`ve also not been very successful.

When working with STATA I`ve so far never had troubles to find the right
information.
So i think I`m not in general too stupid to do some search on the internet.

Please can anyone tell me what this "vignette" is supposed to be and where
to find it?

Thanks a lot,
Samson










--
View this message in context: http://r.789695.n4.nabble.com/r-documentation-rugarch-egarch-tp4680580.html
Sent from the R help mailing list archive at Nabble.com.


From email8889 at gmail.com  Sun Nov 17 00:12:58 2013
From: email8889 at gmail.com (email)
Date: Sun, 17 Nov 2013 01:12:58 +0200
Subject: [R] selecting optimal cluster validation score
Message-ID: <CAJMZ3cdfECoFT-_T-kxco59E47iW6sDStTEAMLdFwe5LfRoo8Q@mail.gmail.com>

Hi:

I have calculated the Silhouette score and Dunn score after
hierarchical clustering for 3 clusters:

#Distance measure
d <- dist(USArrests, method = "euclidean")
#Hierarchical clustering
hc <- hclust(dist(USArrests), "ave")
#calculating silhouette value for 3 clusters
sil<- silhouette(cutree(hc, k=3), d)
#calculating Dunn index for 3 clusters
clus <- cutree(hc, 3)
dun <- dunn(d, clus)

How can the best of the two score be obtained? Is there any package to
automatically obtain the optimal (or best) of the Silhouette and the
Dunn scores ?

Regards:
John


From h.beyer at uq.edu.au  Sun Nov 17 02:51:03 2013
From: h.beyer at uq.edu.au (Hawthorne Beyer)
Date: Sun, 17 Nov 2013 01:51:03 +0000
Subject: [R] order() function, decreasing=TRUE unexpected behaviour
Message-ID: <8CF10AA730C93949BFADDC51D13CC90D41BD1C@UQEXMDA8.soe.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/330985e0/attachment.pl>

From spencer.graves at prodsyse.com  Sun Nov 17 03:19:16 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 16 Nov 2013 18:19:16 -0800
Subject: [R] R for a stats intro for undergrads in the US?
Message-ID: <528827A4.5080309@prodsyse.com>

Hello, All:


       Would anyone recommend R for an introductory statistics class for 
freshman psychology students in the US?  If yes, might there be any 
notes for such available?


       I just checked r-projects.org and CRAN contributed documentation 
and found nothing.


       I have a friend who teaches such a class, and wondered if R might 
be suitable.  The alternative is SPSS at $406 per student.


       Thanks,
       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From umairdurrani at outlook.com  Sun Nov 17 04:58:42 2013
From: umairdurrani at outlook.com (umair durrani)
Date: Sun, 17 Nov 2013 08:58:42 +0500
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <528827A4.5080309@prodsyse.com>
References: <528827A4.5080309@prodsyse.com>
Message-ID: <BLU170-W5589E6340B1FC67CF7B67AC9E50@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/9c04f8db/attachment.pl>

From spencer.graves at prodsyse.com  Sun Nov 17 05:30:06 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sat, 16 Nov 2013 20:30:06 -0800
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <BLU170-W5589E6340B1FC67CF7B67AC9E50@phx.gbl>
References: <528827A4.5080309@prodsyse.com>
	<BLU170-W5589E6340B1FC67CF7B67AC9E50@phx.gbl>
Message-ID: <5288464E.2050208@prodsyse.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131116/2fadf36b/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sun Nov 17 05:38:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 16 Nov 2013 20:38:00 -0800
Subject: [R] order() function, decreasing=TRUE unexpected behaviour
In-Reply-To: <8CF10AA730C93949BFADDC51D13CC90D41BD1C@UQEXMDA8.soe.uq.edu.au>
References: <8CF10AA730C93949BFADDC51D13CC90D41BD1C@UQEXMDA8.soe.uq.edu.au>
Message-ID: <3f151884-2e51-4eaa-b2a3-819edbb80b5e@email.android.com>

I think you are confused, and there is no problem with the order function. Keep in mind that order returns the index values in a sequence such that when the result of the order function is used as indexes for the original sequence then the data will be sorted as desired. You may see the error of your ways more clearly if you use a vector of strings like c("b","a","c","d","e") instead of integer values.

Please configure your email client to send plain text to this list as the Posting Guide requests, as HTML messes up R code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Hawthorne Beyer <h.beyer at uq.edu.au> wrote:
>There appears to be an issue with the decreasing=TRUE option on the
>order() function that indicates either a bug or perhaps a design flaw
>(potentially flawed because I would suggest the majority of users would
>expect different behaviour).
>
># demonstration of problem:
>x <- c(2,1,3,4,5)
>order(x)
>order(x, decreasing=TRUE)
>
>order(x) correctly reports the order as:
>2 1 3 4 5
>I expected the result for order(x, decreasing=TRUE) to be:
>4 5 3 2 1
>but the values actually reported are:
>5 4 3 1 2
>which is also the result of order(-x) (this may indicate a possible
>cause of this issue?).
>
>Thus, the decreasing=TRUE option in the order() function does not
>reverse the order of the values reported under the default of
>decreasing=FALSE in an example with no ties. If this behaviour is by
>design I am struggling to understand what purpose the decreasing=TRUE
>option serves and would like to suggest that this is not consistent
>with how many (most?) users would expect this option to work.
>
>Tested on R2.15.3 and 3.0.1 (both x86_64 linux-gnu) with identical
>results. I have also tried it on other series of numbers with the same
>result.
>
>Apologies if this has been discussed or reported elsewhere but I could
>not find any relevant posts. Perhaps I have failed to understand some
>fundamental issue? Sorry if this is me being dimwitted - it does seem
>hard to believe that there is a bug in a relatively straightforward
>r-base function. But I thought I would mention this as it could impact
>many people.
>
>Many thanks to all the R developers and R community for producing and
>supporting such an outstanding and invaluable product.
>Hawthorne Beyer
>University of Queensland
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Nov 17 06:58:34 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 16 Nov 2013 21:58:34 -0800
Subject: [R] r documentation rugarch egarch
In-Reply-To: <1384642168140-4680580.post@n4.nabble.com>
References: <1384642168140-4680580.post@n4.nabble.com>
Message-ID: <289663cb-eb99-444e-9a04-bb0f3fdc9ac5@email.android.com>

You don't seem to read very well. The rugarch vignette that you said you read clearly states that questions on that package should be directed to the R-sig-finance mailing list. This is not that list.

Before you go deliver this screed to that forum, you may want to give yourself some time to cool off because at this rate you are only going to alienate people who otherwise might help you. If you fail to adjust your approach, we the users of and contributors to R who answer each others questions on our own time (not tech support staff paid to put up with irate buyers of R, since said staff don't exist) are merely going to wait quietly for you to go back to wherever you came from.

PS: You might try typing the word "vignette" into Google.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

randomsamson <joh.mo at web.de> wrote:
>Hi,
>
>I`m about to switch from STATA to R and have serious troubles to find
>proper
>documentations on the internet.
>Right now I try to find a proper documentation of the eGARCH model
>being
>part of the rugarch package.
>
>Neither here
>http://cran.r-project.org/web/packages/rugarch/vignettes/Introduction_to_the_rugarch_package.pdf
>nor here
>http://cran.r-project.org/web/packages/rugarch/rugarch.pdf
>could i find some information that was helping.
>
>In this post
>http://r.789695.n4.nabble.com/RUGARCH-eGARCH-and-variance-targeting-td4634896.html
>someone proposes to read the "vignette on how the unconditional
>variance is
>calculated for the eGARCH
>model"
>I don`t know what is meant by vignette. 
>
>The R-built-in help function tells me about eGARCH: "assymetry term:
>gamma1"
>Thanks a lot R-help. This is relly a lot of information.
>
>I`d like to find out about the eGARCH model notation used in R, the
>settings
>and estimation techniques that are used and/or can be configured in
>this
>case, ...
>
>When searching the internet I`ve also not been very successful.
>
>When working with STATA I`ve so far never had troubles to find the
>right
>information.
>So i think I`m not in general too stupid to do some search on the
>internet.
>
>Please can anyone tell me what this "vignette" is supposed to be and
>where
>to find it?
>
>Thanks a lot,
>Samson
>
>
>
>
>
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/r-documentation-rugarch-egarch-tp4680580.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Sun Nov 17 07:28:53 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 17 Nov 2013 07:28:53 +0100
Subject: [R] The smallest enclosing ball problem
In-Reply-To: <loom.20131116T130416-500@post.gmane.org>
References: <loom.20131116T130416-500@post.gmane.org>
Message-ID: <F07D3877-3CA3-469B-92FB-860EB0EC0860@xs4all.nl>


Forgot to forward my answer to R-help.

Berend


On 16-11-2013, at 13:11, Hans W.Borchers <hwborchers at googlemail.com> wrote:

> I wanted to solve the following geometric optimization problem, sometimes 
> called the "enclosing ball problem":
> 
>   Given a set P = {p_1, ..., p_n} of n points in R^d, find a point p_0 such 
>   that max ||p_i - p_0|| is minimized.
> 
> A known algorithm to solve this as a Qudratic Programming task is as follows:
> 
>   Define matrix C = (p_1, ..., p_n), i.e. coordinates of points in columns,
>   and minimize
>                   x' C' C x - \sum (p_i' p_i) x_i
>   subject to
>                   \sum x_1 = 1, x_i >= 0 .
> 
> Let x0 = (x0_1, ..., x0_n) be an optimal solution, then the linear combination
> 
>   p0 = \sum x0_i p_i
> 
> is the center of the smallest enclosing ball, and the negative value of the 
> objective function at x0 is the squared radius of the ball.
> 
> As an example, find the smallest ball enclosing the points (1,0,0), (0,1,0), 
> and (0.5, 0.5, 0.1) in 3-dim. space. We would expect the center of the ball to 
> be at (0.5, 0.5, 0), and with radius 1/sqrt(2).
> 
>   C <- matrix( c(1, 0, 0.5,
>                  0, 1, 0.5,
>                  0, 0, 0.1), ncol = 3, byrow = TRUE)
> 
>   # We need to define D = 2    C' C, d = (p_i' p_i), A = c(1,1,1), and b = 1
>   D <- 2 * t(C) %*% C
>   d <- apply(C^2, 2, sum)
>   A <- matrix(1, nrow = 1, ncol = 3)
>   b <- 1
> 
>   # Now solve with solve.QP() in package quadprog ...
>   require(quadprog)
>   sol1 <- solve.QP(D, d, t(A), b, meq = 1)
> 
>   # ... and check the result
>   sum(sol1$solution)                  # 1
>   p0 <- c(C %*% sol1$solution)        # 0.50  0.50 -2.45
>   r0 <- sqrt(-sol1$value)             # 2.55
> 
>   # distance of all points to the center
>   sqrt(colSums((C - p0)^2))           # 2.55 2.55 2.55
> 
> As a result we get a ball such that all points lie on the boundary.
> The same happens for 100 points in 100-dim. space (to keep D positive 
> definite, n = d is required).
> That is a very nice, even astounding result, but not what I had hoped for!
> 


At the risk of making a complete fool of myself.

Why the restriction:  \sum x_1 = 1, x_i >= 0 ?

Isn?t just  x_i >= 0 sufficient?

Change your code with this

A <- diag(3)
b <- rep(0,3)
sol2 <- solve.QP(D, d, A, b, meq = 0)
sol2

resulting in this

$solution
[1] 0.5 0.5 0.0
$value
[1] -0.5
$unconstrained.solution
[1]  12.75  12.75 -24.50
$iterations
[1] 2 0
$Lagrangian
[1] 0.00 0.00 0.49
$iact
[1] 3

And $solution seems to be what you want.

And:

p0 <- c(C %*% sol2$solution)
r0 <- sqrt(-sol2$value)

# distance of all points to the center
sqrt(colSums((C - p0)^2))

gives the same results as LowRankQP for the last expression.

Berend



> Compare this with another quadratic programming solver in R, for example 
> LowRankQP() in the package of the same name.
> 
>   require(LowRankQP)
>   sol2 <- LowRankQP(D, -d, A, b, u = rep(3, 3), method="LU")
> 
>   p2 <- c(C %*% sol2$alpha)   # 5.000000e-01 5.000000e-01 1.032019e-12
>   sqrt(colSums((C - p2)^2))   # 0.7071068 0.7071068 0.1000000
> 
> The correct result, and we get correct solutions in higher dimensions, too. 
> LowRankQP works also if we apply it with n > d, e.g., 100 points in 2- 
> or 3-dimensional space, when matrix D is not positive definite -- solve.QP( ) 
> does not work in these cases.
> 
> *** What do I do wrong in calling solve.QP()? ***
> 
> My apologies for this overly long request. I am sending it through the weekend
> hoping that someone may have a bit of time to look at it more closely.
> 
> Hans Werner
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Sun Nov 17 08:12:22 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 17 Nov 2013 18:12:22 +1100
Subject: [R] Calculate Range
In-Reply-To: <1384638589297-4680579.post@n4.nabble.com>
References: <1384638589297-4680579.post@n4.nabble.com>
Message-ID: <52886C56.8050905@bitwrit.com.au>

On 11/17/2013 08:49 AM, SCRIPTHAM wrote:
> Hi
>
> My R version is the current version as at 15 Nov 2013.
>
> I have tried to calculate range using tapply() with FUN=range.
> tapply() returns two fields, the ID field and a field of two text items one
> is the maximum and the other is the minimum.
> I take as the difference max - min, does R use a different term for range in
> tapply?
>
> I have also tried
> aggregate() with Fun=range, with Fun=min and FUN=max
> and they also gave problems.
>
> What is the best route to calculate ranges for groups within a data frame.
>
Hi Scriptham,
It looks like you want to get the difference between the maximum and 
minimum values rather than the actual values. Define a function:

range_span<-function(x) return(diff(range(x)))

and use that as the FUN argument.

Jim


From h.beyer at uq.edu.au  Sun Nov 17 05:49:42 2013
From: h.beyer at uq.edu.au (Hawthorne Beyer)
Date: Sun, 17 Nov 2013 04:49:42 +0000
Subject: [R] order() function, decreasing=TRUE unexpected behaviour
In-Reply-To: <3f151884-2e51-4eaa-b2a3-819edbb80b5e@email.android.com>
References: <8CF10AA730C93949BFADDC51D13CC90D41BD1C@UQEXMDA8.soe.uq.edu.au>,
	<3f151884-2e51-4eaa-b2a3-819edbb80b5e@email.android.com>
Message-ID: <8CF10AA730C93949BFADDC51D13CC90D41ED4A@UQEXMDA8.soe.uq.edu.au>

Thank you Jeff. You are correct. I am relieved it is my mistake. Apologies for bothering everyone. I will try harder next time!
Best wishes,
Hawthorne Beyer
University of Queensland


________________________________________
From: Jeff Newmiller [jdnewmil at dcn.davis.CA.us]
Sent: 17 November 2013 14:38
To: Hawthorne Beyer; r-help at r-project.org
Subject: Re: [R] order() function, decreasing=TRUE unexpected behaviour

I think you are confused, and there is no problem with the order function. Keep in mind that order returns the index values in a sequence such that when the result of the order function is used as indexes for the original sequence then the data will be sorted as desired. You may see the error of your ways more clearly if you use a vector of strings like c("b","a","c","d","e") instead of integer values.

Please configure your email client to send plain text to this list as the Posting Guide requests, as HTML messes up R code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

Hawthorne Beyer <h.beyer at uq.edu.au> wrote:
>There appears to be an issue with the decreasing=TRUE option on the
>order() function that indicates either a bug or perhaps a design flaw
>(potentially flawed because I would suggest the majority of users would
>expect different behaviour).
>
># demonstration of problem:
>x <- c(2,1,3,4,5)
>order(x)
>order(x, decreasing=TRUE)
>
>order(x) correctly reports the order as:
>2 1 3 4 5
>I expected the result for order(x, decreasing=TRUE) to be:
>4 5 3 2 1
>but the values actually reported are:
>5 4 3 1 2
>which is also the result of order(-x) (this may indicate a possible
>cause of this issue?).
>
>Thus, the decreasing=TRUE option in the order() function does not
>reverse the order of the values reported under the default of
>decreasing=FALSE in an example with no ties. If this behaviour is by
>design I am struggling to understand what purpose the decreasing=TRUE
>option serves and would like to suggest that this is not consistent
>with how many (most?) users would expect this option to work.
>
>Tested on R2.15.3 and 3.0.1 (both x86_64 linux-gnu) with identical
>results. I have also tried it on other series of numbers with the same
>result.
>
>Apologies if this has been discussed or reported elsewhere but I could
>not find any relevant posts. Perhaps I have failed to understand some
>fundamental issue? Sorry if this is me being dimwitted - it does seem
>hard to believe that there is a bug in a relatively straightforward
>r-base function. But I thought I would mention this as it could impact
>many people.
>
>Many thanks to all the R developers and R community for producing and
>supporting such an outstanding and invaluable product.
>Hawthorne Beyer
>University of Queensland
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Nov 17 08:25:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 16 Nov 2013 23:25:25 -0800 (PST)
Subject: [R] melt dataframe
In-Reply-To: <1384662485.32144.YahooMailNeo@web160604.mail.bf1.yahoo.com>
References: <1384662485.32144.YahooMailNeo@web160604.mail.bf1.yahoo.com>
Message-ID: <1384673125.4173.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.csv("precipitationRglimclim.csv",header=TRUE,stringsAsFactors=FALSE,sep="\t")
library(reshape2)
dat2M <- melt(dat1,id.var=c("year","month","day"))
dat2M1 <- dat2M[with(dat2M,order(year,month,day,variable)),]
?dim(dat2M1)
#[1] 1972320?????? 5
?row.names(dat2M1) <- 1:nrow(dat2M1)
?colnames(dat2M1)[4:5] <- c("site","rain")


16436*120
#[1] 1972320

A.K.






On Saturday, November 16, 2013 11:28 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:

Hello AK,
I would like to melt the attached dataframe (precipitationRglimclim.csv) into a format as in sampleRglimclim.csv.
I tried doing it using the reshape2 package but did not succeed.

Explanation: The daily data is for 120 sites (G1...G120). For each year, there are 12 months and for each month, there are 1...28 or 30 or 31 days.
Melt the dataframe such that each day in a month has 120 values?corresponding?to the 120 sites.

If you need further explanation let me know.
Thanks so much.
Atem.


From joh.mo at web.de  Sun Nov 17 08:44:11 2013
From: joh.mo at web.de (randomsamson)
Date: Sat, 16 Nov 2013 23:44:11 -0800 (PST)
Subject: [R] r documentation rugarch egarch
In-Reply-To: <289663cb-eb99-444e-9a04-bb0f3fdc9ac5@email.android.com>
References: <1384642168140-4680580.post@n4.nabble.com>
	<289663cb-eb99-444e-9a04-bb0f3fdc9ac5@email.android.com>
Message-ID: <1384674251643-4680605.post@n4.nabble.com>

First I want to apologize for posting in the wrong list. As I`ve experienced
very similar issues with respect to other R packages I thought that my
question was related to a general problem of mine when using the R help and
R documentation (and that this rugarch issue was just an example). That`s
why I thought this list here might be more appropriate.

As I`m not a native english speaker it`s hard for me to get all the subtle
details of Mr. Newmillers answer. But if I`m not wrong there is a relly
strong derogative atmosphere. I think even if I`ve made a mistake (what I`m
sorry for) this is not a nice way to help newcomers. And even If it`s hard
to imagine for a native-speaker: None of my translators could give me an
adequate translation of the word "vignette". Google didn`t help either. But
thanks for the hint to use google, this is a very smart idea I`d never had
figured out myself.

Besides, the STATA forums I used to search are also supported by non-paid
people. They even manage to treat each other with some respect. 



--
View this message in context: http://r.789695.n4.nabble.com/r-documentation-rugarch-egarch-tp4680580p4680605.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Sun Nov 17 09:04:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 00:04:50 -0800 (PST)
Subject: [R] Plotting a list of lists
Message-ID: <1384675490.42979.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
It is not very clear.
May be this gets you started:

set.seed(42)
lst1 <- lapply(1:5, function(i) lapply(1:50,function(i) rnorm(sample(50,1))))
lst2 <- lapply(lst1,function(x) data.frame(X= rep(seq_along(x),sapply(x,length)),Y=unlist(x)))
pdf("test2.pdf")
?lapply(lst2,function(x) with(x,plot(Y~X)))
dev.off()

A.K.


I have a list if lists in R (part of which is shown below). I wish to 
plot these lists on the same graph where each list corresponds to a 
single x coordinate. For example for the 45th list all the values would 
be plotted on the line x=45. Anyone able to help? 

[[45]] 
?[1] -0.110067765 -0.040016980 -0.024073054 -0.221518631 ?0.158046458 
?[6] -0.110134750 ?0.004824416 ?0.067080351 -0.052912475 ?0.034445239 
[11] ?0.017093804 ?0.014526023 ?0.123733756 -0.076593627 -0.049173945 
[16] -0.044804543 ?0.089349788 -0.061330124 -0.108191264 ?0.210778889 
[21] ?0.057898773 -0.000392106 -0.020911704 ?0.084198206 -0.064250534 
[26] -0.041634491 -0.142851316 -0.116919985 ?0.115766019 ?0.082258703 
[31] ?0.048376129 -0.036986678 -0.002247251 ?0.202808035 ?0.178324911 
[36] ?0.027862391 -0.092909969 -0.158287227 ?0.048137063 ?0.142961443 
[41] ?0.024102742 -0.034740816 ?0.095980313 ?0.234679333 ?0.062757475 
[46] -0.083656499 -0.026666635 -0.049571943 -0.003269980 ?0.012924383 


[[46]] 
?[1] ?0.112291702 ?0.455557078 -0.188595792 ?0.023815125 ?0.047757787 
?[6] -0.108520094 ?0.119083003 ?0.065705185 ?0.224999137 ?0.076742666 
[11] ?0.247330698 ?0.096306189 -0.222250082 -0.004899562 -0.026481377 
[16] -0.171317015 ?0.183442656 -0.026224042 ?0.017024487 ?0.180420266 
[21] ?0.108220342 -0.002034567 -0.059184763 ?0.024854329 -0.267982999 
[26] -0.181058542 ?0.271709202 ?0.078113700 ?0.145173899 -0.259035363 
[31] -0.033086712 -0.136858819 -0.232087471 -0.014715389 ?0.105185758 
[36] -0.119881528 ?0.098842549 ?0.060748033 -0.306107128 ?0.022539607 
[41] -0.093208642 ?0.140678025 ?0.095285130 ?0.140788810 -0.274918531 
[46] ?0.080010582 -0.070639892 ?0.100321500 ?0.047547311 ?0.107104289 


[[47]] 
?[1] ?0.137215639 -0.074820424 -0.082442176 ?0.250054175 ?0.185168148 
?[6] -0.146350321 -0.135327713 -0.184682332 ?0.143446849 ?0.047635866 
[11] -0.073068031 -0.002690403 -0.162714729 -0.151941475 -0.122147610 
[16] -0.041184742 ?0.098393496 -0.000948722 -0.164136918 ?0.086485859 
[21] -0.101381633 ?0.017928356 ?0.086042233 ?0.167799050 -0.066286935 
[26] ?0.153897947 ?0.046226772 -0.042488379 ?0.157126544 -0.026546025 
[31] -0.098447831 ?0.248466421 -0.240674997 -0.067275509 ?0.219154426 
[36] ?0.261614097 -0.085938742 ?0.169890170 ?0.038687110 ?0.273939911 
[41] -0.207415094 -0.242613302 -0.070860536 -0.108869865 ?0.002090580


From bhh at xs4all.nl  Sun Nov 17 11:31:29 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 17 Nov 2013 11:31:29 +0100
Subject: [R] The smallest enclosing ball problem
In-Reply-To: <loom.20131116T130416-500@post.gmane.org>
References: <loom.20131116T130416-500@post.gmane.org>
Message-ID: <4803B7B6-F320-4CF8-A196-BF253ACD2BDF@xs4all.nl>


On 16-11-2013, at 13:11, Hans W.Borchers <hwborchers at googlemail.com> wrote:

> I wanted to solve the following geometric optimization problem, sometimes 
> called the "enclosing ball problem":
> 
>    Given a set P = {p_1, ..., p_n} of n points in R^d, find a point p_0 such 
>    that max ||p_i - p_0|| is minimized.
> 
> A known algorithm to solve this as a Qudratic Programming task is as follows:
> 
>    Define matrix C = (p_1, ..., p_n), i.e. coordinates of points in columns,
>    and minimize
>                    x' C' C x - \sum (p_i' p_i) x_i
>    subject to
>                    \sum x_1 = 1, x_i >= 0 .
> 
> Let x0 = (x0_1, ..., x0_n) be an optimal solution, then the linear combination
> 
>    p0 = \sum x0_i p_i
> 
> is the center of the smallest enclosing ball, and the negative value of the 
> objective function at x0 is the squared radius of the ball.
> 
> As an example, find the smallest ball enclosing the points (1,0,0), (0,1,0), 
> and (0.5, 0.5, 0.1) in 3-dim. space. We would expect the center of the ball to 
> be at (0.5, 0.5, 0), and with radius 1/sqrt(2).
> 
>    C <- matrix( c(1, 0, 0.5,
>                   0, 1, 0.5,
>                   0, 0, 0.1), ncol = 3, byrow = TRUE)
> 
>    # We need to define D = 2    C' C, d = (p_i' p_i), A = c(1,1,1), and b = 1
>    D <- 2 * t(C) %*% C
>    d <- apply(C^2, 2, sum)
>    A <- matrix(1, nrow = 1, ncol = 3)
>    b <- 1
> 
>    # Now solve with solve.QP() in package quadprog ...
>    require(quadprog)
>    sol1 <- solve.QP(D, d, t(A), b, meq = 1)
> 
>    # ... and check the result
>    sum(sol1$solution)                  # 1
>    p0 <- c(C %*% sol1$solution)        # 0.50  0.50 -2.45
>    r0 <- sqrt(-sol1$value)             # 2.55
> 
>    # distance of all points to the center
>    sqrt(colSums((C - p0)^2))           # 2.55 2.55 2.55
> 
> As a result we get a ball such that all points lie on the boundary.
> The same happens for 100 points in 100-dim. space (to keep D positive 
> definite, n = d is required).
> That is a very nice, even astounding result, but not what I had hoped for!
> 
> Compare this with another quadratic programming solver in R, for example 
> LowRankQP() in the package of the same name.
> 
>    require(LowRankQP)
>    sol2 <- LowRankQP(D, -d, A, b, u = rep(3, 3), method="LU")
> 
>    p2 <- c(C %*% sol2$alpha)   # 5.000000e-01 5.000000e-01 1.032019e-12
>    sqrt(colSums((C - p2)^2))   # 0.7071068 0.7071068 0.1000000
> 
> The correct result, and we get correct solutions in higher dimensions, too. 
> LowRankQP works also if we apply it with n > d, e.g., 100 points in 2- 
> or 3-dimensional space, when matrix D is not positive definite -- solve.QP( ) 
> does not work in these cases.
> 
> *** What do I do wrong in calling solve.QP()? ***
> 

After  having a closer look at this problem, I believe you did not include the constraint x_i >= 0 in the call to solve.QP.
So with this modification of your code

A <- matrix(rep(1,3),nrow=4,ncol=3,byrow=TRUE)
A[2:4,] <- diag(3)   
b <- c(1,0,0,0)

sol3 <- solve.QP(D, d, t(A), b, meq = 1) # first row of A is an equality
sol3
p0 <- c(C %*% sol3$solution)
r0 <- sqrt(-sol3$value)
p0
r0
sqrt(colSums((C - p0)^2))

one gets the correct answer.
BTW LowRankQP seems to postulate x_i >=0 if I read its manual correctly.

Berend


From hwborchers at googlemail.com  Sun Nov 17 11:32:24 2013
From: hwborchers at googlemail.com (Hans W.Borchers)
Date: Sun, 17 Nov 2013 10:32:24 +0000
Subject: [R] The smallest enclosing ball problem
References: <loom.20131116T130416-500@post.gmane.org>
	<F07D3877-3CA3-469B-92FB-860EB0EC0860@xs4all.nl>
Message-ID: <loom.20131117T112538-993@post.gmane.org>

Berend Hasselman <bhh <at> xs4all.nl> writes:
> Forgot to forward my answer to R-help.
> 
> Berend

Thanks, Berend, for thinking about it. \sum xi = 1  is a necessary condition 
to generate a valid geometric solution. The three points in the example are 
very regular and your apporach works, but imagine some random points:

    set.seed(8237)
    C <- matrix(runif(9), 3, 3)
    D <- 2 * t(C) %*% C
    d <- apply(C^2, 2, sum)
    A <- diag(3)
    b <- rep(0,3)

    require(quadprog)
    sol1 <- solve.QP(D, d, A, b, meq = 0)
    sol1                                # now \sum xi = 1is not fulfilled

    p0 <- c(C %*% sol1$solution)        # 0.3707410 0.3305265 0.2352084
    r0 <- sqrt(-sol1$value)             # 0.5495631

    # distance of all points to the center
    sqrt(colSums((C - p0)^2))           # 0.5495631 0.3119314 0.5495631

Unfortunately, this is not the smallest enclosing ball.
LowRankQP will find the true solution with radius 0.3736386 !

    require(LowRankQP)
    A <- matrix(1, nrow = 1, ncol = 3)
    b <- 1
    
    sol2 <- LowRankQP(D, -d, A, b, u = rep(1, 3), method="LU")
  
    p2 <- c(C %*% sol2$alpha)   # 0.5783628 0.5372570 0.2017087
    sqrt(colSums((C - p2)^2))   # 0.3736386 0.3736386 0.3736386

But the strangest thing is that with \sum xi =1 solve.QP positions all points
on the boundary, though (in my opinion) no constraint requests it. So the
question remains:
                  *** What do I do wrong in calling solve.QP()? ***

Hans Werner

> At the risk of making a complete fool of myself.
> 
> Why the restriction:  \sum x_1 = 1, x_i >= 0 ?
> 
> Isn?t just  x_i >= 0 sufficient?
> 
> Change your code with this
> 
> A <- diag(3)
> b <- rep(0,3)
> sol2 <- solve.QP(D, d, A, b, meq = 0)
> sol2
> 
> resulting in this
> 
> $solution
> [1] 0.5 0.5 0.0
> $value
> [1] -0.5
> $unconstrained.solution
> [1]  12.75  12.75 -24.50
> $iterations
> [1] 2 0
> $Lagrangian
> [1] 0.00 0.00 0.49
> $iact
> [1] 3
> 
> And $solution seems to be what you want.
> 
> And:
> 
> p0 <- c(C %*% sol2$solution)
> r0 <- sqrt(-sol2$value)
> 
> # distance of all points to the center
> sqrt(colSums((C - p0)^2))
> 
> gives the same results as LowRankQP for the last expression.
> 
> Berend
>


From bhh at xs4all.nl  Sun Nov 17 12:05:16 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 17 Nov 2013 12:05:16 +0100
Subject: [R] The smallest enclosing ball problem
In-Reply-To: <loom.20131117T112538-993@post.gmane.org>
References: <loom.20131116T130416-500@post.gmane.org>
	<F07D3877-3CA3-469B-92FB-860EB0EC0860@xs4all.nl>
	<loom.20131117T112538-993@post.gmane.org>
Message-ID: <8CC6B436-9E8A-4EF6-8A45-D10A9F73A331@xs4all.nl>


On 17-11-2013, at 11:32, Hans W.Borchers <hwborchers at googlemail.com> wrote:

> Berend Hasselman <bhh <at> xs4all.nl> writes:
>> Forgot to forward my answer to R-help.
>> 
>> Berend
> 
> Thanks, Berend, for thinking about it. \sum xi = 1  is a necessary condition 
> to generate a valid geometric solution. The three points in the example are 
> very regular and your apporach works, but imagine some random points:
> 
>    set.seed(8237)
>    C <- matrix(runif(9), 3, 3)
>    D <- 2 * t(C) %*% C
>    d <- apply(C^2, 2, sum)
>    A <- diag(3)
>    b <- rep(0,3)
> 
>    require(quadprog)
>    sol1 <- solve.QP(D, d, A, b, meq = 0)
>    sol1                                # now \sum xi = 1is not fulfilled
> 
>    p0 <- c(C %*% sol1$solution)        # 0.3707410 0.3305265 0.2352084
>    r0 <- sqrt(-sol1$value)             # 0.5495631
> 
>    # distance of all points to the center
>    sqrt(colSums((C - p0)^2))           # 0.5495631 0.3119314 0.5495631
> 
> Unfortunately, this is not the smallest enclosing ball.
> LowRankQP will find the true solution with radius 0.3736386 !
> 
>    require(LowRankQP)
>    A <- matrix(1, nrow = 1, ncol = 3)
>    b <- 1
> 
>    sol2 <- LowRankQP(D, -d, A, b, u = rep(1, 3), method="LU")
> 
>    p2 <- c(C %*% sol2$alpha)   # 0.5783628 0.5372570 0.2017087
>    sqrt(colSums((C - p2)^2))   # 0.3736386 0.3736386 0.3736386
> 
> But the strangest thing is that with \sum xi =1 solve.QP positions all points
> on the boundary, though (in my opinion) no constraint requests it. So the
> question remains:
>                  *** What do I do wrong in calling solve.QP()? ***
> 
> Hans Werner

See my second reply to your original post.
Modify your code with

A <- matrix(rep(1,3),nrow=4,ncol=3,byrow=TRUE)
A[2:4,] <- diag(3)   
b <- c(1,0,0,0)

to include constraints x_i>=0 (which LowRankQP includes automatically!) and run solve.QP as follows

sol2 <- solve.QP(D, d, t(A), b, meq = 1)
sol2

p0 <- c(C %*% sol2$solution) 
r0 <- sqrt(-sol2$value) 
p0
r0
# distance of all points to the center
sqrt(colSums((C - p0)^2))
 
and the answers now agree with LowRankQP.

Berend


From hwborchers at googlemail.com  Sun Nov 17 12:20:46 2013
From: hwborchers at googlemail.com (Hans W.Borchers)
Date: Sun, 17 Nov 2013 11:20:46 +0000
Subject: [R] The smallest enclosing ball problem
References: <loom.20131116T130416-500@post.gmane.org>
	<4803B7B6-F320-4CF8-A196-BF253ACD2BDF@xs4all.nl>
Message-ID: <loom.20131117T120728-791@post.gmane.org>

Berend Hasselman <bhh <at> xs4all.nl> writes:
> 

It seems you are absolutely right. I always assumed a quadratic programming 
solver will -- as all linear programming solvers do -- automatically require 
the variables to be positive.

I checked it for some more examples in 10 and even 100 dimensions, and the 
results now agree. Still, it's a bit disappointing that 'quadprog' will not 
solve problems with 10 points in R^3, because the corresponding matrices are 
not positive definite.

Thanks
Hans Werner

> 
> After  having a closer look at this problem, I believe you did not include 
> the constraint x_i >= 0 in the call to solve.QP.
> So with this modification of your code
> 
> A <- matrix(rep(1,3),nrow=4,ncol=3,byrow=TRUE)
> A[2:4,] <- diag(3)   
> b <- c(1,0,0,0)
> 
> sol3 <- solve.QP(D, d, t(A), b, meq = 1) # first row of A is an equality
> sol3
> p0 <- c(C %*% sol3$solution)
> r0 <- sqrt(-sol3$value)
> p0
> r0
> sqrt(colSums((C - p0)^2))
> 
> one gets the correct answer.
> BTW LowRankQP seems to postulate x_i >=0 if I read its manual correctly.
> 
> Berend


From gdraisma at xs4all.nl  Sun Nov 17 12:43:06 2013
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Sun, 17 Nov 2013 12:43:06 +0100
Subject: [R] Lattice: how to change the canvas size with Sweave
Message-ID: <5288ABCA.70608@xs4all.nl>

Dear all,
I would like to include a wide graph with narrow height in my LaTeX 
output. Up to now I only get it done using Stangle and including
   pdf("pietje-001.pdf",width=7,height=4)
   xyplot(...)
   dev.off()
What is the correct way of setting the canvas size?
Thanks.
Gerrit Draisma

==========pietje.tex
\documentclass{article}
\title{How to define the size of the plotting canvas?}
\author{Gerrit Draisma}
\begin{document}
\maketitle
I would like to make this a wide graph with a small height.
How do I do that?
<<>>=
library(lattice)
@
\raggedbottom
\begin{figure}[!h]
\centering
<<echo=FALSE,fig=TRUE>>=
xyplot(runif(11)~(0:10),type="l", aspect=0.4,
scales=list(x=list(tick.number=11),y=list(tick.number=3)))
@
\caption{The canvas is too big!}
\end{figure}
\end{document}
==========


From gdraisma at xs4all.nl  Sun Nov 17 13:16:44 2013
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Sun, 17 Nov 2013 13:16:44 +0100
Subject: [R] Lattice: how to change the canvas size with Sweave
In-Reply-To: <5288ABCA.70608@xs4all.nl>
References: <5288ABCA.70608@xs4all.nl>
Message-ID: <5288B3AC.9000607@xs4all.nl>

Oops,

I forget to write the I included the lines pdf()..(dev.off()
in the file pietje.R generated by Stangle.
And now I see that included pietje.tex in reality was named pietje.rnw
with pietje.tex the result from Sweave.

Apologies for this confusion
Gerrit.


op 11/17/2013 12:43 PM Gerrit Draisma schreef:
> Dear all,
> I would like to include a wide graph with narrow height in my LaTeX
> output. Up to now I only get it done using Stangle and including
>    pdf("pietje-001.pdf",width=7,height=4)
>    xyplot(...)
>    dev.off()
> What is the correct way of setting the canvas size?
> Thanks.
> Gerrit Draisma
>
> ==========pietje.tex
> \documentclass{article}
> \title{How to define the size of the plotting canvas?}
> \author{Gerrit Draisma}
> \begin{document}
> \maketitle
> I would like to make this a wide graph with a small height.
> How do I do that?
> <<>>=
> library(lattice)
> @
> \raggedbottom
> \begin{figure}[!h]
> \centering
> <<echo=FALSE,fig=TRUE>>=
> xyplot(runif(11)~(0:10),type="l", aspect=0.4,
> scales=list(x=list(tick.number=11),y=list(tick.number=3)))
> @
> \caption{The canvas is too big!}
> \end{figure}
> \end{document}
> ==========


From chrisege at stud.ntnu.no  Sun Nov 17 10:21:56 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Sun, 17 Nov 2013 01:21:56 -0800 (PST)
Subject: [R] Hide return values
Message-ID: <1384680116033-4680611.post@n4.nabble.com>

Hi everyone!

I am in the process of writing an R-package and while writing a summary
function, I have come across a problem. I am able to print a summary table
(as in a standard glm() summary) by using *cat()* but the values I return is
also printet. 
How am I able to remove the return values from being printet, but still
being able to grab using e.g. summary$coeff??

Sincerly
Chris



--
View this message in context: http://r.789695.n4.nabble.com/Hide-return-values-tp4680611.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sun Nov 17 14:28:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 17 Nov 2013 07:28:45 -0600
Subject: [R] Hide return values
In-Reply-To: <1384680116033-4680611.post@n4.nabble.com>
References: <1384680116033-4680611.post@n4.nabble.com>
Message-ID: <C5946240-ED71-47FB-94CF-A533F8276843@comcast.net>


On Nov 17, 2013, at 3:21 AM, Chris89 wrote:

> Hi everyone!
>
> I am in the process of writing an R-package and while writing a  
> summary
> function, I have come across a problem. I am able to print a summary  
> table
> (as in a standard glm() summary) by using *cat()* but the values I  
> return is
> also printet.
> How am I able to remove the return values from being printet, but  
> still
> being able to grab using e.g. summary$coeff??

?invisible

-- 
David.


From k.barton at abdn.ac.uk  Sun Nov 17 14:35:02 2013
From: k.barton at abdn.ac.uk (=?UTF-8?B?S2FtaWwgQmFydG/FhA==?=)
Date: Sun, 17 Nov 2013 13:35:02 +0000
Subject: [R] Error in MuMIn "models are not all fitted to the same data"
In-Reply-To: <CAOK+e=Z4wugkodJ0z9-iGkwEGVf-eh9u4kGKqT2NwAxyjEcEGQ@mail.gmail.com>
References: <mailman.19.1384513206.32212.r-help@r-project.org>
	<52864855.7000300@abdn.ac.uk>
	<CAOK+e=Z4wugkodJ0z9-iGkwEGVf-eh9u4kGKqT2NwAxyjEcEGQ@mail.gmail.com>
Message-ID: <5288C606.5070009@abdn.ac.uk>

It's the (typical) na.action = na.omit problem. You have missing values
in your data, so the number of observations differs between models using
different variables.

BTW with the recent lme4 package, your code throws a lot of warnings
about the use of lmer with non-gaussian family and ignored REML
argument. Also, consider using "update" rather than rewriting the models
each time.

kamil

On 2013-11-15 17:10, Lilly Dethier wrote:
> Of course! Here's my data file and R code file. Thanks so much for your
> help!!
>
>
> Lilly Dethier
>
>
> On Fri, Nov 15, 2013 at 8:14 AM, Kamil Barto? <k.barton at abdn.ac.uk
> <mailto:k.barton at abdn.ac.uk>> wrote:
>
>     works ok with mock-up data. Can you give some code to reproduce this
>     error?
>
>     kamil
>
>
>
>     On 2013-11-15 11:00, r-help-request at r-project.org
>     <mailto:r-help-request at r-project.org> wrote:
>
>         Message: 56
>         Date: Thu, 14 Nov 2013 18:01:27 -0800
>         From: Lilly Dethier<lillydethier at gmail.com
>         <mailto:lillydethier at gmail.com>__>
>         To:r-help at r-project.org <mailto:To%3Ar-help at r-project.org>
>         Subject: [R] Error in MuMIn "models are not all fitted to the same
>                data"
>         Message-ID:
>
>         <CAOK+e=Z_0pMEFKdPxZ5Eub+__DYhHFjzGk3Lcqczsa9TimAP4n_w at __mail.gmail.com
>         <mailto:Z_0pMEFKdPxZ5Eub%2BDYhHFjzGk3Lcqczsa9TimAP4n_w at mail.gmail.com>>
>         Content-Type: text/plain
>
>         I'm pretty new to GLMMs and model averaging, but think I'm
>         getting some
>         understanding of it all through lots of reading. However, I keep
>         receiving
>         an error message when trying to average models that I don't
>         understand and
>         can't find any resources about. I'm doing science education
>         research trying
>         to evaluate population demographic factors that predict biology
>         student
>         math performance. I have a lot of factors and so I tested a lot
>         of models.
>         6 of my models had pretty similar AIC values (and evidence
>         ratios of less
>         than 2.7) so I'm trying to average them. I keep receiving an
>         error message
>         that says the models are not fitted to the same data, but I have
>         no idea
>         how this is possible because all the models are from the same
>         set of data
>         (same file and same variables)...strangely it seems to work when
>         I try to
>         average MEx7, MEx10, & MEx22 only OR MEx24, MEx29, and MEx47
>         only. My code
>         is below. Any ideas? Thanks for any advice you can offer!!
>
>         library(MuMIn)
>         MEx7=lmer(cbind(c.score, w.score) ~ year + transfer + gender +
>         p.math +
>         (1|section) + (1|quarter), family=binomial, data=survey.full,
>         REML=F)
>         MEx10=lmer(cbind(c.score, w.score) ~ transfer + gender + p.math
>         + Pmajor +
>         (1|section) + (1|quarter), family=binomial, data=survey.full,
>         REML=F)
>         MEx22=lmer(cbind(c.score, w.score) ~ year + transfer + p.math +
>         (1|section)
>         + (1|quarter), family=binomial, data=survey.full, REML=F)
>         MEx24=lmer(cbind(c.score, w.score) ~ transfer + gender + p.math +
>         (1|section) + (1|quarter), family=binomial, data=survey.full,
>         REML=F)
>         MEx29=lmer(cbind(c.score, w.score) ~ transfer + p.math + Pmajor +
>         (1|section) + (1|quarter), family=binomial, data=survey.full,
>         REML=F)
>         MEx47=lmer(cbind(c.score, w.score) ~ transfer + p.math +
>         (1|section) +
>         (1|quarter), family=binomial, data=survey.full, REML=F)
>         MExAvg=model.avg(rank=AIC, MEx24, MEx7, MEx10, MEx47, MEx29, MEx22)
>
>         Error in model.avg.default(rank = AIC, MEx24, MEx7, MEx10,
>         MEx47, MEx29,  :
>             models are not all fitted to the same data
>         Lilly Dethier
>
>





The University of Aberdeen is a charity registered in Scotland, No SC013683.


From gybrg at Leeds.ac.uk  Sun Nov 17 15:47:03 2013
From: gybrg at Leeds.ac.uk (Benjamin Gillespie)
Date: Sun, 17 Nov 2013 14:47:03 +0000
Subject: [R] Extract values from vector and repeat by group
Message-ID: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>

Hi all,

I hope you can help.

I have a data frame 'df':

group=c(rep(1,8),rep(2,10),rep(3,11))
var=rnorm(29)
time=c(seq(1,8),seq(1,10),seq(1,11))
df=data.frame(group,var,time)

I would like to extract the value from 'var' for each 'group' at 'time'=4 and repeat these extracted values in a new vector ('new') n times where n is the number of rows for each group. I did this by hand as below, but there must be a quicker way:

subset=subset(df,df$time==4)
subset
group        var time
4      1  0.2531270    4
12     2 -0.3600128    4
22     3  0.4194730    4

df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))

Any questions please ask,

Many thanks in advance,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o

From jfox at mcmaster.ca  Sun Nov 17 15:53:54 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 17 Nov 2013 09:53:54 -0500
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <528827A4.5080309@prodsyse.com>
References: <528827A4.5080309@prodsyse.com>
Message-ID: <002e01cee3a4$d6452340$82cf69c0$@mcmaster.ca>

Dear Spencer,

I regularly use R (via the R Commander) for intro stats courses taught to
third-year sociology undergrads (in Canada). Without knowing where your
friend teaches, it's hard to know what her students are like, but in my
experience psychology students are generally more numerate than sociology
students, and first-year students would likely have a bit more trouble with
the course than third-year students. That your friend's department teaches
this course in the first year suggests that it, and possibly its students,
have a quantitative orientation.

I've also used a variety of statistical software to teach intro stats,
including SPSS. I originally wrote the Rcmdr package so that I could use R
instead, and I find that students have no more trouble pointing and clicking
in the R Commander than they do in SPSS. It's also my experience that
computing, regardless of the software that I've used, is the least
problematic part of the course. It's much harder for students to understand
statistical concepts, and even to apply simple formulas correctly, than to
use menu-driven statistical software.

If you'd like to take a look at the course website for my undergrad class
the last time I taught it in 2011-2012, it's at
<http://socserv.socsci.mcmaster.ca/jfox/Courses/soc3h6/index.html>. I'm
currently teaching essentially the same course, but for grad students in an
accelerated one-semester format, and that's at
<http://socserv.socsci.mcmaster.ca/jfox/Courses/soc6z3/index.html>. You'll
notice that in the grad class, students use their own computers, while in
the undergrad class, they use a computer lab. That decision relates more to
the size of the class (about 200 undergrads divided into four labs, 10 grad
students) than to the level of the students.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Spencer Graves
> Sent: Saturday, November 16, 2013 9:19 PM
> To: R list
> Subject: [R] R for a stats intro for undergrads in the US?
> 
> Hello, All:
> 
> 
>        Would anyone recommend R for an introductory statistics class
> for
> freshman psychology students in the US?  If yes, might there be any
> notes for such available?
> 
> 
>        I just checked r-projects.org and CRAN contributed documentation
> and found nothing.
> 
> 
>        I have a friend who teaches such a class, and wondered if R
> might
> be suitable.  The alternative is SPSS at $406 per student.
> 
> 
>        Thanks,
>        Spencer
> 
> 
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Sun Nov 17 16:20:27 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 17 Nov 2013 16:20:27 +0100
Subject: [R] Extract values from vector and repeat by group
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
Message-ID: <3B2391BE-2814-4079-97C8-4EFD097BCE0D@xs4all.nl>


On 17-11-2013, at 15:47, Benjamin Gillespie <gybrg at Leeds.ac.uk> wrote:

> Hi all,
> 
> I hope you can help.
> 
> I have a data frame 'df':
> 
> group=c(rep(1,8),rep(2,10),rep(3,11))
> var=rnorm(29)
> time=c(seq(1,8),seq(1,10),seq(1,11))
> df=data.frame(group,var,time)
> 
> I would like to extract the value from 'var' for each 'group' at 'time'=4 and repeat these extracted values in a new vector ('new') n times where n is the number of rows for each group. I did this by hand as below, but there must be a quicker way:
> 
> subset=subset(df,df$time==4)
> subset
> group        var time
> 4      1  0.2531270    4
> 12     2 -0.3600128    4
> 22     3  0.4194730    4
> 
> df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))
> 
> Any questions please ask,

A very similar question was recently asked on Stackoverflow: http://stackoverflow.com/questions/19971763/r-programming-normalizing-a-column-of-data-by-another-entry-in-2-other-columns

From the answer given there you could try this

set.seed(11) # to make it reproducible

group=c(rep(1,8),rep(2,10),rep(3,11))
var=rnorm(29)
time=c(seq(1,8),seq(1,10),seq(1,11))
df=data.frame(group,var,time)

#df
#df[df$time==4, c("group", "var")]
 
# merge into original data.frame
df <- merge(df, df[df$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))
df

Berend


From friendly at yorku.ca  Sun Nov 17 16:22:19 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sun, 17 Nov 2013 10:22:19 -0500
Subject: [R] repeated-measures multiple regression/ANCOVA/MANCOVA
In-Reply-To: <CAKw8OYz=P5wEKiXZQ+MC8UKnE=bkQwK7ANorT4d4ript_hN5+Q@mail.gmail.com>
References: <CAKw8OYz=P5wEKiXZQ+MC8UKnE=bkQwK7ANorT4d4ript_hN5+Q@mail.gmail.com>
Message-ID: <5288DF2B.5030908@yorku.ca>

On 11/16/2013 11:45 AM, Jakub Szewczyk wrote:
> I am trying to analyze a dataset where I have 1 continuous
> between-item variable (C), and 2 factorial within-item variables (3-
> and 2-level: F3, F2). I'm interested in whether slope of C is
> different from 0 at different combinations of F3 and F2, and whether
> it varies between these combinations.
   [snip]
> I also considered using car::Anova() for running a repeated-measures
> MANCOVA analysis, but if I got this thread right
> (http://thread.gmane.org/gmane.comp.lang.r.general/270271/focus=270275),
> this is (at present) not possible to do.
>
> Are these ways of analyzing data valid?

AFAICS, you do not have a time-varying covariate, so a repeated measures
Anova() should work.  You can probably test your hypotheses using
car::linearHypothesis on the parameters in C:F2, C:F3.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From smartpink111 at yahoo.com  Sun Nov 17 16:38:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 07:38:11 -0800 (PST)
Subject: [R] reshape
Message-ID: <1384702691.34456.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Felipe,

I get the results like this by running the code:
z <-read.table(text="date week length
7/13/2010 28 34
7/13/2010 28 35
7/14/2010 28 35
7/14/2010 28 35
7/14/2010 28 36
7/14/2010 28 36
7/20/2010 29 31
7/16/2010 29 34
7/18/2010 29 34
7/18/2010 29 34
7/21/2010 29 35
7/20/2010 29 36
7/21/2010 29 36
7/22/2010 29 36
7/16/2010 29 37
7/18/2010 29 37
7/20/2010 29 37
7/21/2010 29 37
7/21/2010 29 37
7/22/2010 29 37
7/22/2010 29 37",header=TRUE)

z$ID <- with(z,ave(seq_along(date),date,week,FUN=seq_along))

library(reshape2)
dcast(z,date+ID~week,value.var="length")[,-2]
??????? date 28 29
1? 7/13/2010 34 NA
2? 7/13/2010 35 NA
3? 7/14/2010 35 NA
4? 7/14/2010 35 NA
5? 7/14/2010 36 NA
6? 7/14/2010 36 NA
7? 7/16/2010 NA 34
8? 7/16/2010 NA 37
9? 7/18/2010 NA 34
10 7/18/2010 NA 34
11 7/18/2010 NA 37
12 7/20/2010 NA 31
13 7/20/2010 NA 36
14 7/20/2010 NA 37
15 7/21/2010 NA 35
16 7/21/2010 NA 36
17 7/21/2010 NA 37
18 7/21/2010 NA 37
19 7/22/2010 NA 36
20 7/22/2010 NA 37
21 7/22/2010 NA 37

##Also, didn't got any error with ?reshape()
If you don't want the `dates`, then:
?z$ID <- with(z,ave(seq_along(week),week,FUN=seq_along))
dcast(z,ID~week,value.var="length")[,-1]
?? 28 29
1? 34 31
2? 35 34
3? 35 34
4? 35 34
5? 36 35
6? 36 36
7? NA 36
8? NA 36
9? NA 37
10 NA 37
11 NA 37
12 NA 37
13 NA 37
14 NA 37
15 NA 37

A.K.
?



On Sunday, November 17, 2013 3:57 AM, Felipe Carrillo <mazatlanmexico at yahoo.com> wrote:

Thanks Arun,
I
 tried and got an error message, also the first line of code is showing 
the date as column header but I only want the week as column header. You
 can get rid of the date, I only need the week as column header and the 
values below it.
?dcast(z,date+ID~week,value.var="length")[,-2]
? date 7/13/2010 7/14/2010 7/16/2010 7/18/2010 7/20/2010 7/21/2010 7/22/2010
1 2010??????? 28??????? 28??????? 29??????? 29??????? 29??????? 29??????? 29
2
2010??????? 28??????? 28??????? 29??????? 29??????? 29??????? 29??????? 29
3 2010??????? NA??????? 28??????? NA??????? 29??????? 29??????? 29??????? 29
4 2010??????? NA??????? 28??????? NA??????? NA??????? NA??????? 29???????
NA
> reshape(z,direction="wide",idvar=c("date","ID"),timevar="week")[,-2]
Error in `[.data.frame`(thistime, match(rval[, idvar], thistime[, idvar]),? : 
? undefined columns selected


My dataset?based on the "z" dataset should look like this:
28???? 29? <<<<<Column headers
35???? 31
35???? 34
35???? 34
36?????35
36???? 36
???????? 36
???????? 36
???????? 37
???????? 37
???????? 37
???????? 37
???????? 37
???????? 37
???????? 37


Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA
http://www.fws.gov/redbluff/rbdd_jsmp.aspx




On Sunday, November 17, 2013 12:27 AM, arun <smartpink111 at yahoo.com> wrote:

HI Felipe,
>May be this works for you:
>z$ID <- with(z,ave(seq_along(date),date,week,FUN=seq_along))
>
>library(reshape2)
>dcast(z,date+ID~week,value.var="length")[,-2]
>
>#or
>reshape(z,direction="wide",idvar=c("date","ID"),timevar="week")[,-2]
>
>
>A.K.
>
>
>
>
>
>
>
>
>
>
>On Sunday, November 17, 2013 1:24 AM, Felipe Carrillo <mazatlanmexico at yahoo.com> wrote:
>
>
>
>Hello Arun, I was wondering if you can help me with this question
>
>?How can I put the values of week(28,29) as column headers
>and put the corresponding length values on each week number?
>I heard about dcast but don't know how to use it yet.
>z <-read.table(text="date week length
>7/13/2010?? 28???? 34
>7/13/2010?? 28???? 35
>7/14/2010??
28???? 35
>7/14/2010?? 28???? 35
>7/14/2010?? 28???? 36
>7/14/2010?? 28???? 36
>7/20/2010?? 29???? 31
>7/16/2010?? 29???? 34
>7/18/2010?? 29???? 34
>7/18/2010?? 29???? 34
>7/21/2010?? 29???? 35
>7/20/2010?? 29???? 36
>7/21/2010?? 29???? 36
>7/22/2010?? 29???? 36
>7/16/2010?? 29???? 37
>7/18/2010?? 29???? 37
>7/20/2010??
29????
>37
>7/21/2010?? 29???? 37
>7/21/2010?? 29???? 37
>7/22/2010?? 29???? 37
>7/22/2010?? 29???? 37",header=TRUE)
>
>
>
>
>
>
>
>
>
>
>
>Felipe D. Carrillo
>Supervisory Fishery Biologist
>Department of the Interior
>US Fish & Wildlife Service
>California, USA
>http://www.fws.gov/redbluff/rbdd_jsmp.aspx
>
>


From spencer.graves at structuremonitoring.com  Sun Nov 17 17:04:24 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 17 Nov 2013 08:04:24 -0800
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <002e01cee3a4$d6452340$82cf69c0$@mcmaster.ca>
References: <528827A4.5080309@prodsyse.com>
	<002e01cee3a4$d6452340$82cf69c0$@mcmaster.ca>
Message-ID: <5288E908.3070709@structuremonitoring.com>

Hi, John:  Thanks very much.  That sounds like pretty close to what my 
friend needs -- especially the comparison of Rcmdr with SPSS.  (My 
friend teaches at Santa Clara University, a private university supported 
by the Catholic Church located in Santa Clara, California.  I don't 
know, but I'd guess that their freshmen tend to be more advanced than 
those at community colleges or public universities that don't stress 
research like the University of California or McMaster.)  Spencer


On 11/17/2013 6:53 AM, John Fox wrote:
> Dear Spencer,
>
> I regularly use R (via the R Commander) for intro stats courses taught to
> third-year sociology undergrads (in Canada). Without knowing where your
> friend teaches, it's hard to know what her students are like, but in my
> experience psychology students are generally more numerate than sociology
> students, and first-year students would likely have a bit more trouble with
> the course than third-year students. That your friend's department teaches
> this course in the first year suggests that it, and possibly its students,
> have a quantitative orientation.
>
> I've also used a variety of statistical software to teach intro stats,
> including SPSS. I originally wrote the Rcmdr package so that I could use R
> instead, and I find that students have no more trouble pointing and clicking
> in the R Commander than they do in SPSS. It's also my experience that
> computing, regardless of the software that I've used, is the least
> problematic part of the course. It's much harder for students to understand
> statistical concepts, and even to apply simple formulas correctly, than to
> use menu-driven statistical software.
>
> If you'd like to take a look at the course website for my undergrad class
> the last time I taught it in 2011-2012, it's at
> <http://socserv.socsci.mcmaster.ca/jfox/Courses/soc3h6/index.html>. I'm
> currently teaching essentially the same course, but for grad students in an
> accelerated one-semester format, and that's at
> <http://socserv.socsci.mcmaster.ca/jfox/Courses/soc6z3/index.html>. You'll
> notice that in the grad class, students use their own computers, while in
> the undergrad class, they use a computer lab. That decision relates more to
> the size of the class (about 200 undergrads divided into four labs, 10 grad
> students) than to the level of the students.
>
> I hope this helps,
>   John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Spencer Graves
>> Sent: Saturday, November 16, 2013 9:19 PM
>> To: R list
>> Subject: [R] R for a stats intro for undergrads in the US?
>>
>> Hello, All:
>>
>>
>>         Would anyone recommend R for an introductory statistics class
>> for
>> freshman psychology students in the US?  If yes, might there be any
>> notes for such available?
>>
>>
>>         I just checked r-projects.org and CRAN contributed documentation
>> and found nothing.
>>
>>
>>         I have a friend who teaches such a class, and wondered if R
>> might
>> be suitable.  The alternative is SPSS at $406 per student.
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From ronjaq at gmx.net  Sun Nov 17 15:50:03 2013
From: ronjaq at gmx.net (Stageexp)
Date: Sun, 17 Nov 2013 06:50:03 -0800 (PST)
Subject: [R] Apply function to one specific column / Alternative to for
	loop
In-Reply-To: <1384626267.51320.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1384615829390-4680566.post@n4.nabble.com>
	<1384626267.51320.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1384699803079-4680621.post@n4.nabble.com>


Hi,
Try:
indx <- grep("Test",test_df[,1])? ##assuming that there is some pattern
?res <- within(test_df[-indx,],titel <- rep(test_df$titel[indx],
diff(c(indx,nrow(test_df)+1))-1))

## If you need to change the class

res[] <- lapply(res,function(x) if(any(grepl("[[:alpha:]]",x)))
as.character(x) else as.numeric(as.character(x)))


##Using data.frame(cbind()), etc. creates 


A.K.


This option worked great for me! I knew there was a nicer and much faster
way to solve this. One thing I already learned about R: Never use for-loops,
there is always a better way :-)



--
View this message in context: http://r.789695.n4.nabble.com/Apply-function-to-one-specific-column-Alternative-to-for-loop-tp4680566p4680621.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Sun Nov 17 17:48:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 08:48:44 -0800 (PST)
Subject: [R] Extract values from vector and repeat by group
In-Reply-To: <3B2391BE-2814-4079-97C8-4EFD097BCE0D@xs4all.nl>
References: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
	<3B2391BE-2814-4079-97C8-4EFD097BCE0D@xs4all.nl> 
Message-ID: <1384706924.15570.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

?merge() sometimes change the order.
For example:
df1 <- df[-12,]
df2 <- df1

merge(df1, df1[df1$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))

In that case,

df1$ord1 <- with(df1,order(group,time))
res <- merge(df1, df1[df1$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))
res[order(res$ord1),-4]


#or just
library(plyr)
join(df2,df2[df2$time==4,c("group","var")],by="group",type="inner")


#or you may use:

indx <- with(df1,ave(time==4,group,FUN=any))

?ddply(df1[indx,],.(group),mutate,new=var[time==4])

A.K.






On Sunday, November 17, 2013 10:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:

On 17-11-2013, at 15:47, Benjamin Gillespie <gybrg at Leeds.ac.uk> wrote:

> Hi all,
> 
> I hope you can help.
> 
> I have a data frame 'df':
> 
> group=c(rep(1,8),rep(2,10),rep(3,11))
> var=rnorm(29)
> time=c(seq(1,8),seq(1,10),seq(1,11))
> df=data.frame(group,var,time)
> 
> I would like to extract the value from 'var' for each 'group' at 'time'=4 and repeat these extracted values in a new vector ('new') n times where n is the number of rows for each group. I did this by hand as below, but there must be a quicker way:
> 
> subset=subset(df,df$time==4)
> subset
> group? ? ? ? var time
> 4? ? ? 1? 0.2531270? ? 4
> 12? ?? 2 -0.3600128? ? 4
> 22? ?? 3? 0.4194730? ? 4
> 
> df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))
> 
> Any questions please ask,

A very similar question was recently asked on Stackoverflow: http://stackoverflow.com/questions/19971763/r-programming-normalizing-a-column-of-data-by-another-entry-in-2-other-columns

From the answer given there you could try this

set.seed(11) # to make it reproducible

group=c(rep(1,8),rep(2,10),rep(3,11))
var=rnorm(29)
time=c(seq(1,8),seq(1,10),seq(1,11))
df=data.frame(group,var,time)

#df
#df[df$time==4, c("group", "var")]

# merge into original data.frame
df <- merge(df, df[df$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))
df

Berend


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From yuanzhi.li at usherbrooke.ca  Sun Nov 17 18:11:28 2013
From: yuanzhi.li at usherbrooke.ca (yuanzhi)
Date: Sun, 17 Nov 2013 09:11:28 -0800 (PST)
Subject: [R] volume of ellipsoid
In-Reply-To: <52862CA1.8090001@yorku.ca>
References: <20131113173106.180469aq55kiz9oo@www.usherbrooke.ca>
	<1384431926676-4680435.post@n4.nabble.com>
	<1384439709454-4680445.post@n4.nabble.com>
	<52862CA1.8090001@yorku.ca>
Message-ID: <1384708288189-4680631.post@n4.nabble.com>

Michael Friendly wrote
> On 11/14/2013 9:35 AM, yuanzhi wrote:
>> Hi, Carl Witthoft
>>
>> yes, it looks like a mathematical question. I will try based on your
>> suggestion to calculate the volume of the intersection. But I still want
>> to
>> know whether there are some functions in R which can calculate the volume
>> of
>> an ellipsoid(area for p=2, hypervolume for p>3) containing X, just like
>> the
>> "convhulln" function in "geometry" package which can calculate the volume
>> of
>> convex hull containing X.
>>
> 
> See the Appendix A.2 in my paper on Elliptical Insights ...
> http://www.datavis.ca/papers/ellipses-STS402.pdf
> 
> for the properties of ellipsoids and calculation of (hyper)volumes
> based on a spectral decomposition.
> 
> The intersection of general ellipsoids is mathematically extremely 
> complex.  You can approximate it by acceptance sampling -- finding the
> proportion of random points in R^p in the bounding box of the ellipsoids 
> which are contained in both.
> 
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Thank you for your reply. I think it is a good idea to calculate the volume
in Monte-Carlo method. So the the problem change to be have to quantify
whether a point is inside or outside of a region. Yes, it is easy to
determine a point inside or outside a ellipsoid by seeing whether
(x-x0)'?^(-1)(x-x0)-?2p(?) is greater or smaller than zero, where x0 the
point we want to test. but how can we test whether a point in other shapes
of region(like the bounding box(R^p) as you said or the smallest convex
hull(R^p) of X)? Finally, I aslo want to know how calculate the hypervolume
of the bounding box (when P>3)? Thank you again.



--
View this message in context: http://r.789695.n4.nabble.com/volume-of-ellipsoid-tp4680409p4680631.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Sun Nov 17 18:50:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 09:50:38 -0800 (PST)
Subject: [R] reshape
In-Reply-To: <1384702691.34456.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1384702691.34456.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1384710638.66191.YahooMailNeo@web142604.mail.bf1.yahoo.com>


Hi Felipe,
You may try ?mutate() with ?ddply() from library(plyr)
library(plyr)
library(reshape2)

res <- dcast(ddply(z,.(week),mutate,ID=seq_along(week)),ID~week,value.var="length")[,-1]

If you have multiple years, probably you may need:
z1 <- z ##using the same example
z1[,1] <- gsub("(.\\/.*\\/).*","\\1/2011",z1[,1]) ##changed the year
?z2 <- rbind(z,z1)

?res1 <- dcast(ddply(z2,.(year=gsub(".*\\/.*\\/","",date),week),mutate,ID=seq_along(week)),ID+year~week,value.var="length")

res1[with(res1,order(year,ID)),-1]

A.K.



On Sunday, November 17, 2013 12:00 PM, Felipe Carrillo <mazatlanmexico at yahoo.com> wrote:

The last one without the date seems to work for me, I have multiple years, I will try it on a bigger dataset.
I guess the trick is adding "ID" to the dataset with ave.? Is there anything similar to 'ave' in plyr?
Thanks Arun for your help, really appreciate it.

Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA
http://www.fws.gov/redbluff/rbdd_jsmp.aspx



On Sunday, November 17, 2013 10:38 AM, arun <smartpink111 at yahoo.com> wrote:
Felipe,

I get the results like this by running the code:
z <-read.table(text="date week length
7/13/2010 28 34
7/13/2010 28 35
7/14/2010 28 35
7/14/2010 28 35
7/14/2010 28 36
7/14/2010 28 36
7/20/2010 29 31
7/16/2010 29 34
7/18/2010 29 34
7/18/2010 29 34
7/21/2010 29 35
7/20/2010 29 36
7/21/2010 29 36
7/22/2010 29 36
7/16/2010 29 37
7/18/2010 29 37
7/20/2010 29 37
7/21/2010 29 37
7/21/2010 29 37
7/22/2010 29 37
7/22/2010 29 37",header=TRUE)

z$ID <- with(z,ave(seq_along(date),date,week,FUN=seq_along))

library(reshape2)
dcast(z,date+ID~week,value.var="length")[,-2]
??????? date 28 29
1? 7/13/2010 34 NA
2? 7/13/2010 35 NA
3? 7/14/2010 35 NA
4? 7/14/2010 35 NA
5? 7/14/2010 36 NA
6? 7/14/2010 36 NA
7? 7/16/2010 NA 34
8? 7/16/2010 NA 37
9? 7/18/2010 NA 34
10 7/18/2010 NA 34
11 7/18/2010 NA 37
12 7/20/2010 NA 31
13 7/20/2010 NA 36
14 7/20/2010 NA 37
15 7/21/2010 NA 35
16 7/21/2010 NA 36
17 7/21/2010 NA 37
18 7/21/2010 NA 37
19 7/22/2010 NA 36
20 7/22/2010 NA 37
21 7/22/2010 NA 37

##Also, didn't got any error with ?reshape()
If you don't want the `dates`, then:
?z$ID <- with(z,ave(seq_along(week),week,FUN=seq_along))
dcast(z,ID~week,value.var="length")[,-1]
?? 28 29
1? 34 31
2? 35 34
3? 35 34
4? 35 34
5? 36 35
6? 36 36
7? NA 36
8? NA 36
9? NA 37
10 NA 37
11 NA 37
12 NA 37
13 NA 37
14 NA 37
15 NA 37

A.K.


From smartpink111 at yahoo.com  Sun Nov 17 19:27:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 10:27:07 -0800 (PST)
Subject: [R] creating upper triangular matrix
Message-ID: <1384712827.36496.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1 <- read.table(text="
data data freq
1?????? 2???? 2
1?????? 3???? 1
1?????? 4???? 1
2?????? 3???? 2
2?????? 4???? 1
2?????? 2???? 1
3????? 4?????? 2",sep="",header=TRUE) 
val<- unique(c(dat1[,1],dat1[,2]))
dat2 <-expand.grid(data=val,data.1=val)
library(plyr)
library(reshape2)
res <- dcast(join(dat2,dat1),data~data.1,value.var="freq",fill=0)
row.names(res) <- res[,1]
res1 <- as.matrix(res[,-1])
diag(res1) <-0

#or
?m1 <- matrix(0,length(val),length(val),dimnames=list(val,val))

?indx1 <- outer(colnames(m1),rownames(m1),paste,sep="")
?indx2 <- paste0(dat1[,1],dat1[,2])
m1[match(indx2,indx1)] <- dat1[,3]
?diag(m1) <- 0
?m1
#? 1 2 3 4
#1 0 2 1 1
#2 0 0 2 1
#3 0 0 0 2
#4 0 0 0 0

A.K.


Hello , 
I am working on a project , 
i need to create an upper triangular matrix from the data in this form; 
data data freq 
1 ? ? ? 2 ? ? 2 
1 ? ? ? 3 ? ? 1 
1 ? ? ? 4 ? ? 1 
2 ? ? ? 3 ? ? 2 
2 ? ? ? 4 ? ? 1 
2 ? ? ? 2 ? ? 1 
3 ? ? ?4 ? ? ? 2 

?to a triangular matrix in the following form : 
? ? ?1 ? 2 ? ?3 ? 4 
1 ? ?0 ?2 ? ?1 ? 1 
2 ? ?0 ?0 ? ?2 ? 1 
3 ? ?0 ?0 ? ?0 ? 2 
4 ? ?0 ?0 ? ?0 ? 0 

i am new to R please help 



From jlh.membership at gmail.com  Sun Nov 17 19:32:04 2013
From: jlh.membership at gmail.com (jlh.membership)
Date: Sun, 17 Nov 2013 13:32:04 -0500
Subject: [R] Calculate Range
In-Reply-To: <1384638589297-4680579.post@n4.nabble.com>
References: <1384638589297-4680579.post@n4.nabble.com>
Message-ID: <005601cee3c3$555932c0$000b9840$@gmail.com>

An approach using data tables:

###
library(data.table)
# dt: some data arranged by group
dt <- data.table(group=c(rep("a",5), rep("b",10), rep("c",15)), values=1:30)
# summarize by group
smry <- dt[,list(min=min(values), max=max(values), range=diff(range(values))), by="group"]
smry
###


-----Original Message-----
From: SCRIPTHAM [mailto:JML at CWAZY.CO.UK] 
Sent: Saturday, November 16, 2013 4:50 PM
To: r-help at r-project.org
Subject: [R] Calculate Range

Hi

My R version is the current version as at 15 Nov 2013.

I have tried to calculate range using tapply() with FUN=range.
tapply() returns two fields, the ID field and a field of two text items one is the maximum and the other is the minimum.
I take as the difference max - min, does R use a different term for range in tapply?

I have also tried
aggregate() with Fun=range, with Fun=min and FUN=max and they also gave problems.

What is the best route to calculate ranges for groups within a data frame.

Thanks.
Scriptham.






--
View this message in context: http://r.789695.n4.nabble.com/Calculate-Range-tp4680579.html
Sent from the R help mailing list archive at Nabble.com.


From erinm.hodgess at gmail.com  Sun Nov 17 23:07:36 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 17 Nov 2013 16:07:36 -0600
Subject: [R] quotation marks and scan
Message-ID: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/72494cf6/attachment.pl>

From r.turner at auckland.ac.nz  Sun Nov 17 23:38:30 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 18 Nov 2013 11:38:30 +1300
Subject: [R] quotation marks and scan
In-Reply-To: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
References: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
Message-ID: <52894566.9020709@auckland.ac.nz>


(1) The backslashes are not really there; they are an artefact of the R 
print() function.
Try cat(u,"\n").  I think this might be an FAQ.

(2) Is not your problem the fact that your are setting "replacement" 
equal to the
thing you are trying to get rid of?  I.e. don't you want

     v <- gsub(pattern='\"',replacement='',x=u)     ???

Either I am misunderstanding your intent or you need another cup of coffee.

     cheers,

     Rolf

On 11/18/13 11:07, Erin Hodgess wrote:
> Dear R People:
>
> I'm sure that this is a very simple problem, but I have been wresting with
> it for some time.
>
> I have the following file that has the following one line:
>
>   CRS("+init=epsg:28992")
>
> Fair enough.  I scan it into R and get the following:
>
>> u
> [1] "CRS(\"+init=epsg:28992\")"
>> gsub(pattern='\"',replacement='"',x=u)
> [1] "CRS(\"+init=epsg:28992\")"
>
> I need to get rid of the extra quotation marks and slashes.  I've tried all
> sorts of things, including gsub, as you see,  but no good.


From michael.weylandt at gmail.com  Sun Nov 17 23:42:44 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Sun, 17 Nov 2013 17:42:44 -0500
Subject: [R] quotation marks and scan
In-Reply-To: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
References: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
Message-ID: <EF5D378F-BA5A-4CD8-86B6-22D51FDC5065@gmail.com>

They're not actually there so don't try too hard to rid yourself of them:

x <- "\'"

length(x)
print(x)
cat(x, "\n")

Make sure you're clear on the difference between what's stored by the computer and what it print()s. Rarely the same, though cat() is often slightly more honest. 

On Nov 17, 2013, at 17:07, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Dear R People:
> 
> I'm sure that this is a very simple problem, but I have been wresting with
> it for some time.
> 
> I have the following file that has the following one line:
> 
> CRS("+init=epsg:28992")
> 
> Fair enough.  I scan it into R and get the following:
> 
>> u
> [1] "CRS(\"+init=epsg:28992\")"
>> gsub(pattern='\"',replacement='"',x=u)
> [1] "CRS(\"+init=epsg:28992\")"
> 
> I need to get rid of the extra quotation marks and slashes.  I've tried all
> sorts of things, including gsub, as you see,  but no good.
> 
> Thank you for any help.
> 
> Sincerely,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Sun Nov 17 23:43:18 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 17 Nov 2013 16:43:18 -0600
Subject: [R] quotation marks and scan
In-Reply-To: <52894566.9020709@auckland.ac.nz>
References: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
	<52894566.9020709@auckland.ac.nz>
Message-ID: <CACxE24k9Ntm=ywbmRNQxUubO37hzrYgR45PPFpsRBMan3XgJDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/d4599d97/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Mon Nov 18 00:24:36 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 17 Nov 2013 23:24:36 +0000
Subject: [R] quotation marks and scan
In-Reply-To: <2361ab4e17c846699156850daa665091@EX-1-HT0.lancs.local>
References: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
	<2361ab4e17c846699156850daa665091@EX-1-HT0.lancs.local>
Message-ID: <CANVKczPX40yWSEW_a=YR5Mv2NpFRr-rU+hEA3Ls3XLsXQRz+DQ@mail.gmail.com>

On Sun, Nov 17, 2013 at 10:42 PM, R. Michael Weylandt
<michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
> They're not actually there so don't try too hard to rid yourself of them:
>
> x <- "\'"
>
> length(x)
> print(x)
> cat(x, "\n")

 Did you mean to do 'nchar(x)' to show that \" was one character?
'length' gives the number of elements in a vector, which in this case
is also one.

 > x=c("\"", '\'')
 > length(x)
 [1] 2
 > nchar(x)
 [1] 1 1


From erinm.hodgess at gmail.com  Mon Nov 18 00:37:28 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 17 Nov 2013 17:37:28 -0600
Subject: [R] more rpy2 questions...mostly R
Message-ID: <CACxE24mGKjq-DUCgx654MqBnv3ctAepJndyr14bbey3bDHTKiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/7164478f/attachment.pl>

From Ted.Harding at wlandres.net  Mon Nov 18 00:55:51 2013
From: Ted.Harding at wlandres.net (Ted Harding)
Date: Sun, 17 Nov 2013 23:55:51 +0000
Subject: [R] Fortune? [was: Re:  quotation marks and scan]
In-Reply-To: <52894566.9020709@auckland.ac.nz>
Message-ID: <XFMail.20131117235551.Ted.Harding@wlandres.net>

[See in-line below]
On 17-Nov-2013 22:38:30 Rolf Turner wrote:
> 
> (1) The backslashes are not really there; they are an artefact of the R 
> print() function.
> Try cat(u,"\n").  I think this might be an FAQ.
> 
> (2) Is not your problem the fact that your are setting "replacement" 
> equal to the
> thing you are trying to get rid of?  I.e. don't you want
> 
>      v <- gsub(pattern='\"',replacement='',x=u)     ???
> 


> Either I am misunderstanding your intent or you need another cup of coffee.

Is the above line a Fortune?


>      cheers,
> 
>      Rolf
> 
> On 11/18/13 11:07, Erin Hodgess wrote:
>> Dear R People:
>>
>> I'm sure that this is a very simple problem, but I have been wresting with
>> it for some time.
>>
>> I have the following file that has the following one line:
>>
>>   CRS("+init=epsg:28992")
>>
>> Fair enough.  I scan it into R and get the following:
>>
>>> u
>> [1] "CRS(\"+init=epsg:28992\")"
>>> gsub(pattern='\"',replacement='"',x=u)
>> [1] "CRS(\"+init=epsg:28992\")"
>>
>> I need to get rid of the extra quotation marks and slashes.  I've tried all
>> sorts of things, including gsub, as you see,  but no good.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 17-Nov-2013  Time: 23:55:48
This message was sent by XFMail


From gunter.berton at gene.com  Mon Nov 18 01:20:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 17 Nov 2013 16:20:26 -0800
Subject: [R] creating upper triangular matrix
In-Reply-To: <1384712827.36496.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1384712827.36496.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CACk-te2evBBU08cx0SCK3tGCkg6pwU75hTV7c9-s0z+RGYnaUw@mail.gmail.com>

I believe matrix indexing makes Arun's complex code wholly unnececessary:

Starting with dat1 as above:

m <- matrix(0,4,4)
m[as.matrix(dat1[,1:2])] <- dat1[,3]

## yielding:
m

     [,1] [,2] [,3] [,4]
[1,]    0    2    1    1
[2,]    0    1    2    1
[3,]    0    0    0    2
[4,]    0    0    0    0

If you want to get rid of any nonzero diagonal entries:

diag(m) <- 0 ## does it.

Cheers,
Bert





On Sun, Nov 17, 2013 at 10:27 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> May be this helps:
>
> dat1 <- read.table(text="
> data data freq
> 1       2     2
> 1       3     1
> 1       4     1
> 2       3     2
> 2       4     1
> 2       2     1
> 3      4       2",sep="",header=TRUE)
> val<- unique(c(dat1[,1],dat1[,2]))
> dat2 <-expand.grid(data=val,data.1=val)
> library(plyr)
> library(reshape2)
> res <- dcast(join(dat2,dat1),data~data.1,value.var="freq",fill=0)
> row.names(res) <- res[,1]
> res1 <- as.matrix(res[,-1])
> diag(res1) <-0
>
> #or
>  m1 <- matrix(0,length(val),length(val),dimnames=list(val,val))
>
>  indx1 <- outer(colnames(m1),rownames(m1),paste,sep="")
>  indx2 <- paste0(dat1[,1],dat1[,2])
> m1[match(indx2,indx1)] <- dat1[,3]
>  diag(m1) <- 0
>  m1
> #  1 2 3 4
> #1 0 2 1 1
> #2 0 0 2 1
> #3 0 0 0 2
> #4 0 0 0 0
>
> A.K.
>
>
> Hello ,
> I am working on a project ,
> i need to create an upper triangular matrix from the data in this form;
> data data freq
> 1       2     2
> 1       3     1
> 1       4     1
> 2       3     2
> 2       4     1
> 2       2     1
> 3      4       2
>
>  to a triangular matrix in the following form :
>      1   2    3   4
> 1    0  2    1   1
> 2    0  0    2   1
> 3    0  0    0   2
> 4    0  0    0   0
>
> i am new to R please help
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From jlh.membership at gmail.com  Mon Nov 18 02:22:34 2013
From: jlh.membership at gmail.com (jlh.membership)
Date: Sun, 17 Nov 2013 20:22:34 -0500
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <528827A4.5080309@prodsyse.com>
References: <528827A4.5080309@prodsyse.com>
Message-ID: <000301cee3fc$ae6261f0$0b2725d0$@gmail.com>

Googling "R for psychology students" I found this: 
http://health.adelaide.edu.au/psychology/ccs/docs/lsr/lsr-0.3.pdf

and this:
https://personality-project.org/r/

The latter has links to many short courses and tutorials.

If you do end up using R, I find the following sites extremely helpful:
Quick-R <http://www.statmethods.net/> : (http://www.statmethods.net/)has a very intuitive layout with lots of really helpful
examples.
Cookbook for R <http://www.cookbook-r.com/> : (http://www.cookbook-r.com/) is organized around showing you how to do specific
things.

Know that R is a command driven language, so no "point and click" really - you have to learn the commands which does make for a
learning curve. Still, most basic statistics and a lot of not so basic statistics can be generated with just a few commands. I would
also recommend having students install R-studio <http://www.rstudio.com/>  (http://www.rstudio.com/) in addition to R (there's
controversy about this - many people hate R-Studio). I find it very helpful in organizing work sessions, inspecting datasets,
locating files, etc. 

Good luck with it.

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at prodsyse.com] 
Sent: Saturday, November 16, 2013 9:19 PM
To: R list
Subject: [R] R for a stats intro for undergrads in the US?

Hello, All:


       Would anyone recommend R for an introductory statistics class for freshman psychology students in the US?  If yes, might
there be any notes for such available?


       I just checked r-projects.org and CRAN contributed documentation and found nothing.


       I have a friend who teaches such a class, and wondered if R might 
be suitable.  The alternative is SPSS at $406 per student.


       Thanks,
       Spencer


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com



From andrewdigby at mac.com  Mon Nov 18 02:23:21 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Mon, 18 Nov 2013 14:23:21 +1300
Subject: [R] Inconsistent results between caret+kernlab versions
In-Reply-To: <CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>
References: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>
	<CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
	<CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>
Message-ID: <E2AF4DBC-1D59-4FA8-9940-C6FCA6B93E2A@mac.com>


Hi Max,

Thanks very much for investigating and explaining that - your help and time is much appreciated. 

So as I understand it, using classProbs=F in trainControl() will give me the same accuracy results as before. However, I was relying on the class probabilities to return ROC/sensitivity/specificity, using a custom function similar to twoClassSummary(). 

What I still don't quite understand is which accuracy values from train() I should trust: those using classProbs=T or classProbs=F? I'm using train() to compare different classification methods using several stats (accuracy, AUROC etc), but this issue means that suddenly SVM has got much worse (based on accuracy)! I guess this means that I should roll back to the earlier versions of caret and kernlab (which is a pain because then train often crashes with 'memory map' errors!)?

Thanks,

Andrew
 
On 16/11/2013, at 09:59 , Max Kuhn <mxkuhn at gmail.com> wrote:

> Or not!
> 
> The issue with with kernlab.
> 
> Background: SVM models do not naturally produce class probabilities. A
> secondary model (via Platt) is fit to the raw model output and a
> logistic function is used to translate the raw SVM output to
> probability-like numbers (i.e. sum to zero, between 0 and 1). In
> ksvm(), you need to use the option prob.model = TRUE to get that
> second model.
> 
> I discovered some time ago that there can be a discrepancy in the
> predicted classes that naturally come from the SVM model and those
> derived by using the class associated with the largest class
> probability. This is most likely do to natural error in the secondary
> probability model and should not be unexpected.
> 
> That is the case for your data. In you use the same tuning parameters
> as those suggested by train() and go straight to ksvm():
> 
>> newSVM <- ksvm(x = as.matrix(df[,-1]),
> +                y = df[,1],
> +                kernel = rbfdot(sigma = svm.m1$bestTune$.sigma),
> +                C = svm.m1$bestTune$.C,
> +                prob.model = TRUE)
>> 
>> predict(newSVM, df[43,-1])
> [1] O32078
> 10 Levels: O27479 O31403 O32057 O32059 O32060 O32078 ... O32676
>> predict(newSVM, df[43,-1], type = "probabilities")
>         O27479     O31403    O32057    O32059     O32060    O32078
> [1,] 0.08791826 0.05911645 0.2424997 0.1036943 0.06968587 0.1648394
>         O32089     O32663     O32668     O32676
> [1,] 0.04890477 0.05210836 0.09838892 0.07284396
> 
> Note that, based on the probability model, the class with the largest
> probability is O32057 (p = 0.24) while the basic SVM model predicts
> O32078 (p = 0.16).
> 
> Somebody (maybe me) saw this discrepancy and that led to me to follow this rule:
> 
> if(prob.model = TRUE) use the class with the maximum probability
>   else use the class prediction from ksvm().
> 
> Therefore:
> 
>> predict(svm.m1, df[43,-1])
> [1] O32057
> 10 Levels: O27479 O31403 O32057 O32059 O32060 O32078 ... O32676
> 
> That change occurred between the two caret versions that you tested with.
> 
> (On a side note, can also occur with ksvm() and rpart() if
> cost-sensitive training is used because the class designation takes
> into account the costs but the class probability predictions do not. I
> alerted both package maintainers to the issue some time ago.)
> 
> HTH,
> 
> Max
> 
> On Fri, Nov 15, 2013 at 1:56 PM, Max Kuhn <mxkuhn at gmail.com> wrote:
>> I've looked into this a bit and the issue seems to be with caret. I've
>> been looking at the svn check-ins and nothing stands out to me as the
>> issue so far. The final models that are generated are the same and
>> I'll try to figure out the difference.
>> 
>> Two small notes:
>> 
>> 1) you should set the seed to ensure reproducibility.
>> 2) you really shouldn't use character stings with all numbers as
>> factor levels with caret when you want class probabilities. It should
>> give you a warning about this
>> 
>> Max
>> 
>> On Thu, Nov 14, 2013 at 7:31 PM, Andrew Digby <andrewdigby at mac.com> wrote:
>>> 
>>> I'm using caret to assess classifier performance (and it's great!). However, I've found that my results differ between R2.* and R3.* - reported accuracies are reduced dramatically. I suspect that a code change to kernlab ksvm may be responsible (see version 5.16-24 here: http://cran.r-project.org/web/packages/caret/news.html). I get very different results between caret_5.15-61 + kernlab_0.9-17 and caret_5.17-7 + kernlab_0.9-19 (see below).
>>> 
>>> Can anyone please shed any light on this?
>>> 
>>> Thanks very much!
>>> 
>>> 
>>> ### To replicate:
>>> 
>>> require(repmis)  # For downloading from https
>>> df <- source_data('https://dl.dropboxusercontent.com/u/47973221/data.csv', sep=',')
>>> require(caret)
>>> svm.m1 <- train(df[,-1],df[,1],method='svmRadial',metric='Kappa',tunelength=5,trControl=trainControl(method='repeatedcv', number=10, repeats=10, classProbs=TRUE))
>>> svm.m1
>>> sessionInfo()
>>> 
>>> ### Results - R2.15.2
>>> 
>>>> svm.m1
>>> 1241 samples
>>>   7 predictors
>>>  10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676?
>>> 
>>> No pre-processing
>>> Resampling: Cross-Validation (10 fold, repeated 10 times)
>>> 
>>> Summary of sample sizes: 1116, 1116, 1114, 1118, 1118, 1119, ...
>>> 
>>> Resampling results across tuning parameters:
>>> 
>>>  C     Accuracy  Kappa  Accuracy SD  Kappa SD
>>>  0.25  0.684     0.63   0.0353       0.0416
>>>  0.5   0.729     0.685  0.0379       0.0445
>>>  1     0.756     0.716  0.0357       0.0418
>>> 
>>> Tuning parameter ?sigma? was held constant at a value of 0.247
>>> Kappa was used to select the optimal model using  the largest value.
>>> The final values used for the model were C = 1 and sigma = 0.247.
>>>> sessionInfo()
>>> R version 2.15.2 (2012-10-26)
>>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>>> 
>>> locale:
>>> [1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] e1071_1.6-1     class_7.3-5     kernlab_0.9-17  repmis_0.2.4    caret_5.15-61   reshape2_1.2.2  plyr_1.8        lattice_0.20-10 foreach_1.4.0   cluster_1.14.3
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] codetools_0.2-8 compiler_2.15.2 digest_0.6.0    evaluate_0.4.3  formatR_0.7     grid_2.15.2     httr_0.2        iterators_1.0.6 knitr_1.1       RCurl_1.95-4.1  stringr_0.6.2   tools_2.15.2
>>> 
>>> ### Results - R3.0.2
>>> 
>>>> require(caret)
>>>> svm.m1 <- train(df[,-1],df[,1],method=?svmRadial?,metric=?Kappa?,tunelength=5,trControl=trainControl(method=?repeatedcv?, number=10, repeats=10, classProbs=TRUE))
>>> Loading required package: class
>>> Warning messages:
>>> 1: closing unused connection 4 (https://dl.dropboxusercontent.com/u/47973221/df.Rdata)
>>> 2: executing %dopar% sequentially: no parallel backend registered
>>>> svm.m1
>>> 1241 samples
>>>   7 predictors
>>>  10 classes: ?O27479?, ?O31403?, ?O32057?, ?O32059?, ?O32060?, ?O32078?, ?O32089?, ?O32663?, ?O32668?, ?O32676?
>>> 
>>> No pre-processing
>>> Resampling: Cross-Validation (10 fold, repeated 10 times)
>>> 
>>> Summary of sample sizes: 1118, 1117, 1115, 1117, 1116, 1118, ...
>>> 
>>> Resampling results across tuning parameters:
>>> 
>>>  C     Accuracy  Kappa  Accuracy SD  Kappa SD
>>>  0.25  0.372     0.278  0.033        0.0371
>>>  0.5   0.39      0.297  0.0317       0.0358
>>>  1     0.399     0.307  0.0289       0.0323
>>> 
>>> Tuning parameter ?sigma? was held constant at a value of 0.2148907
>>> Kappa was used to select the optimal model using  the largest value.
>>> The final values used for the model were C = 1 and sigma = 0.215.
>>>> sessionInfo()
>>> R version 3.0.2 (2013-09-25)
>>> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>>> 
>>> locale:
>>> [1] en_NZ.UTF-8/en_NZ.UTF-8/en_NZ.UTF-8/C/en_NZ.UTF-8/en_NZ.UTF-8
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> other attached packages:
>>> [1] e1071_1.6-1     class_7.3-9     kernlab_0.9-19  repmis_0.2.6.2  caret_5.17-7    reshape2_1.2.2  plyr_1.8        lattice_0.20-24 foreach_1.4.1   cluster_1.14.4
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] codetools_0.2-8 compiler_3.0.2  digest_0.6.3    grid_3.0.2      httr_0.2        iterators_1.0.6 RCurl_1.95-4.1  stringr_0.6.2   tools_3.0.2
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> Max
> 
> 
> 
> -- 
> 
> Max


From mxkuhn at gmail.com  Mon Nov 18 02:42:46 2013
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sun, 17 Nov 2013 20:42:46 -0500
Subject: [R] Inconsistent results between caret+kernlab versions
In-Reply-To: <E2AF4DBC-1D59-4FA8-9940-C6FCA6B93E2A@mac.com>
References: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>
	<CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
	<CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>
	<E2AF4DBC-1D59-4FA8-9940-C6FCA6B93E2A@mac.com>
Message-ID: <CAJ9CoWnOC1oGHjCmow+kHE1WdgP3iHO106LnU1HC9W_7zfdJ+Q@mail.gmail.com>

Andrew,

> What I still don't quite understand is which accuracy values from train() I should trust: those using classProbs=T or classProbs=F?

It depends on whether you need the class probabilities and class
predictions to match (which they would if classProbs = TRUE).

Another option is to use a model where this discrepancy does not exist.

>  train often crashes with 'memory map' errors!)?

I've never seen that. You should describe it more.

Max


From cryan at binghamton.edu  Mon Nov 18 02:52:14 2013
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Sun, 17 Nov 2013 20:52:14 -0500
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <528827A4.5080309@prodsyse.com>
References: <528827A4.5080309@prodsyse.com>
Message-ID: <528972CE.9070905@binghamton.edu>

I would recommend it. I have no experience teaching statistics to
psychology students, but I have done a sequence of hands-on workshops
introducing R to a class of high school students who were engaged in a
three-year-long science research class. My presentations were not
discipline-specific, and we have just barely gotten into any real
statistical concepts so far. Mainly it was the nuts and bolts of how to
use base R; the advantages of writing and saving code over a
point-and-click interface, reproducible research and all; and a lot of
graphics. End of last session we just started to tackle the concepts of
sample versus population, and sampling variation.  I could share with
you my org file where I stored all the commands and notes, if it would
be of any use.

--Chris Ryan
SUNY Upstate Medical University
Binghamton, NY

Spencer Graves wrote:
> Hello, All:
> 
> 
>       Would anyone recommend R for an introductory statistics class for
> freshman psychology students in the US?  If yes, might there be any
> notes for such available?
> 
> 
>       I just checked r-projects.org and CRAN contributed documentation
> and found nothing.
> 
> 
>       I have a friend who teaches such a class, and wondered if R might
> be suitable.  The alternative is SPSS at $406 per student.
> 
> 
>       Thanks,
>       Spencer
> 
>


From Peter.Brecknock at bp.com  Mon Nov 18 02:58:35 2013
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Sun, 17 Nov 2013 17:58:35 -0800 (PST)
Subject: [R] midpoint between two dates
In-Reply-To: <1384735136435-4680649.post@n4.nabble.com>
References: <1384735136435-4680649.post@n4.nabble.com>
Message-ID: <1384739915975-4680654.post@n4.nabble.com>

eric wrote
> Is there an easy way to get the midpoint between two dates in a data frame
> ? If I have a dataframe that looks like this :
> 
>  head(x)
>       instDay     remDay exp.time mpy
> 1  2006-02-02 2006-04-03       60 0.2
> 2  2006-04-17 2006-08-17      122 0.3
> 4  2006-08-17 2006-10-23       67 0.4
> 6  2006-10-23 2007-04-03      162 0.3
> 8  2007-04-03 2007-05-15       42 0.8
> 11 2007-05-15 2007-08-01       78 0.3
> 
> I would like an additional column that represents the midpoint between
> instDay and newDay. For those days where the time difference is an odd
> number and the midpoint would not be a specific date, it would be OK to
> round up or round down.
> 
> I thought about converting both columns to numeric values and taking the
> difference, dividing by two with modulus operator, then adding to the
> first column and finally converting back to a date. But I'm think there
> must be a more simple way.

How about ...

date1 = as.Date(c("2013-10-10","2013-11-15","2013-12-25"))
date2 = as.Date(c("2013-10-20","2013-11-20","2013-12-30"))

df <- data.frame(id=c(1,2,3),date1,date2)
df$mid <- df$date1 + floor((df$date2-df$date1)/2)

print(df)

  id      date1      date2        mid
1  1 2013-10-10 2013-10-20 2013-10-15
2  2 2013-11-15 2013-11-20 2013-11-17
3  3 2013-12-25 2013-12-30 2013-12-27


HTH

Pete

 



--
View this message in context: http://r.789695.n4.nabble.com/midpoint-between-two-dates-tp4680649p4680654.html
Sent from the R help mailing list archive at Nabble.com.


From zilefacelvis at yahoo.com  Mon Nov 18 03:30:30 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 17 Nov 2013 18:30:30 -0800 (PST)
Subject: [R] melt dataframe
In-Reply-To: <1384673125.4173.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1384662485.32144.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1384673125.4173.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1384741830.24700.YahooMailNeo@web160606.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/8e2acaca/attachment.pl>

From michael.weylandt at gmail.com  Mon Nov 18 03:51:36 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Sun, 17 Nov 2013 21:51:36 -0500
Subject: [R] quotation marks and scan
In-Reply-To: <CANVKczPX40yWSEW_a=YR5Mv2NpFRr-rU+hEA3Ls3XLsXQRz+DQ@mail.gmail.com>
References: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
	<2361ab4e17c846699156850daa665091@EX-1-HT0.lancs.local>
	<CANVKczPX40yWSEW_a=YR5Mv2NpFRr-rU+hEA3Ls3XLsXQRz+DQ@mail.gmail.com>
Message-ID: <CAAmySGPB18Cvxm=f3hanSn+2pk422uRnsyOwX9h1gtmGsoTh5g@mail.gmail.com>

On Sun, Nov 17, 2013 at 6:24 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Sun, Nov 17, 2013 at 10:42 PM, R. Michael Weylandt
> <michael.weylandt at gmail.com> <michael.weylandt at gmail.com> wrote:
>  Did you mean to do 'nchar(x)' to show that \" was one character?
> 'length' gives the number of elements in a vector, which in this case
> is also one.
>
>  > x=c("\"", '\'')
>  > length(x)
>  [1] 2
>  > nchar(x)
>  [1] 1 1

D'oh! Fair enough,

MW


From collinl at cs.pitt.edu  Mon Nov 18 04:17:12 2013
From: collinl at cs.pitt.edu (Collin Lynch)
Date: Sun, 17 Nov 2013 22:17:12 -0500
Subject: [R] more rpy2 questions...mostly R
In-Reply-To: <CACxE24mGKjq-DUCgx654MqBnv3ctAepJndyr14bbey3bDHTKiA@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.1311172212400.18544-100000@aluminum.cs.pitt.edu>

Erin, at first glance I would say that this is an R error.  When Rpy2
detects an error it will pass it through errors as library errors like
this.  At first glance it appears that your r code is not loading the
requisite packages as it cannot find them.  That I suspect is what is
causing your coordinates error.

I would first run R and confirm that you can load the requisite libraries
in it before depending upon them in rpy2.  In general I find that rpy2 is
a bad interface for debugging R code and you need to run it in R first to
get the problems out.

	Best,
	Collin.

On Sun, 17 Nov 2013, Erin Hodgess wrote:

> Hello again!
>
> I'm using python, rpy2, and R for a project.  It's actually pretty
> interesting.  Anyhow, I pass in an R file to the python program.  However,
> I am getting the following errors, which seem more like R errors(?):
>
> Loading required package: gstat
> Loading required package: automap
> Error in coordinates(x.df) <- ~x + y :
>   could not find function "coordinates<-"
> In addition: Warning messages:
> 1: In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
>   there is no package called ?gstat?
> 2: In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
>   there is no package called ?automap?
> Traceback (most recent call last):
>   File "reg4.py", line 38, in <module>
>     spat1.spat1(file1=file1,file2=file2)
>   File "/usr/local/lib/python2.7/site-packages/rpy2/robjects/functions.py",
> line 86, in __call__
>     return super(SignatureTranslatedFunction, self).__call__(*args,
> **kwargs)
>   File "/usr/local/lib/python2.7/site-packages/rpy2/robjects/functions.py",
> line 35, in __call__
>     res = super(Function, self).__call__(*new_args, **new_kwargs)
> rpy2.rinterface.RRuntimeError: Error in coordinates(x.df) <- ~x + y :
>   could not find function "coordinates<-"
>
> I've checked and gstat and automap are both there.  Here is the actual R
> code:
> spat1 <- function(file1,file2) {
>     require(gstat)
>     require(automap)
>     x.df <- read.table(file=file1,header=TRUE)
>     coordinates(x.df) <- ~x+y
>     zz <- scan(file=file2,what="character")
>     proj4string(x.df) <- zz
>     png(file="map1.png")
>     u <- autoKrige(x.df at data[,1]~1,x.df)
>     plot(u)
>     return(u)
> }
>
>
> I know that there are a few people who have used both rpy2, python and R,
> so I thought I'd launch this out.
>
> Thanks in advance for any help.
>
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
> 	[[alternative HTML version deleted]]
>
>


From andrewdigby at mac.com  Mon Nov 18 04:46:29 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Mon, 18 Nov 2013 16:46:29 +1300
Subject: [R] Inconsistent results between caret+kernlab versions
In-Reply-To: <CAJ9CoWnOC1oGHjCmow+kHE1WdgP3iHO106LnU1HC9W_7zfdJ+Q@mail.gmail.com>
References: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>
	<CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
	<CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>
	<E2AF4DBC-1D59-4FA8-9940-C6FCA6B93E2A@mac.com>
	<CAJ9CoWnOC1oGHjCmow+kHE1WdgP3iHO106LnU1HC9W_7zfdJ+Q@mail.gmail.com>
Message-ID: <85F1F58D-EC97-48A8-BA84-8EB3C2E7BC96@mac.com>


OK, thanks.

I haven't reported the memory map errors because I haven't been able to replicate them reliably: some times they occur, but some times don't, for the same code. I'll have another try, and will report if I can get more information.

Thanks again.

On 18/11/2013, at 14:42 , Max Kuhn <mxkuhn at gmail.com> wrote:

> Andrew,
> 
>> What I still don't quite understand is which accuracy values from train() I should trust: those using classProbs=T or classProbs=F?
> 
> It depends on whether you need the class probabilities and class
> predictions to match (which they would if classProbs = TRUE).
> 
> Another option is to use a model where this discrepancy does not exist.
> 
>> train often crashes with 'memory map' errors!)?
> 
> I've never seen that. You should describe it more.
> 
> Max


From smartpink111 at yahoo.com  Mon Nov 18 04:30:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 17 Nov 2013 19:30:14 -0800 (PST)
Subject: [R] Calculate Range
In-Reply-To: <1384638589297-4680579.post@n4.nabble.com>
References: <1384638589297-4680579.post@n4.nabble.com>
Message-ID: <1384745414.92830.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You may also check:
library(psych)
library(plyr)
df1 <- data.frame(group=rep(letters[1:3],c(5,10,15)), values=1:30)
ddply(df1,.(group),mutate,Range=describe(values)$range) ##depends on how you wanted the output
#or
ddply(df1,.(group),summarise,Range=describe(values)$range)
#or
with(df1,describeBy(values,group,mat=TRUE))[,c("group1","range")]
A.K.




On Sunday, November 17, 2013 12:02 AM, SCRIPTHAM <JML at CWAZY.CO.UK> wrote:
Hi

My R version is the current version as at 15 Nov 2013.

I have tried to calculate range using tapply() with FUN=range.
tapply() returns two fields, the ID field and a field of two text items one
is the maximum and the other is the minimum.
I take as the difference max - min, does R use a different term for range in
tapply?

I have also tried
aggregate() with Fun=range, with Fun=min and FUN=max 
and they also gave problems.

What is the best route to calculate ranges for groups within a data frame.

Thanks.
Scriptham.






--
View this message in context: http://r.789695.n4.nabble.com/Calculate-Range-tp4680579.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tolga.uzuner at gmail.com  Mon Nov 18 05:35:28 2013
From: tolga.uzuner at gmail.com (Tolga Uzuner)
Date: Sun, 17 Nov 2013 23:35:28 -0500
Subject: [R] 2D Interpolation with missing values
Message-ID: <52899910.8030601@gmail.com>

Dear R Users,
I have a 7x16 matrix with missing values. I'd like to do some kind of 
2-d surface fitting/interpolation to fill in the missing values, while 
guaranteeing that they are positive. Most grateful if someone could 
point me in the right direction.
Thanks in advance

Sample matrix below and attached as a .RData file.

 > foo
            1        2         3         4         5 6         7        
8        9       10       11        12       13
2         NA 55.75417        NA  43.44104  59.44768  55.34285 58.53618 
118.8807 111.1920 154.5540 127.3393  88.04989 241.7025
5         NA 77.64135  56.57198  61.53534 116.10166 136.96051 133.25444 
170.6501 241.7467 285.3510 357.0217 368.97401 477.4639
7   83.90995 93.68244  85.06739 131.15748 171.57145 147.81372 181.51127 
224.6683 275.8416 334.7789 386.1349 425.45739 458.5685
10        NA       NA 103.18350 161.03391 159.35678 168.12955 179.35892 
212.2448 270.1914 310.5895 360.8537 415.83569 479.2682
15        NA       NA        NA        NA 198.25427 168.32441 188.73329 
213.6808 225.3273 268.5376       NA        NA       NA
30        NA       NA        NA 136.19717 173.22215 169.56444 194.79908 
265.9728 295.3250 344.5198 310.4714        NA       NA
100       NA       NA        NA        NA        NA        NA NA       
NA       NA       NA       NA 500.12256       NA
           14       15       16
2   514.5015 559.6716       NA
5   645.0066 748.5740 831.9362
7   660.0408 828.3243 580.3799
10  520.8122 884.3661 705.2931
15        NA       NA       NA
30        NA       NA       NA
100       NA       NA       NA
 >

From irafuchs at gmail.com  Mon Nov 18 05:37:53 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Sun, 17 Nov 2013 23:37:53 -0500
Subject: [R] Sending a matrix in an email
Message-ID: <924B3085-E423-443A-9418-0E8A0207B1E6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131117/515db3da/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Mon Nov 18 08:41:49 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 18 Nov 2013 08:41:49 +0100
Subject: [R] Fortune? [was: Re:  quotation marks and scan]
In-Reply-To: <XFMail.20131117235551.Ted.Harding@wlandres.net>
References: <XFMail.20131117235551.Ted.Harding@wlandres.net>
Message-ID: <alpine.DEB.2.10.1311180841290.32112@paninaro.uibk.ac.at>

On Sun, 17 Nov 2013, Ted Harding wrote:

> [See in-line below]
> On 17-Nov-2013 22:38:30 Rolf Turner wrote:
>>
>> (1) The backslashes are not really there; they are an artefact of the R
>> print() function.
>> Try cat(u,"\n").  I think this might be an FAQ.
>>
>> (2) Is not your problem the fact that your are setting "replacement"
>> equal to the
>> thing you are trying to get rid of?  I.e. don't you want
>>
>>      v <- gsub(pattern='\"',replacement='',x=u)     ???
>>
>
>
>> Either I am misunderstanding your intent or you need another cup of coffee.
>
> Is the above line a Fortune?

Why not? ;-) On R-Forge now.
Z

>
>>      cheers,
>>
>>      Rolf
>>
>> On 11/18/13 11:07, Erin Hodgess wrote:
>>> Dear R People:
>>>
>>> I'm sure that this is a very simple problem, but I have been wresting with
>>> it for some time.
>>>
>>> I have the following file that has the following one line:
>>>
>>>   CRS("+init=epsg:28992")
>>>
>>> Fair enough.  I scan it into R and get the following:
>>>
>>>> u
>>> [1] "CRS(\"+init=epsg:28992\")"
>>>> gsub(pattern='\"',replacement='"',x=u)
>>> [1] "CRS(\"+init=epsg:28992\")"
>>>
>>> I need to get rid of the extra quotation marks and slashes.  I've tried all
>>> sorts of things, including gsub, as you see,  but no good.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 17-Nov-2013  Time: 23:55:48
> This message was sent by XFMail
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chrisege at stud.ntnu.no  Mon Nov 18 09:20:32 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Mon, 18 Nov 2013 00:20:32 -0800 (PST)
Subject: [R] Hide return values
In-Reply-To: <C5946240-ED71-47FB-94CF-A533F8276843@comcast.net>
References: <1384680116033-4680611.post@n4.nabble.com>
	<C5946240-ED71-47FB-94CF-A533F8276843@comcast.net>
Message-ID: <1384762832608-4680666.post@n4.nabble.com>

Awesome, thanks!

-Chris



--
View this message in context: http://r.789695.n4.nabble.com/Hide-return-values-tp4680611p4680666.html
Sent from the R help mailing list archive at Nabble.com.


From gybrg at leeds.ac.uk  Mon Nov 18 09:42:31 2013
From: gybrg at leeds.ac.uk (Benjamin Gillespie)
Date: Mon, 18 Nov 2013 08:42:31 +0000
Subject: [R] Extract values from vector and repeat by group
In-Reply-To: <1384706924.15570.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
	<3B2391BE-2814-4079-97C8-4EFD097BCE0D@xs4all.nl>
	,<1384706924.15570.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <894643FDEA3A854A89B3E828737E2B1F0167A39D94FB@HERMES8.ds.leeds.ac.uk>

Brilliant - thanks for all the really useful suggestions, problem = solved.

Many thanks,

Ben Gillespie, Research Postgraduate
o-------------------------------------------------------------------o
School of Geography, University of Leeds, Leeds, LS2 9JT
o-------------------------------------------------------------------o
Tel: +44(0)113 34 33345
Mob: +44(0)770 868 7641
o-------------------------------o
http://www.geog.leeds.ac.uk/
o-------------------------------------o
@RiversBenG
o--------------o
________________________________________
From: arun [smartpink111 at yahoo.com]
Sent: 17 November 2013 16:48
To: R help
Cc: Berend Hasselman; Benjamin Gillespie
Subject: Re: [R] Extract values from vector and repeat by group

Hi,

?merge() sometimes change the order.
For example:
df1 <- df[-12,]
df2 <- df1

merge(df1, df1[df1$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))

In that case,

df1$ord1 <- with(df1,order(group,time))
res <- merge(df1, df1[df1$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))
res[order(res$ord1),-4]


#or just
library(plyr)
join(df2,df2[df2$time==4,c("group","var")],by="group",type="inner")


#or you may use:

indx <- with(df1,ave(time==4,group,FUN=any))

 ddply(df1[indx,],.(group),mutate,new=var[time==4])

A.K.






On Sunday, November 17, 2013 10:22 AM, Berend Hasselman <bhh at xs4all.nl> wrote:

On 17-11-2013, at 15:47, Benjamin Gillespie <gybrg at Leeds.ac.uk> wrote:

> Hi all,
>
> I hope you can help.
>
> I have a data frame 'df':
>
> group=c(rep(1,8),rep(2,10),rep(3,11))
> var=rnorm(29)
> time=c(seq(1,8),seq(1,10),seq(1,11))
> df=data.frame(group,var,time)
>
> I would like to extract the value from 'var' for each 'group' at 'time'=4 and repeat these extracted values in a new vector ('new') n times where n is the number of rows for each group. I did this by hand as below, but there must be a quicker way:
>
> subset=subset(df,df$time==4)
> subset
> group        var time
> 4      1  0.2531270    4
> 12     2 -0.3600128    4
> 22     3  0.4194730    4
>
> df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))
>
> Any questions please ask,

A very similar question was recently asked on Stackoverflow: http://stackoverflow.com/questions/19971763/r-programming-normalizing-a-column-of-data-by-another-entry-in-2-other-columns

>From the answer given there you could try this

set.seed(11) # to make it reproducible

group=c(rep(1,8),rep(2,10),rep(3,11))
var=rnorm(29)
time=c(seq(1,8),seq(1,10),seq(1,11))
df=data.frame(group,var,time)

#df
#df[df$time==4, c("group", "var")]

# merge into original data.frame
df <- merge(df, df[df$time == 4, c("group", "var")], by.x = "group", by.y = "group", suffixes = c("", "GroupSK0"))
df

Berend


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From catalinroibu at gmail.com  Mon Nov 18 13:24:24 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 18 Nov 2013 14:24:24 +0200
Subject: [R] Anova split by factors
Message-ID: <CAEW+BDKDN_1k8Q=XNH0GbGsThsfCWP7oHfKAP0uqjetcTrZopw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/721e4045/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Nov 18 13:33:20 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 18 Nov 2013 12:33:20 +0000
Subject: [R] Anova split by factors
In-Reply-To: <CAEW+BDKDN_1k8Q=XNH0GbGsThsfCWP7oHfKAP0uqjetcTrZopw@mail.gmail.com>
References: <CAEW+BDKDN_1k8Q=XNH0GbGsThsfCWP7oHfKAP0uqjetcTrZopw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB00EFB@inbomail.inbo.be>

Dear Catalin,

Have a look at the plyr package.

library(plyr)
dlply(
        eg,
        .(Exp),
        function(x) {
                aov(masa.uscat.tr~Clona,data=x)
        }
)

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens catalin roibu
Verzonden: maandag 18 november 2013 13:24
Aan: r-help at r-project.org
Onderwerp: [R] Anova split by factors

Hello R-users,
I have a problem with Anova in R and I don't know how to solve that. I want to compute Anova for each experiment (exp). I try this code:

test<-lapply(split(eg,eg$Exp),function(x) aov(masa.uscat.tr ~ Clona,data =
x))
or
test<-by(eg,eg$Exp, function(x) aov(masa.uscat.tr~Clona,data=x))

I want to compute Anova summary for each experiment (exp) and I want to compute Tuckey test for each Anova.

Thank you very much!

My data is like this:



Exp Plot Clona Prov masa uscat tr masa usc. Ram masa usc total B 36 Max4 P Puieti 6.199848485 2.639325843 8.839174328 B 36 Max4 P Puieti 3.87875 1.4798 5.35855 B 36 Max4 P Puieti 7.822702703 3.32852071 11.15122341 B 36 Max4 P Puieti 5.645384615 1.995238095 7.640622711 B 36 Max4 P Puieti 10.2 3.514864865 13.71486486 B 36 Max4 P Puieti 8.815545455 3.35627907 12.17182452 B 36 Max4 P Puieti 5.033333333 1.607142857 6.64047619 B 36 Max4 P Puieti 6.693488372 2.630208333 9.323696705 B 36 Max4 P Puieti 6.021012658 1.60293578 7.623948438 B 36 Max4 P Puieti 10.20582524 3.768314607 13.97413985 B 33 Max4 Butasi 5.899417476 1.745394737 7.644812213 B 33 Max4 Butasi 3.261428571 1.335735294 4.597163866 B 33 Max4 Butasi 3.359508197 1.456641221 4.816149418 B 33 Max4 Butasi 5.036363636 2.097793103 7.13415674 B 33 Max4 Butasi 3.122162162 1.612012579 4.734174741 B 33 Max4 Butasi 5.042474227 3.246916427 8.289390653 B 33 Max4 Butasi 5.058255814 2.724299065 7.782554879 B 33 Max4 Butasi 4.977818182 1.713504274 6.691322455 B 33 Max4 Butasi 3.195294118 1.243411765 4.438705882 B 33 Max4 Butasi 1.831818182 1.009090909 2.840909091 B 30 AF2 Butasi 6.98195122 1.764 8.74595122 B 30 AF2 Butasi 5.858333333 1.686623377 7.54495671 B 30 AF2 Butasi 10.625 3.04 13.665 C 39 AF6 Sade 10.27125 2.283193277 12.55444328 C 39 AF6 Sade 9.473488372 1.909414414 11.38290279 C 39 AF6 Sade 10.4825 2 12.4825 C 39 AF6 Sade 11.61579545 2.431136364 14.04693182 C 39 AF6 Sade 8.185074627 1.809333333 9.99440796 C 39 AF6 Sade 11.04510638 2.23672956 13.28183594 C 39 AF6 Sade 9.066666667 2.473785714 11.54045238 C 39 AF6 Sade 10.12787611 3.097631579 13.22550769 C 39 AF6 Sade 9.171290323 1.821226415 10.99251674 C 39 AF6 Sade 12.1846875 2.262590361 14.44727786 C 42 Pannonia Sade 9.275 2.482173913 11.75717391 C 42 Pannonia Sade 7.21 1.77 8.98 C 42 Pannonia Sade 11.36939394 3.111780822 14.48117476 C 42 Pannonia Sade 7.85296875 1.943475177 9.796443927 C 42 Pannonia Sade 8.25 2.54047619 10.79047619 C 42 Pannonia Sade 8.669277108 2.187071429 10.85634854 C 42 Pannonia Sade 8.510886076 2.05344 10.56432608 C 42 Pannonia Sade 9.362222222 5.525531915 14.88775414 C 42 Pannonia Sade 11.08481928 2.573193277 13.65801255 C 42 Pannonia Sade 10.17462687 3.003225806 13.17785267 C 45 Monviso Sade 12.99693878 3.216083916 16.21302269 C 45 Monviso Sade 11.11456522 1.885714286 13.0002795 C 45 Monviso Sade 8.129333333 1.532666667 9.662 C 45 Monviso Sade 9.943043478 2.38300885 12.32605233 C 45 Monviso Sade 11.9805814 3.080923913 15.06150531 C 45 Monviso Sade 10.31376623 2.210526316 12.52429255 C 45 Monviso Sade 9.947586207 1.860833333 11.80841954 C 45 Monviso Sade 12.24261538 2.166857143 14.40947253 C 45 Monviso Sade 13.56650602 2.414371257 15.98087728 C 45 Monviso Sade 10.87574257 2.922340426 13.798083 C 48 AF2 Sade 9.334545455 2.201822917 11.53636837 C 48 AF2 Sade 9.747640449 2.811780822 12.55942127 C 48 AF2 Sade 14.29541284 4.506885246 18.80229809 C 48 AF2 Sade 10.26451613 3.014322581 13.27883871 C 48 AF2 Sade 13.30924242 3.960661765 17.26990419 C 48 AF2 Sade 13.23228426 5.00546875 18.23775301 C 48 AF2 Sade 14.8277027 4.450447761 19.27815046 C 48 AF2 Sade 15.23669528 7.559322034 22.79601731 C 48 AF2 Sade 13.27198582 3.758252427 17.03023824 C 48 AF2 Sade 13.71364444 5.690444444 19.40408889 C 51 Max4 Sade 8.860884956 5.613586957 14.47447191 C 51 Max4 Sade 13.29153285 5.653061224 18.94459407 C 51 Max4 Sade 9.609850746 3.385714286 12.99556503

--
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From un_tonio at yahoo.com  Mon Nov 18 14:27:20 2013
From: un_tonio at yahoo.com (Tonio)
Date: Mon, 18 Nov 2013 05:27:20 -0800 (PST)
Subject: [R] Rotation of parallel lines
Message-ID: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>



Dear list, 

Consider these two parallel segments in a plot.

plot(c(1, 6), c(2, 2), type="n", xlim=c(0, 7), ylim=c(-2, 6))
segments(1, 1, 6, 1)
segments(1, 3, 6, 3)



How can I rotate the two lines together by a defined angle?


Thank you all in advance.

Best,
Antonio


________________________
Antonio Rivero Ostoic
Assistant professor, PhD

AARHUS UNIVERSITY
School of Business and Social Science
Quantitative Analytics Group and Cognition and Behaviour Lab
Bartholins All? 10 
DK-8000 Aarhus C

T: +45 871 65421
M: jari at asb.dk????????


From irafuchs at gmail.com  Mon Nov 18 14:35:02 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Mon, 18 Nov 2013 08:35:02 -0500
Subject: [R] Sending a matrix in an email
Message-ID: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>

I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix to a format which can be used as the body variable in sendmailR? I see how I can create a file attachment using mime_part but I would like to send the matrix in the body of the email. 

The matrix looks like:

      ABD  DEF  GHI  JKL MNO   TOT 
[1,] 0.44 0.81 1.67 0.37 0.31 -1.18


All the conversions I have tried end up sending the matrix without the colnames.

Thanks.


From petr.pikal at precheza.cz  Mon Nov 18 14:45:22 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 18 Nov 2013 13:45:22 +0000
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time
	to	Learn Few Basics
In-Reply-To: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
References: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9EE98@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Zach Feinstein
> Sent: Wednesday, November 13, 2013 2:57 PM
> To: r-help at r-project.org
> Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
> Learn Few Basics
> 
> I have finally decided that I will learn R and learn it very well. For

If you really decided to invest in learning R you shall first read R-Intro documentation especially chapters 2 and 3 and 1.11.

Eventually you could read whole 102 pages document. It shall not take you more than a week and after that you will be able to do quite sophisticated analysis.

I do not know Rstudio or Rattle but once you taste R console way maybe together with some suitable editor (I use Tinn-R) you will hardly need any GUI add-on.

Regards
Petr

> now I am using a program that a friend of mine developed to do some
> advanced statistical analyses. I downloaded RStudio to my machine.
> [Perhaps RStudio is not the best platform to work from -  I have heard
> that Rattle is sort of the new standard.] I have so far been able to
> highlight the rows of the code that I wish to run, but then I somehow
> turned off seeing the output. I also cannot find where I would locate
> the output window. Yes, frustrated.
> 
> Would any kind soul be interested in helping kickstart my R learning? I
> have JoinMe installed on my machine so I figure we can do it
> interactively. It should not take more than a few minutes. I am already
> very experienced with both C and VBA languages as well as SPSS syntax
> so there is not much need to worry about me being too much of a novice.
> 
> Thank you very much in advance.
> 
> Zach Feinstein
> zfeinstein at isgmn.com<mailto:zfeinstein at isgmn.com>
> (952) 277-0162
> (612) 590-4813 (mobile)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thierry.ONKELINX at inbo.be  Mon Nov 18 15:12:43 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 18 Nov 2013 14:12:43 +0000
Subject: [R] Sending a matrix in an email
In-Reply-To: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB01001@inbomail.inbo.be>

Have you tried dput(your.matrix)?

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Ira Fuchs
Verzonden: maandag 18 november 2013 14:35
Aan: r-help at r-project.org
Onderwerp: [R] Sending a matrix in an email

I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix to a format which can be used as the body variable in sendmailR? I see how I can create a file attachment using mime_part but I would like to send the matrix in the body of the email.

The matrix looks like:

      ABD  DEF  GHI  JKL MNO   TOT
[1,] 0.44 0.81 1.67 0.37 0.31 -1.18


All the conversions I have tried end up sending the matrix without the colnames.

Thanks.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From sarah.goslee at gmail.com  Mon Nov 18 15:13:41 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 18 Nov 2013 09:13:41 -0500
Subject: [R] Sending a matrix in an email
In-Reply-To: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
Message-ID: <CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>

What about dput()?

On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
> I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix to a format which can be used as the body variable in sendmailR? I see how I can create a file attachment using mime_part but I would like to send the matrix in the body of the email.
>
> The matrix looks like:
>
>       ABD  DEF  GHI  JKL MNO   TOT
> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>
>
> All the conversions I have tried end up sending the matrix without the colnames.
>
> Thanks.
>


From petr.pikal at precheza.cz  Mon Nov 18 15:13:39 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 18 Nov 2013 14:13:39 +0000
Subject: [R] Extract values from vector and repeat by group
In-Reply-To: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
References: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9F001@SRVEXCHMBX.precheza.cz>

Hi

probably not most elegant and also not general but

rep(df$var[df$time==4],rle(df$group)$lengths)

or

rep(df$var[df$time==4],  sapply(split(df$var,df$group), length))

shall give you desired vector.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Benjamin Gillespie
> Sent: Sunday, November 17, 2013 3:47 PM
> To: r-help at r-project.org
> Subject: [R] Extract values from vector and repeat by group
> 
> Hi all,
> 
> I hope you can help.
> 
> I have a data frame 'df':
> 
> group=c(rep(1,8),rep(2,10),rep(3,11))
> var=rnorm(29)
> time=c(seq(1,8),seq(1,10),seq(1,11))
> df=data.frame(group,var,time)
> 
> I would like to extract the value from 'var' for each 'group' at
> 'time'=4 and repeat these extracted values in a new vector ('new') n
> times where n is the number of rows for each group. I did this by hand
> as below, but there must be a quicker way:
> 
> subset=subset(df,df$time==4)
> subset
> group        var time
> 4      1  0.2531270    4
> 12     2 -0.3600128    4
> 22     3  0.4194730    4
> 
> df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))
> 
> Any questions please ask,
> 
> Many thanks in advance,
> 
> Ben Gillespie, Research Postgraduate
> o-------------------------------------------------------------------o
> School of Geography, University of Leeds, Leeds, LS2 9JT o-------------
> ------------------------------------------------------o
> Tel: +44(0)113 34 33345
> Mob: +44(0)770 868 7641
> o-------------------------------o
> http://www.geog.leeds.ac.uk/
> o-------------------------------------o
> @RiversBenG
> o--------------o
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From landronimirc at gmail.com  Mon Nov 18 15:15:22 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 18 Nov 2013 15:15:22 +0100
Subject: [R] R for a stats intro for undergrads in the US?
In-Reply-To: <528827A4.5080309@prodsyse.com>
References: <528827A4.5080309@prodsyse.com>
Message-ID: <CABxs9VnbhZz1DSWXqPUGs1o6WwyACiZH_zEWQECC-yOWZXcEJw@mail.gmail.com>

Dear Spencer,
In case you have similar questions you may want to ask them on
r-sig-teaching, which deals specifically with such topics.

Regards,
Liviu

On Sun, Nov 17, 2013 at 3:19 AM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> Hello, All:
>
>
>       Would anyone recommend R for an introductory statistics class for
> freshman psychology students in the US?  If yes, might there be any notes
> for such available?
>
>
>       I just checked r-projects.org and CRAN contributed documentation and
> found nothing.
>
>
>       I have a friend who teaches such a class, and wondered if R might be
> suitable.  The alternative is SPSS at $406 per student.
>
>
>       Thanks,
>       Spencer
>
>
> --
> Spencer Graves, PE, PhD
> President and Chief Technology Officer
> Structure Inspection and Monitoring, Inc.
> 751 Emerson Ct.
> San Jos?, CA 95126
> ph:  408-655-4567
> web:  www.structuremonitoring.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From msuzen at gmail.com  Mon Nov 18 15:25:46 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 18 Nov 2013 15:25:46 +0100
Subject: [R] Sending a matrix in an email
In-Reply-To: <924B3085-E423-443A-9418-0E8A0207B1E6@gmail.com>
References: <924B3085-E423-443A-9418-0E8A0207B1E6@gmail.com>
Message-ID: <CAPtbhHzZr6o+eSEJiX0Af=_FQ3GPbVU4sOpySEdLCBi=BW7vrg@mail.gmail.com>

On 18 November 2013 05:37, Ira Fuchs <irafuchs at gmail.com> wrote:
> I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix

My 1 cent; In case of large objects or full session, suitable for
attachment; RData might be more convenient, i.e., ?save or ?save.image


From irafuchs at gmail.com  Mon Nov 18 15:30:48 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Mon, 18 Nov 2013 09:30:48 -0500
Subject: [R] Sending a matrix in an email
In-Reply-To: <CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
Message-ID: <00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>

Thanks for the suggestion. I just tried dput and it did not produce what sendmailR requires for the body parameter. Here is a simplified version of what I need to do:

> x=matrix(c(1,2,3),1,3)
> x
     [,1] [,2] [,3]
[1,]    1    2    3
> colnames(x)=c("a","b","c")
> x
     a b c
[1,] 1 2 3

> dput(x)
structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
    c("a", "b", "c")))

I want to send x in sendmailR(to,from,x) and have it look more or less like the output above. Simple, right?


On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:

> What about dput()?
> 
> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>> I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix to a format which can be used as the body variable in sendmailR? I see how I can create a file attachment using mime_part but I would like to send the matrix in the body of the email.
>> 
>> The matrix looks like:
>> 
>>      ABD  DEF  GHI  JKL MNO   TOT
>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>> 
>> 
>> All the conversions I have tried end up sending the matrix without the colnames.
>> 
>> Thanks.
>> 


From bu.kawin88 at gmail.com  Mon Nov 18 13:39:03 2013
From: bu.kawin88 at gmail.com (Buddhini Gawarammana)
Date: Mon, 18 Nov 2013 18:09:03 +0530
Subject: [R] Simulation study in R for categorical repeated measures data
Message-ID: <CAKiipwAGb94BOh1pHSz7Re8h+d=qePTW6XxYWuhaf9x7CoYkWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/2078909e/attachment.pl>

From NiMartin at pssd.com  Mon Nov 18 15:29:46 2013
From: NiMartin at pssd.com (Martin, Nick)
Date: Mon, 18 Nov 2013 14:29:46 +0000
Subject: [R] Holt Winters for multiple customers and output with R
Message-ID: <ACBFEBCAC3603143A2398D70711295DD2AF19B72@WMBXPRD04.main.pssworldmedical.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/e5cc93d9/attachment.pl>

From dwinsemius at comcast.net  Mon Nov 18 15:37:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Nov 2013 08:37:52 -0600
Subject: [R] Rotation of parallel lines
In-Reply-To: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>
References: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>
Message-ID: <257E14B5-7D11-4879-939C-B48130342979@comcast.net>


On Nov 18, 2013, at 7:27 AM, Tonio wrote:

>
>
> Dear list,
>
> Consider these two parallel segments in a plot.
>
> plot(c(1, 6), c(2, 2), type="n", xlim=c(0, 7), ylim=c(-2, 6))
> segments(1, 1, 6, 1)
> segments(1, 3, 6, 3)
>
>
>
> How can I rotate the two lines together by a defined angle?

Base graphics do not support object operations. You need to do the  
calculation and redraw the plot.

Either lattice or ggplot2 which depend upon the "grid" system would  
have the possibility to "rotate" a component.

-- 

David Winsemius, MD
Alameda, CA, USA


From zfeinstein at isgmn.com  Mon Nov 18 15:42:04 2013
From: zfeinstein at isgmn.com (Zach Feinstein)
Date: Mon, 18 Nov 2013 14:42:04 +0000
Subject: [R] Providing a Title for a Write.Table - Thinking of Titles in
	SPSS CTABLES
Message-ID: <09b9fd20d86a4e2f8ce9f2e0791968bd@server.isgmn.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/317ffc32/attachment.pl>

From julian.bothe at elitepartner.de  Mon Nov 18 15:43:13 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Mon, 18 Nov 2013 15:43:13 +0100 (CET)
Subject: [R] issues with calling predict.coxph.penal (survival) inside a
	function
In-Reply-To: <5284ECAC.5040504@mayo.edu>
References: <mailman.25.1384426808.2137.r-help@r-project.org>
	<5284ECAC.5040504@mayo.edu>
Message-ID: <f0b745c3.00000d28.0000006a@FIW7PC12.ELITEMEDIANET>

Hello,
and thanks for the answer.

1) I found a work-around - in  the end it is easier than thought before.
The only thing you have to do is to have the same variable name with the
new values.
So if predict(coxph.penal.fit, newdata[subset,]) does not work inside a
function,  the following works:

pred_function <- function(coxph_model, newdata){
#things to do before
newdata=newdata[the_subset_i_want,]
predict(coxph_model, newdata)

}

I attach a working example.

I am not sure, maybe this is even what is written in the help to
NextMethod ;)
" NextMethod works by creating a special call frame for the next method.
If no new arguments are supplied, the arguments will be the same in
number, order and name as those to the current method but their values
will be promises to evaluate their name in the current method and
environment. Any named arguments matched to ... are handled specially:
they either replace existing arguments of the same name or are appended to
the argument list. They are passed on as the promise that was supplied as
an argument to the current environment. (S does this differently!) *If
they have been evaluated in the current (or a previous environment) they
remain evaluated.* (This is a complex area, and subject to change: see the
draft ?R Language Definition?.)" (Help to NextMethod )

2) Terry, I am not sure about the work-around you provided in your mail. I
want to do subsetting on newdata, not on the model.
Additionally, when trying the example you provided, I received different
results. Example is attached.

Thanks and all the best
Julian

#---------------------------

test1 <- data.frame(time=c(4,3,1,1,2,2,3),
              status=c(1,1,1,0,1,1,0),
              x=c(0,2,1,1,1,0,0),
              sex=c(0,0,0,0,1,1,1))

# Fit a stratified model
fit1 <- coxph(Surv(time, status) ~ x + strata(sex), test1)
summary(fit1)

#fit stratified wih spline
fit2 <- coxph(Surv(time, status) ~ pspline(x, df=2) + strata(sex), test1)
summary(fit2)

## work-around
predicting_function_which_works<- function(model, newdata ){
  subs <-vector(mode='logical', length=nrow(newdata))
  subs[3:length(subs)]<- TRUE #try with first values set to false

  newdata_alt<-newdata
  newdata<-newdata[subs,]

  ret<-vector(mode='numeric', length=nrow(newdata_alt))
  ret[!subs]<- NA
  ret[subs]<- predict(model,newdata )
  return(ret)
}

predicting_function_which_works(fit1, test1) # works

predicting_function_which_works(fit2,test1)  # works
predicting_function_which_works(fit2,data.frame(time=c(4,3,1,1,2), # works
                                              status=c(1,1,1,0,1),
                                              x=c(0,2,1,1,2),
                                              sex=c(1,1,0,0,1))
)

## How I understood Terry's work-around. Provides different results and
doesn't consider subset

predicting_function_2 <- function(model, newdata){
  subs <-vector(mode='logical', length=nrow(newdata))
  subs[2:length(subs)]<- TRUE

  newX <- model.matrix(model)
  newY <- model$y
  newfit <- coxph(newY ~ newX, iter=0, init=coef(model))
  newfit$var <- model$var

  #print(model)
  #print(newfit)
  #predict(newfit)

  #ret=predict(newfit)

  print("comparison")
  print(paste(" model, original prediction:", paste(predict(model),
collapse=",")))
  print(paste("newfit, original prediction:", paste(predict(newfit),
collapse=",")))

  ret <- predict (newfit, newdata[subs,])
  return(ret)
}

predicting_function_2(fit1, test1)

predicting_function_2(fit2,test1)


-----Urspr?ngliche Nachricht-----
Von: Terry Therneau [mailto:therneau at mayo.edu]
Gesendet: Donnerstag, 14. November 2013 16:31
An: r-help at r-project.org; julian.bothe at elitepartner.de
Betreff: Re: issues with calling predict.coxph.penal (survival) inside a
function

Thanks for the reproducable example.  I can confirm that it fails on my
machine using survival 2-37.5, the next soon-to-be-released version,

The issue is with NextMethod, and my assumption that the called routine
inherited everything from the parent, including the environment chain.  A
simple test this AM showed me that the assumption is false.  It might have
been true for Splus.  Working this out may take some time -- every other
one of my wrestling matches with predict inside a function has -- and
there is a reasonable chance that it won't make this already overdue
release.

In the meantime, here is a workaround that I have sometimes used in other
situations.
Inside your function do the following: fit a new coxph model with fixed
coefficients, and do prediction on that.

myfun <- function(oldfit, subset) {
    newX <- model.matrix(oldfit)[subset,]
    newY <- oldfit$y[subset]
    newfit <- coxph(newY ~ newX, iter=0, init=coef(oldfit))
    newfit$var <- oldfit$var
    predict(newfit)
    }

If the subset is all of a particular strata, as you indicated, then all of
the predictions will be correct.  If not, then those that make use of the
the baseline hazard (type=
expect) will be incorrect but all others are ok.

Terry Therneau


On 11/14/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hello everyone,
>
>
>
> I got an issue with calling predict.coxph.penal inside a function.
>
>
>
> Regarding the context: My original problem is that I wrote a function
> that uses predict.coxph and survfit(model) to predict
>
> a lot of survival-curves using only the basis-curves for the strata
> (as delivered by survfit(model) ) and then adapts them with
>
> the predicted risk-scores. Because there are cases where my new data
> has strata which didn't exist in the original model I exclude
>
> them, using a Boolean vector inside the function.
>
> I end up with a call like this: predict (coxph_model,
> newdata[subscript_vector,] )
>
>
>
> This works fine for coxph.model, but when I fit a model with a spline
> (class coxph.penal), I get an error:
>
> "Error in `[.data.frame`(newdata, [subscript_vector, ) : object
> '[subscript_vector ' not found"
>
>
>
> I suppose this is because of NextMethod, but I am not sure how to work
> around it. I also read a little bit about all those
> matching-and-frame-issues,
>
> But must confess I am not really into it.
>


From smartpink111 at yahoo.com  Mon Nov 18 15:42:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 18 Nov 2013 06:42:05 -0800 (PST)
Subject: [R] Extract values from vector and repeat by group
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9F001@SRVEXCHMBX.precheza.cz>
References: <894643FDEA3A854A89B3E828737E2B1F0167A39D94F8@HERMES8.ds.leeds.ac.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9F001@SRVEXCHMBX.precheza.cz>
Message-ID: <1384785725.10892.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

I would also add an index to make it work for groups that doesn't have time=4.
df1 <- df[-12,]
fun1 <- function(dat,n) {
?indx <- with(dat,tapply(time==n,group,FUN=any))
?indx2 <- with(dat,ave(time==n,group,FUN=any))
?dat[indx2,"new"] <- rep(dat$var[dat$time==n],rle(dat$group)$lengths[indx])
dat[!is.na(dat$new),] 
?}
fun1(df,4)
fun1(df1,4)

A.K.




On Monday, November 18, 2013 9:18 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
Hi

probably not most elegant and also not general but

rep(df$var[df$time==4],rle(df$group)$lengths)

or

rep(df$var[df$time==4],? sapply(split(df$var,df$group), length))

shall give you desired vector.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Benjamin Gillespie
> Sent: Sunday, November 17, 2013 3:47 PM
> To: r-help at r-project.org
> Subject: [R] Extract values from vector and repeat by group
> 
> Hi all,
> 
> I hope you can help.
> 
> I have a data frame 'df':
> 
> group=c(rep(1,8),rep(2,10),rep(3,11))
> var=rnorm(29)
> time=c(seq(1,8),seq(1,10),seq(1,11))
> df=data.frame(group,var,time)
> 
> I would like to extract the value from 'var' for each 'group' at
> 'time'=4 and repeat these extracted values in a new vector ('new') n
> times where n is the number of rows for each group. I did this by hand
> as below, but there must be a quicker way:
> 
> subset=subset(df,df$time==4)
> subset
> group? ? ? ? var time
> 4? ? ? 1? 0.2531270? ? 4
> 12? ?  2 -0.3600128? ? 4
> 22? ?  3? 0.4194730? ? 4
> 
> df$new=c(rep(0.2531270,8),rep(-0.3600128,10),rep(0.4194730,11))
> 
> Any questions please ask,
> 
> Many thanks in advance,
> 
> Ben Gillespie, Research Postgraduate
> o-------------------------------------------------------------------o
> School of Geography, University of Leeds, Leeds, LS2 9JT o-------------
> ------------------------------------------------------o
> Tel: +44(0)113 34 33345
> Mob: +44(0)770 868 7641
> o-------------------------------o
> http://www.geog.leeds.ac.uk/
> o-------------------------------------o
> @RiversBenG
> o--------------o
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Mon Nov 18 15:47:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Nov 2013 08:47:16 -0600
Subject: [R] Sending a matrix in an email
In-Reply-To: <00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
Message-ID: <087A73FE-B196-491B-9062-FAABFA353CE0@comcast.net>


On Nov 18, 2013, at 8:30 AM, Ira Fuchs wrote:

> Thanks for the suggestion. I just tried dput and it did not produce  
> what sendmailR requires for the body parameter. Here is a simplified  
> version of what I need to do:
>
>> x=matrix(c(1,2,3),1,3)
>> x
>     [,1] [,2] [,3]
> [1,]    1    2    3
>> colnames(x)=c("a","b","c")
>> x
>     a b c
> [1,] 1 2 3
>
>> dput(x)
> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL,
>    c("a", "b", "c")))
>
> I want to send x in sendmailR(to,from,x) and have it look more or  
> less like the output above. Simple, right?

After this at the console:

sink("myfile.txt")
 > x=matrix(c(1,2,3),1,3)
 > x
 > colnames(x)=c("a","b","c")
 > x
 > sink()

I get this in myfile.txt:

      [,1] [,2] [,3]
[1,]    1    2    3
      a b c
[1,] 1 2 3

There is also a capture.output function.

-- 
David

>
>
> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>
>> What about dput()?
>>
>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>  
>> wrote:
>>> I have a matrix which has colnames and I would like to send this  
>>> matrix using sendmailR. How can I convert this simple matrix to a  
>>> format which can be used as the body variable in sendmailR? I see  
>>> how I can create a file attachment using mime_part but I would  
>>> like to send the matrix in the body of the email.
>>>
>>> The matrix looks like:
>>>
>>>     ABD  DEF  GHI  JKL MNO   TOT
>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>
>>>
>>> All the conversions I have tried end up sending the matrix without  
>>> the colnames.
>>>
>>> Thanks.
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From catalinroibu at gmail.com  Mon Nov 18 15:52:25 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Mon, 18 Nov 2013 16:52:25 +0200
Subject: [R] Tukey test for anavo split by multiples factors
Message-ID: <CAEW+BDLaGRjrB7y=nxo7uZwRqqZyqNSKVjNUOcCavJ0fW5RHBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/1cfee0f1/attachment.pl>

From irafuchs at gmail.com  Mon Nov 18 15:54:18 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Mon, 18 Nov 2013 09:54:18 -0500
Subject: [R] Sending a matrix in an email
In-Reply-To: <087A73FE-B196-491B-9062-FAABFA353CE0@comcast.net>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
	<087A73FE-B196-491B-9062-FAABFA353CE0@comcast.net>
Message-ID: <AAC0608B-714F-4A4B-AA89-D0F7DC1D9E06@gmail.com>

That's the ticket!  So many functions?so little time.  Thanks to everyone.
On Nov 18, 2013, at 9:47 AM, David Winsemius wrote:

> 
> On Nov 18, 2013, at 8:30 AM, Ira Fuchs wrote:
> 
>> Thanks for the suggestion. I just tried dput and it did not produce what sendmailR requires for the body parameter. Here is a simplified version of what I need to do:
>> 
>>> x=matrix(c(1,2,3),1,3)
>>> x
>>    [,1] [,2] [,3]
>> [1,]    1    2    3
>>> colnames(x)=c("a","b","c")
>>> x
>>    a b c
>> [1,] 1 2 3
>> 
>>> dput(x)
>> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL,
>>   c("a", "b", "c")))
>> 
>> I want to send x in sendmailR(to,from,x) and have it look more or less like the output above. Simple, right?
> 
> After this at the console:
> 
> sink("myfile.txt")
> > x=matrix(c(1,2,3),1,3)
> > x
> > colnames(x)=c("a","b","c")
> > x
> > sink()
> 
> I get this in myfile.txt:
> 
>     [,1] [,2] [,3]
> [1,]    1    2    3
>     a b c
> [1,] 1 2 3
> 
> There is also a capture.output function.
> 
> -- 
> David
> 
>> 
>> 
>> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>> 
>>> What about dput()?
>>> 
>>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>>>> I have a matrix which has colnames and I would like to send this matrix using sendmailR. How can I convert this simple matrix to a format which can be used as the body variable in sendmailR? I see how I can create a file attachment using mime_part but I would like to send the matrix in the body of the email.
>>>> 
>>>> The matrix looks like:
>>>> 
>>>>    ABD  DEF  GHI  JKL MNO   TOT
>>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>> 
>>>> 
>>>> All the conversions I have tried end up sending the matrix without the colnames.
>>>> 
>>>> Thanks.
>>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius, MD
> Alameda, CA, USA
> 


From carl at witthoft.com  Mon Nov 18 14:07:29 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 18 Nov 2013 05:07:29 -0800 (PST)
Subject: [R] Sending a matrix in an email
In-Reply-To: <924B3085-E423-443A-9418-0E8A0207B1E6@gmail.com>
References: <924B3085-E423-443A-9418-0E8A0207B1E6@gmail.com>
Message-ID: <1384780049622-4680675.post@n4.nabble.com>

I think it'd be easier and safer to save the matrix, either as an .Rdata
binary or as a text file, zip that file, and use the sendmailR tools to
attach the file to your message.


Fuchs Ira-3 wrote
> I have a matrix which has colnames and I would like to send this matrix
> using sendmailR. How can I convert this simple matrix to a format which
> can be used as the body variable in sendmailR? I see how I can create a
> file attachment using mime_part but I would like to send the matrix in the
> body of the email. 
> 
> The matrix looks like:
> 
>       ABD  DEF  GHI  JKL MNO   TOT 
> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
> 
> All the conversions I have tried end up sending the matrix without the
> colnames.
> 
> Thanks.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Sending-a-matrix-in-an-email-tp4680663p4680675.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Mon Nov 18 16:04:21 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 18 Nov 2013 07:04:21 -0800
Subject: [R] Sending a matrix in an email
In-Reply-To: <00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
Message-ID: <5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>

You have not provided the minimal reproducible code that the footer of this email asks for, so we are playing 20 questions.

Perhaps you should convert the matrix to a data frame? Or is this an example of FAQ 7.16?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ira Fuchs <irafuchs at gmail.com> wrote:
>Thanks for the suggestion. I just tried dput and it did not produce
>what sendmailR requires for the body parameter. Here is a simplified
>version of what I need to do:
>
>> x=matrix(c(1,2,3),1,3)
>> x
>     [,1] [,2] [,3]
>[1,]    1    2    3
>> colnames(x)=c("a","b","c")
>> x
>     a b c
>[1,] 1 2 3
>
>> dput(x)
>structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
>    c("a", "b", "c")))
>
>I want to send x in sendmailR(to,from,x) and have it look more or less
>like the output above. Simple, right?
>
>
>On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>
>> What about dput()?
>> 
>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>
>wrote:
>>> I have a matrix which has colnames and I would like to send this
>matrix using sendmailR. How can I convert this simple matrix to a
>format which can be used as the body variable in sendmailR? I see how I
>can create a file attachment using mime_part but I would like to send
>the matrix in the body of the email.
>>> 
>>> The matrix looks like:
>>> 
>>>      ABD  DEF  GHI  JKL MNO   TOT
>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>> 
>>> 
>>> All the conversions I have tried end up sending the matrix without
>the colnames.
>>> 
>>> Thanks.
>>> 
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From carl at witthoft.com  Mon Nov 18 14:04:56 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 18 Nov 2013 05:04:56 -0800 (PST)
Subject: [R] creating upper triangular matrix
In-Reply-To: <CACk-te2evBBU08cx0SCK3tGCkg6pwU75hTV7c9-s0z+RGYnaUw@mail.gmail.com>
References: <1384709399325-4680632.post@n4.nabble.com>
	<1384712827.36496.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CACk-te2evBBU08cx0SCK3tGCkg6pwU75hTV7c9-s0z+RGYnaUw@mail.gmail.com>
Message-ID: <1384779896356-4680674.post@n4.nabble.com>

OK, I'm pre-coffee, but what's wrong with using upper.tri to create a new
matrix and then multiplying that matrix by the original "dat" matrix (direct
multiplication, not matrix multiply) to get the desired answer?


Bert Gunter wrote
> I believe matrix indexing makes Arun's complex code wholly unnececessary:
> 
> Starting with dat1 as above:
> 
> m <- matrix(0,4,4)
> m[as.matrix(dat1[,1:2])] <- dat1[,3]
> 
> ## yielding:
> m
> 
>      [,1] [,2] [,3] [,4]
> [1,]    0    2    1    1
> [2,]    0    1    2    1
> [3,]    0    0    0    2
> [4,]    0    0    0    0
> 
> If you want to get rid of any nonzero diagonal entries:
> 
> diag(m) <- 0 ## does it.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> On Sun, Nov 17, 2013 at 10:27 AM, arun &lt;

> smartpink111@

> &gt; wrote:
>> Hi,
>> May be this helps:
>>
>> dat1 <- read.table(text="
>> data data freq
>> 1       2     2
>> 1       3     1
>> 1       4     1
>> 2       3     2
>> 2       4     1
>> 2       2     1
>> 3      4       2",sep="",header=TRUE)
>> val<- unique(c(dat1[,1],dat1[,2]))
>> dat2 <-expand.grid(data=val,data.1=val)
>> library(plyr)
>> library(reshape2)
>> res <- dcast(join(dat2,dat1),data~data.1,value.var="freq",fill=0)
>> row.names(res) <- res[,1]
>> res1 <- as.matrix(res[,-1])
>> diag(res1) <-0
>>
>> #or
>>  m1 <- matrix(0,length(val),length(val),dimnames=list(val,val))
>>
>>  indx1 <- outer(colnames(m1),rownames(m1),paste,sep="")
>>  indx2 <- paste0(dat1[,1],dat1[,2])
>> m1[match(indx2,indx1)] <- dat1[,3]
>>  diag(m1) <- 0
>>  m1
>> #  1 2 3 4
>> #1 0 2 1 1
>> #2 0 0 2 1
>> #3 0 0 0 2
>> #4 0 0 0 0
>>
>> A.K.
>>
>>
>> Hello ,
>> I am working on a project ,
>> i need to create an upper triangular matrix from the data in this form;
>> data data freq
>> 1       2     2
>> 1       3     1
>> 1       4     1
>> 2       3     2
>> 2       4     1
>> 2       2     1
>> 3      4       2
>>
>>  to a triangular matrix in the following form :
>>      1   2    3   4
>> 1    0  2    1   1
>> 2    0  0    2   1
>> 3    0  0    0   2
>> 4    0  0    0   0
>>
>> i am new to R please help
>>
>>
>> ______________________________________________
>> 

> R-help@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/creating-upper-triangular-matrix-tp4680632p4680674.html
Sent from the R help mailing list archive at Nabble.com.


From irafuchs at gmail.com  Mon Nov 18 16:18:31 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Mon, 18 Nov 2013 10:18:31 -0500
Subject: [R] Sending a matrix in an email
In-Reply-To: <5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
	<5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>
Message-ID: <1B56DFA1-8612-4ACE-9E75-74D4713FB93F@gmail.com>

I thought that I had provided an example of what I wanted to do but in any case, capture.output seems to work, as in

sendmailR(to,from, capture.output(matrix_to_send))

I'm sure that there are myriad other ways (I tried print, which is mentioned in FAQ 7.16 but it doesn't work in this context)

Thanks for your help.
On Nov 18, 2013, at 10:04 AM, Jeff Newmiller wrote:

> You have not provided the minimal reproducible code that the footer of this email asks for, so we are playing 20 questions.
> 
> Perhaps you should convert the matrix to a data frame? Or is this an example of FAQ 7.16?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Ira Fuchs <irafuchs at gmail.com> wrote:
>> Thanks for the suggestion. I just tried dput and it did not produce
>> what sendmailR requires for the body parameter. Here is a simplified
>> version of what I need to do:
>> 
>>> x=matrix(c(1,2,3),1,3)
>>> x
>>    [,1] [,2] [,3]
>> [1,]    1    2    3
>>> colnames(x)=c("a","b","c")
>>> x
>>    a b c
>> [1,] 1 2 3
>> 
>>> dput(x)
>> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
>>   c("a", "b", "c")))
>> 
>> I want to send x in sendmailR(to,from,x) and have it look more or less
>> like the output above. Simple, right?
>> 
>> 
>> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>> 
>>> What about dput()?
>>> 
>>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>
>> wrote:
>>>> I have a matrix which has colnames and I would like to send this
>> matrix using sendmailR. How can I convert this simple matrix to a
>> format which can be used as the body variable in sendmailR? I see how I
>> can create a file attachment using mime_part but I would like to send
>> the matrix in the body of the email.
>>>> 
>>>> The matrix looks like:
>>>> 
>>>>     ABD  DEF  GHI  JKL MNO   TOT
>>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>> 
>>>> 
>>>> All the conversions I have tried end up sending the matrix without
>> the colnames.
>>>> 
>>>> Thanks.
>>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From carl at witthoft.com  Mon Nov 18 16:19:44 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 18 Nov 2013 07:19:44 -0800 (PST)
Subject: [R] Rotation of parallel lines
In-Reply-To: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>
References: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>
Message-ID: <1384787984480-4680695.post@n4.nabble.com>

See my answer at Stack Overflow -- repeated here for anyone else who wants a
trivial function.
# coordinate transform: cartesian plane rotation
xyrot<-function(pairs,ang){
	# pairs must be Nx2 matrix w/ x in first column and y in second
	xrot <- pairs[,1]*cos(ang) - pairs[,2]*sin(ang)
	yrot <- pairs[,1]*sin(ang) + pairs[,2]*cos(ang)
	return(invisible(cbind(xrot,yrot)))
}


tonio wrote
> Dear list, 
> 
> Consider these two parallel segments in a plot.
> 
> plot(c(1, 6), c(2, 2), type="n", xlim=c(0, 7), ylim=c(-2, 6))
> segments(1, 1, 6, 1)
> segments(1, 3, 6, 3)
> 
> 
> 
> How can I rotate the two lines together by a defined angle?
> 
> 
> Thank you all in advance.
> 
> Best,
> Antonio
> 
> 
> ________________________
> Antonio Rivero Ostoic
> Assistant professor, PhD
> 
> AARHUS UNIVERSITY
> School of Business and Social Science
> Quantitative Analytics Group and Cognition and Behaviour Lab
> Bartholins All? 10 
> DK-8000 Aarhus C
> 
> T: +45 871 65421
> M: 

> jari@

> ????????
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Rotation-of-parallel-lines-tp4680676p4680695.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Mon Nov 18 16:47:59 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 18 Nov 2013 07:47:59 -0800
Subject: [R] Sending a matrix in an email
In-Reply-To: <1B56DFA1-8612-4ACE-9E75-74D4713FB93F@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
	<5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>
	<1B56DFA1-8612-4ACE-9E75-74D4713FB93F@gmail.com>
Message-ID: <f5ee1344-ebb9-4228-9396-8bf653849243@email.android.com>

You provided examples of what you wanted, but not examples where the same code in a different context failed to provide the result you wanted. "Reproducible" means "reproduces the problem".
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ira Fuchs <irafuchs at gmail.com> wrote:
>I thought that I had provided an example of what I wanted to do but in
>any case, capture.output seems to work, as in
>
>sendmailR(to,from, capture.output(matrix_to_send))
>
>I'm sure that there are myriad other ways (I tried print, which is
>mentioned in FAQ 7.16 but it doesn't work in this context)
>
>Thanks for your help.
>On Nov 18, 2013, at 10:04 AM, Jeff Newmiller wrote:
>
>> You have not provided the minimal reproducible code that the footer
>of this email asks for, so we are playing 20 questions.
>> 
>> Perhaps you should convert the matrix to a data frame? Or is this an
>example of FAQ 7.16?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> Ira Fuchs <irafuchs at gmail.com> wrote:
>>> Thanks for the suggestion. I just tried dput and it did not produce
>>> what sendmailR requires for the body parameter. Here is a simplified
>>> version of what I need to do:
>>> 
>>>> x=matrix(c(1,2,3),1,3)
>>>> x
>>>    [,1] [,2] [,3]
>>> [1,]    1    2    3
>>>> colnames(x)=c("a","b","c")
>>>> x
>>>    a b c
>>> [1,] 1 2 3
>>> 
>>>> dput(x)
>>> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
>>>   c("a", "b", "c")))
>>> 
>>> I want to send x in sendmailR(to,from,x) and have it look more or
>less
>>> like the output above. Simple, right?
>>> 
>>> 
>>> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>>> 
>>>> What about dput()?
>>>> 
>>>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>
>>> wrote:
>>>>> I have a matrix which has colnames and I would like to send this
>>> matrix using sendmailR. How can I convert this simple matrix to a
>>> format which can be used as the body variable in sendmailR? I see
>how I
>>> can create a file attachment using mime_part but I would like to
>send
>>> the matrix in the body of the email.
>>>>> 
>>>>> The matrix looks like:
>>>>> 
>>>>>     ABD  DEF  GHI  JKL MNO   TOT
>>>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>>> 
>>>>> 
>>>>> All the conversions I have tried end up sending the matrix without
>>> the colnames.
>>>>> 
>>>>> Thanks.
>>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From irafuchs at gmail.com  Mon Nov 18 16:51:27 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Mon, 18 Nov 2013 10:51:27 -0500
Subject: [R] Sending a matrix in an email
In-Reply-To: <f5ee1344-ebb9-4228-9396-8bf653849243@email.android.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
	<5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>
	<1B56DFA1-8612-4ACE-9E75-74D4713FB93F@gmail.com>
	<f5ee1344-ebb9-4228-9396-8bf653849243@email.android.com>
Message-ID: <8CA16AE1-6825-48E4-B247-641D141DDA8E@gmail.com>

I understand what you are saying. I just didn't think that showing a sendmailR with a matrix as the body of the message would have been very helpful since it is the fact that the received email has no content that is the problem and that would not have shown up in the R console output. 
On Nov 18, 2013, at 10:47 AM, Jeff Newmiller wrote:

> You provided examples of what you wanted, but not examples where the same code in a different context failed to provide the result you wanted. "Reproducible" means "reproduces the problem".
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Ira Fuchs <irafuchs at gmail.com> wrote:
>> I thought that I had provided an example of what I wanted to do but in
>> any case, capture.output seems to work, as in
>> 
>> sendmailR(to,from, capture.output(matrix_to_send))
>> 
>> I'm sure that there are myriad other ways (I tried print, which is
>> mentioned in FAQ 7.16 but it doesn't work in this context)
>> 
>> Thanks for your help.
>> On Nov 18, 2013, at 10:04 AM, Jeff Newmiller wrote:
>> 
>>> You have not provided the minimal reproducible code that the footer
>> of this email asks for, so we are playing 20 questions.
>>> 
>>> Perhaps you should convert the matrix to a data frame? Or is this an
>> example of FAQ 7.16?
>>> 
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                     Live:   OO#.. Dead: OO#.. 
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>>> 
>> ---------------------------------------------------------------------------
>> 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> Ira Fuchs <irafuchs at gmail.com> wrote:
>>>> Thanks for the suggestion. I just tried dput and it did not produce
>>>> what sendmailR requires for the body parameter. Here is a simplified
>>>> version of what I need to do:
>>>> 
>>>>> x=matrix(c(1,2,3),1,3)
>>>>> x
>>>>   [,1] [,2] [,3]
>>>> [1,]    1    2    3
>>>>> colnames(x)=c("a","b","c")
>>>>> x
>>>>   a b c
>>>> [1,] 1 2 3
>>>> 
>>>>> dput(x)
>>>> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
>>>>  c("a", "b", "c")))
>>>> 
>>>> I want to send x in sendmailR(to,from,x) and have it look more or
>> less
>>>> like the output above. Simple, right?
>>>> 
>>>> 
>>>> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>>>> 
>>>>> What about dput()?
>>>>> 
>>>>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>
>>>> wrote:
>>>>>> I have a matrix which has colnames and I would like to send this
>>>> matrix using sendmailR. How can I convert this simple matrix to a
>>>> format which can be used as the body variable in sendmailR? I see
>> how I
>>>> can create a file attachment using mime_part but I would like to
>> send
>>>> the matrix in the body of the email.
>>>>>> 
>>>>>> The matrix looks like:
>>>>>> 
>>>>>>    ABD  DEF  GHI  JKL MNO   TOT
>>>>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>>>> 
>>>>>> 
>>>>>> All the conversions I have tried end up sending the matrix without
>>>> the colnames.
>>>>>> 
>>>>>> Thanks.
>>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 


From macqueen1 at llnl.gov  Mon Nov 18 17:38:15 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 18 Nov 2013 16:38:15 +0000
Subject: [R] quotation marks and scan
In-Reply-To: <CACxE24k1-m2HNS2w08qRH_G0t41v9NDmyxJKzgDAHJXkVufwEQ@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D57DBFE@PRDEXMBX-08.the-lab.llnl.gov>

I know you have a solution, but I would have suggested using print() with
quote=FALSE as a better way to illuminate what is going on, as in this
example:

> foo <- 'bah"bah'
> foo
[1] "bah\"bah"
> print(foo)
[1] "bah\"bah"
> print(foo, quote=FALSE)
[1] bah"bah

As others said, the backslash isn't really there. So you only have to get
rid of the " which you can do with
> gsub('"','',foo)
[1] "bahbah"



To summarize, in R, due to its rules for formatting printed output, what
you see isn't always exactly what you have, and this is an example.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/17/13 2:07 PM, "Erin Hodgess" <erinm.hodgess at gmail.com> wrote:

>Dear R People:
>
>I'm sure that this is a very simple problem, but I have been wresting with
>it for some time.
>
>I have the following file that has the following one line:
>
> CRS("+init=epsg:28992")
>
>Fair enough.  I scan it into R and get the following:
>
>> u
>[1] "CRS(\"+init=epsg:28992\")"
>> gsub(pattern='\"',replacement='"',x=u)
>[1] "CRS(\"+init=epsg:28992\")"
>
>I need to get rid of the extra quotation marks and slashes.  I've tried
>all
>sorts of things, including gsub, as you see,  but no good.
>
>Thank you for any help.
>
>Sincerely,
>Erin
>
>
>-- 
>Erin Hodgess
>Associate Professor
>Department of Computer and Mathematical Sciences
>University of Houston - Downtown
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pmenese at gmail.com  Mon Nov 18 17:53:14 2013
From: pmenese at gmail.com (Pablo Menese Camargo)
Date: Mon, 18 Nov 2013 14:53:14 -0200
Subject: [R] multilevel sampling weight
Message-ID: <CAG-zrWpyiTV+Ak7mxqCW_d6Qa=4zdN25As1NeGP2oWmVe_DoqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/8b231cd0/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Nov 18 18:13:43 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 18 Nov 2013 09:13:43 -0800
Subject: [R] Sending a matrix in an email
In-Reply-To: <8CA16AE1-6825-48E4-B247-641D141DDA8E@gmail.com>
References: <215A030F-DAFC-40F5-AEF3-D7EB0B08DBD2@gmail.com>
	<CAM_vju=3CWOOHFda7Ax_X_VRDuF8PVRnhBWvx5PSpYbH7MeWcg@mail.gmail.com>
	<00C513C8-788F-44F3-9A9A-48731725E5B7@gmail.com>
	<5e61c877-c358-4aca-a706-ee6d9bdcc024@email.android.com>
	<1B56DFA1-8612-4ACE-9E75-74D4713FB93F@gmail.com>
	<f5ee1344-ebb9-4228-9396-8bf653849243@email.android.com>
	<8CA16AE1-6825-48E4-B247-641D141DDA8E@gmail.com>
Message-ID: <292b629e-a54f-41bf-a30c-203274fe3484@email.android.com>

No, sorry to flog a dead horse, but you do not appear to get it yet and you really should understand this concept.  The minimal reproducible example would have been R code that we could run that generated an email that you think should have the matrix in it, but does not. In practically all help queries on this list we should be able to run your code and see the not-desired behavior.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ira Fuchs <irafuchs at gmail.com> wrote:
>I understand what you are saying. I just didn't think that showing a
>sendmailR with a matrix as the body of the message would have been very
>helpful since it is the fact that the received email has no content
>that is the problem and that would not have shown up in the R console
>output. 
>On Nov 18, 2013, at 10:47 AM, Jeff Newmiller wrote:
>
>> You provided examples of what you wanted, but not examples where the
>same code in a different context failed to provide the result you
>wanted. "Reproducible" means "reproduces the problem".
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> Ira Fuchs <irafuchs at gmail.com> wrote:
>>> I thought that I had provided an example of what I wanted to do but
>in
>>> any case, capture.output seems to work, as in
>>> 
>>> sendmailR(to,from, capture.output(matrix_to_send))
>>> 
>>> I'm sure that there are myriad other ways (I tried print, which is
>>> mentioned in FAQ 7.16 but it doesn't work in this context)
>>> 
>>> Thanks for your help.
>>> On Nov 18, 2013, at 10:04 AM, Jeff Newmiller wrote:
>>> 
>>>> You have not provided the minimal reproducible code that the footer
>>> of this email asks for, so we are playing 20 questions.
>>>> 
>>>> Perhaps you should convert the matrix to a data frame? Or is this
>an
>>> example of FAQ 7.16?
>>>> 
>>>
>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>> Go...
>>>>                                     Live:   OO#.. Dead: OO#.. 
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>> rocks...1k
>>>> 
>>>
>---------------------------------------------------------------------------
>>> 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> Ira Fuchs <irafuchs at gmail.com> wrote:
>>>>> Thanks for the suggestion. I just tried dput and it did not
>produce
>>>>> what sendmailR requires for the body parameter. Here is a
>simplified
>>>>> version of what I need to do:
>>>>> 
>>>>>> x=matrix(c(1,2,3),1,3)
>>>>>> x
>>>>>   [,1] [,2] [,3]
>>>>> [1,]    1    2    3
>>>>>> colnames(x)=c("a","b","c")
>>>>>> x
>>>>>   a b c
>>>>> [1,] 1 2 3
>>>>> 
>>>>>> dput(x)
>>>>> structure(c(1, 2, 3), .Dim = c(1L, 3L), .Dimnames = list(NULL, 
>>>>>  c("a", "b", "c")))
>>>>> 
>>>>> I want to send x in sendmailR(to,from,x) and have it look more or
>>> less
>>>>> like the output above. Simple, right?
>>>>> 
>>>>> 
>>>>> On Nov 18, 2013, at 9:13 AM, Sarah Goslee wrote:
>>>>> 
>>>>>> What about dput()?
>>>>>> 
>>>>>> On Mon, Nov 18, 2013 at 8:35 AM, Ira Fuchs <irafuchs at gmail.com>
>>>>> wrote:
>>>>>>> I have a matrix which has colnames and I would like to send this
>>>>> matrix using sendmailR. How can I convert this simple matrix to a
>>>>> format which can be used as the body variable in sendmailR? I see
>>> how I
>>>>> can create a file attachment using mime_part but I would like to
>>> send
>>>>> the matrix in the body of the email.
>>>>>>> 
>>>>>>> The matrix looks like:
>>>>>>> 
>>>>>>>    ABD  DEF  GHI  JKL MNO   TOT
>>>>>>> [1,] 0.44 0.81 1.67 0.37 0.31 -1.18
>>>>>>> 
>>>>>>> 
>>>>>>> All the conversions I have tried end up sending the matrix
>without
>>>>> the colnames.
>>>>>>> 
>>>>>>> Thanks.
>>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>


From dwarnold45 at suddenlink.net  Mon Nov 18 19:57:50 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Mon, 18 Nov 2013 10:57:50 -0800 (PST)
Subject: [R] Setting axis scale for a boxplot
Message-ID: <1384801070789-4680704.post@n4.nabble.com>

Hi,

I have this code:

par(mfrow=c(3,1))

x1=rnorm(10,60,1)
x2=rnorm(10,65,1)
x3=rnorm(10,70,1)
boxplot(x1,x2,x3,horizontal=TRUE,main="Example 1")

x1=rnorm(10,60,4)
x2=rnorm(10,65,4)
x3=rnorm(10,70,4)
boxplot(x1,x2,x3,horizontal=TRUE,main="Example 2")

x1=rnorm(10,60,9)
x2=rnorm(10,65,9)
x3=rnorm(10,70,9)
boxplot(x1,x2,x3,horizontal=TRUE,main="Example 3")

par(mfrow=c(1,1))

How can I set the horizontal axis limits on all three images to be the same
for sake of comparison?

D.



--
View this message in context: http://r.789695.n4.nabble.com/Setting-axis-scale-for-a-boxplot-tp4680704.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Mon Nov 18 20:10:00 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 18 Nov 2013 19:10:00 +0000
Subject: [R] Setting axis scale for a boxplot
In-Reply-To: <1384801070789-4680704.post@n4.nabble.com>
References: <1384801070789-4680704.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA15D88@PA-MBX01.na.tibco.com>

> How can I set the horizontal axis limits on all three images to be the same
> for sake of comparison?

Add ylim=c(dataMin, dataMax) to each call to boxplot(), where
you specify values for dataMin and dataMax so their range is
likely to cover all your data.  ('ylim', not 'xlim' - the horizontal=TRUE
flips the meaning of 'x' and 'y'.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of David Arnold
> Sent: Monday, November 18, 2013 10:58 AM
> To: r-help at r-project.org
> Subject: [R] Setting axis scale for a boxplot
> 
> Hi,
> 
> I have this code:
> 
> par(mfrow=c(3,1))
> 
> x1=rnorm(10,60,1)
> x2=rnorm(10,65,1)
> x3=rnorm(10,70,1)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 1")
> 
> x1=rnorm(10,60,4)
> x2=rnorm(10,65,4)
> x3=rnorm(10,70,4)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 2")
> 
> x1=rnorm(10,60,9)
> x2=rnorm(10,65,9)
> x3=rnorm(10,70,9)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 3")
> 
> par(mfrow=c(1,1))
> 
> How can I set the horizontal axis limits on all three images to be the same
> for sake of comparison?
> 
> D.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Setting-axis-scale-for-a-
> boxplot-tp4680704.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Mon Nov 18 20:26:56 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 19 Nov 2013 06:26:56 +1100
Subject: [R] Setting axis scale for a boxplot
In-Reply-To: <1384801070789-4680704.post@n4.nabble.com>
References: <1384801070789-4680704.post@n4.nabble.com>
Message-ID: <528A6A00.8090504@bitwrit.com.au>

On 11/19/2013 05:57 AM, David Arnold wrote:
> Hi,
>
> I have this code:
>
> par(mfrow=c(3,1))
>
> x1=rnorm(10,60,1)
> x2=rnorm(10,65,1)
> x3=rnorm(10,70,1)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 1")
>
> x1=rnorm(10,60,4)
> x2=rnorm(10,65,4)
> x3=rnorm(10,70,4)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 2")
>
> x1=rnorm(10,60,9)
> x2=rnorm(10,65,9)
> x3=rnorm(10,70,9)
> boxplot(x1,x2,x3,horizontal=TRUE,main="Example 3")
>
> par(mfrow=c(1,1))
>
> How can I set the horizontal axis limits on all three images to be the same
> for sake of comparison?
>
Hi David,
In addition to Bill's answer where you specify limits at the beginning, 
if you want to do it "on the fly" and you are not reusing x1, x2 and x3:

x1a=rnorm(10,60,1)
x2a=rnorm(10,65,1)
x3a=rnorm(10,70,1)
x1b=rnorm(10,60,4)
x2b=rnorm(10,65,4)
x3b=rnorm(10,70,4)
x1c=rnorm(10,60,9)
x2c=rnorm(10,65,9)
x3c=rnorm(10,70,9)
ylim<-range(c(x1a,x2a,x3a,x1b,x2b,x3b,x1c,x2c,x3c))
boxplot(x1a,x2a,x3a,ylim=ylim,horizontal=TRUE,main="Example 1")
boxplot(x1b,x2b,x3b,ylim=ylim,horizontal=TRUE,main="Example 2")
boxplot(x1c,x2c,x3c,ylim=ylim,horizontal=TRUE,main="Example 3")

Jim


From nfmcclure at gmail.com  Mon Nov 18 23:40:52 2013
From: nfmcclure at gmail.com (Nick McClure)
Date: Mon, 18 Nov 2013 14:40:52 -0800
Subject: [R] Reading in csv data with ff package
Message-ID: <CAJb9FVz0spYR+WUFMbqm8k6-Uq40GfcG8x+RpDGmYqxfTnSZKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/464835dd/attachment.pl>

From lopez235 at llnl.gov  Tue Nov 19 02:52:35 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 19 Nov 2013 01:52:35 +0000
Subject: [R] Passing parameters in a user defined function to another
 function using ...
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/691fe326/attachment.pl>

From k.moon at student.unimelb.edu.au  Tue Nov 19 03:29:08 2013
From: k.moon at student.unimelb.edu.au (kmmoon100)
Date: Mon, 18 Nov 2013 18:29:08 -0800 (PST)
Subject: [R] How can I get seasonal variation table from generalized
 additive mixed models in R?
Message-ID: <1384828148825-4680710.post@n4.nabble.com>

Hello everyone,

I used a function called gamm in mgcv in R program to investigate seasonal
variation of wind speed based on 13 years of measurement dataset. I would
like to use this variation in my formula for my study but as I am new in R,
it's extremely hard to find values on y-axis.. too many sub-directories of
gamm values make me hard to find what directory was actually used for
y-axis. 
My data set is like this below:

time /day.of.year/ month /day.of.month  /year   / WindSpeed
    1       1                7            24            2000       23.429
    2       2                7            25            2000       29.170
    3       3                7            26            2000       16.813
    4       4                7            27            2000       15.271
    5       5                7            28            2000       10.125
    6       6                7            29            2000       13.938
    7       7                7            30            2000       15.854
    8       8                7            31            2000       10.438
    9       9                8            1              2000       7.125
    .         .                .             .                .            .
    .         .                .             .                .            .

As time stamps are separated, I combined all of them first and then ran
additive modelling to look at seasonal and yearly trends of 13 years of wind
data.

My R codes are described below:
ballarat  <- read.csv("ballarat seasonal daily.csv", header=TRUE, sep=",")
ballarat1 <- within(ballarat, Date <- as.Date(paste(year, month,
day.of.month, sep = "-")))

plot(WindSpeed ~ Date, data = ballarat1, type = "l")

mod       <- gamm(WindSpeed ~ s(day.of.year, bs = "cc") + s(time, bs =
"cr"),
             data = ballarat1, method = "REML",
             correlation = corAR1(form = ~ 1 | year),
             knots = list(day.of.year = c(0, 366)))

summary(mod$gam)

plot(mod$gam, pages = 1)


http://i.stack.imgur.com/wU0AU.jpg

>From the link page of trend graphs, You can see that average wind speed has
about +- 2 km/hr variation. I would like to produce tables (two columns
(first column: x axis values, second column: y axis (variations)) each day
of year) of those two graphs. I assume I need to use gam.predict to get
tables of the prediction? As I am new in R, I still can't understand how I
can make it work even after reading description of ?gam.predict function.
Could you please show me how to do it step by step?

Regards,

Kangmin.





--
View this message in context: http://r.789695.n4.nabble.com/How-can-I-get-seasonal-variation-table-from-generalized-additive-mixed-models-in-R-tp4680710.html
Sent from the R help mailing list archive at Nabble.com.


From lopez235 at llnl.gov  Tue Nov 19 03:47:42 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 19 Nov 2013 02:47:42 +0000
Subject: [R] Passing parameters in a user defined function to another
 function using ...
In-Reply-To: <823450FE-891A-452D-BAAE-D5E48E5B2178@bigelow.org>
References: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>
	<823450FE-891A-452D-BAAE-D5E48E5B2178@bigelow.org>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB24B0@PRDEXMBX-05.the-lab.llnl.gov>

Thanks Ben.

I feel really dumb. I did enter '...' in my sample function in another version of this function. But I just realized I had only done it for the second occurrence of the sample function and not the first.

Dan


-----Original Message-----
From: Ben Tupper [mailto:btupper at bigelow.org] 
Sent: Monday, November 18, 2013 6:00 PM
To: Lopez, Dan
Cc: R help (r-help at r-project.org)
Subject: Re: [R] Passing parameters in a user defined function to another function using ...

Hi,

It's easy, just carry the arguments in '...' forward to where you expect to pass them along.


mynumbs<-function(x,y,z=5,...){
 numbs<-sort(sample(y,z, ...))
 for (i in 1:(x-1))
   numbs<-rbind(numbs,sort(sample(y,z, ...)))
 print(numbs)
}

Cheers,
Ben


On Nov 18, 2013, at 8:52 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:

> Hi R Experts,
> 
> How do you get the ... to work in a user-defined function such as the one I have below?
> For example if I want to pass replace=TRUE to the sample function.
> 
> # This is a sample function that generates x rows of z numbers out of y. Basically a lottery style data set.
> 
> mynumbs<-function(x,y,z=5,...){
>  #x should be a scalar indicating number of rows  #y & z are passed to 
> sample function  #in the future will add option to output as 
> data.frame instead of matrix
> 
>  numbs<-sort(sample(y,z))
>  for (i in 1:(x-1))
>    numbs<-rbind(numbs,sort(sample(y,z)))
>  print(numbs)
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From reith_william at bah.com  Tue Nov 19 05:01:14 2013
From: reith_william at bah.com (wwreith)
Date: Mon, 18 Nov 2013 20:01:14 -0800 (PST)
Subject: [R] 3D Plot of Convex hull
Message-ID: <1384833674457-4680712.post@n4.nabble.com>

I have a data set in which I am trying to plot a convex hull in 3 dim. Below
is a subset of the points I would use. Columns 2,3,4 are my x,y,z
coordinates. I found some ways to plot 2D convext hulls or find a convex
hull for higher dimensions, but not how to plot the data. 

I have have attached an example of what I am shooting for in my plot. 

Thanks for the help!

6466574 37 225 27  53.69230             5
6466575 38 225 27  47.54898             5
6466576 39 225 27  58.71439             5
6466577 40 225 27  67.40830             5
6466578 41 225 27  64.40646             5
6466579 42 225 27  71.59792             5
6466580 43 225 27  66.10197             5
6466581 44 225 27  61.53381             5
6466582 45 225 27  69.49900             5
6466583 46 225 27  93.91280             5
6466800 31 226 27 102.78361             5
6466801 32 226 27  69.58787             5
6466802 33 226 27  67.53348             5
6466803 34 226 27  66.83624             5
6466804 35 226 27  52.74981             5
6466805 36 226 27  58.10865             5
6466806 37 226 27  64.29259             5
6466807 38 226 27  55.37983             5
6466808 39 226 27  58.48212             5
6466809 40 226 27  66.21062             5
6466810 41 226 27  58.39149             5
6466811 42 226 27  60.40741             5
6466812 43 226 27  60.95507             5
6466813 44 226 27  64.16653             5
6466814 45 226 27  62.48255             5
6466815 46 226 27  74.37065             5
6466816 47 226 27 100.51262             5 

<http://r.789695.n4.nabble.com/file/n4680712/turbo_ch3d_lung3.jpg> 



--
View this message in context: http://r.789695.n4.nabble.com/3D-Plot-of-Convex-hull-tp4680712.html
Sent from the R help mailing list archive at Nabble.com.


From Janis.Beckstrand at va.gov  Mon Nov 18 21:46:09 2013
From: Janis.Beckstrand at va.gov (Beckstrand, Janis, NCOD)
Date: Mon, 18 Nov 2013 14:46:09 -0600
Subject: [R] How to convert a 3 dimensional List to make a table with tables
	tabular()?
Message-ID: <2D4ACE41DEFE93428F23D77988EFBCB50B721B73@VHAV10MSGA2.v10.med.va.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/86dd3808/attachment.pl>

From email8889 at gmail.com  Mon Nov 18 22:23:16 2013
From: email8889 at gmail.com (email)
Date: Mon, 18 Nov 2013 23:23:16 +0200
Subject: [R] find variation of a binary matrix
Message-ID: <CAJMZ3cfwprzp-xfHEonnoFLyb=h2jgBUz=tbrKwvZ=yQXzadMg@mail.gmail.com>

Hi:

I want to calculate how much the values in a binary matrix varies, and
for that I apply the sd() method.


mat <- matrix(c(1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1), nrow=4, ncol=3)
stddev <- sd(dist(mat,  method="binary"))

And i get the following answer:

stddev
[1] 0.3442652

Is this correct? Or there is a better way out?

Bests:

John


From tsippel at gmail.com  Mon Nov 18 22:57:38 2013
From: tsippel at gmail.com (tsippel)
Date: Mon, 18 Nov 2013 13:57:38 -0800 (PST)
Subject: [R] reshape data frame
In-Reply-To: <1384559819.65236.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1384548419239-4680539.post@n4.nabble.com>
	<1384559819.65236.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CANgNK76VEcK9G+UxqV9QLJU36MkoEFfAuc3-=xev7uk9ASvzKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/db5f00f1/attachment.pl>

From btupper at bigelow.org  Tue Nov 19 03:00:05 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 18 Nov 2013 21:00:05 -0500
Subject: [R] Passing parameters in a user defined function to another
	function using ...
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <823450FE-891A-452D-BAAE-D5E48E5B2178@bigelow.org>

Hi,

It's easy, just carry the arguments in '?' forward to where you expect to pass them along.


mynumbs<-function(x,y,z=5,...){
 numbs<-sort(sample(y,z, ...))
 for (i in 1:(x-1))
   numbs<-rbind(numbs,sort(sample(y,z, ...)))
 print(numbs)
}

Cheers,
Ben


On Nov 18, 2013, at 8:52 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:

> Hi R Experts,
> 
> How do you get the ... to work in a user-defined function such as the one I have below?
> For example if I want to pass replace=TRUE to the sample function.
> 
> # This is a sample function that generates x rows of z numbers out of y. Basically a lottery style data set.
> 
> mynumbs<-function(x,y,z=5,...){
>  #x should be a scalar indicating number of rows
>  #y & z are passed to sample function
>  #in the future will add option to output as data.frame instead of matrix
> 
>  numbs<-sort(sample(y,z))
>  for (i in 1:(x-1))
>    numbs<-rbind(numbs,sort(sample(y,z)))
>  print(numbs)
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From rmh at temple.edu  Tue Nov 19 03:38:27 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 18 Nov 2013 21:38:27 -0500
Subject: [R] Passing parameters in a user defined function to another
 function using ...
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB2447@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <CAGx1TMDhYrcOpsUjhyfVo3d5gohR_YeiKcn6f=i-R_pOZiOEUw@mail.gmail.com>

numbs <- rbind(numbs, sort(sample(y, z, ... )))

See
?Reserved
which sends you to 'Introduction to R'

Rich

On Mon, Nov 18, 2013 at 8:52 PM, Lopez, Dan <lopez235 at llnl.gov> wrote:
> Hi R Experts,
>
> How do you get the ... to work in a user-defined function such as the one I have below?
> For example if I want to pass replace=TRUE to the sample function.
>
> # This is a sample function that generates x rows of z numbers out of y. Basically a lottery style data set.
>
> mynumbs<-function(x,y,z=5,...){
>   #x should be a scalar indicating number of rows
>   #y & z are passed to sample function
>   #in the future will add option to output as data.frame instead of matrix
>
>   numbs<-sort(sample(y,z))
>   for (i in 1:(x-1))
>     numbs<-rbind(numbs,sort(sample(y,z)))
>   print(numbs)
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From floridmercutio at yahoo.com  Tue Nov 19 03:03:57 2013
From: floridmercutio at yahoo.com (Mercutio Florid)
Date: Mon, 18 Nov 2013 18:03:57 -0800 (PST)
Subject: [R] equal horizontal and vertical proportions in graphics
Message-ID: <1384826637.93310.YahooMailNeo@web160302.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131118/03846111/attachment.pl>

From balu555 at gmx.de  Tue Nov 19 10:11:58 2013
From: balu555 at gmx.de (Uwe Bohne)
Date: Tue, 19 Nov 2013 10:11:58 +0100 (CET)
Subject: [R] Installation problems: Linux Java and R not working together
Message-ID: <trinity-558fe615-9ff7-4180-bd01-9baa92d86564-1384852317939@3capp-gmx-bs29>


   Dear community,

   I almost tried for 3 days now to install rJava and package FSelector on my
   Linux machine but couldn't do so.
   I  searched all the forums and tried some tricks ... but unfortunately
   couldn't find any solution.
   First of all I did try to install rJava in my rkward without any changes ,
   that gave me the following error :

   configure: error: One or more JNI types differ from the corresponding native
   type.  You  may need to use non-standard compiler flags or a different
   compiler in order to fix this.

   ERROR: configuration failed for package ?rJava?

   * removing ?/home/uwe/.rkward/library/rJava?

   Warnmeldung:

   In install.packages(pkgs = c("rJava"), lib = "/home/uwe/.rkward/library", :

   Installation des Pakets ?rJava? hatte Exit-Status ungleich 0


   So then I started searching and found a tip. I did run the following;



   uwe at linux-k2a8:~> sudo R CMD javareconf
   Java interpreter : /usr/bin/java
   Java version     : 1.7.0_45
   Java home path   : /usr/lib/jdk1.7.0_45/jre
   Java compiler    : /usr/bin/javac
   Java headers gen.: /usr/bin/javah
   Java archive tool: /usr/bin/jar
   NOTE: Your JVM has a bogus java.library.path system property!
         Trying a heuristic via sun.boot.library.path to find jvm library...
   Java library path: $(JAVA_HOME)/lib/i386/client
   JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
   JNI cpp flags    : -I$(JAVA_HOME)/../include -I$(JAVA_HOME)/../include/linux
   Updating Java configuration in /usr/lib/R
   Done.



   And also did check 


   uwe at linux-k2a8:~> java -version
   java version "1.7.0_45"
   Java(TM) SE Runtime Environment (build 1.7.0_45-b18)
   Java HotSpot(TM) Server VM (build 24.45-b08, mixed mode)
   uwe at linux-k2a8:~> sudo /usr/sbin/update-alternatives --config java
   There are 4 choices for the alternative java (providing /usr/bin/java).
     Selection    Path                                     Priority   Status
   ------------------------------------------------------------
     0            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     auto mode
     1            /usr/java/latest/bin/java                 1         manual
   mode
   * 2            /usr/lib/jdk_Oracle/bin/java              3         manual
   mode
     3            /usr/lib/jvm/jre-1.5.0-gcj/bin/java       1500      manual
   mode
     4            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     manual
   mode
   Press enter to keep the current choice[*], or type selection number:



   I absolutely don't know what is wrong with that setup since my Java seems to
   have JDK and all the other things needed for R.

   For your Information here my system:
   uwe at linux-k2a8:~> uname -rm
   3.4.63-2.44-desktop i686

   uwe at linux-k2a8:~> cat /proc/version
   Linux version 3.4.63-2.44-desktop (geeko at buildhost) (gcc version 4.7.1
   20120723 [gcc-4_7-branch revision 189773] (S Linux) ) #1 SMP PREEMPT Wed Oct
   2 11:18:32 UTC 2013 (d91a619)



   I would be really thankful for any advise to get rJava (and FSelector)
   running soon.

   Best wishes

   Uwe

From rhelp at eoos.dds.nl  Tue Nov 19 10:12:24 2013
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Tue, 19 Nov 2013 10:12:24 +0100
Subject: [R] Reading in csv data with ff package
In-Reply-To: <CAJb9FVz0spYR+WUFMbqm8k6-Uq40GfcG8x+RpDGmYqxfTnSZKw@mail.gmail.com>
References: <CAJb9FVz0spYR+WUFMbqm8k6-Uq40GfcG8x+RpDGmYqxfTnSZKw@mail.gmail.com>
Message-ID: <20131119101224.Horde.VOVsd2EwhY5Siyt4hMwB1-A@webmailnew.dds.nl>

The following seems to work:

data = read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows = 500,
   next.rows = 1005,sep=",",colClasses = c("integer","factor","logical"))


'character' doesn't work because ff does not support character  
vectors. Character vector need to be stored as factors. The  
disadvantage of that is that the levels are stored in memory, so if  
the number of levels is very large (e.g. with unique strings) you  
might still run into memory problems.

'integer' doesn't work because read.csv.ffdf passes the colClasses on  
to read.table, which then tries to converts your second column to  
integer which it can't.

Jan



Nick McClure <nfmcclure at gmail.com> schreef:

> I've spent some time trying to wrap my head around reading in large csv
> files with the ff-package.  I think I know how to do it, but am bumping
> into some problems.  I've tried to recreate the issues as best as I can
> with a smaller example and maybe someone can help explain the problems.
>
> The following code just creates a csv file with an integer column,
> character column and logical column.
> -------------------------------------------------
> library(ff)
> #Create data
> size = 2000
> fake.data =
> data.frame("Integer"=round(100000*runif(size)),"Character"=sample(LETTERS,size,replace=T),"Logical"=sample(c(T,F),size,replace=T))
>
> #Write to csv
> write.csv(fake.data,"data.csv",row.names=F)
> -------------------------------------------------
>
> Now to read it in as a 'ffdf' class, I can do the following:
>
> -------------------------------------------------
> data = read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows = 500,
> next.rows = 1005,sep=",")
> -------------------------------------------------
>
> That works.  But with my current large data set, read.csv.ffdf is debating
> with me about the classes it's importing. I was also messing around with
> the first.rows/next.rows, but that's a question for another time. So I'll
> try to load the data in, specifying the column types (same exact command,
> except with specifying colClasses):
>
> -------------------------------------------------
>
>> data = read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows =  
>> 500, next.rows = 1005,sep=",",colClasses =  
>> c("integer","integer","logical"))Error in scan(file, what, nmax,  
>> sep, dec, quote, skip, nlines, na.strings,  :
>   scan() expected 'an integer', got '"J"'> data =
> read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows = 500,
> next.rows = 1005,sep=",",colClasses =
> c("integer","character","logical"))Error in ff(initdata = initdata,
> length = length, levels = levels, ordered = ordered,  :
>   vmode 'character' not implemented> data =
> read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows = 500,
> next.rows = 1005,sep=",",colClasses = rep("character",3))Error in
> ff(initdata = initdata, length = length, levels = levels, ordered =
> ordered,  :
>   vmode 'character' not implemented> data =
> read.csv.ffdf(x=NULL,file="data.csv",nrows=1001,first.rows = 500,
> next.rows = 1005,sep=",",colClasses = rep("raw",3))Error in scan(file,
> what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   scan() expected 'a raw', got '8601'
>
> -------------------------------------------------
> I just can't find a combination of classes that will result in this reading
> in.  I really don't understand why the classes 'character' won't work for
> all of them.  Any thoughts as to why?  I appreciate the help and time.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Tue Nov 19 10:37:10 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Nov 2013 09:37:10 +0000
Subject: [R] Installation problems: Linux Java and R not working together
In-Reply-To: <trinity-558fe615-9ff7-4180-bd01-9baa92d86564-1384852317939@3capp-gmx-bs29>
References: <trinity-558fe615-9ff7-4180-bd01-9baa92d86564-1384852317939@3capp-gmx-bs29>
Message-ID: <528B3146.8020401@stats.ox.ac.uk>

First, read the posting guide.  This is a question about compiled code 
and belongs on R-devel.

Second, the answer will be in the config.log file for rJava which you 
have not shown us.  You need to download and unpack it, then run

R CMD INSTALL rJava

and look at rJava/config.log

If that is not sufficient clue, do follow up on R-devel.

On 19/11/2013 09:11, Uwe Bohne wrote:
>
>     Dear community,
>
>     I almost tried for 3 days now to install rJava and package FSelector on my
>     Linux machine but couldn't do so.
>     I  searched all the forums and tried some tricks ... but unfortunately
>     couldn't find any solution.
>     First of all I did try to install rJava in my rkward without any changes ,
>     that gave me the following error :
>
>     configure: error: One or more JNI types differ from the corresponding native
>     type.  You  may need to use non-standard compiler flags or a different
>     compiler in order to fix this.
>
>     ERROR: configuration failed for package ?rJava?
>
>     * removing ?/home/uwe/.rkward/library/rJava?
>
>     Warnmeldung:
>
>     In install.packages(pkgs = c("rJava"), lib = "/home/uwe/.rkward/library", :
>
>     Installation des Pakets ?rJava? hatte Exit-Status ungleich 0
>
>
>     So then I started searching and found a tip. I did run the following;
>
>
>
>     uwe at linux-k2a8:~> sudo R CMD javareconf
>     Java interpreter : /usr/bin/java
>     Java version     : 1.7.0_45
>     Java home path   : /usr/lib/jdk1.7.0_45/jre
>     Java compiler    : /usr/bin/javac
>     Java headers gen.: /usr/bin/javah
>     Java archive tool: /usr/bin/jar
>     NOTE: Your JVM has a bogus java.library.path system property!
>           Trying a heuristic via sun.boot.library.path to find jvm library...
>     Java library path: $(JAVA_HOME)/lib/i386/client
>     JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
>     JNI cpp flags    : -I$(JAVA_HOME)/../include -I$(JAVA_HOME)/../include/linux
>     Updating Java configuration in /usr/lib/R
>     Done.
>
>
>
>     And also did check
>
>
>     uwe at linux-k2a8:~> java -version
>     java version "1.7.0_45"
>     Java(TM) SE Runtime Environment (build 1.7.0_45-b18)
>     Java HotSpot(TM) Server VM (build 24.45-b08, mixed mode)
>     uwe at linux-k2a8:~> sudo /usr/sbin/update-alternatives --config java
>     There are 4 choices for the alternative java (providing /usr/bin/java).
>       Selection    Path                                     Priority   Status
>     ------------------------------------------------------------
>       0            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     auto mode
>       1            /usr/java/latest/bin/java                 1         manual
>     mode
>     * 2            /usr/lib/jdk_Oracle/bin/java              3         manual
>     mode
>       3            /usr/lib/jvm/jre-1.5.0-gcj/bin/java       1500      manual
>     mode
>       4            /usr/lib/jvm/jre-1.7.0-openjdk/bin/java   17147     manual
>     mode
>     Press enter to keep the current choice[*], or type selection number:
>
>
>
>     I absolutely don't know what is wrong with that setup since my Java seems to
>     have JDK and all the other things needed for R.
>
>     For your Information here my system:
>     uwe at linux-k2a8:~> uname -rm
>     3.4.63-2.44-desktop i686
>
>     uwe at linux-k2a8:~> cat /proc/version
>     Linux version 3.4.63-2.44-desktop (geeko at buildhost) (gcc version 4.7.1
>     20120723 [gcc-4_7-branch revision 189773] (S Linux) ) #1 SMP PREEMPT Wed Oct
>     2 11:18:32 UTC 2013 (d91a619)
>
>
>
>     I would be really thankful for any advise to get rJava (and FSelector)
>     running soon.
>
>     Best wishes
>
>     Uwe
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petretta at unina.it  Tue Nov 19 11:29:25 2013
From: petretta at unina.it (petretta at unina.it)
Date: Tue, 19 Nov 2013 11:29:25 +0100
Subject: [R] metafor escalc(measure="SMCC")
Message-ID: <20131119112925.14383okifkbstj0l@inbox.unina.it>

Dear all,

I use R 3.0 for Windows.

I ask how escalc(measure="SMCC") [metafor package] mathematically  
calculate yi and vi when only change score and SD change score are  
provided.

I used the example (repoted below) posted by Qiang Yue at:

http://r.789695.n4.nabble.com/using-metafor-for-meta-analysis-of-before-after-studies-escalc-SMCC-td4667233.html

but it is unclear for me the formula used to derive y1 and v1. I read  
the documentation of metafor package and it is all very well  
described, but I ask if possible for the formula used by  
escalc(measure="SMCC") to mathematically calculate yi and vi.  
Unfortunatel, I have no free access to the paper quoted in metafor  
package.

Beginning example:

fMRS
author year n mean_r sd_r mean_s sd_s r
1 Tom  2006 9  0   0 0.12 0.03    0   0
2 Jack 2012 6  0   0 0.23 0.05    0   0
3 Zhu  2013 8  0   0 0.18 0.05    0   0

> dat_SMCC=escalc(measure="SMCC",data=fMRS,ni=n,m1i=mean_s,m2i=mean_r,sd1i=sd_s,sd2i=sd_r,ri=r
,append=TRUE)
> dat_SMCC
author year n mean_r sd_r mean_s sd_s r  yi      vi
1 Tom 2006  9  0     0    0.12  0.03  0 3.6108 0.8354
2 Jack 2012 6  0     0    0.23  0.05  0 3.8674 1.4131
3 Zhu 2013  8  0     0    0.18  0.05  0 3.1975 0.7640



Sincerely

-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy


From johannesradinger at gmail.com  Tue Nov 19 11:43:31 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 19 Nov 2013 11:43:31 +0100
Subject: [R] Overlay boxplot and scatter.smooth line
Message-ID: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/7181336b/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Tue Nov 19 11:48:33 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Tue, 19 Nov 2013 11:48:33 +0100
Subject: [R] metafor escalc(measure="SMCC")
In-Reply-To: <20131119112925.14383okifkbstj0l@inbox.unina.it>
References: <20131119112925.14383okifkbstj0l@inbox.unina.it>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D9925568A@UM-MAIL4112.unimaas.nl>

Dear Mario,

You can always just inspect the code:

escalc.default

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of petretta at unina.it
> Sent: Tuesday, November 19, 2013 11:29
> To: r-help at r-project.org
> Subject: [R] metafor escalc(measure="SMCC")
> 
> Dear all,
> 
> I use R 3.0 for Windows.
> 
> I ask how escalc(measure="SMCC") [metafor package] mathematically
> calculate yi and vi when only change score and SD change score are
> provided.
> 
> I used the example (repoted below) posted by Qiang Yue at:
> 
> http://r.789695.n4.nabble.com/using-metafor-for-meta-analysis-of-before-
> after-studies-escalc-SMCC-td4667233.html
> 
> but it is unclear for me the formula used to derive y1 and v1. I read
> the documentation of metafor package and it is all very well
> described, but I ask if possible for the formula used by
> escalc(measure="SMCC") to mathematically calculate yi and vi.
> Unfortunatel, I have no free access to the paper quoted in metafor
> package.
> 
> Beginning example:
> 
> fMRS
> author year n mean_r sd_r mean_s sd_s r
> 1 Tom  2006 9  0   0 0.12 0.03    0   0
> 2 Jack 2012 6  0   0 0.23 0.05    0   0
> 3 Zhu  2013 8  0   0 0.18 0.05    0   0
> 
> >
> dat_SMCC=escalc(measure="SMCC",data=fMRS,ni=n,m1i=mean_s,m2i=mean_r,sd1i=s
> d_s,sd2i=sd_r,ri=r
> ,append=TRUE)
> > dat_SMCC
> author year n mean_r sd_r mean_s sd_s r  yi      vi
> 1 Tom 2006  9  0     0    0.12  0.03  0 3.6108 0.8354
> 2 Jack 2012 6  0     0    0.23  0.05  0 3.8674 1.4131
> 3 Zhu 2013  8  0     0    0.18  0.05  0 3.1975 0.7640
> 
> 
> 
> Sincerely
> 
> --
> Mario Petretta
> Department of Translational Medical Sciences
> Naples University Federico II
> Italy
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Tue Nov 19 12:07:49 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 19 Nov 2013 12:07:49 +0100
Subject: [R] image plot with color scale
Message-ID: <CAAjnpdgKVq_=1bEhb+DhoAO2HXWrYOMTxE4Ln+0dvQEP-J=WAQ@mail.gmail.com>

I am plotting an image of correlations but need to add a color scale...

dat<-matrix(rnorm(1000),ncol=5)
labels=c("a","b","c","d","e")
cortmp <- cor(dat)

image(cortmp , axes = F )
axis( 1, at=seq(0,1,length=length(labels)) , labels=labels ,
cex.axis=0.8 ,srt = 45,las=2,cex=1)
axis( 2, at=seq(0,1,length=length(labels)) , labels=labels ,
cex.axis=0.8 ,srt = -45,las=1,cex=1)


> tried image.plot from package fields but :

image.plot(cortmp , axes = F )
axis( 1, at=seq(0,1,length=length(labels)) , labels=labels ,
cex.axis=0.8 ,srt = 45,las=2,cex=1)
axis( 2, at=seq(0,1,length=length(labels)) , labels=labels ,
cex.axis=0.8 ,srt = -45,las=1,cex=1)


but adding the axis fails... (the axis appears but the labls are not shown.

Can anyone can suggest an easy to use image function in R?

best
Witold

-- 
Witold Eryk Wolski


From jim at bitwrit.com.au  Tue Nov 19 12:10:21 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 19 Nov 2013 22:10:21 +1100
Subject: [R] image plot with color scale
In-Reply-To: <CAAjnpdgKVq_=1bEhb+DhoAO2HXWrYOMTxE4Ln+0dvQEP-J=WAQ@mail.gmail.com>
References: <CAAjnpdgKVq_=1bEhb+DhoAO2HXWrYOMTxE4Ln+0dvQEP-J=WAQ@mail.gmail.com>
Message-ID: <528B471D.2080006@bitwrit.com.au>

On 11/19/2013 10:07 PM, Witold E Wolski wrote:
> I am plotting an image of correlations but need to add a color scale...
>
> dat<-matrix(rnorm(1000),ncol=5)
> labels=c("a","b","c","d","e")
> cortmp<- cor(dat)
>
> image(cortmp , axes = F )
> axis( 1, at=seq(0,1,length=length(labels)) , labels=labels ,
> cex.axis=0.8 ,srt = 45,las=2,cex=1)
> axis( 2, at=seq(0,1,length=length(labels)) , labels=labels ,
> cex.axis=0.8 ,srt = -45,las=1,cex=1)
>
>
>> tried image.plot from package fields but :
>
> image.plot(cortmp , axes = F )
> axis( 1, at=seq(0,1,length=length(labels)) , labels=labels ,
> cex.axis=0.8 ,srt = 45,las=2,cex=1)
> axis( 2, at=seq(0,1,length=length(labels)) , labels=labels ,
> cex.axis=0.8 ,srt = -45,las=1,cex=1)
>
>
> but adding the axis fails... (the axis appears but the labls are not shown.
>
> Can anyone can suggest an easy to use image function in R?
>
Hi Witold,
You may find that color2D.matplot (plotrix) will do what you want.

Jim


From murdoch.duncan at gmail.com  Tue Nov 19 12:27:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Nov 2013 06:27:46 -0500
Subject: [R] How to convert a 3 dimensional List to make a table with
 tables tabular()?
In-Reply-To: <2D4ACE41DEFE93428F23D77988EFBCB50B721B73@VHAV10MSGA2.v10.med.va.gov>
References: <2D4ACE41DEFE93428F23D77988EFBCB50B721B73@VHAV10MSGA2.v10.med.va.gov>
Message-ID: <528B4B32.2080003@gmail.com>

On 13-11-18 3:46 PM, Beckstrand, Janis, NCOD wrote:
> I have information in a 3 dimensional list that I want to use to create
> a table for a written report.
>
>
>
> The 3d list was created by applying the epiR function " epitest " to a
> list of 8 2x2 tables using  lapply.
>
> The resulting list gives the 12 statistics with CIs,  that  generated by
> epitest, for each of the 8 matrices (i9, i10, etc).
>
>
>
> The list has the following form:
>
>
>
> Statslow$i9
>
> $aprev
>
>          est     lower    upper
>
> 1 0.2263884 0.2244714 0.228314
>
>
>
> $tprev
>
>         est     lower     upper
>
> 1 0.204388 0.2025413 0.2062442
>
>
>
> Statslow$i10
>
> $aprev
>
>          est     lower    upper
>
> 1 0.227004 0.22545  0.228314
>
>
>
> $tprev
>
>         est     lower     upper
>
> 1 0.204388 0.2025413 0.2062442
>
>
>
>
>
> I want to create a report that has a table in the following format:
>
>                                     I9
> i10
>
>                   Est   lower     upper                   Est  lower
> upper
>
>
>
> aprev   0.23     0.22     0.23                           etc
>
> tprev    0.2       0.20     0.21
>
> etc
>
>
>
> I have read and tried the tables package pdf and also the information at
>
> http://www.r-statistics.com/tag/data-frame/ about cast() and
> tabular.cast_df.r(),
>
> and also all the information I can find on nested tables, but have not
> be successful.
>
> I have tried to use melt() on the 3D list (to create a dataframe
> "statslow.d")  but get what seems more like S3 output :
>
>
>
>    variable     value           L2                L1
>
> 1      est       0.2263884    aprev       i9
>
> 2    lower    0.2244714    aprev      i9
>
> 3    upper   0.2283140    aprev       i9
>
> 4      est       0.2043880     tprev      i9
>
> 5    lower    0.2025413    tprev       i9
>
> 6    upper   0.2062442    tprev       i9
>
>
>
> When I try to use it with tables() I get errors
>
> and I can't see how to use the tables function on it to get what I want.
>
> Here is the tables() code that I have tried:
>
>
>
> class(statslow.d)
>
> [1] "data.frame"
>
>> head(statslow.d)
>
>    variable     value    L2  L1
>
> 1      est 0.2263884 aprev  i9
>
> 2    lower 0.2244714 aprev i9
>
> 3    upper 0.2283140 aprev i9
>
> 4      est 0.2043880 tprev i9
>
> 5    lower 0.2025413 tprev i9
>
> 6    upper 0.2062442 tprev i9
>
>> tabular(statslow.d,L2~L1*variable)
>
> Error in tabular.formula(as.formula(table, env = parent.frame()), ...) :
>
>
>    data must be a dataframe, list or environment
>
>> statslow.d<-as.data.frame(statslow.d)
>
>> tabular(statslow.d,L2~L1*variable)
>
> Error in tabular.formula(as.formula(table, env = parent.frame()), ...) :
>
>
>    data must be a dataframe, list or environment
>
>
>
> I would appreciate any help or hints anyone can give.
>



The arguments to tabular are in the wrong order.  You need to give the 
formula first or name it as "table".  So

tabular(L2 ~ L1*variable, data=statslow.d)

would not give an error, but it probably doesn't do what you want, 
because you don't specify a statistic, so it will default to a count. 
You could use the "mean" function, e.g.

tabular(L2 ~ L1*variable*Heading()*mean, data=statslow.d)

(The Heading() will suppress the column label "mean".)  There are 
examples in the vignette that do fancy formatting of multiple columns, 
so it would be possible to write the interval as [.224, .228] for instance.

Duncan Murdoch


From jim at bitwrit.com.au  Tue Nov 19 12:27:55 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 19 Nov 2013 22:27:55 +1100
Subject: [R] equal horizontal and vertical proportions in graphics
In-Reply-To: <1384826637.93310.YahooMailNeo@web160302.mail.bf1.yahoo.com>
References: <1384826637.93310.YahooMailNeo@web160302.mail.bf1.yahoo.com>
Message-ID: <528B4B3B.9090307@bitwrit.com.au>

On 11/19/2013 01:03 PM, Mercutio Florid wrote:
> I use several different versions of R, including RGui on Windows and rstudio on Linux.  In all cases, I use graphical commands, such as image().
>
> image() displays rectangles, but I want to be able to guarantee that the heights of those rectangles will always equal the widths.  Typically, the rectangles come out with notable asymmetries.
>
> Thus, if I need to draw a perfect circle with square pixels, I usually get a squashed ellipse with oblong pixels.
>
> I have experimented with other commands, and I don't need to continue to use image() if some other command would be more suitable.
>
Hi Mercutio,
If you have matrices with equal numbers of rows and columns, try:

par(pty="s")

to get a square plot. If the number of rows and columns differ you will 
have to adjust the width and height of the graphic device and the 
margins to get squares. For getting circles regardless of plot 
dimensions, try draw.circle in the plotrix package.

Jim


From carl at witthoft.com  Tue Nov 19 13:15:55 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 19 Nov 2013 04:15:55 -0800 (PST)
Subject: [R] equal horizontal and vertical proportions in graphics
In-Reply-To: <1384826637.93310.YahooMailNeo@web160302.mail.bf1.yahoo.com>
References: <1384826637.93310.YahooMailNeo@web160302.mail.bf1.yahoo.com>
Message-ID: <1384863355783-4680727.post@n4.nabble.com>


 see ?par .  Use the argument  asp=TRUE.


Mercutio Florid wrote
> I use several different versions of R, including RGui on Windows and
> rstudio on Linux.? In all cases, I use graphical commands, such as
> image().? 
> 
> image() displays rectangles, but I want to be able to guarantee that the
> heights of those rectangles will always equal the widths.? Typically, the
> rectangles come out with notable asymmetries.
> 
> Thus, if I need to draw a perfect circle with square pixels, I usually get
> a squashed ellipse with oblong pixels.
> 
> I have experimented with other commands, and I don't need to continue to
> use image() if some other command would be more suitable.
> 
> Thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/equal-horizontal-and-vertical-proportions-in-graphics-tp4680716p4680727.html
Sent from the R help mailing list archive at Nabble.com.


From andy_liaw at merck.com  Tue Nov 19 13:53:09 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 19 Nov 2013 07:53:09 -0500
Subject: [R] What is the difference between Mean Decrease Accuracy
 produced by importance(foo) vs foo$importance in a Random Forest Model?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DAFC7A@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DAFC7A@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B8910402@USCTMXP51012.merck.com>

The difference is importance(..., scale=TRUE).  See the help page for detail.  If you extract the $importance component from a randomForest object, you do not get the scaling.

Best,
Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Lopez, Dan
Sent: Wednesday, November 13, 2013 12:16 PM
To: R help (r-help at r-project.org)
Subject: [R] What is the difference between Mean Decrease Accuracy produced by importance(foo) vs foo$importance in a Random Forest Model?

Hi R Expert Community,

My question: What is the difference between Mean Decrease Accuracy produced by importance(foo) vs foo$importance in a Random Forest Model?

I ran a Random Forest classification model where the classifier is binary. I stored the model in object FOREST_model. I than ran importance(FOREST_model) and FOREST_model$importance. I usually use the prior but decided to learn more about what is in summary(randomForest ) so I ran the latter. I expected both to produce identical output. Mean Decrease Gini is the only thing that is identical in both.

I looked at ? Random Forest and Package 'randomForest' documentation and didn't find any info explaining this difference.

I am not including a reproducible example because this is most likely something, perhaps simple, such as one  is divided by something (if so, what?), that I am just not aware of.


importance(FOREST_model)

                         HC          TER MeanDecreaseAccuracy MeanDecreaseGini
APPT_TYP_CD_LL    0.16025157 -0.521041660           0.15670297        12.793624
ORG_NAM_LL        0.20886631 -0.952057325           0.20208393       107.137049
NEW_DISCIPLINE    0.20685079 -0.960719435           0.20076762        86.495063


FOREST_model$importance


                          HC           TER MeanDecreaseAccuracy MeanDecreaseGini

APPT_TYP_CD_LL    0.0049473962 -3.727629e-03         0.0045949805        12.793624

ORG_NAM_LL        0.0090715845 -2.401016e-02         0.0077298067       107.137049

NEW_DISCIPLINE    0.0130672572 -2.656671e-02         0.0114583178        86.495063

Dan Lopez
LLNL, HRIM, Workforce Analytics & Metrics


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From carl at witthoft.com  Tue Nov 19 13:19:35 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Tue, 19 Nov 2013 04:19:35 -0800 (PST)
Subject: [R] Computational differences in R vs Excel
In-Reply-To: <1384862104280-4680726.post@n4.nabble.com>
References: <1384862104280-4680726.post@n4.nabble.com>
Message-ID: <1384863575489-4680730.post@n4.nabble.com>

There are several problems here.   The first is that it's rather unlikely you
really need 10-place accuracy to fit your data.  This suggests you may be
doing something inappropriate such as fitting the wrong function or trying
to extrapolate.   Since you haven't explained what "process" you have that
isn't "converging," since clearly the fitting algorithms themselves have
converged.

Next,  you need to understand that both Excel and R have default convergence
tolerances which may not be identical (as well as default iteration limits).

And finally, of course, there's the question of machine precision limits,
although that is less likely to be a culprit in this instance.  


Soham wrote
> Hello,
>  I am working on fitting a non-linear time series. The results which I
> found using R and Excel are not quite same up to 10-12 places after
> decimal (i require high precision because otherwise the process might not
> converge)
>  For example, i am performing this simple arithmetic:
>     23-(1.346493052*16)+(.663965156*11)+(.008569426*5)-15.23480728
> 
> R gives the result --> -6.432232271 
> Excel gives the result ---> -6.432232266
> 
> The difference is negligible for all practical purposes but it leads to
> entirely different outcomes for me. I read some of the materials available
> online but none were of any help. What is the difference which prompts
> such different results? Is there anything that can be used to solve this
> problem ?
> 
> Please give suggestion if you can. Thanks





--
View this message in context: http://r.789695.n4.nabble.com/Computational-differences-in-R-vs-Excel-tp4680726p4680730.html
Sent from the R help mailing list archive at Nabble.com.


From susana.alberichmesa at osakidetza.net  Tue Nov 19 14:24:00 2013
From: susana.alberichmesa at osakidetza.net (sualme)
Date: Tue, 19 Nov 2013 05:24:00 -0800 (PST)
Subject: [R] Repeated measures with categorical data
Message-ID: <1384867440358-4680733.post@n4.nabble.com>

Hello,
I am working in a longitudinal study, with a categorical variable as a
dependent variable (alcohol consumption: no use, use, abuse and dependence)
with repeated measures (baseline, 1 year, 2 years). Besides I have another
variable with two groups: control and experimental. 

I would like to analyze the evolution in each group, I have though in lme,
but I am not sure if I can do an lme with a categorical vble as dependent
vble, or it must be continuous. If so, which model could I do? I have read
something about lmer, but doesn`t give p-values..


Thanks in advance!



--
View this message in context: http://r.789695.n4.nabble.com/Repeated-measures-with-categorical-data-tp4680733.html
Sent from the R help mailing list archive at Nabble.com.


From floridmercutio at yahoo.com  Tue Nov 19 09:56:43 2013
From: floridmercutio at yahoo.com (Mercutio Florid)
Date: Tue, 19 Nov 2013 00:56:43 -0800 (PST)
Subject: [R] can par()$pin be used to guarantee equal horizontal and
	vertical image lengths?
Message-ID: <1384851403.82348.YahooMailNeo@web160303.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/dbe0c92e/attachment.pl>

From jvadams at usgs.gov  Tue Nov 19 14:35:00 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 19 Nov 2013 07:35:00 -0600
Subject: [R] Providing a Title for a Write.Table - Thinking of Titles in
 SPSS CTABLES
In-Reply-To: <09b9fd20d86a4e2f8ce9f2e0791968bd@server.isgmn.local>
References: <09b9fd20d86a4e2f8ce9f2e0791968bd@server.isgmn.local>
Message-ID: <CAN5YmCEQ6PWQSRJj0-ycTQLe10YcPd8dsWHfXNdv9N-0B_pgDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/3ea475e3/attachment.pl>

From jvadams at usgs.gov  Tue Nov 19 14:39:32 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 19 Nov 2013 07:39:32 -0600
Subject: [R] Overlay boxplot and scatter.smooth line
In-Reply-To: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>
References: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>
Message-ID: <CAN5YmCGVzaRugPvmQPkZV=VXE4tDfgJTGwwqVoSsTTkwsx1O7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/719c6e8c/attachment.pl>

From bbolker at gmail.com  Tue Nov 19 14:50:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 19 Nov 2013 13:50:56 +0000
Subject: [R] Repeated measures with categorical data
References: <1384867440358-4680733.post@n4.nabble.com>
Message-ID: <loom.20131119T144902-423@post.gmane.org>

sualme <susana.alberichmesa <at> osakidetza.net> writes:

> 
> Hello,
> I am working in a longitudinal study, with a categorical variable as a
> dependent variable (alcohol consumption: no use, use, abuse and dependence)
> with repeated measures (baseline, 1 year, 2 years). Besides I have another
> variable with two groups: control and experimental. 
> 
> I would like to analyze the evolution in each group, I have though in lme,
> but I am not sure if I can do an lme with a categorical vble as dependent
> vble, or it must be continuous. If so, which model could I do? I have read
> something about lmer, but doesn`t give p-values..
> 
> Thanks in advance!

  I'd take a look at the clmm function in the 'ordinal' package,
or possibly the MCMCglmm package, and consider posting future questions 
to r-sig-mixed-models at r-project.org .  (Your response variable is
probably considered 'ordinal', i.e. ordered categorical, which may
be helpful terminology in searching for solutions.)

  Ben Bolker


From S.Ellison at lgcgroup.com  Tue Nov 19 15:02:24 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 19 Nov 2013 14:02:24 +0000
Subject: [R] Computational differences in R vs Excel
In-Reply-To: <1384863575489-4680730.post@n4.nabble.com>
References: <1384862104280-4680726.post@n4.nabble.com>
	<1384863575489-4680730.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5605983137@GOLD.corp.lgc-group.com>

> >  For example, i am performing this simple arithmetic:
> >     23-(1.346493052*16)+(.663965156*11)+(.008569426*5)-15.23480728
> >
> > R gives the result --> -6.432232271


My machine (win32, R 3.0.1) gives -6.432232266

Something about your machine, or typing, is different.

It shouldn't be R, as the help system implies it uses the same precision and IEEE floating point rules for all platforms....


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at lgcgroup.com  Tue Nov 19 15:38:27 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 19 Nov 2013 14:38:27 +0000
Subject: [R] Warning message during starts up
In-Reply-To: <CAEqV=werMz7Sb2w1QHS=oDuvZpVyLYnU5QJ=bU0LTEwK1573bQ@mail.gmail.com>
References: <CAEqV=werMz7Sb2w1QHS=oDuvZpVyLYnU5QJ=bU0LTEwK1573bQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5605983189@GOLD.corp.lgc-group.com>

> During startup R gives a Warning message: "Setting LC_CTYPE=en_US
> gnumeric & failed" What is the error and how can I fix it?
Googling the error message provides a number of answers from various sites; perhaps you could try that? It seems silly to retype them here

Incidentally, the answers I saw seem to imply that it's a mac error, but you didn't mention your OS.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From johannesradinger at gmail.com  Tue Nov 19 16:00:31 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 19 Nov 2013 16:00:31 +0100
Subject: [R] Overlay boxplot and scatter.smooth line
In-Reply-To: <CAN5YmCGVzaRugPvmQPkZV=VXE4tDfgJTGwwqVoSsTTkwsx1O7g@mail.gmail.com>
References: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>
	<CAN5YmCGVzaRugPvmQPkZV=VXE4tDfgJTGwwqVoSsTTkwsx1O7g@mail.gmail.com>
Message-ID: <CABsGe_zs7dyfx3ftsn+npJOCNutp1rn_aG-t7N2d26ztZuRR7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/a8c23d3e/attachment.pl>

From smartpink111 at yahoo.com  Tue Nov 19 16:34:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 19 Nov 2013 07:34:01 -0800 (PST)
Subject: [R] How to extract sets of rows (not sorted) from text file in
	R, do some methods on these rows,
	save the result in another text file,
	then pick others set of rows and do the same
In-Reply-To: <1384872404.30392.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1384872404.30392.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1384875241.25223.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
You may need ?split(), or ?aggregate() or ?ddply() from library(plyr)

dat1 <- read.table(tex="1 2 4 7 8 9
1 4 5 8 9
1 4 5 6 9
2 3 4 8
3 6 7 8
1 5 6 9
2 5 7 9",header=FALSE,sep="",fill=TRUE)?
##

?res1 <- do.call(rbind,lapply(split(dat1,dat1[,1]),function(x) c(V1=x[1,1],colSums(x[,-1],na.rm=TRUE))))
?write.table(res1,file="new.txt",row.names=FALSE,quote=FALSE)

#or
res2 <- with(dat1,aggregate(cbind(V2,V3,V4,V5,V6),list(V1=V1),sum,na.rm=TRUE))


#or
library(plyr)
res3 <- ddply(dat1,.(V1),colwise(sum,na.rm=TRUE))

A.K.


Hi, 
in a text file like 
1 2 4 7 8 9 
1 4 5 8 9 
1 4 5 6 9 
2 3 4 8 
3 6 7 8 
1 5 6 9 
2 5 7 9 
And so on 

where the first column represents group's number 

data <- read.table("in.txt") 

## first: 
? ? ? ?- select rows that strat with one (check first column), apply
methods only on thes rows (expect for the first column in each line); 

? ? ? ?- save the result in another text file namely new.txt 

## second: 
? ? ? ?- do the same for these rows start with with two 

? ? ? ?- save the result in new.txt after the prevous result 
And so on 


I have 9000 lines and around 100 groups (first column). 



for (i in 1:9000 ) { 

newdata <- data[ , which(data$V1 =='1')] 

- apply methods 
- save the result 
} 


Thanks for any help


From barry.king at qlx.com  Tue Nov 19 16:49:40 2013
From: barry.king at qlx.com (Barry King)
Date: Tue, 19 Nov 2013 10:49:40 -0500
Subject: [R] XLConnect error - "not implemented yet"
Message-ID: <CAP8WkrzCQeAB1m8-VbQdTigGtLwkNAYJbREGB3teh6TiWLONKg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/9721cea4/attachment.pl>

From ruipbarradas at sapo.pt  Tue Nov 19 17:39:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 19 Nov 2013 16:39:08 +0000
Subject: [R] XLConnect error - "not implemented yet"
In-Reply-To: <CAP8WkrzCQeAB1m8-VbQdTigGtLwkNAYJbREGB3teh6TiWLONKg@mail.gmail.com>
References: <CAP8WkrzCQeAB1m8-VbQdTigGtLwkNAYJbREGB3teh6TiWLONKg@mail.gmail.com>
Message-ID: <528B942C.6000802@sapo.pt>

Hello,

I believe this is the sort of error message you should ask the 
maintainer about.

maintainer('XLConnect')
[1] "Martin Studer <martin.studer at mirai-solutions.com>"

Hope this helps,

Rui Barradas

Em 19-11-2013 15:49, Barry King escreveu:
> When using XLConnect's readWorksheet, instead of it correctly reading
> string and numeric columns, I receive NA's with the following message:
>
> " Error when trying to evaluate cell A2 - not implemented yet"
>
> I do not know what this means.  Can anyone please assist?
>


From dwinsemius at comcast.net  Tue Nov 19 18:14:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 09:14:34 -0800
Subject: [R] 3D Plot of Convex hull
In-Reply-To: <1384833674457-4680712.post@n4.nabble.com>
References: <1384833674457-4680712.post@n4.nabble.com>
Message-ID: <7B29023E-48C3-458B-81B4-B8CD7E14ECD1@comcast.net>


On Nov 18, 2013, at 8:01 PM, wwreith wrote:

> I have a data set in which I am trying to plot a convex hull in 3 dim. Below
> is a subset of the points I would use. Columns 2,3,4 are my x,y,z
> coordinates. I found some ways to plot 2D convext hulls or find a convex
> hull for higher dimensions, but not how to plot the data. 

Doing a simple search with: 3d convex hull r-project .... I find the geometry package supports construction of multidimensional convex hulls and construction of tessalations. That package also suggsets the rgl package, which makes me think that 3d tessellations may be suitable for input to the rgl::surface3d function.

-- 
David.
> 
> I have have attached an example of what I am shooting for in my plot. 
> 
> Thanks for the help!
> 
> 6466574 37 225 27  53.69230             5
> 6466575 38 225 27  47.54898             5
> 6466576 39 225 27  58.71439             5
> 6466577 40 225 27  67.40830             5
> 6466578 41 225 27  64.40646             5
> 6466579 42 225 27  71.59792             5
> 6466580 43 225 27  66.10197             5
> 6466581 44 225 27  61.53381             5
> 6466582 45 225 27  69.49900             5
> 6466583 46 225 27  93.91280             5
> 6466800 31 226 27 102.78361             5
> 6466801 32 226 27  69.58787             5
> 6466802 33 226 27  67.53348             5
> 6466803 34 226 27  66.83624             5
> 6466804 35 226 27  52.74981             5
> 6466805 36 226 27  58.10865             5
> 6466806 37 226 27  64.29259             5
> 6466807 38 226 27  55.37983             5
> 6466808 39 226 27  58.48212             5
> 6466809 40 226 27  66.21062             5
> 6466810 41 226 27  58.39149             5
> 6466811 42 226 27  60.40741             5
> 6466812 43 226 27  60.95507             5
> 6466813 44 226 27  64.16653             5
> 6466814 45 226 27  62.48255             5
> 6466815 46 226 27  74.37065             5
> 6466816 47 226 27 100.51262             5 
> 
> <http://r.789695.n4.nabble.com/file/n4680712/turbo_ch3d_lung3.jpg> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/3D-Plot-of-Convex-hull-tp4680712.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Nov 19 18:28:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 09:28:33 -0800
Subject: [R] Rotation of parallel lines
In-Reply-To: <1384869233.47699.YahooMailNeo@web124501.mail.ne1.yahoo.com>
References: <1384781240.64937.YahooMailNeo@web124501.mail.ne1.yahoo.com>
	<257E14B5-7D11-4879-939C-B48130342979@comcast.net>
	<1384869233.47699.YahooMailNeo@web124501.mail.ne1.yahoo.com>
Message-ID: <13EBEF41-3D38-4483-AD52-A70B5CDDF9CB@comcast.net>


On Nov 19, 2013, at 5:53 AM, Tonio wrote:

> Thank you for your post. I believe that it is possible to make a function to rotate a graphical component that might be based on the rotation matrix.
> 
> 
> I'll take a look to the packages anyway...


It's certainly possible to "rotate"  abstract segment endpoints using a rotation matrix. What is not possible is to claenly erase the original image and replace it with the new image. You could also repeatedly draw new plots with a segment being rotated (around what center you do not say) in angular increments and then assemble a sequence of plots with the animation package. (A rotation matrix would transform segment end-points around the origin.)  As always, a complete description of the desired result is needed and I do not believe you have yet provided such.

-- 
David.
> 
> Den 15:38 mandag den 18. november 2013 skrev David Winsemius <dwinsemius at comcast.net>:
> 
> 
> On Nov 18, 2013, at 7:27 AM, Tonio wrote:
> 
>> 
>> 
>> Dear list,
>> 
>> Consider these two parallel segments in a plot.
>> 
>> plot(c(1, 6), c(2, 2), type="n", xlim=c(0, 7), ylim=c(-2, 6))
>> segments(1, 1, 6, 1)
>> segments(1, 3, 6, 3)
>> 
>> 
>> 
>> How can I rotate the two lines together by a defined angle?
> 
> Base graphics do not support object operations. You need to do the  
> calculation and redraw the plot.
> 
> Either lattice or ggplot2 which depend upon the "grid" system would  
> have the possibility to "rotate" a component.
> 
> -- 
> 
> David Winsemius, MD
> Alameda, CA, USA

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Nov 19 18:37:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 09:37:43 -0800
Subject: [R] Computational differences in R vs Excel
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5605983137@GOLD.corp.lgc-group.com>
References: <1384862104280-4680726.post@n4.nabble.com>
	<1384863575489-4680730.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED5605983137@GOLD.corp.lgc-group.com>
Message-ID: <86604DC0-405E-46F5-A71E-4537D2D24E6E@comcast.net>


On Nov 19, 2013, at 6:02 AM, S Ellison wrote:

>>> For example, i am performing this simple arithmetic:
>>>    23-(1.346493052*16)+(.663965156*11)+(.008569426*5)-15.23480728
>>> 
>>> R gives the result --> -6.432232271
> 
> 
> My machine (win32, R 3.0.1) gives -6.432232266
> 
> Something about your machine, or typing, is different.

I get the same, at least when printing to the same degree of accuracy:

> x <- 23-(1.346493052*16)+(.663965156*11)+(.008569426*5)-15.23480728 
> print(x, digits=10)
[1] -6.432232266


Mac OSX 10.7.5, R 3.0.2

> It shouldn't be R, as the help system implies it uses the same precision and IEEE floating point rules for all platforms....
> 
> 
> S Ellison


-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Nov 19 18:41:40 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 09:41:40 -0800
Subject: [R] Overlay boxplot and scatter.smooth line
In-Reply-To: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>
References: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>
Message-ID: <90CC901B-71B4-4C4E-B560-F0E2F7930DA2@comcast.net>


On Nov 19, 2013, at 2:43 AM, Johannes Radinger wrote:

> Hi,
> 
> I'd like to plot a boxplot and use a scatter.smooth line plot as an overlay
> for this plot.
> This works except for the problem that the x-axis ticks for both plots are
> differently spaced:
> The boxplot ticks are closer and the space between the outer most boxplots
> and the plot region (box) is larger for boxplots than for the
> scatter.smooth plot. Is there any plot-option that can be changed to
> produce the desired plot.
> 
> Here an example to illustrate what problem I am facing:
> 
> x <- c(rep(1,100),rep(2,100),rep(3,100))
> y <- c(rnorm(100,1),rnorm(100,2),rnorm(100,3))
> 
> boxplot(y~x)
> par(new=TRUE)
> scatter.smooth(x, y, xaxt="n", yaxt="n", ann=FALSE)
> 
> Moreover, I'd like to plot just the smoothed line only and not the
> datapoints.

?boxplot  # .... sends you to ?boxplot.stats which should be used to  determine what user coordinates are being used when plotting the boxplot.

xlim  would be suitable for getting both plots on hte same x-scale.
> 

-- 

David Winsemius
Alameda, CA, USA


From calummclean at hotmail.com  Tue Nov 19 19:59:01 2013
From: calummclean at hotmail.com (Calum)
Date: Tue, 19 Nov 2013 10:59:01 -0800 (PST)
Subject: [R] Inverse of Probit
Message-ID: <1384887541789-4680752.post@n4.nabble.com>

Hi there,
I hope someone can help me.

I have a dataset of Concentration against Mortality, and I am trying to
compare the use of Logit and Probit models using this data.

The issue I am having is trying to back transform the data from the probit
model, to plot it in normal space instead of log space.
I know this can be done with a logit model using the code below, where
ilogit is a function for the inverse logit:

NEWCONC <- seq(0,0.6, length=25)
NEWMORT <- predict(LOGIT, Conc=NEWCONC, se=TRUE)

plot(data=DATA, Prop~Conc)
lines(NEWCONC, ilogit(NEWMORT$fit))

However, I can't seem to find a function equivalent to ilogit for a probit
model, that I could use in this code:

NEWCONC <- seq(0,0.6, length=25)
NEWMORT <- predict(PROBIT, Conc=NEWCONC, se=TRUE)

plot(data=DATA, Prop~Conc)
lines(NEWCONC,###INVERSE PROBIT### (NEWMORT$fit))


Any advice on this issue would be appreciated,
Thanks,
Calum



--
View this message in context: http://r.789695.n4.nabble.com/Inverse-of-Probit-tp4680752.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Tue Nov 19 20:36:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 11:36:13 -0800
Subject: [R] Inverse of Probit
In-Reply-To: <1384887541789-4680752.post@n4.nabble.com>
References: <1384887541789-4680752.post@n4.nabble.com>
Message-ID: <EA38D1EB-9DD7-44E0-9623-2E1047CE6213@comcast.net>


On Nov 19, 2013, at 10:59 AM, Calum wrote:

> Hi there,
> I hope someone can help me.
> 
> I have a dataset of Concentration against Mortality, and I am trying to
> compare the use of Logit and Probit models using this data.
> 
> The issue I am having is trying to back transform the data from the probit
> model, to plot it in normal space instead of log space.
> I know this can be done with a logit model using the code below, where
> ilogit is a function for the inverse logit:
> 
> NEWCONC <- seq(0,0.6, length=25)
> NEWMORT <- predict(LOGIT, Conc=NEWCONC, se=TRUE)
> 
> plot(data=DATA, Prop~Conc)
> lines(NEWCONC, ilogit(NEWMORT$fit))
> 
> However, I can't seem to find a function equivalent to ilogit for a probit
> model, that I could use in this code:
> 
> NEWCONC <- seq(0,0.6, length=25)
> NEWMORT <- predict(PROBIT, Conc=NEWCONC, se=TRUE)

You should be looking at ?predict and paying particular attention to the 'type' argument. I think you want: type='response'


> 
> plot(data=DATA, Prop~Conc)
> lines(NEWCONC,###INVERSE PROBIT### (NEWMORT$fit))
> 
> 
> Any advice on this issue would be appreciated,
> Thanks,
> Calum
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Inverse-of-Probit-tp4680752.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sofy.tn at gmail.com  Tue Nov 19 21:09:12 2013
From: sofy.tn at gmail.com (sofeira taajobian)
Date: Tue, 19 Nov 2013 23:39:12 +0330
Subject: [R] Optim function & Hessian matrix
Message-ID: <CAPMvz=Snp8y9c6NLj5hYp2Kr=p2E+HCk_eRMMsdWbuP1gjNEvQ@mail.gmail.com>

Dear  R Users
Hi,


I have very emergency problems in my programming about  finding  MLE
with optim command. I reproduced it  with real data. I guess that my
function object in optim is very sensitive because it has power
function .
Then optim give me lower or initial values for estimates with these
warnings for Hessian matrix computation:
1: In log(B2 * (C2^(y + v))) : NaNs produced
2: In log(B3 * C3^(x + u1)) : NaNs produced
3: In log(B4 * C4^(y + u2)) : NaNs produced
4: In log(B1 * (C1^(x + v))) : NaNs produced
But I have  in result a hessian matrix with only first (2*2) block and
other values are zero.
It would not be the problem of code lead to this.  plz check the code
and data, I attach them with this email. hope it can reduce some
workload as copying and pasting.


what may lead to this and any possible way to solve it? any suggestion
are  appreciated. Plz help me as soon as possible because I don?t have
enough time.
-------------- next part --------------
"x" "y" "v" "d1" "d2" "d3" "h1" "h2" "u1" "u2"
"1" 67.3041095890411 65.0767123287671 2.08493150684932 0 0 0 0 0 0 0
"2" 59.6684931506849 61.0630136986301 3.33424657534247 0 0 0 0 0 0 0
"3" 65.8493150684932 66.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"4" 67.7479452054795 65.0575342465753 0.838356164383562 0 0 0 0 0 0 0
"5" 54.3123287671233 59.4931506849315 2.98082191780822 0 0 0 0 0 0 0
"6" 57.2712328767123 62.0602739726027 1.48219178082192 0 0 0 0 0 0 0
"7" 54.3232876712329 64.4630136986301 4.33424657534247 0 0 0 0 0 0 0
"8" 54.0657534246575 57.8684931506849 0.252054794520548 0 0 0 0 0 0 0
"9" 47.9041095890411 58.9698630136986 2.83835616438356 0 0 0 0 0 0 0
"10" 59.9041095890411 65.4849315068493 0.504109589041096 0 0 0 0 0 0 0
"11" 62.1232876712329 60.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"12" 59.9260273972603 61.3698630136986 5.00821917808219 0 0 0 0 0 0 0
"13" 53.4493150684931 59.7397260273973 3.83835616438356 0 0 0 0 0 0 0
"14" 70.4849315068493 65.2602739726027 2.33424657534247 0 0 0 0 0 0 0
"15" 63.9068493150685 74.3397260273973 5.00821917808219 0 0 0 0 0 0 0
"16" 68.2986301369863 69.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"17" 69.345205479452 71.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"18" 69.5835616438356 72.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"19" 65.1205479452055 63.6082191780822 1.91780821917808 1 0 0 0 0 0 0
"20" 67.0054794520548 69.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"21" 65.3808219178082 71.0027397260274 4.66849315068493 1 0 0 0 0 0 0
"22" 63.7780821917808 65.345205479452 5.00821917808219 0 0 0 0 0 0 0
"23" 64.0465753424658 66.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"24" 70.4383561643836 73.654794520548 5.00821917808219 0 0 0 0 0 0 0
"25" 66.1123287671233 70.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"26" 66.1917808219178 65.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"27" 57.1178082191781 64.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"28" 68.5205479452055 79.6082191780822 0.917808219178082 1 0 0 0 0 0 0
"29" 63.4082191780822 69.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"30" 82.0904109589041 83.572602739726 5.00821917808219 0 0 0 0 0 0 0
"31" 65.5013698630137 65.0794520547945 4.41917808219178 0 0 0 0 0 0 0
"32" 63.9123287671233 65.5917808219178 3.34794520547945 0 0 0 0 0 0 0
"33" 56.5917808219178 58.3123287671233 3.43835616438356 0 0 0 0 0 0 0
"34" 64.2246575342466 63.2301369863014 3.18904109589041 0 0 0 0 0 0 0
"35" 73.2876712328767 71.441095890411 3.75068493150685 0 0 0 1 0 0.158904109589041 0
"36" 63.0986301369863 67.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"37" 68.627397260274 70.0849315068493 5.00821917808219 0 0 0 0 0 0 0
"38" 66.7561643835616 66.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"39" 66.5972602739726 65.5835616438356 1.43287671232877 0 0 0 0 0 0 0
"40" 60.8493150684931 65.7671232876712 3.4027397260274 0 0 0 0 0 0 0
"41" 66.1452054794521 72.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"42" 63.5753424657534 65.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"43" 66.1452054794521 70.1534246575342 5.00821917808219 0 0 0 0 0 0 0
"44" 69.1780821917808 72.6876712328767 5.00821917808219 0 0 0 0 0 0 0
"45" 61.3534246575342 62.5068493150685 1.58630136986301 0 0 0 0 0 0 0
"46" 68.5616438356164 67.8438356164384 5.00821917808219 0 0 0 0 0 0 0
"47" 60.2520547945205 64.9041095890411 3.67123287671233 0 0 0 0 0 0 0
"48" 62.558904109589 65.0547945205479 2.73424657534247 0 0 0 0 0 0 0
"49" 59.8465753424658 65.1780821917808 5.00821917808219 0 0 0 0 0 0 0
"50" 61.7534246575342 63.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"51" 57.9561643835616 63.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"52" 71.1041095890411 74.358904109589 5.00821917808219 0 0 0 0 0 0 0
"53" 73.9123287671233 74.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"54" 81.4465753424657 65.4794520547945 3.47945205479452 0 0 0 0 0 0 0
"55" 78.3534246575342 79.3424657534247 0 0 0 0 1 0 0.421917808219178 0
"56" 72.2301369863014 72.4356164383562 3.33150684931507 0 0 0 1 0 0.0794520547945206 0
"57" 63.7698630136986 65.4931506849315 0.263013698630137 0 0 0 0 0 0 0
"58" 74.0054794520548 74.9561643835616 4.16438356164384 1 0 0 0 0 0 0
"59" 73.4520547945205 73.7068493150685 5.00821917808219 0 0 0 0 0 0 0
"60" 70.3945205479452 66.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"61" 60.7150684931507 66.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"62" 60.8821917808219 59.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"63" 57.6876712328767 60.5698630136986 4.15342465753425 0 0 0 0 0 0 0
"64" 60.5534246575342 63.772602739726 4.15342465753425 0 0 0 0 0 0 0
"65" 71.5178082191781 71.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"66" 30.7150684931507 61.413698630137 5.00821917808219 0 0 0 0 0 0 0
"67" 73.8657534246575 73.8794520547945 0 0 0 0 1 0 2.41643835616438 0
"68" 69.2876712328767 65.7534246575343 3.73150684931507 0 0 0 0 0 0 0
"69" 66.3643835616438 68.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"70" 63.0082191780822 64.6328767123288 1.15342465753425 0 0 0 0 0 0 0
"71" 59.9205479452055 65.6082191780822 2.67123287671233 0 0 0 0 0 0 0
"72" 69.7534246575343 68.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"73" 66.2794520547945 69.0164383561644 5.0027397260274 1 0 0 0 0 0 0
"74" 71.813698630137 73.6931506849315 5.00821917808219 0 0 0 0 0 0 0
"75" 59.8465753424658 61.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"76" 58.7945205479452 65.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"77" 66.6739726027397 65.5095890410959 1.4986301369863 0 0 0 0 0 0 0
"78" 63.8082191780822 62.7123287671233 4.12602739726027 0 0 0 0 0 0 0
"79" 67.6 61.9123287671233 4.24383561643836 0 0 0 0 0 0 0
"80" 62.3753424657534 63.4109589041096 2.75068493150685 1 0 0 0 0 0 0
"81" 61.6657534246575 66.0575342465753 5.00821917808219 0 0 0 0 0 0 0
"82" 63.8246575342466 64.6657534246575 4.33424657534247 0 0 0 0 0 0 0
"83" 63.8712328767123 67.3808219178082 5.00821917808219 0 0 0 0 0 0 0
"84" 61.7890410958904 62.0219178082192 4.33424657534247 0 0 0 0 0 0 0
"85" 63.0657534246575 66.1068493150685 5.00821917808219 0 0 0 0 0 0 0
"86" 59.6602739726027 69.4383561643836 3.66849315068493 1 0 0 0 0 0 0
"87" 53.3506849315068 57.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"88" 56.9643835616438 68.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"89" 60.1780821917808 64.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"90" 55.3095890410959 65.8958904109589 0.558904109589041 0 0 0 0 0 0 0
"91" 62.3479452054795 64.9643835616438 2.98082191780822 0 0 0 0 0 0 0
"92" 58.7643835616438 65.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"93" 63.6082191780822 65.4219178082192 0.671232876712329 0 0 0 0 0 0 0
"94" 55.3808219178082 65.3013698630137 1.81095890410959 0 0 0 0 0 0 0
"95" 66.1041095890411 65.1643835616438 2.25205479452055 0 0 0 0 0 0 0
"96" 65.8739726027397 65.3479452054794 0.671232876712329 0 0 0 0 0 0 0
"97" 52.4958904109589 64.9260273972603 2.16712328767123 0 0 0 0 0 0 0
"98" 60.5232876712329 58.227397260274 1.25753424657534 0 0 0 0 0 0 0
"99" 61.6739726027397 65.172602739726 2.99178082191781 0 0 0 0 0 0 0
"100" 60.4876712328767 68.1780821917808 1.24109589041096 0 0 0 0 0 0 0
"101" 67.5095890410959 68.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"102" 61.8767123287671 64.7315068493151 1.24931506849315 0 0 0 0 0 0 0
"103" 61.4904109589041 64.9561643835616 3.05479452054795 0 0 0 0 0 0 0
"104" 64.5041095890411 64.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"105" 57.8301369863014 65.1123287671233 3.23013698630137 0 0 0 0 0 0 0
"106" 58.5232876712329 64.8657534246575 1.33424657534247 0 0 0 0 0 0 0
"107" 65.3315068493151 65.4547945205479 2.75068493150685 1 0 0 0 0 0 0
"108" 35.4356164383562 62.4904109589041 3.47397260273973 0 0 0 0 0 0 0
"109" 55.1178082191781 57.9232876712329 3.47397260273973 0 0 0 0 0 0 0
"110" 55.027397260274 58.827397260274 3.64931506849315 0 0 0 0 0 0 0
"111" 74.2657534246575 70.7835616438356 2.32876712328767 0 0 0 0 0 0 0
"112" 66.3260273972603 64.8657534246575 1.67123287671233 0 0 0 0 0 0 0
"113" 59.8109589041096 65.8520547945206 5.00821917808219 0 0 0 0 0 0 0
"114" 50.7945205479452 67.1095890410959 0.197260273972603 0 0 0 0 0 0 0
"115" 60.6958904109589 65.5095890410959 2.58630136986301 0 0 0 0 0 0 0
"116" 66.2684931506849 65.3506849315068 4.41917808219178 0 0 0 0 0 0 0
"117" 59.8027397260274 64.9561643835616 3.08493150684932 0 0 0 0 0 0 0
"118" 39.2657534246575 64.758904109589 0.334246575342466 0 0 0 0 0 0 0
"119" 59.0958904109589 66.1424657534247 5.00821917808219 0 0 0 0 0 0 0
"120" 76.772602739726 72.4 5.00821917808219 0 0 0 0 0 0 0
"121" 44.0794520547945 65.0602739726027 2.96438356164384 0 0 0 0 0 0 0
"122" 69.7972602739726 65.2438356164384 3.10958904109589 0 0 0 0 0 0 0
"123" 59.2602739726027 65.654794520548 1.57534246575342 0 0 0 0 0 0 0
"124" 63.0109589041096 65.9643835616438 4.4958904109589 0 0 0 0 0 0 0
"125" 60.2054794520548 59.1205479452055 0.635616438356164 1 0 0 0 0 0 0
"126" 45.4657534246575 65.4712328767123 0.504109589041096 0 0 0 0 0 0 0
"127" 64.0301369863014 65.7917808219178 1.81643835616438 0 0 0 0 0 0 0
"128" 66.0958904109589 66.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"129" 64.372602739726 65.0027397260274 1 0 0 0 0 0 0 0
"130" 61.8602739726027 65.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"131" 60.3835616438356 62.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"132" 66.7780821917808 68.4821917808219 4.08767123287671 1 0 0 0 0 0 0
"133" 66.9479452054795 65.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"134" 63.0767123287671 63.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"135" 70.5808219178082 73.0493150684931 2.24931506849315 1 0 0 0 0 0 0
"136" 72.0301369863014 70.827397260274 5.00821917808219 0 0 0 0 0 0 0
"137" 70.1178082191781 74.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"138" 60.3671232876712 62.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"139" 66.4109589041096 68.4630136986301 5.00821917808219 0 0 0 0 0 0 0
"140" 74.0739726027397 76.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"141" 72.6712328767123 75.4465753424657 5.0027397260274 1 0 0 0 0 0 0
"142" 78.4328767123288 77.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"143" 76.1835616438356 76.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"144" 65.2547945205479 64.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"145" 64.5698630136986 67.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"146" 79.6493150684932 76.2 5.00821917808219 0 0 0 0 0 0 0
"147" 77.8602739726027 74.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"148" 65.3972602739726 68.6164383561644 5.00821917808219 0 0 0 0 0 0 0
"149" 63.3808219178082 65.6465753424658 2.67123287671233 0 0 0 0 0 0 0
"150" 72.7671232876712 70.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"151" 50.6684931506849 61.0931506849315 3.41917808219178 0 0 0 0 0 0 0
"152" 88.4904109589041 89.0602739726027 3.24931506849315 0 0 0 0 1 0 0.147945205479452
"153" 71.6794520547945 79.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"154" 78.213698630137 70.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"155" 60.8904109589041 65.9068493150685 0.915068493150685 0 0 0 0 0 0 0
"156" 73.1260273972603 75.627397260274 4.24931506849315 1 0 0 0 0 0 0
"157" 70.5424657534247 69.4575342465753 5.00821917808219 0 0 0 0 0 0 0
"158" 66.0630136986301 64.8602739726027 2.33424657534247 0 0 0 0 0 0 0
"159" 75.6794520547945 82.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"160" 66.2986301369863 67.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"161" 62.7643835616438 79.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"162" 65.986301369863 68.3260273972603 5.00821917808219 0 0 0 0 0 0 0
"163" 61.7452054794521 65.6082191780822 3.5041095890411 1 0 0 0 0 0 0
"164" 75.9287671232877 77.2958904109589 2.91780821917808 0 0 0 0 1 0 1.08493150684932
"165" 62.9616438356164 64.9835616438356 1.5041095890411 0 0 0 0 0 0 0
"166" 64 70.641095890411 5.00821917808219 0 0 0 0 0 0 0
"167" 58.1095890410959 71.0301369863014 1.75068493150685 1 0 0 0 0 0 0
"168" 57.627397260274 59.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"169" 61.4821917808219 66.8191780821918 5.00821917808219 0 0 0 0 0 0 0
"170" 63.0794520547945 56.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"171" 60.6109589041096 62.0986301369863 5.00821917808219 0 0 0 0 0 0 0
"172" 58.6630136986301 60.5917808219178 1.58630136986301 0 0 0 0 0 0 0
"173" 72.8383561643836 65.427397260274 5.00821917808219 0 0 0 0 0 0 0
"174" 60.6328767123288 63.241095890411 5.00821917808219 0 0 0 0 0 0 0
"175" 63.9232876712329 73.3260273972603 1.75068493150685 1 0 0 0 0 0 0
"176" 64.4767123287671 64.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"177" 62.6821917808219 64.9315068493151 1.83287671232877 0 0 0 0 0 0 0
"178" 62.1972602739726 62.2684931506849 0.915068493150685 0 0 0 0 0 0 0
"179" 59.7698630136986 64.6821917808219 0.0821917808219178 0 0 0 0 0 0 0
"180" 83.8493150684932 85.0657534246575 0.668493150684932 0 0 0 1 0 0.0438356164383562 0
"181" 63.3561643835616 65.2630136986301 0.605479452054794 0 0 0 0 0 0 0
"182" 57.0739726027397 63.841095890411 1.33150684931507 0 0 0 0 0 0 0
"183" 64.0109589041096 65.4821917808219 2.5041095890411 0 0 0 0 0 0 0
"184" 68.1095890410959 69.9561643835616 1.41917808219178 0 0 0 0 0 0 0
"185" 60.7808219178082 65.013698630137 1.81369863013699 0 0 0 0 0 0 0
"186" 63.5780821917808 65.2958904109589 3.41917808219178 0 0 0 0 0 0 0
"187" 60.9506849315068 65.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"188" 67.9917808219178 65.2520547945205 3.47397260273973 0 0 0 0 0 0 0
"189" 64.2109589041096 65.0328767123288 2.88767123287671 0 0 0 0 0 0 0
"190" 64.2575342465753 65.627397260274 5.00821917808219 0 0 0 0 0 0 0
"191" 57.5205479452055 64.7534246575343 4.44931506849315 0 0 0 0 0 0 0
"192" 69.3369863013699 70.1232876712329 2.87945205479452 0 0 0 0 0 0 0
"193" 63.1671232876712 64.7972602739726 2.16712328767123 0 0 0 0 0 0 0
"194" 56.9342465753425 60.0027397260274 2.97808219178082 0 0 0 0 0 0 0
"195" 60.8082191780822 65.0054794520548 4 0 0 0 0 0 0 0
"196" 51.1041095890411 58.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"197" 61.7561643835616 63.9260273972603 3.99178082191781 0 0 0 0 0 0 0
"198" 65.4082191780822 65.5041095890411 2.32876712328767 0 0 0 0 0 0 0
"199" 63.1178082191781 65.4958904109589 0.83013698630137 0 0 0 0 0 0 0
"200" 70.6657534246575 65.1397260273973 3.16712328767123 0 0 0 0 0 0 0
"201" 64.4602739726027 65.8575342465753 2.73150684931507 0 0 0 0 0 0 0
"202" 61.227397260274 63.0821917808219 0.419178082191781 0 0 0 0 0 0 0
"203" 66.5123287671233 65.1369863013699 2.41917808219178 0 0 0 0 0 0 0
"204" 67.6630136986301 64.6794520547945 3.21369863013699 0 0 0 0 0 0 0
"205" 57.7178082191781 65.7068493150685 0.838356164383562 0 0 0 0 0 0 0
"206" 60.7917808219178 64.6821917808219 2.5041095890411 0 0 0 0 0 0 0
"207" 73.972602739726 74.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"208" 63.7643835616438 66.5534246575343 5.00821917808219 0 0 0 0 0 0 0
"209" 62.5890410958904 64.9890410958904 1.58356164383562 1 0 0 0 0 0 0
"210" 61.2712328767123 65.3698630136986 0.482191780821918 1 0 0 0 0 0 0
"211" 67.5123287671233 66.3890410958904 3.33150684931507 0 0 0 0 1 0 0.010958904109589
"212" 63.3232876712329 68.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"213" 52.3698630136986 65.4219178082192 2.55342465753425 0 0 0 0 0 0 0
"214" 64.0547945205479 65.3095890410959 4.33424657534247 0 0 0 0 0 0 0
"215" 68.7342465753425 64.8520547945206 1.47123287671233 0 0 0 0 0 0 0
"216" 57.6191780821918 65.5068493150685 3.14794520547945 0 0 0 0 0 0 0
"217" 63.6739726027397 60.7643835616438 4.76164383561644 0 0 0 0 0 0 0
"218" 64.4520547945205 60.0164383561644 4.41917808219178 0 0 0 0 0 0 0
"219" 74.0904109589041 65.1643835616438 4.95342465753425 0 0 0 0 0 0 0
"220" 82.3808219178082 78.3041095890411 5.00821917808219 0 0 0 0 0 0 0
"221" 58.0602739726027 61.2054794520548 4.5041095890411 0 0 0 0 0 0 0
"222" 63.7671232876712 66.0219178082192 1.25205479452055 1 0 0 0 0 0 0
"223" 60.5753424657534 65.1780821917808 5.00821917808219 0 0 0 0 0 0 0
"224" 65.6794520547945 65.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"225" 60.7671232876712 64.9945205479452 0.271232876712329 0 0 0 0 0 0 0
"226" 72.1671232876712 83.3232876712329 2.91780821917808 0 0 1 0 1 0 0.00547945205479452
"227" 55.7452054794521 65.172602739726 4.91506849315068 0 0 0 0 0 0 0
"228" 64.9534246575342 66.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"229" 65.0438356164384 65.4602739726027 2.17808219178082 0 0 0 0 0 0 0
"230" 67.1342465753425 69.8712328767123 4.41917808219178 0 0 0 0 0 0 0
"231" 53.7506849315068 65.0383561643836 3.08493150684932 0 0 0 0 0 0 0
"232" 61.9616438356164 65.3095890410959 2.23013698630137 0 0 0 0 0 0 0
"233" 64.8164383561644 65.1205479452055 0.928767123287671 0 0 0 0 0 0 0
"234" 60.6684931506849 64.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"235" 45.3890410958904 64.572602739726 5.00821917808219 0 0 0 0 0 0 0
"236" 69.4547945205479 67.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"237" 63.8520547945205 65.5424657534247 5.00821917808219 0 0 0 0 0 0 0
"238" 63.7698630136986 65.4602739726027 2.58356164383562 1 0 0 0 0 0 0
"239" 61.9013698630137 65.7424657534247 5.00821917808219 0 0 0 0 0 0 0
"240" 60.6794520547945 65.8082191780822 1.71232876712329 0 0 0 0 0 0 0
"241" 59.4082191780822 62.7013698630137 5.00821917808219 0 0 0 0 0 0 0
"242" 86.8794520547945 88.3123287671233 4.4986301369863 0 0 0 0 1 0 3.83287671232877
"243" 59.2712328767123 64.7917808219178 3.18904109589041 0 0 0 0 0 0 0
"244" 60.7013698630137 68.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"245" 75.358904109589 76.6301369863014 3.75068493150685 1 0 0 0 0 0 0
"246" 70.0328767123288 72.2027397260274 4.4986301369863 1 0 0 0 0 0 0
"247" 67.3232876712329 66.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"248" 59.7452054794521 65.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"249" 71.654794520548 66.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"250" 66.4109589041096 65.9452054794521 5.00821917808219 0 0 0 0 0 0 0
"251" 64.2712328767123 65.027397260274 3.16712328767123 0 0 0 0 0 0 0
"252" 68.2849315068493 64.9123287671233 3 0 0 0 0 0 0 0
"253" 65.2876712328767 65.2493150684931 3.63013698630137 0 0 0 0 0 0 0
"254" 68.8657534246575 65.227397260274 5.00821917808219 0 0 0 0 0 0 0
"255" 61.9479452054794 65.345205479452 3.75342465753425 0 0 0 0 0 0 0
"256" 73.9232876712329 75.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"257" 61.4027397260274 65.4328767123288 0.742465753424657 0 0 0 0 0 0 0
"258" 24.4109589041096 64.7123287671233 0.671232876712329 0 0 0 0 0 0 0
"259" 65.5643835616438 65.0547945205479 2.5041095890411 0 0 0 0 0 0 0
"260" 64.4602739726027 69.2684931506849 5.00821917808219 0 0 0 0 0 0 0
"261" 60.4602739726027 64.7945205479452 1 0 0 0 0 0 0 0
"262" 69.9561643835616 65.3835616438356 2.6958904109589 0 0 0 0 0 0 0
"263" 60.6657534246575 65.4356164383562 0.83013698630137 0 0 0 0 0 0 0
"264" 62.8794520547945 64.813698630137 2.6958904109589 0 0 0 0 0 0 0
"265" 62.2958904109589 65.1369863013699 2.36712328767123 0 0 0 0 0 0 0
"266" 85.4904109589041 85.6931506849315 0.750684931506849 0 0 0 0 1 0 0.0246575342465753
"267" 67.9205479452055 69.3698630136986 5.00821917808219 0 0 0 0 0 0 0
"268" 63.4712328767123 64.8958904109589 1.5041095890411 0 0 0 0 0 0 0
"269" 64.5041095890411 65.2 1.67123287671233 0 0 0 0 0 0 0
"270" 60.2465753424658 65.0164383561644 3.26301369863014 0 0 0 0 0 0 0
"271" 57.0794520547945 65.3671232876712 4.72602739726027 0 0 0 0 0 0 0
"272" 59.5013698630137 64.2219178082192 3.07671232876712 0 0 0 0 0 0 0
"273" 64.986301369863 64.5506849315069 1.17534246575342 0 0 0 0 0 0 0
"274" 64.0684931506849 64.9452054794521 3.83835616438356 0 0 0 0 0 0 0
"275" 63.7013698630137 63.3068493150685 5.00821917808219 0 0 0 0 0 0 0
"276" 49.2986301369863 64.7205479452055 5.00821917808219 0 0 0 0 0 0 0
"277" 64.4684931506849 65.6931506849315 4.33424657534247 0 0 0 0 0 0 0
"278" 45.6657534246575 64.8657534246575 0.0465753424657534 0 0 0 0 0 0 0
"279" 41.6328767123288 64.8684931506849 3.85479452054795 0 0 0 0 0 0 0
"280" 60.8164383561644 64.8931506849315 3.33424657534247 0 0 0 0 0 0 0
"281" 61.772602739726 66.0794520547945 5.00821917808219 0 0 0 0 0 0 0
"282" 69.7205479452055 69.6082191780822 3.08767123287671 0 1 0 0 0 0 0
"283" 59.1917808219178 66.2246575342466 1.64109589041096 0 0 0 0 0 0 0
"284" 64.2164383561644 65.1561643835616 2.99178082191781 0 0 0 0 0 0 0
"285" 62.8657534246575 65.413698630137 0.147945205479452 0 0 0 1 0 0.750684931506849 0
"286" 66.4109589041096 65.9479452054795 1.55616438356164 0 0 0 0 0 0 0
"287" 61.2767123287671 65.3780821917808 1.41917808219178 0 0 0 0 0 0 0
"288" 57.172602739726 65.8547945205479 1.91506849315068 0 0 0 0 0 0 0
"289" 59.6876712328767 63.1315068493151 0.950684931506849 0 0 0 0 0 0 0
"290" 60.3287671232877 60.0931506849315 0.838356164383562 0 0 0 0 0 0 0
"291" 66.3424657534247 65.9178082191781 1.91506849315068 0 0 0 0 0 0 0
"292" 63.4876712328767 64.3643835616438 0.243835616438356 0 0 0 0 0 0 0
"293" 76.6684931506849 70.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"294" 58.2328767123288 72.7397260273973 4.58356164383562 1 0 0 0 0 0 0
"295" 58.8657534246575 65.0109589041096 0.0821917808219178 0 0 0 0 0 0 0
"296" 67.4438356164383 65.627397260274 0.915068493150685 0 0 0 0 0 0 0
"297" 64.6109589041096 65.4931506849315 1.5041095890411 0 0 0 0 0 0 0
"298" 73.4520547945205 73.7068493150685 5.00821917808219 0 0 0 0 0 0 0
"299" 69.8082191780822 66.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"300" 60.0465753424658 65.9808219178082 5.00821917808219 0 0 0 0 0 0 0
"301" 60.9643835616438 60.0520547945206 5.00821917808219 0 0 0 0 0 0 0
"302" 57.7698630136986 60.6520547945205 4.15342465753425 0 0 0 0 0 0 0
"303" 60.5534246575342 63.772602739726 4.15342465753425 0 0 0 0 0 0 0
"304" 71.5178082191781 71.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"305" 30.0465753424658 60.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"306" 74.5342465753425 74.5479452054795 0 0 0 0 1 0 2.41643835616438 0
"307" 69.2876712328767 65.7534246575343 3.73150684931507 0 0 0 0 0 0 0
"308" 65.6164383561644 68.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"309" 77.3287671232877 74.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"310" 48.4876712328767 65.4794520547945 1.75068493150685 1 0 0 0 0 0 0
"311" 63.0191780821918 65.4328767123288 0.504109589041096 0 0 0 0 0 0 0
"312" 66.345205479452 65.0054794520548 5.00821917808219 0 0 0 0 0 0 0
"313" 60.558904109589 64.6739726027397 4.33424657534247 0 0 0 0 0 0 0
"314" 54.5232876712329 64.8 5.00821917808219 0 0 0 0 0 0 0
"315" 79.8054794520548 79.641095890411 0 0 0 0 1 0 0.350684931506849 0
"316" 64.027397260274 65.7890410958904 1.65205479452055 0 0 0 0 0 0 0
"317" 62.3397260273973 65.5452054794521 0.753424657534247 0 0 0 0 0 0 0
"318" 71.1835616438356 76.9506849315069 5.00821917808219 0 0 0 0 0 0 0
"319" 77.5698630136986 78.186301369863 5.00821917808219 0 0 0 0 0 0 0
"320" 86.0794520547945 85.3479452054794 2.91780821917808 1 0 0 0 0 0 0
"321" 68.7178082191781 67.0986301369863 5.00821917808219 0 0 0 0 0 0 0
"322" 58.7643835616438 63.8356164383562 2.74520547945205 0 0 0 0 0 0 0
"323" 63.0465753424658 66.372602739726 5.00821917808219 0 0 0 0 0 0 0
"324" 63.0712328767123 65.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"325" 57.3342465753425 61.6109589041096 2.9041095890411 0 0 0 0 0 0 0
"326" 61.641095890411 65.4 4.41917808219178 0 0 0 0 0 0 0
"327" 58.4821917808219 61.758904109589 5.00821917808219 0 0 0 0 0 0 0
"328" 63.7178082191781 65.3561643835616 5.00821917808219 0 0 0 0 0 0 0
"329" 64.5616438356164 65.2958904109589 4.62465753424657 0 0 0 0 0 0 0
"330" 52.4712328767123 65.6191780821918 4.67123287671233 0 0 0 0 0 0 0
"331" 64.2547945205479 65.7561643835616 0.742465753424657 0 0 0 0 0 0 0
"332" 60.5808219178082 65.3780821917808 1.30684931506849 0 0 0 0 0 0 0
"333" 70.9315068493151 66.4876712328767 5.00821917808219 0 0 0 0 0 0 0
"334" 65.9452054794521 60.3013698630137 1.16712328767123 0 0 0 0 0 0 0
"335" 64.3890410958904 66.786301369863 5.00821917808219 0 0 0 0 0 0 0
"336" 64.7972602739726 65.3232876712329 5.00821917808219 0 0 0 0 0 0 0
"337" 56.2301369863014 64.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"338" 65.3479452054794 70.6054794520548 0.0876712328767123 1 0 0 0 0 0 0
"339" 61.8438356164384 60.7506849315068 5.00821917808219 0 0 0 0 0 0 0
"340" 61.2958904109589 64.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"341" 65.6054794520548 65.6246575342466 3.47397260273973 0 0 0 0 0 0 0
"342" 75.6684931506849 81.6301369863014 3.08767123287671 0 1 0 0 0 0 0
"343" 68.8438356164384 68.6657534246575 5.00821917808219 0 0 0 0 0 0 0
"344" 55.627397260274 65.3972602739726 0.252054794520548 0 0 0 0 0 0 0
"345" 63.7013698630137 65.0739726027397 3 0 0 0 0 0 0 0
"346" 63.0657534246575 65.8986301369863 0.0301369863013699 0 0 0 0 0 0 0
"347" 62.1780821917808 64.8794520547945 2.5041095890411 0 0 0 0 0 0 0
"348" 83.7671232876712 84.9835616438356 0.668493150684932 0 0 0 1 0 0.0438356164383562 0
"349" 83.8493150684932 85.0657534246575 0.668493150684932 0 0 0 1 0 0.0438356164383562 0
"350" 64.5150684931507 63.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"351" 79.0739726027397 87.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"352" 73.0767123287671 80.8301369863014 4.66849315068493 1 0 0 0 0 0 0
"353" 71.6876712328767 80.2547945205479 0.750684931506849 0 0 0 0 1 0 4.16986301369863
"354" 61.7534246575342 60.2602739726027 4.67123287671233 0 0 0 0 0 0 0
"355" 63.1342465753425 65.2082191780822 1.4986301369863 1 0 0 0 0 0 0
"356" 62.7753424657534 65.2958904109589 0.334246575342466 0 0 0 0 0 0 0
"357" 77.0602739726027 75.3780821917808 2.58356164383562 1 0 0 0 0 0 0
"358" 66.5616438356164 66.2328767123288 3.46027397260274 0 0 0 0 0 0 0
"359" 63.9671232876712 66.558904109589 5.00821917808219 0 0 0 0 0 0 0
"360" 31.4904109589041 65.9561643835616 4.47945205479452 0 0 0 0 0 0 0
"361" 63.7342465753425 65.4602739726027 3.62465753424658 0 0 0 0 0 0 0
"362" 66.0821917808219 65.4109589041096 3.33424657534247 0 0 0 0 0 0 0
"363" 65.5945205479452 65.2301369863014 0.202739726027397 0 0 0 0 0 0 0
"364" 59.8712328767123 60.1260273972603 3.25205479452055 0 0 0 0 0 0 0
"365" 57.2109589041096 65.386301369863 2.66575342465753 0 0 0 0 0 0 0
"366" 58.3397260273973 65.758904109589 1.12054794520548 0 0 0 0 0 0 0
"367" 90.9123287671233 92.2027397260274 1.24931506849315 0 0 0 0 1 0 1.33698630136986
"368" 92.7068493150685 91.4164383561644 1.24931506849315 0 0 0 1 0 1.33698630136986 0
"369" 65.2876712328767 65.4438356164383 1.41917808219178 0 0 0 0 0 0 0
"370" 68.9287671232877 71.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"371" 69.6328767123288 69.9479452054795 5.00821917808219 0 0 0 0 0 0 0
"372" 65.427397260274 65.5095890410959 1.41917808219178 0 0 0 0 0 0 0
"373" 65.6383561643836 65.6575342465753 2.41917808219178 0 0 0 0 0 0 0
"374" 67.1972602739726 69.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"375" 58.9452054794521 64.5095890410959 5 0 0 0 0 0 0 0
"376" 63.2657534246575 67.8904109589041 5.00821917808219 0 0 0 0 0 0 0
"377" 57.4849315068493 65.6630136986301 0.671232876712329 0 0 0 0 0 0 0
"378" 57.7698630136986 64.4438356164383 1.95342465753425 0 0 0 0 0 0 0
"379" 64.5835616438356 65.5698630136986 1.58630136986301 0 0 0 0 0 0 0
"380" 58.4958904109589 65.1835616438356 0.671232876712329 0 0 0 0 0 0 0
"381" 64.5315068493151 65.172602739726 1.53698630136986 0 0 0 0 0 0 0
"382" 63.4849315068493 64.4191780821918 2.24931506849315 1 0 0 0 0 0 0
"383" 63.5342465753425 66.1452054794521 2.27123287671233 0 0 0 0 0 0 0
"384" 63.2931506849315 65.1205479452055 2.16712328767123 0 0 0 0 0 0 0
"385" 54.7561643835616 65.2630136986301 4.67123287671233 0 0 0 0 0 0 0
"386" 63.5835616438356 66.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"387" 61.1260273972603 65.1452054794521 0.810958904109589 0 0 0 0 0 0 0
"388" 61.6712328767123 60.558904109589 1.33424657534247 0 0 0 0 0 0 0
"389" 69.041095890411 67.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"390" 57.0739726027397 57.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"391" 52.2986301369863 57.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"392" 35.6027397260274 64.9123287671233 0.252054794520548 0 0 0 0 0 0 0
"393" 64.3397260273973 67.8027397260274 0.249315068493151 1 0 0 0 0 0 0
"394" 64.0356164383562 65.3068493150685 1.33424657534247 0 0 0 0 0 0 0
"395" 79.241095890411 74.3123287671233 5.00821917808219 0 0 0 0 0 0 0
"396" 68.9534246575342 66.827397260274 5.00821917808219 0 0 0 0 0 0 0
"397" 64.4794520547945 65.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"398" 51.9178082191781 62.4767123287671 1.12602739726027 0 0 0 0 0 0 0
"399" 56.4630136986301 61.6164383561644 3.97534246575342 0 0 0 0 0 0 0
"400" 61.3890410958904 67.2301369863014 5.00821917808219 0 0 0 0 0 0 0
"401" 51.8438356164384 55.7835616438356 2.43835616438356 0 0 0 0 0 0 0
"402" 56.4547945205479 70.7808219178082 1.67123287671233 0 0 0 0 0 0 0
"403" 60.3808219178082 61.0520547945206 4.66301369863014 0 0 0 0 0 0 0
"404" 60.2465753424658 65.9561643835616 5.00821917808219 0 0 0 0 0 0 0
"405" 52.9479452054794 68.3260273972603 5.00821917808219 0 0 0 0 0 0 0
"406" 39.6630136986301 62.3205479452055 1.99452054794521 0 0 0 0 0 0 0
"407" 53.5424657534247 64.9452054794521 3.41917808219178 0 0 0 0 0 0 0
"408" 56.1369863013699 62.0493150684932 5.00821917808219 0 0 0 0 0 0 0
"409" 61.0904109589041 62.9424657534247 4.66301369863014 0 0 0 0 0 0 0
"410" 60.7150684931507 64.4191780821918 2.25479452054795 0 0 0 0 0 0 0
"411" 56.2684931506849 62.358904109589 5.00821917808219 0 0 0 0 0 0 0
"412" 62.9561643835616 65.1698630136986 1.58630136986301 0 0 0 0 0 0 0
"413" 56.2904109589041 57.4246575342466 0.586301369863014 0 0 0 0 0 0 0
"414" 63.9424657534247 64.6109589041096 3.73972602739726 0 0 0 0 0 0 0
"415" 49.413698630137 61.5397260273973 1.16712328767123 0 0 0 0 0 0 0
"416" 76.0301369863014 78.4520547945205 5.00821917808219 0 0 0 0 0 0 0
"417" 85.8657534246575 85.5917808219178 0 0 0 0 0 1 0 4.33698630136986
"418" 76.7945205479452 79.9534246575342 5.00821917808219 0 0 0 0 0 0 0
"419" 87.3561643835616 86.8931506849315 3.75068493150685 1 0 0 0 0 0 0
"420" 59.1643835616438 65.5232876712329 1.33424657534247 0 0 0 0 0 0 0
"421" 82.6383561643836 86.6739726027397 0 0 0 0 0 1 0 1.24657534246575
"422" 78.0904109589041 77.3013698630137 2.24931506849315 1 0 0 0 0 0 0
"423" 66.3643835616438 65.386301369863 1.50684931506849 0 0 0 0 0 0 0
"424" 64.3232876712329 65.8904109589041 0.567123287671233 0 0 0 0 0 0 0
"425" 73.4164383561644 76.986301369863 1.4986301369863 1 0 0 0 0 0 0
"426" 49.358904109589 64.5095890410959 2.33424657534247 0 0 0 0 0 0 0
"427" 63.1342465753425 65.6684931506849 3.66849315068493 1 0 0 0 0 0 0
"428" 60.6191780821918 65.0109589041096 3 0 0 0 0 0 0 0
"429" 64.6958904109589 65.4630136986301 3.38630136986301 0 0 0 0 0 0 0
"430" 61.8958904109589 65.6438356164384 4.46849315068493 0 0 0 0 0 0 0
"431" 73.1808219178082 65.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"432" 55.9890410958904 65.1561643835616 2.5041095890411 0 0 0 0 0 0 0
"433" 47.3150684931507 65.0657534246575 1.06849315068493 0 0 0 0 0 0 0
"434" 51.6602739726027 61.8493150684931 0.83013698630137 0 0 0 0 0 0 0
"435" 62.0109589041096 63.6986301369863 2.45753424657534 0 0 0 0 0 0 0
"436" 76.9890410958904 76.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"437" 76.6602739726027 77.4575342465753 5.00821917808219 0 0 0 0 0 0 0
"438" 76.6602739726027 77.4575342465753 5.00821917808219 0 0 0 0 0 0 0
"439" 81.1452054794521 82.6739726027397 2.41643835616438 1 0 0 0 0 0 0
"440" 58.3561643835616 68.4 5.00821917808219 0 0 0 0 0 0 0
"441" 57.1890410958904 59.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"442" 69.9342465753425 69.0986301369863 5.00821917808219 0 0 0 0 0 0 0
"443" 61.4054794520548 66.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"444" 46.2191780821918 65.5479452054795 3.58630136986301 0 0 0 0 0 0 0
"445" 77.0821917808219 77.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"446" 66.4109589041096 65.627397260274 2.94520547945205 0 0 0 0 0 0 0
"447" 64.5342465753425 61.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"448" 52.172602739726 65.0164383561644 3.05479452054795 0 0 0 0 0 0 0
"449" 65.3287671232877 65.6082191780822 1.16438356164384 1 0 0 0 0 0 0
"450" 58.7068493150685 65.7972602739726 4.83835616438356 0 0 0 0 0 0 0
"451" 61.3287671232877 65.1561643835616 1.02465753424658 0 0 0 0 0 0 0
"452" 60.2821917808219 65.8767123287671 0.904109589041096 0 0 0 0 0 0 0
"453" 70.3150684931507 67.4739726027397 5.00821917808219 0 0 0 0 0 0 0
"454" 62.1041095890411 65.5315068493151 2.34246575342466 0 0 0 0 0 0 0
"455" 65.1780821917808 65.0301369863014 1 0 0 0 0 0 0 0
"456" 60.1397260273973 65.3561643835616 5.00821917808219 0 0 0 0 0 0 0
"457" 59.7506849315068 60.5972602739726 1.67123287671233 0 0 0 0 0 0 0
"458" 76.9890410958904 76.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"459" 76.6602739726027 77.4575342465753 5.00821917808219 0 0 0 0 0 0 0
"460" 56.572602739726 63.6684931506849 5.00821917808219 0 0 0 0 0 0 0
"461" 76.427397260274 77.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"462" 81.1452054794521 82.6739726027397 2.41643835616438 1 0 0 0 0 0 0
"463" 62.4164383561644 63.4328767123288 5.00821917808219 0 0 0 0 0 0 0
"464" 58.3561643835616 68.4 5.00821917808219 0 0 0 0 0 0 0
"465" 66.1452054794521 72.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"466" 68.1123287671233 68.9890410958904 1.66849315068493 1 0 0 0 0 0 0
"467" 68.241095890411 68.4246575342466 3.41643835616438 1 0 0 0 0 0 0
"468" 66.6383561643836 70.1945205479452 0.750684931506849 1 0 0 0 0 0 0
"469" 67.2739726027397 60.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"470" 65.3260273972603 73.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"471" 62.1150684931507 62.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"472" 64.2986301369863 66.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"473" 71.6082191780822 74.641095890411 5.00821917808219 0 0 0 0 0 0 0
"474" 59.1315068493151 64.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"475" 75.6712328767123 71.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"476" 58.3260273972603 60.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"477" 77.0821917808219 77.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"478" 68.7808219178082 79.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"479" 63.3917808219178 65.641095890411 5.00821917808219 0 0 0 0 0 0 0
"480" 72.2438356164384 75.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"481" 72.1917808219178 76.8520547945206 5.00821917808219 0 0 0 0 0 0 0
"482" 79.6328767123288 82.5424657534247 3.41643835616438 0 1 0 0 0 0 0
"483" 66.8164383561644 79.2821917808219 0.416438356164384 1 0 0 0 0 0 0
"484" 72.5315068493151 80.8547945205479 1.75068493150685 1 0 0 0 0 0 0
"485" 68.7068493150685 86.7452054794521 3.0027397260274 0 0 0 0 1 0 0.010958904109589
"486" 72.5095890410959 78.3616438356164 5.00821917808219 0 0 0 0 0 0 0
"487" 71.5287671232877 77.3479452054794 5.00821917808219 0 0 0 0 0 0 0
"488" 64.641095890411 70.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"489" 73.3479452054794 77.5479452054795 5.00821917808219 0 0 0 0 0 0 0
"490" 65.372602739726 74.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"491" 70.5095890410959 74.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"492" 56.8739726027397 57.6794520547945 3.73150684931507 0 0 0 0 0 0 0
"493" 73.7068493150685 74.7671232876712 0.750684931506849 0 1 0 0 0 0 0
"494" 71.2794520547945 74.2383561643836 5.00821917808219 0 0 0 0 0 0 0
"495" 74.2383561643836 76.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"496" 65.6465753424658 71.8657534246575 5.00821917808219 0 0 0 0 0 0 0
"497" 70.0657534246575 72.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"498" 73.5232876712329 75.641095890411 4.83561643835616 1 0 0 0 0 0 0
"499" 64.5178082191781 73.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"500" 69.3945205479452 72.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"501" 64.8356164383562 71.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"502" 75.2383561643836 79.9616438356164 3.08767123287671 0 1 0 0 0 0 0
"503" 69.241095890411 71.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"504" 69.3698630136986 71.6986301369863 5.00821917808219 0 0 0 0 0 0 0
"505" 60.5452054794521 76.8219178082192 5.00821917808219 0 0 0 0 0 0 0
"506" 70.7068493150685 73.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"507" 70.6164383561644 71.8739726027397 1.24931506849315 1 0 0 0 0 0 0
"508" 74.3616438356164 73.1753424657534 5.00821917808219 0 0 0 0 0 0 0
"509" 73.772602739726 80.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"510" 73.0493150684931 71.6109589041096 5.00821917808219 0 0 0 0 0 0 0
"511" 63.9260273972603 66.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"512" 71.1123287671233 71.8438356164384 5.00821917808219 0 0 0 0 0 0 0
"513" 74.8958904109589 76.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"514" 85.3479452054794 85.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"515" 77.2739726027397 82.5424657534247 3.08767123287671 0 1 0 0 0 0 0
"516" 87.9972602739726 85.6849315068493 4.08767123287671 1 0 0 0 0 0 0
"517" 87.9972602739726 86.1835616438356 0 0 0 0 0 1 0 1.4986301369863
"518" 72.7287671232877 78.8219178082192 4.33150684931507 1 0 0 0 0 0 0
"519" 84.4027397260274 84.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"520" 87.9972602739726 83.1068493150685 2.58356164383562 1 0 0 0 0 0 0
"521" 87.9972602739726 88.5205479452055 0.750684931506849 0 1 0 0 0 0 0
"522" 75.1479452054794 72.572602739726 5.00821917808219 0 0 0 0 0 0 0
"523" 66.0191780821918 68.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"524" 64.6712328767123 67.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"525" 63.586301369863 66.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"526" 64.2821917808219 63.4547945205479 1.24931506849315 1 0 0 0 0 0 0
"527" 64.4383561643836 65.9479452054795 2.42191780821918 1 0 0 0 0 0 0
"528" 66.1095890410959 63.0657534246575 3.91506849315068 0 0 0 0 0 0 0
"529" 58.3068493150685 65.586301369863 1.66849315068493 1 0 0 0 0 0 0
"530" 63.641095890411 68.2328767123288 2.40547945205479 0 0 0 0 0 0 0
"531" 71.4109589041096 68.441095890411 5.00821917808219 0 0 0 0 0 0 0
"532" 56.0767123287671 58.2054794520548 3.35890410958904 0 0 0 0 0 0 0
"533" 73.7397260273973 75.4986301369863 5.00821917808219 0 0 0 0 0 0 0
"534" 70.0493150684931 72.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"535" 59.1808219178082 65.3041095890411 3.33424657534247 0 0 0 0 0 0 0
"536" 66.4219178082192 65.6657534246575 4.67123287671233 0 0 0 0 0 0 0
"537" 59.6191780821918 65.0794520547945 2 0 0 0 0 0 0 0
"538" 71.0054794520548 75.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"539" 72.4328767123288 75.9397260273973 3.83561643835616 0 0 1 0 1 0 0.0684931506849315
"540" 66.2739726027397 70.3232876712329 5.00821917808219 0 0 0 0 0 0 0
"541" 71.1534246575342 71.758904109589 5.00821917808219 0 0 0 0 0 0 0
"542" 64.3205479452055 68.3068493150685 5.00821917808219 0 0 0 0 0 0 0
"543" 67.1342465753425 63.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"544" 66.1342465753425 68.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"545" 77.0191780821918 78.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"546" 72.041095890411 76.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"547" 70.3205479452055 68.2191780821918 5.00821917808219 0 0 0 0 0 0 0
"548" 51.5972602739726 67.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"549" 71.3150684931507 72.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"550" 72.158904109589 76.8 5.00821917808219 0 0 0 0 0 0 0
"551" 57 66.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"552" 63.1972602739726 65.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"553" 53.3890410958904 60.0438356164384 1.41643835616438 1 0 0 0 0 0 0
"554" 65.9506849315069 67.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"555" 82.2027397260274 83.2054794520548 0.416438356164384 0 0 0 1 0 2.42191780821918 0
"556" 59.9753424657534 66.9068493150685 5.00821917808219 0 0 0 0 0 0 0
"557" 71.9753424657534 74.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"558" 80.4547945205479 72.4821917808219 3.83561643835616 1 0 0 0 0 0 0
"559" 77.358904109589 81.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"560" 59.3972602739726 66.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"561" 71.7452054794521 76.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"562" 57.6383561643836 63.6739726027397 5.00821917808219 0 0 0 0 0 0 0
"563" 69.1452054794521 71.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"564" 66.5671232876712 69.5671232876712 4.08767123287671 0 1 0 0 0 0 0
"565" 83.1342465753425 87.9561643835616 4.24931506849315 0 0 0 1 0 0.775342465753425 0
"566" 70.8 77.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"567" 68.3342465753425 68.2712328767123 5.00821917808219 0 0 0 0 0 0 0
"568" 70.3178082191781 70.613698630137 5.00821917808219 0 0 0 0 0 0 0
"569" 79.345205479452 75.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"570" 65.6657534246575 75.7068493150685 5.00821917808219 0 0 0 0 0 0 0
"571" 59.0876712328767 69 5.00821917808219 0 0 0 0 0 0 0
"572" 64.8876712328767 63.9917808219178 4 0 0 0 0 0 0 0
"573" 70.6027397260274 67.1178082191781 5.00821917808219 0 0 0 0 0 0 0
"574" 60.6547945205479 72.8356164383562 3.4986301369863 1 0 0 0 0 0 0
"575" 78.6849315068493 77.9232876712329 5.00821917808219 0 0 0 0 0 0 0
"576" 64.213698630137 66.6191780821918 5.00821917808219 0 0 0 0 0 0 0
"577" 71.0794520547945 69.9917808219178 5.00821917808219 0 0 0 0 0 0 0
"578" 75.8246575342466 76.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"579" 67.6328767123288 68.8575342465753 0.331506849315069 1 0 0 0 0 0 0
"580" 66.6383561643836 74.7808219178082 3.4986301369863 1 0 0 0 0 0 0
"581" 69.8602739726027 77.9534246575342 2.83561643835616 0 0 1 0 1 0 0.0191780821917808
"582" 61.558904109589 65.586301369863 0.835616438356164 0 1 0 0 0 0 0
"583" 79.841095890411 77.5808219178082 3.08767123287671 0 1 0 0 0 0 0
"584" 59.9178082191781 69.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"585" 34.9917808219178 68.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"586" 41.8931506849315 72.4630136986301 5.00821917808219 0 0 0 0 0 0 0
"587" 71.1452054794521 64.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"588" 63.3616438356164 65.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"589" 73.6328767123288 75.0986301369863 5.00821917808219 0 0 0 0 0 0 0
"590" 71.3123287671233 71.3041095890411 0.583561643835616 0 1 0 0 0 0 0
"591" 61.413698630137 66.0547945205479 5.00821917808219 0 0 0 0 0 0 0
"592" 56.6520547945205 58.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"593" 60.5150684931507 66.986301369863 5.00821917808219 0 0 0 0 0 0 0
"594" 68.0438356164384 66.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"595" 69.0547945205479 70.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"596" 68.7561643835616 74.1808219178082 5.00821917808219 0 0 0 0 0 0 0
"597" 69.2821917808219 80.8712328767123 5.00821917808219 0 0 0 0 0 0 0
"598" 59.4794520547945 70.2164383561644 2.24931506849315 0 1 0 0 0 0 0
"599" 47.4575342465753 63.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"600" 79.9123287671233 82.7232876712329 2.41643835616438 0 0 1 0 1 0 0.0575342465753425
"601" 66.3205479452055 67.9150684931507 5.00821917808219 0 0 0 0 0 0 0
"602" 65.413698630137 63.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"603" 64.6027397260274 67.4082191780822 5.00821917808219 0 0 0 0 0 0 0
"604" 65.5643835616438 69.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"605" 62.2739726027397 67.641095890411 5.00821917808219 0 0 0 0 0 0 0
"606" 53.5205479452055 79.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"607" 64.3369863013699 68.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"608" 66.0383561643836 68.4684931506849 5.00821917808219 0 0 0 0 0 0 0
"609" 65.9123287671233 64.9643835616438 3.91506849315068 0 0 0 0 0 0 0
"610" 66.0712328767123 67.2712328767123 5.00821917808219 0 0 0 0 0 0 0
"611" 67.6739726027397 67.786301369863 5.00821917808219 0 0 0 0 0 0 0
"612" 54.8027397260274 63.2438356164384 5.00821917808219 0 0 0 0 0 0 0
"613" 60.8246575342466 65.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"614" 73.7561643835616 73.1232876712329 3.33150684931507 1 0 0 0 0 0 0
"615" 73.4684931506849 73.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"616" 61.0739726027397 65.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"617" 66.654794520548 68.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"618" 61.8657534246575 62.6328767123288 5.00821917808219 0 0 0 0 0 0 0
"619" 69.8219178082192 62.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"620" 65.1753424657534 74.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"621" 61.4602739726027 70.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"622" 62.5287671232877 64.8630136986301 3.9972602739726 0 0 0 0 0 0 0
"623" 66.4958904109589 62.4547945205479 5.00821917808219 0 0 0 0 0 0 0
"624" 62.8958904109589 65.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"625" 49.9561643835616 60.9315068493151 5.00821917808219 0 0 0 0 0 0 0
"626" 77.6602739726027 80.3945205479452 3.08767123287671 0 0 1 0 1 0 0.00273972602739726
"627" 54.1479452054795 64.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"628" 76.7945205479452 76.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"629" 59.5232876712329 68.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"630" 67.2054794520548 67.9890410958904 5.0027397260274 0 1 0 0 0 0 0
"631" 50.3260273972603 55.9506849315068 5.00821917808219 0 0 0 0 0 0 0
"632" 71.3780821917808 71.8465753424658 4.75068493150685 1 0 0 0 0 0 0
"633" 61.6356164383562 63.7479452054795 4.83287671232877 0 0 0 0 0 0 0
"634" 71.2191780821918 73.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"635" 63.5260273972603 65.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"636" 61.3945205479452 62.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"637" 62.9945205479452 74.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"638" 72.8054794520548 75.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"639" 52.1890410958904 57.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"640" 62.9315068493151 65.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"641" 61.0383561643836 63.3671232876712 3.67123287671233 0 0 0 0 0 0 0
"642" 70.2602739726027 72.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"643" 64.841095890411 67.3616438356164 5.00821917808219 0 0 0 0 0 0 0
"644" 73.0356164383562 76.8027397260274 2.75068493150685 1 0 0 0 0 0 0
"645" 58.5753424657534 68.613698630137 5.00821917808219 0 0 0 0 0 0 0
"646" 62.0246575342466 65.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"647" 43.0876712328767 53.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"648" 70.6767123287671 67.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"649" 52.2520547945205 56.241095890411 5.00821917808219 0 0 0 0 0 0 0
"650" 68.8246575342466 75.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"651" 76.6712328767123 75.8 4.33150684931507 0 1 0 0 0 0 0
"652" 48.0931506849315 67.4246575342466 2.08767123287671 1 0 0 0 0 0 0
"653" 60.2191780821918 68.9506849315069 5.00821917808219 0 0 0 0 0 0 0
"654" 60.9945205479452 72.9917808219178 5.00821917808219 0 0 0 0 0 0 0
"655" 75.1753424657534 75.2465753424657 5.00821917808219 0 0 0 0 0 0 0
"656" 63.8109589041096 65.9753424657534 4.4986301369863 1 0 0 0 0 0 0
"657" 61.4712328767123 65.586301369863 4.64657534246575 0 0 0 0 0 0 0
"658" 61.4712328767123 65.586301369863 4.64657534246575 0 0 0 0 0 0 0
"659" 62.8602739726027 68.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"660" 62.4191780821918 65.4438356164383 5.00821917808219 0 0 0 0 0 0 0
"661" 65.2684931506849 71.7041095890411 5.00821917808219 0 0 0 0 0 0 0
"662" 74.4657534246575 75.172602739726 4.41643835616438 1 0 0 0 0 0 0
"663" 66.3945205479452 65.1479452054794 5.00821917808219 0 0 0 0 0 0 0
"664" 58.2465753424658 67.8383561643836 5.00821917808219 0 0 0 0 0 0 0
"665" 69.6219178082192 68.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"666" 56.2383561643836 59.5753424657534 5.00821917808219 0 0 0 0 0 0 0
"667" 63.7753424657534 65.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"668" 57.5917808219178 62.9260273972603 0.331506849315069 1 0 0 0 0 0 0
"669" 68.9424657534247 72.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"670" 64.213698630137 67.6383561643836 5.00821917808219 0 0 0 0 0 0 0
"671" 73.2821917808219 74.8082191780822 1.91780821917808 1 0 0 0 0 0 0
"672" 74.1835616438356 69.5123287671233 4.89041095890411 0 0 0 0 0 0 0
"673" 70.5698630136986 69.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"674" 67.5753424657534 59.4520547945205 4.64657534246575 0 0 0 0 0 0 0
"675" 66.7178082191781 67.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"676" 53.0301369863014 62.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"677" 60.3452054794521 66.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"678" 76.6739726027397 79.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"679" 61.6493150684932 64.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"680" 63.4328767123288 67.5232876712329 2.83561643835616 0 1 0 0 0 0 0
"681" 57.4027397260274 59.9780821917808 1.91780821917808 1 0 0 0 0 0 0
"682" 79.8931506849315 74.2931506849315 4.24931506849315 0 1 0 0 0 0 0
"683" 67.6602739726027 66.172602739726 5.00821917808219 0 0 0 0 0 0 0
"684" 66.0438356164384 72.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"685" 65.8712328767123 76.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"686" 38.386301369863 42.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"687" 73.4027397260274 67.5616438356164 5.00821917808219 0 0 0 0 0 0 0
"688" 50.2328767123288 53.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"689" 70.8219178082192 68.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"690" 62.9616438356164 65.654794520548 5.00821917808219 0 0 0 0 0 0 0
"691" 45.1479452054795 47.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"692" 59.7150684931507 65.241095890411 4.24931506849315 1 0 0 0 0 0 0
"693" 66.7178082191781 64.5369863013699 5.00821917808219 0 0 0 0 0 0 0
"694" 65.654794520548 71.841095890411 4.89041095890411 0 0 0 0 0 0 0
"695" 68.3753424657534 80.7835616438356 3.91780821917808 1 0 0 0 0 0 0
"696" 65.9561643835616 65.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"697" 70.5616438356164 64.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"698" 58.2 69.4082191780822 5.00821917808219 0 0 0 0 0 0 0
"699" 59.3369863013699 65.5616438356164 5.00821917808219 0 0 0 0 0 0 0
"700" 48.7534246575342 50.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"701" 60.9917808219178 72.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"702" 40.4054794520548 44.413698630137 5.00821917808219 0 0 0 0 0 0 0
"703" 63.6164383561644 68.3123287671233 4 0 0 0 0 0 0 0
"704" 65.7013698630137 64.6027397260274 3.67123287671233 0 0 0 0 0 0 0
"705" 58.7479452054795 63.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"706" 64.9342465753425 75.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"707" 70.654794520548 70.4520547945205 5.00821917808219 0 0 0 0 0 0 0
"708" 65.9342465753425 70.9835616438356 3.41643835616438 1 0 0 0 0 0 0
"709" 68.8958904109589 65.7150684931507 5.00821917808219 0 0 0 0 0 0 0
"710" 63.2465753424658 66.345205479452 5.00821917808219 0 0 0 0 0 0 0
"711" 65.5917808219178 71.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"712" 64.2054794520548 65.5424657534247 3.67123287671233 0 0 0 0 0 0 0
"713" 46.1232876712329 43.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"714" 42.8027397260274 63.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"715" 62.4657534246575 60.641095890411 3.75068493150685 0 0 0 0 0 0 0
"716" 51.041095890411 60.0794520547945 5.00821917808219 0 0 0 0 0 0 0
"717" 51.1643835616438 57.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"718" 54.3835616438356 59.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"719" 61.1452054794521 64.786301369863 5.00821917808219 0 0 0 0 0 0 0
"720" 68.8191780821918 68.5342465753425 5.00821917808219 0 0 0 0 0 0 0
"721" 55.4904109589041 59.9232876712329 4 0 0 0 0 0 0 0
"722" 68.5452054794521 70.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"723" 63.4931506849315 65.1123287671233 5.00821917808219 0 0 0 0 0 0 0
"724" 65.1424657534247 65.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"725" 40.5808219178082 45.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"726" 34.0904109589041 38.3232876712329 5.00821917808219 0 0 0 0 0 0 0
"727" 59.241095890411 60.2383561643836 5.00821917808219 0 0 0 0 0 0 0
"728" 66.6904109589041 65.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"729" 72.413698630137 62.0547945205479 5.00821917808219 0 0 0 0 0 0 0
"730" 63.5671232876712 65.013698630137 4.16712328767123 0 0 0 0 0 0 0
"731" 45.441095890411 46.0904109589041 5.00821917808219 0 0 0 0 0 0 0
"732" 60.6547945205479 70.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"733" 62.4739726027397 62.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"734" 50.5178082191781 68.1945205479452 1.33150684931507 0 0 1 0 1 0 0.0164383561643836
"735" 48.9890410958904 52.1178082191781 5.00821917808219 0 0 0 0 0 0 0
"736" 55.5506849315069 60.6958904109589 4.39178082191781 0 0 0 0 0 0 0
"737" 63.1232876712329 64.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"738" 65.6109589041096 57.3041095890411 4.39178082191781 0 0 0 0 0 0 0
"739" 62.4602739726027 65.4876712328767 5.00821917808219 0 0 0 0 0 0 0
"740" 57.4164383561644 57.3041095890411 3.91506849315068 0 0 0 0 0 0 0
"741" 62.1232876712329 65.3397260273973 5.00821917808219 0 0 0 0 0 0 0
"742" 30.9232876712329 39.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"743" 65.4739726027397 65.1178082191781 4.16712328767123 0 0 0 0 0 0 0
"744" 37.8054794520548 33.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"745" 48.2027397260274 49.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"746" 63.7369863013699 62.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"747" 64.2630136986301 65.1698630136986 3.16712328767123 0 0 0 0 0 0 0
"748" 57.3534246575342 71.5698630136986 3.5041095890411 1 0 0 0 0 0 0
"749" 35.9671232876712 31.9616438356164 0.583561643835616 0 0 0 0 0 0 0
"750" 60.7671232876712 63.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"751" 65.9397260273973 67.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"752" 54.9945205479452 61.2027397260274 1.48219178082192 0 0 0 0 0 0 0
"753" 41.2493150684932 46.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"754" 64.7452054794521 69.2465753424657 5.00821917808219 0 0 0 0 0 0 0
"755" 75.2383561643836 72.1753424657534 5.00821917808219 0 0 0 0 0 0 0
"756" 74.1643835616438 77.6684931506849 5.00821917808219 0 0 0 0 0 0 0
"757" 68.4328767123288 71.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"758" 69.9315068493151 65.4082191780822 2.00547945205479 0 0 0 0 0 0 0
"759" 56.2109589041096 61.1506849315069 5.00821917808219 0 0 0 0 0 0 0
"760" 52.2849315068493 55.8958904109589 4.94794520547945 0 0 0 0 0 0 0
"761" 77.7561643835616 79.5342465753425 5.00821917808219 0 0 0 0 0 0 0
"762" 68.586301369863 76.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"763" 63.8164383561644 65.1123287671233 3.00547945205479 0 0 0 0 0 0 0
"764" 58.1260273972603 67.5315068493151 2.55616438356164 0 0 0 0 0 0 0
"765" 61.5424657534247 67.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"766" 61.5424657534247 67.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"767" 61.0191780821918 65.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"768" 61.772602739726 66.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"769" 59.2849315068493 64.027397260274 5.00821917808219 0 0 0 0 0 0 0
"770" 59.7287671232877 65.3205479452055 5.00821917808219 0 0 0 0 0 0 0
"771" 68.186301369863 66.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"772" 72.0191780821918 76.441095890411 1.24931506849315 1 0 0 0 0 0 0
"773" 78.1232876712329 77.0931506849315 0.583561643835616 0 1 0 0 0 0 0
"774" 78.3753424657534 77.345205479452 0.583561643835616 0 1 0 0 0 0 0
"775" 68.2520547945205 64.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"776" 54.3369863013699 57.6657534246575 3.33424657534247 0 0 0 0 0 0 0
"777" 60.8109589041096 65.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"778" 63.8109589041096 65.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"779" 69.0356164383562 67.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"780" 64.3424657534247 64.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"781" 62.5479452054795 61.9342465753425 4.03287671232877 0 0 0 0 0 0 0
"782" 63.6684931506849 63.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"783" 70.0712328767123 64.2986301369863 3.08493150684932 0 0 0 0 0 0 0
"784" 55.4767123287671 59.358904109589 5.00821917808219 0 0 0 0 0 0 0
"785" 63.158904109589 63.386301369863 3.66849315068493 0 0 0 0 0 0 0
"786" 61.6739726027397 64.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"787" 70.7780821917808 65.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"788" 61.972602739726 59.7424657534247 3.19178082191781 0 0 0 0 0 0 0
"789" 63.8383561643836 73.241095890411 1.75068493150685 1 0 0 0 0 0 0
"790" 64.172602739726 73.5753424657534 1.75068493150685 1 0 0 0 0 0 0
"791" 65.1561643835616 76.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"792" 65.1561643835616 76.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"793" 73.7917808219178 75.8821917808219 4.4986301369863 1 0 0 0 0 0 0
"794" 73.7917808219178 75.8821917808219 4.4986301369863 1 0 0 0 0 0 0
"795" 78.5287671232877 81.4575342465753 3.33150684931507 1 0 0 0 0 0 0
"796" 73.9534246575342 76.7342465753425 3.66849315068493 1 0 0 0 0 0 0
"797" 71.4438356164383 70.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"798" 71.9369863013699 66.6630136986301 3.7972602739726 0 0 0 0 0 0 0
"799" 58.4191780821918 66.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"800" 59.7068493150685 62.9178082191781 2.88219178082192 0 0 0 0 0 0 0
"801" 59.7068493150685 62.9178082191781 2.88219178082192 0 0 0 0 0 0 0
"802" 80.1698630136986 66.7123287671233 3.67123287671233 0 0 0 0 0 0 0
"803" 74.1178082191781 81.3945205479452 3.7972602739726 0 0 0 0 0 0 0
"804" 72.8493150684932 70.2219178082192 3.7972602739726 0 0 0 0 0 0 0
"805" 59.7753424657534 60.7068493150685 4.55068493150685 0 0 0 0 0 0 0
"806" 67.7945205479452 71.6712328767123 3.67123287671233 0 0 0 0 0 0 0
"807" 65.8931506849315 64.986301369863 3.67123287671233 0 0 0 0 0 0 0
"808" 63.7150684931507 60.6712328767123 4.47397260273973 0 0 0 0 0 0 0
"809" 57.9753424657534 65.1835616438356 3.57808219178082 0 0 0 0 0 0 0
"810" 68.4191780821918 65.8520547945206 3.33424657534247 0 0 0 0 0 0 0
"811" 69.4465753424657 62.5643835616438 2.64657534246575 0 0 0 0 0 0 0
"812" 59.1643835616438 55.9178082191781 3.2027397260274 0 0 0 0 0 0 0
"813" 66.2958904109589 63.6493150684932 1.86575342465753 0 0 0 0 0 0 0
"814" 66.1945205479452 63.5479452054795 1.80547945205479 0 0 0 0 0 0 0
"815" 67.9369863013699 64.4931506849315 0.334246575342466 0 0 0 0 0 0 0
"816" 61.5671232876712 65.8493150684932 1.5041095890411 0 0 0 0 0 0 0
"817" 66.9753424657534 65.3260273972603 0.482191780821918 0 0 0 0 0 0 0
"818" 66.9753424657534 65.3260273972603 0.482191780821918 0 0 0 0 0 0 0
"819" 62.3041095890411 64.3972602739726 1.13698630136986 0 0 0 0 0 0 0
"820" 67.4958904109589 60.3013698630137 0.394520547945205 0 0 0 0 0 0 0
"821" 66.0794520547945 58.1205479452055 0.942465753424658 0 0 0 0 0 0 0
"822" 67.6794520547945 79.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"823" 67.5123287671233 79.7150684931507 5.00821917808219 0 0 0 0 0 0 0
"824" 67.2602739726027 79.4630136986301 5.00821917808219 0 0 0 0 0 0 0
"825" 78.213698630137 70.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"826" 78.213698630137 70.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"827" 68.3671232876712 69.8520547945206 5.00821917808219 0 0 0 0 0 0 0
"828" 64.8356164383562 75.4054794520548 4.83561643835616 1 0 0 0 0 0 0
"829" 64.386301369863 66.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"830" 78.5260273972603 63.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"831" 74.1671232876712 68.9890410958904 5.0027397260274 1 0 0 0 0 0 0
"832" 67.2684931506849 64.2438356164384 5.00821917808219 0 0 0 0 0 0 0
"833" 62.2657534246575 58.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"834" 55.6767123287671 57.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"835" 69.8630136986301 63.0383561643836 0.498630136986301 0 0 0 1 0 0.0575342465753425 0
"836" 70.6465753424658 70.3205479452055 5.00821917808219 0 0 0 0 0 0 0
"837" 65.8328767123288 65 5.00821917808219 0 0 0 0 0 0 0
"838" 59.9534246575342 63.9013698630137 3.8958904109589 0 0 0 0 0 0 0
"839" 62.0164383561644 65.7260273972603 2.81917808219178 0 0 0 0 0 0 0
"840" 62.3945205479452 64.9479452054795 5.00821917808219 0 0 0 0 0 0 0
"841" 60.3808219178082 60.7397260273973 4.36438356164384 0 0 0 0 0 0 0
"842" 66.7397260273973 59.1506849315069 4.01369863013699 0 0 0 0 0 0 0
"843" 59.0054794520548 60.1287671232877 4.22465753424658 0 0 0 0 0 0 0
"844" 66.4027397260274 68.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"845" 65.9917808219178 65.6657534246575 4.55068493150685 0 0 0 0 0 0 0
"846" 45.8630136986301 64.8328767123288 3.63013698630137 0 0 0 0 0 0 0
"847" 53.7342465753425 65.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"848" 54.3205479452055 66.2465753424657 5.00821917808219 0 0 0 0 0 0 0
"849" 62.6438356164384 64.7917808219178 2.38082191780822 0 0 0 0 0 0 0
"850" 65.1287671232877 65.4958904109589 1.36438356164384 0 0 0 0 0 0 0
"851" 54.1041095890411 56.3452054794521 1.0958904109589 0 0 0 0 0 0 0
"852" 65.3287671232877 65.6082191780822 1.16438356164384 1 0 0 0 0 0 0
"853" 77.3150684931507 77.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"854" 61.6767123287671 65.2301369863014 4.01369863013699 0 0 0 0 0 0 0
"855" 59.2082191780822 61.813698630137 4.20547945205479 0 0 0 0 0 0 0
"856" 66.0575342465753 63.6876712328767 2.44383561643836 0 0 0 0 0 0 0
"857" 63.5945205479452 65.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"858" 70.6657534246575 71.3616438356164 3.0027397260274 1 0 0 0 0 0 0
"859" 72.6356164383562 76.8931506849315 5.0027397260274 1 0 0 0 0 0 0
"860" 62.6767123287671 66.654794520548 5.00821917808219 0 0 0 0 0 0 0
"861" 77.1369863013699 79.6109589041096 0.66027397260274 0 0 0 0 0 0 0
"862" 68.1452054794521 71.0904109589041 5.00821917808219 0 0 0 0 0 0 0
"863" 71.6 75.5561643835617 5.00821917808219 0 0 0 0 0 0 0
"864" 65.7068493150685 63.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"865" 56.3534246575342 60.5972602739726 2.5041095890411 0 0 0 0 0 0 0
"866" 58.3260273972603 60.8082191780822 5 0 0 0 0 0 0 0
"867" 55.7698630136986 60.227397260274 3.01095890410959 0 0 0 0 0 0 0
"868" 74.9178082191781 77.0575342465753 0.249315068493151 0 1 0 0 0 0 0
"869" 74.9178082191781 77.0575342465753 0.249315068493151 0 1 0 0 0 0 0
"870" 81.8931506849315 87.8465753424658 0.164383561643836 1 0 0 0 0 0 0
"871" 73.3945205479452 78.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"872" 68.7972602739726 64.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"873" 61.9643835616438 60.9424657534247 2.4958904109589 0 0 0 0 0 0 0
"874" 64.3205479452055 68.6383561643836 5.00821917808219 0 0 0 0 0 0 0
"875" 61.8356164383562 65.1780821917808 4.93150684931507 0 0 0 0 0 0 0
"876" 69.2054794520548 64.9561643835616 4.41917808219178 0 0 0 0 0 0 0
"877" 64.0219178082192 65.4575342465753 4.5041095890411 0 0 0 0 0 0 0
"878" 61.5698630136986 65.2602739726027 3.42465753424658 0 0 0 0 0 0 0
"879" 69.1643835616438 66.9205479452055 5.00821917808219 0 0 0 0 0 0 0
"880" 59.3945205479452 65.8684931506849 3.91506849315068 0 0 0 0 0 0 0
"881" 46.0027397260274 65.772602739726 4.64109589041096 0 0 0 0 0 0 0
"882" 48.0575342465753 67.827397260274 2 0 0 0 0 0 0 0
"883" 67.3424657534247 66.4328767123288 5.00821917808219 0 0 0 0 0 0 0
"884" 53.4191780821918 56.0904109589041 2.58904109589041 0 0 0 0 0 0 0
"885" 49.5452054794521 61.5945205479452 2.98082191780822 0 0 0 0 0 0 0
"886" 74.4821917808219 76.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"887" 73.7260273972603 74.372602739726 4.08767123287671 1 0 0 0 0 0 0
"888" 73.7260273972603 74.372602739726 4.08767123287671 1 0 0 0 0 0 0
"889" 66.7205479452055 61.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"890" 76.8547945205479 78.2684931506849 1.4986301369863 1 0 0 0 0 0 0
"891" 65.2767123287671 64.3534246575342 4.07123287671233 0 0 0 0 0 0 0
"892" 68.7534246575343 67.8301369863014 1.67397260273973 0 0 0 0 0 0 0
"893" 61.4219178082192 65.041095890411 3.41917808219178 0 0 0 0 0 0 0
"894" 63.8356164383562 67.4547945205479 1.67397260273973 0 0 0 0 0 0 0
"895" 63.7753424657534 65.3397260273973 1.0027397260274 1 0 0 0 0 0 0
"896" 47.9178082191781 60.3013698630137 3.12602739726027 0 0 0 0 0 0 0
"897" 60.9616438356164 65.7808219178082 5.00821917808219 0 0 0 0 0 0 0
"898" 60.4958904109589 64.0191780821918 3.51232876712329 0 0 0 0 0 0 0
"899" 61.027397260274 64.5506849315069 3.14794520547945 0 0 0 0 0 0 0
"900" 67.8219178082192 62.4931506849315 2.4 0 0 0 0 0 0 0
"901" 59.786301369863 62.0931506849315 3.15068493150685 0 0 0 0 0 0 0
"902" 69.7205479452055 69.6082191780822 3.08767123287671 0 1 0 0 0 0 0
"903" 63.7287671232877 65.227397260274 1.95616438356164 0 0 0 0 0 0 0
"904" 59.2164383561644 66.2493150684931 1.44931506849315 0 0 0 0 0 0 0
"905" 71.0602739726027 66.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"906" 67.827397260274 69.186301369863 5.00821917808219 0 0 0 0 0 0 0
"907" 69.7068493150685 71.3068493150685 0 0 0 0 0 0 0 0
"908" 71.3753424657534 71.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"909" 67.9534246575342 72.7150684931507 0.583561643835616 0 1 0 0 0 0 0
"910" 67.8712328767123 72.6328767123288 0.583561643835616 0 1 0 0 0 0 0
"911" 61.9178082191781 65.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"912" 55.2219178082192 65.8438356164384 4.91506849315068 0 0 0 0 0 0 0
"913" 60.0328767123288 63.1671232876712 3.5041095890411 0 0 0 0 0 0 0
"914" 67.7287671232877 64.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"915" 57.1917808219178 67.5287671232877 1.33424657534247 0 0 0 0 0 0 0
"916" 69.2739726027397 67.4986301369863 0.334246575342466 0 0 0 0 0 0 0
"917" 72.6849315068493 65.8301369863014 0.301369863013699 0 0 0 0 0 0 0
"918" 77.7917808219178 79.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"919" 73 70.186301369863 5.00821917808219 0 0 0 0 0 0 0
"920" 71.572602739726 72.2986301369863 3.35616438356164 0 0 0 0 0 0 0
"921" 71.572602739726 72.2986301369863 3.35616438356164 0 0 0 0 0 0 0
"922" 69.1945205479452 66.1616438356164 3.35616438356164 0 0 0 0 0 0 0
"923" 69.1945205479452 66.1616438356164 3.35616438356164 0 0 0 0 0 0 0
"924" 65.9643835616438 68.2356164383562 3.35616438356164 0 0 0 0 0 0 0
"925" 65.9643835616438 68.2356164383562 3.35616438356164 0 0 0 0 0 0 0
"926" 62.6547945205479 69.1095890410959 3.35616438356164 0 0 0 0 0 0 0
"927" 62.6547945205479 69.1095890410959 3.35616438356164 0 0 0 0 0 0 0
"928" 60.2986301369863 60.3643835616438 2.9013698630137 0 0 0 0 0 0 0
"929" 59.8356164383562 61.3780821917808 3.47945205479452 0 0 0 0 0 0 0
"930" 57.813698630137 60.8191780821918 3.41917808219178 0 0 0 0 0 0 0
"931" 75.0986301369863 77.3479452054794 5.00821917808219 0 0 0 0 0 0 0
"932" 60.5671232876712 63.4082191780822 5.00821917808219 0 0 0 0 0 0 0
"933" 60.7068493150685 63.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"934" 60.7287671232877 63.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"935" 54.7424657534247 62.8383561643836 3.59178082191781 0 0 0 0 0 0 0
"936" 64.4657534246575 65.0164383561644 3.04931506849315 0 0 0 0 0 0 0
"937" 72.8027397260274 68.0082191780822 5.00821917808219 0 0 0 0 0 0 0
"938" 64.7205479452055 66.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"939" 69.4575342465753 70.6931506849315 5.00821917808219 0 0 0 0 0 0 0
"940" 50.1397260273973 65.0684931506849 4 0 0 0 0 0 0 0
"941" 71.7205479452055 73.654794520548 5.00821917808219 0 0 0 0 0 0 0
"942" 61.8821917808219 61.5260273972603 5 0 0 0 0 0 0 0
"943" 50.9972602739726 64.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"944" 62.0493150684932 65.9369863013699 2.33150684931507 1 0 0 0 0 0 0
"945" 57.3150684931507 67.0164383561644 5.00821917808219 0 0 0 0 0 0 0
"946" 59.6657534246575 63.4931506849315 3.67123287671233 0 0 0 0 0 0 0
"947" 61.8301369863014 61.4712328767123 4.98630136986301 0 0 0 0 0 0 0
"948" 60.0082191780822 65.627397260274 5.00821917808219 0 0 0 0 0 0 0
"949" 67.0246575342466 66.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"950" 65.3890410958904 65.1671232876712 4.16712328767123 0 0 0 0 0 0 0
"951" 52.3698630136986 60.2630136986301 5 0 0 0 0 0 0 0
"952" 59.7068493150685 62.1095890410959 5.00821917808219 0 0 0 0 0 0 0
"953" 51.4493150684931 63.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"954" 55.7561643835616 60.0575342465753 3.41917808219178 0 0 0 0 0 0 0
"955" 56.8219178082192 64.4876712328767 1.9972602739726 0 0 0 0 0 0 0
"956" 54.4575342465753 57.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"957" 58.558904109589 62.4931506849315 5 0 0 0 0 0 0 0
"958" 57.4027397260274 61.4246575342466 4.96712328767123 0 0 0 0 0 0 0
"959" 58.8109589041096 61.213698630137 5.00821917808219 0 0 0 0 0 0 0
"960" 60.3178082191781 66.6328767123288 5.00821917808219 0 0 0 0 0 0 0
"961" 63.3616438356164 65.8767123287671 3.91780821917808 1 0 0 0 0 0 0
"962" 61.5506849315069 65.3150684931507 4.33424657534247 0 0 0 0 0 0 0
"963" 61.4328767123288 61.4356164383562 3.83835616438356 0 0 0 0 0 0 0
"964" 51.0794520547945 60.372602739726 5.00821917808219 0 0 0 0 0 0 0
"965" 57.6739726027397 64.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"966" 62.7424657534247 65.1041095890411 5.00821917808219 0 0 0 0 0 0 0
"967" 64.3068493150685 68.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"968" 53.7479452054795 61.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"969" 65.6191780821918 67.8383561643836 5.00821917808219 0 0 0 0 0 0 0
"970" 65.6191780821918 67.8383561643836 5.00821917808219 0 0 0 0 0 0 0
"971" 74.227397260274 67.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"972" 58.5041095890411 60.613698630137 5 0 0 0 0 0 0 0
"973" 57.9671232876712 55.6520547945205 5.00821917808219 0 0 0 0 0 0 0
"974" 57.0383561643836 59.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"975" 57.4547945205479 64.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"976" 66.5452054794521 62.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"977" 66.9643835616438 63.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"978" 59.9643835616438 63.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"979" 57.4164383561644 59.9178082191781 2.4986301369863 1 0 0 0 0 0 0
"980" 63.3890410958904 62.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"981" 72.8301369863014 71.4849315068493 3.33150684931507 0 1 0 0 0 0 0
"982" 49.2246575342466 62.9315068493151 5 0 0 0 0 0 0 0
"983" 54.2958904109589 60.2109589041096 4.95890410958904 0 0 0 0 0 0 0
"984" 72.9013698630137 68.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"985" 62.4082191780822 66.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"986" 61.8219178082192 65.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"987" 36.4493150684931 54.9397260273973 2.41643835616438 0 0 0 0 0 0 0
"988" 50.2602739726027 60.3205479452055 5 0 0 0 0 0 0 0
"989" 74.7698630136986 65.7013698630137 3.75342465753425 0 0 0 0 0 0 0
"990" 65.1561643835616 65.2301369863014 4.25205479452055 0 0 0 0 0 0 0
"991" 64.1095890410959 65.7479452054795 4.75342465753425 0 0 0 0 0 0 0
"992" 65.1698630136986 65.0465753424658 4 0 0 0 0 0 0 0
"993" 56.6849315068493 63.5150684931507 3.32602739726027 0 0 0 0 0 0 0
"994" 74.5260273972603 72.8219178082192 5.00821917808219 0 0 0 0 0 0 0
"995" 61.9698630136986 69.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"996" 59.6520547945205 65.2904109589041 4.33424657534247 0 0 0 0 0 0 0
"997" 58.8958904109589 65.6109589041096 4.82191780821918 0 0 0 0 0 0 0
"998" 43.9479452054794 66.3369863013699 5.00821917808219 0 0 0 0 0 0 0
"999" 58.2246575342466 59.8630136986301 3.03835616438356 0 0 0 0 0 0 0
"1000" 54.786301369863 58.3123287671233 1.16438356164384 1 0 0 0 0 0 0
"1001" 64.627397260274 62.0109589041096 4.87397260273973 0 0 0 0 0 0 0
"1002" 59.1890410958904 64.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"1003" 61.1616438356164 65.8109589041096 3.83835616438356 0 0 0 0 0 0 0
"1004" 67.9698630136986 67.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"1005" 67.9698630136986 67.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"1006" 56.4054794520548 61.4164383561644 5.00821917808219 0 0 0 0 0 0 0
"1007" 53.5698630136986 60.3452054794521 3.25205479452055 0 0 0 0 0 0 0
"1008" 60.786301369863 62.3150684931507 5 0 0 0 0 0 0 0
"1009" 63.8767123287671 55.4602739726027 3.5041095890411 0 0 0 0 0 0 0
"1010" 54.0356164383562 65.2493150684931 3.24383561643836 0 0 0 0 0 0 0
"1011" 65.5369863013699 65.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"1012" 70.9041095890411 71.5095890410959 5.00821917808219 0 0 0 0 0 0 0
"1013" 59.3917808219178 62.613698630137 2.3041095890411 0 0 0 0 0 0 0
"1014" 67.786301369863 65.0794520547945 4.41917808219178 0 0 0 0 0 0 0
"1015" 64.2356164383562 64.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"1016" 48.8219178082192 54.7808219178082 3.16712328767123 0 0 0 0 0 0 0
"1017" 71.2821917808219 65.8191780821918 5.00821917808219 0 0 0 0 0 0 0
"1018" 47.2794520547945 53.9671232876712 2.9013698630137 0 0 0 0 0 0 0
"1019" 57.972602739726 61.4575342465753 4 0 0 0 0 0 0 0
"1020" 73.1315068493151 65.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"1021" 61.3835616438356 62.2630136986301 1.08767123287671 1 0 0 0 0 0 0
"1022" 58.8575342465753 59.7917808219178 4.49041095890411 0 0 0 0 0 0 0
"1023" 56.1095890410959 58.5232876712329 5.00821917808219 0 0 0 0 0 0 0
"1024" 59.8438356164384 61.7616438356164 4.91232876712329 0 0 0 0 0 0 0
"1025" 60.5315068493151 60.7041095890411 1.83287671232877 1 0 0 0 0 0 0
"1026" 57.4547945205479 61.3041095890411 4.96712328767123 0 0 0 0 0 0 0
"1027" 56.9917808219178 61.3698630136986 4.98630136986301 0 0 0 0 0 0 0
"1028" 55.5671232876712 64.0054794520548 2.53698630136986 0 0 0 0 0 0 0
"1029" 62.8547945205479 61.0684931506849 5 0 0 0 0 0 0 0
"1030" 54.8575342465753 59.1013698630137 3.16712328767123 0 0 0 0 0 0 0
"1031" 57.9506849315068 61.1123287671233 4.95068493150685 0 0 0 0 0 0 0
"1032" 58.586301369863 58.8164383561644 4.5041095890411 0 0 0 0 0 0 0
"1033" 59.986301369863 66.3315068493151 5.00821917808219 0 0 0 0 0 0 0
"1034" 64.5205479452055 65.4657534246575 4.5041095890411 0 0 0 0 0 0 0
"1035" 57.5369863013699 65.6684931506849 2.75068493150685 1 0 0 0 0 0 0
"1036" 62.4849315068493 60.0849315068493 4.33150684931507 0 1 0 0 0 0 0
"1037" 50.1616438356164 60.9068493150685 4.90958904109589 0 0 0 0 0 0 0
"1038" 66.6657534246575 66.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"1039" 57.8438356164384 63.972602739726 4.91506849315068 0 0 0 0 0 0 0
"1040" 52.3808219178082 65.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"1041" 63.6821917808219 65.7671232876712 3.83561643835616 1 0 0 0 0 0 0
"1042" 57.3397260273973 57.7945205479452 2.9972602739726 0 0 0 0 0 0 0
"1043" 66.1780821917808 64.9753424657534 0.750684931506849 1 0 0 0 0 0 0
"1044" 68.6164383561644 65.1013698630137 0.717808219178082 0 0 0 0 0 0 0
"1045" 63.1890410958904 65.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"1046" 58.6219178082192 59.3972602739726 3.03013698630137 0 0 0 0 0 0 0
"1047" 74.6219178082192 76.8438356164384 5.00821917808219 0 0 0 0 0 0 0
"1048" 66.6109589041096 64.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"1049" 70.0246575342466 61.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"1050" 62.2027397260274 67.8 5.00821917808219 0 0 0 0 0 0 0
"1051" 69.8219178082192 71.041095890411 5.00821917808219 0 0 0 0 0 0 0
"1052" 60.7452054794521 64.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"1053" 57.9972602739726 61.5205479452055 4.08767123287671 0 0 0 1 0 0.4 0
"1054" 66.0328767123288 67.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"1055" 71.2986301369863 73.8876712328767 5.00821917808219 0 0 0 0 0 0 0
"1056" 63.8301369863014 60.1890410958904 4.53424657534247 0 0 0 0 0 0 0
"1057" 60.7424657534247 63.4547945205479 5.00821917808219 0 0 0 0 0 0 0
"1058" 64.1041095890411 65.1534246575342 4.92876712328767 0 0 0 0 0 0 0
"1059" 69.1205479452055 65.1808219178082 5.00821917808219 0 0 0 0 0 0 0
"1060" 71.6109589041096 73.3178082191781 4.0027397260274 1 0 0 0 0 0 0
"1061" 77.1315068493151 75.8712328767123 4.16438356164384 1 0 0 0 0 0 0
"1062" 71.5397260273973 75.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"1063" 62.0876712328767 67.8 5.00821917808219 0 0 0 0 0 0 0
"1064" 69.0575342465753 69.7643835616438 5.00821917808219 0 0 0 0 0 0 0
"1065" 65.0547945205479 68.9260273972603 3.05205479452055 0 0 0 0 0 0 0
"1066" 46.8602739726027 67.5397260273973 2.81917808219178 0 0 0 0 0 0 0
"1067" 54.7287671232877 62.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"1068" 59.7424657534247 65.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"1069" 62.6657534246575 68.6520547945206 2.91506849315068 0 0 0 0 0 0 0
"1070" 52.5698630136986 56.1123287671233 1.29315068493151 0 0 0 0 0 0 0
"1071" 66.4794520547945 71.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"1072" 61.3945205479452 65.4684931506849 4.34520547945205 0 0 0 0 0 0 0
"1073" 59.8931506849315 65.3780821917808 4.27945205479452 0 0 0 0 0 0 0
"1074" 59.2383561643836 65.654794520548 2.67123287671233 0 0 0 0 0 0 0
"1075" 62.3342465753425 67.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"1076" 58.7041095890411 66.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"1077" 36.9041095890411 66.6575342465753 5.00821917808219 0 0 0 0 0 0 0
"1078" 57.5780821917808 65.3342465753425 2.38082191780822 0 0 0 0 0 0 0
"1079" 65.613698630137 63.5808219178082 2.42465753424658 0 0 0 0 0 0 0
"1080" 66.1315068493151 71.1917808219178 2.21095890410959 0 0 0 0 0 0 0
"1081" 70.1561643835616 74.358904109589 5.00821917808219 0 0 0 0 0 0 0
"1082" 55.1095890410959 74.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"1083" 65.2958904109589 64.7643835616438 5.00821917808219 0 0 0 0 0 0 0
"1084" 54.4356164383562 60.7041095890411 0.583561643835616 1 0 0 0 0 0 0
"1085" 64.641095890411 66.572602739726 5.00821917808219 0 0 0 0 0 0 0
"1086" 76.6630136986301 70.0849315068493 5.00821917808219 0 0 0 0 0 0 0
"1087" 55.1041095890411 61.372602739726 0.583561643835616 1 0 0 0 0 0 0
"1088" 71.027397260274 71.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"1089" 57.6876712328767 64.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"1090" 65.5917808219178 67.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"1091" 64.558904109589 63.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"1092" 61.1095890410959 63.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"1093" 64.1698630136986 66.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"1094" 64.4191780821918 67.0794520547945 5.00821917808219 0 0 0 0 0 0 0
"1095" 63.6767123287671 63.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"1096" 63.3068493150685 67.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"1097" 64.0931506849315 66.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"1098" 68.4904109589041 68.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"1099" 72.758904109589 74.4630136986301 1.0027397260274 1 0 0 0 0 0 0
"1100" 72.5917808219178 74.2958904109589 1.0027397260274 1 0 0 0 0 0 0
"1101" 55.5369863013699 64.0465753424658 1.67123287671233 0 0 0 0 0 0 0
"1102" 68.0684931506849 65.1068493150685 1.67123287671233 0 0 0 0 0 0 0
"1103" 65.3123287671233 65.7260273972603 1.67123287671233 0 0 0 0 0 0 0
"1104" 66.8712328767123 74.4602739726027 5.00821917808219 0 0 0 0 0 0 0
"1105" 59.4986301369863 62.8219178082192 2.75068493150685 1 0 0 0 0 0 0
"1106" 66.4109589041096 68.2301369863014 5.00821917808219 0 0 0 0 0 0 0
"1107" 69.2328767123288 66.5150684931507 5.00821917808219 0 0 0 0 0 0 0
"1108" 63.9178082191781 67.3753424657534 3.58356164383562 1 0 0 0 0 0 0
"1109" 65.0876712328767 66.827397260274 5.00821917808219 0 0 0 0 0 0 0
"1110" 57.5232876712329 68.2849315068493 1.33150684931507 1 0 0 0 0 0 0
"1111" 58.6 67.2465753424657 5.00821917808219 0 0 0 0 0 0 0
"1112" 56.013698630137 56.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"1113" 65.5424657534247 66.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"1114" 67 66.441095890411 5.00821917808219 0 0 0 0 0 0 0
"1115" 37.6438356164384 65.6767123287671 5.00821917808219 0 0 0 0 0 0 0
"1116" 62.6630136986301 62.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"1117" 57.9506849315068 65.2547945205479 4.12602739726027 0 0 0 0 0 0 0
"1118" 63.3972602739726 65.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"1119" 63.9835616438356 65.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"1120" 75.2657534246575 74.5342465753425 5.00821917808219 0 0 0 0 0 0 0
"1121" 54.1671232876712 57.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"1122" 58.9561643835616 55.9452054794521 3.47671232876712 0 0 0 0 0 0 0
"1123" 64.2438356164384 68.4547945205479 5.00821917808219 0 0 0 0 0 0 0
"1124" 69.5123287671233 69.6630136986301 3.08767123287671 1 0 0 0 0 0 0
"1125" 69.3808219178082 64.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"1126" 67.8904109589041 70.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"1127" 70.3479452054794 68.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"1128" 65.786301369863 68.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"1129" 65.0219178082192 69.4219178082192 5.00821917808219 0 0 0 0 0 0 0
"1130" 65.6657534246575 68.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"1131" 45.772602739726 69.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"1132" 58.6164383561644 69.9205479452055 5.00821917808219 0 0 0 0 0 0 0
"1133" 68.2356164383562 67.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"1134" 67.6602739726027 68.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"1135" 66.5178082191781 66.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"1136" 65.6383561643836 68.6356164383562 5.00821917808219 0 0 0 0 0 0 0
"1137" 65.9808219178082 70.5150684931507 5.00821917808219 0 0 0 0 0 0 0
"1138" 62.4438356164384 70.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"1139" 57.0301369863014 66.1342465753425 2.66849315068493 1 0 0 0 0 0 0
"1140" 62.8082191780822 64.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"1141" 63.7013698630137 65.6109589041096 4.86301369863014 0 0 0 0 0 0 0
"1142" 70.6684931506849 65.5123287671233 3.73972602739726 0 0 0 0 0 0 0
"1143" 64.3205479452055 65.5232876712329 5.00821917808219 0 0 0 0 0 0 0
"1144" 66.4191780821918 67.6219178082192 3.4958904109589 0 0 0 0 0 0 0
"1145" 67.6739726027397 70.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"1146" 65.8712328767123 68.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"1147" 66.986301369863 68.8739726027397 5.00821917808219 0 0 0 0 0 0 0
"1148" 53.1561643835616 57.8438356164384 3.26301369863014 0 0 0 0 0 0 0
"1149" 65.8054794520548 57.241095890411 2.61095890410959 0 0 0 0 0 0 0
"1150" 62.1808219178082 65.5068493150685 1.72054794520548 0 0 0 0 0 0 0
"1151" 61.4356164383562 67.6246575342466 1.72054794520548 0 0 0 0 0 0 0
"1152" 62.013698630137 65.4931506849315 1.5013698630137 0 0 0 0 0 0 0
"1153" 54.758904109589 59.041095890411 1.38356164383562 0 0 0 0 0 0 0
"1154" 53.3671232876712 65.2876712328767 0.334246575342466 0 0 0 0 0 0 0
"1155" 67.7068493150685 67.9808219178082 1.72054794520548 0 0 0 0 0 0 0
"1156" 60.6904109589041 59.186301369863 0.868493150684931 0 0 0 0 0 0 0
"1157" 48.2082191780822 65.186301369863 0.0821917808219178 0 0 0 0 0 0 0
"1158" 59.7534246575342 71.1260273972603 3.25205479452055 0 0 0 0 0 0 0
"1159" 65.5452054794521 66.1972602739726 2.0027397260274 0 0 0 0 0 0 0
"1160" 57.1506849315069 65.4739726027397 3 0 0 0 0 0 0 0
"1161" 59.4 67.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"1162" 59.5342465753425 67.3945205479452 4.95616438356164 0 0 0 0 0 0 0
"1163" 59.3972602739726 65.2082191780822 1.66027397260274 0 0 0 0 0 0 0
"1164" 72.4684931506849 68.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"1165" 65.1671232876712 67.5561643835617 5.00821917808219 0 0 0 0 0 0 0
"1166" 64.4876712328767 65.827397260274 5.00821917808219 0 0 0 0 0 0 0
"1167" 56.4246575342466 66.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"1168" 65.6876712328767 62.4821917808219 5.00821917808219 0 0 0 0 0 0 0
"1169" 66.372602739726 67.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"1170" 62.4082191780822 67.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"1171" 65.5178082191781 66.5232876712329 5.00821917808219 0 0 0 0 0 0 0
"1172" 61.5260273972603 66.3178082191781 5.00821917808219 0 0 0 0 0 0 0
"1173" 65.8054794520548 66.6 5.00821917808219 0 0 0 0 0 0 0
"1174" 64.227397260274 65.4438356164383 5.00821917808219 0 0 0 0 0 0 0
"1175" 40.5397260273973 52.5506849315069 4.53698630136986 0 0 0 0 0 0 0
"1176" 46.3753424657534 54.0301369863014 1.47123287671233 0 0 0 0 0 0 0
"1177" 54.3479452054795 66.3643835616438 4.00821917808219 0 0 0 0 0 0 0
"1178" 55.8876712328767 67.9041095890411 2.63561643835616 0 0 0 0 0 0 0
"1179" 72.1205479452055 67.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"1180" 78.1123287671233 67.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"1181" 62.0520547945206 65.5150684931507 5.00821917808219 0 0 0 0 0 0 0
"1182" 46.1369863013699 64.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"1183" 59.027397260274 62.0849315068493 4.01095890410959 0 0 0 0 0 0 0
"1184" 67.1315068493151 65.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"1185" 56.4794520547945 62.1753424657534 5.00821917808219 0 0 0 0 0 0 0
"1186" 57.0383561643836 64.8712328767123 2.08767123287671 1 0 0 0 0 0 0
"1187" 62.813698630137 65.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"1188" 67.0739726027397 59.4849315068493 4.01369863013699 0 0 0 0 0 0 0
"1189" 66.3753424657534 68.3561643835616 5.00821917808219 0 0 0 0 0 0 0
"1190" 61.7178082191781 63.2054794520548 4.81643835616438 0 0 0 0 0 0 0
"1191" 67.5068493150685 73.1671232876712 2.07671232876712 0 0 0 0 0 0 0
"1192" 52.8684931506849 59.227397260274 2.02191780821918 0 0 0 0 0 0 0
"1193" 64.4383561643836 65.1780821917808 0.917808219178082 1 0 0 0 0 0 0
"1194" 67.2246575342466 68.2931506849315 2.02191780821918 0 0 0 0 0 0 0
"1195" 66.8575342465753 70.227397260274 2.02191780821918 0 0 0 0 0 0 0
"1196" 56.213698630137 69.7315068493151 2.02191780821918 0 0 0 0 0 0 0
"1197" 71.8958904109589 67.8794520547945 2.02191780821918 0 0 0 0 0 0 0
"1198" 53.8054794520548 59.2356164383562 1.64109589041096 0 0 0 0 0 0 0
"1199" 61.041095890411 67.1123287671233 1.64109589041096 0 0 0 0 0 0 0
"1200" 61.8739726027397 61.8931506849315 2.43835616438356 0 0 0 0 0 0 0
"1201" 60.8027397260274 59.827397260274 3.56712328767123 0 0 0 0 0 0 0
"1202" 61.4246575342466 60.4493150684931 2.44383561643836 0 0 0 0 0 0 0
"1203" 53.5671232876712 60.0849315068493 0.616438356164384 0 0 0 0 0 0 0
"1204" 58.6356164383562 60.1013698630137 4.5041095890411 0 0 0 0 0 0 0
"1205" 59.6191780821918 61.0849315068493 3.26575342465753 0 0 0 0 0 0 0
"1206" 59.0219178082192 62.0109589041096 1.76712328767123 0 0 0 0 0 0 0
"1207" 64.6767123287671 65.2684931506849 0.876712328767123 0 0 0 0 0 0 0
"1208" 60.0438356164384 64.2712328767123 1.9972602739726 0 0 0 0 0 0 0
"1209" 67.8356164383562 64.7890410958904 2.03287671232877 0 0 0 0 0 0 0
"1210" 63.4082191780822 65.0246575342466 2.03287671232877 0 0 0 0 0 0 0
"1211" 65.027397260274 65.0465753424658 1.1972602739726 0 0 0 0 0 0 0
"1212" 65.1123287671233 65.1315068493151 1.1972602739726 0 0 0 0 0 0 0
"1213" 71.958904109589 71.0684931506849 1 0 0 0 0 0 0 0
"1214" 52.386301369863 64.7123287671233 1.08493150684932 0 0 0 0 0 0 0
"1215" 62.0657534246575 65.0739726027397 0.942465753424658 0 0 0 0 0 0 0
"1216" 65.5917808219178 65.0630136986301 4.01369863013699 0 0 0 0 0 0 0
"1217" 63.8575342465753 66.8383561643836 5.00821917808219 0 0 0 0 0 0 0
"1218" 65.6328767123288 67.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"1219" 58.0109589041096 65.958904109589 5.00821917808219 0 0 0 0 0 0 0
"1220" 62.427397260274 66.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"1221" 60.3123287671233 67.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"1222" 68.4739726027397 71.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"1223" 69.7890410958904 66.6 5.00821917808219 0 0 0 0 0 0 0
"1224" 59.1123287671233 64.2438356164384 1.0958904109589 0 0 0 0 0 0 0
"1225" 60.1808219178082 67.4164383561644 5.00821917808219 0 0 0 0 0 0 0
"1226" 51.5397260273973 58.613698630137 4.50958904109589 0 0 0 0 0 0 0
"1227" 60.4794520547945 60.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"1228" 60.786301369863 67.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"1229" 66.3260273972603 67.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"1230" 66.572602739726 70.4 1.41643835616438 1 0 0 0 0 0 0
"1231" 53.4602739726027 59.9479452054794 4.14520547945205 0 0 0 0 0 0 0
"1232" 60.0712328767123 66.0712328767123 3.03287671232877 0 0 0 0 0 0 0
"1233" 45.7397260273973 53.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"1234" 59.3315068493151 62.6356164383562 4 0 0 0 0 0 0 0
"1235" 64.3342465753425 67.3068493150685 4.11232876712329 0 0 0 0 0 0 0
"1236" 62.4739726027397 65.8109589041096 3.83835616438356 0 0 0 0 0 0 0
"1237" 60.5643835616438 64.4739726027397 4.24109589041096 0 0 0 0 0 0 0
"1238" 65.1369863013699 65.5397260273973 4.58630136986301 0 0 0 0 0 0 0
"1239" 66.5178082191781 65.3561643835616 2.70684931506849 0 0 0 0 0 0 0
"1240" 58.6657534246575 61.1808219178082 4.16712328767123 0 0 0 0 0 0 0
"1241" 61.958904109589 63.1424657534247 2.92602739726027 0 0 0 0 0 0 0
"1242" 60.3643835616438 65.2027397260274 3.25479452054795 1 0 0 0 0 0 0
"1243" 60.3342465753425 61.1123287671233 4.95890410958904 0 0 0 0 0 0 0
"1244" 64.5123287671233 65.6219178082192 3.67123287671233 0 0 0 0 0 0 0
"1245" 65.5890410958904 70.5424657534247 4.93150684931507 0 0 0 0 0 0 0
"1246" 66.558904109589 71.5123287671233 3.96164383561644 0 0 0 0 0 0 0
"1247" 67.5452054794521 72.4986301369863 2.97534246575342 0 0 0 0 0 0 0
"1248" 68.5452054794521 73.4986301369863 1.97534246575342 0 0 0 0 0 0 0
"1249" 69.5561643835617 74.5095890410959 0.964383561643836 0 0 0 0 0 0 0
"1250" 64.5041095890411 69.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"1251" 59.7041095890411 61.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"1252" 59.9671232876712 71.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"1253" 63.3342465753425 66.5150684931507 3.86301369863014 0 0 0 0 0 0 0
"1254" 66.7753424657534 65.6246575342466 4.82191780821918 0 0 0 0 0 0 0
"1255" 48.3506849315068 63.6027397260274 3.3013698630137 0 0 0 0 0 0 0
"1256" 65.2328767123288 65.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"1257" 63.8328767123288 61.0904109589041 3.75342465753425 0 0 0 0 0 0 0
"1258" 66.0493150684931 65.4904109589041 5.00821917808219 0 0 0 0 0 0 0
"1259" 62.6383561643836 65.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"1260" 68.758904109589 67.8876712328767 5.00821917808219 0 0 0 0 0 0 0
"1261" 76.1232876712329 62.4356164383562 3.68767123287671 0 0 0 0 0 0 0
"1262" 65.7342465753425 65.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"1263" 55.1397260273973 67.4465753424657 4.83561643835616 1 0 0 0 0 0 0
"1264" 59.2465753424658 57.4739726027397 2.86027397260274 0 0 0 0 0 0 0
"1265" 63.4986301369863 65.8356164383562 3.64657534246575 0 0 0 0 0 0 0
"1266" 55.5643835616438 65.0575342465753 5 0 0 0 0 0 0 0
"1267" 66.7945205479452 67.9917808219178 2.4958904109589 0 0 0 0 0 0 0
"1268" 62.7698630136986 64.0849315068493 2.96164383561644 0 0 0 0 0 0 0
"1269" 54.627397260274 67.6191780821918 2.86849315068493 0 0 0 0 0 0 0
"1270" 57.0876712328767 63.1698630136986 1.19178082191781 0 0 0 0 0 0 0
"1271" 52.2493150684932 65.2958904109589 2.25205479452055 0 0 0 0 0 0 0
"1272" 60.7835616438356 62.8328767123288 1.26849315068493 0 0 0 0 0 0 0
"1273" 58.027397260274 61.427397260274 1.0958904109589 0 0 0 0 0 0 0
"1274" 59.3945205479452 62.6876712328767 1.36986301369863 0 0 0 0 0 0 0
"1275" 62.7013698630137 63.5178082191781 0.758904109589041 0 0 0 0 0 0 0
"1276" 48.4246575342466 71.0849315068493 2.78630136986301 0 0 0 0 0 0 0
"1277" 55.7890410958904 64.786301369863 4.09315068493151 0 0 0 0 0 0 0
"1278" 61.627397260274 70.1890410958904 2.25205479452055 0 0 0 0 0 0 0
"1279" 63.5917808219178 65.0027397260274 3.07945205479452 0 0 0 0 0 0 0
"1280" 58.9534246575342 63.8164383561644 2.96164383561644 0 0 0 0 0 0 0
"1281" 68.1013698630137 66.2849315068493 3.64931506849315 0 0 0 0 0 0 0
"1282" 64.1178082191781 65.0547945205479 2.15890410958904 0 0 0 0 0 0 0
"1283" 31.5369863013699 65.6931506849315 0.424657534246575 0 0 0 0 0 0 0
"1284" 58.1890410958904 64.5890410958904 1.27671232876712 0 0 0 0 0 0 0
"1285" 66.7534246575343 65.3369863013699 0.33972602739726 0 0 0 0 0 0 0
"1286" 58.1561643835616 61.4876712328767 1.33424657534247 0 0 0 0 0 0 0
"1287" 59.8547945205479 65.7397260273973 0.920547945205479 0 1 0 0 0 0 0
"1288" 67.4520547945205 65.3424657534247 2.38356164383562 0 0 0 0 0 0 0
"1289" 59.6547945205479 63.213698630137 2.97534246575342 0 0 0 0 0 0 0
"1290" 63.2493150684932 65.5561643835617 3.37534246575342 0 0 0 0 0 0 0
"1291" 62.4849315068493 66.027397260274 1.41643835616438 0 0 1 0 1 0 0.0465753424657534
"1292" 69.6438356164384 65.5643835616438 2.61095890410959 0 0 0 0 0 0 0
"1293" 59.2657534246575 65.0986301369863 0.202739726027397 0 0 0 0 0 0 0
"1294" 58.7506849315068 65.2328767123288 1.2958904109589 0 0 0 0 0 0 0
"1295" 58.3287671232877 60.4904109589041 5.00821917808219 0 0 0 0 0 0 0
"1296" 69.1534246575342 66.3095890410959 5.00821917808219 0 0 0 0 0 0 0
"1297" 58.0356164383562 63.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"1298" 64.8383561643836 65.8876712328767 4.86301369863014 0 0 0 0 0 0 0
"1299" 60.8712328767123 60.1123287671233 3.9041095890411 0 0 0 0 0 0 0
"1300" 61.8246575342466 64.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"1301" 64.0958904109589 65.8849315068493 4.54794520547945 0 0 0 0 0 0 0
"1302" 64.4191780821918 64.4821917808219 0.673972602739726 1 0 0 0 0 0 0
"1303" 68.9698630136986 65.8958904109589 2.35890410958904 0 0 0 0 0 0 0
"1304" 59.5342465753425 64.3835616438356 3.10684931506849 0 0 0 0 0 0 0
"1305" 60.772602739726 65.0931506849315 2.05205479452055 0 0 0 0 0 0 0
"1306" 67.1671232876712 71.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"1307" 59.558904109589 64.3095890410959 1.64109589041096 0 0 0 0 0 0 0
"1308" 61.6684931506849 59.6739726027397 5.00821917808219 0 0 0 0 0 0 0
"1309" 62.1890410958904 65.8849315068493 4.54794520547945 0 0 0 0 0 0 0
"1310" 61.1835616438356 62.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"1311" 63.5835616438356 65.0465753424658 4.08493150684932 0 0 0 0 0 0 0
"1312" 67.5917808219178 66.7561643835616 5.00821917808219 0 0 0 0 0 0 0
"1313" 60.8493150684931 64.9315068493151 2.76986301369863 0 0 0 0 0 0 0
"1314" 64.1452054794521 69.3205479452055 1.16438356164384 1 0 0 0 0 0 0
"1315" 70.3315068493151 65.1561643835616 4.41369863013699 0 0 0 0 0 0 0
"1316" 71.7013698630137 66.5260273972603 3.38082191780822 0 0 0 0 0 0 0
"1317" 66.9123287671233 64.0712328767123 5.00821917808219 0 0 0 0 0 0 0
"1318" 62.1698630136986 65.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"1319" 63.0849315068493 65.4821917808219 5.00821917808219 0 0 0 0 0 0 0
"1320" 61.1068493150685 65.358904109589 5.00821917808219 0 0 0 0 0 0 0
"1321" 64.6164383561644 66.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"1322" 57.7232876712329 58.4602739726027 3.67123287671233 0 0 0 0 0 0 0
"1323" 58.4328767123288 59.1698630136986 2.46027397260274 0 0 0 0 0 0 0
"1324" 60.5616438356164 64.0739726027397 3.83835616438356 0 0 0 0 0 0 0
"1325" 61.1452054794521 64.6575342465753 2.42465753424658 0 0 0 0 0 0 0
"1326" 58.1808219178082 65.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"1327" 47.2082191780822 62.5616438356164 0.238356164383562 0 0 0 0 0 0 0
"1328" 46.958904109589 62.3123287671233 0.238356164383562 0 0 0 0 0 0 0
"1329" 63.6657534246575 66.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"1330" 56.5616438356164 55.3506849315068 2.18904109589041 0 0 0 0 0 0 0
"1331" 67.4383561643836 67.172602739726 0.501369863013699 0 0 0 0 0 0 0
"1332" 65.9808219178082 65.7150684931507 1.79178082191781 0 0 0 0 0 0 0
"1333" 58.2465753424658 65.2191780821918 1.63287671232877 0 0 0 0 0 0 0
"1334" 64.9890410958904 59.4356164383562 5.00821917808219 0 0 0 0 0 0 0
"1335" 54.6547945205479 60.1013698630137 4.5041095890411 0 0 0 0 0 0 0
"1336" 62.0082191780822 66.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"1337" 64.227397260274 67.8931506849315 5.00821917808219 0 0 0 0 0 0 0
"1338" 57.1260273972603 65.4383561643836 0.583561643835616 1 0 0 0 0 0 0
"1339" 66.1479452054794 65.3287671232877 5.00821917808219 0 0 0 0 0 0 0
"1340" 58.6465753424658 65.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"1341" 64.3178082191781 65.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"1342" 62.2767123287671 65.958904109589 2.66849315068493 1 0 0 0 0 0 0
"1343" 62.5041095890411 65.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"1344" 60.2219178082192 65.3698630136986 4.01369863013699 0 0 0 0 0 0 0
"1345" 66.5013698630137 68.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"1346" 68.9150684931507 68.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"1347" 59.3178082191781 68.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"1348" 63.9671232876712 63.9095890410959 4.45753424657534 0 0 0 0 0 0 0
"1349" 68.0191780821918 64.5534246575343 4.0027397260274 0 1 0 0 0 0 0
"1350" 59.2383561643836 67.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"1351" 60.3095890410959 59.3835616438356 3.05753424657534 0 0 0 0 0 0 0
"1352" 50.6904109589041 64.7698630136986 4.23835616438356 0 0 0 0 0 0 0
"1353" 60.5561643835616 65.6465753424658 2.91506849315068 0 0 0 0 0 0 0
"1354" 62.758904109589 70.1397260273973 2.41643835616438 1 0 0 0 0 0 0
"1355" 66.4082191780822 64.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"1356" 66.027397260274 66.3232876712329 5.00821917808219 0 0 0 0 0 0 0
"1357" 58.6684931506849 64.6958904109589 3.07123287671233 0 0 0 0 0 0 0
"1358" 59.3479452054795 63.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"1359" 63.8712328767123 67.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"1360" 56.5260273972603 65.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"1361" 56.2246575342466 68.386301369863 5.00821917808219 0 0 0 0 0 0 0
"1362" 63.7315068493151 65.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"1363" 62.9780821917808 65.986301369863 5.00821917808219 0 0 0 0 0 0 0
"1364" 64.0328767123288 62.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"1365" 61.6931506849315 64.572602739726 4.50684931506849 0 0 0 0 0 0 0
"1366" 67.1890410958904 64.8328767123288 1.49041095890411 0 0 0 0 0 0 0
"1367" 73.2849315068493 67.3835616438356 1.65753424657534 0 0 0 0 0 0 0
"1368" 62.3013698630137 65.9315068493151 2.36438356164384 0 0 0 0 0 0 0
"1369" 50.1890410958904 61.6849315068493 5.00821917808219 0 0 0 0 0 0 0
"1370" 64.1369863013699 65.0493150684931 3 0 0 0 0 0 0 0
"1371" 67.241095890411 68.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"1372" 48.6246575342466 61.0684931506849 5.00821917808219 0 0 0 0 0 0 0
"1373" 57.2602739726027 56.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"1374" 70.013698630137 66.2301369863014 2.66849315068493 0 0 0 0 0 0 0
"1375" 70.3643835616438 67.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"1376" 68.4876712328767 65.8739726027397 4.8 0 0 0 0 0 0 0
"1377" 58.2821917808219 61.5945205479452 4.33698630136986 0 0 0 0 0 0 0
"1378" 63.6520547945205 65.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"1379" 69.5753424657534 64.7945205479452 4.15342465753425 0 0 0 0 0 0 0
"1380" 58.2246575342466 66.5835616438356 3.08767123287671 1 0 0 0 0 0 0
"1381" 63.2547945205479 63.8630136986301 3.8958904109589 0 0 0 0 0 0 0
"1382" 58.7205479452055 60.2082191780822 4 0 0 0 0 0 0 0
"1383" 65.6794520547945 65.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"1384" 64.4767123287671 66.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"1385" 65.7753424657534 61.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"1386" 58.9780821917808 60.3068493150685 3.81917808219178 0 0 0 0 0 0 0
"1387" 65.386301369863 67.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"1388" 63.6986301369863 65.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"1389" 62.0739726027397 65.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"1390" 62.4356164383562 65.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"1391" 61.2931506849315 65.4082191780822 4.8986301369863 0 0 0 0 0 0 0
"1392" 65.4520547945205 65.5506849315069 3.58630136986301 0 0 0 0 0 0 0
"1393" 58.2876712328767 55.2767123287671 3.47671232876712 0 0 0 0 0 0 0
"1394" 46.3205479452055 64.8301369863014 0 0 0 0 0 0 0 0
"1395" 56.8328767123288 60.3643835616438 4.92876712328767 0 0 0 0 0 0 0
"1396" 65.641095890411 65.3890410958904 2.46575342465753 0 0 0 0 0 0 0
"1397" 52.7917808219178 66.0191780821918 4.8986301369863 0 0 0 0 0 0 0
"1398" 64.8547945205479 65.0575342465753 3.3041095890411 0 0 0 0 0 0 0
"1399" 59.172602739726 65.2164383561644 4.24109589041096 0 0 0 0 0 0 0
"1400" 64.1315068493151 63.213698630137 0.501369863013699 1 0 0 0 0 0 0
"1401" 65.8739726027397 65.0547945205479 4.07123287671233 0 0 0 0 0 0 0
"1402" 66.9698630136986 65.3150684931507 5 0 0 0 0 0 0 0
"1403" 59.4465753424658 65.358904109589 4.41917808219178 0 0 0 0 0 0 0
"1404" 62.1972602739726 64.841095890411 3.38356164383562 0 0 0 0 0 0 0
"1405" 54.4739726027397 65.9808219178082 4.84383561643836 0 0 0 0 0 0 0
"1406" 63.9616438356164 64.8465753424658 3.14520547945205 0 0 0 0 0 0 0
"1407" 54.4547945205479 64.9260273972603 2.58356164383562 1 0 0 0 0 0 0
"1408" 65.8164383561644 65.2739726027397 4.33424657534247 0 0 0 0 0 0 0
"1409" 68.5972602739726 64.8547945205479 3.25205479452055 0 0 0 0 0 0 0
"1410" 37.6219178082192 64.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"1411" 49.9616438356164 59.2684931506849 5.00821917808219 0 0 0 0 0 0 0
"1412" 56.1260273972603 61.9506849315068 4.50958904109589 0 0 0 0 0 0 0
"1413" 51.5397260273973 58.613698630137 4.50958904109589 0 0 0 0 0 0 0
"1414" 61.0821917808219 64.6054794520548 3.51232876712329 0 0 0 0 0 0 0
"1415" 58.4383561643836 60.7452054794521 4.41643835616438 0 0 0 0 0 0 0
"1416" 54.6821917808219 65.3808219178082 2.4986301369863 0 0 0 0 0 0 0
"1417" 64.1123287671233 65.0712328767123 1.00821917808219 0 0 0 0 0 0 0
"1418" 65.0383561643836 64.972602739726 1.38356164383562 0 0 0 0 0 0 0
"1419" 63.2794520547945 65.3917808219178 1.80547945205479 0 0 0 0 0 0 0
"1420" 59.2 63.1479452054795 3.8958904109589 0 0 0 0 0 0 0
"1421" 55.986301369863 61.0109589041096 1.52876712328767 0 0 0 0 0 0 0
"1422" 61.6821917808219 65.3917808219178 2.81917808219178 0 0 0 0 0 0 0
"1423" 59.9616438356164 60.3205479452055 4.36438356164384 0 0 0 0 0 0 0
"1424" 64.8602739726027 58.7041095890411 0.986301369863014 0 0 0 0 0 0 0
"1425" 64.8191780821918 58.6630136986301 1.52876712328767 0 0 0 0 0 0 0
"1426" 64.8082191780822 65.4794520547945 2.55890410958904 0 0 0 0 0 0 0
"1427" 59.4246575342466 60.5479452054795 4.22465753424658 0 0 0 0 0 0 0
"1428" 59.3616438356164 62.4191780821918 4.01095890410959 0 0 0 0 0 0 0
"1429" 69.5260273972603 62.7205479452055 1.52876712328767 0 0 0 0 0 0 0
"1430" 64.7616438356164 58.8027397260274 1.52876712328767 0 0 0 0 0 0 0
"1431" 62.9315068493151 59.3479452054795 1.03013698630137 0 0 0 0 0 0 0
"1432" 61.7917808219178 59.6383561643836 1.52876712328767 0 0 0 0 0 0 0
"1433" 59.8547945205479 58.1123287671233 1.52876712328767 0 0 0 0 0 0 0
"1434" 65.386301369863 69.0465753424658 0.835616438356164 0 0 0 0 0 0 0
"1435" 51.5534246575342 60.9616438356164 1.45205479452055 0 0 0 0 0 0 0
"1436" 66.0547945205479 65.1561643835616 1.21095890410959 0 0 0 0 0 0 0
"1437" 63.1452054794521 69.4054794520548 3.41369863013699 0 0 0 0 0 0 0
"1438" 66.6246575342466 65.4602739726027 2.4958904109589 0 0 0 0 0 0 0
"1439" 62.7972602739726 62.4575342465753 3.04931506849315 0 0 0 0 0 0 0
"1440" 44.5671232876712 57.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"1441" 53.8191780821918 55.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"1442" 65.2 64.8657534246575 5.00821917808219 0 0 0 0 0 0 0
"1443" 61.1506849315069 62.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"1444" 59.6739726027397 59.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"1445" 63.3808219178082 55.8931506849315 4.91506849315068 0 0 0 0 0 0 0
"1446" 54.7178082191781 58.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"1447" 55.027397260274 55.5890410958904 0.671232876712329 0 0 0 0 0 0 0
"1448" 59.6739726027397 59.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"1449" 61.2849315068493 62.3835616438356 1.67123287671233 0 0 0 0 0 0 0
"1450" 68.1698630136986 65.4465753424657 4.67123287671233 0 0 0 0 0 0 0
"1451" 49.1342465753425 65.2356164383562 3.66301369863014 0 0 0 0 0 0 0
"1452" 59.958904109589 65.3397260273973 3.47123287671233 0 0 0 0 0 0 0
"1453" 76.7041095890411 77.3643835616438 0.249315068493151 1 0 0 0 0 0 0
"1454" 79.4547945205479 80.9068493150685 5.00821917808219 0 0 0 0 0 0 0
"1455" 72.9095890410959 80.6630136986301 4.66849315068493 1 0 0 0 0 0 0
"1456" 71.0191780821918 79.586301369863 0.750684931506849 0 0 0 0 1 0 4.16986301369863
"1457" 75.9671232876712 77.2904109589041 5.00821917808219 0 0 0 0 0 0 0
"1458" 75.5534246575343 75.972602739726 4.91780821917808 1 0 0 0 0 0 0
"1459" 71.8082191780822 76.027397260274 5.00821917808219 0 0 0 0 0 0 0
"1460" 59.1890410958904 65.758904109589 4.91506849315068 0 0 0 0 0 0 0
"1461" 69.627397260274 64.9808219178082 3.33424657534247 0 0 0 0 0 0 0
"1462" 62.6876712328767 64.3808219178082 0.243835616438356 0 0 0 0 0 0 0
"1463" 65.0630136986301 60.0191780821918 0 0 0 0 0 0 0 0
"1464" 65.4219178082192 65.172602739726 5.00821917808219 0 0 0 0 0 0 0
"1465" 64.1424657534247 65.9561643835616 5.00821917808219 0 0 0 0 0 0 0
"1466" 56.786301369863 61.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"1467" 65.972602739726 67.1013698630137 4.54520547945206 0 0 0 0 0 0 0
"1468" 59.7452054794521 64.7150684931507 2.16712328767123 0 0 0 0 0 0 0
"1469" 62.0958904109589 65.013698630137 3.00547945205479 0 0 0 0 0 0 0
"1470" 60.5260273972603 63.8082191780822 0.334246575342466 0 0 0 0 0 0 0
"1471" 60.7561643835616 64.7068493150685 2.58630136986301 0 0 0 0 0 0 0
"1472" 66.2849315068493 66.027397260274 3.71232876712329 0 0 0 0 0 0 0
"1473" 69.2739726027397 71.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"1474" 70.4575342465753 64.9068493150685 0.753424657534247 0 0 0 0 0 0 0
"1475" 58.0904109589041 59.7315068493151 0.353424657534247 0 0 0 0 0 0 0
"1476" 55.6465753424658 62.0712328767123 0.482191780821918 0 0 0 0 0 0 0
"1477" 57.3808219178082 60.0712328767123 5.00821917808219 0 0 0 0 0 0 0
"1478" 65.4849315068493 63.8931506849315 3.32602739726027 0 0 0 0 0 0 0
"1479" 63.8630136986301 62.7287671232877 3.29041095890411 0 0 0 0 0 0 0
"1480" 60.3260273972603 58.6383561643836 2.26575342465753 0 0 0 0 0 0 0
"1481" 68.1041095890411 69.5178082191781 2.58356164383562 1 0 0 0 0 0 0
"1482" 55.1424657534247 58.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"1483" 63.9369863013699 65.1534246575342 1.89041095890411 0 0 0 0 0 0 0
"1484" 64.5424657534247 67.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"1485" 50.8054794520548 60.6164383561644 3.66849315068493 0 0 0 0 0 0 0
"1486" 64.0876712328767 65.5890410958904 0.742465753424657 0 0 0 0 0 0 0
"1487" 61.027397260274 65.1287671232877 1.41917808219178 0 0 0 0 0 0 0
"1488" 59.8794520547945 65.186301369863 2.11506849315069 0 0 0 0 0 0 0
"1489" 59.4794520547945 68.7616438356164 1 0 0 0 0 0 0 0
"1490" 61.1095890410959 61.3945205479452 1.94794520547945 0 0 0 0 0 0 0
"1491" 60.7232876712329 65.0602739726027 2.97260273972603 0 0 0 0 0 0 0
"1492" 62.0438356164384 66.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"1493" 58.0767123287671 61.841095890411 2.41917808219178 0 0 0 0 0 0 0
"1494" 64.0794520547945 65.158904109589 0.671232876712329 0 0 0 0 0 0 0
"1495" 70.8493150684932 70.7506849315069 5.00821917808219 0 0 0 0 0 0 0
"1496" 63.6109589041096 65.186301369863 3 0 0 0 0 0 0 0
"1497" 55.7479452054795 63.5506849315069 0.389041095890411 1 0 0 0 0 0 0
"1498" 63.158904109589 64.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"1499" 57.827397260274 60.8246575342466 4.57534246575342 0 0 0 0 0 0 0
"1500" 69.1369863013699 69.841095890411 5.00821917808219 0 0 0 0 0 0 0
"1501" 72.1424657534247 65.3178082191781 0.353424657534247 0 0 0 0 0 0 0
"1502" 50.9506849315068 58.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"1503" 54.7616438356164 65.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"1504" 63.213698630137 65.2356164383562 1.5041095890411 0 0 0 0 0 0 0
"1505" 58.3178082191781 64.5561643835617 2.16712328767123 0 0 0 0 0 0 0
"1506" 65.4219178082192 65.4383561643836 0.838356164383562 0 0 0 0 0 0 0
"1507" 66.7260273972603 67.1178082191781 0.750684931506849 1 0 0 0 0 0 0
"1508" 60.3917808219178 66.7178082191781 2.41643835616438 0 0 0 0 0 0 0
"1509" 59.1671232876712 62.5287671232877 3.5041095890411 0 0 0 0 0 0 0
"1510" 61.4657534246575 64.758904109589 0.586301369863014 0 0 0 0 0 0 0
"1511" 67.8493150684932 67.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"1512" 60.7479452054795 64.9205479452055 2.16712328767123 0 0 0 0 0 0 0
"1513" 60.9534246575342 65.0301369863014 4 0 0 0 0 0 0 0
"1514" 63.6493150684932 64.6849315068493 5.00821917808219 0 0 0 0 0 0 0
"1515" 62.6328767123288 65.1616438356164 2.5041095890411 0 0 0 0 0 0 0
"1516" 63.827397260274 65.2575342465753 5.00821917808219 0 0 0 0 0 0 0
"1517" 61.4821917808219 65.041095890411 3.08493150684932 0 0 0 0 0 0 0
"1518" 63.013698630137 60.4246575342466 0.197260273972603 0 0 0 0 0 0 0
"1519" 55.8328767123288 64.8054794520548 1.33424657534247 0 0 0 0 0 0 0
"1520" 58.4958904109589 65.2602739726027 4.64383561643836 0 0 0 0 0 0 0
"1521" 60.1753424657534 68.4904109589041 5.00821917808219 0 0 0 0 0 0 0
"1522" 56.6904109589041 65.5342465753425 0.912328767123288 0 0 0 0 0 0 0
"1523" 60.5369863013699 63.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"1524" 64.7917808219178 65.8876712328767 5.00821917808219 0 0 0 0 0 0 0
"1525" 68.1013698630137 65.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"1526" 61.2876712328767 68.6520547945206 5.00821917808219 0 0 0 0 0 0 0
"1527" 61.8301369863014 65.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"1528" 66.9452054794521 65.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"1529" 57.1424657534247 65.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"1530" 56.827397260274 65.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"1531" 64.9698630136986 65.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"1532" 70.5616438356164 65.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"1533" 66.1041095890411 65.4904109589041 4.6027397260274 0 0 0 0 0 0 0
"1534" 63.6301369863014 64.041095890411 5.00821917808219 0 0 0 0 0 0 0
"1535" 60.9753424657534 63.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"1536" 58.8630136986301 63.0356164383562 4.6027397260274 0 0 0 0 0 0 0
"1537" 56.8794520547945 64.7013698630137 3.34520547945205 0 0 0 0 0 0 0
"1538" 58.6438356164384 63.2630136986301 4.6027397260274 0 0 0 0 0 0 0
"1539" 64.7013698630137 64.0356164383562 3.12602739726027 0 0 0 0 0 0 0
"1540" 72.0493150684931 61.9808219178082 5.00821917808219 0 0 0 0 0 0 0
"1541" 67.2191780821918 62.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"1542" 48.8082191780822 53.1917808219178 0.252054794520548 0 0 0 0 0 0 0
"1543" 61.5424657534247 62.7232876712329 2.67397260273973 0 1 0 0 0 0 0
"1544" 54.3561643835616 62.4739726027397 3.36438356164384 0 0 0 0 0 0 0
"1545" 59.6876712328767 61.2575342465753 3.91506849315068 0 0 0 0 0 0 0
"1546" 50.1150684931507 60.1068493150685 1.80821917808219 0 0 0 0 0 0 0
"1547" 61.1397260273973 61.4 3.11506849315069 0 0 0 0 0 0 0
"1548" 52.213698630137 58.5534246575342 3.4027397260274 0 0 0 0 0 0 0
"1549" 61.441095890411 61.6109589041096 0.887671232876712 0 0 0 0 0 0 0
"1550" 57.4876712328767 60.5506849315069 3.69315068493151 0 0 0 0 0 0 0
"1551" 56.2958904109589 61.3808219178082 4.53150684931507 0 0 0 0 0 0 0
"1552" 45.8027397260274 58.9534246575342 5.00821917808219 0 0 0 0 0 0 0
"1553" 55.2027397260274 61.9835616438356 2.25205479452055 0 0 0 0 0 0 0
"1554" 51.4164383561644 59.0465753424658 3.98082191780822 0 0 0 0 0 0 0
"1555" 63.2657534246575 57.158904109589 1.75342465753425 0 0 0 0 0 0 0
"1556" 49.0575342465753 60.5698630136986 3.45753424657534 0 0 0 0 0 0 0
"1557" 63.8383561643836 60.2602739726027 2.11506849315069 0 0 0 0 0 0 0
"1558" 66.6082191780822 65.4356164383562 1.52876712328767 0 0 0 0 0 0 0
"1559" 52.3698630136986 54.6630136986301 2.99178082191781 0 0 0 0 0 0 0
"1560" 60.1890410958904 60.3753424657534 2.8958904109589 0 0 0 0 0 0 0
"1561" 60.3835616438356 62.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"1562" 56.7835616438356 59.3205479452055 1.52876712328767 0 0 0 0 0 0 0
"1563" 61.4767123287671 61.6301369863014 2.8958904109589 0 0 0 0 0 0 0
"1564" 47.7260273972603 59.2493150684932 1.80821917808219 0 0 0 0 0 0 0
"1565" 58.1945205479452 60.9150684931507 5.00821917808219 0 0 0 0 0 0 0
"1566" 59.986301369863 65.4849315068493 3.45753424657534 0 0 0 0 0 0 0
"1567" 56.7287671232877 61.9753424657534 2.61369863013699 0 0 0 0 0 0 0
"1568" 56.2164383561644 59.6739726027397 1.08493150684932 0 0 0 0 0 0 0
"1569" 48.2219178082192 55.6849315068493 3.45753424657534 0 0 0 0 0 0 0
"1570" 44.3890410958904 56.9479452054794 1.5041095890411 0 0 0 0 0 0 0
"1571" 54.6054794520548 55.841095890411 0.367123287671233 1 0 0 0 0 0 0
"1572" 61.9698630136986 63.8438356164384 1.07945205479452 1 0 0 0 0 0 0
"1573" 51.9178082191781 61.8438356164384 4.84109589041096 0 0 0 0 0 0 0
"1574" 60.4301369863014 64.4246575342466 1.05753424657534 0 0 0 0 0 0 0
"1575" 52.9260273972603 59.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"1576" 62.2547945205479 63.9917808219178 3.24383561643836 0 0 0 0 0 0 0
"1577" 51.3013698630137 59.1178082191781 2.3041095890411 0 0 0 0 0 0 0
"1578" 55.1452054794521 61.9945205479452 2.12876712328767 0 0 0 0 0 0 0
"1579" 50.9178082191781 54 0.424657534246575 0 0 0 0 0 0 0
"1580" 55.9671232876712 59.5506849315069 2.07945205479452 0 0 0 0 0 0 0
"1581" 55.3835616438356 64.9753424657534 2 0 0 0 0 0 0 0
"1582" 60.7671232876712 66.2 2.90684931506849 0 0 0 0 0 0 0
"1583" 60.8465753424658 62.5643835616438 1.63835616438356 0 0 0 0 0 0 0
"1584" 62.6821917808219 65.8712328767123 4.41917808219178 0 0 0 0 0 0 0
"1585" 64.5013698630137 65.1068493150685 2.95342465753425 0 0 0 0 0 0 0
"1586" 67.9424657534247 65.3972602739726 2.51506849315069 0 0 0 0 0 0 0
"1587" 57.041095890411 64.4246575342466 4.60821917808219 0 0 0 0 0 0 0
"1588" 46.0876712328767 65.3260273972603 3.41917808219178 0 0 0 0 0 0 0
"1589" 63.558904109589 65.427397260274 4.59178082191781 0 0 0 0 0 0 0
"1590" 59.1808219178082 64.6356164383562 4.41917808219178 0 0 0 0 0 0 0
"1591" 62.6493150684932 64.972602739726 2.95342465753425 0 0 0 0 0 0 0
"1592" 54.7041095890411 64.9123287671233 2.46301369863014 0 0 0 0 0 0 0
"1593" 54.1068493150685 61.3342465753425 4.44109589041096 0 0 0 0 0 0 0
"1594" 57.4849315068493 64.4712328767123 3.22739726027397 0 0 0 0 0 0 0
"1595" 62.6191780821918 65.3150684931507 2.95342465753425 0 0 0 0 0 0 0
"1596" 60.4301369863014 64.1616438356164 2.83013698630137 0 0 0 0 0 0 0
"1597" 55.186301369863 69.2931506849315 3.3041095890411 0 0 0 0 0 0 0
"1598" 52.6109589041096 64.9835616438356 2.93698630136986 0 0 0 0 0 0 0
"1599" 62.9890410958904 64.8602739726027 3.66849315068493 1 0 0 0 0 0 0
"1600" 63.8904109589041 68.0712328767123 2.95342465753425 0 0 0 0 0 0 0
"1601" 58.2191780821918 62.3150684931507 3.62465753424658 0 0 0 0 0 0 0
"1602" 59.013698630137 65.1205479452055 4.41917808219178 0 0 0 0 0 0 0
"1603" 58.2027397260274 64.6684931506849 4.35616438356164 0 0 0 0 0 0 0
"1604" 60.6356164383562 65.3095890410959 3.08493150684932 1 0 0 0 0 0 0
"1605" 65.4876712328767 62.958904109589 2.51780821917808 0 0 0 0 0 0 0
"1606" 62.8794520547945 65.0575342465753 3.81917808219178 0 0 0 0 0 0 0
"1607" 63.4602739726027 64.3260273972603 3.05479452054795 0 0 0 0 0 0 0
"1608" 63.0821917808219 65.0383561643836 4.28219178082192 0 0 0 0 0 0 0
"1609" 48.2904109589041 60.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"1610" 68.1534246575342 65.5397260273973 4.8 0 0 0 0 0 0 0
"1611" 57.9479452054794 61.2602739726027 4.33698630136986 0 0 0 0 0 0 0
"1612" 61.9342465753425 64.5479452054795 1.31506849315068 0 0 0 0 0 0 0
"1613" 63.1506849315069 64.6438356164384 5.00821917808219 0 0 0 0 0 0 0
"1614" 59.3479452054795 66.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"1615" 63.9835616438356 65.4794520547945 4.6027397260274 0 0 0 0 0 0 0
"1616" 64.5780821917808 65.6630136986301 1.48219178082192 0 0 0 0 0 0 0
"1617" 66.6219178082192 64.6602739726027 1.5041095890411 0 0 0 0 0 0 0
"1618" 52.1972602739726 65.1095890410959 1.77808219178082 0 0 0 0 0 0 0
"1619" 58.9095890410959 66.3178082191781 3.37808219178082 0 0 0 0 0 0 0
"1620" 64.7068493150685 64.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"1621" 56.6 60.7260273972603 3.41917808219178 0 0 0 0 0 0 0
"1622" 58.2794520547945 72.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"1623" 37.0383561643836 65.0794520547945 0.942465753424658 0 0 0 0 0 0 0
"1624" 31.9342465753425 65.3232876712329 1.66027397260274 0 0 0 0 0 0 0
"1625" 43.2109589041096 64.558904109589 2.46301369863014 0 0 0 0 0 0 0
"1626" 50.5616438356164 55.0876712328767 1.38904109589041 0 0 0 0 0 0 0
"1627" 56.1808219178082 59.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"1628" 63.172602739726 59.7095890410959 2.4986301369863 0 0 0 0 0 0 0
"1629" 60.5095890410959 59.7917808219178 4.14520547945205 0 0 0 0 0 0 0
"1630" 59.1506849315069 60.0712328767123 1.35342465753425 0 0 0 0 0 0 0
"1631" 63.9643835616438 64.6712328767123 0.397260273972603 0 0 0 0 0 0 0
"1632" 57.0493150684932 58.5808219178082 0.408219178082192 0 0 0 0 0 0 0
"1633" 67.6356164383562 65.9643835616438 3.9041095890411 0 0 0 0 0 0 0
"1634" 56.9972602739726 58.0849315068493 5.00821917808219 0 0 0 0 0 0 0
"1635" 68.7041095890411 59.9698630136986 0 0 0 0 0 0 0 0
"1636" 64.6958904109589 65.2383561643836 4.93150684931507 0 0 0 0 0 0 0
"1637" 73.8602739726027 65.5945205479452 1.19452054794521 0 0 0 0 0 0 0
"1638" 28.4164383561644 66.1972602739726 4.93150684931507 0 0 0 0 0 0 0
"1639" 73.6986301369863 68.1506849315068 1.19452054794521 0 0 0 0 0 0 0
"1640" 62.4246575342466 68.6821917808219 0.0383561643835616 0 0 0 0 0 0 0
"1641" 68.6821917808219 62.4246575342466 0.0383561643835616 0 0 0 0 0 0 0
"1642" 68.1972602739726 64.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"1643" 44.7506849315068 60.013698630137 1.37534246575342 0 0 0 0 0 0 0
"1644" 55.8164383561644 56.3643835616438 2.09315068493151 0 0 0 0 0 0 0
"1645" 60.9890410958904 66.213698630137 2.86575342465753 0 0 0 0 0 0 0
"1646" 51.172602739726 65.1260273972603 2.93698630136986 0 0 0 0 0 0 0
"1647" 62.841095890411 64.8931506849315 1.19452054794521 0 0 0 0 0 0 0
"1648" 63.6027397260274 65.4054794520548 2.42739726027397 0 0 0 0 0 0 0
"1649" 60.5616438356164 55.8575342465753 3.72876712328767 0 0 0 0 0 0 0
"1650" 57.8246575342466 61.5890410958904 2.41917808219178 0 0 0 0 0 0 0
"1651" 63.9095890410959 65.0849315068493 5.00821917808219 0 0 0 0 0 0 0
"1652" 58.8328767123288 69.1698630136986 1.66301369863014 0 0 0 0 0 0 0
"1653" 71.3068493150685 70.8684931506849 2.29041095890411 0 0 0 0 0 0 0
"1654" 61.4493150684931 65.441095890411 3.32602739726027 0 0 0 0 0 0 0
"1655" 49.6027397260274 62.6164383561644 4.66575342465753 0 0 0 0 0 0 0
"1656" 57.5424657534247 61.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"1657" 63.986301369863 66.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"1658" 73.3643835616438 65.2 5.00821917808219 0 0 0 0 0 0 0
"1659" 55.9315068493151 60.7123287671233 4.6027397260274 0 0 0 0 0 0 0
"1660" 45.8 65.3205479452055 3.66849315068493 0 0 0 0 0 0 0
"1661" 66.4054794520548 65.3123287671233 2.94246575342466 0 0 0 0 0 0 0
"1662" 66.4164383561644 64.8191780821918 0.186301369863014 1 0 0 0 0 0 0
"1663" 64.5671232876712 65.7013698630137 2.93698630136986 0 0 0 0 0 0 0
"1664" 66.0082191780822 64.8465753424658 2.47397260273973 0 0 0 0 0 0 0
"1665" 62.8575342465753 70.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"1666" 72.2219178082192 72.7205479452055 3.74246575342466 0 0 0 0 0 0 0
"1667" 65.3260273972603 65.386301369863 2.26301369863014 0 0 0 0 0 0 0
"1668" 61.4082191780822 68.8821917808219 3.09315068493151 0 0 0 0 0 0 0
"1669" 61.6602739726027 66.2958904109589 4.08767123287671 1 0 0 0 0 0 0
"1670" 61.9616438356164 63.5068493150685 1.41917808219178 0 0 0 0 0 0 0
"1671" 64.9013698630137 65.1397260273973 3.58356164383562 1 0 0 0 0 0 0
"1672" 63.8328767123288 64.5808219178082 2.14794520547945 0 0 0 0 0 0 0
"1673" 63.4575342465753 65.3835616438356 2.53424657534247 0 0 0 0 0 0 0
"1674" 58.7041095890411 66.4 1.52054794520548 0 0 0 0 0 0 0
"1675" 54.6739726027397 56.5095890410959 0.405479452054795 1 0 0 0 0 0 0
"1676" 64.3808219178082 64.2301369863014 3.31780821917808 0 0 0 0 0 0 0
"1677" 67.8 64.2986301369863 0.884931506849315 0 0 0 0 0 0 0
"1678" 58.2383561643836 65.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"1679" 73.7479452054795 70.7068493150685 0.578082191780822 0 0 0 0 0 0 0
"1680" 53.7945205479452 57.6767123287671 1.21095890410959 0 0 0 0 0 0 0
"1681" 54.1972602739726 62.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"1682" 70.9643835616438 69.6602739726027 1.61369863013699 0 0 0 0 0 0 0
"1683" 54.5890410958904 64.0876712328767 2.75068493150685 0 0 0 0 0 0 0
"1684" 63.6630136986301 60.0219178082192 4.53424657534247 0 0 0 0 0 0 0
"1685" 60.5753424657534 63.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"1686" 64.1041095890411 65.1534246575342 4.92876712328767 0 0 0 0 0 0 0
"1687" 69.0356164383562 65.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"1688" 61.0520547945206 65.6904109589041 4.68219178082192 0 0 0 0 0 0 0
"1689" 57.5041095890411 61.813698630137 3.5041095890411 0 0 0 0 0 0 0
"1690" 57.9315068493151 65.0794520547945 3.25205479452055 0 0 0 0 0 0 0
"1691" 55.2849315068493 57.9260273972603 4 0 0 0 0 0 0 0
"1692" 48.1835616438356 57.6767123287671 2.42191780821918 1 0 0 0 0 0 0
"1693" 58.1753424657534 57.986301369863 1.15342465753425 0 0 0 0 0 0 0
"1694" 58.2164383561644 59.4438356164384 1.32602739726027 0 0 0 0 0 0 0
"1695" 63.2493150684932 65.1068493150685 2.95342465753425 0 0 0 0 0 0 0
"1696" 68.0547945205479 65.6520547945206 2.78356164383562 0 0 0 0 0 0 0
"1697" 61.9287671232877 55.5205479452055 1.66301369863014 0 0 0 0 0 0 0
"1698" 70.2520547945205 65.5780821917808 2.72328767123288 0 0 0 0 0 0 0
"1699" 46.0958904109589 65.9178082191781 3.31780821917808 0 0 0 0 0 0 0
"1700" 67.7643835616438 71.4904109589041 3.83835616438356 0 0 0 0 0 0 0
"1701" 71.1972602739726 65.6794520547945 1.33698630136986 0 1 0 0 0 0 0
"1702" 63.3260273972603 65.6246575342466 0.216438356164384 0 0 0 0 0 0 0
"1703" 70.1150684931507 69.8191780821918 2.98082191780822 0 0 0 0 0 0 0
"1704" 60.227397260274 64.8164383561644 3.01095890410959 0 0 0 0 0 0 0
"1705" 52.5150684931507 64.972602739726 3.67123287671233 0 0 0 0 0 0 0
"1706" 64.2164383561644 68.0849315068493 0.528767123287671 0 0 0 0 0 0 0
"1707" 58.172602739726 70.1260273972603 0.928767123287671 0 0 0 0 0 0 0
"1708" 67.0520547945205 70.0054794520548 3.58904109589041 1 0 0 0 0 0 0
"1709" 64.5890410958904 65.2191780821918 3.01369863013699 0 0 0 0 0 0 0
"1710" 65.3780821917808 66.1479452054794 2.25479452054795 0 0 0 0 0 0 0
"1711" 65.2547945205479 67.7424657534247 1.0027397260274 1 0 0 0 0 0 0
"1712" 65.5671232876712 65.5643835616438 1.58356164383562 0 0 0 0 0 0 0
"1713" 39.5287671232877 65.1232876712329 2.94246575342466 0 0 0 0 0 0 0
"1714" 59.841095890411 65.613698630137 4.2 0 0 0 0 0 0 0
"1715" 61.758904109589 65.0082191780822 0.794520547945205 0 0 0 0 0 0 0
"1716" 62.5452054794521 64.4767123287671 3.80821917808219 0 0 0 0 0 0 0
"1717" 49.4301369863014 54.6931506849315 0.36986301369863 0 0 0 0 0 0 0
"1718" 61.4821917808219 65.3835616438356 0.947945205479452 0 0 0 0 0 0 0
"1719" 63.0657534246575 59.7287671232877 0.36986301369863 0 0 0 0 0 0 0
"1720" 53.1534246575342 57.3643835616438 3.34246575342466 0 0 0 0 0 0 0
"1721" 66.7068493150685 63.6547945205479 0.961643835616438 0 0 0 0 0 0 0
"1722" 56.9643835616438 65.1369863013699 0.342465753424658 1 0 0 0 0 0 0
"1723" 59.4356164383562 64.1835616438356 0.810958904109589 0 0 0 0 0 0 0
"1724" 51.4109589041096 63.6438356164384 0.547945205479452 0 0 0 0 0 0 0
"1725" 72.186301369863 65.2849315068493 1.18356164383562 0 0 0 0 0 0 0
"1726" 60.8520547945205 63.5643835616438 1.46301369863014 0 0 0 0 0 0 0
"1727" 68.2520547945205 64.4383561643836 1.1041095890411 0 0 0 0 0 0 0
"1728" 61.158904109589 64.4904109589041 1.08493150684932 0 0 0 0 0 0 0
"1729" 61.8191780821918 65.1506849315068 0.758904109589041 0 0 0 0 0 0 0
"1730" 81.3150684931507 73.7534246575343 1.08493150684932 0 0 0 0 0 0 0
"1731" 81.6109589041096 74.0493150684931 0.789041095890411 0 0 0 0 0 0 0
"1732" 82.2054794520548 74.6438356164384 0.780821917808219 0 0 0 0 0 0 0
"1733" 56.4191780821918 55.5150684931507 0.213698630136986 0 0 0 0 0 0 0
"1734" 58.4958904109589 61.9041095890411 2.44383561643836 0 0 0 0 0 0 0
"1735" 65.7369863013699 63.5945205479452 2.46575342465753 0 0 0 0 0 0 0
"1736" 53.6027397260274 65.9917808219178 2.91506849315068 0 0 0 0 0 0 0
"1737" 56.0109589041096 61.3369863013699 2.46027397260274 0 0 0 0 0 0 0
"1738" 53.0849315068493 61.7232876712329 1.88767123287671 0 0 0 0 0 0 0
"1739" 66.3397260273973 60.8575342465753 1.84931506849315 0 0 0 0 0 0 0
"1740" 65.6520547945206 68.372602739726 0.0602739726027397 1 0 0 0 0 0 0
"1741" 60.3616438356164 63.4219178082192 2.26301369863014 0 0 0 0 0 0 0
"1742" 73.7068493150685 65.9013698630137 1.79452054794521 0 0 0 0 0 0 0
"1743" 70.3205479452055 65.7890410958904 0.597260273972603 0 0 0 0 0 0 0
"1744" 71.8356164383562 66.013698630137 0.56986301369863 0 0 0 0 0 0 0
"1745" 55.9260273972603 63.158904109589 1.87945205479452 0 0 0 0 0 0 0
"1746" 62.3260273972603 64.5315068493151 2.92328767123288 0 0 0 0 0 0 0
"1747" 64.5315068493151 62.3260273972603 2.92328767123288 0 0 0 0 0 0 0
"1748" 63.158904109589 55.9260273972603 1.87945205479452 0 0 0 0 0 0 0
"1749" 64.5013698630137 65.2328767123288 2.07945205479452 0 0 0 0 0 0 0
"1750" 60.7424657534247 65.4575342465753 0.564383561643836 0 0 0 0 0 0 0
"1751" 55.9561643835616 60.7342465753425 0.578082191780822 0 0 0 0 0 0 0
"1752" 64.6356164383562 65.158904109589 0.950684931506849 0 0 0 0 0 0 0
"1753" 64.9123287671233 65.7205479452055 1.63835616438356 0 0 0 0 0 0 0
"1754" 64.0739726027397 65.0904109589041 2.73150684931507 0 0 0 0 0 0 0
"1755" 63.641095890411 65.6876712328767 2.72602739726027 0 0 0 0 0 0 0
"1756" 54.1205479452055 57.4547945205479 2.07945205479452 0 0 0 0 0 0 0
"1757" 65.2904109589041 65.4493150684931 1.2 0 0 0 0 0 0 0
"1758" 65.4520547945205 65.786301369863 2.70684931506849 0 0 0 0 0 0 0
"1759" 60.5068493150685 60.427397260274 2.26301369863014 0 0 0 0 0 0 0
"1760" 65.4054794520548 65.2547945205479 2.69315068493151 0 0 0 0 0 0 0
"1761" 65.2931506849315 65.3150684931507 2.29315068493151 0 0 0 0 0 0 0
"1762" 74.5150684931507 65.372602739726 2.20547945205479 0 0 0 0 0 0 0
"1763" 59.1424657534247 64.8602739726027 0.279452054794521 0 0 0 0 0 0 0
"1764" 62.8904109589041 55.1917808219178 1.63835616438356 0 0 0 0 0 0 0
"1765" 67.3205479452055 61.9917808219178 2.4 0 0 0 0 0 0 0
"1766" 58.5205479452055 61.5095890410959 1.76712328767123 0 0 0 0 0 0 0
"1767" 65.0794520547945 64.1178082191781 1.75068493150685 0 0 0 0 0 0 0
"1768" 61.1041095890411 62.2164383561644 0.794520547945205 0 0 0 0 0 0 0
"1769" 56.3205479452055 60.2246575342466 0.219178082191781 0 0 0 0 0 0 0
"1770" 56.3013698630137 64.5315068493151 1.05753424657534 0 0 0 0 0 0 0
"1771" 64.4712328767123 62.7397260273973 1.30684931506849 0 0 0 0 0 0 0
"1772" 65.558904109589 60.2301369863014 1.44109589041096 0 0 0 0 0 0 0
"1773" 63.7068493150685 64.4849315068493 2.28493150684932 0 0 0 0 0 0 0
"1774" 64.0821917808219 64.7643835616438 0.53972602739726 0 0 0 0 0 0 0
"1775" 52.7561643835616 65.0739726027397 0.473972602739726 0 0 0 0 0 0 0
"1776" 58.4465753424658 65.2575342465753 0.772602739726027 0 0 0 0 0 0 0
"1777" 75.654794520548 65.2164383561644 0.30958904109589 0 0 0 0 0 0 0
"1778" 66.6657534246575 65.3808219178082 0.832876712328767 0 0 0 0 0 0 0
"1779" 59.3452054794521 64.6794520547945 1.9013698630137 0 0 0 0 0 0 0
"1780" 52.4493150684931 54.6602739726027 0.252054794520548 0 0 0 0 0 0 0
"1781" 65.7945205479452 66.4904109589041 1.04931506849315 0 0 0 0 0 0 0
"1782" 58.6027397260274 55.627397260274 0 0 0 0 0 0 0 0
"1783" 61.358904109589 65.1013698630137 1.08493150684932 0 0 0 0 0 0 0
"1784" 67.9041095890411 68.7506849315069 1.87945205479452 0 0 0 0 0 0 0
"1785" 61.2602739726027 69.0849315068493 1.89041095890411 0 0 0 0 0 0 0
"1786" 55.6109589041096 58.9397260273973 0.671232876712329 0 0 0 0 0 0 0
"1787" 60.5424657534247 65.3178082191781 1.40821917808219 0 0 0 0 0 0 0
"1788" 65.8328767123288 65.4246575342466 1.44383561643836 0 0 0 0 0 0 0
"1789" 62.1917808219178 65.0054794520548 0.816438356164384 0 0 0 0 0 0 0
"1790" 58.558904109589 64.5945205479452 1.23013698630137 0 0 0 0 0 0 0
"1791" 70.2356164383562 64.8082191780822 0.750684931506849 0 0 0 0 0 0 0
"1792" 57.5397260273973 65.5068493150685 1.56712328767123 0 0 0 0 0 0 0
"1793" 62.4054794520548 63.7369863013699 0.758904109589041 0 0 0 0 0 0 0
"1794" 53.1205479452055 65.1506849315068 0 0 0 0 0 0 0 0
"1795" 66.3835616438356 65.6219178082192 0.794520547945205 0 0 0 0 0 0 0
"1796" 65.4438356164383 71.758904109589 0.216438356164384 0 0 0 0 0 0 0
"1797" 65.586301369863 69.3506849315068 0.216438356164384 0 0 0 0 0 0 0
"1798" 64.7178082191781 64.7205479452055 0.216438356164384 0 0 0 0 0 0 0
"1799" 59.1616438356164 60.7315068493151 0.216438356164384 0 0 0 0 0 0 0
"1800" 64.4767123287671 71.5232876712329 0.213698630136986 0 0 0 0 0 0 0
"1801" 68.3479452054794 67.7506849315069 0.216438356164384 0 0 0 0 0 0 0
"1802" 59.2054794520548 65.1205479452055 0.216438356164384 0 0 0 0 0 0 0
"1803" 68.1452054794521 69.7835616438356 0.216438356164384 0 0 0 0 0 0 0
"1804" 69.1205479452055 68.9972602739726 0.216438356164384 0 0 0 0 0 0 0
"1805" 59.7123287671233 66.5424657534247 0.216438356164384 0 0 0 0 0 0 0
"1806" 63.6876712328767 69.3260273972603 0.216438356164384 0 0 0 0 0 0 0
"1807" 48.9424657534247 71.3315068493151 0.180821917808219 0 0 0 0 0 0 0
"1808" 63.613698630137 67.2821917808219 0.216438356164384 0 0 0 0 0 0 0
"1809" 64.4164383561644 66.041095890411 0.216438356164384 0 0 0 0 0 0 0
"1810" 57.0630136986301 68.2767123287671 0.216438356164384 0 0 0 0 0 0 0
"1811" 71.3260273972603 71.5178082191781 0.216438356164384 0 0 0 0 0 0 0
"1812" 72.1561643835616 69.4493150684931 0.216438356164384 0 0 0 0 0 0 0
"1813" 69.4438356164383 70.186301369863 0.216438356164384 0 0 0 0 0 0 0
"1814" 76.241095890411 70.7780821917808 0.216438356164384 0 0 0 0 0 0 0
"1815" 63.8767123287671 65.7945205479452 0.216438356164384 0 0 0 0 0 0 0
"1816" 62.372602739726 66.2219178082192 0.216438356164384 0 0 0 0 0 0 0
"1817" 61.9287671232877 66.3068493150685 0.216438356164384 0 0 0 0 0 0 0
"1818" 66.4191780821918 65.3232876712329 1.38356164383562 0 0 0 0 0 0 0
"1819" 65.9013698630137 67.2630136986301 0.717808219178082 0 0 0 0 0 0 0
"1820" 56.8986301369863 63.386301369863 0.942465753424658 0 0 0 0 0 0 0
"1821" 61.7260273972603 65.613698630137 0.43013698630137 0 0 0 0 0 0 0
"1822" 68.5424657534247 65.3123287671233 0.213698630136986 0 0 0 0 0 0 0
"1823" 68.5753424657534 65.345205479452 0.347945205479452 0 0 0 0 0 0 0
"1824" 77.7260273972603 64.8109589041096 0.205479452054795 0 0 0 0 0 0 0
"1825" 53.8164383561644 64.3643835616438 3.98082191780822 0 0 0 0 0 0 0
"1826" 81.1808219178082 84.9534246575342 1.24931506849315 0 0 0 1 0 3.5041095890411 0
"1827" 73.3917808219178 83.8876712328767 3.33150684931507 1 0 0 0 0 0 0
"1828" 65.7917808219178 64.9424657534247 2.98082191780822 0 0 0 0 0 0 0
"1829" 77.0054794520548 82.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"1830" 64.6164383561644 65.5808219178082 2.43835616438356 0 0 0 0 0 0 0
"1831" 68.5205479452055 81.8904109589041 5.00821917808219 0 0 0 0 0 0 0
"1832" 73.9452054794521 76.6767123287671 5.00821917808219 0 0 0 0 0 0 0
"1833" 64.9917808219178 65.5041095890411 1.48219178082192 0 0 0 0 0 0 0
"1834" 72.9479452054795 65.8465753424658 0.915068493150685 0 0 0 0 0 0 0
"1835" 71.4739726027397 76.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"1836" 72.3616438356164 76.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"1837" 71.1369863013699 69.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"1838" 74.3095890410959 72.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"1839" 62.8383561643836 65.7835616438356 2.8986301369863 0 0 0 0 0 0 0
"1840" 63.4 72.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"1841" 80.9780821917808 81.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"1842" 69.3232876712329 74.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"1843" 50.8958904109589 72.6 5.00821917808219 0 0 0 0 0 0 0
"1844" 64.0602739726027 66.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"1845" 50.9671232876712 68.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"1846" 61.5068493150685 65.4876712328767 0.504109589041096 0 0 0 0 0 0 0
"1847" 76.6246575342466 72.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"1848" 64.2109589041096 65.8219178082192 0.838356164383562 0 0 0 0 0 0 0
"1849" 57.6684931506849 65.5890410958904 2.25205479452055 0 0 0 0 0 0 0
"1850" 68.6684931506849 70.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"1851" 73.6164383561644 71.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"1852" 72.441095890411 71.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"1853" 55.8794520547945 67.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"1854" 73.0438356164384 72.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"1855" 56.0684931506849 60.5232876712329 2.56164383561644 0 0 0 0 0 0 0
"1856" 77.3780821917808 77.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"1857" 80.1041095890411 79.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"1858" 65.6301369863014 71.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"1859" 67.5123287671233 65.5534246575343 5.00821917808219 0 0 0 0 0 0 0
"1860" 60.3260273972603 65.1917808219178 1.25205479452055 0 0 0 0 0 0 0
"1861" 75.3315068493151 75.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"1862" 74.8082191780822 80.4164383561644 1.16438356164384 1 0 0 0 0 0 0
"1863" 74.4821917808219 73.2465753424657 5.00821917808219 0 0 0 0 0 0 0
"1864" 63.4082191780822 69.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"1865" 74.7808219178082 81.5753424657534 5.00821917808219 0 0 0 0 0 0 0
"1866" 65.8493150684932 68.441095890411 5.00821917808219 0 0 0 0 0 0 0
"1867" 67.0246575342466 68.5369863013699 5.00821917808219 0 0 0 0 0 0 0
"1868" 70.6657534246575 68.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"1869" 68.572602739726 68.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"1870" 63.4575342465753 66.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"1871" 76.4164383561644 71.186301369863 4.72602739726027 0 0 0 0 0 0 0
"1872" 73.4493150684931 76.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"1873" 63.6301369863014 65.227397260274 1.66849315068493 0 1 0 0 0 0 0
"1874" 64.0356164383562 68.1123287671233 5.00821917808219 0 0 0 0 0 0 0
"1875" 73.3260273972603 78.1287671232877 4.4986301369863 0 1 0 0 0 0 0
"1876" 68.3287671232877 71.9808219178082 5.00821917808219 0 0 0 0 0 0 0
"1877" 65.7479452054795 65.4849315068493 2.5041095890411 0 0 0 0 0 0 0
"1878" 59.5890410958904 65.0547945205479 0.0821917808219178 0 0 0 0 0 0 0
"1879" 61.4958904109589 65.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"1880" 74.1424657534247 75.6 3.53972602739726 0 0 0 0 0 0 0
"1881" 74.0630136986301 86.758904109589 0.224657534246575 1 0 0 0 0 0 0
"1882" 72.0438356164384 70.5698630136986 3.53972602739726 0 0 0 0 0 0 0
"1883" 73.0684931506849 75.5917808219178 3.53972602739726 0 0 0 0 0 0 0
"1884" 64.4246575342466 77.827397260274 3.53972602739726 0 0 0 0 0 0 0
"1885" 66.9616438356164 77.5890410958904 3.53972602739726 0 0 0 0 0 0 0
"1886" 77.8547945205479 78.3890410958904 3.53972602739726 0 0 0 0 0 0 0
"1887" 66.5315068493151 70.1123287671233 3.53972602739726 0 0 0 0 0 0 0
"1888" 51.4164383561644 53.3260273972603 3.84383561643836 0 0 0 0 0 0 0
"1889" 50.6328767123288 52.5424657534247 3.7972602739726 0 0 0 0 0 0 0
"1890" 50.6876712328767 52.8849315068493 3.84383561643836 0 0 0 0 0 0 0
"1891" 58.2383561643836 55.0082191780822 2.92602739726027 0 1 0 0 0 0 0
"1892" 57.5260273972603 54.2958904109589 2.84109589041096 0 1 0 0 0 0 0
"1893" 51.7205479452055 51.7287671232877 4.75342465753425 0 0 0 0 0 0 0
"1894" 55.1643835616438 53.572602739726 3.8958904109589 0 0 0 0 0 0 0
"1895" 54.4328767123288 52.841095890411 3.7972602739726 0 0 0 0 0 0 0
"1896" 67.2876712328767 66.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"1897" 50.7397260273973 51.9534246575342 3.93698630136986 0 0 0 0 0 0 0
"1898" 57.2849315068493 56.1479452054795 4.67123287671233 0 0 0 0 0 0 0
"1899" 59.7315068493151 62.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"1900" 47.9698630136986 54.2027397260274 4.73698630136986 0 0 0 0 0 0 0
"1901" 65.6821917808219 65.2849315068493 2.92328767123288 0 0 0 0 0 0 0
"1902" 58.5369863013699 68.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"1903" 63.9780821917808 72.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"1904" 56.9479452054794 72.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"1905" 63.8109589041096 71.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"1906" 63.5424657534247 69.3534246575342 0.0876712328767123 1 0 0 0 0 0 0
"1907" 52.0246575342466 60.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"1908" 60.5342465753425 64.4328767123288 0.876712328767123 0 0 0 0 0 0 0
"1909" 61.2054794520548 60.4465753424658 3.9041095890411 0 0 0 0 0 0 0
"1910" 64.2438356164384 69.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"1911" 63.8301369863014 69.8082191780822 5.00821917808219 0 0 0 0 0 0 0
"1912" 63.8602739726027 71.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"1913" 67.0356164383562 72.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"1914" 60.6739726027397 71.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"1915" 70.5178082191781 67.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"1916" 68.2794520547945 68.7506849315069 5.00821917808219 0 0 0 0 0 0 0
"1917" 69.2602739726027 71.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"1918" 70.9260273972603 74.1780821917808 5.00821917808219 0 0 0 0 0 0 0
"1919" 67.6383561643836 69.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"1920" 64.9643835616438 68.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"1921" 71.5013698630137 73.2328767123288 5.00821917808219 0 0 0 0 0 0 0
"1922" 64.1561643835616 69.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"1923" 67.986301369863 69.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"1924" 66.5095890410959 68.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"1925" 66.1506849315068 71.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"1926" 59.7150684931507 72.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"1927" 63.0191780821918 68.2191780821918 5.00821917808219 0 0 0 0 0 0 0
"1928" 71.027397260274 70.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"1929" 68.4465753424657 68.2547945205479 2.4986301369863 0 0 0 1 0 0.295890410958904 0
"1930" 54.641095890411 69.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"1931" 63.8630136986301 67.841095890411 5.00821917808219 0 0 0 0 0 0 0
"1932" 65.6301369863014 68.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"1933" 67.6246575342466 68.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"1934" 67.5369863013699 68.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"1935" 64.372602739726 69.3479452054794 5.00821917808219 0 0 0 0 0 0 0
"1936" 66.9917808219178 70.441095890411 5.00821917808219 0 0 0 0 0 0 0
"1937" 68.1369863013699 67.972602739726 5.00821917808219 0 0 0 0 0 0 0
"1938" 73.0520547945205 72.9945205479452 4.24931506849315 1 0 0 0 0 0 0
"1939" 67.9315068493151 70.0575342465753 4.24931506849315 1 0 0 0 0 0 0
"1940" 74.0602739726027 71.8821917808219 4.16438356164384 1 0 0 0 0 0 0
"1941" 75.7123287671233 72.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"1942" 66.9150684931507 69.5369863013699 5.00821917808219 0 0 0 0 0 0 0
"1943" 69.7780821917808 70.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"1944" 66.386301369863 72.958904109589 2.24931506849315 1 0 0 0 0 0 0
"1945" 76.0356164383562 73.6383561643836 5.00821917808219 0 0 0 0 0 0 0
"1946" 67.2328767123288 69.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"1947" 71.1424657534247 68.4712328767123 5.00821917808219 0 0 0 0 0 0 0
"1948" 71.5205479452055 73.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"1949" 69.2328767123288 73.0465753424658 5.00821917808219 0 0 0 0 0 0 0
"1950" 67.9260273972603 70.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"1951" 64.3205479452055 64.1534246575342 3.33150684931507 1 0 0 0 0 0 0
"1952" 69.0986301369863 71.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"1953" 66.8547945205479 70.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"1954" 68.0191780821918 70.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"1955" 70.9178082191781 72.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"1956" 71.9945205479452 70.827397260274 5.00821917808219 0 0 0 0 0 0 0
"1957" 69.6630136986301 74.0904109589041 5.00821917808219 0 0 0 0 0 0 0
"1958" 70.4383561643836 70.1808219178082 5.00821917808219 0 0 0 0 0 0 0
"1959" 68.5424657534247 69.4328767123288 5.00821917808219 0 0 0 0 0 0 0
"1960" 71.6849315068493 70.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"1961" 61.2794520547945 68.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"1962" 62.0328767123288 69.8465753424658 4.4986301369863 1 0 0 0 0 0 0
"1963" 69.2547945205479 67.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"1964" 68.8328767123288 68.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"1965" 66.6630136986301 67.1315068493151 5.00821917808219 0 0 0 0 0 0 0
"1966" 66.6246575342466 66.9095890410959 5.00821917808219 0 0 0 0 0 0 0
"1967" 74.5479452054795 70.8931506849315 5.00821917808219 0 0 0 0 0 0 0
"1968" 70.4602739726027 70.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"1969" 63.7342465753425 71.2 1.24931506849315 1 0 0 0 0 0 0
"1970" 66.0575342465753 66.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"1971" 61.9561643835616 70.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"1972" 68.1616438356164 68.8082191780822 5.00821917808219 0 0 0 0 0 0 0
"1973" 62.9369863013699 66.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"1974" 64.5890410958904 68.0191780821918 4.83561643835616 1 0 0 0 0 0 0
"1975" 73.0876712328767 66.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"1976" 69.1506849315068 72.9945205479452 0.331506849315069 1 0 0 0 0 0 0
"1977" 63.1808219178082 67.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"1978" 71.4630136986301 69.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"1979" 60.4958904109589 66.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"1980" 71.4164383561644 69.9917808219178 5.00821917808219 0 0 0 0 0 0 0
"1981" 65.1917808219178 73.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"1982" 74.9808219178082 73.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"1983" 70.0767123287671 70.627397260274 5.00821917808219 0 0 0 0 0 0 0
"1984" 63.6849315068493 66.7041095890411 5.00821917808219 0 0 0 0 0 0 0
"1985" 55.8986301369863 59.6684931506849 2.15616438356164 0 0 0 0 0 0 0
"1986" 74.8931506849315 69.2904109589041 5.00821917808219 0 0 0 0 0 0 0
"1987" 74.9753424657534 69.372602739726 5.00821917808219 0 0 0 0 0 0 0
"1988" 74.9753424657534 69.372602739726 5.00821917808219 0 0 0 0 0 0 0
"1989" 74.9753424657534 69.372602739726 5.00821917808219 0 0 0 0 0 0 0
"1990" 74.9753424657534 69.372602739726 5.00821917808219 0 0 0 0 0 0 0
"1991" 76.9123287671233 71.3095890410959 3.82465753424658 0 0 0 0 0 0 0
"1992" 66.3150684931507 62.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"1993" 66.3150684931507 62.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"1994" 68.0027397260274 64.6657534246575 3.82465753424658 0 0 0 0 0 0 0
"1995" 62.5534246575342 66.4054794520548 5.00821917808219 0 0 0 0 0 0 0
"1996" 62.8876712328767 66.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"1997" 62.8876712328767 66.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"1998" 62.8876712328767 66.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"1999" 62.8876712328767 66.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"2000" 64.8246575342466 68.6767123287671 3.82465753424658 0 0 0 0 0 0 0
"2001" 62.4164383561644 66.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"2002" 62.4164383561644 66.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"2003" 62.4164383561644 66.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"2004" 64.1041095890411 68.1369863013699 3.82465753424658 0 0 0 0 0 0 0
"2005" 67.3643835616438 66.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2006" 67.3643835616438 66.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2007" 67.3643835616438 66.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2008" 69.3013698630137 68.2520547945205 3.82465753424658 0 0 0 0 0 0 0
"2009" 57.4767123287671 66.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"2010" 57.4767123287671 66.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"2011" 58.5835616438356 67.1945205479452 3.82465753424658 0 0 0 0 0 0 0
"2012" 56.5780821917808 65.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"2013" 56.827397260274 65.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"2014" 58.3452054794521 67.4575342465753 3.82465753424658 0 0 0 0 0 0 0
"2015" 64.6356164383562 64.9643835616438 5.00821917808219 0 0 0 0 0 0 0
"2016" 65.3890410958904 65.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"2017" 67.3260273972603 67.654794520548 3.82465753424658 0 0 0 0 0 0 0
"2018" 70.6438356164384 65.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"2019" 70.6438356164384 65.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"2020" 72.5808219178082 67.4383561643836 3.82465753424658 0 0 0 0 0 0 0
"2021" 66.4383561643836 65.8246575342466 4.6027397260274 0 0 0 0 0 0 0
"2022" 63.9643835616438 64.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"2023" 63.9643835616438 64.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"2024" 65.9013698630137 66.3123287671233 3.82465753424658 0 0 0 0 0 0 0
"2025" 57.4876712328767 65.4465753424657 4.91232876712329 0 0 0 0 0 0 0
"2026" 61.9698630136986 63.8438356164384 1.07945205479452 1 0 0 0 0 0 0
"2027" 61.3095890410959 63.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"2028" 62.7452054794521 65.0575342465753 3.82465753424658 0 0 0 0 0 0 0
"2029" 59.5671232876712 65.0657534246575 3.45753424657534 0 0 0 0 0 0 0
"2030" 53.8164383561644 64.3643835616438 3.98082191780822 0 0 0 0 0 0 0
"2031" 54.1424657534247 64.6904109589041 3.82191780821918 0 0 0 0 0 0 0
"2032" 60.2657534246575 65.6986301369863 2.90684931506849 0 0 0 0 0 0 0
"2033" 65.2465753424657 64.0794520547945 3.19452054794521 0 0 0 0 0 0 0
"2034" 55.7561643835616 63.8876712328767 3.27945205479452 0 0 0 0 0 0 0
"2035" 57.4246575342466 63.6054794520548 4.53424657534247 0 0 0 0 0 0 0
"2036" 59.6931506849315 63.8657534246575 4.6027397260274 0 0 0 0 0 0 0
"2037" 60.0520547945206 64.2246575342466 3.82465753424658 0 0 0 0 0 0 0
"2038" 56.8794520547945 64.7013698630137 3.34520547945205 0 0 0 0 0 0 0
"2039" 58.7260273972603 63.3452054794521 4.6027397260274 0 0 0 0 0 0 0
"2040" 59.6712328767123 64.2904109589041 3.82465753424658 0 0 0 0 0 0 0
"2041" 64.2821917808219 63.6164383561644 3.12602739726027 0 0 0 0 0 0 0
"2042" 72.2164383561644 62.1479452054795 5.00821917808219 0 0 0 0 0 0 0
"2043" 72.2164383561644 62.1479452054795 5.00821917808219 0 0 0 0 0 0 0
"2044" 74.1534246575342 64.0849315068493 3.82465753424658 0 0 0 0 0 0 0
"2045" 67.2191780821918 62.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"2046" 67.2191780821918 62.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"2047" 69.1561643835616 63.972602739726 3.82465753424658 0 0 0 0 0 0 0
"2048" 54.7452054794521 63.9643835616438 4.8986301369863 0 0 0 0 0 0 0
"2049" 48.8082191780822 53.1917808219178 0.252054794520548 0 0 0 0 0 0 0
"2050" 61.2082191780822 62.3890410958904 2.67397260273973 0 1 0 0 0 0 0
"2051" 54.441095890411 62.558904109589 3.36438356164384 0 0 0 0 0 0 0
"2052" 59.7698630136986 61.3397260273973 3.91506849315068 0 0 0 0 0 0 0
"2053" 50.9452054794521 60.9369863013699 1.80821917808219 0 0 0 0 0 0 0
"2054" 60.1013698630137 64.0575342465753 3.45753424657534 0 0 0 0 0 0 0
"2055" 61.3068493150685 61.5671232876712 3.11506849315069 0 0 0 0 0 0 0
"2056" 62.1095890410959 62.2794520547945 0.887671232876712 0 0 0 0 0 0 0
"2057" 57.8219178082192 60.8849315068493 3.69315068493151 0 0 0 0 0 0 0
"2058" 56.2931506849315 61.3780821917808 4.53424657534247 0 0 0 0 0 0 0
"2059" 57.2547945205479 62.3397260273973 3.82465753424658 0 0 0 0 0 0 0
"2060" 59.213698630137 64.9205479452055 2.48219178082192 0 0 0 0 0 0 0
"2061" 46.3890410958904 59.5397260273973 5.00821917808219 0 0 0 0 0 0 0
"2062" 48.3260273972603 61.4767123287671 3.82465753424658 0 0 0 0 0 0 0
"2063" 55.4520547945205 62.2328767123288 2.25205479452055 0 0 0 0 0 0 0
"2064" 51.4164383561644 59.0465753424658 3.98082191780822 0 0 0 0 0 0 0
"2065" 63.8520547945205 57.7452054794521 1.75342465753425 0 0 0 0 0 0 0
"2066" 54.9890410958904 60.6356164383562 0.405479452054795 0 0 0 0 0 0 0
"2067" 49.0575342465753 60.5698630136986 3.45753424657534 0 0 0 0 0 0 0
"2068" 63.8383561643836 60.2602739726027 2.11506849315069 0 0 0 0 0 0 0
"2069" 56.8356164383562 63.5452054794521 3.46027397260274 0 0 0 0 0 0 0
"2070" 65.8684931506849 63.3315068493151 0.334246575342466 0 0 0 0 0 0 0
"2071" 60.7753424657534 60.9616438356164 2.8958904109589 0 0 0 0 0 0 0
"2072" 61.4767123287671 61.6301369863014 2.8958904109589 0 0 0 0 0 0 0
"2073" 48.3945205479452 59.9178082191781 1.80821917808219 0 0 0 0 0 0 0
"2074" 54.6739726027397 60.3643835616438 0.671232876712329 0 0 0 0 0 0 0
"2075" 60.3808219178082 63.1013698630137 3.82465753424658 0 0 0 0 0 0 0
"2076" 62.3890410958904 65.1095890410959 1.81643835616438 0 0 0 0 0 0 0
"2077" 56.7287671232877 61.9753424657534 2.61369863013699 0 0 0 0 0 0 0
"2078" 58.8602739726027 61.6986301369863 0.736986301369863 0 0 0 0 0 0 0
"2079" 54.586301369863 61.2684931506849 0.810958904109589 0 0 0 0 0 0 0
"2080" 56.5506849315069 60.0082191780822 1.08493150684932 0 0 0 0 0 0 0
"2081" 48.3041095890411 55.7671232876712 3.45753424657534 0 0 0 0 0 0 0
"2082" 54.6164383561644 61.1671232876712 0.221917808219178 0 0 0 0 0 0 0
"2083" 57.8493150684931 61.5835616438356 0.778082191780822 0 0 0 0 0 0 0
"2084" 51.7479452054795 61.6739726027397 4.84109589041096 0 0 0 0 0 0 0
"2085" 53.1068493150685 63.0328767123288 3.82465753424658 0 0 0 0 0 0 0
"2086" 61.2602739726027 65.2547945205479 1.05753424657534 0 0 0 0 0 0 0
"2087" 51.4684931506849 59.2849315068493 2.3041095890411 0 0 0 0 0 0 0
"2088" 52.1452054794521 61.9945205479452 2.12876712328767 0 0 0 0 0 0 0
"2089" 51.5041095890411 54.586301369863 0.424657534246575 0 0 0 0 0 0 0
"2090" 56.6356164383562 60.2191780821918 2.07945205479452 0 0 0 0 0 0 0
"2091" 44.0904109589041 60.0164383561644 0.717808219178082 0 0 0 0 0 0 0
"2092" 60.8438356164384 62.5616438356164 1.64109589041096 0 0 0 0 0 0 0
"2093" 63.0027397260274 59.3287671232877 3 0 0 0 0 0 0 0
"2094" 65.0657534246575 65.7753424657534 1.83835616438356 0 0 0 0 0 0 0
"2095" 67.8246575342466 67.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"2096" 58.4767123287671 62.2054794520548 1.04931506849315 0 0 0 0 0 0 0
"2097" 52.2821917808219 54.8054794520548 1.25205479452055 0 0 0 0 0 0 0
"2098" 77.2 78.8054794520548 2.58356164383562 1 0 0 0 0 0 0
"2099" 62.027397260274 65.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"2100" 58.3479452054795 65.0438356164384 4.75342465753425 0 0 0 0 0 0 0
"2101" 63.8191780821918 65.4684931506849 1.5041095890411 0 0 0 0 0 0 0
"2102" 57.0767123287671 65.4657534246575 0.504109589041096 0 0 0 0 0 0 0
"2103" 67.5534246575343 65.7616438356164 1.54246575342466 0 0 0 0 0 0 0
"2104" 63.7753424657534 65.5890410958904 0.586301369863014 0 0 0 0 0 0 0
"2105" 62.8438356164384 64.6767123287671 0.506849315068493 1 0 0 0 0 0 0
"2106" 69.3835616438356 67.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"2107" 61.8328767123288 66.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"2108" 65.213698630137 65.6794520547945 3.75342465753425 0 0 0 0 0 0 0
"2109" 58.8794520547945 65.0054794520548 2.16712328767123 0 0 0 0 0 0 0
"2110" 65.5917808219178 70.5178082191781 5.00821917808219 0 0 0 0 0 0 0
"2111" 66.9534246575342 71.2547945205479 5.00821917808219 0 0 0 0 0 0 0
"2112" 59.7616438356164 67.2520547945205 1.91780821917808 1 0 0 0 0 0 0
"2113" 71.4739726027397 74.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"2114" 66.8849315068493 80.7616438356164 2.58356164383562 1 0 0 0 0 0 0
"2115" 72.9452054794521 72.4712328767123 5.00821917808219 0 0 0 0 0 0 0
"2116" 71.4520547945205 80.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"2117" 65.572602739726 65.3178082191781 2.33424657534247 0 0 0 0 0 0 0
"2118" 69.8684931506849 64.6356164383562 0.419178082191781 0 0 0 0 0 0 0
"2119" 69.8164383561644 72.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"2120" 69.9890410958904 77.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"2121" 63.6109589041096 72.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"2122" 70.1479452054794 78.4164383561644 5.00821917808219 0 0 0 0 0 0 0
"2123" 63.6383561643836 70.9287671232877 3.66849315068493 1 0 0 0 0 0 0
"2124" 78.6767123287671 76.9315068493151 5.00821917808219 0 0 0 0 0 0 0
"2125" 57.227397260274 65.827397260274 5.00821917808219 0 0 0 0 0 0 0
"2126" 65.4767123287671 68.8739726027397 5.00821917808219 0 0 0 0 0 0 0
"2127" 64.4904109589041 65.2630136986301 0.334246575342466 0 0 0 0 0 0 0
"2128" 56.7671232876712 67.8739726027397 0.0575342465753425 0 0 0 0 0 0 0
"2129" 68.3945205479452 68.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"2130" 66.9643835616438 80.2904109589041 3.0027397260274 1 0 0 0 0 0 0
"2131" 57.4164383561644 62.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"2132" 66.7315068493151 69.6191780821918 5.00821917808219 0 0 0 0 0 0 0
"2133" 70.5808219178082 71.586301369863 0 0 0 0 1 0 0.353424657534247 0
"2134" 60.1041095890411 65.8821917808219 4.91506849315068 0 0 0 0 0 0 0
"2135" 69.4191780821918 54.5616438356164 1.33424657534247 0 0 0 0 0 0 0
"2136" 70.372602739726 64.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"2137" 59.8465753424658 65.586301369863 2.43561643835616 0 0 0 0 0 0 0
"2138" 56.3041095890411 65.8904109589041 1.83561643835616 0 0 0 0 0 0 0
"2139" 69.6849315068493 66.2904109589041 5.00821917808219 0 0 0 0 0 0 0
"2140" 64.2547945205479 67.227397260274 5.00821917808219 0 0 0 0 0 0 0
"2141" 71.5671232876712 67.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"2142" 57.4904109589041 62.5561643835616 4.16438356164384 1 0 0 0 0 0 0
"2143" 53.2493150684932 57.3479452054795 5.00821917808219 0 0 0 0 0 0 0
"2144" 57.8109589041096 71.827397260274 2.08767123287671 1 0 0 0 0 0 0
"2145" 54.772602739726 69.5397260273973 5.00821917808219 0 0 0 0 0 0 0
"2146" 57.3890410958904 69.213698630137 5.00821917808219 0 0 0 0 0 0 0
"2147" 67.3123287671233 70.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"2148" 67.5917808219178 70.6109589041096 5.00821917808219 0 0 0 0 0 0 0
"2149" 57.4794520547945 61.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"2150" 65.9479452054795 66.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"2151" 59.7835616438356 64.2465753424657 2.58630136986301 0 0 0 0 0 0 0
"2152" 56.8739726027397 60.0328767123288 2.53424657534247 0 0 0 0 0 0 0
"2153" 59.172602739726 67.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"2154" 61.8547945205479 60.4219178082192 2.61643835616438 0 0 0 0 0 0 0
"2155" 65.3315068493151 65.586301369863 3.58630136986301 0 0 0 0 0 0 0
"2156" 45.1369863013699 60.413698630137 1.86301369863014 0 0 0 0 0 0 0
"2157" 57.6767123287671 65.4 0.394520547945205 0 0 0 0 0 0 0
"2158" 61.4739726027397 63.6301369863014 0.257534246575342 0 0 0 0 0 0 0
"2159" 64.1342465753425 63.2493150684932 5.00821917808219 0 0 0 0 0 0 0
"2160" 57.2356164383562 60.2602739726027 1.67123287671233 0 0 0 0 0 0 0
"2161" 61.8575342465753 61.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"2162" 67.8219178082192 69.9753424657534 0.0876712328767123 1 0 0 0 0 0 0
"2163" 63.1068493150685 64.2328767123288 5.00821917808219 0 0 0 0 0 0 0
"2164" 60.6602739726027 68.772602739726 0.673972602739726 0 1 0 0 0 0 0
"2165" 74.4767123287671 76.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"2166" 64.4027397260274 70.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"2167" 62.6684931506849 57.1205479452055 5.00821917808219 0 0 0 0 0 0 0
"2168" 65.227397260274 66.358904109589 5.00821917808219 0 0 0 0 0 0 0
"2169" 59.3643835616438 61.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"2170" 70.2547945205479 70.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"2171" 61.1205479452055 62.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"2172" 67.8356164383562 68.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"2173" 68.7671232876712 68.9643835616438 4.41095890410959 0 0 0 0 0 0 0
"2174" 72.3753424657534 64.4602739726027 2.33424657534247 0 0 0 0 0 0 0
"2175" 64.1095890410959 66.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"2176" 61.7808219178082 63.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"2177" 73.8246575342466 64.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"2178" 73.8246575342466 64.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"2179" 70.1972602739726 65.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"2180" 64.3150684931507 63.2465753424658 2.41643835616438 0 0 1 0 1 0 0.0465753424657534
"2181" 57.7671232876712 60.241095890411 3.83561643835616 1 0 0 0 0 0 0
"2182" 61.4630136986301 63.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"2183" 66.7287671232877 68.3315068493151 5.00821917808219 0 0 0 0 0 0 0
"2184" 60.7972602739726 60.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"2185" 60.1616438356164 61.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"2186" 60.7452054794521 63.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"2187" 65.5095890410959 67.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"2188" 60.0493150684932 62.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"2189" 60.4821917808219 61.0684931506849 5.00821917808219 0 0 0 0 0 0 0
"2190" 61.1205479452055 66.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"2191" 62.3205479452055 64.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"2192" 68.7479452054795 61.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"2193" 56.8931506849315 59.1178082191781 3.07397260273973 0 0 0 0 0 0 0
"2194" 61.5178082191781 73.2712328767123 2.08767123287671 1 0 0 0 0 0 0
"2195" 69.8849315068493 70.2328767123288 5.00821917808219 0 0 0 0 0 0 0
"2196" 68.5698630136986 68.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"2197" 89.9178082191781 65.2904109589041 3.33424657534247 0 0 0 0 0 0 0
"2198" 65.9095890410959 68.9095890410959 5.00821917808219 0 0 0 0 0 0 0
"2199" 72.1698630136986 70.4465753424657 5.00821917808219 0 0 0 0 0 0 0
"2200" 57.7369863013699 73.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"2201" 63.6383561643836 65.3561643835616 5.00821917808219 0 0 0 0 0 0 0
"2202" 67.0082191780822 70.7150684931507 5.00821917808219 0 0 0 0 0 0 0
"2203" 63.6438356164384 70.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"2204" 55.4328767123288 70.1616438356164 1.0027397260274 1 0 0 0 0 0 0
"2205" 54.7643835616438 69.4904109589041 1.0027397260274 1 0 0 0 0 0 0
"2206" 63.372602739726 70.1013698630137 1.83561643835616 0 1 0 0 0 0 0
"2207" 63.8465753424658 65.8739726027397 4.43561643835616 0 0 0 0 0 0 0
"2208" 62.8876712328767 57.772602739726 5.00821917808219 0 0 0 0 0 0 0
"2209" 62.4630136986301 68.372602739726 5.00821917808219 0 0 0 0 0 0 0
"2210" 55.7123287671233 68.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"2211" 55.7123287671233 68.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"2212" 76.5945205479452 68.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"2213" 60.7917808219178 65.2246575342466 3.95068493150685 0 0 0 0 0 0 0
"2214" 68.4 68.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"2215" 66.1369863013699 66.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"2216" 75.4821917808219 65.1369863013699 3.91780821917808 0 0 0 0 0 0 0
"2217" 66.2547945205479 69.227397260274 5.00821917808219 0 0 0 0 0 0 0
"2218" 69.227397260274 66.2547945205479 5.00821917808219 0 0 0 0 0 0 0
"2219" 68.6054794520548 65.0246575342466 4.96986301369863 0 0 0 0 0 0 0
"2220" 63.6465753424658 67.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"2221" 58.6219178082192 65.4931506849315 4.43561643835616 0 0 0 0 0 0 0
"2222" 65.3232876712329 65.5013698630137 3.95068493150685 0 0 0 0 0 0 0
"2223" 66.8328767123288 68.6328767123288 5.00821917808219 0 0 0 0 0 0 0
"2224" 66.3342465753425 65.5616438356164 4.43561643835616 0 0 0 0 0 0 0
"2225" 67.8630136986301 72.4986301369863 3.33150684931507 1 0 0 0 0 0 0
"2226" 68.5753424657534 70.3315068493151 1.33150684931507 1 0 0 0 0 0 0
"2227" 63.9123287671233 65.8657534246575 2.6958904109589 0 0 0 0 0 0 0
"2228" 60.9671232876712 60.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"2229" 59.2301369863014 64.7068493150685 0.0821917808219178 0 0 0 0 0 0 0
"2230" 79.1095890410959 70.6767123287671 2.76712328767123 0 0 0 0 0 0 0
"2231" 62.441095890411 72.9150684931507 5.00821917808219 0 0 0 0 0 0 0
"2232" 61.1123287671233 65.7205479452055 4.81917808219178 0 0 0 0 0 0 0
"2233" 73.1232876712329 73.6 5.00821917808219 0 0 0 0 0 0 0
"2234" 66.4986301369863 68.2739726027397 2.65753424657534 0 0 0 0 0 0 0
"2235" 59.8849315068493 74.8328767123288 2.03835616438356 0 0 0 0 0 0 0
"2236" 56.2739726027397 55.1232876712329 3.16712328767123 0 0 0 0 0 0 0
"2237" 59.4328767123288 64.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"2238" 66.3397260273973 65.3205479452055 4.91780821917808 0 0 0 0 0 0 0
"2239" 62.2493150684932 62.7397260273973 3.64931506849315 0 0 0 0 0 0 0
"2240" 62.1342465753425 74.6575342465753 3.75890410958904 1 0 0 0 0 0 0
"2241" 68.2958904109589 65.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"2242" 69.4465753424657 66.7753424657534 4.77808219178082 0 0 0 0 0 0 0
"2243" 63.5671232876712 69.4712328767123 4.75342465753425 0 0 0 0 0 0 0
"2244" 61.3945205479452 65.0767123287671 0.0821917808219178 0 0 0 0 0 0 0
"2245" 70.1506849315068 67.1150684931507 1.16438356164384 1 0 0 0 0 0 0
"2246" 51.6630136986301 63.7890410958904 4.81643835616438 0 0 0 0 0 0 0
"2247" 55.1369863013699 65.6849315068493 4.64931506849315 0 0 0 0 0 0 0
"2248" 62.3890410958904 64.8767123287671 2.3972602739726 0 0 0 0 0 0 0
"2249" 61.4904109589041 66.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"2250" 65.7260273972603 65.6493150684932 0.671232876712329 0 0 0 0 0 0 0
"2251" 62.1698630136986 65.4602739726027 2.45753424657534 0 0 0 0 0 0 0
"2252" 49.4027397260274 56.0082191780822 3.27123287671233 0 0 0 0 0 0 0
"2253" 64.7671232876712 67.1369863013699 5.00821917808219 0 0 0 0 0 0 0
"2254" 62.2876712328767 63.9616438356164 3.27123287671233 0 0 0 0 0 0 0
"2255" 65.0931506849315 65.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"2256" 66.0767123287671 66.5534246575343 4.77808219178082 0 0 0 0 0 0 0
"2257" 66.0849315068493 65.6931506849315 5.00821917808219 0 0 0 0 0 0 0
"2258" 75.8027397260274 66.5945205479452 3.58356164383562 1 0 0 0 0 0 0
"2259" 58.5232876712329 56.2684931506849 4.4986301369863 1 0 0 0 0 0 0
"2260" 63.6054794520548 65.641095890411 2.04109589041096 0 0 0 0 0 0 0
"2261" 63.3123287671233 65.6821917808219 2.75342465753425 0 0 0 0 0 0 0
"2262" 54.1342465753425 63.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"2263" 61.9561643835616 63.813698630137 4.81917808219178 0 0 0 0 0 0 0
"2264" 49.6219178082192 56.3479452054795 2.45753424657534 0 0 0 0 0 0 0
"2265" 68.654794520548 67.0767123287671 4.24931506849315 1 0 0 0 0 0 0
"2266" 63.3260273972603 66.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"2267" 78.4301369863014 65.6931506849315 4.72328767123288 0 0 0 0 0 0 0
"2268" 67.0986301369863 68.4602739726027 5.00821917808219 0 0 0 0 0 0 0
"2269" 59.3534246575342 63.3041095890411 5.00821917808219 0 0 0 0 0 0 0
"2270" 62.3068493150685 66.2575342465753 2.80821917808219 0 0 0 0 0 0 0
"2271" 63.6438356164384 65.2383561643836 1.25205479452055 0 0 0 0 0 0 0
"2272" 69.5534246575343 64.0794520547945 4.08493150684932 0 0 0 0 0 0 0
"2273" 61.9452054794521 67.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"2274" 67.2219178082192 68.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"2275" 52.0438356164384 59.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"2276" 64.4767123287671 64.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2277" 54.2493150684932 65.8767123287671 1.91506849315068 0 0 0 0 0 0 0
"2278" 62.7013698630137 65.5452054794521 1.58630136986301 0 0 0 0 0 0 0
"2279" 61.2 65.3205479452055 1.33424657534247 0 0 0 0 0 0 0
"2280" 66.3890410958904 65.8109589041096 3.75068493150685 0 0 0 0 0 0 0
"2281" 62.8630136986301 65.7945205479452 0.531506849315069 0 0 0 0 0 0 0
"2282" 69.3178082191781 65.4520547945205 2.38356164383562 0 0 0 0 0 0 0
"2283" 65.4246575342466 65.2383561643836 5.00821917808219 0 0 0 0 0 0 0
"2284" 81.0821917808219 68.6821917808219 2.58082191780822 0 0 0 0 0 0 0
"2285" 64.972602739726 65.0383561643836 1.08493150684932 0 0 0 0 0 0 0
"2286" 65.8904109589041 65.4356164383562 5.00821917808219 0 0 0 0 0 0 0
"2287" 73.7534246575343 65.0493150684931 1.33150684931507 1 0 0 0 0 0 0
"2288" 64.7945205479452 65.6958904109589 4.75342465753425 0 0 0 0 0 0 0
"2289" 64.9561643835616 65.5013698630137 1.83561643835616 1 0 0 0 0 0 0
"2290" 65.5068493150685 65.4438356164383 3.5041095890411 0 0 0 0 0 0 0
"2291" 71.8054794520548 65.8027397260274 0.838356164383562 0 0 0 0 0 0 0
"2292" 73.3369863013699 65.7397260273973 2.75342465753425 0 0 0 0 0 0 0
"2293" 65.2547945205479 65.0082191780822 2.98082191780822 0 0 0 0 0 0 0
"2294" 48.8246575342466 65.3287671232877 0 0 0 0 0 0 0 0
"2295" 66.6986301369863 65.4301369863014 0.504109589041096 0 0 0 0 0 0 0
"2296" 68.5479452054795 65.8246575342466 3.83835616438356 0 0 0 0 0 0 0
"2297" 66.7890410958904 65.3013698630137 5.00821917808219 0 0 0 0 0 0 0
"2298" 46.8 55.4958904109589 4.41643835616438 1 0 0 0 0 0 0
"2299" 74.9095890410959 64.4164383561644 2.25205479452055 0 0 0 0 0 0 0
"2300" 64.041095890411 65.7561643835616 3.75342465753425 0 0 0 0 0 0 0
"2301" 61.3068493150685 65.1479452054794 0 0 0 0 0 0 0 0
"2302" 64.5205479452055 67.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"2303" 53.9698630136986 55.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"2304" 52.2356164383562 66.0301369863014 0.857534246575342 0 0 0 0 0 0 0
"2305" 50.0931506849315 58.4465753424658 2.92602739726027 0 0 0 0 0 0 0
"2306" 69.3178082191781 56.4958904109589 2.94520547945205 0 0 0 0 0 0 0
"2307" 58.1452054794521 57.4794520547945 2.84383561643836 0 0 0 0 0 0 0
"2308" 62.6575342465753 66.6739726027397 4.0027397260274 1 0 0 0 0 0 0
"2309" 60.6547945205479 65.0739726027397 3.08493150684932 0 0 0 0 0 0 0
"2310" 62.0082191780822 66.427397260274 1.06301369863014 0 0 0 0 0 0 0
"2311" 70.6027397260274 65.7972602739726 3.83835616438356 0 0 0 0 0 0 0
"2312" 70.6767123287671 71.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"2313" 70.0082191780822 70.4712328767123 5.00821917808219 0 0 0 0 0 0 0
"2314" 72.6849315068493 73.1479452054794 3 0 0 0 0 0 0 0
"2315" 73.6849315068493 74.1479452054794 2 0 0 0 0 0 0 0
"2316" 66.2383561643836 72.3369863013699 5.00821917808219 0 0 0 0 0 0 0
"2317" 66.3205479452055 72.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"2318" 68.3287671232877 74.427397260274 3 0 0 0 0 0 0 0
"2319" 69.3287671232877 75.427397260274 2 0 0 0 0 0 0 0
"2320" 52.586301369863 55.6739726027397 5.00821917808219 0 0 0 0 0 0 0
"2321" 55.3479452054795 58.4356164383562 3 0 0 0 0 0 0 0
"2322" 56.3479452054795 59.4356164383562 2 0 0 0 0 0 0 0
"2323" 62.6575342465753 64.9369863013699 2.32602739726027 0 0 0 0 0 0 0
"2324" 60.7917808219178 59.2465753424658 5.00821917808219 0 0 0 0 0 0 0
"2325" 60.2054794520548 58.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"2326" 62.8 61.2547945205479 3 0 0 0 0 0 0 0
"2327" 63.8 62.2547945205479 2 0 0 0 0 0 0 0
"2328" 63.8054794520548 65.9041095890411 0.915068493150685 0 0 0 0 0 0 0
"2329" 59.8109589041096 65.7095890410959 4.75342465753425 0 0 0 0 0 0 0
"2330" 61.8958904109589 67.7945205479452 2 0 0 0 0 0 0 0
"2331" 63.8794520547945 65.4739726027397 0.249315068493151 1 0 0 0 0 0 0
"2332" 53.8328767123288 62.0082191780822 4.72054794520548 0 0 0 0 0 0 0
"2333" 55.8849315068493 64.0602739726027 2 0 0 0 0 0 0 0
"2334" 56.3753424657534 65.3506849315068 1.41917808219178 0 0 0 0 0 0 0
"2335" 60.5945205479452 65.0986301369863 0 0 0 0 0 0 0 0
"2336" 67.0219178082192 64.2767123287671 4.73972602739726 0 0 0 0 0 0 0
"2337" 69.0931506849315 66.3479452054794 2 0 0 0 0 0 0 0
"2338" 57.0630136986301 65.1972602739726 1.12054794520548 0 0 0 0 0 0 0
"2339" 58.4712328767123 65.7780821917808 1.83835616438356 0 0 0 0 0 0 0
"2340" 50.4520547945205 63.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"2341" 50.4520547945205 63.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"2342" 52.4602739726027 65.1698630136986 3 0 0 0 0 0 0 0
"2343" 53.4602739726027 66.1698630136986 2 0 0 0 0 0 0 0
"2344" 62.1095890410959 65.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"2345" 66.7808219178082 72.613698630137 5.00821917808219 0 0 0 0 0 0 0
"2346" 66.7808219178082 72.613698630137 5.00821917808219 0 0 0 0 0 0 0
"2347" 68.7890410958904 74.6219178082192 3 0 0 0 0 0 0 0
"2348" 69.7890410958904 75.6219178082192 2 0 0 0 0 0 0 0
"2349" 62.5808219178082 70.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"2350" 62.5808219178082 70.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"2351" 64.5890410958904 72.7397260273973 3 0 0 0 0 0 0 0
"2352" 65.5890410958904 73.7397260273973 2 0 0 0 0 0 0 0
"2353" 62.6794520547945 62.5424657534247 0.0821917808219178 1 0 0 0 0 0 0
"2354" 57.7123287671233 65.0301369863014 2.08493150684932 0 0 0 0 0 0 0
"2355" 68.8383561643836 65.6904109589041 3.75342465753425 0 0 0 0 0 0 0
"2356" 71.1041095890411 71.6328767123288 0 0 0 0 0 1 0 1.5013698630137
"2357" 71.1041095890411 71.6328767123288 0 0 0 0 0 1 0 1.5013698630137
"2358" 62.6630136986301 62.7260273972603 2.91780821917808 1 0 0 0 0 0 0
"2359" 64.0794520547945 64.1424657534247 0.164383561643836 1 0 0 0 0 0 0
"2360" 56.7150684931507 55.7205479452055 5.00821917808219 0 0 0 0 0 0 0
"2361" 64.2356164383562 68.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"2362" 64.9890410958904 69.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"2363" 67.9972602739726 72.2 2 0 0 0 0 0 0 0
"2364" 66.9972602739726 71.2 3 0 0 0 0 0 0 0
"2365" 66.654794520548 65.3232876712329 1.91506849315068 0 0 0 0 0 0 0
"2366" 65.8684931506849 63.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"2367" 65.8684931506849 63.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"2368" 67.8767123287671 65.5753424657534 3 0 0 0 0 0 0 0
"2369" 68.8767123287671 66.5753424657534 2 0 0 0 0 0 0 0
"2370" 64.2849315068493 61.3972602739726 4.04657534246575 0 0 0 0 0 0 0
"2371" 66.3315068493151 63.4438356164384 2 0 0 0 0 0 0 0
"2372" 73.7178082191781 71.5534246575343 5.00821917808219 0 0 0 0 0 0 0
"2373" 73.5561643835617 71.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"2374" 76.3945205479452 74.2301369863014 3 0 0 0 0 0 0 0
"2375" 77.3945205479452 75.2301369863014 2 0 0 0 0 0 0 0
"2376" 54.3123287671233 59.0547945205479 2.54246575342466 0 0 0 0 0 0 0
"2377" 54.3123287671233 59.0547945205479 2.54246575342466 0 0 0 0 0 0 0
"2378" 60.5013698630137 59.9890410958904 1.17808219178082 0 0 0 0 0 0 0
"2379" 67.9698630136986 68.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"2380" 59.0328767123288 60.827397260274 5.00821917808219 0 0 0 0 0 0 0
"2381" 61.2739726027397 65.6383561643836 4.24657534246575 0 0 0 0 0 0 0
"2382" 62.1424657534247 66.5068493150685 3.71232876712329 0 0 0 0 0 0 0
"2383" 62.2684931506849 66.6328767123288 3.41917808219178 0 0 0 0 0 0 0
"2384" 60.2958904109589 64.8356164383562 0.750684931506849 1 0 0 0 0 0 0
"2385" 67.0438356164384 66.5205479452055 3.91780821917808 0 0 0 0 0 0 0
"2386" 67.8767123287671 67.3534246575342 3.41917808219178 0 0 0 0 0 0 0
"2387" 64.8027397260274 65.4301369863014 3.36712328767123 0 0 0 0 0 0 0
"2388" 58.7698630136986 62.8109589041096 0.986301369863014 0 0 0 0 0 0 0
"2389" 54.4301369863014 65.3068493150685 1.6958904109589 0 0 0 0 0 0 0
"2390" 56.9534246575342 66.1753424657534 5.00821917808219 0 0 0 0 0 0 0
"2391" 59.2109589041096 68.4328767123288 3.41917808219178 0 0 0 0 0 0 0
"2392" 61.0739726027397 66.0054794520548 0.597260273972603 0 0 0 0 0 0 0
"2393" 56.9397260273973 64.9041095890411 0.753424657534247 0 0 0 0 0 0 0
"2394" 61.5260273972603 64.8301369863014 2.08493150684932 0 0 0 0 0 0 0
"2395" 72.041095890411 80.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"2396" 66.5260273972603 65.0794520547945 1.33150684931507 0 0 0 0 0 0 0
"2397" 77.5342465753425 76.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"2398" 66.5369863013699 71.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"2399" 67.7452054794521 71.0657534246575 1.58356164383562 1 0 0 0 0 0 0
"2400" 77.9013698630137 65.5315068493151 0.2 0 0 0 0 0 0 0
"2401" 67.7452054794521 68.5616438356164 5.00821917808219 0 0 0 0 0 0 0
"2402" 69.5150684931507 70.8794520547945 4.91780821917808 1 0 0 0 0 0 0
"2403" 67.5561643835617 66.1479452054794 5.00821917808219 0 0 0 0 0 0 0
"2404" 65.3260273972603 69.5123287671233 4.33150684931507 1 0 0 0 0 0 0
"2405" 69.9945205479452 71.4602739726027 5.00821917808219 0 0 0 0 0 0 0
"2406" 73.6602739726027 72.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"2407" 79.9945205479452 80.9616438356164 0.0876712328767123 1 0 0 0 0 0 0
"2408" 67.3260273972603 67.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"2409" 72.3260273972603 73.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"2410" 75.9945205479452 75.558904109589 5.00821917808219 0 0 0 0 0 0 0
"2411" 67.9945205479452 71.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"2412" 64.9945205479452 63.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"2413" 74.9945205479452 76.613698630137 5.00821917808219 0 0 0 0 0 0 0
"2414" 48.9945205479452 74.0164383561644 4.83561643835616 1 0 0 0 0 0 0
"2415" 67.9945205479452 69.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"2416" 66.9945205479452 68.6849315068493 3.08767123287671 0 1 0 0 0 0 0
"2417" 65.9945205479452 66.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2418" 64.9945205479452 66.4520547945205 5.00821917808219 0 0 0 0 0 0 0
"2419" 61.1041095890411 69.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"2420" 57.9945205479452 59.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"2421" 71.9945205479452 76.358904109589 5.00821917808219 0 0 0 0 0 0 0
"2422" 64.2109589041096 68.8931506849315 5.00821917808219 0 0 0 0 0 0 0
"2423" 63.9945205479452 67.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"2424" 66.2602739726027 62.241095890411 5.00821917808219 0 0 0 0 0 0 0
"2425" 67.4109589041096 68.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"2426" 58.7013698630137 62.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"2427" 66.3479452054794 68.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"2428" 60.2219178082192 68.9013698630137 5.00821917808219 0 0 0 0 0 0 0
"2429" 58.5561643835616 62.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"2430" 58.2958904109589 57.7643835616438 5.00821917808219 0 0 0 0 0 0 0
"2431" 56.6438356164384 66.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"2432" 65.5315068493151 66.3260273972603 5.00821917808219 0 0 0 0 0 0 0
"2433" 69.3013698630137 66.3917808219178 1.66849315068493 1 0 0 0 0 0 0
"2434" 60.5232876712329 63.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"2435" 59.8109589041096 60.7095890410959 5.00821917808219 0 0 0 0 0 0 0
"2436" 64.4356164383562 68.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"2437" 57.641095890411 62.8219178082192 5.00821917808219 0 0 0 0 0 0 0
"2438" 67.9698630136986 64.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"2439" 64.841095890411 66.772602739726 5.00821917808219 0 0 0 0 0 0 0
"2440" 63.4109589041096 64.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"2441" 67.3753424657534 65.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"2442" 59.7095890410959 61.827397260274 5.00821917808219 0 0 0 0 0 0 0
"2443" 60.0164383561644 59.772602739726 5.00821917808219 0 0 0 0 0 0 0
"2444" 66.3178082191781 62.4849315068493 5.00821917808219 0 0 0 0 0 0 0
"2445" 67.4191780821918 62.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"2446" 61.2958904109589 60.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"2447" 60.2383561643836 60.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"2448" 62.172602739726 59.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"2449" 64.0328767123288 63.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"2450" 72.4602739726027 67.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"2451" 63.7342465753425 68.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"2452" 59.3479452054795 63.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"2453" 67.3671232876712 68.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"2454" 66.1890410958904 64.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"2455" 69.5534246575343 70.1972602739726 3.08767123287671 0 1 0 0 0 0 0
"2456" 64.9315068493151 67.5013698630137 5.00821917808219 0 0 0 0 0 0 0
"2457" 60.7671232876712 64.1479452054794 5.00821917808219 0 0 0 0 0 0 0
"2458" 51.0684931506849 56.2054794520548 4.90958904109589 0 0 0 0 0 0 0
"2459" 66.9205479452055 68.4986301369863 5.00821917808219 0 0 0 0 0 0 0
"2460" 60.8684931506849 64.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"2461" 66.2109589041096 66.9506849315069 5.00821917808219 0 0 0 0 0 0 0
"2462" 67.6219178082192 67.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"2463" 63.1506849315069 61.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"2464" 61.0794520547945 63.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"2465" 69.4739726027397 66.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"2466" 67.9342465753425 65.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"2467" 58.8684931506849 62.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"2468" 63.441095890411 63.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"2469" 60.1917808219178 60.9095890410959 4.70684931506849 0 0 0 0 0 0 0
"2470" 63.3643835616438 69.441095890411 5.00821917808219 0 0 0 0 0 0 0
"2471" 46.9808219178082 64.2958904109589 5.00821917808219 0 0 0 0 0 0 0
"2472" 60.1698630136986 60.4493150684931 1.75068493150685 0 0 0 0 0 0 0
"2473" 51.1890410958904 53.3041095890411 3.7041095890411 0 0 0 0 0 0 0
"2474" 55.8191780821918 62.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"2475" 59.213698630137 62.0712328767123 3.08767123287671 0 0 0 0 0 0 0
"2476" 58.0821917808219 59.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"2477" 62.6739726027397 64.3178082191781 3.89315068493151 0 0 0 0 0 0 0
"2478" 60.9342465753425 61.0821917808219 1.17808219178082 0 0 0 0 0 0 0
"2479" 60.0356164383562 61.4301369863014 2.76712328767123 0 0 0 0 0 0 0
"2480" 56.9917808219178 59.2602739726027 2.1972602739726 0 0 0 0 0 0 0
"2481" 59.6602739726027 60.2712328767123 3.9013698630137 0 0 0 0 0 0 0
"2482" 58.3232876712329 57.958904109589 2.40547945205479 0 0 0 0 0 0 0
"2483" 59.1013698630137 62.0904109589041 5.00821917808219 0 0 0 0 0 0 0
"2484" 64.6712328767123 64.613698630137 3.6 0 0 0 0 0 0 0
"2485" 52.9780821917808 53.0520547945206 2.3041095890411 0 0 0 0 0 0 0
"2486" 60.0493150684932 57.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"2487" 38.0328767123288 67.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"2488" 67.5123287671233 67.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"2489" 69.7397260273973 75.3013698630137 0 0 0 0 1 0 2.75068493150685 0
"2490" 63.7397260273973 68.9643835616438 5.00821917808219 0 0 0 0 0 0 0
"2491" 66.7616438356164 69.0821917808219 5.00821917808219 0 0 0 0 0 0 0
"2492" 69.6821917808219 75.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"2493" 67.0739726027397 69.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"2494" 68.6109589041096 68.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"2495" 55.9808219178082 65.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"2496" 72.1835616438356 70.8849315068493 5.00821917808219 0 0 0 0 0 0 0
"2497" 63.8164383561644 68.641095890411 5.00821917808219 0 0 0 0 0 0 0
"2498" 59.8931506849315 58.1890410958904 5.00821917808219 0 0 0 0 0 0 0
"2499" 59.6931506849315 58.6767123287671 5.00821917808219 0 0 0 0 0 0 0
"2500" 52.6794520547945 60.613698630137 5.00821917808219 0 0 0 0 0 0 0
"2501" 61.1205479452055 66.2712328767123 5.00821917808219 0 0 0 0 0 0 0
"2502" 61.9260273972603 70.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"2503" 69.1452054794521 73.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"2504" 65.5616438356164 68.0164383561644 5.00821917808219 0 0 0 0 0 0 0
"2505" 64.8 67.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"2506" 61.386301369863 61.1835616438356 5.00821917808219 0 0 0 0 0 0 0
"2507" 55.2575342465753 57.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"2508" 60.8219178082192 69.441095890411 5.00821917808219 0 0 0 0 0 0 0
"2509" 69.2986301369863 70.027397260274 5.00821917808219 0 0 0 0 0 0 0
"2510" 62.6164383561644 60.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"2511" 68.4054794520548 73.654794520548 1.75068493150685 1 0 0 0 0 0 0
"2512" 68.5260273972603 67.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"2513" 65.4191780821918 68.027397260274 5.00821917808219 0 0 0 0 0 0 0
"2514" 68.0027397260274 69.3260273972603 5.00821917808219 0 0 0 0 0 0 0
"2515" 66.9123287671233 68.413698630137 5.00821917808219 0 0 0 0 0 0 0
"2516" 63.1287671232877 64.8191780821918 5.00821917808219 0 0 0 0 0 0 0
"2517" 60.3945205479452 61.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"2518" 79.2 60.7780821917808 2.9972602739726 0 0 0 0 0 0 0
"2519" 63.1123287671233 65.6164383561644 4.67123287671233 0 0 0 0 0 0 0
"2520" 72.4684931506849 68.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"2521" 65.6712328767123 65.7808219178082 4.83835616438356 0 0 0 0 0 0 0
"2522" 65.6602739726027 60.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"2523" 52.0821917808219 58.0684931506849 5.00821917808219 0 0 0 0 0 0 0
"2524" 64.654794520548 61.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"2525" 63.8054794520548 65.6246575342466 4.67123287671233 0 0 0 0 0 0 0
"2526" 61.9506849315068 65.1479452054794 5.00821917808219 0 0 0 0 0 0 0
"2527" 56.4246575342466 66.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2528" 65.5205479452055 62.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2529" 53.3232876712329 65.6109589041096 4.67123287671233 0 0 0 0 0 0 0
"2530" 66.372602739726 67.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"2531" 61.8219178082192 66.6630136986301 5.00821917808219 0 0 0 0 0 0 0
"2532" 59.5890410958904 63.186301369863 4.72876712328767 0 0 0 0 0 0 0
"2533" 55.4246575342466 62.6575342465753 1.87945205479452 0 0 0 0 0 0 0
"2534" 62.3260273972603 64.5315068493151 2.92328767123288 0 0 0 0 0 0 0
"2535" 64.5315068493151 62.3260273972603 2.92328767123288 0 0 0 0 0 0 0
"2536" 64.4246575342466 64.1068493150685 4.87945205479452 0 0 0 0 0 0 0
"2537" 67.0191780821918 64.841095890411 1.33698630136986 0 0 0 0 0 0 0
"2538" 65.4986301369863 63.4958904109589 5.00821917808219 0 0 0 0 0 0 0
"2539" 64.3780821917808 64.5917808219178 3.07945205479452 0 0 0 0 0 0 0
"2540" 64.0301369863014 62.0712328767123 1.5041095890411 0 0 0 0 0 0 0
"2541" 66.3972602739726 62.5945205479452 4.74794520547945 0 0 0 0 0 0 0
"2542" 62.7123287671233 65.1232876712329 2.9972602739726 0 0 0 0 0 0 0
"2543" 58.5616438356164 61.4 1.08767123287671 1 0 0 0 0 0 0
"2544" 59.1013698630137 62.0904109589041 5.00821917808219 0 0 0 0 0 0 0
"2545" 56.4712328767123 59.827397260274 0.750684931506849 1 0 0 0 0 0 0
"2546" 59.0904109589041 64.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"2547" 49.7671232876712 57.413698630137 3.9013698630137 0 0 0 0 0 0 0
"2548" 58.2849315068493 60.6849315068493 3.51506849315069 0 0 0 0 0 0 0
"2549" 60.7917808219178 60.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"2550" 48.641095890411 63.7452054794521 2.18082191780822 0 0 0 0 0 0 0
"2551" 62.386301369863 64.3342465753425 4.22739726027397 0 0 0 0 0 0 0
"2552" 64.6712328767123 64.613698630137 3.51506849315069 0 0 0 0 0 0 0
"2553" 56.3561643835616 65.627397260274 2.51506849315069 0 0 0 0 0 0 0
"2554" 55.4027397260274 59.413698630137 4.23835616438356 0 0 0 0 0 0 0
"2555" 47.213698630137 58.5150684931507 4.23835616438356 0 0 0 0 0 0 0
"2556" 62.7808219178082 62.172602739726 2.92602739726027 1 0 0 0 0 0 0
"2557" 53.3123287671233 53.386301369863 2.3041095890411 0 0 0 0 0 0 0
"2558" 57.0246575342466 63.7452054794521 3.68219178082192 0 0 0 0 0 0 0
"2559" 53.3534246575342 60.0794520547945 2.3041095890411 0 0 0 0 0 0 0
"2560" 57.758904109589 55.3808219178082 3.35890410958904 0 0 0 0 0 0 0
"2561" 58.4109589041096 65.6328767123288 2.33972602739726 1 0 0 0 0 0 0
"2562" 59.3287671232877 67.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2563" 65.358904109589 62.6547945205479 2.4986301369863 1 0 0 0 0 0 0
"2564" 60.8876712328767 59.8301369863014 2.3041095890411 0 0 0 0 0 0 0
"2565" 61.2657534246575 63.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"2566" 54.1013698630137 57.2794520547945 4.23835616438356 0 0 0 0 0 0 0
"2567" 57.3643835616438 59.6356164383562 4.72602739726027 0 0 0 0 0 0 0
"2568" 60.1808219178082 62.8767123287671 0 0 0 0 1 0 0.175342465753425 0
"2569" 58.1753424657534 53.0821917808219 0.347945205479452 0 0 0 0 0 0 0
"2570" 41.6739726027397 55.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"2571" 60.6739726027397 60.9534246575342 1.74794520547945 0 0 0 0 0 0 0
"2572" 50.8767123287671 52.9917808219178 3.68219178082192 0 0 0 0 0 0 0
"2573" 63.8356164383562 66.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"2574" 60.441095890411 73.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"2575" 64.0739726027397 69.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"2576" 54.0904109589041 57.213698630137 5.00821917808219 0 0 0 0 0 0 0
"2577" 69.1452054794521 73.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"2578" 68.2520547945205 69.5095890410959 2.16438356164384 1 0 0 0 0 0 0
"2579" 68.6438356164384 67.7178082191781 5.00821917808219 0 0 0 0 0 0 0
"2580" 58.6767123287671 66.0520547945205 5.00821917808219 0 0 0 0 0 0 0
"2581" 64.572602739726 68.2109589041096 4.83561643835616 1 0 0 0 0 0 0
"2582" 63.7424657534247 70.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"2583" 78.8383561643836 86.4767123287671 5.00821917808219 0 0 0 0 0 0 0
"2584" 63.2520547945205 62.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"2585" 65.5616438356164 68.0164383561644 5.00821917808219 0 0 0 0 0 0 0
"2586" 64.2739726027397 64.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"2587" 66.3534246575342 72.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"2588" 60.6164383561644 58.1698630136986 3.66849315068493 1 0 0 0 0 0 0
"2589" 68.5808219178082 66.8 5.00821917808219 0 0 0 0 0 0 0
"2590" 62.386301369863 74.3479452054794 5.00821917808219 0 0 0 0 0 0 0
"2591" 63.7671232876712 63.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"2592" 59.6191780821918 69.1780821917808 2.16438356164384 1 0 0 0 0 0 0
"2593" 76.8191780821918 76.9013698630137 5.00821917808219 0 0 0 0 0 0 0
"2594" 60.3753424657534 64.0986301369863 5.00821917808219 0 0 0 0 0 0 0
"2595" 65.613698630137 65.4986301369863 5.00821917808219 0 0 0 0 0 0 0
"2596" 72.2684931506849 71.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"2597" 69.4712328767123 80.3917808219178 4.83561643835616 1 0 0 0 0 0 0
"2598" 64.8821917808219 67.6630136986301 5.00821917808219 0 0 0 0 0 0 0
"2599" 70.7369863013699 74.372602739726 5.00821917808219 0 0 0 0 0 0 0
"2600" 61.2082191780822 63.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"2601" 65.8438356164384 61.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"2602" 50.7780821917808 59.8904109589041 5.00821917808219 0 0 0 0 0 0 0
"2603" 70.8 65.6931506849315 5.00821917808219 0 0 0 0 0 0 0
"2604" 46.4821917808219 59.4630136986301 5.00821917808219 0 0 0 0 0 0 0
"2605" 57.3917808219178 63.3369863013699 5.00821917808219 0 0 0 0 0 0 0
"2606" 65.6328767123288 76.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"2607" 58.5452054794521 61.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"2608" 61.2191780821918 61.0164383561644 5.00821917808219 0 0 0 0 0 0 0
"2609" 65.5178082191781 66.0794520547945 5.00821917808219 0 0 0 0 0 0 0
"2610" 73.9917808219178 72.3561643835616 4.08767123287671 1 0 0 0 0 0 0
"2611" 63.0602739726027 69.7972602739726 5.00821917808219 0 0 0 0 0 0 0
"2612" 78.7178082191781 81.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"2613" 63.9780821917808 67.6 5.00821917808219 0 0 0 0 0 0 0
"2614" 74.2986301369863 72.8 5.00821917808219 0 0 0 0 0 0 0
"2615" 56.0876712328767 58.2054794520548 5.00821917808219 0 0 0 0 0 0 0
"2616" 65.9534246575342 72.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"2617" 62.0958904109589 62.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"2618" 72.7643835616438 68.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"2619" 69.9424657534247 71.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"2620" 63.186301369863 65.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"2621" 73.041095890411 75.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2622" 75.2904109589041 79.0739726027397 5.00821917808219 0 0 0 0 0 0 0
"2623" 87.3479452054794 83.0219178082192 4.91780821917808 1 0 0 0 0 0 0
"2624" 73.3178082191781 64.6849315068493 1.41643835616438 0 0 1 0 1 0 0.0219178082191781
"2625" 63.6027397260274 66.345205479452 2.66849315068493 1 0 0 0 0 0 0
"2626" 65.6520547945206 64.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"2627" 62.3561643835616 68.2547945205479 5.00821917808219 0 0 0 0 0 0 0
"2628" 60.9616438356164 66.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"2629" 63.6712328767123 61.4465753424658 5.00821917808219 0 0 0 0 0 0 0
"2630" 63.027397260274 66.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"2631" 61.8575342465753 61.8191780821918 5.00821917808219 0 0 0 0 0 0 0
"2632" 64.2054794520548 64.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"2633" 62.1452054794521 65.5150684931507 5.00821917808219 0 0 0 0 0 0 0
"2634" 67.1671232876712 66.986301369863 1.64383561643836 0 0 0 0 0 0 0
"2635" 60.5835616438356 63.7424657534247 2.55890410958904 0 0 0 0 0 0 0
"2636" 73.5753424657534 65.0219178082192 3.08493150684932 0 0 0 0 0 0 0
"2637" 47.7561643835616 65.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"2638" 63.5945205479452 70.158904109589 5.00821917808219 0 0 0 0 0 0 0
"2639" 60.0630136986301 65.041095890411 1 0 0 0 0 0 0 0
"2640" 62.986301369863 65.0493150684931 5 0 0 0 0 0 0 0
"2641" 57.4739726027397 70.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"2642" 57.4739726027397 70.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"2643" 61.3068493150685 65.3205479452055 3.33424657534247 0 0 0 0 0 0 0
"2644" 65.4109589041096 65.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"2645" 81.958904109589 79.0794520547945 0.416438356164384 1 0 0 0 0 0 0
"2646" 81.958904109589 79.0794520547945 0.416438356164384 1 0 0 0 0 0 0
"2647" 62.6054794520548 65.3698630136986 1.41917808219178 0 0 0 0 0 0 0
"2648" 65.9232876712329 69.7479452054795 1.91780821917808 1 0 0 0 0 0 0
"2649" 65.9232876712329 69.7479452054795 1.91780821917808 1 0 0 0 0 0 0
"2650" 61.7917808219178 65.3643835616438 4.41917808219178 0 0 0 0 0 0 0
"2651" 70.4575342465753 83.9945205479452 0 0 0 0 0 1 0 0.66027397260274
"2652" 70.4575342465753 83.9945205479452 0 0 0 0 0 1 0 0.66027397260274
"2653" 60.6465753424658 64.8 5.00821917808219 0 0 0 0 0 0 0
"2654" 54.3232876712329 64.9671232876712 2.25205479452055 0 0 0 0 0 0 0
"2655" 71.7945205479452 65.3671232876712 0.583561643835616 1 0 0 0 0 0 0
"2656" 67.2931506849315 65.5835616438356 3.58630136986301 0 0 0 0 0 0 0
"2657" 62.8821917808219 65.5013698630137 2.25205479452055 1 0 0 0 0 0 0
"2658" 57.0821917808219 62.0438356164384 0.953424657534247 0 0 0 0 0 0 0
"2659" 57.4657534246575 65.7342465753425 2.75342465753425 0 0 0 0 0 0 0
"2660" 78.6082191780822 65.6712328767123 0.671232876712329 0 0 0 0 0 0 0
"2661" 49.3205479452055 61.9123287671233 4.81643835616438 0 0 0 0 0 0 0
"2662" 64.2986301369863 69.7506849315069 1.33150684931507 1 0 0 0 0 0 0
"2663" 64.2986301369863 69.7506849315069 1.33150684931507 1 0 0 0 0 0 0
"2664" 67.1890410958904 65.3095890410959 4.33424657534247 0 0 0 0 0 0 0
"2665" 74.227397260274 84.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2666" 74.227397260274 84.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2667" 76.1945205479452 86.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2668" 76.1945205479452 86.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"2669" 54.0684931506849 65.158904109589 5.00821917808219 0 0 0 0 0 0 0
"2670" 55.8630136986301 64.3397260273973 2.08493150684932 0 0 0 0 0 0 0
"2671" 64.7561643835616 65.1178082191781 4.16712328767123 0 0 0 0 0 0 0
"2672" 60.641095890411 66.041095890411 0.665753424657534 0 0 0 0 0 0 0
"2673" 56.9780821917808 64.8438356164384 3.91506849315068 0 0 0 0 0 0 0
"2674" 49.4958904109589 65.4575342465753 3.5041095890411 0 0 0 0 0 0 0
"2675" 71.3150684931507 78.427397260274 5.00821917808219 0 0 0 0 0 0 0
"2676" 71.3150684931507 78.427397260274 5.00821917808219 0 0 0 0 0 0 0
"2677" 44.2986301369863 65.4219178082192 2.02191780821918 0 0 0 0 0 0 0
"2678" 59.5013698630137 76.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"2679" 65.1150684931507 65.1150684931507 1.16712328767123 0 0 0 0 0 0 0
"2680" 62.358904109589 66.027397260274 0 0 0 0 0 0 0 0
"2681" 64.7972602739726 65 0.6 0 0 0 0 0 0 0
"2682" 75.3671232876712 65.0383561643836 3.08493150684932 0 0 0 0 0 0 0
"2683" 54.4328767123288 65.0493150684931 1 0 0 0 0 0 0 0
"2684" 53.5178082191781 65.4986301369863 0.668493150684932 1 0 0 0 0 0 0
"2685" 71.8356164383562 75.7178082191781 0.249315068493151 1 0 0 0 0 0 0
"2686" 71.8356164383562 75.7178082191781 0.249315068493151 1 0 0 0 0 0 0
"2687" 68.1178082191781 65.0520547945205 4.08493150684932 0 0 0 0 0 0 0
"2688" 65.9369863013699 66.2849315068493 3.41643835616438 0 0 1 0 1 0 0.0821917808219178
"2689" 61.4876712328767 64.5123287671233 0.334246575342466 0 0 0 0 0 0 0
"2690" 60.7232876712329 65.1534246575342 0 0 0 0 0 0 0 0
"2691" 64.2684931506849 65.8328767123288 4.83835616438356 0 0 0 0 0 0 0
"2692" 69.2794520547945 72.027397260274 5.00821917808219 0 0 0 0 0 0 0
"2693" 58.8821917808219 65.1287671232877 0 0 0 0 0 0 0 0
"2694" 71.5150684931507 67.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"2695" 61.1753424657534 62.6630136986301 4.30684931506849 0 0 0 0 0 0 0
"2696" 79.6027397260274 80.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2697" 79.6027397260274 80.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2698" 66.7452054794521 65.5945205479452 4.67123287671233 0 0 0 0 0 0 0
"2699" 62.2602739726027 65.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2700" 67.5315068493151 65.5178082191781 2.58630136986301 0 0 0 0 0 0 0
"2701" 56.0438356164384 65.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"2702" 57.1917808219178 65.8958904109589 0.915068493150685 0 0 0 0 0 0 0
"2703" 51.2739726027397 65.0493150684931 2.57808219178082 0 0 0 0 0 0 0
"2704" 54.5068493150685 65.5369863013699 3.58630136986301 0 0 0 0 0 0 0
"2705" 55.5917808219178 65.1068493150685 4.16712328767123 0 0 0 0 0 0 0
"2706" 59.7369863013699 65.0958904109589 0.671232876712329 0 0 0 0 0 0 0
"2707" 38.2739726027397 65.1671232876712 2.55342465753425 0 0 0 0 0 0 0
"2708" 49.4876712328767 63.1917808219178 0.986301369863014 0 0 0 0 0 0 0
"2709" 68.5506849315069 71.4356164383562 5.00821917808219 0 0 0 0 0 0 0
"2710" 67.7315068493151 65.8219178082192 4.83287671232877 0 0 0 0 0 0 0
"2711" 64.8109589041096 65.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"2712" 64.9780821917808 65.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"2713" 65.0356164383562 65.7698630136986 4.95068493150685 0 0 0 0 0 0 0
"2714" 66.9616438356164 67.6958904109589 3.85479452054795 0 0 0 0 0 0 0
"2715" 71.1342465753425 74.4739726027397 5.00821917808219 0 0 0 0 0 0 0
"2716" 65.7671232876712 65.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"2717" 62.9178082191781 70.4575342465753 5.00821917808219 0 0 0 0 0 0 0
"2718" 62.5835616438356 70.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"2719" 67.3068493150685 68.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"2720" 73.4520547945205 76.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"2721" 73.7424657534247 79.0054794520548 5.00821917808219 0 0 0 0 0 0 0
"2722" 74.6986301369863 77.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"2723" 69.7041095890411 70.9616438356164 5.00821917808219 0 0 0 0 0 0 0
"2724" 61.3123287671233 64.6328767123288 3.16712328767123 0 0 0 0 0 0 0
"2725" 66.2958904109589 78.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"2726" 66.7972602739726 78.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"2727" 63.0712328767123 67.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"2728" 63.0712328767123 67.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"2729" 72.158904109589 76.413698630137 3.75068493150685 0 0 1 0 1 0 0.0219178082191781
"2730" 72.158904109589 76.413698630137 3.75068493150685 0 0 1 0 1 0 0.0219178082191781
"2731" 71.0849315068493 70.3342465753425 3.4986301369863 1 0 0 0 0 0 0
"2732" 66.0301369863014 70.3780821917808 5.00821917808219 0 0 0 0 0 0 0
"2733" 58.4849315068493 65.3150684931507 4.77808219178082 0 0 0 0 0 0 0
"2734" 63.3424657534247 73.9616438356164 5.00821917808219 0 0 0 0 0 0 0
"2735" 60.6575342465753 76.8712328767123 5.00821917808219 0 0 0 0 0 0 0
"2736" 73.6328767123288 78.4219178082192 4.66849315068493 1 0 0 0 0 0 0
"2737" 73.6328767123288 78.4219178082192 4.66849315068493 1 0 0 0 0 0 0
"2738" 73.3315068493151 77.9424657534247 0.164383561643836 1 0 0 0 0 0 0
"2739" 73.3315068493151 77.9424657534247 0.164383561643836 1 0 0 0 0 0 0
"2740" 56.8438356164384 59.027397260274 0.712328767123288 1 0 0 0 0 0 0
"2741" 61.0904109589041 68.9506849315069 5.00821917808219 0 0 0 0 0 0 0
"2742" 59.9178082191781 65.4 1.41917808219178 0 0 0 0 0 0 0
"2743" 63.213698630137 64.9342465753425 2.25205479452055 0 0 0 0 0 0 0
"2744" 60.3835616438356 65.013698630137 5.00821917808219 0 0 0 0 0 0 0
"2745" 68.3753424657534 67.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"2746" 74.027397260274 78.6465753424658 1.4986301369863 1 0 0 0 0 0 0
"2747" 74.2767123287671 78.8958904109589 1.4986301369863 1 0 0 0 0 0 0
"2748" 56.7506849315068 65.0575342465753 2.33424657534247 0 0 0 0 0 0 0
"2749" 69.3369863013699 77.8986301369863 0.917808219178082 1 0 0 0 0 0 0
"2750" 69.4191780821918 77.9808219178082 0.917808219178082 1 0 0 0 0 0 0
"2751" 63.7205479452055 65.5260273972603 5.00821917808219 0 0 0 0 0 0 0
"2752" 71.3287671232877 69.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"2753" 73.5890410958904 70.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"2754" 60.0767123287671 64.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"2755" 65.0876712328767 70.786301369863 5.00821917808219 0 0 0 0 0 0 0
"2756" 65.0109589041096 70.7095890410959 5.00821917808219 0 0 0 0 0 0 0
"2757" 65.6328767123288 72.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"2758" 66.4849315068493 65.2465753424657 0.180821917808219 0 0 0 0 0 0 0
"2759" 64.4794520547945 77.3424657534247 5.00821917808219 0 0 0 0 0 0 0
"2760" 63.8931506849315 76.7561643835616 5.00821917808219 0 0 0 0 0 0 0
"2761" 63.7260273972603 65.0849315068493 4.0027397260274 1 0 0 0 0 0 0
"2762" 60.5616438356164 68.586301369863 2.4986301369863 1 0 0 0 0 0 0
"2763" 69.641095890411 65.9698630136986 1.80821917808219 0 0 0 0 0 0 0
"2764" 66.4383561643836 70.3780821917808 3.83561643835616 1 0 0 0 0 0 0
"2765" 68.8465753424658 72.7561643835616 5.00821917808219 0 0 0 0 0 0 0
"2766" 74.8821917808219 72.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"2767" 77.7479452054795 76.7068493150685 3.75068493150685 1 0 0 0 0 0 0
"2768" 74.4739726027397 73.172602739726 5.00821917808219 0 0 0 0 0 0 0
"2769" 67 69.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"2770" 72.7397260273973 73.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"2771" 72.6575342465753 73.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"2772" 63.1232876712329 64.7013698630137 0.419178082191781 0 0 0 0 0 0 0
"2773" 70.986301369863 73.0082191780822 5.00821917808219 0 0 0 0 0 0 0
"2774" 72.8739726027397 75.1835616438356 5.00821917808219 0 0 0 0 0 0 0
"2775" 69.8383561643836 74.8876712328767 3.08767123287671 0 0 0 1 0 0.0575342465753425 0
"2776" 67.6054794520548 74.586301369863 5.00821917808219 0 0 0 0 0 0 0
"2777" 67.9150684931507 76.3178082191781 5.00821917808219 0 0 0 0 0 0 0
"2778" 56.0109589041096 64.8958904109589 2.76712328767123 0 0 0 0 0 0 0
"2779" 69.7972602739726 76.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"2780" 67.0328767123288 70.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"2781" 74.4630136986301 75.8109589041096 5.00821917808219 0 0 0 0 0 0 0
"2782" 64.5178082191781 70.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"2783" 61.2109589041096 70.7041095890411 5.00821917808219 0 0 0 0 0 0 0
"2784" 77.2054794520548 72.8109589041096 0.164383561643836 1 0 0 0 0 0 0
"2785" 64.9260273972603 68.6328767123288 5.00821917808219 0 0 0 0 0 0 0
"2786" 70.5068493150685 72.2712328767123 1.58356164383562 1 0 0 0 0 0 0
"2787" 68.9561643835616 72.3068493150685 3.0027397260274 1 0 0 0 0 0 0
"2788" 67.2164383561644 70.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"2789" 61.8876712328767 70.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"2790" 67.1205479452055 72.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"2791" 70.2849315068493 74.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"2792" 69.4630136986301 73.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"2793" 70.413698630137 73.4630136986301 3.58356164383562 0 0 0 1 0 0.668493150684932 0
"2794" 75.358904109589 77.0547945205479 5.00821917808219 0 0 0 0 0 0 0
"2795" 71.9150684931507 74.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"2796" 71.9534246575342 76.0575342465753 4.75068493150685 1 0 0 0 0 0 0
"2797" 60.5397260273973 64.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"2798" 69.2082191780822 72.7013698630137 5.00821917808219 0 0 0 0 0 0 0
"2799" 66.1698630136986 75.186301369863 5.00821917808219 0 0 0 0 0 0 0
"2800" 69.7917808219178 77.4602739726027 4.16438356164384 1 0 0 0 0 0 0
"2801" 65.4575342465753 73.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"2802" 62.8301369863014 67.7095890410959 5.00821917808219 0 0 0 0 0 0 0
"2803" 63.8657534246575 71.158904109589 5.00821917808219 0 0 0 0 0 0 0
"2804" 62.2821917808219 73.8739726027397 5.00821917808219 0 0 0 0 0 0 0
"2805" 66.4602739726027 70.0849315068493 5.00821917808219 0 0 0 0 0 0 0
"2806" 67.5643835616438 74.2931506849315 2.33150684931507 1 0 0 0 0 0 0
"2807" 69.3753424657534 72.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"2808" 71.1561643835616 71.4958904109589 0.416438356164384 1 0 0 0 0 0 0
"2809" 68.0986301369863 71.4383561643836 1.0027397260274 1 0 0 0 0 0 0
"2810" 73.1890410958904 71.1890410958904 5.00821917808219 0 0 0 0 0 0 0
"2811" 66.027397260274 72.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"2812" 62.9643835616438 67.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"2813" 66.5780821917808 69.4082191780822 5.00821917808219 0 0 0 0 0 0 0
"2814" 61.2219178082192 70.5095890410959 2.33150684931507 1 0 0 0 0 0 0
"2815" 66.9315068493151 73.386301369863 5.00821917808219 0 0 0 0 0 0 0
"2816" 66.9315068493151 73.386301369863 5.00821917808219 0 0 0 0 0 0 0
"2817" 70.972602739726 73.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"2818" 64.4054794520548 72.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"2819" 67.0712328767123 67.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"2820" 74.9753424657534 74.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"2821" 72.7890410958904 74.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"2822" 73.6821917808219 75.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"2823" 63.0821917808219 69.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"2824" 61.3917808219178 65.2821917808219 0.334246575342466 0 0 0 0 0 0 0
"2825" 72.241095890411 74.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"2826" 63.0356164383562 70.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"2827" 70.8465753424658 71.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"2828" 71.213698630137 77.558904109589 5.00821917808219 0 0 0 0 0 0 0
"2829" 74.8876712328767 74.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"2830" 68.4164383561644 73.2986301369863 3.58356164383562 0 1 0 0 0 0 0
"2831" 68.2958904109589 73.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"2832" 63.8438356164384 66.4520547945205 5.00821917808219 0 0 0 0 0 0 0
"2833" 74.9369863013699 74.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"2834" 57.6630136986301 69.7205479452055 4.66849315068493 1 0 0 0 0 0 0
"2835" 64.7068493150685 75.6849315068493 5.00821917808219 0 0 0 0 0 0 0
"2836" 68.8602739726027 71.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"2837" 68.8602739726027 71.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"2838" 73.6465753424658 73.5342465753425 0.164383561643836 1 0 0 0 0 0 0
"2839" 73.6465753424658 73.5342465753425 0.164383561643836 1 0 0 0 0 0 0
"2840" 57.0767123287671 58.5917808219178 0.0712328767123288 1 0 0 0 0 0 0
"2841" 64.8958904109589 71.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"2842" 64.8958904109589 71.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"2843" 71.372602739726 69.027397260274 5.00821917808219 0 0 0 0 0 0 0
"2844" 71.372602739726 69.027397260274 5.00821917808219 0 0 0 0 0 0 0
"2845" 56.6191780821918 59.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"2846" 56.6191780821918 59.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"2847" 55.6849315068493 55.9123287671233 3.83561643835616 0 0 0 0 0 0 0
"2848" 62.772602739726 71.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"2849" 63.0054794520548 67.4 5.00821917808219 0 0 0 0 0 0 0
"2850" 67.3287671232877 67.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"2851" 65.9506849315069 63.9753424657534 3.83835616438356 0 0 0 0 0 0 0
"2852" 65.5315068493151 69.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"2853" 69.586301369863 69.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"2854" 69.586301369863 69.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"2855" 67.1424657534247 70.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"2856" 67.7671232876712 68.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"2857" 69.2602739726027 69.6958904109589 3.66849315068493 1 0 0 0 0 0 0
"2858" 65.0630136986301 69.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"2859" 64.2931506849315 65.8356164383562 3.83835616438356 0 0 0 0 0 0 0
"2860" 67.7178082191781 68.3397260273973 5.00821917808219 0 0 0 0 0 0 0
"2861" 63.2794520547945 66.9561643835616 5.00821917808219 0 0 0 0 0 0 0
"2862" 66.1643835616438 67.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"2863" 68.1315068493151 64.1506849315068 5.00821917808219 0 0 0 0 0 0 0
"2864" 61.7780821917808 63.7424657534247 3.71232876712329 0 0 0 0 0 0 0
"2865" 53.5616438356164 55.9561643835616 1.7013698630137 0 0 0 0 0 0 0
"2866" 68.2575342465753 64.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"2867" 63.013698630137 64.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"2868" 71.9369863013699 65.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"2869" 74.027397260274 65.3424657534247 5.00821917808219 0 0 0 0 0 0 0
"2870" 67.8849315068493 66.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"2871" 62.6657534246575 63.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"2872" 70.8027397260274 64.6191780821918 5.00821917808219 0 0 0 0 0 0 0
"2873" 57.6164383561644 62.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"2874" 59.9260273972603 60.1424657534247 0.917808219178082 1 0 0 0 0 0 0
"2875" 60.6493150684932 62.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"2876" 50.6931506849315 60.4328767123288 1.96164383561644 0 0 0 0 0 0 0
"2877" 52.4575342465753 56.5342465753425 2.58630136986301 0 0 0 0 0 0 0
"2878" 61.6 63.9342465753425 0.704109589041096 0 0 0 0 0 0 0
"2879" 60.8356164383562 58.1616438356164 1.25205479452055 0 0 0 0 0 0 0
"2880" 64.9945205479452 65.027397260274 2.08493150684932 0 0 0 0 0 0 0
"2881" 61.0109589041096 66.4767123287671 0.493150684931507 0 0 0 0 0 0 0
"2882" 57.772602739726 65.2547945205479 2.24657534246575 0 0 0 0 0 0 0
"2883" 63.1479452054795 65.027397260274 1.08493150684932 0 0 0 0 0 0 0
"2884" 63.3068493150685 63.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"2885" 63.2465753424658 69.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"2886" 64.7424657534247 66.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"2887" 72.9397260273973 73.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"2888" 63.2575342465753 66.4602739726027 5.00821917808219 0 0 0 0 0 0 0
"2889" 54.4602739726027 51.586301369863 4.35616438356164 0 0 0 0 0 0 0
"2890" 66.5424657534247 70.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"2891" 64.4301369863014 63.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"2892" 64.172602739726 60.4027397260274 1.41917808219178 0 0 0 0 0 0 0
"2893" 66.0301369863014 61.586301369863 5.00821917808219 0 0 0 0 0 0 0
"2894" 53.2493150684932 61.7534246575342 3.58630136986301 0 0 0 0 0 0 0
"2895" 55.1041095890411 55.2383561643836 0.972602739726027 0 0 0 0 0 0 0
"2896" 66 64.586301369863 3.58630136986301 0 0 0 0 0 0 0
"2897" 65.9643835616438 69.0493150684931 5 0 0 0 0 0 0 0
"2898" 56.1342465753425 55.9917808219178 3.58630136986301 0 0 0 0 0 0 0
"2899" 68.5287671232877 71.6438356164384 5.00821917808219 0 0 0 0 0 0 0
"2900" 71.0493150684931 73.4164383561644 4.24931506849315 0 0 0 1 0 0.575342465753425 0
"2901" 62.4684931506849 68.5506849315069 5 0 0 0 0 0 0 0
"2902" 59.3835616438356 65.3232876712329 5 0 0 0 0 0 0 0
"2903" 73.8794520547945 73.3835616438356 5 0 0 0 0 0 0 0
"2904" 71.9643835616438 75.3835616438356 5 0 0 0 0 0 0 0
"2905" 69.9643835616438 75.9643835616438 5 0 0 0 0 0 0 0
"2906" 60.8027397260274 69.9643835616438 5 0 0 0 0 0 0 0
"2907" 65.6356164383562 71.6356164383562 5 0 0 0 0 0 0 0
"2908" 59.3835616438356 67.2986301369863 5 0 0 0 0 0 0 0
"2909" 57.2164383561644 63.2164383561644 5 0 0 0 0 0 0 0
"2910" 60.8027397260274 71.2164383561644 5 0 0 0 0 0 0 0
"2911" 68.7178082191781 60.1315068493151 5 0 0 0 0 0 0 0
"2912" 71.2986301369863 65.5260273972603 5 0 0 0 0 0 0 0
"2913" 68.3315068493151 66.3424657534247 5.00821917808219 0 0 0 0 0 0 0
"2914" 63.9315068493151 71.2 5.00821917808219 0 0 0 0 0 0 0
"2915" 65.2986301369863 59.8027397260274 5 0 0 0 0 0 0 0
"2916" 62.8027397260274 65.8246575342466 5 0 0 0 0 0 0 0
"2917" 76.2712328767123 71.3123287671233 5.00821917808219 0 0 0 0 0 0 0
"2918" 22.7095890410959 55.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"2919" 68.3178082191781 73.4164383561644 0.668493150684932 1 0 0 0 0 0 0
"2920" 52.1890410958904 55.5945205479452 4.67123287671233 0 0 0 0 0 0 0
"2921" 65.9013698630137 75.2 5.00821917808219 0 0 0 0 0 0 0
"2922" 69.7452054794521 68.8356164383562 3.33150684931507 0 1 0 0 0 0 0
"2923" 67.3945205479452 59.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"2924" 73.8246575342466 69.4547945205479 5.00821917808219 0 0 0 0 0 0 0
"2925" 67.8027397260274 66.5506849315069 5 0 0 0 0 0 0 0
"2926" 57.2986301369863 58.2986301369863 5 0 0 0 0 0 0 0
"2927" 60.0493150684932 59.7178082191781 5 0 0 0 0 0 0 0
"2928" 61.1287671232877 64.0794520547945 0.846575342465753 0 0 0 0 0 0 0
"2929" 53.041095890411 66.2684931506849 4.8986301369863 0 0 0 0 0 0 0
"2930" 56.8219178082192 60.7260273972603 0.219178082191781 0 0 0 0 0 0 0
"2931" 65.1041095890411 65.3068493150685 3.3041095890411 0 0 0 0 0 0 0
"2932" 56.8027397260274 65.0328767123288 1.05753424657534 0 0 0 0 0 0 0
"2933" 65.3013698630137 63.5698630136986 1.30684931506849 0 0 0 0 0 0 0
"2934" 66.3123287671233 60.9835616438356 1.44109589041096 0 0 0 0 0 0 0
"2935" 59.4219178082192 65.4657534246575 4.24109589041096 0 0 0 0 0 0 0
"2936" 64.1342465753425 63.2164383561644 0.501369863013699 1 0 0 0 0 0 0
"2937" 65.8739726027397 65.0547945205479 4.07123287671233 0 0 0 0 0 0 0
"2938" 64.5369863013699 65.3150684931507 2.28493150684932 0 0 0 0 0 0 0
"2939" 64.9123287671233 65.5945205479452 0.53972602739726 0 0 0 0 0 0 0
"2940" 66.9698630136986 65.3150684931507 5 0 0 0 0 0 0 0
"2941" 53.5095890410959 65.827397260274 0.473972602739726 0 0 0 0 0 0 0
"2942" 56.841095890411 57.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"2943" 59.4465753424658 65.358904109589 4.41917808219178 0 0 0 0 0 0 0
"2944" 62.7835616438356 65.427397260274 3.38356164383562 0 0 0 0 0 0 0
"2945" 59.1150684931507 65.9260273972603 0.772602739726027 0 0 0 0 0 0 0
"2946" 62.8465753424658 68.3506849315068 4.8027397260274 0 0 0 0 0 0 0
"2947" 55.1424657534247 66.6493150684932 4.84383561643836 0 0 0 0 0 0 0
"2948" 64.2958904109589 65.1808219178082 3.14520547945205 0 0 0 0 0 0 0
"2949" 60.5315068493151 65.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"2950" 54.5369863013699 65.0082191780822 2.58356164383562 1 0 0 0 0 0 0
"2951" 57.8684931506849 65.3178082191781 4.92054794520548 0 0 0 0 0 0 0
"2952" 49.7205479452055 65.8219178082192 3.66301369863014 0 0 0 0 0 0 0
"2953" 67.4191780821918 66.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"2954" 60.3561643835616 57.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"2955" 59.7260273972603 67.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"2956" 49.9561643835616 56.6630136986301 5.00821917808219 0 0 0 0 0 0 0
"2957" 72.3506849315068 65.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"2958" 65 65.9369863013699 1.0027397260274 1 0 0 0 0 0 0
"2959" 58.6 63.572602739726 5.00821917808219 0 0 0 0 0 0 0
"2960" 73.5917808219178 65.8821917808219 2.75616438356164 0 0 0 0 0 0 0
"2961" 68.1452054794521 62.572602739726 5.00821917808219 0 0 0 0 0 0 0
"2962" 64.2575342465753 66.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"2963" 63.6383561643836 65.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"2964" 52.5561643835616 55.827397260274 1.67397260273973 0 0 0 0 0 0 0
"2965" 69.3369863013699 62.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"2966" 66.6164383561644 63.1561643835616 4.41643835616438 1 0 0 0 0 0 0
"2967" 60.6876712328767 65.186301369863 4.50684931506849 0 0 0 0 0 0 0
"2968" 62.3178082191781 59.8630136986301 3.00547945205479 0 0 0 0 0 0 0
"2969" 60.6164383561644 58.9671232876712 0.693150684931507 0 0 0 0 0 0 0
"2970" 62.2219178082192 65.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"2971" 62.5068493150685 63.8849315068493 5.00821917808219 0 0 0 0 0 0 0
"2972" 59.5178082191781 54.5698630136986 2.08767123287671 0 1 0 0 0 0 0
"2973" 65.627397260274 67.0082191780822 5.00821917808219 0 0 0 0 0 0 0
"2974" 56.4054794520548 57.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"2975" 64.4246575342466 66.6657534246575 5.00821917808219 0 0 0 0 0 0 0
"2976" 59.5835616438356 63.5753424657534 5.00821917808219 0 0 0 0 0 0 0
"2977" 59.9260273972603 60.1205479452055 2.42191780821918 0 0 0 0 0 0 0
"2978" 54.4191780821918 56.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"2979" 41.3150684931507 55.0027397260274 1.08767123287671 0 0 0 0 0 0 0
"2980" 59.9616438356164 65.5150684931507 0.835616438356164 1 0 0 0 0 0 0
"2981" 57.9178082191781 59.7095890410959 5.00821917808219 0 0 0 0 0 0 0
"2982" 64.0520547945205 58.2767123287671 0.16986301369863 0 0 0 0 0 0 0
"2983" 65.5178082191781 61.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"2984" 58.7972602739726 67.8657534246575 0.416438356164384 1 0 0 0 0 0 0
"2985" 61.8 65.6821917808219 3.59178082191781 0 0 0 0 0 0 0
"2986" 57.7260273972603 65.7808219178082 0.673972602739726 0 0 0 0 0 0 0
"2987" 63.3232876712329 65.1095890410959 3.00547945205479 0 0 0 0 0 0 0
"2988" 60.2 65.9506849315069 4.84109589041096 0 0 0 0 0 0 0
"2989" 65.4191780821918 65.0958904109589 0 0 0 0 0 0 0 0
"2990" 64.1835616438356 65.6246575342466 2.50684931506849 0 0 0 0 0 0 0
"2991" 57.1013698630137 65.4219178082192 5.00821917808219 0 0 0 0 0 0 0
"2992" 58.841095890411 67.1616438356164 3.93698630136986 0 0 0 0 0 0 0
"2993" 54.0027397260274 67.8219178082192 5.00821917808219 0 0 0 0 0 0 0
"2994" 54.5068493150685 68.3260273972603 4.67123287671233 0 0 0 0 0 0 0
"2995" 64.386301369863 67.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"2996" 65.3095890410959 68.3534246575342 4.67123287671233 0 0 0 0 0 0 0
"2997" 68.9095890410959 69.4054794520548 5.00821917808219 0 0 0 0 0 0 0
"2998" 69.8328767123288 70.3287671232877 4.67123287671233 0 0 0 0 0 0 0
"2999" 59.3479452054795 66.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"3000" 60.2712328767123 67.0849315068493 4.67123287671233 0 0 0 0 0 0 0
"3001" 62.1479452054795 68.0054794520548 5.00821917808219 0 0 0 0 0 0 0
"3002" 63.0712328767123 68.9287671232877 4.67123287671233 0 0 0 0 0 0 0
"3003" 66.5260273972603 65.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"3004" 67.4493150684931 66.4356164383562 4.67123287671233 0 0 0 0 0 0 0
"3005" 65.1753424657534 65.6657534246575 4.0027397260274 1 0 0 0 0 0 0
"3006" 66.0986301369863 66.5890410958904 3.58904109589041 1 0 0 0 0 0 0
"3007" 72.2767123287671 68.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"3008" 73.6630136986301 74.5917808219178 1.83561643835616 1 0 0 0 0 0 0
"3009" 73.6630136986301 74.5917808219178 1.83561643835616 1 0 0 0 0 0 0
"3010" 84.2849315068493 73.4849315068493 1.41643835616438 1 0 0 0 0 0 0
"3011" 84.2849315068493 73.4849315068493 1.41643835616438 1 0 0 0 0 0 0
"3012" 73.8904109589041 75.0739726027397 5.00821917808219 0 0 0 0 0 0 0
"3013" 73.8904109589041 75.0739726027397 5.00821917808219 0 0 0 0 0 0 0
"3014" 77.4876712328767 74.7369863013699 3.91780821917808 1 0 0 0 0 0 0
"3015" 78.0739726027397 75.3232876712329 3.91780821917808 1 0 0 0 0 0 0
"3016" 68.4931506849315 74.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"3017" 68.5753424657534 74.1041095890411 5.00821917808219 0 0 0 0 0 0 0
"3018" 75.8493150684932 75.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"3019" 75.5123287671233 74.8191780821918 5.00821917808219 0 0 0 0 0 0 0
"3020" 71.4356164383562 77.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"3021" 71.4356164383562 77.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"3022" 69.1698630136986 76.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"3023" 69.1698630136986 76.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"3024" 61.5397260273973 74.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"3025" 61.5397260273973 74.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"3026" 76.3561643835616 77.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"3027" 76.3561643835616 77.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"3028" 64.4630136986301 73.5835616438356 5.00821917808219 0 0 0 0 0 0 0
"3029" 64.6328767123288 73.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"3030" 80.3232876712329 75.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"3031" 80.5753424657534 75.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"3032" 77.7835616438356 74.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"3033" 77.0356164383562 73.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"3034" 78.6219178082192 75.427397260274 5.00821917808219 0 0 0 0 0 0 0
"3035" 78.7890410958904 75.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"3036" 72.9424657534247 74.7205479452055 5.00821917808219 0 0 0 0 0 0 0
"3037" 72.9424657534247 74.7205479452055 5.00821917808219 0 0 0 0 0 0 0
"3038" 67.5150684931507 74.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"3039" 66.8465753424658 74.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"3040" 80.3205479452055 75.5671232876712 3.83561643835616 1 0 0 0 0 0 0
"3041" 80.3205479452055 75.5671232876712 3.83561643835616 1 0 0 0 0 0 0
"3042" 73.2821917808219 73.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"3043" 73.9506849315069 74.3808219178082 5.00821917808219 0 0 0 0 0 0 0
"3044" 55.786301369863 73.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"3045" 56.4547945205479 74.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"3046" 73.958904109589 75.0712328767123 4.66849315068493 1 0 0 0 0 0 0
"3047" 74.627397260274 75.7397260273973 4.66849315068493 1 0 0 0 0 0 0
"3048" 72.9095890410959 74.3260273972603 0.164383561643836 1 0 0 0 0 0 0
"3049" 73.5780821917808 74.9945205479452 0.164383561643836 1 0 0 0 0 0 0
"3050" 65.6794520547945 75.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"3051" 66.3479452054794 76.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"3052" 79.4520547945205 73.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"3053" 80.1205479452055 74.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"3054" 81.0246575342466 76.6931506849315 5.00821917808219 0 0 0 0 0 0 0
"3055" 81.6931506849315 77.3616438356164 5.00821917808219 0 0 0 0 0 0 0
"3056" 74.6465753424658 75.5041095890411 4.33150684931507 0 0 1 0 1 0 0.0602739726027397
"3057" 75.3150684931507 76.172602739726 4.33150684931507 0 0 1 0 1 0 0.0602739726027397
"3058" 77.5972602739726 77.027397260274 0.917808219178082 1 0 0 0 0 0 0
"3059" 78.2657534246575 77.6958904109589 0.917808219178082 1 0 0 0 0 0 0
"3060" 73.0684931506849 74.2383561643836 5.00821917808219 0 0 0 0 0 0 0
"3061" 73.7369863013699 74.9068493150685 5.00821917808219 0 0 0 0 0 0 0
"3062" 76.241095890411 75.1315068493151 4.66849315068493 1 0 0 0 0 0 0
"3063" 76.9095890410959 75.8 4.66849315068493 1 0 0 0 0 0 0
"3064" 74.4 76.6821917808219 5.00821917808219 0 0 0 0 0 0 0
"3065" 75.0684931506849 77.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"3066" 75.9917808219178 76.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"3067" 75.9917808219178 76.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"3068" 73.4465753424657 74.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"3069" 72.7780821917808 73.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"3070" 64.6082191780822 74.1753424657534 4.41643835616438 1 0 0 0 0 0 0
"3071" 63.9397260273973 73.5068493150685 4.41643835616438 1 0 0 0 0 0 0
"3072" 77.1534246575342 76.1068493150685 5.00821917808219 0 0 0 0 0 0 0
"3073" 76.4849315068493 75.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"3074" 71.7068493150685 74.6657534246575 0.917808219178082 1 0 0 0 0 0 0
"3075" 71.0383561643836 73.9972602739726 0.917808219178082 1 0 0 0 0 0 0
"3076" 74.3150684931507 74.7178082191781 0 0 0 0 1 0 0.517808219178082 0
"3077" 73.6465753424658 74.0493150684931 0 0 0 0 1 0 0.517808219178082 0
"3078" 77.7972602739726 77.3013698630137 5.00821917808219 0 0 0 0 0 0 0
"3079" 77.1287671232877 76.6328767123288 5.00821917808219 0 0 0 0 0 0 0
"3080" 68.7698630136986 76.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"3081" 68.1013698630137 75.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"3082" 73.8958904109589 76.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"3083" 73.227397260274 75.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"3084" 72.5780821917808 74.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"3085" 71.9095890410959 73.3561643835616 5.00821917808219 0 0 0 0 0 0 0
"3086" 76.0876712328767 77.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"3087" 75.4191780821918 77.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"3088" 76.9835616438356 77.8904109589041 0.917808219178082 1 0 0 0 0 0 0
"3089" 76.3150684931507 77.2219178082192 0.917808219178082 1 0 0 0 0 0 0
"3090" 65.8054794520548 66.5013698630137 1.03835616438356 0 0 0 0 0 0 0
"3091" 66.8054794520548 66.1095890410959 0.484931506849315 0 0 0 0 0 0 0
"3092" 63.6356164383562 68.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"3093" 62.9671232876712 68.213698630137 5.00821917808219 0 0 0 0 0 0 0
"3094" 63.8082191780822 74.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"3095" 63.1506849315069 65.0657534246575 3.41643835616438 0 0 0 0 0 0 0
"3096" 64.1150684931507 68.8301369863014 2.58356164383562 1 0 0 0 0 0 0
"3097" 60.3260273972603 61.6630136986301 2.75068493150685 1 0 0 0 0 0 0
"3098" 74.9561643835616 68.5342465753425 5.00821917808219 0 0 0 0 0 0 0
"3099" 58.9643835616438 60.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"3100" 59.558904109589 63.013698630137 5.00821917808219 0 0 0 0 0 0 0
"3101" 59.986301369863 64.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"3102" 64.9534246575342 63.4821917808219 5.00821917808219 0 0 0 0 0 0 0
"3103" 60.0164383561644 65.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"3104" 65.5643835616438 65.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"3105" 64.6657534246575 68.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"3106" 64.3095890410959 61.7424657534247 5.00821917808219 0 0 0 0 0 0 0
"3107" 61.3753424657534 67.441095890411 5.00821917808219 0 0 0 0 0 0 0
"3108" 69.6931506849315 64.1041095890411 5.00821917808219 0 0 0 0 0 0 0
"3109" 62.7068493150685 62.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"3110" 63.3780821917808 65.2191780821918 4.84109589041096 0 0 0 0 0 0 0
"3111" 64.9643835616438 68.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"3112" 67.3945205479452 66.0547945205479 5.00821917808219 0 0 0 0 0 0 0
"3113" 67.5972602739726 64.1315068493151 5.0027397260274 0 1 0 0 0 0 0
"3114" 66.1424657534247 62.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"3115" 67.5205479452055 68.9397260273973 5.00821917808219 0 0 0 0 0 0 0
"3116" 65.6109589041096 65.5342465753425 3.50684931506849 0 0 0 0 0 0 0
"3117" 69.8520547945206 68.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"3118" 63.2904109589041 65.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"3119" 64.1890410958904 65.7150684931507 5.00821917808219 0 0 0 0 0 0 0
"3120" 66.9260273972603 65.158904109589 3.00547945205479 0 0 0 0 0 0 0
"3121" 76.9643835616438 80.7013698630137 5.00821917808219 0 0 0 0 0 0 0
"3122" 65.8794520547945 69.3890410958904 5.00821917808219 0 0 0 0 0 0 0
"3123" 75.2246575342466 74.1178082191781 5.00821917808219 0 0 0 0 0 0 0
"3124" 70.8219178082192 71.958904109589 5.00821917808219 0 0 0 0 0 0 0
"3125" 65.8630136986301 64.7095890410959 5.00821917808219 0 0 0 0 0 0 0
"3126" 52.2986301369863 59.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"3127" 70.5095890410959 69.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"3128" 62.6383561643836 60.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"3129" 59.1561643835616 60.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"3130" 55.5917808219178 61.558904109589 5.00821917808219 0 0 0 0 0 0 0
"3131" 62.8821917808219 62.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"3132" 70.1561643835616 73.158904109589 5.00821917808219 0 0 0 0 0 0 0
"3133" 75.6109589041096 76.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"3134" 68.7095890410959 70.027397260274 5.00821917808219 0 0 0 0 0 0 0
"3135" 67.2958904109589 71.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"3136" 64.986301369863 61.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"3137" 66.8986301369863 70.6986301369863 5.00821917808219 0 0 0 0 0 0 0
"3138" 63.3753424657534 62.9479452054794 5.00821917808219 0 0 0 0 0 0 0
"3139" 65.2 60.9561643835616 5.00821917808219 0 0 0 0 0 0 0
"3140" 61.9452054794521 62.5534246575342 3.4986301369863 1 0 0 0 0 0 0
"3141" 68.3178082191781 71.9698630136986 5.00821917808219 0 0 0 0 0 0 0
"3142" 61.3698630136986 67.9315068493151 5.00821917808219 0 0 0 0 0 0 0
"3143" 63.8301369863014 69.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"3144" 70.1753424657534 71.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"3145" 65.4383561643836 70.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"3146" 68.4904109589041 69.3479452054794 1.4986301369863 1 0 0 0 0 0 0
"3147" 61.0109589041096 60.8191780821918 3.41643835616438 0 0 1 0 1 0 0.073972602739726
"3148" 64.3753424657534 67.6 5.00821917808219 0 0 0 0 0 0 0
"3149" 64.7753424657534 62.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"3150" 58.558904109589 62.4328767123288 5.00821917808219 0 0 0 0 0 0 0
"3151" 57.5095890410959 61.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"3152" 60.7068493150685 69.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"3153" 57.1315068493151 63.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"3154" 67.3123287671233 73.4767123287671 5.00821917808219 0 0 0 0 0 0 0
"3155" 63.7835616438356 70.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"3156" 61.2958904109589 68.2328767123288 0.583561643835616 1 0 0 0 0 0 0
"3157" 68.9150684931507 74.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"3158" 60.2520547945205 61.0739726027397 5.00821917808219 0 0 0 0 0 0 0
"3159" 72.2054794520548 74.3260273972603 3.91232876712329 0 0 0 0 0 0 0
"3160" 59.013698630137 64.8958904109589 0.482191780821918 0 0 0 0 0 0 0
"3161" 58.4958904109589 60.3780821917808 3.30958904109589 0 0 0 0 0 0 0
"3162" 66.654794520548 65.8054794520548 4.76438356164384 0 0 0 0 0 0 0
"3163" 63.8684931506849 65.8821917808219 0.915068493150685 0 0 0 0 0 0 0
"3164" 61.6630136986301 65.4657534246575 4.5041095890411 0 0 0 0 0 0 0
"3165" 59.7041095890411 65.2246575342466 1.91506849315068 0 0 0 0 0 0 0
"3166" 59.8575342465753 65.0821917808219 2.97260273972603 0 0 0 0 0 0 0
"3167" 59.2356164383562 65.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"3168" 63.2082191780822 64.6821917808219 2.91780821917808 1 0 0 0 0 0 0
"3169" 55.9561643835616 64.9232876712329 4.51506849315069 0 0 0 0 0 0 0
"3170" 64.1780821917808 65.0575342465753 3.7041095890411 0 0 0 0 0 0 0
"3171" 54.2438356164384 65.0684931506849 2 0 0 0 0 0 0 0
"3172" 60.958904109589 65.6712328767123 4.45205479452055 0 0 0 0 0 0 0
"3173" 61.3616438356164 65.8547945205479 2.91506849315068 0 0 0 0 0 0 0
"3174" 70.5424657534247 64.1753424657534 1.25205479452055 0 0 0 0 0 0 0
"3175" 66.772602739726 65.8328767123288 0.838356164383562 0 0 0 0 0 0 0
"3176" 65.2684931506849 65.0219178082192 1 0 0 0 0 0 0 0
"3177" 62.1534246575342 68.4109589041096 0.980821917808219 0 0 0 0 0 0 0
"3178" 65.0219178082192 65.2684931506849 1 0 0 0 0 0 0 0
"3179" 68.4109589041096 62.1534246575342 0.980821917808219 0 0 0 0 0 0 0
"3180" 64.2328767123288 66.4191780821918 5.00821917808219 0 0 0 0 0 0 0
"3181" 60.7917808219178 60.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"3182" 72.158904109589 63.0958904109589 5.00821917808219 0 0 0 0 0 0 0
"3183" 61.3205479452055 67.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"3184" 61.8547945205479 67.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"3185" 55.7369863013699 57.3424657534247 5.00821917808219 0 0 0 0 0 0 0
"3186" 59.5506849315069 65.827397260274 5.00821917808219 0 0 0 0 0 0 0
"3187" 71.1972602739726 66.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"3188" 64.6630136986301 65.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"3189" 67.3808219178082 67.1534246575342 3.08767123287671 0 1 0 0 0 0 0
"3190" 64.6684931506849 65.8301369863014 0.673972602739726 0 0 0 0 0 0 0
"3191" 60.3287671232877 63.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"3192" 60.372602739726 65.0493150684931 2.92602739726027 0 0 0 0 0 0 0
"3193" 58.3616438356164 65.8712328767123 5.00821917808219 0 0 0 0 0 0 0
"3194" 66.2958904109589 64.7205479452055 2.33698630136986 1 0 0 0 0 0 0
"3195" 70.7013698630137 68.8328767123288 5.00821917808219 0 0 0 0 0 0 0
"3196" 56.5890410958904 62.227397260274 5.00821917808219 0 0 0 0 0 0 0
"3197" 60.1013698630137 61.0931506849315 5.00821917808219 0 0 0 0 0 0 0
"3198" 59.2821917808219 63.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"3199" 59.6164383561644 63.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"3200" 54.7287671232877 56.0575342465753 5.00821917808219 0 0 0 0 0 0 0
"3201" 54.7287671232877 56.0575342465753 5.00821917808219 0 0 0 0 0 0 0
"3202" 54.5780821917808 57.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"3203" 60.8219178082192 64.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"3204" 60.8219178082192 64.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"3205" 64.1452054794521 61.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"3206" 64.2301369863014 60.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"3207" 57.5013698630137 56.5780821917808 4.07397260273973 0 0 0 0 0 0 0
"3208" 62.772602739726 64.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"3209" 58.0465753424658 67.2164383561644 0.164383561643836 1 0 0 0 0 0 0
"3210" 60.9397260273973 65.7232876712329 0.753424657534247 0 0 0 0 0 0 0
"3211" 63.5424657534247 65.4465753424657 3.75342465753425 0 0 0 0 0 0 0
"3212" 67.1506849315068 65.7479452054795 2.75342465753425 0 0 0 0 0 0 0
"3213" 60.8328767123288 65.7123287671233 2.75342465753425 0 0 0 0 0 0 0
"3214" 60.241095890411 65.0191780821918 1.5972602739726 0 0 0 0 0 0 0
"3215" 52.8767123287671 56.9178082191781 5.00821917808219 0 0 0 0 0 0 0
"3216" 66.8794520547945 65.1205479452055 0 0 0 0 0 0 0 0
"3217" 64.3835616438356 66.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"3218" 62.2794520547945 64.3315068493151 1.16712328767123 0 0 0 0 0 0 0
"3219" 63.7698630136986 65.572602739726 2.42739726027397 0 0 0 0 0 0 0
"3220" 68.2219178082192 66.5479452054795 5.00821917808219 0 0 0 0 0 0 0
"3221" 52.1013698630137 55.2575342465753 3.08767123287671 0 1 0 0 0 0 0
"3222" 60.4904109589041 67.7013698630137 5.00821917808219 0 0 0 0 0 0 0
"3223" 65.9315068493151 66.627397260274 5.00821917808219 0 0 0 0 0 0 0
"3224" 60.9534246575342 65.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"3225" 56.6493150684932 71.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"3226" 71.4849315068493 70.7041095890411 5.00821917808219 0 0 0 0 0 0 0
"3227" 63.7315068493151 65.9890410958904 5.00821917808219 0 0 0 0 0 0 0
"3228" 53.9287671232877 61.7068493150685 2.45753424657534 0 0 0 0 0 0 0
"3229" 67.2794520547945 65.3808219178082 1.33424657534247 0 0 0 0 0 0 0
"3230" 61.4246575342466 65.827397260274 4.53424657534247 0 0 0 0 0 0 0
"3231" 64.4493150684931 65.613698630137 1.32602739726027 0 0 0 0 0 0 0
"3232" 67.8712328767123 65.6876712328767 3.13424657534247 0 0 0 0 0 0 0
"3233" 65.0547945205479 69.8493150684932 3.85479452054795 0 0 0 0 0 0 0
"3234" 64.3698630136986 65.2493150684931 1.21095890410959 0 0 0 0 0 0 0
"3235" 59.3561643835616 64.5890410958904 0.0821917808219178 0 0 0 0 0 0 0
"3236" 72.4602739726027 74.041095890411 5.00821917808219 0 0 0 0 0 0 0
"3237" 64.3945205479452 67.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"3238" 60.6684931506849 61.3068493150685 5.00821917808219 0 0 0 0 0 0 0
"3239" 62.6547945205479 63.2931506849315 3.69041095890411 0 0 0 0 0 0 0
"3240" 71.6219178082192 74.8657534246575 5.00821917808219 0 0 0 0 0 0 0
"3241" 59.8438356164384 64.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"3242" 62.6602739726027 67.0794520547945 3.69041095890411 0 0 0 0 0 0 0
"3243" 70.1616438356164 67.172602739726 5.00821917808219 0 0 0 0 0 0 0
"3244" 72.1479452054794 69.158904109589 3.69041095890411 0 0 0 0 0 0 0
"3245" 57.2520547945205 65.4904109589041 5.00821917808219 0 0 0 0 0 0 0
"3246" 59.1534246575342 67.3917808219178 3.69041095890411 0 0 0 0 0 0 0
"3247" 72.0246575342466 70.1890410958904 5.00821917808219 0 0 0 0 0 0 0
"3248" 73.841095890411 72.0054794520548 3.69041095890411 0 0 0 0 0 0 0
"3249" 64.7808219178082 59.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"3250" 66.2657534246575 61.3616438356164 3.69041095890411 0 0 0 0 0 0 0
"3251" 63.2465753424658 60.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"3252" 65.2328767123288 62.9287671232877 3.69041095890411 0 0 0 0 0 0 0
"3253" 60.4520547945205 61.0739726027397 5.00821917808219 0 0 0 0 0 0 0
"3254" 62.3534246575342 62.9753424657534 3.69041095890411 0 0 0 0 0 0 0
"3255" 65.3397260273973 67.5095890410959 3.75068493150685 1 0 0 0 0 0 0
"3256" 68.1561643835616 70.3260273972603 2.42191780821918 1 0 0 0 0 0 0
"3257" 62.5698630136986 72.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"3258" 64.8904109589041 74.4602739726027 3.69041095890411 0 0 0 0 0 0 0
"3259" 61.4438356164384 65.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"3260" 62.9342465753425 66.5561643835617 3.69041095890411 0 0 0 0 0 0 0
"3261" 74.1260273972603 77.7150684931507 3.4986301369863 1 0 0 0 0 0 0
"3262" 76.1123287671233 79.7013698630137 2.16986301369863 1 0 0 0 0 0 0
"3263" 63.6465753424658 67.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"3264" 65.7178082191781 69.4547945205479 3.69041095890411 0 0 0 0 0 0 0
"3265" 63.6931506849315 65.1068493150685 5.00821917808219 0 0 0 0 0 0 0
"3266" 61.3260273972603 65.0328767123288 0.0821917808219178 0 0 0 0 0 0 0
"3267" 73.4602739726027 76.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"3268" 63.7972602739726 68.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"3269" 66.0328767123288 70.6191780821918 3.69041095890411 0 0 0 0 0 0 0
"3270" 53.8821917808219 68.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"3271" 55.5342465753425 70.5561643835617 3.69041095890411 0 0 0 0 0 0 0
"3272" 61.4438356164384 68.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"3273" 63.5123287671233 70.7479452054795 3.69041095890411 0 0 0 0 0 0 0
"3274" 70.3315068493151 74.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"3275" 72.3178082191781 76.0493150684931 3.69041095890411 0 0 0 0 0 0 0
"3276" 60.8767123287671 60.0931506849315 1.02465753424658 0 0 0 0 0 0 0
"3277" 54.358904109589 56.8356164383562 0.704109589041096 0 0 0 0 0 0 0
"3278" 73.3972602739726 71.441095890411 5.00821917808219 0 0 0 0 0 0 0
"3279" 75.8027397260274 73.8465753424658 3.69041095890411 0 0 0 0 0 0 0
"3280" 62.5095890410959 63.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"3281" 64.4958904109589 65.8547945205479 3.69041095890411 0 0 0 0 0 0 0
"3282" 71.2547945205479 72.1561643835616 5.00821917808219 0 0 0 0 0 0 0
"3283" 73.158904109589 74.0602739726027 3.69041095890411 0 0 0 0 0 0 0
"3284" 64.5123287671233 68.0520547945205 5.00821917808219 0 0 0 0 0 0 0
"3285" 67.2520547945205 70.7917808219178 3.69041095890411 0 0 0 0 0 0 0
"3286" 65.9287671232877 70.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"3287" 68.0821917808219 72.4301369863014 3.69041095890411 0 0 0 0 0 0 0
"3288" 61.2082191780822 61.4684931506849 5.00821917808219 0 0 0 0 0 0 0
"3289" 62.9452054794521 63.2054794520548 3.69041095890411 0 0 0 0 0 0 0
"3290" 67.4493150684931 69.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"3291" 69.6849315068493 71.427397260274 3.69041095890411 0 0 0 0 0 0 0
"3292" 73.1780821917808 73.6191780821918 5.00821917808219 0 0 0 0 0 0 0
"3293" 74.4109589041096 74.8520547945206 3.69041095890411 0 0 0 0 0 0 0
"3294" 61.3068493150685 66.8876712328767 5.00821917808219 0 0 0 0 0 0 0
"3295" 63.2109589041096 68.7917808219178 3.69041095890411 0 0 0 0 0 0 0
"3296" 71.627397260274 74.4849315068493 5.00821917808219 0 0 0 0 0 0 0
"3297" 73.1945205479452 76.0520547945205 3.69041095890411 0 0 0 0 0 0 0
"3298" 50.1013698630137 73.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"3299" 52.4246575342466 76.1123287671233 3.69041095890411 0 0 0 0 0 0 0
"3300" 56.2465753424658 59.2465753424658 5.00821917808219 0 0 0 0 0 0 0
"3301" 67.8794520547945 70.4684931506849 5.00821917808219 0 0 0 0 0 0 0
"3302" 62.5808219178082 67.7561643835616 5.00821917808219 0 0 0 0 0 0 0
"3303" 64.7342465753425 69.9095890410959 3.69041095890411 0 0 0 0 0 0 0
"3304" 90.5452054794521 89.9205479452055 5.00821917808219 0 0 0 0 0 0 0
"3305" 63.1178082191781 69.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"3306" 64.8520547945206 71.0876712328767 3.69041095890411 0 0 0 0 0 0 0
"3307" 64.0739726027397 67.8547945205479 5.00821917808219 0 0 0 0 0 0 0
"3308" 66.0602739726027 69.841095890411 3.69041095890411 0 0 0 0 0 0 0
"3309" 76.041095890411 76.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"3310" 78.1945205479452 78.4520547945205 3.69041095890411 0 0 0 0 0 0 0
"3311" 67.7561643835616 67.8547945205479 5.00821917808219 0 0 0 0 0 0 0
"3312" 70.1616438356164 70.2602739726027 3.69041095890411 0 0 0 0 0 0 0
"3313" 50.986301369863 55.1534246575342 5.00821917808219 0 0 0 0 0 0 0
"3314" 68.2 67.3890410958904 3.41643835616438 1 0 0 0 0 0 0
"3315" 63.6575342465753 63.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"3316" 62.2547945205479 61.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"3317" 51.813698630137 62.6767123287671 5.00821917808219 0 0 0 0 0 0 0
"3318" 55.9479452054794 58.9780821917808 5.00821917808219 0 0 0 0 0 0 0
"3319" 60.6465753424658 62.9013698630137 4.91506849315068 0 0 0 0 0 0 0
"3320" 69.8602739726027 65.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"3321" 66.4849315068493 66.2684931506849 5.00821917808219 0 0 0 0 0 0 0
"3322" 58.4383561643836 62.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"3323" 66.7835616438356 68.8739726027397 5.00821917808219 0 0 0 0 0 0 0
"3324" 67.8191780821918 66.4986301369863 5.00821917808219 0 0 0 0 0 0 0
"3325" 60.8301369863014 63.8547945205479 5.00821917808219 0 0 0 0 0 0 0
"3326" 71.5506849315069 65.5123287671233 1.0027397260274 0 0 1 0 1 0 0.0712328767123288
"3327" 65.4 65.6739726027397 4.35890410958904 0 0 0 0 0 0 0
"3328" 64.6657534246575 65.2054794520548 0 0 0 0 0 0 0 0
"3329" 41.8739726027397 61.5561643835616 2.67671232876712 0 0 0 0 0 0 0
"3330" 66.9150684931507 65.3890410958904 2.25479452054795 0 0 0 0 0 0 0
"3331" 67.1753424657534 65.1917808219178 0.298630136986301 0 0 0 0 0 0 0
"3332" 65.0684931506849 65.6684931506849 2.59178082191781 0 0 0 0 0 0 0
"3333" 62.1808219178082 68.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"3334" 58.7178082191781 65.6219178082192 2.67123287671233 0 0 0 0 0 0 0
"3335" 61.4383561643836 64.6986301369863 5.00821917808219 0 0 0 0 0 0 0
"3336" 63.2301369863014 65.6465753424658 3.67123287671233 0 0 0 0 0 0 0
"3337" 60.1890410958904 65.3424657534247 3.67123287671233 0 0 0 0 0 0 0
"3338" 57.5808219178082 66.8 5.00821917808219 0 0 0 0 0 0 0
"3339" 55.7890410958904 62.4109589041096 5.00821917808219 0 0 0 0 0 0 0
"3340" 68.1972602739726 66.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"3341" 65.0520547945205 64.9506849315069 4.93150684931507 0 0 0 0 0 0 0
"3342" 65.1205479452055 66.5178082191781 5.00821917808219 0 0 0 0 0 0 0
"3343" 64.6191780821918 65.1534246575342 4.92054794520548 0 0 0 0 0 0 0
"3344" 59.5753424657534 59.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"3345" 66.7397260273973 65.2219178082192 4.03287671232877 0 0 0 0 0 0 0
"3346" 59.2657534246575 60.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"3347" 64.0109589041096 65.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"3348" 68.6684931506849 66.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"3349" 63.8328767123288 66.227397260274 2.91780821917808 1 0 0 0 0 0 0
"3350" 50.1808219178082 58.6547945205479 5.00821917808219 0 0 0 0 0 0 0
"3351" 67.0876712328767 66.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"3352" 63.8904109589041 66.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"3353" 61.6849315068493 66.3123287671233 5.00821917808219 0 0 0 0 0 0 0
"3354" 67.2684931506849 66.1397260273973 5.00821917808219 0 0 0 0 0 0 0
"3355" 73.5205479452055 65.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"3356" 63.2191780821918 67.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"3357" 62.1205479452055 63.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"3358" 52.9369863013699 65.4876712328767 4.0027397260274 1 0 0 0 0 0 0
"3359" 53.0520547945206 62.0493150684932 3.91780821917808 1 0 0 0 0 0 0
"3360" 64.9835616438356 67.4219178082192 5.00821917808219 0 0 0 0 0 0 0
"3361" 57.4054794520548 59.4520547945205 1.33150684931507 0 0 0 0 0 0 0
"3362" 67.3972602739726 72.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"3363" 61.1945205479452 63.413698630137 5.00821917808219 0 0 0 0 0 0 0
"3364" 52.9534246575342 55.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"3365" 59.0794520547945 64.6356164383562 5.00821917808219 0 0 0 0 0 0 0
"3366" 73.0246575342466 66.6630136986301 5.00821917808219 0 0 0 0 0 0 0
"3367" 70.7397260273973 65.8602739726027 1.16986301369863 1 0 0 0 0 0 0
"3368" 65.6301369863014 65.7397260273973 2.55616438356164 0 0 0 0 0 0 0
"3369" 67.9041095890411 67.2109589041096 5.00821917808219 0 0 0 0 0 0 0
"3370" 60.9232876712329 67.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"3371" 64.6 65.041095890411 2.6958904109589 0 0 0 0 0 0 0
"3372" 71.7698630136986 65.0465753424658 1.66575342465753 1 0 0 0 0 0 0
"3373" 67.1835616438356 65.7561643835616 2.75342465753425 0 0 0 0 0 0 0
"3374" 59.0328767123288 59.6438356164384 5.00821917808219 0 0 0 0 0 0 0
"3375" 63.3671232876712 66.5369863013699 5.00821917808219 0 0 0 0 0 0 0
"3376" 63.7698630136986 66.772602739726 4.91780821917808 1 0 0 0 0 0 0
"3377" 68.3150684931507 77.4684931506849 4.91780821917808 1 0 0 0 0 0 0
"3378" 62.1534246575342 68.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"3379" 67.8027397260274 70.3095890410959 5.00821917808219 0 0 0 0 0 0 0
"3380" 52.0465753424658 69.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"3381" 61.372602739726 65.6082191780822 3.48219178082192 0 0 0 0 0 0 0
"3382" 66.6931506849315 68.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"3383" 58.1945205479452 61.1260273972603 3.38356164383562 0 0 0 0 0 0 0
"3384" 62.6027397260274 64.6684931506849 3.38356164383562 0 0 0 0 0 0 0
"3385" 59.6328767123288 59.9506849315068 5.00821917808219 0 0 0 0 0 0 0
"3386" 64.2904109589041 63.5424657534247 2.55616438356164 0 0 0 0 0 0 0
"3387" 57.3315068493151 64.4630136986301 5.00821917808219 0 0 0 0 0 0 0
"3388" 65.172602739726 65.3835616438356 3.3013698630137 0 0 0 0 0 0 0
"3389" 67.7753424657534 65.5616438356164 4.82191780821918 0 0 0 0 0 0 0
"3390" 64.827397260274 63.8849315068493 3.38356164383562 0 0 0 0 0 0 0
"3391" 66.8164383561644 65.5835616438356 3.38356164383562 0 0 0 0 0 0 0
"3392" 63.3890410958904 64.5041095890411 2.38356164383562 0 0 0 0 0 0 0
"3393" 57.7178082191781 64.9315068493151 5.00821917808219 0 0 0 0 0 0 0
"3394" 72.5780821917808 64.3013698630137 5.00821917808219 0 0 0 0 0 0 0
"3395" 66.9068493150685 62.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"3396" 58.3150684931507 65.8164383561644 3.08767123287671 1 0 0 0 0 0 0
"3397" 65.0082191780822 67.7452054794521 3.80821917808219 0 0 0 0 0 0 0
"3398" 59.4219178082192 60.3917808219178 3.91780821917808 0 0 0 0 0 0 0
"3399" 58.6438356164384 65.3808219178082 5.00821917808219 0 0 0 0 0 0 0
"3400" 57.4 65.386301369863 3.38356164383562 0 0 0 0 0 0 0
"3401" 67.1013698630137 64.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"3402" 56.6191780821918 65.5616438356164 3.38356164383562 0 0 0 0 0 0 0
"3403" 60.3945205479452 66.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"3404" 59.5780821917808 65.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"3405" 56.2794520547945 63.2547945205479 5.00821917808219 0 0 0 0 0 0 0
"3406" 62.613698630137 65.427397260274 3.38356164383562 0 0 0 0 0 0 0
"3407" 55.9315068493151 60.7972602739726 5.00821917808219 0 0 0 0 0 0 0
"3408" 66.358904109589 67.0465753424658 5.00821917808219 0 0 0 0 0 0 0
"3409" 68.1479452054794 64.8712328767123 5.00821917808219 0 0 0 0 0 0 0
"3410" 61.4547945205479 60.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"3411" 65.3616438356164 60.0602739726027 5.00821917808219 0 0 0 0 0 0 0
"3412" 60.4191780821918 65.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"3413" 47.6493150684932 53.172602739726 2.38630136986301 0 0 0 0 0 0 0
"3414" 59.4246575342466 62.5424657534247 5.00821917808219 0 0 0 0 0 0 0
"3415" 62.1013698630137 64.6109589041096 3.3013698630137 0 0 0 0 0 0 0
"3416" 52.4575342465753 60.2493150684932 5.00821917808219 0 0 0 0 0 0 0
"3417" 66.3315068493151 66.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"3418" 58.7643835616438 56.7698630136986 3.74246575342466 0 0 0 0 0 0 0
"3419" 61.6164383561644 63.5479452054795 5.00821917808219 0 0 0 0 0 0 0
"3420" 63.7972602739726 63.0054794520548 0.750684931506849 1 0 0 0 0 0 0
"3421" 63.7835616438356 64.4876712328767 3.38356164383562 0 0 0 0 0 0 0
"3422" 68.7013698630137 65.1369863013699 3.80821917808219 0 0 0 0 0 0 0
"3423" 64.6684931506849 65.2821917808219 3.91780821917808 0 0 0 0 0 0 0
"3424" 70.1890410958904 64.7150684931507 5.00821917808219 0 0 0 0 0 0 0
"3425" 63.586301369863 67.9205479452055 4.30684931506849 0 0 0 0 0 0 0
"3426" 55.1643835616438 60.2356164383562 5.00821917808219 0 0 0 0 0 0 0
"3427" 57.1917808219178 60.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"3428" 65.4082191780822 65.2821917808219 4.90958904109589 0 0 0 0 0 0 0
"3429" 60 65.1178082191781 3.91780821917808 0 0 0 0 0 0 0
"3430" 67.4082191780822 66.413698630137 5.00821917808219 0 0 0 0 0 0 0
"3431" 57.3452054794521 56.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"3432" 61.1753424657534 64.2493150684931 0.331506849315069 1 0 0 0 0 0 0
"3433" 58.5643835616438 65.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"3434" 60.8575342465753 64.6958904109589 5.00821917808219 0 0 0 0 0 0 0
"3435" 57.9753424657534 67.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"3436" 62.5397260273973 65.0712328767123 5.00821917808219 0 0 0 0 0 0 0
"3437" 62.1315068493151 65.2767123287671 2.83561643835616 1 0 0 0 0 0 0
"3438" 68.9041095890411 66.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"3439" 71.7452054794521 68.9068493150685 5.00821917808219 0 0 0 0 0 0 0
"3440" 61.7534246575342 65.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"3441" 65.8219178082192 63.5780821917808 4.47671232876712 0 0 0 0 0 0 0
"3442" 63.4246575342466 59.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"3443" 66.0986301369863 66.8383561643836 3.3013698630137 0 0 0 0 0 0 0
"3444" 55.6712328767123 62.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"3445" 57.7945205479452 64.9616438356164 5.00821917808219 0 0 0 0 0 0 0
"3446" 56.6109589041096 60.772602739726 3.74246575342466 0 0 0 0 0 0 0
"3447" 63.2821917808219 65.4191780821918 4.90958904109589 0 0 0 0 0 0 0
"3448" 63.1643835616438 67.1205479452055 5.00821917808219 0 0 0 0 0 0 0
"3449" 57.5041095890411 60.4438356164384 5.00821917808219 0 0 0 0 0 0 0
"3450" 59.6438356164384 61.5452054794521 3.4986301369863 1 0 0 0 0 0 0
"3451" 61.6301369863014 66.9178082191781 3.3013698630137 0 0 0 0 0 0 0
"3452" 62.8 65.6931506849315 3.38356164383562 0 0 0 0 0 0 0
"3453" 65.0356164383562 63.4082191780822 3.3013698630137 0 0 0 0 0 0 0
"3454" 59.5260273972603 65.6767123287671 3.48219178082192 0 0 0 0 0 0 0
"3455" 56.4438356164384 60.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"3456" 55.5616438356164 55.758904109589 2.55616438356164 0 0 0 0 0 0 0
"3457" 62.6027397260274 63.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"3458" 56.1506849315069 64.6684931506849 5.00821917808219 0 0 0 0 0 0 0
"3459" 66.6684931506849 63.5041095890411 3.3013698630137 0 0 0 0 0 0 0
"3460" 66.3150684931507 67.0027397260274 3.38356164383562 0 0 0 0 0 0 0
"3461" 65.4191780821918 63.2821917808219 4.90958904109589 0 0 0 0 0 0 0
"3462" 61.2027397260274 67.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"3463" 66.2520547945205 64.7534246575343 3.38356164383562 0 0 0 0 0 0 0
"3464" 60.1342465753425 60.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"3465" 73 66.0876712328767 2.38356164383562 0 0 0 0 0 0 0
"3466" 66.3917808219178 55.9068493150685 4.90958904109589 0 0 0 0 0 0 0
"3467" 56.6493150684932 65.158904109589 3.97260273972603 0 0 0 0 0 0 0
"3468" 58.5041095890411 55.2767123287671 3.38356164383562 0 0 0 0 0 0 0
"3469" 68.1452054794521 65.9150684931507 4.08493150684932 1 0 0 0 0 0 0
"3470" 62.213698630137 58.7287671232877 3.38356164383562 0 0 0 0 0 0 0
"3471" 67.4657534246575 63.9315068493151 3.3013698630137 0 0 0 0 0 0 0
"3472" 60.4027397260274 67.0876712328767 4.96712328767123 0 0 0 0 0 0 0
"3473" 57.5397260273973 57.3890410958904 4.82465753424658 0 0 0 0 0 0 0
"3474" 65.172602739726 66.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"3475" 54.0904109589041 63.5452054794521 2.75068493150685 1 0 0 0 0 0 0
"3476" 44.227397260274 55.3287671232877 4.33424657534247 0 0 0 0 0 0 0
"3477" 62.7041095890411 61.4657534246575 0.364383561643836 1 0 0 0 0 0 0
"3478" 72.213698630137 69.3808219178082 5.00821917808219 0 0 0 0 0 0 0
"3479" 65.1671232876712 67.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"3480" 57.2575342465753 61.8164383561644 3.33972602739726 0 0 0 0 0 0 0
"3481" 55.3260273972603 60.7232876712329 3.14794520547945 0 0 0 0 0 0 0
"3482" 64.0082191780822 66.6575342465753 5.00821917808219 0 0 0 0 0 0 0
"3483" 69.3178082191781 65.0986301369863 4.03561643835616 0 0 0 0 0 0 0
"3484" 76.1369863013699 66.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"3485" 59.2739726027397 66.1178082191781 5.00821917808219 0 0 0 0 0 0 0
"3486" 63.6630136986301 69.2657534246575 4.53424657534247 0 0 0 0 0 0 0
"3487" 65.4219178082192 62.8027397260274 2.45753424657534 0 0 0 0 0 0 0
"3488" 64.841095890411 64.8082191780822 5.00821917808219 0 0 0 0 0 0 0
"3489" 65.7643835616438 64.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"3490" 60.6383561643836 64.3123287671233 5.00821917808219 0 0 0 0 0 0 0
"3491" 74.786301369863 69.3315068493151 5.00821917808219 0 0 0 0 0 0 0
"3492" 66.2191780821918 65.1123287671233 4.16712328767123 0 0 0 0 0 0 0
"3493" 59.6904109589041 61.9424657534247 0.838356164383562 0 0 0 0 0 0 0
"3494" 49.8958904109589 55.7315068493151 3.03835616438356 0 0 0 0 0 0 0
"3495" 57.2493150684932 60.5150684931507 2.23287671232877 0 0 0 0 0 0 0
"3496" 87.9945205479452 60.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"3497" 61.0876712328767 61.6547945205479 5.00821917808219 0 0 0 0 0 0 0
"3498" 56.627397260274 60.1369863013699 3.33424657534247 0 0 0 0 0 0 0
"3499" 60.6356164383562 59.0547945205479 2.33424657534247 0 0 0 0 0 0 0
"3500" 54.5178082191781 55.0246575342466 0.989041095890411 0 0 0 0 0 0 0
"3501" 61.8520547945205 62.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"3502" 66.8520547945206 62.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"3503" 64.427397260274 58.827397260274 0.819178082191781 0 0 0 0 0 0 0
"3504" 63.5013698630137 61.4630136986301 3.67123287671233 0 0 0 0 0 0 0
"3505" 60.3068493150685 56.2904109589041 2.72328767123288 0 0 0 0 0 0 0
"3506" 50.9890410958904 62.2547945205479 1 0 0 0 0 0 0 0
"3507" 66.0657534246575 61.0630136986301 5.00821917808219 0 0 0 0 0 0 0
"3508" 53.8191780821918 54.6630136986301 2.5041095890411 0 0 0 0 0 0 0
"3509" 53.3671232876712 58.4602739726027 0.989041095890411 0 0 0 0 0 0 0
"3510" 55.0219178082192 56.0328767123288 0.504109589041096 0 0 0 0 0 0 0
"3511" 55.3342465753425 60.813698630137 1.10684931506849 0 0 0 0 0 0 0
"3512" 44.1260273972603 56.9013698630137 0.89041095890411 0 0 0 0 0 0 0
"3513" 63 57.8054794520548 0.819178082191781 0 0 0 0 0 0 0
"3514" 49.0767123287671 56.2684931506849 0.586301369863014 0 0 0 0 0 0 0
"3515" 52.1041095890411 60.8849315068493 0.378082191780822 0 0 0 0 0 0 0
"3516" 68.3342465753425 62.4767123287671 2 0 0 0 0 0 0 0
"3517" 56.6027397260274 59.3424657534247 1.96164383561644 0 0 0 0 0 0 0
"3518" 57.4876712328767 57.4876712328767 0.89041095890411 0 0 0 0 0 0 0
"3519" 60.6712328767123 56.1972602739726 4.54794520547945 0 0 0 0 0 0 0
"3520" 63.2109589041096 62.813698630137 0.819178082191781 0 0 0 0 0 0 0
"3521" 65.158904109589 65.3178082191781 2.25205479452055 0 0 0 0 0 0 0
"3522" 50.558904109589 60.6 3.25205479452055 0 0 0 0 0 0 0
"3523" 58.9753424657534 58.8164383561644 3.25205479452055 0 0 0 0 0 0 0
"3524" 58.7041095890411 60.9095890410959 5.00821917808219 0 0 0 0 0 0 0
"3525" 51.986301369863 55.3013698630137 2.49315068493151 0 0 0 0 0 0 0
"3526" 55.6082191780822 59.8054794520548 3.04109589041096 0 0 0 0 0 0 0
"3527" 62.2027397260274 65.7479452054795 4 0 0 0 0 0 0 0
"3528" 61.1780821917808 62.2246575342466 3.67123287671233 0 0 0 0 0 0 0
"3529" 56.2602739726027 60.2657534246575 3.67123287671233 0 0 0 0 0 0 0
"3530" 53.0465753424658 59.7917808219178 1.33424657534247 0 0 0 0 0 0 0
"3531" 65.7342465753425 65.1178082191781 2.75342465753425 0 0 0 0 0 0 0
"3532" 53.9287671232877 58.2465753424658 3.41917808219178 0 0 0 0 0 0 0
"3533" 56.5534246575342 57.4219178082192 0.657534246575342 0 0 0 0 0 0 0
"3534" 54.3479452054795 60.5534246575342 5.00821917808219 0 0 0 0 0 0 0
"3535" 69.1643835616438 57.0493150684932 5.00821917808219 0 0 0 0 0 0 0
"3536" 39.1753424657534 54.8520547945205 5.00821917808219 0 0 0 0 0 0 0
"3537" 50.8246575342466 51.4219178082192 3.66027397260274 0 0 0 0 0 0 0
"3538" 61.8191780821918 61.9315068493151 5.00821917808219 0 0 0 0 0 0 0
"3539" 40.8246575342466 48.8712328767123 4.67123287671233 0 0 0 0 0 0 0
"3540" 62.3698630136986 63.2465753424658 5.00821917808219 0 0 0 0 0 0 0
"3541" 59.4219178082192 59.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"3542" 49.4164383561644 55.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"3543" 56.3780821917808 55.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"3544" 57.6 66.8931506849315 4.27945205479452 0 0 0 0 0 0 0
"3545" 58.572602739726 67.8657534246575 3.05753424657534 0 0 0 0 0 0 0
"3546" 63.1342465753425 65.9534246575342 4.27945205479452 0 0 0 0 0 0 0
"3547" 64.1068493150685 66.9260273972603 3.05753424657534 0 0 0 0 0 0 0
"3548" 64.9013698630137 63.9424657534247 4.27945205479452 0 0 0 0 0 0 0
"3549" 65.8739726027397 64.9150684931507 3.05753424657534 0 0 0 0 0 0 0
"3550" 68.1671232876712 68.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"3551" 70.1178082191781 70.8630136986301 3.05753424657534 0 0 0 0 0 0 0
"3552" 57.3178082191781 65.7260273972603 4.27945205479452 0 0 0 0 0 0 0
"3553" 58.2904109589041 66.6986301369863 3.05753424657534 0 0 0 0 0 0 0
"3554" 53.0164383561644 55.441095890411 4.27945205479452 0 0 0 0 0 0 0
"3555" 53.9890410958904 56.413698630137 3.05753424657534 0 0 0 0 0 0 0
"3556" 65.6602739726027 68.9534246575342 5.00821917808219 0 0 0 0 0 0 0
"3557" 67.6109589041096 70.9041095890411 3.05753424657534 0 0 0 0 0 0 0
"3558" 62.4301369863014 65.2904109589041 5.00821917808219 0 0 0 0 0 0 0
"3559" 65.4109589041096 65.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"3560" 65.4109589041096 65.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"3561" 66.1397260273973 67.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"3562" 63.7150684931507 67.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"3563" 55.5780821917808 61.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"3564" 58.0164383561644 60.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"3565" 57.9123287671233 66.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"3566" 64.572602739726 62.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"3567" 47.6821917808219 57.0684931506849 5.00821917808219 0 0 0 0 0 0 0
"3568" 54.4739726027397 56.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"3569" 64.7178082191781 65.3178082191781 2.60821917808219 0 0 0 0 0 0 0
"3570" 59.6767123287671 57.7945205479452 0.583561643835616 0 0 0 0 0 0 0
"3571" 65.0821917808219 65.5534246575343 2.4986301369863 1 0 0 0 0 0 0
"3572" 66.0054794520548 66.4767123287671 1.58356164383562 1 0 0 0 0 0 0
"3573" 60.4547945205479 64.7890410958904 2.4986301369863 1 0 0 0 0 0 0
"3574" 56.0027397260274 60.5753424657534 0.841095890410959 0 0 0 0 0 0 0
"3575" 64.2465753424657 63.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"3576" 66.8164383561644 70.2493150684931 1.88767123287671 0 0 0 0 0 0 0
"3577" 62.4575342465753 64.0027397260274 1.41917808219178 0 0 0 0 0 0 0
"3578" 52.6493150684932 71.7945205479452 2.91780821917808 1 0 0 0 0 0 0
"3579" 52.6493150684932 71.7945205479452 2.91780821917808 1 0 0 0 0 0 0
"3580" 52.6493150684932 71.7945205479452 2.91780821917808 1 0 0 0 0 0 0
"3581" 68.3150684931507 68.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"3582" 68.3150684931507 68.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"3583" 53.1972602739726 55.172602739726 5.00821917808219 0 0 0 0 0 0 0
"3584" 54.5643835616438 54.8547945205479 5.00821917808219 0 0 0 0 0 0 0
"3585" 59.3616438356164 60.1917808219178 1.58630136986301 0 0 0 0 0 0 0
"3586" 68.1342465753425 64.6328767123288 0.884931506849315 0 0 0 0 0 0 0
"3587" 59.1808219178082 65.1890410958904 5.00821917808219 0 0 0 0 0 0 0
"3588" 60.2465753424658 60.7315068493151 5 0 0 0 0 0 0 0
"3589" 56.0438356164384 64.6876712328767 2.83561643835616 1 0 0 0 0 0 0
"3590" 56.6219178082192 62.9808219178082 0.473972602739726 0 0 0 0 0 0 0
"3591" 64.7616438356164 64.813698630137 5.00821917808219 0 0 0 0 0 0 0
"3592" 63.4547945205479 65.2 1.42465753424658 0 0 0 0 0 0 0
"3593" 62.6821917808219 65.1013698630137 2.3041095890411 0 0 0 0 0 0 0
"3594" 63.4082191780822 64.9397260273973 2.32054794520548 0 0 0 0 0 0 0
"3595" 62.427397260274 64.8904109589041 0.252054794520548 0 0 0 0 0 0 0
"3596" 61.0712328767123 64.8356164383562 4.02739726027397 0 0 0 0 0 0 0
"3597" 62.0246575342466 66.5150684931507 5.00821917808219 0 0 0 0 0 0 0
"3598" 53.4575342465753 59.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"3599" 61.9835616438356 68.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"3600" 65.5479452054795 71.7150684931507 3.82465753424658 0 0 0 0 0 0 0
"3601" 62.1808219178082 63.9150684931507 2.98082191780822 0 0 0 0 0 0 0
"3602" 59.4246575342466 64.3917808219178 0.838356164383562 0 0 0 0 0 0 0
"3603" 79.9506849315069 79.2849315068493 1.4986301369863 0 0 0 1 0 0.216438356164384 0
"3604" 80.7068493150685 80.1123287671233 5.00821917808219 0 0 0 0 0 0 0
"3605" 60.7315068493151 66.6465753424658 0.271232876712329 0 0 0 0 0 0 0
"3606" 58.8657534246575 63.2712328767123 2.45753424657534 0 0 0 0 0 0 0
"3607" 56.772602739726 63.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"3608" 49.227397260274 54.841095890411 3.25205479452055 0 0 0 0 0 0 0
"3609" 54.2164383561644 61.3041095890411 0.915068493150685 0 0 0 0 0 0 0
"3610" 61.7671232876712 65.9178082191781 4.15342465753425 0 0 0 0 0 0 0
"3611" 69.3808219178082 72.1479452054794 5.00821917808219 0 0 0 0 0 0 0
"3612" 69.2712328767123 65.5095890410959 5.00821917808219 0 0 0 0 0 0 0
"3613" 64.5479452054795 67.4383561643836 5.00821917808219 0 0 0 0 0 0 0
"3614" 71.7315068493151 66.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"3615" 74.6109589041096 72.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"3616" 86.9260273972603 73.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"3617" 74.9342465753425 72.654794520548 5.00821917808219 0 0 0 0 0 0 0
"3618" 73.0356164383562 71.8 5.00821917808219 0 0 0 0 0 0 0
"3619" 70.1232876712329 70.6328767123288 4.66849315068493 1 0 0 0 0 0 0
"3620" 72.4438356164383 69.3068493150685 5.00821917808219 0 0 0 0 0 0 0
"3621" 71.0794520547945 69.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"3622" 64.4109589041096 68.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"3623" 73.7013698630137 65.0219178082192 5.00821917808219 0 0 0 0 0 0 0
"3624" 62.6438356164384 65.986301369863 5.00821917808219 0 0 0 0 0 0 0
"3625" 67.4438356164383 61.6465753424658 5.00821917808219 0 0 0 0 0 0 0
"3626" 65.4657534246575 65.1890410958904 3.58630136986301 0 0 0 0 0 0 0
"3627" 66.4301369863014 71.6438356164384 4.73698630136986 0 0 0 0 0 0 0
"3628" 61.9753424657534 62.5205479452055 3.58630136986301 0 0 0 0 0 0 0
"3629" 62.0383561643836 62.5835616438356 3.44109589041096 0 0 0 0 0 0 0
"3630" 55.5753424657534 64.3643835616438 3.33972602739726 0 0 0 0 0 0 0
"3631" 71.9232876712329 75.4219178082192 4.8 0 0 0 0 0 0 0
"3632" 72.7917808219178 69.4109589041096 4.42191780821918 0 1 0 0 0 0 0
"3633" 55.8465753424658 61.9205479452055 4.8 0 0 0 0 0 0 0
"3634" 53.4684931506849 54.0356164383562 4.8 0 0 0 0 0 0 0
"3635" 64.8246575342466 66.0027397260274 4.8 0 0 0 0 0 0 0
"3636" 59.6520547945205 71.9917808219178 3.0027397260274 1 0 0 0 0 0 0
"3637" 63.8657534246575 63.3123287671233 4.79452054794521 0 0 0 0 0 0 0
"3638" 66.2767123287671 74.5643835616438 4.8 0 0 0 0 0 0 0
"3639" 65.1068493150685 72.8657534246575 4.73698630136986 0 0 0 0 0 0 0
"3640" 65.2684931506849 65.5561643835617 4.75342465753425 0 0 0 0 0 0 0
"3641" 60.1232876712329 63.7671232876712 4.75342465753425 0 0 0 0 0 0 0
"3642" 59.7232876712329 66.9041095890411 4.75342465753425 0 0 0 0 0 0 0
"3643" 54.627397260274 71.2082191780822 4.75342465753425 0 0 0 0 0 0 0
"3644" 75.4246575342466 73.9506849315069 4.73698630136986 0 0 0 0 0 0 0
"3645" 73.1506849315068 73.3287671232877 4.73698630136986 0 0 0 0 0 0 0
"3646" 65.1315068493151 66.3616438356164 3.58904109589041 1 0 0 0 0 0 0
"3647" 60.0602739726027 60.6876712328767 4.0027397260274 1 0 0 0 0 0 0
"3648" 65.0630136986301 65.3095890410959 0.435616438356164 0 0 0 0 0 0 0
"3649" 66.3205479452055 65.427397260274 4.60547945205479 0 0 0 0 0 0 0
"3650" 61.3616438356164 62.213698630137 4.52876712328767 0 0 0 0 0 0 0
"3651" 62.7123287671233 67.3041095890411 4.52876712328767 0 0 0 0 0 0 0
"3652" 66.1095890410959 65.1095890410959 4.52876712328767 0 0 0 0 0 0 0
"3653" 64.8657534246575 69.8219178082192 1.08493150684932 0 1 0 0 0 0 0
"3654" 52.4356164383562 63.3232876712329 3.38356164383562 0 0 0 0 0 0 0
"3655" 66.7095890410959 65.1315068493151 2.92602739726027 0 0 0 0 0 0 0
"3656" 58.7260273972603 64.654794520548 4.03287671232877 0 0 0 0 0 0 0
"3657" 52.786301369863 64.8164383561644 0 0 0 0 0 0 0 0
"3658" 61.2849315068493 64.986301369863 0.213698630136986 0 0 0 0 0 0 0
"3659" 61.5972602739726 65.213698630137 3.99178082191781 0 0 0 0 0 0 0
"3660" 67.0219178082192 64.6767123287671 4.03287671232877 0 0 0 0 0 0 0
"3661" 56.3068493150685 59.2054794520548 2.82465753424658 0 0 0 0 0 0 0
"3662" 64.0246575342466 64.7643835616438 4.13150684931507 0 0 0 0 0 0 0
"3663" 59.172602739726 62.8684931506849 3.60547945205479 0 0 0 0 0 0 0
"3664" 63.5917808219178 68.241095890411 4.03835616438356 0 0 0 0 0 0 0
"3665" 57.3780821917808 66.186301369863 4.03835616438356 0 0 0 0 0 0 0
"3666" 69.3561643835616 65.4821917808219 4.03835616438356 0 0 0 0 0 0 0
"3667" 66.5369863013699 68.2739726027397 4.03835616438356 0 0 0 0 0 0 0
"3668" 58.2602739726027 57.9205479452055 4.03835616438356 0 0 0 0 0 0 0
"3669" 61.7150684931507 65.6054794520548 4.03835616438356 0 0 0 0 0 0 0
"3670" 60.2767123287671 63.0630136986301 4.03835616438356 0 0 0 0 0 0 0
"3671" 66.7095890410959 68.5917808219178 4.03835616438356 0 0 0 0 0 0 0
"3672" 54.9671232876712 58.0986301369863 4.03835616438356 0 0 0 0 0 0 0
"3673" 69.2821917808219 72.4849315068493 4.03835616438356 0 0 0 0 0 0 0
"3674" 53.0356164383562 56.9068493150685 3.94246575342466 0 0 0 0 0 0 0
"3675" 61.5150684931507 61.4246575342466 4.03835616438356 0 0 0 0 0 0 0
"3676" 68.9205479452055 74.0657534246575 4.03835616438356 0 0 0 0 0 0 0
"3677" 64.8465753424658 73.3753424657534 4.03835616438356 0 0 0 0 0 0 0
"3678" 49.1068493150685 57.5698630136986 4.03835616438356 0 0 0 0 0 0 0
"3679" 64.3616438356164 63.6931506849315 4.03835616438356 0 0 0 0 0 0 0
"3680" 61.4219178082192 66.2109589041096 4.03835616438356 0 0 0 0 0 0 0
"3681" 57.0849315068493 58.2575342465753 4.03835616438356 0 0 0 0 0 0 0
"3682" 74.8054794520548 66.3342465753425 4.03835616438356 0 0 0 0 0 0 0
"3683" 68.2657534246575 70.3917808219178 3.41643835616438 1 0 0 0 0 0 0
"3684" 57.1808219178082 57.2356164383562 4.03835616438356 0 0 0 0 0 0 0
"3685" 58.9808219178082 63.6849315068493 4.03835616438356 0 0 0 0 0 0 0
"3686" 52.5178082191781 55.9013698630137 4.03561643835616 0 0 0 0 0 0 0
"3687" 73.1643835616438 81.1342465753425 4.03835616438356 0 0 0 0 0 0 0
"3688" 42.027397260274 53.0657534246575 4.03835616438356 0 0 0 0 0 0 0
"3689" 60.1643835616438 62.3561643835616 4.03835616438356 0 0 0 0 0 0 0
"3690" 64.2438356164384 66.2958904109589 4.03835616438356 0 0 0 0 0 0 0
"3691" 58.5643835616438 73.5397260273973 4.03835616438356 0 0 0 0 0 0 0
"3692" 55.413698630137 58.5178082191781 4.03835616438356 0 0 0 0 0 0 0
"3693" 51.4191780821918 56.5123287671233 4.03835616438356 0 0 0 0 0 0 0
"3694" 67.9945205479452 67.9178082191781 4.03835616438356 0 0 0 0 0 0 0
"3695" 63.5123287671233 67.1808219178082 2.91780821917808 1 0 0 0 0 0 0
"3696" 63.5616438356164 61.972602739726 4.03835616438356 0 0 0 0 0 0 0
"3697" 58.0164383561644 57.9561643835616 3.33150684931507 1 0 0 0 0 0 0
"3698" 49.3452054794521 53.9342465753425 4.03835616438356 0 0 0 0 0 0 0
"3699" 59.786301369863 54.3287671232877 4.03835616438356 0 0 0 0 0 0 0
"3700" 53.7260273972603 53.3506849315068 4.03835616438356 0 0 0 0 0 0 0
"3701" 49.986301369863 53.8575342465753 4.03835616438356 0 0 0 0 0 0 0
"3702" 60.9643835616438 61.9205479452055 4.03835616438356 0 0 0 0 0 0 0
"3703" 53.2438356164384 54.3123287671233 4.03835616438356 0 0 0 0 0 0 0
"3704" 47.1835616438356 55.7972602739726 4.03835616438356 0 0 0 0 0 0 0
"3705" 55.0547945205479 60.0630136986301 4.03561643835616 0 0 0 0 0 0 0
"3706" 71.5205479452055 76.3123287671233 4.03835616438356 0 0 0 0 0 0 0
"3707" 64.6493150684932 61.8328767123288 4.03835616438356 0 0 0 0 0 0 0
"3708" 50.6739726027397 53.2547945205479 4.03835616438356 0 0 0 0 0 0 0
"3709" 66.0821917808219 74.3945205479452 3.91780821917808 1 0 0 0 0 0 0
"3710" 60.5479452054795 54.6109589041096 4.03835616438356 0 0 0 0 0 0 0
"3711" 64.6986301369863 64.6986301369863 4.03835616438356 0 0 0 0 0 0 0
"3712" 58.1917808219178 57.6849315068493 4.03835616438356 0 0 0 0 0 0 0
"3713" 52.2547945205479 61.6219178082192 4.03835616438356 0 0 0 0 0 0 0
"3714" 72.7041095890411 69.3397260273973 4.03835616438356 0 0 0 0 0 0 0
"3715" 53.1260273972603 55.6821917808219 4.03835616438356 0 0 0 0 0 0 0
"3716" 62.9287671232877 58.7178082191781 4.03835616438356 0 0 0 0 0 0 0
"3717" 60.3013698630137 69.4301369863014 4.03835616438356 0 0 0 0 0 0 0
"3718" 63.1479452054795 60.2 4.03835616438356 0 0 0 0 0 0 0
"3719" 40.841095890411 50.4986301369863 4.03835616438356 0 0 0 0 0 0 0
"3720" 51.3808219178082 52.0547945205479 4.03835616438356 0 0 0 0 0 0 0
"3721" 54.0164383561644 55.2849315068493 4.03835616438356 0 0 0 0 0 0 0
"3722" 55.2821917808219 59.0958904109589 4.03835616438356 0 0 0 0 0 0 0
"3723" 66.4986301369863 58.8876712328767 4.03835616438356 0 0 0 0 0 0 0
"3724" 55.4958904109589 56.8575342465753 4.03835616438356 0 0 0 0 0 0 0
"3725" 46.7698630136986 60.1561643835616 3.97808219178082 0 0 0 0 0 0 0
"3726" 60.5506849315069 62.1315068493151 3.9041095890411 0 0 0 0 0 0 0
"3727" 57.9616438356164 58.9369863013699 3.9041095890411 0 0 0 0 0 0 0
"3728" 54.241095890411 55.4876712328767 3.83835616438356 0 0 0 0 0 0 0
"3729" 57.0575342465753 59.2821917808219 3.9041095890411 0 0 0 0 0 0 0
"3730" 59.6191780821918 63.5671232876712 3.8958904109589 0 0 0 0 0 0 0
"3731" 59.6767123287671 63.6246575342466 3.76164383561644 0 0 0 0 0 0 0
"3732" 62.5917808219178 65.5342465753425 3.76986301369863 0 0 0 0 0 0 0
"3733" 62.2767123287671 65.3205479452055 2.45753424657534 0 0 0 0 0 0 0
"3734" 58.3424657534247 66.1506849315068 1.33698630136986 1 0 0 0 0 0 0
"3735" 66.227397260274 65.4547945205479 3.27945205479452 0 0 0 0 0 0 0
"3736" 66.2328767123288 65.4602739726027 3.10684931506849 0 0 0 0 0 0 0
"3737" 57.5890410958904 59.9890410958904 0.334246575342466 0 0 0 0 0 0 0
"3738" 54.4219178082192 56.627397260274 3.41917808219178 0 0 0 0 0 0 0
"3739" 59.1506849315069 61.572602739726 3.41917808219178 0 0 0 0 0 0 0
"3740" 60.4082191780822 63.4849315068493 3.41917808219178 0 0 0 0 0 0 0
"3741" 64.0739726027397 69.4986301369863 3.41917808219178 0 0 0 0 0 0 0
"3742" 58.0904109589041 58.8438356164384 3.41917808219178 0 0 0 0 0 0 0
"3743" 60.1945205479452 60.2904109589041 3.41917808219178 0 0 0 0 0 0 0
"3744" 63.6739726027397 67.1232876712329 3.41917808219178 0 0 0 0 0 0 0
"3745" 53.1561643835616 62.5342465753425 3.41917808219178 0 0 0 0 0 0 0
"3746" 64.3013698630137 68.2 3.33698630136986 1 0 0 0 0 0 0
"3747" 53.0383561643836 57.6301369863014 3.41917808219178 0 0 0 0 0 0 0
"3748" 65.1780821917808 66.5095890410959 3.41917808219178 0 0 0 0 0 0 0
"3749" 58.4164383561644 63.2821917808219 3.08493150684932 1 0 0 0 0 0 0
"3750" 70.3369863013699 67.572602739726 3.41917808219178 0 0 0 0 0 0 0
"3751" 76.0904109589041 77.5780821917808 0.750684931506849 1 0 0 0 0 0 0
"3752" 69.3972602739726 72.1232876712329 3.41917808219178 0 0 0 0 0 0 0
"3753" 51.3369863013699 57.1917808219178 3.41917808219178 0 0 0 0 0 0 0
"3754" 47.8191780821918 51.3397260273973 3.41917808219178 0 0 0 0 0 0 0
"3755" 66.7643835616438 70.1534246575342 3.41917808219178 0 0 0 0 0 0 0
"3756" 59.2794520547945 60.7397260273973 3.41917808219178 0 0 0 0 0 0 0
"3757" 57.2164383561644 58.8575342465753 3.41917808219178 0 0 0 0 0 0 0
"3758" 67.5205479452055 72.8986301369863 3.41917808219178 0 0 0 0 0 0 0
"3759" 62.6986301369863 59.2383561643836 3.41917808219178 0 0 0 0 0 0 0
"3760" 52.6027397260274 59.0356164383562 3.41917808219178 0 0 0 0 0 0 0
"3761" 61.0493150684932 66.9753424657534 3.41917808219178 0 0 0 0 0 0 0
"3762" 54.4986301369863 59.5424657534247 3.41917808219178 0 0 0 0 0 0 0
"3763" 57.4684931506849 58.9232876712329 0.421917808219178 1 0 0 0 0 0 0
"3764" 56.6164383561644 55.4657534246575 2.27397260273973 0 0 0 0 0 0 0
"3765" 69.654794520548 65.2739726027397 1.4986301369863 1 0 0 0 0 0 0
"3766" 59.9123287671233 61.441095890411 3.41917808219178 0 0 0 0 0 0 0
"3767" 53.6438356164384 63.0849315068493 3.41917808219178 0 0 0 0 0 0 0
"3768" 63.6164383561644 71.5506849315069 3.41917808219178 0 0 0 0 0 0 0
"3769" 61.6054794520548 64.3972602739726 3.41917808219178 0 0 0 0 0 0 0
"3770" 69.2356164383562 70.9315068493151 3.41917808219178 0 0 0 0 0 0 0
"3771" 63.6739726027397 64.8684931506849 0.112328767123288 1 0 0 0 0 0 0
"3772" 58.1479452054795 70.6438356164384 3.41917808219178 0 0 0 0 0 0 0
"3773" 59.0109589041096 72.3013698630137 3.41917808219178 0 0 0 0 0 0 0
"3774" 58.1890410958904 58.9452054794521 1.66575342465753 0 1 0 0 0 0 0
"3775" 51.3917808219178 52.9095890410959 3.41917808219178 0 0 0 0 0 0 0
"3776" 44.4109589041096 48.0986301369863 3.41917808219178 0 0 0 0 0 0 0
"3777" 67.9150684931507 69.9424657534247 3.41917808219178 0 0 0 0 0 0 0
"3778" 63.1561643835616 70.1260273972603 3.41917808219178 0 0 0 0 0 0 0
"3779" 50.2794520547945 68.2438356164384 3.41917808219178 0 0 0 0 0 0 0
"3780" 54.758904109589 61.5013698630137 3.41917808219178 0 0 0 0 0 0 0
"3781" 60.4630136986301 59.5068493150685 3.41917808219178 0 0 0 0 0 0 0
"3782" 76.3095890410959 79.7041095890411 3.41917808219178 0 0 0 0 0 0 0
"3783" 75.5369863013699 72.654794520548 3.41917808219178 0 0 0 0 0 0 0
"3784" 60.0876712328767 66.3835616438356 3.41917808219178 0 0 0 0 0 0 0
"3785" 71.6191780821918 76.9972602739726 3.33698630136986 0 1 0 0 0 0 0
"3786" 80.641095890411 74.1808219178082 3.41917808219178 0 0 0 0 0 0 0
"3787" 71.6575342465753 76.2986301369863 2.58356164383562 1 0 0 0 0 0 0
"3788" 66.9479452054795 76.9287671232877 0.421917808219178 1 0 0 0 0 0 0
"3789" 59.9397260273973 67.2684931506849 0.0821917808219178 1 0 0 0 0 0 0
"3790" 62.3397260273973 73.2794520547945 3.41917808219178 0 0 0 0 0 0 0
"3791" 74.2657534246575 82.0246575342466 0.117808219178082 1 0 0 0 0 0 0
"3792" 77.2219178082192 75.0931506849315 2.42191780821918 1 0 0 0 0 0 0
"3793" 49.6191780821918 55.8904109589041 3.41917808219178 0 0 0 0 0 0 0
"3794" 70.4219178082192 56.8958904109589 3.41917808219178 0 0 0 0 0 0 0
"3795" 67.0493150684931 64.6684931506849 3.41917808219178 0 0 0 0 0 0 0
"3796" 74.6575342465753 80.4219178082192 3.41917808219178 0 0 0 0 0 0 0
"3797" 63.8191780821918 69.4438356164383 3.41917808219178 0 0 0 0 0 0 0
"3798" 60.1972602739726 61.2876712328767 3.41917808219178 0 0 0 0 0 0 0
"3799" 66.0219178082192 71.7753424657534 1.58356164383562 1 0 0 0 0 0 0
"3800" 71.2246575342466 73.8246575342466 0.421917808219178 1 0 0 0 0 0 0
"3801" 67.7479452054795 73.5205479452055 3.41917808219178 0 0 0 0 0 0 0
"3802" 58.0054794520548 60.6 3.41917808219178 0 0 0 0 0 0 0
"3803" 80.0986301369863 80.0301369863014 3.41917808219178 0 0 0 0 0 0 0
"3804" 63.1780821917808 58.5808219178082 3.41917808219178 0 0 0 0 0 0 0
"3805" 59.9643835616438 59.8657534246575 3.41917808219178 0 0 0 0 0 0 0
"3806" 66.0794520547945 63.1945205479452 3.41917808219178 0 0 0 0 0 0 0
"3807" 66.2986301369863 66.841095890411 3.41917808219178 0 0 0 0 0 0 0
"3808" 60.9479452054794 64.7041095890411 3.41917808219178 0 0 0 0 0 0 0
"3809" 50.6684931506849 50.8958904109589 1.5041095890411 0 0 0 0 0 0 0
"3810" 48.4794520547945 49.1232876712329 3.41917808219178 0 0 0 0 0 0 0
"3811" 73.4794520547945 76.0739726027397 3.07671232876712 0 0 0 0 0 0 0
"3812" 72.7095890410959 72.6493150684932 3.41917808219178 0 0 0 0 0 0 0
"3813" 76.1534246575342 64.3506849315068 3.41917808219178 0 0 0 0 0 0 0
"3814" 75.1808219178082 79.4794520547945 2.66575342465753 1 0 0 0 0 0 0
"3815" 71.8794520547945 73.786301369863 3.41917808219178 0 0 0 0 0 0 0
"3816" 62.9616438356164 64.1890410958904 3.41917808219178 0 0 0 0 0 0 0
"3817" 64.8164383561644 70.9369863013699 3.41917808219178 0 0 0 0 0 0 0
"3818" 72.6794520547945 73.7890410958904 3.41917808219178 0 0 0 0 0 0 0
"3819" 61.3424657534247 70.5205479452055 3.41917808219178 0 0 0 0 0 0 0
"3820" 53.5917808219178 56.2986301369863 3.41917808219178 0 0 0 0 0 0 0
"3821" 64.9808219178082 67.5945205479452 3.41917808219178 0 0 0 0 0 0 0
"3822" 65.2191780821918 63.6191780821918 0.0821917808219178 0 1 0 0 0 0 0
"3823" 62.3068493150685 63.9917808219178 3.41917808219178 0 0 0 0 0 0 0
"3824" 48.1890410958904 54.3452054794521 3.41917808219178 0 0 0 0 0 0 0
"3825" 67.3561643835616 65.9068493150685 3.41917808219178 0 0 0 0 0 0 0
"3826" 59.4958904109589 64.2054794520548 3.41917808219178 0 0 0 0 0 0 0
"3827" 60.2712328767123 63.6657534246575 2.90684931506849 0 0 0 0 0 0 0
"3828" 65.7506849315069 64.4164383561644 3.41917808219178 0 0 0 0 0 0 0
"3829" 53.5890410958904 61.3534246575342 3.41917808219178 0 0 0 0 0 0 0
"3830" 74.6219178082192 76.2520547945205 1.66575342465753 1 0 0 0 0 0 0
"3831" 48.5287671232877 50.5808219178082 3.41917808219178 0 0 0 0 0 0 0
"3832" 52.7506849315068 65.4356164383562 1.83835616438356 0 0 0 0 0 0 0
"3833" 58.3041095890411 63.1123287671233 3.41917808219178 0 0 0 0 0 0 0
"3834" 52.7205479452055 54.158904109589 2.16712328767123 0 0 0 0 0 0 0
"3835" 54.8191780821918 55.027397260274 3.41917808219178 0 0 0 0 0 0 0
"3836" 70.4438356164383 78.5479452054795 2.0027397260274 0 0 0 1 0 1.33698630136986 0
"3837" 66.0164383561644 68.7808219178082 3.41917808219178 0 0 0 0 0 0 0
"3838" 66.9506849315069 68.7616438356164 1.33698630136986 1 0 0 0 0 0 0
"3839" 53.2821917808219 63.8356164383562 3.41917808219178 0 0 0 0 0 0 0
"3840" 60.6356164383562 67.1397260273973 3.41917808219178 0 0 0 0 0 0 0
"3841" 66.0027397260274 70.7013698630137 3.41917808219178 0 0 0 0 0 0 0
"3842" 68.2739726027397 64.2767123287671 0.583561643835616 0 1 0 0 0 0 0
"3843" 65.8821917808219 65.3232876712329 3.41917808219178 0 0 0 0 0 0 0
"3844" 62.2328767123288 63.1123287671233 0.161643835616438 0 1 0 0 0 0 0
"3845" 65.8164383561644 69.7506849315069 3.41917808219178 0 0 0 0 0 0 0
"3846" 73.1972602739726 79.2438356164384 0.832876712328767 1 0 0 0 0 0 0
"3847" 70.1753424657534 86.8027397260274 2.25205479452055 0 1 0 0 0 0 0
"3848" 80.3616438356164 77.1232876712329 2.4986301369863 0 0 0 1 0 0.802739726027397 0
"3849" 74.2356164383562 35.8712328767123 3.25205479452055 1 0 0 0 0 0 0
"3850" 76.8821917808219 78.1753424657534 3.41917808219178 0 0 0 0 0 0 0
"3851" 69.7643835616438 78.1178082191781 3.41917808219178 0 0 0 0 0 0 0
"3852" 61.1452054794521 63.1260273972603 3.41917808219178 0 0 0 0 0 0 0
"3853" 56.9452054794521 68.5123287671233 3.41917808219178 0 0 0 0 0 0 0
"3854" 63.1698630136986 64.186301369863 3.41917808219178 0 0 0 0 0 0 0
"3855" 85.6356164383562 88.8794520547945 2.16986301369863 1 0 0 0 0 0 0
"3856" 66.4958904109589 69.8958904109589 3.41917808219178 0 0 0 0 0 0 0
"3857" 61.5095890410959 60.5534246575342 3.41917808219178 0 0 0 0 0 0 0
"3858" 61.4 60.1369863013699 2.5041095890411 0 0 0 0 0 0 0
"3859" 64.3698630136986 72.0164383561644 3.41917808219178 0 0 0 0 0 0 0
"3860" 69.3178082191781 66.3287671232877 3.41917808219178 0 0 0 0 0 0 0
"3861" 46.2767123287671 48.9150684931507 3.41917808219178 0 0 0 0 0 0 0
"3862" 57.1534246575342 57.3369863013699 2.33424657534247 0 0 0 0 0 0 0
"3863" 66.7945205479452 66.9424657534247 3.41917808219178 0 0 0 0 0 0 0
"3864" 51.5178082191781 52.3780821917808 3.41917808219178 0 0 0 0 0 0 0
"3865" 60.3287671232877 63.1205479452055 3.41917808219178 0 0 0 0 0 0 0
"3866" 52.213698630137 59.0493150684932 3.41917808219178 0 0 0 0 0 0 0
"3867" 66.7479452054795 68.3616438356164 3.41917808219178 0 0 0 0 0 0 0
"3868" 64.1150684931507 69.172602739726 3.41917808219178 0 0 0 0 0 0 0
"3869" 52.6849315068493 61.0301369863014 3.41917808219178 0 0 0 0 0 0 0
"3870" 67.9808219178082 74.1205479452055 3.41917808219178 0 0 0 0 0 0 0
"3871" 56.3178082191781 59.8054794520548 3.41917808219178 0 0 0 0 0 0 0
"3872" 58.9424657534247 62.4986301369863 3.41917808219178 0 0 0 0 0 0 0
"3873" 65.2739726027397 63.772602739726 3.41917808219178 0 0 0 0 0 0 0
"3874" 53.5890410958904 62.3397260273973 3.41917808219178 0 0 0 0 0 0 0
"3875" 62.4712328767123 66.3178082191781 3.41917808219178 0 0 0 0 0 0 0
"3876" 48.4 46.0383561643836 3.41917808219178 0 0 0 0 0 0 0
"3877" 70.0164383561644 57.3534246575342 3.41917808219178 0 0 0 0 0 0 0
"3878" 54.9424657534247 55.5506849315069 3.41917808219178 0 0 0 0 0 0 0
"3879" 53.4493150684931 59.7643835616438 3.41917808219178 0 0 0 0 0 0 0
"3880" 54.9369863013699 62.3397260273973 3.41917808219178 0 0 0 0 0 0 0
"3881" 60.1835616438356 58.5452054794521 2.5041095890411 0 0 0 0 0 0 0
"3882" 51.9123287671233 55.5342465753425 3.41917808219178 0 0 0 0 0 0 0
"3883" 58.0739726027397 65.4657534246575 3.41917808219178 0 0 0 0 0 0 0
"3884" 76.3753424657534 80.8027397260274 3.41917808219178 0 0 0 0 0 0 0
"3885" 64.0602739726027 66.3753424657534 3.41917808219178 0 0 0 0 0 0 0
"3886" 51.6547945205479 59.5616438356164 3.41917808219178 0 0 0 0 0 0 0
"3887" 68.1917808219178 70.9178082191781 0.421917808219178 1 0 0 0 0 0 0
"3888" 58.9178082191781 57.9698630136986 3.41917808219178 0 0 0 0 0 0 0
"3889" 62.7972602739726 63.3835616438356 3.41917808219178 0 0 0 0 0 0 0
"3890" 63.9890410958904 69.6383561643836 3.41917808219178 0 0 0 0 0 0 0
"3891" 62.5890410958904 63.841095890411 3.41917808219178 0 0 0 0 0 0 0
"3892" 55.6849315068493 57.9123287671233 3.41917808219178 0 0 0 0 0 0 0
"3893" 62.7178082191781 59.2575342465753 3.41917808219178 0 0 0 0 0 0 0
"3894" 67.427397260274 66.6054794520548 3.41917808219178 0 0 0 0 0 0 0
"3895" 50.7397260273973 60.3835616438356 2.9972602739726 0 0 0 0 0 0 0
"3896" 55.3780821917808 62.3945205479452 3.41917808219178 0 0 0 0 0 0 0
"3897" 49.5835616438356 56.986301369863 3.41917808219178 0 0 0 0 0 0 0
"3898" 64.2164383561644 65.0328767123288 3.41917808219178 0 0 0 0 0 0 0
"3899" 56.4876712328767 59.8465753424658 3.41917808219178 0 0 0 0 0 0 0
"3900" 69.9315068493151 67.4082191780822 3.41917808219178 0 0 0 0 0 0 0
"3901" 54.3424657534247 57.1123287671233 3.41917808219178 0 0 0 0 0 0 0
"3902" 66.7232876712329 66.2301369863014 3.41917808219178 0 0 0 0 0 0 0
"3903" 60.5041095890411 63.5260273972603 3.41917808219178 0 0 0 0 0 0 0
"3904" 57.3945205479452 62.6547945205479 3.41917808219178 0 0 0 0 0 0 0
"3905" 52.7917808219178 64.1945205479452 3.41917808219178 0 0 0 0 0 0 0
"3906" 63.4191780821918 69.372602739726 3.41917808219178 0 0 0 0 0 0 0
"3907" 74.8794520547945 80.5506849315069 3.41917808219178 0 0 0 0 0 0 0
"3908" 65.2493150684931 66.5643835616438 3.41917808219178 0 0 0 0 0 0 0
"3909" 79.972602739726 82.2602739726027 3.41917808219178 0 0 0 0 0 0 0
"3910" 58.9643835616438 60.0191780821918 3.41917808219178 0 0 0 0 0 0 0
"3911" 68.3205479452055 65.0493150684931 3.41917808219178 0 0 0 0 0 0 0
"3912" 67.3972602739726 72.4739726027397 3.41917808219178 0 0 0 0 0 0 0
"3913" 82.5561643835617 82.4328767123288 3.41917808219178 0 0 0 0 0 0 0
"3914" 66.4575342465753 67.1095890410959 3.25205479452055 1 0 0 0 0 0 0
"3915" 59.1041095890411 64.4027397260274 3.41917808219178 0 0 0 0 0 0 0
"3916" 70.1753424657534 72.7068493150685 1.91780821917808 1 0 0 0 0 0 0
"3917" 65.0219178082192 66.5534246575343 3.41917808219178 0 0 0 0 0 0 0
"3918" 62.6356164383562 65.013698630137 0.419178082191781 0 0 0 0 0 0 0
"3919" 60.0904109589041 64.5287671232877 3.41917808219178 0 0 0 0 0 0 0
"3920" 75.972602739726 83.3369863013699 2.42191780821918 1 0 0 0 0 0 0
"3921" 61.958904109589 68.2767123287671 3.41917808219178 0 0 0 0 0 0 0
"3922" 64.6520547945206 62.2493150684932 2.90684931506849 0 0 0 0 0 0 0
"3923" 50.8575342465753 54.6821917808219 2 0 0 0 0 0 0 0
"3924" 54.7561643835616 61.2794520547945 3.41917808219178 0 0 0 0 0 0 0
"3925" 60.441095890411 68.5698630136986 3.41917808219178 0 0 0 0 0 0 0
"3926" 62.8438356164384 61.6712328767123 3.41917808219178 0 0 0 0 0 0 0
"3927" 55.1643835616438 58.5534246575342 3.41917808219178 0 0 0 0 0 0 0
"3928" 49.827397260274 63.413698630137 3.41917808219178 0 0 0 0 0 0 0
"3929" 67.9643835616438 75.9671232876712 1.58356164383562 1 0 0 0 0 0 0
"3930" 66.1095890410959 70.8219178082192 3.41917808219178 0 0 0 0 0 0 0
"3931" 57.2520547945205 65.4739726027397 3.41917808219178 0 0 0 0 0 0 0
"3932" 72.3616438356164 70.2520547945205 3.41917808219178 0 0 0 0 0 0 0
"3933" 62.8493150684931 62.627397260274 3.41917808219178 0 0 0 0 0 0 0
"3934" 63.613698630137 62.8712328767123 3.41917808219178 0 0 0 0 0 0 0
"3935" 51.4575342465753 65.0876712328767 3.41917808219178 0 0 0 0 0 0 0
"3936" 52.6986301369863 58.5178082191781 3.41917808219178 0 0 0 0 0 0 0
"3937" 54.0821917808219 56.1452054794521 0.419178082191781 0 0 0 0 0 0 0
"3938" 73.0876712328767 74.7315068493151 1.4986301369863 1 0 0 0 0 0 0
"3939" 72.7506849315069 86.4 3.41917808219178 0 0 0 0 0 0 0
"3940" 55.4739726027397 60.5698630136986 3.41917808219178 0 0 0 0 0 0 0
"3941" 65.2027397260274 77.2630136986301 3.41917808219178 0 0 0 0 0 0 0
"3942" 53.5068493150685 55.5698630136986 3.41917808219178 0 0 0 0 0 0 0
"3943" 77.4904109589041 80.9424657534247 3.41917808219178 0 0 0 0 0 0 0
"3944" 59.9397260273973 67.3780821917808 1.0027397260274 1 0 0 0 0 0 0
"3945" 77.2739726027397 76.0986301369863 3.41917808219178 0 0 0 0 0 0 0
"3946" 56.4986301369863 69.9150684931507 3.41917808219178 0 0 0 0 0 0 0
"3947" 53.4630136986301 59.9287671232877 3.41917808219178 0 0 0 0 0 0 0
"3948" 73.3698630136986 68.9479452054795 3.41917808219178 0 0 0 0 0 0 0
"3949" 71.4767123287671 76.3698630136986 3.41917808219178 0 0 0 0 0 0 0
"3950" 69.0219178082192 69.9616438356164 3.41917808219178 0 0 0 0 0 0 0
"3951" 65.6684931506849 69.0630136986301 3.41917808219178 0 0 0 0 0 0 0
"3952" 74.3561643835616 74.9178082191781 3.41917808219178 0 0 0 0 0 0 0
"3953" 61.3698630136986 70.7780821917808 3.41917808219178 0 0 0 0 0 0 0
"3954" 68.386301369863 66.1205479452055 3.41917808219178 0 0 0 0 0 0 0
"3955" 72.7315068493151 76.5808219178082 3.41917808219178 0 0 0 0 0 0 0
"3956" 71.0465753424658 73.3506849315068 3.41917808219178 0 0 0 0 0 0 0
"3957" 64.3232876712329 73.8575342465753 3.41917808219178 0 0 0 0 0 0 0
"3958" 72.9260273972603 77.827397260274 3.41917808219178 0 0 0 0 0 0 0
"3959" 58.5780821917808 62.4109589041096 3.41917808219178 0 0 0 0 0 0 0
"3960" 65.3534246575342 60.2246575342466 3.41917808219178 0 0 0 0 0 0 0
"3961" 64.1315068493151 64.2904109589041 3.41917808219178 0 0 0 0 0 0 0
"3962" 66.4794520547945 77.227397260274 3.41917808219178 0 0 0 0 0 0 0
"3963" 70.7150684931507 65.7534246575343 3.41917808219178 0 0 0 0 0 0 0
"3964" 66.2739726027397 74.5260273972603 3.41917808219178 0 0 0 0 0 0 0
"3965" 68.0767123287671 70.1534246575342 3.41917808219178 0 0 0 0 0 0 0
"3966" 56.7506849315068 58.9068493150685 3.41917808219178 0 0 0 0 0 0 0
"3967" 65.0657534246575 65.772602739726 3.41917808219178 0 0 0 0 0 0 0
"3968" 76.6054794520548 82.0931506849315 1.75068493150685 1 0 0 0 0 0 0
"3969" 67.9150684931507 72.8602739726027 3.41917808219178 0 0 0 0 0 0 0
"3970" 64.6027397260274 70.654794520548 3.41917808219178 0 0 0 0 0 0 0
"3971" 85.4630136986301 85.227397260274 3.41917808219178 0 0 0 0 0 0 0
"3972" 75.8767123287671 74.0684931506849 3.41917808219178 0 0 0 0 0 0 0
"3973" 66.2356164383562 70.5068493150685 3.41917808219178 0 0 0 0 0 0 0
"3974" 76.6684931506849 79.3232876712329 2.16986301369863 1 0 0 0 0 0 0
"3975" 70.4958904109589 77.2630136986301 0.178082191780822 0 1 0 0 0 0 0
"3976" 65.6904109589041 73.8027397260274 3.41917808219178 0 0 0 0 0 0 0
"3977" 77.0657534246575 75.7041095890411 3.41917808219178 0 0 0 0 0 0 0
"3978" 84.3972602739726 85.0109589041096 3.41917808219178 0 0 0 0 0 0 0
"3979" 75.8712328767123 75.7123287671233 0.265753424657534 0 1 0 0 0 0 0
"3980" 57.2 66.7068493150685 3.41917808219178 0 0 0 0 0 0 0
"3981" 62.9178082191781 65.6109589041096 3.41917808219178 0 0 0 0 0 0 0
"3982" 59.4191780821918 65.227397260274 3.41917808219178 0 0 0 0 0 0 0
"3983" 66.7561643835616 69.9890410958904 0.750684931506849 1 0 0 0 0 0 0
"3984" 71.7506849315069 69.1561643835616 3.41917808219178 0 0 0 0 0 0 0
"3985" 59.2438356164384 63.4520547945205 3.41917808219178 0 0 0 0 0 0 0
"3986" 61.6246575342466 60.8684931506849 3.41917808219178 0 0 0 0 0 0 0
"3987" 52.641095890411 58.2328767123288 3.41917808219178 0 0 0 0 0 0 0
"3988" 56.9178082191781 63.2520547945205 3.41917808219178 0 0 0 0 0 0 0
"3989" 61.7698630136986 66.5479452054795 3.41917808219178 0 0 0 0 0 0 0
"3990" 51.9917808219178 56.0520547945206 3.41917808219178 0 0 0 0 0 0 0
"3991" 79.027397260274 78.4767123287671 3.41917808219178 0 0 0 0 0 0 0
"3992" 87.0109589041096 76.2219178082192 3.41917808219178 0 0 0 0 0 0 0
"3993" 52.1260273972603 58.2849315068493 3.41917808219178 0 0 0 0 0 0 0
"3994" 85.654794520548 79.1178082191781 2.58356164383562 1 0 0 0 0 0 0
"3995" 65.1068493150685 64.7095890410959 3.41917808219178 0 0 0 0 0 0 0
"3996" 57.1753424657534 58.1260273972603 3.41917808219178 0 0 0 0 0 0 0
"3997" 52.2109589041096 54.5397260273973 3.41917808219178 0 0 0 0 0 0 0
"3998" 47.786301369863 53.9178082191781 3.41917808219178 0 0 0 0 0 0 0
"3999" 63.9424657534247 65.8 3.41917808219178 0 0 0 0 0 0 0
"4000" 55.8054794520548 60.9260273972603 3.41917808219178 0 0 0 0 0 0 0
"4001" 60.5424657534247 65.2219178082192 3.41917808219178 0 0 0 0 0 0 0
"4002" 66.6328767123288 66.4191780821918 3.41917808219178 0 0 0 0 0 0 0
"4003" 59 64.8712328767123 3.41917808219178 0 0 0 0 0 0 0
"4004" 59.1041095890411 59.2109589041096 3.41917808219178 0 0 0 0 0 0 0
"4005" 74.3534246575342 81.6767123287671 2.91780821917808 1 0 0 0 0 0 0
"4006" 67.0027397260274 67.8986301369863 2.83287671232877 1 0 0 0 0 0 0
"4007" 63.0356164383562 58.2356164383562 2.83287671232877 1 0 0 0 0 0 0
"4008" 57.172602739726 61.1369863013699 3.41917808219178 0 0 0 0 0 0 0
"4009" 67.8931506849315 65.1095890410959 0 0 0 0 0 0 0 0
"4010" 54.4684931506849 56.4657534246575 3.41917808219178 0 0 0 0 0 0 0
"4011" 60.7287671232877 64.5342465753425 3.41917808219178 0 0 0 0 0 0 0
"4012" 81.2904109589041 78.2027397260274 3.41917808219178 0 0 0 0 0 0 0
"4013" 63.8219178082192 76.0383561643836 3.41917808219178 0 0 0 0 0 0 0
"4014" 50.2191780821918 67.6301369863014 3.41917808219178 0 0 0 0 0 0 0
"4015" 55.4164383561644 66.3534246575342 3.41917808219178 0 0 0 0 0 0 0
"4016" 70.1671232876712 71.8520547945206 3.41917808219178 0 0 0 0 0 0 0
"4017" 70.3068493150685 74.3753424657534 1.25205479452055 1 0 0 0 0 0 0
"4018" 66.9041095890411 68.2356164383562 3.41917808219178 0 0 0 0 0 0 0
"4019" 72.9808219178082 82.9506849315069 3.41917808219178 0 0 0 0 0 0 0
"4020" 62.2328767123288 68.0986301369863 3.41917808219178 0 0 0 0 0 0 0
"4021" 56.5260273972603 61.5178082191781 3.41917808219178 0 0 0 0 0 0 0
"4022" 46.7643835616438 55.4520547945205 3.41917808219178 0 0 0 0 0 0 0
"4023" 63.5369863013699 68.1972602739726 2.83013698630137 0 0 0 0 0 0 0
"4024" 52.9808219178082 53.1095890410959 3.41917808219178 0 0 0 0 0 0 0
"4025" 56.6602739726027 68.1698630136986 3.41917808219178 0 0 0 0 0 0 0
"4026" 73.558904109589 79.4602739726027 1.25205479452055 1 0 0 0 0 0 0
"4027" 49.4739726027397 55.2794520547945 3.41917808219178 0 0 0 0 0 0 0
"4028" 69.9315068493151 74.4849315068493 3.41917808219178 0 0 0 0 0 0 0
"4029" 71.5123287671233 67.5232876712329 3.41917808219178 0 0 0 0 0 0 0
"4030" 66.0438356164384 66.2 3.41917808219178 0 0 0 0 0 0 0
"4031" 84.7315068493151 83.4027397260274 3.08493150684932 1 0 0 0 0 0 0
"4032" 61 61.8191780821918 3.08493150684932 0 1 0 0 0 0 0
"4033" 55.2520547945205 58.5315068493151 3.41917808219178 0 0 0 0 0 0 0
"4034" 65.641095890411 64.772602739726 3.41917808219178 0 0 0 0 0 0 0
"4035" 81.3123287671233 84.3835616438356 3.41917808219178 0 0 0 0 0 0 0
"4036" 70.5479452054795 79.6904109589041 3.41917808219178 0 0 0 0 0 0 0
"4037" 81.5917808219178 79.3698630136986 2.58356164383562 1 0 0 0 0 0 0
"4038" 66.2876712328767 72.0465753424658 3.41917808219178 0 0 0 0 0 0 0
"4039" 56.5479452054795 58.8767123287671 3.41917808219178 0 0 0 0 0 0 0
"4040" 57.8849315068493 65.6849315068493 3.41917808219178 0 0 0 0 0 0 0
"4041" 59.9506849315068 62.8191780821918 3.41917808219178 0 0 0 0 0 0 0
"4042" 69.1150684931507 73.2219178082192 3.41917808219178 0 0 0 0 0 0 0
"4043" 66.7561643835616 68.8246575342466 3.41917808219178 0 0 0 0 0 0 0
"4044" 60.9808219178082 55.5753424657534 3.41917808219178 0 0 0 0 0 0 0
"4045" 51.2493150684932 60.7561643835616 3.41917808219178 0 0 0 0 0 0 0
"4046" 67.758904109589 71.4191780821918 3.41917808219178 0 0 0 0 0 0 0
"4047" 61.4657534246575 73.5534246575343 3.41917808219178 0 0 0 0 0 0 0
"4048" 59.3452054794521 68.9205479452055 3.41917808219178 0 0 0 0 0 0 0
"4049" 66.358904109589 73.7671232876712 0.917808219178082 1 0 0 0 0 0 0
"4050" 77.2438356164384 79.0821917808219 3.41917808219178 0 0 0 0 0 0 0
"4051" 71.8821917808219 77.6109589041096 3.41917808219178 0 0 0 0 0 0 0
"4052" 70.6986301369863 71.0821917808219 0 0 0 0 1 0 1.16986301369863 0
"4053" 72.2904109589041 82.7041095890411 3.41917808219178 0 0 0 0 0 0 0
"4054" 55.5068493150685 59.641095890411 1.0027397260274 1 0 0 0 0 0 0
"4055" 71.1369863013699 68.013698630137 3.41917808219178 0 0 0 0 0 0 0
"4056" 69.7561643835616 70.0520547945205 3.41917808219178 0 0 0 0 0 0 0
"4057" 73.1452054794521 78.8849315068493 0.832876712328767 1 0 0 0 0 0 0
"4058" 77.3315068493151 84.386301369863 0.246575342465753 1 0 0 0 0 0 0
"4059" 66.227397260274 79.7945205479452 3.41917808219178 0 0 0 0 0 0 0
"4060" 66.6246575342466 63.8301369863014 3.41917808219178 0 0 0 0 0 0 0
"4061" 59.5095890410959 71.6849315068493 3.41917808219178 0 0 0 0 0 0 0
"4062" 64.3068493150685 65.5506849315069 3.41917808219178 0 0 0 0 0 0 0
"4063" 58.1041095890411 65.4465753424657 3.41917808219178 0 0 0 0 0 0 0
"4064" 72.9616438356164 74.9452054794521 1.25205479452055 1 0 0 0 0 0 0
"4065" 66.358904109589 67.6904109589041 3.41917808219178 0 0 0 0 0 0 0
"4066" 51.7315068493151 57.5753424657534 3.41917808219178 0 0 0 0 0 0 0
"4067" 68.6438356164384 68.0794520547945 2.75068493150685 1 0 0 0 0 0 0
"4068" 63.0657534246575 76.4493150684931 0.917808219178082 1 0 0 0 0 0 0
"4069" 70.8246575342466 71.3972602739726 3.41917808219178 0 0 0 0 0 0 0
"4070" 64.9369863013699 72.7397260273973 2.42191780821918 1 0 0 0 0 0 0
"4071" 64.413698630137 64.3698630136986 3.41917808219178 0 0 0 0 0 0 0
"4072" 64.9616438356164 76.6684931506849 3.41917808219178 0 0 0 0 0 0 0
"4073" 52.2054794520548 62.5643835616438 3.41917808219178 0 0 0 0 0 0 0
"4074" 73.1178082191781 76.2931506849315 1.91780821917808 1 0 0 0 0 0 0
"4075" 51.9205479452055 64.386301369863 3.41917808219178 0 0 0 0 0 0 0
"4076" 66.3698630136986 70.5095890410959 3.41917808219178 0 0 0 0 0 0 0
"4077" 84.5917808219178 89.8931506849315 3.41917808219178 0 0 0 0 0 0 0
"4078" 54.7287671232877 60.4904109589041 3.41917808219178 0 0 0 0 0 0 0
"4079" 69.0301369863014 70.5945205479452 3.41917808219178 0 0 0 0 0 0 0
"4080" 68.6465753424658 67.4904109589041 3.41917808219178 0 0 0 0 0 0 0
"4081" 60.7041095890411 68.4712328767123 3.41917808219178 0 0 0 0 0 0 0
"4082" 53.0082191780822 59.2164383561644 3.41917808219178 0 0 0 0 0 0 0
"4083" 69.2164383561644 70.7342465753425 3.41917808219178 0 0 0 0 0 0 0
"4084" 64.786301369863 66.7561643835616 3.41917808219178 0 0 0 0 0 0 0
"4085" 66.9945205479452 67.6986301369863 3.41917808219178 0 0 0 0 0 0 0
"4086" 72.2904109589041 69.6383561643836 3.41917808219178 0 0 0 0 0 0 0
"4087" 74.958904109589 80.7643835616438 2.08493150684932 1 0 0 0 0 0 0
"4088" 73.4 70.6712328767123 3.41917808219178 0 0 0 0 0 0 0
"4089" 76.6849315068493 77.2301369863014 3.41917808219178 0 0 0 0 0 0 0
"4090" 64.7013698630137 68.4986301369863 3.41917808219178 0 0 0 0 0 0 0
"4091" 64.8328767123288 66.6821917808219 3.41917808219178 0 0 0 0 0 0 0
"4092" 67.3917808219178 73.4520547945205 3.41917808219178 0 0 0 0 0 0 0
"4093" 63.1506849315069 57.9013698630137 3.41917808219178 0 0 0 0 0 0 0
"4094" 61.3972602739726 64.0684931506849 3.41917808219178 0 0 0 0 0 0 0
"4095" 59.7123287671233 68.6191780821918 3.41917808219178 0 0 0 0 0 0 0
"4096" 60.8383561643836 56.7479452054795 2.42191780821918 1 0 0 0 0 0 0
"4097" 60.2547945205479 67.8027397260274 3.41917808219178 0 0 0 0 0 0 0
"4098" 68.7013698630137 76.5232876712329 3.41917808219178 0 0 0 0 0 0 0
"4099" 71.0301369863014 73.4493150684931 3.41917808219178 0 0 0 0 0 0 0
"4100" 54.1315068493151 61.7260273972603 3.41917808219178 0 0 0 0 0 0 0
"4101" 78.6246575342466 82.5150684931507 3.41917808219178 0 0 0 0 0 0 0
"4102" 67.2602739726027 66.8465753424658 3.41917808219178 0 0 0 0 0 0 0
"4103" 59.0876712328767 61.6575342465753 2.33698630136986 1 0 0 0 0 0 0
"4104" 77.1315068493151 80.7424657534247 3.08493150684932 1 0 0 0 0 0 0
"4105" 88.0684931506849 71.5561643835617 3.41917808219178 0 0 0 0 0 0 0
"4106" 76.1287671232877 73.6 3.41917808219178 0 0 0 0 0 0 0
"4107" 73.8383561643836 73.0301369863014 3.41917808219178 0 0 0 0 0 0 0
"4108" 79.7041095890411 83.6465753424658 3.08493150684932 1 0 0 0 0 0 0
"4109" 72.1780821917808 67.5205479452055 1.91780821917808 1 0 0 0 0 0 0
"4110" 64.3260273972603 67.5068493150685 2.0027397260274 1 0 0 0 0 0 0
"4111" 67.7150684931507 67.0630136986301 3.41917808219178 0 0 0 0 0 0 0
"4112" 66.6246575342466 68.9424657534247 3.41917808219178 0 0 0 0 0 0 0
"4113" 66.372602739726 75.0712328767123 3.41917808219178 0 0 0 0 0 0 0
"4114" 58.027397260274 64.5095890410959 3.41917808219178 0 0 0 0 0 0 0
"4115" 53.9808219178082 60.0383561643836 0.0821917808219178 0 0 0 0 0 0 0
"4116" 69.1561643835616 73.3506849315068 0.498630136986301 1 0 0 0 0 0 0
"4117" 54.0027397260274 62.4575342465753 0.504109589041096 0 0 0 0 0 0 0
"4118" 55.1452054794521 58.7780821917808 2.41917808219178 0 0 0 0 0 0 0
"4119" 54.4164383561644 65.1424657534247 2.42191780821918 1 0 0 0 0 0 0
"4120" 58.5890410958904 71.4821917808219 3.41917808219178 0 0 0 0 0 0 0
"4121" 57.7041095890411 64.0958904109589 3.41917808219178 0 0 0 0 0 0 0
"4122" 50.9671232876712 52.6027397260274 0.504109589041096 0 0 0 0 0 0 0
"4123" 46.9041095890411 53.5917808219178 3.41917808219178 0 0 0 0 0 0 0
"4124" 66.2931506849315 65.3232876712329 3.41917808219178 0 0 0 0 0 0 0
"4125" 72.6 75.8602739726027 1.66575342465753 0 1 0 0 0 0 0
"4126" 85.7561643835616 85.6739726027397 3.41917808219178 0 0 0 0 0 0 0
"4127" 71.3123287671233 66.6931506849315 3.41917808219178 0 0 0 0 0 0 0
"4128" 59.6849315068493 63.827397260274 3.41917808219178 0 0 0 0 0 0 0
"4129" 63.0191780821918 62.7643835616438 3.41917808219178 0 0 0 0 0 0 0
"4130" 65.958904109589 71.172602739726 3.41917808219178 0 0 0 0 0 0 0
"4131" 69.972602739726 73.3369863013699 3.41917808219178 0 0 0 0 0 0 0
"4132" 52.9232876712329 61.1780821917808 3.41917808219178 0 0 0 0 0 0 0
"4133" 52.0630136986301 55.9671232876712 3.41917808219178 0 0 0 0 0 0 0
"4134" 64.9178082191781 68.0493150684931 1.33698630136986 1 0 0 0 0 0 0
"4135" 63.2657534246575 64.2630136986301 3.41917808219178 0 0 0 0 0 0 0
"4136" 75.6794520547945 73.3095890410959 3.41917808219178 0 0 0 0 0 0 0
"4137" 53.1315068493151 59.0246575342466 3.41917808219178 0 0 0 0 0 0 0
"4138" 61.6 62.5698630136986 3.41917808219178 0 0 0 0 0 0 0
"4139" 64.5178082191781 76.0630136986301 3.41917808219178 0 0 0 0 0 0 0
"4140" 74.0904109589041 78.4657534246575 3.41917808219178 0 0 0 0 0 0 0
"4141" 58.8 66.6109589041096 3.41917808219178 0 0 0 0 0 0 0
"4142" 40.0164383561644 57.3424657534247 3.41917808219178 0 0 0 0 0 0 0
"4143" 67.7068493150685 69.8739726027397 3.41917808219178 0 0 0 0 0 0 0
"4144" 43.7123287671233 66.5369863013699 3.41917808219178 0 0 0 0 0 0 0
"4145" 50.9808219178082 51.1068493150685 3.41917808219178 0 0 0 0 0 0 0
"4146" 66.5835616438356 71.7397260273973 3.41917808219178 0 0 0 0 0 0 0
"4147" 70.9616438356164 72.7424657534247 3.41917808219178 0 0 0 0 0 0 0
"4148" 56.4657534246575 59.8520547945205 3.41917808219178 0 0 0 0 0 0 0
"4149" 70.3178082191781 82.6383561643836 3.41917808219178 0 0 0 0 0 0 0
"4150" 67.4328767123288 63.9945205479452 0 0 0 0 0 1 0 0.917808219178082
"4151" 66.2712328767123 71.8986301369863 3.41917808219178 0 0 0 0 0 0 0
"4152" 63.3917808219178 59.5808219178082 3.41917808219178 0 0 0 0 0 0 0
"4153" 60.358904109589 60.8684931506849 3.41917808219178 0 0 0 0 0 0 0
"4154" 63.4602739726027 62.2602739726027 2.58082191780822 0 0 0 0 0 0 0
"4155" 56.2684931506849 65.3835616438356 3.41917808219178 0 0 0 0 0 0 0
"4156" 62.0876712328767 64.9972602739726 3.41917808219178 0 0 0 0 0 0 0
"4157" 65.5835616438356 68.5123287671233 3.41917808219178 0 0 0 0 0 0 0
"4158" 57.0712328767123 56.7972602739726 3.41917808219178 0 0 0 0 0 0 0
"4159" 67.027397260274 68.8602739726027 3.41917808219178 0 0 0 0 0 0 0
"4160" 54.3945205479452 62.8849315068493 3.41917808219178 0 0 0 0 0 0 0
"4161" 53.1479452054795 59.2438356164384 3.41917808219178 0 0 0 0 0 0 0
"4162" 36.3315068493151 37.4328767123288 1.42191780821918 0 1 0 0 0 0 0
"4163" 58.0164383561644 64.6164383561644 3.41917808219178 0 0 0 0 0 0 0
"4164" 44.2 55.1616438356164 2.16712328767123 0 0 0 0 0 0 0
"4165" 47.1424657534247 63.6356164383562 1.41917808219178 0 0 0 0 0 0 0
"4166" 50.7643835616438 55.3945205479452 3.01095890410959 0 0 0 0 0 0 0
"4167" 45.6356164383562 49.1506849315069 3.41917808219178 0 0 0 0 0 0 0
"4168" 38.5917808219178 44.7753424657534 3.41917808219178 0 0 0 0 0 0 0
"4169" 53.558904109589 57.0931506849315 2.61095890410959 0 0 0 0 0 0 0
"4170" 58.2109589041096 63.3397260273973 2.75068493150685 1 0 0 0 0 0 0
"4171" 50.8520547945205 57.2493150684932 3.41917808219178 0 0 0 0 0 0 0
"4172" 49.5890410958904 58.1917808219178 3.41917808219178 0 0 0 0 0 0 0
"4173" 52.9506849315068 58.2301369863014 3.41917808219178 0 0 0 0 0 0 0
"4174" 63.972602739726 63.9369863013699 2.72876712328767 0 0 0 0 0 0 0
"4175" 72.8082191780822 72.7534246575343 3.25205479452055 0 0 0 0 0 0 0
"4176" 71.4876712328767 67.0876712328767 3.25205479452055 0 0 0 0 0 0 0
"4177" 63.4712328767123 66.3479452054794 3.25205479452055 0 0 0 0 0 0 0
"4178" 56.0630136986301 66.386301369863 3.25205479452055 0 0 0 0 0 0 0
"4179" 68.7917808219178 68.2630136986301 3.16986301369863 1 0 0 0 0 0 0
"4180" 42.7013698630137 68.9315068493151 3.16712328767123 0 0 0 0 0 0 0
"4181" 58.5890410958904 59.9315068493151 3.16712328767123 0 0 0 0 0 0 0
"4182" 65.2109589041096 68.2109589041096 3.08767123287671 0 0 0 0 0 0 0
"4183" 59.8794520547945 62.8794520547945 3.08493150684932 0 0 0 0 0 0 0
"4184" 66.4657534246575 66.958904109589 3.08767123287671 0 0 0 0 0 0 0
"4185" 57.4027397260274 69.7123287671233 3.08767123287671 0 0 0 0 0 0 0
"4186" 57.2931506849315 60.2931506849315 3.08767123287671 0 0 0 0 0 0 0
"4187" 69.7123287671233 71.7123287671233 3.08767123287671 0 0 0 0 0 0 0
"4188" 65.213698630137 67.6328767123288 2.08767123287671 1 0 0 0 0 0 0
"4189" 65.213698630137 64.6328767123288 3.08493150684932 0 0 0 0 0 0 0
"4190" 64.2109589041096 70.1260273972603 3.08767123287671 0 0 0 0 0 0 0
"4191" 73.4657534246575 73.3835616438356 3.08493150684932 0 0 0 0 0 0 0
"4192" 57.3068493150685 71.841095890411 0.835616438356164 1 0 0 0 0 0 0
"4193" 61.1506849315069 62.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"4194" 73.0438356164384 72.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"4195" 70.3123287671233 65.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"4196" 73.2821917808219 72.6328767123288 4.08767123287671 1 0 0 0 0 0 0
"4197" 48.3753424657534 52.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"4198" 68.3150684931507 69.5041095890411 5.00821917808219 0 0 0 0 0 0 0
"4199" 67.2465753424657 69.9534246575342 5.00821917808219 0 0 0 0 0 0 0
"4200" 73.5369863013699 75.4547945205479 5.00821917808219 0 0 0 0 0 0 0
"4201" 58.0383561643836 64.9315068493151 4.93150684931507 0 0 0 0 0 0 0
"4202" 69.0465753424658 74.2794520547945 5.00821917808219 0 0 0 0 0 0 0
"4203" 60.8849315068493 62.8219178082192 5.00821917808219 0 0 0 0 0 0 0
"4204" 66.5068493150685 74.2438356164384 5.00821917808219 0 0 0 0 0 0 0
"4205" 67.0438356164384 74.3397260273973 5.00821917808219 0 0 0 0 0 0 0
"4206" 64 69.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"4207" 60.7150684931507 66.6931506849315 4.64657534246575 0 0 0 0 0 0 0
"4208" 72.013698630137 72.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"4209" 72.6328767123288 73.2821917808219 4.08767123287671 0 1 0 0 0 0 0
"4210" 71.7178082191781 74.7616438356164 5.00821917808219 0 0 0 0 0 0 0
"4211" 65.8794520547945 75.2164383561644 0.0876712328767123 1 0 0 0 0 0 0
"4212" 67.6328767123288 68.9150684931507 2.0027397260274 1 0 0 0 0 0 0
"4213" 75.241095890411 75.213698630137 5.00821917808219 0 0 0 0 0 0 0
"4214" 74.4328767123288 75.7424657534247 5.00821917808219 0 0 0 0 0 0 0
"4215" 64.7698630136986 64.1041095890411 4.71506849315069 0 0 0 0 0 0 0
"4216" 69.2547945205479 74.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"4217" 69.6630136986301 76.9095890410959 5.00821917808219 0 0 0 0 0 0 0
"4218" 65.4602739726027 73.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"4219" 74.0767123287671 75.6383561643836 5.00821917808219 0 0 0 0 0 0 0
"4220" 61.3342465753425 65.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"4221" 63.2602739726027 66.2767123287671 5.00821917808219 0 0 0 0 0 0 0
"4222" 67.8931506849315 70.958904109589 5.00821917808219 0 0 0 0 0 0 0
"4223" 69.7041095890411 69.9917808219178 5.00821917808219 0 0 0 0 0 0 0
"4224" 73.0630136986301 75.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"4225" 73.1643835616438 74.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"4226" 62.8931506849315 65.8931506849315 5.00821917808219 0 0 0 0 0 0 0
"4227" 74.8219178082192 75.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"4228" 76.9452054794521 74.0246575342466 5.00821917808219 0 0 0 0 0 0 0
"4229" 63.3287671232877 69.2027397260274 0.416438356164384 1 0 0 0 0 0 0
"4230" 67.4465753424657 72.2438356164384 5.00821917808219 0 0 0 0 0 0 0
"4231" 69.8054794520548 70.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"4232" 74.1698630136986 76.9342465753425 5.00821917808219 0 0 0 0 0 0 0
"4233" 67.3780821917808 75.6684931506849 5.00821917808219 0 0 0 0 0 0 0
"4234" 61.2602739726027 60.1835616438356 5.00821917808219 0 0 0 0 0 0 0
"4235" 63.7616438356164 64.1780821917808 0.0876712328767123 1 0 0 0 0 0 0
"4236" 70.7369863013699 73.4684931506849 5.00821917808219 0 0 0 0 0 0 0
"4237" 68.4054794520548 70.1123287671233 5.00821917808219 0 0 0 0 0 0 0
"4238" 70.0821917808219 75.5068493150685 2.66849315068493 1 0 0 0 0 0 0
"4239" 68.6328767123288 67.5534246575343 5.00821917808219 0 0 0 0 0 0 0
"4240" 74.8082191780822 75.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"4241" 66.041095890411 73.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"4242" 67.0794520547945 75.8876712328767 5.00821917808219 0 0 0 0 0 0 0
"4243" 69 76.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"4244" 56.4575342465753 62.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"4245" 65.827397260274 67.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"4246" 59.3890410958904 68.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"4247" 70.358904109589 75.413698630137 1.75068493150685 0 0 1 0 1 0 0.0657534246575342
"4248" 60.7479452054795 62.627397260274 0.331506849315069 1 0 0 0 0 0 0
"4249" 59.3369863013699 69.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"4250" 62.6301369863014 74.186301369863 5.00821917808219 0 0 0 0 0 0 0
"4251" 68.345205479452 72.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"4252" 70.7972602739726 74.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"4253" 62.2493150684932 67.2328767123288 5.00821917808219 0 0 0 0 0 0 0
"4254" 69.9369863013699 69.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4255" 67.6712328767123 68.654794520548 5.00821917808219 0 0 0 0 0 0 0
"4256" 65.7835616438356 74.0657534246575 5.00821917808219 0 0 0 0 0 0 0
"4257" 74.4493150684931 76.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"4258" 76.654794520548 75.4986301369863 5.00821917808219 0 0 0 0 0 0 0
"4259" 69.8027397260274 74.6027397260274 5.00821917808219 0 0 0 0 0 0 0
"4260" 62.3369863013699 70.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"4261" 57.8328767123288 70.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"4262" 70.3095890410959 74.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"4263" 75.2684931506849 68.5808219178082 5.00821917808219 0 0 0 0 0 0 0
"4264" 77.8356164383562 74.7753424657534 5.00821917808219 0 0 0 0 0 0 0
"4265" 56.0493150684932 67.3123287671233 5.00821917808219 0 0 0 0 0 0 0
"4266" 69.7095890410959 76.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"4267" 61.9342465753425 75.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4268" 71.3835616438356 73.627397260274 5.00821917808219 0 0 0 0 0 0 0
"4269" 66.2082191780822 75.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"4270" 59.1616438356164 73.827397260274 5.00821917808219 0 0 0 0 0 0 0
"4271" 67.1698630136986 74.5671232876712 5.00821917808219 0 0 0 0 0 0 0
"4272" 75.3917808219178 75.5972602739726 1.83561643835616 0 0 0 1 0 2.91780821917808 0
"4273" 65.2630136986301 72.972602739726 5.00821917808219 0 0 0 0 0 0 0
"4274" 66.5287671232877 75.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"4275" 72.8849315068493 74.3287671232877 0.416438356164384 0 1 0 0 0 0 0
"4276" 67.7424657534247 75.5780821917808 1.75068493150685 1 0 0 0 0 0 0
"4277" 64.2575342465753 74.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"4278" 67.9013698630137 71.158904109589 5.00821917808219 0 0 0 0 0 0 0
"4279" 62.3643835616438 75.6630136986301 5.00821917808219 0 0 0 0 0 0 0
"4280" 70.9315068493151 71.5095890410959 4.08767123287671 0 0 1 0 1 0 0.0246575342465753
"4281" 76.0191780821918 74.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4282" 63.9561643835616 74.8520547945206 5.00821917808219 0 0 0 0 0 0 0
"4283" 68.0383561643836 68.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"4284" 62.7095890410959 69.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"4285" 66.6712328767123 73.9534246575342 5.00821917808219 0 0 0 0 0 0 0
"4286" 70.6109589041096 72.7452054794521 5.00821917808219 0 0 0 0 0 0 0
"4287" 66.7534246575343 72.2849315068493 5.00821917808219 0 0 0 0 0 0 0
"4288" 73.2630136986301 75.2 5.00821917808219 0 0 0 0 0 0 0
"4289" 65.1506849315068 74.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"4290" 70.9397260273973 74.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4291" 71.8109589041096 73.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"4292" 71.6383561643836 74.1369863013699 4.24931506849315 1 0 0 0 0 0 0
"4293" 62.227397260274 74.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"4294" 69.5068493150685 75.6246575342466 5.00821917808219 0 0 0 0 0 0 0
"4295" 66.1260273972603 75.5753424657534 5.00821917808219 0 0 0 0 0 0 0
"4296" 53.241095890411 73.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"4297" 67.2794520547945 74.2575342465753 5.00821917808219 0 0 0 0 0 0 0
"4298" 64.4438356164383 73.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"4299" 70.4547945205479 75.413698630137 5.00821917808219 0 0 0 0 0 0 0
"4300" 76.2630136986301 75.6904109589041 5.00821917808219 0 0 0 0 0 0 0
"4301" 73.7506849315069 69.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"4302" 73.7780821917808 74.0520547945205 5.00821917808219 0 0 0 0 0 0 0
"4303" 60.4356164383562 73.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"4304" 58.2547945205479 76.1013698630137 5.00821917808219 0 0 0 0 0 0 0
"4305" 72.9561643835616 74.0438356164384 5.00821917808219 0 0 0 0 0 0 0
"4306" 71.3095890410959 74.9260273972603 5.00821917808219 0 0 0 0 0 0 0
"4307" 67.9424657534247 67.1808219178082 0.331506849315069 1 0 0 0 0 0 0
"4308" 65.2054794520548 75.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"4309" 60.2821917808219 69.0575342465753 5.00821917808219 0 0 0 0 0 0 0
"4310" 63.6931506849315 74.2958904109589 5.00821917808219 0 0 0 0 0 0 0
"4311" 60.3232876712329 76.5205479452055 3.16438356164384 1 0 0 0 0 0 0
"4312" 67.3041095890411 72.4767123287671 5.00821917808219 0 0 0 0 0 0 0
"4313" 62.7780821917808 73.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"4314" 67.6383561643836 70.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4315" 63.7287671232877 67.958904109589 5.00821917808219 0 0 0 0 0 0 0
"4316" 65.2986301369863 69.1369863013699 5.00821917808219 0 0 0 0 0 0 0
"4317" 67.8657534246575 68.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"4318" 68.0849315068493 76.1013698630137 5.00821917808219 0 0 0 0 0 0 0
"4319" 64.3424657534247 73.027397260274 0.835616438356164 1 0 0 0 0 0 0
"4320" 70.2849315068493 72.013698630137 5.00821917808219 0 0 0 0 0 0 0
"4321" 45.2 75.4657534246575 5.00821917808219 0 0 0 0 0 0 0
"4322" 62.5424657534247 74.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"4323" 69.7205479452055 75.3506849315068 5.00821917808219 0 0 0 0 0 0 0
"4324" 67.8520547945206 75.3671232876712 5.00821917808219 0 0 0 0 0 0 0
"4325" 67.5561643835617 71.7506849315069 5.00821917808219 0 0 0 0 0 0 0
"4326" 69.5013698630137 74.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"4327" 69.8767123287671 74.7561643835616 3.24931506849315 1 0 0 0 0 0 0
"4328" 60.0465753424658 65.5150684931507 1.16438356164384 1 0 0 0 0 0 0
"4329" 73.1671232876712 75.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"4330" 75.1013698630137 70.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"4331" 67.6164383561644 73.2328767123288 5.00821917808219 0 0 0 0 0 0 0
"4332" 69.186301369863 68.6 5.00821917808219 0 0 0 0 0 0 0
"4333" 71.5123287671233 69.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"4334" 79.7479452054795 74.9041095890411 1.4986301369863 0 0 1 0 1 0 0.0794520547945206
"4335" 75.3753424657534 69.2575342465753 5.00821917808219 0 0 0 0 0 0 0
"4336" 61.7698630136986 69.8767123287671 5.00821917808219 0 0 0 0 0 0 0
"4337" 58.4465753424658 63.3095890410959 5.00821917808219 0 0 0 0 0 0 0
"4338" 81.0849315068493 76.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"4339" 72.3315068493151 74.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"4340" 68.1123287671233 70.9753424657534 5.00821917808219 0 0 0 0 0 0 0
"4341" 68.3232876712329 68.2739726027397 5.00821917808219 0 0 0 0 0 0 0
"4342" 73.6657534246575 74.986301369863 5.00821917808219 0 0 0 0 0 0 0
"4343" 70.9287671232877 68.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"4344" 66.6054794520548 73.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"4345" 65.1780821917808 68.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"4346" 66.1917808219178 67.3205479452055 5.0027397260274 1 0 0 0 0 0 0
"4347" 64.7890410958904 67.4684931506849 5.00821917808219 0 0 0 0 0 0 0
"4348" 70.7397260273973 69.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"4349" 69.4849315068493 71.6958904109589 0.416438356164384 1 0 0 0 0 0 0
"4350" 64.2986301369863 68.8301369863014 5.00821917808219 0 0 0 0 0 0 0
"4351" 63.172602739726 66.9095890410959 2.16438356164384 1 0 0 0 0 0 0
"4352" 66.9780821917808 67.3917808219178 3.41643835616438 0 1 0 0 0 0 0
"4353" 68.786301369863 73.958904109589 5.00821917808219 0 0 0 0 0 0 0
"4354" 72.8493150684932 73.5287671232877 4.66849315068493 1 0 0 0 0 0 0
"4355" 67.8109589041096 67.3972602739726 3.41643835616438 1 0 0 0 0 0 0
"4356" 75.3315068493151 73.9945205479452 5.00821917808219 0 0 0 0 0 0 0
"4357" 69.9205479452055 71.4082191780822 5.00821917808219 0 0 0 0 0 0 0
"4358" 70.0547945205479 71.2547945205479 5.00821917808219 0 0 0 0 0 0 0
"4359" 68.9424657534247 68.9917808219178 5.00821917808219 0 0 0 0 0 0 0
"4360" 61.0109589041096 71.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"4361" 68.1534246575342 72.1150684931507 5.00821917808219 0 0 0 0 0 0 0
"4362" 63.4931506849315 68.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"4363" 73.2465753424657 71.9534246575342 1.0027397260274 1 0 0 0 0 0 0
"4364" 66.6465753424658 75.7068493150685 5.00821917808219 0 0 0 0 0 0 0
"4365" 58.9534246575342 67.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"4366" 74.641095890411 68.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"4367" 67.0383561643836 67.5315068493151 5.00821917808219 0 0 0 0 0 0 0
"4368" 60.4383561643836 64.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"4369" 62.8191780821918 69.2602739726027 1.33150684931507 1 0 0 0 0 0 0
"4370" 74.0986301369863 73.958904109589 5.00821917808219 0 0 0 0 0 0 0
"4371" 82.1616438356164 75.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"4372" 68.2794520547945 73.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"4373" 66.8547945205479 67.0082191780822 5.00821917808219 0 0 0 0 0 0 0
"4374" 69.7287671232877 70.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"4375" 56.8684931506849 65.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4376" 66.8 68.841095890411 5.00821917808219 0 0 0 0 0 0 0
"4377" 76.9260273972603 74.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"4378" 68.5123287671233 70.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"4379" 72.6794520547945 74.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"4380" 62.2986301369863 68.586301369863 5.00821917808219 0 0 0 0 0 0 0
"4381" 73.6246575342466 73.7643835616438 5.00821917808219 0 0 0 0 0 0 0
"4382" 52.6027397260274 67.0328767123288 5.00821917808219 0 0 0 0 0 0 0
"4383" 67.4712328767123 69.7506849315069 5.00821917808219 0 0 0 0 0 0 0
"4384" 66.5369863013699 67.5342465753425 5.00821917808219 0 0 0 0 0 0 0
"4385" 70.2958904109589 74.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"4386" 67.6109589041096 70.1671232876712 5.00821917808219 0 0 0 0 0 0 0
"4387" 66.2876712328767 68.3041095890411 5.00821917808219 0 0 0 0 0 0 0
"4388" 61.1890410958904 66.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"4389" 65.3972602739726 68.2849315068493 5.00821917808219 0 0 0 0 0 0 0
"4390" 69.7397260273973 64.4904109589041 5.00821917808219 0 0 0 0 0 0 0
"4391" 67.8547945205479 74.2630136986301 1.0027397260274 0 0 1 0 1 0 0.0328767123287671
"4392" 76.9424657534247 74.5342465753425 3.33150684931507 1 0 0 0 0 0 0
"4393" 67.6684931506849 65.227397260274 5.00821917808219 0 0 0 0 0 0 0
"4394" 69.0082191780822 73.8383561643836 5.00821917808219 0 0 0 0 0 0 0
"4395" 70.3534246575342 73.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"4396" 65.2931506849315 68.4356164383562 5.00821917808219 0 0 0 0 0 0 0
"4397" 65.4520547945205 68.8164383561644 5.00821917808219 0 0 0 0 0 0 0
"4398" 74.0493150684931 72.0219178082192 4.0027397260274 1 0 0 0 0 0 0
"4399" 60.3369863013699 66.4931506849315 5.00821917808219 0 0 0 0 0 0 0
"4400" 68.1917808219178 73.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4401" 68.8931506849315 74.2876712328767 5.00821917808219 0 0 0 0 0 0 0
"4402" 59.6657534246575 68.641095890411 5.00821917808219 0 0 0 0 0 0 0
"4403" 69.9972602739726 69.3205479452055 5.00821917808219 0 0 0 0 0 0 0
"4404" 59.827397260274 67.0794520547945 5.00821917808219 0 0 0 0 0 0 0
"4405" 66.0383561643836 66.5479452054795 5.00821917808219 0 0 0 0 0 0 0
"4406" 67.7780821917808 71.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"4407" 77.9643835616438 75.2684931506849 5.00821917808219 0 0 0 0 0 0 0
"4408" 70.1315068493151 67.6876712328767 5.00821917808219 0 0 0 0 0 0 0
"4409" 73.5369863013699 74.1917808219178 5.00821917808219 0 0 0 0 0 0 0
"4410" 73.5150684931507 68.7369863013699 5.00821917808219 0 0 0 0 0 0 0
"4411" 75.3013698630137 74.2 5.00821917808219 0 0 0 0 0 0 0
"4412" 80.4794520547945 74.9506849315069 5.00821917808219 0 0 0 0 0 0 0
"4413" 62.2849315068493 74.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"4414" 72.7753424657534 70.386301369863 5.00821917808219 0 0 0 0 0 0 0
"4415" 69.8438356164384 73.3753424657534 5.00821917808219 0 0 0 0 0 0 0
"4416" 73.5397260273973 67.6794520547945 5.00821917808219 0 0 0 0 0 0 0
"4417" 70.0767123287671 68.9013698630137 5.00821917808219 0 0 0 0 0 0 0
"4418" 70.3342465753425 67.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"4419" 66.5890410958904 67.7205479452055 5.00821917808219 0 0 0 0 0 0 0
"4420" 67.6164383561644 67.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4421" 73.386301369863 72.5178082191781 5.00821917808219 0 0 0 0 0 0 0
"4422" 71.2767123287671 68.3260273972603 5.00821917808219 0 0 0 0 0 0 0
"4423" 72.4547945205479 68.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"4424" 66.8821917808219 66.372602739726 5.00821917808219 0 0 0 0 0 0 0
"4425" 72.8246575342466 69.441095890411 5.00821917808219 0 0 0 0 0 0 0
"4426" 72.2082191780822 66.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"4427" 70.9506849315069 66.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"4428" 67.413698630137 72.5452054794521 5.00821917808219 0 0 0 0 0 0 0
"4429" 63.227397260274 67.9232876712329 5.00821917808219 0 0 0 0 0 0 0
"4430" 67.6931506849315 74.7287671232877 5.00821917808219 0 0 0 0 0 0 0
"4431" 74.0575342465753 72.3479452054794 3.24931506849315 0 1 0 0 0 0 0
"4432" 65.9479452054795 67.8438356164384 5.00821917808219 0 0 0 0 0 0 0
"4433" 71.6082191780822 70.9095890410959 5.00821917808219 0 0 0 0 0 0 0
"4434" 71.1616438356164 74.3945205479452 5.00821917808219 0 0 0 0 0 0 0
"4435" 73.6684931506849 74.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"4436" 62.5287671232877 67.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"4437" 74.3095890410959 67.2630136986301 5.00821917808219 0 0 0 0 0 0 0
"4438" 70.6602739726027 71.358904109589 5.00821917808219 0 0 0 0 0 0 0
"4439" 65.3150684931507 74.1041095890411 2.24931506849315 1 0 0 0 0 0 0
"4440" 67.2849315068493 69.4465753424657 5.00821917808219 0 0 0 0 0 0 0
"4441" 63.4986301369863 67.6438356164384 5.00821917808219 0 0 0 0 0 0 0
"4442" 75.841095890411 74.9698630136986 4.33150684931507 0 1 0 0 0 0 0
"4443" 75.5945205479452 74.8986301369863 5.00821917808219 0 0 0 0 0 0 0
"4444" 57.2383561643836 72.2027397260274 4.75068493150685 1 0 0 0 0 0 0
"4445" 67.8547945205479 70.2602739726027 5.00821917808219 0 0 0 0 0 0 0
"4446" 76.0493150684931 72.9369863013699 5.00821917808219 0 0 0 0 0 0 0
"4447" 66.9534246575342 66.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"4448" 66.8739726027397 67.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"4449" 70.4082191780822 75.6986301369863 5.00821917808219 0 0 0 0 0 0 0
"4450" 67.6164383561644 67.4602739726027 5.00821917808219 0 0 0 0 0 0 0
"4451" 67.2109589041096 74.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"4452" 72.013698630137 73.7232876712329 3.16438356164384 1 0 0 0 0 0 0
"4453" 60.7397260273973 74.1260273972603 5.00821917808219 0 0 0 0 0 0 0
"4454" 71.3424657534247 70.8876712328767 2.41643835616438 0 0 0 1 0 1.67397260273973 0
"4455" 71.7342465753425 68.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"4456" 69.3643835616438 67.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"4457" 71.2082191780822 66.6657534246575 5.00821917808219 0 0 0 0 0 0 0
"4458" 80.3068493150685 72.3835616438356 5.00821917808219 0 0 0 0 0 0 0
"4459" 71.1095890410959 74.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4460" 65.772602739726 67.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"4461" 72.9972602739726 73.8821917808219 5.00821917808219 0 0 0 0 0 0 0
"4462" 69.2246575342466 73.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"4463" 73.1342465753425 73.1945205479452 4.08767123287671 1 0 0 0 0 0 0
"4464" 71.2 74.5232876712329 1.33150684931507 1 0 0 0 0 0 0
"4465" 64.4191780821918 69.8904109589041 5.00821917808219 0 0 0 0 0 0 0
"4466" 68.9123287671233 68.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"4467" 73.4904109589041 74.2301369863014 1.4986301369863 0 1 0 0 0 0 0
"4468" 71.1890410958904 73.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"4469" 75.3260273972603 69.4054794520548 5.00821917808219 0 0 0 0 0 0 0
"4470" 68.2931506849315 66.8164383561644 3.66849315068493 0 1 0 0 0 0 0
"4471" 74.3479452054794 74.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"4472" 70.2958904109589 73.2246575342466 5.00821917808219 0 0 0 0 0 0 0
"4473" 62.7013698630137 67.8054794520548 5.00821917808219 0 0 0 0 0 0 0
"4474" 67.3698630136986 68.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"4475" 72.3534246575342 72.7890410958904 5.00821917808219 0 0 0 0 0 0 0
"4476" 73.9780821917808 71.0493150684931 5.00821917808219 0 0 0 0 0 0 0
"4477" 70.627397260274 67.7835616438356 5.00821917808219 0 0 0 0 0 0 0
"4478" 66.3150684931507 67.7917808219178 3.66849315068493 1 0 0 0 0 0 0
"4479" 68.558904109589 69.2493150684931 5.00821917808219 0 0 0 0 0 0 0
"4480" 70.1506849315068 68.3041095890411 5.00821917808219 0 0 0 0 0 0 0
"4481" 67.1506849315068 65.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"4482" 76.2465753424657 71.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"4483" 71.9013698630137 73.2931506849315 5.00821917808219 0 0 0 0 0 0 0
"4484" 74.1534246575342 73.413698630137 1.4986301369863 1 0 0 0 0 0 0
"4485" 69.3315068493151 68.1232876712329 5.00821917808219 0 0 0 0 0 0 0
"4486" 74.0657534246575 72.8520547945206 5.00821917808219 0 0 0 0 0 0 0
"4487" 66.9616438356164 67.9424657534247 5.00821917808219 0 0 0 0 0 0 0
"4488" 67.5424657534247 70.5972602739726 5.00821917808219 0 0 0 0 0 0 0
"4489" 70.0246575342466 74.1643835616438 2.08767123287671 1 0 0 0 0 0 0
"4490" 74.9178082191781 70.7780821917808 2.08767123287671 0 1 0 0 0 0 0
"4491" 62.9643835616438 68.8 5.00821917808219 0 0 0 0 0 0 0
"4492" 71.0630136986301 64.3041095890411 5.00821917808219 0 0 0 0 0 0 0
"4493" 66.2383561643836 68.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"4494" 70.345205479452 74.3342465753425 5.00821917808219 0 0 0 0 0 0 0
"4495" 75.8739726027397 68.3917808219178 5.00821917808219 0 0 0 0 0 0 0
"4496" 62.6054794520548 71.0876712328767 5.00821917808219 0 0 0 0 0 0 0
"4497" 74.0109589041096 68.7808219178082 5.00821917808219 0 0 0 0 0 0 0
"4498" 66.1671232876712 66.7342465753425 5.00821917808219 0 0 0 0 0 0 0
"4499" 68.2876712328767 64.345205479452 5.00821917808219 0 0 0 0 0 0 0
"4500" 64.2602739726027 63.4246575342466 5.00821917808219 0 0 0 0 0 0 0
"4501" 62.5232876712329 67.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"4502" 69.8027397260274 74.2712328767123 2.66849315068493 1 0 0 0 0 0 0
"4503" 68.2246575342466 72.7123287671233 5.00821917808219 0 0 0 0 0 0 0
"4504" 71.6986301369863 73.841095890411 4.66849315068493 1 0 0 0 0 0 0
"4505" 68.1972602739726 66.2383561643836 5.00821917808219 0 0 0 0 0 0 0
"4506" 73.7643835616438 71.6219178082192 4.66849315068493 0 1 0 0 0 0 0
"4507" 67.7917808219178 70.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"4508" 64.8054794520548 71.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"4509" 63.8356164383562 65.6657534246575 5.00821917808219 0 0 0 0 0 0 0
"4510" 69.1369863013699 67.8575342465753 5.00821917808219 0 0 0 0 0 0 0
"4511" 70.958904109589 67.7424657534247 5.00821917808219 0 0 0 0 0 0 0
"4512" 61.6876712328767 69.8027397260274 5.00821917808219 0 0 0 0 0 0 0
"4513" 69.627397260274 71.2849315068493 4.58356164383562 1 0 0 0 0 0 0
"4514" 71.6191780821918 69.9616438356164 4.58356164383562 0 1 0 0 0 0 0
"4515" 69.8246575342466 67.5616438356164 5.00821917808219 0 0 0 0 0 0 0
"4516" 66.345205479452 68.0904109589041 0.416438356164384 0 1 0 0 0 0 0
"4517" 62.9698630136986 65.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"4518" 73.5342465753425 71.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"4519" 66.8356164383562 62.1095890410959 5.00821917808219 0 0 0 0 0 0 0
"4520" 67.2356164383562 71.9205479452055 5.00821917808219 0 0 0 0 0 0 0
"4521" 71.1178082191781 71.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"4522" 65.4438356164383 68.8684931506849 5.00821917808219 0 0 0 0 0 0 0
"4523" 65.654794520548 65.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"4524" 65.654794520548 65.7534246575343 5.00821917808219 0 0 0 0 0 0 0
"4525" 69.0684931506849 70.0931506849315 5.00821917808219 0 0 0 0 0 0 0
"4526" 74.186301369863 72.6383561643836 5.00821917808219 0 0 0 0 0 0 0
"4527" 67.3095890410959 68.3369863013699 5.00821917808219 0 0 0 0 0 0 0
"4528" 62.1095890410959 66.8356164383562 5.00821917808219 0 0 0 0 0 0 0
"4529" 70.1753424657534 68.2082191780822 5.00821917808219 0 0 0 0 0 0 0
"4530" 75.1041095890411 71.7917808219178 5.00821917808219 0 0 0 0 0 0 0
"4531" 65.6246575342466 73.9123287671233 5.00821917808219 0 0 0 0 0 0 0
"4532" 67.7671232876712 74.1452054794521 5.00821917808219 0 0 0 0 0 0 0
"4533" 70.4191780821918 74.4575342465753 2.4986301369863 1 0 0 0 0 0 0
"4534" 66.8684931506849 74.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"4535" 72.5095890410959 69.8712328767123 5.00821917808219 0 0 0 0 0 0 0
"4536" 74.9698630136986 73.5232876712329 5.00821917808219 0 0 0 0 0 0 0
"4537" 58.8520547945205 67.7479452054795 5.00821917808219 0 0 0 0 0 0 0
"4538" 66.1205479452055 67.572602739726 5.00821917808219 0 0 0 0 0 0 0
"4539" 73.4356164383562 76.6520547945206 5.00821917808219 0 0 0 0 0 0 0
"4540" 65.0958904109589 65.7260273972603 0.753424657534247 0 0 0 0 0 0 0
"4541" 66.8630136986301 70.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"4542" 66.1342465753425 70.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"4543" 63.1287671232877 63.441095890411 5.00821917808219 0 0 0 0 0 0 0
"4544" 66.9232876712329 65.8 5.00821917808219 0 0 0 0 0 0 0
"4545" 65.3616438356164 65.6082191780822 0.506849315068493 0 0 0 0 0 0 0
"4546" 57.7808219178082 64.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"4547" 77.4794520547945 77.5095890410959 5.00821917808219 0 0 0 0 0 0 0
"4548" 71.3095890410959 73.4054794520548 3.24931506849315 1 0 0 0 0 0 0
"4549" 66.213698630137 68.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"4550" 73.5424657534247 77.5013698630137 4.16438356164384 0 0 1 0 1 0 0.0657534246575342
"4551" 63.8 74.7698630136986 5.00821917808219 0 0 0 0 0 0 0
"4552" 68.9260273972603 72.6602739726027 5.00821917808219 0 0 0 0 0 0 0
"4553" 67.2465753424657 69.0301369863014 5.00821917808219 0 0 0 0 0 0 0
"4554" 72.2684931506849 73.172602739726 5.00821917808219 0 0 0 0 0 0 0
"4555" 64.5013698630137 69.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"4556" 60.758904109589 59.9452054794521 2.41917808219178 0 0 0 0 0 0 0
"4557" 64.2684931506849 65.0739726027397 2.56164383561644 0 0 0 0 0 0 0
"4558" 64.8630136986301 64.8684931506849 2.72602739726027 0 0 0 0 0 0 0
"4559" 59.6246575342466 62.5561643835616 4.92054794520548 0 0 0 0 0 0 0
"4560" 58.4739726027397 63.172602739726 2.29315068493151 0 0 0 0 0 0 0
"4561" 65.4767123287671 65.0082191780822 5.00821917808219 0 0 0 0 0 0 0
"4562" 60.558904109589 62.5534246575342 3.2986301369863 0 0 0 0 0 0 0
"4563" 46.4356164383562 69.9452054794521 2.18904109589041 0 0 0 0 0 0 0
"4564" 67.0547945205479 66.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"4565" 67.0547945205479 66.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"4566" 69.1616438356164 65.0356164383562 2.68493150684932 0 0 0 0 0 0 0
"4567" 67.2164383561644 68.7232876712329 5.00821917808219 0 0 0 0 0 0 0
"4568" 63.9369863013699 64.8767123287671 1.1972602739726 0 0 0 0 0 0 0
"4569" 55.9835616438356 57.2 5.00821917808219 0 0 0 0 0 0 0
"4570" 61.5972602739726 67.5945205479452 5.00821917808219 0 0 0 0 0 0 0
"4571" 61.9315068493151 67.9287671232877 5.00821917808219 0 0 0 0 0 0 0
"4572" 60.0109589041096 61.7315068493151 5.00821917808219 0 0 0 0 0 0 0
"4573" 58.7041095890411 62.7123287671233 1.7013698630137 0 0 0 0 0 0 0
"4574" 61.2876712328767 60.4027397260274 1.6027397260274 0 0 0 0 0 0 0
"4575" 58.3616438356164 63.7561643835616 1.86575342465753 0 0 0 0 0 0 0
"4576" 61.4876712328767 62.3397260273973 2.44657534246575 0 0 0 0 0 0 0
"4577" 52.0465753424658 57.2520547945205 0.463013698630137 0 0 0 0 0 0 0
"4578" 45.1342465753425 64.0438356164384 0.794520547945205 0 0 0 0 0 0 0
"4579" 59.5479452054795 64.427397260274 5.00821917808219 0 0 0 0 0 0 0
"4580" 54.3561643835616 59.8958904109589 5.00821917808219 0 0 0 0 0 0 0
"4581" 56.0602739726027 59.7534246575342 5.00821917808219 0 0 0 0 0 0 0
"4582" 56.4794520547945 60.172602739726 5.00821917808219 0 0 0 0 0 0 0
"4583" 60.1041095890411 59.5068493150685 4.93150684931507 0 0 0 0 0 0 0
"4584" 48.7123287671233 58.041095890411 2.10958904109589 0 0 0 0 0 0 0
"4585" 64.7698630136986 65.0191780821918 5.00821917808219 0 0 0 0 0 0 0
"4586" 56.4876712328767 60.7671232876712 5.00821917808219 0 0 0 0 0 0 0
"4587" 66.1013698630137 66.6493150684932 5.00821917808219 0 0 0 0 0 0 0
"4588" 65.8493150684932 66.3972602739726 5.00821917808219 0 0 0 0 0 0 0
"4589" 67.786301369863 69.2164383561644 2.47671232876712 0 0 0 0 0 0 0
"4590" 63.6191780821918 65.5506849315069 5.00821917808219 0 0 0 0 0 0 0
"4591" 64.613698630137 61.786301369863 5.00821917808219 0 0 0 0 0 0 0
"4592" 54.4821917808219 58.213698630137 2.19178082191781 0 0 0 0 0 0 0
"4593" 65.8602739726027 59.2630136986301 0.791780821917808 0 0 0 0 0 0 0
"4594" 55.441095890411 57.6383561643836 0.701369863013699 0 0 0 0 0 0 0
"4595" 60.5917808219178 65.1150684931507 3.38630136986301 0 0 0 0 0 0 0
"4596" 59.027397260274 59.641095890411 3.38356164383562 0 0 0 0 0 0 0
"4597" 57.7945205479452 69.6301369863014 5.00821917808219 0 0 0 0 0 0 0
"4598" 64.3232876712329 63.1561643835616 2.08767123287671 1 0 0 0 0 0 0
"4599" 61.3342465753425 65.0684931506849 3.48219178082192 0 0 0 0 0 0 0
"4600" 67.6301369863014 64.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"4601" 67.4630136986301 64.0027397260274 5.00821917808219 0 0 0 0 0 0 0
"4602" 75.3369863013699 67.3506849315068 1.2 0 0 0 0 0 0 0
"4603" 54.7315068493151 61.0164383561644 2.11506849315069 0 0 0 0 0 0 0
"4604" 57.7616438356164 62.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"4605" 62.7835616438356 65.1013698630137 2.93424657534247 0 0 0 0 0 0 0
"4606" 61.9095890410959 63.0465753424658 1.62191780821918 0 0 0 0 0 0 0
"4607" 58.8958904109589 62.241095890411 5.00821917808219 0 0 0 0 0 0 0
"4608" 60.4 62.2931506849315 2.72602739726027 0 0 0 0 0 0 0
"4609" 53.1616438356164 59.5452054794521 2.29315068493151 0 0 0 0 0 0 0
"4610" 54.2027397260274 59.4630136986301 2.0986301369863 0 0 0 0 0 0 0
"4611" 62.2383561643836 64.9561643835616 0.493150684931507 0 0 0 0 0 0 0
"4612" 60.7232876712329 60.5068493150685 2.46027397260274 0 0 0 0 0 0 0
"4613" 55.8164383561644 58.4 1.54520547945205 0 0 0 0 0 0 0
"4614" 56.5671232876712 59.9041095890411 2.12876712328767 0 0 0 0 0 0 0
"4615" 60.7041095890411 62.5835616438356 1.77260273972603 0 0 0 0 0 0 0
"4616" 60.613698630137 63.6575342465753 5.00821917808219 0 0 0 0 0 0 0
"4617" 57.0520547945206 62.813698630137 1.43013698630137 0 0 0 0 0 0 0
"4618" 62.1068493150685 60.2438356164384 1.76986301369863 0 0 0 0 0 0 0
"4619" 56.4684931506849 59.3835616438356 0.635616438356164 0 0 0 0 0 0 0
"4620" 58.1260273972603 61.213698630137 0 0 0 0 0 0 0 0
"4621" 63.9287671232877 65.1041095890411 3.98082191780822 0 0 0 0 0 0 0
"4622" 53.558904109589 65.8493150684932 2.46027397260274 0 0 0 0 0 0 0
"4623" 55.3561643835616 58.572602739726 1.94794520547945 0 0 0 0 0 0 0
"4624" 56.8164383561644 59.8246575342466 1.93698630136986 0 0 0 0 0 0 0
"4625" 50.0657534246575 60.9479452054794 1.61917808219178 0 0 0 0 0 0 0
"4626" 62.6767123287671 67.2493150684931 0.378082191780822 1 0 0 0 0 0 0
"4627" 57.1232876712329 65.8493150684932 1.27123287671233 0 0 0 0 0 0 0
"4628" 52.8958904109589 55.8520547945205 2.44657534246575 0 0 0 0 0 0 0
"4629" 68.1178082191781 71.7561643835616 0.405479452054795 1 0 0 0 0 0 0
"4630" 50.1315068493151 60.7671232876712 0.704109589041096 0 0 0 0 0 0 0
"4631" 59.8219178082192 65.4164383561644 0.619178082191781 0 0 0 0 0 0 0
"4632" 61.1945205479452 60.3945205479452 2.11506849315069 0 0 0 0 0 0 0
"4633" 54.5561643835616 56.5643835616438 5.00821917808219 0 0 0 0 0 0 0
"4634" 66.8328767123288 65.1452054794521 1.94520547945205 0 0 0 0 0 0 0
"4635" 58.8493150684931 61.2904109589041 3.97534246575342 0 0 0 0 0 0 0
"4636" 67.7205479452055 65.0602739726027 1.19452054794521 0 0 0 0 0 0 0
"4637" 45.8328767123288 58.5424657534247 0.789041095890411 0 0 0 0 0 0 0
"4638" 70.2876712328767 70.7369863013699 2.56164383561644 0 0 0 0 0 0 0
"4639" 54.4328767123288 60.1068493150685 0.638356164383562 0 0 0 0 0 0 0
"4640" 57.641095890411 61.1123287671233 0.775342465753425 0 0 0 0 0 0 0
"4641" 59.4630136986301 57.1616438356164 5.00821917808219 0 0 0 0 0 0 0
"4642" 42.3561643835616 55.3616438356164 0.216438356164384 0 0 0 0 0 0 0
"4643" 54.4876712328767 65.0986301369863 2.53972602739726 0 0 0 0 0 0 0
"4644" 55.1397260273973 64.1424657534247 5.00821917808219 0 0 0 0 0 0 0
"4645" 54.8054794520548 63.8082191780822 5.00821917808219 0 0 0 0 0 0 0
"4646" 61.041095890411 61.2027397260274 5.00821917808219 0 0 0 0 0 0 0
"4647" 57.3260273972603 66.3013698630137 5.00821917808219 0 0 0 0 0 0 0
"4648" 57.3260273972603 66.3013698630137 5.00821917808219 0 0 0 0 0 0 0
"4649" 58.758904109589 64.4821917808219 3.83835616438356 0 0 0 0 0 0 0
"4650" 63.3698630136986 65.4438356164383 1.35616438356164 0 0 0 0 0 0 0
"4651" 54.613698630137 55.8301369863014 3.38356164383562 0 0 0 0 0 0 0
"4652" 65.2767123287671 67.1260273972603 2.68493150684932 0 0 0 0 0 0 0
"4653" 54.2027397260274 61.4164383561644 1.77808219178082 0 0 0 0 0 0 0
"4654" 53.9671232876712 57.3917808219178 1.63287671232877 0 0 0 0 0 0 0
"4655" 57.9452054794521 58.227397260274 0 0 0 0 0 0 0 0
"4656" 61.5780821917808 58.7698630136986 0.493150684931507 0 0 0 0 0 0 0
"4657" 61.9972602739726 61.1369863013699 2.46027397260274 0 0 0 0 0 0 0
"4658" 64.6849315068493 66.0328767123288 0.638356164383562 0 0 0 0 0 0 0
"4659" 59.2767123287671 59.0027397260274 4.91232876712329 0 0 0 0 0 0 0
"4660" 53.6164383561644 65.4109589041096 1.95890410958904 0 0 0 0 0 0 0
"4661" 54.5835616438356 55.3616438356164 1.27671232876712 0 0 0 0 0 0 0
"4662" 63.7972602739726 65.8 4.8 0 0 0 0 0 0 0
"4663" 53.7616438356164 64.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"4664" 53.7616438356164 64.5780821917808 5.00821917808219 0 0 0 0 0 0 0
"4665" 61.6438356164384 61.3424657534247 2.60821917808219 0 0 0 0 0 0 0
"4666" 61.9671232876712 64.1698630136986 5.00821917808219 0 0 0 0 0 0 0
"4667" 60.8246575342466 61.5287671232877 2.59452054794521 0 0 0 0 0 0 0
"4668" 66.8219178082192 62.5068493150685 1.61917808219178 0 0 0 0 0 0 0
"4669" 65.8520547945206 65.7561643835616 2.1972602739726 0 0 0 0 0 0 0
"4670" 52.7068493150685 55.6109589041096 1.44109589041096 0 0 0 0 0 0 0
"4671" 63.2986301369863 64.7123287671233 1.29041095890411 0 0 0 0 0 0 0
"4672" 66.3260273972603 65.4 1.83287671232877 1 0 0 0 0 0 0
"4673" 63.2547945205479 64.8493150684932 2.59178082191781 0 0 0 0 0 0 0
"4674" 51.4054794520548 60.6054794520548 1.2986301369863 0 0 0 0 0 0 0
"4675" 60.9643835616438 63.8794520547945 0.849315068493151 0 0 0 0 0 0 0
"4676" 58.4958904109589 61.1671232876712 2.07945205479452 0 0 0 0 0 0 0
"4677" 54.2328767123288 59.0493150684932 1.86575342465753 0 0 0 0 0 0 0
"4678" 64.1753424657534 65.8301369863014 1.75342465753425 0 0 0 0 0 0 0
"4679" 62.9013698630137 63.5041095890411 1.12328767123288 0 0 0 0 0 0 0
"4680" 57.3506849315068 60.4602739726027 0.8 0 0 0 0 0 0 0
"4681" 56.5068493150685 59.8027397260274 0.780821917808219 0 0 0 0 0 0 0
"4682" 62.5369863013699 65.4493150684931 0.416438356164384 1 0 0 0 0 0 0
"4683" 60.5452054794521 60.2 1.93972602739726 0 0 0 0 0 0 0
"4684" 50.841095890411 58.558904109589 2.18904109589041 0 0 0 0 0 0 0
"4685" 54.8493150684931 65.0986301369863 1.36438356164384 0 0 0 0 0 0 0
"4686" 60.2027397260274 64.4054794520548 1.36438356164384 0 0 0 0 0 0 0
"4687" 57.5534246575342 62.4164383561644 5.00821917808219 0 0 0 0 0 0 0
"4688" 66.772602739726 64.5013698630137 1.36438356164384 0 0 0 0 0 0 0
"4689" 56.7945205479452 58.7260273972603 5.00821917808219 0 0 0 0 0 0 0
"4690" 58.8383561643836 60.827397260274 1.67945205479452 0 0 0 0 0 0 0
"4691" 70.0575342465753 65.8027397260274 0.742465753424657 0 0 0 0 0 0 0
"4692" 54.9178082191781 58.8493150684931 0.852054794520548 0 0 0 0 0 0 0
"4693" 50.7397260273973 57.0876712328767 1.13698630136986 0 0 0 0 0 0 0
"4694" 66.3397260273973 65.8821917808219 2.16438356164384 1 0 0 0 0 0 0
"4695" 62.9616438356164 62.4027397260274 0.852054794520548 0 0 0 0 0 0 0
"4696" 59.8931506849315 62.8712328767123 2.59178082191781 0 0 0 0 0 0 0
"4697" 48.6657534246575 65.2602739726027 4.8 0 0 0 0 0 0 0
"4698" 63.1424657534247 65.5150684931507 1.27671232876712 0 0 0 0 0 0 0
"4699" 57.9972602739726 65.5068493150685 2.34794520547945 0 0 0 0 0 0 0
"4700" 59.0684931506849 63.8191780821918 2.63013698630137 0 0 0 0 0 0 0
"4701" 68.1397260273973 66.5205479452055 0.791780821917808 0 0 0 0 0 0 0
"4702" 63.0246575342466 65.6931506849315 4.6027397260274 0 0 0 0 0 0 0
"4703" 56.5150684931507 57.827397260274 1.25753424657534 0 0 0 0 0 0 0
"4704" 61.9342465753425 63.4301369863014 2.19452054794521 0 0 0 0 0 0 0
"4705" 61.7479452054795 65.5232876712329 1.43013698630137 0 0 0 0 0 0 0
"4706" 47.6493150684932 64.641095890411 0.775342465753425 0 0 0 0 0 0 0
"4707" 58.7671232876712 60.8438356164384 1.19452054794521 0 0 0 0 0 0 0
"4708" 58.2493150684932 65.613698630137 0.775342465753425 0 0 0 0 0 0 0
"4709" 71.241095890411 62.3369863013699 4.66849315068493 1 0 0 0 0 0 0
"4710" 63.7123287671233 67.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"4711" 63.7123287671233 67.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"4712" 59.3808219178082 64.5972602739726 1.67945205479452 0 0 0 0 0 0 0
"4713" 64.1452054794521 65.9808219178082 1.2986301369863 0 0 0 0 0 0 0
"4714" 75.8657534246575 65.0520547945205 3.64383561643836 0 0 0 0 0 0 0
"4715" 64.958904109589 65.558904109589 0.76986301369863 0 0 0 0 0 0 0
"4716" 71.7753424657534 66.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"4717" 71.7753424657534 66.7945205479452 5.00821917808219 0 0 0 0 0 0 0
"4718" 66.7671232876712 67.0794520547945 0.926027397260274 0 0 0 0 0 0 0
"4719" 63.2849315068493 62.627397260274 0.849315068493151 0 0 0 0 0 0 0
"4720" 54.8904109589041 61.2520547945205 5.00821917808219 0 0 0 0 0 0 0
"4721" 56.5671232876712 60.1753424657534 0.605479452054794 0 0 0 0 0 0 0
"4722" 61.9205479452055 64.2767123287671 1.29041095890411 0 0 0 0 0 0 0
"4723" 61.7753424657534 67.2657534246575 1.26849315068493 0 0 0 0 0 0 0
"4724" 58.8493150684931 59.1534246575342 0.794520547945205 0 0 0 0 0 0 0
"4725" 50.5232876712329 62.0821917808219 5.00821917808219 0 0 0 0 0 0 0
"4726" 57.2767123287671 62.9041095890411 0.249315068493151 1 0 0 0 0 0 0
"4727" 54.6712328767123 64.572602739726 2.53972602739726 0 0 0 0 0 0 0
"4728" 66.3945205479452 64.3342465753425 2.72328767123288 0 0 0 0 0 0 0
"4729" 58.7232876712329 59.2958904109589 0.194520547945205 0 0 0 0 0 0 0
"4730" 60.2054794520548 60.3232876712329 1.24931506849315 0 0 0 0 0 0 0
"4731" 65.2301369863014 62.8684931506849 2.46027397260274 0 0 0 0 0 0 0
"4732" 52.1835616438356 58.1095890410959 2.02465753424658 0 0 0 0 0 0 0
"4733" 60.9095890410959 65.5397260273973 1.44657534246575 0 0 0 0 0 0 0
"4734" 63.2904109589041 64.1068493150685 0.452054794520548 0 0 0 0 0 0 0
"4735" 60.2821917808219 61.4191780821918 0.76986301369863 0 0 0 0 0 0 0
"4736" 70.0301369863014 63.4191780821918 3.81917808219178 0 0 0 0 0 0 0
"4737" 68.0438356164384 71.1479452054794 2.13698630136986 0 0 0 0 0 0 0
"4738" 65.7945205479452 65.2602739726027 3.19452054794521 0 0 0 0 0 0 0
"4739" 73.3945205479452 65.8904109589041 0.756164383561644 0 0 0 0 0 0 0
"4740" 61.5753424657534 64.654794520548 0.753424657534247 0 0 0 0 0 0 0
"4741" 66.3945205479452 67.0794520547945 4.89041095890411 0 0 0 0 0 0 0
"4742" 59.8849315068493 58.1369863013699 0.0383561643835616 0 0 0 0 0 0 0
"4743" 63.0876712328767 65.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"4744" 66.3150684931507 65.2794520547945 0.465753424657534 0 0 0 0 0 0 0
"4745" 64.2054794520548 69.6794520547945 0.945205479452055 0 0 0 0 0 0 0
"4746" 65.5561643835617 66.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"4747" 63.7945205479452 67.6356164383562 0.416438356164384 1 0 0 0 0 0 0
"4748" 63.7945205479452 67.6356164383562 5.00821917808219 0 0 0 0 0 0 0
"4749" 63.4739726027397 65.7095890410959 1.36712328767123 0 0 0 0 0 0 0
"4750" 64.641095890411 66.3671232876712 0.416438356164384 1 0 0 0 0 0 0
"4751" 57.5178082191781 59.241095890411 1.93972602739726 0 0 0 0 0 0 0
"4752" 60.3041095890411 62.7342465753425 2.46027397260274 0 0 0 0 0 0 0
"4753" 65.4794520547945 62.1369863013699 5.00821917808219 0 0 0 0 0 0 0
"4754" 57.6164383561644 65.5041095890411 1.36712328767123 0 0 0 0 0 0 0
"4755" 67.213698630137 66.213698630137 0.378082191780822 0 0 0 0 0 0 0
"4756" 55.0465753424658 61.5506849315069 0.838356164383562 0 0 0 0 0 0 0
"4757" 63.4904109589041 66.2301369863014 4.20821917808219 0 0 0 0 0 0 0
"4758" 62.8301369863014 57.3452054794521 1.63835616438356 0 0 0 0 0 0 0
"4759" 59.4712328767123 56.6109589041096 2.09315068493151 0 0 0 0 0 0 0
"4760" 56.0301369863014 63.958904109589 4.93698630136986 0 0 0 0 0 0 0
"4761" 54.4630136986301 61.1534246575342 3.63561643835616 0 0 0 0 0 0 0
"4762" 65.0630136986301 63.6493150684932 0.621917808219178 0 0 0 0 0 0 0
"4763" 56.4191780821918 55.8986301369863 0.8 0 0 0 0 0 0 0
"4764" 63.6712328767123 64.8438356164384 1.77808219178082 0 0 0 0 0 0 0
"4765" 65.8986301369863 66.2301369863014 2.53972602739726 0 0 0 0 0 0 0
"4766" 58.7287671232877 60.4958904109589 0.947945205479452 0 0 0 0 0 0 0
"4767" 56.4109589041096 65.9123287671233 0.794520547945205 0 0 0 0 0 0 0
"4768" 64.2602739726027 63.3835616438356 0.723287671232877 0 0 0 0 0 0 0
"4769" 45.0465753424658 59.3506849315068 2.59452054794521 0 0 0 0 0 0 0
"4770" 57.386301369863 55.641095890411 0.528767123287671 0 0 0 0 0 0 0
"4771" 62.8191780821918 61.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"4772" 59.5808219178082 66.6767123287671 2 0 0 0 0 0 0 0
"4773" 65.4246575342466 66.441095890411 2 0 0 0 0 0 0 0
"4774" 61.3643835616438 71.4082191780822 2 0 0 0 0 0 0 0
"4775" 69.1534246575342 75.6054794520548 2 0 0 0 0 0 0 0
"4776" 71.9178082191781 72.1013698630137 0.4 1 0 0 0 0 0 0
"4777" 70.2821917808219 63.358904109589 2 0 0 0 0 0 0 0
"4778" 65.1232876712329 65.986301369863 2 0 0 0 0 0 0 0
"4779" 67.3068493150685 69.041095890411 2 0 0 0 0 0 0 0
"4780" 62.1397260273973 67.2958904109589 2 0 0 0 0 0 0 0
"4781" 78.6794520547945 74.0465753424658 2 0 0 0 0 0 0 0
"4782" 61.3342465753425 63.427397260274 2 0 0 0 0 0 0 0
"4783" 66.5534246575343 65.6904109589041 3.25205479452055 0 0 0 0 0 0 0
"4784" 65.9123287671233 66.4465753424657 3.25205479452055 0 0 0 0 0 0 0
"4785" 68.8630136986301 73.3205479452055 3.25205479452055 0 0 0 0 0 0 0
"4786" 70.986301369863 75.4438356164383 0.961643835616438 0 0 0 0 0 0 0
"4787" 56.6849315068493 67.758904109589 3.25205479452055 0 0 0 0 0 0 0
"4788" 59.0575342465753 70.1315068493151 0.961643835616438 0 0 0 0 0 0 0
"4789" 68 65.3041095890411 2.38904109589041 0 0 0 0 0 0 0
"4790" 62.5041095890411 65.4520547945205 4.47123287671233 0 0 0 0 0 0 0
"4791" 57.6958904109589 57.9780821917808 0 0 0 0 0 0 0 0
"4792" 64.4630136986301 68.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"4793" 63 68.6520547945206 5.00821917808219 0 0 0 0 0 0 0
"4794" 62.2246575342466 68.5232876712329 5.00821917808219 0 0 0 0 0 0 0
"4795" 62.6575342465753 64.3835616438356 4.91780821917808 1 0 0 0 0 0 0
"4796" 63.4986301369863 65.4739726027397 5.00821917808219 0 0 0 0 0 0 0
"4797" 57.4986301369863 67.4328767123288 5.00821917808219 0 0 0 0 0 0 0
"4798" 52.8082191780822 57.9972602739726 5.00821917808219 0 0 0 0 0 0 0
"4799" 61.9890410958904 65.1287671232877 5.00821917808219 0 0 0 0 0 0 0
"4800" 57.6356164383562 58.0109589041096 5.00821917808219 0 0 0 0 0 0 0
"4801" 58.5369863013699 62.7561643835616 5.00821917808219 0 0 0 0 0 0 0
"4802" 56.8712328767123 58.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4803" 60.4986301369863 57.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"4804" 55.3342465753425 62.6684931506849 5.00821917808219 0 0 0 0 0 0 0
"4805" 63.8602739726027 65.6520547945206 5.00821917808219 0 0 0 0 0 0 0
"4806" 56.9205479452055 56.5698630136986 5.00821917808219 0 0 0 0 0 0 0
"4807" 69.1287671232877 65.041095890411 4.8986301369863 0 0 0 0 0 0 0
"4808" 61.4575342465753 63.0356164383562 4.47123287671233 0 0 0 0 0 0 0
"4809" 52.4767123287671 64.0986301369863 3.69041095890411 0 0 0 0 0 0 0
"4810" 52.9917808219178 56.6602739726027 3.60821917808219 0 0 0 0 0 0 0
"4811" 59.041095890411 60.5397260273973 3.55616438356164 0 0 0 0 0 0 0
"4812" 66.7095890410959 61.8219178082192 3.48219178082192 0 0 0 0 0 0 0
"4813" 61.7041095890411 61.6986301369863 3.47397260273973 0 0 0 0 0 0 0
"4814" 64.8246575342466 61.2876712328767 2.4986301369863 1 0 0 0 0 0 0
"4815" 66.7506849315069 67.1917808219178 3.08767123287671 0 0 0 0 0 0 0
"4816" 56.9917808219178 58.3835616438356 3.05479452054795 0 0 0 0 0 0 0
"4817" 63.0438356164384 63.5561643835616 3.01095890410959 0 0 0 0 0 0 0
"4818" 64.6109589041096 65.2712328767123 2.23013698630137 0 0 0 0 0 0 0
"4819" 65.0191780821918 65.0493150684931 1.08219178082192 0 0 0 0 0 0 0
"4820" 58.7123287671233 61.5753424657534 1.71232876712329 0 0 0 0 0 0 0
"4821" 65.1342465753425 66.0767123287671 1.08219178082192 0 0 0 0 0 0 0
"4822" 61.5424657534247 62.7232876712329 2.67397260273973 0 1 0 0 0 0 0
"4823" 54.1041095890411 62.2219178082192 3.36438356164384 0 0 0 0 0 0 0
"4824" 72.2164383561644 62.1479452054795 5.00821917808219 0 0 0 0 0 0 0
"4825" 59.7698630136986 61.3397260273973 3.91506849315068 0 0 0 0 0 0 0
"4826" 50.9452054794521 60.9369863013699 1.80821917808219 0 0 0 0 0 0 0
"4827" 56.8794520547945 64.7013698630137 3.34520547945205 0 0 0 0 0 0 0
"4828" 61.3068493150685 61.5671232876712 3.11506849315069 0 0 0 0 0 0 0
"4829" 52.6328767123288 58.972602739726 3.4027397260274 0 0 0 0 0 0 0
"4830" 62.1095890410959 62.2794520547945 0.887671232876712 0 0 0 0 0 0 0
"4831" 57.8219178082192 60.8849315068493 3.69315068493151 0 0 0 0 0 0 0
"4832" 56.2931506849315 61.3780821917808 4.53424657534247 0 0 0 0 0 0 0
"4833" 59.213698630137 64.9205479452055 2.48219178082192 0 0 0 0 0 0 0
"4834" 46.3890410958904 59.5397260273973 5.00821917808219 0 0 0 0 0 0 0
"4835" 64.8684931506849 64.2027397260274 3.12602739726027 0 0 0 0 0 0 0
"4836" 55.4520547945205 62.2328767123288 2.25205479452055 0 0 0 0 0 0 0
"4837" 51.4164383561644 59.0465753424658 3.98082191780822 0 0 0 0 0 0 0
"4838" 63.8520547945205 57.7452054794521 1.75342465753425 0 0 0 0 0 0 0
"4839" 54.9890410958904 60.6356164383562 0.405479452054795 0 0 0 0 0 0 0
"4840" 66.0767123287671 64.9095890410959 3.19452054794521 0 0 0 0 0 0 0
"4841" 49.0575342465753 60.5698630136986 3.45753424657534 0 0 0 0 0 0 0
"4842" 52.1698630136986 58.3342465753425 0.334246575342466 0 0 0 0 0 0 0
"4843" 63.8383561643836 60.2602739726027 2.11506849315069 0 0 0 0 0 0 0
"4844" 66.6082191780822 65.4356164383562 1.52876712328767 0 0 0 0 0 0 0
"4845" 52.3698630136986 54.6630136986301 2.99178082191781 0 0 0 0 0 0 0
"4846" 65.8684931506849 63.3315068493151 0.334246575342466 0 0 0 0 0 0 0
"4847" 60.7753424657534 60.9616438356164 2.8958904109589 0 0 0 0 0 0 0
"4848" 57.2027397260274 59.7397260273973 1.52876712328767 0 0 0 0 0 0 0
"4849" 61.4767123287671 61.6301369863014 2.8958904109589 0 0 0 0 0 0 0
"4850" 53.8164383561644 64.3643835616438 3.98082191780822 0 0 0 0 0 0 0
"4851" 48.3945205479452 59.9178082191781 1.80821917808219 0 0 0 0 0 0 0
"4852" 54.9232876712329 60.613698630137 0.671232876712329 0 0 0 0 0 0 0
"4853" 58.4438356164384 61.1643835616438 5.00821917808219 0 0 0 0 0 0 0
"4854" 60.0684931506849 65.5671232876712 3.45753424657534 0 0 0 0 0 0 0
"4855" 56.7287671232877 61.9753424657534 2.61369863013699 0 0 0 0 0 0 0
"4856" 57.586301369863 61.2684931506849 0.810958904109589 0 0 0 0 0 0 0
"4857" 56.5506849315069 60.0082191780822 1.08493150684932 0 0 0 0 0 0 0
"4858" 67.2191780821918 62.0356164383562 5.00821917808219 0 0 0 0 0 0 0
"4859" 54.6164383561644 61.1671232876712 0.221917808219178 0 0 0 0 0 0 0
"4860" 44.8904109589041 57.4493150684931 1.5041095890411 0 0 0 0 0 0 0
"4861" 60.3342465753425 58.213698630137 0.36986301369863 0 0 0 0 0 0 0
"4862" 61.3095890410959 63.6219178082192 5.00821917808219 0 0 0 0 0 0 0
"4863" 55.1068493150685 56.3424657534247 0.367123287671233 1 0 0 0 0 0 0
"4864" 61.9698630136986 63.8438356164384 1.07945205479452 1 0 0 0 0 0 0
"4865" 57.8520547945205 61.586301369863 0.775342465753425 0 0 0 0 0 0 0
"4866" 52.1671232876712 62.0931506849315 4.84109589041096 0 0 0 0 0 0 0
"4867" 58.7260273972603 63.3452054794521 4.6027397260274 0 0 0 0 0 0 0
"4868" 61.2602739726027 65.2547945205479 1.05753424657534 0 0 0 0 0 0 0
"4869" 62.7561643835616 64.4931506849315 3.24383561643836 0 0 0 0 0 0 0
"4870" 51.4684931506849 59.2849315068493 2.3041095890411 0 0 0 0 0 0 0
"4871" 52.1452054794521 61.9945205479452 2.12876712328767 0 0 0 0 0 0 0
"4872" 44.0904109589041 60.0164383561644 0.717808219178082 0 0 0 0 0 0 0
"4873" 55.3835616438356 64.9753424657534 2 0 0 0 0 0 0 0
"4874" 60.7671232876712 66.2 2.90684931506849 0 0 0 0 0 0 0
"4875" 60.8438356164384 62.5616438356164 1.64109589041096 0 0 0 0 0 0 0
"4876" 64.2520547945205 65.3479452054794 1.12054794520548 0 0 0 0 0 0 0
"4877" 61.9671232876712 63.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"4878" 54.5150684931507 58.1068493150685 5.00821917808219 0 0 0 0 0 0 0
"4879" 64.5452054794521 68.8082191780822 5.00821917808219 0 0 0 0 0 0 0
"4880" 56.758904109589 58.7780821917808 5.00821917808219 0 0 0 0 0 0 0
"4881" 54.2301369863014 62.3534246575342 2.91780821917808 1 0 0 0 0 0 0
"4882" 65.2027397260274 65.5890410958904 5.00821917808219 0 0 0 0 0 0 0
"4883" 60.772602739726 64.6 5.00821917808219 0 0 0 0 0 0 0
"4884" 64.8438356164384 69.4027397260274 5.00821917808219 0 0 0 0 0 0 0
"4885" 61.1068493150685 62.5123287671233 5.00821917808219 0 0 0 0 0 0 0
"4886" 62.3671232876712 65.2657534246575 5.00821917808219 0 0 0 0 0 0 0
"4887" 62.6602739726027 63.7068493150685 3.16712328767123 0 0 0 0 0 0 0
"4888" 54.8958904109589 55.627397260274 2.25479452054795 0 0 0 0 0 0 0
"4889" 55.8712328767123 58.3890410958904 2.73150684931507 0 0 0 0 0 0 0
"4890" 69.6465753424658 56.6356164383562 4.58630136986301 0 0 0 0 0 0 0
"4891" 65.3013698630137 62.0657534246575 4.8 0 0 0 0 0 0 0
"4892" 60.7780821917808 65.2986301369863 5.00821917808219 0 0 0 0 0 0 0
"4893" 55.8712328767123 58.3890410958904 2.73150684931507 0 0 0 0 0 0 0
"4894" 55.8684931506849 58.386301369863 2.48493150684931 0 0 0 0 0 0 0
"4895" 64.1205479452055 65.0794520547945 1 0 0 0 0 0 0 0
"4896" 65.4575342465753 65.3917808219178 1.38356164383562 0 0 0 0 0 0 0
"4897" 67.8821917808219 67.3397260273973 2.52054794520548 0 0 0 0 0 0 0
"4898" 66.8684931506849 66.3260273972603 3.86301369863014 0 0 0 0 0 0 0
"4899" 63.1397260273973 65.6164383561644 0.671232876712329 0 0 0 0 0 0 0
"4900" 39.1808219178082 65.4493150684931 5.00821917808219 0 0 0 0 0 0 0
"4901" 42.1698630136986 68.4383561643836 2.52054794520548 0 0 0 0 0 0 0
"4902" 68.9315068493151 65.1890410958904 3.25205479452055 0 0 0 0 0 0 0
"4903" 69.9972602739726 66.2547945205479 2.52054794520548 0 0 0 0 0 0 0
"4904" 38.2082191780822 65.5205479452055 5.00821917808219 0 0 0 0 0 0 0
"4905" 41.1972602739726 68.5095890410959 2.52054794520548 0 0 0 0 0 0 0
"4906" 73.9945205479452 78.3643835616438 2.52054794520548 0 0 0 0 0 0 0
"4907" 64.7013698630137 73.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"4908" 64.7013698630137 73.5287671232877 5.00821917808219 0 0 0 0 0 0 0
"4909" 70.7397260273973 69.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"4910" 70.7397260273973 69.8602739726027 5.00821917808219 0 0 0 0 0 0 0
"4911" 65.6602739726027 67.8657534246575 4.08767123287671 1 0 0 0 0 0 0
"4912" 65.6602739726027 67.8657534246575 4.08767123287671 1 0 0 0 0 0 0
"4913" 66.8383561643836 72.0465753424658 5.00821917808219 0 0 0 0 0 0 0
"4914" 66.8383561643836 72.0465753424658 5.00821917808219 0 0 0 0 0 0 0
"4915" 71.1945205479452 69.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"4916" 71.1945205479452 69.1342465753425 5.00821917808219 0 0 0 0 0 0 0
"4917" 66.5972602739726 69.1945205479452 5.00821917808219 0 0 0 0 0 0 0
"4918" 66.8438356164384 72.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"4919" 66.8438356164384 72.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"4920" 63.5917808219178 68.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"4921" 63.5917808219178 68.3643835616438 5.00821917808219 0 0 0 0 0 0 0
"4922" 64.9561643835616 69.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"4923" 64.9561643835616 69.2164383561644 5.00821917808219 0 0 0 0 0 0 0
"4924" 67.2438356164384 70.558904109589 5.00821917808219 0 0 0 0 0 0 0
"4925" 67.2438356164384 70.558904109589 5.00821917808219 0 0 0 0 0 0 0
"4926" 66.5424657534247 66.358904109589 5.00821917808219 0 0 0 0 0 0 0
"4927" 66.5424657534247 66.358904109589 5.00821917808219 0 0 0 0 0 0 0
"4928" 72.5178082191781 72.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"4929" 72.5178082191781 72.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"4930" 55.1835616438356 63.6575342465753 5.00821917808219 0 0 0 0 0 0 0
"4931" 55.1835616438356 63.6575342465753 5.00821917808219 0 0 0 0 0 0 0
"4932" 71.6109589041096 73.3178082191781 4.0027397260274 1 0 0 0 0 0 0
"4933" 60.2164383561644 66.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"4934" 60.2164383561644 66.8493150684932 5.00821917808219 0 0 0 0 0 0 0
"4935" 69.7945205479452 72.8602739726027 4.83561643835616 1 0 0 0 0 0 0
"4936" 69.7945205479452 72.8602739726027 4.83561643835616 1 0 0 0 0 0 0
"4937" 71.6712328767123 74.9068493150685 5.00821917808219 0 0 0 0 0 0 0
"4938" 68.3068493150685 68.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"4939" 68.3068493150685 68.4301369863014 5.00821917808219 0 0 0 0 0 0 0
"4940" 65.4958904109589 69.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"4941" 65.4958904109589 69.8465753424658 5.00821917808219 0 0 0 0 0 0 0
"4942" 77.1315068493151 75.8712328767123 4.16438356164384 1 0 0 0 0 0 0
"4943" 66.6027397260274 66.227397260274 5.00821917808219 0 0 0 0 0 0 0
"4944" 66.6027397260274 66.227397260274 5.00821917808219 0 0 0 0 0 0 0
"4945" 66.4520547945205 66.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"4946" 66.4520547945205 66.9671232876712 5.00821917808219 0 0 0 0 0 0 0
"4947" 63.5479452054795 73.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"4948" 63.5479452054795 73.0383561643836 5.00821917808219 0 0 0 0 0 0 0
"4949" 65.8986301369863 69.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"4950" 65.8986301369863 69.6054794520548 5.00821917808219 0 0 0 0 0 0 0
"4951" 63.5780821917808 69.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"4952" 63.5780821917808 69.9835616438356 5.00821917808219 0 0 0 0 0 0 0
"4953" 70.9890410958904 73.1315068493151 5.00821917808219 0 0 0 0 0 0 0
"4954" 70.9890410958904 73.1315068493151 5.00821917808219 0 0 0 0 0 0 0
"4955" 63.6164383561644 70.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"4956" 63.6164383561644 70.3150684931507 5.00821917808219 0 0 0 0 0 0 0
"4957" 71.5397260273973 75.6712328767123 5.00821917808219 0 0 0 0 0 0 0
"4958" 70.2082191780822 74.3013698630137 0.835616438356164 1 0 0 0 0 0 0
"4959" 70.2082191780822 74.3013698630137 0.835616438356164 1 0 0 0 0 0 0
"4960" 72.7287671232877 71.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4961" 72.7287671232877 71.5068493150685 5.00821917808219 0 0 0 0 0 0 0
"4962" 70.986301369863 72 5.00821917808219 0 0 0 0 0 0 0
"4963" 70.986301369863 72 5.00821917808219 0 0 0 0 0 0 0
"4964" 72.5315068493151 72.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"4965" 72.5315068493151 72.9041095890411 5.00821917808219 0 0 0 0 0 0 0
"4966" 63.3205479452055 71.7972602739726 5.00821917808219 0 0 0 0 0 0 0
"4967" 63.3205479452055 71.7972602739726 5.00821917808219 0 0 0 0 0 0 0
"4968" 64.5835616438356 68.7698630136986 5.00821917808219 0 0 0 0 0 0 0
"4969" 64.5835616438356 68.7698630136986 5.00821917808219 0 0 0 0 0 0 0
"4970" 69.5369863013699 70.6739726027397 5.00821917808219 0 0 0 0 0 0 0
"4971" 69.5369863013699 70.6739726027397 5.00821917808219 0 0 0 0 0 0 0
"4972" 68.4904109589041 71.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"4973" 68.4904109589041 71.6082191780822 5.00821917808219 0 0 0 0 0 0 0
"4974" 66.6027397260274 69.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"4975" 66.6027397260274 69.2219178082192 5.00821917808219 0 0 0 0 0 0 0
"4976" 72.2547945205479 72.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"4977" 72.2547945205479 72.1972602739726 5.00821917808219 0 0 0 0 0 0 0
"4978" 64.8246575342466 68.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"4979" 64.8246575342466 68.7397260273973 5.00821917808219 0 0 0 0 0 0 0
"4980" 69.3068493150685 69.9232876712329 5.00821917808219 0 0 0 0 0 0 0
"4981" 69.3068493150685 69.9232876712329 5.00821917808219 0 0 0 0 0 0 0
"4982" 65.6575342465753 72.027397260274 5.00821917808219 0 0 0 0 0 0 0
"4983" 65.6575342465753 72.027397260274 5.00821917808219 0 0 0 0 0 0 0
"4984" 58.9534246575342 70.4 5.00821917808219 0 0 0 0 0 0 0
"4985" 58.9534246575342 70.4 5.00821917808219 0 0 0 0 0 0 0
"4986" 66.213698630137 71.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"4987" 66.213698630137 71.3534246575342 5.00821917808219 0 0 0 0 0 0 0
"4988" 66.7013698630137 66.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"4989" 66.7013698630137 66.8630136986301 5.00821917808219 0 0 0 0 0 0 0
"4990" 68.9150684931507 68.1780821917808 5.00821917808219 0 0 0 0 0 0 0
"4991" 68.9150684931507 68.1780821917808 5.00821917808219 0 0 0 0 0 0 0
"4992" 59.8821917808219 68.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"4993" 59.8821917808219 68.5917808219178 5.00821917808219 0 0 0 0 0 0 0
"4994" 69.7287671232877 68.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"4995" 69.7287671232877 68.4794520547945 5.00821917808219 0 0 0 0 0 0 0
"4996" 58.372602739726 67.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"4997" 58.372602739726 67.2821917808219 5.00821917808219 0 0 0 0 0 0 0
"4998" 68.4465753424657 69.2191780821918 5.00821917808219 0 0 0 0 0 0 0
"4999" 68.4465753424657 69.2191780821918 5.00821917808219 0 0 0 0 0 0 0
"5000" 63.9150684931507 67.7890410958904 5.00821917808219 0 0 0 0 0 0 0

From dwinsemius at comcast.net  Tue Nov 19 22:10:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 13:10:23 -0800
Subject: [R] Optim function & Hessian matrix
In-Reply-To: <CAPMvz=Snp8y9c6NLj5hYp2Kr=p2E+HCk_eRMMsdWbuP1gjNEvQ@mail.gmail.com>
References: <CAPMvz=Snp8y9c6NLj5hYp2Kr=p2E+HCk_eRMMsdWbuP1gjNEvQ@mail.gmail.com>
Message-ID: <C793C0CB-99FB-4454-A000-7E2A5CF7A2A9@comcast.net>


On Nov 19, 2013, at 12:09 PM, sofeira taajobian wrote:

> Dear  R Users
> Hi,
> 
> 
> I have very emergency problems in my programming about  finding  MLE
> with optim command. I reproduced it  with real data. I guess that my
> function object in optim is very sensitive because it has power
> function .
> Then optim give me lower or initial values for estimates with these
> warnings for Hessian matrix computation:
> 1: In log(B2 * (C2^(y + v))) : NaNs produced
> 2: In log(B3 * C3^(x + u1)) : NaNs produced
> 3: In log(B4 * C4^(y + u2)) : NaNs produced
> 4: In log(B1 * (C1^(x + v))) : NaNs produced
> But I have  in result a hessian matrix with only first (2*2) block and
> other values are zero.
> It would not be the problem of code lead to this.  plz check the code
> and data, I attach them with this email. hope it can reduce some
> workload as copying and pasting.
> 
> 
> what may lead to this and any possible way to solve it? any suggestion
> are  appreciated. Plz help me as soon as possible because I don?t have
> enough time.
> <data4.txt>

Only the txt file made it throuhg. If you attached a .R file it would have been scrubbed. You need to rename it <something>.txt so you mailer sends it as MIME-text rather than "unknown"-type.


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From brian.s.diggs at gmail.com  Tue Nov 19 22:00:46 2013
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Tue, 19 Nov 2013 13:00:46 -0800
Subject: [R] Hide return values
In-Reply-To: <C5946240-ED71-47FB-94CF-A533F8276843@comcast.net>
References: <1384680116033-4680611.post@n4.nabble.com>
	<C5946240-ED71-47FB-94CF-A533F8276843@comcast.net>
Message-ID: <528BD17E.2070901@ohsu.edu>

On 11/17/2013 5:28 AM, David Winsemius wrote:
>
> On Nov 17, 2013, at 3:21 AM, Chris89 wrote:
>
>> Hi everyone!
>>
>> I am in the process of writing an R-package and while writing a summary
>> function, I have come across a problem. I am able to print a summary
>> table
>> (as in a standard glm() summary) by using *cat()* but the values I
>> return is
>> also printet.
>> How am I able to remove the return values from being printet, but still
>> being able to grab using e.g. summary$coeff??
>
> ?invisible

But don't. See R FAQ 8.1 for a better approach.

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From xiaochun at iupui.edu  Tue Nov 19 22:40:30 2013
From: xiaochun at iupui.edu (Li, Xiaochun)
Date: Tue, 19 Nov 2013 21:40:30 +0000
Subject: [R] Does function read.sas7bdat() have some memory limitations?
Message-ID: <59BCB7CFDB5BBB4E8FA26956BC3B1D42110C49E9@IU-MSSG-MBX102.ads.iu.edu>

Dear R-ers,

I was trying to read in a large sas7bdat file (size 148094976 bytes) using 'read.sas7bdat()', but it did not read in the data correctly.  E.g., the first 5 rows will come out like this (I'm omitting other columns to keep it readable):

       PERSON_ID           age
1  5.399114e-315 5.329436e-315
2  5.399114e-315 5.328302e-315
3  5.399114e-315 5.332026e-315
4  5.399114e-315 5.329112e-315
5  5.399114e-315 5.331055e-315

If I reduced the original sas dataset to the first 5 rows, 'read.sas7bdat' read them in correctly:

  PERSON_ID age
1    612569  55
2    612571  48
3    612580  78
4    612606  53
5    612617  66

So for now I first saved the sas dataset as .csv, then read using 'read.csv', everything is fine.  

Any suggestion why 'read.sas7bdat' didn't work, and if some fix in its code can make it work?

Thank  you.
_____________________________ 
Xiaochun Li, Ph.D. 
Department of Biostatistics 
Indiana University 
School of Medicine and
Richard M. Fairbanks School of Public Health


From scoyoc at gmail.com  Wed Nov 20 00:44:11 2013
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Tue, 19 Nov 2013 16:44:11 -0700
Subject: [R] Help with removing extra legend elements in ggplot
Message-ID: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/592ac670/attachment.pl>

From dwinsemius at comcast.net  Wed Nov 20 01:12:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 16:12:09 -0800
Subject: [R] Help with removing extra legend elements in ggplot
In-Reply-To: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
References: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
Message-ID: <428E8A62-AC8D-4318-AF61-7795F8FD8B59@comcast.net>


On Nov 19, 2013, at 3:44 PM, Matthew Van Scoyoc wrote:

> I can't get the fine tuning right with my legend. I get an extra legend
> element "10" which is the point size in my plot. Can someone help me get rid
> of this extra element? Additionally I would also like to reduce the size of
> the legend.
> 
> If you want to reproduce my figure you can  download my data in csv format
> here
> <https://github.com/scoyoc/EcoSiteDelineation/blob/master/VegNMDS_scores.csv
>> 
> .
> 
> Here is my code...
> 
>> veg.nmds.sc = read.csv("VegNMDS_scores.csv", header = T)
> 
>> nmds.fig = ggplot(data = veg.nmds.sc, aes(x = NMDS1, y = NMDS2))
>> nmds.fig + geom_point(aes(color = VegType, shape = VegType, size = 10)) +
>> scale_colour_manual(name = "Vegetation Type",
>>                     values = c("blue", "magenta", "gray50", "red",
>> "cyan3",
>>                                "green4", "gold")) +
>> scale_shape_manual(name = "Vegetation Type", values = c(15, 16, 17, 18,
>> 15, 16, 17)) +
>> theme_bw() +
>> theme(panel.background = element_blank(), panel.grid.major =
>> element_blank(),
>>       panel.grid.minor = element_blank(),
>>       legend.key = element_rect(color = "white")
>>       )
> 
> I have been messing around with
>> theme(..., legend.key.size = unit(1, "cm"))
> but I keep getting the error "could not find function unit". I'm not sure
> why, isn't unit supposed to be part of the legend.key argument?

Try this workaround to what sounds like a bug:

library(grid)

# then repeat the call.

-- 

David Winsemius
Alameda, CA, USA


From jim.silverton at gmail.com  Wed Nov 20 01:29:44 2013
From: jim.silverton at gmail.com (Jim Silverton)
Date: Tue, 19 Nov 2013 20:29:44 -0400
Subject: [R] (no subject)
Message-ID: <CAGPwjHwVZmNrVSd8WWjkcOuX62+KqrgnBa1vey5U=ApCJ+afqg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/03e2f154/attachment.pl>

From scoyoc at gmail.com  Wed Nov 20 01:35:25 2013
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Tue, 19 Nov 2013 17:35:25 -0700
Subject: [R] Help with removing extra legend elements in ggplot
In-Reply-To: <428E8A62-AC8D-4318-AF61-7795F8FD8B59@comcast.net>
References: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
	<428E8A62-AC8D-4318-AF61-7795F8FD8B59@comcast.net>
Message-ID: <CALx9ERWOo3qTXYhjR2vrKUKZ+Xkn31qBcksm8OTUKSbMhLC8LQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/b2af4fb8/attachment.pl>

From djmuser at gmail.com  Wed Nov 20 01:52:33 2013
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 19 Nov 2013 16:52:33 -0800
Subject: [R] Help with removing extra legend elements in ggplot
In-Reply-To: <CALx9ERWOo3qTXYhjR2vrKUKZ+Xkn31qBcksm8OTUKSbMhLC8LQ@mail.gmail.com>
References: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
	<428E8A62-AC8D-4318-AF61-7795F8FD8B59@comcast.net>
	<CALx9ERWOo3qTXYhjR2vrKUKZ+Xkn31qBcksm8OTUKSbMhLC8LQ@mail.gmail.com>
Message-ID: <CADv2QyH582BZGC4zeL0e6awG_uBxV++=c10OO7O+Q9KoR6LYmw@mail.gmail.com>

The additional element comes from this code:

geom_point(aes(color = VegType, shape = VegType, size = 10))

Take the size argument outside the aes() statement and the legend will
disappear:

geom_point(aes(color = VegType, shape = VegType), size = 10)

The aes() statement maps a variable to a plot aesthetic. In this case
you're mapping VegType to color and shape. You want to *set* the size
aesthetic to a constant value, and that is done by assigning the value
10 to the size aesthetic outside of aes().

Dennis

On Tue, Nov 19, 2013 at 4:35 PM, Matthew Van Scoyoc <scoyoc at gmail.com> wrote:
> No dice. I still get the "10" legend element.
> Thanks for the quick reply.
> Cheers,
>
> MVS
> =====
> Matthew Van Scoyoc
> Graduate Research Assistant, Ecology
> Wildland Resources Department <http://www.cnr.usu.edu/wild/> & Ecology
> Center <http://www.usu.edu/ecology/>
> Quinney College of Natural Resources <http://cnr.usu.edu/>
> Utah State University
> Logan, UT
>
> <mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
> =====
> Think SNOW!
>
>
> On Tue, Nov 19, 2013 at 5:12 PM, David Winsemius <dwinsemius at comcast.net>wrote:
>
>>
>> On Nov 19, 2013, at 3:44 PM, Matthew Van Scoyoc wrote:
>>
>> > I can't get the fine tuning right with my legend. I get an extra legend
>> > element "10" which is the point size in my plot. Can someone help me get
>> rid
>> > of this extra element? Additionally I would also like to reduce the size
>> of
>> > the legend.
>> >
>> > If you want to reproduce my figure you can  download my data in csv
>> format
>> > here
>> > <
>> https://github.com/scoyoc/EcoSiteDelineation/blob/master/VegNMDS_scores.csv
>> >>
>> > .
>> >
>> > Here is my code...
>> >
>> >> veg.nmds.sc = read.csv("VegNMDS_scores.csv", header = T)
>> >
>> >> nmds.fig = ggplot(data = veg.nmds.sc, aes(x = NMDS1, y = NMDS2))
>> >> nmds.fig + geom_point(aes(color = VegType, shape = VegType, size = 10))
>> +
>> >> scale_colour_manual(name = "Vegetation Type",
>> >>                     values = c("blue", "magenta", "gray50", "red",
>> >> "cyan3",
>> >>                                "green4", "gold")) +
>> >> scale_shape_manual(name = "Vegetation Type", values = c(15, 16, 17, 18,
>> >> 15, 16, 17)) +
>> >> theme_bw() +
>> >> theme(panel.background = element_blank(), panel.grid.major =
>> >> element_blank(),
>> >>       panel.grid.minor = element_blank(),
>> >>       legend.key = element_rect(color = "white")
>> >>       )
>> >
>> > I have been messing around with
>> >> theme(..., legend.key.size = unit(1, "cm"))
>> > but I keep getting the error "could not find function unit". I'm not sure
>> > why, isn't unit supposed to be part of the legend.key argument?
>>
>> Try this workaround to what sounds like a bug:
>>
>> library(grid)
>>
>> # then repeat the call.
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From scoyoc at gmail.com  Wed Nov 20 02:04:37 2013
From: scoyoc at gmail.com (Matthew Van Scoyoc)
Date: Tue, 19 Nov 2013 18:04:37 -0700
Subject: [R] Help with removing extra legend elements in ggplot
In-Reply-To: <CADv2QyH582BZGC4zeL0e6awG_uBxV++=c10OO7O+Q9KoR6LYmw@mail.gmail.com>
References: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
	<428E8A62-AC8D-4318-AF61-7795F8FD8B59@comcast.net>
	<CALx9ERWOo3qTXYhjR2vrKUKZ+Xkn31qBcksm8OTUKSbMhLC8LQ@mail.gmail.com>
	<CADv2QyH582BZGC4zeL0e6awG_uBxV++=c10OO7O+Q9KoR6LYmw@mail.gmail.com>
Message-ID: <CALx9ERU8vpMhk9zkpxbLU7U6pE1wxigTqH=GtBC=AYb9YNLX8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/d7bb9145/attachment.pl>

From kridox at ymail.com  Wed Nov 20 02:20:39 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 20 Nov 2013 10:20:39 +0900
Subject: [R] (no subject)
In-Reply-To: <CAGPwjHwVZmNrVSd8WWjkcOuX62+KqrgnBa1vey5U=ApCJ+afqg@mail.gmail.com>
References: <CAGPwjHwVZmNrVSd8WWjkcOuX62+KqrgnBa1vey5U=ApCJ+afqg@mail.gmail.com>
Message-ID: <CAAcyNCxd=wr98J7d2qPXjY0jAmnNu03YuK8myWJARJ6ew=M-kQ@mail.gmail.com>

Hello,

The value for 'start' is not correct. According to the help for
"fitdistr", 'start' should contain the paramaters used by the random
function (?rchisq)

Hope this helps,
Pascal

On 20 November 2013 09:29, Jim Silverton <jim.silverton at gmail.com> wrote:
> I generated some random data using R and then trying to see if it came from
> the same distribution but the erros keep piling.  Can anyone help?
>
>
>
> y=rchisq(100000,1)
> mean(y)
> var(y)
> library(MASS)
> fitdistr(y, "chi-squared", start = list(4), method = "Brent", lower=0.9,
> upper=3)
>
>
> --
> Thanks,
> Jim.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From pdxgary163 at gmail.com  Wed Nov 20 02:30:52 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Tue, 19 Nov 2013 17:30:52 -0800
Subject: [R] if else in R
Message-ID: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/570fab53/attachment.pl>

From matzke at berkeley.edu  Wed Nov 20 03:41:39 2013
From: matzke at berkeley.edu (Nick Matzke)
Date: Tue, 19 Nov 2013 21:41:39 -0500
Subject: [R] if else in R
In-Reply-To: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
References: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
Message-ID: <CAJdu7BDOrvKoRp2QGg4vs_C_bBnFL5RG4bNbAnxSD2q6-2PqZg@mail.gmail.com>

Hi,

This would be an issue with if() as well as if/else.  ab$b has 4
numbers in it, so ab$b > 0 evaluates to "TRUE TRUE FALSE TRUE" or
whatever. if() can only take a single true or false. Cheers! Nick

On Tue, Nov 19, 2013 at 8:30 PM, Gary Dong <pdxgary163 at gmail.com> wrote:
> Dear R users,
>
> I am a R beginner and I am having trouble in using "If Else" in R. Here is
> an example:
>
> ## create a data frame
>
> a<-c(1,2,3,4)
> b<-c(2,0,5,0)
> ab<-data.frame(cbind(a,b))
>
> ##calculate c, which is the ratio between a and b
>
> if(ab$b>0) {
>  ab$c<-ab$a/ab$b
> } else {
>  ab$c<-0
>  }
>
> here is the error I got:
>
> Warning message:
> In if (ab$b > 0) { :
>   the condition has length > 1 and only the first element will be used.
>
> Any help is appreciated!
>
> Gary
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Wed Nov 20 03:54:43 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 19 Nov 2013 21:54:43 -0500
Subject: [R] if else in R
In-Reply-To: <CAJdu7BDOrvKoRp2QGg4vs_C_bBnFL5RG4bNbAnxSD2q6-2PqZg@mail.gmail.com>
References: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
	<CAJdu7BDOrvKoRp2QGg4vs_C_bBnFL5RG4bNbAnxSD2q6-2PqZg@mail.gmail.com>
Message-ID: <743671A8-81FA-499D-BBDD-666EE264759D@bigelow.org>

Hi,

On Nov 19, 2013, at 9:41 PM, Nick Matzke <matzke at berkeley.edu> wrote:

> Hi,
> 
> This would be an issue with if() as well as if/else.  ab$b has 4
> numbers in it, so ab$b > 0 evaluates to "TRUE TRUE FALSE TRUE" or
> whatever. if() can only take a single true or false. Cheers! Nick
> 

As a follow up, you could make a logical index for the condition as Nick suggests.

a<-c(1,2,3,4)
b<-c(2,0,5,0)
ab<-data.frame(a,b)
ix <- ab[,'b'] > 0
ix
# [1]  TRUE FALSE  TRUE FALSE

ab[ix,'c'] <- ab[ix,'a']/ab[ix,'b']
ab[!ix,'c'] <- 0
ab
#  a b   c
# 1 1 2 0.5
# 2 2 0 0.0
# 3 3 5 0.6
# 4 4 0 0.0

I'm not a big fan of the ab$b form of subsetting, I find ab[,'b'] more readable for my fading eyesight.  But you could do it your way, too.

ab$c[ix] <- ab$a[ix]/ab$b[ix]

Cheers,
Ben


> On Tue, Nov 19, 2013 at 8:30 PM, Gary Dong <pdxgary163 at gmail.com> wrote:
>> Dear R users,
>> 
>> I am a R beginner and I am having trouble in using "If Else" in R. Here is
>> an example:
>> 
>> ## create a data frame
>> 
>> a<-c(1,2,3,4)
>> b<-c(2,0,5,0)
>> ab<-data.frame(cbind(a,b))
>> 
>> ##calculate c, which is the ratio between a and b
>> 
>> if(ab$b>0) {
>> ab$c<-ab$a/ab$b
>> } else {
>> ab$c<-0
>> }
>> 
>> here is the error I got:
>> 
>> Warning message:
>> In if (ab$b > 0) { :
>>  the condition has length > 1 and only the first element will be used.
>> 
>> Any help is appreciated!
>> 
>> Gary
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From smartpink111 at yahoo.com  Wed Nov 20 03:56:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 19 Nov 2013 18:56:19 -0800 (PST)
Subject: [R] if else in R
In-Reply-To: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
References: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
Message-ID: <1384916179.52321.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
within(ab, {c <- ifelse(b>0, a/b,0)})
A.K.




On Tuesday, November 19, 2013 8:51 PM, Gary Dong <pdxgary163 at gmail.com> wrote:
Dear R users,

I am a R beginner and I am having trouble in using "If Else" in R. Here is
an example:

## create a data frame

a<-c(1,2,3,4)
b<-c(2,0,5,0)
ab<-data.frame(cbind(a,b))

##calculate c, which is the ratio between a and b

if(ab$b>0) {
ab$c<-ab$a/ab$b
} else {
ab$c<-0
}

here is the error I got:

Warning message:
In if (ab$b > 0) { :
? the condition has length > 1 and only the first element will be used.

Any help is appreciated!

Gary

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Wed Nov 20 04:02:08 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 19 Nov 2013 19:02:08 -0800
Subject: [R] if else in R
In-Reply-To: <CAJdu7BDOrvKoRp2QGg4vs_C_bBnFL5RG4bNbAnxSD2q6-2PqZg@mail.gmail.com>
References: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
	<CAJdu7BDOrvKoRp2QGg4vs_C_bBnFL5RG4bNbAnxSD2q6-2PqZg@mail.gmail.com>
Message-ID: <c3facd8a-b657-4899-acff-d92e06cfd10f@email.android.com>

Which means you should use the ifelse function...

ab$c <- ifelse( ab$b>0, ab$a/ab$b, 0 )
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Nick Matzke <matzke at berkeley.edu> wrote:
>Hi,
>
>This would be an issue with if() as well as if/else.  ab$b has 4
>numbers in it, so ab$b > 0 evaluates to "TRUE TRUE FALSE TRUE" or
>whatever. if() can only take a single true or false. Cheers! Nick
>
>On Tue, Nov 19, 2013 at 8:30 PM, Gary Dong <pdxgary163 at gmail.com>
>wrote:
>> Dear R users,
>>
>> I am a R beginner and I am having trouble in using "If Else" in R.
>Here is
>> an example:
>>
>> ## create a data frame
>>
>> a<-c(1,2,3,4)
>> b<-c(2,0,5,0)
>> ab<-data.frame(cbind(a,b))
>>
>> ##calculate c, which is the ratio between a and b
>>
>> if(ab$b>0) {
>>  ab$c<-ab$a/ab$b
>> } else {
>>  ab$c<-0
>>  }
>>
>> here is the error I got:
>>
>> Warning message:
>> In if (ab$b > 0) { :
>>   the condition has length > 1 and only the first element will be
>used.
>>
>> Any help is appreciated!
>>
>> Gary
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From nosbueschkai at t-online.de  Wed Nov 20 02:22:43 2013
From: nosbueschkai at t-online.de (Hlebtomane)
Date: Tue, 19 Nov 2013 17:22:43 -0800 (PST)
Subject: [R] If commands in a while loop
Message-ID: <1384910563835-4680775.post@n4.nabble.com>

Unfortunately, the while loop in the following code doesn't seem to work. It
would be very nice
if someone might help me, thanks in advance:

 z = 0*c(1:1000)

  while (sum(z) < 751){
  for(mu in (900:1100)/10000){
  for(i in(1:1000)) {
	z[i] <- V5[i]*exp(5*mu)
  	
	if (z[i] >= 1276281) {z[i] <- 1}
	else{z[i] <- 0}	
	}
	}
  			   }




--
View this message in context: http://r.789695.n4.nabble.com/If-commands-in-a-while-loop-tp4680775.html
Sent from the R help mailing list archive at Nabble.com.


From tovinod at gmail.com  Wed Nov 20 02:30:50 2013
From: tovinod at gmail.com (Vinod Mishra)
Date: Wed, 20 Nov 2013 12:30:50 +1100
Subject: [R] R- package for Parametric Survival Analysis with Left-censored
	data
Message-ID: <FD924877-2682-4799-AC91-7FC65A68FBB0@gmail.com>

Dear All,

I am new to R. Can someone please direct me to an R package using which I can estimate a Parametric Survival Analysis model with Left-censored (delayed entry) data in it. 

I recently received reviewers comment on my submitted article, where the reviewer suggested that only R has capabilities of estimating above mentioned survival model. However, I am not able to figure which specific package in R, the reviewer was referring to. 

Any pointer would be greatly appreciated !!

cheers,

Vinod Mishra  

From dwinsemius at comcast.net  Wed Nov 20 04:12:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 19:12:03 -0800
Subject: [R] if else in R
In-Reply-To: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
References: <CAEVDvzV76YjfnuOi-_xkp9h=6sioAQy+oa3UeYa=6KBV6XibTQ@mail.gmail.com>
Message-ID: <8B83C83A-4791-4ECE-9740-5711F0AD81B8@comcast.net>


On Nov 19, 2013, at 5:30 PM, Gary Dong wrote:

> Dear R users,
> 
> I am a R beginner and I am having trouble in using "If Else" in R. Here is
> an example:
> 
> ## create a data frame
> 
> a<-c(1,2,3,4)
> b<-c(2,0,5,0)
> ab<-data.frame(cbind(a,b))
> 
> ##calculate c, which is the ratio between a and b
> 
> if(ab$b>0) {
> ab$c<-ab$a/ab$b
> } else {
> ab$c<-0
> }
> 
> here is the error I got:

Consider this alternative:

 ab$c <- (ab  >0 ) * ab$a/ab$b

Although in general, you will probably use `ifelse`.

?ifelse   # different than ?"if"

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov 20 04:14:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 19:14:25 -0800
Subject: [R] If commands in a while loop
In-Reply-To: <1384910563835-4680775.post@n4.nabble.com>
References: <1384910563835-4680775.post@n4.nabble.com>
Message-ID: <3D661D50-8C0C-40D0-A4A8-5592C7304420@comcast.net>


On Nov 19, 2013, at 5:22 PM, Hlebtomane wrote:

> Unfortunately, the while loop in the following code doesn't seem to work. It
> would be very nice
> if someone might help me, thanks in advance:
> 
> z = 0*c(1:1000)

I think it is more likely that you don't know what z looks like. Try `head(z)`


> 
>  while (sum(z) < 751){
>  for(mu in (900:1100)/10000){
>  for(i in(1:1000)) {
> 	z[i] <- V5[i]*exp(5*mu)
>  	
> 	if (z[i] >= 1276281) {z[i] <- 1}
> 	else{z[i] <- 0}	
> 	}
> 	}
>  			   }
-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov 20 04:15:58 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 19:15:58 -0800
Subject: [R] R- package for Parametric Survival Analysis with
	Left-censored data
In-Reply-To: <FD924877-2682-4799-AC91-7FC65A68FBB0@gmail.com>
References: <FD924877-2682-4799-AC91-7FC65A68FBB0@gmail.com>
Message-ID: <74357FCC-94DC-4BC5-9D2E-7644308465A7@comcast.net>


On Nov 19, 2013, at 5:30 PM, Vinod Mishra wrote:

> Dear All,
> 
> I am new to R. Can someone please direct me to an R package using which I can estimate a Parametric Survival Analysis model with Left-censored (delayed entry) data in it. 
> 
> I recently received reviewers comment on my submitted article, where the reviewer suggested that only R has capabilities of estimating above mentioned survival model. However, I am not able to figure which specific package in R, the reviewer was referring to. 

Look at:

?Surv 

... after loading the survival package. (I do think you would be advised to seek statistical consultation.)

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Wed Nov 20 05:14:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 19 Nov 2013 20:14:58 -0800 (PST)
Subject: [R] Datatable manipulation
In-Reply-To: <CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>
	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>
Message-ID: <1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- read.table(text="a b c
x 1 4 7
y 2 5 8
z 3 6 9",header=TRUE)
dat2 <- dat1
#either
library(reshape2)
res1 <- within(melt(dat1,id.var="ID"),cell<-as.character(interaction(variable,ID,sep="_")))[,c(4,3)]

#or
indx <- which(dat2>0,arr.ind=TRUE) 
res2 <- data.frame(cell=paste(colnames(dat2)[indx[,2]],rownames(dat2)[indx[,1]],sep="_"),value=dat2[indx],stringsAsFactors=FALSE)
?identical(res1,res2)
#[1] TRUE

A.K.



On Tuesday, November 19, 2013 11:07 PM, Nitisha jha <nitisha999 at gmail.com> wrote:

Hi
could you please let me know the solution?
Thanks




On Wed, Nov 20, 2013 at 4:13 AM, <smartpink111 at yahoo.com> wrote:

Hi,
>If this is a data.frame(), then I have some solution for this problem. ?Also, you need to post it in R-help if that is the case.
>Thanks.
>A.K.
><quote author='nuts'>
>Sample input dataset where a,b,c are col names. x y z are row names.
>? ? ? ? a ? ? ? b ? ? ? c
>x ? ? ? 1 ? ? ? 4 ? ? ? 7
>y ? ? ? 2 ? ? ? 5 ? ? ? 8
>z ? ? ? 3 ? ? ? 6 ? ? ? 9
>
>I want output to be like this after manipulating the dataset.
>cell ? ?value
>a_x ? ? 1
>a_y ? ? 2
>a_z ? ? 3
>b_x ? ? 4
>b_y ? ? 5
>b_z ? ? 6
>c_x ? ? 7
>c_y ? ? 8
>c_z ? ? 9
>where cell and value are the colnames.
>How do I achieve this? I am at a loss here.
>
>
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/Datatable-manipulation-tp4680747.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>


From dwinsemius at comcast.net  Wed Nov 20 08:05:11 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Nov 2013 23:05:11 -0800
Subject: [R] Optim function & Hessian matrix
In-Reply-To: <CAPMvz=Snp8y9c6NLj5hYp2Kr=p2E+HCk_eRMMsdWbuP1gjNEvQ@mail.gmail.com>
References: <CAPMvz=Snp8y9c6NLj5hYp2Kr=p2E+HCk_eRMMsdWbuP1gjNEvQ@mail.gmail.com>
Message-ID: <FB90FD74-A322-456B-B102-4299B0557FFC@comcast.net>

This is the code that was attached. I arrived in the copy sent to my email address:

#------------------

L1=function(X){
B1=X[1]
C1=X[2]
B2=X[3]
C2=X[4]
mu=X[5]

S=-(B1*(C1^x)*((C1^v)-1)/log(C1))
  +(d2*log(B1*(C1^(x+v))))
  -(B2*(C2^y)*((C2^v)-1)/log(C2))
  +(d1*log(B2*(C2^(y+v))))
  -(v*mu)
  +(d3*log(mu))

return(sum(S))
}

L2=function(X){
B3=X[1]
C3=X[2]
sum(-(B3*(C3^(x+u1)-C3^(x))) + h1*log(B3*C3^(x+u1)))
}

L3=function(X){
B4=X[1]
C4=X[2]
sum(-(B4*(C4^(y+u2)-C4^(y))) + h2*log(B4*C4^(y+u2)))
}


L=function(X){
B1=X[1]
C1=X[2]
B2=X[3]
C2=X[4]
mu=X[5]
B3=X[6]
C3=X[7]
B4=X[8]
C4=X[9]


L=L1(c(B1,C1,B2,C2,mu))
 +L2(c(B3,C3))
 +L3(c(B4,C4))
-L
}


Sol=nlminb(c(7.741*10^(-7),1.155,2.422*10^(-5),1.0889,.001307,2.51*10^(-5),1.0712,3.7654*10^(-4),1.0561),L,
lower=c(7.000*10^(-7),1.055,2.122*10^(-5),1.0689,.001107,2.13*10^(-5),1.0088,3.5437*10^(-4),1.0612),
upper=c(1.0299*10^(-6),1.214,2.822*10^(-5),1.0989,.015407,2.77*10^(-5),1.1888,3.8737*10^(-4),1.0812),control=list(iter.max=1500))

par=Sol$par

optim(par,L,method="L-BFGS-B",
lower=c(7.000*10^(-7),1.055,2.122*10^(-5),1.0689,.001107,2.13*10^(-5),1.0088,3.5437*10^(-4),1.0612),
upper=c(1.0299*10^(-6),1.214,2.822*10^(-5),1.0989,.015407,2.77*10^(-5),1.0888,3.8737*10^(-4),1.0712),control=list(maxit=1500,pgtol=10^(-7)),hessian=TRUE)


-- 
David.


On Nov 19, 2013, at 12:09 PM, sofeira taajobian wrote:

> Dear  R Users
> Hi,
> 
> 
> I have very emergency problems in my programming about  finding  MLE
> with optim command. I reproduced it  with real data. I guess that my
> function object in optim is very sensitive because it has power
> function .
> Then optim give me lower or initial values for estimates with these
> warnings for Hessian matrix computation:
> 1: In log(B2 * (C2^(y + v))) : NaNs produced
> 2: In log(B3 * C3^(x + u1)) : NaNs produced
> 3: In log(B4 * C4^(y + u2)) : NaNs produced
> 4: In log(B1 * (C1^(x + v))) : NaNs produced
> But I have  in result a hessian matrix with only first (2*2) block and
> other values are zero.
> It would not be the problem of code lead to this.  plz check the code
> and data, I attach them with this email. hope it can reduce some
> workload as copying and pasting.
> 
> 
> what may lead to this and any possible way to solve it? any suggestion
> are  appreciated. Plz help me as soon as possible because I don?t have
> enough time.
> <data4.txt>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Wed Nov 20 08:17:30 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 20 Nov 2013 08:17:30 +0100
Subject: [R] R- package for Parametric Survival Analysis with
	Left-censored data
In-Reply-To: <74357FCC-94DC-4BC5-9D2E-7644308465A7@comcast.net>
References: <FD924877-2682-4799-AC91-7FC65A68FBB0@gmail.com>
	<74357FCC-94DC-4BC5-9D2E-7644308465A7@comcast.net>
Message-ID: <79AA7C00-7DB3-4851-A24D-10E2A22DBF0F@gmail.com>


On 20 Nov 2013, at 04:15 , David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Nov 19, 2013, at 5:30 PM, Vinod Mishra wrote:
> 
>> Dear All,
>> 
>> I am new to R. Can someone please direct me to an R package using which I can estimate a Parametric Survival Analysis model with Left-censored (delayed entry) data in it. 
>> 
>> I recently received reviewers comment on my submitted article, where the reviewer suggested that only R has capabilities of estimating above mentioned survival model. However, I am not able to figure which specific package in R, the reviewer was referring to. 
> 
> Look at:
> 
> ?Surv 
> 
> ... after loading the survival package. (I do think you would be advised to seek statistical consultation.)
> 

In particular, notice the difference between left censoring (some patients are known to have died at an unknown time before t0) and left truncation (we only know survival times for patients alive at t0). Delayed entry is the latter.

> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From alaios at yahoo.com  Wed Nov 20 08:36:02 2013
From: alaios at yahoo.com (Alaios)
Date: Tue, 19 Nov 2013 23:36:02 -0800 (PST)
Subject: [R] save table to txt file in a printable form
Message-ID: <1384932962.41154.YahooMailNeo@web125301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131119/5e12fe88/attachment.pl>

From es at enricoschumann.net  Wed Nov 20 08:58:07 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Wed, 20 Nov 2013 08:58:07 +0100
Subject: [R] save table to txt file in a printable form
In-Reply-To: <1384932962.41154.YahooMailNeo@web125301.mail.ne1.yahoo.com>
	(alaios@yahoo.com's message of "Tue, 19 Nov 2013 23:36:02 -0800
	(PST)")
References: <1384932962.41154.YahooMailNeo@web125301.mail.ne1.yahoo.com>
Message-ID: <87wqk3ijxs.fsf@enricoschumann.net>

On Wed, 20 Nov 2013, Alaios <alaios at yahoo.com> writes:

> Hi there,
> I would like to save tabular (in R just matrices) in a txt file but in a way that they would be somehow readable.
> That means keeping columns aligned and rows so one can read easily for example the 2,3 element.
>
> IS there a way to do that in R?
> capture.output for example does not produce tables in the way I want to have those.

Please provide an example that shows what you want to achieve, and why
capture.output does not work.

  A <- rnorm(12)
  dim(A) <- c(4,3)
  colnames(A) <- LETTERS[1:3]
  A

  #              A          B          C
  # [1,] 1.3883785  1.7264519 -0.1340838
  # [2,] 1.0601385 -0.2378076  0.2078081
  # [3,] 0.7278065 -0.1279776 -1.1674676
  # [4,] 1.3321629 -1.4082142  0.9145042

  capture.output(A)
  # [1] "             A          B          C"
  # [2] "[1,] 1.3883785  1.7264519 -0.1340838"
  # [3] "[2,] 1.0601385 -0.2378076  0.2078081"
  # [4] "[3,] 0.7278065 -0.1279776 -1.1674676"
  # [5] "[4,] 1.3321629 -1.4082142  0.9145042"

  # writeLines(capture.output(A), "matrix.txt") ## or similar


>
> Regards
> Alex
> 	[[alternative HTML version deleted]]

Please send plain-text emails.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From nosbueschkai at t-online.de  Wed Nov 20 09:13:02 2013
From: nosbueschkai at t-online.de (Hlebtomane)
Date: Wed, 20 Nov 2013 00:13:02 -0800 (PST)
Subject: [R] If commands in a while loop
In-Reply-To: <1384934234507-4680791.post@n4.nabble.com>
References: <1384910563835-4680775.post@n4.nabble.com>
	<3D661D50-8C0C-40D0-A4A8-5592C7304420@comcast.net>
	<1384934234507-4680791.post@n4.nabble.com>
Message-ID: <1384935182648-4680793.post@n4.nabble.com>

Oh I forgot to mention that I had the standard normal distributed RVs in the
exponent to form V5. Otherwise it would make no sense.



--
View this message in context: http://r.789695.n4.nabble.com/If-commands-in-a-while-loop-tp4680775p4680793.html
Sent from the R help mailing list archive at Nabble.com.


From mohan.radhakrishnan at polarisft.com  Wed Nov 20 10:02:07 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 20 Nov 2013 14:32:07 +0530
Subject: [R] Functional Programming patterns
Message-ID: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/0f5c31ac/attachment.pl>

From msuzen at gmail.com  Wed Nov 20 10:42:59 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 20 Nov 2013 10:42:59 +0100
Subject: [R] Functional Programming patterns
In-Reply-To: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>
References: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>
Message-ID: <CAPtbhHxeGDEoFDNvOKKrHJPFVcYUJyVZAMNDHNpF3jnsk_AYjA@mail.gmail.com>

Have you checked the r.lambda package of Brian Lee Yung Rowe
?

http://cran.r-project.org/web/packages/lambda.r/index.html

On 20 November 2013 10:02,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
> '
> Not specific to 'R'. I search for patterns and found
> http://patternsinfp.wordpress.com/ which is too heavy for me. There is a
> 'Pragmatic Programmer' book on such patterns for Scala and Clojure. Is
> there anything for R ?
>
> I wanted to code this. Is there a functional pattern in R for multiple
> 'if' loops like this ?
>
>         if( is.na(str_extract(input,"T[^.]*")[1]) ){
>
>         }else{
>
>
> Thanks,
> Mohan
>
>
> This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michel.arnaud at cirad.fr  Wed Nov 20 11:28:41 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 20 Nov 2013 11:28:41 +0100
Subject: [R] To transform an adjacency matrix
Message-ID: <528C8ED9.4090502@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/850e45dc/attachment.pl>

From kridox at ymail.com  Wed Nov 20 11:55:44 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 20 Nov 2013 19:55:44 +0900
Subject: [R] To transform an adjacency matrix
In-Reply-To: <528C8ED9.4090502@cirad.fr>
References: <528C8ED9.4090502@cirad.fr>
Message-ID: <CAAcyNCwWL+sk=rRMENZ_B0_+fXo6_0DdfDBoNuupniB8XXTsWw@mail.gmail.com>

Hello,

One approach is:

m <- structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,
0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))
out <- which(m==1, arr.ind=TRUE)
out[order(out[,1]),]

Regards,
Pascal

On 20 November 2013 19:28, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> Hi
> I have the following problem
> I would like to build, from a matrix filled with 0 and with 1, a matrix
> or a data.frame which contains, in every line, the number of the line
> and the number of the column of the matrix for which the value is equal
> to 1.
> Exemple :
>
> dput(m)
> structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
> 0, 0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))
>
> Result
>
> 1 5
> 2 3
> 2 4
> 4 1
> 4 3
>
> Thank you for your help
>
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From dulcalma at bigpond.com  Wed Nov 20 12:24:13 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 20 Nov 2013 21:24:13 +1000
Subject: [R] Repeated measures with categorical data
In-Reply-To: <loom.20131119T144902-423@post.gmane.org>
References: <1384867440358-4680733.post@n4.nabble.com>
	<loom.20131119T144902-423@post.gmane.org>
Message-ID: <001101cee5e3$0a95a800$1fc0f800$@bigpond.com>

Also take a look at packages multgee  repolr and VGAM, particularly repolr
if your data does not fit the PO model

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Ben Bolker
Sent: Tuesday, 19 November 2013 23:51
To: r-help at stat.math.ethz.ch
Subject: Re: [R] Repeated measures with categorical data

sualme <susana.alberichmesa <at> osakidetza.net> writes:

> 
> Hello,
> I am working in a longitudinal study, with a categorical variable as a 
> dependent variable (alcohol consumption: no use, use, abuse and 
> dependence) with repeated measures (baseline, 1 year, 2 years). 
> Besides I have another variable with two groups: control and experimental.
> 
> I would like to analyze the evolution in each group, I have though in 
> lme, but I am not sure if I can do an lme with a categorical vble as 
> dependent vble, or it must be continuous. If so, which model could I 
> do? I have read something about lmer, but doesn`t give p-values..
> 
> Thanks in advance!

  I'd take a look at the clmm function in the 'ordinal' package, or possibly
the MCMCglmm package, and consider posting future questions to
r-sig-mixed-models at r-project.org .  (Your response variable is probably
considered 'ordinal', i.e. ordered categorical, which may be helpful
terminology in searching for solutions.)

  Ben Bolker

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rainmaker.nsk at gmail.com  Wed Nov 20 13:13:59 2013
From: rainmaker.nsk at gmail.com (Nachiket Kelkar)
Date: Wed, 20 Nov 2013 17:43:59 +0530
Subject: [R] help with converting a data frame into object of class "track"
Message-ID: <F48C1A4F-16B4-46AA-9639-E676B985E33E@gmail.com>

Dear R users,

I am trying to run a Bayesian change point analysis on a time series with the R package "bcpa". However, the data file needs to be of the class "track". My data file is at present a three-column data frame (Time, X and Y coordinates) and I am unable to change to class "track" using either "setClass", "setAs" or "as", and if I try to coerce it gives an error message that doesn't allow me to do that.

Please help!

Best regards,

Nachiket

ATREE, Bangalore

From carl at witthoft.com  Wed Nov 20 13:24:00 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Wed, 20 Nov 2013 04:24:00 -0800 (PST)
Subject: [R] Multiple if statement in loop condition
In-Reply-To: <1384942699996-4680797.post@n4.nabble.com>
References: <1384942699996-4680797.post@n4.nabble.com>
Message-ID: <1384950240514-4680803.post@n4.nabble.com>

What this message means is that a "{" showed up when some other bracket was
unpaired.  In this case, if you check your code, you'll see that 
"if(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0))"  is
lacking a closing ")"  for the if clause.

 

Phalaen wrote
> Hi! 
> I am a Phd student in the university of Padua and I am trying to write a
> little script (the first!) to make a simulation on epidemiology.
> I'd like to change the values of a vector of 883 values basing on a
> neighbour matrix constructed with nb2mat from a shapefile: if i and j (two
> cells) are neighbour (matrix) and i or j have a positive value in the
> vector, I'd like to transform the value of both i and j to 1 (positive),
> otherwise the value of i and j should remain 0. When I launch the next
> little script:
> 
> for(i in 1:883)
>  { for(j in 1:883)
>   { if(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0)) {
> 	 vectorID[i] = 1 & vectorID[j] = 1
> 		print(vectorID)
>  } } } 
> 
> the answer from the software is:
> Error: unexpected '{' in:
> " { for(j in 1:883)
>  { while(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0)) {"
> 
> I think that it is an error in the statement for if but I can not
> understand how to solve it...
> Thank you everyone!
> Elisa





--
View this message in context: http://r.789695.n4.nabble.com/Multiple-if-statement-in-loop-condition-tp4680797p4680803.html
Sent from the R help mailing list archive at Nabble.com.


From michel.arnaud at cirad.fr  Wed Nov 20 13:45:17 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 20 Nov 2013 13:45:17 +0100
Subject: [R] To transform an adjacency matrix
In-Reply-To: <CAAcyNCwWL+sk=rRMENZ_B0_+fXo6_0DdfDBoNuupniB8XXTsWw@mail.gmail.com>
References: <528C8ED9.4090502@cirad.fr>
	<CAAcyNCwWL+sk=rRMENZ_B0_+fXo6_0DdfDBoNuupniB8XXTsWw@mail.gmail.com>
Message-ID: <528CAEDD.8000808@cirad.fr>

Thank you Pascal
Its fine
Michel
Le 20/11/2013 11:55, Pascal Oettli a ?crit :
> Hello,
>
> One approach is:
>
> m <- structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,
> 0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))
> out <- which(m==1, arr.ind=TRUE)
> out[order(out[,1]),]
>
> Regards,
> Pascal
>
> On 20 November 2013 19:28, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>> Hi
>> I have the following problem
>> I would like to build, from a matrix filled with 0 and with 1, a matrix
>> or a data.frame which contains, in every line, the number of the line
>> and the number of the column of the matrix for which the value is equal
>> to 1.
>> Exemple :
>>
>> dput(m)
>> structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
>> 0, 0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))
>>
>> Result
>>
>> 1 5
>> 2 3
>> 2 4
>> 4 1
>> 4 3
>>
>> Thank you for your help
>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>>
>>          [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From h.wickham at gmail.com  Wed Nov 20 14:16:30 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 20 Nov 2013 07:16:30 -0600
Subject: [R] Functional Programming patterns
In-Reply-To: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>
References: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>
Message-ID: <CABdHhvGA0spVVv6a+Lj8UcyHGVA2ahfdesszJrYbdKhdTtvX4A@mail.gmail.com>

I have some notes on functional programming in R at http://adv-r.had.co.nz/.

Hadley

On Wed, Nov 20, 2013 at 3:02 AM,  <mohan.radhakrishnan at polarisft.com> wrote:
> Hi,
> '
> Not specific to 'R'. I search for patterns and found
> http://patternsinfp.wordpress.com/ which is too heavy for me. There is a
> 'Pragmatic Programmer' book on such patterns for Scala and Clojure. Is
> there anything for R ?
>
> I wanted to code this. Is there a functional pattern in R for multiple
> 'if' loops like this ?
>
>         if( is.na(str_extract(input,"T[^.]*")[1]) ){
>
>         }else{
>
>
> Thanks,
> Mohan
>
>
> This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.
>
> Visit us at http://www.polarisFT.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From smartpink111 at yahoo.com  Wed Nov 20 14:47:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 05:47:55 -0800 (PST)
Subject: [R] regression by group summary error
In-Reply-To: <CAEW+BD+dcF5Fu+pQT0PzJxqOFb8AJ62=wfDEWxDJ5s1yARwkPA@mail.gmail.com>
References: <CAEW+BD+dcF5Fu+pQT0PzJxqOFb8AJ62=wfDEWxDJ5s1yARwkPA@mail.gmail.com>
Message-ID: <1384955275.10800.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Catalin,

I tried with a subset of the variables.? Infact, there is an option in lmList() to subset

biN <- bi[,c(1,3,22,34)]
str(biN)
'data.frame':??? 66 obs. of? 4 variables:
?$ Exp????????? : chr? "B" "B" "B" "B" ...
?$ Clona??????? : Factor w/ 5 levels "A4A","AF2","Max4",..: 3 3 3 3 3 3 3 3 3 3 ...
?$ CR2V.cm.???? : num? 20.4 19.6 24 22.2 27.6 24.2 19.4 22.2 21.5 28.2 ...
?$ masa.uscat.tr: num? 6.2 3.88 7.82 5.65 10.2 ...


?by(biN,biN$Exp, function(x) summary(lmList(masa.uscat.tr~CR2V.cm.|Clona,data=x,na.action=na.omit)))
biN$Exp: B
Call:
? Model: masa.uscat.tr ~ CR2V.cm. | Clona 
?? Data: x 

Coefficients:
?? (Intercept) 
??? Estimate?? Std. Error????? t value???? Pr(>|t|) 
-8.252204377? 1.668647582 -4.945444721? 0.001127319 
?? CR2V.cm. 
??? Estimate?? Std. Error????? t value???? Pr(>|t|) 
6.674136e-01 7.218748e-02 9.245559e+00 1.519752e-05 

Residual standard error: 0.6671037 on 8 degrees of freedom

------------------------------------------------------------ 
biN$Exp: C
Call:
? Model: masa.uscat.tr ~ CR2V.cm. | Clona 
?? Data: x 

Coefficients:
?? (Intercept) 
?????????? Estimate Std. Error?? t value?? Pr(>|t|)
A4A?????? -6.941742?? 6.698275 -1.036348 0.30545738
AF2????? -10.368170?? 4.669365 -2.220467 0.03135312
Max4????? -6.766456?? 2.925135 -2.313211 0.02523457
Monviso??? 9.493789?? 3.779740? 2.511757 0.01558630
Pannonia? -8.044174?? 3.617619 -2.223610 0.03112594
?? CR2V.cm. 
?????????? Estimate Std. Error?? t value???? Pr(>|t|)
A4A????? 0.62752742? 0.2513938 2.4961928 1.619954e-02
AF2????? 0.72802937? 0.1609617 4.5229977 4.270833e-05
Max4???? 0.63517380? 0.1377759 4.6101954 3.209599e-05
Monviso? 0.04123701? 0.1366451 0.3017818 7.641786e-01
Pannonia 0.74293255? 0.1187515 6.2561931 1.194664e-07

Residual standard error: 1.473519 on 46 degrees of freedom




A.K.






On Wednesday, November 20, 2013 5:53 AM, catalin roibu <catalinroibu at gmail.com> wrote:

Hello!
I have a problem with R. I want to apply a linear model for data composed by two groups (Exp and Clona). i try this code:
by(bi,bi$Exp, function(x) lmList(masa.uscat.tr~CR2V.cm.|Clona,data=x,na.action=na.omit))

But I want to view to summary for each Exp and i try this code:
by(bi,bi$Exp, function(x) summary(lmList(masa.uscat.tr~CR2V.cm.|Clona,data=x,na.action=na.omit)))

And I have this error:
Error in `[<-`(`*tmp*`, use, use, ii, value = lst[[ii]]) :?
? subscript out of bounds

Please help me to solve this problem!

Thank you very much!

?My data is:

ExpPlotClonaProvmasa uscat trmasa usc. Rammasa usc total
B36Max4 PPuieti6.1998484852.6393258438.839174328
B36Max4 PPuieti3.878751.47985.35855
B36Max4 PPuieti7.8227027033.3285207111.15122341
B36Max4 PPuieti5.6453846151.9952380957.640622711
B36Max4 PPuieti10.23.51486486513.71486486
B36Max4 PPuieti8.8155454553.3562790712.17182452
B36Max4 PPuieti5.0333333331.6071428576.64047619
B36Max4 PPuieti6.6934883722.6302083339.323696705
B36Max4 PPuieti6.0210126581.602935787.623948438
B36Max4 PPuieti10.205825243.76831460713.97413985
B33Max4Butasi5.8994174761.7453947377.644812213
B33Max4Butasi3.2614285711.3357352944.597163866
B33Max4Butasi3.3595081971.4566412214.816149418
B33Max4Butasi5.0363636362.0977931037.13415674
B33Max4Butasi3.1221621621.6120125794.734174741
B33Max4Butasi5.0424742273.2469164278.289390653
B33Max4Butasi5.0582558142.7242990657.782554879
B33Max4Butasi4.9778181821.7135042746.691322455
B33Max4Butasi3.1952941181.2434117654.438705882
B33Max4Butasi1.8318181821.0090909092.840909091
B30AF2Butasi6.981951221.7648.74595122
B30AF2Butasi5.8583333331.6866233777.54495671
B30AF2Butasi10.6253.0413.665
C39AF6Sade10.271252.28319327712.55444328
C39AF6Sade9.4734883721.90941441411.38290279
C39AF6Sade10.4825212.4825
C39AF6Sade11.615795452.43113636414.04693182
C39AF6Sade8.1850746271.8093333339.99440796
C39AF6Sade11.045106382.2367295613.28183594
C39AF6Sade9.0666666672.47378571411.54045238
C39AF6Sade10.127876113.09763157913.22550769
C39AF6Sade9.1712903231.82122641510.99251674
C39AF6Sade12.18468752.26259036114.44727786
C42PannoniaSade9.2752.48217391311.75717391
C42PannoniaSade7.211.778.98
C42PannoniaSade11.369393943.11178082214.48117476
C42PannoniaSade7.852968751.9434751779.796443927
C42PannoniaSade8.252.5404761910.79047619
C42PannoniaSade8.6692771082.18707142910.85634854
C42PannoniaSade8.5108860762.0534410.56432608
C42PannoniaSade9.3622222225.52553191514.88775414
C42PannoniaSade11.084819282.57319327713.65801255
C42PannoniaSade10.174626873.00322580613.17785267
C45MonvisoSade12.996938783.21608391616.21302269
C45MonvisoSade11.114565221.88571428613.0002795
C45MonvisoSade8.1293333331.5326666679.662
C45MonvisoSade9.9430434782.3830088512.32605233
C45MonvisoSade11.98058143.08092391315.06150531
C45MonvisoSade10.313766232.21052631612.52429255
C45MonvisoSade9.9475862071.86083333311.80841954
C45MonvisoSade12.242615382.16685714314.40947253
C45MonvisoSade13.566506022.41437125715.98087728
C45MonvisoSade10.875742572.92234042613.798083
C48AF2Sade9.3345454552.20182291711.53636837
C48AF2Sade9.7476404492.81178082212.55942127
C48AF2Sade14.295412844.50688524618.80229809
C48AF2Sade10.264516133.01432258113.27883871
C48AF2Sade13.309242423.96066176517.26990419
C48AF2Sade13.232284265.0054687518.23775301
C48AF2Sade14.82770274.45044776119.27815046
C48AF2Sade15.236695287.55932203422.79601731
C48AF2Sade13.271985823.75825242717.03023824
C48AF2Sade13.713644445.69044444419.40408889
C51Max4Sade8.8608849565.61358695714.47447191
C51Max4Sade13.291532855.65306122418.94459407
C51Max4Sade9.6098507463.38571428612.99556503


-- 

---
Catalin-Constantin ROIBU
Lecturer PhD,?Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone?? ??? +4 0230 52 29 78, ext. 531
mobile phone ? +4 0745 53 18 01
?????????????????????? +4 0766 71 76 58
FAX:?????????? ??? ??? ?????? +4 0230 52 16 64
silvic.usv.ro


From abitbol at sent.com  Wed Nov 20 15:17:03 2013
From: abitbol at sent.com (Jean-Louis Abitbol)
Date: Wed, 20 Nov 2013 15:17:03 +0100
Subject: [R] Parametrizing heading in tables package
Message-ID: <1384957023.24479.49863137.7B895E1B@webmail.messagingengine.com>

Dear R-Helpers,

I am using the (great) tables package in a function this way:

parplot <- function (x){
test <- pkqps[pkqps$estimate == x,]
####
#some plotting 
#####
tab <- tabular((Heading("Analyte")*(analyte) * Heading(Site)* (fsite)) 
         ~ (n=1)+ Justify(c)*Heading(substitute(test$estimate[1]))
               *(result)*(Mean + Median + Min + Max + CV)
                   * Format(digits = 1), data = test)
html(tab, file = paste(qpar$param[1],"stat",".html", sep=""))
}
parplot("Cmax")
parplot("AUClast")
etc...

I am trying to parametrize the heading in tabular with
"Heading(substitute(test$estimate[1]))".
test$estimate[1] is a character variate which is the name I want to
appear in the heading (ie Cmax for example in the first call of the
function.

This does not work and produces just "substitute(test$estimate[1])" in
the heading. 

I Have also tried quote() without success.

Any advice on how to do this will be much appreciated,

Best wishes, JL


From murdoch.duncan at gmail.com  Wed Nov 20 15:35:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Nov 2013 09:35:41 -0500
Subject: [R] Parametrizing heading in tables package
In-Reply-To: <1384957023.24479.49863137.7B895E1B@webmail.messagingengine.com>
References: <1384957023.24479.49863137.7B895E1B@webmail.messagingengine.com>
Message-ID: <528CC8BD.8030607@gmail.com>

On 20/11/2013 9:17 AM, Jean-Louis Abitbol wrote:
> Dear R-Helpers,
>
> I am using the (great) tables package in a function this way:
>
> parplot <- function (x){
> test <- pkqps[pkqps$estimate == x,]
> ####
> #some plotting
> #####
> tab <- tabular((Heading("Analyte")*(analyte) * Heading(Site)* (fsite))
>           ~ (n=1)+ Justify(c)*Heading(substitute(test$estimate[1]))
>                 *(result)*(Mean + Median + Min + Max + CV)
>                     * Format(digits = 1), data = test)
> html(tab, file = paste(qpar$param[1],"stat",".html", sep=""))
> }
> parplot("Cmax")
> parplot("AUClast")
> etc...
>
> I am trying to parametrize the heading in tabular with
> "Heading(substitute(test$estimate[1]))".
> test$estimate[1] is a character variate which is the name I want to
> appear in the heading (ie Cmax for example in the first call of the
> function.
>
> This does not work and produces just "substitute(test$estimate[1])" in
> the heading.

I would use substitute() on the whole formula.  For example,

a <- "New heading"
x <- rnorm(100)

tabular( substitute( Heading( head )*x ~ mean, list(head = a) ) )

Duncan Murdoch


From smartpink111 at yahoo.com  Wed Nov 20 16:03:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 07:03:06 -0800 (PST)
Subject: [R] How to create running averages
Message-ID: <1384959786.60637.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,
Not sure if this is what you wanted.

mydf[,1] <- mydf[,1]+ISOdatetime(1970,1,1,0,0,0)
library(zoo)
?z1 <- zoo(mydf[,2],mydf[,1])

fun1 <- function(z,n,k){
?unlist(lapply(split(z,((seq_along(z)-1) %/% n) +1), function(x) rollapply(c(rep(NA,k),x),width=n,mean,na.rm=TRUE)),use.names=FALSE)
?}

#1-10
fun1(z1,10,9)

#1-3
fun1(z1,3,2)

#4-7
fun1(z1,7,3)
#8-10
fun1(z1,10,2)

A.K.



I have a data frame that contains daily temperature and want to 
calculate running averages from the lags. How could I create the 
following four averages: 1 to 10 days, 1 to 3 days and 4 to ?7 days and 8 to 10 days? 

Thanks 

> dput(mydf) 
structure(list(mydate = c(1104537600, 1104624000, 1104710400, 
1104796800, 1104883200, 1104969600, 1105056000, 1105142400, 1105228800, 
1105315200, 1105401600, 1105488000, 1105574400, 1105660800, 1105747200, 
1105833600, 1105920000, 1106006400, 1106092800, 1106179200, 1106265600, 
1106352000, 1106438400, 1106524800, 1106611200, 1106697600, 1106784000, 
1106870400, 1106956800, 1107043200, 1107129600, 1107216000, 1107302400, 
1107388800, 1107475200, 1107561600, 1107648000, 1107734400, 1107820800, 
1107907200, 1107993600, 1108080000, 1108166400, 1108252800, 1108339200, 
1108425600, 1108512000, 1108598400, 1108684800, 1108771200, 1108857600, 
1108944000, 1109030400, 1109116800, 1109203200, 1109289600, 1109376000, 
1109462400, 1109548800, 1109635200), temperature = c(27.2355645811212, 
24.7572454841433, 25.8807360325073, 23.604983194918, 25.3806158930898, 
25.4522163920789, 23.3634003395322, 21.8857290467555, 25.7885123837986, 
25.2892335838452, 28.576293971409, 23.9336020581815, 27.0939456273958, 
28.3913410122702, 25.909021640904, 26.2460484822251, 25.1575616245794, 
22.8368740313366, 27.6642857968485, 25.1196788026597, 22.5894167843065, 
30.2988617359284, 24.8434897031825, 23.4057719286007, 24.4344849657242, 
26.1064563281548, 28.8237562787261, 26.2779314012608, 24.9246895989705, 
25.9247118455481, 26.8168149658814, 24.5976817973611, 23.0279799404805, 
23.8692145542798, 20.5706428459246, 25.2535816755043, 24.1579034687891, 
26.2783929119493, 24.1524000712139, 23.6602196383023, 24.0011597837778, 
21.2285591199996, 26.019106804625, 27.8057491046718, 24.3857746554726, 
27.0899941525061, 29.3171144596242, 25.6280205868316, 24.5556883088479, 
27.8460189886338, 27.614311224526, 26.3826496863349, 23.357578632432, 
22.6042279901428, 23.3671729098119, 26.3785847646844, 24.3646932790827, 
25.9119679458049, 26.5848087900931, 27.0119408766481)), .Names = c("mydate", 
"temperature"), row.names = c(NA, -60L), class = "data.frame")


From dcarlson at tamu.edu  Wed Nov 20 16:38:39 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 20 Nov 2013 09:38:39 -0600
Subject: [R] To transform an adjacency matrix
In-Reply-To: <528C8ED9.4090502@cirad.fr>
References: <528C8ED9.4090502@cirad.fr>
Message-ID: <01fc01cee606$95b06240$c11126c0$@tamu.edu>

> indx <- arrayInd(which(m>0), .dim=c(5, 5))
> indx
     [,1] [,2]
[1,]    4    1
[2,]    2    3
[3,]    4    3
[4,]    2    4
[5,]    1    5
# If you want the result sorted
> indx[order(indx[,1], indx[,2]),]
     [,1] [,2]
[1,]    1    5
[2,]    2    3
[3,]    2    4
[4,]    4    1
[5,]    4    3

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Arnaud Michel
Sent: Wednesday, November 20, 2013 4:29 AM
To: R help
Subject: [R] To transform an adjacency matrix

Hi
I have the following problem
I would like to build, from a matrix filled with 0 and with 1, a
matrix 
or a data.frame which contains, in every line, the number of the
line 
and the number of the column of the matrix for which the value
is equal 
to 1.
Exemple :

dput(m)
structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
0, 0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))

Result

1 5
2 3
2 4
4 1
4 3

Thank you for your help

-- 
Michel ARNAUD
Chargi de mission auprhs du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


	[[alternative HTML version deleted]]


From istazahn at gmail.com  Wed Nov 20 16:44:17 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 20 Nov 2013 10:44:17 -0500
Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
 Learn Few Basics
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9EE98@SRVEXCHMBX.precheza.cz>
References: <36fdb03529f041c99caf513ef9248390@server.isgmn.local>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9EE98@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+vqiLF0fWdVonAMKNJB7A2f5ce2psSPbMEmpEPrrNtmyNX7-g@mail.gmail.com>

On Mon, Nov 18, 2013 at 8:45 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Zach Feinstein
>> Sent: Wednesday, November 13, 2013 2:57 PM
>> To: r-help at r-project.org
>> Subject: [R] R Beginner - Need Perhaps 5 - 10 Minutes of R User Time to
>> Learn Few Basics
>>
>> I have finally decided that I will learn R and learn it very well. For
>
> If you really decided to invest in learning R you shall first read R-Intro documentation especially chapters 2 and 3 and 1.11.
>
> Eventually you could read whole 102 pages document. It shall not take you more than a week and after that you will be able to do quite sophisticated analysis.
>
> I do not know Rstudio or Rattle but once you taste R console way maybe together with some suitable editor (I use Tinn-R) you will hardly need any GUI add-on.

Rstudio basically gives you a suitable editor and an R console, albeit
in an IDE layout. It is what I recommend for newbies who don't already
know emacs.

Best,
Ista

>
> Regards
> Petr
>
>> now I am using a program that a friend of mine developed to do some
>> advanced statistical analyses. I downloaded RStudio to my machine.
>> [Perhaps RStudio is not the best platform to work from -  I have heard
>> that Rattle is sort of the new standard.] I have so far been able to
>> highlight the rows of the code that I wish to run, but then I somehow
>> turned off seeing the output. I also cannot find where I would locate
>> the output window. Yes, frustrated.
>>
>> Would any kind soul be interested in helping kickstart my R learning? I
>> have JoinMe installed on my machine so I figure we can do it
>> interactively. It should not take more than a few minutes. I am already
>> very experienced with both C and VBA languages as well as SPSS syntax
>> so there is not much need to worry about me being too much of a novice.
>>
>> Thank you very much in advance.
>>
>> Zach Feinstein
>> zfeinstein at isgmn.com<mailto:zfeinstein at isgmn.com>
>> (952) 277-0162
>> (612) 590-4813 (mobile)
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Nov 20 17:21:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 08:21:44 -0800
Subject: [R] Multiple if statement in loop condition
In-Reply-To: <1384950240514-4680803.post@n4.nabble.com>
References: <1384942699996-4680797.post@n4.nabble.com>
	<1384950240514-4680803.post@n4.nabble.com>
Message-ID: <8F79E9A4-989B-40E6-9757-65BC73C1C0FC@comcast.net>


On Nov 20, 2013, at 4:24 AM, Carl Witthoft wrote:

> What this message means is that a "{" showed up when some other bracket was
> unpaired.  In this case, if you check your code, you'll see that 
> "if(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0))"  is
> lacking a closing ")"  for the if clause.

Arguably it is due to the superfluous "(" after the "&". Further evidence perhaps of the value of adding spaces before and after parentheses. Also evidence of the value of an R-aware editor.

-- 
David.
> 
> Phalaen wrote
>> Hi! 
>> I am a Phd student in the university of Padua and I am trying to write a
>> little script (the first!) to make a simulation on epidemiology.
>> I'd like to change the values of a vector of 883 values basing on a
>> neighbour matrix constructed with nb2mat from a shapefile: if i and j (two
>> cells) are neighbour (matrix) and i or j have a positive value in the
>> vector, I'd like to transform the value of both i and j to 1 (positive),
>> otherwise the value of i and j should remain 0. When I launch the next
>> little script:
>> 
>> for(i in 1:883)
>> { for(j in 1:883)
>>  { if(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0)) {
>> 	 vectorID[i] = 1 & vectorID[j] = 1
>> 		print(vectorID)
>> } } } 
>> 
>> the answer from the software is:
>> Error: unexpected '{' in:
>> " { for(j in 1:883)
>> { while(MatriceDist[i,j] > 0 & ((vectorID[i] > 0 | vectorID[j] > 0)) {"
>> 
>> I think that it is an error in the statement for if but I can not
>> understand how to solve it...
>> Thank you everyone!
>> Elisa
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Multiple-if-statement-in-loop-condition-tp4680797p4680803.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Wed Nov 20 17:26:49 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 20 Nov 2013 16:26:49 +0000
Subject: [R] (no subject)
In-Reply-To: <CAGPwjHwVZmNrVSd8WWjkcOuX62+KqrgnBa1vey5U=ApCJ+afqg@mail.gmail.com>
References: <CAGPwjHwVZmNrVSd8WWjkcOuX62+KqrgnBa1vey5U=ApCJ+afqg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA16269@PA-MBX01.na.tibco.com>

> fitdistr(y, "chi-squared", start = list(4), method = "Brent", lower=0.9, upper=3)

First, it would  be nice if your mail had a subject line and you showed
the error message you got from this command.
I got:
  > z <- fitdistr(y, "chi-squared", start = list(4), method="Brent", lower=0.9, upper=3)
  > z
  Error in dn[[2L]] : subscript out of bounds
  > str(z)
  List of 5
   $ estimate: num 1
   $ sd      : num 0.00286
   $ vcov    : num [1, 1] 8.16e-06
   $ loglik  : num -79007
   $ n       : int 100000
   - attr(*, "class")= chr "fitdistr"
showing that the error was in the printing of the result, not in computing
the result.

There are a few problems here.  First, the print method assumes that the
optimizer attaches parameter names to the parameter vector.  Second,
optim(method="Brent") does not attach a name to its output parameter the
way the other optimization method do (I suppose that is because it only
works on univariate problems.)  Third, you didn't supply a parameter name
in 'start'.

You can get a printable answer by using the default method and supplying
a name for the parameter.
   > zz <- fitdistr(y, "chi-squared", start = list(df=4), lower=0.9, upper=3)
   > zz
          df     
     1.003840114 
    (0.002856363)
   > str(zz)
   List of 5
    $ estimate: Named num 1
     ..- attr(*, "names")= chr "df"
    $ sd      : Named num 0.00286
     ..- attr(*, "names")= chr "df"
    $ vcov    : num [1, 1] 8.16e-06
     ..- attr(*, "dimnames")=List of 2
     .. ..$ : chr "df"
     .. ..$ : chr "df"
    $ loglik  : num -79007
    $ n       : int 100000
    - attr(*, "class")= chr "fitdistr"

By the way, giving a starting value that is not between the upper and lower
limits that you also gave is asking for trouble of a different sort.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jim Silverton
> Sent: Tuesday, November 19, 2013 4:30 PM
> To: r-help at r-project.org
> Subject: [R] (no subject)
> 
> I generated some random data using R and then trying to see if it came from
> the same distribution but the erros keep piling.  Can anyone help?
> 
> 
> 
> y=rchisq(100000,1)
> mean(y)
> var(y)
> library(MASS)
> fitdistr(y, "chi-squared", start = list(4), method = "Brent", lower=0.9,
> upper=3)
> 
> 
> --
> Thanks,
> Jim.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jlh.membership at gmail.com  Wed Nov 20 17:39:17 2013
From: jlh.membership at gmail.com (jlh.membership)
Date: Wed, 20 Nov 2013 11:39:17 -0500
Subject: [R] Overlay boxplot and scatter.smooth line
In-Reply-To: <CABsGe_zs7dyfx3ftsn+npJOCNutp1rn_aG-t7N2d26ztZuRR7A@mail.gmail.com>
References: <CABsGe_ze+TeorzmHDp=SGf9g2ajS28VvGqgvfZOoHC4Yq78TsQ@mail.gmail.com>	<CAN5YmCGVzaRugPvmQPkZV=VXE4tDfgJTGwwqVoSsTTkwsx1O7g@mail.gmail.com>
	<CABsGe_zs7dyfx3ftsn+npJOCNutp1rn_aG-t7N2d26ztZuRR7A@mail.gmail.com>
Message-ID: <001301cee60f$13468650$39d392f0$@gmail.com>

Same thing using ggplot...

# your data
x <- c(rep(1,100),rep(2,100),rep(3,100))
y <- c(rnorm(100,1),rnorm(100,2),rnorm(100,3))

df <- data.frame(x=x, y=y)

library(ggplot2)
ggp <- ggplot(df) + labs(x="X", y="Y") 
ggp <- ggp + geom_boxplot(aes(x=factor(x), y=y)) 
ggp <- ggp + geom_smooth(formula=y~x, aes(x=x, y=y), method="loess", se=F) 
ggp

Setting method="lm" above would plot linear model instead of loess, setting se=T (the default) would plot 95% CL for the model.

Adding the line:
ggp <- ggp +  stat_summary(fun.data="mean_cl_normal", aes(x=factor(x),y=y), size=1.2, color="red")
ggp

will overlay mean and 95% CL (assuming normal distribution of error) at each level of x. 

-----Original Message-----
From: Johannes Radinger [mailto:johannesradinger at gmail.com] 
Sent: Tuesday, November 19, 2013 10:01 AM
To: Adams, Jean
Cc: R help
Subject: Re: [R] Overlay boxplot and scatter.smooth line

Thanks...that works great!

/J


On Tue, Nov 19, 2013 at 2:39 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Use lines() with loess.smooth() instead of scatter.smooth() to add to 
> the already existing boxplot.  For example,
>
> boxplot(y~x)
> lines(loess.smooth(x, y))
>
> Jean
>
>
> On Tue, Nov 19, 2013 at 4:43 AM, Johannes Radinger < 
> johannesradinger at gmail.com> wrote:
>
>> Hi,
>>
>> I'd like to plot a boxplot and use a scatter.smooth line plot as an 
>> overlay for this plot.
>> This works except for the problem that the x-axis ticks for both 
>> plots are differently spaced:
>> The boxplot ticks are closer and the space between the outer most 
>> boxplots and the plot region (box) is larger for boxplots than for 
>> the scatter.smooth plot. Is there any plot-option that can be changed 
>> to produce the desired plot.
>>
>> Here an example to illustrate what problem I am facing:
>>
>> x <- c(rep(1,100),rep(2,100),rep(3,100))
>> y <- c(rnorm(100,1),rnorm(100,2),rnorm(100,3))
>>
>> boxplot(y~x)
>> par(new=TRUE)
>> scatter.smooth(x, y, xaxt="n", yaxt="n", ann=FALSE)
>>
>> Moreover, I'd like to plot just the smoothed line only and not the 
>> datapoints.
>> Any suggestions?
>>
>> best regards,
>>
>> J.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From dwarnold45 at suddenlink.net  Wed Nov 20 17:40:42 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Wed, 20 Nov 2013 08:40:42 -0800 (PST)
Subject: [R] Setting axis scale for a boxplot
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA15D88@PA-MBX01.na.tibco.com>
References: <1384801070789-4680704.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B933FA15D88@PA-MBX01.na.tibco.com>
Message-ID: <1384965642363-4680821.post@n4.nabble.com>

Thanks, these replies worked.

D.



--
View this message in context: http://r.789695.n4.nabble.com/Setting-axis-scale-for-a-boxplot-tp4680704p4680821.html
Sent from the R help mailing list archive at Nabble.com.


From laura.vossen at neuro.uu.se  Wed Nov 20 14:11:21 2013
From: laura.vossen at neuro.uu.se (Laura Vossen)
Date: Wed, 20 Nov 2013 05:11:21 -0800 (PST)
Subject: [R] RCmdr issues
In-Reply-To: <1384544619095-4680537.post@n4.nabble.com>
References: <1384544619095-4680537.post@n4.nabble.com>
Message-ID: <1384953081791-4680804.post@n4.nabble.com>

I have the same problem with my macbook air (OS X 10.9)



--
View this message in context: http://r.789695.n4.nabble.com/RCmdr-issues-tp4680537p4680804.html
Sent from the R help mailing list archive at Nabble.com.


From floor_biemans at hotmail.com  Wed Nov 20 12:51:52 2013
From: floor_biemans at hotmail.com (Floor Biemans)
Date: Wed, 20 Nov 2013 12:51:52 +0100
Subject: [R] Binomial GLM in Stata and R
Message-ID: <DUB117-W123009A8DE81A52F7D6404E97E60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/fb6f5746/attachment.pl>

From dalmaso.elisa at gmail.com  Wed Nov 20 14:43:12 2013
From: dalmaso.elisa at gmail.com (Phalaen)
Date: Wed, 20 Nov 2013 05:43:12 -0800 (PST)
Subject: [R] Multiple if statement in loop condition
In-Reply-To: <1384950240514-4680803.post@n4.nabble.com>
References: <1384942699996-4680797.post@n4.nabble.com>
	<1384950240514-4680803.post@n4.nabble.com>
Message-ID: <CABb8FvDuUD66_iFw8+p_M0b-9__s-oy8rcrhcf-dtM2iHJsWYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/5f02d7c5/attachment.pl>

From nitisha999 at gmail.com  Wed Nov 20 16:56:27 2013
From: nitisha999 at gmail.com (Nitisha jha)
Date: Wed, 20 Nov 2013 21:26:27 +0530
Subject: [R] Datatable manipulation
In-Reply-To: <1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>
	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>
	<1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAOdnBQe17qqWG0KAsG+KFeXpJTe7WQTtjFdKqCJQGGCk2OdZVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/e073aef9/attachment.pl>

From andy_liaw at merck.com  Wed Nov 20 19:19:06 2013
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 20 Nov 2013 13:19:06 -0500
Subject: [R] Split type in the RandomForest package
In-Reply-To: <69DCF4799E57F541A264D05A8468CC8954E9B230@icexch-m1.ic.ac.uk>
References: <69DCF4799E57F541A264D05A8468CC8954E9B230@icexch-m1.ic.ac.uk>
Message-ID: <D5FA03935F7418419332B61CA255F65FA5B8910CEB@USCTMXP51012.merck.com>

Classification trees use the Gini index, whereas the regression trees use sum of squared errors.  They are "hard-wired" into the C/Fortran code, so not easily changeable.

Best,
Andy

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Cheng, Chuan
Sent: Monday, September 30, 2013 6:30 AM
To: 'R-help at r-project.org'
Subject: [R] Split type in the RandomForest package

Hi guys,

I'm new to Random Forest package and I'd like to know what type of split is used in the package for classification? Or can I configure the package to use different split type (like simple split alongside single attribute axis or linear split based on several attributes etc..)

Thanks a lot!

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Notice:  This e-mail message, together with any attachme...{{dropped:11}}


From behe.brian at gmail.com  Wed Nov 20 20:26:27 2013
From: behe.brian at gmail.com (Brian Behe)
Date: Wed, 20 Nov 2013 14:26:27 -0500
Subject: [R] R NNET object Question
Message-ID: <CAKr2b+4+8-nQzHGw=_FbzQt-66_sYkRhhXymC5Nojm-F+BL_JA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/2369a50d/attachment.pl>

From dr.vinay.muc at gmail.com  Wed Nov 20 21:01:18 2013
From: dr.vinay.muc at gmail.com (Dr.Vinay Pitchika)
Date: Wed, 20 Nov 2013 21:01:18 +0100
Subject: [R] How to stop Kaplan-Meier curve at a time point
Message-ID: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/57b5466c/attachment.pl>

From jfox at mcmaster.ca  Wed Nov 20 21:37:39 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 20 Nov 2013 15:37:39 -0500
Subject: [R] RCmdr issues
In-Reply-To: <1384953081791-4680804.post@n4.nabble.com>
References: <1384544619095-4680537.post@n4.nabble.com>
	<1384953081791-4680804.post@n4.nabble.com>
Message-ID: <web-484237871@cgpsrv2.cis.mcmaster.ca>

Dear Laura,

I assume that you're responding to the message that I posted on R-SIG-Mac. If so, I'm not sure why you switched to R-help nor why you changed the subject of the message. Please see the subsequent messages on R-SIG-Mac under the subject "Problems with Rcmdr via XQuartz on OSX Mavericks," and in particular the solution (at least for the time-being) of running R in a terminal window.

Best,
 John

On Wed, 20 Nov 2013 05:11:21 -0800 (PST)
 Laura Vossen <laura.vossen at neuro.uu.se> wrote:
> I have the same problem with my macbook air (OS X 10.9)
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/RCmdr-issues-tp4680537p4680804.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From trevordaviswalker at gmail.com  Wed Nov 20 20:35:23 2013
From: trevordaviswalker at gmail.com (Trevor Walker)
Date: Wed, 20 Nov 2013 14:35:23 -0500
Subject: [R] Percentiles for unequal probability sample
Message-ID: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/1abb9d24/attachment.pl>

From mherting at chla.usc.edu  Wed Nov 20 19:04:45 2013
From: mherting at chla.usc.edu (megan herting)
Date: Wed, 20 Nov 2013 10:04:45 -0800 (PST)
Subject: [R] nlme function summary.lmList cannot be found with new versions
Message-ID: <1384970685431-4680825.post@n4.nabble.com>

Hello,

I installed the newest version of R (3.0.2) as well as the newest version of
nlme (3.1-113) in order to use summary.lmList and other nlme functions. Once
loading the new library, lmList and summary.lm can be found, but a number of
additional functions cannot be found via command. 

Versions installed and loaded are correct. Any suggestions on how to allow
for these functions of the new version of nlme to be found and used? 

Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/nlme-function-summary-lmList-cannot-be-found-with-new-versions-tp4680825.html
Sent from the R help mailing list archive at Nabble.com.


From jluo.rhelp at gmail.com  Wed Nov 20 21:44:51 2013
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Wed, 20 Nov 2013 15:44:51 -0500
Subject: [R] bias in AUCRF?
Message-ID: <CAD-E8+4oW2h76-a4HSHDUJEyVmwFqErZ57+4sF_jrzQyGkHGBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/e114390f/attachment.pl>

From dimitri.liakhovitski at gmail.com  Wed Nov 20 22:41:22 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 20 Nov 2013 16:41:22 -0500
Subject: [R] balanced design package?
Message-ID: <CAN2xGJZ_3D+jvwRru1SMgrTwWh34Dr+Mb3OdTLF42yAdQ23FAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/c67e8dbd/attachment.pl>

From bbolker at gmail.com  Wed Nov 20 22:42:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Nov 2013 21:42:18 +0000
Subject: [R] nlme function summary.lmList cannot be found with new
	versions
References: <1384970685431-4680825.post@n4.nabble.com>
Message-ID: <loom.20131120T224055-646@post.gmane.org>

megan herting <mherting <at> chla.usc.edu> writes:

> 
> Hello,
> 
> I installed the newest version of R (3.0.2) as well as the 
> newest version of
> nlme (3.1-113) in order to use summary.lmList and other 
> nlme functions. Once
> loading the new library, lmList and summary.lm can be found,
>  but a number of
> additional functions cannot be found via command. 
> 
> Versions installed and loaded are correct. Any suggestions on how to allow
> for these functions of the new version of nlme to be found and used? 
> 

  R started exporting a lot fewer functions from base packages
(i.e., making them easily/publicly available).  You can use
getAnywhere() to find out where a hidden method lives, if you don't
know, but in this case I think

nlme:::summary.lmList 

should work.  (For everyday use you shouldn't need to dig out
hidden functions with ::: -- if you have an object of class 'lmList',
then summary(object) should just work.)


From bbolker at gmail.com  Wed Nov 20 22:49:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Nov 2013 21:49:13 +0000
Subject: [R] Inverse of Probit
References: <1384887541789-4680752.post@n4.nabble.com>
	<EA38D1EB-9DD7-44E0-9623-2E1047CE6213@comcast.net>
Message-ID: <loom.20131120T224635-355@post.gmane.org>

David Winsemius <dwinsemius <at> comcast.net> writes:

> 
> 
> On Nov 19, 2013, at 10:59 AM, Calum wrote:
> 
> > Hi there,
> > I hope someone can help me.
> > 
> > I have a dataset of Concentration against Mortality, and I am trying to
> > compare the use of Logit and Probit models using this data.

 [snip snip snip]

  There are three ways you can get the inverse-link function

1. dig into the family object: binomial(link="probit")$linkinv
2. know that the probit link is the qnorm() (Normal quantile) function,
and the inverse-probit is pnorm() (the Normal CDF). (Similarly, it
seems that a lot of users don't know that plogis()/qlogis() similarly
provide the logistic and logit functions ...
3. As David Winsemius suggests, use predict(...,type="response")
(but options #1 and #2 are useful in providing flexibility).


From bbolker at gmail.com  Wed Nov 20 22:45:00 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 20 Nov 2013 21:45:00 +0000
Subject: [R] Binomial GLM in Stata and R
References: <DUB117-W123009A8DE81A52F7D6404E97E60@phx.gbl>
Message-ID: <loom.20131120T224404-937@post.gmane.org>

Floor Biemans <floor_biemans <at> hotmail.com> writes:

[snip]

> The stata code I have is:
> 
> glm c IndA fia, family(binomial s) link(cloglog) offset(offset)
> 
> The R code is:
> 
> glmt <- glm(data=dataset, c ~ IndA + fia, offset = offset, family =
binomial(link = cloglog))
> 
> Which yields different results from the Stata output.
>  I think the difference is in the variable s that is
> included in the binomial family in Stata (bold in the code).
>  How can I incorporate this variable in the R
> code?  

Cross-posted to stack overflow:

http://stackoverflow.com/questions/20094074/reproduce-stata-code-in-r-binomial-glm/20094514#20094514

glmt <- glm(data=dataset, cbind(c,s-c) ~ IndA + fia, 
    offset = offset, family = binomial(link = cloglog))


From jvadams at usgs.gov  Wed Nov 20 23:25:47 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 20 Nov 2013 16:25:47 -0600
Subject: [R] Percentiles for unequal probability sample
In-Reply-To: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
References: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
Message-ID: <CAN5YmCGE2pV8FGKv-QMKbJC=cE_us2tWUTFx2WViZBDDgxhaKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/24442a32/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Nov 20 23:32:07 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 20 Nov 2013 22:32:07 +0000
Subject: [R] nlme function summary.lmList cannot be found with new
	versions
In-Reply-To: <loom.20131120T224055-646@post.gmane.org>
References: <1384970685431-4680825.post@n4.nabble.com>
	<loom.20131120T224055-646@post.gmane.org>
Message-ID: <528D3867.2020407@stats.ox.ac.uk>

On 20/11/2013 21:42, Ben Bolker wrote:
> megan herting <mherting <at> chla.usc.edu> writes:
>
>>
>> Hello,
>>
>> I installed the newest version of R (3.0.2) as well as the
>> newest version of
>> nlme (3.1-113) in order to use summary.lmList and other
>> nlme functions. Once
>> loading the new library, lmList and summary.lm can be found,
>>   but a number of
>> additional functions cannot be found via command.
>>
>> Versions installed and loaded are correct. Any suggestions on how to allow
>> for these functions of the new version of nlme to be found and used?
>>
>
>    R started exporting a lot fewer functions from base packages
> (i.e., making them easily/publicly available).  You can use

Well, nlme is not a base package (it is a recommended package), and 
summary.lmList was not exported in 2004 when the current SVN repository 
was started.  And I just fired up R 2.0.0 (Oct 2004) to cross-check.

> getAnywhere() to find out where a hidden method lives, if you don't
> know, but in this case I think
>
> nlme:::summary.lmList
>
> should work.  (For everyday use you shouldn't need to dig out
> hidden functions with ::: -- if you have an object of class 'lmList',
> then summary(object) should just work.)

As ?summary.lmList says the 'Usage' is.

So someone is using some very old documentation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jim at bitwrit.com.au  Wed Nov 20 23:33:40 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 21 Nov 2013 09:33:40 +1100
Subject: [R] balanced design package?
In-Reply-To: <CAN2xGJZ_3D+jvwRru1SMgrTwWh34Dr+Mb3OdTLF42yAdQ23FAA@mail.gmail.com>
References: <CAN2xGJZ_3D+jvwRru1SMgrTwWh34Dr+Mb3OdTLF42yAdQ23FAA@mail.gmail.com>
Message-ID: <528D38C4.6070603@bitwrit.com.au>

On 11/21/2013 08:41 AM, Dimitri Liakhovitski wrote:
> Dear everybody,
>
> I have 20 levels of a factor.
> I want to create 1000 combinations of 6 different levels of that factor so
> that each level is repeated about the same number of times (across 100
> combinations) and so that the number of times level X is combined with
> level Y is also about the same (across 1000 combinations).
> So, it's an experimental design question.
> I don't think I can use algDesign for that.
>
Hi Dimitri,
This is but a guess, but might help:

combn(20,6)[,seq(1,38000,by=38)]

Jim


From dwinsemius at comcast.net  Wed Nov 20 23:49:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 14:49:13 -0800
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
References: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
Message-ID: <2EB5BD4A-E93D-4BFB-8455-3CC3855D785E@comcast.net>


On Nov 20, 2013, at 12:01 PM, Dr.Vinay Pitchika wrote:

> Hello R users
> 
> I have a question with Kaplan-Meier Curve with respect to my research. We
> have done a retrospective study on fillings in the tooth and their survival
> in relation to the many influencing factors. We had a long follow-up time
> (upto 8yrs for some variables). However, we decided to stop the analysis at
> the 6year follow up time, so that we can have uniform follow-up time for
> all the variables.
> 
> I did play a bit with the formula and tried to stop the Kaplan-Meier curve
> at my desired time (2190days)or roughly 6 years. However, my question is I
> want to find the significance (log rank test) at this time point between
> the two curves; because I am not able to find a way to stop the survfit at
> this time point with my knowledge. Below is the code I used.
> 
> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender)

I'm assuming that you have a dataframe with those variables and have attached it. If so, then:

dfrm <- detach(said_df)

# If not, then:

dfrm <- data.frame(Survival_days, Outcome, Gender)

Gender2<-survfit(Surv(Survival_days, Outcome)~Gender, 
                  data=dfrm, subset = Survival_days < 6*365.25 )

> 
> plot (Gender2, xmax=2190, mark.time=FALSE, col=c(1:2), xlab="Survival time
> (Days)", ylab="Survival probability", main="Gender") # mark.time=FALSE will
> remove the censoring lines in the graph. If censoring lines are needed,
> then remove the mark.time section in the formula.
> 
> legend("topright",c("Females", "Males"), col=(1:2), lwd=0.5)
> 
> Am sure, the code in the first line has to be modified. Please help me with
> this and I will be very thankful to you.
> 


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov 20 23:50:58 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 14:50:58 -0800
Subject: [R] bias in AUCRF?
In-Reply-To: <CAD-E8+4oW2h76-a4HSHDUJEyVmwFqErZ57+4sF_jrzQyGkHGBw@mail.gmail.com>
References: <CAD-E8+4oW2h76-a4HSHDUJEyVmwFqErZ57+4sF_jrzQyGkHGBw@mail.gmail.com>
Message-ID: <9B9774D1-22F8-4036-9D23-7B36CF75EE37@comcast.net>


On Nov 20, 2013, at 12:44 PM, Jack Luo wrote:

> Hi,
> 
> I am using the AUCRF package for my data and I was firstly impressed by the
> high performance of OOB-AUC. But after a while, I feel it might be due to
> some sort of bias, which motivates me to use random data (generated using
> rnorm) for a test.
> 
> The design is very simple: 100 observations with 50 in class 0 and 50 in
> class 1. The number of variables is something I tuned (the main idea is
> that if there is bias, the performance should increase with more
> variables).
> 
> Presumably, there is no signal in the data and the true unbiased AUC should
> not be too different from 0.5.
> 
> The results are worrisome to me: the OOB AUC is a lot higher than 0.5, and
> with more variables, it gets even higher.
> 
> Am I misunderstanding anything here?
> 
> Below is the R code I used to test:
> 
> Nvar = 200  # number of variables
> Label = as.factor(c(rep(0,50),rep(1,50)))  # class label
> AUC_r = NULL
> 
> for (k in 1:10) {  # control the randomness of generating random data
>  set.seed(k)
>  Arandom = matrix(rnorm(Nvar*length(Label)),nc = Nvar)
>  DF = data.frame(Arandom,Label = Label)
>  for (j in 1:20) {  # control the randomness of OOB
>    if (j %% 10 == 0) {cat(k,j,"\n")}
>    set.seed(j)
>    fit <- AUCRF(Label~., data=DF)
>    AUC_r = cbind(AUC_r,fit$AUCcurve$AUC)
>  }
> }
> 
> plot(fit$AUCcurve$k,apply(AUC_r,1,mean),type = "b",pch = 3,xlab = "# of
> Vars", lwd = 2, col = 2,ylab = "OOB-AUC",ylim = c(0.4,1))
> 

Shouldn't this question go to the package maintainer before being sent to Rhelp?

> 
> Thanks,
> 
> -Jack
> 
> 	[[alternative HTML version deleted]]
And:
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov 20 23:56:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 14:56:34 -0800
Subject: [R] Percentiles for unequal probability sample
In-Reply-To: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
References: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
Message-ID: <3B72F117-B1C1-4E99-81DE-E21E82137B8A@comcast.net>


On Nov 20, 2013, at 11:35 AM, Trevor Walker wrote:

> I often work with tree data that is sampled with probability proportional
> to size, which presents a special challenge when describing the frequency
> distribution.  For example, R functions like quantile() and fitdistr()
> expect each observation to have equal sample probability.  As a workaround,
> I have been "exploding"/"mushrooming" my data based on the appropriate
> expansion factors.  However, this can take a LONG TIME and I am reaching
> out for more efficient suggestions, particularly for the quantile()
> function.  Example of my workaround:
> 

The 'Hmisc' package has a `wtd.quantile` function. I seem to remember that it might have been borrowed from the quantreg package.


> # trees.df represents random sample with probability proportional to size
> (of diameter) using "basal area factor" of 20
> trees.df <- data.frame(Diameter=rnorm(10, mean=10, sd=2),
> TreesPerAcre=numeric(10))
> trees.df$TreesPerAcre <- 20/(trees.df$Diameter^2*pi/576)    # expansion
> factor for each observation
> 
> # to obtain percentiles that are weighted by trees per acre, "explode"
> diameter data
> explodeFactor <- 10 # represents ten acres
> treeCount <- sum(round(trees.df$TreesPerAcre*explodeFactor ))
> explodedDiameters.df <- data.frame(Diameter=numeric(treeCount))
> k=0 # initialize counter k
> for (i in 1:length(trees.df$Diameter)){
>  for (j in 1:round(trees.df$TreesPerAcre[i]*explodeFactor)){
>    k <- k +1
>    explodedDiameters.df$Diameter[k] <- trees.df$Diameter[i]
>   }
> }
> 
> quantile(explodedDiameters.df$Diameter) # appropriate percentiles (for
> trees per acre)
> quantile(trees.df$Diameter)             # percentiles biased upwards
> 
> 
> 
> Trevor Walker
> 
-- 

David Winsemius
Alameda, CA, USA


From rkoenker at illinois.edu  Thu Nov 21 03:21:26 2013
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 20 Nov 2013 20:21:26 -0600
Subject: [R] Percentiles for unequal probability sample
In-Reply-To: <1f61939c96124a7192ffe425b827a0a9@CHIHT1.ad.uillinois.edu>
References: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
	<1f61939c96124a7192ffe425b827a0a9@CHIHT1.ad.uillinois.edu>
Message-ID: <2340DDF0-F68D-4A91-834A-EB9B63FC7A86@illinois.edu>

You could try:

require(quantreg)
qs <- rq(x ~ 1, weights = w, tau = 1:3/4)


Roger Koenker
rkoenker at illinois.edu




On Nov 20, 2013, at 4:56 PM, David Winsemius wrote:

> 
> On Nov 20, 2013, at 11:35 AM, Trevor Walker wrote:
> 
>> I often work with tree data that is sampled with probability proportional
>> to size, which presents a special challenge when describing the frequency
>> distribution.  For example, R functions like quantile() and fitdistr()
>> expect each observation to have equal sample probability.  As a workaround,
>> I have been "exploding"/"mushrooming" my data based on the appropriate
>> expansion factors.  However, this can take a LONG TIME and I am reaching
>> out for more efficient suggestions, particularly for the quantile()
>> function.  Example of my workaround:
>> 
> 
> The 'Hmisc' package has a `wtd.quantile` function. I seem to remember that it might have been borrowed from the quantreg package.
> 
> 
>> # trees.df represents random sample with probability proportional to size
>> (of diameter) using "basal area factor" of 20
>> trees.df <- data.frame(Diameter=rnorm(10, mean=10, sd=2),
>> TreesPerAcre=numeric(10))
>> trees.df$TreesPerAcre <- 20/(trees.df$Diameter^2*pi/576)    # expansion
>> factor for each observation
>> 
>> # to obtain percentiles that are weighted by trees per acre, "explode"
>> diameter data
>> explodeFactor <- 10 # represents ten acres
>> treeCount <- sum(round(trees.df$TreesPerAcre*explodeFactor ))
>> explodedDiameters.df <- data.frame(Diameter=numeric(treeCount))
>> k=0 # initialize counter k
>> for (i in 1:length(trees.df$Diameter)){
>> for (j in 1:round(trees.df$TreesPerAcre[i]*explodeFactor)){
>>   k <- k +1
>>   explodedDiameters.df$Diameter[k] <- trees.df$Diameter[i]
>>  }
>> }
>> 
>> quantile(explodedDiameters.df$Diameter) # appropriate percentiles (for
>> trees per acre)
>> quantile(trees.df$Diameter)             # percentiles biased upwards
>> 
>> 
>> 
>> Trevor Walker
>> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wangdan412 at gmail.com  Thu Nov 21 04:12:32 2013
From: wangdan412 at gmail.com (dan wang)
Date: Wed, 20 Nov 2013 22:12:32 -0500
Subject: [R] integrate
Message-ID: <CA+1Z_YvpWgOyOUmCrz-gu3MEcRCVh+Mskpm7+az9GxtzREU01w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/67f6b88e/attachment.pl>

From dwinsemius at comcast.net  Thu Nov 21 05:39:42 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 20:39:42 -0800
Subject: [R] integrate
In-Reply-To: <CA+1Z_YvpWgOyOUmCrz-gu3MEcRCVh+Mskpm7+az9GxtzREU01w@mail.gmail.com>
References: <CA+1Z_YvpWgOyOUmCrz-gu3MEcRCVh+Mskpm7+az9GxtzREU01w@mail.gmail.com>
Message-ID: <52657A00-C3D9-4E96-AF81-1F06F49D4402@comcast.net>


On Nov 20, 2013, at 7:12 PM, dan wang wrote:

> Hi all,
> 
> Can anyone help me with below integrate function?
> 
> Basically, I want to calculate the integral of  the sum of two kernel
> density functions.
> But the error shows that:
> In x - a :
>  longer object length is not a multiple of shorter object length
> 
> y1 = rnorm(10)
> y2 = rnorm(10)
> fhat <- function(x,a){h=density(a)$bw;sum(dnorm((x-a)/h)/h/length(a))}
> 
> integrand1 <- function(p) {
>             fhat(p,y1)+fhat(p,y2)
>         }
> integrate(integrand1,lower = -Inf, upper = Inf)

So, .... where is "a"?

-- 


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Nov 21 05:52:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Nov 2013 20:52:15 -0800
Subject: [R] integrate
In-Reply-To: <52657A00-C3D9-4E96-AF81-1F06F49D4402@comcast.net>
References: <CA+1Z_YvpWgOyOUmCrz-gu3MEcRCVh+Mskpm7+az9GxtzREU01w@mail.gmail.com>
	<52657A00-C3D9-4E96-AF81-1F06F49D4402@comcast.net>
Message-ID: <0903A0CD-EF4D-49EE-A0F6-5F05431079C0@comcast.net>


On Nov 20, 2013, at 8:39 PM, David Winsemius wrote:

> 
> On Nov 20, 2013, at 7:12 PM, dan wang wrote:
> 
>> Hi all,
>> 
>> Can anyone help me with below integrate function?
>> 
>> Basically, I want to calculate the integral of  the sum of two kernel
>> density functions.
>> But the error shows that:
>> In x - a :
>> longer object length is not a multiple of shorter object length
>> 
>> y1 = rnorm(10)
>> y2 = rnorm(10)
>> fhat <- function(x,a){h=density(a)$bw;sum(dnorm((x-a)/h)/h/length(a))}
>> 
>> integrand1 <- function(p) {
>>            fhat(p,y1)+fhat(p,y2)
>>        }
>> integrate(integrand1,lower = -Inf, upper = Inf)
> 
> So, .... where is "a"?

Ignore that person. Try this:


Vintegrand <- Vectorize(integrand1)
integrate( Vintegrand, lower = -Inf, upper = Inf)
#----------------
2 with absolute error < 2.4e-05

David Winsemius
Alameda, CA, USA


From noahsilverman at g.ucla.edu  Wed Nov 20 21:16:54 2013
From: noahsilverman at g.ucla.edu (Noah Silverman)
Date: Wed, 20 Nov 2013 12:16:54 -0800
Subject: [R] Thoughts for faster indexing
Message-ID: <528D18B6.1000502@g.ucla.edu>

Hello,

I have a fairly large data.frame.  (About 150,000 rows of 100
variables.) There are case IDs, and multiple entries for each ID, with a
date stamp.  (i.e. records of peoples activity.)


I need to iterate over each person (record ID) in the data set, and then
process their data for each date.  The processing part is fast, the date
part is fast.  Locating the records is slow.  I've even tried using
data.table, with ID set as the index, and it is still slow.

The line with the slow process (According to Rprof) is:


j <- which( d$id == person )

(I then process all the records indexed by j, which seems fast enough.)

where d is my data.frame or data.table

I thought that using the data.table indexing would speed things up, but
not in this case.

Any ideas on how to speed this up?


Thanks!

-- 
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From jjjyue1234 at gmail.com  Wed Nov 20 20:15:25 2013
From: jjjyue1234 at gmail.com (Junjie Jiang)
Date: Wed, 20 Nov 2013 11:15:25 -0800
Subject: [R] Convergent Cross Mapping
In-Reply-To: <op.wvuj6h19zqkd1e@nirvana>
References: <op.wvuj6h19zqkd1e@nirvana>
Message-ID: <34711adb-d7fa-4907-b83c-875f65f8b1c3@googlegroups.com>



? 2013?4?21????UTC+8??12?02?31??Lorenzo Isella???
>
> Dear All, 
> I am looking for an R implementation of the convergent cross mapping 
> method (see http://bit.ly/XN8OZX and 
>
> http://www.uvm.edu/~cdanfort/csc-reading-group/sugihara-causality-science-2012.pdf  
> ) 
>
> The method is presented as an improvement over Granger causality (   
> http://bit.ly/XN8ydi ), but its implementation (involving shadows of   
> multidimensional manifolds) must be quite some work... 
> Does anybody know if there is an R implementation somewhere? 
> Cheers 
>
> Lorenzo 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>





  do you get the code? if have the code if you can get me a copy thanks I 
am also looking for the code about the convergent cross mapping's code.

From jjjyue1234 at gmail.com  Wed Nov 20 20:15:25 2013
From: jjjyue1234 at gmail.com (Junjie Jiang)
Date: Wed, 20 Nov 2013 11:15:25 -0800 (PST)
Subject: [R] Convergent Cross Mapping
In-Reply-To: <op.wvuj6h19zqkd1e@nirvana>
References: <op.wvuj6h19zqkd1e@nirvana>
Message-ID: <34711adb-d7fa-4907-b83c-875f65f8b1c3@googlegroups.com>



? 2013?4?21????UTC+8??12?02?31??Lorenzo Isella???
>
> Dear All, 
> I am looking for an R implementation of the convergent cross mapping 
> method (see http://bit.ly/XN8OZX and 
>
> http://www.uvm.edu/~cdanfort/csc-reading-group/sugihara-causality-science-2012.pdf  
> ) 
>
> The method is presented as an improvement over Granger causality (   
> http://bit.ly/XN8ydi ), but its implementation (involving shadows of   
> multidimensional manifolds) must be quite some work... 
> Does anybody know if there is an R implementation somewhere? 
> Cheers 
>
> Lorenzo 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>





  do you get the code? if have the code if you can get me a copy thanks I 
am also looking for the code about the convergent cross mapping's code.

From dawn1313 at gmail.com  Wed Nov 20 22:13:18 2013
From: dawn1313 at gmail.com (Dawn)
Date: Wed, 20 Nov 2013 16:13:18 -0500
Subject: [R] error in install
Message-ID: <CABtBq8GK0=a89-SEDcP1TWm=yr_u8YthdcwpgGg5q6gh8vCH2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/844c5df6/attachment.pl>

From lizconsidine at gmail.com  Thu Nov 21 01:01:47 2013
From: lizconsidine at gmail.com (Betty)
Date: Wed, 20 Nov 2013 16:01:47 -0800 (PST)
Subject: [R] PLS-DA and LV variance with mixOmics
In-Reply-To: <1348772576673-4644415.post@n4.nabble.com>
References: <1348772576673-4644415.post@n4.nabble.com>
Message-ID: <94575e8c-aed5-4286-8321-a6102186961b@googlegroups.com>

Hi Roberto,
I need to do the same..did you manage to figure it out?
Thanks.

On Thursday, September 27, 2012 8:02:56 PM UTC+1, Roberto wrote:
>
> Hi all, 
> I need to obtain the LV variance from my PLS-DA analysis. 
> I tried to read the reference manuale of the package, but I do not found 
> information about that. 
>
> Someone know a way to do it? 
>
> Thank you, 
> Roberto 
>
>
>
> -- 
> View this message in context: 
> http://r.789695.n4.nabble.com/PLS-DA-and-LV-variance-with-mixOmics-tp4644415.html 
> Sent from the R help mailing list archive at Nabble.com. 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From vijaychowdhari at gmail.com  Thu Nov 21 01:54:49 2013
From: vijaychowdhari at gmail.com (Vijay Chowdhari)
Date: Wed, 20 Nov 2013 16:54:49 -0800
Subject: [R] Reverse geocoding Latitude and Longitude to address/name of
	location
Message-ID: <CAPpreQe6j467aty_X=HJ_e9rqjKDj5UcGxoBKdE-guqoUntABA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/43279c12/attachment.pl>

From putra_autumn86 at yahoo.com  Thu Nov 21 03:43:26 2013
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Wed, 20 Nov 2013 18:43:26 -0800 (PST)
Subject: [R] The profile log-likelihood problem
Message-ID: <1385001806.72319.YahooMailNeo@web126104.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131120/a11a6823/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 21 04:20:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 19:20:33 -0800 (PST)
Subject: [R] How to extract sets of rows (not sorted) from text file in
	R, do some methods on these rows,
	save the result in another text file,
	then pick others set of rows and do the same
In-Reply-To: <CAGBvU3kFa2_B986YMOyWxWc_V6druk7BHFTi_gp4f5wXpKVXPw@mail.gmail.com>
References: <19851505.203024.1384898086959.JavaMail.nabble@joe.nabble.com>
	<CAGBvU3kFa2_B986YMOyWxWc_V6druk7BHFTi_gp4f5wXpKVXPw@mail.gmail.com>
Message-ID: <1385004033.8484.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
dat1 <- read.csv("Manal.csv",header=FALSE) 
str(dat1)
#'data.frame':??? 31 obs. of? 9 variables:
# $ V1: int? 1 1 1 1 3 1 2 2 3 2 ...
# $ V2: int? 1 1 0 0 0 1 0 0 0 0 ...
# $ V3: int? 0 0 1 0 0 0 0 0 0 0 ...
# $ V4: int? 1 1 0 0 0 0 0 0 0 0 ...
# $ V5: int? 0 0 1 0 1 0 0 1 1 0 ...
# $ V6: int? 0 0 0 0 0 0 0 0 0 0 ...
# $ V7: int? 1 0 0 0 0 0 0 0 0 0 ...
# $ V8: int? 0 1 0 0 0 0 0 0 0 0 ...
# $ V9: int? 0 0 1 0 1 0 0 0 0 0 ...
res <- do.call(rbind,lapply(split(dat1[,-1],dat1[,1]),function(x) (colSums(x)>= nrow(x)/2)*1))
dim(res)
#[1] 10? 8


res[1:2,] ## this is the result you showed in the excel sheet
? V2 V3 V4 V5 V6 V7 V8 V9
#1? 1? 0? 0? 0? 0? 0? 0? 0
#2? 0? 0? 0? 0? 0? 0? 0? 0

Then, you can use ?write.table() as showed previously.


A.K.







On Wednesday, November 20, 2013 7:27 PM, Manal H <manal76 at gmail.com> wrote:

Hi
First thanks a lot for answering me. sorry if I wasn't clear, English is not my first language.?I tried to use your code but it didn't give?what I want. I'm new in r, so sorry for being annoying.

I have attached a? reproducible example?


thanks and best




On Tue, Nov 19, 2013 at 1:55 PM, <smartpink111 at yahoo.com> wrote:

Hi,
>
>I am not sure I understand you completely. ?Are you applying the same set of methods on each of the groups? ?If yes, then the methods I showed should work. ?If it is not the case, please provide a reproducible example.
>Thanks.
>A.K.
>
><quote author='memi'>
>
>Thanks a lot arun kirshna , but my question was:
>
>I have this input data
>1 2 4 7
>1 4 5 8
>1 4 5 6
>2 3 4 8
>3 6 7 8
>1 5 6 9
>2 5 7 9
>3 7 9 11
>
>I want the output like:
>
>step1: ?from the input data, extract the rows that start with one
>after I do this step,
>I got the following rows: (I don't want extract the first column that
>represents the group number)
>?2 4 7
>?4 5 8
>?4 5 6
>?5 6 9
>
>step1.1: apply some methods in the extracted data, then save the result in
>new text file.
>-----
>
>
>step2: ? from the input data, extract the rows that start with two
>after I do this step,
>I got the following rows: (I don't want extract the first column that
>represents the group number)
>?3 4 8
>?5 7 9
>
>step2.1: apply some methods in the extracted data, then save the result
>after the result in step one.
>----
>
>step3: ?from the input data, extract the rows that start with three
>after I do this step,
>I got the following rows: (I don't want extract the first column that
>represents the group number)
>?6 7 8
>?7 9 11
>
>step3.1: apply some methods in the extracted data, then save the result
>after the result in step two.
>-----
>
>and so on
>my input txt file has more than 9000 rows, each row start with group number,
>these number from 1 to 100
>so I want do the process 100 times (from ?1 to 100)
>?- extract the rows that start with 1, apply methods on them, save the
>result in new txt file
>- ?extract the rows that start with 2, apply methods on them, save the
>result in new txt file after the previous result.
>- ?extract the rows that start with 3, apply methods on them, save the
>result in new txt file after the previous result.
>- ?extract the rows that start with 4, apply methods on them, save the
>result in new txt file after the previous result.
>
>.
>.
>- ?extract the rows that start with 100, apply methods on them, save the
>result in new txt file after the previous result.
>
>
>
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/Re-How-to-extract-sets-of-rows-not-sorted-from-text-file-in-R-do-some-methods-on-these-rows-save-thee-tp4680741p4680759.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>


From ekbrown at k-state.edu  Thu Nov 21 04:45:26 2013
From: ekbrown at k-state.edu (Earl Brown)
Date: Wed, 20 Nov 2013 22:45:26 -0500 (EST)
Subject: [R] RStudio and R.app "segmentation fault" errors
In-Reply-To: <1823033592.71607462.1385005450162.JavaMail.root@k-state.edu>
Message-ID: <1203602439.71609689.1385005526144.JavaMail.root@k-state.edu>

R-helpers,

I'm using system() to run a shell script that uses a library written in C++ to analyze natural language (FreeLing: http://nlp.lsi.upc.edu/freeling). When I run the following code in RStudio (0.97.248) and R.app (1.62) on Max OSX (10.7.5):

> cmd <- "analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt"
> tagged.text <- do.call(system, args = list(command = cmd, intern = T))

I sometimes receive a "Segmentation fault" error:

/usr/local/bin/analyze: line 39:  2806 Segmentation fault: 11  $FREELING/bin/analyzer $param
Warning message:
running command 'analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt' had status 139 

and sometimes I receive a "Trace/BPT trap: 5" error:

dyld: lazy symbol binding failed: Symbol not found: __ZN6icu_496LocaleD1Ev
  Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
  Expected in: flat namespace

dyld: Symbol not found: __ZN6icu_496LocaleD1Ev
  Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
  Expected in: flat namespace

/usr/local/bin/analyze: line 39:  2864 Trace/BPT trap: 5       $FREELING/bin/analyzer $param
Warning message:
running command 'analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt' had status 133 

However, when I open a Terminal window and start R there and then run the code I don't get either error message and I get the output I expect. So, the obvious work-around is to simply run my R scripts that use FreeLing (the C++ library) in an R session within Terminal. But, I'm curious to know why RStudio and R.app have problems with it, and if there is anything that I can do to be able to use RStudio and/or R.app when I want to call this C++ library.

Here's my info:
> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.0.2

Thanks in advance for your help and ideas. Earl Brown

-----
Earl K. Brown, PhD
Assistant Professor of Spanish (Linguistics)
Advisor, TEFL MA Program
Department of Modern Languages
Kansas State University
www-personal.ksu.edu/~ekbrown


From jdnewmil at dcn.davis.CA.us  Thu Nov 21 07:34:12 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 20 Nov 2013 22:34:12 -0800
Subject: [R] RStudio and R.app "segmentation fault" errors
In-Reply-To: <1203602439.71609689.1385005526144.JavaMail.root@k-state.edu>
References: <1203602439.71609689.1385005526144.JavaMail.root@k-state.edu>
Message-ID: <224dca6a-22a7-4e93-9f14-f2b312025c30@email.android.com>

Why isn't it as obvious to you as it is to me that this question belongs on the RStudio forum rather than here?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Earl Brown <ekbrown at k-state.edu> wrote:
>R-helpers,
>
>I'm using system() to run a shell script that uses a library written in
>C++ to analyze natural language (FreeLing:
>http://nlp.lsi.upc.edu/freeling). When I run the following code in
>RStudio (0.97.248) and R.app (1.62) on Max OSX (10.7.5):
>
>> cmd <- "analyze -f /usr/local/share/freeling/config/es.cfg --lang es
>--outf tagged </Users/earlbrown/temp_input.txt"
>> tagged.text <- do.call(system, args = list(command = cmd, intern =
>T))
>
>I sometimes receive a "Segmentation fault" error:
>
>/usr/local/bin/analyze: line 39:  2806 Segmentation fault: 11 
>$FREELING/bin/analyzer $param
>Warning message:
>running command 'analyze -f /usr/local/share/freeling/config/es.cfg
>--lang es --outf tagged </Users/earlbrown/temp_input.txt' had status
>139 
>
>and sometimes I receive a "Trace/BPT trap: 5" error:
>
>dyld: lazy symbol binding failed: Symbol not found:
>__ZN6icu_496LocaleD1Ev
>  Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
>  Expected in: flat namespace
>
>dyld: Symbol not found: __ZN6icu_496LocaleD1Ev
>  Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
>  Expected in: flat namespace
>
>/usr/local/bin/analyze: line 39:  2864 Trace/BPT trap: 5      
>$FREELING/bin/analyzer $param
>Warning message:
>running command 'analyze -f /usr/local/share/freeling/config/es.cfg
>--lang es --outf tagged </Users/earlbrown/temp_input.txt' had status
>133 
>
>However, when I open a Terminal window and start R there and then run
>the code I don't get either error message and I get the output I
>expect. So, the obvious work-around is to simply run my R scripts that
>use FreeLing (the C++ library) in an R session within Terminal. But,
>I'm curious to know why RStudio and R.app have problems with it, and if
>there is anything that I can do to be able to use RStudio and/or R.app
>when I want to call this C++ library.
>
>Here's my info:
>> sessionInfo()
>R version 3.0.2 (2013-09-25)
>Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
>locale:
>[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] tools_3.0.2
>
>Thanks in advance for your help and ideas. Earl Brown
>
>-----
>Earl K. Brown, PhD
>Assistant Professor of Spanish (Linguistics)
>Advisor, TEFL MA Program
>Department of Modern Languages
>Kansas State University
>www-personal.ksu.edu/~ekbrown
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Nov 21 07:34:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 22:34:10 -0800 (PST)
Subject: [R] how can I import a number of datsets in a folder in my
	working directory to a list in R
Message-ID: <1385015650.73407.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

Suppose, if I create 15 files in my working directory.
set.seed(48)
lapply(1:15,function(i) {m1 <- matrix(sample(1:20,1686*2,replace=TRUE),nrow=1686,ncol=2); write.table(m1,paste0("file_",i,".txt"),row.names=FALSE,quote=FALSE)})

?D <-dir()
D1 <- D[order(as.numeric(gsub("\\D+","",D)))]
D1

?res <- t(sapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
dim(res)
#[1]?? 15 1686
#or
res1 <- do.call(rbind,lapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
?dim(res1)
#[1]?? 15 1686
?dimnames(res) <- dimnames(res1)
?identical(res,res1)
#[1] TRUE

A.K.


I have a folder containing 15 text files in my working directory. ?I 
want to use the dir() function 
D<-dir(path="IR",all.files=F,full.names=F,recursive=T) to get the 
files in a filelist in R 
....D<-dir(path="IR",all.files=F,full.names=F,recursive=T) . the 
output is that D is a list of the names of the 15. however, the files 
are inaccessible. I want R to access to access each file which is a 
matrix of dimension 1686 by 2 so I can be able to form a new matrix (15 
by 1686) using the rbind function binding the second columns of the 15 
files together.


From tgs.public.mail at gmail.com  Thu Nov 21 07:36:01 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Thu, 21 Nov 2013 01:36:01 -0500
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
References: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
Message-ID: <CAHJ=y96y1OtPB+LPExJxqj6aaTjkyr=oodo1DFSZnF9kgfq07A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/7114a71c/attachment.pl>

From tgs.public.mail at gmail.com  Thu Nov 21 07:43:55 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Thu, 21 Nov 2013 01:43:55 -0500
Subject: [R] can par()$pin be used to guarantee equal horizontal and
 vertical image lengths?
In-Reply-To: <1384851403.82348.YahooMailNeo@web160303.mail.bf1.yahoo.com>
References: <1384851403.82348.YahooMailNeo@web160303.mail.bf1.yahoo.com>
Message-ID: <CAHJ=y95Nxn5u6BEqRkRW8KO08L6Ms2pCEbQcVUHt17gih94Zaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/fff9d303/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 21 07:43:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 22:43:34 -0800 (PST)
Subject: [R] How to use For loop to read multiple files
Message-ID: <1385016214.77065.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

I guess the trouble is here:
lapply(1:4,function(i) {paste(("file_",i,".txt"),sep="")})
Error: unexpected ',' in "lapply(1:4,function(i) {paste(("file_",

?lapply(1:4,function(i) {paste("file_",i,".txt",sep="")}) #works
#or
lapply(1:4,function(i) {paste0("file_",i,".txt",sep="")})
A.K.




Hi guys im having trouble running a for loop 

i have files name ie dog_1.txt to dog_70.txt which have been 
split into said files due to size issues and small memory on my computer 

## Getting correlation data 
sto = numeric(67) 

#Loop function to get data imported and obtain correlation 
for(i in 1:67) { 
? 
? file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_", i, ".txt"), sep="") 
? d = read.table(file) 
? sto[i] = cor(d[,1], d[,2]) 
} 

The problem is the file naming because some how it keeps putting in characters outside the quotation marks???? 

this is the output: 

+ file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_", i, ".txt"), sep="") 
Error: unexpected ',' in: 
"for(i in 1:67) { 
file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_"," 

As you can see, it goes right ahead and reads outside the quotation marks and even skips the .txt part... 

Any help is appreciated


From smartpink111 at yahoo.com  Thu Nov 21 07:45:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 20 Nov 2013 22:45:09 -0800 (PST)
Subject: [R] How to use For loop to read multiple files
In-Reply-To: <1385016214.77065.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1385016214.77065.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1385016309.12677.YahooMailNeo@web142603.mail.bf1.yahoo.com>



I forgot to delete the `sep` from the 2nd option:
?lapply(1:4,function(i) {paste0("file_",i,".txt")})
A.K.


On Thursday, November 21, 2013 1:43 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

I guess the trouble is here:
lapply(1:4,function(i) {paste(("file_",i,".txt"),sep="")})
Error: unexpected ',' in "lapply(1:4,function(i) {paste(("file_",

?lapply(1:4,function(i) {paste("file_",i,".txt",sep="")}) #works
#or
lapply(1:4,function(i) {paste0("file_",i,".txt",sep="")})
A.K.




Hi guys im having trouble running a for loop 

i have files name ie dog_1.txt to dog_70.txt which have been 
split into said files due to size issues and small memory on my computer 

## Getting correlation data 
sto = numeric(67) 

#Loop function to get data imported and obtain correlation 
for(i in 1:67) { 
? 
? file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_", i, ".txt"), sep="") 
? d = read.table(file) 
? sto[i] = cor(d[,1], d[,2]) 
} 

The problem is the file naming because some how it keeps putting in characters outside the quotation marks???? 

this is the output: 

+ file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_", i, ".txt"), sep="") 
Error: unexpected ',' in: 
"for(i in 1:67) { 
file = paste(("/Users/uqmbui/Dropbox/QBI/Data:Information/split_by_twin/data_mz_partial_normalized_"," 

As you can see, it goes right ahead and reads outside the quotation marks and even skips the .txt part... 

Any help is appreciated


From michel.arnaud at cirad.fr  Thu Nov 21 08:34:30 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 21 Nov 2013 08:34:30 +0100
Subject: [R] To transform an adjacency matrix
In-Reply-To: <CADv2QyGyqXZs+gQb-qh6Tr3NewgsEsX95TNbJe95RObg9UA_pg@mail.gmail.com>
References: <528C8ED9.4090502@cirad.fr>
	<CADv2QyGyqXZs+gQb-qh6Tr3NewgsEsX95TNbJe95RObg9UA_pg@mail.gmail.com>
Message-ID: <528DB786.8090704@cirad.fr>

Thank you also for your help
Michel
Le 20/11/2013 19:04, Dennis Murphy a ?crit :
> Hi:
>
> which(m == 1L, arr.ind = TRUE)
>
> Dennis
>
> On Wed, Nov 20, 2013 at 2:28 AM, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>> Hi
>> I have the following problem
>> I would like to build, from a matrix filled with 0 and with 1, a matrix
>> or a data.frame which contains, in every line, the number of the line
>> and the number of the column of the matrix for which the value is equal
>> to 1.
>> Exemple :
>>
>> dput(m)
>> structure(c(0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,
>> 0, 0, 0, 1, 0, 0, 0, 0), .Dim = c(5L, 5L))
>>
>> Result
>>
>> 1 5
>> 2 3
>> 2 4
>> 4 1
>> 4 3
>>
>> Thank you for your help
>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>>
>>          [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From pedro.carmona at uv.es  Thu Nov 21 08:19:56 2013
From: pedro.carmona at uv.es (=?ISO-8859-1?Q?Pedro_Carmona_Ib=E1=F1ez?=)
Date: Thu, 21 Nov 2013 08:19:56 +0100
Subject: [R] Cost function in cv. glm for a fitted logistic model when
 cutoff value of the model is not 0.5
Message-ID: <CAHhGfjY66c=XXD_87Tv6VDKPuezOfoB0HahL4HoizrT+OeNSiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/2ab508eb/attachment.pl>

From highstat at highstat.com  Thu Nov 21 09:35:06 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 21 Nov 2013 08:35:06 +0000
Subject: [R] Course: Introduction to Linear mixed effects models,
 GLMM and MCMC with R
Message-ID: <528DC5BA.4000908@highstat.com>

We would like to announce the following statistics course;

Course: Introduction to Linear mixed effects models, GLMM and MCMC with R
When: 10-14 February, 2014
Where: Pousada de juventude parque das nacoes. Rua de Moscavide, Lt 47 ? 
101, 1998- 011. Lisbon, Portugal
Info: http://www.highstat.com/statscourse.htm
Flyer: http://www.highstat.com/Courses/Flyer2014_02SIM_LisbonV2.pdf

Kind regards,

Alain


-- 
Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007)
2. Mixed effects models and extensions in ecology with R (2009)
3. A Beginner's Guide to R (2009)
4. Zero Inflated Models and GLMM with R (2012)
5. A Beginner's Guide to GAM (2012)
6. A Beginner's Guide to GLM and GLMM (2013)

Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From tlumley at uw.edu  Thu Nov 21 10:11:49 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 21 Nov 2013 22:11:49 +1300
Subject: [R] Percentiles for unequal probability sample
In-Reply-To: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
References: <CAMDVrE06vTpcY991vB+6SdDbTVP9ONypE39M88OesajRox8P2A@mail.gmail.com>
Message-ID: <CAJ55+dL8YUWCgTm4YqKveWfHOhvS-Lrv=WupV2bAnC_iS58Xfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/cc3217ed/attachment.pl>

From murdoch.duncan at gmail.com  Thu Nov 21 11:43:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Nov 2013 05:43:48 -0500
Subject: [R] RStudio and R.app "segmentation fault" errors
In-Reply-To: <1203602439.71609689.1385005526144.JavaMail.root@k-state.edu>
References: <1203602439.71609689.1385005526144.JavaMail.root@k-state.edu>
Message-ID: <528DE3E4.7050604@gmail.com>

On 13-11-20 10:45 PM, Earl Brown wrote:
> R-helpers,
>
> I'm using system() to run a shell script that uses a library written in C++ to analyze natural language (FreeLing: http://nlp.lsi.upc.edu/freeling). When I run the following code in RStudio (0.97.248) and R.app (1.62) on Max OSX (10.7.5):
>
>> cmd <- "analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt"
>> tagged.text <- do.call(system, args = list(command = cmd, intern = T))
>
> I sometimes receive a "Segmentation fault" error:
>
> /usr/local/bin/analyze: line 39:  2806 Segmentation fault: 11  $FREELING/bin/analyzer $param
> Warning message:
> running command 'analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt' had status 139

That's clearly a bug in the library or in the program that calls it 
(i.e. "analyze").

>
> and sometimes I receive a "Trace/BPT trap: 5" error:
>
> dyld: lazy symbol binding failed: Symbol not found: __ZN6icu_496LocaleD1Ev
>    Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
>    Expected in: flat namespace
>
> dyld: Symbol not found: __ZN6icu_496LocaleD1Ev
>    Referenced from: /usr/local/lib/libfreeling-3.1-alfa1.dylib
>    Expected in: flat namespace
>
> /usr/local/bin/analyze: line 39:  2864 Trace/BPT trap: 5       $FREELING/bin/analyzer $param
> Warning message:
> running command 'analyze -f /usr/local/share/freeling/config/es.cfg --lang es --outf tagged </Users/earlbrown/temp_input.txt' had status 133
>
> However, when I open a Terminal window and start R there and then run the code I don't get either error message and I get the output I expect. So, the obvious work-around is to simply run my R scripts that use FreeLing (the C++ library) in an R session within Terminal. But, I'm curious to know why RStudio and R.app have problems with it, and if there is anything that I can do to be able to use RStudio and/or R.app when I want to call this C++ library.

Presumably R.app and RStudio run the program in a different environment 
than R does at the command line.  One obvious guess is that the standard 
file handles (stdin, stdout, stderr) would be handled quite differently. 
  Another is that the program may be loaded at a different address, or 
with a different amount of memory available to it.

In any case, it's pretty clearly not a bug in R.app or RStudio.

Duncan Murdoch


> Here's my info:
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
> Thanks in advance for your help and ideas. Earl Brown
>
> -----
> Earl K. Brown, PhD
> Assistant Professor of Spanish (Linguistics)
> Advisor, TEFL MA Program
> Department of Modern Languages
> Kansas State University
> www-personal.ksu.edu/~ekbrown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lordpreetam at gmail.com  Thu Nov 21 12:09:31 2013
From: lordpreetam at gmail.com (Preetam Pal)
Date: Thu, 21 Nov 2013 16:39:31 +0530
Subject: [R] Plotting multiple confidence intervals in the same graph
Message-ID: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/1c37ad46/attachment.pl>

From jholtman at gmail.com  Thu Nov 21 12:34:12 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Thu, 21 Nov 2013 06:34:12 -0500
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528D18B6.1000502@g.ucla.edu>
References: <528D18B6.1000502@g.ucla.edu>
Message-ID: <721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>

you need to show the statement in context with the rest of the script.  you need to tell us what you want to do, not how you want to do it.  

Sent from my iPad

On Nov 20, 2013, at 15:16, Noah Silverman <noahsilverman at g.ucla.edu> wrote:

> Hello,
> 
> I have a fairly large data.frame.  (About 150,000 rows of 100
> variables.) There are case IDs, and multiple entries for each ID, with a
> date stamp.  (i.e. records of peoples activity.)
> 
> 
> I need to iterate over each person (record ID) in the data set, and then
> process their data for each date.  The processing part is fast, the date
> part is fast.  Locating the records is slow.  I've even tried using
> data.table, with ID set as the index, and it is still slow.
> 
> The line with the slow process (According to Rprof) is:
> 
> 
> j <- which( d$id == person )
> 
> (I then process all the records indexed by j, which seems fast enough.)
> 
> where d is my data.frame or data.table
> 
> I thought that using the data.table indexing would speed things up, but
> not in this case.
> 
> Any ideas on how to speed this up?
> 
> 
> Thanks!
> 
> -- 
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petretta at unina.it  Thu Nov 21 13:39:20 2013
From: petretta at unina.it (petretta at unina.it)
Date: Thu, 21 Nov 2013 13:39:20 +0100
Subject: [R]  metafor escalc(measure="SMCC")
Message-ID: <403e6f1238db76585598668a7ce80098.squirrel@webmailsquirrel.unina.it>

Many thanks to Wolfgang Viechtbauer for the prompt and clear answer.
However, I'm unable to understand what .cmicalc mathematically does in the
code line:

cmi <- .cmicalc(mi)

I look in the metafor documentation and in R (?.cmical and ??.cmicalc) but
I have no result. Please, can I have further explanation on this point?

Sorry for the trouble

Sincerely

Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy

>
Message: 50
Date: Tue, 19 Nov 2013 11:48:33 +0100
From: "Viechtbauer Wolfgang (STAT)"
        <wolfgang.viechtbauer at maastrichtuniversity.nl>
To: "petretta at unina.it" <petretta at unina.it>, "r-help at r-project.org"
        <r-help at r-project.org>
Subject: Re: [R] metafor escalc(measure="SMCC")
Message-ID:
        <077E31A57DA26E46AB0D493C9966AC730D9925568A at UM-MAIL4112.unimaas.nl>
Content-Type: text/plain; charset="us-ascii"

Dear Mario,

You can always just inspect the code:

escalc.default

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 | http://www.wvbauer.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of petretta at unina.it
> Sent: Tuesday, November 19, 2013 11:29
> To: r-help at r-project.org
> Subject: [R] metafor escalc(measure="SMCC")
>
> Dear all,
>
> I use R 3.0 for Windows.
>
> I ask how escalc(measure="SMCC") [metafor package] mathematically
> calculate yi and vi when only change score and SD change score are
> provided.
>
> I used the example (repoted below) posted by Qiang Yue at:
>
> http://r.789695.n4.nabble.com/using-metafor-for-meta-analysis-of-before-
> after-studies-escalc-SMCC-td4667233.html
>
> but it is unclear for me the formula used to derive y1 and v1. I read
> the documentation of metafor package and it is all very well
> described, but I ask if possible for the formula used by
> escalc(measure="SMCC") to mathematically calculate yi and vi.
> Unfortunatel, I have no free access to the paper quoted in metafor
> package.
>
> Beginning example:
>
> fMRS
> author year n mean_r sd_r mean_s sd_s r
> 1 Tom  2006 9  0   0 0.12 0.03    0   0
> 2 Jack 2012 6  0   0 0.23 0.05    0   0
> 3 Zhu  2013 8  0   0 0.18 0.05    0   0
>
> >
> dat_SMCC=escalc(measure="SMCC",data=fMRS,ni=n,m1i=mean_s,m2i=mean_r,sd1i=s
> d_s,sd2i=sd_r,ri=r
> ,append=TRUE)
> > dat_SMCC
> author year n mean_r sd_r mean_s sd_s r  yi      vi
> 1 Tom 2006  9  0     0    0.12  0.03  0 3.6108 0.8354
> 2 Jack 2012 6  0     0    0.23  0.05  0 3.8674 1.4131
> 3 Zhu 2013  8  0     0    0.18  0.05  0 3.1975 0.7640
>
>
>
> Sincerely
>
> --
> Mario Petretta
> Department of Translational Medical Sciences
> Naples University Federico II
> Italy
>


From gferraz29 at gmail.com  Thu Nov 21 13:47:50 2013
From: gferraz29 at gmail.com (=?iso-8859-1?Q?Gon=E7alo_Ferraz?=)
Date: Thu, 21 Nov 2013 10:47:50 -0200
Subject: [R] overlaying 2D grid on randomly distributed points
Message-ID: <41D1B412-63F7-4B2A-A9BA-4D971531EB68@gmail.com>

Hi, I have a cloud of randomly distributed points in 2-dimensional space and want to set up a grid, with a given grid-cell size, that minimizes the distance between my points and the grid nodes. Does anyone know of an R function or toolbox that somehow addresses this problem? This is a problem of optimizing the location of the grid, not a problem of deciding what should be the grid-cell size, because size is already given. Thank you.
Gon?alo

From chrisaa at med.umich.edu  Thu Nov 21 14:08:31 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Thu, 21 Nov 2013 13:08:31 +0000
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <2EB5BD4A-E93D-4BFB-8455-3CC3855D785E@comcast.net>
References: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
	<2EB5BD4A-E93D-4BFB-8455-3CC3855D785E@comcast.net>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C230CEB@UHEXMBSPR03.umhs.med.umich.edu>

That subset will give you right truncation, not right censoring.  See code below.  Use Thomas's solution.

Chris


library(survival)
set.seed(20131121)
ngroup <- 100
xxx <- rep(0:1, e=ngroup)
ttt <- rexp(length(xxx), rate=xxx+.5)
plot(survfit(Surv(ttt) ~ xxx))
survdiff(Surv(ttt) ~ xxx)

# impose earlier stop time?
tstop <- 2
lines(survfit(Surv(ttt) ~ xxx, subset=ttt<tstop), col=2)
survdiff(Surv(ttt) ~ xxx, subset=ttt<tstop)

# censor at earlier stop time
ddd <- ttt<tstop
ttt2<- pmin(ttt, tstop)

lines(survfit(Surv(ttt2, ddd) ~ xxx), col=3)
survdiff(Surv(ttt2, ddd) ~ xxx)
# green lines match black lines up to tstop




-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Wednesday, November 20, 2013 5:49 PM
To: Dr.Vinay Pitchika
Cc: r-help at r-project.org
Subject: Re: [R] How to stop Kaplan-Meier curve at a time point


On Nov 20, 2013, at 12:01 PM, Dr.Vinay Pitchika wrote:

> Hello R users
> 
> I have a question with Kaplan-Meier Curve with respect to my research. We
> have done a retrospective study on fillings in the tooth and their survival
> in relation to the many influencing factors. We had a long follow-up time
> (upto 8yrs for some variables). However, we decided to stop the analysis at
> the 6year follow up time, so that we can have uniform follow-up time for
> all the variables.
> 
> I did play a bit with the formula and tried to stop the Kaplan-Meier curve
> at my desired time (2190days)or roughly 6 years. However, my question is I
> want to find the significance (log rank test) at this time point between
> the two curves; because I am not able to find a way to stop the survfit at
> this time point with my knowledge. Below is the code I used.
> 
> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender)

I'm assuming that you have a dataframe with those variables and have attached it. If so, then:

dfrm <- detach(said_df)

# If not, then:

dfrm <- data.frame(Survival_days, Outcome, Gender)

Gender2<-survfit(Surv(Survival_days, Outcome)~Gender, 
                  data=dfrm, subset = Survival_days < 6*365.25 )

> 
> plot (Gender2, xmax=2190, mark.time=FALSE, col=c(1:2), xlab="Survival time
> (Days)", ylab="Survival probability", main="Gender") # mark.time=FALSE will
> remove the censoring lines in the graph. If censoring lines are needed,
> then remove the mark.time section in the formula.
> 
> legend("topright",c("Females", "Males"), col=(1:2), lwd=0.5)
> 
> Am sure, the code in the first line has to be modified. Please help me with
> this and I will be very thankful to you.
> 


David Winsemius
Alameda, CA, USA


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From carl at witthoft.com  Thu Nov 21 14:21:33 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 21 Nov 2013 05:21:33 -0800 (PST)
Subject: [R] Question on xyplot
In-Reply-To: <1384980970037-4680833.post@n4.nabble.com>
References: <1384980970037-4680833.post@n4.nabble.com>
Message-ID: <1385040093136-4680888.post@n4.nabble.com>

you didn't show us the code you used to generate the legend.
I'm guessing you want to add to the legend list something like "lty=0:7" .



KB wrote
> I recently started using R, so I'm not really experienced with it. My
> question is on adjusting xyplots to get lty lines instead of coloured
> lines. 
> 
> My datasets looks about this:
> year    area    species        x
> 1998      1         x1          0.005
> 1998      2         x2          0.006
> etc. 
> 
> year is factor from 1967 to 2013
> area is factor from 1 to 10
> species if factor, with 7 species
> 
> the following code works:
> xyplot(x~Year|Area, data=prob2, groups=Species, type="l", auto.key=TRUE)
> 
> but then I have all coloured lines. 
> 
> when I insert lty=0:7, col="black", it works, however my legend stays with
> different colours 
> 
> What do I have to insert in my code to get black lty lines also in the
> legend? 
> 
> Thanks in advance!





--
View this message in context: http://r.789695.n4.nabble.com/Question-on-xyplot-tp4680833p4680888.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Thu Nov 21 14:23:35 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Thu, 21 Nov 2013 05:23:35 -0800 (PST)
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528D18B6.1000502@g.ucla.edu>
References: <528D18B6.1000502@g.ucla.edu>
Message-ID: <1385040215488-4680889.post@n4.nabble.com>

What the Data Munger Guru said.
Plus: this is almost certainly a job for ddply or data.table.



Noah Silverman-2 wrote
> Hello,
> 
> I have a fairly large data.frame.  (About 150,000 rows of 100
> variables.) There are case IDs, and multiple entries for each ID, with a
> date stamp.  (i.e. records of peoples activity.)
> 
> 
> I need to iterate over each person (record ID) in the data set, and then
> process their data for each date.  The processing part is fast, the date
> part is fast.  Locating the records is slow.  I've even tried using
> data.table, with ID set as the index, and it is still slow.
> 
> The line with the slow process (According to Rprof) is:
> 
> 
> j <- which( d$id == person )
> 
> (I then process all the records indexed by j, which seems fast enough.)
> 
> where d is my data.frame or data.table
> 
> I thought that using the data.table indexing would speed things up, but
> not in this case.
> 
> Any ideas on how to speed this up?
> 
> 
> Thanks!
> 
> -- 
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Thoughts-for-faster-indexing-tp4680854p4680889.html
Sent from the R help mailing list archive at Nabble.com.


From wangdan412 at gmail.com  Thu Nov 21 14:50:45 2013
From: wangdan412 at gmail.com (dan wang)
Date: Thu, 21 Nov 2013 08:50:45 -0500
Subject: [R] integrate
In-Reply-To: <0903A0CD-EF4D-49EE-A0F6-5F05431079C0@comcast.net>
References: <CA+1Z_YvpWgOyOUmCrz-gu3MEcRCVh+Mskpm7+az9GxtzREU01w@mail.gmail.com>
	<52657A00-C3D9-4E96-AF81-1F06F49D4402@comcast.net>
	<0903A0CD-EF4D-49EE-A0F6-5F05431079C0@comcast.net>
Message-ID: <CA+1Z_Yu_JAV0y+bxAFk69LdSzoW5gO1m0aM9essYyzOXyPnz-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/dd2ff850/attachment.pl>

From Rainer at krugs.de  Thu Nov 21 14:51:58 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 21 Nov 2013 14:51:58 +0100
Subject: [R] Thoughts for faster indexing
In-Reply-To: <721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>
References: <528D18B6.1000502@g.ucla.edu>
	<721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>
Message-ID: <528E0FFE.7030300@krugs.de>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1



On 11/21/13, 12:34 , Jim Holtman wrote:
> you need to show the statement in context with the rest of the
> script.  you need to tell us what you want to do, not how you want
> to do it.

Agreed - a few details will result in guesses (see my guess below)

> 
> Sent from my iPad
> 
> On Nov 20, 2013, at 15:16, Noah Silverman
> <noahsilverman at g.ucla.edu> wrote:
> 
>> Hello,
>> 
>> I have a fairly large data.frame.  (About 150,000 rows of 100 
>> variables.) There are case IDs, and multiple entries for each ID,
>> with a date stamp.  (i.e. records of peoples activity.)
>> 
>> 
>> I need to iterate over each person (record ID) in the data set,
>> and then process their data for each date.  The processing part
>> is fast, the date part is fast.  Locating the records is slow.
>> I've even tried using data.table, with ID set as the index, and
>> it is still slow.
>> 
>> The line with the slow process (According to Rprof) is:
>> 
>> 
>> j <- which( d$id == person )

Possibly use

d_by_id <- split(d, d$id)

which splits the data.frame d into a listt, where each list represents
the data.frame of one id.

But: Just a guess.

Cheers,

Rainer

>> 
>> (I then process all the records indexed by j, which seems fast
>> enough.)
>> 
>> where d is my data.frame or data.table
>> 
>> I thought that using the data.table indexing would speed things
>> up, but not in this case.
>> 
>> Any ideas on how to speed this up?
>> 
>> 
>> Thanks!
>> 
>> -- Noah Silverman, M.S., C.Phil UCLA Department of Statistics 
>> 8117 Math Sciences Building Los Angeles, CA 90095
>> 
>> ______________________________________________ 
>> R-help at r-project.org mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide http://www.R-project.org/posting-guide.html and
>> provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
> 

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSjg/+AAoJENvXNx4PUvmC/kcH/3eaMvOTCAvA6ewwH/XJHH6X
B4BgstscvvJ3yArFeWqLIV0CEgk3da4c28+4Jk50vnltRVwUieFxKA1UK6Ef3gPl
pZUg9TaUNAeHPfkrxQSrYIa+hLWMZ1Ybe6GM1OlXnkc9ZBT9KS+rX3HFfr9rdyFI
Rv7SgrylUnpZIyiMeAzQS/FBzozV3G6mGu8FJ8YW5mHCqajI2alK3B3BBREzuLsL
ZMSuFDPTzxrE63O+uU6yFDibhz/4chKVz6CEF52WUgpgP+X4rW/DcLDrDfXxEvwM
ZDHcOZ8FJsuDl1lb1bdzSyS61KfzWls37i9VtOozqQwSFbaHbcdV16jHCPDzRPA=
=u5ol
-----END PGP SIGNATURE-----


From petr.pikal at precheza.cz  Thu Nov 21 15:13:27 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 21 Nov 2013 14:13:27 +0000
Subject: [R] Plotting multiple confidence intervals in the same graph
In-Reply-To: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>
References: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9FBE0@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Preetam Pal
> Sent: Thursday, November 21, 2013 12:10 PM
> To: r-help at r-project.org
> Subject: [R] Plotting multiple confidence intervals in the same graph
> 
> Hi,
> 
> I have 100 observations X1,X2,......,X100 and the confidence interval
> limits for the mean at 5% level of significance.
> I wanted to repeat this procedure say 50 times and see how many times
> the hypothetical mean is included in the confidence intervals.

Hm, I do not understand well what procedure you want to repeat 50 times?

> Analytically I have done this, but I am thinking if I can plot the 50
> confidence interval in the same graph and may be have a vertical line
> denoting the hypothetical mean. This will be a good visual
> representation I think.Can I use different colors as well?

If you want to have 50 colours you will not be able to distinguish differences. How do you want to plot 50 confidence intervals?

Something like that comes to mind but you shall be more specific about what do you want

plot(1,1, type="n")
arrows(1,.8,1,1.2, angle=90, code=3)
abline(h=1.1, col=2)

Regards
Petr

> 
> I request for your help on this.
> 
> Thanks and Regards,
> Preetam
> 
> 
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No.
> N-114
> Statistics Division,
> C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Nov 21 15:18:31 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Nov 2013 15:18:31 +0100
Subject: [R] Does function read.sas7bdat() have some memory limitations?
In-Reply-To: <59BCB7CFDB5BBB4E8FA26956BC3B1D42110C49E9@IU-MSSG-MBX102.ads.iu.edu>
References: <59BCB7CFDB5BBB4E8FA26956BC3B1D42110C49E9@IU-MSSG-MBX102.ads.iu.edu>
Message-ID: <22C90A32-CBB3-4084-8F3D-6D394B74997E@gmail.com>

This certainly looks like a bug, and there are many ways of inducing bugs that only show up with large datasets - buffer overruns, fields that are too small to hold the number of rows, etc. Remember that there is NO official documentation of the .sas7bdat format, everything has been reverse engineered, and if something in the format is different for very large datasets, it may well have gone unnoticed.

However, read.sas7bdat is from the sas7bdat package which has a maintainer.  It is not unlikely that he is interested in tracking down the root cause, if you show him how to generate SAS datasets that reproduce the issue.

Best,
Peter D.

On 19 Nov 2013, at 22:40 , Li, Xiaochun <xiaochun at iupui.edu> wrote:

> Dear R-ers,
> 
> I was trying to read in a large sas7bdat file (size 148094976 bytes) using 'read.sas7bdat()', but it did not read in the data correctly.  E.g., the first 5 rows will come out like this (I'm omitting other columns to keep it readable):
> 
>       PERSON_ID           age
> 1  5.399114e-315 5.329436e-315
> 2  5.399114e-315 5.328302e-315
> 3  5.399114e-315 5.332026e-315
> 4  5.399114e-315 5.329112e-315
> 5  5.399114e-315 5.331055e-315
> 
> If I reduced the original sas dataset to the first 5 rows, 'read.sas7bdat' read them in correctly:
> 
>  PERSON_ID age
> 1    612569  55
> 2    612571  48
> 3    612580  78
> 4    612606  53
> 5    612617  66
> 
> So for now I first saved the sas dataset as .csv, then read using 'read.csv', everything is fine.  
> 
> Any suggestion why 'read.sas7bdat' didn't work, and if some fix in its code can make it work?
> 
> Thank  you.
> _____________________________ 
> Xiaochun Li, Ph.D. 
> Department of Biostatistics 
> Indiana University 
> School of Medicine and
> Richard M. Fairbanks School of Public Health
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Thu Nov 21 15:34:03 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 21 Nov 2013 06:34:03 -0800
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528E0FFE.7030300@krugs.de>
References: <528D18B6.1000502@g.ucla.edu>
	<721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>
	<528E0FFE.7030300@krugs.de>
Message-ID: <CACk-te2s3LBF6DcwcBWubNYjF-9SGbafTWaf2prHwQTFvLdoHQ@mail.gmail.com>

.... or use tapply(seq_len(nrow(d),d$id,...) or a wrapper version
thereof (by, aggregate,...)

However, it would not surprise me if this does not help. I suspect
that the problem is not what you think but in the code and context you
omitted, as others have already noted.

-- Bert

On Thu, Nov 21, 2013 at 5:51 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA1
>
>
>
> On 11/21/13, 12:34 , Jim Holtman wrote:
>> you need to show the statement in context with the rest of the
>> script.  you need to tell us what you want to do, not how you want
>> to do it.
>
> Agreed - a few details will result in guesses (see my guess below)
>
>>
>> Sent from my iPad
>>
>> On Nov 20, 2013, at 15:16, Noah Silverman
>> <noahsilverman at g.ucla.edu> wrote:
>>
>>> Hello,
>>>
>>> I have a fairly large data.frame.  (About 150,000 rows of 100
>>> variables.) There are case IDs, and multiple entries for each ID,
>>> with a date stamp.  (i.e. records of peoples activity.)
>>>
>>>
>>> I need to iterate over each person (record ID) in the data set,
>>> and then process their data for each date.  The processing part
>>> is fast, the date part is fast.  Locating the records is slow.
>>> I've even tried using data.table, with ID set as the index, and
>>> it is still slow.
>>>
>>> The line with the slow process (According to Rprof) is:
>>>
>>>
>>> j <- which( d$id == person )
>
> Possibly use
>
> d_by_id <- split(d, d$id)
>
> which splits the data.frame d into a listt, where each list represents
> the data.frame of one id.
>
> But: Just a guess.
>
> Cheers,
>
> Rainer
>
>>>
>>> (I then process all the records indexed by j, which seems fast
>>> enough.)
>>>
>>> where d is my data.frame or data.table
>>>
>>> I thought that using the data.table indexing would speed things
>>> up, but not in this case.
>>>
>>> Any ideas on how to speed this up?
>>>
>>>
>>> Thanks!
>>>
>>> -- Noah Silverman, M.S., C.Phil UCLA Department of Statistics
>>> 8117 Math Sciences Building Los Angeles, CA 90095
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>> posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>> read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> - --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
> Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.22 (Darwin)
> Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/
>
> iQEcBAEBAgAGBQJSjg/+AAoJENvXNx4PUvmC/kcH/3eaMvOTCAvA6ewwH/XJHH6X
> B4BgstscvvJ3yArFeWqLIV0CEgk3da4c28+4Jk50vnltRVwUieFxKA1UK6Ef3gPl
> pZUg9TaUNAeHPfkrxQSrYIa+hLWMZ1Ybe6GM1OlXnkc9ZBT9KS+rX3HFfr9rdyFI
> Rv7SgrylUnpZIyiMeAzQS/FBzozV3G6mGu8FJ8YW5mHCqajI2alK3B3BBREzuLsL
> ZMSuFDPTzxrE63O+uU6yFDibhz/4chKVz6CEF52WUgpgP+X4rW/DcLDrDfXxEvwM
> ZDHcOZ8FJsuDl1lb1bdzSyS61KfzWls37i9VtOozqQwSFbaHbcdV16jHCPDzRPA=
> =u5ol
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From xiaochun at iupui.edu  Thu Nov 21 15:45:57 2013
From: xiaochun at iupui.edu (Li, Xiaochun)
Date: Thu, 21 Nov 2013 14:45:57 +0000
Subject: [R] Does function read.sas7bdat() have some memory limitations?
In-Reply-To: <22C90A32-CBB3-4084-8F3D-6D394B74997E@gmail.com>
References: <59BCB7CFDB5BBB4E8FA26956BC3B1D42110C49E9@IU-MSSG-MBX102.ads.iu.edu>
	<22C90A32-CBB3-4084-8F3D-6D394B74997E@gmail.com>
Message-ID: <59BCB7CFDB5BBB4E8FA26956BC3B1D42110C637C@IU-MSSG-MBX102.ads.iu.edu>

Thank you, Peter.  I'll generate a self-contained example and contact the maintainer.

Xiaochun

-----Original Message-----
From: peter dalgaard [mailto:pdalgd at gmail.com] 
Sent: Thursday, November 21, 2013 9:19 AM
To: Li, Xiaochun
Cc: r-help at R-project.org
Subject: Re: [R] Does function read.sas7bdat() have some memory limitations?

This certainly looks like a bug, and there are many ways of inducing bugs that only show up with large datasets - buffer overruns, fields that are too small to hold the number of rows, etc. Remember that there is NO official documentation of the .sas7bdat format, everything has been reverse engineered, and if something in the format is different for very large datasets, it may well have gone unnoticed.

However, read.sas7bdat is from the sas7bdat package which has a maintainer.  It is not unlikely that he is interested in tracking down the root cause, if you show him how to generate SAS datasets that reproduce the issue.

Best,
Peter D.

On 19 Nov 2013, at 22:40 , Li, Xiaochun <xiaochun at iupui.edu> wrote:

> Dear R-ers,
> 
> I was trying to read in a large sas7bdat file (size 148094976 bytes) using 'read.sas7bdat()', but it did not read in the data correctly.  E.g., the first 5 rows will come out like this (I'm omitting other columns to keep it readable):
> 
>       PERSON_ID           age
> 1  5.399114e-315 5.329436e-315
> 2  5.399114e-315 5.328302e-315
> 3  5.399114e-315 5.332026e-315
> 4  5.399114e-315 5.329112e-315
> 5  5.399114e-315 5.331055e-315
> 
> If I reduced the original sas dataset to the first 5 rows, 'read.sas7bdat' read them in correctly:
> 
>  PERSON_ID age
> 1    612569  55
> 2    612571  48
> 3    612580  78
> 4    612606  53
> 5    612617  66
> 
> So for now I first saved the sas dataset as .csv, then read using 'read.csv', everything is fine.  
> 
> Any suggestion why 'read.sas7bdat' didn't work, and if some fix in its code can make it work?
> 
> Thank  you.
> _____________________________
> Xiaochun Li, Ph.D. 
> Department of Biostatistics
> Indiana University
> School of Medicine and
> Richard M. Fairbanks School of Public Health
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tgs.public.mail at gmail.com  Thu Nov 21 15:48:31 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Thu, 21 Nov 2013 09:48:31 -0500
Subject: [R] Plotting multiple confidence intervals in the same graph
In-Reply-To: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>
References: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>
Message-ID: <CAHJ=y96YnFSMPQOMrGsccDM7uE9AMLK1UwOARnmGQ6+G=6oyOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/22737224/attachment.pl>

From cs_2002 at hotmail.com  Thu Nov 21 16:10:18 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Thu, 21 Nov 2013 18:10:18 +0300
Subject: [R] frequency of numbers
Message-ID: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/e579e7f8/attachment.pl>

From deter088 at umn.edu  Thu Nov 21 16:14:11 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Thu, 21 Nov 2013 09:14:11 -0600
Subject: [R] frequency of numbers
In-Reply-To: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>
References: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>
Message-ID: <CAOLJphmLrtJ5qSfpXnWGYS=bm=Wd59B6rFKjF7csbf59nER=Hg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/341a6405/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 21 16:20:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 07:20:10 -0800 (PST)
Subject: [R] frequency of numbers
In-Reply-To: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>
References: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>
Message-ID: <1385047210.53267.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

From the dscription, looks like you need ?rle()
vec1 <- c(111, 106, 117, 108, 120, 108, 108, 116, 116, 113) 
?res <- rle(vec1)$lengths
?names(res) <- rle(vec1)$values
?res[res>1]
#108 116 
#? 2?? 2 

length(res[res>1])



A.K.




On Thursday, November 21, 2013 10:12 AM, b. alzahrani <cs_2002 at hotmail.com> wrote:

hi guys

Assume I have this dataframe:
v3$number_of_ones
[1] 111 106 117 108 120 108 108 116 116 113 
Is there any command in r that gives me the frequency of these numbers (how many each number is repeated e.g. the number 108 repeated 2 and 111 repeated one an so on)

I have around 10^6 number and would like to see how many each number if repeated.

Regards
******************************************************************
Bander Alzahrani, 


??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Nov 21 15:06:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 06:06:20 -0800 (PST)
Subject: [R] how can I import a number of datsets in a folder in my
	working directory to a list in R
In-Reply-To: <1385015650.73407.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1385015650.73407.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1385042780.56123.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
#Generating the files

fileList1 <- paste0(rep(LETTERS[1:5],each=3),1:3,".txt")
set.seed(48)
lapply(fileList1,function(x) {m1 <- matrix(sample(1:20,1686*2,replace=TRUE),nrow=1686,ncol=2); write.table(m1,paste0("/home/arunksa111/Trial6/IR/",x),row.names=FALSE,quote=FALSE)}) 


dir()
#[1] "hcluster.r" "IR"???? ##created another file in working directory to mimic the situation? 
?D <- dir(path="IR",all.files=F,full.names=F,recursive=T)
D
# [1] "A1.txt" "A2.txt" "A3.txt" "B1.txt" "B2.txt" "B3.txt" "C1.txt" "C2.txt"
# [9] "C3.txt" "D1.txt" "D2.txt" "D3.txt" "E1.txt" "E2.txt" "E3.txt"

res1 <- do.call(rbind,lapply(D,function(x) {x1 <- read.table(paste0("/home/arunksa111/Trial6/IR/",x),header=TRUE);x1[,2]}))? ##change the path 
?dim(res1)
#[1]?? 15 1686
#or
res2 <- do.call(rbind,lapply(D,function(x) {x1 <- read.table(paste0(getwd(),"/IR/",x),header=TRUE);x1[,2]}))? 
?identical(res1,res2)
#[1] TRUE



A.K.



Thanks for your prompt reply AK. I tried the script and it is still not working. The situation is this: the 15 files are inside a 
folder named "IR" in my working directory. The folder is NOT my working 
directory but is INSIDE my working directory;so my working directory is 
just like this
auto.r
rangescale.r
mncn.r
hcluster.r
IR(the folder that contains the 15 files)

The 15 files 
in the folder are named 
A1.txt,A2.txt,A3.txt,B1.txt,B2.txt,B3.txt,C1.txt,C2.txt,C3.txt,D1.txt,D2.txt,D3.txt,E1.txt,E2.txt,E3.txt. The challenge is to get the files into R using the dir() ,for loop 
,read.table and rbind to form a matrix containing only the 2nd column of each files. then create a vector of the filenames. If I make the folder "IR" my working directory, I wont be able to use the functions listed 
above on the data. Please help me look at this, critically. Thank you




On Thursday, November 21, 2013 1:34 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

Suppose, if I create 15 files in my working directory.
set.seed(48)
lapply(1:15,function(i) {m1 <- matrix(sample(1:20,1686*2,replace=TRUE),nrow=1686,ncol=2); write.table(m1,paste0("file_",i,".txt"),row.names=FALSE,quote=FALSE)})

?D <-dir()
D1 <- D[order(as.numeric(gsub("\\D+","",D)))]
D1

?res <- t(sapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
dim(res)
#[1]?? 15 1686
#or
res1 <- do.call(rbind,lapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
?dim(res1)
#[1]?? 15 1686
?dimnames(res) <- dimnames(res1)
?identical(res,res1)
#[1] TRUE

A.K.


I have a folder containing 15 text files in my working directory. ?I 
want to use the dir() function 
D<-dir(path="IR",all.files=F,full.names=F,recursive=T) to get the 
files in a filelist in R 
....D<-dir(path="IR",all.files=F,full.names=F,recursive=T) . the 
output is that D is a list of the names of the 15. however, the files 
are inaccessible. I want R to access to access each file which is a 
matrix of dimension 1686 by 2 so I can be able to form a new matrix (15 
by 1686) using the rbind function binding the second columns of the 15 
files together.


From jeremyclarkmel at gmail.com  Thu Nov 21 11:57:29 2013
From: jeremyclarkmel at gmail.com (Jeremy Clark)
Date: Thu, 21 Nov 2013 11:57:29 +0100
Subject: [R] Functions in formulae ??
Message-ID: <CADy4v+8pHroO7y-=bAUS40yBOFO9Nmip+y_n28pPTemHJi23xA@mail.gmail.com>

Dear All,

In the following simple case I can't seem to get an improved fit,
despite trying all of the control possibilities. As there seem to be
no examples anywhere which show use of functions such as "dnorm"
within a formula, and as I am not confident at all that my formula is
correctly configured, I would appreciate some feedback ! Many thanks
in advance.

library(minpack.lm)

gg<-c(170,        171,      172,      173,      174,      175,
176,      177,      178,      179,      180,      181,      182,
183,      184,            185,      186,      187,      188,      189,
     190,      191,      192,      193,      194,      195,      196,
    197,      198,      199,            200,      201,      202,
203,      204,      205,      206,      207,      208,      209)

 dd<-c(1673,      1659,    1738,    1687,    1882,    2010,    2202,
 2248,    2409,    2417,    2215,    2279,    2539,    2479,    2341,
          2395,    2314,    2404,    2369,    2254,    2048,    1899,
  1892,    1744,    1333,    1183,    982,      772,      526,
451,            335,      253,      157,      108,      67,        44,
       26,        12,        10,        0)

 dd100000 <- dd * 0.00001

 dd100000gg <- data.frame(dd100000, gg)

 ## modLM4:

modLM4 <- nlsLM(dd100000 ~ dnorm(gg, mu,sigma, log = FALSE),  data =
dd100000gg, start = c(mu = 190, sigma = 10), trace = TRUE)

windows()
## plot data
plot(gg, dd100000, main = "modLM4")
## plot fitted values
lines(gg, fitted(modLM4), col = 2, lwd = 2)


From dcarlson at tamu.edu  Thu Nov 21 16:33:12 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 21 Nov 2013 09:33:12 -0600
Subject: [R] Plotting multiple confidence intervals in the same graph
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9FBE0@SRVEXCHMBX.precheza.cz>
References: <CAHVFrXE1+95E8r7h09mJqjVaJ=O5b65poSxxc0=e02dQVj8O9w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B9FBE0@SRVEXCHMBX.precheza.cz>
Message-ID: <00ea01cee6ce$fd314880$f793d980$@tamu.edu>

Maybe something like this, assuming mean=0:

samsize <- 100 
replicates <- 50
pval <- .05

samples <- replicate(replicates, rnorm(samsize))
confint <- t(apply(samples, 2, function(x)
c(mean(x)-qt(1-pval/2, 
   df=samsize-1)*sd(x)/sqrt(samsize), 
   mean(x)+qt(1-pval/2, df=samsize-1)*sd(x)/sqrt(samsize))))

# Simple plot
plot(c(0, 0), c(1, replicates), col="black", typ="l",
ylab="Samples",
   xlab="Confidence Interval")
segments(confint[,1], 1:replicates, confint[,2], 1:replicates)

# Use red if mean outside interval
outside <- ifelse(confint[,1]>0 | confint[,2]<0, 2, 1)
plot(c(0, 0), c(1, replicates), col="black", typ="l",
ylab="Samples",
   xlab="Confidence Interval")
segments(confint[,1], 1:replicates, confint[,2], 1:replicates,
col=outside)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Thursday, November 21, 2013 8:13 AM
To: Preetam Pal; r-help at r-project.org
Subject: Re: [R] Plotting multiple confidence intervals in the
same graph

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Preetam Pal
> Sent: Thursday, November 21, 2013 12:10 PM
> To: r-help at r-project.org
> Subject: [R] Plotting multiple confidence intervals in the
same graph
> 
> Hi,
> 
> I have 100 observations X1,X2,......,X100 and the confidence
interval
> limits for the mean at 5% level of significance.
> I wanted to repeat this procedure say 50 times and see how
many times
> the hypothetical mean is included in the confidence intervals.

Hm, I do not understand well what procedure you want to repeat
50 times?

> Analytically I have done this, but I am thinking if I can plot
the 50
> confidence interval in the same graph and may be have a
vertical line
> denoting the hypothetical mean. This will be a good visual
> representation I think.Can I use different colors as well?

If you want to have 50 colours you will not be able to
distinguish differences. How do you want to plot 50 confidence
intervals?

Something like that comes to mind but you shall be more specific
about what do you want

plot(1,1, type="n")
arrows(1,.8,1,1.2, angle=90, code=3)
abline(h=1.1, col=2)

Regards
Petr

> 
> I request for your help on this.
> 
> Thanks and Regards,
> Preetam
> 
> 
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,
Room No.
> N-114
> Statistics Division,
> C.V.Raman
> Hall
> Indian Statistical Institute,
B.H.O.S.
> Kolkata
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From macqueen1 at llnl.gov  Thu Nov 21 16:42:06 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 21 Nov 2013 15:42:06 +0000
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528D18B6.1000502@g.ucla.edu>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D58F4B7@PRDEXMBX-08.the-lab.llnl.gov>

I have some processes where I do the same thing, iterate over subsets of a
data frame.
My data frame has ~250,000 rows, 30 variables, and the subsets are such
that there are about 6000 of them.

Performing a which() statement like yours seems quite fast.

For example, wrapping unix.time() around the which() expression, I get

   user  system elapsed   0.008   0.000   0.008

It's hard for me to imagine the single task of getting the indexes is slow
enough to be a bottleneck.



On the other hand, if the variable being used to identify subsets is a
factor with many levels (~6000 in my case), it is noticeably slower.

   user  system elapsed
  0.024   0.002   0.026


I haven't tested it, and have no real expectation that it will make a
difference, but perhaps sorting by the index variable before iterating
will help (if you haven't already). Since these are not true indexes in
the sense used by relational database systems, maybe it will make a
difference.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/20/13 12:16 PM, "Noah Silverman" <noahsilverman at g.ucla.edu> wrote:

>Hello,
>
>I have a fairly large data.frame.  (About 150,000 rows of 100
>variables.) There are case IDs, and multiple entries for each ID, with a
>date stamp.  (i.e. records of peoples activity.)
>
>
>I need to iterate over each person (record ID) in the data set, and then
>process their data for each date.  The processing part is fast, the date
>part is fast.  Locating the records is slow.  I've even tried using
>data.table, with ID set as the index, and it is still slow.
>
>The line with the slow process (According to Rprof) is:
>
>
>j <- which( d$id == person )
>
>(I then process all the records indexed by j, which seems fast enough.)
>
>where d is my data.frame or data.table
>
>I thought that using the data.table indexing would speed things up, but
>not in this case.
>
>Any ideas on how to speed this up?
>
>
>Thanks!
>
>-- 
>Noah Silverman, M.S., C.Phil
>UCLA Department of Statistics
>8117 Math Sciences Building
>Los Angeles, CA 90095
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wangdan412 at gmail.com  Thu Nov 21 16:46:30 2013
From: wangdan412 at gmail.com (dan wang)
Date: Thu, 21 Nov 2013 10:46:30 -0500
Subject: [R] about the integrate
Message-ID: <CA+1Z_YubPagqVOoniR=qJw53DggUfqjYwz0TzHvdvXQ6qjFFJQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/75e6ef5a/attachment.pl>

From btupper at bigelow.org  Thu Nov 21 16:56:14 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 21 Nov 2013 10:56:14 -0500
Subject: [R] Thoughts for faster indexing
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D58F4B7@PRDEXMBX-08.the-lab.llnl.gov>
References: <5E1B812FAC2C4A49B3D99593B5A521910D58F4B7@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <B7D03B72-5213-4F45-A6BC-ECBED1F728A6@bigelow.org>

Hi,

On Nov 21, 2013, at 10:42 AM, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:

> I have some processes where I do the same thing, iterate over subsets of a
> data frame.
> My data frame has ~250,000 rows, 30 variables, and the subsets are such
> that there are about 6000 of them.
> 
> Performing a which() statement like yours seems quite fast.
> 
> For example, wrapping unix.time() around the which() expression, I get
> 
>   user  system elapsed   0.008   0.000   0.008
> 
> It's hard for me to imagine the single task of getting the indexes is slow
> enough to be a bottleneck.
> 
> 
> 
> On the other hand, if the variable being used to identify subsets is a
> factor with many levels (~6000 in my case), it is noticeably slower.
> 
>   user  system elapsed
>  0.024   0.002   0.026
> 
> 
> I haven't tested it, and have no real expectation that it will make a
> difference, but perhaps sorting by the index variable before iterating
> will help (if you haven't already). Since these are not true indexes in
> the sense used by relational database systems, maybe it will make a
> difference.
> 

You might also want to check this out?

http://adv-r.had.co.nz/Performance.html

Cheers,
Ben



> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 11/20/13 12:16 PM, "Noah Silverman" <noahsilverman at g.ucla.edu> wrote:
> 
>> Hello,
>> 
>> I have a fairly large data.frame.  (About 150,000 rows of 100
>> variables.) There are case IDs, and multiple entries for each ID, with a
>> date stamp.  (i.e. records of peoples activity.)
>> 
>> 
>> I need to iterate over each person (record ID) in the data set, and then
>> process their data for each date.  The processing part is fast, the date
>> part is fast.  Locating the records is slow.  I've even tried using
>> data.table, with ID set as the index, and it is still slow.
>> 
>> The line with the slow process (According to Rprof) is:
>> 
>> 
>> j <- which( d$id == person )
>> 
>> (I then process all the records indexed by j, which seems fast enough.)
>> 
>> where d is my data.frame or data.table
>> 
>> I thought that using the data.table indexing would speed things up, but
>> not in this case.
>> 
>> Any ideas on how to speed this up?
>> 
>> 
>> Thanks!
>> 
>> -- 
>> Noah Silverman, M.S., C.Phil
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From jvadams at usgs.gov  Thu Nov 21 17:06:00 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 21 Nov 2013 10:06:00 -0600
Subject: [R] overlaying 2D grid on randomly distributed points
In-Reply-To: <41D1B412-63F7-4B2A-A9BA-4D971531EB68@gmail.com>
References: <41D1B412-63F7-4B2A-A9BA-4D971531EB68@gmail.com>
Message-ID: <CAN5YmCG3ndbEbYU59t9TCum2Qfw8AkKXpze=a17JMTJdRmC4qQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/1faf1081/attachment.pl>

From tgs at email.unc.edu  Thu Nov 21 17:11:37 2013
From: tgs at email.unc.edu (Thomas Stewart)
Date: Thu, 21 Nov 2013 11:11:37 -0500
Subject: [R] overlaying 2D grid on randomly distributed points
In-Reply-To: <41D1B412-63F7-4B2A-A9BA-4D971531EB68@gmail.com>
References: <41D1B412-63F7-4B2A-A9BA-4D971531EB68@gmail.com>
Message-ID: <CAHJ=y94ozbV0yfRB6Ndx0qSB0quckrfgFAOSV0-B9eAYz_rr6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/9fe4448c/attachment.pl>

From cs_2002 at hotmail.com  Thu Nov 21 17:31:03 2013
From: cs_2002 at hotmail.com (b. alzahrani)
Date: Thu, 21 Nov 2013 19:31:03 +0300
Subject: [R] frequency of numbers
In-Reply-To: <CAOLJphmLrtJ5qSfpXnWGYS=bm=Wd59B6rFKjF7csbf59nER=Hg@mail.gmail.com>
References: <DUB126-W4D0005659539924E2C48C80E10@phx.gbl>,
	<CAOLJphmLrtJ5qSfpXnWGYS=bm=Wd59B6rFKjF7csbf59nER=Hg@mail.gmail.com>
Message-ID: <DUB126-W87D297DF13DA6D79422B6F80E10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/b805fcb0/attachment.pl>

From wdunlap at tibco.com  Thu Nov 21 17:48:44 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 Nov 2013 16:48:44 +0000
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528D18B6.1000502@g.ucla.edu>
References: <528D18B6.1000502@g.ucla.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA1664F@PA-MBX01.na.tibco.com>

> The line with the slow process (According to Rprof) is:
> j <- which( d$id == person )
> (I then process all the records indexed by j, which seems fast enough.)

Using split() once (and using its output in a loop) instead of == applied to
a long vector many times, as in
   for(j in split(seq_along(d$id), people)) {
       # newdata[j,] <- process(data[j,])
   }
is typically faster.  But this is the sort of thing that tapply() and the functions
in package:plyr do for you.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Noah Silverman
> Sent: Wednesday, November 20, 2013 12:17 PM
> To: 'R-help at r-project.org'
> Subject: [R] Thoughts for faster indexing
> 
> Hello,
> 
> I have a fairly large data.frame.  (About 150,000 rows of 100
> variables.) There are case IDs, and multiple entries for each ID, with a
> date stamp.  (i.e. records of peoples activity.)
> 
> 
> I need to iterate over each person (record ID) in the data set, and then
> process their data for each date.  The processing part is fast, the date
> part is fast.  Locating the records is slow.  I've even tried using
> data.table, with ID set as the index, and it is still slow.
> 
> The line with the slow process (According to Rprof) is:
> 
> 
> j <- which( d$id == person )
> 
> (I then process all the records indexed by j, which seems fast enough.)
> 
> where d is my data.frame or data.table
> 
> I thought that using the data.table indexing would speed things up, but
> not in this case.
> 
> Any ideas on how to speed this up?
> 
> 
> Thanks!
> 
> --
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Nov 21 17:49:42 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 21 Nov 2013 11:49:42 -0500
Subject: [R] error in install
In-Reply-To: <CABtBq8GK0=a89-SEDcP1TWm=yr_u8YthdcwpgGg5q6gh8vCH2w@mail.gmail.com>
References: <CABtBq8GK0=a89-SEDcP1TWm=yr_u8YthdcwpgGg5q6gh8vCH2w@mail.gmail.com>
Message-ID: <CA+vqiLEXOjK1DRVA29scNJP=yGEOUYQ5vvHK3VZpQ_qic0Aibw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/386b6a98/attachment.pl>

From therneau at mayo.edu  Thu Nov 21 17:52:45 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 21 Nov 2013 10:52:45 -0600
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <mailman.29.1385031609.28618.r-help@r-project.org>
References: <mailman.29.1385031609.28618.r-help@r-project.org>
Message-ID: <528E3A5D.8060703@mayo.edu>

Here is the simplest answer that I know.

    outcome6 <- ifelse(Survival_days > 2190, 0, Outcome)
    survfit(Surv(Survival_days, outcome6) ~ Gender)

This assumes that the variable Outcome is coded as 0/1.  If it were instead FALSE/TRUE 
then change the 0 to "FALSE" in the first line.
The logrank test adds a term to the computation at each death time, so changing all the 
deaths after time 2160 to "censored" effectively ignores any information after that point. 
  There is no need to modify the time variable.

David W's suggestion to add "subset = (Survival_days <= 2190) was incorrect, effectively 
removing all of the most successful outcomes from the study.  It will thus lead to an 
underestimate of tooth survival.  (This was a surprise - David usually bats 1000 on 
survival questions, and I greatly appreciate his input to this list.)

Terry Therneau
(author of the package)


On 11/21/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hello R users
>
> I have a question with Kaplan-Meier Curve with respect to my research. We
> have done a retrospective study on fillings in the tooth and their survival
> in relation to the many influencing factors. We had a long follow-up time
> (upto 8yrs for some variables). However, we decided to stop the analysis at
> the 6year follow up time, so that we can have uniform follow-up time for
> all the variables.
>
> I did play a bit with the formula and tried to stop the Kaplan-Meier curve
> at my desired time (2190days)or roughly 6 years. However, my question is I
> want to find the significance (log rank test) at this time point between
> the two curves; because I am not able to find a way to stop the survfit at
> this time point with my knowledge. Below is the code I used.
>
> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender)
>
> plot (Gender2, xmax=2190, mark.time=FALSE, col=c(1:2), xlab="Survival time
> (Days)", ylab="Survival probability", main="Gender") # mark.time=FALSE will
> remove the censoring lines in the graph. If censoring lines are needed,
> then remove the mark.time section in the formula.
>
> legend("topright",c("Females", "Males"), col=(1:2), lwd=0.5)
>
> Am sure, the code in the first line has to be modified. Please help me with
> this and I will be very thankful to you.
>
> Thanks in advance


From nfultz at gmail.com  Thu Nov 21 18:45:02 2013
From: nfultz at gmail.com (Neal Fultz)
Date: Thu, 21 Nov 2013 09:45:02 -0800
Subject: [R] Thoughts for faster indexing
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA1664F@PA-MBX01.na.tibco.com>
References: <528D18B6.1000502@g.ucla.edu>
	<E66794E69CFDE04D9A70842786030B933FA1664F@PA-MBX01.na.tibco.com>
Message-ID: <CAL9B2vcJTkJG2O4FD=Q3HVmGju7f-AqPCJ+B+43mTXAA12FHtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/69bfe785/attachment.pl>

From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Nov 21 19:08:14 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 21 Nov 2013 19:08:14 +0100
Subject: [R] metafor escalc(measure="SMCC")
In-Reply-To: <403e6f1238db76585598668a7ce80098.squirrel@webmailsquirrel.unina.it>
References: <403e6f1238db76585598668a7ce80098.squirrel@webmailsquirrel.unina.it>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D99255ED7@UM-MAIL4112.unimaas.nl>

.cmicalc is a non-exported function. You can see the code with:

getAnywhere(.cmicalc)

Best,
Wolfgang

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of petretta at unina.it
> Sent: Thursday, November 21, 2013 13:39
> To: r-help at r-project.org
> Subject: [R] metafor escalc(measure="SMCC")
> 
> Many thanks to Wolfgang Viechtbauer for the prompt and clear answer.
> However, I'm unable to understand what .cmicalc mathematically does in the
> code line:
> 
> cmi <- .cmicalc(mi)
> 
> I look in the metafor documentation and in R (?.cmical and ??.cmicalc) but
> I have no result. Please, can I have further explanation on this point?
> 
> Sorry for the trouble
> 
> Sincerely
> 
> Mario Petretta
> Department of Translational Medical Sciences
> Naples University Federico II
> Italy
> 
> >
> Message: 50
> Date: Tue, 19 Nov 2013 11:48:33 +0100
> From: "Viechtbauer Wolfgang (STAT)"
>         <wolfgang.viechtbauer at maastrichtuniversity.nl>
> To: "petretta at unina.it" <petretta at unina.it>, "r-help at r-project.org"
>         <r-help at r-project.org>
> Subject: Re: [R] metafor escalc(measure="SMCC")
> Message-ID:
>         <077E31A57DA26E46AB0D493C9966AC730D9925568A at UM-
> MAIL4112.unimaas.nl>
> Content-Type: text/plain; charset="us-ascii"
> 
> Dear Mario,
> 
> You can always just inspect the code:
> 
> escalc.default
> 
> Best,
> Wolfgang
> 
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> > On Behalf Of petretta at unina.it
> > Sent: Tuesday, November 19, 2013 11:29
> > To: r-help at r-project.org
> > Subject: [R] metafor escalc(measure="SMCC")
> >
> > Dear all,
> >
> > I use R 3.0 for Windows.
> >
> > I ask how escalc(measure="SMCC") [metafor package] mathematically
> > calculate yi and vi when only change score and SD change score are
> > provided.
> >
> > I used the example (repoted below) posted by Qiang Yue at:
> >
> > http://r.789695.n4.nabble.com/using-metafor-for-meta-analysis-of-before-
> > after-studies-escalc-SMCC-td4667233.html
> >
> > but it is unclear for me the formula used to derive y1 and v1. I read
> > the documentation of metafor package and it is all very well
> > described, but I ask if possible for the formula used by
> > escalc(measure="SMCC") to mathematically calculate yi and vi.
> > Unfortunatel, I have no free access to the paper quoted in metafor
> > package.
> >
> > Beginning example:
> >
> > fMRS
> > author year n mean_r sd_r mean_s sd_s r
> > 1 Tom  2006 9  0   0 0.12 0.03    0   0
> > 2 Jack 2012 6  0   0 0.23 0.05    0   0
> > 3 Zhu  2013 8  0   0 0.18 0.05    0   0
> >
> > >
> >
> dat_SMCC=escalc(measure="SMCC",data=fMRS,ni=n,m1i=mean_s,m2i=mean_r,sd1i=s
> > d_s,sd2i=sd_r,ri=r
> > ,append=TRUE)
> > > dat_SMCC
> > author year n mean_r sd_r mean_s sd_s r  yi      vi
> > 1 Tom 2006  9  0     0    0.12  0.03  0 3.6108 0.8354
> > 2 Jack 2012 6  0     0    0.23  0.05  0 3.8674 1.4131
> > 3 Zhu 2013  8  0     0    0.18  0.05  0 3.1975 0.7640
> >
> >
> >
> > Sincerely
> >
> > --
> > Mario Petretta
> > Department of Translational Medical Sciences
> > Naples University Federico II
> > Italy
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Nov 21 19:59:13 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 21 Nov 2013 18:59:13 +0000
Subject: [R] Thoughts for faster indexing
References: <528D18B6.1000502@g.ucla.edu>
	<E66794E69CFDE04D9A70842786030B933FA1664F@PA-MBX01.na.tibco.com>
	<CAL9B2vcJTkJG2O4FD=Q3HVmGju7f-AqPCJ+B+43mTXAA12FHtA@mail.gmail.com>
Message-ID: <loom.20131121T195843-889@post.gmane.org>

Neal Fultz <nfultz <at> gmail.com> writes:

> 
> Noah,
> 
> If N is # of rows, k is # of unique IDs
> 
> Using which() is O(N), using which() in a loop is going to  be O(Nk);
> 
> sorting the entire data is O(N ln N) and then you can process it in
> contiguous blocks, no which required.
> 
> -Neal
> 

  You might also take a look at the 'dplyr' package on Github: it's
next-gen plyr, engineered for performance ...

https://github.com/hadley/dplyr


From andrzej.bienczak at googlemail.com  Thu Nov 21 19:59:38 2013
From: andrzej.bienczak at googlemail.com (Andrzej Bienczak)
Date: Thu, 21 Nov 2013 20:59:38 +0200
Subject: [R] How to add unique occasions based on date within a subject in R?
Message-ID: <011601cee6eb$d5c3b900$814b2b00$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/a383cef2/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 21 20:08:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 11:08:31 -0800 (PST)
Subject: [R] Fwd:  Datatable manipulation
In-Reply-To: <CAOdnBQe-oSCqC5gd4OzbSo6Ti=xp+vV6PEDPSpPE6idQV3dN5w@mail.gmail.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>	<1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAOdnBQe17qqWG0KAsG+KFeXpJTe7WQTtjFdKqCJQGGCk2OdZVQ@mail.gmail.com>	<CADv2QyEekzWiFg_PAOtM+YsKDiVRkZVCMcD=9BGCOU1fzzWyAA@mail.gmail.com>	<CAOdnBQeUj990vBUk3y0qDgb+UKJkQbDxQQc+_0-rrrKwTt7mmA@mail.gmail.com>	<CADv2QyFp0nu6NsxorwcPVwCS0F=5bJu0Sun=DhzNo8yaf-U+Ow@mail.gmail.com>	<CAOdnBQeM+X_sUPwPGZZF2Cx0qoEsYhQS9xoXGVuRMtsA9qdNOA@mail.gmail.com>
	<CAOdnBQe-oSCqC5gd4OzbSo6Ti=xp+vV6PEDPSpPE6idQV3dN5w@mail.gmail.com>
Message-ID: <1385060911.77793.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
Try:

dat1 <- read.table(text="a ??? b ??? c ??? d?????? e
1 ??? 2 ??? 3 ??? 4 ??? 5
10 ??? 9 ??? 8 ??? 7 ??? 6",sep="",header=TRUE)

Names1<- read.table(text="Original? ??? New??? 
e ??? ee
b ??? bb??? 
a ??? aa
c ??? cc
d ??? dd",sep="",header=TRUE,stringsAsFactors=FALSE)

It is better to dput() your dataset.? For example:
?dput(Names1)
structure(list(Original = c("e", "b", "a", "c", "d"), New = c("ee", 
"bb", "aa", "cc", "dd")), .Names = c("Original", "New"), class = "data.frame", row.names = c(NA, 
-5L))


?names(dat1) <- Names1[,2][match(names(dat1), Names1[,1])] ##
?dat1
#? aa bb cc dd ee
#1? 1? 2? 3? 4? 5
#2 10? 9? 8? 7? 6
A.K.





On Thursday, November 21, 2013 1:45 PM, Nitisha jha <nitisha999 at gmail.com> wrote:

Hi,

Thanks. I used as.character() and got the right strings.

Btw, I have lots of handicaps regarding R.

I have to rename the columns(I have 22 columns here). I have the new names along with the original names in another dataset. Right now, I am going hardcoding all the? 19 name changes(tedious and not optimum). 1st 3 names remain the same. I will give u a sample dataset. Let me know if there is any easy way of doing this.? Pardon the displaced column labels.



Original dataset. 



?? a b c d??????????? ? 
e 
1 2 3 4 5 
10 9 8 7 6 





Dataset for name change 


Original? New 



e ee 



b bb 



a aa 



c cc 



d dd 








I want my final dataset to be like this: 

aa bb cc dd ee 
1 2 3 4 5 
10 9 8 7 6 



?Could u tell me an optimal way to do it. My method is tedious and not good. 

Also, is there a way to import .xls without perl (windows)?


Thanks for being patient. :)


From smartpink111 at yahoo.com  Thu Nov 21 20:42:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 11:42:22 -0800 (PST)
Subject: [R] How to add unique occasions based on date within a subject
	in R?
In-Reply-To: <011601cee6eb$d5c3b900$814b2b00$@gmail.com>
References: <011601cee6eb$d5c3b900$814b2b00$@gmail.com>
Message-ID: <1385062942.13194.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be you can try:
###Use dput()

dat1 <- structure(list(trialno = c(11301L, 11301L, 11301L, 11301L, 11301L, 
11301L, 11301L, 11301L, 11301L, 11301L, 11302L, 11302L, 11302L, 
11302L, 11302L, 11302L, 11302L, 11302L, 11302L, 11302L), event = c("pm_intake", 
"am_intake", "pk1", "pm_intake", "am_intake", "pk1", "pk2", "pm_intake", 
"am_intake", "pk1", "pm_intake", "am_intake", "pk1", "pm_intake", 
"am_intake", "pk1", "pk2", "pm_intake", "am_intake", "pk1"), 
??? date = c("2010-11-24", "2010-11-25", "2010-11-25", "2010-12-22", 
??? "2010-12-23", "2010-12-23", "2010-12-23", "2011-02-02", "2011-02-03", 
??? "2011-02-03", "2010-11-24", "2010-11-25", "2010-11-25", "2010-12-22", 
??? "2010-12-23", "2010-12-23", "2010-12-23", "2011-02-02", "2011-02-03", 
??? "2011-02-03"), time = c("19:00", "07:00", "10:30", "19:00", 
??? "07:00", "09:54", "13:07", "19:00", "07:00", "11:30", "19:00", 
??? "07:00", "10:30", "19:00", "07:00", "09:54", "13:07", "19:00", 
??? "07:00", "11:30")), .Names = c("trialno", "event", "date", 
"time"), class = "data.frame", row.names = c("3", "4", "5", "6", 
"7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", 
"18", "19", "20", "21", "22"))


splitData<- split(dat1, dat1$trialno) #using your code
res <-? unsplit(lapply(splitData,function(x) within(x,OCC <- cumsum(ave(seq_along(date),date,FUN=seq_along)==1))),dat1$trialno)

?res$OCC
?#[1] 1 2 2 3 4 4 4 5 6 6 1 2 2 3 4 4 4 5 6 6


A.K.





On Thursday, November 21, 2013 2:04 PM, Andrzej Bienczak <andrzej.bienczak at googlemail.com> wrote:
Hi All, 



I'm trying to figure out how in my data set to add a column including a
count of unique events based on date. Here is a part of my data set:



? ? ? ? ? ? ? ? trialno? ? ?  event? ? ? ? ? ? ? ? ?  date? ? ? ? ? time

3? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-11-24? ? ? ? ? 19:00

4? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-11-25? ? ? ? ? 07:00

5? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?  2010-11-25
10:30

6? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-12-22? ? ? ? ? 19:00

7? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-12-23? ? ? ? ? 07:00

8? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2010-12-23
09:54

9? ? ? ? ? ? ? 11301? ? pk2? ? ? ? ? ? ? ? ? ? ? ?  2010-12-23
13:07

10? ? ? ? ?  11301? ? pm_intake? ? ? ? ? 2011-02-02? ? ? ? ? 19:00

11? ? ? ? ?  11301? ? am_intake? ? ? ? ? 2011-02-03? ? ? ? ? 07:00

12? ? ? ? ?  11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2011-02-03? ? ? ? ? 11:30







Basically each date within each patient would indicate a new occasion. If
patient has just drug administration - it's one occasion but if patient had
drug administration and two measurements on the same day, they all count as
the same occasion. The data set does not have a regular patters (each
patient has a different number of events on each date and events in total).

What I'm trying to achieve is:



? ? ? ? ? ? ? ? trialno? ? ?  event? ? ? ? ? ? ? ? ? ?  date? ? ? ? ? time
OCC

3? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-11-24? ? ? ? ? 19:00? ? ? 1

4? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-11-25? ? ? ? ? 07:00? ? ? 2

5? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?  2010-11-25
10:30? ? ? 2

6? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-12-22? ? ? ? ? 19:00? ? ? 3

7? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-12-23? ? ? ? ? 07:00? ? ? 4

8? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?  2010-12-23
09:54? ? ? 4

9? ? ? ? ? ? ? 11301? ? pk2? ? ? ? ? ? ? ? ? ? ? ?  2010-12-23
13:07? ? ? 4

10? ? ? ? ?  11301? ? pm_intake? ? ? ? ? 2011-02-02? ? ? ? ? 19:00? ? ? 5

11? ? ? ? ?  11301? ? am_intake? ? ? ? ? 2011-02-03? ? ? ? ? 07:00? ? ? 6

12? ? ? ? ?  11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2011-02-03? ? ? ? ? 11:30
6



I think I should apply some kind of a loop to identify within each patient
unique dates and count them...

I thought about splitting the whole data set into patients using split
function:

splitData<- split(data, data$trialno)



And applying lapply and transform to add a new column OCC (occasion) but I
don't know how to count those as integers...

I was thinking:



splitData<- lapply(splitData, function(df) {

? ? ?  transform(df, OCC= ????????????????  )}

do.call ("rbind", splitData)



I know how to do it in Excell:

=IF(D5=D4, E4,E4+1)

(if the cell value in neighbouring cell is same as in the cell above, then
value in my cell is same as in one above, else it's one greater)-this way
first cell in E column has to be 1 and the others are integers of new date
events.

Help much appreciated!

Andrzej




??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Thu Nov 21 20:56:11 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 21 Nov 2013 11:56:11 -0800
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <30411786F64EEF46856EFBA2CD9177992C230CEB@UHEXMBSPR03.umhs.med.umich.edu>
References: <CACR65sH8+nDJa2rN47JJ+sbbyfV7FNXi9SsmrEs0e77SJ40=9g@mail.gmail.com>
	<2EB5BD4A-E93D-4BFB-8455-3CC3855D785E@comcast.net>
	<30411786F64EEF46856EFBA2CD9177992C230CEB@UHEXMBSPR03.umhs.med.umich.edu>
Message-ID: <3BBDDF12-F9A7-4AB5-A62B-C3B6133B3D40@comcast.net>


On Nov 21, 2013, at 5:08 AM, Andrews, Chris wrote:

> That subset will give you right truncation, not right censoring.  See code below.  Use Thomas's solution.

I completely agree that my strategy was wrong. It inappropriately removed the long-lived cases from the riskset at earlier times so there would be an over-estimate of risk in proportion to the ratio of such cases to the entire population.

-- 
David.


> 
> Chris
> 
> 
> library(survival)
> set.seed(20131121)
> ngroup <- 100
> xxx <- rep(0:1, e=ngroup)
> ttt <- rexp(length(xxx), rate=xxx+.5)
> plot(survfit(Surv(ttt) ~ xxx))
> survdiff(Surv(ttt) ~ xxx)
> 
> # impose earlier stop time?
> tstop <- 2
> lines(survfit(Surv(ttt) ~ xxx, subset=ttt<tstop), col=2)
> survdiff(Surv(ttt) ~ xxx, subset=ttt<tstop)
> 
> # censor at earlier stop time
> ddd <- ttt<tstop
> ttt2<- pmin(ttt, tstop)
> 
> lines(survfit(Surv(ttt2, ddd) ~ xxx), col=3)
> survdiff(Surv(ttt2, ddd) ~ xxx)
> # green lines match black lines up to tstop
> 
> 
> 
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Wednesday, November 20, 2013 5:49 PM
> To: Dr.Vinay Pitchika
> Cc: r-help at r-project.org
> Subject: Re: [R] How to stop Kaplan-Meier curve at a time point
> 
> 
> On Nov 20, 2013, at 12:01 PM, Dr.Vinay Pitchika wrote:
> 
>> Hello R users
>> 
>> I have a question with Kaplan-Meier Curve with respect to my research. We
>> have done a retrospective study on fillings in the tooth and their survival
>> in relation to the many influencing factors. We had a long follow-up time
>> (upto 8yrs for some variables). However, we decided to stop the analysis at
>> the 6year follow up time, so that we can have uniform follow-up time for
>> all the variables.
>> 
>> I did play a bit with the formula and tried to stop the Kaplan-Meier curve
>> at my desired time (2190days)or roughly 6 years. However, my question is I
>> want to find the significance (log rank test) at this time point between
>> the two curves; because I am not able to find a way to stop the survfit at
>> this time point with my knowledge. Below is the code I used.
>> 
>> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender)
> 
> I'm assuming that you have a dataframe with those variables and have attached it. If so, then:
> 
> dfrm <- detach(said_df)
> 
> # If not, then:
> 
> dfrm <- data.frame(Survival_days, Outcome, Gender)
> 
> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender, 
>                  data=dfrm, subset = Survival_days < 6*365.25 )
> 
>> 
>> plot (Gender2, xmax=2190, mark.time=FALSE, col=c(1:2), xlab="Survival time
>> (Days)", ylab="Survival probability", main="Gender") # mark.time=FALSE will
>> remove the censoring lines in the graph. If censoring lines are needed,
>> then remove the mark.time section in the formula.
>> 
>> legend("topright",c("Females", "Males"), col=(1:2), lwd=0.5)
>> 
>> Am sure, the code in the first line has to be modified. Please help me with
>> this and I will be very thankful to you.
>> 
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 
> 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Nov 21 21:11:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 12:11:31 -0800 (PST)
Subject: [R] How to add unique occasions based on date within a subject
	in R?
In-Reply-To: <1385062942.13194.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <011601cee6eb$d5c3b900$814b2b00$@gmail.com>
	<1385062942.13194.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1385064691.6553.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
May be you can try:
###Use dput()

dat1 <- structure(list(trialno = c(11301L, 11301L, 11301L, 11301L, 11301L, 
11301L, 11301L, 11301L, 11301L, 11301L, 11302L, 11302L, 11302L, 
11302L, 11302L, 11302L, 11302L, 11302L, 11302L, 11302L), event = c("pm_intake", 
"am_intake", "pk1", "pm_intake", "am_intake", "pk1", "pk2", "pm_intake", 
"am_intake", "pk1", "pm_intake", "am_intake", "pk1", "pm_intake", 
"am_intake", "pk1", "pk2", "pm_intake", "am_intake", "pk1"), 
??? date = c("2010-11-24", "2010-11-25", "2010-11-25", "2010-12-22", 
??? "2010-12-23", "2010-12-23", "2010-12-23", "2011-02-02", "2011-02-03", 
??? "2011-02-03", "2010-11-24", "2010-11-25", "2010-11-25", "2010-12-22", 
??? "2010-12-23", "2010-12-23", "2010-12-23", "2011-02-02", "2011-02-03", 
??? "2011-02-03"), time = c("19:00", "07:00", "10:30", "19:00", 
??? "07:00", "09:54", "13:07", "19:00", "07:00", "11:30", "19:00", 
??? "07:00", "10:30", "19:00", "07:00", "09:54", "13:07", "19:00", 
??? "07:00", "11:30")), .Names = c("trialno", "event", "date", 
"time"), class = "data.frame", row.names = c("3", "4", "5", "6", 
"7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", 
"18", "19", "20", "21", "22"))


splitData<- split(dat1, dat1$trialno) #using your code
res <-? unsplit(lapply(splitData,function(x) within(x,OCC <- cumsum(ave(seq_along(date),date,FUN=seq_along)==1))),dat1$trialno)

?res$OCC
?#[1] 1 2 2 3 4 4 4 5 6 6 1 2 2 3 4 4 4 5 6 6

#or

?within(dat1,OCC <- as.numeric(ave(date,trialno,FUN= function(x) cumsum(ave(seq_along(x),x,FUN=seq_along)==1))))


A.K.






On Thursday, November 21, 2013 2:04 PM, Andrzej Bienczak <andrzej.bienczak at googlemail.com> wrote:
Hi All, 



I'm trying to figure out how in my data set to add a column including a
count of unique events based on date. Here is a part of my data set:



? ? ? ? ? ? ? ? trialno? ? ?? event? ? ? ? ? ? ? ? ?? date? ? ? ? ? time

3? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-11-24? ? ? ? ? 19:00

4? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-11-25? ? ? ? ? 07:00

5? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?? 2010-11-25
10:30

6? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-12-22? ? ? ? ? 19:00

7? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-12-23? ? ? ? ? 07:00

8? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2010-12-23
09:54

9? ? ? ? ? ? ? 11301? ? pk2? ? ? ? ? ? ? ? ? ? ? ?? 2010-12-23
13:07

10? ? ? ? ?? 11301? ? pm_intake? ? ? ? ? 2011-02-02? ? ? ? ? 19:00

11? ? ? ? ?? 11301? ? am_intake? ? ? ? ? 2011-02-03? ? ? ? ? 07:00

12? ? ? ? ?? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2011-02-03? ? ? ? ? 11:30







Basically each date within each patient would indicate a new occasion. If
patient has just drug administration - it's one occasion but if patient had
drug administration and two measurements on the same day, they all count as
the same occasion. The data set does not have a regular patters (each
patient has a different number of events on each date and events in total).

What I'm trying to achieve is:



? ? ? ? ? ? ? ? trialno? ? ?? event? ? ? ? ? ? ? ? ? ?? date? ? ? ? ? time
OCC

3? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-11-24? ? ? ? ? 19:00? ? ? 1

4? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-11-25? ? ? ? ? 07:00? ? ? 2

5? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?? 2010-11-25
10:30? ? ? 2

6? ? ? ? ? ? ? 11301? ? pm_intake? ? ? ? ? 2010-12-22? ? ? ? ? 19:00? ? ? 3

7? ? ? ? ? ? ? 11301? ? am_intake? ? ? ? ? 2010-12-23? ? ? ? ? 07:00? ? ? 4

8? ? ? ? ? ? ? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ?? 2010-12-23
09:54? ? ? 4

9? ? ? ? ? ? ? 11301? ? pk2? ? ? ? ? ? ? ? ? ? ? ?? 2010-12-23
13:07? ? ? 4

10? ? ? ? ?? 11301? ? pm_intake? ? ? ? ? 2011-02-02? ? ? ? ? 19:00? ? ? 5

11? ? ? ? ?? 11301? ? am_intake? ? ? ? ? 2011-02-03? ? ? ? ? 07:00? ? ? 6

12? ? ? ? ?? 11301? ? pk1? ? ? ? ? ? ? ? ? ? ? ? 2011-02-03? ? ? ? ? 11:30
6



I think I should apply some kind of a loop to identify within each patient
unique dates and count them...

I thought about splitting the whole data set into patients using split
function:

splitData<- split(data, data$trialno)



And applying lapply and transform to add a new column OCC (occasion) but I
don't know how to count those as integers...

I was thinking:



splitData<- lapply(splitData, function(df) {

? ? ?? transform(df, OCC= ????????????????? )}

do.call ("rbind", splitData)



I know how to do it in Excell:

=IF(D5=D4, E4,E4+1)

(if the cell value in neighbouring cell is same as in the cell above, then
value in my cell is same as in one above, else it's one greater)-this way
first cell in E column has to be 1 and the others are integers of new date
events.

Help much appreciated!

Andrzej




??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jlh.membership at gmail.com  Thu Nov 21 21:41:52 2013
From: jlh.membership at gmail.com (jlh.membership)
Date: Thu, 21 Nov 2013 15:41:52 -0500
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528D18B6.1000502@g.ucla.edu>
References: <528D18B6.1000502@g.ucla.edu>
Message-ID: <000601cee6fa$23c998f0$6b5ccad0$@gmail.com>

Not sure this helps but...
 
######
# data frame with 30,000 ID's, each with 5 "dates", plus some random data...
df <- data.frame(id=rep(1:30000, each=5), 
                                  date=rep(1:5, each=30000),
                                  x=rnorm(150000), y=rnorm(150000, mean=1),z=rnorm(150000,mean=3))
dt <- data.table(dt, key=id)      # note you have to set the  key...

# No difference when using which
system.time(for (i in 1:300) {j <- which(df$id==i)})
  user  system elapsed
  0.73    0.06    0.79

system.time(for (i in 1:300) {j <- which(dt$id==i)})
  user  system elapsed
  0.69    0.04    0.76

# 20 X faster using joins
system.time(for (i in 1:300) {select <- df[df$id==i,]})
  user  system elapsed
  19.25    0.36   19.64 
system.time(for (i in 1:300) {select <- dt[id==i,]})
  user  system elapsed
  4.32    0.11    4.45 
system.time(for (i in 1:300) {select <- dt[J(i)]})
  user  system elapsed
  0.88    0.00    0.88
######

Note that extracting select with a data table join still took longer than generating an "index" using which, but having all the
columns in one step, instead of just the index might speed up later operations.


-----Original Message-----
From: Noah Silverman [mailto:noahsilverman at g.ucla.edu] 
Sent: Wednesday, November 20, 2013 3:17 PM
To: 'R-help at r-project.org'
Subject: [R] Thoughts for faster indexing

Hello,

I have a fairly large data.frame.  (About 150,000 rows of 100
variables.) There are case IDs, and multiple entries for each ID, with a date stamp.  (i.e. records of peoples activity.)


I need to iterate over each person (record ID) in the data set, and then process their data for each date.  The processing part is
fast, the date part is fast.  Locating the records is slow.  I've even tried using data.table, with ID set as the index, and it is
still slow.

The line with the slow process (According to Rprof) is:


j <- which( d$id == person )

(I then process all the records indexed by j, which seems fast enough.)

where d is my data.frame or data.table

I thought that using the data.table indexing would speed things up, but not in this case.

Any ideas on how to speed this up?


Thanks!

--
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From smartpink111 at yahoo.com  Thu Nov 21 21:25:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 12:25:19 -0800 (PST)
Subject: [R] how can I import a number of datsets in a folder in my
	working directory to a list in R
In-Reply-To: <1385042780.56123.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1385015650.73407.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1385042780.56123.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1385065519.18213.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try:
1st part:

res3 <- vector()
for(i in 1:length(D)){
?res3 <- rbind(res3, read.table(paste0(getwd(),"/IR/",D[i]),header=TRUE)[,2])
?res3
?}
?dim(res3)
#[1]?? 15 1686
?identical(res2,res3)
#[1] TRUE


2nd part:

vec1 <- unlist(lapply(D,function(x) {x1 <- read.table(paste0(getwd(),"/IR/",x),header=TRUE);x1[,1]}))
length(vec1)
#[1] 25290
?15*1686
#[1] 25290


3rd part (not clear):
Dvec <- gsub("\\..*","",D)
?Dvec
# [1] "A1" "A2" "A3" "B1" "B2" "B3" "C1" "C2" "C3" "D1" "D2" "D3" "E1" "E2" "E3"


A.K.


hi AK
?thanks . that was perfect! please i need to use 
the for-loop function (for i in 1:length(D)) to achieve same result. i 
also would like to be able to access the temporary matrix x1 so I can 
extract the first column(which is common to the 15 files) in a vector. 
how do I get the file names(i.e A1 A2 etc) in a character vector too? 
sorry to bother you AK, just that as a new R user, I am finding it a bit
 difficult. thanks in advance.





On Thursday, November 21, 2013 9:06 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
#Generating the files

fileList1 <- paste0(rep(LETTERS[1:5],each=3),1:3,".txt")
set.seed(48)
lapply(fileList1,function(x) {m1 <- matrix(sample(1:20,1686*2,replace=TRUE),nrow=1686,ncol=2); write.table(m1,paste0("/home/arunksa111/Trial6/IR/",x),row.names=FALSE,quote=FALSE)}) 


dir()
#[1] "hcluster.r" "IR"???? ##created another file in working directory to mimic the situation? 
?D <- dir(path="IR",all.files=F,full.names=F,recursive=T)
D
# [1] "A1.txt" "A2.txt" "A3.txt" "B1.txt" "B2.txt" "B3.txt" "C1.txt" "C2.txt"
# [9] "C3.txt" "D1.txt" "D2.txt" "D3.txt" "E1.txt" "E2.txt" "E3.txt"

res1 <- do.call(rbind,lapply(D,function(x) {x1 <- read.table(paste0("/home/arunksa111/Trial6/IR/",x),header=TRUE);x1[,2]}))? ##change the path 
?dim(res1)
#[1]?? 15 1686
#or
res2 <- do.call(rbind,lapply(D,function(x) {x1 <- read.table(paste0(getwd(),"/IR/",x),header=TRUE);x1[,2]}))? 
?identical(res1,res2)
#[1] TRUE



A.K.



Thanks for your prompt reply AK. I tried the script and it is still not working. The situation is this: the 15 files are inside a 
folder named "IR" in my working directory. The folder is NOT my working 
directory but is INSIDE my working directory;so my working directory is 
just like this
auto.r
rangescale.r
mncn.r
hcluster.r
IR(the folder that contains the 15 files)

The 15 files 
in the folder are named 
A1.txt,A2.txt,A3.txt,B1.txt,B2.txt,B3.txt,C1.txt,C2.txt,C3.txt,D1.txt,D2.txt,D3.txt,E1.txt,E2.txt,E3.txt. The challenge is to get the files into R using the dir() ,for loop 
,read.table and rbind to form a matrix containing only the 2nd column of each files. then create a vector of the filenames. If I make the folder "IR" my working directory, I wont be able to use the functions listed 
above on the data. Please help me look at this, critically. Thank you





On Thursday, November 21, 2013 1:34 AM, arun <smartpink111 at yahoo.com> wrote:
Hi,

Suppose, if I create 15 files in my working directory.
set.seed(48)
lapply(1:15,function(i) {m1 <- matrix(sample(1:20,1686*2,replace=TRUE),nrow=1686,ncol=2); write.table(m1,paste0("file_",i,".txt"),row.names=FALSE,quote=FALSE)})

?D <-dir()
D1 <- D[order(as.numeric(gsub("\\D+","",D)))]
D1

?res <- t(sapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
dim(res)
#[1]?? 15 1686
#or
res1 <- do.call(rbind,lapply(D1,function(x) {x1<- read.table(x,header=TRUE); x1[,2]}))
?dim(res1)
#[1]?? 15 1686
?dimnames(res) <- dimnames(res1)
?identical(res,res1)
#[1] TRUE

A.K.


I have a folder containing 15 text files in my working directory. ?I 
want to use the dir() function 
D<-dir(path="IR",all.files=F,full.names=F,recursive=T) to get the 
files in a filelist in R 
....D<-dir(path="IR",all.files=F,full.names=F,recursive=T) . the 
output is that D is a list of the names of the 15. however, the files 
are inaccessible. I want R to access to access each file which is a 
matrix of dimension 1686 by 2 so I can be able to form a new matrix (15 
by 1686) using the rbind function binding the second columns of the 15 
files together.


From r.turner at auckland.ac.nz  Thu Nov 21 22:35:51 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 22 Nov 2013 10:35:51 +1300
Subject: [R] about the integrate
In-Reply-To: <CA+1Z_YubPagqVOoniR=qJw53DggUfqjYwz0TzHvdvXQ6qjFFJQ@mail.gmail.com>
References: <CA+1Z_YubPagqVOoniR=qJw53DggUfqjYwz0TzHvdvXQ6qjFFJQ@mail.gmail.com>
Message-ID: <528E7CB7.5050105@auckland.ac.nz>



Think about what you are actually getting from pnorm().

For each scalar "s" you want to get

     pnorm(s,mu[2],sigma[2])    pnorm(s,mu[3],sigma[3]) 
pnorm(s,mu[4],sigma[4])

(and then take products of things).

But when "s" is a vector you get

pnorm(s[1],mu[2],sigma[2])    pnorm(s[2],mu[3],sigma[3]) 
pnorm(s[3],mu[4],sigma[4])

pnorm(s[4],mu[2],sigma[2])    pnorm(s[5],mu[3],sigma[3]) 
pnorm(s[6],mu[4],sigma[4]) ...

and the product will be nothing like what you want.

Vectors get re-cycled in R.

Note that you get a single scalar quantity from the "prod(1 - 
pnorm(...))" component of
test2().  That single scalar multiplies each entry of the vector 
dnorm(s,mu[1],sigma[1]).

Whereas you want dnorm(s[i],mu[1],sigma[1]) to be multiplied by a 
product involving
only pnorm() terms evaluated at s[i].  That is what Vectorize() arranges 
for you.

If you are going to use R you should learn its syntax and know about 
things like the
re-cycling of vectors.

     cheers,

     Rolf Turner

On 11/22/13 04:46, dan wang wrote:
> Hi all,
>
> I tried below two methods to calculate the integrate of a same function.
> Two different results are given.
> The first one should be the right answer.
> Can any one help to explain why?
> Another issue is, the first one is not convenient as I have to update the
> mu and sigma outside the function. How can I modify the second one so I
> could issue the parameters in the integrate function.
> Thanks in advance,
>
> Dan
>
> test <- function(s){
>         prod(1-pnorm(s,mu[-1],sigma[-1]))*dnorm(s,mu[1],sigma[1])
>
> }
> testV <- Vectorize(test)
> mu=c(0,0,0,0)
> sigma=c(1,1,1,1)
> integrate(testV,lower=-Inf,upper=Inf)$value
>
>
> test2 <- function(s, mu, sigma){
>         prod(1-pnorm(s,mu[-1],sigma[-1]))*dnorm(s,mu[1],sigma[1])
>
> }
> integrate(test2,mu=c(0,0,0,0),sigma=c(1,1,1,1),lower=-Inf,upper=Inf)$value


From JSorkin at grecc.umaryland.edu  Thu Nov 21 23:07:42 2013
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 21 Nov 2013 17:07:42 -0500
Subject: [R] Repeated measures ANOVA for unbalanc
Message-ID: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>

R 3.0.1
Windows 7 
Rstudio 0.97.551
 
Colleagues,
The last time I thought about using lmer to run an unbalanced repeated measures ANOVA, I found that the package did not return p values or SEs. I believe this was because Professor Bates had important questions about the theory behind the required computations and was in the process of developing a new, improved algorithm. Has this situation changed? Has Prof. Bates, or anyone else, implemented a repeated measures ANOVA package for R that can be perform unbalanced repeated measures ANOVA and which produces valid p values and SEs? If so, what is the name of the package?
Thank you,
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From Janis.Beckstrand at va.gov  Thu Nov 21 22:34:20 2013
From: Janis.Beckstrand at va.gov (Beckstrand, Janis, NCOD)
Date: Thu, 21 Nov 2013 15:34:20 -0600
Subject: [R] How to get a nested " list of lists of data.frames" into a
	data.frame or nested dataframe for easy viewing
Message-ID: <2D4ACE41DEFE93428F23D77988EFBCB50B7AE741@VHAV10MSGA2.v10.med.va.gov>

I have data in a list of the form: list(list(dataframe())). It have
attached some random data with this structure called "l.Rdata".  The
structures in l.Rdata are as follows: a list of 4 groups: a list of 12
statistics: (and for each statistic, a dataframe contains (1row,3cols)
of values named "estimates", "lowerCL", "upperCL"). See the sample data
set attached.

I am using the following syntax to create this type of file:

require(epiR)
l<-lapply(seq_len(ncol(data[,])),function(i) {output<-epi.tests(g2[[i]],
conf.level = 0.95, verbose = TRUE)
    return(output)}) #The package "epi.tests" produces 12 statistics and
is in the epiR{}  program.

I need to get the information in my lists, like l.Rdata, into get a
data.frame or other format (using cat or xtable or something?) that is
easily readable and that  I see on the screen and save and print out,
and  that looks like
                                      group1
group2                         group3                        group4
Statistics	Est (lower,upper)        Est (lower,upper)      Est
(lower,upper)     Est (lower,upper)
aprev                     .32  (.29,.34)                        .31
(.27, .25)              etc	                               etc
tprev
etc
.
Statistic 12         .40 (.38, .42)
etc                          etc

I have looked at the various examples of how to get a list format to a
dataframe at
http://stackoverflow.com/questions/4512465/what-is-the-most-efficient-wa
y-to-cast-a-list-as-a-data-frame?rq=1 and at
http://stackoverflow.com/questions/4227223/r-list-to-data-frame

And (I think) I have attempted to use them all!, trying also to augment
each of them to convert the list of lists in the structure for output
that I need. 
After several days of trying, the structures I get out are still not
conducive to getting the data into a data.frame format where I  have
12 observations(statistics) of 12 (4 x 3) numbers that I can label or
nest into 4 groups to view on a screen or print out.  

I also have a second problem which I think it related.  As shown above,
I want to collapse the columns named "lower" and "upper" in l.Rdata into
to single "Confidence Interval (CI)" column,  within each of the groups
and add the formatting (  ,   ) to the column.  But my syntax for this
doesn't work either. 
Even when I pull out a list for a single group...(like group1) and
redefine it as.data.frame (using as.matrix, rbind, unlist, etc), I am
not getting the syntax "paste(group1[,2},group1[,3],collapse=", ") " to
collapse the rows in columns 2 and 3, even though I think this syntax is
exactly like syntax that I have used successfully before. (I copied the
syntax out of a program that has run fine before). I have looked for and
tried other options such as concatenate, sprint, etc. I think this
second problem is due to the fact that I still have a "list" structure
hidden in my attempts at transforming the structures in l.Rdata.

Any help is appreciated.  Thanks Jan

Jan Beckstrand 

From sailingwave at gmail.com  Thu Nov 21 23:05:27 2013
From: sailingwave at gmail.com (Nan Wang)
Date: Thu, 21 Nov 2013 14:05:27 -0800
Subject: [R] Is there a way to optimize a function that has the dot-dot-dot
 (...) argument using optim()
Message-ID: <CAObt1rEr9bn+kSgVAtO5PxaBeYN_q8PsR9fnv+9v-=WbGhtLCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/1c21b63b/attachment.pl>

From jfox at mcmaster.ca  Thu Nov 21 23:19:12 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 21 Nov 2013 17:19:12 -0500
Subject: [R] Repeated measures ANOVA for unbalanc
In-Reply-To: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
References: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
Message-ID: <007901cee707$b54e54c0$1feafe40$@mcmaster.ca>

Dear John,

The Anova() function in the car package will perform a traditional
unbalanced repeated-measures ANOVA (or MANOVA). See the R Journal article at
<http://journal.r-project.org/archive/2013-1/fox-friendly-weisberg.pdf>.

I hope this helps,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of John Sorkin
> Sent: Thursday, November 21, 2013 5:08 PM
> To: r-help at r-project.org
> Subject: [R] Repeated measures ANOVA for unbalanc
> 
> R 3.0.1
> Windows 7
> Rstudio 0.97.551
> 
> Colleagues,
> The last time I thought about using lmer to run an unbalanced repeated
> measures ANOVA, I found that the package did not return p values or
> SEs. I believe this was because Professor Bates had important questions
> about the theory behind the required computations and was in the
> process of developing a new, improved algorithm. Has this situation
> changed? Has Prof. Bates, or anyone else, implemented a repeated
> measures ANOVA package for R that can be perform unbalanced repeated
> measures ANOVA and which produces valid p values and SEs? If so, what
> is the name of the package?
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:6}}


From tdenes at cogpsyphy.hu  Thu Nov 21 23:21:28 2013
From: tdenes at cogpsyphy.hu (Toth, Denes)
Date: Thu, 21 Nov 2013 23:21:28 +0100
Subject: [R] Repeated measures ANOVA for unbalanc
In-Reply-To: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
References: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
Message-ID: <6dddf30ddda1a796aab2c4731edb1d6b.squirrel@webmail.cogpsyphy.hu>


Hi,

The new lme4 package has a bootMer function, so it is fairly easy to
compute bootstrap statistics.
The following packages could be what you are looking for:
1) lmerTest (see ?lmerTest:::lmer)
2) car (see Anova)
3) afex (see mixed)
4) LMERConvenienceFunctions (see pamer.fnc)

HTH,
  Denes


> R 3.0.1
> Windows 7
> Rstudio 0.97.551
>
> Colleagues,
> The last time I thought about using lmer to run an unbalanced repeated
> measures ANOVA, I found that the package did not return p values or SEs. I
> believe this was because Professor Bates had important questions about the
> theory behind the required computations and was in the process of
> developing a new, improved algorithm. Has this situation changed? Has
> Prof. Bates, or anyone else, implemented a repeated measures ANOVA package
> for R that can be perform unbalanced repeated measures ANOVA and which
> produces valid p values and SEs? If so, what is the name of the package?
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:13}}


From gunter.berton at gene.com  Thu Nov 21 23:25:14 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 21 Nov 2013 14:25:14 -0800
Subject: [R] Repeated measures ANOVA for unbalanc
In-Reply-To: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
References: <528E3DDE020000CB000F8C4A@smtp.medicine.umaryland.edu>
Message-ID: <CACk-te0B0ErR38aZTQFw3sbdHEE9z_RG_Uz5Zm0N4wD6wKw5QQ@mail.gmail.com>

Well ...

1. Try the latest version of lmer/lme4 and see for yourself. I think
the answer is still no.

2. If 1 is true, then I think you need to ask whether you **want** to
use a package that returns p values and se's, whether it exists or
not.

Cheers,
Bert



On Thu, Nov 21, 2013 at 2:07 PM, John Sorkin
<JSorkin at grecc.umaryland.edu> wrote:
> R 3.0.1
> Windows 7
> Rstudio 0.97.551
>
> Colleagues,
> The last time I thought about using lmer to run an unbalanced repeated measures ANOVA, I found that the package did not return p values or SEs. I believe this was because Professor Bates had important questions about the theory behind the required computations and was in the process of developing a new, improved algorithm. Has this situation changed? Has Prof. Bates, or anyone else, implemented a repeated measures ANOVA package for R that can be perform unbalanced repeated measures ANOVA and which produces valid p values and SEs? If so, what is the name of the package?
> Thank you,
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:23}}


From ruipbarradas at sapo.pt  Thu Nov 21 23:33:58 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 21 Nov 2013 22:33:58 +0000
Subject: [R] Is there a way to optimize a function that has the
 dot-dot-dot (...) argument using optim()
In-Reply-To: <CAObt1rEr9bn+kSgVAtO5PxaBeYN_q8PsR9fnv+9v-=WbGhtLCg@mail.gmail.com>
References: <CAObt1rEr9bn+kSgVAtO5PxaBeYN_q8PsR9fnv+9v-=WbGhtLCg@mail.gmail.com>
Message-ID: <528E8A56.1030706@sapo.pt>

Hello,

?optim has a dots argument, so just pass whatever you want after 'gr'. 
Something like the following.

optim(-3, foo, NULL, 1, 2)

Hope this helps,

Rui Barradas

Em 21-11-2013 22:05, Nan Wang escreveu:
> Hi everyone,
>
> If the function I am trying to optimize have the ... argument, how to pass
> it to optim()?
>
> For example, we want to minimize this very simple function:
>
> foo <- function(a, ...) {
>    var=list(...)
>    (a-1)^2+do.call(sum,var)
> }
>
> Although the ... in this function doesn't make any difference.
>
> Thanks,
>
> Nan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sgeorgi at student.ethz.ch  Thu Nov 21 23:43:34 2013
From: sgeorgi at student.ethz.ch (Smilyanov  Georgi)
Date: Thu, 21 Nov 2013 22:43:34 +0000
Subject: [R] changing the surface coloring (using lattice::wireframe)
Message-ID: <8AFF49EF6B3F5C419F8AC44BE350CE0518D011B2@MBX22.d.ethz.ch>

Hi all,

I am using lattice::wireframe to create a surface. I need to change the coloring so that it depends on the x or y variable (instead of on z). How should this be done? The documentation says that the color is automatically chosen to depend on the height (e.g. z).

Thanks!
Georgi

From dulcalma at bigpond.com  Fri Nov 22 00:08:41 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 22 Nov 2013 09:08:41 +1000
Subject: [R] Question on xyplot
In-Reply-To: <1385040093136-4680888.post@n4.nabble.com>
References: <1384980970037-4680833.post@n4.nabble.com>
	<1385040093136-4680888.post@n4.nabble.com>
Message-ID: <001201cee70e$9f2789d0$dd769d70$@bigpond.com>

Hi

I missed the original posting

I think to get the full picture we need to a reproducible example eg by dput
of the data. 

To keep all the information about a plot you can use the par.settings
argument which is an alternative to trellis.par.set().
Try names(trellis.par.get()) to get a list of all the arguments
Or for an individual one
trellis.par.get()$superpose.line # or
trellis.par.get()[[21]] 

The legend colours lines and symbols are controlled by superpose.symbol,
superpose.line and superpose.polygon so setting these can fix things.

Eg
par.settings = list(superpose.line = list(lty = 0:7, col = 1:8, lwd = 10)),

The other alternative is to use the key argument eg

key=list(text =list(...),
               lines=list(lty = 0:7, col = 1:8, lwd = 10),
               points = list(...)),   

I frequently put everything in par.settings when I have a simple panel
function eg 

panel = function(x,y,...){
panel.abline(...)
xyplot(x, y, ...)

}

or when the panel function is not required.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Carl Witthoft
Sent: Thursday, 21 November 2013 23:22
To: r-help at r-project.org
Subject: Re: [R] Question on xyplot

you didn't show us the code you used to generate the legend.
I'm guessing you want to add to the legend list something like "lty=0:7" .



KB wrote
> I recently started using R, so I'm not really experienced with it. My 
> question is on adjusting xyplots to get lty lines instead of coloured 
> lines.
> 
> My datasets looks about this:
> year    area    species        x
> 1998      1         x1          0.005
> 1998      2         x2          0.006
> etc. 
> 
> year is factor from 1967 to 2013
> area is factor from 1 to 10
> species if factor, with 7 species
> 
> the following code works:
> xyplot(x~Year|Area, data=prob2, groups=Species, type="l", 
> auto.key=TRUE)
> 
> but then I have all coloured lines. 
> 
> when I insert lty=0:7, col="black", it works, however my legend stays 
> with different colours
> 
> What do I have to insert in my code to get black lty lines also in the 
> legend?
> 
> Thanks in advance!





--
View this message in context:
http://r.789695.n4.nabble.com/Question-on-xyplot-tp4680833p4680888.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Fri Nov 22 00:18:41 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 22 Nov 2013 09:18:41 +1000
Subject: [R] The profile log-likelihood problem
In-Reply-To: <1385001806.72319.YahooMailNeo@web126104.mail.ne1.yahoo.com>
References: <1385001806.72319.YahooMailNeo@web126104.mail.ne1.yahoo.com>
Message-ID: <001901cee710$04785110$0d68f330$@bigpond.com>

Hi

Without knowing anything about the data and the warning messages, however
the p.vec value seems a little strange.
try 
p.vec= seq(1.35, 1.75, by = 0.1) 

It could be that you have run out of memory to do 50 sets of calculations

If ok with the result then repeat with a narrower focus. Most probably
quicker


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of smart hendsome
Sent: Thursday, 21 November 2013 12:43
To: r-help at r-project.org
Cc: roslinazairimah at ump.edu.my
Subject: [R] The profile log-likelihood problem

Hi, Im still new to R and I have a problem regarding the code below. I don't
know how to solve that. I want to compute profile log-likelihood using the
rainfall data. I use the code below from Dunn:



"
tweedie.profile(Amount~Year*Month,p.vec=seq(1.35,1.75,length=50),method="ser
ies",do.ci=TRUE) "

I got the message below when I run the code above. Anyone know why the p.vec
taken from 1.35 to 1.75? Can someone help me? 


"1.35 1.358163 1.366327 1.374490 1.382653 1.390816 1.398980 1.407143
1.415306 1.423469 1.431633 1.439796 1.447959 1.456122 1.464286 1.472449
1.480612 1.488776 1.496939 1.505102 1.513265 1.521429 1.529592 1.537755
1.545918 1.554082 1.562245 1.570408 1.578571 1.586735 1.594898 1.603061
1.611224 1.619388 1.627551 1.635714 1.643878 1.652041 1.660204 1.668367
1.676531 1.684694 1.692857 1.701020 1.709184 1.717347 1.725510 1.733673
1.741837 1.75 ..................................................Done.
  No valid values of the likelihood computed: smooth aborted
   Consider trying another value for the input  method.
Error in if ((xi.max > 0) & (xi.max < 1)) { : 
  missing value where TRUE/FALSE needed
In addition: There were 50 or more warnings (use warnings() to see the first
50)"

Thanks for yourattention and help.

Regard,
Zuhri
	[[alternative HTML version deleted]]


From lopez235 at llnl.gov  Fri Nov 22 00:32:41 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 21 Nov 2013 23:32:41 +0000
Subject: [R] How do  I identify non-sequential data?
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/13df05dd/attachment.pl>

From sreckojoksimovic at gmail.com  Fri Nov 22 00:52:47 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Thu, 21 Nov 2013 15:52:47 -0800
Subject: [R] Regression model
Message-ID: <CAM8BP_nsUxdZeHRG9KXAOaBrbqrWe+riyq_PkwHyM1PLAmU5FQ@mail.gmail.com>

Hi,

I'm trying to fit regression model, but there is something wrong with it.
The dataset contains 85 observations for 85 students.Those observations are
counts of several actions, and dependent variable is final score. More
precisely, I have 5 IV and one DV. I'm trying to build regression model to
check whether those variables can predict the final score.

I'm attaching output of several steps, but I tried to following procedure:
- build model with only those two variables
- summary shows that non of them is significant predictor of the final
outcome.
- test for multicollinearity revealed tolerance below 0.2 (potential
problem)
- build two new models having as a predictor only one of those values
- both models show that variable used for the model is significant
predictor. Separately they are significant, together not. Probably
multicollinearity problem, but...
- as I keep adding other variables to one or the other model, Multiple
R-squared slightly increases.
- I tried to compare different models using anova, but non of them seems to
be better.

How to determine which model is better?

Thanks
-------------- next part --------------
> lm.all.1 <- lm(mark~IA+IC, data=social_presence_data)
> summary(lm.all.1)

Call:
lm(formula = mark ~ IA + IC, data = social_presence_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.5969 -0.2573  0.2599  0.5819  1.2955 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.78938    0.24599  11.339   <2e-16 ***
IA           0.02844    0.04503   0.632    0.530    
IC           0.01979    0.02601   0.761    0.449    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.031 on 79 degrees of freedom
Multiple R-squared:   0.12,	Adjusted R-squared:  0.09774 
F-statistic: 5.387 on 2 and 79 DF,  p-value: 0.006407

> 1/vif(lm.all.1)
       IA        IC 
0.1719037 0.1719037 
> dwt(lm.all.1)
 lag Autocorrelation D-W Statistic p-value
   1      0.09176706      1.815883   0.372
 Alternative hypothesis: rho != 0
> lm.all.2 <- lm(mark~IA, data=social_presence_data)
> lm.all.3 <- lm(mark~IC, data=social_presence_data)
> anova(lm.all.2, lm.all.3)
Analysis of Variance Table

Model 1: mark ~ IA
Model 2: mark ~ IC
  Res.Df    RSS Df Sum of Sq F Pr(>F)
1     80 84.604                      
2     80 84.413  0   0.19141         
> anova(lm.all.1, lm.all.3)
Analysis of Variance Table

Model 1: mark ~ IA + IC
Model 2: mark ~ IC
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     79 83.989                           
2     80 84.413 -1  -0.42402 0.3988 0.5295
> anova(lm.all.1, lm.all.2)
Analysis of Variance Table

Model 1: mark ~ IA + IC
Model 2: mark ~ IA
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     79 83.989                           
2     80 84.604 -1  -0.61543 0.5789  0.449
> summary(lm.all.2)

Call:
lm(formula = mark ~ IA, data = social_presence_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.5409 -0.2539  0.2283  0.5793  1.2956 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.88517    0.21078  13.688  < 2e-16 ***
IA           0.05961    0.01862   3.202  0.00196 ** 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.028 on 80 degrees of freedom
Multiple R-squared:  0.1136,	Adjusted R-squared:  0.1025 
F-statistic: 10.25 on 1 and 80 DF,  p-value: 0.001962

> summary(lm.all.3)

Call:
lm(formula = mark ~ IC, data = social_presence_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.6320 -0.2562  0.2590  0.5764  1.2585 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.76364    0.24168  11.435  < 2e-16 ***
IC           0.03473    0.01074   3.233  0.00178 ** 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.027 on 80 degrees of freedom
Multiple R-squared:  0.1156,	Adjusted R-squared:  0.1045 
F-statistic: 10.45 on 1 and 80 DF,  p-value: 0.001779

> lm.all.3.1 <- lm(mark~IC+AU, data=social_presence_data)
> summary(lm.all.3.1)

Call:
lm(formula = mark ~ IC + AU, data = social_presence_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.5951 -0.2618  0.2378  0.5907  1.2619 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  2.77600    0.24499  11.331  < 2e-16 ***
IC           0.03276    0.01191   2.752  0.00735 ** 
AU           0.04994    0.12697   0.393  0.69514    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.033 on 79 degrees of freedom
Multiple R-squared:  0.1173,	Adjusted R-squared:  0.09496 
F-statistic: 5.249 on 2 and 79 DF,  p-value: 0.007236

From macqueen1 at llnl.gov  Fri Nov 22 00:58:02 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 21 Nov 2013 23:58:02 +0000
Subject: [R] How do  I identify non-sequential data?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D596949@PRDEXMBX-08.the-lab.llnl.gov>

Dan,
Does this do it?

## where dt is the data

tmp <- split(dt, dt$ID)

foo <- lapply(tmp, function(x) any(diff(x$YoS) > 1))

foo <- data.frame( ID=names(foo), gap=unlist(foo))

Note that I ignored dept.
Little hard to see how YoS can increase by more than one when the year
increases by only one ... unless this is a search for erroneous data.

-Don



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/21/13 3:32 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:

>Hi R Experts,
>
>About the data:
>My data consists of people (ID) with years of service (Yos) for each
>year. An ID can appear multiple times.
>The data is sorted by ID then by Year.
>
>Problem:
>I need to extract ID data with non-sequential YoS rows. For example below
>that would be all rows for ID 33 and 16 since they have a non-sequential
>YoS.
>To accomplish this I figured I could create a column called 'CheckVal'
>that takes current row YoS minus previous row YoS. The first instance for
>each ID will be 0. 'CheckVal' in the below data set was created in Excel.
>I want to know how to do this in R.
>Is there a package I can use or specific function or set of functions I
>can use to accomplish this?
>
>#My data looks like:
>> testSeq
>
>   ID Year YoS CheckVal dept
>
>1  12 2010 1.1      0.0    A
>
>2  12 2011 2.1      1.0    A
>
>3  44 2009 1.4      0.0    C
>
>4  44 2010 2.4      1.0    C
>
>5  44 2011 3.4      1.0    B
>
>6  33 2009 2.3      0.0    A
>
>7  33 2010 4.4      2.1    A
>
>8  16 2009 1.6      0.0    B
>
>9  16 2010 2.6      1.0    B
>
>10 16 2011 5.6      3.0    C
>
>11 16 2012 6.6      1.0    A
>
>#here is dput of data for R
>
>Structure(list(ID = c(12, 12, 44, 44, 44, 33, 33, 16, 16, 16,
>
>16), Year = c(2010, 2011, 2009, 2010, 2011, 2009, 2010, 2009,
>
>2010, 2011, 2012), YoS = c(1.1, 2.1, 1.4, 2.4, 3.4, 2.3, 4.4,
>
>1.6, 2.6, 5.6, 6.6), CheckVal = c(0, 1, 0, 1, 1, 0, 2.1, 0, 1,
>
>3, 1), dept = structure(c(1L, 1L, 3L, 3L, 2L, 1L, 1L, 2L, 2L,
>
>3L, 1L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("ID",
>
>"Year", "YoS", "CheckVal", "dept"), row.names = c(NA, 11L), class =
>"data.frame")
>
>Dan
>Workforce Analyst
>LLNL
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Nov 22 00:58:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 21 Nov 2013 15:58:06 -0800 (PST)
Subject: [R] How do  I identify non-sequential data?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <1385078286.49701.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You may try:
?with(testSeq,ave(YoS,ID,FUN=function(x) c(0,diff(x))))
# [1] 0.0 1.0 0.0 1.0 1.0 0.0 2.1 0.0 1.0 3.0 1.0

?testSeq[!!(with(testSeq,ave(YoS,ID,FUN=function(x) any(c(0,diff(x))>1)))),]

A.K.




On Thursday, November 21, 2013 6:55 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

About the data:
My data consists of people (ID) with years of service (Yos) for each year. An ID can appear multiple times.
The data is sorted by ID then by Year.

Problem:
I need to extract ID data with non-sequential YoS rows. For example below that would be all rows for ID 33 and 16 since they have a non-sequential YoS.
To accomplish this I figured I could create a column called 'CheckVal' that takes current row YoS minus previous row YoS. The first instance for each ID will be 0. 'CheckVal' in the below data set was created in Excel. I want to know how to do this in R.
Is there a package I can use or specific function or set of functions I can use to accomplish this?

#My data looks like:
> testSeq

?  ID Year YoS CheckVal dept

1? 12 2010 1.1? ? ? 0.0? ? A

2? 12 2011 2.1? ? ? 1.0? ? A

3? 44 2009 1.4? ? ? 0.0? ? C

4? 44 2010 2.4? ? ? 1.0? ? C

5? 44 2011 3.4? ? ? 1.0? ? B

6? 33 2009 2.3? ? ? 0.0? ? A

7? 33 2010 4.4? ? ? 2.1? ? A

8? 16 2009 1.6? ? ? 0.0? ? B

9? 16 2010 2.6? ? ? 1.0? ? B

10 16 2011 5.6? ? ? 3.0? ? C

11 16 2012 6.6? ? ? 1.0? ? A

#here is dput of data for R

Structure(list(ID = c(12, 12, 44, 44, 44, 33, 33, 16, 16, 16,

16), Year = c(2010, 2011, 2009, 2010, 2011, 2009, 2010, 2009,

2010, 2011, 2012), YoS = c(1.1, 2.1, 1.4, 2.4, 3.4, 2.3, 4.4,

1.6, 2.6, 5.6, 6.6), CheckVal = c(0, 1, 0, 1, 1, 0, 2.1, 0, 1,

3, 1), dept = structure(c(1L, 1L, 3L, 3L, 2L, 1L, 1L, 2L, 2L,

3L, 1L), .Label = c("A", "B", "C"), class = "factor")), .Names = c("ID",

"Year", "YoS", "CheckVal", "dept"), row.names = c(NA, 11L), class = "data.frame")

Dan
Workforce Analyst
LLNL

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From lopez235 at llnl.gov  Fri Nov 22 01:38:29 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Fri, 22 Nov 2013 00:38:29 +0000
Subject: [R] How do  I identify non-sequential data?
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521910D596949@PRDEXMBX-08.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov>
	<5E1B812FAC2C4A49B3D99593B5A521910D596949@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB3FAF@PRDEXMBX-05.the-lab.llnl.gov>

Hi Don,

Yes, I am error checking a dataset produced by a query.  Most likely a problem with the query but wanted to assess the problem first.

BTW Arun provided another solution which is similar to yours but uses the function ave instead:
 testSeq[!!(with(testSeq,ave(YoS,ID,FUN=function(x) any(c(0,diff(x))>1)))),]

I appreciate your response on this.
Dan


-----Original Message-----
From: MacQueen, Don 
Sent: Thursday, November 21, 2013 3:58 PM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: Re: [R] How do I identify non-sequential data?

Dan,
Does this do it?

## where dt is the data

tmp <- split(dt, dt$ID)

foo <- lapply(tmp, function(x) any(diff(x$YoS) > 1))

foo <- data.frame( ID=names(foo), gap=unlist(foo))

Note that I ignored dept.
Little hard to see how YoS can increase by more than one when the year increases by only one ... unless this is a search for erroneous data.

-Don



--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/21/13 3:32 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:

>Hi R Experts,
>
>About the data:
>My data consists of people (ID) with years of service (Yos) for each 
>year. An ID can appear multiple times.
>The data is sorted by ID then by Year.
>
>Problem:
>I need to extract ID data with non-sequential YoS rows. For example 
>below that would be all rows for ID 33 and 16 since they have a 
>non-sequential YoS.
>To accomplish this I figured I could create a column called 'CheckVal'
>that takes current row YoS minus previous row YoS. The first instance 
>for each ID will be 0. 'CheckVal' in the below data set was created in Excel.
>I want to know how to do this in R.
>Is there a package I can use or specific function or set of functions I 
>can use to accomplish this?
>
>#My data looks like:
>> testSeq
>
>   ID Year YoS CheckVal dept
>
>1  12 2010 1.1      0.0    A
>
>2  12 2011 2.1      1.0    A
>
>3  44 2009 1.4      0.0    C
>
>4  44 2010 2.4      1.0    C
>
>5  44 2011 3.4      1.0    B
>
>6  33 2009 2.3      0.0    A
>
>7  33 2010 4.4      2.1    A
>
>8  16 2009 1.6      0.0    B
>
>9  16 2010 2.6      1.0    B
>
>10 16 2011 5.6      3.0    C
>
>11 16 2012 6.6      1.0    A
>
>#here is dput of data for R
>
>Structure(list(ID = c(12, 12, 44, 44, 44, 33, 33, 16, 16, 16,
>
>16), Year = c(2010, 2011, 2009, 2010, 2011, 2009, 2010, 2009,
>
>2010, 2011, 2012), YoS = c(1.1, 2.1, 1.4, 2.4, 3.4, 2.3, 4.4,
>
>1.6, 2.6, 5.6, 6.6), CheckVal = c(0, 1, 0, 1, 1, 0, 2.1, 0, 1,
>
>3, 1), dept = structure(c(1L, 1L, 3L, 3L, 2L, 1L, 1L, 2L, 2L,
>
>3L, 1L), .Label = c("A", "B", "C"), class = "factor")), .Names = 
>c("ID",
>
>"Year", "YoS", "CheckVal", "dept"), row.names = c(NA, 11L), class =
>"data.frame")
>
>Dan
>Workforce Analyst
>LLNL
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Nov 22 01:42:52 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 22 Nov 2013 13:42:52 +1300
Subject: [R] Regression model
In-Reply-To: <CAM8BP_nsUxdZeHRG9KXAOaBrbqrWe+riyq_PkwHyM1PLAmU5FQ@mail.gmail.com>
References: <CAM8BP_nsUxdZeHRG9KXAOaBrbqrWe+riyq_PkwHyM1PLAmU5FQ@mail.gmail.com>
Message-ID: <528EA88C.20604@auckland.ac.nz>


(1) Is this homework?  (This list doesn't do homework for people!)
(Animals maybe, but not people! :-) )

(2) Your question isn't really an R question but rather a 
statistics/linear modelling
question.  It is possible that you might get some insight from Frank 
Harrel's book
"Regression Modelling Strategies" (Springer, 2001).

     cheers,

     Rolf Turner

On 11/22/13 12:52, srecko joksimovic wrote:
> Hi,
>
> I'm trying to fit regression model, but there is something wrong with it.
> The dataset contains 85 observations for 85 students.Those observations are
> counts of several actions, and dependent variable is final score. More
> precisely, I have 5 IV and one DV. I'm trying to build regression model to
> check whether those variables can predict the final score.
>
> I'm attaching output of several steps, but I tried to following procedure:
> - build model with only those two variables
> - summary shows that non of them is significant predictor of the final
> outcome.
> - test for multicollinearity revealed tolerance below 0.2 (potential
> problem)
> - build two new models having as a predictor only one of those values
> - both models show that variable used for the model is significant
> predictor. Separately they are significant, together not. Probably
> multicollinearity problem, but...
> - as I keep adding other variables to one or the other model, Multiple
> R-squared slightly increases.
> - I tried to compare different models using anova, but non of them seems to
> be better.
>
> How to determine which model is better?


From sreckojoksimovic at gmail.com  Fri Nov 22 01:46:41 2013
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Thu, 21 Nov 2013 16:46:41 -0800
Subject: [R] Regression model
In-Reply-To: <528EA88C.20604@auckland.ac.nz>
References: <CAM8BP_nsUxdZeHRG9KXAOaBrbqrWe+riyq_PkwHyM1PLAmU5FQ@mail.gmail.com>
	<528EA88C.20604@auckland.ac.nz>
Message-ID: <CAM8BP_ndh7NXxQBfhwKhnD5ih8Awc6=ARG0gNV=ntigvz4sk8Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/68bfea06/attachment.pl>

From jun.shen.ut at gmail.com  Fri Nov 22 03:57:52 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 21 Nov 2013 21:57:52 -0500
Subject: [R] multiple pages with ggplot2 possible?
Message-ID: <CAMCXXmrNn89T=6UsBPqqxiS9OswByzVwLXVW1Cbphux23nEO=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/9547fa57/attachment.pl>

From ivo.welch at anderson.ucla.edu  Fri Nov 22 05:35:20 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Thu, 21 Nov 2013 20:35:20 -0800
Subject: [R] xyz-contour plot (irregular grid)
Message-ID: <CAPr7RtXG-+mfUef7KFcduwXM=-vn=-S3jtROc7cW88a1nz1e9w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131121/46579cb3/attachment.pl>

From rmh at temple.edu  Fri Nov 22 06:07:15 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 22 Nov 2013 00:07:15 -0500
Subject: [R] use of bquote
Message-ID: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>

When I use run this expression

a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))

the subtitle contains three copies of the "a = 2  b = 3" phrase.
Why does it do that?  How do I tell it to give me only one copy?

Rich


From wdunlap at tibco.com  Fri Nov 22 06:47:59 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 22 Nov 2013 05:47:59 +0000
Subject: [R] use of bquote
In-Reply-To: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
References: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>

> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
> 
> the subtitle contains three copies of the "a = 2  b = 3" phrase.
> Why does it do that?  How do I tell it to give me only one copy?

To avoid it don't wrap bquote() with c().  The following does what you asked for:
    a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = bquote(a == .(a) ~ b==.(b)))

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Richard M. Heiberger
> Sent: Thursday, November 21, 2013 9:07 PM
> To: r-help
> Subject: [R] use of bquote
> 
> When I use run this expression
> 
> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
> 
> the subtitle contains three copies of the "a = 2  b = 3" phrase.
> Why does it do that?  How do I tell it to give me only one copy?
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Nov 22 07:53:10 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 22 Nov 2013 19:53:10 +1300
Subject: [R] use of bquote
In-Reply-To: <E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>
References: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>
Message-ID: <528EFF56.5060108@auckland.ac.nz>

On 11/22/13 18:47, William Dunlap wrote:
>> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
>>
>> the subtitle contains three copies of the "a = 2  b = 3" phrase.
>> Why does it do that?  How do I tell it to give me only one copy?
> To avoid it don't wrap bquote() with c().  The following does what you asked for:
>      a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = bquote(a == .(a) ~ b==.(b)))

Not for me it doesn't.  Without the c() wrapper, I get no subtitle at 
all.  Your recipe seems to
work with base graphics and plot() but not with lattice and xyplot().  
Also the c() wrapper
seems to have no impact when used with plot().

Moreover I am mystified by the impact of the c() wrapper when used with 
xyplot().

The result returned by bquote() has class "call".  The result returned 
by c(bquote(...)) is a
list, of length 1, whose sole entry is of class "call" and is, as one 
might expect, equal to the
result returned by bquote().

But why should passing this length-1 list as the value for "sub" cause a 
triplication of the
subtitle?

     cheers,

     Rolf


From jdnewmil at dcn.davis.CA.us  Fri Nov 22 08:43:16 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 21 Nov 2013 23:43:16 -0800
Subject: [R] multiple pages with ggplot2 possible?
In-Reply-To: <CAMCXXmrNn89T=6UsBPqqxiS9OswByzVwLXVW1Cbphux23nEO=g@mail.gmail.com>
References: <CAMCXXmrNn89T=6UsBPqqxiS9OswByzVwLXVW1Cbphux23nEO=g@mail.gmail.com>
Message-ID: <edd9e039-ef19-4f38-a93d-854598ec02e9@email.android.com>

I don't think anything has changed in the fundamental design of ggplot2, so the answer is still no.
But you can use some kind of loop (for, or *apply) to generate them sequentially. What do you plan to do with them? Save as jpeg? Append into a pdf? Embed in an Sweave or knitr file?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Jun Shen <jun.shen.ut at gmail.com> wrote:
>Dear all,
>
>This question was asked a few years ago. Back then, the answer was NO.
>Just
>wonder if the package has been updated to make it possible.
>
>An example (Theoph is a dataset coming with R)
>
>ggplot(data=Theoph, aes(x=Time, y=conc)) + geom_point() +
>facet_wrap(~Subject)
>
>gives me all 12 subjects on one page. Can I break it down to several
>pages?
>say 2x2 on each page?
>
>Thanks.
>
>Jun
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Nov 22 09:14:24 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 22 Nov 2013 09:14:24 +0100
Subject: [R] use of bquote
In-Reply-To: <528EFF56.5060108@auckland.ac.nz>
References: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>
	<528EFF56.5060108@auckland.ac.nz>
Message-ID: <EF7ADE08-FCC2-475F-A186-4464F3D7971C@gmail.com>


On 22 Nov 2013, at 07:53 , Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 11/22/13 18:47, William Dunlap wrote:
>>> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
>>> 
>>> the subtitle contains three copies of the "a = 2  b = 3" phrase.
>>> Why does it do that?  How do I tell it to give me only one copy?
>> To avoid it don't wrap bquote() with c().  The following does what you asked for:
>>     a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = bquote(a == .(a) ~ b==.(b)))
> 
> Not for me it doesn't.  Without the c() wrapper, I get no subtitle at all.  Your recipe seems to
> work with base graphics and plot() but not with lattice and xyplot().  Also the c() wrapper
> seems to have no impact when used with plot().
> 
> Moreover I am mystified by the impact of the c() wrapper when used with xyplot().
> 
> The result returned by bquote() has class "call".  The result returned by c(bquote(...)) is a
> list, of length 1, whose sole entry is of class "call" and is, as one might expect, equal to the
> result returned by bquote().
> 
> But why should passing this length-1 list as the value for "sub" cause a triplication of the
> subtitle?

I dunno either, but a hint at the reason would be to look at what happens with

xyplot(0 ~ 1, sub=list(quote(1+1)))

When you do computing on the language, sometimes quote()?ing is not sufficient protection against evaluation. That?s what expression objects are for. 

A solution seems to be

xyplot(0 ~ 1, sub=as.expression(
	bquote(pi==.(pi) ~ e==.(exp(1)))
))




-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Fri Nov 22 14:57:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 22 Nov 2013 05:57:37 -0800 (PST)
Subject: [R] Fwd:  Datatable manipulation
In-Reply-To: <CAOdnBQeaoEJ1+oChvSz_OSPcNeeNdi1SavuZ=RXVHExb9tiXXA@mail.gmail.com>
References: <21642760.204077.1384901008484.JavaMail.nabble@joe.nabble.com>	<CAOdnBQfu9cDF45XBVR6NzC3nkxd4vFrCAO+15OqtLT5TEVE3Gw@mail.gmail.com>	<1384920898.83429.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAOdnBQe17qqWG0KAsG+KFeXpJTe7WQTtjFdKqCJQGGCk2OdZVQ@mail.gmail.com>	<CADv2QyEekzWiFg_PAOtM+YsKDiVRkZVCMcD=9BGCOU1fzzWyAA@mail.gmail.com>	<CAOdnBQeUj990vBUk3y0qDgb+UKJkQbDxQQc+_0-rrrKwTt7mmA@mail.gmail.com>	<CADv2QyFp0nu6NsxorwcPVwCS0F=5bJu0Sun=DhzNo8yaf-U+Ow@mail.gmail.com>	<CAOdnBQeM+X_sUPwPGZZF2Cx0qoEsYhQS9xoXGVuRMtsA9qdNOA@mail.gmail.com>	<CAOdnBQe-oSCqC5gd4OzbSo6Ti=xp+vV6PEDPSpPE6idQV3dN5w@mail.gmail.com>	<1385060911.77793.YahooMailNeo@web142603.mail.bf1.yahoo.com>	<CAOdnBQcjkyZ6b9hM1cvE+omBRSgJaC-f3Of3xPneB0N1HWTW3w@mail.gmail.com>	<1385093979.31906.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAOdnBQffCL257uYm-z+U3Hs4uAnpt7_QMngZPZA+9u-_5fdwOg@mail.gmail.com>	<1385103858.90641.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAOdnBQcrKOdf-sLfo=Bz-w5bA+4TRr9i4aMkpctYorH6OBksjw@mail.gmail.com>
	<CAOdnBQeaoEJ1+oChvSz_OSPcNeeNdi1SavuZ=RXVHExb9tiXXA@mail.gmail.com>
Message-ID: <1385128657.10818.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,
Assuming that this is the case:
dat1 <- read.table(text="a???? b???? c???? d?????? e
1???? 2???? 3???? 4???? 5
10???? 9???? 8???? 7???? 6",sep="",header=TRUE)

Names1<- read.table(text="Original????? New?? 
e???? ee
g??? gg
a???? aa
c???? cc
f???? ff",sep="",header=TRUE,stringsAsFactors=FALSE)
?
?indx <- match(names(dat1),Names1[,1])
?names(dat1)[names(dat1) %in% Names1[,1]] <- Names1[,2][indx[!is.na(indx)]]
?dat1
#? aa b cc d ee
#1? 1 2? 3 4? 5
#2 10 9? 8 7? 6


A.K.

On Friday, November 22, 2013 4:46 AM, Nitisha jha <nitisha999 at gmail.com> wrote:

Hey! I got this one. :)
For the match function, actually I just want the ones that are matching to be replaced. Rest should stay the same. How do I do that? When I tried your command, if there is no match, it writes var2 or something.?



>>>On Fri, Nov 22, 2013 at 12:38 AM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>
>>>>
>>>>Hi,
>>>>Try:
>>>>
>>>>dat1 <- read.table(text="a ??? b ??? c ??? d?????? e
>>>>
>>>>1 ??? 2 ??? 3 ??? 4 ??? 5
>>>>10 ??? 9 ??? 8 ??? 7 ??? 6",sep="",header=TRUE)
>>>>
>>>>Names1<- read.table(text="Original? ??? New???
>>>>
>>>>e ??? ee
>>>>b ??? bb???
>>>>a ??? aa
>>>>c ??? cc
>>>>d ??? dd",sep="",header=TRUE,stringsAsFactors=FALSE)
>>>>
>>>>It is better to dput() your dataset.? For example:
>>>>?dput(Names1)
>>>>structure(list(Original = c("e", "b", "a", "c", "d"), New = c("ee",
>>>>"bb", "aa", "cc", "dd")), .Names = c("Original", "New"), class = "data.frame", row.names = c(NA,
>>>>-5L))
>>>>
>>>>
>>>>?names(dat1) <- Names1[,2][match(names(dat1), Names1[,1])] ##
>>>>?dat1
>>>>#? aa bb cc dd ee
>>>>#1? 1? 2? 3? 4? 5
>>>>#2 10? 9? 8? 7? 6
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>On Thursday, November 21, 2013 1:45 PM, Nitisha jha <nitisha999 at gmail.com> wrote:
>>>>
>>>>Hi,
>>>>
>>>>Thanks. I used as.character() and got the right strings.
>>>>
>>>>Btw, I have lots of handicaps regarding R.
>>>>
>>>>I have to rename the columns(I have 22 columns here). I have the new names along with the original names in another dataset. Right now, I am going hardcoding all the? 19 name changes(tedious and not optimum). 1st 3 names remain the same. I will give u a sample dataset. Let me know if there is any easy way of doing this.? Pardon the displaced column labels.
>>>>
>>>>
>>>>
>>>>Original dataset.
>>>>
>>>>
>>>>
>>>>?? a b c d??????????? ?
>>>>e
>>>>1 2 3 4 5
>>>>10 9 8 7 6
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>Dataset for name change
>>>>
>>>>
>>>>Original? New
>>>>
>>>>
>>>>
>>>>e ee
>>>>
>>>>
>>>>
>>>>b bb
>>>>
>>>>
>>>>
>>>>a aa
>>>>
>>>>
>>>>
>>>>c cc
>>>>
>>>>
>>>>
>>>>d dd
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>I want my final dataset to be like this:
>>>>
>>>>aa bb cc dd ee
>>>>1 2 3 4 5
>>>>10 9 8 7 6
>>>>
>>>>
>>>>
>>>>?Could u tell me an optimal way to do it. My method is tedious and not good.
>>>>
>>>>Also, is there a way to import .xls without perl (windows)?
>>>>
>>>>
>>>>Thanks for being patient. :)
>>>>
>>>
>>
>


From smartpink111 at yahoo.com  Fri Nov 22 15:37:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 22 Nov 2013 06:37:06 -0800 (PST)
Subject: [R] Recode values
Message-ID: <1385131026.51330.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

May be this helps:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(c(NA,0:2),20,replace=TRUE),ncol=2))
dat2 <- dat1
?lst1 <- list(letters[1:3],letters[26:24])
library(plyr)

?dat1[] <-lapply(seq_len(ncol(dat1)),function(i) {x1 <-dat1[,i]; x2 <- lst1[[i]]; mapvalues(x1,c(0,1,2),x2)})

#Or
dat2[] <-lapply(seq_len(ncol(dat2)),function(i) as.character(factor(dat2[,i],labels=lst1[[i]])))

?identical(dat1,dat2)
#[1] TRUE
A.K.


Hi I'm Pasquale, 
I need to recode variables (columns) of a dataframe (call it X). The
 observations (rows) are coded as numeric 0,1,2 and NA. I managed to use
 the lapply() function with recode() as FUN and for() loop but I failed. 
My problem is that for each columns the recoding system is different (i.e. for V1 the code will be 0=a, 1=b, 2=c, for V2 0=z, 1=y, 2=x). 
My new codes are stored in another data frame (call it Y). colnames(X) and rownames(Y) matches. 
How can I solve this situation? 

Thanks a lot in advance, 
Pasquale


From lorenzo.isella at gmail.com  Fri Nov 22 16:06:17 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 22 Nov 2013 16:06:17 +0100
Subject: [R] R and Interactive Visualizations
Message-ID: <op.w6yhkrgyzqkd1e@enea>

Dear All,
I use several R libraries (ggplot2, igraph etc...) for producing static  
visualizations.
However, I'd like to be able to go beyond this.
Things I may like to be able to achieve (relying on R as much as possible):

1) network visualizations such that when you click on a node, you see its  
properties and the network layout centers on that node
2) geographical plots (e.g. European countries colored according to their  
GDP and the possibility to see some other metadata when I click on one of  
them)
3) being able to select/deselect some dataset in a conventional plot (e.g.  
multiple stacked histograms)

and so on and so forth...

I did some online research and came across potentially many resources like


http://bit.ly/18dkX1P
http://bit.ly/18dkXPF
http://bit.ly/1jsksk4
http://bit.ly/1jskyrO

but I honestly have no idea about where to start from.
Making the interactive visualizations available on a website is a logical  
second step, but first things first.
I am sure that plenty of people on this list have a strong expertise about  
the interactive visualizations, so any suggestion is welcome.
Cheers

Lorenzo


From lorenzo.isella at gmail.com  Fri Nov 22 16:08:27 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Fri, 22 Nov 2013 16:08:27 +0100
Subject: [R] R and Interactive Visualizations
Message-ID: <op.w6yhodyfzqkd1e@enea>

Dear All,
I use several R libraries (ggplot2, igraph etc...) for producing static
visualizations.
However, I'd like to be able to go beyond this.
Things I may like to be able to achieve (relying on R as much as possible):

1) network visualizations such that when you click on a node, you see its
properties and the network layout centers on that node
2) geographical plots (e.g. European countries colored according to their
GDP and the possibility to see some other metadata when I click on one of
them)
3) being able to select/deselect some dataset in a conventional plot (e.g.
multiple stacked histograms)

and so on and so forth...

I did some online research and came across potentially many resources like


http://bit.ly/18dkX1P
http://bit.ly/18dkXPF
http://bit.ly/1jsksk4
http://bit.ly/1jskyrO

but I honestly have no idea about where to start from.
Making the interactive visualizations available on a website is a logical
second step, but first things first.
I am sure that plenty of people on this list have a strong expertise about
the interactive visualizations, so any suggestion is welcome.
Cheers

Lorenzo


From hanson at depauw.edu  Fri Nov 22 16:24:27 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Fri, 22 Nov 2013 10:24:27 -0500
Subject: [R] R and Interactive Visualizations
In-Reply-To: <op.w6yhodyfzqkd1e@enea>
References: <op.w6yhodyfzqkd1e@enea>
Message-ID: <9766701F-9DE5-49DE-BA84-120855302227@depauw.edu>

I think you will need to do this in a web page running java.  So you need a way to link your R stuff to java, possibly back and forth depending upon exactly what you end up doing.  You've found some pages already.  But look also at shiny and d3.

http://www.rstudio.com/shiny/
http://d3js.org/

And there are other flavors.  It mostly depends upon whether you want to write the java or let a package do it for you.

Others may have better ideas.  Bryan

On Nov 22, 2013, at 10:08 AM, "Lorenzo Isella" <lorenzo.isella at gmail.com> wrote:

> Dear All,
> I use several R libraries (ggplot2, igraph etc...) for producing static
> visualizations.
> However, I'd like to be able to go beyond this.
> Things I may like to be able to achieve (relying on R as much as possible):
> 
> 1) network visualizations such that when you click on a node, you see its
> properties and the network layout centers on that node
> 2) geographical plots (e.g. European countries colored according to their
> GDP and the possibility to see some other metadata when I click on one of
> them)
> 3) being able to select/deselect some dataset in a conventional plot (e.g.
> multiple stacked histograms)
> 
> and so on and so forth...
> 
> I did some online research and came across potentially many resources like
> 
> 
> http://bit.ly/18dkX1P
> http://bit.ly/18dkXPF
> http://bit.ly/1jsksk4
> http://bit.ly/1jskyrO
> 
> but I honestly have no idea about where to start from.
> Making the interactive visualizations available on a website is a logical
> second step, but first things first.
> I am sure that plenty of people on this list have a strong expertise about
> the interactive visualizations, so any suggestion is welcome.
> Cheers
> 
> Lorenzo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Nov 22 16:30:50 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 22 Nov 2013 09:30:50 -0600
Subject: [R] xyz-contour plot (irregular grid)
In-Reply-To: <CAPr7RtXG-+mfUef7KFcduwXM=-vn=-S3jtROc7cW88a1nz1e9w@mail.gmail.com>
References: <CAPr7RtXG-+mfUef7KFcduwXM=-vn=-S3jtROc7cW88a1nz1e9w@mail.gmail.com>
Message-ID: <027001cee797$d3185bf0$794913d0$@tamu.edu>

I'm not sure if there is a single function, but a quick script
would look something like this and would be easily adjusted

attach(mtcars)
mtcars.ls <- loess(mpg~wt*hp)
wtg <- seq(min(wt), max(wt), length.out=50)
hpg <- seq(min(hp), max(hp), length.out=50)
grid <- expand.grid(wt=wtg, hp=hpg)
mpg.fit <- predict(mtcars.ls, grid)
contour(wtg, hpg, mpg.fit, xlab="Weight (1,000 lbs)", 
  ylab="Horsepower")
points(wt, hp, pch=20)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of ivo welch
Sent: Thursday, November 21, 2013 10:35 PM
To: r-help
Subject: [R] xyz-contour plot (irregular grid)

Dear R users:  before I try to undertake my own rewrite, has
anyone already
written a contour function that does not require a regularly
spaced grid,
preferably plot.contour(x,y,z,...)?

(it would be nice if it were based on loess() and plot()?
further
annotations, changes, etc., would then be easier.)

sincerely, /iaw

----
Ivo Welch (ivo.welch at gmail.com)

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From abhishek.vit at gmail.com  Fri Nov 22 16:59:28 2013
From: abhishek.vit at gmail.com (Abhishek Pratap)
Date: Fri, 22 Nov 2013 07:59:28 -0800
Subject: [R] how to make R render plots faster
Message-ID: <CAJbA1KC9h4kUyf9QV5eSnrdT4ZK7tnVh-LaLRYSPp2VA-pQSng@mail.gmail.com>

Hi All

We are using R to spit out plots(heatmaps) which are being rendered on
a shiny app (web page). Currently we are facing an issue with the time
it takes R to render a plot taking out the time it takes to do the
computation. Let me show the same through a contrived example. In this
basic test case R takes ~17 seconds to render and save a heatmap file
as png (data computer time is taken out : row and cols clusters are
precomputed)

I am wondering is there a way to reduce the time it takes to render
this plot type by a significant factor. Maybe I am missing on some
other constant computation which can be also taken out of the heatmap
function.

PS: cross posted on stackoverflow
http://stackoverflow.com/questions/20149107/how-to-make-r-render-plots-faster

Thanks!
-Abhi


**generate data**

    m1 <- matrix(rnorm(500000,mean=15,sd=4),ncol=100)
    m2 <- matrix(rnorm(500000,mean=30,sd=3),ncol=100)
    m <- cbind(m1,m2)
    dim(m)


**basic heat map with all computation**

    png('test_heatmap.png')
    system.time(heatmap(m))

    user  system elapsed
    29.327   0.637  30.526



**do the clustering out of heatmap function : mainly to test the plot
rendering time**

    > system.time(hcr <- hclust(dist(m)))
       user  system elapsed
      9.992   0.126  10.144
    > system.time(hcc <- hclust(dist(t(m))))
       user  system elapsed
      0.659   0.002   0.662
    > system.time(ddr <- as.dendrogram(hcr))
       user  system elapsed
      0.498   0.010   0.508
    > system.time(ddc <- as.dendrogram(hcc))
       user  system elapsed
      0.011   0.000   0.011

**heatmap rendering time with pre-computed row/col dendogram**

    png('test_heatmap.png')
    > system.time(heatmap(m,Rowv=ddr,Colv=ddc))
       user  system elapsed
     16.128   0.558  17.171


From David.Reiner at xrtrading.com  Fri Nov 22 17:16:41 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Fri, 22 Nov 2013 10:16:41 -0600
Subject: [R] [SPAM] - Re: How do I identify non-sequential data? - Found
 word(s) list error in the Text body
In-Reply-To: <5cd07d07-96fb-4cd6-b3c3-5db9043db81b@r-project.org>
References: <56180B40A4F72A4083C75B30DA86297333DB3EC7@PRDEXMBX-05.the-lab.llnl.gov><5E1B812FAC2C4A49B3D99593B5A521910D596949@PRDEXMBX-08.the-lab.llnl.gov>
	<5cd07d07-96fb-4cd6-b3c3-5db9043db81b@r-project.org>
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A58F49C18@HQ-POST1>

Similar to Don MacQueen's:

unsplit(lapply(split(DF, DF$ID), transform, cv = c(0, diff(YoS))), DF$ID)

-- David Reiner


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Lopez, Dan
Sent: Thursday, November 21, 2013 6:38 PM
To: MacQueen, Don
Cc: R help (r-help at r-project.org)
Subject: [SPAM] - Re: [R] How do I identify non-sequential data? - Found word(s) list error in the Text body

Hi Don,

Yes, I am error checking a dataset produced by a query.  Most likely a problem with the query but wanted to assess the problem first.

BTW Arun provided another solution which is similar to yours but uses the function ave instead:
 testSeq[!!(with(testSeq,ave(YoS,ID,FUN=function(x) any(c(0,diff(x))>1)))),]

I appreciate your response on this.
Dan


-----Original Message-----
From: MacQueen, Don
Sent: Thursday, November 21, 2013 3:58 PM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: Re: [R] How do I identify non-sequential data?

Dan,
Does this do it?

## where dt is the data

tmp <- split(dt, dt$ID)

foo <- lapply(tmp, function(x) any(diff(x$YoS) > 1))

foo <- data.frame( ID=names(foo), gap=unlist(foo))

Note that I ignored dept.
Little hard to see how YoS can increase by more than one when the year increases by only one ... unless this is a search for erroneous data.

-Don



--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/21/13 3:32 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:

>Hi R Experts,
>
>About the data:
>My data consists of people (ID) with years of service (Yos) for each
>year. An ID can appear multiple times.
>The data is sorted by ID then by Year.
>
>Problem:
>I need to extract ID data with non-sequential YoS rows. For example
>below that would be all rows for ID 33 and 16 since they have a
>non-sequential YoS.
>To accomplish this I figured I could create a column called 'CheckVal'
>that takes current row YoS minus previous row YoS. The first instance
>for each ID will be 0. 'CheckVal' in the below data set was created in Excel.
>I want to know how to do this in R.
>Is there a package I can use or specific function or set of functions I
>can use to accomplish this?
>
>#My data looks like:
>> testSeq
>
>   ID Year YoS CheckVal dept
>
>1  12 2010 1.1      0.0    A
>
>2  12 2011 2.1      1.0    A
>
>3  44 2009 1.4      0.0    C
>
>4  44 2010 2.4      1.0    C
>
>5  44 2011 3.4      1.0    B
>
>6  33 2009 2.3      0.0    A
>
>7  33 2010 4.4      2.1    A
>
>8  16 2009 1.6      0.0    B
>
>9  16 2010 2.6      1.0    B
>
>10 16 2011 5.6      3.0    C
>
>11 16 2012 6.6      1.0    A
>
>#here is dput of data for R
>
>Structure(list(ID = c(12, 12, 44, 44, 44, 33, 33, 16, 16, 16,
>
>16), Year = c(2010, 2011, 2009, 2010, 2011, 2009, 2010, 2009,
>
>2010, 2011, 2012), YoS = c(1.1, 2.1, 1.4, 2.4, 3.4, 2.3, 4.4,
>
>1.6, 2.6, 5.6, 6.6), CheckVal = c(0, 1, 0, 1, 1, 0, 2.1, 0, 1,
>
>3, 1), dept = structure(c(1L, 1L, 3L, 3L, 2L, 1L, 1L, 2L, 2L,
>
>3L, 1L), .Label = c("A", "B", "C"), class = "factor")), .Names =
>c("ID",
>
>"Year", "YoS", "CheckVal", "dept"), row.names = c(NA, 11L), class =
>"data.frame")
>
>Dan
>Workforce Analyst
>LLNL
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From kinsham at verizon.net  Fri Nov 22 17:47:36 2013
From: kinsham at verizon.net (Chris Wilkinson)
Date: Fri, 22 Nov 2013 11:47:36 -0500
Subject: [R] Principal Components in a Linear Model
Message-ID: <001a01cee7a2$8ca07fd0$a5e17f70$@net>

My data has correlations between predictors so I think it would be
advantageous to rotate the axes with prcomp().

> census <-
read.table(paste("http://www.stat.wisc.edu/~rich/JWMULT02dat","T8-5.DAT",sep
="/"),header=F)
> census
      V1   V2    V3   V4   V5
1  5.935 14.2 2.265 2.27 2.91
2  1.523 13.1 0.597 0.75 2.62
3  2.599 12.7 1.237 1.11 1.72
4  4.009 15.2 1.649 0.81 3.02
5  4.687 14.7 2.312 2.50 2.22
6  8.044 15.6 3.641 4.51 2.36
7  2.766 13.3 1.244 1.03 1.97
8  6.538 17.0 2.618 2.39 1.85
9  6.451 12.9 3.147 5.52 2.01
10 3.314 12.2 1.606 2.18 1.82
11 3.777 13.0 2.119 2.83 1.80
12 1.530 13.8 0.798 0.84 4.25
13 2.768 13.6 1.336 1.75 2.64
14 6.585 14.9 2.763 1.91 3.17

> pca1 <- prcomp(census)
> summary(pca1)
Importance of components:
                          PC1    PC2     PC3     PC4     PC5
Standard deviation     2.6327 1.3361 0.62422 0.47909 0.11897
Proportion of Variance 0.7413 0.1909 0.04168 0.02455 0.00151
Cumulative Proportion  0.7413 0.9323 0.97394 0.99849 1.00000

> pca1$rotation # eigenvectors
           PC1         PC2          PC3         PC4          PC5
V1 -0.78120807  0.07087183 -0.003656607  0.54171007  0.302039670
V2 -0.30564856  0.76387277  0.161817438 -0.54479937  0.009279632
V3 -0.33444840 -0.08290788 -0.014841008  0.05101636 -0.937255367
V4 -0.42600795 -0.57945799 -0.220453468 -0.63601254  0.172145212
V5  0.05435431  0.26235528 -0.961759720  0.05127599 -0.024583093

I'd like to create a linear model based on the rotated axes.

> linmod <- lm(y~a+b+....)

Could someone be kind enough to suggest how to code a, b...?

Chris


From noor_aziani at yahoo.com  Fri Nov 22 10:28:17 2013
From: noor_aziani at yahoo.com (Noor Aziani Bt Harun)
Date: Fri, 22 Nov 2013 17:28:17 +0800
Subject: [R] Question about error of "non-numeric
	argument	to	binary	operator"
Message-ID: <000001cee765$30857990$91906cb0$@yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/cf7f37d6/attachment.pl>

From Sinnwell.Jason at mayo.edu  Tue Nov 19 19:58:07 2013
From: Sinnwell.Jason at mayo.edu (Sinnwell, Jason P.)
Date: Tue, 19 Nov 2013 18:58:07 +0000
Subject: [R] [R-pkgs] Introducing pedgene 1.2 on CRAN
Message-ID: <46602276E511624D9CC6B8650147C245BAE836@MSGPEXCHA08A.mfad.mfroot.org>

Dear useRs:

We would like to introduce the "pedgene" package, version 1.2, available now on CRAN, with a brief manual available as a vignette:
http://cran.r-project.org/web/packages/pedgene/index.html

The pedgene package performs gene-level kernel and burden association tests with disease status and continuous response 
for pedigree data, as described in our recent paper:

	Schaid, D. J., McDonnell, S. K., Sinnwell, J. P. and Thibodeau, S. N. (2013), Multiple Genetic Variant Association 
	Testing by Collapsing and Kernel Methods With Pedigree or Population Structured Data. Genet. Epidemiol., 
	37: 409-418.  doi: 10.1002/gepi.21727
	LINK:   http://onlinelibrary.wiley.com/doi/10.1002/gepi.21727/abstract

We have received some valuable feedback, and welcome more.

Best,
Jason Sinnwell, MS
Mayo Clinic
Division of Biomedical Statistics and Informatics
200 1st St SW
Rochester MN 55905

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From lillo_dicarlo at live.it  Fri Nov 22 11:13:34 2013
From: lillo_dicarlo at live.it (lillosdos)
Date: Fri, 22 Nov 2013 02:13:34 -0800 (PST)
Subject: [R] Recode values
Message-ID: <1385115214037-4680959.post@n4.nabble.com>

Hi I'm Pasquale,
I need to recode variables (columns) of a dataframe (call it X). The
observations (rows) are coded as numeric 0,1,2 and NA. I managed to use the
lapply() function with recode() as FUN and for() loop but I failed.
*My problem is that for each columns the recoding system is different *(i.e.
for V1 the code will be 0=a, 1=b, 2=c, for V2 0=z, 1=y, 2=x). 
My new codes are stored in another data frame (call it Y). colnames(X) and
rownames(Y) matches.
How can I solve this situation?

Thanks a lot in advance,
Pasquale



--
View this message in context: http://r.789695.n4.nabble.com/Recode-values-tp4680959.html
Sent from the R help mailing list archive at Nabble.com.


From rb459 at georgetown.edu  Fri Nov 22 14:52:02 2013
From: rb459 at georgetown.edu (Rachel Blum)
Date: Fri, 22 Nov 2013 08:52:02 -0500
Subject: [R] problem with CSV and R
Message-ID: <CALDs+F=5HGX=gSL20Qf58-5KmHhBeY2v96DZ1BQ0nuaqx5bUsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/104b64ee/attachment.pl>

From pmassicotte at hotmail.com  Fri Nov 22 17:58:22 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 22 Nov 2013 16:58:22 +0000
Subject: [R] data manipulation
Message-ID: <COL127-W75704F3045A931410D884B3E00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/6a462815/attachment.pl>

From carina.salt at googlemail.com  Fri Nov 22 18:18:54 2013
From: carina.salt at googlemail.com (Carina Salt)
Date: Fri, 22 Nov 2013 17:18:54 +0000
Subject: [R] Use of 'by' function with FUN=mean
Message-ID: <CAB+PZ6DqYWktmi_BVZ0pWgVy5vVd48UTHjHW6NGwF=b6DV323g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/e1443712/attachment.pl>

From 538280 at gmail.com  Fri Nov 22 18:25:50 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 22 Nov 2013 10:25:50 -0700
Subject: [R] R and Interactive Visualizations
In-Reply-To: <op.w6yhkrgyzqkd1e@enea>
References: <op.w6yhkrgyzqkd1e@enea>
Message-ID: <CAFEqCdz8j1F1qPNL9oi_qWPRA=P8HXG9FHAB2KMYFBOCmOZfwA@mail.gmail.com>

For task #1, if you have the coordinates where the nodes were plotted
then you can just pass this information along with the meta data to
the identify function (assuming base graphics).  If you want the
metadata to only appear for the current point (disappear when leave
that point) then look at the HWidentify and HTKidentify functions in
the TeachingDemos package.

For task #2, if you have a point within each country that the person
can click on (point at capitol city, intial letter of country name,
etc.) then you can just use identify again.  If you want to capture a
click anywhere within the polygon(s) then you can use the locator
function to capture the coordinates of the point clicked on, then use
tools within packages like sp (I think the over function is the
current best one) to identify which polygon/country the point is in,
then add the appropriate metadata at the point clicked.

For number 3, there is some functionality like this in the iplots
package, the ggobi tool, and the TkBrush function in the TeachingDemos
package.  If those do not do what you want, then give us some more
detail on what you would like to do.

On Fri, Nov 22, 2013 at 8:06 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> I use several R libraries (ggplot2, igraph etc...) for producing static
> visualizations.
> However, I'd like to be able to go beyond this.
> Things I may like to be able to achieve (relying on R as much as possible):
>
> 1) network visualizations such that when you click on a node, you see its
> properties and the network layout centers on that node
> 2) geographical plots (e.g. European countries colored according to their
> GDP and the possibility to see some other metadata when I click on one of
> them)
> 3) being able to select/deselect some dataset in a conventional plot (e.g.
> multiple stacked histograms)
>
> and so on and so forth...
>
> I did some online research and came across potentially many resources like
>
>
> http://bit.ly/18dkX1P
> http://bit.ly/18dkXPF
> http://bit.ly/1jsksk4
> http://bit.ly/1jskyrO
>
> but I honestly have no idea about where to start from.
> Making the interactive visualizations available on a website is a logical
> second step, but first things first.
> I am sure that plenty of people on this list have a strong expertise about
> the interactive visualizations, so any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From carina.salt at googlemail.com  Fri Nov 22 18:29:38 2013
From: carina.salt at googlemail.com (Carina Salt)
Date: Fri, 22 Nov 2013 17:29:38 +0000
Subject: [R] Fwd: Use of 'by' function with FUN=mean
In-Reply-To: <CAB+PZ6DqYWktmi_BVZ0pWgVy5vVd48UTHjHW6NGwF=b6DV323g@mail.gmail.com>
References: <CAB+PZ6DqYWktmi_BVZ0pWgVy5vVd48UTHjHW6NGwF=b6DV323g@mail.gmail.com>
Message-ID: <CAB+PZ6A_evEemBADhNdW1w60Z0hC_iGCbCc8AEPcVkj_Mi+Y5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/da3af755/attachment.pl>

From gunter.berton at gene.com  Fri Nov 22 18:36:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 22 Nov 2013 09:36:05 -0800
Subject: [R] Principal Components in a Linear Model
In-Reply-To: <001a01cee7a2$8ca07fd0$a5e17f70$@net>
References: <001a01cee7a2$8ca07fd0$a5e17f70$@net>
Message-ID: <CACk-te1_4duqXh-xefkJ9qBbA815hHiBHrWoJxhGWmYOWvKccQ@mail.gmail.com>

1. Probably not, depending on what you expect to gain from this. R's
numerical procedures can almost certainly handle the correlations.

2. Search on "R package for principal components regression" instead
of rolling your own.There are several (e.g. "chemometrics", "pls",
etc.)

-- Bert

On Fri, Nov 22, 2013 at 8:47 AM, Chris Wilkinson <kinsham at verizon.net> wrote:
> My data has correlations between predictors so I think it would be
> advantageous to rotate the axes with prcomp().
>
>> census <-
> read.table(paste("http://www.stat.wisc.edu/~rich/JWMULT02dat","T8-5.DAT",sep
> ="/"),header=F)
>> census
>       V1   V2    V3   V4   V5
> 1  5.935 14.2 2.265 2.27 2.91
> 2  1.523 13.1 0.597 0.75 2.62
> 3  2.599 12.7 1.237 1.11 1.72
> 4  4.009 15.2 1.649 0.81 3.02
> 5  4.687 14.7 2.312 2.50 2.22
> 6  8.044 15.6 3.641 4.51 2.36
> 7  2.766 13.3 1.244 1.03 1.97
> 8  6.538 17.0 2.618 2.39 1.85
> 9  6.451 12.9 3.147 5.52 2.01
> 10 3.314 12.2 1.606 2.18 1.82
> 11 3.777 13.0 2.119 2.83 1.80
> 12 1.530 13.8 0.798 0.84 4.25
> 13 2.768 13.6 1.336 1.75 2.64
> 14 6.585 14.9 2.763 1.91 3.17
>
>> pca1 <- prcomp(census)
>> summary(pca1)
> Importance of components:
>                           PC1    PC2     PC3     PC4     PC5
> Standard deviation     2.6327 1.3361 0.62422 0.47909 0.11897
> Proportion of Variance 0.7413 0.1909 0.04168 0.02455 0.00151
> Cumulative Proportion  0.7413 0.9323 0.97394 0.99849 1.00000
>
>> pca1$rotation # eigenvectors
>            PC1         PC2          PC3         PC4          PC5
> V1 -0.78120807  0.07087183 -0.003656607  0.54171007  0.302039670
> V2 -0.30564856  0.76387277  0.161817438 -0.54479937  0.009279632
> V3 -0.33444840 -0.08290788 -0.014841008  0.05101636 -0.937255367
> V4 -0.42600795 -0.57945799 -0.220453468 -0.63601254  0.172145212
> V5  0.05435431  0.26235528 -0.961759720  0.05127599 -0.024583093
>
> I'd like to create a linear model based on the rotated axes.
>
>> linmod <- lm(y~a+b+....)
>
> Could someone be kind enough to suggest how to code a, b...?
>
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From murdoch.duncan at gmail.com  Fri Nov 22 18:43:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 Nov 2013 12:43:30 -0500
Subject: [R] R and Interactive Visualizations
In-Reply-To: <op.w6yhkrgyzqkd1e@enea>
References: <op.w6yhkrgyzqkd1e@enea>
Message-ID: <528F97C2.8070102@gmail.com>

On 22/11/2013 10:06 AM, Lorenzo Isella wrote:
> Dear All,
> I use several R libraries (ggplot2, igraph etc...) for producing static
> visualizations.
> However, I'd like to be able to go beyond this.
> Things I may like to be able to achieve (relying on R as much as possible):
>
> 1) network visualizations such that when you click on a node, you see its
> properties and the network layout centers on that node
> 2) geographical plots (e.g. European countries colored according to their
> GDP and the possibility to see some other metadata when I click on one of
> them)
> 3) being able to select/deselect some dataset in a conventional plot (e.g.
> multiple stacked histograms)
>
> and so on and so forth...
>
> I did some online research and came across potentially many resources like
>
>
> http://bit.ly/18dkX1P
> http://bit.ly/18dkXPF
> http://bit.ly/1jsksk4
> http://bit.ly/1jskyrO
>
> but I honestly have no idea about where to start from.
> Making the interactive visualizations available on a website is a logical
> second step, but first things first.
> I am sure that plenty of people on this list have a strong expertise about
> the interactive visualizations, so any suggestion is welcome.

Besides what has been mentioned so far, you should look at the gridSVG 
package.  There are a number of examples linked from its web page 
http://sjp.co.nz/projects/gridsvg/.

Duncan Murdoch


From dwinsemius at comcast.net  Fri Nov 22 18:46:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Nov 2013 09:46:05 -0800
Subject: [R] use of bquote
In-Reply-To: <EF7ADE08-FCC2-475F-A186-4464F3D7971C@gmail.com>
References: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>
	<528EFF56.5060108@auckland.ac.nz>
	<EF7ADE08-FCC2-475F-A186-4464F3D7971C@gmail.com>
Message-ID: <4E211B2B-3DDD-488C-A015-881045A933B9@comcast.net>


On Nov 22, 2013, at 12:14 AM, peter dalgaard wrote:

> 
> On 22 Nov 2013, at 07:53 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> On 11/22/13 18:47, William Dunlap wrote:
>>>> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
>>>> 
>>>> the subtitle contains three copies of the "a = 2  b = 3" phrase.
>>>> Why does it do that?  How do I tell it to give me only one copy?
>>> To avoid it don't wrap bquote() with c().  The following does what you asked for:
>>>    a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = bquote(a == .(a) ~ b==.(b)))
>> 
>> Not for me it doesn't.  Without the c() wrapper, I get no subtitle at all.  Your recipe seems to
>> work with base graphics and plot() but not with lattice and xyplot().  Also the c() wrapper
>> seems to have no impact when used with plot().
>> 
>> Moreover I am mystified by the impact of the c() wrapper when used with xyplot().
>> 
>> The result returned by bquote() has class "call".  The result returned by c(bquote(...)) is a
>> list, of length 1, whose sole entry is of class "call" and is, as one might expect, equal to the
>> result returned by bquote().
>> 
>> But why should passing this length-1 list as the value for "sub" cause a triplication of the
>> subtitle?
> 
> I dunno either, but a hint at the reason would be to look at what happens with
> 
> xyplot(0 ~ 1, sub=list(quote(1+1)))
> 
> When you do computing on the language, sometimes quote()?ing is not sufficient protection against evaluation. That?s what expression objects are for. 
> 
> A solution seems to be
> 
> xyplot(0 ~ 1, sub=as.expression(
> 	bquote(pi==.(pi) ~ e==.(exp(1)))
> ))
> 

I had an email exchange with Deepayan a few years ago and he rightly said that the docs stated that the arguments to xlab, ylab, sub and main were supposed to be unevaluated _expressions_ . Neither `bquote` nor `substitute` return values as such:

> is.expression(substitute(a == A ~ b ==B, list(A=a, B=b) ))
[1] FALSE
> is.expression(bquote(a == .(a) ~ b==.(b)))
[1] FALSE

> 
--

David Winsemius
Alameda, CA, USA


From HDoran at air.org  Fri Nov 22 18:46:49 2013
From: HDoran at air.org (Doran, Harold)
Date: Fri, 22 Nov 2013 17:46:49 +0000
Subject: [R] problem with CSV and R
In-Reply-To: <CALDs+F=5HGX=gSL20Qf58-5KmHhBeY2v96DZ1BQ0nuaqx5bUsA@mail.gmail.com>
References: <CALDs+F=5HGX=gSL20Qf58-5KmHhBeY2v96DZ1BQ0nuaqx5bUsA@mail.gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6867949D6B6@DC1VEX10MB001.air.org>

Rachel

Using fix() is not really a good way to view or modify your data. It is better to use functions like head(), tail() or index values in the dataframe to view your data and then also modify elements through indexing. 

For instance, something like this

> tmp <- data.frame(v1 = rnorm(10), v2 = rnorm(10))
> tmp[5,2] <- 10000
> tmp[1:5, 1:2]
          v1            v2
1 -0.8304551    -0.8040750
2  1.3093233     0.1811745
3 -0.1827682     1.0008157
4  0.7504598     0.5815853
5  0.3392462 10000.0000000


And hello from another person in Georgetown. 


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rachel Blum
Sent: Friday, November 22, 2013 8:52 AM
To: r-help at r-project.org
Subject: [R] problem with CSV and R

Hi,

I'm building my own dataset using data downloaded from my qualtrics survey (in .csv format), supplemented by my coding of qualitative variables. When I first downloaded the .csv from qualtrics, it loaded into R quite easily, and I was able to use the fix(dta) command to see my variables. However, once I started editing and coding qualitative variables, something went wrong. R will still let me load the .csv, but as soon as I type fix(dta) it gives me an error message:

*run_REngineRmainloop: exception *** - [__NSPlaceholdArray initWithObjects:count:]:attempt to insert nil object from objects[881] caught during REPL iteration. Update to the latest GUI version and consider reporting this properly (see FAG) if it persists and is not known.*

I made sure none of my columns read in with "i." I'm running the latest version of R (I am using a mac). Is it possible that, due to some of the new variables that have blank cells (i.e. I've made a lot of dummies, coding responses as 1, but leaving others blank) that it's choking? Help!

Rachel

--
Rachel Blum, MA
PhD Candidate in Government
Georgetown University

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pburns at pburns.seanet.com  Fri Nov 22 18:51:24 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 22 Nov 2013 17:51:24 +0000
Subject: [R] data manipulation
In-Reply-To: <COL127-W75704F3045A931410D884B3E00@phx.gbl>
References: <COL127-W75704F3045A931410D884B3E00@phx.gbl>
Message-ID: <528F999C.10904@pburns.seanet.com>

I think a list is the wrong structure,
a vector would be better since you can
use 'match':

# transform data structure:
neutralVec <- unlist(neutral_classes)

names(neutralVec) <- 
names(neutral_classes[rep(1:length(neutral_classes), 
sapply(neutral_classes, length))]

# get one or more results with 'match':
names(neutralVec[match(c(50, 20, 10, -4), neutralVec)])

# result:
# [1] "B" "D" "D" NA


Pat


On 22/11/2013 16:58, philippe massicotte wrote:
> Hi everyone.
> I have a list like this:
> neutral_classes = list(A = 71:100, B = 46:70, C = 21:45, D = 0:20)
> and I'm trying to return the letter of the named vector for with an integer belong. For example, B if I use the value 50.
> Any help would be greatly appreciated.
> Regards,Phil 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From dwinsemius at comcast.net  Fri Nov 22 18:52:18 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Nov 2013 09:52:18 -0800
Subject: [R] xyz-contour plot (irregular grid)
In-Reply-To: <CAPr7RtXG-+mfUef7KFcduwXM=-vn=-S3jtROc7cW88a1nz1e9w@mail.gmail.com>
References: <CAPr7RtXG-+mfUef7KFcduwXM=-vn=-S3jtROc7cW88a1nz1e9w@mail.gmail.com>
Message-ID: <7B580B9E-2192-4486-ADD9-13590A18A3FB@comcast.net>


On Nov 21, 2013, at 8:35 PM, ivo welch wrote:

> Dear R users:  before I try to undertake my own rewrite, has anyone already
> written a contour function that does not require a regularly spaced grid,
> preferably plot.contour(x,y,z,...)?
> 
> (it would be nice if it were based on loess() and plot()?  further
> annotations, changes, etc., would then be easier.)

The akima function in the package by the same name provides that facility.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Nov 22 18:59:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Nov 2013 09:59:31 -0800
Subject: [R] Question about error of "non-numeric
	argument	to	binary	operator"
In-Reply-To: <000001cee765$30857990$91906cb0$@yahoo.com>
References: <000001cee765$30857990$91906cb0$@yahoo.com>
Message-ID: <DAC2A7B5-2C02-49E7-BB66-A9D52240760D@comcast.net>


On Nov 22, 2013, at 1:28 AM, Noor Aziani Bt Harun wrote:

> Hi,
> 
> I'm going to run my thesis that use R language for Lee-Carter method but
> some error occur when I'm running this code.
> 
> Please guide me Sir.
> 
> 
> 
>> male.lca<-lca(malaysia.male)
> 
> Error in pop * mx : non-numeric argument to binary operator

You have provided very little information. Missing are any description of the dataset and no information about where you are getting the lca function. Why should we be guessing about these bits?

> 	[[alternative HTML version deleted]]
> 
The Posting Guide requests that you not format your postings in HTML.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Fri Nov 22 18:58:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 22 Nov 2013 09:58:42 -0800 (PST)
Subject: [R] data manipulation
Message-ID: <1385143122.87047.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You could use either:
names(which(sapply(lapply(neutral_classes,`%in%`,50),any)))
#[1] "B"


#or
vec1 <-unlist(neutral_classes)
?names(vec1) <- gsub("\\d+","",names(vec1))
?names(vec1)[vec1==50]
#[1] "B"



A.K.


Hi everyone. 
I have a list like this: 
neutral_classes = list(A = 71:100, B = 46:70, C = 21:45, D = 0:20) 
and I'm trying to return the letter of the named vector for with an integer belong. For example, B if I use the value 50. 
Any help would be greatly appreciated. 
Regards,Phil 		 	 ? 		 ?


From pburns at pburns.seanet.com  Fri Nov 22 19:04:16 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 22 Nov 2013 18:04:16 +0000
Subject: [R] data manipulation
In-Reply-To: <528F999C.10904@pburns.seanet.com>
References: <COL127-W75704F3045A931410D884B3E00@phx.gbl>
	<528F999C.10904@pburns.seanet.com>
Message-ID: <528F9CA0.8060309@pburns.seanet.com>

The final ")" went missing in the command
starting 'names(neutralVec) <- '.

On 22/11/2013 17:51, Patrick Burns wrote:
> I think a list is the wrong structure,
> a vector would be better since you can
> use 'match':
>
> # transform data structure:
> neutralVec <- unlist(neutral_classes)
>
> names(neutralVec) <-
> names(neutral_classes[rep(1:length(neutral_classes),
> sapply(neutral_classes, length))]
>
> # get one or more results with 'match':
> names(neutralVec[match(c(50, 20, 10, -4), neutralVec)])
>
> # result:
> # [1] "B" "D" "D" NA
>
>
> Pat
>
>
> On 22/11/2013 16:58, philippe massicotte wrote:
>> Hi everyone.
>> I have a list like this:
>> neutral_classes = list(A = 71:100, B = 46:70, C = 21:45, D = 0:20)
>> and I'm trying to return the letter of the named vector for with an
>> integer belong. For example, B if I use the value 50.
>> Any help would be greatly appreciated.
>> Regards,Phil
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From pmassicotte at hotmail.com  Fri Nov 22 19:17:03 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 22 Nov 2013 18:17:03 +0000
Subject: [R] data manipulation
In-Reply-To: <528F9CA0.8060309@pburns.seanet.com>
References: <COL127-W75704F3045A931410D884B3E00@phx.gbl>
	<528F999C.10904@pburns.seanet.com>, <528F9CA0.8060309@pburns.seanet.com>
Message-ID: <COL127-W32FD0B68FD717CC4B24E0EB3E00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/ab951b51/attachment.pl>

From pmassicotte at hotmail.com  Fri Nov 22 19:27:18 2013
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Fri, 22 Nov 2013 18:27:18 +0000
Subject: [R] data manipulation
In-Reply-To: <COL127-W32FD0B68FD717CC4B24E0EB3E00@phx.gbl>
References: <COL127-W75704F3045A931410D884B3E00@phx.gbl>,
	<528F999C.10904@pburns.seanet.com>, 
	<528F9CA0.8060309@pburns.seanet.com>,
	<COL127-W32FD0B68FD717CC4B24E0EB3E00@phx.gbl>
Message-ID: <COL127-W17594A40BC46050855CB6EB3E00@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/7745931e/attachment.pl>

From rmh at temple.edu  Fri Nov 22 20:00:14 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 22 Nov 2013 14:00:14 -0500
Subject: [R] use of bquote
In-Reply-To: <EF7ADE08-FCC2-475F-A186-4464F3D7971C@gmail.com>
References: <CAGx1TMA_YCdn0sBUNkWCdPJGYxDP+jwqykcdSXbsQbL=2Vu2Gw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B933FA16A2E@PA-MBX01.na.tibco.com>
	<528EFF56.5060108@auckland.ac.nz>
	<EF7ADE08-FCC2-475F-A186-4464F3D7971C@gmail.com>
Message-ID: <CAGx1TMCVC-Yud4c9dLEX4JB+enV3Y21H-dbysBPg4dbFT4Uoyw@mail.gmail.com>

Peter,

thank you.  this is perfect.  I have been looking for this idiom for years.

xyplot(0 ~ 1, sub=as.expression(
        bquote(pi==.(pi) ~ e==.(exp(1)))
))


Can you add this idiom to the examples in the ?plotmath page.
And perhaps also to the ?xyplot page

Rich

On Fri, Nov 22, 2013 at 3:14 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On 22 Nov 2013, at 07:53 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>> On 11/22/13 18:47, William Dunlap wrote:
>>>> a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = c(bquote(a == .(a) ~ b==.(b))))
>>>>
>>>> the subtitle contains three copies of the "a = 2  b = 3" phrase.
>>>> Why does it do that?  How do I tell it to give me only one copy?
>>> To avoid it don't wrap bquote() with c().  The following does what you asked for:
>>>     a <- 2; b <- 3; xyplot(1:10 ~ a*(1:10), sub = bquote(a == .(a) ~ b==.(b)))
>>
>> Not for me it doesn't.  Without the c() wrapper, I get no subtitle at all.  Your recipe seems to
>> work with base graphics and plot() but not with lattice and xyplot().  Also the c() wrapper
>> seems to have no impact when used with plot().
>>
>> Moreover I am mystified by the impact of the c() wrapper when used with xyplot().
>>
>> The result returned by bquote() has class "call".  The result returned by c(bquote(...)) is a
>> list, of length 1, whose sole entry is of class "call" and is, as one might expect, equal to the
>> result returned by bquote().
>>
>> But why should passing this length-1 list as the value for "sub" cause a triplication of the
>> subtitle?
>
> I dunno either, but a hint at the reason would be to look at what happens with
>
> xyplot(0 ~ 1, sub=list(quote(1+1)))
>
> When you do computing on the language, sometimes quote()?ing is not sufficient protection against evaluation. That?s what expression objects are for.
>
> A solution seems to be
>
> xyplot(0 ~ 1, sub=as.expression(
>         bquote(pi==.(pi) ~ e==.(exp(1)))
> ))
>
>
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petretta at unina.it  Fri Nov 22 20:08:40 2013
From: petretta at unina.it (petretta at unina.it)
Date: Fri, 22 Nov 2013 20:08:40 +0100
Subject: [R]  metafor escalc(measure="SMCC")
Message-ID: <20131122200840.51525pcvh6xmr4xk@inbox.unina.it>

Many thanks to Wolfgang Wiechtbauer for the explanation.

Sincerely

Mario Petretta


Message: 31
  Date: Thu, 21 Nov 2013 19:08:14 +0100
  From: "Viechtbauer Wolfgang (STAT)"
          <wolfgang.viechtbauer at maastrichtuniversity.nl>
  To: "petretta at unina.it" <petretta at unina.it>, "r-help at r-project.org"
          <r-help at r-project.org>
  Subject: Re: [R] metafor escalc(measure="SMCC")
  Message-ID:
          <077E31A57DA26E46AB0D493C9966AC730D99255ED7 at UM-MAIL4112.unimaas.nl>
  Content-Type: text/plain; charset="us-ascii"

  .cmicalc is a non-exported function. You can see the code with:

  getAnywhere(.cmicalc)

  Best,
  Wolfgang


[Nascondi Testo quotato]
-----Original Message-----
  From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
  On Behalf Of petretta at unina.it
  Sent: Thursday, November 21, 2013 13:39
  To: r-help at r-project.org
  Subject: [R] metafor escalc(measure="SMCC")

  Many thanks to Wolfgang Viechtbauer for the prompt and clear answer.
  However, I'm unable to understand what .cmicalc mathematically does in the
  code line:

  cmi <- .cmicalc(mi)

  I look in the metafor documentation and in R (?.cmical and ??.cmicalc) but
  I have no result. Please, can I have further explanation on this point?

  Sorry for the trouble

  Sincerely

  Mario Petretta
  Department of Translational Medical Sciences
  Naples University Federico II
  Italy




Message: 50 Date: Tue, 19 Nov 2013 11:48:33 +0100
  From: "Viechtbauer Wolfgang (STAT)"
           <wolfgang.viechtbauer at maastrichtuniversity.nl>
  To: "petretta at unina.it" <petretta at unina.it>, "r-help at r-project.org"
           <r-help at r-project.org>
  Subject: Re: [R] metafor escalc(measure="SMCC")
  Message-ID:
           <077E31A57DA26E46AB0D493C9966AC730D9925568A at UM-
MAIL4112.unimaas.nl>
  Content-Type: text/plain; charset="us-ascii"

  Dear Mario,

  You can always just inspect the code:

  escalc.default

  Best,
  Wolfgang

  --
  Wolfgang Viechtbauer, Ph.D., Statistician
  Department of Psychiatry and Psychology
  School for Mental Health and Neuroscience
  Faculty of Health, Medicine, and Life Sciences
  Maastricht University, P.O. Box 616 (VIJV1)
  6200 MD Maastricht, The Netherlands
  +31 (43) 388-4170 | http://www.wvbauer.com


-----Original Message-----
  From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
  On Behalf Of petretta at unina.it
  Sent: Tuesday, November 19, 2013 11:29
  To: r-help at r-project.org
  Subject: [R] metafor escalc(measure="SMCC")

  Dear all,

  I use R 3.0 for Windows.

  I ask how escalc(measure="SMCC") [metafor package] mathematically
  calculate yi and vi when only change score and SD change score are
  provided.

  I used the example (repoted below) posted by Qiang Yue at:

http://r.789695.n4.nabble.com/using-metafor-for-meta-analysis-of-before-
  after-studies-escalc-SMCC-td4667233.html

  but it is unclear for me the formula used to derive y1 and v1. I read
  the documentation of metafor package and it is all very well
  described, but I ask if possible for the formula used by
  escalc(measure="SMCC") to mathematically calculate yi and vi.
  Unfortunatel, I have no free access to the paper quoted in metafor
  package.

  Beginning example:

  fMRS
  author year n mean_r sd_r mean_s sd_s r
  1 Tom  2006 9  0   0 0.12 0.03    0   0
  2 Jack 2012 6  0   0 0.23 0.05    0   0
  3 Zhu  2013 8  0   0 0.18 0.05    0   0




dat_SMCC=escalc(measure="SMCC",data=fMRS,ni=n,m1i=mean_s,m2i=mean_r,sd1i=s
d_s,sd2i=sd_r,ri=r
  ,append=TRUE)

dat_SMCC

author year n mean_r sd_r mean_s sd_s r  yi      vi 1 Tom 2006  9  0    
   0    0.12  0.03  0 3.6108 0.8354
  2 Jack 2012 6  0     0    0.23  0.05  0 3.8674 1.4131
  3 Zhu 2013  8  0     0    0.18  0.05  0 3.1975 0.7640



  Sincerely

  --
  Mario Petretta
  Department of Translational Medical Sciences
  Naples University Federico II
  Italy

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
  PLEASE do read the posting guide http://www.R-project.org/posting-
  guide.html
  and provide commented, minimal, self-contained, reproducible code.


-- 
Mario Petretta
Department of Translational Medical Sciences
Naples University Federico II
Italy


From vijaychowdhari at gmail.com  Fri Nov 22 18:37:45 2013
From: vijaychowdhari at gmail.com (Vijay Chowdhari)
Date: Fri, 22 Nov 2013 09:37:45 -0800
Subject: [R] Appending Excel File Data in different folders into Single
	Dataframe
Message-ID: <CAPpreQdn4Y5+4cBway5MOUSb=R4iC3M=dzouMDU8+k6WkFaGTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/0fc3f982/attachment.pl>

From dcarlson at tamu.edu  Fri Nov 22 20:37:47 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 22 Nov 2013 13:37:47 -0600
Subject: [R] data manipulation
In-Reply-To: <COL127-W17594A40BC46050855CB6EB3E00@phx.gbl>
References: <COL127-W75704F3045A931410D884B3E00@phx.gbl>,
	<528F999C.10904@pburns.seanet.com>,
	<528F9CA0.8060309@pburns.seanet.com>,
	<COL127-W32FD0B68FD717CC4B24E0EB3E00@phx.gbl>
	<COL127-W17594A40BC46050855CB6EB3E00@phx.gbl>
Message-ID: <001001cee7ba$52caaa70$f85fff50$@tamu.edu>

You probably want to use cut(), but as currently stated, your
intervals leave gaps (between 20 and 21 for example):

set.seed(42)
values <- runif(25)*100
values
 [1] 91.480604 93.707541 28.613953 83.044763 64.174552 51.909595
73.658831
 [8] 13.466660 65.699229 70.506478 45.774178 71.911225 93.467225
25.542882
[15] 46.229282 94.001452 97.822643 11.748736 47.499708 56.033275
90.403139
[22] 13.871017 98.889173 94.666823  8.243756
> code <- cut(values, breaks=c(-1, 20, 45, 70, 100),
labels=LETTERS[4:1])
> code
 [1] A A C A B B A D B A B A A C B A A D B B A D A A D
Levels: D C B A

The levels are defined as (-1,20], (20,45], (45,70], (70,100] so
the second interval includes anything larger than 20 up to and
including 45.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of philippe
massicotte
Sent: Friday, November 22, 2013 12:27 PM
To: r-help at r-project.org
Subject: Re: [R] data manipulation

Hi again.
I realized that the example I give is not valid, because the
number I'm using is not an integer (ex. 50.1).
So I thought using 
is.between = function(x, a, b) {  (x - a)  *  (b - x) > 0}
But I'm not sure how to use it with lapply to avoid looping in
my code.
Regards,Phil
> From: pmassicotte at hotmail.com
> To: r-help at r-project.org
> Date: Fri, 22 Nov 2013 18:17:03 +0000
> Subject: Re: [R] data manipulation
> 
> Thank you everyone for your suggestions.
> 
> > Date: Fri, 22 Nov 2013 18:04:16 +0000
> > From: pburns at pburns.seanet.com
> > To: pmassicotte at hotmail.com; r-help at r-project.org
> > Subject: Re: [R] data manipulation
> > 
> > The final ")" went missing in the command
> > starting 'names(neutralVec) <- '.
> > 
> > On 22/11/2013 17:51, Patrick Burns wrote:
> > > I think a list is the wrong structure,
> > > a vector would be better since you can
> > > use 'match':
> > >
> > > # transform data structure:
> > > neutralVec <- unlist(neutral_classes)
> > >
> > > names(neutralVec) <-
> > > names(neutral_classes[rep(1:length(neutral_classes),
> > > sapply(neutral_classes, length))]
> > >
> > > # get one or more results with 'match':
> > > names(neutralVec[match(c(50, 20, 10, -4), neutralVec)])
> > >
> > > # result:
> > > # [1] "B" "D" "D" NA
> > >
> > >
> > > Pat
> > >
> > >
> > > On 22/11/2013 16:58, philippe massicotte wrote:
> > >> Hi everyone.
> > >> I have a list like this:
> > >> neutral_classes = list(A = 71:100, B = 46:70, C = 21:45,
D = 0:20)
> > >> and I'm trying to return the letter of the named vector
for with an
> > >> integer belong. For example, B if I use the value 50.
> > >> Any help would be greatly appreciated.
> > >> Regards,Phil
> > >>     [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained,
reproducible code.
> > >>
> > >
> > 
> > -- 
> > Patrick Burns
> > pburns at pburns.seanet.com
> > twitter: @burnsstat @portfolioprobe
> > http://www.portfolioprobe.com/blog
> > http://www.burns-stat.com
> > (home of:
> >   'Impatient R'
> >   'The R Inferno'
> >   'Tao Te Programming')
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From dcarlson at tamu.edu  Fri Nov 22 20:39:14 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 22 Nov 2013 13:39:14 -0600
Subject: [R] FW:  Principal Components in a Linear Model
References: <001a01cee7a2$8ca07fd0$a5e17f70$@net>
	<CACk-te1_4duqXh-xefkJ9qBbA815hHiBHrWoJxhGWmYOWvKccQ@mail.gmail.com>
Message-ID: <001301cee7ba$86708f20$9351ad60$@tamu.edu>

Bert is correct. 

In addition, you are using prcomp() for your principal
components analysis so the initial principal component loadings
are called "rotation" in contrast to princomp() where they are
called "loadings." So you do not have "rotated" components in
the traditional sense of the word. If you compare the results,
you will see that the two agree (with reflection of the first
four components). To rotate the results you would need to use
varimax() or another function (e.g. principal() in package
psych) that provides more rotation methods. 

Also stored in the output from prcomp() is an object called "x."
These are the principal component scores for each component.
They are uncorrelated and could be used as explanatory variables
in a regression analysis. But

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Friday, November 22, 2013 11:36 AM
To: Chris Wilkinson
Cc: r-help at r-project.org
Subject: Re: [R] Principal Components in a Linear Model

1. Probably not, depending on what you expect to gain from this.
R's
numerical procedures can almost certainly handle the
correlations.

2. Search on "R package for principal components regression"
instead
of rolling your own.There are several (e.g. "chemometrics",
"pls",
etc.)

-- Bert

On Fri, Nov 22, 2013 at 8:47 AM, Chris Wilkinson
<kinsham at verizon.net> wrote:
> My data has correlations between predictors so I think it
would be
> advantageous to rotate the axes with prcomp().
>
>> census <-
>
read.table(paste("http://www.stat.wisc.edu/~rich/JWMULT02dat","T
8-5.DAT",sep
> ="/"),header=F)
>> census
>       V1   V2    V3   V4   V5
> 1  5.935 14.2 2.265 2.27 2.91
> 2  1.523 13.1 0.597 0.75 2.62
> 3  2.599 12.7 1.237 1.11 1.72
> 4  4.009 15.2 1.649 0.81 3.02
> 5  4.687 14.7 2.312 2.50 2.22
> 6  8.044 15.6 3.641 4.51 2.36
> 7  2.766 13.3 1.244 1.03 1.97
> 8  6.538 17.0 2.618 2.39 1.85
> 9  6.451 12.9 3.147 5.52 2.01
> 10 3.314 12.2 1.606 2.18 1.82
> 11 3.777 13.0 2.119 2.83 1.80
> 12 1.530 13.8 0.798 0.84 4.25
> 13 2.768 13.6 1.336 1.75 2.64
> 14 6.585 14.9 2.763 1.91 3.17
>
>> pca1 <- prcomp(census)
>> summary(pca1)
> Importance of components:
>                           PC1    PC2     PC3     PC4     PC5
> Standard deviation     2.6327 1.3361 0.62422 0.47909 0.11897
> Proportion of Variance 0.7413 0.1909 0.04168 0.02455 0.00151
> Cumulative Proportion  0.7413 0.9323 0.97394 0.99849 1.00000
>
>> pca1$rotation # eigenvectors
>            PC1         PC2          PC3         PC4
PC5
> V1 -0.78120807  0.07087183 -0.003656607  0.54171007
0.302039670
> V2 -0.30564856  0.76387277  0.161817438 -0.54479937
0.009279632
> V3 -0.33444840 -0.08290788 -0.014841008  0.05101636
-0.937255367
> V4 -0.42600795 -0.57945799 -0.220453468 -0.63601254
0.172145212
> V5  0.05435431  0.26235528 -0.961759720  0.05127599
-0.024583093
>
> I'd like to create a linear model based on the rotated axes.
>
>> linmod <- lm(y~a+b+....)
>
> Could someone be kind enough to suggest how to code a, b...?
>
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From pdalgd at gmail.com  Fri Nov 22 20:42:26 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 22 Nov 2013 20:42:26 +0100
Subject: [R] Recode values
In-Reply-To: <1385115214037-4680959.post@n4.nabble.com>
References: <1385115214037-4680959.post@n4.nabble.com>
Message-ID: <3B04251A-57AA-4A88-B8C3-C341DD726EDB@gmail.com>


On 22 Nov 2013, at 11:13 , lillosdos <lillo_dicarlo at live.it> wrote:

> Hi I'm Pasquale,
> I need to recode variables (columns) of a dataframe (call it X). The
> observations (rows) are coded as numeric 0,1,2 and NA. I managed to use the
> lapply() function with recode() as FUN and for() loop but I failed.
> *My problem is that for each columns the recoding system is different *(i.e.
> for V1 the code will be 0=a, 1=b, 2=c, for V2 0=z, 1=y, 2=x). 
> My new codes are stored in another data frame (call it Y). colnames(X) and
> rownames(Y) matches.
> How can I solve this situation?

Why rownames(Y) (typo?)

I?d expect the ticket to be 

f <- function(x,names) factor(x, levels=0:2, labels=names)  

and then

mapply(FUN=f, X, listofnamevectors)

where listofnamevectors could be just Y or as.data.frame(t(Y)) depending on whether rownames(Y) was really colnames(Y) or not.

> 
> Thanks a lot in advance,
> Pasquale
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Recode-values-tp4680959.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Fri Nov 22 21:13:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 22 Nov 2013 12:13:55 -0800 (PST)
Subject: [R] Appending Excel File Data in different folders into Single
	Dataframe
Message-ID: <1385151235.4402.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

Suppose I have all the folders in my working directory.
?dir(recursive=T) #created two folders each with a single excel file
#[1] "Folder1/File1.xls" "Folder2/File2.xls"
library(XLConnect)

lst1 <- lapply(dir(recursive=T),function(x) {wb <- loadWorkbook(x); readWorksheet(wb,sheet="Sheet1")}) 


lst1
#[[1]]
#????????? State????? Lat???? Lon?????????????????????????? Address
#1 Anchorage USA 45.87576 -12.567 Starbucks, Van dyke road, 33456, 
#2??? Albany USA 42.40000? 73.450?????? 1417, Central Avenue, 12205
#
#[[2]]
#????????? State?? Lat??? Lon????????????????????????? Address
#1?? Altanta USA 33.45? 84.23?????? 441, 16th street NW, 30363
#2 Anchorage USA 61.13 149.54 1140 W Parks Hwy, Wasilla, 99654
#3? Amarillo USA 35.11 101.50????????? 900, S. Harrison, 79101


do.call(rbind,lst1)
A.K.




I have about 10 folders in my directory i.e Folder 1  Folder 10. Each 
Folder has a single excel file containing data with the following 
attributes State,lat,lon, address i.e 



State ? ? ? ? ? ? ? ? Lat ? ? ? ? ? ? ? ? ? Lon ? ? ? ? ? ? ? ? ? ?Address 

Anchorage ? ?45.87576 ? ? -12.567 ? ? ? ? ?Starbucks, Van dyke road, 33456, 
USA 





I would like to write a script in R that goes through each folder and 
gathers the data to create a single data frame that has all the data in 
each folder. So I would have a single data frame that consists of all 
observation appended together from in each excel file in each folder in one 
data frame i.e?


State ? ? ? Lat ? ? ? ? ? ? ?Lon ? ? ? ? ? ? Address 

xxx ? ? ? ? ?xxx ? ? ? ? ? ? ? xxx ? ? ? ? ? ? ?xxx 

xxx ? ? ? ? ?xxx ? ? ? ? ? ? ? xxx ? ? ? ? ? ? ?xxx 

xxx ? ? ? ? ?xxx ? ? ? ? ? ? ? xxx ? ? ? ? ? ? ?xxx 



Please let me know how I would go about this 

Vijay 



From dulcalma at bigpond.com  Fri Nov 22 23:15:40 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 23 Nov 2013 08:15:40 +1000
Subject: [R] FW:  The profile log-likelihood problem
References: <1385001806.72319.YahooMailNeo@web126104.mail.ne1.yahoo.com> 
Message-ID: <000601cee7d0$61a1a380$24e4ea80$@bigpond.com>

Sending again as it did not make the list

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Friday, 22 November 2013 09:19
To: 'smart hendsome'; R
Subject: RE: [R] The profile log-likelihood problem

Hi

Without knowing anything about the data and the warning messages, however
the p.vec value seems a little strange.
try 
p.vec= seq(1.35, 1.75, by = 0.1) 

It could be that you have run out of memory to do 50 sets of calculations

If ok with the result then repeat with a narrower focus. Most probably
quicker


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of smart hendsome
Sent: Thursday, 21 November 2013 12:43
To: r-help at r-project.org
Cc: roslinazairimah at ump.edu.my
Subject: [R] The profile log-likelihood problem

Hi, Im still new to R and I have a problem regarding the code below. I don't
know how to solve that. I want to compute profile log-likelihood using the
rainfall data. I use the code below from Dunn:



"
tweedie.profile(Amount~Year*Month,p.vec=seq(1.35,1.75,length=50),method="ser
ies",do.ci=TRUE) "

I got the message below when I run the code above. Anyone know why the p.vec
taken from 1.35 to 1.75? Can someone help me? 


"1.35 1.358163 1.366327 1.374490 1.382653 1.390816 1.398980 1.407143
1.415306 1.423469 1.431633 1.439796 1.447959 1.456122 1.464286 1.472449
1.480612 1.488776 1.496939 1.505102 1.513265 1.521429 1.529592 1.537755
1.545918 1.554082 1.562245 1.570408 1.578571 1.586735 1.594898 1.603061
1.611224 1.619388 1.627551 1.635714 1.643878 1.652041 1.660204 1.668367
1.676531 1.684694 1.692857 1.701020 1.709184 1.717347 1.725510 1.733673
1.741837 1.75 ..................................................Done.
  No valid values of the likelihood computed: smooth aborted
   Consider trying another value for the input  method.
Error in if ((xi.max > 0) & (xi.max < 1)) { : 
  missing value where TRUE/FALSE needed
In addition: There were 50 or more warnings (use warnings() to see the first
50)"

Thanks for yourattention and help.

Regard,
Zuhri
	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Fri Nov 22 23:16:20 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 23 Nov 2013 08:16:20 +1000
Subject: [R] FW:  changing the surface coloring (using lattice::wireframe)
References: <8AFF49EF6B3F5C419F8AC44BE350CE0518D011B2@MBX22.d.ethz.ch> 
Message-ID: <000701cee7d0$7919a260$6b4ce720$@bigpond.com>

Sending again as it did not make the list

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Friday, 22 November 2013 09:35
To: 'Smilyanov Georgi'
Subject: RE: [R] changing the surface coloring (using lattice::wireframe)

Hi Georgi

I have not used wireframe for years but I think it is similar to levelplot
as it is in that "group"

Depending on what you want try something like

              cuts     = 6,
              at       = c(0,1,5,15,25,35,55),
              col.regions =
c("#FFFFFF","#00FFFF","#A9E2FF","#8080FF","#0000FF","#FFD18F","#FF0000"),

which I just plucked from some scripts for levelplot that I had

I think that you need to read the documentation on it as well as drape may
come into play

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Smilyanov Georgi
Sent: Friday, 22 November 2013 08:44
To: mailman, r-help
Subject: [R] changing the surface coloring (using lattice::wireframe)

Hi all,

I am using lattice::wireframe to create a surface. I need to change the
coloring so that it depends on the x or y variable (instead of on z). How
should this be done? The documentation says that the color is automatically
chosen to depend on the height (e.g. z).

Thanks!
Georgi
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dobzhanski at gmail.com  Fri Nov 22 22:43:04 2013
From: dobzhanski at gmail.com (john d)
Date: Fri, 22 Nov 2013 19:43:04 -0200
Subject: [R] averaging rows on a data.frame according to a factor
Message-ID: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131122/8778108b/attachment.pl>

From dwinsemius at comcast.net  Sat Nov 23 00:01:10 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Nov 2013 15:01:10 -0800
Subject: [R] averaging rows on a data.frame according to a factor
In-Reply-To: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
References: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
Message-ID: <0D24B459-C8C5-4DF3-948E-603C4AFAAFA5@comcast.net>


On Nov 22, 2013, at 1:43 PM, john d wrote:

> Dear all,
> 
> I apologize for the newbie question, but I'm stuck.
> 
> I have a data frame in the following form:
> 
> dat<-as.data.frame(cbind(c("a","a","a","b","b"), c(1,2,3,3,2),c(4,3,5,4,4)))
> 
> I need a way to generate a new dataframe with the average for each factor.
> The result should look like:

Well, using the data,frame(cbind(...)) will ensure that you will NOT get factors, since cbind creates a matrix and that structure will not hold factors.

> 
> res<-as.data.frame(cbind(c("a","b"), c(2,2.5),c(4,4)))

Ouch.


Look at ?tapply or ?aggregate.

Perhaps:

dat<-data.frame(facts= c("a","a","a","b","b"), nums1=c(1,2,3,3,2),nums2=c(4,3,5,4,4))

aggregate(dat[-1], dat[1], mean)



> Any help would be greatly appreciated.
> 
> Jonathan
> 
> 	[[alternative HTML version deleted]]

Newbie or not, you should still read the Posting Guide.

> 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sat Nov 23 00:02:11 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 22 Nov 2013 23:02:11 +0000
Subject: [R] averaging rows on a data.frame according to a factor
In-Reply-To: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
References: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
Message-ID: <528FE273.6070202@sapo.pt>

Hello,

Try the following.

aggregate(cbind(V2, V3) ~ V1, dat, FUN = mean)


Hope this helps,

Rui Barradas

Em 22-11-2013 21:43, john d escreveu:
> Dear all,
>
> I apologize for the newbie question, but I'm stuck.
>
> I have a data frame in the following form:
>
> dat<-as.data.frame(cbind(c("a","a","a","b","b"), c(1,2,3,3,2),c(4,3,5,4,4)))
>
> I need a way to generate a new dataframe with the average for each factor.
> The result should look like:
>
> res<-as.data.frame(cbind(c("a","b"), c(2,2.5),c(4,4)))
>
> Any help would be greatly appreciated.
>
> Jonathan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sat Nov 23 00:11:29 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 22 Nov 2013 23:11:29 +0000
Subject: [R] averaging rows on a data.frame according to a factor
In-Reply-To: <528FE273.6070202@sapo.pt>
References: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
	<528FE273.6070202@sapo.pt>
Message-ID: <528FE4A1.4090004@sapo.pt>

Sorry, there's a bug in my previous answer.

dat <- data.frame(c("a","a","a","b","b"), c(1,2,3,3,2), c(4,3,5,4,4))

aggregate(as.matrix(dat[,-1]) ~ dat[,1], FUN = mean)


Don't use as.data.frame(cbind(...)), everything becomes factors.

Rui Barradas

Em 22-11-2013 23:02, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
> aggregate(cbind(V2, V3) ~ V1, dat, FUN = mean)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 22-11-2013 21:43, john d escreveu:
>> Dear all,
>>
>> I apologize for the newbie question, but I'm stuck.
>>
>> I have a data frame in the following form:
>>
>> dat<-as.data.frame(cbind(c("a","a","a","b","b"),
>> c(1,2,3,3,2),c(4,3,5,4,4)))
>>
>> I need a way to generate a new dataframe with the average for each
>> factor.
>> The result should look like:
>>
>> res<-as.data.frame(cbind(c("a","b"), c(2,2.5),c(4,4)))
>>
>> Any help would be greatly appreciated.
>>
>> Jonathan
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Nov 23 00:46:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 22 Nov 2013 15:46:06 -0800 (PST)
Subject: [R] averaging rows on a data.frame according to a factor
In-Reply-To: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
References: <CAMLNaBb5cPkh+p0XsWzsrEikA65z7kr2pUrn8CGAhvRxB29VjQ@mail.gmail.com>
Message-ID: <1385163966.52449.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,


dat<-as.data.frame(cbind(c("a","a","a","b","b"), c(1,2,3,3,2),c(4,3,5,4,4)))
?str(dat)
#'data.frame':??? 5 obs. of? 3 variables:
# $ V1: Factor w/ 2 levels "a","b": 1 1 1 2 2
# $ V2: Factor w/ 3 levels "1","2","3": 1 2 3 3 2
# $ V3: Factor w/ 3 levels "3","4","5": 2 1 3 2 2

#better way would be
dat<-data.frame(V1=c("a","a","a","b","b"), V2=c(1,2,3,3,2),V3=c(4,3,5,4,4))
?str(dat)
#'data.frame':??? 5 obs. of? 3 variables:
# $ V1: Factor w/ 2 levels "a","b": 1 1 1 2 2
# $ V2: num? 1 2 3 3 2
# $ V3: num? 4 3 5 4 4

library(plyr)
?ddply(dat,.(V1),colwise(mean))

#or
?aggregate(.~V1,data=dat,mean)

A.K.

On Friday, November 22, 2013 5:45 PM, john d <dobzhanski at gmail.com> wrote:
Dear all,

I apologize for the newbie question, but I'm stuck.

I have a data frame in the following form:

dat<-as.data.frame(cbind(c("a","a","a","b","b"), c(1,2,3,3,2),c(4,3,5,4,4)))

I need a way to generate a new dataframe with the average for each factor.
The result should look like:

res<-as.data.frame(cbind(c("a","b"), c(2,2.5),c(4,4)))

Any help would be greatly appreciated.

Jonathan

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smckinney at bccrc.ca  Sat Nov 23 02:16:52 2013
From: smckinney at bccrc.ca (Steven McKinney)
Date: Fri, 22 Nov 2013 17:16:52 -0800
Subject: [R] [R-SIG-Mac] morley object?
In-Reply-To: <CA+mFFDNehh4XtTBk9K+qcGNCq7QO65s5CPnWdRgtTmqQRsBYZQ@mail.gmail.com>
References: <CA+mFFDNehh4XtTBk9K+qcGNCq7QO65s5CPnWdRgtTmqQRsBYZQ@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CB926B118@crcmail4.BCCRC.CA>

Hi Ann

Looks like a typo - I see "moreley.tab" that should be "morley.tab".
Works for me after correcting that.

> filepath <- system.file("data", "moreley.tab", package="datasets")
> filepath
[1] ""
> 
> filepath <- system.file("data", "morley.tab", package="datasets")
> filepath
[1] "C:/PROGRA~1/R/R-30~1.1/library/datasets/data/morley.tab"
> mm <- read.table(filepath)
> head(mm)
    Expt Run Speed
001    1   1   850
002    1   2   740
003    1   3   900
004    1   4  1070
005    1   5   930
006    1   6   850
> 


Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre





> -----Original Message-----
> From: r-sig-mac-bounces at r-project.org [mailto:r-sig-mac-bounces at r-
> project.org] On Behalf Of Ann Summy
> Sent: November-22-13 4:56 PM
> To: r-sig-mac; r-help
> Subject: [R-SIG-Mac] morley object?
> 
> Brand new to R and not a sys admin or programmer type.  I am trying to work
> through the intro tutorial in the sample session here
> http://cran.r-project.org/doc/manuals/R-intro.html#A-sample-session.
> 
> I have an error when following the instructions below:
> 
> > The next section will look at data from the classical experiment of
> > Michelson to measure the speed of light. This dataset is available in the
> > morley object, but we will read it to illustrate the read.table function.
> > filepath <- system.file("data", "morley.tab" ,
> package="datasets")filepath
> >
> > Get the path to the data file.
> > file.show(filepath)
> >
> > Optional. Look at the file.
> > mm <- read.table(filepath)mm
> >
> > Read in the Michelson data as a data frame, and look at it. There are
> five
> > experiments (column Expt) and each has 20 runs (column Run) and sl is the
> > recorded speed of light, suitably coded.
> >
> Here is my result:
> 
> > > filepath <- system.file("data", "moreley.tab", package="datasets")
> 
> > filepath
> 
> [1] ""
> 
> > file.show(filepath)
> 
> > mm <- read.table(filepath)
> 
> Error in read.table(filepath) : no lines available in input
> 
> In addition: Warning message:
> 
> In file(file, "rt") :
> 
>   file("") only supports open = "w+" and open = "w+b": using the former
> 
> 
> Is it because I am missing this "morley object"?  How do I see a list of
> what objects I have installed?  I installed
> R-2.15.3.pkg<http://cran.r-project.org/bin/macosx/old/R-2.15.3.pkg>,
> because
> I am teaching myself on a 32-bit Macbook.
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac


From dmck at u.washington.edu  Sat Nov 23 05:43:53 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 22 Nov 2013 20:43:53 -0800
Subject: [R]  divergent colors around zero in levelplot()
Message-ID: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>

I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).

I am using R 3.0.2 on OSX 10.9

Here is an example

x <- y <- c(1:25) 
grid <- expand.grid(x=x,y=y)
grid$z <- sort(runif(625,min=-1,max=12))
levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5

# do something clever here
# e.g., my.colors <- <create a palette that splits at zero>

levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue

Ideas appreciated.  Thanks in advance.



Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor 
School of Environmental and Forest Sciences 
University of Washington 
 
dmck at uw.edu


From gunter.berton at gene.com  Sat Nov 23 07:25:29 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 22 Nov 2013 22:25:29 -0800
Subject: [R] divergent colors around zero in levelplot()
In-Reply-To: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
Message-ID: <CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>

Use the Rcolorbrewer package.

-- Bert

On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>
> I am using R 3.0.2 on OSX 10.9
>
> Here is an example
>
> x <- y <- c(1:25)
> grid <- expand.grid(x=x,y=y)
> grid$z <- sort(runif(625,min=-1,max=12))
> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>
> # do something clever here
> # e.g., my.colors <- <create a palette that splits at zero>
>
> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>
> Ideas appreciated.  Thanks in advance.
>
>
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
>
> dmck at uw.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dmck at u.washington.edu  Sat Nov 23 07:30:26 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Fri, 22 Nov 2013 22:30:26 -0800
Subject: [R] divergent colors around zero in levelplot()
In-Reply-To: <CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
Message-ID: <EBF94D0A-AFF5-4B15-BDD7-109F8545D5AF@u.washington.edu>

Thanks Bert.  I?ll check it out.

Don

On Nov 22, 2013, at 10:25 PM, Bert Gunter <gunter.berton at gene.com> wrote:

> Use the Rcolorbrewer package.
> 
> -- Bert
> 
> On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
>> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
>> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>> 
>> I am using R 3.0.2 on OSX 10.9
>> 
>> Here is an example
>> 
>> x <- y <- c(1:25)
>> grid <- expand.grid(x=x,y=y)
>> grid$z <- sort(runif(625,min=-1,max=12))
>> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>> 
>> # do something clever here
>> # e.g., my.colors <- <create a palette that splits at zero>
>> 
>> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>> 
>> Ideas appreciated.  Thanks in advance.
>> 
>> 
>> 
>> Don McKenzie
>> Research Ecologist
>> Pacific Wildland Fire Sciences Lab
>> US Forest Service
>> 
>> Affiliate Professor
>> School of Environmental and Forest Sciences
>> University of Washington
>> 
>> dmck at uw.edu
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374

Don McKenzie
Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences 
College of the Environment
University of Washington
dmck at uw.edu


From Achim.Zeileis at uibk.ac.at  Sat Nov 23 10:47:18 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 23 Nov 2013 10:47:18 +0100 (CET)
Subject: [R] divergent colors around zero in levelplot()
In-Reply-To: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
Message-ID: <alpine.DEB.2.10.1311231044000.4854@paninaro.uibk.ac.at>

On Fri, 22 Nov 2013, Don McKenzie wrote:

> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>
> I am using R 3.0.2 on OSX 10.9
>
> Here is an example
>
> x <- y <- c(1:25)
> grid <- expand.grid(x=x,y=y)
> grid$z <- sort(runif(625,min=-1,max=12))
> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>
> # do something clever here
> # e.g., my.colors <- <create a palette that splits at zero>
>
> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>
> Ideas appreciated.  Thanks in advance.

One approach is to limit the range of colors (to match the range of the 
data) as you suggest above. The other approach is to extend the range of 
the legend (beyond the range of the data). For example:

levelplot(z ~ x*y, grid, at = seq(-12, 12, length = 100))

This produces a legend that is symmetric around zero.

For other/better diverging color palettes, you can use the RColorBrewer 
package (as suggested by Bert) or the colorspace package (see e.g., its 
graphical choose_color() tool).

>
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
>
> dmck at uw.edu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From f.harrell at vanderbilt.edu  Sat Nov 23 14:48:09 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Sat, 23 Nov 2013 07:48:09 -0600
Subject: [R] [R-pkgs] Hmisc package 3.13-0
Message-ID: <5290B219.3020505@vanderbilt.edu>

A significant update to the Hmisc package is now available on CRAN for 
all platforms.  Hmisc source is now on github at 
https://github.com/harrelfe/Hmisc and the full change log may be found 
at https://github.com/harrelfe/Hmisc/commits/master

The most important updates are additions of new graphics functions for 
summarizing and displaying data with an aim of replacing tables.  There 
is also an interface to Duncan Murdoch's tables package for advanced 
LaTeX table making, allowing Hmisc variable labels and units of 
measurement to be automatically incorporated into table row or column 
labels.  New functions are overviewed and exemplified at 
http://biostat.mc.vanderbilt.edu/HmiscNew .  There is also a new 
function latexTherm that writes a LaTeX picture environment for 
including a series of thermometers inside LaTeX text.  This is intended 
especially for figure captions where the analyst wishes to provide a 
snapshot of the fraction of observations that are used in the current 
graphic.

The dotchart3 function is an improvement of dotchart2.

The rcspline.eval function, used by the rms package's rcs function, has 
better default knot placement for restricted cubic splines (natural 
splines) when there are ties in the predictor at the lowest or highest 
value (e.g., clumping at zero).

The most recent updates to Hmisc are

    * Changed n location (nloc argument) in bpplotM
    * Improved dotchart3 to better compute string widths when there is a 
mixture of expressions and regular strings for auxdata/auxtitle
    * Changed rlegend to not take logs if log axes are in effect.  Fixes 
Ecdf(..., log='x', label.curves=list(keys=1:3)).  Thanks: Bayazid Sarker 
<sarkarbayazid at gmail.com>
          * Extended non-panel (regular) version of plsmo to handle matrix y
    * Likewise for summaryRc
    * Added xlim to bpplotM
    * Added latexTherm function to create LaTeX picture environments to 
add a series of thermometers to LaTeX text
    * Fixed deff to handle the case where R^2 = 1.  Thanks: Matthieu 
Stigler <matthieu.stigler at gmail.com>
    * Added new test file for wtd.mean, wtd.quantile
    * New test aregImpute3.r for glm Poisson regression
    * Improved describe.vector to format single unique values
    * Took aware warning about var, s.e., t, p in fit.mult.impute
    * Changed wtd.loess.noiter to use loess instead of stats:::simpleLoess

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kiotoqq at gmail.com  Sat Nov 23 16:04:51 2013
From: kiotoqq at gmail.com (maggy yan)
Date: Sat, 23 Nov 2013 16:04:51 +0100
Subject: [R]  how to melt variable to one variable
Message-ID: <CAK70=f4beYTES7je34AsT-F4hZDN7bHqdHFdVDqrUnPA4AKRtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131123/f4dacf61/attachment.pl>

From smartpink111 at yahoo.com  Sat Nov 23 17:30:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 23 Nov 2013 08:30:52 -0800 (PST)
Subject: [R] Combine columns having same column name from multiple data
	frames
Message-ID: <1385224252.64809.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You may try:
lapply(seq_len(ncol(data1)),function(i) {x1 <- do.call(cbind,lapply(lapply(as.list(paste0("data",1:3)),get),`[`,i)); write.csv(x1,paste0("new",i,".csv"),quote=FALSE) })

A.K.


Dear All, 

I am trying to combine columns having same name from 3 different
 data frames and create new data frame with combined columns. The 
challenging thing is each data-frame has 100 columns so I have to create
 100 new data frames and write each data-frame as new text file with 
unique column name. 

Example: 

> data1 
? ? ? ? ? ? ? ? ?1 ? ? ? ? 2 ? ? ? ? 3 ? ? ? ? 4 ? ? ? ? 5 ? ? ? ? 6 ? ? ? ? 7 ? ? ? ? 8 ? ? ? ? 9 
x ? ? ? ? -39532.0 ?-39472.0 ?-39472.0 ?-39592.0 ?-39532.0 ?-39472.0 ?-39412.0 ?-39592.0 ?-39412.0 
y ? ? ? ?2015408.1 2015348.1 2015288.1 2015228.1 2015228.1 2015228.1 2015228.1 2015168.1 2015168.1 
id ? ? ? ? ? ? 1.0 ? ? ? 2.0 ? ? ? 3.0 ? ? ? 4.0 ? ? ? 5.0 ? ? ? 6.0 ? ? ? 7.0 ? ? ? 8.0 ? ? ? 9.0 
srad_120 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 ? ? 496.0 
srad_121 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 ? ? 441.6 
srad_122 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 ? ? 150.4 
srad_123 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 ? ? 249.6 
srad_124 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 ? ? 272.0 
srad_125 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 ? ? 153.6 

> data2 
? ? ? ? ? ? ? ? ?1 ? ? ? ? 2 ? ? ? ? 3 ? ? ? ? 4 ? ? ? ? 5 ? ? ? ? 6 ? ? ? ? 7 ? ? ? ? 8 ? ? ? ? 9 
x ? ? ? ? -39532.0 ?-39472.0 ?-39472.0 ?-39592.0 ?-39532.0 ?-39472.0 ?-39412.0 ?-39592.0 ?-39412.0 
y ? ? ? ?2015408.1 2015348.1 2015288.1 2015228.1 2015228.1 2015228.1 2015228.1 2015168.1 2015168.1 
id ? ? ? ? ? ? 1.0 ? ? ? 2.0 ? ? ? 3.0 ? ? ? 4.0 ? ? ? 5.0 ? ? ? 6.0 ? ? ? 7.0 ? ? ? 8.0 ? ? ? 9.0 
srad_120 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 ? ? 542.0 
srad_121 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 ? ? 487.6 
srad_122 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 ? ? 196.4 
srad_123 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 ? ? 295.6 
srad_124 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 ? ? 318.0 
srad_125 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 ? ? 199.6 

> data3 
? ? ? ? ? ? ? ? ?1 ? ? ? ? 2 ? ? ? ? 3 ? ? ? ? 4 ? ? ? ? 5 ? ? ? ? 6 ? ? ? ? 7 ? ? ? ? 8 ? ? ? ? 9 
x ? ? ? ? -39532.0 ?-39472.0 ?-39472.0 ?-39592.0 ?-39532.0 ?-39472.0 ?-39412.0 ?-39592.0 ?-39412.0 
y ? ? ? ?2015408.1 2015348.1 2015288.1 2015228.1 2015228.1 2015228.1 2015228.1 2015168.1 2015168.1 
id ? ? ? ? ? ? 1.0 ? ? ? 2.0 ? ? ? 3.0 ? ? ? 4.0 ? ? ? 5.0 ? ? ? 6.0 ? ? ? 7.0 ? ? ? 8.0 ? ? ? 9.0 
srad_120 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 ? ? 578.0 
srad_121 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 ? ? 523.6 
srad_122 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 ? ? 232.4 
srad_123 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 ? ? 331.6 
srad_124 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 ? ? 354.0 
srad_125 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 ? ? 235.6 

write.csv(cbind(data1[,1], data2[,1], data3[,1]), "new1.csv") 
Above statement generates new csv file that has first column of each data frame (data1, data2, data3). 
? ? ? ? V1	V2	V3 
x	-39531.99524	-39531.99524	-39531.99524 
y	2015408.131	2015408.131	2015408.131 
id	1	 ? ? ? ? ? ? ? ? ? ? ?1	 ? ? ? ? ? ? ? ? ? ? ? ? ? 1 
srad_120	496	 ? ? ? ? ? ?542	 ? ? ? ? ? ? ? ? ?578 
srad_121	441.6000061	487.6000061	523.6000061 
srad_122	150.3999939	196.3999939	232.3999939 
srad_123	249.6000061	295.6000061	331.6000061 
srad_124	272	 ? ? ? ? ? ? ? ? ? ? 318	 ? ? ? ? ? ? 354 
srad_125	153.6000061	199.6000061	235.6000061 

Similarly I need to create 9 csv files using 9 columns in each data frame. If possible, please help in this. 

Thank you very much.


From eg.spanakis at gmail.com  Sat Nov 23 10:48:24 2013
From: eg.spanakis at gmail.com (Manos Spanakis)
Date: Sat, 23 Nov 2013 11:48:24 +0200
Subject: [R] Randomize two categories testing a specific condition R version
 3.0.2 windows 32 bit
Message-ID: <CAFuS6E_Z4uPCH6GR1eBBn2WDGQm5ELnnjDB6i53THc0J0UxqWA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131123/fc5f4e47/attachment.pl>

From elgriego777 at gmail.com  Sat Nov 23 17:49:45 2013
From: elgriego777 at gmail.com (Juan Manuel Reyes S)
Date: Sat, 23 Nov 2013 13:49:45 -0300
Subject: [R] Question about compatibility
Message-ID: <CACY5Zsdg9QvfRg3mQYf7TnLDsrdkX-PX-RcHmWBnMcZyhN5NqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131123/e0a2e449/attachment.pl>

From pburns at pburns.seanet.com  Sat Nov 23 19:45:20 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 23 Nov 2013 18:45:20 +0000
Subject: [R] Question about compatibility
In-Reply-To: <CACY5Zsdg9QvfRg3mQYf7TnLDsrdkX-PX-RcHmWBnMcZyhN5NqA@mail.gmail.com>
References: <CACY5Zsdg9QvfRg3mQYf7TnLDsrdkX-PX-RcHmWBnMcZyhN5NqA@mail.gmail.com>
Message-ID: <5290F7C0.10301@pburns.seanet.com>

If you are anything like me, then the main
thing that you could do to win the game is
to type the name of the file correctly.

Given that is a near impossibility for me,
when I'm on Windows I use 'file.choose' to
get the correct name.  Your command would
look like:

example=read.table(file=file.choose(), header=TRUE,sep=",")

The other likely problem is that you and
R are not agreeing on what the working
directory is.  You can see what R thinks it
is by typing:

getwd()

You can change what it thinks it is with
the 'setwd' function (or via the menu --
the file menu in Rgui or session menu in
RStudio).

Welcome to the R world.

Pat


On 23/11/2013 16:49, Juan Manuel Reyes S wrote:
> Dear R- project
>
> I am beginning to work in R. When I was trying to read data for external
> files with command read.table  in R, R was reporting me:
>
>   example=read.table(file="example.text", header=TRUE,sep=",")
>
> Error in file(file, "rt") : It is not posible to open connection
> Adem?s: Mensajes de aviso perdidos
> In file(file, "rt") :
>   It is not posible to open the file  'example.text': No such file or
> directory
>
> I am using office 365 and my computer has Windows 8.
>
> What can I do?
>
> Thank you members of R- project
>
> Juan Manuel
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From halim10-fes at sust.edu  Sat Nov 23 20:00:31 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Sun, 24 Nov 2013 01:00:31 +0600
Subject: [R] Problems dealing with matrices
Message-ID: <20131123181936.M40852@sust.edu>

Dear R-friends,

Hope you doing well. I've been trying to deal with the following problem for 
the couple of days but couldn't come up with a solution. It would be great if 
any of you could give some insight into it.

I have three matrices like:

dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00,
                0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00,
                0.09),nrow=5,ncol=5)
volinp<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)

scvol<-matrix(c(1:40),nrow=5,ncol=8)

What I essentially want to do is to add each value in scvol[1,] with the 
volinp[1,1] and then multiply each new volinp with dcvol and finally put the 
outputs in a new matrix.

Thanks in advance.

Halim                
---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From smartpink111 at yahoo.com  Sat Nov 23 23:07:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 23 Nov 2013 14:07:07 -0800 (PST)
Subject: [R] how to melt variable to one variable
In-Reply-To: <CAK70=f6z+Wmowg3Yg6M-ngVP=F=jJpBhjAyA3dWtXJd8C_u0Cg@mail.gmail.com>
References: <CAK70=f4beYTES7je34AsT-F4hZDN7bHqdHFdVDqrUnPA4AKRtw@mail.gmail.com>	<1385221787.79498.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAK70=f6z+Wmowg3Yg6M-ngVP=F=jJpBhjAyA3dWtXJd8C_u0Cg@mail.gmail.com>
Message-ID: <1385244427.37037.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
I am not getting any errors.

data_chir <- read.table(text="N1_re N2_re N3_re
yes no no
no yes no
na yes yes
no na no",sep="",header=TRUE,stringsAsFactors=FALSE,na.strings="na")
library(reshape2)
melt(data_chir, measure.vars=c("N1_re", "N2_re"), var="zpd")
? N3_re?? zpd value
1??? no N1_re?? yes
2??? no N1_re??? no
3?? yes N1_re? <NA>
4??? no N1_re??? no
5??? no N2_re??? no
6??? no N2_re?? yes
7?? yes N2_re?? yes
8??? no N2_re? <NA>
A.K.




On Saturday, November 23, 2013 5:02 PM, maggy yan <kiotoqq at gmail.com> wrote:

sorry, I forgot that.. the variables look like this:
N1_re N2_re N3_re
yes no no
no yes no
na ye yes
no na no



2013/11/23 arun <smartpink111 at yahoo.com>

Hi,
>You need to make a reproducible example for others to understand the error.?
>?set.seed(49)
>?data_chir <- data.frame(N1_re=sample(c(NA,"yes","no"),100,replace=TRUE),N2_re=sample(c(NA,"yes","no"),100,replace=TRUE),stringsAsFactors=FALSE)
>?melt(data_chir, measure.vars=c("N1_re", "N2_re"), var="zpd") #no errors here.
>
>
>A.K.
>
>
>
>
>
>On Saturday, November 23, 2013 10:07 AM, maggy yan <kiotoqq at gmail.com> wrote:
>I want to make a stacked bar plot with one bar for two variables from my
>data "chir", the two variables have about 100 values like no, yes and na. I
>want to show how many no, yes and na they both have together with the
>stacked bar. I tried to melt these to variables first like this:
>
>melt1=melt(data_chir, measure.vars=c("N1_re", "N2_re"), var="zpd")
>
>but it says " arguments imply differing number of rows: 98, 196"
>
>
>maybe there is another way to make the plot without melt?
>
>thanks in advance!
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From djnordlund at frontier.com  Sat Nov 23 23:54:02 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Sat, 23 Nov 2013 14:54:02 -0800
Subject: [R] Randomize two categories testing a specific condition R
	version 3.0.2 windows 32 bit
In-Reply-To: <CAFuS6E_Z4uPCH6GR1eBBn2WDGQm5ELnnjDB6i53THc0J0UxqWA@mail.gmail.com>
References: <CAFuS6E_Z4uPCH6GR1eBBn2WDGQm5ELnnjDB6i53THc0J0UxqWA@mail.gmail.com>
Message-ID: <29A76998B9B14545A9B7B76217EFA82C@Aragorn>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Manos Spanakis
> Sent: Saturday, November 23, 2013 1:48 AM
> To: R-help at r-project.org
> Subject: [R] Randomize two categories testing a specific condition R
> version 3.0.2 windows 32 bit
> 
> Hello everyone I am new to R. At this time I am trying to create a vector
> so i can randomize two categories a,b under the following conditions :
> Take a random x from random uniform(0,1) if x<0.5 then the vector takes
> value a else takes b . This continues until the number of a's-the number
> of
> b's > 2 at this point i want to change the possibility that a's and b's
> are
> assigned to the vector to 0.2 (if x<0.2 then a). This probability i want
> to
> change again if the number of b's - the number of a's > 2 to 0.8(if x<0.8
> then a). However because i have random numbers i may have the above
> situation vice versa. (first b's-a's>2 then a's-b's>2) .finally sth like
> vector<- a,b,a,a,a,b,b,a . I thought to use a for loop and this is my code
> ;
> 
> set.seed(10)
> x<- rep(NA, 20)
> tmp<- rep(FALSE, 20)for(i in 1:20) {
> x[i]<- runif(1)
> tmp<- x[i]<0.5if(2 * sum(tmp) - i + 1 > 2) {
> tmp[i]<- x[i]<0.2} else {
> tmp[i]<- x[i]<0.8}}
> 
> Although the code runs without errors it doesnt return what i want . How
> 
> am I wrong? Should i have to use next or break statement here or sth else?
> 
> please help me.Thanks in advance
> 

It is not clear to me what your exact boundary conditions are for changing probabilities, or even what your real goal is, but maybe something like the following will get you started.  Stage=1 is before there are greater than 2  'a's and 2 'b's. 

set.seed(3724)
x <- character(0)
p <- .5
stage <- 1
for(i in 1:20){
  x <- c(x, sample(c('a','b'),1,prob=c(p,1-p)))
  suma <- sum(x=='a')
  sumb <- sum(x=='b') 
  #check if first condition is met
  if(suma > 2 & sumb > 2) {
    #select a starting value for changed p value and do this only once
    if(stage == 1) {stage <- 2; if(suma >= sumb) p <-.8 else p <- .2}
    #check for excess of 'a's or 'b's    if(suma - sumb > 2) p <- .2
    if(sumb - suma > 2) p <- .8
    }
}      

If this doesn't do what you want, then write back to R-help describing what your ultimate goal is (i.e., what this method of randomization is supposed to accomplish), and someone may be able to give you better advice.

Hope this is helpful,

Dan 

Daniel Nordlund
Bothell, WA USA
 


From dwarnold45 at suddenlink.net  Sun Nov 24 00:51:30 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 23 Nov 2013 15:51:30 -0800 (PST)
Subject: [R] Label point with (x,hat(y))
Message-ID: <1385250690877-4681049.post@n4.nabble.com>

Hi,

I'd like to do this:

text(1,3,"(x,yhat)",pos=3)

But using (x,hat(y)). Any suggestions?

D.



--
View this message in context: http://r.789695.n4.nabble.com/Label-point-with-x-hat-y-tp4681049.html
Sent from the R help mailing list archive at Nabble.com.


From jorgeivanvelez at gmail.com  Sun Nov 24 03:18:09 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 24 Nov 2013 13:18:09 +1100
Subject: [R] Label point with (x,hat(y))
In-Reply-To: <1385250690877-4681049.post@n4.nabble.com>
References: <1385250690877-4681049.post@n4.nabble.com>
Message-ID: <CAKL8G3Gt_CgH2AS7TpwuvztbDNw0_gsMmMFR-fcyWYGxJzacfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/44169eb8/attachment.pl>

From amie_hunter at hotmail.com  Sat Nov 23 22:39:07 2013
From: amie_hunter at hotmail.com (Amie Hunter)
Date: Sat, 23 Nov 2013 21:39:07 +0000
Subject: [R] Speeding up code
Message-ID: <DUB124-W60450242921F2B111DADB80E30@phx.gbl>

Hello R experts, 

I'm new to R and I'm wanting to know what is the best way to speed up my code. I've read that you can vectorize the code but I'm unsure on how to implement this into my code.


df <- data.frame(31790,31790)

for (i in 1:31790) 
{
? for (j in i:31790) 
? {
??? ken<-cor(cldm[i,3:17],cldm[j,3:17], method="kendall", use="pairwise")
??? dis2<-deg.dist(cldm[i,2],cldm[i,1],cldm[j,2],cldm[j,1])
?? ?
??? df[i,j]<-ifelse(dis2<=500,ken,NA)
??? }
? } 
df

Thanks! 		 	   		  

From ahoerner at rprogress.org  Sun Nov 24 04:38:38 2013
From: ahoerner at rprogress.org (andrewH)
Date: Sat, 23 Nov 2013 19:38:38 -0800 (PST)
Subject: [R] filehash error in the colbycol method for as.data.frame from a
 large object
Message-ID: <1385264317768-4681052.post@n4.nabble.com>

Dear Folks-- 
I have a 14 gig .csv file with 731 columns. I have read it into a colbycol
object (which took overnight ? about 16 hours) using the code below, which
produced no warnings or error messages. The object, CPS62_12, is 49 gig.
After the reading, summary() produced the output below and colnames()
successfully returned the names of all 731 columns.


> CPS62_12 <- cbc.read.table(
+ "C:\\R_PROJ\\INEQ_TRENDS\\TESTS\\monofile_ALLVARS\\cps_00078.csv",
+ header = T, sep = "," )
> summary(CPS62_12)
Object of class colbycol with 8093281 rows and 731 columns.
Data for the object is stored at
C:\DOCUME~1\ADMINI~2\LOCALS~1\Temp\RtmpMj3LRP\dir1a6d82a1df37.
> nrow(CPS62_12)
[1] 8093281
> ncol(CPS62_12)
[1] 731
> colnames(CPS62_12)
  [1] "RECTYPE"     "YEAR"        "SERIAL"      "MISH"  <etc.>

I then ran as.data.frame() (code below) and got the following error and
warning message:

> income_HH_CPS <-as.data.frame(CPS62_12,
+ c(YEAR, STATEFIP, RECTYPE, SERIAL, HWTSUPP, HHINCOME, NUMPREC))
Error in readSingleKey(con, map, key) : 
  unable to obtain value for key 'RECTYPE'
In addition: Warning message:
In readKeyMap(filecon) : NAs introduced by coercion

I tried the command on a number of column name combinations and subsequently
always got the error message without the warning. The error is always on
RECTYPE, which is the name of the first column in the csv file. 

I am as yet not able to reproduce this error on a smaller object. I copied
the first 10 lines of my file into an object by using a connection with
readLines. I evaluated the object in the console, and passed the result into
notepad, and saved it. Then I manually sliced off all but the first 15
variables. The resulting file sailed through the code above and produced a
data frame faultlessly. This undercut my leading theory, which was that the
slash double-quotes (/") that bracketed the column names were causing the
problem. 

I tried running cbc.get.col on the second variable in the file, YEAR. These
two commands:

yearCPS <-cbc.get.col(CPS62_12, YEAR)
yearCPS <-cbc.get.col(CPS62_12, 2)

both resulted in the following error message:

Error in readSingleKey(con, map, key) : 
  unable to obtain value for key 'YEAR'

Note that numerical indexing still returned an error on the variable name,
YEAR. I got the same result for several other variables, returning their own
names

I tracked the error message back to the following function in the filehash
package:

readSingleKey <- function(con, map, key) {
        start <- map[[key]]
        if(is.null(start))
                stop(gettextf("unable to obtain value for key '%s'", key))
        seek(con, start, rw = "read")
        unserialize(con)
}

Now I am at a loss. I see that the element ?key? of the list ?map? has the
value NULL,  that any call to as.data.frame uses RECTYPE as the key, and
that any call to cbc.get.col() uses the passed variable name as a key, even
those that only pass a number.  But I don?t know much of anything about file
hashing, and I have run out of ideas.

Can anyone tell me what I am doing wrong, or whether there is a particular
problem with my file that is likely to be causing this problem, or what my
next diagnostic step should be? Please be aware that I can only do things I
can run on 3 gig of ram.

I am running R under RStudio 0.97.551, on a Widows XP machine with Service
Pack 3.

Sincerely, andrewH




--
View this message in context: http://r.789695.n4.nabble.com/filehash-error-in-the-colbycol-method-for-as-data-frame-from-a-large-object-tp4681052.html
Sent from the R help mailing list archive at Nabble.com.


From halim10-fes at sust.edu  Sun Nov 24 05:22:02 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Sun, 24 Nov 2013 10:22:02 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <20131124042202.M10213@sust.edu>

Hi Arun,

Thank you very much for your response. Sorry, if I couldn't explain clearly. I 
think, I should restate the problem to get exactly what I want. Here it goes:

I have 2 matrices and 1 vector, namely,

dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00,
                0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00,
                0.09),nrow=5,ncol=5)

volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)

volinp<-c(1:40)

What I essentially want to do is to multiply 'dcmat' with 'volmat' and dump 
the output in a new matrix 'vol'. But before that, in the first step, I want 
to add volinp[1] with volmat[1,1]. So, the first column of the output matrix 
'vol' matrix will be:

        [,1]
[1,]   13.13
[2,]   61.61
[3,]   25.25
[4,]    0.00
[5,]    0.00

In the 2nd step, I want to add vol[1,1] with volinp[2]. and replace this value 
with volmat[1,1]. The new 'volmat' will look like:

       [,1]
[1,]   15.13
[2,]    0.00
[3,]    0.00
[4,]    0.00
[5,]    0.00

And then multiply 'dcmat' with the new 'volmat', and the 2nd column of output 
matrix 'vol' will look like:

       [,2]
[1,] 1.9669
[2,] 9.2293
[3,] 3.7825
[4,] 0.0000
[5,] 0.0000

Then again, replace the volmat[1,1] with vol[1,2] + volinp[3] and multiply the 
new 'volmat' with 'dcmat'. This addition, multiplication, and dumping will 
continue up to the length of 'volinp' and the final output matrix 'vol' will 
be something like:

      [,1]    [,2]      [,3]  ...length(volinp)
[1,] 13.13  1.9669  0.645697  ...
[2,] 61.61  9.2293  3.029809  ...
[3,] 25.25  3.7825  1.241725  ...
[4,]  0.00  0.0000  0.000000  ...
[5,]  0.00  0.0000  0.000000  ...   

Within my limited capacity, I've tried to come up with a solution but failed. 

I'll appreciate your/others' help with gratefulness.

Regards,

Halim

---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com
 
On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> Hi,
> Could you show your expected output?? It is a bit unclear from the 
description.
> 
> On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> fes at sust.edu> wrote: Dear R-friends,
> 
> Hope you doing well. I've been trying to deal with the following 
> problem for the couple of days but couldn't come up with a solution. 
> It would be great if any of you could give some insight into it.
> 
> I have three matrices like:
> 
> dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
volinp<-
> matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> 
> scvol<-matrix(c(1:40),nrow=5,ncol=8)
> 
> What I essentially want to do is to add each value in scvol[1,] with 
> the volinp[1,1] and then multiply each new volinp with dcvol and 
> finally put the outputs in a new matrix.
> 
> Thanks in advance.
> 
> Halim? ? ? ? ? ? ? ? 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From pradeep.babu at gmail.com  Sun Nov 24 06:04:02 2013
From: pradeep.babu at gmail.com (Pradeep Babu S.)
Date: Sun, 24 Nov 2013 10:34:02 +0530
Subject: [R] How should I specify partially crossed random effects in lme?
Message-ID: <CAJv2FdB_gcyQ62bywSHWy6HXUZoXPTFN9-vq-9A=Bdrfd72kMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/7a54dcf2/attachment.pl>

From halim10-fes at sust.edu  Sun Nov 24 06:12:33 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Sun, 24 Nov 2013 11:12:33 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <20131124051233.M87627@sust.edu>


Please apologize me! Earlier I've sent a message erroneously. Following is the 
original problem for which I'm seeking help. Extremely sorry...  


Hi Arun,

Thank you very much for your response. Sorry, if I couldn't explain clearly. I 
think, I should restate the problem to get exactly what I want. Here it goes:

I have 2 matrices and 1 vector, namely,

dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00,
                0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00,
                0.09),nrow=5,ncol=5)

volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)

volinp<-c(1:40)

What I essentially want to do is to multiply 'dcmat' with 'volmat' and dump 
the output in a new matrix 'vol'. But before that, in the first step, I want 
to add volinp[1] with volmat[1,1]. So, the first column of the output matrix 
'vol' matrix will be:

        [,1]
[1,]   13.13
[2,]   61.61
[3,]   25.25
[4,]    0.00
[5,]    0.00

In the 2nd step, I want to replace 'volmat' with vol[,1] and add volinp[2] 
with vol[1,1]. The new 'volmat' will look like:

        [,1]
[1,]   15.13
[2,]   61.61
[3,]   25.25
[4,]    0.00
[5,]    0.00

Then multiply 'dcmat' with the new 'volmat', and the 2nd column of output 
matrix 'vol' will look like:

        [,2]
[1,]  1.9669
[2,] 41.2665
[3,] 41.2232
[4,] 13.1199
[5,]  2.7775

Then again, replace the 'volmat' with vol[,2], add volinp[3] with vol[1,2] and 
multiply the new 'volmat' with 'dcmat'. This replacement, addition, 
multiplication, and dumping will continue up to the length of 'volinp' and the 
final output matrix 'vol' will be something like:

      [,1]    [,2]      [,3]    ...length(volinp)
[1,] 13.13   1.9669   0.645697  ...
[2,] 61.61  41.2665  24.488389  ...
[3,] 25.25  41.2232  40.419786  ...
[4,]  0.00  13.1199  22.116099  ...
[5,]  0.00   2.7775   7.670905  ...   

Within my limited capacity, I've tried to come up with a solution but failed. 

I'll appreciate your/others' help with gratefulness.

Regards,

Halim

---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com
 
On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> Hi,
> Could you show your expected output?? It is a bit unclear from the 
description.
> 
> On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> fes at sust.edu> wrote: Dear R-friends,
> 
> Hope you doing well. I've been trying to deal with the following 
> problem for the couple of days but couldn't come up with a solution. 
> It would be great if any of you could give some insight into it.
> 
> I have three matrices like:
> 
> dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
volinp<-
> matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> 
> scvol<-matrix(c(1:40),nrow=5,ncol=8)
> 
> What I essentially want to do is to add each value in scvol[1,] with 
> the volinp[1,1] and then multiply each new volinp with dcvol and 
> finally put the outputs in a new matrix.
> 
> Thanks in advance.
> 
> Halim? ? ? ? ? ? ? ? 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From jdnewmil at dcn.davis.CA.us  Sun Nov 24 08:43:58 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 23 Nov 2013 23:43:58 -0800
Subject: [R] Speeding up code
In-Reply-To: <DUB124-W60450242921F2B111DADB80E30@phx.gbl>
References: <DUB124-W60450242921F2B111DADB80E30@phx.gbl>
Message-ID: <7a7df444-09a9-423c-af6c-f5226acae650@email.android.com>

What is cldm?

We (and therefore you, to verify that we can) should be able to copy the example from the email and paste it into a newly-started instance of R. Not having some example data similar to yours to work with puts us at a major disadvantage. It would also be helpful to know what you are trying to accomplish (description).

You might want to use the str function to understand what each object you are creating really is. I don't know what you want the "df" object to be, but a data frame of two values in default-named columns is unusual. You may be confusing matrices with data frames?

(Note that there is a function called df in the core libraries, so you might want to avoid using that name to avoid confusion.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Amie Hunter <amie_hunter at hotmail.com> wrote:
>Hello R experts, 
>
>I'm new to R and I'm wanting to know what is the best way to speed up
>my code. I've read that you can vectorize the code but I'm unsure on
>how to implement this into my code.
>
>
>df <- data.frame(31790,31790)
>
>for (i in 1:31790) 
>{
>? for (j in i:31790) 
>? {
>??? ken<-cor(cldm[i,3:17],cldm[j,3:17], method="kendall",
>use="pairwise")
>??? dis2<-deg.dist(cldm[i,2],cldm[i,1],cldm[j,2],cldm[j,1])
>?? ?
>??? df[i,j]<-ifelse(dis2<=500,ken,NA)
>??? }
>? } 
>df
>
>Thanks! 		 	   		  
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Nov 24 09:37:07 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 24 Nov 2013 00:37:07 -0800 (PST)
Subject: [R] Problems dealing with matrices
In-Reply-To: <20131124051233.M87627@sust.edu>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
Message-ID: <alpine.BSF.2.00.1311240013490.75552@pedal.dcn.davis.ca.us>

I think the following is a pretty literal translation from your 
description. Looks like a linear difference equation with a ramp forcing 
function.

wt <- matrix( c(1,0,0,0,0 ), nrow=5 )
vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
vol[ , 1 ] <- dcmat %*% ( volmat + wt )

for ( idx in volinp[ -1 ] ) {
   vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + idx * wt )
}

On Sun, 24 Nov 2013, halim10-fes wrote:

>
> Please apologize me! Earlier I've sent a message erroneously. Following is the
> original problem for which I'm seeking help. Extremely sorry...
>
>
> Hi Arun,
>
> Thank you very much for your response. Sorry, if I couldn't explain clearly. I
> think, I should restate the problem to get exactly what I want. Here it goes:
>
> I have 2 matrices and 1 vector, namely,
>
> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00,
>                0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00,
>                0.09),nrow=5,ncol=5)
>
> volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
>
> volinp<-c(1:40)
>
> What I essentially want to do is to multiply 'dcmat' with 'volmat' and dump
> the output in a new matrix 'vol'. But before that, in the first step, I want
> to add volinp[1] with volmat[1,1]. So, the first column of the output matrix
> 'vol' matrix will be:
>
>        [,1]
> [1,]   13.13
> [2,]   61.61
> [3,]   25.25
> [4,]    0.00
> [5,]    0.00
>
> In the 2nd step, I want to replace 'volmat' with vol[,1] and add volinp[2]
> with vol[1,1]. The new 'volmat' will look like:
>
>        [,1]
> [1,]   15.13
> [2,]   61.61
> [3,]   25.25
> [4,]    0.00
> [5,]    0.00
>
> Then multiply 'dcmat' with the new 'volmat', and the 2nd column of output
> matrix 'vol' will look like:
>
>        [,2]
> [1,]  1.9669
> [2,] 41.2665
> [3,] 41.2232
> [4,] 13.1199
> [5,]  2.7775
>
> Then again, replace the 'volmat' with vol[,2], add volinp[3] with vol[1,2] and
> multiply the new 'volmat' with 'dcmat'. This replacement, addition,
> multiplication, and dumping will continue up to the length of 'volinp' and the
> final output matrix 'vol' will be something like:
>
>      [,1]    [,2]      [,3]    ...length(volinp)
> [1,] 13.13   1.9669   0.645697  ...
> [2,] 61.61  41.2665  24.488389  ...
> [3,] 25.25  41.2232  40.419786  ...
> [4,]  0.00  13.1199  22.116099  ...
> [5,]  0.00   2.7775   7.670905  ...
>
> Within my limited capacity, I've tried to come up with a solution but failed.
>
> I'll appreciate your/others' help with gratefulness.
>
> Regards,
>
> Halim
>
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
>
> On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
>> Hi,
>> Could you show your expected output?? It is a bit unclear from the
> description.
>>
>> On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
>> fes at sust.edu> wrote: Dear R-friends,
>>
>> Hope you doing well. I've been trying to deal with the following
>> problem for the couple of days but couldn't come up with a solution.
>> It would be great if any of you could give some insight into it.
>>
>> I have three matrices like:
>>
>> dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
>> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
>> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> volinp<-
>> matrix(c(100,0,0,0,0),nrow=5,ncol=1)
>>
>> scvol<-matrix(c(1:40),nrow=5,ncol=8)
>>
>> What I essentially want to do is to add each value in scvol[1,] with
>> the volinp[1,1] and then multiply each new volinp with dcvol and
>> finally put the outputs in a new matrix.
>>
>> Thanks in advance.
>>
>> Halim? ? ? ? ? ? ? ?
>> ---------------
>> Md. Abdul Halim
>> Assistant Professor
>> Department of Forestry and Environmental Science
>> Shahjalal University of Science and Technology,Sylhet-3114,
>> Bangladesh.
>> Cell: +8801714078386.
>> alt. e-mail: xou03 at yahoo.com
>>
>> --
>> This message has been scanned for viruses and
>> dangerous content by MailScanner, and is
>> believed to be clean.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From safisce at gmail.com  Sun Nov 24 10:03:48 2013
From: safisce at gmail.com (Safiye Celik)
Date: Sun, 24 Nov 2013 01:03:48 -0800
Subject: [R] GotoBLAS2 with multiple cores
Message-ID: <CAJRSaT_6ZWNAdfUdrSvS_i5g6g0roq3TjFmkq3hALSLBGmhA4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/29c6437d/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Nov 24 10:21:56 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 24 Nov 2013 09:21:56 +0000
Subject: [R] GotoBLAS2 with multiple cores
In-Reply-To: <CAJRSaT_6ZWNAdfUdrSvS_i5g6g0roq3TjFmkq3hALSLBGmhA4w@mail.gmail.com>
References: <CAJRSaT_6ZWNAdfUdrSvS_i5g6g0roq3TjFmkq3hALSLBGmhA4w@mail.gmail.com>
Message-ID: <5291C534.3070605@stats.ox.ac.uk>

This really is the wrong list (R-devel or R-SIG-HPC?): see the posting 
guide.  But there are two issues.

- How your BLAS controls its core usage (which is in its documentation).

- How your third-party package interacts with a BLAS which uses multiple 
cores, and for that you need to ask the package maintainers.

On 24/11/2013 09:03, Safiye Celik wrote:
> Hi,
>
> I am trying to use GotoBLAS2 on R 3.0 on Unix. I downloaded GotoBLAS2
> source code from TACC web site, compiled it, and replaced libRblas.so with
> libgoto2.so, following the instructions at the link
> http://www.rochester.edu/college/gradstudents/jolmsted/files/computing/BLAS.pdf.

Much better to use the definitive R documentation at 
http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Shared-BLAS .

> The simple matrix operations in R like "determinant" are 20 times faster
> than before (I am using huge matrices), which is good. However, I cannot
> use many cores in parallel now.
>
> For example, below code runs forever. But if I use commented out "for"
> instead of "foreach", it takes just a second. When I was using R's default
> BLAS library, I could run below code (using many cores) (but it took more
> time since BLAS was not optimized, of course)..
>
> library("foreach")
> library("doParallel")
>
> registerDoParallel(cores=2)set.seed(100)
> foreach (i = 1:2) %dopar% {# for (i in 1:2) {
> a = replicate(1000, rnorm(1000))
> d = determinant(a)
>
> So, is it possible to use many cores at the same time with GotoBLAS2, do
> you have any ideas?
>
> Thanks a lot in advance.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From halim10-fes at sust.edu  Sun Nov 24 11:31:59 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Sun, 24 Nov 2013 16:31:59 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <alpine.BSF.2.00.1311240013490.75552@pedal.dcn.davis.ca.us>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<alpine.BSF.2.00.1311240013490.75552@pedal.dcn.davis.ca.us>
Message-ID: <20131124102354.M60339@sust.edu>

Hi Jeff,

Thank you very much for your response. Your code produced exactly the same as 
I described. I also like your idea of including 'wt' matrix. Can you please 
suggest me if the 'volinp' is not sequential? Consider a new 'volinp', like:  

volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)

How can I deal with this?

Regards,

Halim

On Sun, 24 Nov 2013 00:37:07 -0800 (PST), Jeff Newmiller wrote
> I think the following is a pretty literal translation from your 
> description. Looks like a linear difference equation with a ramp 
> forcing function.
> 
> wt <- matrix( c(1,0,0,0,0 ), nrow=5 )
> vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> 
> for ( idx in volinp[ -1 ] ) {
>    vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + idx * wt )
> }
> 
> On Sun, 24 Nov 2013, halim10-fes wrote:
> 
> >
> > Please apologize me! Earlier I've sent a message erroneously. Following is 
the
> > original problem for which I'm seeking help. Extremely sorry...
> >
> >
> > Hi Arun,
> >
> > Thank you very much for your response. Sorry, if I couldn't explain 
clearly. I
> > think, I should restate the problem to get exactly what I want. Here it 
goes:
> >
> > I have 2 matrices and 1 vector, namely,
> >
> > dcmat<-
matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00,
> >                
0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00,
> >                0.09),nrow=5,ncol=5)
> >
> > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> >
> > volinp<-c(1:40)
> >
> > What I essentially want to do is to multiply 'dcmat' with 'volmat' and 
dump
> > the output in a new matrix 'vol'. But before that, in the first step, I 
want
> > to add volinp[1] with volmat[1,1]. So, the first column of the output 
matrix
> > 'vol' matrix will be:
> >
> >        [,1]
> > [1,]   13.13
> > [2,]   61.61
> > [3,]   25.25
> > [4,]    0.00
> > [5,]    0.00
> >
> > In the 2nd step, I want to replace 'volmat' with vol[,1] and add volinp[2]
> > with vol[1,1]. The new 'volmat' will look like:
> >
> >        [,1]
> > [1,]   15.13
> > [2,]   61.61
> > [3,]   25.25
> > [4,]    0.00
> > [5,]    0.00
> >
> > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of output
> > matrix 'vol' will look like:
> >
> >        [,2]
> > [1,]  1.9669
> > [2,] 41.2665
> > [3,] 41.2232
> > [4,] 13.1199
> > [5,]  2.7775
> >
> > Then again, replace the 'volmat' with vol[,2], add volinp[3] with vol[1,2] 
and
> > multiply the new 'volmat' with 'dcmat'. This replacement, addition,
> > multiplication, and dumping will continue up to the length of 'volinp' and 
the
> > final output matrix 'vol' will be something like:
> >
> >      [,1]    [,2]      [,3]    ...length(volinp)
> > [1,] 13.13   1.9669   0.645697  ...
> > [2,] 61.61  41.2665  24.488389  ...
> > [3,] 25.25  41.2232  40.419786  ...
> > [4,]  0.00  13.1199  22.116099  ...
> > [5,]  0.00   2.7775   7.670905  ...
> >
> > Within my limited capacity, I've tried to come up with a solution but 
failed.
> >
> > I'll appreciate your/others' help with gratefulness.
> >
> > Regards,
> >
> > Halim
> >
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> >
> > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> >> Hi,
> >> Could you show your expected output?? It is a bit unclear from the
> > description.
> >>
> >> On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> >> fes at sust.edu> wrote: Dear R-friends,
> >>
> >> Hope you doing well. I've been trying to deal with the following
> >> problem for the couple of days but couldn't come up with a solution.
> >> It would be great if any of you could give some insight into it.
> >>
> >> I have three matrices like:
> >>
> >> dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> >> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> >> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > volinp<-
> >> matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> >>
> >> scvol<-matrix(c(1:40),nrow=5,ncol=8)
> >>
> >> What I essentially want to do is to add each value in scvol[1,] with
> >> the volinp[1,1] and then multiply each new volinp with dcvol and
> >> finally put the outputs in a new matrix.
> >>
> >> Thanks in advance.
> >>
> >> Halim? ? ? ? ? ? ? ?
> >> ---------------
> >> Md. Abdul Halim
> >> Assistant Professor
> >> Department of Forestry and Environmental Science
> >> Shahjalal University of Science and Technology,Sylhet-3114,
> >> Bangladesh.
> >> Cell: +8801714078386.
> >> alt. e-mail: xou03 at yahoo.com
> >>
> >> --
> >> This message has been scanned for viruses and
> >> dangerous content by MailScanner, and is
> >> believed to be clean.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  
> Live Go...                                       Live:   OO#.. Dead: 
> OO#..  Playing Research Engineer (Solar/Batteries            O.O#.   
>     #.O#.  with /Software/Embedded Controllers)               .OO#.  
>      .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com

-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From luis_cerchiaro at hotmail.com  Sun Nov 24 10:08:45 2013
From: luis_cerchiaro at hotmail.com (Luis Miguel Cerchiaro Barros)
Date: Sun, 24 Nov 2013 10:08:45 +0100
Subject: [R] create a new dataframe with intervals and computing a weighted
 average for each of its rows
Message-ID: <DUB123-W95AE659A25F6ADDE5FB1EF9E20@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/707fa775/attachment.pl>

From gunter.berton at gene.com  Sun Nov 24 16:19:24 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 24 Nov 2013 07:19:24 -0800
Subject: [R] create a new dataframe with intervals and computing a
 weighted average for each of its rows
In-Reply-To: <DUB123-W95AE659A25F6ADDE5FB1EF9E20@phx.gbl>
References: <DUB123-W95AE659A25F6ADDE5FB1EF9E20@phx.gbl>
Message-ID: <CACk-te0eyfoRsi-mE0ym6Oo84Ecp4v0tQoAF_A7gupOVg3sxng@mail.gmail.com>

This post is complete garbage, and a great example of why not
bothering to read or follow the posting guide will cause a post to be
ignored.

1. It was not posted in plain text as the posting guide asks.

2. dput() was not used to pass example data

3. It appears the OP has not done due diligence by going through the
Introduction to R or other online tutorials to learn how R works,
although the post was so garbled that I may be wrong about that. My
apology, if so.

Cheers,
Bert



On Sun, Nov 24, 2013 at 1:08 AM, Luis Miguel Cerchiaro Barros
<luis_cerchiaro at hotmail.com> wrote:
>
>
>
>
> I need you help with this problem, I have a data-frame like this:
>     BHID=c(43,43,43,43,44,44,44,44,44)    FROM=c(50.9,46.7,44.2,43.1,52.3,51.9,49.3,46.2,42.38)    TO=c(46.7,44.2,43.1,40.9,51.9,49.3,46.2,42.38,36.3)    AR=c(45,46,0.0,38.45,50.05,22.9,0,25,9)    DF<-data.frame(BHID,FROM,TO,VALUE)        #add the length     DF$LENGTH=DF$FROM-DF$TO
> where:
> + BHID: is the borehole identification+ FROM: is  the start for every interval+ TO: is the end for every interval+ AR: is the value of our variable+ LENGTH: is the distance between FROM and TO
> what I want, is create a data frame which is "normalized", it means that every interval has the same length and the column **AR** is calculated as a Weighted arithmetic mean from the old **AR** and  **LENGTH** as its weight.
> For more clarity I going to show you how should look the desire data frame.
>     BHID        FROM    TO          AR          LENGTH    43        50.9        47.9       45.0     3.0    43       47.9        44.9       45.6     3.0    43       44.9        41.9       26.113      3.0    43            41.9        40.9    38.45        1.0    44....
> where:
> 1. AR is the Weighted arithmetic mean
> I have to make a clarification about the result:
> here I attached an example of my excel table with calculations:
>     ROW_ID BHID NEW_FROM NEW_TO NEW_AR  OLD_FROM OLD_TO WEIGHTS OLD_AR    1                 43   50.9         47.9              45               50.9    46.7              3.0      45    2                 43   47.9         44.9              45.6             50.9    46.7              1.2      45    2                 43   47.9         44.9                               46.7    44.2              1.8      46    3                 43   44.9         41.9              26.113    46.7   44.2              0.7      46    3                 43   44.9         41.9                                44.2   43.1              1.1      0    3                  43   44.9         41.9                               43.1    40.9              1.2      38.45    4              43   41.9         40.9              38.45     43.1   40.9              1.0      38.45
>
> you see guys, the NEW_AR is the weighted mean of the OLD_AR and its weights are in the column WEIGHTS.
> If you see the column LENGTH in the original data frame you can see, that the values are different, with the "normalization" we try to make that LENGTH uniform, in this case we choose the value 3.0 of course the last value of each borehole data could had a different LENGTH in this case 1.0
> What I have done to achieve the result
> OK guys in first place I have to say, I am not a professional and I am still learning  how to use R,
> my approximation is not elegant, I am trying to take the start and end of each borehole and use the function skeleton what I wrote, to create an uniform skeleton for the whole dataframe.
>     skeleton<-function(DF,LEN){    # define function to create a new skeleton    divide.int<-function(FROM,TO,div){    n=as.integer((FROM-TO)/div)+1    from=seq(FROM,(FROM-(n-1)*div),-div)    to=seq(FROM-(n-(n-1))*div,FROM-(n-1)*div,-div)    to[n]=TO    range<-data.frame(BHID=borehole_names[i,1],FROM=from,TO=to) # create a data.frame class object    range<-range[!(range$FROM==range$TO),] # erase the last value    }    # subset the data set for every borehole    borehole_names<-unique(DF["BHID"]) # collars id with cores    borehole_number<-nrow(borehole_names)  # collar number    #define an empty data.frame     borehole_Out<-data.frame(BHID=integer(),FROM=numeric(),TO=numeric())    # initialize the counter    i=1    # from this point starts the loop---------------    while(i<=borehole_number){    DFi <- subset(DF, BHID %in% borehole_names[i,1]) # Individual data frame for each boreholes    # take the beginning and end of every BOREHOLE    startBH<-head(DFi$FROM,1)    endBH<-t!
>  ail(DFi$TO,1)    # create the normalized intervals    borehole_i<-divide.int(FROM=startBH,TO=endBH,div=LEN)    borehole_Out<-rbind(borehole_Out,borehole_i)    i=i+1    }    borehole_Out    }    # TEST------------------------------------------    TEST<-skeleton(DF=DF,LEN=3.0)    TEST$LENGTH=TEST$FROM-TEST$TO
> later I am trying to use the packages PLYR or DATA.TABLE to calculate the weighted means in AR but as I said I just started to use R and don't understand yet how this packages work
> again thanks in advanced and sorry for my bumpy english
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From gunter.berton at gene.com  Sun Nov 24 16:21:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 24 Nov 2013 07:21:16 -0800
Subject: [R] How should I specify partially crossed random effects in
	lme?
In-Reply-To: <CAJv2FdB_gcyQ62bywSHWy6HXUZoXPTFN9-vq-9A=Bdrfd72kMw@mail.gmail.com>
References: <CAJv2FdB_gcyQ62bywSHWy6HXUZoXPTFN9-vq-9A=Bdrfd72kMw@mail.gmail.com>
Message-ID: <CACk-te0NfMuUEtUJRyCukSmJJoFBULcwf3E=RCp70Gg7Dx5S-A@mail.gmail.com>

You are more likely to get a useful response on the r-sig-mixed-models
list rather than here.

Cheers,
Bert

On Sat, Nov 23, 2013 at 9:04 PM, Pradeep Babu S. <pradeep.babu at gmail.com> wrote:
> Dear all,
> I am new to R and would like your help with lme formula for partially
> crossed random effect in a random-intercept, random-slope model.
> In the longitudinal data I have, each subject (barring some dropouts) was
> tested at 5 different occasions. The standardized tests were administered
> by 3 different examiners, with 2 of them present at all occasions, and the
> 3rd one administering tests only on the last two occasions. The subjects
> were randomly assigned to the examiners.
> I tested the following models:
> model1<-lme(score~time*covariate,random=~time|subject,method="REML",na.action=na.omit,data=dat)
> model2<-lme(score~time*covariate,random=list(examiner=~1,subject=~time),method="REML",na.action=na.omit,data=dat)
>
> anova(model1,model2) gives p<0.05 with better model fit for model2.
>
> I would like to know if model2 is the correct way to specify the partially
> crossed random effect in the data I described.
>
> thanks!
> Pradeep Babu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwarnold45 at suddenlink.net  Sun Nov 24 17:20:15 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sun, 24 Nov 2013 08:20:15 -0800 (PST)
Subject: [R] Label point with (x,hat(y))
In-Reply-To: <1385250690877-4681049.post@n4.nabble.com>
References: <1385250690877-4681049.post@n4.nabble.com>
Message-ID: <1385310015145-4681065.post@n4.nabble.com>

Thanks, that worked well.

D.



--
View this message in context: http://r.789695.n4.nabble.com/Label-point-with-x-hat-y-tp4681049p4681065.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Sun Nov 24 16:45:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 24 Nov 2013 07:45:24 -0800 (PST)
Subject: [R] Problems dealing with matrices
In-Reply-To: <20131124103317.M34808@sust.edu>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
Message-ID: <1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Halim,
I guess this works for you.? Modifying Jeff's solution:

volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
vol1 <- dcmat %*% (volmat +wt)
for(idx in seq_along(volinp)[-1]){
?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
?}

#or

vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
vol[ , 1 ] <- dcmat %*% ( volmat + wt )

for ( idx in seq_along(volinp)[ -1 ] ) {
? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
}
identical(vol,vol1)
#[1] TRUE


A.K.


On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-fes at sust.edu> wrote:
Hi Arun,

OK, no problem. Thank you very much for your attention. I've posted an annex 
to my previous problem. I will appreciate your comments/suggestions on it.

Off-topic: You're a very helpful man. I like your attitude to helping others.

Take care.

Halim

On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> Hi,
> Please disregard my earlier message. Looks like Jeff understand it 
> better and answered it. Regards, Arun
> 
> On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> I am finding some inconsistency with your description.
> For example:
> volinp[1]+volmat[1,1]
> [1] 101
> 
> On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> fes at sust.edu> wrote:
> 
> Please apologize me! Earlier I've sent a message erroneously. 
> Following is the original problem for which I'm seeking help. 
> Extremely sorry...?
> 
> Hi Arun,
> 
> Thank you very much for your response. Sorry, if I couldn't explain 
> clearly. I think, I should restate the problem to get exactly what I 
> want. Here it goes:
> 
> I have 2 matrices and 1 vector, namely,
> 
> dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> 
> volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> 
> volinp<-c(1:40)
> 
> What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> and dump the output in a new matrix 'vol'. But before that, in the 
> first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> column of the output matrix 'vol' matrix will be:
> 
> ? ? ? ? [,1]
> [1,]?? 13.13
> [2,]?? 61.61
> [3,]?? 25.25
> [4,]? ? 0.00
> [5,]? ? 0.00
> 
> In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> volinp[2] with vol[1,1]. The new 'volmat' will look like:
> 
> ? ? ? ? [,1]
> [1,]?? 15.13
> [2,]?? 61.61
> [3,]?? 25.25
> [4,]? ? 0.00
> [5,]? ? 0.00
> 
> Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> output matrix 'vol' will look like:
> 
> ? ? ? ? [,2]
> [1,]? 1.9669
> [2,] 41.2665
> [3,] 41.2232
> [4,] 13.1199
> [5,]? 2.7775
> 
> Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> replacement, addition, multiplication, and dumping will continue up 
> to the length of 'volinp' and the final output matrix 'vol' will be 
> something like:
> 
> ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> [1,] 13.13?? 1.9669?? 0.645697? ...
> [2,] 61.61? 41.2665? 24.488389? ...
> [3,] 25.25? 41.2232? 40.419786? ...
> [4,]? 0.00? 13.1199? 22.116099? ...
> [5,]? 0.00?? 2.7775?? 7.670905? ...?
> 
> Within my limited capacity, I've tried to come up with a solution 
> but failed.
> 
> I'll appreciate your/others' help with gratefulness.
> 
> Regards,
> 
> Halim
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > Hi,
> > Could you show your expected output?? It is a bit unclear from the 
> description.
> > 
> > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > fes at sust.edu> wrote: Dear R-friends,
> > 
> > Hope you doing well. I've been trying to deal with the following 
> > problem for the couple of days but couldn't come up with a solution. 
> > It would be great if any of you could give some insight into it.
> > 
> > I have three matrices like:
> > 
> > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> volinp<-
> > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > 
> > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > 
> > What I essentially want to do is to add each value in scvol[1,] with 
> > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > finally put the outputs in a new matrix.
> > 
> > Thanks in advance.
> > 
> > Halim? ? ? ? ? ? ? ? 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.



---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From gunter.berton at gene.com  Sun Nov 24 18:13:30 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 24 Nov 2013 09:13:30 -0800
Subject: [R] Should there be an R-beginners list?
Message-ID: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>

Folks:

If this has been previously discussed and settled, please say so and
refer me to the discussion. If you believe this to be inappropriate or
otherwise frivolous, also please say so, as I do not wish to waste
your time or this space.

I write as a long time reader and sometimes contributor to r-help. Due
to R's growth in usage by a broad data analysis community (engineers,
scientists, social scientists, finance, "informaticians", as well as
more "traditional" statisticians), this list seems to me to becoming
deluged by requests for help by "casual" users and students for whom R
is not going to be regularly or extensively used. I would characterize
this group as having only basic statistical, programming, and data
analysis skills. This is not meant as a criticism, and there are
certainly many for whom this is inaccurate. But ...

By and large, such users have not spend much time with R's docs,
including tutorials or FAQ's. Many of their posts reflect this, and
can be answered with basic replies or references to docs, to wit: What
is the difference between "ifelse" and "if else"? FAQ 7.31. Confusion
of data frames, matrices, and spreadsheet tables; etc.

Would it be useful, then, to establish an R-beginners list
specifically to absorb this traffic and free up R-help from what I
would say was its original intent, to provide a forum for serious,
more dedicated R users (Again, no criticism is intended here)?

I realize that, whether or not this suggestion is worthwhile, there
are several ways it could fail. First, too few might be interested in
responding to posts on the new list. Second, too few might consider
themselves "beginners" who post to it. Etc. So I would certainly say
any such effort ought to be a pilot and tentative .

I'll stop here. Again, criticize freely and/or send me off somewhere
else to prior discussion. Or to where it should be discussed. Or just
ignore, of course.

Best,
Bert



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From nhoughton01 at gmail.com  Sun Nov 24 17:49:03 2013
From: nhoughton01 at gmail.com (Natalie Houghton McNair)
Date: Sun, 24 Nov 2013 08:49:03 -0800
Subject: [R] Plotting multiple trends on one graph
Message-ID: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/d149c38e/attachment.pl>

From xie at yihui.name  Sun Nov 24 20:04:43 2013
From: xie at yihui.name (Yihui Xie)
Date: Sun, 24 Nov 2013 13:04:43 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
Message-ID: <CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>

I'm not aware of a discussion on this, but I would say no.
Fragmentation is bad. Further fragmentation is worse.

TL;DR
=====

Actually I'd say all mailing lists except r-devel should be moving to
StackOverlow in the future (disclaimer: I'm not affiliated with it).
Mailing lists are good for a smaller group of people, and especially
good when more focused on discussions on development (including bug
reports). The better place for questions is a web forum. Both you and
I have been staying in these R mailing lists for a few years now. You
can recall how many times a user was asked to post to another mailing
list ("this is not an appropriate list to ask your question; please
post to r-such-and-such instead"), how many times you see something
like "Alternative HTML removed", how many times you see a post "Bla
Bla (was: Foo Bar)", and how many times users were reminded "Please
read the posting guide", "Please do read", and "PLEASE do read". But
it just does not help much even if you write "PLEASE DO READ".

Why do we have such problems in the mailing lists again and again? Is
that simply because users are not respecting the rules? I do not think
so. I believe that is the flaw of mailing lists. A mailing list is
managed by a small team (hey, Martin, thank you). On StackOverflow,
you simply edit the tags of a post to make it belong to a new "mailing
list" (you can post with tags "r+ubuntu+graphics", or "r+lattice",
etc). There is no need to request and wait for the system admin to
make a decision. Users can help themselves, and help others as well.
HTML can be good in many cases, actually. Who hates syntax
highlighting and R plots in an R question? You are free to ask a
question that is poorly formatted, and there are good chances that it
will be immediately edited by another experienced user. You are free
to yell in the comments asking for more details before posting a
formal answer. You can express "ah, this is a bad question" by
down-voting so that future readers know that guy screwed up and we
just let the world ignore the noise. It is like peer-review, and the
reviewers can help you improve your post. In a mailing list, when you
are done, you are done. You are forever written in history, right or
wrong, smart or stupid. You want to delete your record in the history?
No, no, gentleman, it was your fault not reading the post guide.

For me, I understand all the rationale behind the mailing list model.
I'm just saying, the primary goal for such a service is to discuss
issues about R, instead of issues induced by the mailing list itself.
We could have made some issues not directly related to R go away by
community efforts instead of giving instructions a million times,
given an appropriate platform.

Five years, 42,000 posts: http://stackoverflow.com/questions/tagged/r
I'm not terribly worried about transition from mailing lists to SO.

Sorry about the generalization of the original topic, but I hate using
a new title "Should there be R mailing lists? (was: Should there be an
R-beginners list?)"

Last but not least, I probably need to clarify that I benefited a lot
from the mailing lists in the past, and I truly appreciate it. I wrote
this with the future in mind, not the past. The past was good, and the
future can be better.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Sun, Nov 24, 2013 at 11:13 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Folks:
>
> If this has been previously discussed and settled, please say so and
> refer me to the discussion. If you believe this to be inappropriate or
> otherwise frivolous, also please say so, as I do not wish to waste
> your time or this space.
>
> I write as a long time reader and sometimes contributor to r-help. Due
> to R's growth in usage by a broad data analysis community (engineers,
> scientists, social scientists, finance, "informaticians", as well as
> more "traditional" statisticians), this list seems to me to becoming
> deluged by requests for help by "casual" users and students for whom R
> is not going to be regularly or extensively used. I would characterize
> this group as having only basic statistical, programming, and data
> analysis skills. This is not meant as a criticism, and there are
> certainly many for whom this is inaccurate. But ...
>
> By and large, such users have not spend much time with R's docs,
> including tutorials or FAQ's. Many of their posts reflect this, and
> can be answered with basic replies or references to docs, to wit: What
> is the difference between "ifelse" and "if else"? FAQ 7.31. Confusion
> of data frames, matrices, and spreadsheet tables; etc.
>
> Would it be useful, then, to establish an R-beginners list
> specifically to absorb this traffic and free up R-help from what I
> would say was its original intent, to provide a forum for serious,
> more dedicated R users (Again, no criticism is intended here)?
>
> I realize that, whether or not this suggestion is worthwhile, there
> are several ways it could fail. First, too few might be interested in
> responding to posts on the new list. Second, too few might consider
> themselves "beginners" who post to it. Etc. So I would certainly say
> any such effort ought to be a pilot and tentative .
>
> I'll stop here. Again, criticize freely and/or send me off somewhere
> else to prior discussion. Or to where it should be discussed. Or just
> ignore, of course.
>
> Best,
> Bert
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> (650) 467-7374
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwarnold45 at suddenlink.net  Sun Nov 24 20:42:05 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sun, 24 Nov 2013 11:42:05 -0800 (PST)
Subject: [R] Creating a set that has line of best fit y=3+2x so that SST, SSR,
 SSE are whole numbers
Message-ID: <1385322125912-4681074.post@n4.nabble.com>

I wanted to find a set (x,y) of integers so that their line of best fit was y
= 3 + 2x. So I thought I'd be losing 2 degrees of freedom and chose

1,2,3,4, and x

for my explanatory data and 

3, 8, 8, 12, and y

for my response data. I then used b = (n sum(xy) - sum(x)sum(y))/(n sum(x^2)
- (sum(x))^2) to determine the equation
2=(5(xy+91)-(x+10)(y+31))/(5(x^2+30)-(x+10)^2). Then, because (mean(x),
mean(y)) lies on the line of best fit, and mean(x)=(x+10)/5 and
mean(y)=(y+31)/5, subbing them gave me the equation y=2x+4. Subbing that
into my first equation gave me x=-1 and y=2.

Sure enough:
x <- c(-1,1,2,3,4)
y <- c(2,3,8,8,12)
plot(x,y)
lm.res <- lm(y~x)
lm.res
abline(lm.res)

Gave me the correct coefficients.

Coefficients:
(Intercept)            x  
          3            2  

Also, it was true that  SSY = SSR + SSE, where SSY=sum(y-mean(y))^2,
SSR=(yhat-mean(y))^2, and SSE=sum(y-yhat)^2.

yhat <- predict(lm.res)
tab <- cbind(x,y,yhat,(y-mean(y))^2,(yhat-mean(y))^2,(y-yhat)^2)
addmargins(tab,1)

     x  y yhat              
1   -1  2    1 21.16 31.36 1
2    1  3    5 12.96  2.56 4
3    2  8    7  1.96  0.16 1
4    3  8    9  1.96  5.76 1
5    4 12   11 29.16 19.36 1
Sum  9 33   33 67.20 59.20 8

That is, 67.20 = 59.20 + 8.

However, what I'd like to have is a set of numbers x and y that have a line
of best fit with equation y = 3+ 2x, but all of the numbers in the last
table are integers (or whole numbers). That would give me a good image I can
show in class to demonstrate this idea without having to do too many
calculations with decimals.

Wondering if their might be a method in R to keep picking choices for x and
y until this happens?

D.








--
View this message in context: http://r.789695.n4.nabble.com/Creating-a-set-that-has-line-of-best-fit-y-3-2x-so-that-SST-SSR-SSE-are-whole-numbers-tp4681074.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Sun Nov 24 20:54:38 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 24 Nov 2013 11:54:38 -0800
Subject: [R] create a new dataframe with intervals and computing a
	weighted average for each of its rows
In-Reply-To: <CACk-te0eyfoRsi-mE0ym6Oo84Ecp4v0tQoAF_A7gupOVg3sxng@mail.gmail.com>
References: <DUB123-W95AE659A25F6ADDE5FB1EF9E20@phx.gbl>
	<CACk-te0eyfoRsi-mE0ym6Oo84Ecp4v0tQoAF_A7gupOVg3sxng@mail.gmail.com>
Message-ID: <0242ff63-8a06-4d3a-90c7-9bf9052807d2@email.android.com>

Well, in his defense, he did provide quite a bit of R code, and did use a data.frame function to build a sample input data frame, so there was some effort made to communicate.

Unfortunately, after inserting newlines in the code that were demolished by the HTML, the code still does not run because it references a VALUE vector that is missing. By the name this seems like it might be important, but you don't reference it later so it is hard to guess what he wants to do.

Luis:
Your code is quite complicated after that, but I think you are doing way too much work on dividing up your data into groups since the ave function, aggregate function or the plyr library can simplify this very much. Since I don't see what you want to DO with each group, it is hard to show you a simpler way to do it. Perhaps you should just work through the examples for some of those functions.

Note that the only reliable way to give us sample data is using the dput function (or the data.frame function). Formatted tables pasted from spreadsheets just don't get through the email list clearly. Nor do most attachments.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Bert Gunter <gunter.berton at gene.com> wrote:
>This post is complete garbage, and a great example of why not
>bothering to read or follow the posting guide will cause a post to be
>ignored.
>
>1. It was not posted in plain text as the posting guide asks.
>
>2. dput() was not used to pass example data
>
>3. It appears the OP has not done due diligence by going through the
>Introduction to R or other online tutorials to learn how R works,
>although the post was so garbled that I may be wrong about that. My
>apology, if so.
>
>Cheers,
>Bert
>
>
>
>On Sun, Nov 24, 2013 at 1:08 AM, Luis Miguel Cerchiaro Barros
><luis_cerchiaro at hotmail.com> wrote:
>>
>>
>>
>>
>> I need you help with this problem, I have a data-frame like this:
>>     BHID=c(43,43,43,43,44,44,44,44,44)   
>FROM=c(50.9,46.7,44.2,43.1,52.3,51.9,49.3,46.2,42.38)   
>TO=c(46.7,44.2,43.1,40.9,51.9,49.3,46.2,42.38,36.3)   
>AR=c(45,46,0.0,38.45,50.05,22.9,0,25,9)   
>DF<-data.frame(BHID,FROM,TO,VALUE)        #add the length    
>DF$LENGTH=DF$FROM-DF$TO
>> where:
>> + BHID: is the borehole identification+ FROM: is  the start for every
>interval+ TO: is the end for every interval+ AR: is the value of our
>variable+ LENGTH: is the distance between FROM and TO
>> what I want, is create a data frame which is "normalized", it means
>that every interval has the same length and the column **AR** is
>calculated as a Weighted arithmetic mean from the old **AR** and 
>**LENGTH** as its weight.
>> For more clarity I going to show you how should look the desire data
>frame.
>>     BHID        FROM    TO          AR          LENGTH    43       
>50.9        47.9       45.0     3.0    43       47.9        44.9      
>45.6     3.0    43       44.9        41.9       26.113      3.0    43  
>         41.9        40.9    38.45        1.0    44....
>> where:
>> 1. AR is the Weighted arithmetic mean
>> I have to make a clarification about the result:
>> here I attached an example of my excel table with calculations:
>>     ROW_ID BHID NEW_FROM NEW_TO NEW_AR  OLD_FROM OLD_TO WEIGHTS
>OLD_AR    1                 43   50.9         47.9              45     
>50.9    46.7              3.0      45    2                 43   47.9   
>44.9              45.6             50.9    46.7              1.2     
>45    2                 43   47.9         44.9                         
>46.7    44.2              1.8      46    3                 43   44.9   
>41.9              26.113    46.7   44.2              0.7      46    3  
>43   44.9         41.9                                44.2   43.1      
>1.1      0    3                  43   44.9         41.9                
>43.1    40.9              1.2      38.45    4              43   41.9   
>    40.9              38.45     43.1   40.9              1.0      38.45
>>
>> you see guys, the NEW_AR is the weighted mean of the OLD_AR and its
>weights are in the column WEIGHTS.
>> If you see the column LENGTH in the original data frame you can see,
>that the values are different, with the "normalization" we try to make
>that LENGTH uniform, in this case we choose the value 3.0 of course the
>last value of each borehole data could had a different LENGTH in this
>case 1.0
>> What I have done to achieve the result
>> OK guys in first place I have to say, I am not a professional and I
>am still learning  how to use R,
>> my approximation is not elegant, I am trying to take the start and
>end of each borehole and use the function skeleton what I wrote, to
>create an uniform skeleton for the whole dataframe.
>>     skeleton<-function(DF,LEN){    # define function to create a new
>skeleton    divide.int<-function(FROM,TO,div){   
>n=as.integer((FROM-TO)/div)+1    from=seq(FROM,(FROM-(n-1)*div),-div)  
>to=seq(FROM-(n-(n-1))*div,FROM-(n-1)*div,-div)    to[n]=TO   
>range<-data.frame(BHID=borehole_names[i,1],FROM=from,TO=to) # create a
>data.frame class object    range<-range[!(range$FROM==range$TO),] #
>erase the last value    }    # subset the data set for every borehole  
>borehole_names<-unique(DF["BHID"]) # collars id with cores   
>borehole_number<-nrow(borehole_names)  # collar number    #define an
>empty data.frame    
>borehole_Out<-data.frame(BHID=integer(),FROM=numeric(),TO=numeric())   
># initialize the counter    i=1    # from this point starts the
>loop---------------    while(i<=borehole_number){    DFi <- subset(DF,
>BHID %in% borehole_names[i,1]) # Individual data frame for each
>boreholes    # take the beginning and end of every BOREHOLE   
>startBH<-head(DFi$FROM,1)    endBH<!
> 
> 
> -t!
>>  ail(DFi$TO,1)    # create the normalized intervals   
>borehole_i<-divide.int(FROM=startBH,TO=endBH,div=LEN)   
>borehole_Out<-rbind(borehole_Out,borehole_i)    i=i+1    }   
>borehole_Out    }    # TEST------------------------------------------  
> TEST<-skeleton(DF=DF,LEN=3.0)    TEST$LENGTH=TEST$FROM-TEST$TO
>> later I am trying to use the packages PLYR or DATA.TABLE to calculate
>the weighted means in AR but as I said I just started to use R and
>don't understand yet how this packages work
>> again thanks in advanced and sorry for my bumpy english
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Nov 24 21:00:46 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 Nov 2013 15:00:46 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
Message-ID: <52925AEE.1040505@gmail.com>

On 13-11-24 2:04 PM, Yihui Xie wrote:
> I'm not aware of a discussion on this, but I would say no.
> Fragmentation is bad. Further fragmentation is worse.
>
> TL;DR
> =====
>
> Actually I'd say all mailing lists except r-devel should be moving to
> StackOverlow in the future (disclaimer: I'm not affiliated with it).

I would generally agree with you, except for a few points.

1.  I avoid StackOverflow, because they claim copyright on the 
compilation.  As I read their terms of service, it would be illegal for 
anyone to download and duplicate all postings about R.  So a posting 
there is only available as long as they choose to make it available. 
Postings to the mailing list are archived in several places.

2.  I think an interface like StackOverflow is better than the mailing 
list interface, and will eventually win out.  R-help needs to do 
nothing, once someone puts together something like StackOverflow that 
attracts most of the people who give good answers, R-help will just fade 
away.

Duncan Murdoch



> Mailing lists are good for a smaller group of people, and especially
> good when more focused on discussions on development (including bug
> reports). The better place for questions is a web forum. Both you and
> I have been staying in these R mailing lists for a few years now. You
> can recall how many times a user was asked to post to another mailing
> list ("this is not an appropriate list to ask your question; please
> post to r-such-and-such instead"), how many times you see something
> like "Alternative HTML removed", how many times you see a post "Bla
> Bla (was: Foo Bar)", and how many times users were reminded "Please
> read the posting guide", "Please do read", and "PLEASE do read". But
> it just does not help much even if you write "PLEASE DO READ".
>
> Why do we have such problems in the mailing lists again and again? Is
> that simply because users are not respecting the rules? I do not think
> so. I believe that is the flaw of mailing lists. A mailing list is
> managed by a small team (hey, Martin, thank you). On StackOverflow,
> you simply edit the tags of a post to make it belong to a new "mailing
> list" (you can post with tags "r+ubuntu+graphics", or "r+lattice",
> etc). There is no need to request and wait for the system admin to
> make a decision. Users can help themselves, and help others as well.
> HTML can be good in many cases, actually. Who hates syntax
> highlighting and R plots in an R question? You are free to ask a
> question that is poorly formatted, and there are good chances that it
> will be immediately edited by another experienced user. You are free
> to yell in the comments asking for more details before posting a
> formal answer. You can express "ah, this is a bad question" by
> down-voting so that future readers know that guy screwed up and we
> just let the world ignore the noise. It is like peer-review, and the
> reviewers can help you improve your post. In a mailing list, when you
> are done, you are done. You are forever written in history, right or
> wrong, smart or stupid. You want to delete your record in the history?
> No, no, gentleman, it was your fault not reading the post guide.
>
> For me, I understand all the rationale behind the mailing list model.
> I'm just saying, the primary goal for such a service is to discuss
> issues about R, instead of issues induced by the mailing list itself.
> We could have made some issues not directly related to R go away by
> community efforts instead of giving instructions a million times,
> given an appropriate platform.
>
> Five years, 42,000 posts: http://stackoverflow.com/questions/tagged/r
> I'm not terribly worried about transition from mailing lists to SO.
>
> Sorry about the generalization of the original topic, but I hate using
> a new title "Should there be R mailing lists? (was: Should there be an
> R-beginners list?)"
>
> Last but not least, I probably need to clarify that I benefited a lot
> from the mailing lists in the past, and I truly appreciate it. I wrote
> this with the future in mind, not the past. The past was good, and the
> future can be better.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Sun, Nov 24, 2013 at 11:13 AM, Bert Gunter <gunter.berton at gene.com> wrote:
>> Folks:
>>
>> If this has been previously discussed and settled, please say so and
>> refer me to the discussion. If you believe this to be inappropriate or
>> otherwise frivolous, also please say so, as I do not wish to waste
>> your time or this space.
>>
>> I write as a long time reader and sometimes contributor to r-help. Due
>> to R's growth in usage by a broad data analysis community (engineers,
>> scientists, social scientists, finance, "informaticians", as well as
>> more "traditional" statisticians), this list seems to me to becoming
>> deluged by requests for help by "casual" users and students for whom R
>> is not going to be regularly or extensively used. I would characterize
>> this group as having only basic statistical, programming, and data
>> analysis skills. This is not meant as a criticism, and there are
>> certainly many for whom this is inaccurate. But ...
>>
>> By and large, such users have not spend much time with R's docs,
>> including tutorials or FAQ's. Many of their posts reflect this, and
>> can be answered with basic replies or references to docs, to wit: What
>> is the difference between "ifelse" and "if else"? FAQ 7.31. Confusion
>> of data frames, matrices, and spreadsheet tables; etc.
>>
>> Would it be useful, then, to establish an R-beginners list
>> specifically to absorb this traffic and free up R-help from what I
>> would say was its original intent, to provide a forum for serious,
>> more dedicated R users (Again, no criticism is intended here)?
>>
>> I realize that, whether or not this suggestion is worthwhile, there
>> are several ways it could fail. First, too few might be interested in
>> responding to posts on the new list. Second, too few might consider
>> themselves "beginners" who post to it. Etc. So I would certainly say
>> any such effort ought to be a pilot and tentative .
>>
>> I'll stop here. Again, criticize freely and/or send me off somewhere
>> else to prior discussion. Or to where it should be discussed. Or just
>> ignore, of course.
>>
>> Best,
>> Bert
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> (650) 467-7374
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From breden at sfu.ca  Sun Nov 24 20:41:07 2013
From: breden at sfu.ca (Felix Breden)
Date: Sun, 24 Nov 2013 11:41:07 -0800 (PST)
Subject: [R] testing for bimodal and for dip in between modes in R
In-Reply-To: <45458313.410653731.1385321950428.JavaMail.root@jaguar7.sfu.ca>
Message-ID: <1314763945.410655617.1385322067823.JavaMail.root@jaguar7.sfu.ca>

Hi 
I have distributions that are typically bimodal (see attached .pdf), and I would like to test for bimodality, and then estimate the point between the two modes, the dip in the distributions. any help would be greatly appreciated.
thanks
felix 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: m66.junction.aln.pairwise.histogram.pdf
Type: application/pdf
Size: 4803 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/ae8707ec/attachment.pdf>

From xie at yihui.name  Sun Nov 24 22:13:38 2013
From: xie at yihui.name (Yihui Xie)
Date: Sun, 24 Nov 2013 15:13:38 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <52925AEE.1040505@gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<52925AEE.1040505@gmail.com>
Message-ID: <CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>

I do not see how it can be illegal to download and duplicate the
posts, since all the content is licensed under CC BY-SA. I might have
missed something there: http://stackexchange.com/legal If that is
really the case, I think I will have to reconsider if I should use it
any more.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Sun, Nov 24, 2013 at 2:00 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-11-24 2:04 PM, Yihui Xie wrote:
>>
>> I'm not aware of a discussion on this, but I would say no.
>> Fragmentation is bad. Further fragmentation is worse.
>>
>> TL;DR
>> =====
>>
>> Actually I'd say all mailing lists except r-devel should be moving to
>> StackOverlow in the future (disclaimer: I'm not affiliated with it).
>
>
> I would generally agree with you, except for a few points.
>
> 1.  I avoid StackOverflow, because they claim copyright on the compilation.
> As I read their terms of service, it would be illegal for anyone to download
> and duplicate all postings about R.  So a posting there is only available as
> long as they choose to make it available. Postings to the mailing list are
> archived in several places.
>
> 2.  I think an interface like StackOverflow is better than the mailing list
> interface, and will eventually win out.  R-help needs to do nothing, once
> someone puts together something like StackOverflow that attracts most of the
> people who give good answers, R-help will just fade away.
>
> Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Nov 24 22:36:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 Nov 2013 16:36:35 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<52925AEE.1040505@gmail.com>
	<CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>
Message-ID: <52927163.9090508@gmail.com>

On 13-11-24 4:13 PM, Yihui Xie wrote:
> I do not see how it can be illegal to download and duplicate the
> posts, since all the content is licensed under CC BY-SA. I might have
> missed something there: http://stackexchange.com/legal If that is
> really the case, I think I will have to reconsider if I should use it
> any more.

I'm not a lawyer, but I see claims restricting users to "personal use".

Duncan Murdoch

>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Sun, Nov 24, 2013 at 2:00 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 13-11-24 2:04 PM, Yihui Xie wrote:
>>>
>>> I'm not aware of a discussion on this, but I would say no.
>>> Fragmentation is bad. Further fragmentation is worse.
>>>
>>> TL;DR
>>> =====
>>>
>>> Actually I'd say all mailing lists except r-devel should be moving to
>>> StackOverlow in the future (disclaimer: I'm not affiliated with it).
>>
>>
>> I would generally agree with you, except for a few points.
>>
>> 1.  I avoid StackOverflow, because they claim copyright on the compilation.
>> As I read their terms of service, it would be illegal for anyone to download
>> and duplicate all postings about R.  So a posting there is only available as
>> long as they choose to make it available. Postings to the mailing list are
>> archived in several places.
>>
>> 2.  I think an interface like StackOverflow is better than the mailing list
>> interface, and will eventually win out.  R-help needs to do nothing, once
>> someone puts together something like StackOverflow that attracts most of the
>> people who give good answers, R-help will just fade away.
>>
>> Duncan Murdoch


From andrewdigby at mac.com  Sun Nov 24 23:09:03 2013
From: andrewdigby at mac.com (Andrew Digby)
Date: Mon, 25 Nov 2013 11:09:03 +1300
Subject: [R] Inconsistent results between caret+kernlab versions
In-Reply-To: <CAJ9CoWnOC1oGHjCmow+kHE1WdgP3iHO106LnU1HC9W_7zfdJ+Q@mail.gmail.com>
References: <A436003D-FAC7-4075-B692-6FF2D64CBE3A@mac.com>
	<CAJ9CoWme2hj2FXp4egNXTnLG__qy2P-MXCg9qTD5iNapdRO+hA@mail.gmail.com>
	<CAJ9CoW=0--wH-WmQNmJtCgvZP-vu6kEUszuUtU8+ji0OmVDGrA@mail.gmail.com>
	<E2AF4DBC-1D59-4FA8-9940-C6FCA6B93E2A@mac.com>
	<CAJ9CoWnOC1oGHjCmow+kHE1WdgP3iHO106LnU1HC9W_7zfdJ+Q@mail.gmail.com>
Message-ID: <3AA7EAC0-7045-4C31-A7B8-ADB0E573DBAA@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/f9003647/attachment.pl>

From rshepard at appl-ecosys.com  Sun Nov 24 19:46:26 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 24 Nov 2013 10:46:26 -0800 (PST)
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1311241038160.18596@salmo.appl-ecosys.com>

On Sun, 24 Nov 2013, Bert Gunter wrote:

> Would it be useful, then, to establish an R-beginners list specifically to
> absorb this traffic and free up R-help from what I would say was its
> original intent, to provide a forum for serious, more dedicated R users
> (Again, no criticism is intended here)?

Bert,

   I support the idea. There are a number of specialized sub-lists
(e.g., ecological, mixed effects, spatial) so there's every reason to have a
new SIG: new users.

> I realize that, whether or not this suggestion is worthwhile, there are
> several ways it could fail. First, too few might be interested in
> responding to posts on the new list. Second, too few might consider
> themselves "beginners" who post to it. Etc. So I would certainly say any
> such effort ought to be a pilot and tentative .

   From what I see on the main mail list (where a lot of beginner questions
could be answered by the available docs or the many dead tree books that
I've read and use a references) folks will be willing to self-identify as
belonging to this category and get the tutoring they need without being put
down or feeling uncomfortable.

   You're correct that not every user spends his or her working life using R;
many of us use multiple technical tools as needed by each project. At some
point we were all newcomers to R, and each of us has a different ability to
self-learn.

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From rshepard at appl-ecosys.com  Sun Nov 24 21:04:42 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Sun, 24 Nov 2013 12:04:42 -0800 (PST)
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>

On Sun, 24 Nov 2013, Yihui Xie wrote:

> Mailing lists are good for a smaller group of people, and especially
> good when more focused on discussions on development (including bug
> reports). The better place for questions is a web forum.

   I disagree. Mail lists push messages to subscribers while web fora require
one to use a browser, log in, then pull messages. Not nearly as convenient.

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From lianoglou.steve at gene.com  Sun Nov 24 23:42:04 2013
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Sun, 24 Nov 2013 14:42:04 -0800
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <52927163.9090508@gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<52925AEE.1040505@gmail.com>
	<CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>
	<52927163.9090508@gmail.com>
Message-ID: <CAHA9McPy58OaBRFFgdAcy-CLVhcjoHvRfaD8_fMtU7uzu=91PQ@mail.gmail.com>

Hi,

On Sun, Nov 24, 2013 at 1:36 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-11-24 4:13 PM, Yihui Xie wrote:
>>
>> I do not see how it can be illegal to download and duplicate the
>> posts, since all the content is licensed under CC BY-SA. I might have
>> missed something there: http://stackexchange.com/legal If that is
>> really the case, I think I will have to reconsider if I should use it
>> any more.
>
>
> I'm not a lawyer, but I see claims restricting users to "personal use".

I guess one would have to clarify what is and isn't possible with the
data. I'm guessing they are trying to scare people/entities away from
trawling SO and repackaging it into another inko/knowledgebase
offering.

That having been said, there is a SO clone that was developed by the
folks at biostars.org which is an OSS StackOverflow "clone"

https://github.com/ialbert/biostar-central

Someone would just need to host it, though.

Given SO's critical mass, though, I think it's hard to argue against
simply using that.

-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech


From erinm.hodgess at gmail.com  Mon Nov 25 00:15:32 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 24 Nov 2013 17:15:32 -0600
Subject: [R] persp3d and rsm models
Message-ID: <CACxE24n=pQFMShiG5e_6ZJ6uPHO1CewnVi2zqbupVs-uyKtALg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/f81a1963/attachment.pl>

From erinm.hodgess at gmail.com  Mon Nov 25 00:23:55 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sun, 24 Nov 2013 17:23:55 -0600
Subject: [R] persp3d and rsm models
In-Reply-To: <CACxE24n=pQFMShiG5e_6ZJ6uPHO1CewnVi2zqbupVs-uyKtALg@mail.gmail.com>
References: <CACxE24n=pQFMShiG5e_6ZJ6uPHO1CewnVi2zqbupVs-uyKtALg@mail.gmail.com>
Message-ID: <CACxE24mdjOGLoaBfrDOMwXdaqthRgZsQ+9eGhLT_TXn=LsAMCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/9aafb7af/attachment.pl>

From murdoch.duncan at gmail.com  Mon Nov 25 00:28:59 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 Nov 2013 18:28:59 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CAHA9McPy58OaBRFFgdAcy-CLVhcjoHvRfaD8_fMtU7uzu=91PQ@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>	<52925AEE.1040505@gmail.com>	<CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>	<52927163.9090508@gmail.com>
	<CAHA9McPy58OaBRFFgdAcy-CLVhcjoHvRfaD8_fMtU7uzu=91PQ@mail.gmail.com>
Message-ID: <52928BBB.7070102@gmail.com>

On 13-11-24 5:42 PM, Steve Lianoglou wrote:
> Hi,
>
> On Sun, Nov 24, 2013 at 1:36 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 13-11-24 4:13 PM, Yihui Xie wrote:
>>>
>>> I do not see how it can be illegal to download and duplicate the
>>> posts, since all the content is licensed under CC BY-SA. I might have
>>> missed something there: http://stackexchange.com/legal If that is
>>> really the case, I think I will have to reconsider if I should use it
>>> any more.
>>
>>
>> I'm not a lawyer, but I see claims restricting users to "personal use".
>
> I guess one would have to clarify what is and isn't possible with the
> data. I'm guessing they are trying to scare people/entities away from
> trawling SO and repackaging it into another inko/knowledgebase
> offering.

But that is exactly the capability I was asking for, and it's a 
capability which the mailing list currently has.  (E.g.  nabble 
repackages the list, and there are lots of sites that archive it.)

>
> That having been said, there is a SO clone that was developed by the
> folks at biostars.org which is an OSS StackOverflow "clone"
>
> https://github.com/ialbert/biostar-central
>
> Someone would just need to host it, though.
>
> Given SO's critical mass, though, I think it's hard to argue against
> simply using that.

Not for me.

Duncan Murdoch

>
> -steve
>


From dulcalma at bigpond.com  Mon Nov 25 01:05:57 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 25 Nov 2013 10:05:57 +1000
Subject: [R] Plotting multiple trends on one graph
In-Reply-To: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
References: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
Message-ID: <000c01cee972$1e2b97c0$5a82c740$@bigpond.com>

Hi Natalie

Here is an option using lattice. I think below will get you some way to what
you want

This is your data formatted. in future please dput your data  as your data
was scrambled.
# dput(dat)
dat <- structure(list(TagID = c(4926L, 4926L, 4926L, 4926L, 4926L, 4926L,
4926L, 4926L, 4926L, 4926L, 4926L, 4929L, 4929L, 4929L, 4929L, 
4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 
4929L), Station = c("KLB", "MS01", "MS02", "MS03", "MS04", "MS05", 
"MS06", "MS07", "MS08", "MS09", "MS10", "KLB", "MS01", "MS02", 
"MS03", "MS04", "MS05", "MS06", "MS07", "MS08", "MS09", "MS10", 
"MS11", "MS12", "MS13"), datetime = c("12/21/2012 1:52", "12/21/2012 2:38", 
"12/21/2012 3:48", "12/21/2012 4:19", "12/21/2012 4:34", "12/21/2012 5:01", 
"12/21/2012 6:54", "12/21/2012 7:21", "12/21/2012 10:23", "12/21/2012
12:16", 
"12/21/2012 14:38", "12/21/2012 1:08", "12/21/2012 2:12", "12/21/2012 3:33",

"12/21/2012 3:59", "12/21/2012 4:13", "12/21/2012 5:00", "12/21/2012 6:52", 
"12/21/2012 7:32", "12/21/2012 10:16", "12/21/2012 11:43", "12/21/2012
14:02", 
"12/22/2012 2:50", "12/22/2012 5:04", "12/22/2012 13:59"), gspd_mps = c(NA, 
0.851, 0.629, 0.86, 1.131, 0.9, 0.798, 0.853, 0.694, 0.6, 0.647, 
NA, 0.611, 0.563, 1.04, 1.082, 0.475, 0.796, 0.563, 0.809, 0.783, 
0.657, 0.326, 0.709, 0.688)), .Names = c("TagID", "Station", 
"datetime", "gspd_mps"), class = "data.frame", row.names = c(NA, 
-25L))

# factor of id
dat[,1] <- factor(dat[,1])
# convert to datetime
x <- paste(dat[,3])
x <- strptime(x, "%m/%d/%Y %H:%M")

I have added a few extra formatting options but I will leave you to format
the x labels as an exercise.

# lattice plot conditioned by station
library(lattice)
xyplot(gspd_mps ~ as.POSIXct(x)|Station, dat,
       as.table = TRUE,
       layout = c(1,14),
       groups = TagID,
       strip = FALSE,
       type = c("p","g"),
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list(cex = c(1,0.7),
                                                   col = c("red","blue"),
                                                   pch = c(20,3))),
       strip.left = strip.custom(par.strip.text = list(cex = 0.65) ),
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       auto.key = TRUE
       )

# using latticeExtra conditioned by station and tag
library(latticeExtra)
useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2,
xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       type = c("p","g")
       )
) ## useOuterStrips

useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2,
xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       panel = function(x,y, ...){
                 panel.grid(h = 0, v= -1)
                 panel.xyplot(x,y,...)
               }
       )
) ## useOuterStrips

HTH
Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Natalie Houghton McNair
Sent: Monday, 25 November 2013 02:49
To: R-help at r-project.org
Subject: [R] Plotting multiple trends on one graph

>
> Hello all,
>
> I am tracking hundreds of animals through a system with multiple 
> timing points.  I want to graph the movement of individuals through 
> the whole array on one graph, but I can't figure out how to do that.  
> An example of my data is below.  Basically for each 'TagID', I want to
graph the 'date'
> or 'gspd_mps' on the X axis and 'Station' on the Y axis, with all 
> TagID's on one graph.
>

Thanks for the help!!  I'm very new to R.
Natalie

   TagID Station datetime gspd_mps  4926 KLB 12/21/2012 1:52 NA  4926
MS01 12/21/2012
2:38 0.851  4926 MS02 12/21/2012 3:48 0.629  4926 MS03 12/21/2012 4:19 0.86
4926 MS04 12/21/2012 4:34 1.131  4926 MS05 12/21/2012 5:01 0.9  4926
MS06 12/21/2012
6:54 0.798  4926 MS07 12/21/2012 7:21 0.853  4926 MS08 12/21/2012 10:23
0.694  4926 MS09 12/21/2012 12:16 0.6  4926 MS10 12/21/2012 14:38 0.647
4929 KLB 12/21/2012 1:08 NA  4929 MS01 12/21/2012 2:12 0.611  4929
MS02 12/21/2012
3:33 0.563  4929 MS03 12/21/2012 3:59 1.04  4929 MS04 12/21/2012 4:13 1.082
4929 MS05 12/21/2012 5:00 0.475  4929 MS06 12/21/2012 6:52 0.796  4929
MS07 12/21/2012
7:32 0.563  4929 MS08 12/21/2012 10:16 0.809  4929 MS09 12/21/2012 11:43
0.783  4929 MS10 12/21/2012 14:02 0.657  4929 MS11 12/22/2012 2:50 0.326
4929 MS12 12/22/2012 5:04 0.709  4929 MS13 12/22/2012 13:59 0.688
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From memilanuk at gmail.com  Mon Nov 25 01:30:14 2013
From: memilanuk at gmail.com (memilanuk)
Date: Sun, 24 Nov 2013 16:30:14 -0800
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
Message-ID: <52929A16.4020501@gmail.com>

On 11/24/2013 12:04 PM, Rich Shepard wrote:
> On Sun, 24 Nov 2013, Yihui Xie wrote:
>
>> Mailing lists are good for a smaller group of people, and especially
>> good when more focused on discussions on development (including bug
>> reports). The better place for questions is a web forum.
>
>    I disagree. Mail lists push messages to subscribers while web fora
> require
> one to use a browser, log in, then pull messages. Not nearly as convenient.
>
> Rich
>

With the StackOverflow model, you can either view the list of posts 
related to a specific tag via RSS, or subscribe for email notification 
of new updates on that topic.

Add in the added bonus of the ability to moderate and/or cull spam and 
redundant questions, etc. and the targeted focus of a SO-type forum 
increases dramatically IMHO.


From memilanuk at gmail.com  Mon Nov 25 01:30:14 2013
From: memilanuk at gmail.com (memilanuk)
Date: Sun, 24 Nov 2013 16:30:14 -0800
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
Message-ID: <52929A16.4020501@gmail.com>

On 11/24/2013 12:04 PM, Rich Shepard wrote:
> On Sun, 24 Nov 2013, Yihui Xie wrote:
>
>> Mailing lists are good for a smaller group of people, and especially
>> good when more focused on discussions on development (including bug
>> reports). The better place for questions is a web forum.
>
>    I disagree. Mail lists push messages to subscribers while web fora
> require
> one to use a browser, log in, then pull messages. Not nearly as convenient.
>
> Rich
>

With the StackOverflow model, you can either view the list of posts 
related to a specific tag via RSS, or subscribe for email notification 
of new updates on that topic.

Add in the added bonus of the ability to moderate and/or cull spam and 
redundant questions, etc. and the targeted focus of a SO-type forum 
increases dramatically IMHO.


From JSorkin at grecc.umaryland.edu  Mon Nov 25 01:37:46 2013
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 24 Nov 2013 19:37:46 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <52929A16.4020501@gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
Message-ID: <5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>

Mailing list vs. stack overflow, I have no opinion, but
beginners list NO! I was a beginner at one time and the
mailing list worked just fine. I see no reason to divide our 
efforts across two lists (be they mailing lists or stack overflow).
John

 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> memilanuk <memilanuk at gmail.com> 11/24/2013 7:30 PM >>>
On 11/24/2013 12:04 PM, Rich Shepard wrote:
> On Sun, 24 Nov 2013, Yihui Xie wrote:
>
>> Mailing lists are good for a smaller group of people, and especially
>> good when more focused on discussions on development (including bug
>> reports). The better place for questions is a web forum.
>
>    I disagree. Mail lists push messages to subscribers while web fora
> require
> one to use a browser, log in, then pull messages. Not nearly as convenient.
>
> Rich
>

With the StackOverflow model, you can either view the list of posts 
related to a specific tag via RSS, or subscribe for email notification 
of new updates on that topic.

Add in the added bonus of the ability to moderate and/or cull spam and 
redundant questions, etc. and the targeted focus of a SO-type forum 
increases dramatically IMHO.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From jim at mail.bitwrit.com.au  Sun Nov 24 22:43:55 2013
From: jim at mail.bitwrit.com.au (Jim Lemon)
Date: Mon, 25 Nov 2013 08:43:55 +1100 (EST)
Subject: [R] Plotting multiple trends on one graph
In-Reply-To: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
References: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
Message-ID: <7109.1.126.85.62.1385329435.squirrel@www.bitwrit.com.au>

>>
>> Hello all,
>>
>> I am tracking hundreds of animals through a system with multiple timing
>> points.  I want to graph the movement of individuals through the whole
>> array on one graph, but I can't figure out how to do that.  An example
>> of
>> my data is below.  Basically for each 'TagID', I want to graph the
>> 'date'
>> or 'gspd_mps' on the X axis and 'Station' on the Y axis, with all
>> TagID's
>> on one graph.
>>
>
Hi Natalie,
This can be done with the matplot function, but see previous posts on how
to display dates if you have trouble with that. You will probably have to
convert your dates to date objects with as.Date or strptime.

Jim


From kristi.glover at hotmail.com  Mon Nov 25 03:29:45 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sun, 24 Nov 2013 22:29:45 -0400
Subject: [R] stack data (from rows to column)
Message-ID: <COL129-W2268D5A7B23248785FE122FAED0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131124/398c51d6/attachment.pl>

From smartpink111 at yahoo.com  Mon Nov 25 03:47:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 24 Nov 2013 18:47:23 -0800 (PST)
Subject: [R] stack data (from rows to column)
In-Reply-To: <COL129-W2268D5A7B23248785FE122FAED0@phx.gbl>
References: <COL129-W2268D5A7B23248785FE122FAED0@phx.gbl>
Message-ID: <1385347643.76172.YahooMailNeo@web142605.mail.bf1.yahoo.com>



HI,
Try:
?library(reshape2)
?melt(data,measure.vars=c("t1","t2"),var="ind")

A.K.


On Sunday, November 24, 2013 9:31 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:
I was just wondering how to stack values of columns to rows. Would you give me some idea how I can stack? I just want to stack columns 2 and 3 but not column1. The column 1 is supposed to be repeated. I was able to stack using "stack" but I could not repeat the column 1.? 

For example I have data like this
group t1 t2 t3
101 -31.77083 -33.79167
103 -27.26667 -27.9

data<-structure(list(group = c(101L, 103L), t1 = c(-31.77083, -27.26667
), t2 = c(-33.79167, -27.9)), .Names = c("group", "t1", "t2"), class = "data.frame", row.names = c(NA, 
-2L))

-----
Want to make like this"
group? ?  values? ?  ind
101? ?  -31.7708? ?  t1
103? ?  -27.2667? ?  t1
101? ?  -33.7917? ?  t2
103? ?  -27.9? ?  t2

final<-structure(list(group = c(101L, 103L, 101L, 103L), values = c(-31.77083, 
-27.26667, -33.79167, -27.9), ind = structure(c(1L, 1L, 2L, 2L
), .Label = c("t1", "t2"), class = "factor")), .Names = c("group", 
"values", "ind"), class = "data.frame", row.names = c(NA, -4L
))

I really appreciate for your help.
thanks 
? ? ? ? ? ? 
??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jwd at surewest.net  Mon Nov 25 06:53:21 2013
From: jwd at surewest.net (jwd)
Date: Sun, 24 Nov 2013 21:53:21 -0800
Subject: [R] Help with removing extra legend elements in ggplot
In-Reply-To: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
References: <CALx9ERVtXTAqeU0LpeSy5Gomew8Lfz+UkJ38pjhJ3d1rc0caiw@mail.gmail.com>
Message-ID: <20131124215321.5eed361d@draco.site>

On Tue, 19 Nov 2013 16:44:11 -0700
Matthew Van Scoyoc <scoyoc at gmail.com> wrote:

You want to consider this as a programming bug in your code.  Executing
each line sequentially shows that the problem appears in the second
line:

nmds.fig + geom_point(aes(color = VegType, shape = VegType, size = 10))

?aes() and ?geom_point() reveals a misplaced right parenthesis. "Size"
belongs to geom_point(), not aes() as you have it grouped.

jwdougherty


From rh at knut-krueger.de  Mon Nov 25 10:10:40 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Mon, 25 Nov 2013 10:10:40 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
Message-ID: <52931410.4080102@knut-krueger.de>

Hi to all,
how can I read exel files where the decimal sign is comma instead dot.
I get the data as ascii and when converting "3,5" with as.numeric the  
3,5 will be converted to NA

Kind Regards Knut


From landronimirc at gmail.com  Mon Nov 25 10:24:33 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 25 Nov 2013 10:24:33 +0100
Subject: [R] convert data frame: two variables into _one_ binary variable
Message-ID: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>

Dear all,
I am trying to convert the following data frame into a format more
useful for me:
> library("HSAUR2", lib.loc="C:/Program Files/R/R-3.0.2/library")
Loading required package: tools

Attaching package: ?HSAUR2?

The following object is masked _by_ ?.GlobalEnv?:

    womensrole

> head(womensrole)
  education gender agree disagree sexe
1         0   Male     4        2    0
2         1   Male     2        0    0
3         2   Male     4        0    0
4         3   Male     6        3    0
5         4   Male     5        5    0
6         5   Male    13        7    0


In 'womensrole', how do I convert 'agree' and 'disagree' variables
into one proper binary variable, say:
  education gender agree sexe
1         0   Male     TRUE           0
2         0   Male     TRUE           0
3         0   Male     TRUE           0
4         0   Male     TRUE           0
5         0   Male     FALSE           0
6         0   Male     FALSE           0
7         1   Male     TRUE           0
8         1   Male     TRUE           0
9         2   Male     TRUE           0
10         2   Male     TRUE           0
11         2   Male     TRUE           0
12         2   Male     TRUE           0
[..]

I'm sure there is an easy way to do this (in the form of 'melt',
'cast', etc.), but I'm not sure how to approach the problem.

Regards,
Liviu

-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From petr.pikal at precheza.cz  Mon Nov 25 11:29:08 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 25 Nov 2013 10:29:08 +0000
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <52931410.4080102@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>

Hi

Either change comma to dot in Excel (but sometimes Excel is rather reluctant to accept such changes).

Or change commaa to dot in R which probably can be easily done by gsub command

Or read data with option dec=",". I do not know XLConnect but in read.table it is optional parameter and maybe it is also readWorksheet.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Knut Krueger
> Sent: Monday, November 25, 2013 10:11 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] XLConnect readWorksheet comma decimal sign
> 
> Hi to all,
> how can I read exel files where the decimal sign is comma instead dot.
> I get the data as ascii and when converting "3,5" with as.numeric the
> 3,5 will be converted to NA
> 
> Kind Regards Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Mon Nov 25 12:31:22 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 25 Nov 2013 12:31:22 +0100
Subject: [R] testing for bimodal and for dip in between modes in R
In-Reply-To: <1314763945.410655617.1385322067823.JavaMail.root@jaguar7.sfu.ca>
References: <1314763945.410655617.1385322067823.JavaMail.root@jaguar7.sfu.ca>
Message-ID: <2D315B7B-29AB-4BE5-B067-2116ADCE41E8@uni-bonn.de>

Testing for bimodality is rather testing for unimodality. Hartigan and Hartigan (1985) presented the Dip-Test which is implemented in the R package DipTest with a much better approximation of the test distribution. If the test statistic is too high unimodality is rejected. To estimate the dip point you could choose among several possibilities: (1) A very easy method is to use the kmeans function for a kmeans cluster and use the point in the middle of the connecting line between the kmeans cluster centers. (2) You could estimate a finite mixture distribution and take the middle of the connecting line of the modes.

Best

Simon
 
On 24 Nov 2013, at 20:41, Felix Breden <breden at sfu.ca> wrote:

> Hi 
> I have distributions that are typically bimodal (see attached .pdf), and I would like to test for bimodality, and then estimate the point between the two modes, the dip in the distributions. any help would be greatly appreciated.
> thanks
> felix <m66.junction.aln.pairwise.histogram.pdf>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rh at knut-krueger.de  Mon Nov 25 13:06:35 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Mon, 25 Nov 2013 13:06:35 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
References: <52931410.4080102@knut-krueger.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
Message-ID: <52933D4B.90803@knut-krueger.de>

Am 25.11.2013 11:29, schrieb PIKAL Petr:
> Hi
>
> Either change comma to dot in Excel (but sometimes Excel is rather reluctant to accept such changes).
>
> Or change commaa to dot in R which probably can be easily done by gsub command
>
> Or read data with option dec=",". I do not know XLConnect but in read.table it is optional parameter and maybe it is also readWorksheet.
>
> Regards
> Petr
read table is not able to read xls and xlsx files

I found the reason there are NA inside the column but
   gdata  read.xls  is doing the job fine, but it needs the perl 
interpreter, nor problem but somthing to install addtionally
   also Rcmdr has also no problems with NA in a decimal data column
   readWorksheet does the job also when no NA is in the column and with 
NA readWorksheet is interpreting the NA like any other text.

Knut


From arman.eshaghi at gmail.com  Mon Nov 25 13:08:43 2013
From: arman.eshaghi at gmail.com (Arman Eshaghi)
Date: Mon, 25 Nov 2013 15:38:43 +0330
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
Message-ID: <CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/9ecb05dc/attachment.pl>

From jonas.josefsson at slu.se  Mon Nov 25 11:47:06 2013
From: jonas.josefsson at slu.se (Jonas Josefsson)
Date: Mon, 25 Nov 2013 10:47:06 +0000
Subject: [R] Independent variable dependent on offset in GLMM
Message-ID: <CEB8E939.36C8%jonas.josefsson@slu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/ca91dff0/attachment.pl>

From b.cesqui at hsantalucia.it  Mon Nov 25 11:13:02 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Mon, 25 Nov 2013 11:13:02 +0100
Subject: [R] lmer specification for random effects: contradictory reults
Message-ID: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/75167077/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Mon Nov 25 14:20:53 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 25 Nov 2013 13:20:53 +0000
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <152e4fab94c64a3297e0fbfbc9ada7b8@EX-0-HT0.lancs.local>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<152e4fab94c64a3297e0fbfbc9ada7b8@EX-0-HT0.lancs.local>
Message-ID: <CANVKczN+zzsY2iMATeYZNxwMo_pJze-NHg9-Ob-TyLMrNEhVhw@mail.gmail.com>

If you want a vision of an R-beginners list, it is a boot stamping
"ITS IN THE DOCUMENTATION" into a newbies face - forever.

http://www.brainyquote.com/quotes/quotes/g/georgeorwe159438.html

slight exaggeration perhaps, but most R-beginners would benefit from
reading a bit more documentation and "LURKING MOAR" on the mailing
list before asking. Same applies to posting on StackOverflow.

Barry


On Mon, Nov 25, 2013 at 12:08 PM, Arman Eshaghi <arman.eshaghi at gmail.com> wrote:
> I do not agree with a separate beginner's list. But I do stand with moving
> to stackoverflow, mainly because of the easier google search than current
> mailing list. It could make it more accessible.
>
>
> On Mon, Nov 25, 2013 at 4:07 AM, John Sorkin <JSorkin at grecc.umaryland.edu>wrote:
>
>> Mailing list vs. stack overflow, I have no opinion, but
>> beginners list NO! I was a beginner at one time and the
>> mailing list worked just fine. I see no reason to divide our
>> efforts across two lists (be they mailing lists or stack overflow).
>> John
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> >>> memilanuk <memilanuk at gmail.com> 11/24/2013 7:30 PM >>>
>> On 11/24/2013 12:04 PM, Rich Shepard wrote:
>> > On Sun, 24 Nov 2013, Yihui Xie wrote:
>> >
>> >> Mailing lists are good for a smaller group of people, and especially
>> >> good when more focused on discussions on development (including bug
>> >> reports). The better place for questions is a web forum.
>> >
>> >    I disagree. Mail lists push messages to subscribers while web fora
>> > require
>> > one to use a browser, log in, then pull messages. Not nearly as
>> convenient.
>> >
>> > Rich
>> >
>>
>> With the StackOverflow model, you can either view the list of posts
>> related to a specific tag via RSS, or subscribe for email notification
>> of new updates on that topic.
>>
>> Add in the added bonus of the ability to moderate and/or cull spam and
>> redundant questions, etc. and the targeted focus of a SO-type forum
>> increases dramatically IMHO.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:18}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gps at asu.edu  Mon Nov 25 14:29:37 2013
From: gps at asu.edu (Geoffrey Smith)
Date: Mon, 25 Nov 2013 06:29:37 -0700
Subject: [R] Structural break test Andrews (2003)
Message-ID: <CAGRravbhaKuqwjMpSTcv7Bjx7q9suSu-2sbiwe7KbqQ4cK0zfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/df19cda8/attachment.pl>

From h.wickham at gmail.com  Mon Nov 25 14:47:27 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Nov 2013 07:47:27 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <52927163.9090508@gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<52925AEE.1040505@gmail.com>
	<CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>
	<52927163.9090508@gmail.com>
Message-ID: <CABdHhvGVJ24oJ6M9GB3wxb+ZXZp1kh3J6rJQStqVjUNs32N7qw@mail.gmail.com>

>> I do not see how it can be illegal to download and duplicate the
>> posts, since all the content is licensed under CC BY-SA. I might have
>> missed something there: http://stackexchange.com/legal If that is
>> really the case, I think I will have to reconsider if I should use it
>> any more.
>
> I'm not a lawyer, but I see claims restricting users to "personal use".

Neither am I, but I don't see any claims about personal use in the
"Subscriber Content" section, which is what concerns content that
other people have uploaded to stackoverflow. As Yihui says, all
questions and answers (as opposed to the stuff written by
stackoverflow the company) is licensed with
http://creativecommons.org/licenses/by-sa/2.5/.

I suspect you'll find that the mailing list is in more of a grey area
since authors own the copyright to their posts and haven't agreed to
any redistribution (apart from what is obvious in signing up for a
mailing list).

Hadley


-- 
http://had.co.nz/


From Thierry.ONKELINX at inbo.be  Mon Nov 25 14:48:17 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 25 Nov 2013 13:48:17 +0000
Subject: [R] lmer specification for random effects: contradictory reults
In-Reply-To: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
References: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
Message-ID: <AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>

Dear Benedetta,

I think you might want (1+T+Z|subject) as random effects  rather than (1+T|subject) + (1 + Z|subject). The latter has two random intercepts per subject: a recipe for disaster.

Follow-up posts should only go to the mixed models mailing list which I'm cc'ing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Benedetta Cesqui
Verzonden: maandag 25 november 2013 11:13
Aan: r-help at r-project.org
Onderwerp: [R] lmer specification for random effects: contradictory reults

Hi All,



I was wondering if someone could help me to solve this issue with lmer.
In order to understand the best mixed effects model to fit my data, I compared the following options according to the procedures specified in many papers (i.e. Baayen <http://www.google.it/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDsQFjAA
&url=http%3A%2F%2Fwww.ualberta.ca%2F~baayen%2Fpublications%2FbaayenDavidsonB
ates.pdf&ei=FhqTUoXuJKKV7Abds4GYBA&usg=AFQjCNFst7GT7mBX7w9lXItJTtELJSKWJg&si
g2=KGA5MHxOvEGwDxf-Gcqi6g&bvm>  R.H. et al 2008) Here, dT_purs is the response variable, T and Z are the fixed effects, and subject is the random effect. Random and fixed effects are crossed.:

mod0 <- lmer(dT_purs ~ T + Z + (1|subject), data = x)
mod1 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject), data = x)
mod2 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod3 <- lmer(dT_purs ~ T * Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod4 <- lmer(dT_purs ~ T * Z + (1| subject), data = x)


anova(mod0, mod1,mod2, mod3, mod4)



Data: x

Models:

mod0: dT_purs ~ T + Z + (1 | subject)

mod4: dT_purs ~ T * Z + (1 | subject )

mod1: dT_purs ~ T + Z + (1 + T| subject)

mod2: dT_purs ~ T + Z + (1 + T| subject ) + (1 + Z | subject)

mod3: dT_purs ~ T * Z + (1 + T| subject) + (1 + Z | subject)

     Df     AIC     BIC logLik deviance   Chisq Chi Df Pr(>Chisq)

mod0  5 -689.81 -669.46 349.91  -699.81

mod4  6 -689.57 -665.14 350.78  -701.57  1.7532      1   0.185473

mod1  7 -689.12 -660.62 351.56  -703.12  1.5504      1   0.213070

mod2 10 -695.67 -654.97 357.84  -715.67 12.5563      3   0.005701 **

mod3 11 -695.83 -651.05 358.92  -717.83  2.1580      1   0.141825

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





It turns out that mod2 has the right level of complexity for this dataset.

However when I looked at its summary, I got a correlation of -0.87 for the
random effects relative to the T effect and -1 for the random effects
relatively to the Z.





summary(mod2)

Linear mixed model fit by maximum likelihood ['lmerMod']

Formula: dT_purs ~T + Z + (1 + T | subject) + (1 + Z | subject)

   Data: x



      AIC       BIC    logLik  deviance

-695.6729 -654.9655  357.8364 -715.6729



Random effects:

Groups     Name        Variance  Std.Dev. Corr

 subject   (Intercept) 0.0032063 0.05662

            T       0.0117204 0.10826  -0.87

subject.1 (Intercept) 0.0005673 0.02382

            Z           0.0025859 0.05085  1.00

 Residual               0.0104551 0.10225

Number of obs: 433, groups: soggetto, 7



Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.02489    0.03833   0.650

T        0.52010    0.05905   8.808

Z           -0.09019    0.02199  -4.101



Correlation of Fixed Effects:

      (Intr) tempo

T -0.901

Z      0.218 -0.026





If I understand correctly what the correlation parameters reported in the
table are, the correlation of 1 means that, for the Z effects the random
intercept is perfectly collinear with the random slope. Thus, we fit the
wrong model. A random intercept only model would have sufficed.

Am I correct?



If so, should I take mod1 (mod1 <- dT_purs ~ T + Z + (1 + T | subject )
instead of mod2 to fit my data?

Why are these results contradictory?

Finally is a correlation value of -0.87 a too high or an acceptable value ?



Thanks for help me in advance!



Best



Benedetta





---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From petr.pikal at precheza.cz  Mon Nov 25 14:56:57 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 25 Nov 2013 13:56:57 +0000
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>

Hi

I doubt if people start to search answers if they often do not search them in help pages and documentation provided. 

I must agree with Duncan that if Stackoverflow was far more better than this help list most people would seek advice there then here. Is there any evidence in decreasing traffic here? 

Anyway, similar discussion went in 2003 with outcome that was not in favour for separate beginner list http://tolstoy.newcastle.edu.au/R/help/03b/7944.html

Petr

BTW it is pitty that r help archive does not extend over year 2012. I found that *Last message date: Tue 31 Jan 2012 - 12:19:21 GMT



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Arman Eshaghi
> Sent: Monday, November 25, 2013 1:09 PM
> To: John Sorkin
> Cc: r-help at r-project.org; memilanuk
> Subject: Re: [R] Should there be an R-beginners list?
> 
> I do not agree with a separate beginner's list. But I do stand with
> moving to stackoverflow, mainly because of the easier google search
> than current mailing list. It could make it more accessible.
> 
> 
> On Mon, Nov 25, 2013 at 4:07 AM, John Sorkin
> <JSorkin at grecc.umaryland.edu>wrote:
> 
> > Mailing list vs. stack overflow, I have no opinion, but beginners
> list
> > NO! I was a beginner at one time and the mailing list worked just
> > fine. I see no reason to divide our efforts across two lists (be they
> > mailing lists or stack overflow).
> > John
> >
> >
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> > Geriatric Medicine Baltimore VA Medical Center 10 North Greene Street
> > GRECC (BT/18/GR) Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> > >>> memilanuk <memilanuk at gmail.com> 11/24/2013 7:30 PM >>>
> > On 11/24/2013 12:04 PM, Rich Shepard wrote:
> > > On Sun, 24 Nov 2013, Yihui Xie wrote:
> > >
> > >> Mailing lists are good for a smaller group of people, and
> > >> especially good when more focused on discussions on development
> > >> (including bug reports). The better place for questions is a web
> forum.
> > >
> > >    I disagree. Mail lists push messages to subscribers while web
> > > fora require one to use a browser, log in, then pull messages. Not
> > > nearly as
> > convenient.
> > >
> > > Rich
> > >
> >
> > With the StackOverflow model, you can either view the list of posts
> > related to a specific tag via RSS, or subscribe for email
> notification
> > of new updates on that topic.
> >
> > Add in the added bonus of the ability to moderate and/or cull spam
> and
> > redundant questions, etc. and the targeted focus of a SO-type forum
> > increases dramatically IMHO.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > Confidentiality Statement:
> > This email message, including any attachments, is for
> > ...{{dropped:18}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Mon Nov 25 15:04:54 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 25 Nov 2013 15:04:54 +0100 (CET)
Subject: [R] Structural break test Andrews (2003)
In-Reply-To: <CAGRravbhaKuqwjMpSTcv7Bjx7q9suSu-2sbiwe7KbqQ4cK0zfw@mail.gmail.com>
References: <CAGRravbhaKuqwjMpSTcv7Bjx7q9suSu-2sbiwe7KbqQ4cK0zfw@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1311251504390.10210@paninaro.uibk.ac.at>

On Mon, 25 Nov 2013, Geoffrey Smith wrote:

> Dear Friends, I am looking for an R version of the structural break test 
> in Andrews (2003).  The excellent strucchange package does not include 
> this test (yet?).  Is this test available in another package?  If not, 
> might there already be a function written to do this test?  Thank you 
> very much.
>
> Citation: Andrews, D.W.K. (2003), End-of-Sample Instability Tests.
> Econometrica, 71: 1661?1694.

To the best of my knowledge there is no R package that implements this 
test. (If there is please let me know.)

I decided not to implement it in "strucchange" because I found the 
"monitoring" framework formulated by Chu et al. (1996, Econometrica) more 
useful for tackling changes that occur after a certain point in time only. 
See ?mefp and the references therein for a detailed discussion of the 
"monitoring" framework.

Best,
Z

> 	[[alternative HTML version deleted]]
>
>


From jrkrideau at inbox.com  Mon Nov 25 15:24:06 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 25 Nov 2013 06:24:06 -0800
Subject: [R] Plotting multiple trends on one graph
In-Reply-To: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
Message-ID: <7BE14006288.00000314jrkrideau@inbox.com>

I am not sure I have grasped what you want but have a look at this using  ggplot2 with Duncan's modified data set (with his factor and striptime commands executed)

You will probably need to install ggplot2 :
install.packages("ggplot2) 


library(ggplot2)
ggplot(dat, aes(gspd_mps, Station )) + geom_point() +
  facet_grid(TagID ~ .)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: nhoughton01 at gmail.com
> Sent: Sun, 24 Nov 2013 08:49:03 -0800
> To: r-help at r-project.org
> Subject: [R] Plotting multiple trends on one graph
> 
>> 
>> Hello all,
>> 
>> I am tracking hundreds of animals through a system with multiple timing
>> points.  I want to graph the movement of individuals through the whole
>> array on one graph, but I can't figure out how to do that.  An example
>> of
>> my data is below.  Basically for each 'TagID', I want to graph the
>> 'date'
>> or 'gspd_mps' on the X axis and 'Station' on the Y axis, with all
>> TagID's
>> on one graph.
>> 
> 
> Thanks for the help!!  I'm very new to R.
> Natalie
> 
>    TagID Station datetime gspd_mps  4926 KLB 12/21/2012 1:52 NA  4926
> MS01 12/21/2012
> 2:38 0.851  4926 MS02 12/21/2012 3:48 0.629  4926 MS03 12/21/2012 4:19
> 0.86
> 4926 MS04 12/21/2012 4:34 1.131  4926 MS05 12/21/2012 5:01 0.9  4926
> MS06 12/21/2012
> 6:54 0.798  4926 MS07 12/21/2012 7:21 0.853  4926 MS08 12/21/2012 10:23
> 0.694  4926 MS09 12/21/2012 12:16 0.6  4926 MS10 12/21/2012 14:38 0.647
> 4929 KLB 12/21/2012 1:08 NA  4929 MS01 12/21/2012 2:12 0.611  4929
> MS02 12/21/2012
> 3:33 0.563  4929 MS03 12/21/2012 3:59 1.04  4929 MS04 12/21/2012 4:13
> 1.082
> 4929 MS05 12/21/2012 5:00 0.475  4929 MS06 12/21/2012 6:52 0.796  4929
> MS07 12/21/2012
> 7:32 0.563  4929 MS08 12/21/2012 10:16 0.809  4929 MS09 12/21/2012 11:43
> 0.783  4929 MS10 12/21/2012 14:02 0.657  4929 MS11 12/22/2012 2:50 0.326
> 4929 MS12 12/22/2012 5:04 0.709  4929 MS13 12/22/2012 13:59 0.688
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From ii54250 at msn.com  Mon Nov 25 15:46:02 2013
From: ii54250 at msn.com (IOANNA)
Date: Mon, 25 Nov 2013 14:46:02 +0000
Subject: [R]  Aggregating spatial data
Message-ID: <DUB126-DS25882EDD4A1C4E978986B1F3ED0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/f82954db/attachment.pl>

From dcarlson at tamu.edu  Mon Nov 25 16:20:50 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 25 Nov 2013 09:20:50 -0600
Subject: [R] Aggregating spatial data
In-Reply-To: <DUB126-DS25882EDD4A1C4E978986B1F3ED0@phx.gbl>
References: <DUB126-DS25882EDD4A1C4E978986B1F3ED0@phx.gbl>
Message-ID: <020f01cee9f1$ecd49cf0$c67dd6d0$@tamu.edu>

Something like this?

> s <- expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))
> w <-
data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4)),
+   z2=seq(1,length(s$x),by=1))
> w$EW <- cut(w$x, breaks=c(.5, 50.5, 100.5), labels=c("West",
"East"))
> w$NS <- cut(w$y, breaks=c(.5, 50.5, 100.5), labels=c("South",
"North"))
> aggregate(z1~EW+NS, w, table)
    EW    NS z1.1 z1.2 z1.3 z1.4
1 West South 2600 2600 2400 2400
2 East South 2400 2400 2600 2600
3 West North 2600 2600 2400 2400
4 East North 2400 2400 2600 2600
> table(w$z1)

    1     2     3     4 
10000 10000 10000 10000 
> aggregate(z2~EW+NS, w, mean)
    EW    NS     z2
1 West South 2475.5
2 East South 2525.5
3 West North 7475.5
4 East North 7525.5

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of IOANNA
Sent: Monday, November 25, 2013 8:46 AM
To: r-help at r-project.org
Subject: [R] Aggregating spatial data
Importance: High

Hello all, 

 

I have a data frame in the form:

 

s<-expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))

w<-data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4))
,z2=seq(1,le
ngth(s$x),by=1))

 

The w$x and w$y represent the location of points and z1 and z2
attributes
corresponding to these points. 

 

 

My question is how to divide this area in 4 sub-areas of equal
points each
and produce the counts of z1= '1', '2' , '3' in each quarter as
well as mean
values of z2 for each quarter. 

 

Best, 

Ioanna


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From murdoch.duncan at gmail.com  Mon Nov 25 16:24:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 Nov 2013 10:24:27 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CABdHhvGVJ24oJ6M9GB3wxb+ZXZp1kh3J6rJQStqVjUNs32N7qw@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<52925AEE.1040505@gmail.com>
	<CANROs4dTLn9qSCkZPNWj+N60JOKnOb0gz5OXT9nZv2FtaEnx4Q@mail.gmail.com>
	<52927163.9090508@gmail.com>
	<CABdHhvGVJ24oJ6M9GB3wxb+ZXZp1kh3J6rJQStqVjUNs32N7qw@mail.gmail.com>
Message-ID: <52936BAB.8030807@gmail.com>

On 25/11/2013 8:47 AM, Hadley Wickham wrote:
> >> I do not see how it can be illegal to download and duplicate the
> >> posts, since all the content is licensed under CC BY-SA. I might have
> >> missed something there: http://stackexchange.com/legal If that is
> >> really the case, I think I will have to reconsider if I should use it
> >> any more.
> >
> > I'm not a lawyer, but I see claims restricting users to "personal use".
>
> Neither am I, but I don't see any claims about personal use in the
> "Subscriber Content" section, which is what concerns content that
> other people have uploaded to stackoverflow. As Yihui says, all
> questions and answers (as opposed to the stuff written by
> stackoverflow the company) is licensed with
> http://creativecommons.org/licenses/by-sa/2.5/.
>
> I suspect you'll find that the mailing list is in more of a grey area
> since authors own the copyright to their posts and haven't agreed to
> any redistribution (apart from what is obvious in signing up for a
> mailing list).

I like the colour grey.  It means that the mailing list is archived in 
lots of places.  SO isn't.

Duncan Murdoch


From marc_schwartz at me.com  Mon Nov 25 16:25:45 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 25 Nov 2013 09:25:45 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>
Message-ID: <8E90E04A-53CD-413B-84CD-9F4A8AC123E5@me.com>

On Nov 25, 2013, at 7:56 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
> 
> I doubt if people start to search answers if they often do not search them in help pages and documentation provided. 
> 
> I must agree with Duncan that if Stackoverflow was far more better than this help list most people would seek advice there then here. Is there any evidence in decreasing traffic here? 
> 
> Anyway, similar discussion went in 2003 with outcome that was not in favour for separate beginner list http://tolstoy.newcastle.edu.au/R/help/03b/7944.html
> 
> Petr
> 
> BTW it is pitty that r help archive does not extend over year 2012. I found that *Last message date: Tue 31 Jan 2012 - 12:19:21 GMT


Petr,

I may be confusing your final statement above, but the **main** R-Help archive is current to today:

  https://stat.ethz.ch/pipermail/r-help/

That being said, as one who has been interacting on R-Help (and other R-* lists) for a dozen years or so, I would have to say that one would need to have their head in the sand to not be cognizant of the dramatic decline in the traffic on R-Help in recent years. Simply keeping subjective track of the declining daily traffic ought to be sufficient.

Due to work related time constraints, my posting here in recent times has dropped notably. I do still read many of the R-Help posts and along with Martin, am co-moderator on R-Devel. So am still involved in that capacity.

I do follow SO and SE via RSS feed, so am aware of the increasing traffic there, albeit, I have not posted there.

In addition, there are a multitude of other online locations where R related posts have begun to accumulate. These include various LinkedIn groups, R related blogs, ResearchGate and others. I do believe, however, that SO is the dominant force in the shift of traffic.

To answer Petr's question above, I updated and re-ran some code that I had used some years ago to estimate the traffic on various lists/fora:

  https://stat.ethz.ch/pipermail/r-help/2009-January/184196.html

To that end, I am attaching a PDF file that contains a barplot of the annual R-Help traffic volume since 1997, through this month. The grey bars represent the actual annual traffic volumes of posts to R-Help.

For 2013, I added a red segment to the bar, which shows the projected number of posts for the full year, albeit, it is simply based upon the mean number of posts per day, averaged over the YTD volume, projected over the remaining days in the year, without any seasonal adjustments. So it may be optimistic, as we are coming into the holiday season for many.

Bottom line, while the trend was dramatically positive through 2010, peaking at a little over 41,000 total posts, the volume has just as dramatically declined in 2013 to a projected ~21,400. This means that the volume for 2013 has dropped back to the approximate volume of 2005.

Only time will tell if the dramatic decline will continue, or reach some new reasonable asymptote that is simply reflective of the distribution of traffic on various other online resources.

To the original query posted by Bert, I would say no, there is not a need for a beginner's list.

Regards,

Marc Schwartz


-------------- next part --------------
A non-text attachment was scrubbed...
Name: R-Help.pdf
Type: application/pdf
Size: 4934 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/d021dc80/attachment.pdf>
-------------- next part --------------




From h.wickham at gmail.com  Mon Nov 25 16:55:05 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Nov 2013 09:55:05 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <8E90E04A-53CD-413B-84CD-9F4A8AC123E5@me.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>
	<8E90E04A-53CD-413B-84CD-9F4A8AC123E5@me.com>
Message-ID: <CABdHhvEayivC2RHQLwvYSxD4BRK0FvHTDNN-jUbQzmp7Hdq2Sw@mail.gmail.com>

Here's a similar plot for stackoverflow:
http://data.stackexchange.com/stackoverflow/query/150130/r-questions-and-answers-per-year#graph

and one broken down by month
http://data.stackexchange.com/stackoverflow/query/150129/r-questions-and-answers-per-month#graph

Hadley

On Mon, Nov 25, 2013 at 9:25 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Nov 25, 2013, at 7:56 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> I doubt if people start to search answers if they often do not search them in help pages and documentation provided.
>>
>> I must agree with Duncan that if Stackoverflow was far more better than this help list most people would seek advice there then here. Is there any evidence in decreasing traffic here?
>>
>> Anyway, similar discussion went in 2003 with outcome that was not in favour for separate beginner list http://tolstoy.newcastle.edu.au/R/help/03b/7944.html
>>
>> Petr
>>
>> BTW it is pitty that r help archive does not extend over year 2012. I found that *Last message date: Tue 31 Jan 2012 - 12:19:21 GMT
>
>
> Petr,
>
> I may be confusing your final statement above, but the **main** R-Help archive is current to today:
>
>   https://stat.ethz.ch/pipermail/r-help/
>
> That being said, as one who has been interacting on R-Help (and other R-* lists) for a dozen years or so, I would have to say that one would need to have their head in the sand to not be cognizant of the dramatic decline in the traffic on R-Help in recent years. Simply keeping subjective track of the declining daily traffic ought to be sufficient.
>
> Due to work related time constraints, my posting here in recent times has dropped notably. I do still read many of the R-Help posts and along with Martin, am co-moderator on R-Devel. So am still involved in that capacity.
>
> I do follow SO and SE via RSS feed, so am aware of the increasing traffic there, albeit, I have not posted there.
>
> In addition, there are a multitude of other online locations where R related posts have begun to accumulate. These include various LinkedIn groups, R related blogs, ResearchGate and others. I do believe, however, that SO is the dominant force in the shift of traffic.
>
> To answer Petr's question above, I updated and re-ran some code that I had used some years ago to estimate the traffic on various lists/fora:
>
>   https://stat.ethz.ch/pipermail/r-help/2009-January/184196.html
>
> To that end, I am attaching a PDF file that contains a barplot of the annual R-Help traffic volume since 1997, through this month. The grey bars represent the actual annual traffic volumes of posts to R-Help.
>
> For 2013, I added a red segment to the bar, which shows the projected number of posts for the full year, albeit, it is simply based upon the mean number of posts per day, averaged over the YTD volume, projected over the remaining days in the year, without any seasonal adjustments. So it may be optimistic, as we are coming into the holiday season for many.
>
> Bottom line, while the trend was dramatically positive through 2010, peaking at a little over 41,000 total posts, the volume has just as dramatically declined in 2013 to a projected ~21,400. This means that the volume for 2013 has dropped back to the approximate volume of 2005.
>
> Only time will tell if the dramatic decline will continue, or reach some new reasonable asymptote that is simply reflective of the distribution of traffic on various other online resources.
>
> To the original query posted by Bert, I would say no, there is not a need for a beginner's list.
>
> Regards,
>
> Marc Schwartz
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
http://had.co.nz/


From b.rowlingson at lancaster.ac.uk  Mon Nov 25 16:58:22 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 25 Nov 2013 15:58:22 +0000
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <e6fd6d0fbc6645508e20a0a9f17bc9ef@EX-0-HT0.lancs.local>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>
	<e6fd6d0fbc6645508e20a0a9f17bc9ef@EX-0-HT0.lancs.local>
Message-ID: <CANVKczNsxHR--sk-hFDMhETreTbQavU68=zHEuv=Vqb=7x415Q@mail.gmail.com>

Joran (on StackOverflow chat, funnily enough) has just pointed us to this:

http://www.win.tue.nl/~bvasiles/papers/cscw14.pdf  "How Social Q&A
Sites are Changing Knowledge Sharing
in Open Source Software Communities"

which includes a graph of postings to R-help and questions tagged
'[r]' on StackOverflow. By the end of 2012 SO was getting about twice
as many [r]-tagged questions as R-help was getting new threads.

The paper is a very detailed discussion on the use of mailing lists
and discussion sites.


On Mon, Nov 25, 2013 at 3:25 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> On Nov 25, 2013, at 7:56 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> I doubt if people start to search answers if they often do not search them
>> in help pages and documentation provided.
>>
>> I must agree with Duncan that if Stackoverflow was far more better than
>> this help list most people would seek advice there then here. Is there any
>> evidence in decreasing traffic here?
>>
>> Anyway, similar discussion went in 2003 with outcome that was not in
>> favour for separate beginner list
>> http://tolstoy.newcastle.edu.au/R/help/03b/7944.html
>>
>> Petr
>>
>> BTW it is pitty that r help archive does not extend over year 2012. I
>> found that *Last message date: Tue 31 Jan 2012 - 12:19:21 GMT
>
>
> Petr,
>
> I may be confusing your final statement above, but the **main** R-Help
> archive is current to today:
>
>   https://stat.ethz.ch/pipermail/r-help/
>
> That being said, as one who has been interacting on R-Help (and other R-*
> lists) for a dozen years or so, I would have to say that one would need to
> have their head in the sand to not be cognizant of the dramatic decline in
> the traffic on R-Help in recent years. Simply keeping subjective track of
> the declining daily traffic ought to be sufficient.
>
> Due to work related time constraints, my posting here in recent times has
> dropped notably. I do still read many of the R-Help posts and along with
> Martin, am co-moderator on R-Devel. So am still involved in that capacity.
>
> I do follow SO and SE via RSS feed, so am aware of the increasing traffic
> there, albeit, I have not posted there.
>
> In addition, there are a multitude of other online locations where R related
> posts have begun to accumulate. These include various LinkedIn groups, R
> related blogs, ResearchGate and others. I do believe, however, that SO is
> the dominant force in the shift of traffic.
>
> To answer Petr's question above, I updated and re-ran some code that I had
> used some years ago to estimate the traffic on various lists/fora:
>
>   https://stat.ethz.ch/pipermail/r-help/2009-January/184196.html
>
> To that end, I am attaching a PDF file that contains a barplot of the annual
> R-Help traffic volume since 1997, through this month. The grey bars
> represent the actual annual traffic volumes of posts to R-Help.
>
> For 2013, I added a red segment to the bar, which shows the projected number
> of posts for the full year, albeit, it is simply based upon the mean number
> of posts per day, averaged over the YTD volume, projected over the remaining
> days in the year, without any seasonal adjustments. So it may be optimistic,
> as we are coming into the holiday season for many.
>
> Bottom line, while the trend was dramatically positive through 2010, peaking
> at a little over 41,000 total posts, the volume has just as dramatically
> declined in 2013 to a projected ~21,400. This means that the volume for 2013
> has dropped back to the approximate volume of 2005.
>
> Only time will tell if the dramatic decline will continue, or reach some new
> reasonable asymptote that is simply reflective of the distribution of
> traffic on various other online resources.
>
> To the original query posted by Bert, I would say no, there is not a need
> for a beginner's list.
>
> Regards,
>
> Marc Schwartz
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Mon Nov 25 17:01:29 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Nov 2013 10:01:29 -0600
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CABdHhvEayivC2RHQLwvYSxD4BRK0FvHTDNN-jUbQzmp7Hdq2Sw@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<52929A16.4020501@gmail.com>
	<5292558A020000CB000F8FD5@smtp.medicine.umaryland.edu>
	<CAKy1A=G7a3q6FZYHP9fFKW1QAwNUv7GHBSsizPt1xR_=pEKcuA@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA0681@SRVEXCHMBX.precheza.cz>
	<8E90E04A-53CD-413B-84CD-9F4A8AC123E5@me.com>
	<CABdHhvEayivC2RHQLwvYSxD4BRK0FvHTDNN-jUbQzmp7Hdq2Sw@mail.gmail.com>
Message-ID: <CABdHhvHwkMqmMkLLAmC3PHFbVtEg4VwR0wYtMxnWOoh00HBnLg@mail.gmail.com>

Oops, I misunderstood the database schema, and that only includes
_questions_ tagged R, not the corresponding answers.

Hadley

On Mon, Nov 25, 2013 at 9:55 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> Here's a similar plot for stackoverflow:
> http://data.stackexchange.com/stackoverflow/query/150130/r-questions-and-answers-per-year#graph
>
> and one broken down by month
> http://data.stackexchange.com/stackoverflow/query/150129/r-questions-and-answers-per-month#graph
>
> Hadley
>
> On Mon, Nov 25, 2013 at 9:25 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> On Nov 25, 2013, at 7:56 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>
>>> Hi
>>>
>>> I doubt if people start to search answers if they often do not search them in help pages and documentation provided.
>>>
>>> I must agree with Duncan that if Stackoverflow was far more better than this help list most people would seek advice there then here. Is there any evidence in decreasing traffic here?
>>>
>>> Anyway, similar discussion went in 2003 with outcome that was not in favour for separate beginner list http://tolstoy.newcastle.edu.au/R/help/03b/7944.html
>>>
>>> Petr
>>>
>>> BTW it is pitty that r help archive does not extend over year 2012. I found that *Last message date: Tue 31 Jan 2012 - 12:19:21 GMT
>>
>>
>> Petr,
>>
>> I may be confusing your final statement above, but the **main** R-Help archive is current to today:
>>
>>   https://stat.ethz.ch/pipermail/r-help/
>>
>> That being said, as one who has been interacting on R-Help (and other R-* lists) for a dozen years or so, I would have to say that one would need to have their head in the sand to not be cognizant of the dramatic decline in the traffic on R-Help in recent years. Simply keeping subjective track of the declining daily traffic ought to be sufficient.
>>
>> Due to work related time constraints, my posting here in recent times has dropped notably. I do still read many of the R-Help posts and along with Martin, am co-moderator on R-Devel. So am still involved in that capacity.
>>
>> I do follow SO and SE via RSS feed, so am aware of the increasing traffic there, albeit, I have not posted there.
>>
>> In addition, there are a multitude of other online locations where R related posts have begun to accumulate. These include various LinkedIn groups, R related blogs, ResearchGate and others. I do believe, however, that SO is the dominant force in the shift of traffic.
>>
>> To answer Petr's question above, I updated and re-ran some code that I had used some years ago to estimate the traffic on various lists/fora:
>>
>>   https://stat.ethz.ch/pipermail/r-help/2009-January/184196.html
>>
>> To that end, I am attaching a PDF file that contains a barplot of the annual R-Help traffic volume since 1997, through this month. The grey bars represent the actual annual traffic volumes of posts to R-Help.
>>
>> For 2013, I added a red segment to the bar, which shows the projected number of posts for the full year, albeit, it is simply based upon the mean number of posts per day, averaged over the YTD volume, projected over the remaining days in the year, without any seasonal adjustments. So it may be optimistic, as we are coming into the holiday season for many.
>>
>> Bottom line, while the trend was dramatically positive through 2010, peaking at a little over 41,000 total posts, the volume has just as dramatically declined in 2013 to a projected ~21,400. This means that the volume for 2013 has dropped back to the approximate volume of 2005.
>>
>> Only time will tell if the dramatic decline will continue, or reach some new reasonable asymptote that is simply reflective of the distribution of traffic on various other online resources.
>>
>> To the original query posted by Bert, I would say no, there is not a need for a beginner's list.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> http://had.co.nz/



-- 
http://had.co.nz/


From pgilbert902 at gmail.com  Mon Nov 25 18:10:53 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 25 Nov 2013 12:10:53 -0500
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <mailman.17.1385377207.30613.r-help@r-project.org>
References: <mailman.17.1385377207.30613.r-help@r-project.org>
Message-ID: <5293849D.8010902@gmail.com>



On 13-11-25 06:00 AM, r-help-request at r-project.org wrote:
> Date: Sun, 24 Nov 2013 13:04:43 -0600
> From: Yihui Xie<xie at yihui.name>
> To: Bert Gunter<gunter.berton at gene.com>
> Cc:"r-help at r-project.org"  <r-help at r-project.org>
> Subject: Re: [R] Should there be an R-beginners list?
> Message-ID:
> 	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> I'm not aware of a discussion on this, but I would say no.

Just for the record, there was a discussion of this in a thread called 
"newbie list" in August 2001 when R-help started getting busy:
   http://tolstoy.newcastle.edu.au/R/help/01c/0880.html
Predates StackOverflow I think, but several of the comments may still be 
valid.

Paul

> Fragmentation is bad. Further fragmentation is worse.
>
> TL;DR
> =====
>
> Actually I'd say all mailing lists except r-devel should be moving to
> StackOverlow in the future (disclaimer: I'm not affiliated with it).
> Mailing lists are good for a smaller group of people, and especially
> good when more focused on discussions on development (including bug
> reports). The better place for questions is a web forum. Both you and
> I have been staying in these R mailing lists for a few years now. You
> can recall how many times a user was asked to post to another mailing
> list ("this is not an appropriate list to ask your question; please
> post to r-such-and-such instead"), how many times you see something
> like "Alternative HTML removed", how many times you see a post "Bla
> Bla (was: Foo Bar)", and how many times users were reminded "Please
> read the posting guide", "Please do read", and "PLEASE do read". But
> it just does not help much even if you write "PLEASE DO READ".
>
> Why do we have such problems in the mailing lists again and again? Is
> that simply because users are not respecting the rules? I do not think
> so. I believe that is the flaw of mailing lists. A mailing list is
> managed by a small team (hey, Martin, thank you). On StackOverflow,
> you simply edit the tags of a post to make it belong to a new "mailing
> list" (you can post with tags "r+ubuntu+graphics", or "r+lattice",
> etc). There is no need to request and wait for the system admin to
> make a decision. Users can help themselves, and help others as well.
> HTML can be good in many cases, actually. Who hates syntax
> highlighting and R plots in an R question? You are free to ask a
> question that is poorly formatted, and there are good chances that it
> will be immediately edited by another experienced user. You are free
> to yell in the comments asking for more details before posting a
> formal answer. You can express "ah, this is a bad question" by
> down-voting so that future readers know that guy screwed up and we
> just let the world ignore the noise. It is like peer-review, and the
> reviewers can help you improve your post. In a mailing list, when you
> are done, you are done. You are forever written in history, right or
> wrong, smart or stupid. You want to delete your record in the history?
> No, no, gentleman, it was your fault not reading the post guide.
>
> For me, I understand all the rationale behind the mailing list model.
> I'm just saying, the primary goal for such a service is to discuss
> issues about R, instead of issues induced by the mailing list itself.
> We could have made some issues not directly related to R go away by
> community efforts instead of giving instructions a million times,
> given an appropriate platform.
>
> Five years, 42,000 posts:http://stackoverflow.com/questions/tagged/r
> I'm not terribly worried about transition from mailing lists to SO.
>
> Sorry about the generalization of the original topic, but I hate using
> a new title "Should there be R mailing lists? (was: Should there be an
> R-beginners list?)"
>
> Last but not least, I probably need to clarify that I benefited a lot
> from the mailing lists in the past, and I truly appreciate it. I wrote
> this with the future in mind, not the past. The past was good, and the
> future can be better.
>
> Regards,
> Yihui
> --
> Yihui Xie<xieyihui at gmail.com>
> Web:http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Sun, Nov 24, 2013 at 11:13 AM, Bert Gunter<gunter.berton at gene.com>  wrote:
>> >Folks:
>> >
>> >If this has been previously discussed and settled, please say so and
>> >refer me to the discussion. If you believe this to be inappropriate or
>> >otherwise frivolous, also please say so, as I do not wish to waste
>> >your time or this space.
>> >
>> >I write as a long time reader and sometimes contributor to r-help. Due
>> >to R's growth in usage by a broad data analysis community (engineers,
>> >scientists, social scientists, finance, "informaticians", as well as
>> >more "traditional" statisticians), this list seems to me to becoming
>> >deluged by requests for help by "casual" users and students for whom R
>> >is not going to be regularly or extensively used. I would characterize
>> >this group as having only basic statistical, programming, and data
>> >analysis skills. This is not meant as a criticism, and there are
>> >certainly many for whom this is inaccurate. But ...
>> >
>> >By and large, such users have not spend much time with R's docs,
>> >including tutorials or FAQ's. Many of their posts reflect this, and
>> >can be answered with basic replies or references to docs, to wit: What
>> >is the difference between "ifelse" and "if else"? FAQ 7.31. Confusion
>> >of data frames, matrices, and spreadsheet tables; etc.
>> >
>> >Would it be useful, then, to establish an R-beginners list
>> >specifically to absorb this traffic and free up R-help from what I
>> >would say was its original intent, to provide a forum for serious,
>> >more dedicated R users (Again, no criticism is intended here)?
>> >
>> >I realize that, whether or not this suggestion is worthwhile, there
>> >are several ways it could fail. First, too few might be interested in
>> >responding to posts on the new list. Second, too few might consider
>> >themselves "beginners" who post to it. Etc. So I would certainly say
>> >any such effort ought to be a pilot and tentative .
>> >
>> >I'll stop here. Again, criticize freely and/or send me off somewhere
>> >else to prior discussion. Or to where it should be discussed. Or just
>> >ignore, of course.
>> >
>> >Best,
>> >Bert
>> >
>> >
>> >
>> >--
>> >
>> >Bert Gunter
>> >Genentech Nonclinical Biostatistics
>> >
>> >(650) 467-7374


From carl at witthoft.com  Mon Nov 25 18:13:47 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 25 Nov 2013 09:13:47 -0800 (PST)
Subject: [R] convert data frame: two variables into _one_ binary variable
In-Reply-To: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
References: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
Message-ID: <1385399627282-4681123.post@n4.nabble.com>

In R,  as.logical() and other functions treat anything >0 as TRUE.  Thus:

Rgames> foo<-sample(0:5,10,rep=TRUE)
Rgames> foo
 [1] 0 5 1 0 1 5 2 5 4 5
Rgames> as.logical(foo)
 [1] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

For your case,  simply  (womensrole$agree>womensrole$disagree) will return
the logical vector you want.
Just for info,
In R,  as.logical() and other functions treat anything >0 as TRUE.  Thus:

Rgames> foo<-sample(0:5,10,rep=TRUE)
Rgames> foo
 [1] 0 5 1 0 1 5 2 5 4 5
Rgames> as.logical(foo)
 [1] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE



Liviu Andronic wrote
> Dear all,
> I am trying to convert the following data frame into a format more
> useful for me:
>> library("HSAUR2", lib.loc="C:/Program Files/R/R-3.0.2/library")
> Loading required package: tools
> 
> Attaching package: ?HSAUR2?
> 
> The following object is masked _by_ ?.GlobalEnv?:
> 
>     womensrole
> 
>> head(womensrole)
>   education gender agree disagree sexe
> 1         0   Male     4        2    0
> 2         1   Male     2        0    0
> 3         2   Male     4        0    0
> 4         3   Male     6        3    0
> 5         4   Male     5        5    0
> 6         5   Male    13        7    0
> 
> 
> In 'womensrole', how do I convert 'agree' and 'disagree' variables
> into one proper binary variable, say:
>   education gender agree sexe
> 1         0   Male     TRUE           0
> 2         0   Male     TRUE           0
> 3         0   Male     TRUE           0
> 4         0   Male     TRUE           0
> 5         0   Male     FALSE           0
> 6         0   Male     FALSE           0
> 7         1   Male     TRUE           0
> 8         1   Male     TRUE           0
> 9         2   Male     TRUE           0
> 10         2   Male     TRUE           0
> 11         2   Male     TRUE           0
> 12         2   Male     TRUE           0
> [..]
> 
> I'm sure there is an easy way to do this (in the form of 'melt',
> 'cast', etc.), but I'm not sure how to approach the problem.
> 
> Regards,
> Liviu
> 
> -- 
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/convert-data-frame-two-variables-into-one-binary-variable-tp4681098p4681123.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Mon Nov 25 18:18:16 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Mon, 25 Nov 2013 09:18:16 -0800 (PST)
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
Message-ID: <1385399896439-4681124.post@n4.nabble.com>

A couple things:
First,  "Beginners' lists" never work.  Beginners invariably can't read (cf.
posting guidelines), so they will post to the "main" list anyway.

Second, I see some people prefer to receive email-lists of the topics, and
others prefer to work via a webbrowser interface.  I'd have to say the
overwhelming popularity of StackExchange suggests the latter is a much
bigger group.  AFAIK it's possible to generate an RSS or possibly some sort
of pure e-mail feed from SO but I don't know for certain, but in any case, 
the only question is whether r-help will die of lonliness.  Nobody is
suggesting it be shut down.  

I'll also point out that it's much easier to filter SO (by topic and by
score) than r-help.

Carl, the DataMungerGuru-accolyte



--
View this message in context: http://r.789695.n4.nabble.com/Should-there-be-an-R-beginners-list-tp4681068p4681124.html
Sent from the R help mailing list archive at Nabble.com.


From dcarlson at tamu.edu  Mon Nov 25 18:59:55 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 25 Nov 2013 11:59:55 -0600
Subject: [R] convert data frame: two variables into _one_ binary variable
In-Reply-To: <1385399627282-4681123.post@n4.nabble.com>
References: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
	<1385399627282-4681123.post@n4.nabble.com>
Message-ID: <003501ceea08$25920e90$70b62bb0$@tamu.edu>

I think the OP was looking to expand the data frame so that each row was a single observation so that the first row becomes 6 rows, 4-TRUE and 2-FALSE. Something like this

> womensrole <- HSAUR::womensrole
> step1 <- reshape(womensrole, varying=c("agree", "disagree"), 
+   v.names="Freq", timevar="Agree", times=c(TRUE, FALSE), 
+   direction="long")
> step1 <- step1[order(step1$id),]
> rownames(step1) <- NULL # Simplify the row names
> step2 <- step1[rep(rownames(step1), step1$Freq), c(5, 1:3)]
> rownames(step2) <- NULL # Simplify the row names
> head(step2, 12)
   id education  sex Agree
1   1         0 Male  TRUE
2   1         0 Male  TRUE
3   1         0 Male  TRUE
4   1         0 Male  TRUE
5   1         0 Male FALSE
6   1         0 Male FALSE
7   2         1 Male  TRUE
8   2         1 Male  TRUE
9   3         2 Male  TRUE
10  3         2 Male  TRUE
11  3         2 Male  TRUE
12  3         2 Male  TRUE

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Carl Witthoft
Sent: Monday, November 25, 2013 11:14 AM
To: r-help at r-project.org
Subject: Re: [R] convert data frame: two variables into _one_ binary variable

In R,  as.logical() and other functions treat anything >0 as TRUE.  Thus:

Rgames> foo<-sample(0:5,10,rep=TRUE)
Rgames> foo
 [1] 0 5 1 0 1 5 2 5 4 5
Rgames> as.logical(foo)
 [1] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

For your case,  simply  (womensrole$agree>womensrole$disagree) will return
the logical vector you want.
Just for info,
In R,  as.logical() and other functions treat anything >0 as TRUE.  Thus:

Rgames> foo<-sample(0:5,10,rep=TRUE)
Rgames> foo
 [1] 0 5 1 0 1 5 2 5 4 5
Rgames> as.logical(foo)
 [1] FALSE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE



Liviu Andronic wrote
> Dear all,
> I am trying to convert the following data frame into a format more
> useful for me:
>> library("HSAUR2", lib.loc="C:/Program Files/R/R-3.0.2/library")
> Loading required package: tools
> 
> Attaching package: ?HSAUR2?
> 
> The following object is masked _by_ ?.GlobalEnv?:
> 
>     womensrole
> 
>> head(womensrole)
>   education gender agree disagree sexe
> 1         0   Male     4        2    0
> 2         1   Male     2        0    0
> 3         2   Male     4        0    0
> 4         3   Male     6        3    0
> 5         4   Male     5        5    0
> 6         5   Male    13        7    0
> 
> 
> In 'womensrole', how do I convert 'agree' and 'disagree' variables
> into one proper binary variable, say:
>   education gender agree sexe
> 1         0   Male     TRUE           0
> 2         0   Male     TRUE           0
> 3         0   Male     TRUE           0
> 4         0   Male     TRUE           0
> 5         0   Male     FALSE           0
> 6         0   Male     FALSE           0
> 7         1   Male     TRUE           0
> 8         1   Male     TRUE           0
> 9         2   Male     TRUE           0
> 10         2   Male     TRUE           0
> 11         2   Male     TRUE           0
> 12         2   Male     TRUE           0
> [..]
> 
> I'm sure there is an easy way to do this (in the form of 'melt',
> 'cast', etc.), but I'm not sure how to approach the problem.
> 
> Regards,
> Liviu
> 
> -- 
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/convert-data-frame-two-variables-into-one-binary-variable-tp4681098p4681123.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Nov 25 19:45:46 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 25 Nov 2013 18:45:46 +0000
Subject: [R] Speeding up code
In-Reply-To: <DUB124-W60450242921F2B111DADB80E30@phx.gbl>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521910D5A289C@PRDEXMBX-08.the-lab.llnl.gov>

ditto to everything Jeff Newmiller said, but I'll take it a little further.

I'm guessing that with
   df <- data.frame(31790,31790)
you thought you were creating something with 31790 rows and 31790 columns.
You weren't. You were creating a data frame with one row and two columns:

> data.frame(31790,31790)
  X31790 X31790.1
1  31790    31790

Given that in your loop you assign values to df[i,j],
and having started with just one row and two columns, it follows
that every time you assign to df[i,j] you are increasing
the size of your data frame, and that will slow things down.

Initialize with a matrix (I'll call it 'res' instead of 'df'):

  res <- matrix(NA, 31790,31790)

Then inside your loop, you can use
  

   if (dis2<=500) res[i,j] <- ken

No need to deal with 'else', since the matrix is initialized
with NA.

The ifelse() function was a less than ideal choice,
since it is designed for vector arguments, and your value, dis2,
appears to always have length = 1. You could have used
  df[i,j] <- if (dis2 <= 500) ken else NA
but as I mentioned above, if you initialize to NA there's no need
handle the 'else' case inside the loop.

It may be possible to vectorize your loop, but I kind of doubt it,
considering that you're using the cor() followed by the deg.dist()
function at every iteration.

However, you could calculate the dis2 value first, and then calculate
ken only when dis2 is <= 500. You're calculating ken even when it's not
needed. Avoiding that should speed things up.

I don't know what deg.dist() is doing, but if it is calculating distances
between points, there are functions for doing that on whole bunches
of points at once. Perhaps your data could be rearranged to work
with one of those.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 11/23/13 1:39 PM, "Amie Hunter" <amie_hunter at hotmail.com> wrote:

>Hello R experts, 
>
>I'm new to R and I'm wanting to know what is the best way to speed up my
>code. I've read that you can vectorize the code but I'm unsure on how to
>implement this into my code.
>
>
>df <- data.frame(31790,31790)
>
>for (i in 1:31790)
>{
>  for (j in i:31790)
>  {
>    ken<-cor(cldm[i,3:17],cldm[j,3:17], method="kendall", use="pairwise")
>    dis2<-deg.dist(cldm[i,2],cldm[i,1],cldm[j,2],cldm[j,1])
>    
>    df[i,j]<-ifelse(dis2<=500,ken,NA)
>    }
>  } 
>df
>
>Thanks! 		 	   		 
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tgs.public.mail at gmail.com  Mon Nov 25 20:26:33 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Mon, 25 Nov 2013 14:26:33 -0500
Subject: [R] convert data frame: two variables into _one_ binary variable
In-Reply-To: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
References: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
Message-ID: <CAHJ=y95Y5ty7jtSyYVFh-PDVaP_6WAhnguZWCP=sNAzM-POWSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/aa52f58b/attachment.pl>

From Jason.Law at portlandoregon.gov  Mon Nov 25 21:24:03 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Mon, 25 Nov 2013 12:24:03 -0800
Subject: [R] Plotting multiple trends on one graph
In-Reply-To: <000c01cee972$1e2b97c0$5a82c740$@bigpond.com>
References: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
	<000c01cee972$1e2b97c0$5a82c740$@bigpond.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184F0D238D5@MAIL2.rose.portland.local>

Natalie,

I'm assuming this is some kind of passive animal sampling?  Instream PIT tags for fish?  In that case, you can get what I think you want using ggplot2 and something like this:

dat$TagID <- as.factor(dat$TagID)
dat$Station <- as.factor(dat$Station)
dat$Station2 <- as.numeric(dat$Station)

ggplot(dat, aes(datetime, Station2, colour = TagID)) + geom_line() + scale_y_continuous(breaks = 1:nlevels(dat$Station), labels = levels(dat$Station))

This assumes that the stations are equidistant.  If you have actual distances between your sampling stations and would like your graphs to reflect that you can easily modify the code above so that you plot the distances on the y axis and then label the axis using scale_y_continuous.

Using facet_wrap or facet_grid will let you separate the animals into different plots.  

Regards,

Jason Law
Statistician
City of Portland
Bureau of Environmental Services
Water Pollution Control Laboratory
6543 N Burlington Avenue
Portland, OR 97203-5452
jason.law at portlandoregon.gov

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Mackay
Sent: Sunday, November 24, 2013 4:06 PM
To: 'Natalie Houghton McNair'
Cc: R
Subject: Re: [R] Plotting multiple trends on one graph

Hi Natalie

Here is an option using lattice. I think below will get you some way to what you want

This is your data formatted. in future please dput your data  as your data was scrambled.
# dput(dat)
dat <- structure(list(TagID = c(4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4926L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L), Station = c("KLB", "MS01", "MS02", "MS03", "MS04", "MS05", "MS06", "MS07", "MS08", "MS09", "MS10", "KLB", "MS01", "MS02", "MS03", "MS04", "MS05", "MS06", "MS07", "MS08", "MS09", "MS10", "MS11", "MS12", "MS13"), datetime = c("12/21/2012 1:52", "12/21/2012 2:38",
"12/21/2012 3:48", "12/21/2012 4:19", "12/21/2012 4:34", "12/21/2012 5:01",
"12/21/2012 6:54", "12/21/2012 7:21", "12/21/2012 10:23", "12/21/2012 12:16",
"12/21/2012 14:38", "12/21/2012 1:08", "12/21/2012 2:12", "12/21/2012 3:33",

"12/21/2012 3:59", "12/21/2012 4:13", "12/21/2012 5:00", "12/21/2012 6:52",
"12/21/2012 7:32", "12/21/2012 10:16", "12/21/2012 11:43", "12/21/2012 14:02",
"12/22/2012 2:50", "12/22/2012 5:04", "12/22/2012 13:59"), gspd_mps = c(NA, 0.851, 0.629, 0.86, 1.131, 0.9, 0.798, 0.853, 0.694, 0.6, 0.647, NA, 0.611, 0.563, 1.04, 1.082, 0.475, 0.796, 0.563, 0.809, 0.783, 0.657, 0.326, 0.709, 0.688)), .Names = c("TagID", "Station", "datetime", "gspd_mps"), class = "data.frame", row.names = c(NA,
-25L))

# factor of id
dat[,1] <- factor(dat[,1])
# convert to datetime
x <- paste(dat[,3])
x <- strptime(x, "%m/%d/%Y %H:%M")

I have added a few extra formatting options but I will leave you to format the x labels as an exercise.

# lattice plot conditioned by station
library(lattice)
xyplot(gspd_mps ~ as.POSIXct(x)|Station, dat,
       as.table = TRUE,
       layout = c(1,14),
       groups = TagID,
       strip = FALSE,
       type = c("p","g"),
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list(cex = c(1,0.7),
                                                   col = c("red","blue"),
                                                   pch = c(20,3))),
       strip.left = strip.custom(par.strip.text = list(cex = 0.65) ),
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       auto.key = TRUE
       )

# using latticeExtra conditioned by station and tag
library(latticeExtra)
useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2, xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       type = c("p","g")
       )
) ## useOuterStrips

useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2, xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       panel = function(x,y, ...){
                 panel.grid(h = 0, v= -1)
                 panel.xyplot(x,y,...)
               }
       )
) ## useOuterStrips

HTH
Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Natalie Houghton McNair
Sent: Monday, 25 November 2013 02:49
To: R-help at r-project.org
Subject: [R] Plotting multiple trends on one graph

>
> Hello all,
>
> I am tracking hundreds of animals through a system with multiple 
> timing points.  I want to graph the movement of individuals through 
> the whole array on one graph, but I can't figure out how to do that.
> An example of my data is below.  Basically for each 'TagID', I want to
graph the 'date'
> or 'gspd_mps' on the X axis and 'Station' on the Y axis, with all 
> TagID's on one graph.
>

Thanks for the help!!  I'm very new to R.
Natalie

   TagID Station datetime gspd_mps  4926 KLB 12/21/2012 1:52 NA  4926
MS01 12/21/2012
2:38 0.851  4926 MS02 12/21/2012 3:48 0.629  4926 MS03 12/21/2012 4:19 0.86
4926 MS04 12/21/2012 4:34 1.131  4926 MS05 12/21/2012 5:01 0.9  4926
MS06 12/21/2012
6:54 0.798  4926 MS07 12/21/2012 7:21 0.853  4926 MS08 12/21/2012 10:23
0.694  4926 MS09 12/21/2012 12:16 0.6  4926 MS10 12/21/2012 14:38 0.647
4929 KLB 12/21/2012 1:08 NA  4929 MS01 12/21/2012 2:12 0.611  4929
MS02 12/21/2012
3:33 0.563  4929 MS03 12/21/2012 3:59 1.04  4929 MS04 12/21/2012 4:13 1.082
4929 MS05 12/21/2012 5:00 0.475  4929 MS06 12/21/2012 6:52 0.796  4929
MS07 12/21/2012
7:32 0.563  4929 MS08 12/21/2012 10:16 0.809  4929 MS09 12/21/2012 11:43
0.783  4929 MS10 12/21/2012 14:02 0.657  4929 MS11 12/22/2012 2:50 0.326
4929 MS12 12/22/2012 5:04 0.709  4929 MS13 12/22/2012 13:59 0.688
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Mon Nov 25 23:34:04 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 26 Nov 2013 08:34:04 +1000
Subject: [R] FW:  Plotting multiple trends on one graph
References: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>
Message-ID: <001c01ceea2e$730f97c0$592ec740$@bigpond.com>

Sending again as apparently did not make the list

Duncan

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Monday, 25 November 2013 10:06
To: 'Natalie Houghton McNair'
Cc: R
Subject: RE: [R] Plotting multiple trends on one graph

Hi Natalie

Here is an option using lattice. I think below will get you some way to what
you want

This is your data formatted. in future please dput your data  as your data
was scrambled.
# dput(dat)
dat <- structure(list(TagID = c(4926L, 4926L, 4926L, 4926L, 4926L, 4926L,
4926L, 4926L, 4926L, 4926L, 4926L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L,
4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L, 4929L), Station = c("KLB",
"MS01", "MS02", "MS03", "MS04", "MS05", "MS06", "MS07", "MS08", "MS09",
"MS10", "KLB", "MS01", "MS02", "MS03", "MS04", "MS05", "MS06", "MS07",
"MS08", "MS09", "MS10", "MS11", "MS12", "MS13"), datetime = c("12/21/2012
1:52", "12/21/2012 2:38",
"12/21/2012 3:48", "12/21/2012 4:19", "12/21/2012 4:34", "12/21/2012 5:01",
"12/21/2012 6:54", "12/21/2012 7:21", "12/21/2012 10:23", "12/21/2012
12:16",
"12/21/2012 14:38", "12/21/2012 1:08", "12/21/2012 2:12", "12/21/2012 3:33",
"12/21/2012 3:59", "12/21/2012 4:13", "12/21/2012 5:00", "12/21/2012 6:52",
"12/21/2012 7:32", "12/21/2012 10:16", "12/21/2012 11:43", "12/21/2012
14:02",
"12/22/2012 2:50", "12/22/2012 5:04", "12/22/2012 13:59"), gspd_mps = c(NA,
0.851, 0.629, 0.86, 1.131, 0.9, 0.798, 0.853, 0.694, 0.6, 0.647, NA, 0.611,
0.563, 1.04, 1.082, 0.475, 0.796, 0.563, 0.809, 0.783, 0.657, 0.326, 0.709,
0.688)), .Names = c("TagID", "Station", "datetime", "gspd_mps"), class =
"data.frame", row.names = c(NA,
-25L))

# factor of id
dat[,1] <- factor(dat[,1])
# convert to datetime
x <- paste(dat[,3])
x <- strptime(x, "%m/%d/%Y %H:%M")

I have added a few extra formatting options but I will leave you to format
the x labels as an exercise.

# lattice plot conditioned by station
library(lattice)
xyplot(gspd_mps ~ as.POSIXct(x)|Station, dat,
       as.table = TRUE,
       layout = c(1,14),
       groups = TagID,
       strip = FALSE,
       type = c("p","g"),
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list(cex = c(1,0.7),
                                                   col = c("red","blue"),
                                                   pch = c(20,3))),
       strip.left = strip.custom(par.strip.text = list(cex = 0.65) ),
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       auto.key = TRUE
       )

# using latticeExtra conditioned by station and tag
library(latticeExtra)
useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2,
xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       type = c("p","g")
       )
) ## useOuterStrips

useOuterStrips(strip      = strip.custom(factor.levels = paste("TagID",
unique(dat$TagID)),
                                         par.strip.text = list(cex = 0.85)),
               strip.left = strip.custom(horizontal = TRUE,
                                         par.strip.text = list(cex = 0.75)),
                                         strip.left.lines = 2,
xyplot(gspd_mps ~ as.POSIXct(x)|TagID*Station, dat,
       as.table = TRUE,
       scales = list(x = list(alternating = FALSE,
                              rot = 90)),
       panel = function(x,y, ...){
                 panel.grid(h = 0, v= -1)
                 panel.xyplot(x,y,...)
               }
       )
) ## useOuterStrips

HTH
Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Natalie Houghton McNair
Sent: Monday, 25 November 2013 02:49
To: R-help at r-project.org
Subject: [R] Plotting multiple trends on one graph

>
> Hello all,
>
> I am tracking hundreds of animals through a system with multiple 
> timing points.  I want to graph the movement of individuals through 
> the whole array on one graph, but I can't figure out how to do that.
> An example of my data is below.  Basically for each 'TagID', I want to
graph the 'date'
> or 'gspd_mps' on the X axis and 'Station' on the Y axis, with all 
> TagID's on one graph.
>

Thanks for the help!!  I'm very new to R.
Natalie

   TagID Station datetime gspd_mps  4926 KLB 12/21/2012 1:52 NA  4926
MS01 12/21/2012
2:38 0.851  4926 MS02 12/21/2012 3:48 0.629  4926 MS03 12/21/2012 4:19 0.86
4926 MS04 12/21/2012 4:34 1.131  4926 MS05 12/21/2012 5:01 0.9  4926
MS06 12/21/2012
6:54 0.798  4926 MS07 12/21/2012 7:21 0.853  4926 MS08 12/21/2012 10:23
0.694  4926 MS09 12/21/2012 12:16 0.6  4926 MS10 12/21/2012 14:38 0.647
4929 KLB 12/21/2012 1:08 NA  4929 MS01 12/21/2012 2:12 0.611  4929
MS02 12/21/2012
3:33 0.563  4929 MS03 12/21/2012 3:59 1.04  4929 MS04 12/21/2012 4:13 1.082
4929 MS05 12/21/2012 5:00 0.475  4929 MS06 12/21/2012 6:52 0.796  4929
MS07 12/21/2012
7:32 0.563  4929 MS08 12/21/2012 10:16 0.809  4929 MS09 12/21/2012 11:43
0.783  4929 MS10 12/21/2012 14:02 0.657  4929 MS11 12/22/2012 2:50 0.326
4929 MS12 12/22/2012 5:04 0.709  4929 MS13 12/22/2012 13:59 0.688
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdxgary163 at gmail.com  Tue Nov 26 00:35:40 2013
From: pdxgary163 at gmail.com (Gary Dong)
Date: Mon, 25 Nov 2013 15:35:40 -0800
Subject: [R] summary many regressions
Message-ID: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/2ec8f22b/attachment.pl>

From smartpink111 at yahoo.com  Mon Nov 25 15:45:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 25 Nov 2013 06:45:28 -0800 (PST)
Subject: [R] convert data frame: two variables into _one_ binary variable
In-Reply-To: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
References: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
Message-ID: <1385390728.24063.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
One way would be:

womensrole <- read.table(text="education gender agree disagree sexe
1??????? 0? Male??? 4??????? 2??? 0
2??????? 1? Male??? 2??????? 0??? 0
3??????? 2? Male??? 4??????? 0??? 0
4??????? 3? Male??? 6??????? 3??? 0
5??????? 4? Male??? 5??????? 5??? 0
6??????? 5? Male??? 13??????? 7??? 0",sep="",header=TRUE,stringsAsFactors=FALSE)
library(reshape2)
?res1 <- melt(womensrole,measure.vars=c("agree","disagree"),var="agree")
?res2 <- within(res1[rep(1:nrow(res1),res1$value),], agree <- agree=="agree")[,c(1,2,4,3)]
?res2New <- res2[order(res2$education),]
row.names(res2New) <- 1:nrow(res2New)

A.K.



On Monday, November 25, 2013 4:24 AM, Liviu Andronic <landronimirc at gmail.com> wrote:
Dear all,
I am trying to convert the following data frame into a format more
useful for me:
> library("HSAUR2", lib.loc="C:/Program Files/R/R-3.0.2/library")
Loading required package: tools

Attaching package: ?HSAUR2?

The following object is masked _by_ ?.GlobalEnv?:

? ? womensrole

> head(womensrole)
? education gender agree disagree sexe
1? ? ? ?  0?  Male? ?  4? ? ? ? 2? ? 0
2? ? ? ?  1?  Male? ?  2? ? ? ? 0? ? 0
3? ? ? ?  2?  Male? ?  4? ? ? ? 0? ? 0
4? ? ? ?  3?  Male? ?  6? ? ? ? 3? ? 0
5? ? ? ?  4?  Male? ?  5? ? ? ? 5? ? 0
6? ? ? ?  5?  Male? ? 13? ? ? ? 7? ? 0


In 'womensrole', how do I convert 'agree' and 'disagree' variables
into one proper binary variable, say:
? education gender agree sexe
1? ? ? ?  0?  Male? ?  TRUE? ? ? ? ?  0
2? ? ? ?  0?  Male? ?  TRUE? ? ? ? ?  0
3? ? ? ?  0?  Male? ?  TRUE? ? ? ? ?  0
4? ? ? ?  0?  Male? ?  TRUE? ? ? ? ?  0
5? ? ? ?  0?  Male? ?  FALSE? ? ? ? ?  0
6? ? ? ?  0?  Male? ?  FALSE? ? ? ? ?  0
7? ? ? ?  1?  Male? ?  TRUE? ? ? ? ?  0
8? ? ? ?  1?  Male? ?  TRUE? ? ? ? ?  0
9? ? ? ?  2?  Male? ?  TRUE? ? ? ? ?  0
10? ? ? ?  2?  Male? ?  TRUE? ? ? ? ?  0
11? ? ? ?  2?  Male? ?  TRUE? ? ? ? ?  0
12? ? ? ?  2?  Male? ?  TRUE? ? ? ? ?  0
[..]

I'm sure there is an easy way to do this (in the form of 'melt',
'cast', etc.), but I'm not sure how to approach the problem.

Regards,
Liviu

-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From d-zimmermann at gmx.net  Mon Nov 25 16:19:09 2013
From: d-zimmermann at gmx.net (Dirk Zimmermann)
Date: Mon, 25 Nov 2013 07:19:09 -0800 (PST)
Subject: [R] Fetching data from MySQL via odbcConnect - Error in
 as.POSIXlt.character(x, tz, ...) :
Message-ID: <1385392749732-4681116.post@n4.nabble.com>

Hi!

I am trying to retrieve data from a MySQL Database using RODBC with the
commands odbcConnect and sqlFetch. There are different data files in the
database and in some cases it works without any difficulties. Nevertheless I
get an error with some data files. Since I'm not familiar with MySQL I hope
to get some ideas here.

My code looks as follows:

myconn <-odbcConnect("database", uid="user", pwd="password")
data1<- sqlFetch(myconn, 'data1')
data2 <- sqlFetch(myconn, 'data2')
close(myconn)

It works fine for data1 but for data2 I get the following error:

Error in as.POSIXlt.character(x, tz, ...) : 
  character string is not in a standard unambiguous format

As I've checked the data files, they use the same types of variables and I
have no clue where the not standard unambiguous format stems from.

Hope to get some help!

Dirk



--
View this message in context: http://r.789695.n4.nabble.com/Fetching-data-from-MySQL-via-odbcConnect-Error-in-as-POSIXlt-character-x-tz-tp4681116.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Nov 25 20:43:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 25 Nov 2013 11:43:03 -0800 (PST)
Subject: [R] Hey guys
Message-ID: <1385408583.91470.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
dat1<- t(dat[,-1]) 
?colnames(dat1) <- dat[,1]

covmat <- cov(dat1)

A.K.

I'm running into this error and I'm not sure how fix it 
Error: is.numeric(x) || is.logical(x) is not TRUE 

This is my data frame 
geneExpression_Lab10.txt
This is the homework instructions in case you want to see 
Lab10.pdf

This is my code 

dat <-read.delim("~/Dropbox/Homework/R Studio/geneExpression_Lab10.txt", header=F) 
dat <- as.matrix(dat) 
dat <- t(as.matrix(dat)) 
covmat <-cov(dat) #Error: is.numeric(x) || is.logical(x) is not TRUE 
eigvec <- eigen(covmat)$vectors 
eigval <- eigen(covmat)$values 
eigvec 
adjusted.dat <- sapply(1:ncol(dat), function(i) dat[,i]- mean(dat[,i])) 
new.dat <- adjusted.dat %*% eigvec 
plot(new.dat) 
cov(new.dat)


From maximilian.butler at gmail.com  Mon Nov 25 15:01:11 2013
From: maximilian.butler at gmail.com (Maximilian Butler)
Date: Mon, 25 Nov 2013 09:01:11 -0500
Subject: [R] cut2 not binning interval endpoints correctly
Message-ID: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/65b9a26e/attachment.pl>

From b.cesqui at hsantalucia.it  Mon Nov 25 15:45:30 2013
From: b.cesqui at hsantalucia.it (Benedetta Cesqui)
Date: Mon, 25 Nov 2013 15:45:30 +0100
Subject: [R] R: lmer specification for random effects: contradictory reults
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>
References: <001401cee9c6$ed8536d0$c88fa470$@cesqui@hsantalucia.it>
	<AA818EAD2576BC488B4F623941DA7427DFB04A1A@inbomail.inbo.be>
Message-ID: <000301cee9ed$02ef6f10$08ce4d30$@cesqui@hsantalucia.it>

Dear Thierry,

thank you for the quick reply.
I have only one question about the approach you proposed.
As you suggested, imagine that the model we end up after the model selection
procedure is:

mod2.1 <- lmer(dT_purs ~ T + Z + (1 +T+Z| subject), data =x, REML= FALSE)

According to the common procedures specified in many manuals and recent
papers, if I want to compute the p_values relative to each term, I will
perform a likelihood test, in which the deviance of the (-2LL) of a model
containing the specific term is compared to another model without it.
In the case of the fixed effect terms I have no problem in the
interpretation of the results. Each comparison returns a significance
associated with the estimated coefficient of the term.
Thus in this case:

mod2.2 <- lmer(dT_purs ~ Z + (1 +T+Z|soggetto)  , data = x, REML = FALSE)
mod2.3 <- lmer(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x, REML = FALSE)
anova(mod2.1, mod2.2)
p_valueT = 3.203e-05
anova(mod2.1, mod2.3)
p_valueZ = 0.001793

What about the p_value relative to the (1+T+Z|subject)?
One option is to compute:
mod2.4 <- lm(dT_purs ~ T + (1 +T+Z|soggetto)  , data = x)
and then execute the loklikelihood test as follows:

L0 <-logLik(mod2.4)
L1 <-logLik(mod2.1)
LR <--2*(L1-L0)
pv <- pchisq(LR,2,ncp = 0, lower.tai=FALSE,log.p = FALSE)

However, what can I conclude on the random slopeif it is significant? 

With the previouse approach using the model:
mod2 <- lmer(dT_purs ~ T + Z + (1 +T| subject) + (1+ Z| subject), data =x)

The comparison among the models in which the different termd were
included/excluded provided me the following results:
	p_valueT = 1.269e-07;
	p_valueZ =0.00322 
	p_valueTS =  0.4277
	p_valueZS = 0.005701

I interpreted the ones relative to the random effects as if the subjects
differed not only in their overall responses, but also in the nature of
their response dT_purse values in the different T conditions, but not in the
different Z conditions.

Benedetta


-----Messaggio originale-----
Da: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Inviato: luned? 25 novembre 2013 14:48
A: Benedetta Cesqui; r-help at r-project.org
Cc: r-sig-mixed-models at r-project.org
Oggetto: RE: [R] lmer specification for random effects: contradictory reults

Dear Benedetta,

I think you might want (1+T+Z|subject) as random effects  rather than
(1+T|subject) + (1 + Z|subject). The latter has two random intercepts per
subject: a recipe for disaster.

Follow-up posts should only go to the mixed models mailing list which I'm
cc'ing.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than
asking him to perform a post-mortem examination: he may be able to say what
the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
Namens Benedetta Cesqui
Verzonden: maandag 25 november 2013 11:13
Aan: r-help at r-project.org
Onderwerp: [R] lmer specification for random effects: contradictory reults

Hi All,



I was wondering if someone could help me to solve this issue with lmer.
In order to understand the best mixed effects model to fit my data, I
compared the following options according to the procedures specified in many
papers (i.e. Baayen
<http://www.google.it/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDsQFjAA
&url=http%3A%2F%2Fwww.ualberta.ca%2F~baayen%2Fpublications%2FbaayenDavidsonB
ates.pdf&ei=FhqTUoXuJKKV7Abds4GYBA&usg=AFQjCNFst7GT7mBX7w9lXItJTtELJSKWJg&si
g2=KGA5MHxOvEGwDxf-Gcqi6g&bvm>  R.H. et al 2008) Here, dT_purs is the
response variable, T and Z are the fixed effects, and subject is the random
effect. Random and fixed effects are crossed.:

mod0 <- lmer(dT_purs ~ T + Z + (1|subject), data = x)
mod1 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject), data = x)
mod2 <- lmer(dT_purs ~ T + Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod3 <- lmer(dT_purs ~ T * Z + (1 +tempo| subject) + (1+ Z| subject), data =
x)
mod4 <- lmer(dT_purs ~ T * Z + (1| subject), data = x)


anova(mod0, mod1,mod2, mod3, mod4)



Data: x

Models:

mod0: dT_purs ~ T + Z + (1 | subject)

mod4: dT_purs ~ T * Z + (1 | subject )

mod1: dT_purs ~ T + Z + (1 + T| subject)

mod2: dT_purs ~ T + Z + (1 + T| subject ) + (1 + Z | subject)

mod3: dT_purs ~ T * Z + (1 + T| subject) + (1 + Z | subject)

     Df     AIC     BIC logLik deviance   Chisq Chi Df Pr(>Chisq)

mod0  5 -689.81 -669.46 349.91  -699.81

mod4  6 -689.57 -665.14 350.78  -701.57  1.7532      1   0.185473

mod1  7 -689.12 -660.62 351.56  -703.12  1.5504      1   0.213070

mod2 10 -695.67 -654.97 357.84  -715.67 12.5563      3   0.005701 **

mod3 11 -695.83 -651.05 358.92  -717.83  2.1580      1   0.141825

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





It turns out that mod2 has the right level of complexity for this dataset.

However when I looked at its summary, I got a correlation of -0.87 for the
random effects relative to the T effect and -1 for the random effects
relatively to the Z.





summary(mod2)

Linear mixed model fit by maximum likelihood ['lmerMod']

Formula: dT_purs ~T + Z + (1 + T | subject) + (1 + Z | subject)

   Data: x



      AIC       BIC    logLik  deviance

-695.6729 -654.9655  357.8364 -715.6729



Random effects:

Groups     Name        Variance  Std.Dev. Corr

 subject   (Intercept) 0.0032063 0.05662

            T       0.0117204 0.10826  -0.87

subject.1 (Intercept) 0.0005673 0.02382

            Z           0.0025859 0.05085  1.00

 Residual               0.0104551 0.10225

Number of obs: 433, groups: soggetto, 7



Fixed effects:

            Estimate Std. Error t value

(Intercept)  0.02489    0.03833   0.650

T        0.52010    0.05905   8.808

Z           -0.09019    0.02199  -4.101



Correlation of Fixed Effects:

      (Intr) tempo

T -0.901

Z      0.218 -0.026





If I understand correctly what the correlation parameters reported in the
table are, the correlation of 1 means that, for the Z effects the random
intercept is perfectly collinear with the random slope. Thus, we fit the
wrong model. A random intercept only model would have sufficed.

Am I correct?



If so, should I take mod1 (mod1 <- dT_purs ~ T + Z + (1 + T | subject )
instead of mod2 to fit my data?

Why are these results contradictory?

Finally is a correlation value of -0.87 a too high or an acceptable value ?



Thanks for help me in advance!



Best



Benedetta





---

Benedetta Cesqui, Ph.D.

Laboratory of Neuromotor Physiology

IRCCS Fondazione Santa Lucia

Via Ardeatina 306

00179 Rome, Italy

tel: (+39) 06-51501485

fax:(+39) 06-51501482

E_mail:  b.cesqui at hsantalucia.it




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * * Dit
bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en
binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd
is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the
writer and may not be regarded as stating an official position of INBO, as
long as the message is not confirmed by a duly signed document.


From xiaoyue-ma at live.cn  Mon Nov 25 23:05:27 2013
From: xiaoyue-ma at live.cn (MaXiaoyue)
Date: Mon, 25 Nov 2013 16:05:27 -0600
Subject: [R] Durbin Watson Test Bound in R
Message-ID: <BLU0-SMTP18987C96527C201C456753C98ED0@phx.gbl>

Hi,

How could I use R to check Durbin Watson Test Bound?


Best,
Rebecca


From dmck at u.washington.edu  Tue Nov 26 01:27:18 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Mon, 25 Nov 2013 16:27:18 -0800
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
	divergent colors around zero in levelplot()
In-Reply-To: <CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
Message-ID: <E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>

Bert or anyone else familiar with RColorBrewer:

Has anyone tried to accomplish with RColorBrewer what I asked about in my original post (below)? 

Here is an example cribbed from the levelplot() help examples

x <- seq(pi/4, 5 * pi, length.out = 100)
y <- seq(pi/4, 5 * pi, length.out = 100)
r <- as.vector(sqrt(outer(x^2, y^2, "+")))
grid <- expand.grid(x=x, y=y)
grid$z <- cos(r^2) * exp(-r/(pi^3))

# now use RColorBrewer to get a palette

library("RColorBrewer?)
levelplot(z~x*y, grid,col.regions=brewer.pal(6,"BrBG?))   # the numeric argument to brewer.pal is the number of colors used ? I tried several

This gives me a nice brown-to-green gradient but does not (AFAICS) give me control over where the center of the divergence lies. Even in this symmetrical
example, I can?t get it to be at zero ? it repeats on either side of zero.

thanks to anyone who pages through all this and makes a suggestion, even if it doesn?t work.  :-)

On Nov 22, 2013, at 10:25 PM, Bert Gunter <gunter.berton at gene.com> wrote:

> Use the Rcolorbrewer package.
> 
> -- Bert
> 
> On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
>> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
>> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>> 
>> I am using R 3.0.2 on OSX 10.9
>> 
>> Here is an example
>> 
>> x <- y <- c(1:25)
>> grid <- expand.grid(x=x,y=y)
>> grid$z <- sort(runif(625,min=-1,max=12))
>> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>> 
>> # do something clever here
>> # e.g., my.colors <- <create a palette that splits at zero>
>> 
>> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>> 
>> Ideas appreciated.  Thanks in advance.
>> 
>> 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> (650) 467-7374

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From dmck at u.washington.edu  Tue Nov 26 01:34:20 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Mon, 25 Nov 2013 16:34:20 -0800
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
	divergent colors around zero in levelplot()
In-Reply-To: <E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
Message-ID: <CF0B9061-616B-4FE4-B7E4-C62E958FF152@u.washington.edu>

Never mind.   Solved.  ?cuts? argument back in levelplot(). Duh.

On Nov 25, 2013, at 4:27 PM, Don McKenzie <dmck at u.washington.edu> wrote:

> Bert or anyone else familiar with RColorBrewer:
> 
> Has anyone tried to accomplish with RColorBrewer what I asked about in my original post (below)? 
> 
> Here is an example cribbed from the levelplot() help examples
> 
> x <- seq(pi/4, 5 * pi, length.out = 100)
> y <- seq(pi/4, 5 * pi, length.out = 100)
> r <- as.vector(sqrt(outer(x^2, y^2, "+")))
> grid <- expand.grid(x=x, y=y)
> grid$z <- cos(r^2) * exp(-r/(pi^3))
> 
> # now use RColorBrewer to get a palette
> 
> library("RColorBrewer?)
> levelplot(z~x*y, grid,col.regions=brewer.pal(6,"BrBG?))   # the numeric argument to brewer.pal is the number of colors used ? I tried several
> 
> This gives me a nice brown-to-green gradient but does not (AFAICS) give me control over where the center of the divergence lies. Even in this symmetrical
> example, I can?t get it to be at zero ? it repeats on either side of zero.
> 
> thanks to anyone who pages through all this and makes a suggestion, even if it doesn?t work.  :-)
> 
> On Nov 22, 2013, at 10:25 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
>> Use the Rcolorbrewer package.
>> 
>> -- Bert
>> 
>> On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>>> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
>>> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
>>> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>>> 
>>> I am using R 3.0.2 on OSX 10.9
>>> 
>>> Here is an example
>>> 
>>> x <- y <- c(1:25)
>>> grid <- expand.grid(x=x,y=y)
>>> grid$z <- sort(runif(625,min=-1,max=12))
>>> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>>> 
>>> # do something clever here
>>> # e.g., my.colors <- <create a palette that splits at zero>
>>> 
>>> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>>> 
>>> Ideas appreciated.  Thanks in advance.
>>> 
>>> 
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> (650) 467-7374
> 
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Science Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
> 
> 
> 

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From jholtman at gmail.com  Tue Nov 26 01:45:16 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 25 Nov 2013 19:45:16 -0500
Subject: [R] cut2 not binning interval endpoints correctly
In-Reply-To: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
References: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
Message-ID: <D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>

FAQ 7.31

Sent from my iPad

On Nov 25, 2013, at 9:01, Maximilian Butler <maximilian.butler at gmail.com> wrote:

> Hi everyone,
> 
> I am attempting to bin a vector of numbers between 0 and 1 into intervals
> of 0.001 but many values at the endpoints of the intervals are getting
> binned into the wrong interval. For example, the first 3 rows are binned
> incorrectly here:
> 
> library(Hmisc)
> df=data.frame(x=c(0.308,0.422,0.174,0.04709))
> df$bucket=cut2(df$x,seq(0,1,0.001),oneval=FALSE)
> print(df)
>        x        bucket
> 1 0.30800 [0.307,0.308)
> 2 0.42200 [0.421,0.422)
> 3 0.17400 [0.173,0.174)
> 4 0.04709 [0.047,0.048)
> 
> I have tried closing and reopening RStudio after clearing the workspace and
> reinstalling the Hmisc package. I am running R version 3.0.2 on Windows 7
> 64-bit. Thank you.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Nov 26 02:14:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 25 Nov 2013 17:14:34 -0800
Subject: [R] summary many regressions
In-Reply-To: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
References: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
Message-ID: <64CD164E-E96D-4DAE-BC0D-8A3688ABFA7C@comcast.net>


On Nov 25, 2013, at 3:35 PM, Gary Dong wrote:

> Dear R users,
> 
> I have a large data set which includes data from 300 cities. I want to run
> a biviriate regression for each city and record the coefficient and the
> adjusted R square.
> 
> For example, in the following, I have 10 cities represented by numbers from
> 1 to 10:
> 
> x = cumsum(c(0, runif(999, -1, +1)))
> y = cumsum(c(0, runif(999, -1, +1)))
> city = rep(1:10,each=100)
> data<-data.frame(cbind(x,y,city))
> 
> I can manually run regressions for each city:
> fit_city1 <- lm(y ~ x,data=subset(data,data$city==1))
> summary(fit_city1)
> 
> Obvious, it is very tedious to run 300 regressions. I wonder if there is a
> quicker way to do this. Use for loop?  what I want to see is something like
> this:
> 
> City        Coefficient       Adjusted R square
> 1              -0.05                  0.36
> 2              -0.12                  0.20
> 3              -0.05                  0.32
> .....
> 
The way to get the most rapid response from this list is to post a dataset that represents the complexity of the problem. Presumably this large dataset is either a dataframe with a column of city entries or a list of dataframes. Why not post dput() applied to an extract of three of the cities and include sufficient rows to allow a regression?

> 
> 	[[alternative HTML version deleted]]
> 

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

This is a plain text list.

-- 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Tue Nov 26 02:57:34 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 25 Nov 2013 17:57:34 -0800
Subject: [R] Durbin Watson Test Bound in R
In-Reply-To: <BLU0-SMTP18987C96527C201C456753C98ED0@phx.gbl>
References: <BLU0-SMTP18987C96527C201C456753C98ED0@phx.gbl>
Message-ID: <8c7c9fda-87fb-4143-b665-52f3495d67fb@email.android.com>

I would first enter

?RSiteSearch

at the R console, and learn how to sift through the 5000+ packages at CRAN for myself.

Then I would enter

RSiteSearch("Durbin")

and then study the many options available.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

MaXiaoyue <xiaoyue-ma at live.cn> wrote:
>Hi,
>
>How could I use R to check Durbin Watson Test Bound?
>
>
>Best,
>Rebecca
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dmck at u.washington.edu  Tue Nov 26 04:28:48 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Mon, 25 Nov 2013 19:28:48 -0800
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
	divergent colors around zero in levelplot()
In-Reply-To: <E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
Message-ID: <3593D6F5-87D7-47B1-841E-EC8367ECB33D@u.washington.edu>

In case anyone cares (?), here is a function to do what I was asking, which doesn?t use colorBrewer but could with some hacking. I?m sure it?s fragile, but it works with well behaved integers and zero in the middle, which was all I needed. The output is a palette that can be passed to levelplot() and other functions.

Cheers

diverge.color <- function(start.color,end.color,min.value,max.value,mid.value=0,mid.color="ivory")

{
	# based on ideas from Maureen Kennedy, Nick Povak, and Alina Cansler

        # creates a palette for the current session for a divergent-color
	# graphic with a non-symmetric range
	# "cuts" = the number of slices to be made in the range above and below "mid.value"

        ramp1 <- colorRampPalette(c(start.color,mid.color))
        ramp2 <- colorRampPalette(c(mid.color,end.color))

       # now specify the number of values on either side of "mid.value"
       
       max.breaks <- round(max.value - mid.value)
       min.breaks <- round(mid.value - min.value)
       
       num.breaks <- max(max.breaks,min.breaks)
       
       low.ramp <- ramp1(num.breaks)
       high.ramp <- ramp2(num.breaks)
       
       # now create a combined ramp from the higher values of "low.ramp" and 
       # the lower values of "high.ramp", with the longer one using all values 
       # high.ramp starts at 2 to avoid duplicating zero
       
       myColors <- c(low.ramp[(num.breaks-min.breaks):num.breaks],high.ramp[2:max.breaks])
  
      myColors
}
 

On Nov 25, 2013, at 4:27 PM, Don McKenzie <dmck at u.washington.edu> wrote:

> Bert or anyone else familiar with RColorBrewer:
> 
> Has anyone tried to accomplish with RColorBrewer what I asked about in my original post (below)? 
> 
> Here is an example cribbed from the levelplot() help examples
> 
> x <- seq(pi/4, 5 * pi, length.out = 100)
> y <- seq(pi/4, 5 * pi, length.out = 100)
> r <- as.vector(sqrt(outer(x^2, y^2, "+")))
> grid <- expand.grid(x=x, y=y)
> grid$z <- cos(r^2) * exp(-r/(pi^3))
> 
> # now use RColorBrewer to get a palette
> 
> library("RColorBrewer?)
> levelplot(z~x*y, grid,col.regions=brewer.pal(6,"BrBG?))   # the numeric argument to brewer.pal is the number of colors used ? I tried several
> 
> This gives me a nice brown-to-green gradient but does not (AFAICS) give me control over where the center of the divergence lies. Even in this symmetrical
> example, I can?t get it to be at zero ? it repeats on either side of zero.
> 
> thanks to anyone who pages through all this and makes a suggestion, even if it doesn?t work.  :-)
> 
> On Nov 22, 2013, at 10:25 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
>> Use the Rcolorbrewer package.
>> 
>> -- Bert
>> 
>> On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>>> I would like to produce a levelplot with divergent colors such that increasingly negative values of Z get darker in the first color and increasingly
>>> positive values get darker in the second color.  this is common in cartography. I have tried tinkering with the col.regions argument but the best I can do
>>> is to get the split in the middle of my range of Z, but in my particular case range(Z) is (-1,12).
>>> 
>>> I am using R 3.0.2 on OSX 10.9
>>> 
>>> Here is an example
>>> 
>>> x <- y <- c(1:25)
>>> grid <- expand.grid(x=x,y=y)
>>> grid$z <- sort(runif(625,min=-1,max=12))
>>> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the split is at ~5.5
>>> 
>>> # do something clever here
>>> # e.g., my.colors <- <create a palette that splits at zero>
>>> 
>>> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be some light pink at the bottom and the rest increasingly intense blue
>>> 
>>> Ideas appreciated.  Thanks in advance.
>>> 
>>> 
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> (650) 467-7374
> 
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Science Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
> 
> 
> 

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From smartpink111 at yahoo.com  Tue Nov 26 01:27:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 25 Nov 2013 16:27:25 -0800 (PST)
Subject: [R] summary many regressions
In-Reply-To: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
References: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
Message-ID: <1385425645.78322.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
res <- do.call(rbind,lapply(split(data,data$city),function(z) {fit_city <- lm(y~x,data=z);data.frame(City=unique(z$city),Coefficient=coef(fit_city)[2],Adjusted_R_square= summary(fit_city)$adj.r.squared)}))

A.K.




On Monday, November 25, 2013 6:37 PM, Gary Dong <pdxgary163 at gmail.com> wrote:
Dear R users,

I have a large data set which includes data from 300 cities. I want to run
a biviriate regression for each city and record the coefficient and the
adjusted R square.

For example, in the following, I have 10 cities represented by numbers from
1 to 10:

x = cumsum(c(0, runif(999, -1, +1)))
y = cumsum(c(0, runif(999, -1, +1)))
city = rep(1:10,each=100)
data<-data.frame(cbind(x,y,city))

I can manually run regressions for each city:
fit_city1 <- lm(y ~ x,data=subset(data,data$city==1))
summary(fit_city1)

Obvious, it is very tedious to run 300 regressions. I wonder if there is a
quicker way to do this. Use for loop?? what I want to see is something like
this:

City? ? ? ? Coefficient? ? ?  Adjusted R square
1? ? ? ? ? ? ? -0.05? ? ? ? ? ? ? ? ? 0.36
2? ? ? ? ? ? ? -0.12? ? ? ? ? ? ? ? ? 0.20
3? ? ? ? ? ? ? -0.05? ? ? ? ? ? ? ? ? 0.32
.....

Any advice is appreciated!

Gary

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From acansler at uw.edu  Tue Nov 26 02:02:32 2013
From: acansler at uw.edu (C. Alina Cansler)
Date: Mon, 25 Nov 2013 17:02:32 -0800
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
 divergent colors around zero in levelplot()
In-Reply-To: <E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
Message-ID: <CABz5LGVyVwuGt4iYGXu_Qx+D8QH67SwhbFiOpcguCtBw5BUqsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/0e6703a9/attachment.pl>

From rameelavc at yahoo.com  Tue Nov 26 05:20:16 2013
From: rameelavc at yahoo.com (Rameela Chandrasekhar)
Date: Mon, 25 Nov 2013 20:20:16 -0800 (PST)
Subject: [R] Multinomial regression with repeated measures
Message-ID: <1385439616.50173.YahooMailNeo@web125703.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131125/ba587a56/attachment.pl>

From mohan.radhakrishnan at polarisft.com  Tue Nov 26 06:24:14 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 26 Nov 2013 10:54:14 +0530
Subject: [R] Functional Programming patterns
In-Reply-To: <CABdHhvGA0spVVv6a+Lj8UcyHGVA2ahfdesszJrYbdKhdTtvX4A@mail.gmail.com>
References: <OFEA5B866D.6A630923-ON65257C29.00310F92-65257C29.00319D3E@polarisft.com>
	<CABdHhvGA0spVVv6a+Lj8UcyHGVA2ahfdesszJrYbdKhdTtvX4A@mail.gmail.com>
Message-ID: <OF726E849B.D6B78E3E-ON65257C2F.001D8361-65257C2F.001DAD82@polarisft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/ec51b8c2/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Tue Nov 26 08:34:06 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 26 Nov 2013 08:34:06 +0100 (CET)
Subject: [R] Durbin Watson Test Bound in R
In-Reply-To: <BLU0-SMTP18987C96527C201C456753C98ED0@phx.gbl>
References: <BLU0-SMTP18987C96527C201C456753C98ED0@phx.gbl>
Message-ID: <alpine.DEB.2.10.1311260831040.19136@paninaro.uibk.ac.at>

On Mon, 25 Nov 2013, MaXiaoyue wrote:

> Hi,
>
> How could I use R to check Durbin Watson Test Bound?

Although the bounds approach to the Durbin-Watson test is still described 
in many text books, there are actually various ways to get p-values for 
the Durbin-Watson statistic. dwtest() in "lmtest" implements the exact 
p-value (assuming normal disturbances) as well as the asymptotic 
approximation. durbinWatsonTest() in "car" implements a bootstrap approach 
(that is also applicable to lags higher than 1).

>
> Best,
> Rebecca
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Achim.Zeileis at uibk.ac.at  Tue Nov 26 08:41:48 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 26 Nov 2013 08:41:48 +0100 (CET)
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
 divergent colors around zero in levelplot()
In-Reply-To: <CABz5LGVyVwuGt4iYGXu_Qx+D8QH67SwhbFiOpcguCtBw5BUqsg@mail.gmail.com>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
	<CABz5LGVyVwuGt4iYGXu_Qx+D8QH67SwhbFiOpcguCtBw5BUqsg@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1311260835390.19136@paninaro.uibk.ac.at>

On Mon, 25 Nov 2013, C. Alina Cansler wrote:

> Don,
>
> This looks helpful:
> https://stat.ethz.ch/pipermail/r-help/2011-March/272361.html
>
> Also, here is some code that I had, and tried to make applicable to your
> question:
>
> div.colors <-colorRampPalette(c("blue", "white", "red" ))
> x<-seq(-1,12,1);x
> palette(div.colors(length(x)))
> y<- rep(1,length(x))
> barplot(y,  col=x+2, space=0, axes=FALSE, border = NA  ,   cex.names=1.3 ,
> xlab="", ylab="",xaxt="n")

These colors are not very well balanced because "blue" is much darker than 
"red". You can see that more clearly when you desaturate the colors where 
the blue branch corresponds to darker colors than the red branch.

The palettes in RColorBrewer or colorspace offer better balanced palettes. 
Consider the code below.

And as for the original question: diverge_hcl(99) would be one option to 
obtain 99 divergent colors in "colorspace".

library("colorspace")
pal <- function(col, border = "light gray") {
   n <- length(col)
   plot(0, 0, type="n", xlim = c(0, 1), ylim = c(0, 1),
     axes = FALSE, xlab = "", ylab = "")
   rect(0:(n-1)/n, 0, 1:n/n, 1, col = col, border = border)
}

par(mfrow = c(2, 2), mar = rep(1, 4))
pal(div.colors(9))
pal(diverge_hcl(9))
pal(desaturate(div.colors(9)))
pal(desaturate(diverge_hcl(9)))


> -Alina
>
>
>
>
> On Mon, Nov 25, 2013 at 4:27 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>
>> Bert or anyone else familiar with RColorBrewer:
>>
>> Has anyone tried to accomplish with RColorBrewer what I asked about in my
>> original post (below)?
>>
>> Here is an example cribbed from the levelplot() help examples
>>
>> x <- seq(pi/4, 5 * pi, length.out = 100)
>> y <- seq(pi/4, 5 * pi, length.out = 100)
>> r <- as.vector(sqrt(outer(x^2, y^2, "+")))
>> grid <- expand.grid(x=x, y=y)
>> grid$z <- cos(r^2) * exp(-r/(pi^3))
>>
>> # now use RColorBrewer to get a palette
>>
>> library("RColorBrewer?)
>> levelplot(z~x*y, grid,col.regions=brewer.pal(6,"BrBG?))   # the numeric
>> argument to brewer.pal is the number of colors used ? I tried several
>>
>> This gives me a nice brown-to-green gradient but does not (AFAICS) give me
>> control over where the center of the divergence lies. Even in this
>> symmetrical
>> example, I can?t get it to be at zero ? it repeats on either side of zero.
>>
>> thanks to anyone who pages through all this and makes a suggestion, even
>> if it doesn?t work.  :-)
>>
>> On Nov 22, 2013, at 10:25 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>>
>>> Use the Rcolorbrewer package.
>>>
>>> -- Bert
>>>
>>> On Fri, Nov 22, 2013 at 8:43 PM, Don McKenzie <dmck at u.washington.edu>
>> wrote:
>>>> I would like to produce a levelplot with divergent colors such that
>> increasingly negative values of Z get darker in the first color and
>> increasingly
>>>> positive values get darker in the second color.  this is common in
>> cartography. I have tried tinkering with the col.regions argument but the
>> best I can do
>>>> is to get the split in the middle of my range of Z, but in my
>> particular case range(Z) is (-1,12).
>>>>
>>>> I am using R 3.0.2 on OSX 10.9
>>>>
>>>> Here is an example
>>>>
>>>> x <- y <- c(1:25)
>>>> grid <- expand.grid(x=x,y=y)
>>>> grid$z <- sort(runif(625,min=-1,max=12))
>>>> levelplot(z ~ x*y,grid)   # produces the default pink and blue but the
>> split is at ~5.5
>>>>
>>>> # do something clever here
>>>> # e.g., my.colors <- <create a palette that splits at zero>
>>>>
>>>> levelplot(z ~ x*y,grid,col.regions=my.colors)  # so there should be
>> some light pink at the bottom and the rest increasingly intense blue
>>>>
>>>> Ideas appreciated.  Thanks in advance.
>>>>
>>>>
>>>
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>>
>>> (650) 467-7374
>>
>> Don McKenzie
>> Research Ecologist
>> Pacific Wildland Fire Science Lab
>> US Forest Service
>>
>> Affiliate Professor
>> School of Environmental and Forest Sciences
>> University of Washington
>> dmck at uw.edu
>>
>>
>>
>>
>
>
> -- 
> C. Alina Cansler
> Fire and Mountain Ecology Lab
> School of Environmental and Forest Sciences
> College of the Environment
> University of Washington
> E-mail: acansler at uw.edu
> Cell: 206-794-1630
>
> 	[[alternative HTML version deleted]]
>
>


From suparna.mitra.sm at gmail.com  Tue Nov 26 08:51:02 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Tue, 26 Nov 2013 15:51:02 +0800
Subject: [R] Bootstrap or subsampling using loop?
Message-ID: <CAFdg=fVfTgx=Pb11MDWZ5_6hA4mfTY7YphiWDs+w2HJLE_Wvuw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/bbd16c47/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Tue Nov 26 09:25:14 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 26 Nov 2013 08:25:14 +0000
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
 divergent colors around zero in levelplot()
In-Reply-To: <9486ef447fd7425188777f98e25ef378@EX-1-HT0.lancs.local>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
	<9486ef447fd7425188777f98e25ef378@EX-1-HT0.lancs.local>
Message-ID: <CANVKczO3VmESpZQko1WR+gOWvWMGaJXKaZpDLO9MeC+Fekjf3Q@mail.gmail.com>

On Tue, Nov 26, 2013 at 1:02 AM, C. Alina Cansler <acansler at uw.edu> wrote:
> Don,
>
> This looks helpful:
> https://stat.ethz.ch/pipermail/r-help/2011-March/272361.html

Yes, he's a helpful chap.

 The fundamental problem here is the colour palette. When I was a boy
all we had was a pen plotter with four coloured pens, and of course
you could stick different coloured pens in the different pen slots and
draw four different coloured lines. So your graphics package just said
which number pen it was going to use and the colour that came out was
up to you. Most R graphics functions still have this concept, although
there may be over 100 pens and you don't end up swearing when one runs
out of ink. A numeric value is converted to an integer and the integer
does a lookup in a palette to get the colour.

 What you really want, and what my colourscheme package did, was to
create functions that let users map values directly to colours. You
could then plot points and lines using that function which meant
totally controlled value-to-colour mappings that could be used across
different plots if desired. That worked because points and lines lets
you specify a colour value directly using something like col="#FF23EC"
(as well as allowing col=23 and doing a palette lookup).

 But the image function (and probably levelplot) doesn't allow that so
there's various tricks to make functional colour lookups work. I would
convert the image matrix values to a matrix of colours, then create a
matrix of the values 1:(n*m), and then image() that 1:(n*m) matrix
using the colour matrix as a palette. That way each cell had its own
palette entry, and you controlled that colour using the value-colour
function.

 Or you could just use ggplot which I'm pretty sure has the same
concept of mapping values to colours.

Barry


From ripley at stats.ox.ac.uk  Tue Nov 26 10:58:42 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Nov 2013 09:58:42 +0000
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
 divergent colors around zero in levelplot()
In-Reply-To: <CANVKczO3VmESpZQko1WR+gOWvWMGaJXKaZpDLO9MeC+Fekjf3Q@mail.gmail.com>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>	<9486ef447fd7425188777f98e25ef378@EX-1-HT0.lancs.local>
	<CANVKczO3VmESpZQko1WR+gOWvWMGaJXKaZpDLO9MeC+Fekjf3Q@mail.gmail.com>
Message-ID: <529470D2.90509@stats.ox.ac.uk>

On 26/11/2013 08:25, Barry Rowlingson wrote:
> On Tue, Nov 26, 2013 at 1:02 AM, C. Alina Cansler <acansler at uw.edu> wrote:
>> Don,
>>
>> This looks helpful:
>> https://stat.ethz.ch/pipermail/r-help/2011-March/272361.html
>
> Yes, he's a helpful chap.
>
>   The fundamental problem here is the colour palette. When I was a boy
> all we had was a pen plotter with four coloured pens, and of course
> you could stick different coloured pens in the different pen slots and
> draw four different coloured lines. So your graphics package just said
> which number pen it was going to use and the colour that came out was
> up to you. Most R graphics functions still have this concept, although
> there may be over 100 pens and you don't end up swearing when one runs
> out of ink. A numeric value is converted to an integer and the integer
> does a lookup in a palette to get the colour.
>
>   What you really want, and what my colourscheme package did, was to
> create functions that let users map values directly to colours. You
> could then plot points and lines using that function which meant
> totally controlled value-to-colour mappings that could be used across
> different plots if desired. That worked because points and lines lets
> you specify a colour value directly using something like col="#FF23EC"
> (as well as allowing col=23 and doing a palette lookup).
>
>   But the image function (and probably levelplot) doesn't allow that so

Mis-information alert!   The help says

      col: a list of colors such as that generated by ?rainbow?,
           ?heat.colors?, ?topo.colors?, ?terrain.colors? or similar
           functions.

and look at what they generate.  Or see e.g. ?col2rgb .

Although base graphics has the concept of a palette of colours, AFAIK it 
has always been bolted on top of a general colour specification, 
originally RGB and for many years already RGBA.

> there's various tricks to make functional colour lookups work. I would
> convert the image matrix values to a matrix of colours, then create a
> matrix of the values 1:(n*m), and then image() that 1:(n*m) matrix
> using the colour matrix as a palette. That way each cell had its own
> palette entry, and you controlled that colour using the value-colour
> function.
>
>   Or you could just use ggplot which I'm pretty sure has the same
> concept of mapping values to colours.
>
> Barry
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Tue Nov 26 11:12:18 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 26 Nov 2013 10:12:18 +0000
Subject: [R] summary many regressions
In-Reply-To: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
References: <CAEVDvzWcZOAEVL=Tw_XyMiafvADK_ROVwy5MaGBxmr4sEZXyPA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA07FD@SRVEXCHMBX.precheza.cz>

Hi

It is work for split/lapply or sapply approach.

ff<-function(data) {ss<-lm(y~x, data); c(coef(ss), summary(ss)$adj.r.squared)}
lapply(split(data[,1:2], data$city), ff)

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Gary Dong
> Sent: Tuesday, November 26, 2013 12:36 AM
> To: r-help at r-project.org
> Subject: [R] summary many regressions
> 
> Dear R users,
> 
> I have a large data set which includes data from 300 cities. I want to
> run a biviriate regression for each city and record the coefficient and
> the adjusted R square.
> 
> For example, in the following, I have 10 cities represented by numbers
> from
> 1 to 10:
> 
> x = cumsum(c(0, runif(999, -1, +1)))
> y = cumsum(c(0, runif(999, -1, +1)))
> city = rep(1:10,each=100)
> data<-data.frame(cbind(x,y,city))
> 
> I can manually run regressions for each city:
> fit_city1 <- lm(y ~ x,data=subset(data,data$city==1))
> summary(fit_city1)
> 
> Obvious, it is very tedious to run 300 regressions. I wonder if there
> is a quicker way to do this. Use for loop?  what I want to see is
> something like
> this:
> 
> City        Coefficient       Adjusted R square
> 1              -0.05                  0.36
> 2              -0.12                  0.20
> 3              -0.05                  0.32
> .....
> 
> Any advice is appreciated!
> 
> Gary
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Tue Nov 26 11:12:51 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 26 Nov 2013 10:12:51 +0000
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
 divergent colors around zero in levelplot()
In-Reply-To: <c1e075cf5f724ea387e7ba261b331863@EX-1-HT0.lancs.local>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
	<9486ef447fd7425188777f98e25ef378@EX-1-HT0.lancs.local>
	<CANVKczO3VmESpZQko1WR+gOWvWMGaJXKaZpDLO9MeC+Fekjf3Q@mail.gmail.com>
	<c1e075cf5f724ea387e7ba261b331863@EX-1-HT0.lancs.local>
Message-ID: <CANVKczOCThmBqhZTAsxWYAPa0fgua3Esa2nAh0P+rvSeXJ=83Q@mail.gmail.com>

On Tue, Nov 26, 2013 at 9:58 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:

>>   But the image function (and probably levelplot) doesn't allow that so
>
> Mis-information alert!   The help says
>
>       col: a list of colors such as that generated by ?rainbow?,
>            ?heat.colors?, ?topo.colors?, ?terrain.colors? or similar
>            functions.
>
> and look at what they generate.  Or see e.g. ?col2rgb .
>
> Although base graphics has the concept of a palette of colours, AFAIK it
> has always been bolted on top of a general colour specification,
> originally RGB and for many years already RGBA.


 Yes image allows you to specify col=, but it always specifies a
palette. The matrix values are scaled from 1:length(col) and looked up
in that palette. You can't call image with z as matrix of colours and
get those colours, nor set col to a matrix of colours and a see those
colours laid out. This is unlike points() where specifying col= as a
vector of the same length as the number of points gives you a 1:1
mapping of points to colours.

 To do image() with a 1:1 mapping of cell values to colours requires a
tiny bit of hoop-jumping.

Barry


From gb at stat.umu.se  Tue Nov 26 12:34:57 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 26 Nov 2013 12:34:57 +0100
Subject: [R] How to stop Kaplan-Meier curve at a time point
In-Reply-To: <5294749C.3050409@stat.umu.se>
References: <5294749C.3050409@stat.umu.se>
Message-ID: <52948761.6040408@stat.umu.se>

The functions 'age.window' and 'cal.window' in the package 'eha' are
designed to perform 'rectangular cuts' in the Lexis diagram. So, in your
case,

> require(eha)
> dat <- data.frame(enter = rep(0, length(Survival_days), exit =
Survival_days, event = Outcome)
> dat.1 <- age.window(dat, c(0, 2190))

and 'dat.1' is your right-censored data set.

G?ran Brostr?m

On 11/21/2013 07:36 AM, Thomas Stewart wrote:
> One solution is to format the data as if the follow-up period ended on day
> 2190.  For example,
>
> TTT <- Survival_days
> DDD <- Outcome
>
> DDD[ TTT>2190 ] <- 0
> TTT[ TTT>2190 ] <- 2190
>
> survfit(Surv(TTT, DDD) ~ Gender)
>
> -tgs
>
>
>
> On Wed, Nov 20, 2013 at 3:01 PM, Dr.Vinay Pitchika
> <dr.vinay.muc at gmail.com>wrote:
>
>> Hello R users
>>
>> I have a question with Kaplan-Meier Curve with respect to my research. We
>> have done a retrospective study on fillings in the tooth and their survival
>> in relation to the many influencing factors. We had a long follow-up time
>> (upto 8yrs for some variables). However, we decided to stop the analysis at
>> the 6year follow up time, so that we can have uniform follow-up time for
>> all the variables.
>>
>> I did play a bit with the formula and tried to stop the Kaplan-Meier curve
>> at my desired time (2190days)or roughly 6 years. However, my question is I
>> want to find the significance (log rank test) at this time point between
>> the two curves; because I am not able to find a way to stop the survfit at
>> this time point with my knowledge. Below is the code I used.
>>
>> Gender2<-survfit(Surv(Survival_days, Outcome)~Gender)
>>
>> plot (Gender2, xmax=2190, mark.time=FALSE, col=c(1:2), xlab="Survival time
>> (Days)", ylab="Survival probability", main="Gender") # mark.time=FALSE will
>> remove the censoring lines in the graph. If censoring lines are needed,
>> then remove the mark.time section in the formula.
>>
>> legend("topright",c("Females", "Males"), col=(1:2), lwd=0.5)
>>
>> Am sure, the code in the first line has to be modified. Please help me with
>> this and I will be very thankful to you.
>>
>> Thanks in advance
>>
>> Regards
>> Vinay
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From landronimirc at gmail.com  Tue Nov 26 12:41:36 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Tue, 26 Nov 2013 12:41:36 +0100
Subject: [R] convert data frame: two variables into _one_ binary variable
In-Reply-To: <CAHJ=y95Y5ty7jtSyYVFh-PDVaP_6WAhnguZWCP=sNAzM-POWSQ@mail.gmail.com>
References: <CABxs9VnMMigE4p6T+cN=Oouz95KtEXS-EY032TgRyaTUSW4AJg@mail.gmail.com>
	<CAHJ=y95Y5ty7jtSyYVFh-PDVaP_6WAhnguZWCP=sNAzM-POWSQ@mail.gmail.com>
Message-ID: <CABxs9VmuhPRcXuwjg7siyyTRsCvSOUeH_6ZEaHP32qpC9PkfRA@mail.gmail.com>

Dear all,
Thank you so much for all the replies.

The following worked exactly as needed:
> library("HSAUR2", lib.loc="/home/liv/R/i686-pc-linux-gnu-library/3.0")
> library("reshape2", lib.loc="/usr/local/lib/R/site-library")
> data(womensrole)
> zzz <- melt(womensrole,id.var=c("education","gender"))
> zzzz <- zzz[rep(1:nrow(zzz), zzz$value), 1:4 ]
> zzzz$agree <- zzzz$variable == 'agree'
> zzzz[ zzzz$education %in% 0:1, ]
education gender variable value agree
1 0 Male agree 4 TRUE
1.1 0 Male agree 4 TRUE
1.2 0 Male agree 4 TRUE
1.3 0 Male agree 4 TRUE
2 1 Male agree 2 TRUE
2.1 1 Male agree 2 TRUE
22 0 Female agree 4 TRUE
22.1 0 Female agree 4 TRUE
22.2 0 Female agree 4 TRUE
22.3 0 Female agree 4 TRUE
23 1 Female agree 1 TRUE
43 0 Male disagree 2 FALSE
43.1 0 Male disagree 2 FALSE
64 0 Female disagree 2 FALSE
64.1 0 Female disagree 2 FALSE

Regards,
Liviu


On Mon, Nov 25, 2013 at 8:26 PM, Thomas Stewart
<tgs.public.mail at gmail.com> wrote:
> I do not think Carl's solution answers your question.  Try this:
>
> z <- textConnection(
> "education gender agree disagree sexe
> 1         0   Male     4        2    0
> 2         1   Male     2        0    0
> 3         2   Male     4        0    0
> 4         3   Male     6        3    0
> 5         4   Male     5        5    0
> 6         5   Male    13        7    0"
> )
>
> zz <- read.table(z,header=TRUE, stringsAsFactors=FALSE);
> close(z)
>
> zzz <- melt(zz,id.var=c("education","gender","sexe"))
> zzzz <- zzz[rep(1:nrow(zzz), zzz$value), 1:4 ]
> zzzz$agree <- zzzz$variable == 'agree'
>
> zzzz
>
> -tgs
>
>
> On Mon, Nov 25, 2013 at 4:24 AM, Liviu Andronic <landronimirc at gmail.com>
> wrote:
>>
>> Dear all,
>> I am trying to convert the following data frame into a format more
>> useful for me:
>> > library("HSAUR2", lib.loc="C:/Program Files/R/R-3.0.2/library")
>> Loading required package: tools
>>
>> Attaching package: ?HSAUR2?
>>
>> The following object is masked _by_ ?.GlobalEnv?:
>>
>>     womensrole
>>
>> > head(womensrole)
>>   education gender agree disagree sexe
>> 1         0   Male     4        2    0
>> 2         1   Male     2        0    0
>> 3         2   Male     4        0    0
>> 4         3   Male     6        3    0
>> 5         4   Male     5        5    0
>> 6         5   Male    13        7    0
>>
>>
>> In 'womensrole', how do I convert 'agree' and 'disagree' variables
>> into one proper binary variable, say:
>>   education gender agree sexe
>> 1         0   Male     TRUE           0
>> 2         0   Male     TRUE           0
>> 3         0   Male     TRUE           0
>> 4         0   Male     TRUE           0
>> 5         0   Male     FALSE           0
>> 6         0   Male     FALSE           0
>> 7         1   Male     TRUE           0
>> 8         1   Male     TRUE           0
>> 9         2   Male     TRUE           0
>> 10         2   Male     TRUE           0
>> 11         2   Male     TRUE           0
>> 12         2   Male     TRUE           0
>> [..]
>>
>> I'm sure there is an easy way to do this (in the form of 'melt',
>> 'cast', etc.), but I'm not sure how to approach the problem.
>>
>> Regards,
>> Liviu
>>
>> --
>> Do you know how to read?
>> http://www.alienetworks.com/srtest.cfm
>> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
>> Do you know how to write?
>> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From htl10 at users.sourceforge.net  Tue Nov 26 12:51:24 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 26 Nov 2013 11:51:24 +0000
Subject: [R] freetype 2.5.1 and mono 3.2.5 (was Re: new bugs and new bundles
 Re: [Rd] R/Sweave/cairo/freetype bug fix.)
In-Reply-To: <5225B120.8050406@users.sourceforge.net>
References: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>
	<5225B120.8050406@users.sourceforge.net>
Message-ID: <52948B3C.8020801@users.sourceforge.net>

The freetype people fixed the 2nd set of issues with system fonts shipped with 
Mac OS X, and released 2.5.1 almost immediately after that. So there are
new bundles under http://sourceforge.net/projects/outmodedbonsai/files/R/ .

Just a reminder that the official R binaries for windows/mac OS X are statically 
linked with rather dated versions of freetype with a few known issues. This 
affects the cairo-based functionalities in R. So a rebuild is needed.

Most unix users should just upgrade their system's libfreetype, and 
dynamic-linking should take care of the rest.

Also the routine upgrade of mono 3.2 5. It is, as usual, slightly adapted to
run Illumina GenomeStudio and ...-like workloads on Linux and Mac OS X better.

Hin-Tak Leung wrote:
> The most up-to-date version of freetype (2.5.0.1) have problems with at least
> two of the system fonts shipped with Mac OS X. So the "p1" in "2.5.0.1p1":
>
> cairo-1.12.16+freetype-2.5.0.1p1_macosx.tar.bz2
> cairo-1.12.16+freetype-2.5.0.1p1_windows.tar.bz2
>
> means "2.5.0.1" + 274207eb9a0e3bb20edf30e9a62e25120d5d15e5 (the fix for one of
> the problems). There might be p2 bundles if 2.5.1 doesn't come out soon enough
> with fixes for the rest of the problems.
>
> http://sourceforge.net/projects/outmodedbonsai/files/R/
>
> Just so we are clear, if freetype have problem with a system font, fontconfig
> has problem with a system font, and cairo and R etc.
>
> Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for
> windows and Mac OS X at some stage, but if somebody want to beat me to it,
> please feel free to do so.


From philip.brown at bristol.ac.uk  Tue Nov 26 12:43:58 2013
From: philip.brown at bristol.ac.uk (philthe1st)
Date: Tue, 26 Nov 2013 03:43:58 -0800 (PST)
Subject: [R] error in eval
Message-ID: <1385466238664-4681170.post@n4.nabble.com>

Hi there, I am learning to use and understand R but have come up against a
problem. I'm sure it is a pretty simple thing, but I can't find a solution.
I wonder if anyone could help?

I have been using the "The R Book" by Crawley and working through some of
the examples before trying to apply them to my data.

Yesterday I tried to following from page 560:

> lizards<-read.table('lizards.txt',header=T,sep='\t')
> head(lizards)
   n   sun height  perch    time  species
1 20 Shade   High  Broad Morning opalinus
2 13 Shade    Low  Broad Morning opalinus
3  8 Shade   High Narrow Morning opalinus
4  6 Shade    Low Narrow Morning opalinus
5 34   Sun   High  Broad Morning opalinus
6 31   Sun    Low  Broad Morning opalinus
> model1<-glm(n~sun*height*perch*time*species,poisson)

The GLM worked and I got the correct results.

In the mean time I have had a play around with my data in R and installed
package "pscl". I then then came to back to page 560 to play around with
some variables and could not load the glm I needed. This time, using the
exact same codes as above I received the message:

Error in eval(expr, envir, enclos) : object 'n' not found

Looking at other peoples questions about this problem I have tried changing
"sep" but with no luck. Can anyone help  me work out what has changed since
yesterday and how to get the glm codes working again?

Thank you in advance for any help/suggestions.
Phil



--
View this message in context: http://r.789695.n4.nabble.com/error-in-eval-tp4681170.html
Sent from the R help mailing list archive at Nabble.com.


From Tomer.Czaczkes at biologie.uni-regensburg.de  Tue Nov 26 12:27:47 2013
From: Tomer.Czaczkes at biologie.uni-regensburg.de (Tomer Czaczkes)
Date: Tue, 26 Nov 2013 12:27:47 +0100
Subject: [R] Direct (null) hypothesis testing using GLMMs - possible?
Message-ID: <529493C3020000ED0001868E@gwsmtp1.uni-regensburg.de>

Dear Forumites,



Hi, I'm a long time eavesdropper, first time poster, but I simply couldn't

find any answer to this perhaps rather naive question:



I am trying to see if my data is significantly different from a null

hypothesis using GLMMs.

I would like to run a GLMM because I have random effects. In the future I

might want to do a similar thing with a non-Gaussian distribution structure

as well.



In my current example, I have a series of proportions - in this case the

proportion of ants on one of two available paths. My null-hypothesis is 0.5:

that the ants choose a path randomly, so there will be a more or less amount

of ants on both paths at any given time.



The only way I could think of doing this would be to make a dummy dataset

with a mean of 0.5 and a reasonable variance, put both the dummy data and

real data into one dataframe, and test whether data type (dummy or real) is

a significant predictor of "proportion of ants choosing side X".



 Is there any more elegant way of doing this with a GLMM? Alternatively, can

anyone suggest an alternative way to do such a thing? I will want to add

interactions to the model as well. I generally use the LME4 package, and the

lmer function.





Many thanks for you attention, and I hope my first foray into forum-posting

wasn't hopelessly naive or misplaced...



Tommy

---

University of Regensburg


Dr. Tomer J. Czaczkes
University of Regensburg



From ii54250 at msn.com  Tue Nov 26 13:02:27 2013
From: ii54250 at msn.com (IOANNA)
Date: Tue, 26 Nov 2013 12:02:27 +0000
Subject: [R] Aggregating spatial data
In-Reply-To: <020f01cee9f1$ecd49cf0$c67dd6d0$@tamu.edu>
References: <DUB126-DS25882EDD4A1C4E978986B1F3ED0@phx.gbl>
	<020f01cee9f1$ecd49cf0$c67dd6d0$@tamu.edu>
Message-ID: <DUB126-DS129D45DD81D97BA4292E05F3EC0@phx.gbl>

Fantastic. Thanks very much! Is there an easy  way to plot the points and
the 4 areas?

Best, 
Ioanna

-----Original Message-----
From: David Carlson [mailto:dcarlson at tamu.edu] 
Sent: 25 November 2013 15:21
To: 'IOANNA'; r-help at r-project.org
Subject: RE: [R] Aggregating spatial data

Something like this?

> s <- expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))
> w <-
data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4)),
+   z2=seq(1,length(s$x),by=1))
> w$EW <- cut(w$x, breaks=c(.5, 50.5, 100.5), labels=c("West",
"East"))
> w$NS <- cut(w$y, breaks=c(.5, 50.5, 100.5), labels=c("South",
"North"))
> aggregate(z1~EW+NS, w, table)
    EW    NS z1.1 z1.2 z1.3 z1.4
1 West South 2600 2600 2400 2400
2 East South 2400 2400 2600 2600
3 West North 2600 2600 2400 2400
4 East North 2400 2400 2600 2600
> table(w$z1)

    1     2     3     4 
10000 10000 10000 10000 
> aggregate(z2~EW+NS, w, mean)
    EW    NS     z2
1 West South 2475.5
2 East South 2525.5
3 West North 7475.5
4 East North 7525.5

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of IOANNA
Sent: Monday, November 25, 2013 8:46 AM
To: r-help at r-project.org
Subject: [R] Aggregating spatial data
Importance: High

Hello all, 

 

I have a data frame in the form:

 

s<-expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))

w<-data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4))
,z2=seq(1,le
ngth(s$x),by=1))

 

The w$x and w$y represent the location of points and z1 and z2 attributes
corresponding to these points. 

 

 

My question is how to divide this area in 4 sub-areas of equal points each
and produce the counts of z1= '1', '2' , '3' in each quarter as well as mean
values of z2 for each quarter. 

 

Best, 

Ioanna


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From assymeon2 at hotmail.com  Tue Nov 26 09:32:53 2013
From: assymeon2 at hotmail.com (ANNA SIMEONIDOU)
Date: Tue, 26 Nov 2013 10:32:53 +0200
Subject: [R]  Problem with loop, matrix and data frame
In-Reply-To: <DUB116-W668962EE03F0A032C811ACECEC0@phx.gbl>
References: <DUB116-W668962EE03F0A032C811ACECEC0@phx.gbl>
Message-ID: <DUB116-W66D772910DC32D561DA279ECEC0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/139fd778/attachment.pl>

From S.Ellison at lgcgroup.com  Tue Nov 26 14:46:20 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 26 Nov 2013 13:46:20 +0000
Subject: [R] cut2 not binning interval endpoints correctly
In-Reply-To: <D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>
References: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
	<D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5605AD3C9C@GOLD.corp.lgc-group.com>

> -----Original Message-----
> > I am attempting to bin a vector of numbers between 0 and 1 into
> > intervals of 0.001 but many values at the endpoints of the intervals
> > are getting binned into the wrong interval. For example, the first 3
> > rows are binned incorrectly here:
>
> From: Jim Holtman
> FAQ 7.31
> 
Maybe. But 

#and
0.308 == seq(0, 0.310, 0.001)[309]
# [1] TRUE

seems to suggest that while some oddities may be explained by finite precision, 0.308 is exactly represented by the cut sequence  here, so .308 should be OK.

#in addition, extending  the OP's example
df <- data.frame(x=c(0.308,0.422,0.174,0.04709))
df$bucket <- cut2(df$x,seq(0,1,0.001),oneval=FALSE)
df$cutR <- cut(df$x,seq(0,1,0.001),right=FALSE)
df

#         x        bucket          cutR
# 1 0.30800 [0.307,0.308) [0.308,0.309)
# 2 0.42200 [0.421,0.422) [0.422,0.423)
# 3 0.17400 [0.173,0.174) [0.173,0.174)
# 4 0.04709 [0.047,0.048) [0.047,0.048)

implies that cut2 is not doing the same thing as cut despite the same intended outcome (at least on R 3.0.1, my present version at work).

This may be one for Frank Harrell ...

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jholtman at gmail.com  Tue Nov 26 15:00:20 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 26 Nov 2013 09:00:20 -0500
Subject: [R] cut2 not binning interval endpoints correctly
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5605AD3C9C@GOLD.corp.lgc-group.com>
References: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
	<D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5605AD3C9C@GOLD.corp.lgc-group.com>
Message-ID: <CAAxdm-7B+JBVgwAx2VDL4uMO9AXa+yo34UREfLQSUMj0AnAMmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/77853dd7/attachment.pl>

From pdalgd at gmail.com  Tue Nov 26 15:00:52 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 26 Nov 2013 15:00:52 +0100
Subject: [R] error in eval
In-Reply-To: <1385466238664-4681170.post@n4.nabble.com>
References: <1385466238664-4681170.post@n4.nabble.com>
Message-ID: <B18B0951-ABF1-4A0C-9812-4F688F8EEEEC@gmail.com>

AFAICT, your code should not be expected to run unless you have an attach(lizards) prior to the glm() call. Either that or you need data=lizards in the call itself.

-pd

On 26 Nov 2013, at 12:43 , philthe1st <philip.brown at bristol.ac.uk> wrote:

> Hi there, I am learning to use and understand R but have come up against a
> problem. I'm sure it is a pretty simple thing, but I can't find a solution.
> I wonder if anyone could help?
> 
> I have been using the "The R Book" by Crawley and working through some of
> the examples before trying to apply them to my data.
> 
> Yesterday I tried to following from page 560:
> 
>> lizards<-read.table('lizards.txt',header=T,sep='\t')
>> head(lizards)
>   n   sun height  perch    time  species
> 1 20 Shade   High  Broad Morning opalinus
> 2 13 Shade    Low  Broad Morning opalinus
> 3  8 Shade   High Narrow Morning opalinus
> 4  6 Shade    Low Narrow Morning opalinus
> 5 34   Sun   High  Broad Morning opalinus
> 6 31   Sun    Low  Broad Morning opalinus
>> model1<-glm(n~sun*height*perch*time*species,poisson)
> 
> The GLM worked and I got the correct results.
> 
> In the mean time I have had a play around with my data in R and installed
> package "pscl". I then then came to back to page 560 to play around with
> some variables and could not load the glm I needed. This time, using the
> exact same codes as above I received the message:
> 
> Error in eval(expr, envir, enclos) : object 'n' not found
> 
> Looking at other peoples questions about this problem I have tried changing
> "sep" but with no luck. Can anyone help  me work out what has changed since
> yesterday and how to get the glm codes working again?
> 
> Thank you in advance for any help/suggestions.
> Phil
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/error-in-eval-tp4681170.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From igorjrr at gmail.com  Tue Nov 26 15:36:28 2013
From: igorjrr at gmail.com (Igor Ribeiro)
Date: Tue, 26 Nov 2013 09:36:28 -0500
Subject: [R] SVG export - RGB fill
Message-ID: <CALfhqnkq53jLV-jESJ-Wjzdoyeh+=j_8Pyv76xG=TiL9R9O89A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/7a224023/attachment.pl>

From dcarlson at tamu.edu  Tue Nov 26 15:53:14 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 26 Nov 2013 08:53:14 -0600
Subject: [R] error in eval
In-Reply-To: <B18B0951-ABF1-4A0C-9812-4F688F8EEEEC@gmail.com>
References: <1385466238664-4681170.post@n4.nabble.com>
	<B18B0951-ABF1-4A0C-9812-4F688F8EEEEC@gmail.com>
Message-ID: <015101ceeab7$3c2fe690$b48fb3b0$@tamu.edu>

And in fact

attach(lizards)

is included on page 560. You must have left it out of your
example code. Without it, your first example would not have run
either. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of peter
dalgaard
Sent: Tuesday, November 26, 2013 8:01 AM
To: philthe1st
Cc: r-help help
Subject: Re: [R] error in eval

AFAICT, your code should not be expected to run unless you have
an attach(lizards) prior to the glm() call. Either that or you
need data=lizards in the call itself.

-pd

On 26 Nov 2013, at 12:43 , philthe1st
<philip.brown at bristol.ac.uk> wrote:

> Hi there, I am learning to use and understand R but have come
up against a
> problem. I'm sure it is a pretty simple thing, but I can't
find a solution.
> I wonder if anyone could help?
> 
> I have been using the "The R Book" by Crawley and working
through some of
> the examples before trying to apply them to my data.
> 
> Yesterday I tried to following from page 560:
> 
>> lizards<-read.table('lizards.txt',header=T,sep='\t')
>> head(lizards)
>   n   sun height  perch    time  species
> 1 20 Shade   High  Broad Morning opalinus
> 2 13 Shade    Low  Broad Morning opalinus
> 3  8 Shade   High Narrow Morning opalinus
> 4  6 Shade    Low Narrow Morning opalinus
> 5 34   Sun   High  Broad Morning opalinus
> 6 31   Sun    Low  Broad Morning opalinus
>> model1<-glm(n~sun*height*perch*time*species,poisson)
> 
> The GLM worked and I got the correct results.
> 
> In the mean time I have had a play around with my data in R
and installed
> package "pscl". I then then came to back to page 560 to play
around with
> some variables and could not load the glm I needed. This time,
using the
> exact same codes as above I received the message:
> 
> Error in eval(expr, envir, enclos) : object 'n' not found
> 
> Looking at other peoples questions about this problem I have
tried changing
> "sep" but with no luck. Can anyone help  me work out what has
changed since
> yesterday and how to get the glm codes working again?
> 
> Thank you in advance for any help/suggestions.
> Phil
> 
> 
> 
> --
> View this message in context:
http://r.789695.n4.nabble.com/error-in-eval-tp4681170.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From bbolker at gmail.com  Tue Nov 26 16:16:02 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Nov 2013 15:16:02 +0000
Subject: [R] Independent variable dependent on offset in GLMM
References: <CEB8E939.36C8%jonas.josefsson@slu.se>
Message-ID: <loom.20131126T160636-904@post.gmane.org>

Jonas Josefsson <jonas.josefsson <at> slu.se> writes:

> 
> Hi!
 
  (I was initially going to say that this question would probably be
better on r-sig-mixed-models at r-project.org, but now that I've been
through it I've changed my mind -- there aren't really any issues here
that are specific to mixed models ... it's really mostly a
*statistical* question rather than an R question, and as such might
belong on a statistics forum such as http://stats.stackexchange.com ...)

> I'm running glmer (lme4) models with biodiversity data and I'm
> having trouble with understanding/finding information on how the
> offset() option is implemented.
 
> Explicitly, I'm wondering if the offset is only implemented on the
> dependent variable (as I think it is), or does it also affect
> independent variables in the model (was told this by a stat guy at
> our department)?

  I'm not perfectly sure I understand your question, but as I understand
it you are right and the stat guy in your department is wrong (but
perhaps you misunderstood them?). The offset term is added to the linear
predictor of the model.
 
> My data is inventories of birds (species richness and abundance) at
> the scale of whole farms. Thus, each observation has a different
> inventory area which I am accounting for in the model as: offset =
> log(INVAREA).

  It makes quite a bit of sense to model abundance as directly
proportional to area (i.e., you are in effect modeling density rather
than total counts, but accounting for changes in Poisson sampling
variance appropriately).  I'm not so sure it makes sense to 
model species richness as directly proportional to area.  You might
want to consider adding log(area) as a covariate rather than as
an offset, which is then essentially assuming a power-law relationship
between area and species richness (log(richness) = beta_a*log(area)
-> richness = area^beta).

> However, as a fixed effect in the model I've got the number of
> different crop types in the inventoried area.  As this variable is
> also affected by inventoried area, I would like to account for this
> in some way, but I find it difficult to know the best way to do so.

> Right now, I have made a linear quadratic function (using lm) of
> crop number ~ inventoried area + inventoried area^2 to describe how
> crop number increases with increasing sample size (area). Then, I
> have subtracted fitted values from observed number of crops and used
> this measure in the models. Is this a reasonable work around?

  This doesn't make very much sense to me, but it will depend
on your general model of what's going on. I would have guessed that
abundance (for example) would depend on the number of crop types
available, not on whether the number of crop types was higher than
expected for a sample of a given area.  I suppose it's possible, though.


From dcarlson at tamu.edu  Tue Nov 26 16:42:15 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 26 Nov 2013 09:42:15 -0600
Subject: [R] Aggregating spatial data
In-Reply-To: <DUB126-DS129D45DD81D97BA4292E05F3EC0@phx.gbl>
References: <DUB126-DS25882EDD4A1C4E978986B1F3ED0@phx.gbl>
	<020f01cee9f1$ecd49cf0$c67dd6d0$@tamu.edu>
	<DUB126-DS129D45DD81D97BA4292E05F3EC0@phx.gbl>
Message-ID: <017001ceeabe$15225360$3f66fa20$@tamu.edu>

The points are easy:

plot(y~x, w, pch=".", asp=1)

The four polygons are just four polygon() calls:

polygon(c(.5, .5, 50.5, 50.5), c(.5, 50.5, 50.5, .5))
polygon(c(.5, .5, 50.5, 50.5), c(50.5, 100.5, 100.5, 50.5))
polygon(c(50.5, 50.5, 100.5, 100.5), c(.5, 50.5, 50.5, .5))
polygon(c(50.5, 50.5, 100.5, 100.5), c(50.5, 100.5, 100.5,
50.5))

To make the process more generalizable (at least for square
blocks), try this:

block <- c(2, 2)
size <- 50
start <- c(.5, .5)
for (i in 0:(block[1]-1)) {
	for (j in 0:(block[2]-1)) {
		px <- start[1]+i*size
		py <- start[2]+j*size 
		polygon(c(px, px, px+size, px+size), 
			c(py, py+size, py+size, py),
border="red")
	}
}

David

-----Original Message-----
From: IOANNA [mailto:ii54250 at msn.com] 
Sent: Tuesday, November 26, 2013 6:02 AM
To: dcarlson at tamu.edu
Cc: r-help at r-project.org
Subject: RE: [R] Aggregating spatial data

Fantastic. Thanks very much! Is there an easy  way to plot the
points and
the 4 areas?

Best, 
Ioanna

-----Original Message-----
From: David Carlson [mailto:dcarlson at tamu.edu] 
Sent: 25 November 2013 15:21
To: 'IOANNA'; r-help at r-project.org
Subject: RE: [R] Aggregating spatial data

Something like this?

> s <- expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))
> w <-
data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4)),
+   z2=seq(1,length(s$x),by=1))
> w$EW <- cut(w$x, breaks=c(.5, 50.5, 100.5), labels=c("West",
"East"))
> w$NS <- cut(w$y, breaks=c(.5, 50.5, 100.5), labels=c("South",
"North"))
> aggregate(z1~EW+NS, w, table)
    EW    NS z1.1 z1.2 z1.3 z1.4
1 West South 2600 2600 2400 2400
2 East South 2400 2400 2600 2600
3 West North 2600 2600 2400 2400
4 East North 2400 2400 2600 2600
> table(w$z1)

    1     2     3     4 
10000 10000 10000 10000 
> aggregate(z2~EW+NS, w, mean)
    EW    NS     z2
1 West South 2475.5
2 East South 2525.5
3 West North 7475.5
4 East North 7525.5

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of IOANNA
Sent: Monday, November 25, 2013 8:46 AM
To: r-help at r-project.org
Subject: [R] Aggregating spatial data
Importance: High

Hello all, 

 

I have a data frame in the form:

 

s<-expand.grid(x=seq(1,100,by=1),y=seq(1,100,by=1))

w<-data.frame(x=s$x,y=s$y,z1=rep(c(1,2,3,4),times=length(s$x/4))
,z2=seq(1,le
ngth(s$x),by=1))

 

The w$x and w$y represent the location of points and z1 and z2
attributes
corresponding to these points. 

 

 

My question is how to divide this area in 4 sub-areas of equal
points each
and produce the counts of z1= '1', '2' , '3' in each quarter as
well as mean
values of z2 for each quarter. 

 

Best, 

Ioanna


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From kiangati at gmail.com  Tue Nov 26 17:28:47 2013
From: kiangati at gmail.com (Keniajin Wambui)
Date: Tue, 26 Nov 2013 19:28:47 +0300
Subject: [R] Subscript out of bounds
Message-ID: <CAE=fH8EZfeZQmGZ7m2RkQBg6CwEJwA-Nha13SVDXQEq4mJK49A@mail.gmail.com>

I am using R3.0.2 on a windows 64 bit machine. I building a .rnw file
from an .r file. I am using MikTex as the engine for latex. The
function dtaStata <- read.dta("core2.dta", convert.dates=TRUE) works
well in .R but; When I try reading a dta (stata) file I get an error
"subscript out of bounds". The file has 52 variables and over 90000
observations

Below is the code in latex

\section{Introduction}
The following clinical variables are in the core data set

<<echo=false, results=hide>>=
#setting the working directory
setwd("H:/Rjob/coreGraphs/core2Report/")

#load the packages
library(ggplot2)
library(foreign)
library(reshape2)
library(psych)
library(epicalc)
library(plyr)
library(doBy) #used to summarize

##load the core 2 data
dtaStata <- read.dta("core2.dta", convert.dates=TRUE)
dtaStata <- as.data.frame(dtaStata)
dtaStata$ndad<-as.Date(dtaStata$ndad, origin='1960-01-01')
totalData <- table(dtaStata$yr)
#variables in core2
@
the data has \Sexpr{ncol(dtaStata)} columns \Sexpr{getwd()}
\clearpage
\end{document}

-- 
Mega Six Solutions
Web Designer and Research Consultant


From smartpink111 at yahoo.com  Tue Nov 26 16:38:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 26 Nov 2013 07:38:13 -0800 (PST)
Subject: [R] How to merge sequences with new sequence insertion
In-Reply-To: <1385478031.90472.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1385478031.90472.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1385480293.39901.YahooMailNeo@web142604.mail.bf1.yahoo.com>





Hi,
Try:

Lines1 <- readLines(textConnection(">contig number 11
tttgctcggaggggatc
>contig number 23
gaaaacacttccttattatacaggtaaaccgtatttggat
>contig number 3
aaagctcggaggggatcccct")) 


seq1 <- "nnnnncattccattcattaattaattaatgaatgaatgnnnnn"
concatenated_contig <- paste(Lines1[!grepl(">",Lines1)],collapse=seq1)
concatenated_contig
#[1] #"tttgctcggaggggatcnnnnncattccattcattaattaattaatgaatgaatgnnnnngaaaacacttccttattatacaggtaaaccgtatttggatnnnnncattccattcattaattaattaatgaatgaatgnnnnnaaagctcggaggggatcccct"
A.K.



Hi all, 

I have a sequence files with huge number of contigs such as (contig number does not reflect the order): 

>contig number 11 
tttgctcggaggggatc 
>contig number 23 
gaaaacacttccttattatacaggtaaaccgtatttggat 
>contig number 3 
aaagctcggaggggatcccct 
... 
.. 

I want to concatenate the contigs such that the above order is 
preserved, and also, I want to insert the sequence 
"nnnnncattccattcattaattaattaatgaatgaatgnnnnn" in each contig boundaries 
(here are two contig boundaries), such that the final output file would 
become as follows: 


>concatenated contig 
tttgctcggaggggatcnnnnncattccattcattaattaattaatgaatgaatgnnnnngaaaacacttccttattatacaggtaaaccgtatttggatnnnnncattccattcattaattaattaatgaatgaatgnnnnnaaagctcggaggggatcccct 

Any help in solving the problem is highly appreciated. Thanks in advance..


From antoine.migeon at u-bourgogne.fr  Tue Nov 26 13:37:05 2013
From: antoine.migeon at u-bourgogne.fr (Antoine Migeon)
Date: Tue, 26 Nov 2013 13:37:05 +0100
Subject: [R] cannot load pbdMPI package after compilation
In-Reply-To: <51B5C369.90106@u-bourgogne.fr>
References: <51B1D53C.1090305@u-bourgogne.fr>
	<51B53732.6050607@ymail.com>	<51B56FE8.50803@stats.ox.ac.uk>
	<51B5C369.90106@u-bourgogne.fr>
Message-ID: <529495F1.6080804@u-bourgogne.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/5a28349a/attachment.pl>

From ulhaqz at gmail.com  Tue Nov 26 15:59:28 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Tue, 26 Nov 2013 19:59:28 +0500
Subject: [R] Generating Frequency Values
Message-ID: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/d9a28c13/attachment.pl>

From philip.brown at bristol.ac.uk  Tue Nov 26 16:20:27 2013
From: philip.brown at bristol.ac.uk (philthe1st)
Date: Tue, 26 Nov 2013 07:20:27 -0800 (PST)
Subject: [R] error in eval
In-Reply-To: <1385466238664-4681170.post@n4.nabble.com>
References: <1385466238664-4681170.post@n4.nabble.com>
Message-ID: <1385479227347-4681187.post@n4.nabble.com>

Thank you for your replies,

A massive oversight on my part. I did include it the first time but not
later on. Sorry to waste your time with this simple question.

Thanks,
Phil



--
View this message in context: http://r.789695.n4.nabble.com/error-in-eval-tp4681170p4681187.html
Sent from the R help mailing list archive at Nabble.com.


From irafuchs at gmail.com  Tue Nov 26 18:34:57 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Tue, 26 Nov 2013 12:34:57 -0500
Subject: [R] Installing quantstrat
Message-ID: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>

I would like to try to run the quantstrat package (located here: https://r-forge.r-project.org/R/?group_id=316). However, if I try to load quantstrat, I get a warning that it is not available for R v3.0.1, so perhaps that is the end of it. 
Does anyone know if it is possible to run quantstrat with the current version of R?

From josh.m.ulrich at gmail.com  Tue Nov 26 18:41:10 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 26 Nov 2013 11:41:10 -0600
Subject: [R] Installing quantstrat
In-Reply-To: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>
References: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>
Message-ID: <CAPPM_gTFg_YNM3AbeAwX21DsESewC-PRP1QG+PAZvQVHx3xiUg@mail.gmail.com>

On Tue, Nov 26, 2013 at 11:34 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
> I would like to try to run the quantstrat package (located here: https://r-forge.r-project.org/R/?group_id=316). However, if I try to load quantstrat, I get a warning that it is not available for R v3.0.1, so perhaps that is the end of it.
> Does anyone know if it is possible to run quantstrat with the current version of R?

Yep, see here: http://stackoverflow.com/q/11105131/271616

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From sarah.goslee at gmail.com  Tue Nov 26 18:41:44 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 26 Nov 2013 12:41:44 -0500
Subject: [R] Generating Frequency Values
In-Reply-To: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
References: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
Message-ID: <CAM_vjumEym6VNNunnhKGWNyUTchDdo5_cUAhg0JFHvr+maC=kQ@mail.gmail.com>

Hi,

If I understand the question don't you simply want:

> with(df.1, rep(Piglets, times=Frequency))
 [1]  5  7  7  8  8  8  9  9  9 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11
[26] 11 12 12 12 12 12 13 13 13 14 14


Sarah

On Tue, Nov 26, 2013 at 9:59 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:
> Hi,
>
> My problem is as follows:
>
> INPUT:
> "Frequency" from one column and  value of "Piglets" from another one
>
> OUTPUT:
> Repeat this "Piglet" value as per the "Frequency"
> i.e.
> Piglet 1, Frequency 3, implies 1,1,1
> Piglet 7, Frequency 2, implies 7,7
>
> SOLUTION:
> This is what I have tried so far:
>
> 1. A helper function:
>> dput(fn.1)
> function (df.1, vt.1)
> {
>     i = c(1)
>     for (i in seq_along(dim(df.1)[1])) {
>         print(i)
>         temp = rep(df.1$Piglets[i], df.1$Frequency[i])
>         append(vt.1, values = temp)
>     }
> }
>
> 2. A dummy data frame:
>> dput(df.1)
> structure(list(Piglets = 5:14, Frequency = c(1L, 0L, 2L, 3L,
> 3L, 9L, 8L, 5L, 3L, 2L)), .Names = c("Piglets", "Frequency"), class =
> "data.frame", row.names = c(NA,
> -10L))
>
> 3. A dummy vector to hold results:
>> dput(vt.1)
> 1
>
> 4. Finally the function call:
> fn.1(df.1, vt.1)
>
> 5. The results is:
> [1] 1
>
> PROBLEM:
> The result is not a repetition of Piglet value as per their respective
> frequencies.
>
>
>
> Thanks in advance for guidance and help.
>
> CheeRs !
>
>
> p.s I have used caps for my heading / sections, nothing else is implied by
> their use.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From dmck at u.washington.edu  Tue Nov 26 18:48:13 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Tue, 26 Nov 2013 09:48:13 -0800
Subject: [R] specify breaks in divergent palette in RColorBrewer: was
	divergent colors around zero in levelplot()
In-Reply-To: <CANVKczOCThmBqhZTAsxWYAPa0fgua3Esa2nAh0P+rvSeXJ=83Q@mail.gmail.com>
References: <181A14B7-C25B-46DE-8432-02E60DB9AA64@u.washington.edu>
	<CACk-te0VQLrwNow4PrGwr8CCgpAhaxe2h3BGVcfpaogcmdrYqQ@mail.gmail.com>
	<E527B8A3-84BB-4833-AC87-29B0213CE9F2@u.washington.edu>
	<9486ef447fd7425188777f98e25ef378@EX-1-HT0.lancs.local>
	<CANVKczO3VmESpZQko1WR+gOWvWMGaJXKaZpDLO9MeC+Fekjf3Q@mail.gmail.com>
	<c1e075cf5f724ea387e7ba261b331863@EX-1-HT0.lancs.local>
	<CANVKczOCThmBqhZTAsxWYAPa0fgua3Esa2nAh0P+rvSeXJ=83Q@mail.gmail.com>
Message-ID: <FD723D02-1D2F-4D60-B0E4-D8AE6E152B66@u.washington.edu>

Thanks to everyone who weighed in on this.  I found a naive solution that was good enough for my needs, and it may take me a bit to get the subtleties
of your comments.

On Nov 26, 2013, at 2:12 AM, Barry Rowlingson <b.rowlingson at lancaster.ac.uk> wrote:

> On Tue, Nov 26, 2013 at 9:58 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
> 
>>>  But the image function (and probably levelplot) doesn't allow that so
>> 
>> Mis-information alert!   The help says
>> 
>>      col: a list of colors such as that generated by ?rainbow?,
>>           ?heat.colors?, ?topo.colors?, ?terrain.colors? or similar
>>           functions.
>> 
>> and look at what they generate.  Or see e.g. ?col2rgb .
>> 
>> Although base graphics has the concept of a palette of colours, AFAIK it
>> has always been bolted on top of a general colour specification,
>> originally RGB and for many years already RGBA.
> 
> 
> Yes image allows you to specify col=, but it always specifies a
> palette. The matrix values are scaled from 1:length(col) and looked up
> in that palette. You can't call image with z as matrix of colours and
> get those colours, nor set col to a matrix of colours and a see those
> colours laid out. This is unlike points() where specifying col= as a
> vector of the same length as the number of points gives you a 1:1
> mapping of points to colours.
> 
> To do image() with a 1:1 mapping of cell values to colours requires a
> tiny bit of hoop-jumping.
> 
> Barry
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From irafuchs at gmail.com  Tue Nov 26 18:55:30 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Tue, 26 Nov 2013 12:55:30 -0500
Subject: [R] Installing quantstrat
In-Reply-To: <CAPPM_gTFg_YNM3AbeAwX21DsESewC-PRP1QG+PAZvQVHx3xiUg@mail.gmail.com>
References: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>
	<CAPPM_gTFg_YNM3AbeAwX21DsESewC-PRP1QG+PAZvQVHx3xiUg@mail.gmail.com>
Message-ID: <9C245CCF-FC45-4E65-B6C6-E3005AA655F1@gmail.com>

Thanks. Since quantstrat showed a Last change date of only 6 days ago and a Build status of "Current", I blithely assumed that the command that is shown for installing it would work:

install.packages("quantstrat", repos="http://R-Forge.R-project.org")
Installing package into ?/Users/ihf/Library/R/3.0/library?
(as ?lib? is unspecified)
Warning: unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0

   package ?quantstrat? is available as a source package but not as a binary

Warning message:
package ?quantstrat? is not available (for R version 3.0.1) 

Based on the posting you referred to on stackoverflow, I need to download the SVN version and then see if I can build it. Although, I presume that if it were that simple, why would the version crated a week ago not work?

On Nov 26, 2013, at 12:41 PM, Joshua Ulrich wrote:

> On Tue, Nov 26, 2013 at 11:34 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>> I would like to try to run the quantstrat package (located here: https://r-forge.r-project.org/R/?group_id=316). However, if I try to load quantstrat, I get a warning that it is not available for R v3.0.1, so perhaps that is the end of it.
>> Does anyone know if it is possible to run quantstrat with the current version of R?
> 
> Yep, see here: http://stackoverflow.com/q/11105131/271616
> 
> Best,
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Tue Nov 26 18:59:27 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 26 Nov 2013 11:59:27 -0600
Subject: [R] Installing quantstrat
In-Reply-To: <9C245CCF-FC45-4E65-B6C6-E3005AA655F1@gmail.com>
References: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>
	<CAPPM_gTFg_YNM3AbeAwX21DsESewC-PRP1QG+PAZvQVHx3xiUg@mail.gmail.com>
	<9C245CCF-FC45-4E65-B6C6-E3005AA655F1@gmail.com>
Message-ID: <CAPPM_gTBPPa==+714px526i4BX+JV5sjsCfSUGa80rwiwKsb2Q@mail.gmail.com>

On Tue, Nov 26, 2013 at 11:55 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
> Thanks. Since quantstrat showed a Last change date of only 6 days ago and a Build status of "Current", I blithely assumed that the command that is shown for installing it would work:
>
> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
> Installing package into ?/Users/ihf/Library/R/3.0/library?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0
>
>    package ?quantstrat? is available as a source package but not as a binary
>
> Warning message:
> package ?quantstrat? is not available (for R version 3.0.1)
>
> Based on the posting you referred to on stackoverflow, I need to download the SVN version and then see if I can build it. Although, I presume that if it were that simple, why would the version crated a week ago not work?
>
I don't know; that's a question for the R-Forge maintainers.  It looks
like they're building with 3.0.2, but I'm not sure that matters.  The
easiest thing to do it just check out the source and build it
yourself.

> On Nov 26, 2013, at 12:41 PM, Joshua Ulrich wrote:
>
>> On Tue, Nov 26, 2013 at 11:34 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>>> I would like to try to run the quantstrat package (located here: https://r-forge.r-project.org/R/?group_id=316). However, if I try to load quantstrat, I get a warning that it is not available for R v3.0.1, so perhaps that is the end of it.
>>> Does anyone know if it is possible to run quantstrat with the current version of R?
>>
>> Yep, see here: http://stackoverflow.com/q/11105131/271616
>>
>> Best,
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>


From adelessafi at gmail.com  Tue Nov 26 19:11:59 2013
From: adelessafi at gmail.com (Adel ESSAFI)
Date: Tue, 26 Nov 2013 19:11:59 +0100
Subject: [R] legend for bar plot ?
Message-ID: <CAF=-T0jJK=XhFnpYpsM00qkazMc=ZTD+PhyKYBrgz-CkRjA7Zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/db29c884/attachment.pl>

From adelessafi at gmail.com  Tue Nov 26 19:15:34 2013
From: adelessafi at gmail.com (Adel ESSAFI)
Date: Tue, 26 Nov 2013 19:15:34 +0100
Subject: [R] legend for bar plot ?
Message-ID: <CAF=-T0gY799=kQodEAckTC4OAZU9-BYeFzDkz9ogF+6a31W1Jg@mail.gmail.com>

Hello;
I have the following table
> m
    V2 V1      V3
1  C/L  0  732179
3  C/S  0  803926
19 D/F  0  724924
17 D/I  0  755841
13 D/L  0  731904
15 D/S  0  798289
11 I/F  0  871670
9  I/I  0  897718
5  I/L  0 2628113
7  I/S  0 2628113
2  C/L  1 1107269
4  C/S  1 1395714
20 D/F  1 1181282
18 D/I  1 1264249
14 D/L  1 1107595
16 D/S  1 1399836
12 I/F  1 1304294
10 I/I  1 1542813
6  I/L  1 2628113
8  I/S  1 2475448
as you can see, the table is sorted by the second and the first column.
with this command :
 barplot(m$V3,names.arg=m$V2,col=rainbow(10))
I succeded to print the figure attached.
Now, I need to indicate that the first 10 bar are for beta=0 and the second
10 bars are for beta=1.
Could you help please.
Best regards


-- 
PhD candidate in Computer Science
Address
3 avenue lamine, cit? ezzahra, Sousse 4000
Tunisia
tel: +216 97 246 706 (+33640302046 jusqu'au 15/6)
fax: +216 71 391 166
-------------- next part --------------
A non-text attachment was scrubbed...
Name: plot.pdf
Type: application/pdf
Size: 7165 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/7b0617b7/attachment.pdf>

From jdnewmil at dcn.davis.CA.us  Tue Nov 26 19:00:10 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 26 Nov 2013 10:00:10 -0800
Subject: [R] Subscript out of bounds
In-Reply-To: <CAE=fH8EZfeZQmGZ7m2RkQBg6CwEJwA-Nha13SVDXQEq4mJK49A@mail.gmail.com>
References: <CAE=fH8EZfeZQmGZ7m2RkQBg6CwEJwA-Nha13SVDXQEq4mJK49A@mail.gmail.com>
Message-ID: <4b09adfc-0863-47ff-9947-327b07434a44@email.android.com>

This is the kind of question where including the output of sessionInfo() is a really good idea.

This would, for example, answer the question of whether you are in fact using the x64 version of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Keniajin Wambui <kiangati at gmail.com> wrote:
>I am using R3.0.2 on a windows 64 bit machine. I building a .rnw file
>from an .r file. I am using MikTex as the engine for latex. The
>function dtaStata <- read.dta("core2.dta", convert.dates=TRUE) works
>well in .R but; When I try reading a dta (stata) file I get an error
>"subscript out of bounds". The file has 52 variables and over 90000
>observations
>
>Below is the code in latex
>
>\section{Introduction}
>The following clinical variables are in the core data set
>
><<echo=false, results=hide>>=
>#setting the working directory
>setwd("H:/Rjob/coreGraphs/core2Report/")
>
>#load the packages
>library(ggplot2)
>library(foreign)
>library(reshape2)
>library(psych)
>library(epicalc)
>library(plyr)
>library(doBy) #used to summarize
>
>##load the core 2 data
>dtaStata <- read.dta("core2.dta", convert.dates=TRUE)
>dtaStata <- as.data.frame(dtaStata)
>dtaStata$ndad<-as.Date(dtaStata$ndad, origin='1960-01-01')
>totalData <- table(dtaStata$yr)
>#variables in core2
>@
>the data has \Sexpr{ncol(dtaStata)} columns \Sexpr{getwd()}
>\clearpage
>\end{document}


From smartpink111 at yahoo.com  Tue Nov 26 18:43:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 26 Nov 2013 09:43:31 -0800 (PST)
Subject: [R] Generating Frequency Values
In-Reply-To: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
References: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
Message-ID: <1385487811.46339.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

Not sure whether this is what you wanted.
df.1[rep(1:nrow(df.1),df.1[,2]),]
A.K.




On Tuesday, November 26, 2013 12:31 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:
Hi,

My problem is as follows:

INPUT:
"Frequency" from one column and? value of "Piglets" from another one

OUTPUT:
Repeat this "Piglet" value as per the "Frequency"
i.e.
Piglet 1, Frequency 3, implies 1,1,1
Piglet 7, Frequency 2, implies 7,7

SOLUTION:
This is what I have tried so far:

1. A helper function:
> dput(fn.1)
function (df.1, vt.1)
{
? ? i = c(1)
? ? for (i in seq_along(dim(df.1)[1])) {
? ? ? ? print(i)
? ? ? ? temp = rep(df.1$Piglets[i], df.1$Frequency[i])
? ? ? ? append(vt.1, values = temp)
? ? }
}

2. A dummy data frame:
> dput(df.1)
structure(list(Piglets = 5:14, Frequency = c(1L, 0L, 2L, 3L,
3L, 9L, 8L, 5L, 3L, 2L)), .Names = c("Piglets", "Frequency"), class =
"data.frame", row.names = c(NA,
-10L))

3. A dummy vector to hold results:
> dput(vt.1)
1

4. Finally the function call:
fn.1(df.1, vt.1)

5. The results is:
[1] 1

PROBLEM:
The result is not a repetition of Piglet value as per their respective
frequencies.



Thanks in advance for guidance and help.

CheeRs !


p.s I have used caps for my heading / sections, nothing else is implied by
their use.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Tue Nov 26 19:19:10 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 26 Nov 2013 19:19:10 +0100
Subject: [R] Generating Frequency Values
In-Reply-To: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
References: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
Message-ID: <80096A98-C971-4D4A-91CC-BC6C4C952B37@xs4all.nl>


On 26-11-2013, at 15:59, Burhan ul haq <ulhaqz at gmail.com> wrote:

> Hi,
> 
> My problem is as follows:
> 
> INPUT:
> "Frequency" from one column and  value of "Piglets" from another one
> 
> OUTPUT:
> Repeat this "Piglet" value as per the "Frequency"
> i.e.
> Piglet 1, Frequency 3, implies 1,1,1
> Piglet 7, Frequency 2, implies 7,7
> 
> SOLUTION:
> This is what I have tried so far:
> 
> 1. A helper function:
>> dput(fn.1)
> function (df.1, vt.1)
> {
>    i = c(1)
>    for (i in seq_along(dim(df.1)[1])) {
>        print(i)
>        temp = rep(df.1$Piglets[i], df.1$Frequency[i])
>        append(vt.1, values = temp)
>    }
> }
> 

There is a lot wrong with your function.
You should assign the result of append to vt.1
The function should return vt.1
Use seq_len instead of seq_along.

The function should be something like this

fn.1 <- function (df.1, vt.1)
{
   for (i in seq_len(length.out=dim(df.1)[1])) {
       print(i)
       temp = rep(df.1$Piglets[i], df.1$Frequency[i])
       vt.1 <- append(vt.1, values = temp)
   }
   vt.1
}

But Sarah?s solution is the way to go.

Berend


> 2. A dummy data frame:
>> dput(df.1)
> structure(list(Piglets = 5:14, Frequency = c(1L, 0L, 2L, 3L,
> 3L, 9L, 8L, 5L, 3L, 2L)), .Names = c("Piglets", "Frequency"), class =
> "data.frame", row.names = c(NA,
> -10L))
> 
> 3. A dummy vector to hold results:
>> dput(vt.1)
> 1
> 
> 4. Finally the function call:
> fn.1(df.1, vt.1)
> 
> 5. The results is:
> [1] 1
> 
> PROBLEM:
> The result is not a repetition of Piglet value as per their respective
> frequencies.
> 
> 
> 
> Thanks in advance for guidance and help.
> 
> CheeRs !
> 
> 
> p.s I have used caps for my heading / sections, nothing else is implied by
> their use.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From irafuchs at gmail.com  Tue Nov 26 19:30:45 2013
From: irafuchs at gmail.com (Ira Fuchs)
Date: Tue, 26 Nov 2013 13:30:45 -0500
Subject: [R] Installing quantstrat
In-Reply-To: <CAPPM_gTBPPa==+714px526i4BX+JV5sjsCfSUGa80rwiwKsb2Q@mail.gmail.com>
References: <CCA0F236-F869-4B2C-8FDA-29134859D3C1@gmail.com>
	<CAPPM_gTFg_YNM3AbeAwX21DsESewC-PRP1QG+PAZvQVHx3xiUg@mail.gmail.com>
	<9C245CCF-FC45-4E65-B6C6-E3005AA655F1@gmail.com>
	<CAPPM_gTBPPa==+714px526i4BX+JV5sjsCfSUGa80rwiwKsb2Q@mail.gmail.com>
Message-ID: <31797B44-D729-44B3-B170-9ADD2149D058@gmail.com>

Thanks for your help! I got quantstrat working after building it along with the FinancialInstrument and blotter packages (as well as foreach).

Ira


On Nov 26, 2013, at 12:59 PM, Joshua Ulrich wrote:

> On Tue, Nov 26, 2013 at 11:55 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>> Thanks. Since quantstrat showed a Last change date of only 6 days ago and a Build status of "Current", I blithely assumed that the command that is shown for installing it would work:
>> 
>> install.packages("quantstrat", repos="http://R-Forge.R-project.org")
>> Installing package into ?/Users/ihf/Library/R/3.0/library?
>> (as ?lib? is unspecified)
>> Warning: unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0
>> 
>>   package ?quantstrat? is available as a source package but not as a binary
>> 
>> Warning message:
>> package ?quantstrat? is not available (for R version 3.0.1)
>> 
>> Based on the posting you referred to on stackoverflow, I need to download the SVN version and then see if I can build it. Although, I presume that if it were that simple, why would the version crated a week ago not work?
>> 
> I don't know; that's a question for the R-Forge maintainers.  It looks
> like they're building with 3.0.2, but I'm not sure that matters.  The
> easiest thing to do it just check out the source and build it
> yourself.
> 
>> On Nov 26, 2013, at 12:41 PM, Joshua Ulrich wrote:
>> 
>>> On Tue, Nov 26, 2013 at 11:34 AM, Ira Fuchs <irafuchs at gmail.com> wrote:
>>>> I would like to try to run the quantstrat package (located here: https://r-forge.r-project.org/R/?group_id=316). However, if I try to load quantstrat, I get a warning that it is not available for R v3.0.1, so perhaps that is the end of it.
>>>> Does anyone know if it is possible to run quantstrat with the current version of R?
>>> 
>>> Yep, see here: http://stackoverflow.com/q/11105131/271616
>>> 
>>> Best,
>>> --
>>> Joshua Ulrich  |  about.me/joshuaulrich
>>> FOSS Trading  |  www.fosstrading.com
>> 


From jholtman at gmail.com  Tue Nov 26 20:11:16 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 26 Nov 2013 14:11:16 -0500
Subject: [R] Problem with loop, matrix and data frame
In-Reply-To: <DUB116-W66D772910DC32D561DA279ECEC0@phx.gbl>
References: <DUB116-W668962EE03F0A032C811ACECEC0@phx.gbl>
	<DUB116-W66D772910DC32D561DA279ECEC0@phx.gbl>
Message-ID: <CAAxdm-4BvBQRVvXLZVsG-WHY--ELeOoTQdssCrp1OQ2efcxH_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/cd9bc362/attachment.pl>

From noahsilverman at ucla.edu  Tue Nov 26 20:41:37 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Tue, 26 Nov 2013 11:41:37 -0800
Subject: [R] Thoughts for faster indexing
In-Reply-To: <528E0FFE.7030300@krugs.de>
References: <528D18B6.1000502@g.ucla.edu>
	<721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>
	<528E0FFE.7030300@krugs.de>
Message-ID: <5294F971.8050907@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/a4cda904/attachment.pl>

From lopez235 at llnl.gov  Tue Nov 26 21:08:45 2013
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Tue, 26 Nov 2013 20:08:45 +0000
Subject: [R] How do I extract Random Forest Terms and Probabilities?
Message-ID: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/1587e351/attachment.pl>

From lianoglou.steve at gene.com  Tue Nov 26 21:23:51 2013
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Tue, 26 Nov 2013 12:23:51 -0800
Subject: [R] Thoughts for faster indexing
In-Reply-To: <5294F971.8050907@ucla.edu>
References: <528D18B6.1000502@g.ucla.edu>
	<721AD4DE-A850-4CE4-B4C7-662F903AF79A@gmail.com>
	<528E0FFE.7030300@krugs.de> <5294F971.8050907@ucla.edu>
Message-ID: <CAHA9McM0zWrmf_gK8afRn45=0i1DW4V_0nzTh6yA3sCfVda_+w@mail.gmail.com>

Hi,

On Tue, Nov 26, 2013 at 11:41 AM, Noah Silverman <noahsilverman at ucla.edu> wrote:
> All interesting suggestions.
>
> I guess a better example of the code would have been a good idea.  So,
> I'll put a relevant snippet here.
>
> Rows are cases.  There are multiple cases for each ID, marked with a
> date.  I'm trying to calculate a time recency weighted score for a
> covariate, added as a new column in the data.frame.
>
> So, for each row, I need to see which ID it belongs to, then get all the
> scores prior to this row's date, then compute the recency weighted summary.
>
> Right now, I do this in an obvious, but very very slow way.
>
> Here is my slow code:
> ======================
> for(i in 1:nrow(d)){
>     for(j in which( d$id == d$id[i] & d$date[j] < d$date[i]) ){
>         days_since = as.numeric( d$date[i] - d$date[j] )
>         w <- exp( -days_since/decay )
>         temp <- temp + w * as.numeric(d[j,'score'])
>         wTemp <- wTemp + w
>     }
>
>     temp <- temp / wTemp
>     d$newScore[i,] <- temp
> }
> ======================
>
> One immediate thought was to turn the "date" into an integer.  That
> should save a few cycles of date math.
>
> I need to do this process for a bunch of scores.  A grid search over
> different time decay levels might be nice.  So any speedup to this
> routine will save me a ton of time.
>
> Ideas?

A few quick ones.

You had said you tried data.table and found it to be slow still -- my
guess is that you might not have used it correctly, so here is a rough
sketch of what to do.

Let's assume that your date is converted to some integer -- I will
leave that excercise to you :-) -- but it seems like you just want to
calculate number of (whole) days since an event that you have a record
for, so this should be (in principle) easy to do (if you really need
full power of "date math", data.table supports that as well).

Also you never "reset" your `temp` variable, so it looks like you are
carrying over `temp` from one `id` group to the next (and, while I
have no knowledge of your problem, I would imagine this is not what
you want to do)

Anyway some rough ideas to get you started:

R> d <- as.data.table(d)
R> setkeyv(d, c('id', 'date'))

Now records within each date are ordered from first to last.

The specifics of your decay score escape me a bit, eg. what is the
value of "days_since" for the first record of each id? I'll let you
figure that out, but in the non-edge cases, it looks like you can just
calculate "days since" by subtracting the current date from the date
recorded in the record before it. (Note that `.I` is special
data.table variable for the row number of a given record in the
original data.table):

d[, newScore := {
  ## handle edge case for first record w/in each `id` group
  days_since <- date - d$date[.I -1]
  w <- exp(-days_since / decay)
  ## ...
  ## Some other stuff you are doing here which I can't
  ## understand with temp ... then multiple the 'score' column
  ## for the given row by the your correctly calculated weight `w`
  ## for that row (whatever it might be).
  w * score
}, by='id']

HTH,
-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech


From tsippel at gmail.com  Tue Nov 26 22:07:57 2013
From: tsippel at gmail.com (Tim Sippel)
Date: Tue, 26 Nov 2013 13:07:57 -0800
Subject: [R] Append text to panels of lattice::barchart()
Message-ID: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/6d36694e/attachment.pl>

From smartpink111 at yahoo.com  Tue Nov 26 21:23:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 26 Nov 2013 12:23:24 -0800 (PST)
Subject: [R] legend for bar plot ?
In-Reply-To: <CAF=-T0jJK=XhFnpYpsM00qkazMc=ZTD+PhyKYBrgz-CkRjA7Zw@mail.gmail.com>
References: <CAF=-T0jJK=XhFnpYpsM00qkazMc=ZTD+PhyKYBrgz-CkRjA7Zw@mail.gmail.com>
Message-ID: <1385497404.93296.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be:

barplot(m$V3,names.arg=paste(m$V2,m$V1,sep="\n"),col=rainbow(10))
#or
barplot(m$V3,names.arg=m$V2,col=rainbow(20),legend=m$V1, args.legend = list(x = "topright",box.lwd=0,border=FALSE))
A.K.




On Tuesday, November 26, 2013 1:18 PM, Adel ESSAFI <adelessafi at gmail.com> wrote:
Hello;
I have the following table
> m
? ? V2 V1? ? ? V3
1? C/L? 0? 732179
3? C/S? 0? 803926
19 D/F? 0? 724924
17 D/I? 0? 755841
13 D/L? 0? 731904
15 D/S? 0? 798289
11 I/F? 0? 871670
9? I/I? 0? 897718
5? I/L? 0 2628113
7? I/S? 0 2628113
2? C/L? 1 1107269
4? C/S? 1 1395714
20 D/F? 1 1181282
18 D/I? 1 1264249
14 D/L? 1 1107595
16 D/S? 1 1399836
12 I/F? 1 1304294
10 I/I? 1 1542813
6? I/L? 1 2628113
8? I/S? 1 2475448
as you can see, the table is sorted by the second and the first column.
with this command :
barplot(m$V3,names.arg=m$V2,col=rainbow(10))
I succeded to print the figure attached.
Now, I need to indicate that the first 10 bar are for beta=0 and the second
10 bars are for beta=1.
Could you help please.
Best regards


-- 
PhD candidate in Computer Science
Address
3 avenue lamine, cit? ezzahra, Sousse 4000
Tunisia
tel: +216 97 246 706 (+33640302046 jusqu'au 15/6)
fax: +216 71 391 166

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gerald.jean at dgag.ca  Tue Nov 26 19:19:26 2013
From: gerald.jean at dgag.ca (gerald.jean at dgag.ca)
Date: Tue, 26 Nov 2013 13:19:26 -0500
Subject: [R] Coding systems.
Message-ID: <OFCE3F49D2.A4ECC682-ON85257C2F.0064396C-85257C2F.0064A86C@dgag.ca>



Hello,

I am using R, 2.15.2, on a 64-bit Linux box.  I run R through Emacs' ESS.

R runs in a French, Canadian-French, locale and lately I got surprising
results
from functions making factor variables from character variables.  Many of
the
variables in input data.frames are character variables and contain latin
accents, for exemple the "?" in "Montr?al".  I waisted several days playing
with coding systems and trying to understand why some code when run one
command at
a time from the command line gives the expected result while when cut and
pasted in a function it doesn't???

For example the following code:

==============================================================================
ttt.rmr <- sima.31122012$rmrnom
ttt.rmr.2 <- ifelse (ttt.rmr %in% c("Edmonton", "Edmundston",
                                    "Charlottetown", "Calgary", "Winnipeg",
                                    "Victoria", "Vancouver", "Toronto",
                                    "St. John's", "Saskatoon", "Regina",
                                    "Qu?bec", "Ottawa - Gatineau (Ontario",
                                    "Ottawa - Gatineau (partie",
"Montr?al",
                                    "Halifax", "Fredericton"),
                     "Grandes villes", ifelse(ttt.rmr == "", "Manquant",
"Autres"))
unique(ttt.rmr.2)
ttt.rmr.2 <- factor(ttt.rmr.2, levels = c("Grandes villes", "Autres",
"Manquant"),
                    labels = c("Grandes villes", "Autres", "Manquant"))

==============================================================================

will have "Montr?al" and "Qu?bec" in the "Grandes villes" level of the
factor
variable, while running the same code in a function will have them in
"Autres".
The variable "rmr.Merged" in the data.frame "test2.sima.31122012.DataPrep"
is
the output of the function, which, of course, does a lot of other stuff.

==============================================================================
ttt.w <- which(ttt.rmr.2 != test2.sima.31122012.DataPrep$rmr.Merged)
frequence(test2.sima.31122012.DataPrep$rmrnom[ttt.w])
         Frequency  Percent Cum.Freq Cum.Percent
Montr?al   1301254 79.57173  1301254    79.57173
Qu?bec      334068 20.42827  1635322   100.00000
==============================================================================

All other city names, no accents, were correctly classified but "Montr?al"
and
"Qu?bec", together they represent over 1.5M records, not negligeable!!!

Following is my ".Renviron" file where I set up environment variables for
R.

R_PROFILE_USER="/home/jeg002/MyRwork/StartUp/profile.R"
# export R_PROFILE_USER
R_HISTFILE="/home/jeg002/MyRwork/.Rhistory"
## Default editor
EDITOR=${EDITOR-${VISUAL-'/usr/local/bin/emacsclient'}}
## Default pager
PAGER=${PAGER-'/usr/local/bin/emacsclient'}

## Setting locale, hoping it will be OK "all" the time!!!
LANG=fr_CA
LANGUAGE=fr_CA
LC_ADDRESS=fr_CA
LC_COLLATE=fr_CA
LC_TYPE=fr_CA
LC_IDENTIFICATION=fr_CA
LC_MEASUREMENT=fr_CA
LC_MESSAGES=fr_CA
LC_NAME=fr_CA
LC_PAPER=en_US
LC_NUMERIC=en_US
LC_TELEPHONE=fr_CA
LC_MONETARY=fr_CA
LC_TIME=fr_CA
R_PAPERSIZE='letter'
==============================================================================

and:

> Sys.getlocale()
[1]
"LC_CTYPE=fr_CA;LC_NUMERIC=C;LC_TIME=fr_CA;LC_COLLATE=fr_CA;LC_MONETARY=fr_CA;LC_MESSAGES=fr_CA;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_CA;LC_IDENTIFICATION=C"

> Sys.getenv(c("LANGUAGE", "LANG"))
LANGUAGE     LANG
 "fr_CA"  "fr_CA"

I must be missing something!!!  Maybe someone can make sense of this!!!
Thanks
for your support,

G?rald Jean
                                                                                   
 (Embedded image moved to file:                                                    
 pic06023.gif)                                                                     
                                                                                   
 Gerald Jean, M. Sc. en statistiques                                               
 Conseiller senior en statistiques     L?vis (si?ge social)                        
                                                                                   
 Actuariat corporatif,                 418 835-4900, poste                         
 Mod?lisation et Recherche             7639                                        
 Assurance de dommages                 1 877 835-4900, poste                       
 Mouvement Desjardins                  7639                                        
                                       T?l?copieur : 418                           
                                       835-6657                                    
                                                                                   


                                                                                  
 Faites bonne impression et imprimez seulement au besoin!                         
                                                                                  
 Ce courriel est confidentiel, peut ?tre prot?g? par le secret professionnel et   
 est adress? exclusivement au destinataire. Il est strictement interdit ? toute   
 autre personne de diffuser, distribuer ou reproduire ce message. Si vous l'avez  
 re?u par erreur, veuillez imm?diatement le d?truire et aviser l'exp?diteur.      
 Merci.                                                                           
                                                                                  


From p_connolly at slingshot.co.nz  Tue Nov 26 22:58:32 2013
From: p_connolly at slingshot.co.nz (p_connolly)
Date: Wed, 27 Nov 2013 10:58:32 +1300
Subject: [R] Append text to panels of lattice::barchart()
In-Reply-To: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>
References: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>
Message-ID: <913d272795812aac426efddd819f6320@slingshot.co.nz>

On 2013-11-27 10:07, Tim Sippel wrote:
> I could use a little help writing a panel function to append text to 
> each
> panel of a lattice::barchart().  Below is a modified version of the 
> barley
> dataset to illustrate.
> 
> data(barley)
> # add a new variable called samp.size
> barley$samp.size<-round(runif(n=nrow(barley), min=0, max=50),0)
> # Below is a barchart plot for this example
> barchart(yield ~ variety | site, data = barley,
>          groups = year, layout = c(1,6), stack = TRUE,
>          auto.key = list(space = "right"),
>          ylab = "Barley Yield (bushels/acre)",
>          scales = list(x = list(rot = 45)))
> # I need to add to each panel the sum of samp.size by the groups 
> variable
> (year) for that panel.
> # So the text appended to the top panel (Waseca) might say "1931=15,
> 1932=20", and same for each subsequent panel.

All you need is to modify the levels associated with the site factor.  
Here's  a trivial addition to give you the idea:

levels(barley$site) <- paste(levels(barley$site), LETTERS[1:6])

Then the same call you used will work.  Of course, you'll need to do a 
bit more than LETTERS[1:6] but I'm sure you know how to do that.

HTH


> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Nov 26 23:08:40 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 27 Nov 2013 08:08:40 +1000
Subject: [R] Append text to panels of lattice::barchart()
In-Reply-To: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>
References: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>
Message-ID: <001b01ceeaf4$108e15b0$31aa4110$@bigpond.com>

Hi

Try

barchart(yield ~ variety | site, data = barley,
          groups = year, layout = c(1,6), stack = TRUE,
          auto.key = list(space = "right"),
          ylab = "Barley Yield (bushels/acre)",
          scales = list(x = list(rot = 45)),
          panel = function(x,y,...){
          
                    pnl = panel.number()
                    panel.barchart(x,y,...)
                   
                    if (pnl == 6) grid.text("1931=15, 1932=20", 0.5, 0.88,
gp = gpar(cex = 0.8))

                  }
)

if you had as.table = TRUE as an argument pnl==1 would apply to the top
panel

you then have to repeat the line an amend the pnl == 6. 
On a panel basis is easier than on a plot basis as the xy coordinates are
easily managed.

Another way is trellis.focus but possibly a little fiddlier

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au 

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Tim Sippel
Sent: Wednesday, 27 November 2013 07:08
To: r-help at r-project.org
Subject: [R] Append text to panels of lattice::barchart()

I could use a little help writing a panel function to append text to each
panel of a lattice::barchart().  Below is a modified version of the barley
dataset to illustrate.

data(barley)
# add a new variable called samp.size
barley$samp.size<-round(runif(n=nrow(barley), min=0, max=50),0) # Below is a
barchart plot for this example barchart(yield ~ variety | site, data =
barley,
         groups = year, layout = c(1,6), stack = TRUE,
         auto.key = list(space = "right"),
         ylab = "Barley Yield (bushels/acre)",
         scales = list(x = list(rot = 45))) # I need to add to each panel
the sum of samp.size by the groups variable
(year) for that panel.
# So the text appended to the top panel (Waseca) might say "1931=15,
1932=20", and same for each subsequent panel.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Nov 26 23:30:13 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 27 Nov 2013 08:30:13 +1000
Subject: [R] Plotting multiple trends on one graph
In-Reply-To: <CAJea-HbuxPnRTFsN7pr10thGQRuQCuS0tMuU_rza4Aca4YyEMQ@mail.gmail.com>
References: <CAJea-HYDXHjVR2q=bW+ghueO6kidTpnbsV=f2tBwnj2rh75p1A@mail.gmail.com>	<000c01cee972$1e2b97c0$5a82c740$@bigpond.com>
	<CAJea-HbuxPnRTFsN7pr10thGQRuQCuS0tMuU_rza4Aca4YyEMQ@mail.gmail.com>
Message-ID: <000001ceeaf7$1472c290$3d5847b0$@bigpond.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/0659c3c4/attachment.pl>

From tsippel at gmail.com  Tue Nov 26 23:45:09 2013
From: tsippel at gmail.com (Tim Sippel)
Date: Tue, 26 Nov 2013 14:45:09 -0800
Subject: [R] Append text to panels of lattice::barchart()
In-Reply-To: <001b01ceeaf4$108e15b0$31aa4110$@bigpond.com>
References: <CANgNK74fvh7w+HbrRA=cBs6knS6TTY23nyP7kghfr1LC7x+fVw@mail.gmail.com>
	<001b01ceeaf4$108e15b0$31aa4110$@bigpond.com>
Message-ID: <CANgNK74=_TSOXtk-BoLHUF-SdxOZd4S7pL2tMf=xjh=ME3B30A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/25e848ed/attachment.pl>

From bbolker at gmail.com  Wed Nov 27 00:27:55 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Nov 2013 23:27:55 +0000
Subject: [R] Direct (null) hypothesis testing using GLMMs - possible?
References: <529493C3020000ED0001868E@gwsmtp1.uni-regensburg.de>
Message-ID: <loom.20131127T002119-302@post.gmane.org>

Tomer Czaczkes <Tomer.Czaczkes <at> biologie.uni-regensburg.de> writes:

> 
> Dear Forumites,
> 
> Hi, I'm a long time eavesdropper, first time poster, but I simply couldn't
> find any answer to this perhaps rather naive question:
> 
> I am trying to see if my data is significantly different from a null
> hypothesis using GLMMs.
> 
> I would like to run a GLMM because I have random effects. In the future I
> might want to do a similar thing with a non-Gaussian distribution structure
> as well.

  That could be considerably more difficult. There is some literature on
non-Gaussian random effects, but you'd probably have to write your own mixed
model code in AD Model Builder or WinBUGS/JAGS/Stan.

> In my current example, I have a series of proportions - in this case the
> proportion of ants on one of two available paths. My null-hypothesis is 0.5:
> that the ants choose a path randomly, so there will be a more or less amount
> of ants on both paths at any given time.
> The only way I could think of doing this would be to make a dummy dataset
> with a mean of 0.5 and a reasonable variance, put both the dummy data and
> real data into one dataframe, and test whether data type (dummy or real) is
> a significant predictor of "proportion of ants choosing side X".
> 
>  Is there any more elegant way of doing this with a GLMM? Alternatively, can
> anyone suggest an alternative way to do such a thing? I will want to add
> interactions to the model as well. I generally use the LME4 package, and the
> lmer function.
> 
> Many thanks for you attention, and I hope my first foray into forum-posting
> wasn't hopelessly naive or misplaced...
> 
> Tommy

  Well, it's a little bit misplaced (in general questions about mixed
models are better off on r-sig-mixed-models at r-project.org), but actually
your question is not specific to GLMMs, but applies more generally to
generalized linear models (without the mixed part).

  If you have binomial data (i.e. you know the total number, as well
as the proportion), and if you use a symmetric link function (such as
the default logit, or the probit) then an estimated intercept of 0
corresponds to a probability of 0.5, and so the hypothesis test of
intercept=0 corresponds to a test against the null hypothesis that
the probability is 0.5.

  Hope that helps.


From smartpink111 at yahoo.com  Wed Nov 27 00:56:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 26 Nov 2013 15:56:52 -0800 (PST)
Subject: [R] How do I extract Random Forest Terms and Probabilities?
In-Reply-To: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>
References: <56180B40A4F72A4083C75B30DA86297333DB5643@PRDEXMBX-05.the-lab.llnl.gov>
Message-ID: <1385510212.89885.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
For the first part, you could do:

fmi2 <- fmi 
attributes(fmi2$terms) <- NULL
capture.output(fmi2$terms)
#[1] "Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width"

A.k.

On Tuesday, November 26, 2013 3:55 PM, "Lopez, Dan" <lopez235 at llnl.gov> wrote:
Hi R Experts,

I need your help with two question regarding randomForest.


1.? ? ?  When I run a Random Forest model how do I extract the formula I used so that I can store it in a character vector in a dataframe?
For example the dataframe might look like this if I am running models using the IRIS dataset
#ModelID,Type,

#001,RF,Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width

fmi<-randomForest(Species~.,iris,mtry=3,ntry=500)
#I know one place where the information is in fmi$terms but not sure how to extract just the formula info. Or perhaps there is somewhere else in fmi that I could get this?


2.? ? ?  How do I get the probabilities (probability-like values) from the model that was run? I know for the test set I can use predict. And I know to extract the classifications from the model I use fmi$predicted. But where are the probabilities?


Dan
Workforce Analyst
HRIM - Workforce Analytics & Metrics
LLNL


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From halim10-fes at sust.edu  Wed Nov 27 03:38:16 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Wed, 27 Nov 2013 08:38:16 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <20131127023716.M4379@sust.edu>

Hi Arun,

Thanks for your help. Sorry for my late response. Take care and stay fine.

Regards,

Halim


On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
> Hi Halim,
> I guess this works for you.? Modifying Jeff's solution:
> 
> volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
> vol1 <- dcmat %*% (volmat +wt)
> for(idx in seq_along(volinp)[-1]){
> ?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
> ?}
> 
> #or
> 
> vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> 
> for ( idx in seq_along(volinp)[ -1 ] ) {
> ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
> }
> identical(vol,vol1)
> #[1] TRUE
> 
> A.K.
> 
> On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
> fes at sust.edu> wrote: Hi Arun,
> 
> OK, no problem. Thank you very much for your attention. I've posted 
> an annex to my previous problem. I will appreciate your 
> comments/suggestions on it.
> 
> Off-topic: You're a very helpful man. I like your attitude to 
> helping others.
> 
> Take care.
> 
> Halim
> 
> On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> > Hi,
> > Please disregard my earlier message. Looks like Jeff understand it 
> > better and answered it. Regards, Arun
> > 
> > On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> wrote:
> > Hi,
> > I am finding some inconsistency with your description.
> > For example:
> > volinp[1]+volmat[1,1]
> > [1] 101
> > 
> > On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> > fes at sust.edu> wrote:
> > 
> > Please apologize me! Earlier I've sent a message erroneously. 
> > Following is the original problem for which I'm seeking help. 
> > Extremely sorry...?
> > 
> > Hi Arun,
> > 
> > Thank you very much for your response. Sorry, if I couldn't explain 
> > clearly. I think, I should restate the problem to get exactly what I 
> > want. Here it goes:
> > 
> > I have 2 matrices and 1 vector, namely,
> > 
> > dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > 
> > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > 
> > volinp<-c(1:40)
> > 
> > What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> > and dump the output in a new matrix 'vol'. But before that, in the 
> > first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> > column of the output matrix 'vol' matrix will be:
> > 
> > ? ? ? ? [,1]
> > [1,]?? 13.13
> > [2,]?? 61.61
> > [3,]?? 25.25
> > [4,]? ? 0.00
> > [5,]? ? 0.00
> > 
> > In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> > volinp[2] with vol[1,1]. The new 'volmat' will look like:
> > 
> > ? ? ? ? [,1]
> > [1,]?? 15.13
> > [2,]?? 61.61
> > [3,]?? 25.25
> > [4,]? ? 0.00
> > [5,]? ? 0.00
> > 
> > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> > output matrix 'vol' will look like:
> > 
> > ? ? ? ? [,2]
> > [1,]? 1.9669
> > [2,] 41.2665
> > [3,] 41.2232
> > [4,] 13.1199
> > [5,]? 2.7775
> > 
> > Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> > vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> > replacement, addition, multiplication, and dumping will continue up 
> > to the length of 'volinp' and the final output matrix 'vol' will be 
> > something like:
> > 
> > ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> > [1,] 13.13?? 1.9669?? 0.645697? ...
> > [2,] 61.61? 41.2665? 24.488389? ...
> > [3,] 25.25? 41.2232? 40.419786? ...
> > [4,]? 0.00? 13.1199? 22.116099? ...
> > [5,]? 0.00?? 2.7775?? 7.670905? ...?
> > 
> > Within my limited capacity, I've tried to come up with a solution 
> > but failed.
> > 
> > I'll appreciate your/others' help with gratefulness.
> > 
> > Regards,
> > 
> > Halim
> > 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > > Hi,
> > > Could you show your expected output?? It is a bit unclear from the 
> > description.
> > > 
> > > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > > fes at sust.edu> wrote: Dear R-friends,
> > > 
> > > Hope you doing well. I've been trying to deal with the following 
> > > problem for the couple of days but couldn't come up with a solution. 
> > > It would be great if any of you could give some insight into it.
> > > 
> > > I have three matrices like:
> > > 
> > > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> > volinp<-
> > > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > 
> > > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > > 
> > > What I essentially want to do is to add each value in scvol[1,] with 
> > > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > > finally put the outputs in a new matrix.
> > > 
> > > Thanks in advance.
> > > 
> > > Halim? ? ? ? ? ? ? ? 
> > > ---------------
> > > Md. Abdul Halim
> > > Assistant Professor
> > > Department of Forestry and Environmental Science
> > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > Bangladesh.
> > > Cell: +8801714078386.
> > > alt. e-mail: xou03 at yahoo.com
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com


-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From jeremyclarkmel at gmail.com  Wed Nov 27 01:44:05 2013
From: jeremyclarkmel at gmail.com (Jeremy Clark)
Date: Wed, 27 Nov 2013 01:44:05 +0100
Subject: [R] Functions in formulae ??
In-Reply-To: <CADy4v+8pHroO7y-=bAUS40yBOFO9Nmip+y_n28pPTemHJi23xA@mail.gmail.com>
References: <CADy4v+8pHroO7y-=bAUS40yBOFO9Nmip+y_n28pPTemHJi23xA@mail.gmail.com>
Message-ID: <CADy4v+9Y8mNiSDzoxMSju6i1RKq-MzhDs3UjA2Jp_bAa5XWP5w@mail.gmail.com>

Dear All,

In the following simple case I can't seem to get an improved fit,
despite trying all of the control possibilities. As there seem to be
no examples anywhere which show use of functions such as "dnorm"
within a formula, and as I am not confident at all that my formula is
correctly configured, I would appreciate some feedback ! Many thanks
in advance.

library(minpack.lm)

gg<-c(170,        171,      172,      173,      174,      175,
176,      177,      178,      179,      180,      181,      182,
183,      184,            185,      186,      187,      188,      189,
     190,      191,      192,      193,      194,      195,      196,
    197,      198,      199,            200,      201,      202,
203,      204,      205,      206,      207,      208,      209)

 dd<-c(1673,      1659,    1738,    1687,    1882,    2010,    2202,
 2248,    2409,    2417,    2215,    2279,    2539,    2479,    2341,
          2395,    2314,    2404,    2369,    2254,    2048,    1899,
  1892,    1744,    1333,    1183,    982,      772,      526,
451,            335,      253,      157,      108,      67,        44,
       26,        12,        10,        0)

 dd100000 <- dd * 0.00001

 dd100000gg <- data.frame(dd100000, gg)

 ## modLM4:

modLM4 <- nlsLM(dd100000 ~ dnorm(gg, mu,sigma, log = FALSE),  data =
dd100000gg, start = c(mu = 190, sigma = 10), trace = TRUE)

windows()
## plot data
plot(gg, dd100000, main = "modLM4")
## plot fitted values
lines(gg, fitted(modLM4), col = 2, lwd = 2)

On Thu, Nov 21, 2013 at 11:57 AM, Jeremy Clark <jeremyclarkmel at gmail.com> wrote:
> Dear All,
>
> In the following simple case I can't seem to get an improved fit,
> despite trying all of the control possibilities. As there seem to be
> no examples anywhere which show use of functions such as "dnorm"
> within a formula, and as I am not confident at all that my formula is
> correctly configured, I would appreciate some feedback ! Many thanks
> in advance.
>
> library(minpack.lm)
>
> gg<-c(170,        171,      172,      173,      174,      175,
> 176,      177,      178,      179,      180,      181,      182,
> 183,      184,            185,      186,      187,      188,      189,
>      190,      191,      192,      193,      194,      195,      196,
>     197,      198,      199,            200,      201,      202,
> 203,      204,      205,      206,      207,      208,      209)
>
>  dd<-c(1673,      1659,    1738,    1687,    1882,    2010,    2202,
>  2248,    2409,    2417,    2215,    2279,    2539,    2479,    2341,
>           2395,    2314,    2404,    2369,    2254,    2048,    1899,
>   1892,    1744,    1333,    1183,    982,      772,      526,
> 451,            335,      253,      157,      108,      67,        44,
>        26,        12,        10,        0)
>
>  dd100000 <- dd * 0.00001
>
>  dd100000gg <- data.frame(dd100000, gg)
>
>  ## modLM4:
>
> modLM4 <- nlsLM(dd100000 ~ dnorm(gg, mu,sigma, log = FALSE),  data =
> dd100000gg, start = c(mu = 190, sigma = 10), trace = TRUE)
>
> windows()
> ## plot data
> plot(gg, dd100000, main = "modLM4")
> ## plot fitted values
> lines(gg, fitted(modLM4), col = 2, lwd = 2)



-- 


MEDIMEL,
www.plastic-surgery-poland.co.uk
www.chirurgia-szczecin.pl
Jeremy Clark. Address: ul. Klonowica 45/2, 71-249 Szczecin, Poland.


From jeremyclarkmel at gmail.com  Wed Nov 27 01:47:30 2013
From: jeremyclarkmel at gmail.com (Jeremy Clark)
Date: Wed, 27 Nov 2013 01:47:30 +0100
Subject: [R] Functions in formulae ??
In-Reply-To: <CADy4v+8pHroO7y-=bAUS40yBOFO9Nmip+y_n28pPTemHJi23xA@mail.gmail.com>
References: <CADy4v+8pHroO7y-=bAUS40yBOFO9Nmip+y_n28pPTemHJi23xA@mail.gmail.com>
Message-ID: <CADy4v+-D=Fz4sGH_wSr4Eg373-MLjaBp5wg60wkUs+i6A+xu-w@mail.gmail.com>

PLEASE REMOVE THIS MESSAGE AND PREVIOUS COPIES ! - Many thanks


Dear All,

In the following simple case I can't seem to get an improved fit,
despite trying all of the control possibilities. As there seem to be
no examples anywhere which show use of functions such as "dnorm"
within a formula, and as I am not confident at all that my formula is
correctly configured, I would appreciate some feedback ! Many thanks
in advance.

library(minpack.lm)

gg<-c(170,        171,      172,      173,      174,      175,
176,      177,      178,      179,      180,      181,      182,
183,      184,            185,      186,      187,      188,      189,
     190,      191,      192,      193,      194,      195,      196,
    197,      198,      199,            200,      201,      202,
203,      204,      205,      206,      207,      208,      209)

 dd<-c(1673,      1659,    1738,    1687,    1882,    2010,    2202,
 2248,    2409,    2417,    2215,    2279,    2539,    2479,    2341,
          2395,    2314,    2404,    2369,    2254,    2048,    1899,
  1892,    1744,    1333,    1183,    982,      772,      526,
451,            335,      253,      157,      108,      67,        44,
       26,        12,        10,        0)

 dd100000 <- dd * 0.00001

 dd100000gg <- data.frame(dd100000, gg)

 ## modLM4:

modLM4 <- nlsLM(dd100000 ~ dnorm(gg, mu,sigma, log = FALSE),  data =
dd100000gg, start = c(mu = 190, sigma = 10), trace = TRUE)

windows()
## plot data
plot(gg, dd100000, main = "modLM4")
## plot fitted values
lines(gg, fitted(modLM4), col = 2, lwd = 2)

On Thu, Nov 21, 2013 at 11:57 AM, Jeremy Clark <jeremyclarkmel at gmail.com> wrote:
> Dear All,
>
> In the following simple case I can't seem to get an improved fit,
> despite trying all of the control possibilities. As there seem to be
> no examples anywhere which show use of functions such as "dnorm"
> within a formula, and as I am not confident at all that my formula is
> correctly configured, I would appreciate some feedback ! Many thanks
> in advance.
>
> library(minpack.lm)
>
> gg<-c(170,        171,      172,      173,      174,      175,
> 176,      177,      178,      179,      180,      181,      182,
> 183,      184,            185,      186,      187,      188,      189,
>      190,      191,      192,      193,      194,      195,      196,
>     197,      198,      199,            200,      201,      202,
> 203,      204,      205,      206,      207,      208,      209)
>
>  dd<-c(1673,      1659,    1738,    1687,    1882,    2010,    2202,
>  2248,    2409,    2417,    2215,    2279,    2539,    2479,    2341,
>           2395,    2314,    2404,    2369,    2254,    2048,    1899,
>   1892,    1744,    1333,    1183,    982,      772,      526,
> 451,            335,      253,      157,      108,      67,        44,
>        26,        12,        10,        0)
>
>  dd100000 <- dd * 0.00001
>
>  dd100000gg <- data.frame(dd100000, gg)
>
>  ## modLM4:
>
> modLM4 <- nlsLM(dd100000 ~ dnorm(gg, mu,sigma, log = FALSE),  data =
> dd100000gg, start = c(mu = 190, sigma = 10), trace = TRUE)
>
> windows()
> ## plot data
> plot(gg, dd100000, main = "modLM4")
> ## plot fitted values
> lines(gg, fitted(modLM4), col = 2, lwd = 2)



-- 


MEDIMEL,
www.plastic-surgery-poland.co.uk
www.chirurgia-szczecin.pl
Jeremy Clark. Address: ul. Klonowica 45/2, 71-249 Szczecin, Poland.


From beatrice_perron at hotmail.com  Wed Nov 27 02:03:01 2013
From: beatrice_perron at hotmail.com (=?iso-8859-1?B?QulhdHJpY2UgUGVycm9u?=)
Date: Tue, 26 Nov 2013 20:03:01 -0500
Subject: [R] Tukey, Bartlett
Message-ID: <BLU170-W129E2C0C38C729B8D198ADB8BEF0@phx.gbl>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/06f02530/attachment.pl>

From jacq.pless at gmail.com  Wed Nov 27 03:19:58 2013
From: jacq.pless at gmail.com (Jacquelyn Pless)
Date: Tue, 26 Nov 2013 19:19:58 -0700
Subject: [R] trouble using mat2listw function to create spatial weights
	object
Message-ID: <CAC0ELpKKGvOW0xDa4g-9oHKZBN_u=E9SDdCTSLOL5AGgnepfoQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/f82ac267/attachment.pl>

From jing.chen.jc29 at gmail.com  Wed Nov 27 03:21:57 2013
From: jing.chen.jc29 at gmail.com (Mina Chen)
Date: Wed, 27 Nov 2013 10:21:57 +0800
Subject: [R] Control the whole margin of a graph(including plot area and
 title/footnote) in R
Message-ID: <CAGJE0Z4KtLpB9NO-MXQREpu+Q9KLO0HK+jAVmCwd2QqAJVTj5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/1bfc05d6/attachment.pl>

From gibinod at yahoo.com  Wed Nov 27 05:16:36 2013
From: gibinod at yahoo.com (Binod Manandhar)
Date: Tue, 26 Nov 2013 20:16:36 -0800 (PST)
Subject: [R] roots for two variables.
Message-ID: <1385525796.91457.YahooMailNeo@web165004.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/45ab6f2b/attachment.pl>

From dmck at u.washington.edu  Wed Nov 27 05:53:47 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Tue, 26 Nov 2013 20:53:47 -0800
Subject: [R] Tukey, Bartlett
In-Reply-To: <BLU170-W129E2C0C38C729B8D198ADB8BEF0@phx.gbl>
References: <BLU170-W129E2C0C38C729B8D198ADB8BEF0@phx.gbl>
Message-ID: <717CFAF4-AD35-4C41-9568-F898EB4DFCBC@u.washington.edu>


On Nov 26, 2013, at 5:03 PM, B?atrice Perron <beatrice_perron at hotmail.com> wrote:

> Bonjour, j'ai une s?rie de 18 groupes de donn?es de 20 r?plicats chaque ? comparer (dont plusieurs controles). Est-ce que je peux faire un test de Tukey pour analyser autant de donn?es? si oui, comment? sinon, quel test je peux faire?
> 
> J'ai fait un bartlett.test pour v?rifier l'?galit? des variances et la valeurs du test statistique me donne plus que 600, est-ce normal? 
> 
> Merci!

Here is a URL where you can read an R ?FAQ? (des questiones frequentes) on post-hoc comparisons, but you need to consult a statistician on which test to use for your experiment.  

http://www.ats.ucla.edu/stat/r/faq/posthoc.htm
> 
> 
> 
> 
> 
> 
> 
>  		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Science Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From kridox at ymail.com  Wed Nov 27 05:59:11 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 27 Nov 2013 13:59:11 +0900
Subject: [R] Tukey, Bartlett
In-Reply-To: <BLU170-W129E2C0C38C729B8D198ADB8BEF0@phx.gbl>
References: <BLU170-W129E2C0C38C729B8D198ADB8BEF0@phx.gbl>
Message-ID: <CAAcyNCzHN7gX2U29QT5Gq_qMH2tLwOqYoEgBYpZBYFhXhUWPBQ@mail.gmail.com>

Bonjour,

Il serait pr?f?rable de poster votre question en anglais. Mais ? mon
sens, ceci est plut?t une question de statistique g?n?rale, sans
rapport direct avec R.

Please post your question in English, as everybody would be able to
understand it. But I would ask a local statistician for testing
procedure. And come back here if you are facing problem to apply it
using R.

Cordialement,
Pascal

2013/11/27 B?atrice Perron <beatrice_perron at hotmail.com>:
> Bonjour, j'ai une s?rie de 18 groupes de donn?es de 20 r?plicats chaque ? comparer (dont plusieurs controles). Est-ce que je peux faire un test de Tukey pour analyser autant de donn?es? si oui, comment? sinon, quel test je peux faire?
>
> J'ai fait un bartlett.test pour v?rifier l'?galit? des variances et la valeurs du test statistique me donne plus que 600, est-ce normal?
>
> Merci!
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ulhaqz at gmail.com  Wed Nov 27 06:50:45 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Wed, 27 Nov 2013 10:50:45 +0500
Subject: [R] Generating Frequency Values
In-Reply-To: <80096A98-C971-4D4A-91CC-BC6C4C952B37@xs4all.nl>
References: <CADw4Cku2QnZZ7NbjT74yz+Xt-TYOdA88v_eMicMP1=akO=tX6A@mail.gmail.com>
	<80096A98-C971-4D4A-91CC-BC6C4C952B37@xs4all.nl>
Message-ID: <CADw4CksOZDP2vPDh0LVxvLjQF3=jCVSeUaFMimgWidph=veOWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/13cb2caf/attachment.pl>

From soconnor at lakeheadu.ca  Wed Nov 27 06:55:17 2013
From: soconnor at lakeheadu.ca (Sheri O'Connor)
Date: Wed, 27 Nov 2013 00:55:17 -0500
Subject: [R] Buse's GLS R2
Message-ID: <CABf=2VGPqTi7nuBaAP6YgOxLAq0onzVYq2T0z-T9aMgvv9FthA@mail.gmail.com>

I was wondering if anyone knew of a package that contained a function
of Buse's (http://www.jstor.org/stable/2683631 ) GLS R2 equation? If
not, I would greatly appreciate any pointers about how I would
implement Buse's equation using the results from nlme::gls function!

Thanks very much for your time,
Sheri

BTW, I would be happy to send along the article.


From dulcalma at bigpond.com  Wed Nov 27 07:20:50 2013
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 27 Nov 2013 16:20:50 +1000
Subject: [R] Control the whole margin of a graph(including plot area and
	title/footnote) in R
In-Reply-To: <CAGJE0Z4KtLpB9NO-MXQREpu+Q9KLO0HK+jAVmCwd2QqAJVTj5Q@mail.gmail.com>
References: <CAGJE0Z4KtLpB9NO-MXQREpu+Q9KLO0HK+jAVmCwd2QqAJVTj5Q@mail.gmail.com>
Message-ID: <001201ceeb38$d19f5860$74de0920$@bigpond.com>

Hi

I do not know what in.data is and I am not familiar with ggplot2

and I am not sure what you mean

I think you need to keep things simple and explain what you want and dput a
dataset

Try this

xyplot(test2 ~ test1, data     = in.data,
       groups   = SEX,
       par.settings = list(par.main.text = list(cex = 0.8)),
      main = "This is the title\nThis is the sub-title"
)

also have a look at

?lattice::plot.trellis

If you want to split your graph area into several "panes"

HTH

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Mina Chen
Sent: Wednesday, 27 November 2013 12:22
To: r-help at r-project.org
Subject: [R] Control the whole margin of a graph(including plot area and
title/footnote) in R

Hi,

I am a novice of R and I have attended the coursea courses for computing for
R analysis.
Recently I am using both the lattice and ggplots package to create
scatterplot in R.
when using lattice package, I can contrl the whole graph size(including plot
area and title/footnote) with below codes:

xyplot(
  test2 ~ test1,
  data     = in.data,
  groups   = SEX,
  #title
  main     = textGrob(c("This is the title", "\nThis is the sub-title"),
                      x = unit(c(left.margin,left.margin), "inches"),
                      just  = "left",
                      gp    = gpar(fontsize = c(title.font, title.font),
lineheight = 1.5)),
  #footnote
  sub = textGrob(paste(footnote1,Sys.time(),sep="\n"),
                 x = unit(c(left.margin), "inches"),
                 y = unit(c(bottom.margin), "inches"),
                 just = c("left", "bottom"),
                 gp = gpar(fontsize = footer.font,lineheight=0.9)) # Figure
margins lattice.options = list(layout.widths = leftright.margin,
layout.heights =
topbottome.margin)
)
You can see that the lattice.options can control the whole figure size
including title and footnote.
while with ggplot2, I create a plot use qplot(...) then control plot margin
with:
theme(plot.margin=unit(x=c(top.margin,right.margin,bottom.margin,left.margin
),units="inches"))
then  add title and footnote with arrangeGrob.
 g<-arrangeGrob(myplot, main=textGrob(c(title1, title2),
                                       x = unit(c(left.margin,left.margin),
"inches"),
                                       y = unit(c(-top.margin,-top.margin),
"inches"),
                                       just  = "left",
                                       gp    = gpar(fontsize =
c(title.font, title.font),

fontface=c("plain","plain"),
                                                    lineheight = 1.5)),
                 sub = textGrob(paste(footnote1,Sys.time(),sep="\n"),
                                x = unit(c(left.margin), "inches"),
                                y = unit(c(bottom.margin), "inches"),
                                just = c("left", "bottom"),
                                gp = gpar(fontsize =
footer.font,lineheight=0.9)))

  g

In this way, the plot.margin only control the plot area, not control title
and footnote. So how should I do to control the both plot area and title
area in ggplot2 (just like lattice package)?
If the answer is not, in this case I will prefer lattice pakcage.

I will very appreciate your reply! Thanks!


Best regards,
Mina

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kiangati at gmail.com  Wed Nov 27 07:25:31 2013
From: kiangati at gmail.com (Keniajin Wambui)
Date: Wed, 27 Nov 2013 09:25:31 +0300
Subject: [R] Subscript out of bounds
In-Reply-To: <4b09adfc-0863-47ff-9947-327b07434a44@email.android.com>
References: <CAE=fH8EZfeZQmGZ7m2RkQBg6CwEJwA-Nha13SVDXQEq4mJK49A@mail.gmail.com>
	<4b09adfc-0863-47ff-9947-327b07434a44@email.android.com>
Message-ID: <CAE=fH8E_=J00FS9p9sUUopuQ8B0kqKDVAq-3iYBb71W9RRgF1g@mail.gmail.com>

Dear Jeff;
Below is the output for sessioninfo()

R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.2

On Tue, Nov 26, 2013 at 9:00 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> This is the kind of question where including the output of sessionInfo() is a really good idea.
>
> This would, for example, answer the question of whether you are in fact using the x64 version of R.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Keniajin Wambui <kiangati at gmail.com> wrote:
>>I am using R3.0.2 on a windows 64 bit machine. I building a .rnw file
>>from an .r file. I am using MikTex as the engine for latex. The
>>function dtaStata <- read.dta("core2.dta", convert.dates=TRUE) works
>>well in .R but; When I try reading a dta (stata) file I get an error
>>"subscript out of bounds". The file has 52 variables and over 90000
>>observations
>>
>>Below is the code in latex
>>
>>\section{Introduction}
>>The following clinical variables are in the core data set
>>
>><<echo=false, results=hide>>=
>>#setting the working directory
>>setwd("H:/Rjob/coreGraphs/core2Report/")
>>
>>#load the packages
>>library(ggplot2)
>>library(foreign)
>>library(reshape2)
>>library(psych)
>>library(epicalc)
>>library(plyr)
>>library(doBy) #used to summarize
>>
>>##load the core 2 data
>>dtaStata <- read.dta("core2.dta", convert.dates=TRUE)
>>dtaStata <- as.data.frame(dtaStata)
>>dtaStata$ndad<-as.Date(dtaStata$ndad, origin='1960-01-01')
>>totalData <- table(dtaStata$yr)
>>#variables in core2
>>@
>>the data has \Sexpr{ncol(dtaStata)} columns \Sexpr{getwd()}
>>\clearpage
>>\end{document}
>



-- 
Mega Six Solutions
Web Designer and Research Consultant


From kridox at ymail.com  Wed Nov 27 07:26:58 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 27 Nov 2013 15:26:58 +0900
Subject: [R] Buse's GLS R2
In-Reply-To: <CABf=2VGPqTi7nuBaAP6YgOxLAq0onzVYq2T0z-T9aMgvv9FthA@mail.gmail.com>
References: <CABf=2VGPqTi7nuBaAP6YgOxLAq0onzVYq2T0z-T9aMgvv9FthA@mail.gmail.com>
Message-ID: <CAAcyNCxurH+4MPZ3nMVZ3ihmZ79oWmouHOtToX3TKbrsN=XNUQ@mail.gmail.com>

Hello,

Using 'sos':

library(sos)
findFn('buse')

Hope this helps,
Pascal

On 27 November 2013 14:55, Sheri O'Connor <soconnor at lakeheadu.ca> wrote:
> I was wondering if anyone knew of a package that contained a function
> of Buse's (http://www.jstor.org/stable/2683631 ) GLS R2 equation? If
> not, I would greatly appreciate any pointers about how I would
> implement Buse's equation using the results from nlme::gls function!
>
> Thanks very much for your time,
> Sheri
>
> BTW, I would be happy to send along the article.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kiangati at gmail.com  Wed Nov 27 07:39:17 2013
From: kiangati at gmail.com (Keniajin Wambui)
Date: Wed, 27 Nov 2013 09:39:17 +0300
Subject: [R] Subscript out of bounds
In-Reply-To: <CAE=fH8E_=J00FS9p9sUUopuQ8B0kqKDVAq-3iYBb71W9RRgF1g@mail.gmail.com>
References: <CAE=fH8EZfeZQmGZ7m2RkQBg6CwEJwA-Nha13SVDXQEq4mJK49A@mail.gmail.com>
	<4b09adfc-0863-47ff-9947-327b07434a44@email.android.com>
	<CAE=fH8E_=J00FS9p9sUUopuQ8B0kqKDVAq-3iYBb71W9RRgF1g@mail.gmail.com>
Message-ID: <CAE=fH8H_EH51P-7wrrvUzFa8_U=zi9tDPP15GFEq+HEcNAhtug@mail.gmail.com>

Here is the error am getting

Error:  chunk 1
Error in tt[[ll[v]]] : subscript out of bounds
Error in rle(filenames) : 'x' must be an atomic vector
Calls: <Anonymous> -> <Anonymous> -> RweaveTryStop
Execution halted


On Wed, Nov 27, 2013 at 9:25 AM, Keniajin Wambui <kiangati at gmail.com> wrote:
> Dear Jeff;
> Below is the output for sessioninfo()
>
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.2
>
> On Tue, Nov 26, 2013 at 9:00 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> This is the kind of question where including the output of sessionInfo() is a really good idea.
>>
>> This would, for example, answer the question of whether you are in fact using the x64 version of R.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> Keniajin Wambui <kiangati at gmail.com> wrote:
>>>I am using R3.0.2 on a windows 64 bit machine. I building a .rnw file
>>>from an .r file. I am using MikTex as the engine for latex. The
>>>function dtaStata <- read.dta("core2.dta", convert.dates=TRUE) works
>>>well in .R but; When I try reading a dta (stata) file I get an error
>>>"subscript out of bounds". The file has 52 variables and over 90000
>>>observations
>>>
>>>Below is the code in latex
>>>
>>>\section{Introduction}
>>>The following clinical variables are in the core data set
>>>
>>><<echo=false, results=hide>>=
>>>#setting the working directory
>>>setwd("H:/Rjob/coreGraphs/core2Report/")
>>>
>>>#load the packages
>>>library(ggplot2)
>>>library(foreign)
>>>library(reshape2)
>>>library(psych)
>>>library(epicalc)
>>>library(plyr)
>>>library(doBy) #used to summarize
>>>
>>>##load the core 2 data
>>>dtaStata <- read.dta("core2.dta", convert.dates=TRUE)
>>>dtaStata <- as.data.frame(dtaStata)
>>>dtaStata$ndad<-as.Date(dtaStata$ndad, origin='1960-01-01')
>>>totalData <- table(dtaStata$yr)
>>>#variables in core2
>>>@
>>>the data has \Sexpr{ncol(dtaStata)} columns \Sexpr{getwd()}
>>>\clearpage
>>>\end{document}
>>
>
>
>
> --
> Mega Six Solutions
> Web Designer and Research Consultant



-- 
Mega Six Solutions
Web Designer and Research Consultant


From bhh at xs4all.nl  Wed Nov 27 08:11:42 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 27 Nov 2013 08:11:42 +0100
Subject: [R] roots for two variables.
In-Reply-To: <1385525796.91457.YahooMailNeo@web165004.mail.bf1.yahoo.com>
References: <1385525796.91457.YahooMailNeo@web165004.mail.bf1.yahoo.com>
Message-ID: <30A55A87-411C-4124-94A1-30002E969369@xs4all.nl>


On 27-11-2013, at 05:16, Binod Manandhar <gibinod at yahoo.com> wrote:

> I was trying to find root for two non-linear equations.  My equation is similar as follows:
>  120 ? 5* exp(b0+b1*4)
> / (1+ exp(b0+b1*4) ) = 0
>  690 ? 31*
> exp(b0+b1*4) / (1+ exp(b0+b1*4) ) =0
>  
> How could find value of bo and b1 root values? 
> Thank you in advance.

You can use packages nleqslv, BB, (and ktsolve) for solving systems of non linear equations.
See the taskviews Optimization and NumericalMathematics on CRAN.

But you will not succeed in your case.

In your equations replace the expression exp(b0+b1*4) / (1+ exp(b0+b1*4) ) with Z.
Then you have two linear equations:

120-5*Z=0
690-31*Z=0

The system is incompatible. You can?t solve this for Z.

So you need to rethink your equations.

Berend

>  
> Saymi
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rhelp at eoos.dds.nl  Wed Nov 27 08:26:09 2013
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Wed, 27 Nov 2013 08:26:09 +0100
Subject: [R] Coding systems.
In-Reply-To: <OFCE3F49D2.A4ECC682-ON85257C2F.0064396C-85257C2F.0064A86C@dgag.ca>
References: <OFCE3F49D2.A4ECC682-ON85257C2F.0064396C-85257C2F.0064A86C@dgag.ca>
Message-ID: <20131127082609.Horde.CaTef2EwhY5SlZ6R7yoRf4A@webmailnew.dds.nl>


Could it be that your r-script is saved in a different encoding than  
the one used by R (which will probably be UTF8 since you're working on  
linux)?

-- 
Jan



gerald.jean at dgag.ca schreef:

> Hello,
>
> I am using R, 2.15.2, on a 64-bit Linux box.  I run R through Emacs' ESS.
>
> R runs in a French, Canadian-French, locale and lately I got surprising
> results
> from functions making factor variables from character variables.  Many of
> the
> variables in input data.frames are character variables and contain latin
> accents, for exemple the "?" in "Montr?al".  I waisted several days playing
> with coding systems and trying to understand why some code when run one
> command at
> a time from the command line gives the expected result while when cut and
> pasted in a function it doesn't???
>
> For example the following code:
>
> ==============================================================================
> ttt.rmr <- sima.31122012$rmrnom
> ttt.rmr.2 <- ifelse (ttt.rmr %in% c("Edmonton", "Edmundston",
>                                     "Charlottetown", "Calgary", "Winnipeg",
>                                     "Victoria", "Vancouver", "Toronto",
>                                     "St. John's", "Saskatoon", "Regina",
>                                     "Qu?bec", "Ottawa - Gatineau (Ontario",
>                                     "Ottawa - Gatineau (partie",
> "Montr?al",
>                                     "Halifax", "Fredericton"),
>                      "Grandes villes", ifelse(ttt.rmr == "", "Manquant",
> "Autres"))
> unique(ttt.rmr.2)
> ttt.rmr.2 <- factor(ttt.rmr.2, levels = c("Grandes villes", "Autres",
> "Manquant"),
>                     labels = c("Grandes villes", "Autres", "Manquant"))
>
> ==============================================================================
>
> will have "Montr?al" and "Qu?bec" in the "Grandes villes" level of the
> factor
> variable, while running the same code in a function will have them in
> "Autres".
> The variable "rmr.Merged" in the data.frame "test2.sima.31122012.DataPrep"
> is
> the output of the function, which, of course, does a lot of other stuff.
>
> ==============================================================================
> ttt.w <- which(ttt.rmr.2 != test2.sima.31122012.DataPrep$rmr.Merged)
> frequence(test2.sima.31122012.DataPrep$rmrnom[ttt.w])
>          Frequency  Percent Cum.Freq Cum.Percent
> Montr?al   1301254 79.57173  1301254    79.57173
> Qu?bec      334068 20.42827  1635322   100.00000
> ==============================================================================
>
> All other city names, no accents, were correctly classified but "Montr?al"
> and
> "Qu?bec", together they represent over 1.5M records, not negligeable!!!
>
> Following is my ".Renviron" file where I set up environment variables for
> R.
>
> R_PROFILE_USER="/home/jeg002/MyRwork/StartUp/profile.R"
> # export R_PROFILE_USER
> R_HISTFILE="/home/jeg002/MyRwork/.Rhistory"
> ## Default editor
> EDITOR=${EDITOR-${VISUAL-'/usr/local/bin/emacsclient'}}
> ## Default pager
> PAGER=${PAGER-'/usr/local/bin/emacsclient'}
>
> ## Setting locale, hoping it will be OK "all" the time!!!
> LANG=fr_CA
> LANGUAGE=fr_CA
> LC_ADDRESS=fr_CA
> LC_COLLATE=fr_CA
> LC_TYPE=fr_CA
> LC_IDENTIFICATION=fr_CA
> LC_MEASUREMENT=fr_CA
> LC_MESSAGES=fr_CA
> LC_NAME=fr_CA
> LC_PAPER=en_US
> LC_NUMERIC=en_US
> LC_TELEPHONE=fr_CA
> LC_MONETARY=fr_CA
> LC_TIME=fr_CA
> R_PAPERSIZE='letter'
> ==============================================================================
>
> and:
>
>> Sys.getlocale()
> [1]
> "LC_CTYPE=fr_CA;LC_NUMERIC=C;LC_TIME=fr_CA;LC_COLLATE=fr_CA;LC_MONETARY=fr_CA;LC_MESSAGES=fr_CA;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_CA;LC_IDENTIFICATION=C"
>
>> Sys.getenv(c("LANGUAGE", "LANG"))
> LANGUAGE     LANG
>  "fr_CA"  "fr_CA"
>
> I must be missing something!!!  Maybe someone can make sense of this!!!
> Thanks
> for your support,
>
> G?rald Jean
>
>  (Embedded image moved to file:
>  pic06023.gif)
>
>  Gerald Jean, M. Sc. en statistiques
>  Conseiller senior en statistiques     L?vis (si?ge social)
>
>  Actuariat corporatif,                 418 835-4900, poste
>  Mod?lisation et Recherche             7639
>  Assurance de dommages                 1 877 835-4900, poste
>  Mouvement Desjardins                  7639
>                                        T?l?copieur : 418
>                                        835-6657
>
>
>
>
>  Faites bonne impression et imprimez seulement au besoin!
>
>  Ce courriel est confidentiel, peut ?tre prot?g? par le secret  
> professionnel et
>  est adress? exclusivement au destinataire. Il est strictement  
> interdit ? toute
>  autre personne de diffuser, distribuer ou reproduire ce message. Si  
> vous l'avez
>  re?u par erreur, veuillez imm?diatement le d?truire et aviser l'exp?diteur.
>  Merci.


From r.turner at auckland.ac.nz  Wed Nov 27 09:47:16 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 27 Nov 2013 21:47:16 +1300
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
Message-ID: <5295B194.9010100@auckland.ac.nz>

On 11/25/13 09:04, Rich Shepard wrote:
> On Sun, 24 Nov 2013, Yihui Xie wrote:
>
>> Mailing lists are good for a smaller group of people, and especially
>> good when more focused on discussions on development (including bug
>> reports). The better place for questions is a web forum.
>
>   I disagree. Mail lists push messages to subscribers while web fora 
> require
> one to use a browser, log in, then pull messages. Not nearly as 
> convenient.

Well expressed Rich.  I agree with you completely.

     cheers,

     Rolf Turner


From lorenzo.isella at gmail.com  Wed Nov 27 09:55:09 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Wed, 27 Nov 2013 09:55:09 +0100
Subject: [R] GADM Data Download
Message-ID: <op.w669p7a4zqkd1e@enea>

Dear All,
Please consider the snippet at the end of the email.
I often download some maps (in the R format) from

http://www.gadm.org/

However, when I run (typically more than once) a variation of the script  
below (based on http://bit.ly/1b3W0Aa ),
I often get


Error in load(url(paste("http://gadm.org/data/rda/", fileName, "_adm",  :
   cannot open the connection
In addition: Warning message:
In load(url(paste("http://gadm.org/data/rda/", fileName, "_adm",  :
   cannot open: HTTP status was '504 Gateway Time-out'


Does anybody know if gadm blocks repeated attempts to retrieve the same  
data?
I am not talking about saturated its bandwidth, just retrieving a few tens  
of Mb per day at most.
Many thanks

Lorenzo







##############################################?	


## you will need the sp-package
library('sp')

## load a file from GADM (you just have to specify the countries "special  
part" of the file name, like "ARG" for Argentina. Optionally you can  
specify which level you want to have
loadGADM <- function (fileName, level = 0, ...) {
     load(url(paste("http://gadm.org/data/rda/", fileName, "_adm", level,  
".RData", sep     = "")))
     gadm
}

## the maps objects get a prefix (like "ARG_" for Argentina)
changeGADMPrefix <- function (GADM, prefix) {
     GADM <- spChFIDs(GADM, paste(prefix, row.names(GADM), sep = "_"))
     GADM
}

## load file and change prefix
loadChangePrefix <- function (fileName, level = 0, ...) {
     theFile <- loadGADM(fileName, level)
     theFile <- changeGADMPrefix(theFile, fileName)
     theFile
}

## this function creates a SpatialPolygonsDataFrame that contains all maps  
you specify in "fileNames".
## E.g.:
## spdf <- getCountries(c("ARG","BOL","CHL"))
## plot(spdf) # should draw a map with Brasil, Argentina and Chile on it.
getCountries <- function (fileNames, level = 0, ...) {
     polygon <- sapply(fileNames, loadChangePrefix, level)
     polyMap <- do.call("rbind", polygon)
     polyMap
}

################################################################
################################################################
################################################################
################################################################


spdf <- getCountries(c("ITA","FRA", "DEU","BEL", "LUX", "ESP",
                        "FIN", "SWE","DNK", "POL", "PRT", "CZE",
                        "SVK", "SVN", "GBR", "IRL", "ROU", "HUN",
                        "NLD", "AUT", "BGR","GRC",
                        "EST","LVA", "LTU","CYP","MLT", "HRV", "CHE"
                        ))


save(spdf,file="gadm_data.Rdata")


From coding1227 at gmail.com  Wed Nov 27 07:32:09 2013
From: coding1227 at gmail.com (Luke M)
Date: Tue, 26 Nov 2013 20:32:09 -1000
Subject: [R] Y-axis label not plotting
Message-ID: <CAJo_tOJWA7481bAcXNryQSNQgEYY_mWJVcUKZj8OQTUg=Wwjog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131126/33f4ddf4/attachment.pl>

From connect.chris at gmail.com  Wed Nov 27 08:53:07 2013
From: connect.chris at gmail.com (Chris Linton)
Date: Wed, 27 Nov 2013 02:53:07 -0500
Subject: [R] MANOVA Question
Message-ID: <CACWFPSfJfAb43FCREc-5_WVB9gUOOi4Vs+mVPokuNfD9MQNajA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/068f0950/attachment.pl>

From joseclaudio.faria at gmail.com  Wed Nov 27 11:22:23 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Wed, 27 Nov 2013 08:22:23 -0200
Subject: [R] Tinn-R user guide (latex sources) available on GitHub
Message-ID: <CAN+Emd_ynVkdVQSCFW_aR9n3r3O8UFceHo0LiSQbsPtGKssD=g@mail.gmail.com>

Dears user,

The Tinn-R User Guide is completely written in LaTeX and the idea
behind this to be available on GitHub is that it has contributions
from multiple users.

If you find something that you would like to include or impruve:
please, fell free to make it better.

This User Guide have been developing under both OS: Windows and Linux.

Under Windows: we have been using Tinn-R as editor and MikTeX as compiler.

Under Linux: we have been using Vim (with LaTeX-Box plugin) as editor
and TexLive as compiler.

Link: https://github.com/jcfaria/Tinn-R-User-Guide

Regards,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From jim at bitwrit.com.au  Wed Nov 27 11:23:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 27 Nov 2013 21:23:19 +1100
Subject: [R] Y-axis label not plotting
In-Reply-To: <CAJo_tOJWA7481bAcXNryQSNQgEYY_mWJVcUKZj8OQTUg=Wwjog@mail.gmail.com>
References: <CAJo_tOJWA7481bAcXNryQSNQgEYY_mWJVcUKZj8OQTUg=Wwjog@mail.gmail.com>
Message-ID: <5295C817.7000206@bitwrit.com.au>

On 11/27/2013 05:32 PM, Luke M wrote:
> Dear R community
>
> I am trying to make an XY plot that shows temperature (y axis) as a
> function of time (x axis) but I am having some problems. When I use the
> code shown below:
>
> 1. my plot does not show any of the y-axis labels even though there is
> plenty of white space there (i.e.: I am getting no y-axis title, and no
> y-axis labels at each tick mark). Is my command syntax incorrect?
>
> 2. Also, I was wondering... is there a way to tell R to plot the last 30
> days of data in the x-axis?
>
>
> Thank you so much in advance!!
>
>
> Here's my code so far:
>
> bdata=read.table('cleandata.asc',header=FALSE)
> dates1<- strptime(paste(bdata$V2, bdata$V3), format="%m/%d/%Y %H:%M:%S")
> temp1 = bdata[,4]
> par(mar=c(5, 6, 4, 2))
> plot(dates1, temp1,type="o",col="red",pch=20,xlab="x axis", main="my plot",
> ylab="y axis", ylim=c(0,40), yaxp = c(0,40,10))
>
>
> PS: just fyi, my data looks like this:
>
Hi Luke,
Thanks for including the data. When I plot it, I get both y axis label 
and y axis tick labels.

If you only want the last 30 days, you could select them like this:

last30<-dates1 >= strptime("2013-10-14","%Y-%m-%d")
plot(dates1[last30],temp1[last30],type="o",col="red",pch=20,
  xlab="x axis", main="my plot", ylab="y axis", ylim=c(0,40),
  yaxp = c(0,40,10))

Jim


From jorismeys at gmail.com  Wed Nov 27 14:57:47 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 27 Nov 2013 14:57:47 +0100
Subject: [R] Tinn-R user guide (latex sources) available on GitHub
In-Reply-To: <CAN+Emd_ynVkdVQSCFW_aR9n3r3O8UFceHo0LiSQbsPtGKssD=g@mail.gmail.com>
References: <CAN+Emd_ynVkdVQSCFW_aR9n3r3O8UFceHo0LiSQbsPtGKssD=g@mail.gmail.com>
Message-ID: <CAO1zAVaF0xUSwUVx46w3S750A8+ReX9+G+oQ8cvAyTH1iKtQsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/a9bd09a8/attachment.pl>

From jorismeys at gmail.com  Wed Nov 27 15:09:58 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 27 Nov 2013 15:09:58 +0100
Subject: [R] Should there be an R-beginners list?
In-Reply-To: <5295B194.9010100@auckland.ac.nz>
References: <CACk-te1orcbUuwDYpMU7B_CY6biuHmAGg6HCPMYGx6N2r8ismg@mail.gmail.com>
	<CANROs4d=UsU3oFqmTXBugV9v4_T9R+c3M0S15LrDcFPDj1Q_Vw@mail.gmail.com>
	<alpine.LNX.2.00.1311241203140.18596@salmo.appl-ecosys.com>
	<5295B194.9010100@auckland.ac.nz>
Message-ID: <CAO1zAVbZzVg77eyGFd9eu-R+kBT39p6V_yEazSR3Lge3w6dj7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/3f2b584a/attachment.pl>

From GITTEBA at HUM-GEN.AU.DK  Wed Nov 27 13:21:33 2013
From: GITTEBA at HUM-GEN.AU.DK (Gitte Brinch Andersen)
Date: Wed, 27 Nov 2013 12:21:33 +0000
Subject: [R] Space in label name
Message-ID: <5AB19DB4-C818-429D-877A-656288D3127D@hum-gen.au.dk>

Hi

I am doing a cluster analysis and I have some troubles with the label names.

In the text file I have my data in, the first row contains the names of the samples. They are called "FFPE Tumor 2", "Fresh Frozen Tumor 2" etc.

But when the cluster is made the label names contains periods instead of space in the name.
I can't figure out how to change this, so I get spaces in the label names.
I hope someone can help?

The code I have used is:

#Set where you want to save your images/clusters
setwd("/Users/gban/Desktop/Lung Cancer/PAXgene article figures/PAXgene cluster + Venn analysis")

#Read in data
data<-read.table("/Users/gban/Desktop/Lung Cancer/PAXgene article figures/PAXgene cluster + Venn analysis/BetaValue_ALL_tumo1_dup2_Codename.txt",sep="\t",dec=",",header=TRUE)

# Throw out rows with missing values.
data = na.omit(data)

#Turn the data into a matrix
Data_matrix<-as.matrix(data)

#Calculate the distance
Data_dist<-dist(t(data))

#Make the cluster
hc = hclust(Data_dist,method="ward")

# reduced label size
par(cex=0.7, mar=c(5, 8, 4, 1))
plot(hc, xlab="", ylab="", main="", sub="", axes=FALSE)
par(cex=1)
title(xlab="", ylab="", main="Cluster analysis")
axis(2)

The cluster output:
[cid:D57BB82B-3ACF-4681-BCA8-D8202EA34294 at eduroam.net.au.dk]
Kind regards

Gitte Brinch Andersen

Ph.d student
Department of Biomedicine
Wilhelm Meyers All? 4
Aarhus Universitet
DK-8000 Aarhus C

E-mail: gitteba at hum-gen.au.dk<mailto:gitteba at hum-gen.au.dk>



From friendly at yorku.ca  Wed Nov 27 15:24:22 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 27 Nov 2013 09:24:22 -0500
Subject: [R] xtable:  custom row.names, move caption to top
Message-ID: <52960096.1060704@yorku.ca>

With xtable, I'm producing one-way tables from table objects in 
horizontal form as shown below.
I'd like to change the labels used for the rows and move the caption to 
the top of the table,
as is typically standard for tables.  I can hand-edit, but would prefer 
to do it in code.

data(Saxony, package="vcd")
library(xtable)
saxtab <- xtable(t(addmargins(Saxony)), digits=0,
     caption="Number of male children in 6115 Saxony families of size 12")

print(saxtab)
 > print(saxtab)
% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Wed Nov 27 09:12:16 2013
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrrrrrrrrr}
   \hline
  & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
   \hline
1 & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 478 & 181 & 45 
& 7 & 6115 \\
    \hline
\end{tabular}
\caption{Number of male children in 6115 Saxony families of size 12}
\end{table}
 >

The desired form looks like this, with row.names = c("Males ($k$)", 
"Families ($n_k$)")

% latex table generated in R 3.0.1 by xtable 1.7-1 package
% Tue Nov 26 14:56:02 2013
\begin{table}[ht]
\caption{Number of male children in 6115 Saxony families of size 12} 
\label{tab:saxtab}
\centering
\begin{tabular}{l|rrrrrrrrrrrrrr}
   \hline
Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
   \hline
Families ($n_k$) & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 
478 & 181 & 45 & 7 & 6115 \\
    \hline
\end{tabular}
\end{table}

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From barthelmess at stlawu.edu  Wed Nov 27 15:44:24 2013
From: barthelmess at stlawu.edu (Erika Barthelmess)
Date: Wed, 27 Nov 2013 14:44:24 +0000
Subject: [R] Etimating time to run an analysis?
Message-ID: <CEBB6F72.CFB7%barthelmess@stlawu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/79f2e806/attachment.pl>

From soconnor at lakeheadu.ca  Wed Nov 27 15:54:19 2013
From: soconnor at lakeheadu.ca (Sheri O'Connor)
Date: Wed, 27 Nov 2013 09:54:19 -0500
Subject: [R] Buse's GLS R2
In-Reply-To: <CAAcyNCxurH+4MPZ3nMVZ3ihmZ79oWmouHOtToX3TKbrsN=XNUQ@mail.gmail.com>
References: <CABf=2VGPqTi7nuBaAP6YgOxLAq0onzVYq2T0z-T9aMgvv9FthA@mail.gmail.com>
	<CAAcyNCxurH+4MPZ3nMVZ3ihmZ79oWmouHOtToX3TKbrsN=XNUQ@mail.gmail.com>
Message-ID: <CABf=2VHoigLdqUBuPJhVxA0BVnf5uumsSysO5HSK9XkbtcdWkA@mail.gmail.com>

Thanks very much Pascal. That is a very useful package!

On Wed, Nov 27, 2013 at 1:26 AM, Pascal Oettli <kridox at ymail.com> wrote:
> Hello,
>
> Using 'sos':
>
> library(sos)
> findFn('buse')
>
> Hope this helps,
> Pascal
>
> On 27 November 2013 14:55, Sheri O'Connor <soconnor at lakeheadu.ca> wrote:
>> I was wondering if anyone knew of a package that contained a function
>> of Buse's (http://www.jstor.org/stable/2683631 ) GLS R2 equation? If
>> not, I would greatly appreciate any pointers about how I would
>> implement Buse's equation using the results from nlme::gls function!
>>
>> Thanks very much for your time,
>> Sheri
>>
>> BTW, I would be happy to send along the article.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan


From barvazduck at gmail.com  Wed Nov 27 16:22:54 2013
From: barvazduck at gmail.com (raz)
Date: Wed, 27 Nov 2013 17:22:54 +0200
Subject: [R] Conditional error bars
Message-ID: <CAGHW+oKyo48ivEArYQ0kyTSznJwSEYBxjY-nJg98yW4oBnFJ8w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/4f8174ad/attachment.pl>

From wdunlap at tibco.com  Wed Nov 27 16:34:16 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 27 Nov 2013 15:34:16 +0000
Subject: [R] Conditional error bars
In-Reply-To: <CAGHW+oKyo48ivEArYQ0kyTSznJwSEYBxjY-nJg98yW4oBnFJ8w@mail.gmail.com>
References: <CAGHW+oKyo48ivEArYQ0kyTSznJwSEYBxjY-nJg98yW4oBnFJ8w@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA19A6D@PA-MBX01.na.tibco.com>

Change your two lines
>     arrows(xvals, mean, xvals, CI.H, angle=90,length=length)
>     arrows(xvals, mean, xvals, CI.L, angle=90,length=length)
to the one line
       arrows(xvals, mean, xvals, mean + sign(mean) * se, angle=90, length=length)

(I would also use a scatter plot instead of a barplot for this sort of thing and
draw both error bars.  I think the bars give a misleading impression of what
is going on.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of raz
> Sent: Wednesday, November 27, 2013 7:23 AM
> To: r-help at r-project.org
> Subject: [R] Conditional error bars
> 
> How can I condition any error bar function that use the arrows() function,
> such as 'CI.plot' (see example below) or 'error.bars', to draw only upper
> error bar (upper CI) if the bar value (mean) is positive and the lower
> error bar (lower CI) if bar value is negative?
> 
> CI.plot <- function(mean, se,length, ylim=c(-5, max(CI.H)), ...) {
>     CI.H <- mean+se
>     CI.L <- mean-se
>     xvals <- barplot(mean, ylim=ylim, ...) # Plot bars
>     arrows(xvals, mean, xvals, CI.H, angle=90,length=length)
>     arrows(xvals, mean, xvals, CI.L, angle=90,length=length)
> }
> 
> CI.plot(D,SE,0.01)
> 
> thanks,
> --
> \m/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Rainer.Schuermann at gmx.net  Wed Nov 27 17:43:30 2013
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Wed, 27 Nov 2013 17:43:30 +0100
Subject: [R] xtable:  custom row.names, move caption to top
In-Reply-To: <52960096.1060704@yorku.ca>
References: <52960096.1060704@yorku.ca>
Message-ID: <6941964.LykLa6F2rY@rainer>

You get the cation to the top of the table with
print( saxtab, caption.placement = "top" )

Formatting the table the way you want can be done like this - I did not manage to carry the LaTeX math formatting for the row names over ($k$ and $n_k$)but the rest should be very much what you want:

saxtab <- t( as.data.frame( addmargins( Saxony ) ) )
rownames( saxtab ) <- c( "Males (k)", "Families (n_k)" )
saxtab <- xtable( saxtab, digits = 0,
     caption = "Number of male children in 6115 Saxony families of size 12",
     align = "l|rrrrrrrrrrrrrr" )
print( saxtab, caption.placement = "top", include.colnames = FALSE, 
     hline.after = c( NULL, 0, nrow( saxtab ) ) )


% latex table generated in R 3.0.2 by xtable 1.7-1 package
% Wed Nov 27 17:41:17 2013
\begin{table}[ht]
\centering
\caption{Number of male children in 6115 Saxony families of size 12} 
\begin{tabular}{l|rrrrrrrrrrrrrr}
   \hline
Males (k) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\ 
  Families (n\_k) &    3 &   24 &  104 &  286 &  670 & 1033 & 1343 & 1112 &  829 &  478 &  181 &   45 &    7 & 6115 \\ 
   \hline
\end{tabular}
\end{table}




On Wednesday 27 November 2013 09:24:22 Michael Friendly wrote:
> With xtable, I'm producing one-way tables from table objects in 
> horizontal form as shown below.
> I'd like to change the labels used for the rows and move the caption to 
> the top of the table,
> as is typically standard for tables.  I can hand-edit, but would prefer 
> to do it in code.
> 
> data(Saxony, package="vcd")
> library(xtable)
> saxtab <- xtable(t(addmargins(Saxony)), digits=0,
>      caption="Number of male children in 6115 Saxony families of size 12")
> 
> print(saxtab)
>  > print(saxtab)
> % latex table generated in R 3.0.1 by xtable 1.7-1 package
> % Wed Nov 27 09:12:16 2013
> \begin{table}[ht]
> \centering
> \begin{tabular}{rrrrrrrrrrrrrrr}
>    \hline
>   & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>    \hline
> 1 & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 478 & 181 & 45 
> & 7 & 6115 \\
>     \hline
> \end{tabular}
> \caption{Number of male children in 6115 Saxony families of size 12}
> \end{table}
>  >
> 
> The desired form looks like this, with row.names = c("Males ($k$)", 
> "Families ($n_k$)")
> 
> % latex table generated in R 3.0.1 by xtable 1.7-1 package
> % Tue Nov 26 14:56:02 2013
> \begin{table}[ht]
> \caption{Number of male children in 6115 Saxony families of size 12} 
> \label{tab:saxtab}
> \centering
> \begin{tabular}{l|rrrrrrrrrrrrrr}
>    \hline
> Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>    \hline
> Families ($n_k$) & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 
> 478 & 181 & 45 & 7 & 6115 \\
>     \hline
> \end{tabular}
> \end{table}
> 
>


From gerald.jean at dgag.ca  Wed Nov 27 17:46:44 2013
From: gerald.jean at dgag.ca (gerald.jean at dgag.ca)
Date: Wed, 27 Nov 2013 11:46:44 -0500
Subject: [R] Coding systems.
In-Reply-To: <20131127082609.Horde.CaTef2EwhY5SlZ6R7yoRf4A@webmailnew.dds.nl>
Message-ID: <OF83DBC985.675F588C-ON85257C30.005AE079-85257C30.005C2BDF@dgag.ca>


Hello,

as Jan pointed out the problem is with the encoding in which R saves the
fucntion.  If I set this encoding to "UTF-8" in source everything is fine.

If I go either in my .bash_profile or my .Renviron file and set all LOCALE
variables to "fr_CA.UTF8" it should do the job, and to a certain point it
does, I can source, and save in my personnal library functions with
multibyte characters and they will run as expected.

BUT with these settings

at startup R throws the following error:

Erreur : caract?res multioctets incorrects dans l'analyse de code (parser)
? la ligne 28

which translates in something like:

Error: incorrect multi-byte characters in the code analysis (parser) at
line 28

Further more I can't install any package, install.packages returns the same
error and stops execution???

I know the work around is to not specify an UTF-8 locale in my profiles and
explicitly pass the argument "encoding = 'UTF-8'" to source.  But to me,
this is somewhat of an inconsistency!!!

Thanks to Jan for his insights,

G?rald
                                                                                   
 (Embedded image moved to file:                                                    
 pic09232.gif)                                                                     
                                                                                   
 Gerald Jean, M. Sc. en statistiques                                               
 Conseiller senior en statistiques     L?vis (si?ge social)                        
                                                                                   
 Actuariat corporatif,                 418 835-4900, poste                         
 Mod?lisation et Recherche             7639                                        
 Assurance de dommages                 1 877 835-4900, poste                       
 Mouvement Desjardins                  7639                                        
                                       T?l?copieur : 418                           
                                       835-6657                                    
                                                                                   


                                                                                  
 Faites bonne impression et imprimez seulement au besoin!                         
                                                                                  
 Ce courriel est confidentiel, peut ?tre prot?g? par le secret professionnel et   
 est adress? exclusivement au destinataire. Il est strictement interdit ? toute   
 autre personne de diffuser, distribuer ou reproduire ce message. Si vous l'avez  
 re?u par erreur, veuillez imm?diatement le d?truire et aviser l'exp?diteur.      
 Merci.                                                                           
                                                                                  





                                                                           
             Jan van der Laan                                              
             <rhelp at eoos.dds.n                                             
             l>                                                          A 
                                       r-help at r-project.org                
             2013/11/27 02:26                                           cc 
                                       gerald.jean at dgag.ca                 
                                                                     Objet 
                                       Re: [R] Coding systems.             
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           





Could it be that your r-script is saved in a different encoding than
the one used by R (which will probably be UTF8 since you're working on
linux)?

--
Jan



gerald.jean at dgag.ca schreef:

> Hello,
>
> I am using R, 2.15.2, on a 64-bit Linux box.  I run R through Emacs' ESS.
>
> R runs in a French, Canadian-French, locale and lately I got surprising
> results
> from functions making factor variables from character variables.  Many of
> the
> variables in input data.frames are character variables and contain latin
> accents, for exemple the "?" in "Montr?al".  I waisted several days
playing
> with coding systems and trying to understand why some code when run one
> command at
> a time from the command line gives the expected result while when cut and
> pasted in a function it doesn't???
>
> For example the following code:
>
>
==============================================================================

> ttt.rmr <- sima.31122012$rmrnom
> ttt.rmr.2 <- ifelse (ttt.rmr %in% c("Edmonton", "Edmundston",
>                                     "Charlottetown", "Calgary",
"Winnipeg",
>                                     "Victoria", "Vancouver", "Toronto",
>                                     "St. John's", "Saskatoon", "Regina",
>                                     "Qu?bec", "Ottawa - Gatineau
(Ontario",
>                                     "Ottawa - Gatineau (partie",
> "Montr?al",
>                                     "Halifax", "Fredericton"),
>                      "Grandes villes", ifelse(ttt.rmr == "", "Manquant",
> "Autres"))
> unique(ttt.rmr.2)
> ttt.rmr.2 <- factor(ttt.rmr.2, levels = c("Grandes villes", "Autres",
> "Manquant"),
>                     labels = c("Grandes villes", "Autres", "Manquant"))
>
>
==============================================================================

>
> will have "Montr?al" and "Qu?bec" in the "Grandes villes" level of the
> factor
> variable, while running the same code in a function will have them in
> "Autres".
> The variable "rmr.Merged" in the data.frame
"test2.sima.31122012.DataPrep"
> is
> the output of the function, which, of course, does a lot of other stuff.
>
>
==============================================================================

> ttt.w <- which(ttt.rmr.2 != test2.sima.31122012.DataPrep$rmr.Merged)
> frequence(test2.sima.31122012.DataPrep$rmrnom[ttt.w])
>          Frequency  Percent Cum.Freq Cum.Percent
> Montr?al   1301254 79.57173  1301254    79.57173
> Qu?bec      334068 20.42827  1635322   100.00000
>
==============================================================================

>
> All other city names, no accents, were correctly classified but
"Montr?al"
> and
> "Qu?bec", together they represent over 1.5M records, not negligeable!!!
>
> Following is my ".Renviron" file where I set up environment variables for
> R.
>
> R_PROFILE_USER="/home/jeg002/MyRwork/StartUp/profile.R"
> # export R_PROFILE_USER
> R_HISTFILE="/home/jeg002/MyRwork/.Rhistory"
> ## Default editor
> EDITOR=${EDITOR-${VISUAL-'/usr/local/bin/emacsclient'}}
> ## Default pager
> PAGER=${PAGER-'/usr/local/bin/emacsclient'}
>
> ## Setting locale, hoping it will be OK "all" the time!!!
> LANG=fr_CA
> LANGUAGE=fr_CA
> LC_ADDRESS=fr_CA
> LC_COLLATE=fr_CA
> LC_TYPE=fr_CA
> LC_IDENTIFICATION=fr_CA
> LC_MEASUREMENT=fr_CA
> LC_MESSAGES=fr_CA
> LC_NAME=fr_CA
> LC_PAPER=en_US
> LC_NUMERIC=en_US
> LC_TELEPHONE=fr_CA
> LC_MONETARY=fr_CA
> LC_TIME=fr_CA
> R_PAPERSIZE='letter'
>
==============================================================================

>
> and:
>
>> Sys.getlocale()
> [1]
>
"LC_CTYPE=fr_CA;LC_NUMERIC=C;LC_TIME=fr_CA;LC_COLLATE=fr_CA;LC_MONETARY=fr_CA;LC_MESSAGES=fr_CA;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=fr_CA;LC_IDENTIFICATION=C"

>
>> Sys.getenv(c("LANGUAGE", "LANG"))
> LANGUAGE     LANG
>  "fr_CA"  "fr_CA"
>
> I must be missing something!!!  Maybe someone can make sense of this!!!
> Thanks
> for your support,
>
> G?rald Jean
>
>  (Embedded image moved to file:
>  pic06023.gif)
>
>  Gerald Jean, M. Sc. en statistiques
>  Conseiller senior en statistiques     L?vis (si?ge social)
>
>  Actuariat corporatif,                 418 835-4900, poste
>  Mod?lisation et Recherche             7639
>  Assurance de dommages                 1 877 835-4900, poste
>  Mouvement Desjardins                  7639
>                                        T?l?copieur : 418
>                                        835-6657
>
>
>
>
>  Faites bonne impression et imprimez seulement au besoin!
>
>  Ce courriel est confidentiel, peut ?tre prot?g? par le secret
> professionnel et
>  est adress? exclusivement au destinataire. Il est strictement
> interdit ? toute
>  autre personne de diffuser, distribuer ou reproduire ce message. Si
> vous l'avez
>  re?u par erreur, veuillez imm?diatement le d?truire et aviser
l'exp?diteur.
>  Merci.




From S.Ellison at LGCGroup.com  Wed Nov 27 18:12:28 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 27 Nov 2013 17:12:28 +0000
Subject: [R] cut2 not binning interval endpoints correctly
In-Reply-To: <CAAxdm-7B+JBVgwAx2VDL4uMO9AXa+yo34UREfLQSUMj0AnAMmA@mail.gmail.com>
References: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
	<D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5605AD3C9C@GOLD.corp.lgc-group.com>
	<CAAxdm-7B+JBVgwAx2VDL4uMO9AXa+yo34UREfLQSUMj0AnAMmA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5605AD4322@GOLD.corp.lgc-group.com>



> -----Original Message-----
>jim holtman <jholtman at gmail.com>
> You need to look at the full accuracy of the number representation:
Um... I think I did. But I'm not sure you did.... 
print(..., digits=20) has used different numbers of digits for your two print()s, probably because print() decided it needed more digits for the multi-valued vector. The internal representations were the same. Try

print(seq(0, 0.310, 0.001)[309], digits = 20)
[1] 0.307999999999999996

print(seq(0, 0.310, 0.001)[309], digits = 22)
[1] 0.3079999999999999960032

> print(0.308, digits = 22)
[1] 0.3079999999999999960032

0.308 does match the cut boundary 'exactly' in this case (which is why the usually unwise '==' returned TRUE), though neither is exactly 0.308. 

Nonetheless, I understand that FAQ 7.31 is a good candidate for other 'unexpected' cut2 results. However, that isn't the whole story. It doesn't explain the corresponding cut(, right=FALSE) result, which should give the same answer as cut2 if finite representation were the sole cause. So there's summat else going on.


Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From Rainer.Schuermann at gmx.net  Wed Nov 27 18:20:00 2013
From: Rainer.Schuermann at gmx.net (Rainer Schuermann)
Date: Wed, 27 Nov 2013 18:20 +0100
Subject: [R] xtable:  custom row.names, move caption to top
In-Reply-To: <6941964.LykLa6F2rY@rainer>
References: <52960096.1060704@yorku.ca> <6941964.LykLa6F2rY@rainer>
Message-ID: <5835845.iqmY8DoEhQ@rainer>

UPDATE:
Now including the LaTeX math formatting

saxtab <- t( as.data.frame( addmargins( Saxony ) ) )
rownames( saxtab ) <- c( "Males ($k$)", "Families ($n_k$)" )
saxtab <- xtable( saxtab, digits = 0,
     caption = "Number of male children in 6115 Saxony families of size 12",
     align = "l|rrrrrrrrrrrrrr" )
print( saxtab, caption.placement = "top", include.colnames = FALSE, 
     hline.after = c( NULL, 0, nrow( saxtab ) ),
     sanitize.text.function = function(x) { x } )

% latex table generated in R 3.0.2 by xtable 1.7-1 package
% Wed Nov 27 18:16:47 2013
\begin{table}[ht]
\centering
\caption{Number of male children in 6115 Saxony families of size 12} 
\begin{tabular}{l|rrrrrrrrrrrrrr}
   \hline
Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\ 
  Families ($n_k$) &    3 &   24 &  104 &  286 &  670 & 1033 & 1343 & 1112 &  829 &  478 &  181 &   45 &    7 & 6115 \\ 
   \hline
\end{tabular}
\end{table}




On Wednesday 27 November 2013 17:43:30 Rainer Schuermann wrote:
> You get the cation to the top of the table with
> print( saxtab, caption.placement = "top" )
> 
> Formatting the table the way you want can be done like this - I did not manage to carry the LaTeX math formatting for the row names over ($k$ and $n_k$)but the rest should be very much what you want:
> 
> saxtab <- t( as.data.frame( addmargins( Saxony ) ) )
> rownames( saxtab ) <- c( "Males (k)", "Families (n_k)" )
> saxtab <- xtable( saxtab, digits = 0,
>      caption = "Number of male children in 6115 Saxony families of size 12",
>      align = "l|rrrrrrrrrrrrrr" )
> print( saxtab, caption.placement = "top", include.colnames = FALSE, 
>      hline.after = c( NULL, 0, nrow( saxtab ) ) )
> 
> 
> % latex table generated in R 3.0.2 by xtable 1.7-1 package
> % Wed Nov 27 17:41:17 2013
> \begin{table}[ht]
> \centering
> \caption{Number of male children in 6115 Saxony families of size 12} 
> \begin{tabular}{l|rrrrrrrrrrrrrr}
>    \hline
> Males (k) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\ 
>   Families (n\_k) &    3 &   24 &  104 &  286 &  670 & 1033 & 1343 & 1112 &  829 &  478 &  181 &   45 &    7 & 6115 \\ 
>    \hline
> \end{tabular}
> \end{table}
> 
> 
> 
> 
> On Wednesday 27 November 2013 09:24:22 Michael Friendly wrote:
> > With xtable, I'm producing one-way tables from table objects in 
> > horizontal form as shown below.
> > I'd like to change the labels used for the rows and move the caption to 
> > the top of the table,
> > as is typically standard for tables.  I can hand-edit, but would prefer 
> > to do it in code.
> > 
> > data(Saxony, package="vcd")
> > library(xtable)
> > saxtab <- xtable(t(addmargins(Saxony)), digits=0,
> >      caption="Number of male children in 6115 Saxony families of size 12")
> > 
> > print(saxtab)
> >  > print(saxtab)
> > % latex table generated in R 3.0.1 by xtable 1.7-1 package
> > % Wed Nov 27 09:12:16 2013
> > \begin{table}[ht]
> > \centering
> > \begin{tabular}{rrrrrrrrrrrrrrr}
> >    \hline
> >   & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
> >    \hline
> > 1 & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 478 & 181 & 45 
> > & 7 & 6115 \\
> >     \hline
> > \end{tabular}
> > \caption{Number of male children in 6115 Saxony families of size 12}
> > \end{table}
> >  >
> > 
> > The desired form looks like this, with row.names = c("Males ($k$)", 
> > "Families ($n_k$)")
> > 
> > % latex table generated in R 3.0.1 by xtable 1.7-1 package
> > % Tue Nov 26 14:56:02 2013
> > \begin{table}[ht]
> > \caption{Number of male children in 6115 Saxony families of size 12} 
> > \label{tab:saxtab}
> > \centering
> > \begin{tabular}{l|rrrrrrrrrrrrrr}
> >    \hline
> > Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
> >    \hline
> > Families ($n_k$) & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 
> > 478 & 181 & 45 & 7 & 6115 \\
> >     \hline
> > \end{tabular}
> > \end{table}
> > 
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From coding1227 at gmail.com  Wed Nov 27 16:10:26 2013
From: coding1227 at gmail.com (Luke M)
Date: Wed, 27 Nov 2013 05:10:26 -1000
Subject: [R] Y-axis label not plotting
In-Reply-To: <5295C817.7000206@bitwrit.com.au>
References: <CAJo_tOJWA7481bAcXNryQSNQgEYY_mWJVcUKZj8OQTUg=Wwjog@mail.gmail.com>
	<5295C817.7000206@bitwrit.com.au>
Message-ID: <CAJo_tOLxAyn_K3Co4+dBwZTdADdHjSiNFWQcGeA545GGniu4wg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/17a42e47/attachment.pl>

From alamont082 at gmail.com  Wed Nov 27 18:12:50 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Wed, 27 Nov 2013 12:12:50 -0500
Subject: [R] ifelse, apply, if
Message-ID: <CALxSy06Di_ct+sQov13A7kAg3L16YViQHRxxiFSrvahYWT7K+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/d5174fcf/attachment.pl>

From wdunlap at tibco.com  Wed Nov 27 18:51:39 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 27 Nov 2013 17:51:39 +0000
Subject: [R] cut2 not binning interval endpoints correctly
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5605AD4322@GOLD.corp.lgc-group.com>
References: <CAGWMLifWxFejNQnGhC6i-kLdO5buLqJ4YtQ7mN=nz105H6n57Q@mail.gmail.com>
	<D427782F-6F51-4C4E-8CB1-3637A011E3C4@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5605AD3C9C@GOLD.corp.lgc-group.com>
	<CAAxdm-7B+JBVgwAx2VDL4uMO9AXa+yo34UREfLQSUMj0AnAMmA@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5605AD4322@GOLD.corp.lgc-group.com>
Message-ID: <E66794E69CFDE04D9A70842786030B933FA19B3F@PA-MBX01.na.tibco.com>

You can look at the source code of Hmisc::cut2() to see what is going on -- it does
 a lot more than calling cut() with different default arguments.  Another
approach to debugging this is to use trace() to see what cut2() passes down
to the default cut method:

> trace(cut.default, quote(cat("   x=", deparse(x), "\n   breaks=", deparse(breaks), "\n")))
Tracing function "cut.default" in package "base"
[1] "cut.default"
> z <- cut2(c(0.30800), seq(0,1,0.001)[306:315], oneval=FALSE)
Tracing cut.default(x, k2) on entry 
   x= 0.308 
   breaks= c(0.3045, 0.3055, 0.3065, 0.3075, 0.3085, 0.3095, 0.3105, 0.3115,  0.3125, 0.314) 
> z
[1] [0.308,0.309)
9 Levels: [0.305,0.306) [0.306,0.307) [0.307,0.308) ... [0.313,0.314]

I.e., this has little to do with floating point errors in cut(). 

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of S Ellison
> Sent: Wednesday, November 27, 2013 9:12 AM
> To: r-help at r-project.org
> Subject: Re: [R] cut2 not binning interval endpoints correctly
> 
> 
> 
> > -----Original Message-----
> >jim holtman <jholtman at gmail.com>
> > You need to look at the full accuracy of the number representation:
> Um... I think I did. But I'm not sure you did....
> print(..., digits=20) has used different numbers of digits for your two print()s, probably
> because print() decided it needed more digits for the multi-valued vector. The internal
> representations were the same. Try
> 
> print(seq(0, 0.310, 0.001)[309], digits = 20)
> [1] 0.307999999999999996
> 
> print(seq(0, 0.310, 0.001)[309], digits = 22)
> [1] 0.3079999999999999960032
> 
> > print(0.308, digits = 22)
> [1] 0.3079999999999999960032
> 
> 0.308 does match the cut boundary 'exactly' in this case (which is why the usually unwise
> '==' returned TRUE), though neither is exactly 0.308.
> 
> Nonetheless, I understand that FAQ 7.31 is a good candidate for other 'unexpected' cut2
> results. However, that isn't the whole story. It doesn't explain the corresponding cut(,
> right=FALSE) result, which should give the same answer as cut2 if finite representation
> were the sole cause. So there's summat else going on.
> 
> 
> Steve E
> 
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Wed Nov 27 20:17:52 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 27 Nov 2013 14:17:52 -0500
Subject: [R] Space in label name
In-Reply-To: <5AB19DB4-C818-429D-877A-656288D3127D@hum-gen.au.dk>
References: <5AB19DB4-C818-429D-877A-656288D3127D@hum-gen.au.dk>
Message-ID: <CAAxdm-5sDsfoHS8_go3ENOOvs5B5kEVU5E-0K5Bwz9rZ8PR4Kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/6840f574/attachment.pl>

From goran.brostrom at umu.se  Wed Nov 27 21:19:11 2013
From: goran.brostrom at umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Wed, 27 Nov 2013 21:19:11 +0100
Subject: [R] R- package for Parametric Survival Analysis with
 Left-censored data
In-Reply-To: <79AA7C00-7DB3-4851-A24D-10E2A22DBF0F@gmail.com>
References: <FD924877-2682-4799-AC91-7FC65A68FBB0@gmail.com>	<74357FCC-94DC-4BC5-9D2E-7644308465A7@comcast.net>
	<79AA7C00-7DB3-4851-A24D-10E2A22DBF0F@gmail.com>
Message-ID: <529653BF.70800@umu.se>



On 11/20/2013 08:17 AM, peter dalgaard wrote:
>
> On 20 Nov 2013, at 04:15 , David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> On Nov 19, 2013, at 5:30 PM, Vinod Mishra wrote:
>>
>>> Dear All,
>>>
>>> I am new to R. Can someone please direct me to an R package using
>>> which I can estimate a Parametric Survival Analysis model with
>>> Left-censored (delayed entry) data in it.
>>>
>>> I recently received reviewers comment on my submitted article,
>>> where the reviewer suggested that only R has capabilities of
>>> estimating above mentioned survival model. However, I am not able
>>> to figure which specific package in R, the reviewer was referring
>>> to.
>>
>> Look at:
>>
>> ?Surv
>>
>> ... after loading the survival package. (I do think you would be
>> advised to seek statistical consultation.)
>>
>
> In particular, notice the difference between left censoring (some
> patients are known to have died at an unknown time before t0) and
> left truncation (we only know survival times for patients alive at
> t0). Delayed entry is the latter.

And in that case you could try the functions 'phreg' (parametric 
proportional hazards models) and 'aftreg' (accelerated failure time 
models) in the package 'eha'. Both functions allow for left truncation, 
right censoring and and a choice of distributions.

G?ran Brostr?m

>
>> --
>>
>> David Winsemius Alameda, CA, USA
>>
>> ______________________________________________ R-help at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
>> read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From bbolker at gmail.com  Wed Nov 27 22:14:35 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 27 Nov 2013 21:14:35 +0000
Subject: [R] Etimating time to run an analysis?
References: <CEBB6F72.CFB7%barthelmess@stlawu.edu>
Message-ID: <loom.20131127T220809-835@post.gmane.org>

Erika Barthelmess <barthelmess <at> stlawu.edu> writes:

> Hi everyone,
> 
> I'm new to this list and have searched R help prior for an answer 
> to this question, without luck.  If I'm
> posting in error, please forgive.
> 
> I'm thinking about using package MuMIn to do multimodel inference 
> with logistic regression.  I have many
> (25) possible predictors and am curious if there is a way to 
> estimate how long the dredge command might take
> to run?
> 
> Any suggestions most welcome.
> 
> Thanks,
> erika

  This is likely to be a bad idea.  With 25 predictors you have 2^25 =
33 million candidate models (you can think of an array of models, each
predictor is either present or absent in each model -- that makes this
a set of 25-digit binary strings ...).  (If this doesn't make sense,
convince yourself by writing out the number of possible models for a
1-parameter (2), 2-parameter (4), and 3-parameter (8) model, and do
the extrapolation.) So pick a model of intermediate complexity, run
it, see how long it takes, and multiply that by 33 million ...  (if
each model takes about one second to fit, the analysis will take
about a year to run).

  You might want to look into penalized regression approaches
(e.g. see the glmnet package), which are a much more efficient
approach to this type of problem.


From friendly at yorku.ca  Wed Nov 27 22:32:54 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 27 Nov 2013 16:32:54 -0500
Subject: [R] xtable:  custom row.names, move caption to top
In-Reply-To: <5835845.iqmY8DoEhQ@rainer>
References: <52960096.1060704@yorku.ca> <6941964.LykLa6F2rY@rainer>
	<5835845.iqmY8DoEhQ@rainer>
Message-ID: <52966506.2010002@yorku.ca>

Thanks so much, Rainer.
Your detailed example has taught me a lot of what I need to use xtable
more productively, in particular the options for the print() method.

-Michael

On 11/27/2013 12:20 PM, Rainer Schuermann wrote:
> UPDATE:
> Now including the LaTeX math formatting
>
> saxtab <- t( as.data.frame( addmargins( Saxony ) ) )
> rownames( saxtab ) <- c( "Males ($k$)", "Families ($n_k$)" )
> saxtab <- xtable( saxtab, digits = 0,
>       caption = "Number of male children in 6115 Saxony families of size 12",
>       align = "l|rrrrrrrrrrrrrr" )
> print( saxtab, caption.placement = "top", include.colnames = FALSE,
>       hline.after = c( NULL, 0, nrow( saxtab ) ),
>       sanitize.text.function = function(x) { x } )
>
> % latex table generated in R 3.0.2 by xtable 1.7-1 package
> % Wed Nov 27 18:16:47 2013
> \begin{table}[ht]
> \centering
> \caption{Number of male children in 6115 Saxony families of size 12}
> \begin{tabular}{l|rrrrrrrrrrrrrr}
>     \hline
> Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>    Families ($n_k$) &    3 &   24 &  104 &  286 &  670 & 1033 & 1343 & 1112 &  829 &  478 &  181 &   45 &    7 & 6115 \\
>     \hline
> \end{tabular}
> \end{table}
>
>
>
>
> On Wednesday 27 November 2013 17:43:30 Rainer Schuermann wrote:
>> You get the cation to the top of the table with
>> print( saxtab, caption.placement = "top" )
>>
>> Formatting the table the way you want can be done like this - I did not manage to carry the LaTeX math formatting for the row names over ($k$ and $n_k$)but the rest should be very much what you want:
>>
>> saxtab <- t( as.data.frame( addmargins( Saxony ) ) )
>> rownames( saxtab ) <- c( "Males (k)", "Families (n_k)" )
>> saxtab <- xtable( saxtab, digits = 0,
>>       caption = "Number of male children in 6115 Saxony families of size 12",
>>       align = "l|rrrrrrrrrrrrrr" )
>> print( saxtab, caption.placement = "top", include.colnames = FALSE,
>>       hline.after = c( NULL, 0, nrow( saxtab ) ) )
>>
>>
>> % latex table generated in R 3.0.2 by xtable 1.7-1 package
>> % Wed Nov 27 17:41:17 2013
>> \begin{table}[ht]
>> \centering
>> \caption{Number of male children in 6115 Saxony families of size 12}
>> \begin{tabular}{l|rrrrrrrrrrrrrr}
>>     \hline
>> Males (k) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>>    Families (n\_k) &    3 &   24 &  104 &  286 &  670 & 1033 & 1343 & 1112 &  829 &  478 &  181 &   45 &    7 & 6115 \\
>>     \hline
>> \end{tabular}
>> \end{table}
>>
>>
>>
>>
>> On Wednesday 27 November 2013 09:24:22 Michael Friendly wrote:
>>> With xtable, I'm producing one-way tables from table objects in
>>> horizontal form as shown below.
>>> I'd like to change the labels used for the rows and move the caption to
>>> the top of the table,
>>> as is typically standard for tables.  I can hand-edit, but would prefer
>>> to do it in code.
>>>
>>> data(Saxony, package="vcd")
>>> library(xtable)
>>> saxtab <- xtable(t(addmargins(Saxony)), digits=0,
>>>       caption="Number of male children in 6115 Saxony families of size 12")
>>>
>>> print(saxtab)
>>>   > print(saxtab)
>>> % latex table generated in R 3.0.1 by xtable 1.7-1 package
>>> % Wed Nov 27 09:12:16 2013
>>> \begin{table}[ht]
>>> \centering
>>> \begin{tabular}{rrrrrrrrrrrrrrr}
>>>     \hline
>>>    & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>>>     \hline
>>> 1 & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 & 478 & 181 & 45
>>> & 7 & 6115 \\
>>>      \hline
>>> \end{tabular}
>>> \caption{Number of male children in 6115 Saxony families of size 12}
>>> \end{table}
>>>   >
>>>
>>> The desired form looks like this, with row.names = c("Males ($k$)",
>>> "Families ($n_k$)")
>>>
>>> % latex table generated in R 3.0.1 by xtable 1.7-1 package
>>> % Tue Nov 26 14:56:02 2013
>>> \begin{table}[ht]
>>> \caption{Number of male children in 6115 Saxony families of size 12}
>>> \label{tab:saxtab}
>>> \centering
>>> \begin{tabular}{l|rrrrrrrrrrrrrr}
>>>     \hline
>>> Males ($k$) & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
>>>     \hline
>>> Families ($n_k$) & 3 & 24 & 104 & 286 & 670 & 1033 & 1343 & 1112 & 829 &
>>> 478 & 181 & 45 & 7 & 6115 \\
>>>      \hline
>>> \end{tabular}
>>> \end{table}
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From gunter.berton at gene.com  Wed Nov 27 22:36:01 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 27 Nov 2013 13:36:01 -0800
Subject: [R] Etimating time to run an analysis?
In-Reply-To: <loom.20131127T220809-835@post.gmane.org>
References: <CEBB6F72.CFB7%barthelmess@stlawu.edu>
	<loom.20131127T220809-835@post.gmane.org>
Message-ID: <CACk-te17LujfFSvFbbDzpxzqdU9OP_ug60-ewijkp7FBryT2Hg@mail.gmail.com>

I would say that if the OP even contemplated this, it strongly
suggests that she needs to consult a local statistician for help.

Cheers,
Bert

On Wed, Nov 27, 2013 at 1:14 PM, Ben Bolker <bbolker at gmail.com> wrote:
> Erika Barthelmess <barthelmess <at> stlawu.edu> writes:
>
>> Hi everyone,
>>
>> I'm new to this list and have searched R help prior for an answer
>> to this question, without luck.  If I'm
>> posting in error, please forgive.
>>
>> I'm thinking about using package MuMIn to do multimodel inference
>> with logistic regression.  I have many
>> (25) possible predictors and am curious if there is a way to
>> estimate how long the dredge command might take
>> to run?
>>
>> Any suggestions most welcome.
>>
>> Thanks,
>> erika
>
>   This is likely to be a bad idea.  With 25 predictors you have 2^25 =
> 33 million candidate models (you can think of an array of models, each
> predictor is either present or absent in each model -- that makes this
> a set of 25-digit binary strings ...).  (If this doesn't make sense,
> convince yourself by writing out the number of possible models for a
> 1-parameter (2), 2-parameter (4), and 3-parameter (8) model, and do
> the extrapolation.) So pick a model of intermediate complexity, run
> it, see how long it takes, and multiply that by 33 million ...  (if
> each model takes about one second to fit, the analysis will take
> about a year to run).
>
>   You might want to look into penalized regression approaches
> (e.g. see the glmnet package), which are a much more efficient
> approach to this type of problem.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From joseclaudio.faria at gmail.com  Wed Nov 27 23:00:06 2013
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Wed, 27 Nov 2013 20:00:06 -0200
Subject: [R] Tinn-R: source code on GitHub
Message-ID: <CAN+Emd9G0NCtvTFbuRvUCsqr_R0A2-Kki+LdB5QJWBg+0aErvQ@mail.gmail.com>

Dear list,

The source code of Tinn-R editor is available on GitHub:
https://github.com/jcfaria/Tinn-R

Tinn-R is free, simple but efficient replacement for the basic code
editor provided by Rgui.
The project is coordinate by Jos? Cl?udio Faria/UESC/DCET.
All users are welcome to make it better.

LANGUAGE: Object Pascal
IDE: Delphi 2007

Regards,
-- 
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From jim at bitwrit.com.au  Wed Nov 27 23:33:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 28 Nov 2013 09:33:19 +1100
Subject: [R] Y-axis label not plotting
In-Reply-To: <CAJo_tOLxAyn_K3Co4+dBwZTdADdHjSiNFWQcGeA545GGniu4wg@mail.gmail.com>
References: <CAJo_tOJWA7481bAcXNryQSNQgEYY_mWJVcUKZj8OQTUg=Wwjog@mail.gmail.com>	<5295C817.7000206@bitwrit.com.au>
	<CAJo_tOLxAyn_K3Co4+dBwZTdADdHjSiNFWQcGeA545GGniu4wg@mail.gmail.com>
Message-ID: <5296732F.1000903@bitwrit.com.au>

On 11/28/2013 02:10 AM, Luke M wrote:
> Thanks for the follow-up. Per your suggestion, I was able to plot the
> data for the last 30 days with no problem.
>
> However... I am still confused about the y-axis labels (values, title,
> etc) not plotting. If the scripting works as it should, what could cause
> the labels not to show up? A while ago I think that I accidentally
> changed something (not sure what) on the default settings (I was trying
> to learn how to make plots), and I wonder if this could cause the
> problem I am having...
>
>
>
Hi Luke,
As I wrote, when I ran your code (albeit directly reading in the two 
variables and dropping your timezone in "dates1") I got the axis label 
and tick labels. If it was some default setting, you shouldn't get them 
on _any_ plot. The following gives me a plot that looks okay.

temp1<-c(6.81,26.81,26.81,26.81,26.87,26.87,
26.87,26.87,27.06,27.06,27.06,27.06,
27.06,27.06,27.06,27.06,27.06,27.06,
27.06,27.06,27.06,27.06,27.06,27.06,
27.06,27.06,27.06,27.06,27.06,27.06,
27.06,27.06,27.06,27.06,27.06,27.06,
27.06,27.06,27.06,27.06,27.06,27.00,
27.00,27.06,27.06,27.06,27.00,27.00,
27.06,27.00,27.00,27.00,27.00,27.00,
27.00,27.00,27.00,26.94,26.94,26.94,
26.94,27.00,26.94,26.94,26.94,26.94,
26.94,26.94,26.94,26.94,26.94,27.00,
26.94,26.94,26.94,26.94,26.94,26.94,
26.94,26.94,26.94)

dates1<-c("2013-01-12 18:10:28","2013-10-24 18:10:43",
"2013-10-29 18:10:49","2013-11-14 18:10:52",
"2013-11-14 18:12:10","2013-11-14 18:12:12",
"2013-11-14 18:12:21","2013-11-14 18:12:22",
"2013-11-14 18:17:10","2013-11-14 18:17:11",
"2013-11-14 18:17:13","2013-11-14 18:17:14",
"2013-11-14 18:17:15","2013-11-14 18:17:17",
"2013-11-14 18:17:18","2013-11-14 18:17:20",
"2013-11-14 18:17:21","2013-11-14 18:17:22",
"2013-11-14 18:17:24","2013-11-14 18:17:25",
"2013-11-14 18:17:26","2013-11-14 18:17:28",
"2013-11-14 18:17:29","2013-11-14 18:17:30",
"2013-11-14 18:17:32","2013-11-14 18:17:33",
"2013-11-14 18:17:34","2013-11-14 18:17:36",
"2013-11-14 18:17:37","2013-11-14 18:17:38",
"2013-11-14 18:17:40","2013-11-14 18:17:41",
"2013-11-14 18:17:42","2013-11-14 18:17:44",
"2013-11-14 18:17:45","2013-11-14 18:17:46",
"2013-11-14 18:18:47","2013-11-14 18:18:48",
"2013-11-14 18:18:50","2013-11-14 18:18:51",
"2013-11-14 18:18:52","2013-11-14 18:18:54",
"2013-11-14 18:18:55","2013-11-14 18:18:56",
"2013-11-14 18:18:58","2013-11-14 18:18:59",
"2013-11-14 18:19:10","2013-11-14 18:19:11",
"2013-11-14 18:19:12","2013-11-14 18:19:14",
"2013-11-14 18:19:15","2013-11-14 18:19:16",
"2013-11-14 18:19:18","2013-11-14 18:19:19",
"2013-11-14 18:19:20","2013-11-14 18:19:22",
"2013-11-14 18:19:23","2013-11-14 18:20:24",
"2013-11-14 18:20:26","2013-11-14 18:20:27",
"2013-11-14 18:20:29","2013-11-14 18:20:30",
"2013-11-14 18:20:31","2013-11-14 18:20:33",
"2013-11-14 18:20:34","2013-11-14 18:20:35",
"2013-11-14 18:20:37","2013-11-14 18:20:38",
"2013-11-14 18:20:39","2013-11-14 18:20:41",
"2013-11-14 18:20:42","2013-11-14 18:20:43",
"2013-11-14 18:20:45","2013-11-14 18:20:46",
"2013-11-14 18:20:47","2013-11-14 18:20:49",
"2013-11-14 18:20:50","2013-11-14 18:20:51",
"2013-11-14 18:20:53","2013-11-14 18:20:54",
"2013-11-14 18:20:55")

dates1<-strptime(dates1,"%Y-%m-%d %H:%M:%S")

par(mar=c(5, 6, 4, 2))
plot(dates1, temp1,type="o",col="red",pch=20,xlab="x axis",
  main="my plot",ylab="y axis", ylim=c(0,40), yaxp = c(0,40,10))

Jim


From revanth at codeforce.com  Wed Nov 27 23:24:24 2013
From: revanth at codeforce.com (Revanth kumar Gudimalla)
Date: Wed, 27 Nov 2013 17:24:24 -0500
Subject: [R] Requirement for Ruby on rails  [REQ:10217055]
Message-ID: <201311272221.rARML0RO025259@hypatia.math.ethz.ch>


   [1]Click here to unsubscribe if you no longer wish to receive our emails

   Dear Recruiter,

   Here   is our Direct   client   requirement   which   can   be  filled
   immediately. Kindly respond to this requirement with your consultant resume,
   contact and current location info to speed up the interview process.

   [2]Click  here  to submit for this position online and to speed up the
   process.
   Job Title:

   Ruby on rails


   Location:
   NYC, NY

   
    # of Positions: 1, Duration: 6 Months

    

   Description:

   We are looking for candidates who have experience into Ruby on rails along
   with java, mvc architecture, front end tool, spring MVC.
   [3]Click  here  to submit for this position online and to speed up the
   process.
   Please  respond  with you consultant resume, contact, rate and current
   location info to speed up the interview process. I will contact you if I
   need further details.

   CodeForce  Ranked  # 57 on Forbes listings for Americas Most Promising
   Companies

   [4]http://www.forbes.com/most-promising-companies/list/

   [5]http://www.forbes.com/companies/codeforce-360/



   Thanks & Regards,

   Revanth. K. Gudimalla

   Recruiting Manager

   CODEFORCE 360

   ERP & IT Services / Consulting Development Staffing

   Work: (770) 410-7770 Ext: 376 | Fax: (770) - 410 - 7737

   URL: [6]www.codeforce.com| E-mail: [7]revanth at codeforce.com

   Gtalk: [8]revanth.recruiter at gmail.com | Yahoo: [9]revanthg90 at yahoo.com

   [10]http://www.linkedin.com/in/revanthkgudimalla

   [11]https://www.facebook.com/CodeForce360

   [12]http://twitter.com/codeforce360

   [13]http://www.linkedin.com/company/codeforce-360

   Office Location:
   11381 Southbridge Pkwy, Alpharetta, GA 30022


    
   [14]Click here to unsubscribe from our mailing list and your name will be
   removed immediately.

     _________________________________________________________________

   This email is generated using [15]CONREP software.
   [16][8011234857.jpg] 

   G5540

References

   1. http://adso.conrep.com/conrep/actions/mail/unsubscribe.php?param=QVBSSUQ9MTEwMTAwOTcyMDE5JkFQTUlEPTQyNCZDTVBDRD01NTQwJkZST009cmV2YW50aEBjb2RlZm9yY2UuY29tJlRPPXItaGVscEByLXByb2plY3Qub3JnJkpPQklEPTExMDEwMTA2MzIyNiZTVUJKPVJlcXVpcmVtZW50IGZvciBSdWJ5IG9uIHJhaWxzICBbUkVROjEwMjE3MDU1XSZ1c3JpZD0xMTAyNjU2NjA2NzkmSkJDSUQ9NjEwMDIzMTU2MTg3
   2. http://adso.conrep.com/conrep/web/parse/resumeparsing/screen1.php?CUSID=5540110100010334&weblinkflg=1&REQID=110671124362&apmid=412&APMID=412&RECTR=110265660638&CPFID=&VENID=&JOBID=610023156187&Source=JobPortal&LEAID=110100972019&SOURC=VM
   3. http://adso.conrep.com/conrep/web/parse/resumeparsing/screen1.php?CUSID=5540110100010334&weblinkflg=1&REQID=110671124362&apmid=412&APMID=412&RECTR=110265660638&CPFID=&VENID=&JOBID=610023156187&Source=JobPortal&LEAID=110100972019&SOURC=VM
   4. http://www.forbes.com/most-promising-companies/list/
   5. http://www.forbes.com/companies/codeforce-360/
   6. http://www.codeforce.com%7c/
   7. mailto:revanth at codeforce.com
   8. mailto:revanth.recruiter at gmail.com
   9. mailto:revanthg90 at yahoo.com
  10. http://www.linkedin.com/in/revanthkgudimalla
  11. https://www.facebook.com/CodeForce360
  12. http://twitter.com/codeforce360
  13. http://www.linkedin.com/company/codeforce-360
  14. http://adso.conrep.com/conrep/actions/mail/unsubscribe.php?param=QVBSSUQ9MTEwMTAwOTcyMDE5JkFQTUlEPTQyNCZDTVBDRD01NTQwJkZST009cmV2YW50aEBjb2RlZm9yY2UuY29tJlRPPXItaGVscEByLXByb2plY3Qub3JnJkpPQklEPTExMDEwMTA2MzIyNiZTVUJKPVJlcXVpcmVtZW50IGZvciBSdWJ5IG9uIHJhaWxzICBbUkVROjEwMjE3MDU1XSZ1c3JpZD0xMTAyNjU2NjA2NzkmSkJDSUQ9NjEwMDIzMTU2MTg3
  15. http://www.conrep.com/?emlsrc=-110265660679&emailed=r-help at r-project.org&T=MM
  16. http://www.conrep.com/?emlsrc=-110265660679&emailed=r-help at r-project.org&T=MM

From lamonta at mailbox.sc.edu  Wed Nov 27 18:33:51 2013
From: lamonta at mailbox.sc.edu (Andrea Lamont)
Date: Wed, 27 Nov 2013 12:33:51 -0500
Subject: [R] if, apply, ifelse
Message-ID: <CALxSy05Ed3NOzMBCGG127p_ppeoVoNfROfO=qDj8SL_c-TZNWQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/98cf011a/attachment.ksh>

From coleoguy at gmail.com  Wed Nov 27 22:07:44 2013
From: coleoguy at gmail.com (Heath Blackmon)
Date: Wed, 27 Nov 2013 16:07:44 -0500
Subject: [R] heat map bin locations
Message-ID: <CAJVSDAABHCoYhWz9_rama=adkHXR69Prv59b4=4CZjuZLnffKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/9dd6f54c/attachment.pl>

From yserbest at prodigy.net  Wed Nov 27 23:39:51 2013
From: yserbest at prodigy.net (yetik serbest)
Date: Wed, 27 Nov 2013 14:39:51 -0800 (PST)
Subject: [R] importing many csv files into separate matrices
Message-ID: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>

Hi Everyone,
?
I am trying to import many CSV files to their own matrices. Example, alaska_93.csv to alaska. When I execute the following, for each csv.file separately it is successful.
?
singleCSVFile2Matrix <- function(x,path) {
?assign(gsub(pattern=".csv",x,replacement=""),read.csv(paste(path,x,sep="")))
}
?
when I try to include it in a loop in another function (I have so many csv files to import), it doesn't work. I mean the following function doesn't do it.
?
loadCSVFiles_old <- function(path) {
?x <- list.files(path)
?for (i in 1:length(x)) {
??assign(gsub(pattern=".csv",x[i],replacement=""),read.csv(paste(path,x[i],sep="")))
??}
}
?
Instead, if I execute the foor loop in the command line, it works. I am puzzled. Appreciate any help.
?
thanks
yetik


From wmbereng at yahoo.com  Thu Nov 28 08:06:11 2013
From: wmbereng at yahoo.com (Mosiuoa Bereng)
Date: Wed, 27 Nov 2013 23:06:11 -0800 (PST)
Subject: [R] error message
Message-ID: <1385622371.4900.YahooMailNeo@web163902.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131127/a12583d7/attachment.pl>

From miaojpm at gmail.com  Thu Nov 28 08:50:13 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 28 Nov 2013 15:50:13 +0800
Subject: [R] Find the prediction or the fitted values for an lm model
Message-ID: <CABcx46CNZE=a3=Se=bexP0H=sLnVXsfSAQGK2vMDMr=W-MXN-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/12ca20e2/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Thu Nov 28 09:17:45 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 28 Nov 2013 09:17:45 +0100 (CET)
Subject: [R] Find the prediction or the fitted values for an lm model
In-Reply-To: <CABcx46CNZE=a3=Se=bexP0H=sLnVXsfSAQGK2vMDMr=W-MXN-g@mail.gmail.com>
References: <CABcx46CNZE=a3=Se=bexP0H=sLnVXsfSAQGK2vMDMr=W-MXN-g@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1311280917030.11556@paninaro.uibk.ac.at>

On Thu, 28 Nov 2013, jpm miao wrote:

> Hi,
>
>   I would like to fit my data with a 4th order polynomial. Now I have only
> 5 data point, I should have a polynomial that exactly pass the five point
>
>   Then I would like to compute the "fitted" or "predict" value with a
> relatively large x dataset. How can I do it?
>
>   BTW, I thought the model "prodfn" should pass by (0,0), but I just
> wonder why the const is unequal to zero
>
> x1<-c(0,3,4,5,8)
> y1<-c(0,1,4,7,8)
> prodfn<-lm(y1 ~ poly(x1, 4))
>
> x<-seq(0,8,0.01)
>
> temp<-predict(prodfn,data.frame(x=x))   # This line does not work..

You need to call the variable x1 because that is the name you used in the 
original data:

plot(x, predict(prodfn,data.frame(x1=x)), type = "l")
points(x1, y1)

>
>> prodfn
>
> Call:
> lm(formula = y1 ~ poly(x1, 4))
>
> Coefficients:
> (Intercept)  poly(x1, 4)1  poly(x1, 4)2  poly(x1, 4)3  poly(x1, 4)4
>   4.000e+00     6.517e+00    -4.918e-16    -2.744e+00    -8.882e-16
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Nov 27 22:25:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 13:25:18 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
In-Reply-To: <CAJ0Fr65F7sZ=FMmgyRzpx7eHyULheaAvL3r18dR2T-RkT=4Nrw@mail.gmail.com>
References: <17248699.88711.1385583052615.JavaMail.nabble@joe.nabble.com>	<CAJ0Fr65TxQG1Hud2Es0_vtp3q4u1L-dbgJ2U4YnGTd2Y+1LBAw@mail.gmail.com>	<1385583871.77172.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr65F7sZ=FMmgyRzpx7eHyULheaAvL3r18dR2T-RkT=4Nrw@mail.gmail.com>
Message-ID: <1385587518.90142.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You may try something like:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(1:300,41082*15,replace=TRUE),ncol=15)) #created only 15 columns as shown in your model
?dat1$indx <- as.numeric(gl(334*123,123,334*123))
names(dat1)[1] <- "rate"
?lst1 <- split(dat1[,-16],dat1[,16])
any(sapply(lst1,nrow)!=123)
#[1] FALSE
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
?length(lst2)
#[1] 334


A.K.




On Wednesday, November 27, 2013 3:41 PM, nooldor <nooldor at gmail.com> wrote:


Thank you for reply.


OK.


you are right, let's make it more clear:

regressions would look like that:

summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+
???????????? +beta.wig+beta.wig.eq
?????????? +beta.sp
?????????? +beta.wig.macro
?????????? +beta.sp.macro
?????????? +beta.sentim.pl+beta.sentim.pl.ort
?????????? +beta.sentim.usa+beta.sentim.usa.ort, data=data))


the problem is how to make this lm() above for "rolling window" id est for first 334 observations? (total observations: 123*334). 
I need to run regresion_1 for first 334 observations, regression_2 for next 334 obs (from 335 to 669) and so on till regression_123 (from last 40748 till 41082).

And each time I run such regression I would like to save results (summary and mentioned tests).


Then I would like to repeat the same procedure but for rlm() and lmrob() if possible.


Hope it's better described now.








On 27 November 2013 21:24, arun <smartpink111 at yahoo.com> wrote:

So, if you have 49 dependent variables, what would be the model for one of the 123 regressions.
>You haven't provided any reproducible example, so its a lot of guess work.
>
>
>
>
>
>
>
>
>
>
>On Wednesday, November 27, 2013 3:18 PM, nooldor <nooldor at gmail.com> wrote:
>
>HI,
>
>Yes, I need to run regression 123 times - each time for 334 subjects with 49 dependent variables.
>Now I am trying "rollapply" function, but as I mentioned I am beginner so it takes time ...
>
>
>
>
>On 27 November 2013 21:11, <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>You said you wanted 123 test results of 'lm'. ?You have 49 dependent variables. ?So, there is something missing in your description.
>>
>><quote author='nooldor'>
>>Hi all!
>>
>>I am very beginner in R so please excuse me some of the naive questions. I
>>am learning.
>>Here is description of my problem:
>>
>>I have database (in single csv file)
>>? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ...
>>characteristic_49
>>subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... |
>>c49_1_t=1
>>subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... |
>>c49_2_t=1
>>subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... |
>>c49_3_t=1
>>...
>>subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... |
>>c49_334_t=1
>>subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... |
>>c49_1_t=2
>>subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... |
>>c49_2_t=2
>>subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... |
>>c49_3_t=2
>>...
>>subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... |
>>c49_3_t=2
>>
>>and so on ... till t (time) = 123
>>
>>so I have 334 subjects with 49 characteristics measured in 123 points of
>>time.
>>
>>I would like to run 123 regressions (three kinds: lm, rlm and lmrob - for
>>comparison reasons) each one for 334 subjects and 49 dependent variables and
>>after each regression (actually after conducting each of the three
>>regressions:lm, rlm and lmrob) I would like to save txt (or csv) file with
>>results (summary) and some test* (each regression can be named reg_1, reg_2
>>... reg_123) for those regressions.
>>
>>I think I can write "tests" part of the script alone (could you write me
>>some comments where exactly I should put it in script to have the test
>>automatically repeated the results saved), but 'saving' and 'repeating 123
>>times' procedures are quite complicated for me, at least now. So here I am
>>asking for help with it.
>>
>>In the end I would like to have three txt (or csv) files:
>>one containing 123 "summaries" and test results of lm,
>>one containing 123 "summaries" and test results of rlm
>>and one containing 123 "summaries" and test results of lmrob.
>>
>>Could someone help me with this task?
>>I am grateful for your help and support.
>>
>>________________
>>*like:
>>jarque.bera.test()
>>vif()
>>ncvTest()
>>durbinWatsonTest()
>>
>>---some of them are not applicable for rlm and lmrob - so in this case I
>>would like to have "test NA" in the three output txt (or csv) files
>>Some of them are also not applicable to cross-sectional regressions ... but
>>still I would like to keep them in script for later modifications
>></quote>
>>Quoted from:
>>http://r.789695.n4.nabble.com/Automatic-saving-of-many-regression-s-output-tp4681284.html
>>
>>
>>_____________________________________
>>Sent from http://r.789695.n4.nabble.com
>>
>>
>


From smartpink111 at yahoo.com  Wed Nov 27 23:27:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 14:27:40 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
Message-ID: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(c(NA,1:50),41082*15,replace=TRUE),ncol=15))
?dat1$indx <- as.numeric(gl(334*123,123,334*123))
names(dat1)[1] <- "rate"
?lst1 <- split(dat1[,-16],dat1[,16])
any(sapply(lst1,nrow)!=123)
#[1] FALSE
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
?length(lst2)
#[1] 334

A.K.

Hi all! 

I am very beginner in R so please excuse me some of the naive questions. I am learning. 
Here is description of my problem: 

I have database (in single csv file) 
? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ... ? ? ? ? ?characteristic_49 
subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... | ? ? c49_1_t=1 
subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... | ? ? c49_2_t=1 
subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... | ? ? c49_3_t=1 
... 
subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... | ? ? c49_334_t=1 
subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... | ? ? c49_1_t=2 
subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... | ? ? c49_2_t=2 
subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 
... 
subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 

and so on ... till t (time) = 123 

so I have 334 subjects with 49 characteristics measured in 123 points of time. 

I would like to run 123 regressions (three kinds: lm, rlm and 
lmrob - for comparison reasons) each one for 334 subjects and 49 
dependent variables and after each regression (actually after conducting
 each of the three regressions:lm, rlm and lmrob) I would like to save 
txt (or csv) file with results (summary) and some test* (each regression
 can be named reg_1, reg_2 ... reg_123) for those regressions. 

To make things more clear: 
regressions would look like that: 

summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+ 
? ? ? ? ? ? ?+beta.wig+beta.wig.eq 
? ? ? ? ? ?+beta.sp 
? ? ? ? ? ?+beta.wig.macro 
? ? ? ? ? ?+beta.sp.macro 
? ? ? ? ? ?+beta.sentim.pl+beta.sentim.pl.ort 
? ? ? ? ? ?+beta.sentim.usa+beta.sentim.usa.ort, data=data)) 

the problem is how to make this lm() above for "rolling window" 
id est for first 334 observations? (total observations: 123*334) and so 
on. 
I need to run regression_1 for first 334 observations, regression_2 
for next 334 obs (from 335 to 669) and so on till regression_123 (from 
last 40748 till 41082). 
And each time I run such regression I would like to save results (summary and mentioned tests). 

Then I would like to repeat the same procedure but for rlm() and lmrob() if possible. 

I think I can write "tests" part of the script alone (could you 
write me some comments where exactly I should put it in script to have 
the test automatically repeated the results saved), but 'saving' and 
'repeating 123 times' procedures are quite complicated for me, at least 
now. So here I am asking for help with it. 

In the end I would like to have three txt (or csv) files: 
one containing 123 "summaries" and test results of lm, 
one containing 123 "summaries" and test results of rlm 
and one containing 123 "summaries" and test results of lmrob. 

Could someone help me with this task? 
I am grateful for your help and support. 

________________ 
*like: 
jarque.bera.test() 
vif() 
ncvTest() 
durbinWatsonTest() 

---some of them are not applicable for rlm and lmrob - so in 
this case I would like to have "test NA" in the three output txt (or 
csv) files 
Some of them are also not applicable to cross-sectional regressions 
... but still I would like to keep them in script for later 
modifications


From smartpink111 at yahoo.com  Wed Nov 27 23:37:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 14:37:51 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
In-Reply-To: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1385591871.22041.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

lst1[[1]][,2] <- NA
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
? 0 (non-NA) cases



lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~.,data=x)) )
A.K.



Hi,

thank you for help. :-)

I applied your script to the data but I have got the error:

Error
 in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 
(non-NA) casesI forget to write that some of the data are NA.

I executed this code:

lst1 <- split(data[,-16],data[,16])
>any(sapply(lst1,nrow)!=123)
>#[1] FALSE
>lst2
 <- lapply(lst1,function(x) 
summary(lm(rate~cap.log+liqamih.log+pbv,data=x))) # here I can set the 
dependent variables if I? want to test different versions of the model 
(e.g with only e dependent variables), right?
>length(lst2)
>#[1] 334
>




On Wednesday, November 27, 2013 5:27 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(c(NA,1:50),41082*15,replace=TRUE),ncol=15))
?dat1$indx <- as.numeric(gl(334*123,123,334*123))
names(dat1)[1] <- "rate"
?lst1 <- split(dat1[,-16],dat1[,16])
any(sapply(lst1,nrow)!=123)
#[1] FALSE
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
?length(lst2)
#[1] 334

A.K.

Hi all! 

I am very beginner in R so please excuse me some of the naive questions. I am learning. 
Here is description of my problem: 

I have database (in single csv file) 
? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ... ? ? ? ? ?characteristic_49 
subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... | ? ? c49_1_t=1 
subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... | ? ? c49_2_t=1 
subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... | ? ? c49_3_t=1 
... 
subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... | ? ? c49_334_t=1 
subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... | ? ? c49_1_t=2 
subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... | ? ? c49_2_t=2 
subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 
... 
subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 

and so on ... till t (time) = 123 

so I have 334 subjects with 49 characteristics measured in 123 points of time. 

I would like to run 123 regressions (three kinds: lm, rlm and 
lmrob - for comparison reasons) each one for 334 subjects and 49 
dependent variables and after each regression (actually after conducting
each of the three regressions:lm, rlm and lmrob) I would like to save 
txt (or csv) file with results (summary) and some test* (each regression
can be named reg_1, reg_2 ... reg_123) for those regressions. 

To make things more clear: 
regressions would look like that: 

summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+ 
? ? ? ? ? ? ?+beta.wig+beta.wig.eq 
? ? ? ? ? ?+beta.sp 
? ? ? ? ? ?+beta.wig.macro 
? ? ? ? ? ?+beta.sp.macro 
? ? ? ? ? ?+beta.sentim.pl+beta.sentim.pl.ort 
? ? ? ? ? ?+beta.sentim.usa+beta.sentim.usa.ort, data=data)) 

the problem is how to make this lm() above for "rolling window" 
id est for first 334 observations? (total observations: 123*334) and so 
on. 
I need to run regression_1 for first 334 observations, regression_2 
for next 334 obs (from 335 to 669) and so on till regression_123 (from 
last 40748 till 41082). 
And each time I run such regression I would like to save results (summary and mentioned tests). 

Then I would like to repeat the same procedure but for rlm() and lmrob() if possible. 

I think I can write "tests" part of the script alone (could you 
write me some comments where exactly I should put it in script to have 
the test automatically repeated the results saved), but 'saving' and 
'repeating 123 times' procedures are quite complicated for me, at least 
now. So here I am asking for help with it. 

In the end I would like to have three txt (or csv) files: 
one containing 123 "summaries" and test results of lm, 
one containing 123 "summaries" and test results of rlm 
and one containing 123 "summaries" and test results of lmrob. 

Could someone help me with this task? 
I am grateful for your help and support. 

________________ 
*like: 
jarque.bera.test() 
vif() 
ncvTest() 
durbinWatsonTest() 

---some of them are not applicable for rlm and lmrob - so in 
this case I would like to have "test NA" in the three output txt (or 
csv) files 
Some of them are also not applicable to cross-sectional regressions 
... but still I would like to keep them in script for later 
modifications


From smartpink111 at yahoo.com  Thu Nov 28 00:38:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 15:38:37 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
In-Reply-To: <1385592597.76384.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385591871.22041.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1385592597.76384.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1385595517.59333.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

2. You need to tell which package you are using.

3. Does this work for you?
capture.output(lst2,file="nooldor.txt")

4. 


lst2
 <- lapply(lst1[sapply(lst1,function(x) 
!(all(rowSums(is.na(x))>0)))],function(x) 
print(summary(lm(rate~.,data=x)))? ###prints the output on R console

A.K.


Hi,

Thank you for patience and help :-)

now the code looks like that:


data<-read.table("reg3-dane.csv", head=T, sep=";", dec=",")
>data$indx <- as.numeric(gl(334*123,123,334*123))
>lst1
 <- split(data[,-16],data[,16]) # 1. by changing "16" parameter I can
 add or remove variables (also by modyfing the "reg3-dane.csv" file), 
right?
>any(sapply(lst1,nrow)!=123)
>#[1] FALSE
>lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~cap.log+liqamih.log+pbv,data=x)) )
>length(lst2)
 # 2.where I can place the test for each (from 123) regression like 
jarque.bera.test()?
vif()?
ncvTest()?
durbinWatsonTest() to have it saved with regression summary? and 3. how 
to get those list with results more user-friendly? I would like to get 
the report? 
>#[1] 334? 
>

is it ok?

Could you help me with the questions in remarks above?

And could you modify the script to also print the summary (and tests) of each regression (each of 123) in console?


Best wishes!
T.S.



On Wednesday, November 27, 2013 5:49 PM, arun <smartpink111 at yahoo.com> wrote:



Hi,

lst1[[1]][,2] <- NA
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
? 0 (non-NA) cases



lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~.,data=x)) )
A.K.



Hi,

thank you for help. :-)

I applied your script to the data but I have got the error:

Error
in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 
(non-NA) casesI forget to write that some of the data are NA.

I executed this code:

lst1 <- split(data[,-16],data[,16])
>any(sapply(lst1,nrow)!=123)
>#[1] FALSE
>lst2
<- lapply(lst1,function(x) 
summary(lm(rate~cap.log+liqamih.log+pbv,data=x))) # here I can set the 
dependent variables if I? want to test different versions of the model 
(e.g with only e dependent variables), right?
>length(lst2)
>#[1] 334
>





On Wednesday, November 27, 2013 5:27 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(c(NA,1:50),41082*15,replace=TRUE),ncol=15))
?dat1$indx <- as.numeric(gl(334*123,123,334*123))
names(dat1)[1] <- "rate"
?lst1 <- split(dat1[,-16],dat1[,16])
any(sapply(lst1,nrow)!=123)
#[1] FALSE
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
?length(lst2)
#[1] 334

A.K.

Hi all! 

I am very beginner in R so please excuse me some of the naive questions. I am learning. 
Here is description of my problem: 

I have database (in single csv file) 
? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ... ? ? ? ? ?characteristic_49 
subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... | ? ? c49_1_t=1 
subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... | ? ? c49_2_t=1 
subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... | ? ? c49_3_t=1 
... 
subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... | ? ? c49_334_t=1 
subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... | ? ? c49_1_t=2 
subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... | ? ? c49_2_t=2 
subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 
... 
subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 

and so on ... till t (time) = 123 

so I have 334 subjects with 49 characteristics measured in 123 points of time. 

I would like to run 123 regressions (three kinds: lm, rlm and 
lmrob - for comparison reasons) each one for 334 subjects and 49 
dependent variables and after each regression (actually after conducting
each of the three regressions:lm, rlm and lmrob) I would like to save 
txt (or csv) file with results (summary) and some test* (each regression
can be named reg_1, reg_2 ... reg_123) for those regressions. 

To make things more clear: 
regressions would look like that: 

summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+ 
? ? ? ? ? ? ?+beta.wig+beta.wig.eq 
? ? ? ? ? ?+beta.sp 
? ? ? ? ? ?+beta.wig.macro 
? ? ? ? ? ?+beta.sp.macro 
? ? ? ? ? ?+beta.sentim.pl+beta.sentim.pl.ort 
? ? ? ? ? ?+beta.sentim.usa+beta.sentim.usa.ort, data=data)) 

the problem is how to make this lm() above for "rolling window" 
id est for first 334 observations? (total observations: 123*334) and so 
on. 
I need to run regression_1 for first 334 observations, regression_2 
for next 334 obs (from 335 to 669) and so on till regression_123 (from 
last 40748 till 41082). 
And each time I run such regression I would like to save results (summary and mentioned tests). 

Then I would like to repeat the same procedure but for rlm() and lmrob() if possible. 

I think I can write "tests" part of the script alone (could you 
write me some comments where exactly I should put it in script to have 
the test automatically repeated the results saved), but 'saving' and 
'repeating 123 times' procedures are quite complicated for me, at least 
now. So here I am asking for help with it. 

In the end I would like to have three txt (or csv) files: 
one containing 123 "summaries" and test results of lm, 
one containing 123 "summaries" and test results of rlm 
and one containing 123 "summaries" and test results of lmrob. 

Could someone help me with this task? 
I am grateful for your help and support. 

________________ 
*like: 
jarque.bera.test() 
vif() 
ncvTest() 
durbinWatsonTest() 

---some of them are not applicable for rlm and lmrob - so in 
this case I would like to have "test NA" in the three output txt (or 
csv) files 
Some of them are also not applicable to cross-sectional regressions 
... but still I would like to keep them in script for later 
modifications


From smartpink111 at yahoo.com  Thu Nov 28 01:26:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 16:26:36 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
In-Reply-To: <1385595517.59333.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385591871.22041.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1385592597.76384.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1385595517.59333.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1385598396.73615.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,

Just tried ncvTest() and durbinWatsonTest() from library(car)


f4 <- function(meanmod, dta, varmod) {
assign(".dta", dta, envir=.GlobalEnv)
assign(".meanmod", meanmod, envir=.GlobalEnv)
m1 <- lm(.meanmod, .dta)
ans <- ncvTest(m1, varmod)
remove(".dta", envir=.GlobalEnv)
remove(".meanmod", envir=.GlobalEnv)
ans
}
library(car)
?lst3 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) f4(rate~., x))
?lst4 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) durbinWatsonTest(lm(rate~., x)))
?jarque.bera.test() from library(tseries) is applied on a numeric vector or time series. 

A.K.





On Wednesday, November 27, 2013 6:38 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,

2. You need to tell which package you are using.

3. Does this work for you?
capture.output(lst2,file="nooldor.txt")

4. 


lst2
<- lapply(lst1[sapply(lst1,function(x) 
!(all(rowSums(is.na(x))>0)))],function(x) 
print(summary(lm(rate~.,data=x)))? ###prints the output on R console

A.K.


Hi,

Thank you for patience and help :-)

now the code looks like that:


data<-read.table("reg3-dane.csv", head=T, sep=";", dec=",")
>data$indx <- as.numeric(gl(334*123,123,334*123))
>lst1
<- split(data[,-16],data[,16]) # 1. by changing "16" parameter I can
add or remove variables (also by modyfing the "reg3-dane.csv" file), 
right?
>any(sapply(lst1,nrow)!=123)
>#[1] FALSE
>lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~cap.log+liqamih.log+pbv,data=x)) )
>length(lst2)
# 2.where I can place the test for each (from 123) regression like 
jarque.bera.test()?
vif()?
ncvTest()?
durbinWatsonTest() to have it saved with regression summary? and 3. how 
to get those list with results more user-friendly? I would like to get 
the report? 
>#[1] 334? 
>

is it ok?

Could you help me with the questions in remarks above?

And could you modify the script to also print the summary (and tests) of each regression (each of 123) in console?


Best wishes!
T.S.




On Wednesday, November 27, 2013 5:49 PM, arun <smartpink111 at yahoo.com> wrote:



Hi,

lst1[[1]][,2] <- NA
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
? 0 (non-NA) cases



lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~.,data=x)) )
A.K.



Hi,

thank you for help. :-)

I applied your script to the data but I have got the error:

Error
in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 
(non-NA) casesI forget to write that some of the data are NA.

I executed this code:

lst1 <- split(data[,-16],data[,16])
>any(sapply(lst1,nrow)!=123)
>#[1] FALSE
>lst2
<- lapply(lst1,function(x) 
summary(lm(rate~cap.log+liqamih.log+pbv,data=x))) # here I can set the 
dependent variables if I? want to test different versions of the model 
(e.g with only e dependent variables), right?
>length(lst2)
>#[1] 334
>





On Wednesday, November 27, 2013 5:27 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
Try:
set.seed(49)
dat1 <- as.data.frame(matrix(sample(c(NA,1:50),41082*15,replace=TRUE),ncol=15))
?dat1$indx <- as.numeric(gl(334*123,123,334*123))
names(dat1)[1] <- "rate"
?lst1 <- split(dat1[,-16],dat1[,16])
any(sapply(lst1,nrow)!=123)
#[1] FALSE
lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
?length(lst2)
#[1] 334

A.K.

Hi all! 

I am very beginner in R so please excuse me some of the naive questions. I am learning. 
Here is description of my problem: 

I have database (in single csv file) 
? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ... ? ? ? ? ?characteristic_49 
subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... | ? ? c49_1_t=1 
subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... | ? ? c49_2_t=1 
subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... | ? ? c49_3_t=1 
... 
subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... | ? ? c49_334_t=1 
subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... | ? ? c49_1_t=2 
subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... | ? ? c49_2_t=2 
subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 
... 
subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2 

and so on ... till t (time) = 123 

so I have 334 subjects with 49 characteristics measured in 123 points of time. 

I would like to run 123 regressions (three kinds: lm, rlm and 
lmrob - for comparison reasons) each one for 334 subjects and 49 
dependent variables and after each regression (actually after conducting
each of the three regressions:lm, rlm and lmrob) I would like to save 
txt (or csv) file with results (summary) and some test* (each regression
can be named reg_1, reg_2 ... reg_123) for those regressions. 

To make things more clear: 
regressions would look like that: 

summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+ 
? ? ? ? ? ? ?+beta.wig+beta.wig.eq 
? ? ? ? ? ?+beta.sp 
? ? ? ? ? ?+beta.wig.macro 
? ? ? ? ? ?+beta.sp.macro 
? ? ? ? ? ?+beta.sentim.pl+beta.sentim.pl.ort 
? ? ? ? ? ?+beta.sentim.usa+beta.sentim.usa.ort, data=data)) 

the problem is how to make this lm() above for "rolling window" 
id est for first 334 observations? (total observations: 123*334) and so 
on. 
I need to run regression_1 for first 334 observations, regression_2 
for next 334 obs (from 335 to 669) and so on till regression_123 (from 
last 40748 till 41082). 
And each time I run such regression I would like to save results (summary and mentioned tests). 

Then I would like to repeat the same procedure but for rlm() and lmrob() if possible. 

I think I can write "tests" part of the script alone (could you 
write me some comments where exactly I should put it in script to have 
the test automatically repeated the results saved), but 'saving' and 
'repeating 123 times' procedures are quite complicated for me, at least 
now. So here I am asking for help with it. 

In the end I would like to have three txt (or csv) files: 
one containing 123 "summaries" and test results of lm, 
one containing 123 "summaries" and test results of rlm 
and one containing 123 "summaries" and test results of lmrob. 

Could someone help me with this task? 
I am grateful for your help and support. 

________________ 
*like: 
jarque.bera.test() 
vif() 
ncvTest() 
durbinWatsonTest() 

---some of them are not applicable for rlm and lmrob - so in 
this case I would like to have "test NA" in the three output txt (or 
csv) files 
Some of them are also not applicable to cross-sectional regressions 
... but still I would like to keep them in script for later 
modifications


From smartpink111 at yahoo.com  Thu Nov 28 04:01:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 27 Nov 2013 19:01:24 -0800 (PST)
Subject: [R] Automatic saving of many regression's output
In-Reply-To: <CAJ0Fr64wfrjUnbHGFpmEWGHJpE3Qs7b=OwabHepuX+bV6SFqnw@mail.gmail.com>
References: <1385591260.34547.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<1385591871.22041.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<1385592597.76384.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<1385595517.59333.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAJ0Fr67tVfXq3xMtED8j3GCMoq2wrDy+1xh0QmRcZWZu98rVYA@mail.gmail.com>	<1385598813.63809.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAJ0Fr64wfrjUnbHGFpmEWGHJpE3Qs7b=OwabHepuX+bV6SFqnw@mail.gmail.com>
Message-ID: <1385607684.92065.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
No problem,

You could try:
library(tseries)

res6 <- do.call(rbind,lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) {resid <- residuals(lm(rate~.,data=x)); unlist(jarque.bera.test(resid)[1:3])}) )


 A.K.




On Wednesday, November 27, 2013 7:47 PM, Tomasz Schabek <schabek.tomasz at gmail.com> wrote:

Great!

Thank you for help one more time!
yes, you are right - jarque.bera.test() should be applied to a vector, so the deal is: residuals from each of those 123 regressions captured by e.g:
"resid <-residuals(model)"? and "jarque.bera.test(resid)" are tested in jarque.bera.test(). Could you manage it?

You are really helpful and kind person!




Kind regards,
Atenciosamente,
Pozdrawiam,

T. S.


On 28 November 2013 01:33, arun <smartpink111 at yahoo.com> wrote:


>
>Hi,
>In that case:
>
>?lst5 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) vif(lm(rate~., x)))
>res5 <- do.call(rbind,lst5)
>
>
>As I mentioned earlier, it is not clear how you wanted to test jarque.bera.test().? Also, the results from lst3,lst4,lst5 etc could be saved using capture.output() (not tested though).? Or if you wanted to modify it and wanted only specific categories, for example:
>?res4 <- do.call(rbind,lapply(lst4,function(x) unlist(x[-4])))
>
>
>
>?
>
>On Wednesday, November 27, 2013 7:21 PM, nooldor <nooldor at gmail.com> wrote:
>
>Thank you for fast answer!
>
>and big THANK for help!
>
>I found error in the previous script (it was doing 334 regressions on 123 length vectors and it should be opposite: 123 regressions on 334 length vector) anyway I modify it:
>
>data<-read.table("reg3-dane.csv", head=T, sep=";", dec=",")
>>data$indx <- as.numeric(gl(123*334,334,123*334))
>>lst1 <- split(data[,-16],data[,16])
>>any(sapply(lst1,nrow)!=123)
>>#[1] FALSE
>>lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~cap.log,data=x)) )
>>capture.output(lst2,file="nooldor.txt")
>>it's ok now (at least when I compared regression summary from excel and R it was the same :-) )
>
>
>capture.output(lst2,file="nooldor.txt") works fine!
>
>packages:
>vif {car}
>jarque.bera.test {tseries}
>
>ncvTest {car}
>durbinWatsonTest {car}
>
>
>R version 3.0.2 (2013-09-25)
>
>
>T.S.
>
>
>On 28 November 2013 00:38, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>
>>2. You need to tell which package you are using.
>>
>>3. Does this work for you?
>>capture.output(lst2,file="nooldor.txt")
>>
>>4.
>>
>>
>>
>>lst2
>>?<- lapply(lst1[sapply(lst1,function(x)
>>!(all(rowSums(is.na(x))>0)))],function(x)
>>print(summary(lm(rate~.,data=x)))? ###prints the output on R console
>>
>>A.K.
>>
>>
>>
>>Hi,
>>
>>Thank you for patience and help :-)
>>
>>now the code looks like that:
>>
>>
>>data<-read.table("reg3-dane.csv", head=T, sep=";", dec=",")
>>>data$indx <- as.numeric(gl(334*123,123,334*123))
>>>lst1
>>
>>?<- split(data[,-16],data[,16]) # 1. by changing "16" parameter I can
>>?add or remove variables (also by modyfing the "reg3-dane.csv" file),
>>right?
>>>any(sapply(lst1,nrow)!=123)
>>>#[1] FALSE
>>
>>>lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~cap.log+liqamih.log+pbv,data=x)) )
>>>length(lst2)
>>?# 2.where I can place the test for each (from 123) regression like
>>jarque.bera.test()?
>>vif()?
>>ncvTest()?
>>durbinWatsonTest() to have it saved with regression summary? and 3. how
>>to get those list with results more user-friendly? I would like to get
>>the report?
>>>#[1] 334?
>>>
>>
>>is it ok?
>>
>>Could you help me with the questions in remarks above?
>>
>>And could you modify the script to also print the summary (and tests) of each regression (each of 123) in console?
>>
>>
>>Best wishes!
>>T.S.
>>
>>
>>
>>
>>On Wednesday, November 27, 2013 5:49 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>
>>
>>Hi,
>>
>>lst1[[1]][,2] <- NA
>>lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
>>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
>>? 0 (non-NA) cases
>>
>>
>>
>>lst2 <- lapply(lst1[sapply(lst1,function(x) !(all(rowSums(is.na(x))>0)))],function(x) summary(lm(rate~.,data=x)) )
>>A.K.
>>
>>
>>
>>Hi,
>>
>>thank you for help. :-)
>>
>>I applied your script to the data but I have got the error:
>>
>>Error
>>in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0
>>(non-NA) casesI forget to write that some of the data are NA.
>>
>>I executed this code:
>>
>>lst1 <- split(data[,-16],data[,16])
>>>any(sapply(lst1,nrow)!=123)
>>>#[1] FALSE
>>>lst2
>><- lapply(lst1,function(x)
>>summary(lm(rate~cap.log+liqamih.log+pbv,data=x))) # here I can set the
>>dependent variables if I? want to test different versions of the model
>>(e.g with only e dependent variables), right?
>>>length(lst2)
>>>#[1] 334
>>>
>>
>>
>>
>>
>>
>>On Wednesday, November 27, 2013 5:27 PM, arun <smartpink111 at yahoo.com> wrote:
>>Hi,
>>Try:
>>set.seed(49)
>>dat1 <- as.data.frame(matrix(sample(c(NA,1:50),41082*15,replace=TRUE),ncol=15))
>>?dat1$indx <- as.numeric(gl(334*123,123,334*123))
>>names(dat1)[1] <- "rate"
>>?lst1 <- split(dat1[,-16],dat1[,16])
>>any(sapply(lst1,nrow)!=123)
>>#[1] FALSE
>>lst2 <- lapply(lst1,function(x) summary(lm(rate~.,data=x)))
>>?length(lst2)
>>#[1] 334
>>
>>A.K.
>>
>>Hi all!
>>
>>I am very beginner in R so please excuse me some of the naive questions. I am learning.
>>Here is description of my problem:
>>
>>I have database (in single csv file)
>>? ? ? ? ? ? ? ? ? ?characteristic_1 ? ?characteristic_2 ? ? ? ? ? ? ? ... ? ? ? ? ?characteristic_49
>>subject_1 ? ? | ? ? ?c1_1_t=1 ? ? ? ? ? ? | ? c2_1_t=1 ? ? ? ? ? ? ... | ? ? c49_1_t=1
>>subject_2 ? ? | ? ? ?c1_2_t=1 ? ? ? ? ? ? | ? c2_2_t=1 ? ? ? ? ? ? ... | ? ? c49_2_t=1
>>subject_3 ? ? | ? ? ?c1_3_t=1 ? ? ? ? ? ? | ? c2_3_t=1 ? ? ? ? ? ? ... | ? ? c49_3_t=1
>>...
>>subject_334 ?| ? ? ?c1_334_t=1 ? ? ? ? | ? c2_334_t=1 ? ? ? ? ?... | ? ? c49_334_t=1
>>subject_1 ? ? | ? ? ?c1_1_t=2 ? ? ? ? ? ?| ? c2_1_t=2 ? ? ? ? ? ? ?... | ? ? c49_1_t=2
>>subject_2 ? ? | ? ? ?c1_2_t=2 ? ? ? ? ? ?| ? c2_2_t=2 ? ? ? ? ? ? ?... | ? ? c49_2_t=2
>>subject_3 ? ? | ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2
>>...
>>subject_334 ?| ? ? ?c1_3_t=2 ? ? ? ? ? ?| ? c2_3_t=2 ? ? ? ? ? ? ?... | ? ? c49_3_t=2
>>
>>and so on ... till t (time) = 123
>>
>>so I have 334 subjects with 49 characteristics measured in 123 points of time.
>>
>>I would like to run 123 regressions (three kinds: lm, rlm and
>>lmrob - for comparison reasons) each one for 334 subjects and 49
>>dependent variables and after each regression (actually after conducting
>>each of the three regressions:lm, rlm and lmrob) I would like to save
>>txt (or csv) file with results (summary) and some test* (each regression
>>can be named reg_1, reg_2 ... reg_123) for those regressions.
>>
>>To make things more clear:
>>regressions would look like that:
>>
>>summary(lm(rate~cap.log+liqamih.log+liqwol.log+pbv.log+mom.log+
>>? ? ? ? ? ? ?+beta.wig+beta.wig.eq
>>? ? ? ? ? ?+beta.sp
>>? ? ? ? ? ?+beta.wig.macro
>>? ? ? ? ? ?+beta.sp.macro
>>? ? ? ? ? ?+beta.sentim.pl+beta.sentim.pl.ort
>>? ? ? ? ? ?+beta.sentim.usa+beta.sentim.usa.ort, data=data))
>>
>>the problem is how to make this lm() above for "rolling window"
>>id est for first 334 observations? (total observations: 123*334) and so
>>on.
>>I need to run regression_1 for first 334 observations, regression_2
>>for next 334 obs (from 335 to 669) and so on till regression_123 (from
>>last 40748 till 41082).
>>And each time I run such regression I would like to save results (summary and mentioned tests).
>>
>>Then I would like to repeat the same procedure but for rlm() and lmrob() if possible.
>>
>>I think I can write "tests" part of the script alone (could you
>>write me some comments where exactly I should put it in script to have
>>the test automatically repeated the results saved), but 'saving' and
>>'repeating 123 times' procedures are quite complicated for me, at least
>>now. So here I am asking for help with it.
>>
>>In the end I would like to have three txt (or csv) files:
>>one containing 123 "summaries" and test results of lm,
>>one containing 123 "summaries" and test results of rlm
>>and one containing 123 "summaries" and test results of lmrob.
>>
>>Could someone help me with this task?
>>I am grateful for your help and support.
>>
>>________________
>>*like:
>>jarque.bera.test()
>>vif()
>>ncvTest()
>>durbinWatsonTest()
>>
>>---some of them are not applicable for rlm and lmrob - so in
>>this case I would like to have "test NA" in the three output txt (or
>>csv) files
>>Some of them are also not applicable to cross-sectional regressions
>>... but still I would like to keep them in script for later
>>modifications
>>
>


From r.turner at auckland.ac.nz  Thu Nov 28 09:36:53 2013
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 28 Nov 2013 21:36:53 +1300
Subject: [R] Find the prediction or the fitted values for an lm model
In-Reply-To: <CABcx46CNZE=a3=Se=bexP0H=sLnVXsfSAQGK2vMDMr=W-MXN-g@mail.gmail.com>
References: <CABcx46CNZE=a3=Se=bexP0H=sLnVXsfSAQGK2vMDMr=W-MXN-g@mail.gmail.com>
Message-ID: <529700A5.3090701@auckland.ac.nz>


See in-line below.

On 11/28/13 20:50, jpm miao wrote:
> Hi,
>
>     I would like to fit my data with a 4th order polynomial. Now I have only
> 5 data point, I should have a polynomial that exactly pass the five point
>
>     Then I would like to compute the "fitted" or "predict" value with a
> relatively large x dataset. How can I do it?
>
>     BTW, I thought the model "prodfn" should pass by (0,0), but I just
> wonder why the const is unequal to zero

Because poly() produces orthonormalized polynomials,  Look at poly(x1,4).
It is not much like cbind(x1,x1^2,x1^3,x1^4), is it?

     cheers,

     Rolf Turner
>
> x1<-c(0,3,4,5,8)
> y1<-c(0,1,4,7,8)
> prodfn<-lm(y1 ~ poly(x1, 4))
>
> x<-seq(0,8,0.01)
>
> temp<-predict(prodfn,data.frame(x=x))   # This line does not work..
>
>
>> prodfn
> Call:
> lm(formula = y1 ~ poly(x1, 4))
>
> Coefficients:
>   (Intercept)  poly(x1, 4)1  poly(x1, 4)2  poly(x1, 4)3  poly(x1, 4)4
>     4.000e+00     6.517e+00    -4.918e-16    -2.744e+00    -8.882e-16
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From halim10-fes at sust.edu  Thu Nov 28 08:17:24 2013
From: halim10-fes at sust.edu (halim10-fes)
Date: Thu, 28 Nov 2013 13:17:24 +0600
Subject: [R] Problems dealing with matrices
In-Reply-To: <1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<20131127023716.M4379@sust.edu>
	<1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <20131128042927.M43811@sust.edu>

Hi,

Sorry for continuous bothering. Continuum of the previous problem...

I have the following matrices and vectors,

dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00, 
                0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00, 
                0.09),nrow=5,ncol=5) 

volini<-matrix(c(0,0,0,0,0),nrow=5,ncol=1)

volinp1<-c(0, 0.0004669094, 0.0027610861, 0.0086204692, 0.0200137754, 
0.0389069106 ,0.0670942588, 0.1060941424, 0.1570990708, 0.2209672605, 
0.2982420945, 0.3891882830, 0.4938361307, 0.6120278338, 0.7434618363, 
0.8877329008, 1.0443667375, 1.2128488387, 1.3926476912, 1.5832328410, 
1.7840884399, 1.9947229566, 2.2146757191, 2.4435209092, 2.6808695568, 
2.9263700050, 3.1797072430, 3.4406014299, 3.7088058696, 3.9841046430, 
4.2663100561, 4.5552600226, 4.8508154713, 5.1528578389, 5.4612866929,
5.7760175114, 6.0969796345, 6.4241143947, 6.7573734248, 7, 7 ,7, 7, 7, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,  7,  
7, 7, 7)


I've calculated the following matrices vol and volyrdc1 (obviously with the 
help of Jeff and Arun):

#Blank matrices for dumping final values

vol <- matrix( NA, nrow=5, ncol=length(volinp1))

volyrdc1<-matrix(NA, nrow=5,ncol=length(volinp1),dimnames= 
list(c("DC1","DC2","DC3","DC4","DC5"),c(seq(0,500,5))))

vol[ , 1 ] <- dcmat %*% (volini+(volinp1[1]*wt))

wt<-matrix(c(1,0,0,0,0),nrow=5)

for ( idx in seq_along(volinp1)[ -1 ] ) { 
  vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp1[idx] * wt ) 
}  

vol

volyrdc1[,1]<-vol[,1]

for ( idx in seq_along(volinp1)[ -1 ] ) { 
  volyrdc1[ , idx ] <- vol[ , idx-1 ] + volinp1[idx] * wt
  }  
volyrdc1

My final matrix in 'volyrdc1' (kind of transition matrix model). 

Now, what I want to do is to calculate when the colsum<-colSums(volyrdc1) 
reaches a certain value and I want to get the index of the element in the 
'colsum' vector at that point. For e.g. when colsum[colsum>=18] ? It will give 
a series of cases where the condition is true. But I want index of the element 
immediately when the condition is met. In this case, the answer I want is 140 
(colsum[29] returns both value (18.63) and the character ("140") attributing 
the index). Actually, in my case 140 is year (age) when the 'colsum' becomes 
>=18. At is point it would be great if I can calculate when 'colsum' levels 
off (up to two decimal place)? The answer is: 305 and at that point 
colsum==45.37.  

I also want to calculate what should be the value in volini[1,1] to get a 
certain value in 'colsum' at a certain year (age)(vector element index 
explained earlier)? For e.g. I want to find out that what should be the value 
in volini[1,1] if I want colsum==18 at 100(charater attributing colsum[21])? 
The answer is: 15910 and the 'volini' matrix will look like:

volini<-matrix(c(15910,0,0,0,0),nrow=5,ncol=1)

Any pointer, suggestions,... will be gratefully acknowledged.

P.S. Can you please suggest me any effective R programming book that describe 
core elements of R programming?

Thanks in advance.

Regards,

Halim? ? ? ? ? ? ? ? 
---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com







On Tue, 26 Nov 2013 20:21:14 -0800 (PST), arun wrote
> HI Halim,
> 
> No problem.
> Regards,
> Arun
> 
> On Tuesday, November 26, 2013 11:18 PM, halim10-fes <halim10-
> fes at sust.edu> wrote: Hi Arun,
> 
> Thanks for your help. Sorry for my late response. Take care and stay 
> fine.
> 
> Regards,
> 
> Halim
> 
> On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
> > Hi Halim,
> > I guess this works for you.? Modifying Jeff's solution:
> > 
> > volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
> > vol1 <- dcmat %*% (volmat +wt)
> > for(idx in seq_along(volinp)[-1]){
> > ?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
> > ?}
> > 
> > #or
> > 
> > vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> > vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> > 
> > for ( idx in seq_along(volinp)[ -1 ] ) {
> > ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
> > }
> > identical(vol,vol1)
> > #[1] TRUE
> > 
> > A.K.
> > 
> > On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
> > fes at sust.edu> wrote: Hi Arun,
> > 
> > OK, no problem. Thank you very much for your attention. I've posted 
> > an annex to my previous problem. I will appreciate your 
> > comments/suggestions on it.
> > 
> > Off-topic: You're a very helpful man. I like your attitude to 
> > helping others.
> > 
> > Take care.
> > 
> > Halim
> > 
> > On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> > > Hi,
> > > Please disregard my earlier message. Looks like Jeff understand it 
> > > better and answered it. Regards, Arun
> > > 
> > > On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> 
wrote:
> > > Hi,
> > > I am finding some inconsistency with your description.
> > > For example:
> > > volinp[1]+volmat[1,1]
> > > [1] 101
> > > 
> > > On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> > > fes at sust.edu> wrote:
> > > 
> > > Please apologize me! Earlier I've sent a message erroneously. 
> > > Following is the original problem for which I'm seeking help. 
> > > Extremely sorry...?
> > > 
> > > Hi Arun,
> > > 
> > > Thank you very much for your response. Sorry, if I couldn't explain 
> > > clearly. I think, I should restate the problem to get exactly what I 
> > > want. Here it goes:
> > > 
> > > I have 2 matrices and 1 vector, namely,
> > > 
> > > dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > > 
> > > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > 
> > > volinp<-c(1:40)
> > > 
> > > What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> > > and dump the output in a new matrix 'vol'. But before that, in the 
> > > first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> > > column of the output matrix 'vol' matrix will be:
> > > 
> > > ? ? ? ? [,1]
> > > [1,]?? 13.13
> > > [2,]?? 61.61
> > > [3,]?? 25.25
> > > [4,]? ? 0.00
> > > [5,]? ? 0.00
> > > 
> > > In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> > > volinp[2] with vol[1,1]. The new 'volmat' will look like:
> > > 
> > > ? ? ? ? [,1]
> > > [1,]?? 15.13
> > > [2,]?? 61.61
> > > [3,]?? 25.25
> > > [4,]? ? 0.00
> > > [5,]? ? 0.00
> > > 
> > > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> > > output matrix 'vol' will look like:
> > > 
> > > ? ? ? ? [,2]
> > > [1,]? 1.9669
> > > [2,] 41.2665
> > > [3,] 41.2232
> > > [4,] 13.1199
> > > [5,]? 2.7775
> > > 
> > > Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> > > vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> > > replacement, addition, multiplication, and dumping will continue up 
> > > to the length of 'volinp' and the final output matrix 'vol' will be 
> > > something like:
> > > 
> > > ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> > > [1,] 13.13?? 1.9669?? 0.645697? ...
> > > [2,] 61.61? 41.2665? 24.488389? ...
> > > [3,] 25.25? 41.2232? 40.419786? ...
> > > [4,]? 0.00? 13.1199? 22.116099? ...
> > > [5,]? 0.00?? 2.7775?? 7.670905? ...?
> > > 
> > > Within my limited capacity, I've tried to come up with a solution 
> > > but failed.
> > > 
> > > I'll appreciate your/others' help with gratefulness.
> > > 
> > > Regards,
> > > 
> > > Halim
> > > 
> > > ---------------
> > > Md. Abdul Halim
> > > Assistant Professor
> > > Department of Forestry and Environmental Science
> > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > Bangladesh.
> > > Cell: +8801714078386.
> > > alt. e-mail: xou03 at yahoo.com
> > > 
> > > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > > > Hi,
> > > > Could you show your expected output?? It is a bit unclear from the 
> > > description.
> > > > 
> > > > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > > > fes at sust.edu> wrote: Dear R-friends,
> > > > 
> > > > Hope you doing well. I've been trying to deal with the following 
> > > > problem for the couple of days but couldn't come up with a solution. 
> > > > It would be great if any of you could give some insight into it.
> > > > 
> > > > I have three matrices like:
> > > > 
> > > > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> > > volinp<-
> > > > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > 
> > > > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > > > 
> > > > What I essentially want to do is to add each value in scvol[1,] with 
> > > > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > > > finally put the outputs in a new matrix.
> > > > 
> > > > Thanks in advance.
> > > > 
> > > > Halim? ? ? ? ? ? ? ? 
> > > > ---------------
> > > > Md. Abdul Halim
> > > > Assistant Professor
> > > > Department of Forestry and Environmental Science
> > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > Bangladesh.
> > > > Cell: +8801714078386.
> > > > alt. e-mail: xou03 at yahoo.com
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> 
> > 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com

-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From jim at bitwrit.com.au  Thu Nov 28 10:10:59 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 28 Nov 2013 20:10:59 +1100
Subject: [R] if, apply, ifelse
In-Reply-To: <CALxSy05Ed3NOzMBCGG127p_ppeoVoNfROfO=qDj8SL_c-TZNWQ@mail.gmail.com>
References: <CALxSy05Ed3NOzMBCGG127p_ppeoVoNfROfO=qDj8SL_c-TZNWQ@mail.gmail.com>
Message-ID: <529708A3.20904@bitwrit.com.au>

On 11/28/2013 04:33 AM, Andrea Lamont wrote:
> Hello:
>
> This seems like an obvious question, but I am having trouble answering it.
> I am new to R, so I apologize if its too simple to be posting. I have
> searched for solutions to no avail.
>
> I have data that I am trying to set up for further analysis ("training
> data"). What I need is 12 groups based on patterns of 4 variables. The
> complication comes in when missing data is present. Let  me describe with
> an example - focusing on just 3 of the 12 groups:
>...
> Any ideas on how to approach this efficiently?
>
Hi Andrea,
I would first convert the matrix "a" to a data frame:

a1<-as.data.frame(a)

Then I would start adding columns:

# group 1 is a 1 (logical TRUE) in col1 and at least one other 1
# here NAs are converted to zeros
a1$group1<-a1$col1 & (ifelse(is.na(a1$col2),0,a1$col2) |
  ifelse(is.na(a1$col3),0,a1$col3) |
  ifelse(is.na(a1$col4),0,a1$col4))
# group 2 is a 1 in col1 and no other 1s
# here NAs are converted to 1s
a1$group2<-a1$col1 & !(ifelse(is.na(a1$col2),1,a1$col2) |
  ifelse(is.na(a1$col3),1,a1$col3) |
  ifelse(is.na(a1$col4),1,a1$col4))
# here NAs are converted to 1s
a1$group3<-!ifelse(is.na(a1$col1),1,a1$col1)

and so on. It is clunky, but then you've got a clunky problem.

Jim


From jjonphl at gmail.com  Thu Nov 28 12:40:41 2013
From: jjonphl at gmail.com (Miguel Manese)
Date: Thu, 28 Nov 2013 19:40:41 +0800
Subject: [R] if, apply, ifelse
In-Reply-To: <529708A3.20904@bitwrit.com.au>
References: <CALxSy05Ed3NOzMBCGG127p_ppeoVoNfROfO=qDj8SL_c-TZNWQ@mail.gmail.com>
	<529708A3.20904@bitwrit.com.au>
Message-ID: <CAK2ScDgMwpUyPnYHXTzkSunzP7Vw-ZAr=bkCkHao_98pW4a6aA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/e31a499c/attachment.pl>

From giulia.dilauro at gmail.com  Thu Nov 28 12:12:05 2013
From: giulia.dilauro at gmail.com (Giulia Di Lauro)
Date: Thu, 28 Nov 2013 12:12:05 +0100
Subject: [R] help ANN
Message-ID: <CA+0e6-93nOk6qy+4yNWGQc2pr0HgSofoz2pJAOqQxYqcuFPM4g@mail.gmail.com>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/8a32f3a1/attachment.pl>

From matteo.ichino at gmail.com  Thu Nov 28 11:43:55 2013
From: matteo.ichino at gmail.com (Matteo Charlie Ichino)
Date: Thu, 28 Nov 2013 10:43:55 +0000
Subject: [R] ODE does not reach steady state and increase exponentially
Message-ID: <CAB_wXe_yeB-id1xO_2Ukff2PS-DytJykUi9AzNipFq_N=Eb8DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/ad89adc1/attachment.pl>

From merja.t.elo at luukku.com  Thu Nov 28 13:09:37 2013
From: merja.t.elo at luukku.com (M Elo)
Date: Thu, 28 Nov 2013 04:09:37 -0800 (PST)
Subject: [R] Multivariate dispersion & distances
Message-ID: <1385640577555-4681326.post@n4.nabble.com>

Dear All,

I'm using betadisper {vegan} and I'm interested not only in the dispersion
within the group but also the distances between the groups. With betadisper
I get distances to group centroids but is it possible to get distances to
other groups centroids? 

It might be possible to do it by hand by the formula given in the
description of the betadisper (below) but I'm a bit confused how to treat
the imaginary part there...

z[ij]^c = sqrt(Delta^2(u[ij]^+, c[i]^+) - Delta^2(u[ij]^-, c[i]^-))


I would highly appreciate all the help I can get!

-Merja





--
View this message in context: http://r.789695.n4.nabble.com/Multivariate-dispersion-distances-tp4681326.html
Sent from the R help mailing list archive at Nabble.com.


From eliza_botto at hotmail.com  Thu Nov 28 14:54:37 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 28 Nov 2013 13:54:37 +0000
Subject: [R] date format
Message-ID: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/b6c0684b/attachment.pl>

From jari.oksanen at oulu.fi  Thu Nov 28 15:35:25 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 28 Nov 2013 14:35:25 +0000
Subject: [R] Multivariate dispersion & distances
References: <1385640577555-4681326.post@n4.nabble.com>
Message-ID: <loom.20131128T152958-832@post.gmane.org>

M Elo <merja.t.elo <at> luukku.com> writes:

> 
> Dear All,
> 
> I'm using betadisper {vegan} and I'm interested not only in the dispersion
> within the group but also the distances between the groups. With betadisper
> I get distances to group centroids but is it possible to get distances to
> other groups centroids? 
> 
> It might be possible to do it by hand by the formula given in the
> description of the betadisper (below) but I'm a bit confused how to treat
> the imaginary part there...
> 
> z[ij]^c = sqrt(Delta^2(u[ij]^+, c[i]^+) - Delta^2(u[ij]^-, c[i]^-))
> 
> I would highly appreciate all the help I can get!

Merja,

You should do it exactly in the same way as you wrote above: subtract the
squared Euclidean distances in the imaginary part from the squared
Euclidean distances in the real part and take the square root. I think
doing this by hand is the only way to do this directly. The scope of 
the method is to compare dispersions within groups. There are other
tools to compare the locations of group centroids (adonis in vegan), but
they won't give you distances.

Cheers, Jari Oksanen


From gunter.berton at gene.com  Thu Nov 28 15:45:43 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 28 Nov 2013 06:45:43 -0800
Subject: [R] if, apply, ifelse
In-Reply-To: <529708A3.20904@bitwrit.com.au>
References: <CALxSy05Ed3NOzMBCGG127p_ppeoVoNfROfO=qDj8SL_c-TZNWQ@mail.gmail.com>
	<529708A3.20904@bitwrit.com.au>
Message-ID: <CACk-te0ZL+RdV8OvWn-nm2+RL7B_Pik-W40a69qtKB2ORY-z8A@mail.gmail.com>

Jim, et. al:

rowSums(a, na.rm=TRUE) ## Fast!

tells you whether you have 0, 1, or >= 1 TRUE in each row.
This can then be combined with the ifelse() conditions to get what the
OP seems to want. As you said, it's clunky, and is just a minor
simplification. But, then again, her logic seemed somewhat confusing.

Cheers,
Bert



On Thu, Nov 28, 2013 at 1:10 AM, Jim Lemon <jim at bitwrit.com.au> wrote:
> On 11/28/2013 04:33 AM, Andrea Lamont wrote:
>>
>> Hello:
>>
>> This seems like an obvious question, but I am having trouble answering it.
>> I am new to R, so I apologize if its too simple to be posting. I have
>> searched for solutions to no avail.
>>
>> I have data that I am trying to set up for further analysis ("training
>> data"). What I need is 12 groups based on patterns of 4 variables. The
>> complication comes in when missing data is present. Let  me describe with
>> an example - focusing on just 3 of the 12 groups:
>> ...
>> Any ideas on how to approach this efficiently?
>>
> Hi Andrea,
> I would first convert the matrix "a" to a data frame:
>
> a1<-as.data.frame(a)
>
> Then I would start adding columns:
>
> # group 1 is a 1 (logical TRUE) in col1 and at least one other 1
> # here NAs are converted to zeros
> a1$group1<-a1$col1 & (ifelse(is.na(a1$col2),0,a1$col2) |
>  ifelse(is.na(a1$col3),0,a1$col3) |
>  ifelse(is.na(a1$col4),0,a1$col4))
> # group 2 is a 1 in col1 and no other 1s
> # here NAs are converted to 1s
> a1$group2<-a1$col1 & !(ifelse(is.na(a1$col2),1,a1$col2) |
>  ifelse(is.na(a1$col3),1,a1$col3) |
>  ifelse(is.na(a1$col4),1,a1$col4))
> # here NAs are converted to 1s
> a1$group3<-!ifelse(is.na(a1$col1),1,a1$col1)
>
> and so on. It is clunky, but then you've got a clunky problem.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From bbolker at gmail.com  Thu Nov 28 16:07:29 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 28 Nov 2013 15:07:29 +0000
Subject: [R] date format
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
Message-ID: <loom.20131128T160643-841@post.gmane.org>

eliza botto <eliza_botto <at> hotmail.com> writes:

> 
> Dear Users of R,
> I have a data frame with three column, the first column contains years,
the second one months and third one,
> the days (cbind(yyyy mm dd)). I want to combine them so that i have one
column with the date format as (dd.mm.yyyy).
> Is there a way of doing that.
> Thanks in advance,
> Eliza 		 	   	

  I think just paste(dd,mm,yyyy,sep=".") should work fine (where 'dd','mm',
'yyyy' are references to your columns)


From eliza_botto at hotmail.com  Thu Nov 28 16:14:40 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 28 Nov 2013 15:14:40 +0000
Subject: [R] date format
In-Reply-To: <52975CC6.7070105@web.de>
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>,
	<52975CC6.7070105@web.de>
Message-ID: <BLU170-W12800EABBC3115C5D9E054C89EE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/37dcde83/attachment.pl>

From ruipbarradas at sapo.pt  Thu Nov 28 16:16:35 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 28 Nov 2013 15:16:35 +0000
Subject: [R] date format
In-Reply-To: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
Message-ID: <52975E53.1070001@sapo.pt>

Hello,

Maybe something like the following.

dat <- data.frame(yyyy = 2011:2013, mm = 1:3, dd = 4:6)

apply(dat, 1, function(x) paste(rev(x), collapse = "."))


Hope this helps,

Rui Barradas

Em 28-11-2013 13:54, eliza botto escreveu:
> Dear Users of R,
> I have a data frame with three column, the first column contains years, the second one months and third one, the days (cbind(yyyy mm dd)). I want to combine them so that i have one column with the date format as (dd.mm.yyyy).
> Is there a way of doing that.
> Thanks in advance,
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From eliza_botto at hotmail.com  Thu Nov 28 16:17:42 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 28 Nov 2013 15:17:42 +0000
Subject: [R] date format
In-Reply-To: <52975E53.1070001@sapo.pt>
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>,
	<52975E53.1070001@sapo.pt>
Message-ID: <BLU170-W79D2FB9CB6C7D1545E8F9589EE0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/aad837ec/attachment.pl>

From ulhaqz at gmail.com  Thu Nov 28 16:04:38 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Thu, 28 Nov 2013 20:04:38 +0500
Subject: [R] Relative Cumulative Frequency of Event Occurence
Message-ID: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/2ec970d3/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 28 16:10:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 07:10:26 -0800 (PST)
Subject: [R] date format
In-Reply-To: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
Message-ID: <1385651426.18660.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
dat1 <- data.frame(years=rep(1991:1992,12), months=rep(1:12,2),days= rep(1,24))
?dat1$day <- format(as.Date(paste(dat1[,1],sprintf("%02d",dat1[,2]),sprintf("%02d",dat1[,3]),sep="."),"%Y.%m.%d"),"%d.%m.%Y")
A.K.




On Thursday, November 28, 2013 8:56 AM, eliza botto <eliza_botto at hotmail.com> wrote:
Dear Users of R,
I have a data frame with three column, the first column contains years, the second one months and third one, the days (cbind(yyyy mm dd)). I want to combine them so that i have one column with the date format as (dd.mm.yyyy).
Is there a way of doing that.
Thanks in advance,
Eliza ??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Nov 28 16:24:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 07:24:09 -0800 (PST)
Subject: [R] date format
In-Reply-To: <52975E53.1070001@sapo.pt>
References: <BLU170-W299FA391A7F1D53D87F7F189EE0@phx.gbl>
	<52975E53.1070001@sapo.pt>
Message-ID: <1385652249.94695.YahooMailNeo@web142601.mail.bf1.yahoo.com>

#Or
?paste(dat[,3],dat[,2],dat[,1],sep=".")
#[1] "4.1.2011" "5.2.2012" "6.3.2013"
#
?as.character(interaction(dat[,3:1]))


?paste(sprintf("%02d",dat[,3]),sprintf("%02d",dat[,2]),dat[,1],sep=".")
#[1] "04.01.2011" "05.02.2012" "06.03.2013"


A.K.




On Thursday, November 28, 2013 10:18 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
Hello,

Maybe something like the following.

dat <- data.frame(yyyy = 2011:2013, mm = 1:3, dd = 4:6)

apply(dat, 1, function(x) paste(rev(x), collapse = "."))


Hope this helps,

Rui Barradas

Em 28-11-2013 13:54, eliza botto escreveu:
> Dear Users of R,
> I have a data frame with three column, the first column contains years, the second one months and third one, the days (cbind(yyyy mm dd)). I want to combine them so that i have one column with the date format as (dd.mm.yyyy).
> Is there a way of doing that.
> Thanks in advance,
> Eliza ??? ???  ??? ?  ??? ??? 
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Nov 28 17:11:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 08:11:20 -0800 (PST)
Subject: [R] Problems dealing with matrices
In-Reply-To: <20131128042927.M43811@sust.edu>
References: <20131123181936.M40852@sust.edu>
	<1385244612.73376.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<20131124051233.M87627@sust.edu>
	<1385281433.29640.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1385284698.38816.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<20131124103317.M34808@sust.edu>
	<1385307924.1089.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<20131127023716.M4379@sust.edu>
	<1385526074.98197.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<20131128042927.M43811@sust.edu>
Message-ID: <1385655080.66014.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Halim,

For the first two questions, you may try:
colsum1 <- colSums(volyrdc1)
min(which(colsum1>=18))
#[1] 29
#or
?head(which(colsum1>=18),1)
#140 
# 29?


colsum1[substr(colsum1,6,7)=="00"]? ## this is not very clear
???? 305 
45.37004?
#or
colsum1[colsum1>=18][substr(colsum1[colsum1>=18],6,7)=="00"]
???? 305 
45.37004 

#because
sprintf("%.4f",colsum1[colsum1>=18])
colsum1[colsum1>=18][gsub(".*\\.\\d{2}","",sprintf("%.4f",colsum1[colsum1>=18]))=="00"]
???? 180????? 305 
32.88996 45.37004 



A.K.




On Thursday, November 28, 2013 3:57 AM, halim10-fes <halim10-fes at sust.edu> wrote:
Hi,

Sorry for continuous bothering. Continuum of the previous problem...

I have the following matrices and vectors,

dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,0.00,0.00, 
? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,0.00,0.00,0.00,0.00, 
? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 

volini<-matrix(c(0,0,0,0,0),nrow=5,ncol=1)

volinp1<-c(0, 0.0004669094, 0.0027610861, 0.0086204692, 0.0200137754, 
0.0389069106 ,0.0670942588, 0.1060941424, 0.1570990708, 0.2209672605, 
0.2982420945, 0.3891882830, 0.4938361307, 0.6120278338, 0.7434618363, 
0.8877329008, 1.0443667375, 1.2128488387, 1.3926476912, 1.5832328410, 
1.7840884399, 1.9947229566, 2.2146757191, 2.4435209092, 2.6808695568, 
2.9263700050, 3.1797072430, 3.4406014299, 3.7088058696, 3.9841046430, 
4.2663100561, 4.5552600226, 4.8508154713, 5.1528578389, 5.4612866929,
5.7760175114, 6.0969796345, 6.4241143947, 6.7573734248, 7, 7 ,7, 7, 7, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 
7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,? 7,? 
7, 7, 7)


I've calculated the following matrices vol and volyrdc1 (obviously with the 
help of Jeff and Arun):

#Blank matrices for dumping final values

vol <- matrix( NA, nrow=5, ncol=length(volinp1))

volyrdc1<-matrix(NA, nrow=5,ncol=length(volinp1),dimnames= 
list(c("DC1","DC2","DC3","DC4","DC5"),c(seq(0,500,5))))

vol[ , 1 ] <- dcmat %*% (volini+(volinp1[1]*wt))

wt<-matrix(c(1,0,0,0,0),nrow=5)

for ( idx in seq_along(volinp1)[ -1 ] ) { 
? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp1[idx] * wt ) 
}? 

vol

volyrdc1[,1]<-vol[,1]

for ( idx in seq_along(volinp1)[ -1 ] ) { 
? volyrdc1[ , idx ] <- vol[ , idx-1 ] + volinp1[idx] * wt
? }? 
volyrdc1

My final matrix in 'volyrdc1' (kind of transition matrix model). 

Now, what I want to do is to calculate when the colsum<-colSums(volyrdc1) 
reaches a certain value and I want to get the index of the element in the 
'colsum' vector at that point. For e.g. when colsum[colsum>=18] ? It will give 
a series of cases where the condition is true. But I want index of the element 
immediately when the condition is met. In this case, the answer I want is 140 
(colsum[29] returns both value (18.63) and the character ("140") attributing 
the index). Actually, in my case 140 is year (age) when the 'colsum' becomes 
>=18. At is point it would be great if I can calculate when 'colsum' levels 
off (up to two decimal place)? The answer is: 305 and at that point 
colsum==45.37.? 

I also want to calculate what should be the value in volini[1,1] to get a 
certain value in 'colsum' at a certain year (age)(vector element index 
explained earlier)? For e.g. I want to find out that what should be the value 
in volini[1,1] if I want colsum==18 at 100(charater attributing colsum[21])? 
The answer is: 15910 and the 'volini' matrix will look like:

volini<-matrix(c(15910,0,0,0,0),nrow=5,ncol=1)

Any pointer, suggestions,... will be gratefully acknowledged.

P.S. Can you please suggest me any effective R programming book that describe 
core elements of R programming?

Thanks in advance.

Regards,

Halim? ? ? ? ? ? ? ? 
---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com







On Tue, 26 Nov 2013 20:21:14 -0800 (PST), arun wrote
> HI Halim,
> 
> No problem.
> Regards,
> Arun
> 
> On Tuesday, November 26, 2013 11:18 PM, halim10-fes <halim10-
> fes at sust.edu> wrote: Hi Arun,
> 
> Thanks for your help. Sorry for my late response. Take care and stay 
> fine.
> 
> Regards,
> 
> Halim
> 
> On Sun, 24 Nov 2013 07:45:24 -0800 (PST), arun wrote
> > Hi Halim,
> > I guess this works for you.? Modifying Jeff's solution:
> > 
> > volinp<-c(0,0.000467,0.002762,0.008621,0.020014,0.038907,0.067094)
> > vol1 <- dcmat %*% (volmat +wt)
> > for(idx in seq_along(volinp)[-1]){
> > ?vol1 <- cbind(vol1,dcmat %*% (vol1[,idx-1] + volinp[idx] *wt))
> > ?}
> > 
> > #or
> > 
> > vol <- matrix( NA, nrow=5, ncol=length( volinp ) )
> > vol[ , 1 ] <- dcmat %*% ( volmat + wt )
> > 
> > for ( idx in seq_along(volinp)[ -1 ] ) {
> > ? vol[ , idx ] <- dcmat %*% ( vol[ , idx-1 ] + volinp[idx] * wt )
> > }
> > identical(vol,vol1)
> > #[1] TRUE
> > 
> > A.K.
> > 
> > On Sunday, November 24, 2013 7:16 AM, halim10-fes <halim10-
> > fes at sust.edu> wrote: Hi Arun,
> > 
> > OK, no problem. Thank you very much for your attention. I've posted 
> > an annex to my previous problem. I will appreciate your 
> > comments/suggestions on it.
> > 
> > Off-topic: You're a very helpful man. I like your attitude to 
> > helping others.
> > 
> > Take care.
> > 
> > Halim
> > 
> > On Sun, 24 Nov 2013 01:18:18 -0800 (PST), arun wrote
> > > Hi,
> > > Please disregard my earlier message. Looks like Jeff understand it 
> > > better and answered it. Regards, Arun
> > > 
> > > On Sunday, November 24, 2013 3:23 AM, arun <smartpink111 at yahoo.com> 
wrote:
> > > Hi,
> > > I am finding some inconsistency with your description.
> > > For example:
> > > volinp[1]+volmat[1,1]
> > > [1] 101
> > > 
> > > On Sunday, November 24, 2013 1:52 AM, halim10-fes <halim10-
> > > fes at sust.edu> wrote:
> > > 
> > > Please apologize me! Earlier I've sent a message erroneously. 
> > > Following is the original problem for which I'm seeking help. 
> > > Extremely sorry...?
> > > 
> > > Hi Arun,
> > > 
> > > Thank you very much for your response. Sorry, if I couldn't explain 
> > > clearly. I think, I should restate the problem to get exactly what I 
> > > want. Here it goes:
> > > 
> > > I have 2 matrices and 1 vector, namely,
> > > 
> > > dcmat<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5)
> > > 
> > > volmat<-matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > 
> > > volinp<-c(1:40)
> > > 
> > > What I essentially want to do is to multiply 'dcmat' with 'volmat' 
> > > and dump the output in a new matrix 'vol'. But before that, in the 
> > > first step, I want to add volinp[1] with volmat[1,1]. So, the first 
> > > column of the output matrix 'vol' matrix will be:
> > > 
> > > ? ? ? ? [,1]
> > > [1,]?? 13.13
> > > [2,]?? 61.61
> > > [3,]?? 25.25
> > > [4,]? ? 0.00
> > > [5,]? ? 0.00
> > > 
> > > In the 2nd step, I want to replace 'volmat' with vol[,1] and add 
> > > volinp[2] with vol[1,1]. The new 'volmat' will look like:
> > > 
> > > ? ? ? ? [,1]
> > > [1,]?? 15.13
> > > [2,]?? 61.61
> > > [3,]?? 25.25
> > > [4,]? ? 0.00
> > > [5,]? ? 0.00
> > > 
> > > Then multiply 'dcmat' with the new 'volmat', and the 2nd column of 
> > > output matrix 'vol' will look like:
> > > 
> > > ? ? ? ? [,2]
> > > [1,]? 1.9669
> > > [2,] 41.2665
> > > [3,] 41.2232
> > > [4,] 13.1199
> > > [5,]? 2.7775
> > > 
> > > Then again, replace the 'volmat' with vol[,2], add volinp[3] with 
> > > vol[1,2] and multiply the new 'volmat' with 'dcmat'. This 
> > > replacement, addition, multiplication, and dumping will continue up 
> > > to the length of 'volinp' and the final output matrix 'vol' will be 
> > > something like:
> > > 
> > > ? ? ? [,1]? ? [,2]? ? ? [,3]? ? ...length(volinp)
> > > [1,] 13.13?? 1.9669?? 0.645697? ...
> > > [2,] 61.61? 41.2665? 24.488389? ...
> > > [3,] 25.25? 41.2232? 40.419786? ...
> > > [4,]? 0.00? 13.1199? 22.116099? ...
> > > [5,]? 0.00?? 2.7775?? 7.670905? ...?
> > > 
> > > Within my limited capacity, I've tried to come up with a solution 
> > > but failed.
> > > 
> > > I'll appreciate your/others' help with gratefulness.
> > > 
> > > Regards,
> > > 
> > > Halim
> > > 
> > > ---------------
> > > Md. Abdul Halim
> > > Assistant Professor
> > > Department of Forestry and Environmental Science
> > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > Bangladesh.
> > > Cell: +8801714078386.
> > > alt. e-mail: xou03 at yahoo.com
> > > 
> > > On Sat, 23 Nov 2013 14:10:12 -0800 (PST), arun wrote
> > > > Hi,
> > > > Could you show your expected output?? It is a bit unclear from the 
> > > description.
> > > > 
> > > > On Saturday, November 23, 2013 2:00 PM, halim10-fes <halim10-
> > > > fes at sust.edu> wrote: Dear R-friends,
> > > > 
> > > > Hope you doing well. I've been trying to deal with the following 
> > > > problem for the couple of days but couldn't come up with a solution. 
> > > > It would be great if any of you could give some insight into it.
> > > > 
> > > > I have three matrices like:
> > > > 
> > > > dcvol<-matrix(c(0.13,0.61,0.25,0.00,0.00,0.00,0.52,0.37,0.09,0.00,
> > > > 0.00,0.00, ? ? ? ? ? ? ? ? 0.58,0.30,0.11,0.00,0.00,0.00,0.46,0.22,
> > > > 0.00,0.00,0.00,0.00, ? ? ? ? ? ? ? ? 0.09),nrow=5,ncol=5) 
> > > volinp<-
> > > > matrix(c(100,0,0,0,0),nrow=5,ncol=1)
> > > > 
> > > > scvol<-matrix(c(1:40),nrow=5,ncol=8)
> > > > 
> > > > What I essentially want to do is to add each value in scvol[1,] with 
> > > > the volinp[1,1] and then multiply each new volinp with dcvol and 
> > > > finally put the outputs in a new matrix.
> > > > 
> > > > Thanks in advance.
> > > > 
> > > > Halim? ? ? ? ? ? ? ? 
> > > > ---------------
> > > > Md. Abdul Halim
> > > > Assistant Professor
> > > > Department of Forestry and Environmental Science
> > > > Shahjalal University of Science and Technology,Sylhet-3114,
> > > > Bangladesh.
> > > > Cell: +8801714078386.
> > > > alt. e-mail: xou03 at yahoo.com
> > > > 
> > > > -- 
> > > > This message has been scanned for viruses and
> > > > dangerous content by MailScanner, and is
> > > > believed to be clean.
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.
> > > 
> > > -- 
> > > This message has been scanned for viruses and
> > > dangerous content by MailScanner, and is
> > > believed to be clean.

> 
> > 
> > ---------------
> > Md. Abdul Halim
> > Assistant Professor
> > Department of Forestry and Environmental Science
> > Shahjalal University of Science and Technology,Sylhet-3114,
> > Bangladesh.
> > Cell: +8801714078386.
> > alt. e-mail: xou03 at yahoo.com
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> > 
> > -- 
> > This message has been scanned for viruses and
> > dangerous content by MailScanner, and is
> > believed to be clean.
> 
> ---------------
> Md. Abdul Halim
> Assistant Professor
> Department of Forestry and Environmental Science
> Shahjalal University of Science and Technology,Sylhet-3114,
> Bangladesh.
> Cell: +8801714078386.
> alt. e-mail: xou03 at yahoo.com
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> -- 
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.


---------------
Md. Abdul Halim
Assistant Professor
Department of Forestry and Environmental Science
Shahjalal University of Science and Technology,Sylhet-3114,
Bangladesh.
Cell: +8801714078386.
alt. e-mail: xou03 at yahoo.com

-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.


From smartpink111 at yahoo.com  Thu Nov 28 17:40:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 08:40:12 -0800 (PST)
Subject: [R] Relative Cumulative Frequency of Event Occurence
In-Reply-To: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>
References: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>
Message-ID: <1385656812.66472.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
From the dput() version of df.1, it looks like you want:
cumsum(df.1[,4]=="Yes")/seq_len(nrow(df.1))
?[1] 0.0000000 0.5000000 0.3333333 0.2500000 0.4000000 0.3333333 0.4285714
?[8] 0.5000000 0.4444444 0.5000000


A.K.


On Thursday, November 28, 2013 11:26 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:
Hi,

My objective is to calculate "Relative (Cumulative) Frequency of Event
Occurrence" - something as follows:

Sample.Number 1st.Fly 2nd.Fly? Did.E.occur? Relative.Cum.Frequency.of.E
1 G B No 0.000
2 B B Yes 0.500
3 B G No 0.333
4 G B No 0.250
5 G G Yes 0.400
6 G B No 0.333
7 B B Yes 0.429
8 G G Yes 0.500
9 G B No 0.444
10 B B Yes 0.500

Please refer to the code below:
##############################################################
# 1.
v.fly=c("G","B") # Outcome is Green or Blue fly

# 2.
n=10 # No of Events / Trials

# 3.
v.smp = seq(1:n) # Event Id

# 4.
v.fst = sample(v.fly,n,rep=T) # Simulating First Draw

# 5.
v.sec = sample(v.fly,n,rep=T)? # Simulating Second Draw

# 6.
df.1 = data.frame(sample = v.smp, fst=v.fst, sec = v.sec) # Clumping in a DF

# 7.
df.1$E.Occur = with(df.1, ifelse(fst==sec,TRUE,FALSE)) # Event Occurs, if
color is same in both the the draws

# 8.
df.1$Rel.Freq = with(df.1, cumsum(E.occur)/(E.Occur)) # Relative Frequency
>> This line does NOT work, and needs to fix the denominator part
##############################################################

Problem is with #8, specifically the part:
cumsum(E.occur)/(E.Occur)

The denominator E.Occur is a fixed value, instead of a moving count. I have
tried nrow(), length() but none provides a moving version of row count, as
cumsum does for the "True" values, occurring so far.

> dput(df.1)
structure(list(Sample.Number = 1:10, X1st.Fly = c("G", "B", "B",
"G", "G", "G", "B", "G", "G", "B"), X2nd.Fly = c("B", "B", "G",
"B", "G", "B", "B", "G", "B", "B"), Did.E.occur. = c("No", "Yes",
"No", "No", "Yes", "No", "Yes", "Yes", "No", "Yes"),
Relative.Cum.Frequency.of.E = c(0,
0.5, 0.333, 0.25, 0.4, 0.333, 0.429, 0.5, 0.444, 0.5)), .Names =
c("Sample.Number",
"X1st.Fly", "X2nd.Fly", "Did.E.occur.", "Relative.Cum.Frequency.of.E"
), class = "data.frame", row.names = c(NA, -10L))


Cheers !

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ft122310 at ohio.edu  Thu Nov 28 17:46:56 2013
From: ft122310 at ohio.edu (Castro, Salvador)
Date: Thu, 28 Nov 2013 11:46:56 -0500
Subject: [R] normal curve on the diagonal of pairs
Message-ID: <2AFEC8FF-5ED4-4721-B5BD-E66209F609A9@ohio.edu>

Hi
I am trying to add the normal curve on the diagonal of a matrix scatter plot. The code below works if I plot a single histogram with the normal curve but not placed on the diagonal of the matrix. Plots attached. Thank you for your time. 
-SC

This code doesn?t produce normal curves correctly:
# Matrix Scatter Plot for the test multicollinearity and linear relationship between each pair of dependent variables
# ********************************************************************************************************
# panel.smooth function is built in.
# panel.cor puts correlation in upper panels, size proportional to correlation
panel.cor <- function(x, y, digits=3, prefix="", cex.cor, ...)
{
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, col = "red", cex = cex.cor * r)
}

## put histograms on the diagonal
panel.hist <- function(x, ...)
{
  usr <- par("usr")
  on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = F)
  breaks <- h$breaks
  nB <- length(breaks)
  y <- h$counts 
  y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)

  # Add a Normal Curve
  xfit <- seq(min(x, na.rm = T), max(x, na.rm = T), length = 40) 
  yfit <- dnorm(xfit, mean = mean (x, na.rm = T), sd = sd(x, na.rm = T)) 
  yfit <- yfit*diff(h$mids[1:2])*length(x) 
  lines(xfit, yfit, col = "blue", lwd = 2)
}

quartz(title="", 8, 8)
pairs(~achieve + evaluation + aptitude + affect, data = components, 
      lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist,
      main="Scatterplot Matrix with Correlations", na.action = stats::na.pass, pch = 21,
      bg = c("#1E90FF", "#ADFF2F")[unclass(components$passfail)])


However, this code produces the normal curve correctly:

quartz(title="Histograms")
layout(matrix(c(1,2,3,4),2,2)) #divide graph  
h <- hist(na.omit(components$affect), breaks = "Sturges", xlab="achievement", include.lowest = TRUE, 
             right = TRUE, density = NULL, angle = 45, border = NULL,
             main="Histogram with Normal Curve", col="red",
             axes = TRUE, plot = TRUE, labels = FALSE, warn.unused = TRUE) 

xfit <- seq(min(components$affect, na.rm = T), max(components$affect, na.rm = T), length=40) 
yfit<-dnorm(xfit, mean = mean (components$affect, na.rm = T),sd = sd(components$affect, na.rm = T)) 
yfit <- yfit*diff(h$mids[1:2])*length(components$affect) 
lines(xfit, yfit, col="blue", lwd=2)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.pdf
Type: application/pdf
Size: 460885 bytes
Desc: Rplot.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/d561701c/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot03.pdf
Type: application/pdf
Size: 4983 bytes
Desc: Rplot03.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/d561701c/attachment-0001.pdf>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ATT00001.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/d561701c/attachment.txt>

From gervais.jesse at courrier.uqam.ca  Thu Nov 28 19:23:48 2013
From: gervais.jesse at courrier.uqam.ca (Jesse Gervais)
Date: Thu, 28 Nov 2013 13:23:48 -0500
Subject: [R] polychoric correlation with multiple imputations,
	a Strate and a Weight
Message-ID: <CADfL=7Y_NanXhV+v05zM_aKE+CFyg0+g8RUyGZ14owiU11uqjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/a90d3312/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 28 18:12:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 09:12:09 -0800 (PST)
Subject: [R] Assiging name to ip address range
Message-ID: <1385658729.49774.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi , 


If it is like:


vec1 <- c("10.20.30.01","10.20.30.02","10.20.30.40","10.20.30.41","10.20.30.45","10.20.30.254","10.20.30.255","10.20.30.256","10.20.30.313")
vec2 <- as.numeric(paste0(gsub("^\\d{2}\\.\\d{2}\\.(\\d{2}\\.).*","\\1",vec1),sprintf("%03d",as.numeric(gsub("^\\d{2}\\.\\d{2}\\.\\d{2}\\.","",vec1)))))
?as.character(cut(vec2,breaks=c(30,30.040,30.255,30.313),labels=paste0("SKH",1:3)))
#[1] "SKH1" "SKH1" "SKH1" "SKH2" "SKH2" "SKH2" "SKH2" "SKH3" "SKH3"


#or if the column is:
dat1 <- data.frame(iprange =c("10.20.30.01 - 10.20.30.40", "10.20.30.40 - 10.20.30.255"))
?dat1[,1] <- factor(dat1[,1],labels=paste0("SKH",1:2))
A.K.




I have an ip address column in my dataset which r read as factor.I want to create a new variable for a range 
like if 10.20.30.01 - 10.20.30.40 then SKH1 
? ? ?if 10.20.30.40 -10.20.30.255 then SKH2 & so on 

10.20 will always remian same ,other values will change 
I have around 500 values which i want to assign as per ip address.i 
am not able to use greater than or less than function .please advise how
 to do that. 

Thanks!! 



From o.irazoki at gmail.com  Thu Nov 28 18:18:10 2013
From: o.irazoki at gmail.com (Gmail)
Date: Thu, 28 Nov 2013 18:18:10 +0100
Subject: [R] Counting variables repeted in dataframe columns to create a
 presence-absence table
Message-ID: <52977AD2.70509@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131128/1ac79cc9/attachment.pl>

From smartpink111 at yahoo.com  Thu Nov 28 18:57:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 09:57:07 -0800 (PST)
Subject: [R] Adding NA values in random positions in a dataframe
Message-ID: <1385661427.78119.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
One way would be:
?set.seed(42)
?dat1 <- as.data.frame(matrix(sample(c(1:5,NA),50,replace=TRUE,prob=c(10,15,15,20,30,10)),ncol=5))
set.seed(49)
?dat1[!is.na(dat1)][ match( sample(seq(dat1[!is.na(dat1)]),length(dat1[!is.na(dat1)])*(0.20)),seq(dat1[!is.na(dat1)]))] <- NA
length(dat1[is.na(dat1)])/length(unlist(dat1))
#[1] 0.28

A.K.


Hello, I'm quite new at R so I don't know which is the most efficient 
way to execute a function that I could write easily in other languages. 

This is my problem: I have a dataframe with a certain numbers of
 NA (approximately 10%). I want to add other NA values in random 
positions of the dataframes until reaching an overall proportions of NA 
values of 30% (clearly the positions with NA values don't have to 
change). I tried looking at iterative function in R as apply or sapply 
but I can't actually figure out how to use them in this case. Thank you.


From dwinsemius at comcast.net  Thu Nov 28 21:28:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 Nov 2013 12:28:35 -0800
Subject: [R] importing many csv files into separate matrices
In-Reply-To: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>
References: <1385591991.65178.YahooMailBasic@web184301.mail.ne1.yahoo.com>
Message-ID: <B2DE5640-EB47-4CAB-8635-9A5E4B50544D@comcast.net>


On Nov 27, 2013, at 2:39 PM, yetik serbest wrote:

> Hi Everyone,
>  
> I am trying to import many CSV files to their own matrices. Example, alaska_93.csv to alaska. When I execute the following, for each csv.file separately it is successful.
>  
> singleCSVFile2Matrix <- function(x,path) {
>  assign(gsub(pattern=".csv",x,replacement=""),read.csv(paste(path,x,sep="")))
> }
>  
> when I try to include it in a loop in another function (I have so many csv files to import), it doesn't work. I mean the following function doesn't do it.
>  
> loadCSVFiles_old <- function(path) {
>  x <- list.files(path)
>  for (i in 1:length(x)) {
>   assign(gsub(pattern=".csv",x[i],replacement=""),read.csv(paste(path,x[i],sep="")))
>   }
> }

It appears you are not returning the values that you created inside that function to the global environment. I would have expected that you would either given `assign` an environment argument or that you would have created a list of items to return from the function.

?environment
?assign

Perhaps:

loadCSVFiles_old <- function(path) {
 x <- list.files(path)
 for (i in 1:length(x)) {
  assign(gsub(pattern=".csv",x[i],replacement=""),
         read.csv(paste(path,x[i],sep="")))
         envir=.GlobalEnv
  }
}



>  
> Instead, if I execute the foor loop in the command line, it works. I am puzzled. Appreciate any help.
>  
> thanks
> yetik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Nov 28 20:57:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Nov 2013 11:57:22 -0800 (PST)
Subject: [R] Counting variables repeted in dataframe columns to create a
	presence-absence table
In-Reply-To: <52977AD2.70509@gmail.com>
References: <52977AD2.70509@gmail.com>
Message-ID: <1385668642.77281.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Try:
data_m <- read.table(text="Abortusovis07918 Agona08561 Anatum08125 Arizonae65S Braenderup08488
1????? S5305B_IGR S5305B_IGR? S5305B_IGR? S5305B_IGR S5305B_IGR
2????? S5305A_IGR S5300A_IGR? S5305A_IGR? S5300A_IGR S5300A_IGR
3????? S5300A_IGR S5300B_IGR? S5300A_IGR? S5300B_IGR S5300B_IGR
4????? S5300B_IGR S5299B_IGR? S5300B_IGR? S5299B_IGR S5299B_IGR
5????? S5299B_IGR S5299A_IGR? S5299B_IGR? S5829B_IGR S5299A_IGR",sep="",header=TRUE,stringsAsFactors=FALSE)
?data_m$new <-1
library(reshape2)
?dM <- melt(data_m,id.vars="new")
xtabs(new~value+variable,dM)
#or
?dcast(dM,value~variable,value.var="new",fill=0)


A.K.


On Thursday, November 28, 2013 12:18 PM, Gmail <o.irazoki at gmail.com> wrote:
Hi!

I'm new in R and I'm writing you asking for some guidance. I had 
analyzed a comparative genomic microarray data of /56 Salmonella/ 
strains to identify absent genes in each of the serovars, and finally I 
got a matrix that looks like that:

> data[1:5,1:5]
?  Abortusovis07918 Agona08561 Anatum08125 Arizonae65S Braenderup08488
1? ? ?  S5305B_IGR S5305B_IGR? S5305B_IGR? S5305B_IGR S5305B_IGR
2? ? ?  S5305A_IGR S5300A_IGR? S5305A_IGR? S5300A_IGR S5300A_IGR
3? ? ?  S5300A_IGR S5300B_IGR? S5300A_IGR? S5300B_IGR S5300B_IGR
4? ? ?  S5300B_IGR S5299B_IGR? S5300B_IGR? S5299B_IGR S5299B_IGR
5? ? ?  S5299B_IGR S5299A_IGR? S5299B_IGR? S5829B_IGR S5299A_IGR

The variables corresponds to those genes identified as absent in each of 
the serovars. I would like to create a presence-absence matrix of those 
genes comparing all the serovars at the same time, I assume that should 
not be complicated but I don't know how to do it.

I would like a matrix similar to the next one:

> data_m[1:5,1:5]
? ? ? ? ? ? ?  Abortusovis07918 Agona08561 Anatum08125 Arizonae65S 
Braenderup08488
S5305B_IGR? ? ? ? ? 1? ? ? ? ? ? ? ? 1? ? ? ? ?  1? ? ? ? 1? ? ? 1
S5305A_IGR? ? ? ? ? 1? ? ? ? ? ? ? ? 0? ? ? ? ?  1? ? ? ? 0? ?  0
S5300A_IGR? ? ? ? ? 1? ? ? ? ? ? ? ? 1? ? ? ? ?  1? ? ? ? 1? ? ? 1

Any help would be welcome, and thank you in advance,

Oihane


-- 

Oihane Irazoki Sanchez
PhD Student, Molecular Microbiology

Genetics and Microbiology Department, Faculty of Biosciences
Autonomous University of Barcelona
08193 Bellaterra (Barcelona), Spain

Telf: 34 - 935 811 665
E-mail: oihane.irazoki at uab.cat / o.irazoki at gmail.com


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From calum at callingthetune.co.uk  Fri Nov 29 11:07:11 2013
From: calum at callingthetune.co.uk (Calum Galleitch)
Date: Fri, 29 Nov 2013 10:07:11 +0000
Subject: [R] Formatting output of plotKML
Message-ID: <CALbM3JMRpNLkqQQh1nnQQ4POSRHFCoG_zrgS=0rNBA5h6M1KCg@mail.gmail.com>

Hello,

I previously submitted the below query to r-sig-geo, but have had no
response.  Before I start bothering individual maintainers, I wonder
if anyone on this list has any experience with the package and (or!)
can diagnose my problems?

Thanks,
Calum

Hello,

I am having a little trouble with plotKML and I am not sure whether to
ascribe it to my incompetence (most likely), incomplete documentation,
or other incorrect behaviour.

My aim is to produce a display in Google Earth visualising point data,
and I wish to control the size, label, and colour of these points. I
have succesfully achieved the first two but am struggling a little to
achieve the latter. I have attached my test data below along with the
script I am using and sessionInfo(). The test data is in the UK's
National Grid co-ordinate system so it gets converted before writing
out as a SpacialPointsDataFrame.

According to the ?plotKML documentation there is a colour argument;
however attempting to call it with a vector of required colours fails:

> plotKML(map_data_lat_long,
+ file.name='test.kml',
+ points_names = map_data_lat_long at data$Label,
+ colour = col2kml("red") # or map_data_lat_long at data$colour -
with or without col2kml
+ )
Error in `[.data.frame`(obj at data, , as.character(colour)) :
undefined columns selected

Suspecting a localisation issue I tried color instead. This did not
error, however it just generated the default colour palette. Other
incantations of various sorts have not really helped, including
replacing named colours with the output of col2kml in the data.

I have tried to use kml_aes but it's not very clear to me how it is to be used.

Any advice will be most welcome, even if just possible avenues to
attack. Also, I am not wedded by any means to plotKML and suggestions
for similar methods to achieve the same ends would also be helpful.

Many thanks,
Calum

test.csv:

xCord,yCord,size,Label,colour
532063,180615,14854874,Label A 1,red
537441,179551,851711370,Label A 2,red
560496,193284,652296152,Label A 3,red
324608,673413,936830099,Label A 4,red
532912,181045,734565801,Label B1,yellow
533045,181729,213722268,Label B2,yellow
530997,181334,104685106,Label B3,yellow
412716,94732,129014315,Label B4,yellow
532922,182308,385289711,Label B5,yellow
412782,93652,203823599,Label B6,yellow
533087,181376,666606649,Label B7,yellow
257763,665929,270940754,Label B8,yellow
410777,91722,442497572,Label B9,yellow
529425,181882,784422025,Label B10,yellow
532099,181799,679613728,Label B11,yellow
317524,671657,15213991,Label B12,yellow
532083,181106,51632818,Label B13,yellow
538538,181218,753123608,Label B14,yellow
409275,183852,916308988,Label B15,yellow
410525,91826,315714830,Label B16,yellow
531754,181472,533400391,Label B17,yellow
531283,180728,555929970,Label C1,green
532626,182039,873479599,Label C2,green
531808,180688,646380547,Label C3,green
531420,180361,672470450,Label C4,green
406677,287059,570024001,Label C5,green
360081,173983,877518563,Label C6,green
531881,180954,31953847,Label C7,green
533121,181183,983234849,Label C8,green
532923,180402,247198656,Label C9,green
532462,181973,442823961,Label C10,green
261791,669595,730094270,Label C11,green
459422,302817,884024369,Label D1,blue
429471,434310,235268642,Label D2,blue
379879,395710,674285057,Label D3,blue
384301,398337,920018841,Label D4,blue
624079,309248,317068333,Label D5,blue
625735,310478,944036809,Label D6,blue
622527,307366,269074659,Label D7,blue
629426,308707,796105708,Label D8,blue
628978,309282,469163049,Label D9,blue
309342,722860,550759988,Label D10,blue
433071,384763,205810120,Label D11,blue
433895,389174,859445905,Label D12,blue
443319,118260,662205408,Label D13,blue
459825,451261,465489204,Label D14,blue
459630,451405,807818766,Label D15,blue

Script:

# Load required libraries
library("plotKML")

# Read data
csvFile <- "test.csv"
map_data <- read.csv(csvFile, header=TRUE)

# Specify what are the x, y columns and create co-ordinate system
coordinates( map_data ) <- c("xCord","yCord")
proj4string( map_data ) <- CRS("+init=epsg:27700")

# Convert OS grid to lat/long
map_data_lat_long <- spTransform( map_data, CRS("+proj=longlat +datum=WGS84"))

# Carry out plotting
kml_aes(map_data_lat_long, colour=
col2kml(map_data_lat_long at data$colour)) #unsure about this!
plotKML(map_data_lat_long,
file.name='test.kml',
points_names = map_data_lat_long at data$Label
)


> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats graphics grDevices utils datasets methods base

other attached packages:
[1] plotKML_0.3-8 sp_1.0-12

loaded via a namespace (and not attached):
[1] aqp_1.5-3 cluster_1.14.4 colorRamps_2.3 colorspace_1.2-4
[5] dichromat_2.0-0 dismo_0.8-17 grid_3.0.2 gstat_1.0-17
[9] Hmisc_3.12-2 intervals_0.14.0 labeling_0.2 lattice_0.20-23
[13] munsell_0.4.2 pixmap_0.4-11 plotrix_3.5-2 plyr_1.8
[17] raster_2.1-49 RColorBrewer_1.0-5 reshape_0.8.4 rgdal_0.8-11
[21] rpart_4.1-3 RSAGA_0.93-6 scales_0.2.3 spacetime_1.0-9
[25] stringr_0.6.2 tools_3.0.2 XML_3.98-1.1 xts_0.9-7
[29] zoo_1.7-10


From S.Ellison at lgcgroup.com  Fri Nov 29 14:49:34 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 29 Nov 2013 13:49:34 +0000
Subject: [R] help ANN
In-Reply-To: <CA+0e6-93nOk6qy+4yNWGQc2pr0HgSofoz2pJAOqQxYqcuFPM4g@mail.gmail.com>
References: <CA+0e6-93nOk6qy+4yNWGQc2pr0HgSofoz2pJAOqQxYqcuFPM4g@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED56C98AEE7A@GOLD.corp.lgc-group.com>

> I would like to create an artificial neural network with R but I don't know its
> parameters jet (number of layers, number of neurons,...).
> I downloaded the package ANN and I use the function "ANNGA", but I'm
> afraid I haven't really created a neural network. In fact, at the end of the
> process I have just this output:
> 
> Call:
> ANNGA.default(x = input, y = output, design = c(1, 3, 1), population = 100,
>     mutation = 0.2, crossover = 0.6, maxW = 10, minW = -10, maxGen = 1000,
>     error = 0.001)
> 
> **********************************************************
> ******************
> Mean Squared Error------------------------------> 0.01148523
> R2----------------------------------------------> 0.6918387
> Number of generation----------------------------> 1001 Weight range at
> initialization------------------> [ 10 , -10 ] Weight range resulted from the
> optimisation-----> [ 13.58698 , -12.93606 ]
> **********************************************************
> ******************
> 
> Well, I would like to know if there is in ANN a function to *create* a neural
> network and if not, which package I have to download, Nnet?

What you have done is create an ANN object, print it's summary information and then discard it.

if you want to keep it and use it for something, assign it to a variable; for example:

my.ANN <- ANNGA.default(x = input, y = output, design = c(1, 3, 1), population = 100,
     mutation = 0.2, crossover = 0.6, maxW = 10, minW = -10, maxGen = 1000,
     error = 0.001)

You can then inspect, print, or predict with the object my.ANN. For example, you can say simply 
predict(my.ANN) 

to see the output values predicted for the inputs you supplied.

This goes for a lot of R fitting functions; they return objects which are printed and discarded unless you assign them to something.


S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From rh at knut-krueger.de  Fri Nov 29 15:18:00 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 29 Nov 2013 15:18:00 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <52933D4B.90803@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de>
Message-ID: <5298A218.2090303@knut-krueger.de>

Am 25.11.2013 13:06, schrieb Knut Krueger:
>
>> how can I read exel files where the decimal sign is comma instead dot.
>> I get the data as ascii and when converting "3,5" with as.numeric 
>> the  3,5 will be converted to NA 
>
I think here is a major bug because no warning is genereated.
It is impossible to change  excel to dot decimal separator.
First reason it is unusual  in our (and I think also  other countries).
Lot of computers in the university are using decimal separator mostly 
without R. The user would be  unable (or simply do not want) to use it 
furthermore.

A question
does anybody know whether Rcmdr and XLConnect are using the same or 
different ways to import Excel?
We found also that RCmdr is setting comma separated values to na if 
there is an NA in the column.

Maybe it more useful to discuss this in the devel group?  (set the 
follow up to DEVEL)

Knut


From laubuzdugan at gmail.com  Fri Nov 29 15:12:18 2013
From: laubuzdugan at gmail.com (Laura Buzdugan)
Date: Fri, 29 Nov 2013 15:12:18 +0100
Subject: [R] Lasso function that can handle NA values
Message-ID: <50C6EDB5-3AAF-416D-801D-36A47D1E1F41@gmail.com>

Hi everyone,

I have a large dataset with missing values. I tried using glmnet, but it seems that it cannot handle NA values in the design matrix. I also tried lars, but I get an error too. Does anyone know of any package for computing the lasso solution which handles NA values?

From gunter.berton at gene.com  Fri Nov 29 16:58:49 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 29 Nov 2013 07:58:49 -0800
Subject: [R] Lasso function that can handle NA values
In-Reply-To: <50C6EDB5-3AAF-416D-801D-36A47D1E1F41@gmail.com>
References: <50C6EDB5-3AAF-416D-801D-36A47D1E1F41@gmail.com>
Message-ID: <CACk-te2-YbFC6dF36w2eioAjnOq6KAAkbcyaQatyWtkwFYEG_g@mail.gmail.com>

?na.omit

??

But it is certainly true that omitting missing values first and
analyzing the remaining data can:

1. Leave you with no data to analyze

2. Result in biased and misleading conclusions if the missingness
mechanism is related to the covariates.

In general, handling data with missing values properly can be a very
difficult  or even insoluble problem. You may wish to consult with a
local statistician knowledgeable in such matters (I am not, for
example).

Cheers,
Bert

On Fri, Nov 29, 2013 at 6:12 AM, Laura Buzdugan <laubuzdugan at gmail.com> wrote:
> Hi everyone,
>
> I have a large dataset with missing values. I tried using glmnet, but it seems that it cannot handle NA values in the design matrix. I also tried lars, but I get an error too. Does anyone know of any package for computing the lasso solution which handles NA values?
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From dwinsemius at comcast.net  Fri Nov 29 18:31:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 Nov 2013 09:31:23 -0800
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <5298A218.2090303@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
Message-ID: <5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>


On Nov 29, 2013, at 6:18 AM, Knut Krueger wrote:

> Am 25.11.2013 13:06, schrieb Knut Krueger:
>> 
>>> how can I read exel files where the decimal sign is comma instead dot.
>>> I get the data as ascii and when converting "3,5" with as.numeric the  3,5 will be converted to NA 
>> 
> I think here is a major bug because no warning is genereated.

You were already advised how to change the defaults for R's input functions' behaviors with respect to decimal separators. (I would add that you should also become familiar with the 'colClasses' argument.)


> It is impossible to change  excel to dot decimal separator.
> First reason it is unusual  in our (and I think also  other countries).
> Lot of computers in the university are using decimal separator mostly without R. The user would be  unable (or simply do not want) to use it furthermore.
> 
> A question
> does anybody know whether Rcmdr and XLConnect are using the same or different ways to import Excel?

Rcmdr: same ; XLConnect:different

You should read the help pages for XLConnect.

> We found also that RCmdr is setting comma separated values to na if there is an NA in the column.
> 
> Maybe it more useful to discuss this in the devel group?  (set the follow up to DEVEL)

No. This is more a sign of your lack of experience with R. There are wiki-pages with advice about various ways to do Excel input. (You surely cannot think you are the first to experience this. This has been a difficulty for 15 years, and more with Excel than with R.)


> 
> Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rh at knut-krueger.de  Fri Nov 29 19:30:36 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Fri, 29 Nov 2013 19:30:36 +0100
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
Message-ID: <5298DD4C.1080404@knut-krueger.de>

Am 29.11.2013 18:31, schrieb David Winsemius:
> On Nov 29, 2013, at 6:18 AM, Knut Krueger wrote:
>
>> Am 25.11.2013 13:06, schrieb Knut Krueger:
>>>> how can I read exel files where the decimal sign is comma instead dot.
>>>> I get the data as ascii and when converting "3,5" with as.numeric the  3,5 will be converted to NA
>> I think here is a major bug because no warning is genereated.
> You were already advised how to change the defaults for R's input functions' behaviors with respect to decimal separators. (I would add that you should also become familiar with the 'colClasses' argument.)
? I was adviced:
> ither change comma to dot in Excel (but sometimes Excel is rather reluctant to accept such changes).
Thats impossible, we are used to hit the comma
>
> Or change commaa to dot in R which probably can be easily done by gsub command
Thats also impossible because the data are lost after teh import
>
> Or read data with option dec=",". I do not know XLConnect but in read.table it is optional parameter and maybe it is also readWorksheet.
Read data has no problem
> does anybody know whether Rcmdr and XLCOnnectare using the same or different ways to import Excel?
> Rcmdr: same ; XLConnect:different
>
> You should read the help pages for XLConnect.
http://cran.r-project.org/web/packages/XLConnect/XLConnect.pdf
sorry I did not found anything.
>
>> We found also that RCmdr is setting comma separated values to na if there is an NA in the column.
>>
>> Maybe it more useful to discuss this in the devel group?  (set the follow up to DEVEL)
> No. This is more a sign of your lack of experience with R. There are wiki-pages with advice about various ways to do Excel input. (You surely cannot think you are the first to experience this. This has been a difficulty for 15 years, and more with Excel than with R.)

Once again I have no problems to get the data inside R but I am looking 
for a solution to get an error message instead of setting 0,25 to na and 
only i a few column not in the hole sheet. That's a behaviour what I am 
expecting from MS not from R
But I got definitely wrong inputs with lost data with loadWorkbook. But 
it is not reproducable. doing the same  with a fresh environment,not 
after working 5 hours with R,  the excel sheet is imported without 
error. I am no a newbie in R and i am using it nearly 10 years. Them 
same problem occoured with RCmdr in the university by a phd Student. I 
can not reproduce the problem with the same script and the same file. 
Maybe you can agree that this is strange. Its a kind of "never be sure 
to get the correct data" and that happened to me the first time with R.

Knut


From jdnewmil at dcn.davis.CA.us  Fri Nov 29 20:32:18 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 29 Nov 2013 11:32:18 -0800
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <5298DD4C.1080404@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
	<5298DD4C.1080404@knut-krueger.de>
Message-ID: <349b76b3-6093-4238-8b5c-96208b77d95c@email.android.com>

Please understand that this is a contributed package, and definitive assistance can only be provided by the package author. Type 

maintainer("XLConnect")

for contact information, and read the package info at cran.r-project.org/web/packages/XLConnect/index.html. R-devel is unlikely to be a more appropriate forum either.

I avoid reading Excel files directly simply because I have lost interest in fighting these battles. When I need to read many Excel files I write a macro in Excel to export to CSV and work with sane data in R. Others seem to feel these libraries work well for them, but if they don't speak up then complaining at those who do speak up won't necessarily make them say anything.

You do need to understand that reading data in odd formats must often initially be done in character format so you can apply special format parsing functions to the data yourself. In the standard data input functions the colClasses parameter can be used to control this. However,  since I don't use XLConnect I cannot tell you whether that parameter applies to that library or not.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Knut Krueger <rh at knut-krueger.de> wrote:
>Am 29.11.2013 18:31, schrieb David Winsemius:
>> On Nov 29, 2013, at 6:18 AM, Knut Krueger wrote:
>>
>>> Am 25.11.2013 13:06, schrieb Knut Krueger:
>>>>> how can I read exel files where the decimal sign is comma instead
>dot.
>>>>> I get the data as ascii and when converting "3,5" with as.numeric
>the  3,5 will be converted to NA
>>> I think here is a major bug because no warning is genereated.
>> You were already advised how to change the defaults for R's input
>functions' behaviors with respect to decimal separators. (I would add
>that you should also become familiar with the 'colClasses' argument.)
>? I was adviced:
>> ither change comma to dot in Excel (but sometimes Excel is rather
>reluctant to accept such changes).
>Thats impossible, we are used to hit the comma
>>
>> Or change commaa to dot in R which probably can be easily done by
>gsub command
>Thats also impossible because the data are lost after teh import
>>
>> Or read data with option dec=",". I do not know XLConnect but in
>read.table it is optional parameter and maybe it is also readWorksheet.
>Read data has no problem
>> does anybody know whether Rcmdr and XLCOnnectare using the same or
>different ways to import Excel?
>> Rcmdr: same ; XLConnect:different
>>
>> You should read the help pages for XLConnect.
>http://cran.r-project.org/web/packages/XLConnect/XLConnect.pdf
>sorry I did not found anything.
>>
>>> We found also that RCmdr is setting comma separated values to na if
>there is an NA in the column.
>>>
>>> Maybe it more useful to discuss this in the devel group?  (set the
>follow up to DEVEL)
>> No. This is more a sign of your lack of experience with R. There are
>wiki-pages with advice about various ways to do Excel input. (You
>surely cannot think you are the first to experience this. This has been
>a difficulty for 15 years, and more with Excel than with R.)
>
>Once again I have no problems to get the data inside R but I am looking
>
>for a solution to get an error message instead of setting 0,25 to na
>and 
>only i a few column not in the hole sheet. That's a behaviour what I am
>
>expecting from MS not from R
>But I got definitely wrong inputs with lost data with loadWorkbook. But
>
>it is not reproducable. doing the same  with a fresh environment,not 
>after working 5 hours with R,  the excel sheet is imported without 
>error. I am no a newbie in R and i am using it nearly 10 years. Them 
>same problem occoured with RCmdr in the university by a phd Student. I 
>can not reproduce the problem with the same script and the same file. 
>Maybe you can agree that this is strange. Its a kind of "never be sure 
>to get the correct data" and that happened to me the first time with R.
>
>Knut
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ulhaqz at gmail.com  Fri Nov 29 18:36:10 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Fri, 29 Nov 2013 22:36:10 +0500
Subject: [R] Relative Cumulative Frequency of Event Occurence
In-Reply-To: <1385656812.66472.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>
	<1385656812.66472.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CADw4Cku0Akt1VXZrnEPeP1m9P+qPLYGod4WUd=3E-L61i_C6ZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/f2b4b99f/attachment.pl>

From ulhaqz at gmail.com  Fri Nov 29 18:42:06 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Fri, 29 Nov 2013 22:42:06 +0500
Subject: [R] Help with "Cast" Function
Message-ID: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/aff59f54/attachment.pl>

From smartpink111 at yahoo.com  Fri Nov 29 18:56:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 29 Nov 2013 09:56:11 -0800 (PST)
Subject: [R] Relative Cumulative Frequency of Event Occurence
In-Reply-To: <CADw4Cku0Akt1VXZrnEPeP1m9P+qPLYGod4WUd=3E-L61i_C6ZQ@mail.gmail.com>
References: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>	<1385656812.66472.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CADw4Cku0Akt1VXZrnEPeP1m9P+qPLYGod4WUd=3E-L61i_C6ZQ@mail.gmail.com>
Message-ID: <1385747771.24294.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Burhan,

No problem.? One suggestion in this code would be:
? with(df.1, cumsum(E.Occur==TRUE)/(seq_len(nrow(df.1))))? ##==TRUE is not needed
?identical( with(df.1, cumsum(E.Occur)/(seq_len(nrow(df.1)))),?? with(df.1, cumsum(E.Occur==TRUE)/(seq_len(nrow(df.1)))) )


?is.logical(TRUE)
#[1] TRUE


is.logical("Yes")
#[1] FALSE
A.K.






On Friday, November 29, 2013 12:36 PM, Burhan ul haq <ulhaqz at gmail.com> wrote:

Hi Arun,

Thanks a lot. It works perfectly.

Here is the complete code - for all those who are interested to see "Rel Cum Freq oscillating to reach the Expected Value"

# Bernouilli Trial where:
v.fly=c("G","B") # Outcome is Green or Blue fly
n=100 # No of Events / Trials
v.smp = seq(1:n) # Event Id
v.fst = sample(v.fly,n,rep=T) # Simulating First Draw
v.sec = sample(v.fly,n,rep=T) ?# Simulating Second Draw
df.1 = data.frame(sample = v.smp, fst=v.fst, sec = v.sec) # Clumping in a DF
df.1$E.Occur = with(df.1, ifelse(fst==sec,TRUE,FALSE)) # Event Occurs, if color is same in both the the draws
df.1$Rel.Freq = with(df.1, cumsum(E.Occur==TRUE)/(seq_len(nrow(df.1)))) # Relative Frequency?
df.1$Rel.Freq = round(df.1$Rel.Freq,2)

ggplot(df.1, aes(x=sample,y=Rel.Freq))+geom_line(col="green",size=2)+geom_abline(intercept=0.5,slope=0)+geom_point(col="blue")+labs(x="Sample No",y="Relative Cum Freq",title="Rel Cum Freq approaching 0.5 Value") + annotate("text",x=60,y=0.53,label="Probability of 0.5") ?



Cheers !?



On Thu, Nov 28, 2013 at 9:40 PM, arun <smartpink111 at yahoo.com> wrote:

HI,
>From the dput() version of df.1, it looks like you want:
>cumsum(df.1[,4]=="Yes")/seq_len(nrow(df.1))
>?[1] 0.0000000 0.5000000 0.3333333 0.2500000 0.4000000 0.3333333 0.4285714
>?[8] 0.5000000 0.4444444 0.5000000
>
>
>A.K.
>
>
>
>On Thursday, November 28, 2013 11:26 AM, Burhan ul haq <ulhaqz at gmail.com> wrote:
>Hi,
>
>My objective is to calculate "Relative (Cumulative) Frequency of Event
>Occurrence" - something as follows:
>
>Sample.Number 1st.Fly 2nd.Fly? Did.E.occur? Relative.Cum.Frequency.of.E
>1 G B No 0.000
>2 B B Yes 0.500
>3 B G No 0.333
>4 G B No 0.250
>5 G G Yes 0.400
>6 G B No 0.333
>7 B B Yes 0.429
>8 G G Yes 0.500
>9 G B No 0.444
>10 B B Yes 0.500
>
>Please refer to the code below:
>##############################################################
># 1.
>v.fly=c("G","B") # Outcome is Green or Blue fly
>
># 2.
>n=10 # No of Events / Trials
>
># 3.
>v.smp = seq(1:n) # Event Id
>
># 4.
>v.fst = sample(v.fly,n,rep=T) # Simulating First Draw
>
># 5.
>v.sec = sample(v.fly,n,rep=T)? # Simulating Second Draw
>
># 6.
>df.1 = data.frame(sample = v.smp, fst=v.fst, sec = v.sec) # Clumping in a DF
>
># 7.
>df.1$E.Occur = with(df.1, ifelse(fst==sec,TRUE,FALSE)) # Event Occurs, if
>color is same in both the the draws
>
># 8.
>df.1$Rel.Freq = with(df.1, cumsum(E.occur)/(E.Occur)) # Relative Frequency
>>> This line does NOT work, and needs to fix the denominator part
>##############################################################
>
>Problem is with #8, specifically the part:
>cumsum(E.occur)/(E.Occur)
>
>The denominator E.Occur is a fixed value, instead of a moving count. I have
>tried nrow(), length() but none provides a moving version of row count, as
>cumsum does for the "True" values, occurring so far.
>
>> dput(df.1)
>structure(list(Sample.Number = 1:10, X1st.Fly = c("G", "B", "B",
>"G", "G", "G", "B", "G", "G", "B"), X2nd.Fly = c("B", "B", "G",
>"B", "G", "B", "B", "G", "B", "B"), Did.E.occur. = c("No", "Yes",
>"No", "No", "Yes", "No", "Yes", "Yes", "No", "Yes"),
>Relative.Cum.Frequency.of.E = c(0,
>0.5, 0.333, 0.25, 0.4, 0.333, 0.429, 0.5, 0.444, 0.5)), .Names =
>c("Sample.Number",
>"X1st.Fly", "X2nd.Fly", "Did.E.occur.", "Relative.Cum.Frequency.of.E"
>), class = "data.frame", row.names = c(NA, -10L))
>
>
>Cheers !
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From adel.daoud at sociology.gu.se  Fri Nov 29 19:08:46 2013
From: adel.daoud at sociology.gu.se (Adel)
Date: Fri, 29 Nov 2013 10:08:46 -0800 (PST)
Subject: [R] the wilcox.test() and pairwise.wilcox.test are producing
 different results
Message-ID: <CAEJCy7iDrz5kgc3Jj8GpiYr_7axo7j2goFA4W4YjJJPj2ATQRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/246608e0/attachment.pl>

From smartpink111 at yahoo.com  Fri Nov 29 19:09:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 29 Nov 2013 10:09:02 -0800 (PST)
Subject: [R] Adding NA values in random positions in a dataframe
In-Reply-To: <1385661427.78119.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1385661427.78119.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1385748542.74149.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
I used that because 10% of the values in the data were already NA. 


You are right.? Sorry, ?match() is unnecessary.? I was trying another solution with match() which didn't work out and forgot to check whether it was adequate or not.
set.seed(49)
dat1[!is.na(dat1)][sample(seq(dat1[!is.na(dat1)]),length(dat1[!is.na(dat1)])*(0.20))] <- NA
A.K.


Thanks for the reply. I don't get the 0.20 multiplied by the length of the non NA value, where did you take it from? 

Furthermore, why do we have to use the function match? Wouldn't it be enough to use the saple function? 


On Thursday, November 28, 2013 12:57 PM, arun <smartpink111 at yahoo.com> wrote:
Hi,
One way would be:
?set.seed(42)
?dat1 <- as.data.frame(matrix(sample(c(1:5,NA),50,replace=TRUE,prob=c(10,15,15,20,30,10)),ncol=5))
set.seed(49)
?dat1[!is.na(dat1)][ match( sample(seq(dat1[!is.na(dat1)]),length(dat1[!is.na(dat1)])*(0.20)),seq(dat1[!is.na(dat1)]))] <- NA
length(dat1[is.na(dat1)])/length(unlist(dat1))
#[1] 0.28

A.K.


Hello, I'm quite new at R so I don't know which is the most efficient 
way to execute a function that I could write easily in other languages. 

This is my problem: I have a dataframe with a certain numbers of
NA (approximately 10%). I want to add other NA values in random 
positions of the dataframes until reaching an overall proportions of NA 
values of 30% (clearly the positions with NA values don't have to 
change). I tried looking at iterative function in R as apply or sapply 
but I can't actually figure out how to use them in this case. Thank you.


From smartpink111 at yahoo.com  Fri Nov 29 20:29:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 29 Nov 2013 11:29:17 -0800 (PST)
Subject: [R] the wilcox.test() and pairwise.wilcox.test are producing
	different results
Message-ID: <1385753357.46286.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

Have you tried p.adjust="none"

?pairwise.wilcox.test(daily_long$value,daily_long$variable, paired=T,p.adj="none") 


pairwise.wilcox.test(Ozone, Month, p.adj = "none")
A.K.


Dear list member,
?
I want to compare if
the rank order is significantly different for seven different measures. So we
have same sample but different measures which reduces the problem to a paired
one sample Wilcox test if I understood the test correctly. In constructed toy examples
for my sake of understanding, but things are not adding up. Basically, the wilcox.test()
and pairwise.wilcox.test are producing different results when they should not
(according to my understanding of course):
?
#take a vector
daily.intake <-
c(5260,5470,5640,6180,6390,6515,
????????????????? + 6805,7515,7515,8230,8770)
?
#I get desired results
when I do the following
daily<-data.frame(pre=daily.intake,
post=daily.intake)
?
#add som differences
daily[1,1]<-5000
daily[2,1]<-5100
?
?
#reshape the data for
pairwise comparison
library(reshape2)
daily_long<-melt(daily,
id=) 
?
#conduct simple test
wilcox.test(daily$pre,daily$post,
paired=T) #produces desired results
?
#do the test again but
now in a pairwise, which produces the same p-value as in the simple test above
pairwise.wilcox.test(daily_long$value,daily_long$variable,
paired=T) 
?
#But now I the issues
arise when testing more than two vectors.
?
#take three
vectors this time
daily<-data.frame(pre=daily.intake,
post=daily.intake, posttwo=daily.intake)
?
#add some differences
daily[1,1]<-5000
daily[2,1]<-5100
daily[10,3]<-9000
daily[11,3]<-9100
?
#the wilcox.test()
produces a set of p-values 
wilcox.test(daily$pre,daily$posttwo,
paired=T)
?wilcox.test(daily$pre,daily$post, paired=T) 
wilcox.test(daily$post,daily$posttwo,
paired=T) 
?
#and the
pairwise.wilcox.test produces another set
pairwise.wilcox.test(daily_long$value,daily_long$variable,
paired=T) 
?
?
?
##And from the manual
for pairwise.wilcox we get similar issues
?
#produces a given set
of p-values
attach(airquality)
Month <- factor(Month, labels =
month.abb[5:9])
## These give warnings because of ties :
pairwise.wilcox.test(Ozone, Month)
pairwise.wilcox.test(Ozone, Month, p.adj =
"bonf")
detach()
?
#but if we want to test the rank difference between
the 6th and 7th month we get a p-value of 0.5775
?
testar skillnaden mellan 6e och 7e m?naden ? observ
however that this data is not paired which makes it different to the example I
gave above.
#p-v?rdet ?r?0.5775
?
air<-subset(airquality,
airquality$Month < 7)
?
#p-value is now 0.1925
wilcox.test(air$Ozone~air$Month)
?
?
What am I doing wrong
here? 
Best
Adel
-- 
Adel Daoud, PhD
Visiting researcher
(post-doc)


Max Planck Institute for the Study of Societies / Max-Planck-Institut f?r
Gesellschaftsforschung
Paulstr. 3 | 506 76 K?ln | Germany
Tel.: + 49 (0) 221 2767-534
[hidden email]
?Department of
Sociology and Work Science, ?University of Gothenburg
Box 720
405 30 G?teborg, Sweden
Visiting address: Spr?ngkullsgatan 25, room K109
+46 031-786 41 73
[hidden email]


From dwinsemius at comcast.net  Fri Nov 29 20:39:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 Nov 2013 11:39:07 -0800
Subject: [R] XLConnect readWorksheet   comma decimal sign
In-Reply-To: <5298DD4C.1080404@knut-krueger.de>
References: <52931410.4080102@knut-krueger.de>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BA05B8@SRVEXCHMBX.precheza.cz>
	<52933D4B.90803@knut-krueger.de> <5298A218.2090303@knut-krueger.de>
	<5422DC5C-24A7-4BA6-A43A-44340703398A@comcast.net>
	<5298DD4C.1080404@knut-krueger.de>
Message-ID: <33144A60-5037-4C76-B950-3376B4B14902@comcast.net>


On Nov 29, 2013, at 10:30 AM, Knut Krueger wrote:

> Am 29.11.2013 18:31, schrieb David Winsemius:
>> On Nov 29, 2013, at 6:18 AM, Knut Krueger wrote:
>> 
>>> Am 25.11.2013 13:06, schrieb Knut Krueger:
>>>>> how can I read exel files where the decimal sign is comma instead dot.
>>>>> I get the data as ascii and when converting "3,5" with as.numeric the  3,5 will be converted to NA
>>> I think here is a major bug because no warning is genereated.
>> You were already advised how to change the defaults for R's input functions' behaviors with respect to decimal separators. (I would add that you should also become familiar with the 'colClasses' argument.)
> ? I was adviced:
>> ither change comma to dot in Excel (but sometimes Excel is rather reluctant to accept such changes).

Well, I suppose you were, but I was referring to the advice to ' read data with option:  dec="," '. The reason I advised to also look at colClasses was to provide a mechanism for asserting that certain columns were "numeric". With a combination of dec="," and colCalsses="numeric" you would get coercion to 'numeric' after the decimal-punkts (as ",") were changed to decimal-points (as ".").

> Thats impossible, we are used to hit the comma

I don't know what that means.

>> 
>> Or change commaa to dot in R which probably can be easily done by gsub command
> Thats also impossible because the data are lost after teh import

Until you show a reproducible example, we will not be able to offer further advice:

>> 
>> Or read data with option dec=",". I do not know XLConnect but in read.table it is optional parameter and maybe it is also readWorksheet.

I was not making any advice contingent on XLConnect (other than to read it's help page to answer your question about how it was importing from xls files. My memory was that it used perl scripts but looking at its DESCRIPTION file I see that it is Java based.)


> Read data has no problem
>> does anybody know whether Rcmdr and XLCOnnectare using the same or different ways to import Excel?
>> Rcmdr: same ; XLConnect:different
>> 
>> You should read the help pages for XLConnect.
> http://cran.r-project.org/web/packages/XLConnect/XLConnect.pdf
> sorry I did not found anything.
>> 
>>> We found also that RCmdr is setting comma separated values to na if there is an NA in the column.
>>> 
>>> Maybe it more useful to discuss this in the devel group?  (set the follow up to DEVEL)
>> No. This is more a sign of your lack of experience with R. There are wiki-pages with advice about various ways to do Excel input. (You surely cannot think you are the first to experience this. This has been a difficulty for 15 years, and more with Excel than with R.)
> 
> Once again I have no problems to get the data inside R but I am looking for a solution to get an error message instead of setting 0,25 to na and only i a few column not in the hole sheet. That's a behaviour what I am expecting from MS not from R

You should post the code you used and the output from head(dfrm) where dfrm is the name of the object you created with whatever code you have never shown.
 
> But I got definitely wrong inputs with lost data with loadWorkbook.

If you are asking about XLConnect then correspond with the package authors.


> But it is not reproducable. doing the same  with a fresh environment,not after working 5 hours with R,  the excel sheet is imported without error. I am no a newbie in R and i am using it nearly 10 years. Them same problem occoured with RCmdr in the university by a phd Student. I can not reproduce the problem with the same script and the same file. Maybe you can agree that this is strange. Its a kind of "never be sure to get the correct data" and that happened to me the first time with R.
> 
> Knut
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From carl at witthoft.com  Fri Nov 29 21:14:29 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Fri, 29 Nov 2013 12:14:29 -0800 (PST)
Subject: [R] Help with "Cast" Function
In-Reply-To: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>
References: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>
Message-ID: <1385756069023-4681384.post@n4.nabble.com>

I see your desired output has rather fewer data than the input data frame.  
Instead of making us pore over a bunch of numbers, can you explain exactly
what filtering you wish to do to get the specific subset 
of {male/female} {alcohol/caffeine} you're trying to get?



BHM wrote
> Hi,
> 
> This is the input data frame:
> 
> ###############################################
> df.1 = read.table(header=T,text="
> id gender WMC_alcohol WMC_caffeine WMC_no.drug RT_alcohol RT_caffeine
> RT_no.drug
> 1 1 female 3.7 3.7 3.9 488 236 371
> 2 2 female 6.4 7.3 7.9 607 376 349
> 3 3 female 4.6 7.4 7.3 643 226 412
> 4 4 male 6.4 7.8 8.2 684 206 252
> 5 5 female 4.9 5.2 7.0 593 262 439
> 6 6 male 5.4 6.6 7.2 492 230 464
> 7 7 male 7.9 7.9 8.9 690 259 327
> 8 8 male 4.1 5.9 4.5 486 230 305
> 9 9 female 5.2 6.2 7.2 686 273 327
> 10 10 female 6.2 7.4 7.8 645 240 498
>                   ")
> ###############################################
> 
> This is the desired output:
> ###############################################
> id gender drug WMC RT
> 1 1 female alcohol 3.7 488
> 2 2 female alcohol 6.4 607
> 3 3 female alcohol 4.6 643
> 4 4 male alcohol 6.4 684
> 5 5 female alcohol 4.9 593
> 6 6 male alcohol 5.4 492
> 7 7 male alcohol 7.9 690
> 8 8 male alcohol 4.1 486
> 9 9 female alcohol 5.2 686
> 10 10 female alcohol 6.2 645
> 11 1 female caffeine 3.7 236
> 12 2 female caffeine 7.3 376
> ###############################################
> 
> I know some melt and cast magic is required. But I was unable to sort it
> myself.
> 
> Here are the dput versions:
> 
> Input Data Frame
> ###############################################
>> dput(df.1)
> structure(list(id = 1:10, gender = structure(c(1L, 1L, 1L, 2L,
> 1L, 2L, 2L, 2L, 1L, 1L), .Label = c("female", "male"), class = "factor"),
>     WMC_alcohol = c(3.7, 6.4, 4.6, 6.4, 4.9, 5.4, 7.9, 4.1, 5.2,
>     6.2), WMC_caffeine = c(3.7, 7.3, 7.4, 7.8, 5.2, 6.6, 7.9,
>     5.9, 6.2, 7.4), WMC_no.drug = c(3.9, 7.9, 7.3, 8.2, 7, 7.2,
>     8.9, 4.5, 7.2, 7.8), RT_alcohol = c(488L, 607L, 643L, 684L,
>     593L, 492L, 690L, 486L, 686L, 645L), RT_caffeine = c(236L,
>     376L, 226L, 206L, 262L, 230L, 259L, 230L, 273L, 240L), RT_no.drug =
> c(371L,
>     349L, 412L, 252L, 439L, 464L, 327L, 305L, 327L, 498L)), .Names =
> c("id",
> "gender", "WMC_alcohol", "WMC_caffeine", "WMC_no.drug", "RT_alcohol",
> "RT_caffeine", "RT_no.drug"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10"))
> 
> 
> Output Data Frame
> ###############################################
>> dput(df.output)
> structure(list(id = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 1L, 2L), gender = structure(c(1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L,
> 1L, 1L, 1L, 1L), .Label = c("female", "male"), class = "factor"),
>     drug = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>     2L, 2L), .Label = c("alcohol", "caffeine"), class = "factor"),
>     WMC = c(3.7, 6.4, 4.6, 6.4, 4.9, 5.4, 7.9, 4.1, 5.2, 6.2,
>     3.7, 7.3), RT = c(488L, 607L, 643L, 684L, 593L, 492L, 690L,
>     486L, 686L, 645L, 236L, 376L)), .Names = c("id", "gender",
> "drug", "WMC", "RT"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"))
> 
> 
> Cheers !
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Help-with-Cast-Function-tp4681381p4681384.html
Sent from the R help mailing list archive at Nabble.com.


From carl at witthoft.com  Fri Nov 29 21:16:06 2013
From: carl at witthoft.com (Carl Witthoft)
Date: Fri, 29 Nov 2013 12:16:06 -0800 (PST)
Subject: [R] How to draw a shade overlapping of three circles (or other
 shapes) with certain areas?
In-Reply-To: <1385708942053-4681356.post@n4.nabble.com>
References: <1385708942053-4681356.post@n4.nabble.com>
Message-ID: <1385756166716-4681385.post@n4.nabble.com>


Pardon the pedantry, but doyou know what a "Venn Diagram" is?  Because there
are two or three

packages at CRAN which will generate Venn diagrams for you given exactly
that sort of source data.
 

Yi.Zou wrote
> Hi all, 
> 
> I am thinking of making a graph with three dataset A,B,C with shared
> common ?area? with each other. i.e. shade overlapping of three circles (or
> other shapes such as ellipses or ploygon). 
> 
> My data are like this:
> A: 20
> B: 15
> C: 15
> A&B: 10
> A&C: 12
> B&C: 8
> A&B&C?4
> 
> It should make sure that each area of the circle (or other shape) can
> reflect the proportion of the number (I can transfer the number to
> proportion of course). 
> 
> Anyone can help me? Many thanks!!





--
View this message in context: http://r.789695.n4.nabble.com/How-to-draw-a-shade-overlapping-of-three-circles-or-other-shapes-with-certain-areas-tp4681356p4681385.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Nov 29 21:20:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 Nov 2013 12:20:44 -0800
Subject: [R] Help with "Cast" Function
In-Reply-To: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>
References: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>
Message-ID: <A03429DC-77E2-4622-A8FD-0CB2F243934F@comcast.net>


On Nov 29, 2013, at 9:42 AM, Burhan ul haq wrote:

> Hi,
> 
> This is the input data frame:
> 
> ###############################################
> df.1 = read.table(header=T,text="
> id gender WMC_alcohol WMC_caffeine WMC_no.drug RT_alcohol RT_caffeine
> RT_no.drug
> 1 1 female 3.7 3.7 3.9 488 236 371
> 2 2 female 6.4 7.3 7.9 607 376 349
> 3 3 female 4.6 7.4 7.3 643 226 412
> 4 4 male 6.4 7.8 8.2 684 206 252
> 5 5 female 4.9 5.2 7.0 593 262 439
> 6 6 male 5.4 6.6 7.2 492 230 464
> 7 7 male 7.9 7.9 8.9 690 259 327
> 8 8 male 4.1 5.9 4.5 486 230 305
> 9 9 female 5.2 6.2 7.2 686 273 327
> 10 10 female 6.2 7.4 7.8 645 240 498
>                  ")
> ###############################################
> 
> This is the desired output:
> ###############################################
> id gender drug WMC RT
> 1 1 female alcohol 3.7 488
> 2 2 female alcohol 6.4 607
> 3 3 female alcohol 4.6 643
> 4 4 male alcohol 6.4 684
> 5 5 female alcohol 4.9 593
> 6 6 male alcohol 5.4 492
> 7 7 male alcohol 7.9 690
> 8 8 male alcohol 4.1 486
> 9 9 female alcohol 5.2 686
> 10 10 female alcohol 6.2 645
> 11 1 female caffeine 3.7 236
> 12 2 female caffeine 7.3 376
> ###############################################
> 
> I know some melt and cast magic is required. But I was unable to sort it
> myself.
> 
# this is base::reshape

reshape(df.1, idvar=1:2, sep="_", direction="long", varying=names(df.1)[3:8])


> Here are the dput versions:
> 
> Input Data Frame
> ###############################################
>> dput(df.1)
> structure(list(id = 1:10, gender = structure(c(1L, 1L, 1L, 2L,
> 1L, 2L, 2L, 2L, 1L, 1L), .Label = c("female", "male"), class = "factor"),
>    WMC_alcohol = c(3.7, 6.4, 4.6, 6.4, 4.9, 5.4, 7.9, 4.1, 5.2,
>    6.2), WMC_caffeine = c(3.7, 7.3, 7.4, 7.8, 5.2, 6.6, 7.9,
>    5.9, 6.2, 7.4), WMC_no.drug = c(3.9, 7.9, 7.3, 8.2, 7, 7.2,
>    8.9, 4.5, 7.2, 7.8), RT_alcohol = c(488L, 607L, 643L, 684L,
>    593L, 492L, 690L, 486L, 686L, 645L), RT_caffeine = c(236L,
>    376L, 226L, 206L, 262L, 230L, 259L, 230L, 273L, 240L), RT_no.drug =
> c(371L,
>    349L, 412L, 252L, 439L, 464L, 327L, 305L, 327L, 498L)), .Names =
> c("id",
> "gender", "WMC_alcohol", "WMC_caffeine", "WMC_no.drug", "RT_alcohol",
> "RT_caffeine", "RT_no.drug"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10"))
> 
> 
> Output Data Frame
> ###############################################
>> dput(df.output)
> structure(list(id = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 1L, 2L), gender = structure(c(1L, 1L, 1L, 2L, 1L, 2L, 2L, 2L,
> 1L, 1L, 1L, 1L), .Label = c("female", "male"), class = "factor"),
>    drug = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>    2L, 2L), .Label = c("alcohol", "caffeine"), class = "factor"),
>    WMC = c(3.7, 6.4, 4.6, 6.4, 4.9, 5.4, 7.9, 4.1, 5.2, 6.2,
>    3.7, 7.3), RT = c(488L, 607L, 643L, 684L, 593L, 492L, 690L,
>    486L, 686L, 645L, 236L, 376L)), .Names = c("id", "gender",
> "drug", "WMC", "RT"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12"))
> 
> 
> Cheers !
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jacq.pless at gmail.com  Fri Nov 29 21:05:34 2013
From: jacq.pless at gmail.com (Jacquelyn Pless)
Date: Fri, 29 Nov 2013 13:05:34 -0700
Subject: [R] mat2listw function
Message-ID: <CAC0ELpLiXu8ewZGwSQP5Wr8raTn8BhSpRyT6SbQUsn2xLnG3yQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/683a4061/attachment.pl>

From gunter.berton at gene.com  Fri Nov 29 22:00:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 29 Nov 2013 13:00:04 -0800
Subject: [R] Adding NA values in random positions in a dataframe
In-Reply-To: <1385748542.74149.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1385661427.78119.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1385748542.74149.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CACk-te1_xxp0ONW7ZE3PXYyX0QFUxm7ds6ye8FOrZ1yNDpeO8g@mail.gmail.com>

An essentially identical approach that may be a tad clearer -- but
requires additional space -- first creates a logical vector for the
locations of the NA's in the unlisted data.frame. Further NA positions
are randomly added and then the augmented vector is used as a logical
matrix to index where the NA's should go in the data frame:

df <- data.frame(a = c(1:3,NA,4:6),
                b=c(letters[1:6],NA),
                 c= c(1,NA,runif(5)))

nr <- nrow(df); nc <- ncol(df)
p <- .3 ## desired total proportion of NA's

ina <- is.na(unlist(df)) ## logical vector, TRUE corresponds to NA positions
n2 <- floor(p*nr*nc) - sum(ina)  ## number of new NA's

ina[sample(which(!is.na(ina)), n2)] <- TRUE
df[matrix(ina, nr=nr,nc=nc)]<- NA ## using matrix indexing

df

Cheers,
Bert

On Fri, Nov 29, 2013 at 10:09 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> I used that because 10% of the values in the data were already NA.
>
>
> You are right.  Sorry, ?match() is unnecessary.  I was trying another solution with match() which didn't work out and forgot to check whether it was adequate or not.
> set.seed(49)
> dat1[!is.na(dat1)][sample(seq(dat1[!is.na(dat1)]),length(dat1[!is.na(dat1)])*(0.20))] <- NA
> A.K.
>
>
> Thanks for the reply. I don't get the 0.20 multiplied by the length of the non NA value, where did you take it from?
>
> Furthermore, why do we have to use the function match? Wouldn't it be enough to use the saple function?
>
>
> On Thursday, November 28, 2013 12:57 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> One way would be:
>  set.seed(42)
>  dat1 <- as.data.frame(matrix(sample(c(1:5,NA),50,replace=TRUE,prob=c(10,15,15,20,30,10)),ncol=5))
> set.seed(49)
>  dat1[!is.na(dat1)][ match( sample(seq(dat1[!is.na(dat1)]),length(dat1[!is.na(dat1)])*(0.20)),seq(dat1[!is.na(dat1)]))] <- NA
> length(dat1[is.na(dat1)])/length(unlist(dat1))
> #[1] 0.28
>
> A.K.
>
>
> Hello, I'm quite new at R so I don't know which is the most efficient
> way to execute a function that I could write easily in other languages.
>
> This is my problem: I have a dataframe with a certain numbers of
> NA (approximately 10%). I want to add other NA values in random
> positions of the dataframes until reaching an overall proportions of NA
> values of 30% (clearly the positions with NA values don't have to
> change). I tried looking at iterative function in R as apply or sapply
> but I can't actually figure out how to use them in this case. Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From nooldor at gmail.com  Fri Nov 29 23:22:03 2013
From: nooldor at gmail.com (nooldor)
Date: Fri, 29 Nov 2013 23:22:03 +0100
Subject: [R] Multiple regressions with changing dependent variable and time
	span
Message-ID: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/586f3b77/attachment.pl>

From jdkoola at gmail.com  Sat Nov 30 05:52:27 2013
From: jdkoola at gmail.com (Jejo Koola)
Date: Fri, 29 Nov 2013 22:52:27 -0600
Subject: [R] bnlearn and very large datasets (> 1 million observations)
Message-ID: <CADnN+ckp+afLvdOkcsH_X4TNd1erUcBL0KzB5o5JHJn58LPsRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131129/a21008e5/attachment.pl>

From smartpink111 at yahoo.com  Sat Nov 30 07:42:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 29 Nov 2013 22:42:33 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time	span
In-Reply-To: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>
Message-ID: <1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
The link seems to be not working.? From the description, it looks like:
set.seed(432)
dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))

?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
library(zoo)

res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))

row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
?dim(res)
#[1] 41082???? 4

coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
#(Intercept)???????? F.1???????? F.2???????? F.3 
#109.9168150? -0.1705361? -0.1028231?? 0.2027911 
coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
#(Intercept)???????? F.1???????? F.2???????? F.3 
#119.3718949? -0.1660709? -0.2059830?? 0.1338608 
res[1:2,]
#??? (Intercept)??????? F.1??????? F.2?????? F.3
#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608

A.K.





On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
Hi all!


I am just starting my adventure with R, so excuse me naive questions.

My data look like that:

<http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>

I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
regression.

Total span of the time is 154 observations. But I would like to have rolling
window regression with length of 31 observations.

I would like to run script like that:

summary(lm(r.1~F.1+F.2+F.3, data=data))
vif(lm(r.1~F.1+F.2+F.3, data=data))

But for each of 334 (r.1 to r.334) dependent variables separately and with
rolling-window of the length 31obs.

Id est:
summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
31. for the first regression) times for rolling-fixed period of 31 obs.

The next regression would be:
summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
summary(lm(r.334~F.1+F.2+F.3, data=data))

It means it would be 123 x 334 regressions (=41082 regressions)

I would like to save results (summary + vif test) of all those 41082
regressions in one read-user-friendly file like this given by e.g command
capture.output()

Could you help with it?

Regards,

T.S.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ulhaqz at gmail.com  Sat Nov 30 07:52:15 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Sat, 30 Nov 2013 11:52:15 +0500
Subject: [R] Help with "Cast" Function
In-Reply-To: <A03429DC-77E2-4622-A8FD-0CB2F243934F@comcast.net>
References: <CADw4Ckvd8wqYbCdfz+5mVBphaWm31YEuXE0NqOcZ-TF2gzX9fA@mail.gmail.com>
	<A03429DC-77E2-4622-A8FD-0CB2F243934F@comcast.net>
Message-ID: <CADw4CkvpEZYjeP+6y1JAC7x9krz8CVn2DVLLyXzAbk6tVQSCAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/d4c9b81f/attachment.pl>

From ulhaqz at gmail.com  Sat Nov 30 07:58:20 2013
From: ulhaqz at gmail.com (Burhan ul haq)
Date: Sat, 30 Nov 2013 11:58:20 +0500
Subject: [R] Relative Cumulative Frequency of Event Occurence
In-Reply-To: <1385747771.24294.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CADw4CkuSfKg0SW_zhxJf6k+3eQshm7D6Bt2zLcf=mUD8Te=x-Q@mail.gmail.com>
	<1385656812.66472.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CADw4Cku0Akt1VXZrnEPeP1m9P+qPLYGod4WUd=3E-L61i_C6ZQ@mail.gmail.com>
	<1385747771.24294.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CADw4Cksz7YFsYZeyVmvJWiiu+4sbLNkPGufCNZFZwgTiOxLH5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/6f82bb3f/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Nov 30 08:29:12 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 Nov 2013 07:29:12 +0000
Subject: [R] bnlearn and very large datasets (> 1 million observations)
In-Reply-To: <CADnN+ckp+afLvdOkcsH_X4TNd1erUcBL0KzB5o5JHJn58LPsRQ@mail.gmail.com>
References: <CADnN+ckp+afLvdOkcsH_X4TNd1erUcBL0KzB5o5JHJn58LPsRQ@mail.gmail.com>
Message-ID: <529993C8.6020608@stats.ox.ac.uk>

On 30/11/2013 04:52, Jejo Koola wrote:
> Hi
>
> Anyone have experience with very large datasets and the Bayesian Network
> package, bnlearn?  In my experience R doesn't react well to very large
> datasets.

Maybe, but a million is not 'very large': R handles billions of 
observations without problems on machines with commensurate resources.

Package bnlearn is not 'R'.  Your questions are not about R itself and 
should be addressed to the package maintainer.

> Is there a way to divide up the dataset into pieces and incrementally learn
> the network with the pieces?  This would also be helpful incase R crashes,
> because I could save the network after learning each piece.
>
> Thank you.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do, including what it says about HTML mail and about 'crashes'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chiao at alum.mit.edu  Sat Nov 30 08:19:19 2013
From: chiao at alum.mit.edu (Chiao-Lun Cheng)
Date: Sat, 30 Nov 2013 15:19:19 +0800
Subject: [R] Latent Heteroskedasticity
Message-ID: <CAKC5MQYM+-ZrzpgpANBPO9xErBO9isTe9xrf8WAqGKV5wckzZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/6d4ee835/attachment.pl>

From eloyack at arcadia.edu  Sat Nov 30 08:37:56 2013
From: eloyack at arcadia.edu (Loyack, Eric)
Date: Sat, 30 Nov 2013 02:37:56 -0500
Subject: [R] beginner help: 10th index is being overwritten by 11th
Message-ID: <CAMuLRvEaU9feh0s51JvVVUwLZY5T7oawZ9-gODwnjwx1ZBokvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/34ddc066/attachment.pl>

From bhh at xs4all.nl  Sat Nov 30 10:16:32 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 30 Nov 2013 10:16:32 +0100
Subject: [R] beginner help: 10th index is being overwritten by 11th
In-Reply-To: <CAMuLRvEaU9feh0s51JvVVUwLZY5T7oawZ9-gODwnjwx1ZBokvQ@mail.gmail.com>
References: <CAMuLRvEaU9feh0s51JvVVUwLZY5T7oawZ9-gODwnjwx1ZBokvQ@mail.gmail.com>
Message-ID: <F7D15815-1E81-4916-9F87-850CBC3D7592@xs4all.nl>


On 30-11-2013, at 08:37, Loyack, Eric <eloyack at arcadia.edu> wrote:

> I am using R Studio and writing code to determine p-values for statistical
> t-tests.  Code is below.  When I print out the values in the loop for
> PTMpvalMeans they are correct, but when I store them the 10th one
> overwrites the 11th.  Can someone tell me what I am doing wrong? Thanks in
> advance, Eric
> 

R FAQ 7.31 (http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f)

Insert print(formatC(10*rho+1,digits=16,format="f")) before the line with print(PTMpvalMeans[rho*10 + 1]) in your code and you should see what?s wrong.

Use an explicit counter variable k and increment with k <- k+1 to index your vectors.

Berend

> rho <- 0.0
> PTMpvalMeans <- numeric(11)
> while (rho < 1.0){
> x1 <- rnorm(25,0,1)
> x2 <- rnorm(25,0,1)
> y1 <- rnorm(25,0,1)
> y2 <- rnorm(25,0,1)
> w1 <- rho*x1 + sqrt(1-rho^2)*y1
> w2 <- rho*x2 + sqrt(1-rho^2)*y2
> controlPretest <- 50 + 10*x1
> groupPretest <- 50 + 10*x2
> controlPosttest <- 60 + 10*w1
> groupPosttest <- 70 + 10*w2
> postTestMethod <-
> t.test(controlPosttest,groupPosttest,mu=0,alternative="two.sided")
> PTMpval <- postTestMethod$p.value
> for (i in 1:999){
> x1 <- rnorm(25,0,1)
> x2 <- rnorm(25,0,1)
> y1 <- rnorm(25,0,1)
> y2 <- rnorm(25,0,1)
> w1 <- rho*x1 + sqrt(1-rho^2)*y1
> w2 <- rho*x2 + sqrt(1-rho^2)*y2
> controlPretestLoop <- 50 + 10*x1
> groupPretestLoop <- 50 + 10*x2
> controlPosttestLoop <- 60 + 10*w1
> groupPosttestLoop <- 70 + 10*w2
> controlPretest <- c(controlPretest,controlPretestLoop)
> groupPosttest <- c(groupPosttest,groupPosttestLoop)
> groupPretest <- c(groupPretest,groupPretestLoop)
> controlPosttest <- c(controlPosttest,controlPosttestLoop)
> postTestMethodLoop <-
> t.test(controlPosttestLoop,groupPosttestLoop,mu=0,alternative="two.sided")
> PTMpvalLoop <- postTestMethodLoop$p.value
> PTMpval <- c(PTMpval,PTMpvalLoop)
> }
> PTMpvalMeans[rho*10 + 1] <- mean(PTMpval)
> print(rho)
> print(PTMpvalMeans[rho*10 + 1])
> rho <- rho + 0.1
> }
> PTMpvalMeans
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Nov 30 10:19:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 30 Nov 2013 18:19:50 +0900
Subject: [R] beginner help: 10th index is being overwritten by 11th
In-Reply-To: <CAMuLRvEaU9feh0s51JvVVUwLZY5T7oawZ9-gODwnjwx1ZBokvQ@mail.gmail.com>
References: <CAMuLRvEaU9feh0s51JvVVUwLZY5T7oawZ9-gODwnjwx1ZBokvQ@mail.gmail.com>
Message-ID: <5299ADB6.3040802@gmail.com>

On 13-11-30 4:37 PM, Loyack, Eric wrote:
> I am using R Studio and writing code to determine p-values for statistical
> t-tests.  Code is below.  When I print out the values in the loop for
> PTMpvalMeans they are correct, but when I store them the 10th one
> overwrites the 11th.  Can someone tell me what I am doing wrong? Thanks in
> advance, Eric

It looks like a fairly obscure case of FAQ 7.31.  It's a bad idea to use 
0.1 as a loop increment, because fractions like that can't be 
represented exactly, and rounding error accumulates.

Duncan Murdoch

>
> rho <- 0.0
> PTMpvalMeans <- numeric(11)
> while (rho < 1.0){
> x1 <- rnorm(25,0,1)
> x2 <- rnorm(25,0,1)
> y1 <- rnorm(25,0,1)
> y2 <- rnorm(25,0,1)
> w1 <- rho*x1 + sqrt(1-rho^2)*y1
> w2 <- rho*x2 + sqrt(1-rho^2)*y2
> controlPretest <- 50 + 10*x1
> groupPretest <- 50 + 10*x2
> controlPosttest <- 60 + 10*w1
> groupPosttest <- 70 + 10*w2
> postTestMethod <-
> t.test(controlPosttest,groupPosttest,mu=0,alternative="two.sided")
> PTMpval <- postTestMethod$p.value
> for (i in 1:999){
> x1 <- rnorm(25,0,1)
> x2 <- rnorm(25,0,1)
> y1 <- rnorm(25,0,1)
> y2 <- rnorm(25,0,1)
> w1 <- rho*x1 + sqrt(1-rho^2)*y1
> w2 <- rho*x2 + sqrt(1-rho^2)*y2
> controlPretestLoop <- 50 + 10*x1
> groupPretestLoop <- 50 + 10*x2
> controlPosttestLoop <- 60 + 10*w1
> groupPosttestLoop <- 70 + 10*w2
> controlPretest <- c(controlPretest,controlPretestLoop)
> groupPosttest <- c(groupPosttest,groupPosttestLoop)
> groupPretest <- c(groupPretest,groupPretestLoop)
> controlPosttest <- c(controlPosttest,controlPosttestLoop)
> postTestMethodLoop <-
> t.test(controlPosttestLoop,groupPosttestLoop,mu=0,alternative="two.sided")
> PTMpvalLoop <- postTestMethodLoop$p.value
> PTMpval <- c(PTMpval,PTMpvalLoop)
> }
> PTMpvalMeans[rho*10 + 1] <- mean(PTMpval)
> print(rho)
> print(PTMpvalMeans[rho*10 + 1])
> rho <- rho + 0.1
> }
> PTMpvalMeans
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Sat Nov 30 10:43:23 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 30 Nov 2013 20:43:23 +1100
Subject: [R] mat2listw function
In-Reply-To: <CAC0ELpLiXu8ewZGwSQP5Wr8raTn8BhSpRyT6SbQUsn2xLnG3yQ@mail.gmail.com>
References: <CAC0ELpLiXu8ewZGwSQP5Wr8raTn8BhSpRyT6SbQUsn2xLnG3yQ@mail.gmail.com>
Message-ID: <5299B33B.3050809@bitwrit.com.au>

On 11/30/2013 07:05 AM, Jacquelyn Pless wrote:
> Hi all,
>
> I am attempting to create a weights object and perform a Moran I test as
> well. I have a very large spatial weights matrix (roughly 22,000x22,000)
> that was created in Excel and read into R, and I'm now trying to implement:
>
> library(spdep)
> SW=mat2listw(matrix)
>
> I am getting the following error:
> Error in if (any(x<0)) stop ("values in x cannot be negative"): missing
> value where TRUE/FALSE needed.
>
> What's going wrong here? My current matrix is all 0's and 1's, with no
> missing values and no negative elements. What am I missing?
>
> I'd appreciate any advice. Thanks in advance for your help!
>
Hi Jacquelyn,
The first thing I would do is enter:

sum(is.na(x))

and if anything other than zero is returned, you will know what's wrong. 
Your dataset has been imported from Excel, and that application is 
notorious for exporting things in the way it knows you want them to be. Not.

Jim


From tomfabtastic at hotmail.com  Sat Nov 30 11:42:03 2013
From: tomfabtastic at hotmail.com (Tom O'Brien)
Date: Sat, 30 Nov 2013 23:42:03 +1300
Subject: [R] Solve PDE with initial and boundary conditions in R
Message-ID: <BAY170-W75CCD110C3AB603A40F49CC4E80@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/a7a8b3e0/attachment.pl>

From philipp.grueber at ebs.edu  Sat Nov 30 15:03:38 2013
From: philipp.grueber at ebs.edu (Philipp Grueber)
Date: Sat, 30 Nov 2013 06:03:38 -0800 (PST)
Subject: [R] Calculate Adjusted vcov Matrix acc. to Shanken(1992) (Generated
 Regressor Problem)
Message-ID: <1385820218832-4681404.post@n4.nabble.com>

Dear R Users,

I wish to estimate a regression:
y=a+b x1+c x2+d x3+e 
where a is the constant, b,c,d are coefficients and e represents the
residuals. However, I find x1 and x2 to correlate. In order to avoid
multicollinearity, I split up the estimation:

(1) x2~a1+ b1 x1 + e1
(2) y=a2+b2 x1+ c2 e1+ d2 x3+e2

I believe that using the residuals from regression (1) in (2) induces an
?generated regressor problem? which biases the standard errors obtained (I
am not quite sure because both x1 and the error e1 both are included in my
second regression). (Shanken1992) provides an adjustment which however
refers to a panel setup. Obviously, my setup is unrelated to panels.

Question:
If being applicable to my setup at all, is there an R implementation of
Shanken?s adjustment? See my example below. I try to replicate the
explanation provided in Ch.12 of John Chohcrane's "Asset Pricing" book (page
237ff).  

Any help is highly appreciated. Thank you very much in advance!
Best wishes,
Philipp

PS: Note that a similar question was asked by someone else only few days ago
in the stackexchange network. See
http://stats.stackexchange.com/questions/77617/shanken-1992-correction-for-t-statistics




##################################################################
##################################################################
##################################################################


#packages
library(lmtest)

#Data
y<-rnorm(100)
x1<-rnorm(100)
x2<-rnorm(100)
x3<-rnorm(100)

#I wish to estimate y=c+x1+x2+x3+u but cor(x1,x2) is high. Therefore twostep
procedure: (1) x2~c1+x1+u1 (2) y=c2+x1+u1+x3+u2.
res1<-lm(x2~x1)
coeftest(res1,vcov.=vcov(res1))
vcov(res1)

#I am able to calculate this manually.
X1<-as.matrix(data.frame(A=rep(1,100),B=x1),stringsAsFactors=FALSE)
betas<-solve(crossprod(X1,X1))%*%t(X1)%*%x2
round(coef(res1),digits=10)==round(betas,digits=10)
betas
u1<-resid(res1)
n1<-length(y)
k1<-ncol(X1)
vcov1 = 1/(n1-k1) * as.numeric(t(u1)%*%u1) * solve(t(X1)%*%X1) #= 1/T
vcov1

#Now I do my second regression:
Y<-as.matrix(y)
X2<-as.matrix(data.frame(A=1,B=x1,C=u1,D=x3))
res2<-lm(y~x1+u1+x3)
coeftest(res2,vcov.=vcov(res2))
vcov(res2)

#This is the (biased) variance-covariance matrix:
u2<-resid(res2)
n2<-length(y)
k2<-ncol(X2)
vcov2 = 1/(n2-k2) * as.numeric(t(u2)%*%u2) * solve(t(X2)%*%X2) #= 1/T
vcov2


##############
##############
# So far, this was easy, but in order to implement the Shanken(1992)
adjustment, I need to calculate the variance-covariance matrix manually in
the following way: (See Chohcrane (2005) Asset Pricing Ch.12):  
var_coef<-function(x){
x_mm<-model.matrix(x)
x_s2<-summary(x)$sigma^2
solve(t(x_mm)%*%x_mm)%*%t(x_mm)%*%(x_s2*diag(nobs(x)))%*%x_mm%*%solve(t(x_mm)%*%x_mm)
}
vcov_manual<-var_coef(x=res1)
vcov1
round(vcov1,digits=10)==round(vcov_manual,digits=10)


##################################
# This is where I begin to question whether Shanken's adjustment makes sense
in my setup at all.
##################################
#I calculate the covariance matrix of the residuals cov(u,u')   (note: I am
not sure what it actually tells me / whether it makes sense in my setup)
cov_resid<-function(x){
x_mm<-model.matrix(x)
x_s2<-summary(x)$sigma^2
(diag(nobs(x))-x_mm%*%solve(t(x_mm)%*%x_mm)%*%t(x_mm))%*%(x_s2*diag(nobs(x)))%*%t(diag(nobs(x))-x_mm%*%solve(t(x_mm)%*%x_mm)%*%t(x_mm))
}
cov_resid<-cov_resid(x=res1)
cov_resid[95:100,95:100] #to show only a part

#Another way to go to:
H1<-X1%*%solve(t(X1)%*%X1)%*%t(X1)
((diag(100)-H1)*summary(res1)$sigma^2)[95:100,95:100]

round(((diag(100)-H1)*summary(res1)$sigma^2)[95:100,95:100],digits=10)==round(cov_resid[95:100,95:100],digits=10)

##################################
# This is where I really struggle. I do not know how to get cov(x1,x1').
##################################

#The error covariance of the second regression should be
H1<-X1%*%solve(t(X1)%*%X1)%*%t(X1)
sigma<-((diag(100)-H1)*summary(res1)$sigma^2)
sigma_f<-"???"


#Since the variance-covariance matrix of the second regression should be
vcov2=1/T*((b'b)^(-1)b'Sb(b'b)-sigma_f) I assume:
x=X2
sigma2_f<-(solve(t(x)%*%x)%*%t(x)%*%(sigma)%*%x%*%solve(t(x)%*%x))-vcov2*100
#But then the error covariance cannot be calculated as in Chochrane:
err_cov<-1/100*(coef(res1)%*%sigma2_f%*%coef(res1)+sigma)

##################################
# And then?
##################################

#Given I was able to derive sigma and sigma_f correctly (and that they made
sense), I could then include the Shanken adjustment:
...*(1+t(lambdas)%*%solve(sig_f)%*%lambdas)...
var_coef_adj<-function(x,sig,sig_f){
lambdas<-coef(x)
x_mm<-model.matrix(x)
x_s2<-summary(x)$sigma^2
1/100*(solve(t(x_mm)%*%x_mm)%*%t(x_mm)%*%(sig)%*%x_mm%*%solve(t(x_mm)%*%x_mm) 
*(1+t(lambdas)%*%solve(sig_f)%*%lambdas) +sig_f)
}
#...and thus, hope to obtain the corrected variance-covariance matrix for
the second regression
vcov2_adj<-var_coef_adj(x=res2, sig=sigma, sig_f=sigma2_f)


##################################################################
##################################################################
##################################################################





-----
____________________________________
EBS Universitaet fuer Wirtschaft und Recht
FARE Department
Wiesbaden/ Germany
http://www.ebs.edu/index.php?id=finacc&L=0
--
View this message in context: http://r.789695.n4.nabble.com/Calculate-Adjusted-vcov-Matrix-acc-to-Shanken-1992-Generated-Regressor-Problem-tp4681404.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Sat Nov 30 15:20:41 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 30 Nov 2013 15:20:41 +0100
Subject: [R] Solve PDE with initial and boundary conditions in R
In-Reply-To: <BAY170-W75CCD110C3AB603A40F49CC4E80@phx.gbl>
References: <BAY170-W75CCD110C3AB603A40F49CC4E80@phx.gbl>
Message-ID: <158966F6-A683-48DA-A380-D12137A01737@xs4all.nl>


On 30-11-2013, at 11:42, Tom O'Brien <tomfabtastic at hotmail.com> wrote:

> Hi,I am trying to port the Matlab code in the link below to R: http://en.literateprograms.org/Asian_Option_Pricing_(MATLAB)This code solves a PDE with initial and boundary conditions.Could anyone point me in the right direction in terms of what packages I should use ?Best Regards,Tom 	


See the task view ?Differential Equations? on CRAN: http://cran.r-project.org/web/views/DifferentialEquations.html

Berend

> 	 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nooldor at gmail.com  Sat Nov 30 16:09:38 2013
From: nooldor at gmail.com (nooldor)
Date: Sat, 30 Nov 2013 16:09:38 +0100
Subject: [R] Multiple regressions with changing dependent variable and
 time span
In-Reply-To: <1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>
	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/16a34c68/attachment.pl>

From dwinsemius at comcast.net  Sat Nov 30 17:50:48 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 Nov 2013 08:50:48 -0800
Subject: [R] mat2listw function
In-Reply-To: <5299B33B.3050809@bitwrit.com.au>
References: <CAC0ELpLiXu8ewZGwSQP5Wr8raTn8BhSpRyT6SbQUsn2xLnG3yQ@mail.gmail.com>
	<5299B33B.3050809@bitwrit.com.au>
Message-ID: <95364E15-3C32-4A92-97EB-BFFD1588C620@comcast.net>


On Nov 30, 2013, at 1:43 AM, Jim Lemon wrote:

> On 11/30/2013 07:05 AM, Jacquelyn Pless wrote:
>> Hi all,
>> 
>> I am attempting to create a weights object and perform a Moran I test as
>> well. I have a very large spatial weights matrix (roughly 22,000x22,000)
>> that was created in Excel and read into R, and I'm now trying to implement:
>> 
>> library(spdep)
>> SW=mat2listw(matrix)
>> 
>> I am getting the following error:
>> Error in if (any(x<0)) stop ("values in x cannot be negative"): missing
>> value where TRUE/FALSE needed.
>> 
>> What's going wrong here? My current matrix is all 0's and 1's, with no
>> missing values and no negative elements. What am I missing?
>> 
>> I'd appreciate any advice. Thanks in advance for your help!
>> 
> Hi Jacquelyn,
> The first thing I would do is enter:
> 
> sum(is.na(x))
> 
> and if anything other than zero is returned, you will know what's wrong. Your dataset has been imported from Excel, and that application is notorious for exporting things in the way it knows you want them to be. Not.
> 

The second thing to do (since I wonder if an NA value would provoke that error) is to run 

class(matrix)

I'm guessing it's not a matrix and perhaps a dataframe. In which case then run:

lapply(matrix, class) to see if the columns are "numeric". I'm guessing they may be "factor".

-- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sat Nov 30 18:11:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 30 Nov 2013 09:11:17 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time span
In-Reply-To: <CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>
Message-ID: <1385831477.36735.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
#####1 & 2:

set.seed(432)
dat1 <- as.data.frame(matrix(sample(c(1:60,NA),154*337,replace=TRUE),ncol=337))
?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))

?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
?
?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
library(zoo)
rollapply(lst2[[1]],width=32,FUN=function(z) {z1 <- as.data.frame(z); sum(!!rowSums(is.na(z1)))},by.column=FALSE,align="right")
?#[1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3
?#[38] 4 4 4 4 4 4 4 4 4 3 3 3 3 4 4 4 4 4 4 4 5 5 5 4 4 4 4 4 3 3 3 3 2 2 2 2 2
?#[75] 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2
#[112] 2 2 2 2 2 2 2 2 2 2 2 2

?
res1 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else rep(NA,9)},by.column=FALSE,align="right")))
row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
?dim(res1)
#[1] 41082???? 9


###3. 


library(car)

# vif()
res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); vif(l1) } else rep(NA,3)},by.column=FALSE,align="right")))
row.names(res2) <- rep(paste("r",1:334,sep="."),each=123)
dim(res2)
#[1] 41082???? 3


#DW statistic:
?lst3 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1) } else rep(NA,4)},by.column=FALSE,align="right"))
?res3 <- do.call(rbind,lapply(lst3,function(x) x[,-4]))
row.names(res3) <- rep(paste("r",1:334,sep="."),each=123)
?dim(res3)
#[1] 41082???? 3

##ncvTest()
f4 <- function(meanmod, dta, varmod) {
assign(".dta", dta, envir=.GlobalEnv)
assign(".meanmod", meanmod, envir=.GlobalEnv)
m1 <- lm(.meanmod, .dta)
ans <- ncvTest(m1, varmod)
remove(".dta", envir=.GlobalEnv)
remove(".meanmod", envir=.GlobalEnv)
ans
}

?lst4 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-f4(r~.,z1) } else NA},by.column=FALSE,align="right"))
names(lst4) <- paste("r",1:334,sep=".") 
length(lst4)
#[1] 334


###jarque.bera.test
library(tseries)
res5 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); resid <- residuals(l1); unlist(jarque.bera.test(resid)[1:3]) } else rep(NA,3)},by.column=FALSE,align="right")))
?dim(res5)
#[1] 41082???? 3


##the lag() thing is not clear.

A.K.






On Saturday, November 30, 2013 10:09 AM, nooldor <nooldor at gmail.com> wrote:

Hi,

Thanks for reply!


Three things:
1. 
I did not write that some of the data has more then 31 NA in the column and then it is not possible to run lm()

Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 (non-NA) casesIn this case program should return "NA" symbol and go further, in the case when length of the observations is shorter then 31 program should always return "NA" but go further .


2. in your result matrix there are only 4 columns (for estimates of the coefficients), is it possible to put there 4 more columns with p-values and one column with R squared


3. basic statistical test for the regressions:

inflation factors can be captured by:
res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) 
? vif(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))

and DW statistic:
res3 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) 
? durbinWatsonTest(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))


3a)is that right? 
3b) how to do and have in user-friendly form durbinWatsonTest for more then 1 lag?

3c) how to apply: jarque.bera.test from library(tseries) and ncvTest from library(car) ???






Pozdrowienia,

Tomasz Schabek


On 30 November 2013 07:42, arun <smartpink111 at yahoo.com> wrote:

Hi,
>The link seems to be not working.? From the description, it looks like:
>set.seed(432)
>dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>
>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>library(zoo)
>
>res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>
>row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
>?dim(res)
>#[1] 41082???? 4
>
>coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
>#(Intercept)???????? F.1???????? F.2???????? F.3
>#109.9168150? -0.1705361? -0.1028231?? 0.2027911
>coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
>#(Intercept)???????? F.1???????? F.2???????? F.3
>#119.3718949? -0.1660709? -0.2059830?? 0.1338608
>res[1:2,]
>#??? (Intercept)??????? F.1??????? F.2?????? F.3
>#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
>#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608
>
>A.K.
>
>
>
>
>
>
>On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
>Hi all!
>
>
>I am just starting my adventure with R, so excuse me naive questions.
>
>My data look like that:
>
><http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>
>
>I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
>(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
>regression.
>
>Total span of the time is 154 observations. But I would like to have rolling
>window regression with length of 31 observations.
>
>I would like to run script like that:
>
>summary(lm(r.1~F.1+F.2+F.3, data=data))
>vif(lm(r.1~F.1+F.2+F.3, data=data))
>
>But for each of 334 (r.1 to r.334) dependent variables separately and with
>rolling-window of the length 31obs.
>
>Id est:
>summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
>31. for the first regression) times for rolling-fixed period of 31 obs.
>
>The next regression would be:
>summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
>summary(lm(r.334~F.1+F.2+F.3, data=data))
>
>It means it would be 123 x 334 regressions (=41082 regressions)
>
>I would like to save results (summary + vif test) of all those 41082
>regressions in one read-user-friendly file like this given by e.g command
>capture.output()
>
>Could you help with it?
>
>Regards,
>
>T.S.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From smartpink111 at yahoo.com  Sat Nov 30 21:12:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 30 Nov 2013 12:12:43 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time span
In-Reply-To: <CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>
Message-ID: <1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

I was able to read the file after saving it as .csv.? It seems to work without any errors.

dat1<-read.csv("Book2.csv", header=T)
###same as previous

lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
library(zoo)
res1 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else rep(NA,9)},by.column=FALSE,align="right")))
row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
?dim(res1)
#[1] 41082???? 9

#vif
?library(car)
res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); vif(l1) } else rep(NA,3)},by.column=FALSE,align="right")))
row.names(res2) <- rep(paste("r",1:334,sep="."),each=123)
dim(res2)
#[1] 41082???? 3

#DW statistic:
?lst3 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1) } else rep(NA,4)},by.column=FALSE,align="right"))
?res3 <- do.call(rbind,lapply(lst3,function(x) x[,-4]))
row.names(res3) <- rep(paste("r",1:334,sep="."),each=123)
?dim(res3)
#[1] 41082???? 3
##ncvTest()
f4 <- function(meanmod, dta, varmod) {
assign(".dta", dta, envir=.GlobalEnv)
assign(".meanmod", meanmod, envir=.GlobalEnv)
m1 <- lm(.meanmod, .dta)
ans <- ncvTest(m1, varmod)
remove(".dta", envir=.GlobalEnv)
remove(".meanmod", envir=.GlobalEnv)
ans
}

?lst4 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-f4(r~.,z1) } else NA},by.column=FALSE,align="right"))
names(lst4) <- paste("r",1:334,sep=".") 
length(lst4)
#[1] 334


###jarque.bera.test
library(tseries)
res5 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); resid <- residuals(l1); unlist(jarque.bera.test(resid)[1:3]) } else rep(NA,3)},by.column=FALSE,align="right")))
?dim(res5)
#[1] 41082???? 3

A.K.







On Saturday, November 30, 2013 1:44 PM, nooldor <nooldor at gmail.com> wrote:

here is in .xlsx should be easy to open and eventually find&replace commas according to you excel settings (or maybe it will do it automatically)






On 30 November 2013 19:15, arun <smartpink111 at yahoo.com> wrote:

I tried that, but:
>
>
>
>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>> str(dat1)
>'data.frame':??? 154 obs. of? 1 variable:
>
>Then I changed to:
>dat1<-read.table("Book2.csv", head=T, sep="\t", dec=",")
>> str(dat1)
>'data.frame':??? 154 obs. of? 661 variables:
>Both of them are wrong as the number of variables should be 337.
>A.K.
>
>
>
>
>
>
>
>On Saturday, November 30, 2013 12:53 PM, nooldor <nooldor at gmail.com> wrote:
>
>Thank you,
>
>I got your reply. I am just testing your script. I will let you know how is it soon.
>
>.csv could be problematic as commas are used as dec separator (Eastern Europe excel settings) ... I read it in R with this:
>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>
>Thank you very much !!!
>
>T.S.
>
>
>
>
>On 30 November 2013 18:39, arun <smartpink111 at yahoo.com> wrote:
>
>I couldn't read the "Book.csv" as the format is completely messed up.? Anyway, I hope the solution works on your dataset.
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>On Saturday, November 30, 2013 10:34 AM, nooldor <nooldor at gmail.com> wrote:
>>
>>
>>ok.
>>
>>
>>> dat1<-read.table("Book2.csv", head=T, sep=";", dec=",") > colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep=".")) > lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x])) > lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} ) > sum(!!rowSums(is.na(lst2[[1]]))) [1] 57 > #[1] 40 > sapply(lst2,function(x) sum(!!rowSums(is.na(x)))) [1] 57??0 > #[1] 40 46
>>in att you have the data file
>>
>>
>>
>>
>>
>>
>>On 30 November 2013 16:22, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>The first point is not that clear.
>>>
>>>Could you show the expected results in this case?
>>>
>>>set.seed(432)
>>>dat1 <- as.data.frame(matrix(sample(c(1:10,NA),154*5,replace=TRUE),ncol=5))
>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep="."))
>>>lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>
>>>
>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>?sum(!!rowSums(is.na(lst2[[1]])))
>>>#[1] 40
>>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>>#[1] 40 46
>>>
>>>
>>>A.K.
>>>
>>>
>>>
>>>On Saturday, November 30, 2013 10:09 AM, nooldor <nooldor at gmail.com> wrote:
>>>
>>>Hi,
>>>
>>>Thanks for reply!
>>>
>>>
>>>Three things:
>>>1.
>>>I did not write that some of the data has more then 31 NA in the column and then it is not possible to run lm()
>>>
>>>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 (non-NA) casesIn this case program should return "NA" symbol and go further, in the case when length of the observations is shorter then 31 program should always return "NA" but go further .
>>>
>>>
>>>
>>>2. in your result matrix there are only 4 columns (for estimates of the coefficients), is it possible to put there 4 more columns with p-values and one column with R squared
>>>
>>>
>>>3. basic statistical test for the regressions:
>>>
>>>inflation factors can be captured by:
>>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>? vif(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>
>>>and DW statistic:
>>>res3 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>? durbinWatsonTest(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>
>>>
>>>3a)is that right?
>>>
>>>3b) how to do and have in user-friendly form durbinWatsonTest for more then 1 lag?
>>>
>>>3c) how to apply: jarque.bera.test from library(tseries) and ncvTest from library(car) ???
>>>
>>>
>>>
>>>
>>>
>>>
>>>Pozdrowienia,
>>>
>>>Tomasz Schabek
>>>
>>>
>>>On 30 November 2013 07:42, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>The link seems to be not working.? From the description, it looks like:
>>>>set.seed(432)
>>>>dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
>>>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>
>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>library(zoo)
>>>>
>>>>res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>
>>>>row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
>>>>?dim(res)
>>>>#[1] 41082???? 4
>>>>
>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>#109.9168150? -0.1705361? -0.1028231?? 0.2027911
>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>#119.3718949? -0.1660709? -0.2059830?? 0.1338608
>>>>res[1:2,]
>>>>#??? (Intercept)??????? F.1??????? F.2?????? F.3
>>>>#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
>>>>#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608
>>>>
>>>>A.K.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
>>>>Hi all!
>>>>
>>>>
>>>>I am just starting my adventure with R, so excuse me naive questions.
>>>>
>>>>My data look like that:
>>>>
>>>><http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>
>>>>
>>>>I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
>>>>(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
>>>>regression.
>>>>
>>>>Total span of the time is 154 observations. But I would like to have rolling
>>>>window regression with length of 31 observations.
>>>>
>>>>I would like to run script like that:
>>>>
>>>>summary(lm(r.1~F.1+F.2+F.3, data=data))
>>>>vif(lm(r.1~F.1+F.2+F.3, data=data))
>>>>
>>>>But for each of 334 (r.1 to r.334) dependent variables separately and with
>>>>rolling-window of the length 31obs.
>>>>
>>>>Id est:
>>>>summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
>>>>31. for the first regression) times for rolling-fixed period of 31 obs.
>>>>
>>>>The next regression would be:
>>>>summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
>>>>summary(lm(r.334~F.1+F.2+F.3, data=data))
>>>>
>>>>It means it would be 123 x 334 regressions (=41082 regressions)
>>>>
>>>>I would like to save results (summary + vif test) of all those 41082
>>>>regressions in one read-user-friendly file like this given by e.g command
>>>>capture.output()
>>>>
>>>>Could you help with it?
>>>>
>>>>Regards,
>>>>
>>>>T.S.
>>>>
>>>>??? [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>
>


From nooldor at gmail.com  Sat Nov 30 23:03:39 2013
From: nooldor at gmail.com (nooldor)
Date: Sat, 30 Nov 2013 23:03:39 +0100
Subject: [R] Multiple regressions with changing dependent variable and
 time span
In-Reply-To: <1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>
	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>
	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>
	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>
	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>
	<1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20131130/24fb6044/attachment.pl>

From smartpink111 at yahoo.com  Sat Nov 30 23:28:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 30 Nov 2013 14:28:18 -0800 (PST)
Subject: [R] Multiple regressions with changing dependent variable and
	time span
In-Reply-To: <CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>
References: <CAJ0Fr658HvcC1H4-QvZpVQAWrP5_hv5LCwvKJ2m2ucxaV0EN=Q@mail.gmail.com>	<1385793753.75342.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<CAJ0Fr65P64FveOztRxhyJ166Qcnp1cKdbfZCYaFLsEz05xpsCg@mail.gmail.com>	<1385824938.22462.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAJ0Fr65Y6zVuJE8mBoX__bfkvGxWwUsyA9ZS_kUWnaVdy0b2MA@mail.gmail.com>	<1385833171.99079.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr65i-x80BLTAXBibQNt1nQg8J-RVPccFgBJmq9zSerczuA@mail.gmail.com>	<1385835354.85727.YahooMailNeo@web142601.mail.bf1.yahoo.com>	<CAJ0Fr6739v28rf7yNqFgguMMoqi8bav6D7Wn8Q0TUDoqjdzBPw@mail.gmail.com>	<1385842363.40647.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CAJ0Fr67iCNgF-Eqr6_XpsUsa7eb0fjJSqK_CN=mtvbfuZWXPNQ@mail.gmail.com>
Message-ID: <1385850498.46297.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
No problem.

In that case, each column will be a list.? For example if I take the first element of `lst2`
dW1 <- rollapply(lst2[[1]],width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right")

?tail(dW1[,1],1)
#[[1]]
#[1] -0.3602936? 0.1975667 -0.1740797


You can store it by:
resdW1 <- do.call(cbind,lapply(seq_len(ncol(dW1)),function(i) do.call(rbind,dW1[,i]))[1:3])


Similarly, for more than one elements (using a subset of lst2- as it takes time)


lst3 <- lapply(lst2[1:2],function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1,max.lag=3) } else rep(NA,4)},by.column=FALSE,align="right"))

lst3New <- lapply(lst3,function(x) do.call(cbind,lapply(seq_len(ncol(x)),function(i) do.call(rbind,x[,i]))[1:3]))

lst3New <- lapply(lst3New, function(x) {colnames(x) <- paste0(rep(c("r","dw","p"),each=3),1:3); x})

A.K.

On Saturday, November 30, 2013 5:03 PM, nooldor <nooldor at gmail.com> wrote:

Hey!


Yes,
only the D-W test takes so much time, did not check it yet

I checked results (estimates) with manually run regressions (in excel) and they are correct.


I only change the "width" to 31 and "each=123" to 124, cause it should be ((154-31)+1) x 334 = 41416 matrix


with the lag in D-W test I was wondering how to have table when I use durbinWatsonTest(l1,3) - with three lags instead of default 1.

but I can manage it - just need to learn about functions used by you.


Any way: BIG THANK to you!


Best wishes,
T.S.





On 30 November 2013 21:12, arun <smartpink111 at yahoo.com> wrote:

Hi,
>
>I was able to read the file after saving it as .csv.? It seems to work without any errors.
>
>dat1<-read.csv("Book2.csv", header=T)
>###same as previous
>
>
>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>library(zoo)
>
>res1 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); c(coef(l1), pval=summary(l1)$coef[,4], rsquare=summary(l1)$r.squared) } else rep(NA,9)},by.column=FALSE,align="right")))
>row.names(res1) <- rep(paste("r",1:334,sep="."),each=123)
>?dim(res1)
>#[1] 41082???? 9
>
>#vif
>?library(car)
>
>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); vif(l1) } else rep(NA,3)},by.column=FALSE,align="right")))
>row.names(res2) <- rep(paste("r",1:334,sep="."),each=123)
>dim(res2)
>#[1] 41082???? 3
>
>#DW statistic:
>?lst3 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); durbinWatsonTest(l1) } else rep(NA,4)},by.column=FALSE,align="right"))
>?res3 <- do.call(rbind,lapply(lst3,function(x) x[,-4]))
>row.names(res3) <- rep(paste("r",1:334,sep="."),each=123)
>?dim(res3)
>#[1] 41082???? 3
>##ncvTest()
>f4 <- function(meanmod, dta, varmod) {
>assign(".dta", dta, envir=.GlobalEnv)
>assign(".meanmod", meanmod, envir=.GlobalEnv)
>m1 <- lm(.meanmod, .dta)
>ans <- ncvTest(m1, varmod)
>remove(".dta", envir=.GlobalEnv)
>remove(".meanmod", envir=.GlobalEnv)
>ans
>}
>
>?lst4 <- lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-f4(r~.,z1) } else NA},by.column=FALSE,align="right"))
>names(lst4) <- paste("r",1:334,sep=".")
>length(lst4)
>#[1] 334
>
>
>###jarque.bera.test
>library(tseries)
>res5 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) {z1 <- as.data.frame(z); if(!sum(!!rowSums(is.na(z1)))) {l1 <-lm(r~F.1+F.2+F.3,data=z1); resid <- residuals(l1); unlist(jarque.bera.test(resid)[1:3]) } else rep(NA,3)},by.column=FALSE,align="right")))
>?dim(res5)
>#[1] 41082???? 3
>
>A.K.
>
>
>
>
>
>
>
>
>On Saturday, November 30, 2013 1:44 PM, nooldor <nooldor at gmail.com> wrote:
>
>here is in .xlsx should be easy to open and eventually find&replace commas according to you excel settings (or maybe it will do it automatically)
>
>
>
>
>
>
>On 30 November 2013 19:15, arun <smartpink111 at yahoo.com> wrote:
>
>I tried that, but:
>>
>>
>>
>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>> str(dat1)
>>'data.frame':??? 154 obs. of? 1 variable:
>>
>>Then I changed to:
>>dat1<-read.table("Book2.csv", head=T, sep="\t", dec=",")
>>> str(dat1)
>>'data.frame':??? 154 obs. of? 661 variables:
>>Both of them are wrong as the number of variables should be 337.
>>A.K.
>>
>>
>>
>>
>>
>>
>>
>>On Saturday, November 30, 2013 12:53 PM, nooldor <nooldor at gmail.com> wrote:
>>
>>Thank you,
>>
>>I got your reply. I am just testing your script. I will let you know how is it soon.
>>
>>.csv could be problematic as commas are used as dec separator (Eastern Europe excel settings) ... I read it in R with this:
>>dat1<-read.table("Book2.csv", head=T, sep=";", dec=",")
>>
>>Thank you very much !!!
>>
>>T.S.
>>
>>
>>
>>
>>On 30 November 2013 18:39, arun <smartpink111 at yahoo.com> wrote:
>>
>>I couldn't read the "Book.csv" as the format is completely messed up.? Anyway, I hope the solution works on your dataset.
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>On Saturday, November 30, 2013 10:34 AM, nooldor <nooldor at gmail.com> wrote:
>>>
>>>
>>>ok.
>>>
>>>
>>>> dat1<-read.table("Book2.csv", head=T, sep=";", dec=",") > colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep=".")) > lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x])) > lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} ) > sum(!!rowSums(is.na(lst2[[1]]))) [1] 57 > #[1] 40 > sapply(lst2,function(x) sum(!!rowSums(is.na(x)))) [1] 57??0 > #[1] 40 46
>>>in att you have the data file
>>>
>>>
>>>
>>>
>>>
>>>
>>>On 30 November 2013 16:22, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>The first point is not that clear.
>>>>
>>>>Could you show the expected results in this case?
>>>>
>>>>set.seed(432)
>>>>dat1 <- as.data.frame(matrix(sample(c(1:10,NA),154*5,replace=TRUE),ncol=5))
>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:2,sep="."))
>>>>lst1 <- lapply(paste("r",1:2,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>
>>>>
>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>?sum(!!rowSums(is.na(lst2[[1]])))
>>>>#[1] 40
>>>>?sapply(lst2,function(x) sum(!!rowSums(is.na(x))))
>>>>#[1] 40 46
>>>>
>>>>
>>>>A.K.
>>>>
>>>>
>>>>
>>>>On Saturday, November 30, 2013 10:09 AM, nooldor <nooldor at gmail.com> wrote:
>>>>
>>>>Hi,
>>>>
>>>>Thanks for reply!
>>>>
>>>>
>>>>Three things:
>>>>1.
>>>>I did not write that some of the data has more then 31 NA in the column and then it is not possible to run lm()
>>>>
>>>>Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :??0 (non-NA) casesIn this case program should return "NA" symbol and go further, in the case when length of the observations is shorter then 31 program should always return "NA" but go further .
>>>>
>>>>
>>>>
>>>>2. in your result matrix there are only 4 columns (for estimates of the coefficients), is it possible to put there 4 more columns with p-values and one column with R squared
>>>>
>>>>
>>>>3. basic statistical test for the regressions:
>>>>
>>>>inflation factors can be captured by:
>>>>res2 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>? vif(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>
>>>>and DW statistic:
>>>>res3 <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z)
>>>>? durbinWatsonTest(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>
>>>>
>>>>3a)is that right?
>>>>
>>>>3b) how to do and have in user-friendly form durbinWatsonTest for more then 1 lag?
>>>>
>>>>3c) how to apply: jarque.bera.test from library(tseries) and ncvTest from library(car) ???
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>Pozdrowienia,
>>>>
>>>>Tomasz Schabek
>>>>
>>>>
>>>>On 30 November 2013 07:42, arun <smartpink111 at yahoo.com> wrote:
>>>>
>>>>Hi,
>>>>>The link seems to be not working.? From the description, it looks like:
>>>>>set.seed(432)
>>>>>dat1 <- as.data.frame(matrix(sample(200,154*337,replace=TRUE),ncol=337))
>>>>>?colnames(dat1) <- c(paste("F",1:3,sep="."),paste("r",1:334,sep="."))
>>>>>lst1 <- lapply(paste("r",1:334,sep="."),function(x) cbind(dat1[,c(1:3)],dat1[x]))
>>>>>
>>>>>?lst2 <- lapply(lst1,function(x) {colnames(x)[4] <-"r";x} )
>>>>>library(zoo)
>>>>>
>>>>>res <- do.call(rbind,lapply(lst2,function(x) rollapply(x,width=32,FUN=function(z) coef(lm(r~ F.1+F.2+F.3,data=as.data.frame(z))),by.column=FALSE,align="right")))
>>>>>
>>>>>row.names(res) <- rep(paste("r",1:334,sep="."),each=123)
>>>>>?dim(res)
>>>>>#[1] 41082???? 4
>>>>>
>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[1:32,]) )
>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>#109.9168150? -0.1705361? -0.1028231?? 0.2027911
>>>>>coef(lm(r.1~F.1+F.2+F.3,data=dat1[2:33,]) )
>>>>>#(Intercept)???????? F.1???????? F.2???????? F.3
>>>>>#119.3718949? -0.1660709? -0.2059830?? 0.1338608
>>>>>res[1:2,]
>>>>>#??? (Intercept)??????? F.1??????? F.2?????? F.3
>>>>>#r.1??? 109.9168 -0.1705361 -0.1028231 0.2027911
>>>>>#r.1??? 119.3719 -0.1660709 -0.2059830 0.1338608
>>>>>
>>>>>A.K.
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>On Friday, November 29, 2013 6:43 PM, nooldor <nooldor at gmail.com> wrote:
>>>>>Hi all!
>>>>>
>>>>>
>>>>>I am just starting my adventure with R, so excuse me naive questions.
>>>>>
>>>>>My data look like that:
>>>>>
>>>>><http://r.789695.n4.nabble.com/file/n4681391/data_descr_img.jpg>
>>>>>
>>>>>I have 3 independent variables (F.1, F.2 and F.3) and 334 other variables
>>>>>(r.1, r.2, ... r.334) - each one of these will be dependent variable in my
>>>>>regression.
>>>>>
>>>>>Total span of the time is 154 observations. But I would like to have rolling
>>>>>window regression with length of 31 observations.
>>>>>
>>>>>I would like to run script like that:
>>>>>
>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>vif(lm(r.1~F.1+F.2+F.3, data=data))
>>>>>
>>>>>But for each of 334 (r.1 to r.334) dependent variables separately and with
>>>>>rolling-window of the length 31obs.
>>>>>
>>>>>Id est:
>>>>>summary(lm(r.1~F.1+F.2+F.3, data=data)) would be run 123 (154 total obs -
>>>>>31. for the first regression) times for rolling-fixed period of 31 obs.
>>>>>
>>>>>The next regression would be:
>>>>>summary(lm(r.2~F.1+F.2+F.3, data=data)) also 123 times ... and so on till
>>>>>summary(lm(r.334~F.1+F.2+F.3, data=data))
>>>>>
>>>>>It means it would be 123 x 334 regressions (=41082 regressions)
>>>>>
>>>>>I would like to save results (summary + vif test) of all those 41082
>>>>>regressions in one read-user-friendly file like this given by e.g command
>>>>>capture.output()
>>>>>
>>>>>Could you help with it?
>>>>>
>>>>>Regards,
>>>>>
>>>>>T.S.
>>>>>
>>>>>??? [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>
>>
>


