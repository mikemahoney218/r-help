From altomani.andrea at gmail.com  Fri Sep  1 16:23:24 2017
From: altomani.andrea at gmail.com (Andrea Altomani)
Date: Fri, 1 Sep 2017 16:23:24 +0200
Subject: [R] Precision error in time index of ts objects
Message-ID: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>

I have a time series x, and two other series obtained from it:

x <- structure(2017, .Tsp = c(2017.41666666667, 2017.41666666667, 12),
class = "ts")
y <- floor(x)
z <- x-y

I would expect the three series to have exactly the same index.
However I get the following

> time(x)-time(y)
     Jun
2017   0

as expected, but

> time(x)-time(z)
integer(0)
Warning message:
In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
deparse(substitute(e2))[1L]),  :
  non-intersecting series

and indeed, comparing the indices gives:

> time(x)[1]-time(z)[1]
[1] 3.183231e-12

Is this a bug in R, or is it one of the expected precision errors due
to the use of limited precision floats?

I am using R 3.4.0 (2017-04-21) on Windows (64-bit).

Thaks!

Andrea Altomani


From jdnewmil at dcn.davis.ca.us  Fri Sep  1 17:52:52 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 01 Sep 2017 08:52:52 -0700
Subject: [R] Precision error in time index of ts objects
In-Reply-To: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
References: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
Message-ID: <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>

You already know the answer. Why ask? 
-- 
Sent from my phone. Please excuse my brevity.

On September 1, 2017 7:23:24 AM PDT, Andrea Altomani <altomani.andrea at gmail.com> wrote:
>I have a time series x, and two other series obtained from it:
>
>x <- structure(2017, .Tsp = c(2017.41666666667, 2017.41666666667, 12),
>class = "ts")
>y <- floor(x)
>z <- x-y
>
>I would expect the three series to have exactly the same index.
>However I get the following
>
>> time(x)-time(y)
>     Jun
>2017   0
>
>as expected, but
>
>> time(x)-time(z)
>integer(0)
>Warning message:
>In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
>deparse(substitute(e2))[1L]),  :
>  non-intersecting series
>
>and indeed, comparing the indices gives:
>
>> time(x)[1]-time(z)[1]
>[1] 3.183231e-12
>
>Is this a bug in R, or is it one of the expected precision errors due
>to the use of limited precision floats?
>
>I am using R 3.4.0 (2017-04-21) on Windows (64-bit).
>
>Thaks!
>
>Andrea Altomani
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From altomani.andrea at gmail.com  Fri Sep  1 19:36:56 2017
From: altomani.andrea at gmail.com (Andrea Altomani)
Date: Fri, 01 Sep 2017 17:36:56 +0000
Subject: [R] Precision error in time index of ts objects
In-Reply-To: <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>
References: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
 <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>
Message-ID: <CAFaNUJK-0ai2aEXXwJS0soQR0BK3WRF2mG96yZdTmZBvgjj8MQ@mail.gmail.com>

I should have formulated my question in a more specific way.

1. I suspect this is a floating point precision issue. I am not very
knowledgeable about R internals, can someone else confirm it?

2. Should this be considered a bug or not, because it is "just a precision
issue"? Should I report it?

3. How can it happen? From a quick review of ts.R, it looks like the values
of the time index are never modified, but only possibly removed. In my case:
   - x and y have the same index.
   - the subtraction operator recognizes this, and create a new ts with one
entry
   - the result of the subtraction has an index which is different from the
input.
  This is very surprising to me, and I am curious to understand the problem.


--
Andrea Altomani



On Fri, Sep 1, 2017 at 5:53 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You already know the answer. Why ask?
> --
> Sent from my phone. Please excuse my brevity.
>
> On September 1, 2017 7:23:24 AM PDT, Andrea Altomani <
> altomani.andrea at gmail.com> wrote:
> >I have a time series x, and two other series obtained from it:
> >
> >x <- structure(2017, .Tsp = c(2017.41666666667, 2017.41666666667, 12),
> >class = "ts")
> >y <- floor(x)
> >z <- x-y
> >
> >I would expect the three series to have exactly the same index.
> >However I get the following
> >
> >> time(x)-time(y)
> >     Jun
> >2017   0
> >
> >as expected, but
> >
> >> time(x)-time(z)
> >integer(0)
> >Warning message:
> >In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
> >deparse(substitute(e2))[1L]),  :
> >  non-intersecting series
> >
> >and indeed, comparing the indices gives:
> >
> >> time(x)[1]-time(z)[1]
> >[1] 3.183231e-12
> >
> >Is this a bug in R, or is it one of the expected precision errors due
> >to the use of limited precision floats?
> >
> >I am using R 3.4.0 (2017-04-21) on Windows (64-bit).
> >
> >Thaks!
> >
> >Andrea Altomani
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From taur.vil at gmail.com  Fri Sep  1 20:02:04 2017
From: taur.vil at gmail.com (Tauras Vilgalys)
Date: Fri, 1 Sep 2017 14:02:04 -0400
Subject: [R] How does pbtree (from the phytools package) work?
Message-ID: <CAM-xYmROqj5g=Bx5cd2u9-QNgAv924b1e1Uof9y5y0YeVtaUoQ@mail.gmail.com>

Hi, I'm interested in using pbtree (package phytools) to simulate a
phylogeny, but would first like to understand how the simulation works
(i.e. when does a split occur and how is the split chosen?). Can anyone
point me to the model that is used?

Thank you!

	[[alternative HTML version deleted]]


From merlinverdecia at infomed.sld.cu  Fri Sep  1 22:25:47 2017
From: merlinverdecia at infomed.sld.cu (merlinverdecia at infomed.sld.cu)
Date: Fri, 01 Sep 2017 16:25:47 -0400
Subject: [R] correlation between nominal and ordinal
Message-ID: <20170901162547.71152juawubmdp3f@webmail.sld.cu>

I would be very grateful if you would tell me how I can find the  
degree of correlation between a nominal dependent variable and an  
independent ordinal variable. The nominal variable has only two  
levels: YES and NO.
thank you very much in advance
regards,
merlin

----------------------------------------------------------------




--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From ruipbarradas at sapo.pt  Fri Sep  1 23:47:17 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Fri, 01 Sep 2017 22:47:17 +0100
Subject: [R] How does pbtree (from the phytools package) work?
In-Reply-To: <CAM-xYmROqj5g=Bx5cd2u9-QNgAv924b1e1Uof9y5y0YeVtaUoQ@mail.gmail.com>
Message-ID: <20170901224717.Horde.vejaW7bSKb2DBoHOK0dfPg7@mail.sapo.pt>

Hello,

The best way for you to know that is to read the package's documentation.

https://cran.r-project.org/web/packages/phytools/index.html

I suggest the refference manual phytools.pdf

Hope this helps,

Rui Barradas



Citando Tauras Vilgalys <taur.vil at gmail.com>:

> Hi, I'm interested in using pbtree (package phytools) to simulate a
> phylogeny, but would first like to understand how the simulation works
> (i.e. when does a split occur and how is the split chosen?). Can anyone
> point me to the model that is used?
>
> Thank you!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Sep  2 00:25:13 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 1 Sep 2017 15:25:13 -0700
Subject: [R] correlation between nominal and ordinal
In-Reply-To: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
References: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
Message-ID: <CAGxFJbRrHK=W8tozrQXF7Rj=zVFJKYV1p31gFThjV3=VtB4WBA@mail.gmail.com>

Wrong list. This list is about programming in R, not statistics. Try
stats.stackexchange.com instead for statistics questions.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 1, 2017 at 1:25 PM, <merlinverdecia at infomed.sld.cu> wrote:

> I would be very grateful if you would tell me how I can find the degree of
> correlation between a nominal dependent variable and an independent ordinal
> variable. The nominal variable has only two levels: YES and NO.
> thank you very much in advance
> regards,
> merlin
>
> ----------------------------------------------------------------
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que
> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
> Nacional de Salud. La persona que envia este correo asume el compromiso de
> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sat Sep  2 00:30:53 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 2 Sep 2017 00:30:53 +0200 (CEST)
Subject: [R] Precision error in time index of ts objects
In-Reply-To: <CAFaNUJK-0ai2aEXXwJS0soQR0BK3WRF2mG96yZdTmZBvgjj8MQ@mail.gmail.com>
References: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
 <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>
 <CAFaNUJK-0ai2aEXXwJS0soQR0BK3WRF2mG96yZdTmZBvgjj8MQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1709020007120.12886@paninaro>

On Fri, 1 Sep 2017, Andrea Altomani wrote:

> I should have formulated my question in a more specific way.
>
> 1. I suspect this is a floating point precision issue. I am not very 
> knowledgeable about R internals, can someone else confirm it?

Yes. If you represent a series with increment 1/12 it depends on how you 
do it. As a simple example consider the following two descriptions of the 
same time point:

2 - 1/12
## [1] 1.916667

1 + 11/12
## [1] 1.916667

However, both are not identical:

(2 - 1/12) == (1 + 11/12)
## [1] FALSE

The difference is just the .Machine$double.eps:

(2 - 1/12) - (1 + 11/12)
## [1] 2.220446e-16

> 2. Should this be considered a bug or not, because it is "just a 
> precision issue"? Should I report it?

I don't think it is a bug because of the (non-standard) way how you 
created the time series.

> 3. How can it happen? From a quick review of ts.R, it looks like the values
> of the time index are never modified, but only possibly removed. In my case:
>   - x and y have the same index.
>   - the subtraction operator recognizes this, and create a new ts with one
> entry
>   - the result of the subtraction has an index which is different from the
> input.
>  This is very surprising to me, and I am curious to understand the problem.

The object 'x' and hence the object 'y' have the same time index. But in 
'z' a new time index is created which is subtly different from that of 
'x'. The reason for this is that R doesn't expect an object like 'x' to 
exist.

You should create a "ts" object with ts(), e.g.,

x <- ts(2017, start = c(2017, 6), freqency = 12)

But you created something close to the internal representation...but not 
close enough:

y <- structure(2017, .Tsp = c(2017.416667, 2017.416667, 12), class = "ts")

The print functions prints both print(x) and print(y) as

       Jun
2017 2017

However, aligning the two time indexes in x - y or ts.intersect(x, y) does 
not work...because they are not the same

as.numeric(time(x)) - as.numeric(time(y))
## [1] -3.333332e-07

The "ts" code tries to avoid these situations by making many time index 
comparisons only up to a precision of getOption("ts.eps") (1e-5 by 
default) but this is not used everywhere. See ?options:

     'ts.eps': the relative tolerance for certain time series ('ts')
           computations.  Default '1e-05'.

Of course, you could ask for this being used in more places, e.g., in 
stats:::.cbind.ts() where (st > en) is used rather than ((st - en) > 
getOption("ts.eps")). But it's probably safer to just use ts() rather than 
structure(). Or if you use the latter make sure that you do at a high 
enough precision.

hth,
Z


> On Fri, Sep 1, 2017 at 5:53 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> You already know the answer. Why ask?
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On September 1, 2017 7:23:24 AM PDT, Andrea Altomani <
>> altomani.andrea at gmail.com> wrote:
>>> I have a time series x, and two other series obtained from it:
>>>
>>> x <- structure(2017, .Tsp = c(2017.41666666667, 2017.41666666667, 12),
>>> class = "ts")
>>> y <- floor(x)
>>> z <- x-y
>>>
>>> I would expect the three series to have exactly the same index.
>>> However I get the following
>>>
>>>> time(x)-time(y)
>>>     Jun
>>> 2017   0
>>>
>>> as expected, but
>>>
>>>> time(x)-time(z)
>>> integer(0)
>>> Warning message:
>>> In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
>>> deparse(substitute(e2))[1L]),  :
>>>  non-intersecting series
>>>
>>> and indeed, comparing the indices gives:
>>>
>>>> time(x)[1]-time(z)[1]
>>> [1] 3.183231e-12
>>>
>>> Is this a bug in R, or is it one of the expected precision errors due
>>> to the use of limited precision floats?
>>>
>>> I am using R 3.4.0 (2017-04-21) on Windows (64-bit).
>>>
>>> Thaks!
>>>
>>> Andrea Altomani
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From yliu206 at jhu.edu  Sat Sep  2 01:37:42 2017
From: yliu206 at jhu.edu (Yingrui Liu)
Date: Fri, 1 Sep 2017 23:37:42 +0000
Subject: [R] How to use getSymbols() to get annual data
Message-ID: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>

Dear Sir/Madam,


How to use getSymbols() to get annual data? For example, I need the annual stock price of APPLE from the year 2000 to 2016. How to write the command? I only know how to get the daily data. It is:


getSymbols("AAPL",from="2000-01-01",to="2016-12-31")


Thank you very much.


Have a good week!


Best regards,


Yingrui Liu


	[[alternative HTML version deleted]]


From mrguilfoyle at gmail.com  Sat Sep  2 05:42:12 2017
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Sat, 2 Sep 2017 04:42:12 +0100
Subject: [R] correlation between nominal and ordinal
In-Reply-To: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
References: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
Message-ID: <A2192A2D-6BEC-433C-8C1B-F2C8528B3159@gmail.com>

Any of the usual rank correlation methods should be fine if you're expecting a monotonic relationship e.g. Spearman's rho or Kendall's tau.

> On 1 Sep 2017, at 21:25, merlinverdecia at infomed.sld.cu wrote:
> 
> I would be very grateful if you would tell me how I can find the degree of correlation between a nominal dependent variable and an independent ordinal variable. The nominal variable has only two levels: YES and NO.
> thank you very much in advance
> regards,
> merlin
> 
> ----------------------------------------------------------------
> 
> 
> 
> 
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas
> 
> Infomed: http://www.sld.cu/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Sep  2 06:54:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 1 Sep 2017 21:54:59 -0700 (PDT)
Subject: [R] How to use getSymbols() to get annual data
In-Reply-To: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
References: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
Message-ID: <alpine.BSF.2.00.1709012140380.48664@pedal.dcn.davis.ca.us>

I suppose that might depend what you mean by "annual data".

?yearlyReturn

or

###
library(quantmod)
#> Loading required package: xts
#> Loading required package: zoo
#>
#> Attaching package: 'zoo'
#> The following objects are masked from 'package:base':
#>
#>     as.Date, as.Date.numeric
#> Loading required package: TTR
#> Version 0.4-0 included new data defaults. See ?getSymbols.
getSymbols("AAPL",from="2000-01-01",to="2016-12-31")
#> 'getSymbols' currently uses auto.assign=TRUE by default, but will
#> use auto.assign=FALSE in 0.5-0. You will still be able to use
#> 'loadSymbols' to automatically load data. 
getOption("getSymbols.env")
#> and getOption("getSymbols.auto.assign") will still be checked for
#> alternate defaults.
#>
#> This message is shown once per session and may be disabled by 
setting
#> options("getSymbols.warning4.0"=FALSE). See ?getSymbols for details.
#>
#> WARNING: There have been significant changes to Yahoo Finance data.
#> Please see the Warning section of '?getSymbols.yahoo' for details.
#>
#> This message is shown once per session and may be disabled by 
setting
#> options("getSymbols.yahoo.warning"=FALSE).
#> [1] "AAPL"
AAPL[ aggregate( index( AAPL )
                , list( Yr = as.POSIXlt( index( AAPL ) )$year + 1900 )
                , FUN=function(d) head(d,1)
                )$x
     ]
#>            AAPL.Open AAPL.High AAPL.Low AAPL.Close AAPL.Volume
#> 2000-01-03     4.163     4.466    4.037   3.997768   133949200
#> 2001-01-02     1.181     1.211    1.156   1.062500   113078000
#> 2002-01-02     1.751     1.850    1.744   1.664286   132374200
#> 2003-01-02     1.140     1.185    1.139   1.057143    45357200
#> 2004-01-02     1.711     1.727    1.682   1.520000    36160600
#> 2005-01-03     5.143     5.169    4.970   4.520714   172998000
#> 2006-01-03    11.493    11.870   11.473  10.678572   201808600
#> 2007-01-03    13.702    13.748   13.005  11.971429   309579900
#> 2008-01-02    31.642    31.799   30.575  27.834286   269794700
#> 2009-01-02    13.637    14.456   13.523  12.964286   186503800
#> 2010-01-04    33.891    34.061   33.724  30.572857   123432400
#> 2011-01-03    51.709    52.442   51.582  47.081429   111284600
#> 2012-01-03    65.009    65.501   64.945  58.747143    75555200
#> 2013-01-02    87.167    87.353   85.249  78.432854   140129500
#> 2014-01-02    85.317    85.524   84.755  79.018570    58671200
#> 2015-01-02   117.249   117.302  112.997 109.330002    53204600
#> 2016-01-04   106.198   109.055  105.567 105.349998    67649400
#>            AAPL.Adjusted
#> 2000-01-03      3.596616
#> 2001-01-02      0.955884
#> 2002-01-02      1.497285
#> 2003-01-02      0.951065
#> 2004-01-02      1.367477
#> 2005-01-03      4.067089
#> 2006-01-03      9.607041
#> 2007-01-03     10.770167
#> 2008-01-02     25.041281
#> 2009-01-02     11.663397
#> 2010-01-04     27.505054
#> 2011-01-03     42.357094
#> 2012-01-03     52.852215
#> 2013-01-02     71.189217
#> 2014-01-02     73.522530
#> 2015-01-02    103.866470
#> 2016-01-04    101.790649
###

Please study the Posting Guide (plain text format, etc), and the vignette 
for the reprex package which can help you confirm your example will run 
for us. (quantmod is not a package we all use...)

On Fri, 1 Sep 2017, Yingrui Liu wrote:

> Dear Sir/Madam,
>
>
> How to use getSymbols() to get annual data? For example, I need the annual stock price of APPLE from the year 2000 to 2016. How to write the command? I only know how to get the daily data. It is:
>
>
> getSymbols("AAPL",from="2000-01-01",to="2016-12-31")
>
>
> Thank you very much.
>
>
> Have a good week!
>
>
> Best regards,
>
>
> Yingrui Liu
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bgunter.4567 at gmail.com  Sat Sep  2 07:09:36 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 1 Sep 2017 22:09:36 -0700
Subject: [R] How to use getSymbols() to get annual data
In-Reply-To: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
References: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
Message-ID: <CAGxFJbStMdE77GWOp+E4OAGqcADPxgv0_MhVkCy+VdgYpeMjqw@mail.gmail.com>

Reading ?getSymbols, why do think you can get yearly data if the src --
"yahoo" by default -- only contains daily data? And if you can get the
daily data, why can't you just pick a day from each year to make it yearly?

Note: I'm not a quantmod user, so apologies if I just don't get it.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 1, 2017 at 4:37 PM, Yingrui Liu <yliu206 at jhu.edu> wrote:

> Dear Sir/Madam,
>
>
> How to use getSymbols() to get annual data? For example, I need the annual
> stock price of APPLE from the year 2000 to 2016. How to write the command?
> I only know how to get the daily data. It is:
>
>
> getSymbols("AAPL",from="2000-01-01",to="2016-12-31")
>
>
> Thank you very much.
>
>
> Have a good week!
>
>
> Best regards,
>
>
> Yingrui Liu
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From christian at echoffmann.ch  Sat Sep  2 11:40:02 2017
From: christian at echoffmann.ch (Christian)
Date: Sat, 2 Sep 2017 11:40:02 +0200
Subject: [R] Block comment?
Message-ID: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>

I consider it quite worth while to introduce into R syntax a nestable 
block comment like

#{
<block of code>
}#

It would make documentation more easily manageable and lucid.
Is there considerable need for this.

Please, comment on this.
How about R core?

Christian
-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From drjimlemon at gmail.com  Sat Sep  2 12:41:07 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 2 Sep 2017 20:41:07 +1000
Subject: [R] correlation between nominal and ordinal
In-Reply-To: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
References: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
Message-ID: <CA+8X3fWHb9sBvXhpnM_Mv3_S7yd2rnNk5pA+-CdAT1fSopXm7A@mail.gmail.com>

hi merlin,
Check out the hetcor package.

Jim


On Sat, Sep 2, 2017 at 6:25 AM,  <merlinverdecia at infomed.sld.cu> wrote:
> I would be very grateful if you would tell me how I can find the degree of
> correlation between a nominal dependent variable and an independent ordinal
> variable. The nominal variable has only two levels: YES and NO.
> thank you very much in advance
> regards,
> merlin
>
> ----------------------------------------------------------------
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico que
> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
> Nacional de Salud. La persona que envia este correo asume el compromiso de
> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From altomani.andrea at gmail.com  Sat Sep  2 13:20:55 2017
From: altomani.andrea at gmail.com (Andrea Altomani)
Date: Sat, 02 Sep 2017 11:20:55 +0000
Subject: [R] Precision error in time index of ts objects
In-Reply-To: <alpine.DEB.2.20.1709020007120.12886@paninaro>
References: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
 <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>
 <CAFaNUJK-0ai2aEXXwJS0soQR0BK3WRF2mG96yZdTmZBvgjj8MQ@mail.gmail.com>
 <alpine.DEB.2.20.1709020007120.12886@paninaro>
Message-ID: <CAFaNUJJGOcCBVYJTww+Qhf4D_jDEUk8MWXETQ+ZQ-Dbz7NrHfQ@mail.gmail.com>

Thanks for the very detailed explanation.

I did not create the series using structure(), that was the result of
dump() on an intermediate object created within tsdisagg::ta(), which is
where I found the error in the first place. ta() indeed manipulates .Tsp
directly, rather than using ts. I guess this is a bug in tsdisagg then.

Thanks!


-- 
Andrea Altomani


On Sat, Sep 2, 2017 at 12:31 AM Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Fri, 1 Sep 2017, Andrea Altomani wrote:
>
> > I should have formulated my question in a more specific way.
> >
> > 1. I suspect this is a floating point precision issue. I am not very
> > knowledgeable about R internals, can someone else confirm it?
>
> Yes. If you represent a series with increment 1/12 it depends on how you
> do it. As a simple example consider the following two descriptions of the
> same time point:
>
> 2 - 1/12
> ## [1] 1.916667
>
> 1 + 11/12
> ## [1] 1.916667
>
> However, both are not identical:
>
> (2 - 1/12) == (1 + 11/12)
> ## [1] FALSE
>
> The difference is just the .Machine$double.eps:
>
> (2 - 1/12) - (1 + 11/12)
> ## [1] 2.220446e-16
>
> > 2. Should this be considered a bug or not, because it is "just a
> > precision issue"? Should I report it?
>
> I don't think it is a bug because of the (non-standard) way how you
> created the time series.
>
> > 3. How can it happen? From a quick review of ts.R, it looks like the
> values
> > of the time index are never modified, but only possibly removed. In my
> case:
> >   - x and y have the same index.
> >   - the subtraction operator recognizes this, and create a new ts with
> one
> > entry
> >   - the result of the subtraction has an index which is different from
> the
> > input.
> >  This is very surprising to me, and I am curious to understand the
> problem.
>
> The object 'x' and hence the object 'y' have the same time index. But in
> 'z' a new time index is created which is subtly different from that of
> 'x'. The reason for this is that R doesn't expect an object like 'x' to
> exist.
>
> You should create a "ts" object with ts(), e.g.,
>
> x <- ts(2017, start = c(2017, 6), freqency = 12)
>
> But you created something close to the internal representation...but not
> close enough:
>
> y <- structure(2017, .Tsp = c(2017.416667, 2017.416667, 12), class = "ts")
>
> The print functions prints both print(x) and print(y) as
>
>        Jun
> 2017 2017
>
> However, aligning the two time indexes in x - y or ts.intersect(x, y) does
> not work...because they are not the same
>
> as.numeric(time(x)) - as.numeric(time(y))
> ## [1] -3.333332e-07
>
> The "ts" code tries to avoid these situations by making many time index
> comparisons only up to a precision of getOption("ts.eps") (1e-5 by
> default) but this is not used everywhere. See ?options:
>
>      'ts.eps': the relative tolerance for certain time series ('ts')
>            computations.  Default '1e-05'.
>
> Of course, you could ask for this being used in more places, e.g., in
> stats:::.cbind.ts() where (st > en) is used rather than ((st - en) >
> getOption("ts.eps")). But it's probably safer to just use ts() rather than
> structure(). Or if you use the latter make sure that you do at a high
> enough precision.
>
> hth,
> Z
>
>
> > On Fri, Sep 1, 2017 at 5:53 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> You already know the answer. Why ask?
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On September 1, 2017 7:23:24 AM PDT, Andrea Altomani <
> >> altomani.andrea at gmail.com> wrote:
> >>> I have a time series x, and two other series obtained from it:
> >>>
> >>> x <- structure(2017, .Tsp = c(2017.41666666667, 2017.41666666667, 12),
> >>> class = "ts")
> >>> y <- floor(x)
> >>> z <- x-y
> >>>
> >>> I would expect the three series to have exactly the same index.
> >>> However I get the following
> >>>
> >>>> time(x)-time(y)
> >>>     Jun
> >>> 2017   0
> >>>
> >>> as expected, but
> >>>
> >>>> time(x)-time(z)
> >>> integer(0)
> >>> Warning message:
> >>> In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
> >>> deparse(substitute(e2))[1L]),  :
> >>>  non-intersecting series
> >>>
> >>> and indeed, comparing the indices gives:
> >>>
> >>>> time(x)[1]-time(z)[1]
> >>> [1] 3.183231e-12
> >>>
> >>> Is this a bug in R, or is it one of the expected precision errors due
> >>> to the use of limited precision floats?
> >>>
> >>> I am using R 3.4.0 (2017-04-21) on Windows (64-bit).
> >>>
> >>> Thaks!
> >>>
> >>> Andrea Altomani
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Sep  2 14:09:03 2017
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 2 Sep 2017 14:09:03 +0200
Subject: [R] Block comment?
In-Reply-To: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
Message-ID: <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>



On 02.09.2017 11:40, Christian wrote:
> I consider it quite worth while to introduce into R syntax a nestable 
> block comment like
> 
> #{
> <block of code>
> }#

if(FALSE){
<block of code>
}

Best,
Uwe Ligges


> It would make documentation more easily manageable and lucid.
> Is there considerable need for this.
> 
> Please, comment on this.
> How about R core?
> 
> Christian


From murdoch.duncan at gmail.com  Sat Sep  2 14:15:18 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 2 Sep 2017 08:15:18 -0400
Subject: [R] How to use getSymbols() to get annual data
In-Reply-To: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
References: <CY4PR0101MB30943C4D4FED0C16B0520FA6EA920@CY4PR0101MB3094.prod.exchangelabs.com>
Message-ID: <6b163d11-bdd3-51cc-8fa0-aab6412f39bd@gmail.com>

On 01/09/2017 7:37 PM, Yingrui Liu wrote:
> Dear Sir/Madam,
> 
> 
> How to use getSymbols() to get annual data? For example, I need the annual stock price of APPLE from the year 2000 to 2016. How to write the command? I only know how to get the daily data. It is:
> 
> 
> getSymbols("AAPL",from="2000-01-01",to="2016-12-31")
> 
> 

Presumably you'd need to loop over the years:  get all the daily data in 
a year, calculate the overall High and Low, take the Open from the first 
date, the Close from the last one, and repeat.

Duncan Murdoch


From msuzen at gmail.com  Sat Sep  2 16:54:18 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Sat, 2 Sep 2017 16:54:18 +0200
Subject: [R] Block comment?
In-Reply-To: <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
Message-ID: <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>

AFAIK block comment is not possible
it needs to be implemented in R interpreter and defined in the
parser.'If' solution is not elegant.

On 2 September 2017 at 14:09, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 02.09.2017 11:40, Christian wrote:
>>
>> I consider it quite worth while to introduce into R syntax a nestable
>> block comment like
>>
>> #{
>> <block of code>
>> }#
>
>
> if(FALSE){
> <block of code>
> }
>
> Best,
> Uwe Ligges
>
>
>> It would make documentation more easily manageable and lucid.
>> Is there considerable need for this.
>>
>> Please, comment on this.
>> How about R core?
>>
>> Christian
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Sep  2 17:14:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 2 Sep 2017 08:14:12 -0700
Subject: [R] Block comment?
In-Reply-To: <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
Message-ID: <CAGxFJbTY9i=gAntAKtmOECqGaP0HPKBzaVRgfJpPCFOqN+ddBw@mail.gmail.com>

Uwe showed an R code -ish way to do it. RStudio and probably other R UI's
and IDE's -- which is the way most folks write code, I think -- also make
it easy to do.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 2, 2017 at 7:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:

> AFAIK block comment is not possible
> it needs to be implemented in R interpreter and defined in the
> parser.'If' solution is not elegant.
>
> On 2 September 2017 at 14:09, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
> >
> >
> > On 02.09.2017 11:40, Christian wrote:
> >>
> >> I consider it quite worth while to introduce into R syntax a nestable
> >> block comment like
> >>
> >> #{
> >> <block of code>
> >> }#
> >
> >
> > if(FALSE){
> > <block of code>
> > }
> >
> > Best,
> > Uwe Ligges
> >
> >
> >> It would make documentation more easily manageable and lucid.
> >> Is there considerable need for this.
> >>
> >> Please, comment on this.
> >> How about R core?
> >>
> >> Christian
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Sep  2 17:40:55 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 02 Sep 2017 08:40:55 -0700
Subject: [R] Block comment?
In-Reply-To: <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
Message-ID: <482BFC73-BCC1-43DA-94D3-4F807A01CB96@dcn.davis.ca.us>

I agree, since one reason for block commenting is to include syntactically-invalid information (such as broken code) in the source code.

However, block commenting is not wholly a good thing, as both the R parser and human coders often find it challenging to identify where the end of the block is, making it difficult to tell whether you are looking at live code or comments.  A good editor can add/remove comment marks to "blocks" of lines of code, relieving the programmer of tedium while maintaining clarity about which lines are active or not.

Block commenting is also a bit of a cultural thing, like using or avoiding tab characters in code, or vi-vs-emacs... it is hard to change people's minds about it, and potentially inflammatory to try. I think it is safe to say that the designers of R were aware of block commenting and consciously chose to not include it in the language.
-- 
Sent from my phone. Please excuse my brevity.

On September 2, 2017 7:54:18 AM PDT, "Suzen, Mehmet" <msuzen at gmail.com> wrote:
>AFAIK block comment is not possible
>it needs to be implemented in R interpreter and defined in the
>parser.'If' solution is not elegant.
>
>On 2 September 2017 at 14:09, Uwe Ligges
><ligges at statistik.tu-dortmund.de> wrote:
>>
>>
>> On 02.09.2017 11:40, Christian wrote:
>>>
>>> I consider it quite worth while to introduce into R syntax a
>nestable
>>> block comment like
>>>
>>> #{
>>> <block of code>
>>> }#
>>
>>
>> if(FALSE){
>> <block of code>
>> }
>>
>> Best,
>> Uwe Ligges
>>
>>
>>> It would make documentation more easily manageable and lucid.
>>> Is there considerable need for this.
>>>
>>> Please, comment on this.
>>> How about R core?
>>>
>>> Christian
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Sep  2 17:56:33 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 2 Sep 2017 08:56:33 -0700
Subject: [R] Block comment?
In-Reply-To: <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
Message-ID: <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>

Is the reason you want a block comment containing code (as opposed to
arbitrary text) that you want to be able to easily run the commented out
code?  If so the 'if()' construct has the advantage that you only need to
change code at the start of the comment, not at both ends.

The if(FALSE) could be if(isTRUE(getOption("DEBUG_ISSUE_XYZ"))) so you
would not even have to change code to re-enable the debugging code, just
call options(DEBUG_ISSUE_XYX=TRUE)).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Sep 2, 2017 at 7:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:

> AFAIK block comment is not possible
> it needs to be implemented in R interpreter and defined in the
> parser.'If' solution is not elegant.
>
> On 2 September 2017 at 14:09, Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
> >
> >
> > On 02.09.2017 11:40, Christian wrote:
> >>
> >> I consider it quite worth while to introduce into R syntax a nestable
> >> block comment like
> >>
> >> #{
> >> <block of code>
> >> }#
> >
> >
> > if(FALSE){
> > <block of code>
> > }
> >
> > Best,
> > Uwe Ligges
> >
> >
> >> It would make documentation more easily manageable and lucid.
> >> Is there considerable need for this.
> >>
> >> Please, comment on this.
> >> How about R core?
> >>
> >> Christian
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matthias-gondan at gmx.de  Sat Sep  2 19:22:22 2017
From: matthias-gondan at gmx.de (Matthias Gondan)
Date: Sat, 2 Sep 2017 19:22:22 +0200
Subject: [R] Strange lazy evaluation of default arguments
Message-ID: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>

Dear R developers,

sessionInfo() below

Please have a look at the following two versions of the same function:

1. Intended behavior:

> Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
+ {
+   print(c(u, l, mu)) # here, l is set to u?s value
+   u = u/sqrt(sigma2)
+   l = l/sqrt(sigma2)
+   mu = mu/sqrt(sigma2)
+   print(c(u, l, mu))
+ }
> 
> Su1()
[1] 100.00 100.00   0.53
[1] 23.2558140 23.2558140  0.1232558

In the first version, both u and l are correctly divided by 4.3.

2. Strange behavior:

> Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
+ {
+   # print(c(u, l, mu))
+   u = u/sqrt(sigma2)
+   l = l/sqrt(sigma2) # here, l is set to u?s value
+   mu = mu/sqrt(sigma2)
+   print(c(u, l, mu))
+ }
> 
> Su2()
[1] 23.2558140  5.4083288  0.1232558
In the second version, the print function is commented out, so the variable u is 
copied to l (lowercase L) at a later place, and L is divided twice by 4.3.

Is this behavior intended? It seems strange that the result depends on a debugging message.

Best wishes,

Matthias


> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252    LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.1 tools_3.4.1   


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sat Sep  2 19:33:11 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 02 Sep 2017 18:33:11 +0100
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
Message-ID: <20170902183311.Horde.ahHsAl7ERDoX5FnSu-uvAKS@mail.sapo.pt>

Hello,

One way of preventing that is to use ?force.
Just put

    force(l)

right after the commented out print and before you change 'u'.

Hope this helps,

Rui Barradas



Citando Matthias Gondan <matthias-gondan at gmx.de>:

> Dear R developers,
>
> sessionInfo() below
>
> Please have a look at the following two versions of the same function:
>
> 1. Intended behavior:
>
>> Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   print(c(u, l, mu)) # here, l is set to u?s value
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2)
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
>>
>> Su1()
> [1] 100.00 100.00   0.53
> [1] 23.2558140 23.2558140  0.1232558
>
> In the first version, both u and l are correctly divided by 4.3.
>
> 2. Strange behavior:
>
>> Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   # print(c(u, l, mu))
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2) # here, l is set to u?s value
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
>>
>> Su2()
> [1] 23.2558140  5.4083288  0.1232558
In the second version, the print
> function is commented out, so the variable u is
> copied to l (lowercase L) at a later place, and L is divided twice by 4.3.
>
> Is this behavior intended? It seems strange that the result depends  
> on a debugging message.
>
> Best wishes,
>
> Matthias


> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252     
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 tools_3.4.1
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Sep  2 19:40:50 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 2 Sep 2017 10:40:50 -0700
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <20170902183311.Horde.ahHsAl7ERDoX5FnSu-uvAKS@mail.sapo.pt>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
 <20170902183311.Horde.ahHsAl7ERDoX5FnSu-uvAKS@mail.sapo.pt>
Message-ID: <CAF8bMcZHfZXCtnzpe2o=9Qm2YRWfiipKAXWZc8T=Kup9PEBwqg@mail.gmail.com>

Another way to avoid the problem is to not redefine variables that are
arguments.  E.g.,

> Su3 <- function(u=100, l=u, mu=0.53, sigma2=4.3^2, verbose)
  {
    if (verbose) {
      print(c(u, l, mu))
    }
    uNormalized <- u/sqrt(sigma2)
    lNormalized <- l/sqrt(sigma2)
    muNormalized <- mu/sqrt(sigma2)
    c(uNormalized, lNormalized, muNormalized)
  }
> Su3(verbose=TRUE)
[1] 100.00 100.00   0.53
[1] 23.2558140 23.2558140  0.1232558
> Su3(verbose=FALSE)
[1] 23.2558140 23.2558140  0.1232558

Not redefining variables at all makes debugging easier, although it may
waste space.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Sep 2, 2017 at 10:33 AM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> One way of preventing that is to use ?force.
> Just put
>
>    force(l)
>
> right after the commented out print and before you change 'u'.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Citando Matthias Gondan <matthias-gondan at gmx.de>:
>
>
> Dear R developers,
>>
>> sessionInfo() below
>>
>> Please have a look at the following two versions of the same function:
>>
>> 1. Intended behavior:
>>
>> Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>>>
>> + {
>> +   print(c(u, l, mu)) # here, l is set to u?s value
>> +   u = u/sqrt(sigma2)
>> +   l = l/sqrt(sigma2)
>> +   mu = mu/sqrt(sigma2)
>> +   print(c(u, l, mu))
>> + }
>>
>>>
>>> Su1()
>>>
>> [1] 100.00 100.00   0.53
>> [1] 23.2558140 23.2558140  0.1232558
>>
>> In the first version, both u and l are correctly divided by 4.3.
>>
>> 2. Strange behavior:
>>
>> Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>>>
>> + {
>> +   # print(c(u, l, mu))
>> +   u = u/sqrt(sigma2)
>> +   l = l/sqrt(sigma2) # here, l is set to u?s value
>> +   mu = mu/sqrt(sigma2)
>> +   print(c(u, l, mu))
>> + }
>>
>>>
>>> Su2()
>>>
>> [1] 23.2558140  5.4083288  0.1232558
>>
> In the second version, the print
>
>> function is commented out, so the variable u is
>> copied to l (lowercase L) at a later place, and L is divided twice by 4.3.
>>
>> Is this behavior intended? It seems strange that the result depends on a
>> debugging message.
>>
>> Best wishes,
>>
>> Matthias
>>
>
>
> sessionInfo()
>> R version 3.4.1 (2017-06-30)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> LC_MONETARY=German_Germany.1252
>> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.1 tools_3.4.1
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matthias-gondan at gmx.de  Sat Sep  2 19:53:14 2017
From: matthias-gondan at gmx.de (Matthias Gondan)
Date: Sat, 2 Sep 2017 19:53:14 +0200
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <CAF8bMcZHfZXCtnzpe2o=9Qm2YRWfiipKAXWZc8T=Kup9PEBwqg@mail.gmail.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
 <20170902183311.Horde.ahHsAl7ERDoX5FnSu-uvAKS@mail.sapo.pt>
 <CAF8bMcZHfZXCtnzpe2o=9Qm2YRWfiipKAXWZc8T=Kup9PEBwqg@mail.gmail.com>
Message-ID: <0MZgdm-1e467y1cBK-00LS9c@mail.gmx.com>

Dear Bill,

All makes perfect sense (including the late evaluation). I actually discovered the problem by looking at old code which used your proposed solution. Still I find it strange (and, hnestly, I don?t like R?s behavior in this respect), and I am wondering why u is not being copied to L just before u is assigned a new value. Of course, this would require the R interpreter to track all these dependencies in both ways incl. more complicated ones in which L might depend on more than just u.

In the future, I?ll avoid dependencies between parameters.

Su4 <- function(u=100, l=100, mu=0.53, sigma2=4.3^2) # instead of l=u

And maybe also ?in-place? changes of values?

Best regards,

Matthias

Von: William Dunlap
Gesendet: Samstag, 2. September 2017 19:41
An: Rui Barradas
Cc: Matthias Gondan; r-help at r-project.org
Betreff: Re: [R] Strange lazy evaluation of default arguments

Another way to avoid the problem is to not redefine variables that are arguments.? E.g.,

> Su3 <- function(u=100, l=u, mu=0.53, sigma2=4.3^2, verbose)
? {
? ? if (verbose) {
? ? ? print(c(u, l, mu))
? ? }
? ? uNormalized <- u/sqrt(sigma2)
? ? lNormalized <- l/sqrt(sigma2)
? ? muNormalized <- mu/sqrt(sigma2)
? ? c(uNormalized, lNormalized, muNormalized)
? }
> Su3(verbose=TRUE)
[1] 100.00 100.00 ? 0.53
[1] 23.2558140 23.2558140 ?0.1232558
> Su3(verbose=FALSE)
[1] 23.2558140 23.2558140 ?0.1232558

Not redefining variables at all makes debugging easier, although it may waste space.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Sep 2, 2017 at 10:33 AM, <ruipbarradas at sapo.pt> wrote:
Hello,

One way of preventing that is to use ?force.
Just put

? ?force(l)

right after the commented out print and before you change 'u'.

Hope this helps,

Rui Barradas



Citando Matthias Gondan <matthias-gondan at gmx.de>:

Dear R developers,

sessionInfo() below

Please have a look at the following two versions of the same function:

1. Intended behavior:
Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
+ {
+? ?print(c(u, l, mu)) # here, l is set to u?s value
+? ?u = u/sqrt(sigma2)
+? ?l = l/sqrt(sigma2)
+? ?mu = mu/sqrt(sigma2)
+? ?print(c(u, l, mu))
+ }

Su1()
[1] 100.00 100.00? ?0.53
[1] 23.2558140 23.2558140? 0.1232558

In the first version, both u and l are correctly divided by 4.3.

2. Strange behavior:
Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
+ {
+? ?# print(c(u, l, mu))
+? ?u = u/sqrt(sigma2)
+? ?l = l/sqrt(sigma2) # here, l is set to u?s value
+? ?mu = mu/sqrt(sigma2)
+? ?print(c(u, l, mu))
+ }

Su2()
[1] 23.2558140? 5.4083288? 0.1232558
In the second version, the print
function is commented out, so the variable u is
copied to l (lowercase L) at a later place, and L is divided twice by 4.3.

Is this behavior intended? It seems strange that the result depends on a debugging message.

Best wishes,

Matthias

sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252? ? LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? LC_TIME=German_Germany.1252

attached base packages:
[1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base

loaded via a namespace (and not attached):
[1] compiler_3.4.1 tools_3.4.1


? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Sep  2 19:55:46 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 02 Sep 2017 10:55:46 -0700
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
Message-ID: <DB721DA3-A5BB-4241-9253-0ED53E170A47@dcn.davis.ca.us>

Yes, this is intended behavior, and it has everything to do with where the parameters are first referenced and nothing to do with debugging. 
-- 
Sent from my phone. Please excuse my brevity.

On September 2, 2017 10:22:22 AM PDT, Matthias Gondan <matthias-gondan at gmx.de> wrote:
>Dear R developers,
>
>sessionInfo() below
>
>Please have a look at the following two versions of the same function:
>
>1. Intended behavior:
>
>> Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>+ {
>+   print(c(u, l, mu)) # here, l is set to u?s value
>+   u = u/sqrt(sigma2)
>+   l = l/sqrt(sigma2)
>+   mu = mu/sqrt(sigma2)
>+   print(c(u, l, mu))
>+ }
>> 
>> Su1()
>[1] 100.00 100.00   0.53
>[1] 23.2558140 23.2558140  0.1232558
>
>In the first version, both u and l are correctly divided by 4.3.
>
>2. Strange behavior:
>
>> Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>+ {
>+   # print(c(u, l, mu))
>+   u = u/sqrt(sigma2)
>+   l = l/sqrt(sigma2) # here, l is set to u?s value
>+   mu = mu/sqrt(sigma2)
>+   print(c(u, l, mu))
>+ }
>> 
>> Su2()
>[1] 23.2558140  5.4083288  0.1232558>In the second version, the print
>function is commented out, so the variable u is 
>copied to l (lowercase L) at a later place, and L is divided twice by
>4.3.
>
>Is this behavior intended? It seems strange that the result depends on
>a debugging message.
>
>Best wishes,
>
>Matthias>>>> sessionInfo()
>R version 3.4.1 (2017-06-30)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows >= 8 x64 (build 9200)
>
>Matrix products: default
>
>locale:
>[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   
>LC_MONETARY=German_Germany.1252
>[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252    
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.1 tools_3.4.1   
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Sep  2 21:48:52 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 2 Sep 2017 12:48:52 -0700
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
Message-ID: <CAGxFJbTmCdCWRjJeAD8Aru1KY2P3oGVeEaG-m+E2o-J7z038dQ@mail.gmail.com>

This is exactly as expected. See section 4.3.3 of the R Language definition
or google around on "R Lazy Evaluation" for details.

You should not "expect" R's semantics to be the same as other languages
with which you may be familiar. Spending time with a good tutorial or two
should help you sort out points of similarity and differences.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 2, 2017 at 10:22 AM, Matthias Gondan <matthias-gondan at gmx.de>
wrote:

> Dear R developers,
>
> sessionInfo() below
>
> Please have a look at the following two versions of the same function:
>
> 1. Intended behavior:
>
> > Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   print(c(u, l, mu)) # here, l is set to u?s value
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2)
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su1()
> [1] 100.00 100.00   0.53
> [1] 23.2558140 23.2558140  0.1232558
>
> In the first version, both u and l are correctly divided by 4.3.
>
> 2. Strange behavior:
>
> > Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   # print(c(u, l, mu))
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2) # here, l is set to u?s value
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su2()
> [1] 23.2558140  5.4083288  0.1232558
> In the second version, the print function is commented out, so the
> variable u is
> copied to l (lowercase L) at a later place, and L is divided twice by 4.3.
>
> Is this behavior intended? It seems strange that the result depends on a
> debugging message.
>
> Best wishes,
>
> Matthias
>
>
> > sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 tools_3.4.1
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Sat Sep  2 21:55:29 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 2 Sep 2017 21:55:29 +0200 (CEST)
Subject: [R] Precision error in time index of ts objects
In-Reply-To: <CAFaNUJJGOcCBVYJTww+Qhf4D_jDEUk8MWXETQ+ZQ-Dbz7NrHfQ@mail.gmail.com>
References: <CAFaNUJKf+K_d8_qQ5YTWPX=BP8qeyyHf6r6bWWjg4z_oqWrzww@mail.gmail.com>
 <6088B9BE-82FF-4024-B44D-B428BD248FF1@dcn.davis.ca.us>
 <CAFaNUJK-0ai2aEXXwJS0soQR0BK3WRF2mG96yZdTmZBvgjj8MQ@mail.gmail.com>
 <alpine.DEB.2.20.1709020007120.12886@paninaro>
 <CAFaNUJJGOcCBVYJTww+Qhf4D_jDEUk8MWXETQ+ZQ-Dbz7NrHfQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1709022149270.24802@paninaro>

On Sat, 2 Sep 2017, Andrea Altomani wrote:

> Thanks for the very detailed explanation.
> I did not create the series using structure(), that was the result of dump()
> on an intermediate object created within tsdisagg::ta(),

There is no tsdisagg package on CRAN, just tsdisagg2. But this does not 
have a function ta(). So I guess it's tempdisagg you are using?

> which is where I found the error in the first place. ta() indeed 
> manipulates .Tsp directly, rather than using ts. I guess this is a bug 
> in tsdisagg then.

I just grabbed the latest version of tempdisagg from CRAN and this does 
not seem to have ".Tsp" anywhere in the code. It employs ts() in a couple 
of places so I'm not sure which part of the code you are referring to 
exactly.

> On Sat, Sep 2, 2017 at 12:31 AM Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> wrote:
>       On Fri, 1 Sep 2017, Andrea Altomani wrote:
>
>       > I should have formulated my question in a more specific way.
>       >
>       > 1. I suspect this is a floating point precision issue. I am
>       not very
>       > knowledgeable about R internals, can someone else confirm it?
>
>       Yes. If you represent a series with increment 1/12 it depends on
>       how you
>       do it. As a simple example consider the following two
>       descriptions of the
>       same time point:
>
>       2 - 1/12
>       ## [1] 1.916667
>
>       1 + 11/12
>       ## [1] 1.916667
>
>       However, both are not identical:
>
>       (2 - 1/12) == (1 + 11/12)
>       ## [1] FALSE
>
>       The difference is just the .Machine$double.eps:
>
>       (2 - 1/12) - (1 + 11/12)
>       ## [1] 2.220446e-16
>
>       > 2. Should this be considered a bug or not, because it is "just
>       a
>       > precision issue"? Should I report it?
>
>       I don't think it is a bug because of the (non-standard) way how
>       you
>       created the time series.
>
>       > 3. How can it happen? From a quick review of ts.R, it looks
>       like the values
>       > of the time index are never modified, but only possibly
>       removed. In my case:
>       >? ?- x and y have the same index.
>       >? ?- the subtraction operator recognizes this, and create a new
>       ts with one
>       > entry
>       >? ?- the result of the subtraction has an index which is
>       different from the
>       > input.
>       >? This is very surprising to me, and I am curious to understand
>       the problem.
>
>       The object 'x' and hence the object 'y' have the same time
>       index. But in
>       'z' a new time index is created which is subtly different from
>       that of
>       'x'. The reason for this is that R doesn't expect an object like
>       'x' to
>       exist.
>
>       You should create a "ts" object with ts(), e.g.,
>
>       x <- ts(2017, start = c(2017, 6), freqency = 12)
>
>       But you created something close to the internal
>       representation...but not
>       close enough:
>
>       y <- structure(2017, .Tsp = c(2017.416667, 2017.416667, 12),
>       class = "ts")
>
>       The print functions prints both print(x) and print(y) as
>
>       ? ? ? ?Jun
>       2017 2017
>
>       However, aligning the two time indexes in x - y or
>       ts.intersect(x, y) does
>       not work...because they are not the same
>
>       as.numeric(time(x)) - as.numeric(time(y))
>       ## [1] -3.333332e-07
>
>       The "ts" code tries to avoid these situations by making many
>       time index
>       comparisons only up to a precision of getOption("ts.eps") (1e-5
>       by
>       default) but this is not used everywhere. See ?options:
>
>       ? ? ?'ts.eps': the relative tolerance for certain time series
>       ('ts')
>       ? ? ? ? ? ?computations.? Default '1e-05'.
>
>       Of course, you could ask for this being used in more places,
>       e.g., in
>       stats:::.cbind.ts() where (st > en) is used rather than ((st -
>       en) >
>       getOption("ts.eps")). But it's probably safer to just use ts()
>       rather than
>       structure(). Or if you use the latter make sure that you do at a
>       high
>       enough precision.
>
>       hth,
>       Z
> 
>
>       > On Fri, Sep 1, 2017 at 5:53 PM Jeff Newmiller
>       <jdnewmil at dcn.davis.ca.us>
>       > wrote:
>       >
>       >> You already know the answer. Why ask?
>       >> --
>       >> Sent from my phone. Please excuse my brevity.
>       >>
>       >> On September 1, 2017 7:23:24 AM PDT, Andrea Altomani <
>       >> altomani.andrea at gmail.com> wrote:
>       >>> I have a time series x, and two other series obtained from
>       it:
>       >>>
>       >>> x <- structure(2017, .Tsp = c(2017.41666666667,
>       2017.41666666667, 12),
>       >>> class = "ts")
>       >>> y <- floor(x)
>       >>> z <- x-y
>       >>>
>       >>> I would expect the three series to have exactly the same
>       index.
>       >>> However I get the following
>       >>>
>       >>>> time(x)-time(y)
>       >>>? ? ?Jun
>       >>> 2017? ?0
>       >>>
>       >>> as expected, but
>       >>>
>       >>>> time(x)-time(z)
>       >>> integer(0)
>       >>> Warning message:
>       >>> In .cbind.ts(list(e1, e2), c(deparse(substitute(e1))[1L],
>       >>> deparse(substitute(e2))[1L]),? :
>       >>>? non-intersecting series
>       >>>
>       >>> and indeed, comparing the indices gives:
>       >>>
>       >>>> time(x)[1]-time(z)[1]
>       >>> [1] 3.183231e-12
>       >>>
>       >>> Is this a bug in R, or is it one of the expected precision
>       errors due
>       >>> to the use of limited precision floats?
>       >>>
>       >>> I am using R 3.4.0 (2017-04-21) on Windows (64-bit).
>       >>>
>       >>> Thaks!
>       >>>
>       >>> Andrea Altomani
>       >>>
>       >>> ______________________________________________
>       >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>       more, see
>       >>> https://stat.ethz.ch/mailman/listinfo/r-help
>       >>> PLEASE do read the posting guide
>       >>> http://www.R-project.org/posting-guide.html
>       >>> and provide commented, minimal, self-contained, reproducible
>       code.
>       >>
>       >
>       >? ? ? ?[[alternative HTML version deleted]]
>       >
>       > ______________________________________________
>       > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>       see
>       > https://stat.ethz.ch/mailman/listinfo/r-help
>       > PLEASE do read the posting guide
>       http://www.R-project.org/posting-guide.html
>       > and provide commented, minimal, self-contained, reproducible
>       code.
>       >
> 
> 
>

From stefania.pecore at univ-ubs.fr  Sat Sep  2 17:26:19 2017
From: stefania.pecore at univ-ubs.fr (stefania.pecore at univ-ubs.fr)
Date: Sat, 2 Sep 2017 17:26:19 +0200
Subject: [R] problem in testing data with e1071 package (SVM Multiclass)
Message-ID: <a2f6eab9-1c7e-d043-b1ee-61d886a14c64@univ-ubs.fr>

Hello all,

this is the first time I'm using R and e1071 package and SVM multiclass 
(and I'm not a statistician)! I'm very confused, then. The goal is: I 
have a sentence with sunny; it will be classified as "yes" sentence; I 
have a sentence with cloud, it will be classified as "maybe"; I have a 
sentence with rainy il will be classified as "no".

The true goal is to do some text classification to apply then for my 
research.

I have two files:

  * train.csv: a file where there are two columns/Variables one is the
    data, the other is the label

Example:

|V1 V2 1sunny yes 2sunny sunny yes 3sunny rainy sunny yes 4sunny cloud 
sunny yes 5rainy no6rainy rainy no7rainy sunny rainy no8rainy cloud 
rainy no9cloud maybe 10cloud cloud maybe 11cloud rainy cloud maybe 
12cloud sunny cloud maybe|

  * test.csv: in this file there are the new data to be classified and
    it is in one column/variable.

Example:

|V1 1sunny 2rainy 3hello 4cloud 5a 6b 7cloud 8d 9e 10f 11g 12hello|

Following the examples from the iris dataset 
(https://cran.r-project.org/web/packages/e1071/e1071.pdfandhttp://rischanlab.github.io/SVM.html) 
I created my model and then test the training data in this way:

|>library(e1071)
>train <-read.csv(file="./train.csv",sep =";",header =FALSE)
 >test <-read.csv(file="./test.csv",sep =";",header =FALSE)>attach(train)
>x <-subset(train,select=-V2)
>y <-V2 >model <-svm(V2 ~.,data =train,probability=TRUE)
>summary(model)
Call:svm(formula =V2 ~.,data =train,probability 
=TRUE)Parameters:SVM-Type:C-classification SVM-Kernel:radial 
cost:1gamma:0.08333333Numberof SupportVectors:12(444)Numberof 
Classes:3Levels:maybe noyes
>pred <-predict(model,x)
 >system.time(pred <-predict(model,x))
user system elapsed 000
 >table(pred,y)y
|

|pred maybe noyes maybe 400no040yes 004>pred 123456789101112yes yes yes 
yes nonononomaybe maybe maybe maybe Levels:maybe noyes|


||

I think it's ok until now. Now the question is: what about the test 
data? I didn't find anything for the test data. Then, I thought that 
maybe I should test the model with the test data. And I did this:

| >test V1 1sunny 2rainy 3hello 4cloud 5a 6b 7cloud 8d 9e 10f 11g 12hello 
 >z <-subset(test,select=V1)>pred 
<-predict(model,z)Errorinpredict.svm(model,z):test data does notmatch 
model !|

What is wrong here? Can you please explain me how can I test new data 
using the old train model? For two days I asked everywhere and saw many 
websites but didn't find a solution and it's very complicated because I 
think that the logic behind the code is ok, but something is missin in 
my way to express it using R.

Thank you for your help

||


	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Sep  3 00:57:26 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 3 Sep 2017 10:57:26 +1200
Subject: [R] [FORGED] Re:  Block comment?
In-Reply-To: <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
 <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
Message-ID: <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>

On 03/09/17 03:56, William Dunlap via R-help wrote:
> Is the reason you want a block comment containing code (as opposed to
> arbitrary text) that you want to be able to easily run the commented out
> code?  If so the 'if()' construct has the advantage that you only need to
> change code at the start of the comment, not at both ends.
> 
> The if(FALSE) could be if(isTRUE(getOption("DEBUG_ISSUE_XYZ"))) so you
> would not even have to change code to re-enable the debugging code, just
> call options(DEBUG_ISSUE_XYX=TRUE)).


(a) The foregoing is getting too subtle for my feeble brain.

(b) A fundamental problem with the

    if(FALSE) {
       ...
    }

paradigm is that the enclosed code must be syntactically valid, and 
there are certainly situations in which one might wish to comment out 
sections of code that are *not* syntactically valid.  E.g. one might 
wish to comment out *part* of a piece of syntactically valid code for 
the purpose of experimenting with an alternative approach.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On Sat, Sep 2, 2017 at 7:54 AM, Suzen, Mehmet <msuzen at gmail.com> wrote:
> 
>> AFAIK block comment is not possible
>> it needs to be implemented in R interpreter and defined in the
>> parser.'If' solution is not elegant.
>>
>> On 2 September 2017 at 14:09, Uwe Ligges
>> <ligges at statistik.tu-dortmund.de> wrote:
>>>
>>>
>>> On 02.09.2017 11:40, Christian wrote:
>>>>
>>>> I consider it quite worth while to introduce into R syntax a nestable
>>>> block comment like
>>>>
>>>> #{
>>>> <block of code>
>>>> }#
>>>
>>>
>>> if(FALSE){
>>> <block of code>
>>> }
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>
>>>> It would make documentation more easily manageable and lucid.
>>>> Is there considerable need for this.
>>>>
>>>> Please, comment on this.
>>>> How about R core?
>>>>
>>>> Christian
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sun Sep  3 02:29:14 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 2 Sep 2017 20:29:14 -0400
Subject: [R] [FORGED] Re: Block comment?
In-Reply-To: <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
 <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
 <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>
Message-ID: <c182eb0f-328e-6e30-5b37-ef94a71a8cba@gmail.com>

On 02/09/2017 6:57 PM, Rolf Turner wrote:
> On 03/09/17 03:56, William Dunlap via R-help wrote:
>> Is the reason you want a block comment containing code (as opposed to
>> arbitrary text) that you want to be able to easily run the commented out
>> code?  If so the 'if()' construct has the advantage that you only need to
>> change code at the start of the comment, not at both ends.
>>
>> The if(FALSE) could be if(isTRUE(getOption("DEBUG_ISSUE_XYZ"))) so you
>> would not even have to change code to re-enable the debugging code, just
>> call options(DEBUG_ISSUE_XYX=TRUE)).
> 
> 
> (a) The foregoing is getting too subtle for my feeble brain.
> 
> (b) A fundamental problem with the
> 
>      if(FALSE) {
>         ...
>      }
> 
> paradigm is that the enclosed code must be syntactically valid, and
> there are certainly situations in which one might wish to comment out
> sections of code that are *not* syntactically valid.  E.g. one might
> wish to comment out *part* of a piece of syntactically valid code for
> the purpose of experimenting with an alternative approach.

If the code is not syntactically valid, why would you expect the block 
comment to be syntactically valid?  The proposal at the start of this 
thread was that #{ would open the block and would be matched by }# to 
close the block.  What if the closing sequence occurred within the block 
unintentionally?  Then the poor feeble programmer would be even more 
confused.

I like the current rule:  any line starting with # is a comment. 
(Actually the rule is a bit more subtle than that, but it's close.)
If I want to comment out a block, I can spend a long time typing # at 
the start of every line, or I can ask my editor to do it.  I don't need 
to worry if something in the block unintentionally closes it, because 
that's impossible.  If the first line is a comment, all the rest are too.

Duncan Murdoch


From r.turner at auckland.ac.nz  Sun Sep  3 06:49:04 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 3 Sep 2017 16:49:04 +1200
Subject: [R] [FORGED] Re: Block comment?
In-Reply-To: <c182eb0f-328e-6e30-5b37-ef94a71a8cba@gmail.com>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
 <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
 <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>
 <c182eb0f-328e-6e30-5b37-ef94a71a8cba@gmail.com>
Message-ID: <223f1b93-e900-6dbb-85b8-fc0e16e894d8@auckland.ac.nz>


On 03/09/17 12:29, Duncan Murdoch wrote:

> On 02/09/2017 6:57 PM, Rolf Turner wrote:
>> On 03/09/17 03:56, William Dunlap via R-help wrote:
>>> Is the reason you want a block comment containing code (as opposed to
>>> arbitrary text) that you want to be able to easily run the commented out
>>> code?  If so the 'if()' construct has the advantage that you only 
>>> need to
>>> change code at the start of the comment, not at both ends.
>>>
>>> The if(FALSE) could be if(isTRUE(getOption("DEBUG_ISSUE_XYZ"))) so you
>>> would not even have to change code to re-enable the debugging code, just
>>> call options(DEBUG_ISSUE_XYX=TRUE)).
>>
>>
>> (a) The foregoing is getting too subtle for my feeble brain.
>>
>> (b) A fundamental problem with the
>>
>>      if(FALSE) {
>>         ...
>>      }
>>
>> paradigm is that the enclosed code must be syntactically valid, and
>> there are certainly situations in which one might wish to comment out
>> sections of code that are *not* syntactically valid.  E.g. one might
>> wish to comment out *part* of a piece of syntactically valid code for
>> the purpose of experimenting with an alternative approach.
> 
> If the code is not syntactically valid, why would you expect the block 
> comment to be syntactically valid?

I thought I had made that clear.  One might wish to comment out a 
*piece* of syntactically valid code (with a view to replacing it).
The piece commented out might not be syntactically valid simply because 
it is *just a piece* and might thereby be incomplete.

> The proposal at the start of this 
> thread was that #{ would open the block and would be matched by }# to 
> close the block.  What if the closing sequence occurred within the block 
> unintentionally?  Then the poor feeble programmer would be even more 
> confused.

Do not the same considerations essentially apply to the well established
/* .... */ convention used in C?  Well maybe you simply *can't* get the 
"*/" string within a block of C code, but still ....

If "#{....}#" runs this risk, then some other construction which doesn't 
run the risk could be used.

> I like the current rule: 

De gustibus non disputandum.

> any line starting with # is a comment. 
> (Actually the rule is a bit more subtle than that, but it's close.)
> If I want to comment out a block, I can spend a long time typing # at 
> the start of every line, or I can ask my editor to do it.  I don't need 
> to worry if something in the block unintentionally closes it, because 
> that's impossible.  If the first line is a comment, all the rest are too.

I don't follow the foregoing, but no matter.  I'm slow.

This issue is quite obviously No Big Deal.  Block comments are a 
convenience that it would be nice to have, but obviously one can live 
without them and not suffer unduly.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Sun Sep  3 14:43:26 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 3 Sep 2017 08:43:26 -0400
Subject: [R] [FORGED] Re: Block comment?
In-Reply-To: <223f1b93-e900-6dbb-85b8-fc0e16e894d8@auckland.ac.nz>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
 <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
 <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>
 <c182eb0f-328e-6e30-5b37-ef94a71a8cba@gmail.com>
 <223f1b93-e900-6dbb-85b8-fc0e16e894d8@auckland.ac.nz>
Message-ID: <1d648a93-bb70-6da3-ff94-49e0e9e095ee@gmail.com>

On 03/09/2017 12:49 AM, Rolf Turner wrote:
> 
> On 03/09/17 12:29, Duncan Murdoch wrote:
> 
>> On 02/09/2017 6:57 PM, Rolf Turner wrote:
>>> On 03/09/17 03:56, William Dunlap via R-help wrote:
>>>> Is the reason you want a block comment containing code (as opposed to
>>>> arbitrary text) that you want to be able to easily run the commented out
>>>> code?  If so the 'if()' construct has the advantage that you only
>>>> need to
>>>> change code at the start of the comment, not at both ends.
>>>>
>>>> The if(FALSE) could be if(isTRUE(getOption("DEBUG_ISSUE_XYZ"))) so you
>>>> would not even have to change code to re-enable the debugging code, just
>>>> call options(DEBUG_ISSUE_XYX=TRUE)).
>>>
>>>
>>> (a) The foregoing is getting too subtle for my feeble brain.
>>>
>>> (b) A fundamental problem with the
>>>
>>>       if(FALSE) {
>>>          ...
>>>       }
>>>
>>> paradigm is that the enclosed code must be syntactically valid, and
>>> there are certainly situations in which one might wish to comment out
>>> sections of code that are *not* syntactically valid.  E.g. one might
>>> wish to comment out *part* of a piece of syntactically valid code for
>>> the purpose of experimenting with an alternative approach.
>>
>> If the code is not syntactically valid, why would you expect the block
>> comment to be syntactically valid?
> 
> I thought I had made that clear.  One might wish to comment out a
> *piece* of syntactically valid code (with a view to replacing it).
> The piece commented out might not be syntactically valid simply because
> it is *just a piece* and might thereby be incomplete.
> 
>> The proposal at the start of this
>> thread was that #{ would open the block and would be matched by }# to
>> close the block.  What if the closing sequence occurred within the block
>> unintentionally?  Then the poor feeble programmer would be even more
>> confused.
> 
> Do not the same considerations essentially apply to the well established
> /* .... */ convention used in C?  Well maybe you simply *can't* get the
> "*/" string within a block of C code, but still ....

Those aren't nestable.  You can have as many opening /* sequences as you 
like, and the first */ will close the comment.  The usual recommendation 
for nestable comments in C++ is to use #if 0 ... #endif, a lot like 
Uwe's suggestion.  (Since this is a preprocessor command, what falls 
between the markers doesn't need to be legal C++, but it does need to be 
legal preprocessor markup.)

> 
> If "#{....}#" runs this risk, then some other construction which doesn't
> run the risk could be used.
> 
>> I like the current rule:
> 
> De gustibus non disputandum.
> 
>> any line starting with # is a comment.
>> (Actually the rule is a bit more subtle than that, but it's close.)
>> If I want to comment out a block, I can spend a long time typing # at
>> the start of every line, or I can ask my editor to do it.  I don't need
>> to worry if something in the block unintentionally closes it, because
>> that's impossible.  If the first line is a comment, all the rest are too.
> 
> I don't follow the foregoing, but no matter.  I'm slow.

A shorter version:  just put # at the start of every line in the block.
That's nestable, but if you mess up the nesting, it's still completely 
obvious what is commented out and what is not.

Duncan Murdoch

> 
> This issue is quite obviously No Big Deal.  Block comments are a
> convenience that it would be nice to have, but obviously one can live
> without them and not suffer unduly.
> 
> cheers,
> 
> Rolf
>


From dwinsemius at comcast.net  Sun Sep  3 18:21:07 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 3 Sep 2017 09:21:07 -0700
Subject: [R] correlation between nominal and ordinal
In-Reply-To: <CA+8X3fWHb9sBvXhpnM_Mv3_S7yd2rnNk5pA+-CdAT1fSopXm7A@mail.gmail.com>
References: <20170901162547.71152juawubmdp3f@webmail.sld.cu>
 <CA+8X3fWHb9sBvXhpnM_Mv3_S7yd2rnNk5pA+-CdAT1fSopXm7A@mail.gmail.com>
Message-ID: <ECB63693-2046-4AE2-A563-5BAF48A9413F@comcast.net>


> On Sep 2, 2017, at 3:41 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> hi merlin,
> Check out the hetcor package.


I found a hetcor function in the polycor package.

Another method might be to use the lrm function in the rms package. It supports proportional odds ordinal logistic regression models.

-- 
David.


> 
> Jim
> 
> 
> On Sat, Sep 2, 2017 at 6:25 AM,  <merlinverdecia at infomed.sld.cu> wrote:
>> I would be very grateful if you would tell me how I can find the degree of
>> correlation between a nominal dependent variable and an independent ordinal
>> variable. The nominal variable has only two levels: YES and NO.
>> thank you very much in advance
>> regards,
>> merlin
>> 
>> ----------------------------------------------------------------
>> 
>> 
>> 
>> 
>> --
>> Este mensaje le ha llegado mediante el servicio de correo electronico que
>> ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema
>> Nacional de Salud. La persona que envia este correo asume el compromiso de
>> usar el servicio a tales fines y cumplir con las regulaciones establecidas
>> 
>> Infomed: http://www.sld.cu/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hemantsain55 at gmail.com  Mon Sep  4 09:31:20 2017
From: hemantsain55 at gmail.com (Hemant Sain)
Date: Mon, 4 Sep 2017 13:01:20 +0530
Subject: [R] Dataframe Manipulation
In-Reply-To: <CAKVAULM3DNBLoSQaV1bbmoULgLeZNo7mCPije3b4hTFA=FYxmg@mail.gmail.com>
References: <CAJL6Qs8LsW2R-P0N6kixdXVt7Rt_8K5QiCEsROphAdWV_Zs8Qg@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAACA2E@SRVEXCHCM301.precheza.cz>
 <CAJL6Qs-kQug__PdUGO=6F4FtyH3FZ9g49kxwepYE_EvSp8pQWA@mail.gmail.com>
 <CAKVAULPKqqE_VBmNirjSHNNeqHHP9Es050gvWmUv4pYq0O4m_g@mail.gmail.com>
 <CAJL6Qs_ke75CUswqRpWkwr4XO7AJ8BL1TdOY2jyTRzucBTGcUw@mail.gmail.com>
 <CAJL6Qs8QEExUP++gj2fTTLFPnDy7Gsv6f-qzf0U5DQpXh2uV2Q@mail.gmail.com>
 <CAKVAULM3DNBLoSQaV1bbmoULgLeZNo7mCPije3b4hTFA=FYxmg@mail.gmail.com>
Message-ID: <CAJL6Qs8kaD=-Uap_uDiA8a+X5kt3N-DFmOpssN6iDHtBk+c+-Q@mail.gmail.com>

Hello Ulrik,
Can you please explain this code means how and what this code is doing
because I'm not able to understand it, if you can explain it i can use it
in future by doing some Lil bit manipulation.

Thanks


data_help <-
  data_help %>%
  mutate(Purchase_ID = 1:n()) %>%
  group_by(Purchase_ID) %>%
    do(split_items(.))

cat_help %>% gather("Foo", "Item") %>%
  filter(!is.na(Item)) %>%
    left_join(data_help, by = "Item") %>%
  group_by(Foo, Purchase_ID) %>%
  summarise(Item = paste(Item, collapse = ", ")) %>%
  spread(key = "Foo", value = "Item")

On 31 August 2017 at 13:17, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:

> Hi Hemant,
>
> the solution is really quite similar, and the logic is identical:
>
> library(readr)
> library(dplyr)
> library(stringr)
> library(tidyr)
>
> data_help <- read_csv("data_help.csv")
> cat_help <- read_csv("cat_help.csv")
>
> # Helper function to split the Items and create a data_frame
> split_items <- function(items){
>   x <- items$Items_purchased_on_Receipts %>%
>     str_split(pattern = ",") %>%
>     unlist(use.names = FALSE)
>
>   data_frame(Item = x, Purchase_ID = items$Purchase_ID)
> }
>
> data_help <-
>   data_help %>%
>   mutate(Purchase_ID = 1:n()) %>%
>   group_by(Purchase_ID) %>%
>     do(split_items(.))
>
> cat_help %>% gather("Foo", "Item") %>%
>   filter(!is.na(Item)) %>%
>     left_join(data_help, by = "Item") %>%
>   group_by(Foo, Purchase_ID) %>%
>   summarise(Item = paste(Item, collapse = ", ")) %>%
>   spread(key = "Foo", value = "Item")
>
> HTH
> Ulrik
>
> On Wed, 30 Aug 2017 at 13:22 Hemant Sain <hemantsain55 at gmail.com> wrote:
>
>> by using these two tables we have to create third table in this format
>> where categories will be on the top and transaction will be in the rows,
>>
>> On 30 August 2017 at 16:42, Hemant Sain <hemantsain55 at gmail.com> wrote:
>>
>>> Hello Ulrik,
>>> Can you please once check this code again on the following data set
>>> because it doesn't giving same output to me due to absence of quantity,a
>>> compare to previous demo data set becaue spiting is getting done on the
>>> basis of quantity and in real data set quantity is missing. so please use
>>> following data set and help me out please consider this mail is my final
>>> email i won't bother you again but its about my job please help me
>>> .
>>>
>>> Note* the file I'm attaching is very confidential
>>>
>>> On 30 August 2017 at 15:02, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>  wrote:
>>>
>>>> Hi Hemant,
>>>>
>>>> Does this help you along?
>>>>
>>>> table_1 <- textConnection("Item_1;Item_2;Item_3
>>>> 1KG banana;300ML milk;1kg sugar
>>>> 2Large Corona_Beer;2pack Fries;
>>>> 2 Lux_Soap;1kg sugar;")
>>>>
>>>> table_1 <- read.csv(table_1, sep = ";", na.strings = "",
>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>
>>>> table_2 <- textConnection("Toiletries;Fruits;Beverages;Snacks;Vegetables;Clothings;Dairy
>>>> Products
>>>> Soap;banana;Corona_Beer;King Burger;Pumpkin;Adidas Sport Tshirt XL;milk
>>>> Shampoo;Mango;Red Label Whisky;Fries;Potato;Nike Shorts Black L;Butter
>>>> Showergel;Oranges;grey Cocktail;cheese pizza;Tomato;Puma Jersy red
>>>> M;sugar
>>>> Lux_Soap;;2 Large corona Beer;;Cheese;Toothpaste")
>>>>
>>>> table_2 <- read.csv(table_2, sep = ";", na.strings = "",
>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>
>>>> library(tidyr)
>>>> library(dplyr)
>>>>
>>>> table_2 <- gather(table_2, "Category", "Item")
>>>>
>>>> table_1 <- gather(table_1, "Foo", "Item") %>%
>>>>   filter(!is.na(Item))
>>>>
>>>> table_1 <- separate(table_1, col = "Item", into = c("Quantity",
>>>> "Item"), sep = " ")
>>>>
>>>> table_3 <- left_join(table_1, table_2, by = "Item") %>%
>>>>   mutate(Item = paste(Quantity, Item)) %>%
>>>>   select(-Quantity)
>>>>
>>>> table_3 %>%
>>>>   group_by(Foo, Category) %>%
>>>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>>>   spread(key = "Category", value = "Item")
>>>>
>>>> You need to figure out how to handle words written with different cases
>>>> and how to get the quantity in an universal way. For the code above, I
>>>> corrected these things by hand in the example data.
>>>>
>>>> HTH
>>>> Ulrik
>>>>
>>>> On Wed, 30 Aug 2017 at 10:16 Hemant Sain <hemantsain55 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hey PIKAL,
>>>>> It's not a homework neithe that is the real dataset i have signer NDA
>>>>> for
>>>>> my company so that i can share the original data file, Actually I'm
>>>>> working
>>>>> on a market basket analysis task but not able to convert my existing
>>>>> data
>>>>> table to appropriate format so that i can apply Apriori algorithm
>>>>> using R,
>>>>> and this is very important me to get it done because I'm an intern and
>>>>> if i
>>>>> won't get it done they will not  going to hire me as a full-time
>>>>> employee.
>>>>> i tried everything by myself but not able to get it done.
>>>>> your precious 10-15 can save my upcoming years. so please if you can
>>>>> please
>>>>> help me through this.
>>>>> i want another dataset based on first two dataset i have mentioned .
>>>>>
>>>>> Thanks
>>>>>
>>>>> On 30 August 2017 at 12:49, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>>>
>>>>> > Hi
>>>>> >
>>>>> > It seems to me like homework, there is no homework policy on this
>>>>> help
>>>>> > list.
>>>>> >
>>>>> > What do you want to do with your table 3? It seems to me futile.
>>>>> >
>>>>> > Anyway, some combination of melt, merge, cast and regular expressions
>>>>> > could be employed in such task, but it could be rather tricky.
>>>>> >
>>>>> > But be aware that
>>>>> >
>>>>> > Suger does not match sugar (I wonder that sugar is dairy product)
>>>>> >
>>>>> > and you mix uppercase and lowercase letters which could be also
>>>>> > problematic, when matching words.
>>>>> >
>>>>> > Cheers
>>>>> > Petr
>>>>> >
>>>>> > > -----Original Message-----
>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>> Hemant
>>>>> > Sain
>>>>> > > Sent: Wednesday, August 30, 2017 8:28 AM
>>>>> > > To: r-help at r-project.org
>>>>> > > Subject: [R] Dataframe Manipulation
>>>>> > >
>>>>> > > i want to do a market basket analysis and I?m trying to create a
>>>>> dataset
>>>>> > for that
>>>>> > > i have two tables, one table contains daily transaction of
>>>>> products in
>>>>> > which
>>>>> > > each row of table shows item purchased by the customer, The second
>>>>> table
>>>>> > > contains parent group under those products are fallen, for example
>>>>> under
>>>>> > fruit
>>>>> > > category there are several fruits like mango, banana, apple etc.
>>>>> > > i want to create a third table in which parent group are mentioned
>>>>> as
>>>>> > header
>>>>> > > which can be extracted from Table 2, and all the rows represent
>>>>> > transaction of
>>>>> > > products
>>>>> > >
>>>>> > > with their names, and if there is no transaction for any parent
>>>>> category
>>>>> > then
>>>>> > > the cell supposed to fill as NA. please help me with R or C/c++
>>>>> code( R
>>>>> > would be
>>>>> > >
>>>>> > > preferred) here I?m attaching you all three tables for better
>>>>> reference
>>>>> > i have
>>>>> > > first two tables and i want to get a table like table 3
>>>>> > >
>>>>> > > Tables are explained in the attached doc.
>>>>> > >
>>>>> > > --
>>>>> > > hemantsain.com
>>>>> >
>>>>> > ________________________________
>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>> jsou
>>>>> > ur?eny pouze jeho adres?t?m.
>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>>>> jeho kopie
>>>>> > vyma?te ze sv?ho syst?mu.
>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>>>> email
>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>> modifikacemi
>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>> >
>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>> p?ijmout;
>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>>>> strany
>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>> zmocn?n
>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>>>> tohoto
>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>> jejich
>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>> >
>>>>> > This e-mail and any documents attached to it may be confidential and
>>>>> are
>>>>> > intended only for its intended recipients.
>>>>> > If you received this e-mail by mistake, please immediately inform its
>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>> its
>>>>> > copies from your system.
>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>> manner.
>>>>> > The sender of this e-mail shall not be liable for any possible damage
>>>>> > caused by modifications of the e-mail or by delay with transfer of
>>>>> the
>>>>> > email.
>>>>> >
>>>>> > In case that this e-mail forms part of business dealings:
>>>>> > - the sender reserves the right to end negotiations about entering
>>>>> into a
>>>>> > contract in any time, for any reason, and without stating any
>>>>> reasoning.
>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>> excludes
>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>> any
>>>>> > amendment or variation.
>>>>> > - the sender insists on that the respective contract is concluded
>>>>> only
>>>>> > upon an express mutual agreement on all its aspects.
>>>>> > - the sender of this e-mail informs that he/she is not authorized to
>>>>> enter
>>>>> > into any contracts on behalf of the company except for cases in which
>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>> authorization
>>>>> > or power of attorney is submitted to the recipient or the person
>>>>> > represented by the recipient, or the existence of such authorization
>>>>> is
>>>>> > known to the recipient of the person represented by the recipient.
>>>>> >
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> hemantsain.com
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html <http://www.r-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>> --
>>> hemantsain.com
>>>
>>
>>
>>
>> --
>> hemantsain.com
>>
>


-- 
hemantsain.com

On 31 August 2017 at 13:17, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:

> Hi Hemant,
>
> the solution is really quite similar, and the logic is identical:
>
> library(readr)
> library(dplyr)
> library(stringr)
> library(tidyr)
>
> data_help <- read_csv("data_help.csv")
> cat_help <- read_csv("cat_help.csv")
>
> # Helper function to split the Items and create a data_frame
> split_items <- function(items){
>   x <- items$Items_purchased_on_Receipts %>%
>     str_split(pattern = ",") %>%
>     unlist(use.names = FALSE)
>
>   data_frame(Item = x, Purchase_ID = items$Purchase_ID)
> }
>
> data_help <-
>   data_help %>%
>   mutate(Purchase_ID = 1:n()) %>%
>   group_by(Purchase_ID) %>%
>     do(split_items(.))
>
> cat_help %>% gather("Foo", "Item") %>%
>   filter(!is.na(Item)) %>%
>     left_join(data_help, by = "Item") %>%
>   group_by(Foo, Purchase_ID) %>%
>   summarise(Item = paste(Item, collapse = ", ")) %>%
>   spread(key = "Foo", value = "Item")
>
> HTH
> Ulrik
>
> On Wed, 30 Aug 2017 at 13:22 Hemant Sain <hemantsain55 at gmail.com> wrote:
>
>> by using these two tables we have to create third table in this format
>> where categories will be on the top and transaction will be in the rows,
>>
>> On 30 August 2017 at 16:42, Hemant Sain <hemantsain55 at gmail.com> wrote:
>>
>>> Hello Ulrik,
>>> Can you please once check this code again on the following data set
>>> because it doesn't giving same output to me due to absence of quantity,a
>>> compare to previous demo data set becaue spiting is getting done on the
>>> basis of quantity and in real data set quantity is missing. so please use
>>> following data set and help me out please consider this mail is my final
>>> email i won't bother you again but its about my job please help me
>>> .
>>>
>>> Note* the file I'm attaching is very confidential
>>>
>>> On 30 August 2017 at 15:02, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>> wrote:
>>>
>>>> Hi Hemant,
>>>>
>>>> Does this help you along?
>>>>
>>>> table_1 <- textConnection("Item_1;Item_2;Item_3
>>>> 1KG banana;300ML milk;1kg sugar
>>>> 2Large Corona_Beer;2pack Fries;
>>>> 2 Lux_Soap;1kg sugar;")
>>>>
>>>> table_1 <- read.csv(table_1, sep = ";", na.strings = "",
>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>
>>>> table_2 <- textConnection("Toiletries;Fruits;Beverages;Snacks;Vegetables;Clothings;Dairy
>>>> Products
>>>> Soap;banana;Corona_Beer;King Burger;Pumpkin;Adidas Sport Tshirt XL;milk
>>>> Shampoo;Mango;Red Label Whisky;Fries;Potato;Nike Shorts Black L;Butter
>>>> Showergel;Oranges;grey Cocktail;cheese pizza;Tomato;Puma Jersy red
>>>> M;sugar
>>>> Lux_Soap;;2 Large corona Beer;;Cheese;Toothpaste")
>>>>
>>>> table_2 <- read.csv(table_2, sep = ";", na.strings = "",
>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>
>>>> library(tidyr)
>>>> library(dplyr)
>>>>
>>>> table_2 <- gather(table_2, "Category", "Item")
>>>>
>>>> table_1 <- gather(table_1, "Foo", "Item") %>%
>>>>   filter(!is.na(Item))
>>>>
>>>> table_1 <- separate(table_1, col = "Item", into = c("Quantity",
>>>> "Item"), sep = " ")
>>>>
>>>> table_3 <- left_join(table_1, table_2, by = "Item") %>%
>>>>   mutate(Item = paste(Quantity, Item)) %>%
>>>>   select(-Quantity)
>>>>
>>>> table_3 %>%
>>>>   group_by(Foo, Category) %>%
>>>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>>>   spread(key = "Category", value = "Item")
>>>>
>>>> You need to figure out how to handle words written with different cases
>>>> and how to get the quantity in an universal way. For the code above, I
>>>> corrected these things by hand in the example data.
>>>>
>>>> HTH
>>>> Ulrik
>>>>
>>>> On Wed, 30 Aug 2017 at 10:16 Hemant Sain <hemantsain55 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hey PIKAL,
>>>>> It's not a homework neithe that is the real dataset i have signer NDA
>>>>> for
>>>>> my company so that i can share the original data file, Actually I'm
>>>>> working
>>>>> on a market basket analysis task but not able to convert my existing
>>>>> data
>>>>> table to appropriate format so that i can apply Apriori algorithm
>>>>> using R,
>>>>> and this is very important me to get it done because I'm an intern and
>>>>> if i
>>>>> won't get it done they will not  going to hire me as a full-time
>>>>> employee.
>>>>> i tried everything by myself but not able to get it done.
>>>>> your precious 10-15 can save my upcoming years. so please if you can
>>>>> please
>>>>> help me through this.
>>>>> i want another dataset based on first two dataset i have mentioned .
>>>>>
>>>>> Thanks
>>>>>
>>>>> On 30 August 2017 at 12:49, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>>>>>
>>>>> > Hi
>>>>> >
>>>>> > It seems to me like homework, there is no homework policy on this
>>>>> help
>>>>> > list.
>>>>> >
>>>>> > What do you want to do with your table 3? It seems to me futile.
>>>>> >
>>>>> > Anyway, some combination of melt, merge, cast and regular expressions
>>>>> > could be employed in such task, but it could be rather tricky.
>>>>> >
>>>>> > But be aware that
>>>>> >
>>>>> > Suger does not match sugar (I wonder that sugar is dairy product)
>>>>> >
>>>>> > and you mix uppercase and lowercase letters which could be also
>>>>> > problematic, when matching words.
>>>>> >
>>>>> > Cheers
>>>>> > Petr
>>>>> >
>>>>> > > -----Original Message-----
>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>> Hemant
>>>>> > Sain
>>>>> > > Sent: Wednesday, August 30, 2017 8:28 AM
>>>>> > > To: r-help at r-project.org
>>>>> > > Subject: [R] Dataframe Manipulation
>>>>> > >
>>>>> > > i want to do a market basket analysis and I?m trying to create a
>>>>> dataset
>>>>> > for that
>>>>> > > i have two tables, one table contains daily transaction of
>>>>> products in
>>>>> > which
>>>>> > > each row of table shows item purchased by the customer, The second
>>>>> table
>>>>> > > contains parent group under those products are fallen, for example
>>>>> under
>>>>> > fruit
>>>>> > > category there are several fruits like mango, banana, apple etc.
>>>>> > > i want to create a third table in which parent group are mentioned
>>>>> as
>>>>> > header
>>>>> > > which can be extracted from Table 2, and all the rows represent
>>>>> > transaction of
>>>>> > > products
>>>>> > >
>>>>> > > with their names, and if there is no transaction for any parent
>>>>> category
>>>>> > then
>>>>> > > the cell supposed to fill as NA. please help me with R or C/c++
>>>>> code( R
>>>>> > would be
>>>>> > >
>>>>> > > preferred) here I?m attaching you all three tables for better
>>>>> reference
>>>>> > i have
>>>>> > > first two tables and i want to get a table like table 3
>>>>> > >
>>>>> > > Tables are explained in the attached doc.
>>>>> > >
>>>>> > > --
>>>>> > > hemantsain.com
>>>>> >
>>>>> > ________________________________
>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>> jsou
>>>>> > ur?eny pouze jeho adres?t?m.
>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>>>> jeho kopie
>>>>> > vyma?te ze sv?ho syst?mu.
>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>>>>> email
>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>> modifikacemi
>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>> >
>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>> p?ijmout;
>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>>>> strany
>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>> zmocn?n
>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
>>>>> tohoto
>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>> jejich
>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>> >
>>>>> > This e-mail and any documents attached to it may be confidential and
>>>>> are
>>>>> > intended only for its intended recipients.
>>>>> > If you received this e-mail by mistake, please immediately inform its
>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>> its
>>>>> > copies from your system.
>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>> manner.
>>>>> > The sender of this e-mail shall not be liable for any possible damage
>>>>> > caused by modifications of the e-mail or by delay with transfer of
>>>>> the
>>>>> > email.
>>>>> >
>>>>> > In case that this e-mail forms part of business dealings:
>>>>> > - the sender reserves the right to end negotiations about entering
>>>>> into a
>>>>> > contract in any time, for any reason, and without stating any
>>>>> reasoning.
>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>> excludes
>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>> any
>>>>> > amendment or variation.
>>>>> > - the sender insists on that the respective contract is concluded
>>>>> only
>>>>> > upon an express mutual agreement on all its aspects.
>>>>> > - the sender of this e-mail informs that he/she is not authorized to
>>>>> enter
>>>>> > into any contracts on behalf of the company except for cases in which
>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>> authorization
>>>>> > or power of attorney is submitted to the recipient or the person
>>>>> > represented by the recipient, or the existence of such authorization
>>>>> is
>>>>> > known to the recipient of the person represented by the recipient.
>>>>> >
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> hemantsain.com
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>>
>>> --
>>> hemantsain.com
>>>
>>
>>
>>
>> --
>> hemantsain.com
>>
>


-- 
hemantsain.com

	[[alternative HTML version deleted]]


From jonathan.shore at gmail.com  Sat Sep  2 20:25:09 2017
From: jonathan.shore at gmail.com (Jonathan Shore)
Date: Sat, 2 Sep 2017 14:25:09 -0400
Subject: [R] [R-pkgs] New package: rDotNet
Message-ID: <24DBDC04-F467-47DD-99A6-4A5E04DBF549@gmail.com>


I?ve published a package on CRAN called ?rDotNet?.  rDotNet allows R to access .NET libraries. From R one can:

* create .NET objects
* call member functions
* call class functions (i.e. static members)
* access and set properties
* access indexing members

The package will run with either mono on OS X / Linux or the Microsoft .NET VM on windows.   Find the source and description of the package on:

https://github.com/tr8dr/.Net-Bridge/blob/master/src/R/rDotNet/ <https://github.com/tr8dr/.Net-Bridge/blob/master/src/R/rDotNet/>

And the CRAN link as:

https://cran.r-project.org/web/packages/rDotNet/index.html <https://cran.r-project.org/web/packages/rDotNet/index.html>

The package is stable, as has been in use for some years, but only now packaged up for public use on CRAN.  Feel free to contact with questions or suggestions on GitHub or by email.  

Regards
--
Jonathan Shore




	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From mashranga at yahoo.com  Mon Sep  4 14:31:17 2017
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Mon, 4 Sep 2017 12:31:17 +0000 (UTC)
Subject: [R] Merge by Range in R
References: <1197943157.2415416.1504528277701.ref@mail.yahoo.com>
Message-ID: <1197943157.2415416.1504528277701@mail.yahoo.com>

Hi,?
I have two big data set.?

data _1 :?
> dim(data_1)
[1] 15820 5

> head(data_1)
? ?Chromosome ?????Start????????End????????Feature GroupA_3
1: ? ? ? ????????chr1 521369 ?750000 ????chr1-0001 ? ?????0.170
2: ? ? ? ????????chr1 750001 ?800000 ????chr1-0002 ? ????-0.086
3: ? ? ? ????????chr1 800001 ?850000 ????chr1-0003 ? ?????0.006
4: ? ? ? ????????chr1 850001 ?900000 ????chr1-0004 ? ?????0.050
5: ? ? ? ????????chr1 900001 ?950000 ????chr1-0005 ? ?????0.062
6: ? ? ? ????????chr1 950001 1000000 ? ?chr1-0006 ? ????-0.016

data_2:
> dim(data_2)
[1] 470870 5

> head(data_2)
? ?Chromosome ????Start ? End????????????Feature ????GroupA_3
1: ? ? ? ????????chr1 15864 15865 ????cg13869341 ? ?????????0.207
2: ? ? ? ????????chr1 18826 18827 ????cg14008030 ? ????????-0.288
3: ? ? ? ????????chr1 29406 29407 ????cg12045430 ? ????????-0.331
4: ? ? ? ????????chr1 29424 29425 ????cg20826792 ? ????????-0.074
5: ? ? ? ????????chr1 29434 29435 ????cg00381604 ? ?????????0.141
6: ? ? ? ????????chr1 68848 68849 ????cg20253340 ? ????????-0.458


What I want to do :?
Based on column name "Chromosome", "Start" and "End" of two data set , ? I want to find which row (preciously "Feature") of data_2 is in every range ( between "Start" and "End") of data_1 ? Also "Chromosome" column element should be match between two data set.?

I have tried "GenomicRanges" packages describe in the post ?
https://stackoverflow.com/questions/11892241/merge-by-range-in-r-applying-loops
But i was not successful. Can any one please help me to do this fast, as the data is very big ??
Thanks in advance.


Regards.............
Tanvir Ahamed Stockholm, Sweden???? |??mashranga at yahoo.com

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Sep  4 20:37:53 2017
From: jholtman at gmail.com (jim holtman)
Date: Mon, 4 Sep 2017 14:37:53 -0400
Subject: [R] Merge by Range in R
In-Reply-To: <1197943157.2415416.1504528277701@mail.yahoo.com>
References: <1197943157.2415416.1504528277701.ref@mail.yahoo.com>
 <1197943157.2415416.1504528277701@mail.yahoo.com>
Message-ID: <CAAxdm-5fFnvnYM07Pn+Udc21h4EN+4-RNoUxaGt7SPnujJkVNA@mail.gmail.com>

Have you tried 'foverlaps' in the data.table package?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Sep 4, 2017 at 8:31 AM, Mohammad Tanvir Ahamed via R-help <
r-help at r-project.org> wrote:

> Hi,
> I have two big data set.
>
> data _1 :
> > dim(data_1)
> [1] 15820 5
>
> > head(data_1)
>    Chromosome      Start        End        Feature GroupA_3
> 1:               chr1 521369  750000     chr1-0001        0.170
> 2:               chr1 750001  800000     chr1-0002       -0.086
> 3:               chr1 800001  850000     chr1-0003        0.006
> 4:               chr1 850001  900000     chr1-0004        0.050
> 5:               chr1 900001  950000     chr1-0005        0.062
> 6:               chr1 950001 1000000    chr1-0006       -0.016
>
> data_2:
> > dim(data_2)
> [1] 470870 5
>
> > head(data_2)
>    Chromosome     Start   End            Feature     GroupA_3
> 1:               chr1 15864 15865     cg13869341            0.207
> 2:               chr1 18826 18827     cg14008030           -0.288
> 3:               chr1 29406 29407     cg12045430           -0.331
> 4:               chr1 29424 29425     cg20826792           -0.074
> 5:               chr1 29434 29435     cg00381604            0.141
> 6:               chr1 68848 68849     cg20253340           -0.458
>
>
> What I want to do :
> Based on column name "Chromosome", "Start" and "End" of two data set ,   I
> want to find which row (preciously "Feature") of data_2 is in every range (
> between "Start" and "End") of data_1 ? Also "Chromosome" column element
> should be match between two data set.
>
> I have tried "GenomicRanges" packages describe in the post
> https://stackoverflow.com/questions/11892241/merge-by-
> range-in-r-applying-loops
> But i was not successful. Can any one please help me to do this fast, as
> the data is very big ?
> Thanks in advance.
>
>
> Regards.............
> Tanvir Ahamed Stockholm, Sweden     |  mashranga at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From isabella at ghement.ca  Mon Sep  4 21:00:27 2017
From: isabella at ghement.ca (isabella at ghement.ca)
Date: Mon, 4 Sep 2017 14:00:27 -0500
Subject: [R] JSM 2018 Invited Session Proposals on Statistical Graphics and
	Data Visualization Due by September 7, 2017
Message-ID: <36260.1504551627@ghement.ca>

Dear Colleagues,

If you work in the statistical graphics and/or data visualization fields, please consider organizing an invited session for the JSM 2018 conference in Vancouver, whose 
theme is ?#LeadWithStatistics.?

ASA's Section on Statistical Graphics will sponsor 3 invited sessions at JSM 2018, with a further 1-2 proposals having the potential to be included in the JSM 2018 
conference program through open competition. 

Invited session proposals need to be submitted by September 7th, 2017 via the website: http://ww2.amstat.org/meetings/jsm/2018/submissions.cfm. When submitting 
your proposal, please list the ASA Section on Statistical Graphics as the sponsor of your invited session. 

Invited sessions include invited papers and panels:

* Invited paper sessions consist of 2?6 presenters and/or discussants.
* Invited panels have 3?6 panelists providing commentary on a particular topic.

An invited session proposal includes a session title, general description of the session, list of participants, and tentative talk titles.

If you are interested in organizing an invited session, you need to select a session topic and solicit potential speakers. Once you have a sufficient number of committed 
speakers, you can submit your proposal online by the September 7, 2017 deadline.

To have the best chance of receiving an invited session slot, you need to: 

* Have solid new work in an important field;
* Know some of your competitors working in the same field;
* Be willing to reach out to your competitors and forge a session with energy in it.

For more details, please refer to http://ww2.amstat.org/meetings/jsm/2018/invitedsessions.cfm. 

Many thanks, 

Isabella

Isabella R. Ghement, Ph.D. 
JSM 2018 Program Chair for the ASA Section on Statistical Graphics
E-mail: isabella at ghement.ca




Isabella R. Ghement, Ph.D.
Ghement Statistical Consulting Company Ltd.
301-7031 Blundell Road, Richmond, B.C., Canada, V6Y 1J5
Tel: 604-767-1250
Fax: 604-270-3922
E-mail: isabella at ghement.ca
Web: www.ghement.ca


From infojomy at gmail.com  Tue Sep  5 07:31:52 2017
From: infojomy at gmail.com (Jomy Jose)
Date: Tue, 5 Sep 2017 11:01:52 +0530
Subject: [R] Sample size calculation for three-way incomplete block
	crossover study.
Message-ID: <CADGufDF_SrL+9QvsiqO2GrxqBxfbcR=gw_gBdu5Nw_SZbcXFvg@mail.gmail.com>

Hi

In R,how to do sample size calculation for three-way incomplete block
crossover study where within subject residual standard deviation,treatment
difference and power is given.

Thanks in advance.

Regards
Jose

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Sep  5 09:39:11 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 05 Sep 2017 07:39:11 +0000
Subject: [R] Dataframe Manipulation
In-Reply-To: <CAJL6Qs8kaD=-Uap_uDiA8a+X5kt3N-DFmOpssN6iDHtBk+c+-Q@mail.gmail.com>
References: <CAJL6Qs8LsW2R-P0N6kixdXVt7Rt_8K5QiCEsROphAdWV_Zs8Qg@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAACA2E@SRVEXCHCM301.precheza.cz>
 <CAJL6Qs-kQug__PdUGO=6F4FtyH3FZ9g49kxwepYE_EvSp8pQWA@mail.gmail.com>
 <CAKVAULPKqqE_VBmNirjSHNNeqHHP9Es050gvWmUv4pYq0O4m_g@mail.gmail.com>
 <CAJL6Qs_ke75CUswqRpWkwr4XO7AJ8BL1TdOY2jyTRzucBTGcUw@mail.gmail.com>
 <CAJL6Qs8QEExUP++gj2fTTLFPnDy7Gsv6f-qzf0U5DQpXh2uV2Q@mail.gmail.com>
 <CAKVAULM3DNBLoSQaV1bbmoULgLeZNo7mCPije3b4hTFA=FYxmg@mail.gmail.com>
 <CAJL6Qs8kaD=-Uap_uDiA8a+X5kt3N-DFmOpssN6iDHtBk+c+-Q@mail.gmail.com>
Message-ID: <CAKVAULOWHDMMwdVvJrU+-L68GtVRM-yRVi_9hUGTAwxHorJT4Q@mail.gmail.com>

Hi Hemant,

data_help <- data_help %>%
# Add a dummy index for each purchase to keep a memory of the purchase
since it will dissappear later on. You could also use row number
mutate(Purchase_ID = 1:n()) %>%
# For each purchase id
group_by(Purchase_ID) %>%
# Call the split_items function, which returns a data.frame
do(split_items(.))

cat_help %>%
# Make the data.frame long where the column names are gathered in a dummy
column and the items (the content of each column) in another column called
Item
gather("Foo", "Item") %>%
filter(!is.na(Item)) %>%
left_join(data_help, by = "Item") %>%
group_by(Foo, Purchase_ID) %>%
# Combine the items for each purchase and item type and make a wide
data.frame
summarise(Item = paste(Item, collapse = ", ")) %>%
spread(key = "Foo", value = "Item")

I suggest that you read the book [R for Data Science](http://r4ds.had.co.nz/)
by Garrett Grolemund and Hadley Wickham

Best wishes,
Ulrik

On Mo., 4. Sep. 2017, 09:31 Hemant Sain <hemantsain55 at gmail.com> wrote:

> Hello Ulrik,
> Can you please explain this code means how and what this code is doing
> because I'm not able to understand it, if you can explain it i can use it
> in future by doing some Lil bit manipulation.
>
> Thanks
>
>
> data_help <-
>   data_help %>%
>   mutate(Purchase_ID = 1:n()) %>%
>   group_by(Purchase_ID) %>%
>     do(split_items(.))
>
> cat_help %>% gather("Foo", "Item") %>%
>   filter(!is.na(Item)) %>%
>     left_join(data_help, by = "Item") %>%
>   group_by(Foo, Purchase_ID) %>%
>   summarise(Item = paste(Item, collapse = ", ")) %>%
>   spread(key = "Foo", value = "Item")
>
> On 31 August 2017 at 13:17, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>
>> Hi Hemant,
>>
>> the solution is really quite similar, and the logic is identical:
>>
>> library(readr)
>> library(dplyr)
>> library(stringr)
>> library(tidyr)
>>
>> data_help <- read_csv("data_help.csv")
>> cat_help <- read_csv("cat_help.csv")
>>
>> # Helper function to split the Items and create a data_frame
>> split_items <- function(items){
>>   x <- items$Items_purchased_on_Receipts %>%
>>     str_split(pattern = ",") %>%
>>     unlist(use.names = FALSE)
>>
>>   data_frame(Item = x, Purchase_ID = items$Purchase_ID)
>> }
>>
>> data_help <-
>>   data_help %>%
>>   mutate(Purchase_ID = 1:n()) %>%
>>   group_by(Purchase_ID) %>%
>>     do(split_items(.))
>>
>> cat_help %>% gather("Foo", "Item") %>%
>>   filter(!is.na(Item)) %>%
>>     left_join(data_help, by = "Item") %>%
>>   group_by(Foo, Purchase_ID) %>%
>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>   spread(key = "Foo", value = "Item")
>>
>> HTH
>> Ulrik
>>
>> On Wed, 30 Aug 2017 at 13:22 Hemant Sain <hemantsain55 at gmail.com> wrote:
>>
>>> by using these two tables we have to create third table in this format
>>> where categories will be on the top and transaction will be in the rows,
>>>
>>> On 30 August 2017 at 16:42, Hemant Sain <hemantsain55 at gmail.com> wrote:
>>>
>>>> Hello Ulrik,
>>>> Can you please once check this code again on the following data set
>>>> because it doesn't giving same output to me due to absence of quantity,a
>>>> compare to previous demo data set becaue spiting is getting done on the
>>>> basis of quantity and in real data set quantity is missing. so please use
>>>> following data set and help me out please consider this mail is my final
>>>> email i won't bother you again but its about my job please help me
>>>> .
>>>>
>>>> Note* the file I'm attaching is very confidential
>>>>
>>>> On 30 August 2017 at 15:02, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>>  wrote:
>>>>
>>>>> Hi Hemant,
>>>>>
>>>>> Does this help you along?
>>>>>
>>>>> table_1 <- textConnection("Item_1;Item_2;Item_3
>>>>> 1KG banana;300ML milk;1kg sugar
>>>>> 2Large Corona_Beer;2pack Fries;
>>>>> 2 Lux_Soap;1kg sugar;")
>>>>>
>>>>> table_1 <- read.csv(table_1, sep = ";", na.strings = "",
>>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>>
>>>>> table_2 <-
>>>>> textConnection("Toiletries;Fruits;Beverages;Snacks;Vegetables;Clothings;Dairy
>>>>> Products
>>>>> Soap;banana;Corona_Beer;King Burger;Pumpkin;Adidas Sport Tshirt XL;milk
>>>>> Shampoo;Mango;Red Label Whisky;Fries;Potato;Nike Shorts Black L;Butter
>>>>> Showergel;Oranges;grey Cocktail;cheese pizza;Tomato;Puma Jersy red
>>>>> M;sugar
>>>>> Lux_Soap;;2 Large corona Beer;;Cheese;Toothpaste")
>>>>>
>>>>> table_2 <- read.csv(table_2, sep = ";", na.strings = "",
>>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>>
>>>>> library(tidyr)
>>>>> library(dplyr)
>>>>>
>>>>> table_2 <- gather(table_2, "Category", "Item")
>>>>>
>>>>> table_1 <- gather(table_1, "Foo", "Item") %>%
>>>>>   filter(!is.na(Item))
>>>>>
>>>>> table_1 <- separate(table_1, col = "Item", into = c("Quantity",
>>>>> "Item"), sep = " ")
>>>>>
>>>>> table_3 <- left_join(table_1, table_2, by = "Item") %>%
>>>>>   mutate(Item = paste(Quantity, Item)) %>%
>>>>>   select(-Quantity)
>>>>>
>>>>> table_3 %>%
>>>>>   group_by(Foo, Category) %>%
>>>>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>>>>   spread(key = "Category", value = "Item")
>>>>>
>>>>> You need to figure out how to handle words written with different
>>>>> cases and how to get the quantity in an universal way. For the code above,
>>>>> I corrected these things by hand in the example data.
>>>>>
>>>>> HTH
>>>>> Ulrik
>>>>>
>>>>> On Wed, 30 Aug 2017 at 10:16 Hemant Sain <hemantsain55 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hey PIKAL,
>>>>>> It's not a homework neithe that is the real dataset i have signer NDA
>>>>>> for
>>>>>> my company so that i can share the original data file, Actually I'm
>>>>>> working
>>>>>> on a market basket analysis task but not able to convert my existing
>>>>>> data
>>>>>> table to appropriate format so that i can apply Apriori algorithm
>>>>>> using R,
>>>>>> and this is very important me to get it done because I'm an intern
>>>>>> and if i
>>>>>> won't get it done they will not  going to hire me as a full-time
>>>>>> employee.
>>>>>> i tried everything by myself but not able to get it done.
>>>>>> your precious 10-15 can save my upcoming years. so please if you can
>>>>>> please
>>>>>> help me through this.
>>>>>> i want another dataset based on first two dataset i have mentioned .
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> On 30 August 2017 at 12:49, PIKAL Petr <petr.pikal at precheza.cz>
>>>>>> wrote:
>>>>>>
>>>>>> > Hi
>>>>>> >
>>>>>> > It seems to me like homework, there is no homework policy on this
>>>>>> help
>>>>>> > list.
>>>>>> >
>>>>>> > What do you want to do with your table 3? It seems to me futile.
>>>>>> >
>>>>>> > Anyway, some combination of melt, merge, cast and regular
>>>>>> expressions
>>>>>> > could be employed in such task, but it could be rather tricky.
>>>>>> >
>>>>>> > But be aware that
>>>>>> >
>>>>>> > Suger does not match sugar (I wonder that sugar is dairy product)
>>>>>> >
>>>>>> > and you mix uppercase and lowercase letters which could be also
>>>>>> > problematic, when matching words.
>>>>>> >
>>>>>> > Cheers
>>>>>> > Petr
>>>>>> >
>>>>>> > > -----Original Message-----
>>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>>> Hemant
>>>>>> > Sain
>>>>>> > > Sent: Wednesday, August 30, 2017 8:28 AM
>>>>>> > > To: r-help at r-project.org
>>>>>> > > Subject: [R] Dataframe Manipulation
>>>>>> > >
>>>>>> > > i want to do a market basket analysis and I?m trying to create a
>>>>>> dataset
>>>>>> > for that
>>>>>> > > i have two tables, one table contains daily transaction of
>>>>>> products in
>>>>>> > which
>>>>>> > > each row of table shows item purchased by the customer, The
>>>>>> second table
>>>>>> > > contains parent group under those products are fallen, for
>>>>>> example under
>>>>>> > fruit
>>>>>> > > category there are several fruits like mango, banana, apple etc.
>>>>>> > > i want to create a third table in which parent group are
>>>>>> mentioned as
>>>>>> > header
>>>>>> > > which can be extracted from Table 2, and all the rows represent
>>>>>> > transaction of
>>>>>> > > products
>>>>>> > >
>>>>>> > > with their names, and if there is no transaction for any parent
>>>>>> category
>>>>>> > then
>>>>>> > > the cell supposed to fill as NA. please help me with R or C/c++
>>>>>> code( R
>>>>>> > would be
>>>>>> > >
>>>>>> > > preferred) here I?m attaching you all three tables for better
>>>>>> reference
>>>>>> > i have
>>>>>> > > first two tables and i want to get a table like table 3
>>>>>> > >
>>>>>> > > Tables are explained in the attached doc.
>>>>>> > >
>>>>>> > > --
>>>>>> > > hemantsain.com
>>>>>> >
>>>>>> > ________________________________
>>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>>> jsou
>>>>>> > ur?eny pouze jeho adres?t?m.
>>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>>>>> jeho kopie
>>>>>> > vyma?te ze sv?ho syst?mu.
>>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>>>>> tento email
>>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>>> modifikacemi
>>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>>> >
>>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>>> p?ijmout;
>>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>>>>> strany
>>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>>> zmocn?n
>>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>>>>> adres?tovi tohoto
>>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>>> jejich
>>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>>> >
>>>>>> > This e-mail and any documents attached to it may be confidential
>>>>>> and are
>>>>>> > intended only for its intended recipients.
>>>>>> > If you received this e-mail by mistake, please immediately inform
>>>>>> its
>>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>>> its
>>>>>> > copies from your system.
>>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>>> manner.
>>>>>> > The sender of this e-mail shall not be liable for any possible
>>>>>> damage
>>>>>> > caused by modifications of the e-mail or by delay with transfer of
>>>>>> the
>>>>>> > email.
>>>>>> >
>>>>>> > In case that this e-mail forms part of business dealings:
>>>>>> > - the sender reserves the right to end negotiations about entering
>>>>>> into a
>>>>>> > contract in any time, for any reason, and without stating any
>>>>>> reasoning.
>>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>>> excludes
>>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>>> any
>>>>>> > amendment or variation.
>>>>>> > - the sender insists on that the respective contract is concluded
>>>>>> only
>>>>>> > upon an express mutual agreement on all its aspects.
>>>>>> > - the sender of this e-mail informs that he/she is not authorized
>>>>>> to enter
>>>>>> > into any contracts on behalf of the company except for cases in
>>>>>> which
>>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>>> authorization
>>>>>> > or power of attorney is submitted to the recipient or the person
>>>>>> > represented by the recipient, or the existence of such
>>>>>> authorization is
>>>>>> > known to the recipient of the person represented by the recipient.
>>>>>> >
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> hemantsain.com
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> <http://www.r-project.org/posting-guide.html>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> hemantsain.com
>>>>
>>>
>>>
>>>
>>> --
>>> hemantsain.com
>>>
>>
>
>
> --
> hemantsain.com
>
> On 31 August 2017 at 13:17, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:
>
>> Hi Hemant,
>>
>> the solution is really quite similar, and the logic is identical:
>>
>> library(readr)
>> library(dplyr)
>> library(stringr)
>> library(tidyr)
>>
>> data_help <- read_csv("data_help.csv")
>> cat_help <- read_csv("cat_help.csv")
>>
>> # Helper function to split the Items and create a data_frame
>> split_items <- function(items){
>>   x <- items$Items_purchased_on_Receipts %>%
>>     str_split(pattern = ",") %>%
>>     unlist(use.names = FALSE)
>>
>>   data_frame(Item = x, Purchase_ID = items$Purchase_ID)
>> }
>>
>> data_help <-
>>   data_help %>%
>>   mutate(Purchase_ID = 1:n()) %>%
>>   group_by(Purchase_ID) %>%
>>     do(split_items(.))
>>
>> cat_help %>% gather("Foo", "Item") %>%
>>   filter(!is.na(Item)) %>%
>>     left_join(data_help, by = "Item") %>%
>>   group_by(Foo, Purchase_ID) %>%
>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>   spread(key = "Foo", value = "Item")
>>
>> HTH
>> Ulrik
>>
>> On Wed, 30 Aug 2017 at 13:22 Hemant Sain <hemantsain55 at gmail.com> wrote:
>>
>>> by using these two tables we have to create third table in this format
>>> where categories will be on the top and transaction will be in the rows,
>>>
>>> On 30 August 2017 at 16:42, Hemant Sain <hemantsain55 at gmail.com> wrote:
>>>
>>>> Hello Ulrik,
>>>> Can you please once check this code again on the following data set
>>>> because it doesn't giving same output to me due to absence of quantity,a
>>>> compare to previous demo data set becaue spiting is getting done on the
>>>> basis of quantity and in real data set quantity is missing. so please use
>>>> following data set and help me out please consider this mail is my final
>>>> email i won't bother you again but its about my job please help me
>>>> .
>>>>
>>>> Note* the file I'm attaching is very confidential
>>>>
>>>> On 30 August 2017 at 15:02, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Hemant,
>>>>>
>>>>> Does this help you along?
>>>>>
>>>>> table_1 <- textConnection("Item_1;Item_2;Item_3
>>>>> 1KG banana;300ML milk;1kg sugar
>>>>> 2Large Corona_Beer;2pack Fries;
>>>>> 2 Lux_Soap;1kg sugar;")
>>>>>
>>>>> table_1 <- read.csv(table_1, sep = ";", na.strings = "",
>>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>>
>>>>> table_2 <-
>>>>> textConnection("Toiletries;Fruits;Beverages;Snacks;Vegetables;Clothings;Dairy
>>>>> Products
>>>>> Soap;banana;Corona_Beer;King Burger;Pumpkin;Adidas Sport Tshirt XL;milk
>>>>> Shampoo;Mango;Red Label Whisky;Fries;Potato;Nike Shorts Black L;Butter
>>>>> Showergel;Oranges;grey Cocktail;cheese pizza;Tomato;Puma Jersy red
>>>>> M;sugar
>>>>> Lux_Soap;;2 Large corona Beer;;Cheese;Toothpaste")
>>>>>
>>>>> table_2 <- read.csv(table_2, sep = ";", na.strings = "",
>>>>> stringsAsFactors = FALSE, check.names = FALSE)
>>>>>
>>>>> library(tidyr)
>>>>> library(dplyr)
>>>>>
>>>>> table_2 <- gather(table_2, "Category", "Item")
>>>>>
>>>>> table_1 <- gather(table_1, "Foo", "Item") %>%
>>>>>   filter(!is.na(Item))
>>>>>
>>>>> table_1 <- separate(table_1, col = "Item", into = c("Quantity",
>>>>> "Item"), sep = " ")
>>>>>
>>>>> table_3 <- left_join(table_1, table_2, by = "Item") %>%
>>>>>   mutate(Item = paste(Quantity, Item)) %>%
>>>>>   select(-Quantity)
>>>>>
>>>>> table_3 %>%
>>>>>   group_by(Foo, Category) %>%
>>>>>   summarise(Item = paste(Item, collapse = ", ")) %>%
>>>>>   spread(key = "Category", value = "Item")
>>>>>
>>>>> You need to figure out how to handle words written with different
>>>>> cases and how to get the quantity in an universal way. For the code above,
>>>>> I corrected these things by hand in the example data.
>>>>>
>>>>> HTH
>>>>> Ulrik
>>>>>
>>>>> On Wed, 30 Aug 2017 at 10:16 Hemant Sain <hemantsain55 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hey PIKAL,
>>>>>> It's not a homework neithe that is the real dataset i have signer NDA
>>>>>> for
>>>>>> my company so that i can share the original data file, Actually I'm
>>>>>> working
>>>>>> on a market basket analysis task but not able to convert my existing
>>>>>> data
>>>>>> table to appropriate format so that i can apply Apriori algorithm
>>>>>> using R,
>>>>>> and this is very important me to get it done because I'm an intern
>>>>>> and if i
>>>>>> won't get it done they will not  going to hire me as a full-time
>>>>>> employee.
>>>>>> i tried everything by myself but not able to get it done.
>>>>>> your precious 10-15 can save my upcoming years. so please if you can
>>>>>> please
>>>>>> help me through this.
>>>>>> i want another dataset based on first two dataset i have mentioned .
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> On 30 August 2017 at 12:49, PIKAL Petr <petr.pikal at precheza.cz>
>>>>>> wrote:
>>>>>>
>>>>>> > Hi
>>>>>> >
>>>>>> > It seems to me like homework, there is no homework policy on this
>>>>>> help
>>>>>> > list.
>>>>>> >
>>>>>> > What do you want to do with your table 3? It seems to me futile.
>>>>>> >
>>>>>> > Anyway, some combination of melt, merge, cast and regular
>>>>>> expressions
>>>>>> > could be employed in such task, but it could be rather tricky.
>>>>>> >
>>>>>> > But be aware that
>>>>>> >
>>>>>> > Suger does not match sugar (I wonder that sugar is dairy product)
>>>>>> >
>>>>>> > and you mix uppercase and lowercase letters which could be also
>>>>>> > problematic, when matching words.
>>>>>> >
>>>>>> > Cheers
>>>>>> > Petr
>>>>>> >
>>>>>> > > -----Original Message-----
>>>>>> > > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>>>>> Hemant
>>>>>> > Sain
>>>>>> > > Sent: Wednesday, August 30, 2017 8:28 AM
>>>>>> > > To: r-help at r-project.org
>>>>>> > > Subject: [R] Dataframe Manipulation
>>>>>> > >
>>>>>> > > i want to do a market basket analysis and I?m trying to create a
>>>>>> dataset
>>>>>> > for that
>>>>>> > > i have two tables, one table contains daily transaction of
>>>>>> products in
>>>>>> > which
>>>>>> > > each row of table shows item purchased by the customer, The
>>>>>> second table
>>>>>> > > contains parent group under those products are fallen, for
>>>>>> example under
>>>>>> > fruit
>>>>>> > > category there are several fruits like mango, banana, apple etc.
>>>>>> > > i want to create a third table in which parent group are
>>>>>> mentioned as
>>>>>> > header
>>>>>> > > which can be extracted from Table 2, and all the rows represent
>>>>>> > transaction of
>>>>>> > > products
>>>>>> > >
>>>>>> > > with their names, and if there is no transaction for any parent
>>>>>> category
>>>>>> > then
>>>>>> > > the cell supposed to fill as NA. please help me with R or C/c++
>>>>>> code( R
>>>>>> > would be
>>>>>> > >
>>>>>> > > preferred) here I?m attaching you all three tables for better
>>>>>> reference
>>>>>> > i have
>>>>>> > > first two tables and i want to get a table like table 3
>>>>>> > >
>>>>>> > > Tables are explained in the attached doc.
>>>>>> > >
>>>>>> > > --
>>>>>> > > hemantsain.com
>>>>>> >
>>>>>> > ________________________________
>>>>>> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>>>>>> jsou
>>>>>> > ur?eny pouze jeho adres?t?m.
>>>>>> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>>>>> > neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>>>>> jeho kopie
>>>>>> > vyma?te ze sv?ho syst?mu.
>>>>>> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>>>>> tento email
>>>>>> > jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>>>>> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>>>>> modifikacemi
>>>>>> > ?i zpo?d?n?m p?enosu e-mailu.
>>>>>> >
>>>>>> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>>>>> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>>>>> > smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>>>>> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>>>>> p?ijmout;
>>>>>> > Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>>>>> strany
>>>>>> > p??jemce s dodatkem ?i odchylkou.
>>>>>> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>>>>> > v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>>>>> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>>>>> > spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>>>>>> zmocn?n
>>>>>> > nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>>>>> adres?tovi tohoto
>>>>>> > emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>>>>> jejich
>>>>>> > existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>>>>> >
>>>>>> > This e-mail and any documents attached to it may be confidential
>>>>>> and are
>>>>>> > intended only for its intended recipients.
>>>>>> > If you received this e-mail by mistake, please immediately inform
>>>>>> its
>>>>>> > sender. Delete the contents of this e-mail with all attachments and
>>>>>> its
>>>>>> > copies from your system.
>>>>>> > If you are not the intended recipient of this e-mail, you are not
>>>>>> > authorized to use, disseminate, copy or disclose this e-mail in any
>>>>>> manner.
>>>>>> > The sender of this e-mail shall not be liable for any possible
>>>>>> damage
>>>>>> > caused by modifications of the e-mail or by delay with transfer of
>>>>>> the
>>>>>> > email.
>>>>>> >
>>>>>> > In case that this e-mail forms part of business dealings:
>>>>>> > - the sender reserves the right to end negotiations about entering
>>>>>> into a
>>>>>> > contract in any time, for any reason, and without stating any
>>>>>> reasoning.
>>>>>> > - if the e-mail contains an offer, the recipient is entitled to
>>>>>> > immediately accept such offer; The sender of this e-mail (offer)
>>>>>> excludes
>>>>>> > any acceptance of the offer on the part of the recipient containing
>>>>>> any
>>>>>> > amendment or variation.
>>>>>> > - the sender insists on that the respective contract is concluded
>>>>>> only
>>>>>> > upon an express mutual agreement on all its aspects.
>>>>>> > - the sender of this e-mail informs that he/she is not authorized
>>>>>> to enter
>>>>>> > into any contracts on behalf of the company except for cases in
>>>>>> which
>>>>>> > he/she is expressly authorized to do so in writing, and such
>>>>>> authorization
>>>>>> > or power of attorney is submitted to the recipient or the person
>>>>>> > represented by the recipient, or the existence of such
>>>>>> authorization is
>>>>>> > known to the recipient of the person represented by the recipient.
>>>>>> >
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> hemantsain.com
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> hemantsain.com
>>>>
>>>
>>>
>>>
>>> --
>>> hemantsain.com
>>>
>>
>
>
> --
> hemantsain.com
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Tue Sep  5 16:17:10 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 5 Sep 2017 15:17:10 +0100
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
Message-ID: <1A8C1289955EF649A09086A153E267240BD80E9477@GBTEDVPEXCMB04.corp.lgc-group.com>

Mathias,
If it's any comfort, I appreciated the example; 'expected' behaviour maybe, but a very nice example for staff/student training!

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias
> Gondan
> Sent: 02 September 2017 18:22
> To: r-help at r-project.org
> Subject: [R] Strange lazy evaluation of default arguments
> 
> Dear R developers,
> 
> sessionInfo() below
> 
> Please have a look at the following two versions of the same function:
> 
> 1. Intended behavior:
> 
> > Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   print(c(u, l, mu)) # here, l is set to u?s value
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2)
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su1()
> [1] 100.00 100.00   0.53
> [1] 23.2558140 23.2558140  0.1232558
> 
> In the first version, both u and l are correctly divided by 4.3.
> 
> 2. Strange behavior:
> 
> > Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   # print(c(u, l, mu))
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2) # here, l is set to u?s value
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su2()
> [1] 23.2558140  5.4083288  0.1232558
> In the second version, the print function is commented out, so the variable u
> is copied to l (lowercase L) at a later place, and L is divided twice by 4.3.
> 
> Is this behavior intended? It seems strange that the result depends on a
> debugging message.
> 
> Best wishes,
> 
> Matthias
> 
> 
> > sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
> x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 tools_3.4.1
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From bgunter.4567 at gmail.com  Tue Sep  5 16:31:26 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 5 Sep 2017 07:31:26 -0700
Subject: [R] Sample size calculation for three-way incomplete block
 crossover study.
In-Reply-To: <CADGufDF_SrL+9QvsiqO2GrxqBxfbcR=gw_gBdu5Nw_SZbcXFvg@mail.gmail.com>
References: <CADGufDF_SrL+9QvsiqO2GrxqBxfbcR=gw_gBdu5Nw_SZbcXFvg@mail.gmail.com>
Message-ID: <CAGxFJbQpiQX2hsPDhEtk=jNnZ67Q4upsVnLZBkth-uu_XbhjQg@mail.gmail.com>

Sounds like a homework problem. This list has a no homework policy if it is.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 4, 2017 at 10:31 PM, Jomy Jose <infojomy at gmail.com> wrote:

> Hi
>
> In R,how to do sample size calculation for three-way incomplete block
> crossover study where within subject residual standard deviation,treatment
> difference and power is given.
>
> Thanks in advance.
>
> Regards
> Jose
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matthias-gondan at gmx.de  Tue Sep  5 16:49:21 2017
From: matthias-gondan at gmx.de (Matthias Gondan)
Date: Tue, 5 Sep 2017 16:49:21 +0200
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <1A8C1289955EF649A09086A153E267240BD80E9477@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
 <1A8C1289955EF649A09086A153E267240BD80E9477@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <0MJFBe-1dmUHK03GU-002qKO@mail.gmx.com>

Dear S Ellison,

Thanks for the flowers! Indeed, I was actually considering to use it in my own teaching material, as well. With rounded numbers, of course.

Though I am still slightly disturbed about this feature. I thought, now it is the time to switch to Python, but that?s even worse, see here:

def add_elem(List=[]):
    List.append('elem')
    return List

>>> add_elem([2])
[2, 'elem']
>>> add_elem()
['elem']
>>> add_elem()
['elem', 'elem'] <<<<<<<<<<< why on earth does this happen? [it?s documented behavior, but still?]

So, I?ll stick with R. Still 25 years or so until retirement, but I?ll survive, even without crossreferenced default arguments.

Best wishes,

Matthias


Von: S Ellison
Gesendet: Dienstag, 5. September 2017 16:17
An: Matthias Gondan; r-help at r-project.org
Betreff: RE: [R] Strange lazy evaluation of default arguments

Mathias,
If it's any comfort, I appreciated the example; 'expected' behaviour maybe, but a very nice example for staff/student training!

S Ellison


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias
> Gondan
> Sent: 02 September 2017 18:22
> To: r-help at r-project.org
> Subject: [R] Strange lazy evaluation of default arguments
> 
> Dear R developers,
> 
> sessionInfo() below
> 
> Please have a look at the following two versions of the same function:
> 
> 1. Intended behavior:
> 
> > Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   print(c(u, l, mu)) # here, l is set to u?s value
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2)
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su1()
> [1] 100.00 100.00   0.53
> [1] 23.2558140 23.2558140  0.1232558
> 
> In the first version, both u and l are correctly divided by 4.3.
> 
> 2. Strange behavior:
> 
> > Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
> + {
> +   # print(c(u, l, mu))
> +   u = u/sqrt(sigma2)
> +   l = l/sqrt(sigma2) # here, l is set to u?s value
> +   mu = mu/sqrt(sigma2)
> +   print(c(u, l, mu))
> + }
> >
> > Su2()
> [1] 23.2558140  5.4083288  0.1232558
> In the second version, the print function is commented out, so the variable u
> is copied to l (lowercase L) at a later place, and L is divided twice by 4.3.
> 
> Is this behavior intended? It seems strange that the result depends on a
> debugging message.
> 
> Best wishes,
> 
> Matthias
> 
> 
> > sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
> x64 (build 9200)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> LC_MONETARY=German_Germany.1252
> [4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 tools_3.4.1
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:12}}


From jdnewmil at dcn.davis.ca.us  Tue Sep  5 17:35:13 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 05 Sep 2017 08:35:13 -0700
Subject: [R] Strange lazy evaluation of default arguments
In-Reply-To: <0MZgdm-1e467y1cBK-00LS9c@mail.gmx.com>
References: <0LwrwO-1dPlOV2An2-016QZF@mail.gmx.com>
 <20170902183311.Horde.ahHsAl7ERDoX5FnSu-uvAKS@mail.sapo.pt>
 <CAF8bMcZHfZXCtnzpe2o=9Qm2YRWfiipKAXWZc8T=Kup9PEBwqg@mail.gmail.com>
 <0MZgdm-1e467y1cBK-00LS9c@mail.gmx.com>
Message-ID: <0F64A821-72C5-4113-B5B0-36E7B2D963D7@dcn.davis.ca.us>

>In the future, I?ll avoid dependencies between parameters.

You don't need to cut off your nose to spite your face... you are the one writing the code that breaks the dependency, so you have the option to not write your code that way (e.g. by using force() as Rui suggests).
-- 
Sent from my phone. Please excuse my brevity.

On September 2, 2017 10:53:14 AM PDT, Matthias Gondan <matthias-gondan at gmx.de> wrote:
>Dear Bill,
>
>All makes perfect sense (including the late evaluation). I actually
>discovered the problem by looking at old code which used your proposed
>solution. Still I find it strange (and, hnestly, I don?t like R?s
>behavior in this respect), and I am wondering why u is not being copied
>to L just before u is assigned a new value. Of course, this would
>require the R interpreter to track all these dependencies in both ways
>incl. more complicated ones in which L might depend on more than just
>u.
>
>In the future, I?ll avoid dependencies between parameters.
>
>Su4 <- function(u=100, l=100, mu=0.53, sigma2=4.3^2) # instead of l=u
>
>And maybe also ?in-place? changes of values?
>
>Best regards,
>
>Matthias
>
>Von: William Dunlap
>Gesendet: Samstag, 2. September 2017 19:41
>An: Rui Barradas
>Cc: Matthias Gondan; r-help at r-project.org
>Betreff: Re: [R] Strange lazy evaluation of default arguments
>
>Another way to avoid the problem is to not redefine variables that are
>arguments.? E.g.,
>
>> Su3 <- function(u=100, l=u, mu=0.53, sigma2=4.3^2, verbose)
>? {
>? ? if (verbose) {
>? ? ? print(c(u, l, mu))
>? ? }
>? ? uNormalized <- u/sqrt(sigma2)
>? ? lNormalized <- l/sqrt(sigma2)
>? ? muNormalized <- mu/sqrt(sigma2)
>? ? c(uNormalized, lNormalized, muNormalized)
>? }
>> Su3(verbose=TRUE)
>[1] 100.00 100.00 ? 0.53
>[1] 23.2558140 23.2558140 ?0.1232558
>> Su3(verbose=FALSE)
>[1] 23.2558140 23.2558140 ?0.1232558
>
>Not redefining variables at all makes debugging easier, although it may
>waste space.
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Sat, Sep 2, 2017 at 10:33 AM, <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>One way of preventing that is to use ?force.
>Just put
>
>? ?force(l)
>
>right after the commented out print and before you change 'u'.
>
>Hope this helps,
>
>Rui Barradas
>
>
>
>Citando Matthias Gondan <matthias-gondan at gmx.de>:
>
>Dear R developers,
>
>sessionInfo() below
>
>Please have a look at the following two versions of the same function:
>
>1. Intended behavior:
>Su1 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>+ {
>+? ?print(c(u, l, mu)) # here, l is set to u?s value
>+? ?u = u/sqrt(sigma2)
>+? ?l = l/sqrt(sigma2)
>+? ?mu = mu/sqrt(sigma2)
>+? ?print(c(u, l, mu))
>+ }
>
>Su1()
>[1] 100.00 100.00? ?0.53
>[1] 23.2558140 23.2558140? 0.1232558
>
>In the first version, both u and l are correctly divided by 4.3.
>
>2. Strange behavior:
>Su2 = function(u=100, l=u, mu=0.53, sigma2=4.3^2)
>+ {
>+? ?# print(c(u, l, mu))
>+? ?u = u/sqrt(sigma2)
>+? ?l = l/sqrt(sigma2) # here, l is set to u?s value
>+? ?mu = mu/sqrt(sigma2)
>+? ?print(c(u, l, mu))
>+ }
>
>Su2()
>[1] 23.2558140? 5.4083288? 0.1232558
>In the second version, the print
>function is commented out, so the variable u is
>copied to l (lowercase L) at a later place, and L is divided twice by
>4.3.
>
>Is this behavior intended? It seems strange that the result depends on
>a debugging message.
>
>Best wishes,
>
>Matthias
>
>sessionInfo()
>R version 3.4.1 (2017-06-30)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows >= 8 x64 (build 9200)
>
>Matrix products: default
>
>locale:
>[1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252? ?
>LC_MONETARY=German_Germany.1252
>[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? LC_TIME=German_Germany.1252
>
>attached base packages:
>[1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base
>
>loaded via a namespace (and not attached):
>[1] compiler_3.4.1 tools_3.4.1
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Tim.Glover at amecfw.com  Tue Sep  5 15:24:30 2017
From: Tim.Glover at amecfw.com (Glover, Tim)
Date: Tue, 5 Sep 2017 13:24:30 +0000
Subject: [R] Interesting behavior of lm() with small, problematic data sets
Message-ID: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>

I've recently come across the following results reported from the lm() function when applied to a particular type of admittedly difficult data.  When working with
small data sets (for instance 3 points) with the same response for different predicting variable, the resulting slope estimate is a reasonable approximation of the expected 0.0, but the p-value of that slope estimate is a surprising value.  A reproducible example is included below, along with the output of the summary of results

######### example code
x <- c(1,2,3)
y <- c(1,1,1)

#above results in{ (1,1) (2,1) (3,1)} data set to regress

new.rez <- lm (y ~ x) # regress constant y on changing x)
summary(new.rez) # display results of regression

######## end of example code

Results:

Call:
lm(formula = y ~ x)

Residuals:
         1          2          3
 5.906e-17 -1.181e-16  5.906e-17

Coefficients:
              Estimate Std. Error    t value Pr(>|t|)
(Intercept)  1.000e+00  2.210e-16  4.525e+15   <2e-16 ***
x           -1.772e-16  1.023e-16 -1.732e+00    0.333
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.447e-16 on 1 degrees of freedom
Multiple R-squared:  0.7794,    Adjusted R-squared:  0.5589
F-statistic: 3.534 on 1 and 1 DF,  p-value: 0.3112

Warning message:
In summary.lm(new.rez) : essentially perfect fit: summary may be unreliable


##############

There is a warning that the summary may be unreliable sue to the essentially perfect fit, but a p-value of 0.3112 doesn?t seem reasonable.
As a side note, the various r^2 values seem odd too.







Tim Glover
Senior Scientist II (Geochemistry, Statistics), Americas - Environment & Infrastructure, Amec Foster Wheeler
271 Mill Road, Chelmsford, Massachusetts, USA 01824-4105
T +01 978 692 9090      D +01 978 392 5383      M +01 850 445 5039
tim.glover at amecfw.com      amecfw.com


This message is the property of Amec Foster Wheeler plc and/or its subsidiaries and/or affiliates and is intended only for the named recipient(s). Its contents (including any attachments) may be confidential, legally privileged or otherwise protected from disclosure by law. Unauthorised use, copying, distribution or disclosure of any of it may be unlawful and is strictly prohibited. We assume no responsibility to persons other than the intended named recipient(s) and do not accept liability for any errors or omissions which are a result of email transmission. If you have received this message in error, please notify us immediately by reply email to the sender and confirm that the original message and any attachments and copies have been destroyed and deleted from your system. If you do not wish to receive future unsolicited commercial electronic messages from us, please forward this email to: unsubscribe at amecfw.com and include ?Unsubscribe? in the subject line. If applicable, you will continue to receive invoices, project communications and similar factual, non-commercial electronic communications.

Please click http://amecfw.com/email-disclaimer for notices and company information in relation to emails originating in the UK, Italy or France.


From S.Ellison at LGCGroup.com  Tue Sep  5 17:47:40 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 5 Sep 2017 16:47:40 +0100
Subject: [R] [FORGED] Re: Block comment?
In-Reply-To: <223f1b93-e900-6dbb-85b8-fc0e16e894d8@auckland.ac.nz>
References: <46b6cc6e-b1c6-e47c-5fc4-c8c338621776@echoffmann.ch>
 <6163f4b4-483d-fd54-3c26-36311cbd784b@statistik.tu-dortmund.de>
 <CAPtbhHzLpWJG3k_c_qssYPUybLo5-rKKX_aeJ5QTLsGG8douXA@mail.gmail.com>
 <CAF8bMcahE+F4qbLYmmnaE7mVL8iMTGVpub6Psb5MeK8+S7W5Jw@mail.gmail.com>
 <82f019cc-b39c-2e0d-1530-dd4adf0977f7@auckland.ac.nz>
 <c182eb0f-328e-6e30-5b37-ef94a71a8cba@gmail.com>
 <223f1b93-e900-6dbb-85b8-fc0e16e894d8@auckland.ac.nz>
Message-ID: <1A8C1289955EF649A09086A153E267240BD80E94C3@GBTEDVPEXCMB04.corp.lgc-group.com>

> Do not the same considerations essentially apply to the well established
> /* .... */ convention used in C?  Well maybe you simply *can't* get the "*/"
> string within a block of C code, but still ....
Yes, the same problem arises in C. And you _can_ get */ in valid code - as the closing part of a comment. Attempts to nest C block comments result in part of the outer block becoming uncommented and the outer block comment terminator becoming invalid syntax.

For example
main() {
 /*
    /* Hello world */   <- now the comment terminator
         printf("hello world") 
 /*  <- oops
} 

Avoiding that trap is one reason that ANSI C block comments often use an extra ' *' at the beginning of each line - as in

/* **************
 * An example ANSI C  
 * heading   
 * ************** */
which rather undermines the convenience of the whole thing.

So there's probably more than one reason // was added to C. That and better editors.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.ca.us  Tue Sep  5 18:05:09 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 05 Sep 2017 09:05:09 -0700
Subject: [R] Interesting behavior of lm() with small,
	problematic data sets
In-Reply-To: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
Message-ID: <7A9D1A2D-6023-4BFC-BD16-8707C493140A@dcn.davis.ca.us>

Why does an unreliable fit have to provide "reasonable" results?

More specifically, p-values arise from observed distributions... if your slopes are "in the noise" then the slope estimate's location within that distribution could be anywhere relative to the center and spread of that very narrow distribution, leading to, ah, what was it... oh, right... "unreliable" results.
-- 
Sent from my phone. Please excuse my brevity.

On September 5, 2017 6:24:30 AM PDT, "Glover, Tim" <Tim.Glover at amecfw.com> wrote:
>I've recently come across the following results reported from the lm()
>function when applied to a particular type of admittedly difficult
>data.  When working with
>small data sets (for instance 3 points) with the same response for
>different predicting variable, the resulting slope estimate is a
>reasonable approximation of the expected 0.0, but the p-value of that
>slope estimate is a surprising value.  A reproducible example is
>included below, along with the output of the summary of results
>
>######### example code
>x <- c(1,2,3)
>y <- c(1,1,1)
>
>#above results in{ (1,1) (2,1) (3,1)} data set to regress
>
>new.rez <- lm (y ~ x) # regress constant y on changing x)
>summary(new.rez) # display results of regression
>
>######## end of example code
>
>Results:
>
>Call:
>lm(formula = y ~ x)
>
>Residuals:
>         1          2          3
> 5.906e-17 -1.181e-16  5.906e-17
>
>Coefficients:
>              Estimate Std. Error    t value Pr(>|t|)
>(Intercept)  1.000e+00  2.210e-16  4.525e+15   <2e-16 ***
>x           -1.772e-16  1.023e-16 -1.732e+00    0.333
>---
>Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>Residual standard error: 1.447e-16 on 1 degrees of freedom
>Multiple R-squared:  0.7794,    Adjusted R-squared:  0.5589
>F-statistic: 3.534 on 1 and 1 DF,  p-value: 0.3112
>
>Warning message:
>In summary.lm(new.rez) : essentially perfect fit: summary may be
>unreliable
>
>
>##############
>
>There is a warning that the summary may be unreliable sue to the
>essentially perfect fit, but a p-value of 0.3112 doesn?t seem
>reasonable.
>As a side note, the various r^2 values seem odd too.
>
>
>
>
>
>
>
>Tim Glover
>Senior Scientist II (Geochemistry, Statistics), Americas - Environment
>& Infrastructure, Amec Foster Wheeler
>271 Mill Road, Chelmsford, Massachusetts, USA 01824-4105
>T +01 978 692 9090      D +01 978 392 5383      M +01 850 445 5039
>tim.glover at amecfw.com      amecfw.com
>
>
>This message is the property of Amec Foster Wheeler plc and/or its
>subsidiaries and/or affiliates and is intended only for the named
>recipient(s). Its contents (including any attachments) may be
>confidential, legally privileged or otherwise protected from disclosure
>by law. Unauthorised use, copying, distribution or disclosure of any of
>it may be unlawful and is strictly prohibited. We assume no
>responsibility to persons other than the intended named recipient(s)
>and do not accept liability for any errors or omissions which are a
>result of email transmission. If you have received this message in
>error, please notify us immediately by reply email to the sender and
>confirm that the original message and any attachments and copies have
>been destroyed and deleted from your system. If you do not wish to
>receive future unsolicited commercial electronic messages from us,
>please forward this email to: unsubscribe at amecfw.com and include
>?Unsubscribe? in the subject line. If applicable, you will continue to
>receive invoices, project communications and similar factual,
>non-commercial electronic communications.
>
>Please click http://amecfw.com/email-disclaimer for notices and company
>information in relation to emails originating in the UK, Italy or
>France.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Sep  5 18:28:51 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Sep 2017 09:28:51 -0700
Subject: [R] Interesting behavior of lm() with small,
	problematic data sets
In-Reply-To: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
Message-ID: <724E8B35-A86F-4F10-8EE2-96BC8846EA50@comcast.net>


> On Sep 5, 2017, at 6:24 AM, Glover, Tim <Tim.Glover at amecfw.com> wrote:
> 
> I've recently come across the following results reported from the lm() function when applied to a particular type of admittedly difficult data.  When working with
> small data sets (for instance 3 points) with the same response for different predicting variable, the resulting slope estimate is a reasonable approximation of the expected 0.0, but the p-value of that slope estimate is a surprising value.  A reproducible example is included below, along with the output of the summary of results
> 
> ######### example code
> x <- c(1,2,3)
> y <- c(1,1,1)
> 
> #above results in{ (1,1) (2,1) (3,1)} data set to regress
> 
> new.rez <- lm (y ~ x) # regress constant y on changing x)
> summary(new.rez) # display results of regression
> 
> ######## end of example code
> 
> Results:
> 
> Call:
> lm(formula = y ~ x)
> 
> Residuals:
>         1          2          3
> 5.906e-17 -1.181e-16  5.906e-17
> 
> Coefficients:
>              Estimate Std. Error    t value Pr(>|t|)
> (Intercept)  1.000e+00  2.210e-16  4.525e+15   <2e-16 ***
> x           -1.772e-16  1.023e-16 -1.732e+00    0.333
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 1.447e-16 on 1 degrees of freedom
> Multiple R-squared:  0.7794,    Adjusted R-squared:  0.5589
> F-statistic: 3.534 on 1 and 1 DF,  p-value: 0.3112
> 
> Warning message:
> In summary.lm(new.rez) : essentially perfect fit: summary may be unreliable
> 
> 
> ##############
> 
> There is a warning that the summary may be unreliable sue to the essentially perfect fit, but a p-value of 0.3112 doesn?t seem reasonable.
> As a side note, the various r^2 values seem odd too.

You have an overfitted model with only 3 perfectly fit-able data points and you are whinging about a Wald statistic about which you were warned. I think you are wasting our time. (But I'm fully retired and I have a lot of time to waste.)

I seem to remember that a t-distribution with 1 degree of freedom is actually the Cauchy distribution. I would point out that you can also get:

> 2*pt(-1.732e+00, 1)
[1] 0.3333414

So maybe from that perspective any value might be "reasonable" from the perspective that you have that particular number data points (so one degree of freedom) and are using an estimate of the t-statistic which is essentially the ratio of 0/0 from a numerical point of view.

-- 
David.


From mark.hogue at srs.gov  Tue Sep  5 18:31:14 2017
From: mark.hogue at srs.gov (mark.hogue at srs.gov)
Date: Tue, 5 Sep 2017 12:31:14 -0400
Subject: [R] Interesting behavior of lm() with small,
	problematic data sets
In-Reply-To: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
Message-ID: <OF553F6200.82F1AF5A-ON85258192.005A75F1-85258192.005AC01D@srs.gov>

Tim,

I think what you're seeing is 
https://en.wikipedia.org/wiki/Loss_of_significance.

Cheers,

Mark



From:   "Glover, Tim" <Tim.Glover at amecfw.com>
To:     "r-help at r-project.org" <r-help at r-project.org>
Date:   09/05/2017 11:37 AM
Subject:        [R] Interesting behavior of lm() with small, problematic 
data sets
Sent by:        "R-help" <r-help-bounces at r-project.org>



I've recently come across the following results reported from the lm() 
function when applied to a particular type of admittedly difficult data. 
When working with
small data sets (for instance 3 points) with the same response for 
different predicting variable, the resulting slope estimate is a 
reasonable approximation of the expected 0.0, but the p-value of that 
slope estimate is a surprising value.  A reproducible example is included 
below, along with the output of the summary of results

######### example code
x <- c(1,2,3)
y <- c(1,1,1)

#above results in{ (1,1) (2,1) (3,1)} data set to regress

new.rez <- lm (y ~ x) # regress constant y on changing x)
summary(new.rez) # display results of regression

######## end of example code

Results:

Call:
lm(formula = y ~ x)

Residuals:
         1          2          3
 5.906e-17 -1.181e-16  5.906e-17

Coefficients:
              Estimate Std. Error    t value Pr(>|t|)
(Intercept)  1.000e+00  2.210e-16  4.525e+15   <2e-16 ***
x           -1.772e-16  1.023e-16 -1.732e+00    0.333
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.447e-16 on 1 degrees of freedom
Multiple R-squared:  0.7794,    Adjusted R-squared:  0.5589
F-statistic: 3.534 on 1 and 1 DF,  p-value: 0.3112

Warning message:
In summary.lm(new.rez) : essentially perfect fit: summary may be 
unreliable


##############

There is a warning that the summary may be unreliable sue to the 
essentially perfect fit, but a p-value of 0.3112 doesn?t seem reasonable.
As a side note, the various r^2 values seem odd too.







Tim Glover
Senior Scientist II (Geochemistry, Statistics), Americas - Environment & 
Infrastructure, Amec Foster Wheeler
271 Mill Road, Chelmsford, Massachusetts, USA 01824-4105
T +01 978 692 9090      D +01 978 392 5383      M +01 850 445 5039
tim.glover at amecfw.com      amecfw.com


This message is the property of Amec Foster Wheeler plc and/or its 
subsidiaries and/or affiliates and is intended only for the named 
recipient(s). Its contents (including any attachments) may be 
confidential, legally privileged or otherwise protected from disclosure by 
law. Unauthorised use, copying, distribution or disclosure of any of it 
may be unlawful and is strictly prohibited. We assume no responsibility to 
persons other than the intended named recipient(s) and do not accept 
liability for any errors or omissions which are a result of email 
transmission. If you have received this message in error, please notify us 
immediately by reply email to the sender and confirm that the original 
message and any attachments and copies have been destroyed and deleted 
from your system. If you do not wish to receive future unsolicited 
commercial electronic messages from us, please forward this email to: 
unsubscribe at amecfw.com and include ?Unsubscribe? in the subject line. If 
applicable, you will continue to receive invoices, project communications 
and similar factual, non-commercial electronic communications.

Please click http://amecfw.com/email-disclaimer for notices and company 
information in relation to emails originating in the UK, Italy or France.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Wed Sep  6 11:41:46 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 6 Sep 2017 11:41:46 +0200
Subject: [R] post_processor in rmarkdown not working
Message-ID: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>

Dear all,

I'm trying to write a post_processor() for a custom rmarkdown format. The
goal of the post_processor() is to modify the latex file before it is
compiled. For some reason the post_processor() is not run. The
post_processor() does work when I run it manually on the tex file.

Any suggestions on what I'm doing wrong? Below is the relevant snippet of
the code. The full code is available at
https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
is an Rmd is a MWE that fails compile because the post_processor() is not
run.

Best regards,

Thierry

  post_processor <- function(
    metadata, input_file, output_file, clean, verbose
  ) {
    text <- readLines(output_file, warn = FALSE)

    # set correct text in fmtext environment
    end_first_page <- grep("\\\\EndFirstPage", text) #nolint
    if (length(end_first_page) == 1) {
      maketitle <- grep("\\\\maketitle", text) #nolint
      text <- c(
        text[1:(maketitle - 1)],
        "\\begin{fmtext}",
        text[(maketitle + 1):(end_first_page - 1)],
        "\\end{fmtext}",
        "\\maketitle",
        text[(end_first_page + 1):length(text)]
      )
      writeLines(enc2utf8(text), output_file, useBytes = TRUE)
    }
    output_file
  }

  output_format(
    knitr = knitr_options(
      opts_knit = list(
        width = 60,
        concordance = TRUE
      ),
      opts_chunk = opts_chunk,
      knit_hooks = knit_hooks
    ),
    pandoc = pandoc_options(
      to = "latex",
      latex_engine = "xelatex",
      args = args,
      keep_tex = keep_tex
    ),
    post_processor = post_processor,
    clean_supporting = !keep_tex
  )



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Wed Sep  6 15:10:30 2017
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 6 Sep 2017 14:10:30 +0100
Subject: [R] Interesting behavior of lm() with small,
 problematic data sets
In-Reply-To: <OF553F6200.82F1AF5A-ON85258192.005A75F1-85258192.005AC01D@srs.gov>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
 <OF553F6200.82F1AF5A-ON85258192.005A75F1-85258192.005AC01D@srs.gov>
Message-ID: <1A8C1289955EF649A09086A153E267240BD80E96B1@GBTEDVPEXCMB04.corp.lgc-group.com>

> I think what you're seeing is
> https://en.wikipedia.org/wiki/Loss_of_significance.

Almost. 
All the results in the OP's summary are reflections of finite precision in the analytically exact solution, leading to residuals smaller than the double precision limit. The summary is correctly warning that it's all potentially nonsense, and indeed the only things you can trust are the coefficient values (to within .Machine$double.eps or thereabouts)

Interestingly, though, my current version of R (3.4.0) gives numerically exact coefficients (c(1,0) and identically zero standard errors.

So this particular example is apparently version-specific.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From loesljrg at accucom.net  Wed Sep  6 15:22:18 2017
From: loesljrg at accucom.net (JRG)
Date: Wed, 6 Sep 2017 09:22:18 -0400
Subject: [R] Interesting behavior of lm() with small,
 problematic data sets
In-Reply-To: <1A8C1289955EF649A09086A153E267240BD80E96B1@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
 <OF553F6200.82F1AF5A-ON85258192.005A75F1-85258192.005AC01D@srs.gov>
 <1A8C1289955EF649A09086A153E267240BD80E96B1@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <c26a3987-9fc5-db90-181f-2b86cee78b08@accucom.net>

Indeed (version-specific).

With R 3.4.1 on linux, I get coefficients and residuals that are
numerically exact, F-statistic = NaN, p-value = NA, R-squared = NaN, etc.

All of which is what ought to happen, given that the response variable
(y) is not actually variable.


---JRG
John R. Gleason


On 09/06/2017 09:10 AM, S Ellison wrote:
>> I think what you're seeing is
>> https://en.wikipedia.org/wiki/Loss_of_significance.
> 
> Almost. 
> All the results in the OP's summary are reflections of finite precision in the analytically exact solution, leading to residuals smaller than the double precision limit. The summary is correctly warning that it's all potentially nonsense, and indeed the only things you can trust are the coefficient values (to within .Machine$double.eps or thereabouts)
> 
> Interestingly, though, my current version of R (3.4.0) gives numerically exact coefficients (c(1,0) and identically zero standard errors.
> 
> So this particular example is apparently version-specific.
> 
> S Ellison
> 
> 
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From manojoak at yahoo.com  Wed Sep  6 15:14:23 2017
From: manojoak at yahoo.com (manoj oak)
Date: Wed, 6 Sep 2017 13:14:23 +0000 (UTC)
Subject: [R] Help
References: <800405348.3795613.1504703663917.ref@mail.yahoo.com>
Message-ID: <800405348.3795613.1504703663917@mail.yahoo.com>

Hello,
I want to analysis of NIR spectra and develop prediction models using pls, mpls, pcr statics. ?I used inspectr package, processed and modified the spectra, but how i do the prediction using packages pls and caret do not know. If some one is ready to do the help I will appreciate it.?
with best regardsManoj Oak ?

	[[alternative HTML version deleted]]


From fisher at plessthan.com  Wed Sep  6 17:11:43 2017
From: fisher at plessthan.com (Dennis Fisher)
Date: Wed, 6 Sep 2017 08:11:43 -0700
Subject: [R] Using quantmod to obtain current Dow Jones index
Message-ID: <E25CCB78-CCC8-4934-8000-CF905AFD08E0@plessthan.com>

R 3.4.1
OS X

Colleagues,

I am just learning to use the quantmod package and I have encountered something that I don?t understand.

This works:
	getSymbols("^DJI") 

This does not work:
	getQuote("^DJI?)
It returns only NAs:
	Trade Time Last Change % Change Open High Low Volume 
	^DJI <NA> N/A N/A N/A N/A N/A N/A N/A 

Two questions:
	1.  Is there some way to obtain the current DJI using quantmod?
	2.  If not, can someone suggest alternatives?

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From jpolo at mail.usf.edu  Wed Sep  6 20:52:31 2017
From: jpolo at mail.usf.edu (john polo)
Date: Wed, 6 Sep 2017 13:52:31 -0500
Subject: [R] rgdal error when trying to import raster
Message-ID: <1663e237-e682-b534-9d89-d29a83d9e15a@mail.usf.edu>

Dear useRs,

I am trying to import a raster with the line:

nlcd <- raster("/home/jpolo/NRI/nlcd_nri5000.tif")

And I keep getting an error like this:

"Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, 
logical.return = TRUE,? :
 ? there is no package called 'rgdal'
Error in .rasterObjectFromFile(x, band = band, objecttype = 
"RasterLayer",? :
 ? Cannot create RasterLayer object from this file; perhaps you need to 
install rgdal first
Calls: raster -> raster -> .local -> .rasterObjectFromFile
Execution halted"

This is the session info:

"R version 3.2.5 (2016-04-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS release 6.3 (Final)

locale:
[1] C

attached base packages:
[1] methods?? stats???? graphics? grDevices utils datasets? base

other attached packages:
[1] raster_2.5-8 sp_1.2-4???? rgeos_0.3-23

loaded via a namespace (and not attached):
[1] Rcpp_0.12.10??? grid_3.2.5????? lattice_0.20-35 "

I know the R version is old, but this is a system that I can not update, 
I have no control over it. Because the version of R is old, the admin 
told me that they cannot install rgdal. I am not using library(rgdal) 
and none of the other libraries that are loaded require rgdal. The 
package raster does suggest it though. Is that causing the problem? Is 
there a way to avoid this? Any help is welcome.

best,

John


-- 
"Ask a man to be quiet,
and he'll be silent for a moment.
Feed a man to a red dragon
and he'll be silent for a lifetime."
-Anne Isabella Thackeray Ritchie


From btupper at bigelow.org  Thu Sep  7 00:29:41 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 6 Sep 2017 18:29:41 -0400
Subject: [R] rgdal error when trying to import raster
In-Reply-To: <1663e237-e682-b534-9d89-d29a83d9e15a@mail.usf.edu>
References: <1663e237-e682-b534-9d89-d29a83d9e15a@mail.usf.edu>
Message-ID: <DA725F8F-B3C2-4A80-A643-808E78C796F5@bigelow.org>

Hi,

The message "there is no package called 'rgdal'" means that you don't have rgdal installed.

https://cran.r-project.org/web/packages/rgdal/index.html

Also, you will get very good patial-centric help if you subscribed to r-sig-geo here

https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Cheers,
Ben



> On Sep 6, 2017, at 2:52 PM, john polo <jpolo at mail.usf.edu> wrote:
> 
> Dear useRs,
> 
> I am trying to import a raster with the line:
> 
> nlcd <- raster("/home/jpolo/NRI/nlcd_nri5000.tif")
> 
> And I keep getting an error like this:
> 
> "Warning message:
> In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>   there is no package called 'rgdal'
> Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer",  :
>   Cannot create RasterLayer object from this file; perhaps you need to install rgdal first
> Calls: raster -> raster -> .local -> .rasterObjectFromFile
> Execution halted"
> 
> This is the session info:
> 
> "R version 3.2.5 (2016-04-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: CentOS release 6.3 (Final)
> 
> locale:
> [1] C
> 
> attached base packages:
> [1] methods   stats     graphics  grDevices utils datasets  base
> 
> other attached packages:
> [1] raster_2.5-8 sp_1.2-4     rgeos_0.3-23
> 
> loaded via a namespace (and not attached):
> [1] Rcpp_0.12.10    grid_3.2.5      lattice_0.20-35 "
> 
> I know the R version is old, but this is a system that I can not update, I have no control over it. Because the version of R is old, the admin told me that they cannot install rgdal. I am not using library(rgdal) and none of the other libraries that are loaded require rgdal. The package raster does suggest it though. Is that causing the problem? Is there a way to avoid this? Any help is welcome.
> 
> best,
> 
> John
> 
> 
> -- 
> "Ask a man to be quiet,
> and he'll be silent for a moment.
> Feed a man to a red dragon
> and he'll be silent for a lifetime."
> -Anne Isabella Thackeray Ritchie
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/


From roy.mendelssohn at noaa.gov  Thu Sep  7 00:41:56 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 6 Sep 2017 15:41:56 -0700
Subject: [R] withr::set_makevars
Message-ID: <41FAD8F8-1759-4793-9C1C-F78782710EC6@noaa.gov>

Hi All;

This problem has come about from trying to learn some of the review practices recommend by rOpensci.  One of them is to use the package goodpractice.  After installing goodpractice, it kept failing on my own packages which are under development, and I was concerned something was funny in my own ,  so I have a fork of the package rerddap,  and I tested goodpractice on that.  I get the error:

> Error in set_makevars(new, path, makevars_file, assignment = assignment) : 
>   Multiple results for CXXFLAGS found, something is wrong.FALSE
> 


So after some playing around that is from the very first test,  which uses the covr:package_coverage(), and sure enough running that produces the same error.  Looking at the code,  that error is being thrown by the function withr::set_makevars().  We are now too many layers deep into packages for me to follow what is going on,  but the kicker is Scott Chamberlain can run it without any errors on the same package.  Session_info for both of us follows.  If any one has any suggestions both as to what is causing this and a possible solution,  would appreciate it.

Roy's sessionInfo is after running the commands:

Sys.setenv(NOT_CRAN = "true") 
x = goodpractice::gp(path = ".", checks = all_checks()[2:230])

Scott's is after running:

Sys.setenv(NOT_CRAN = "true") 
x = goodpractice::gp()




Roy's_session_info()
? Session info ??????????????????????????????????????????????????????????????????????????????????????????????????????????????
 setting  value                       
 version  R version 3.4.1 (2017-06-30)
 os       macOS Sierra 10.12.6        
 system   x86_64, darwin15.6.0        
 ui       RStudio                     
 language (EN)                        
 collate  en_US.UTF-8                 
 tz       America/Los_Angeles         
 date     2017-09-06                  

? Packages  package      * version     date       source                                   
 assertthat     0.2.0       2017-04-11 CRAN (R 3.4.1)                           
 backports      1.1.0       2017-05-22 CRAN (R 3.4.0)                           
 callr          1.0.0.9000  2017-09-02 Github (r-lib/callr at 2dffbbe)             
 clisymbols     1.2.0       2017-09-02 Github (gaborcsardi/clisymbols at e49b4f5)  
 covr           3.0.0       2017-06-26 CRAN (R 3.4.1)                           
 crayon         1.3.2.9000  2017-08-25 Github (gaborcsardi/crayon at e4dba3b)      
 cyclocomp      1.1.0       2017-09-02 Github (MangoTheCat/cyclocomp at 6156a12)   
 debugme        1.0.2       2017-03-01 CRAN (R 3.4.0)                           
 desc           1.1.1       2017-08-03 CRAN (R 3.4.1)                           
 devtools       1.13.3.9000 2017-08-31 Github (hadley/devtools at 91490d1)         
 digest         0.6.12      2017-01-27 CRAN (R 3.4.1)                           
 goodpractice * 1.0.0       2017-09-02 Github (MangoTheCat/goodpractice at 9969799)
 httr           1.3.1       2017-08-20 CRAN (R 3.4.1)                           
 igraph         1.1.2       2017-07-21 CRAN (R 3.4.1)                           
 jsonlite       1.5         2017-06-01 CRAN (R 3.4.0)                           
 knitr          1.17        2017-08-10 CRAN (R 3.4.1)                           
 lazyeval       0.2.0       2016-06-12 CRAN (R 3.4.0)                           
 lintr          1.0.1       2017-08-10 CRAN (R 3.4.1)                           
 magrittr       1.5         2014-11-22 CRAN (R 3.4.0)                           
 memoise        1.1.0       2017-04-21 CRAN (R 3.4.0)                           
 pkgbuild       0.0.0.9000  2017-08-31 Github (r-lib/pkgbuild at 6574561)          
 pkgconfig      2.0.1       2017-03-21 CRAN (R 3.4.0)                           
 pkgload        0.0.0.9000  2017-08-31 Github (r-pkgs/pkgload at 80a6493)          
 praise         1.0.0       2015-08-11 CRAN (R 3.4.0)                           
 processx       2.0.0.1     2017-07-30 CRAN (R 3.4.1)                           
 R6             2.2.2       2017-06-17 CRAN (R 3.4.0)                           
 rcmdcheck      1.2.1       2016-09-28 CRAN (R 3.4.0)                           
 Rcpp           0.12.12     2017-07-15 CRAN (R 3.4.1)                           
 remotes        1.1.0       2017-07-09 CRAN (R 3.4.1)                           
 rex            1.1.1       2016-12-05 CRAN (R 3.4.0)                           
 rlang          0.1.2.9000  2017-09-05 Github (tidyverse/rlang at fd64bce)         
 rprojroot      1.2         2017-01-16 CRAN (R 3.4.0)                           
 rstudioapi     0.6.0.9000  2017-08-31 Github (rstudio/rstudioapi at e1e466b)      
 sessioninfo    1.0.1       2017-08-31 Github (r-lib/sessioninfo at e813de4)       
 stringi        1.1.5       2017-04-07 CRAN (R 3.4.0)                           
 stringr        1.2.0       2017-02-18 CRAN (R 3.4.0)                           
 usethis        0.0.0.9000  2017-08-31 Github (r-lib/usethis at 12e6f95)           
 whoami         1.1.1       2015-07-13 CRAN (R 3.4.0)                           
 withr          2.0.0       2017-07-28 CRAN (R 3.4.1)                           
 xml2           1.1.1       2017-01-24 CRAN (R 3.4.0)                           
 xmlparsedata   1.0.1       2016-06-18 CRAN (R 3.4.0)                           
 yaml           2.1.14      2016-11-12 CRAN (R 3.4.0)                           


Scott's _ sessionInfo()      
Session info ------------------------------------------------------------------
 setting  value
 version  R version 3.4.1 Patched (2017-07-04 r72893)
 system   x86_64, darwin15.6.0
 ui       X11
 language (EN)
 collate  en_US.UTF-8
 tz       America/Los_Angeles
 date     2017-09-06

Packages ----------------------------------------------------------------------
 package      * version    date       source
 assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)
 backports      1.1.0      2017-05-22 CRAN (R 3.4.0)
 base         * 3.4.1      2017-07-06 local
 callr          1.0.0.9000 2017-07-31 Github (r-lib/callr at ce3f15c)
 clisymbols     1.2.0      2017-06-10 Github (gaborcsardi/clisymbols at 83b13a0)
 compiler       3.4.1      2017-07-06 local
 covr           3.0.0      2017-06-26 CRAN (R 3.4.0)
 crayon         1.3.2.9000 2017-07-31 Github (gaborcsardi/crayon at 750190f)
 cyclocomp      1.1.0      2017-05-04 Github (MangoTheCat/cyclocomp at 6156a12)
 datasets     * 3.4.1      2017-07-06 local
 debugme        1.0.2      2017-03-01 cran (@1.0.2)
 desc           1.1.1      2017-08-03 CRAN (R 3.4.1)
 devtools     * 1.13.3     2017-08-02 CRAN (R 3.4.1)
 digest         0.6.12     2017-01-27 CRAN (R 3.4.0)
 goodpractice   1.0.0      2017-06-10 Github (MangoTheCat/goodpractice at 9969799)
 graphics     * 3.4.1      2017-07-06 local
 grDevices    * 3.4.1      2017-07-06 local
 httr           1.3.1      2017-08-20 CRAN (R 3.4.1)
 jsonlite       1.5        2017-06-01 CRAN (R 3.4.0)
 lazyeval       0.2.0      2016-06-12 CRAN (R 3.4.0)
 lintr          1.0.1      2017-08-10 CRAN (R 3.4.1)
 magrittr       1.5        2014-11-22 CRAN (R 3.4.0)
 memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)
 methods      * 3.4.1      2017-07-06 local
 praise         1.0.0      2015-08-11 CRAN (R 3.4.0)
 prettyunits    1.0.2      2015-07-13 CRAN (R 3.4.0)
 processx       2.0.1.9000 2017-07-31 Github (r-lib/processx at c02b0f3)
 R6             2.2.2      2017-06-17 CRAN (R 3.4.0)
 rcmdcheck      1.2.1.9000 2017-06-10 Github (r-pkgs/rcmdcheck at a18119c)
 Rcpp           0.12.12    2017-07-15 cran (@0.12.12)
 remotes        1.1.0      2017-07-09 CRAN (R 3.4.1)
 rex            1.1.1      2016-03-11 CRAN (R 3.4.0)
 rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)
 rstudioapi     0.6        2016-06-27 CRAN (R 3.4.0)
 stats        * 3.4.1      2017-07-06 local
 tools          3.4.1      2017-07-06 local
 utils        * 3.4.1      2017-07-06 local
 whoami         1.1.1      2015-07-13 CRAN (R 3.4.0)
 withr          2.0.0      2017-09-05 Github (jimhester/withr at eff4818)
 xml2           1.1.1      2017-01-24 CRAN (R 3.4.0)
 xmlparsedata   1.0.1      2016-06-18 cran (@1.0.1)


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jdnewmil at dcn.davis.ca.us  Thu Sep  7 01:20:30 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 06 Sep 2017 16:20:30 -0700
Subject: [R] rgdal error when trying to import raster
In-Reply-To: <DA725F8F-B3C2-4A80-A643-808E78C796F5@bigelow.org>
References: <1663e237-e682-b534-9d89-d29a83d9e15a@mail.usf.edu>
 <DA725F8F-B3C2-4A80-A643-808E78C796F5@bigelow.org>
Message-ID: <9262FFBC-1FD8-4522-9BC7-061B5E8143D9@dcn.davis.ca.us>

Indeed, Ben, but the question was something more like it is not a Dependency, just Suggested, so why the error...

John:

If you read the Introduction to the 'raster' package vignette, it indicates that some input formats are supported within the raster package and some rely on other packages. Clearly the attempt to read a TIFF was an example of the latter. Had you used a different input file format the issue of rgdal might never have appeared... ergo, Suggests rather than Depends. 

Note that someone may feel pity for your plight, John, and give you a convenient alternative way to import the data to raster (there are other packages that read TIFF but you would probably have to roll the geolocation yourself... an avenue for which help would be better pursued on R-sig-geo), but the premise of your email (cannot upgrade) does put it squarely in the off-topic category according to the Posting Guide. Fortunately R is open-source so if you are diligent you can write/borrow R code as needed or even recompile R and necessary packages entirely within your personal development directories with no system installation to bother your sysadmin about... but you might also just go find another computer to do your work on.
-- 
Sent from my phone. Please excuse my brevity.

On September 6, 2017 3:29:41 PM PDT, Ben Tupper <btupper at bigelow.org> wrote:
>Hi,
>
>The message "there is no package called 'rgdal'" means that you don't
>have rgdal installed.
>
>https://cran.r-project.org/web/packages/rgdal/index.html
>
>Also, you will get very good patial-centric help if you subscribed to
>r-sig-geo here
>
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>Cheers,
>Ben
>
>
>
>> On Sep 6, 2017, at 2:52 PM, john polo <jpolo at mail.usf.edu> wrote:
>> 
>> Dear useRs,
>> 
>> I am trying to import a raster with the line:
>> 
>> nlcd <- raster("/home/jpolo/NRI/nlcd_nri5000.tif")
>> 
>> And I keep getting an error like this:
>> 
>> "Warning message:
>> In library(package, lib.loc = lib.loc, character.only = TRUE,
>logical.return = TRUE,  :
>>   there is no package called 'rgdal'
>> Error in .rasterObjectFromFile(x, band = band, objecttype =
>"RasterLayer",  :
>>   Cannot create RasterLayer object from this file; perhaps you need
>to install rgdal first
>> Calls: raster -> raster -> .local -> .rasterObjectFromFile
>> Execution halted"
>> 
>> This is the session info:
>> 
>> "R version 3.2.5 (2016-04-14)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: CentOS release 6.3 (Final)
>> 
>> locale:
>> [1] C
>> 
>> attached base packages:
>> [1] methods   stats     graphics  grDevices utils datasets  base
>> 
>> other attached packages:
>> [1] raster_2.5-8 sp_1.2-4     rgeos_0.3-23
>> 
>> loaded via a namespace (and not attached):
>> [1] Rcpp_0.12.10    grid_3.2.5      lattice_0.20-35 "
>> 
>> I know the R version is old, but this is a system that I can not
>update, I have no control over it. Because the version of R is old, the
>admin told me that they cannot install rgdal. I am not using
>library(rgdal) and none of the other libraries that are loaded require
>rgdal. The package raster does suggest it though. Is that causing the
>problem? Is there a way to avoid this? Any help is welcome.
>> 
>> best,
>> 
>> John
>> 
>> 
>> -- 
>> "Ask a man to be quiet,
>> and he'll be silent for a moment.
>> Feed a man to a red dragon
>> and he'll be silent for a lifetime."
>> -Anne Isabella Thackeray Ritchie
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>Ben Tupper
>Bigelow Laboratory for Ocean Sciences
>60 Bigelow Drive, P.O. Box 380
>East Boothbay, Maine 04544
>http://www.bigelow.org
>
>Ecocast Reports: http://seascapemodeling.org/ecocast.html
>Tick Reports: https://report.bigelow.org/tick/
>Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Thu Sep  7 01:44:18 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 6 Sep 2017 19:44:18 -0400
Subject: [R] rgdal error when trying to import raster
In-Reply-To: <9262FFBC-1FD8-4522-9BC7-061B5E8143D9@dcn.davis.ca.us>
References: <1663e237-e682-b534-9d89-d29a83d9e15a@mail.usf.edu>
 <DA725F8F-B3C2-4A80-A643-808E78C796F5@bigelow.org>
 <9262FFBC-1FD8-4522-9BC7-061B5E8143D9@dcn.davis.ca.us>
Message-ID: <9089B7F9-83F6-433B-B14B-434F00F42AA0@bigelow.org>

Ah, I didn't read the entire message.  Sorry about that!


> On Sep 6, 2017, at 7:20 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Indeed, Ben, but the question was something more like it is not a Dependency, just Suggested, so why the error...
> 
> John:
> 
> If you read the Introduction to the 'raster' package vignette, it indicates that some input formats are supported within the raster package and some rely on other packages. Clearly the attempt to read a TIFF was an example of the latter. Had you used a different input file format the issue of rgdal might never have appeared... ergo, Suggests rather than Depends. 
> 
> Note that someone may feel pity for your plight, John, and give you a convenient alternative way to import the data to raster (there are other packages that read TIFF but you would probably have to roll the geolocation yourself... an avenue for which help would be better pursued on R-sig-geo), but the premise of your email (cannot upgrade) does put it squarely in the off-topic category according to the Posting Guide. Fortunately R is open-source so if you are diligent you can write/borrow R code as needed or even recompile R and necessary packages entirely within your personal development directories with no system installation to bother your sysadmin about... but you might also just go find another computer to do your work on.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On September 6, 2017 3:29:41 PM PDT, Ben Tupper <btupper at bigelow.org> wrote:
>> Hi,
>> 
>> The message "there is no package called 'rgdal'" means that you don't
>> have rgdal installed.
>> 
>> https://cran.r-project.org/web/packages/rgdal/index.html
>> 
>> Also, you will get very good patial-centric help if you subscribed to
>> r-sig-geo here
>> 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> Cheers,
>> Ben
>> 
>> 
>> 
>>> On Sep 6, 2017, at 2:52 PM, john polo <jpolo at mail.usf.edu> wrote:
>>> 
>>> Dear useRs,
>>> 
>>> I am trying to import a raster with the line:
>>> 
>>> nlcd <- raster("/home/jpolo/NRI/nlcd_nri5000.tif")
>>> 
>>> And I keep getting an error like this:
>>> 
>>> "Warning message:
>>> In library(package, lib.loc = lib.loc, character.only = TRUE,
>> logical.return = TRUE,  :
>>>  there is no package called 'rgdal'
>>> Error in .rasterObjectFromFile(x, band = band, objecttype =
>> "RasterLayer",  :
>>>  Cannot create RasterLayer object from this file; perhaps you need
>> to install rgdal first
>>> Calls: raster -> raster -> .local -> .rasterObjectFromFile
>>> Execution halted"
>>> 
>>> This is the session info:
>>> 
>>> "R version 3.2.5 (2016-04-14)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: CentOS release 6.3 (Final)
>>> 
>>> locale:
>>> [1] C
>>> 
>>> attached base packages:
>>> [1] methods   stats     graphics  grDevices utils datasets  base
>>> 
>>> other attached packages:
>>> [1] raster_2.5-8 sp_1.2-4     rgeos_0.3-23
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_0.12.10    grid_3.2.5      lattice_0.20-35 "
>>> 
>>> I know the R version is old, but this is a system that I can not
>> update, I have no control over it. Because the version of R is old, the
>> admin told me that they cannot install rgdal. I am not using
>> library(rgdal) and none of the other libraries that are loaded require
>> rgdal. The package raster does suggest it though. Is that causing the
>> problem? Is there a way to avoid this? Any help is welcome.
>>> 
>>> best,
>>> 
>>> John
>>> 
>>> 
>>> -- 
>>> "Ask a man to be quiet,
>>> and he'll be silent for a moment.
>>> Feed a man to a red dragon
>>> and he'll be silent for a lifetime."
>>> -Anne Isabella Thackeray Ritchie
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecocast Reports: http://seascapemodeling.org/ecocast.html
>> Tick Reports: https://report.bigelow.org/tick/
>> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/


From wdunlap at tibco.com  Thu Sep  7 02:26:09 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 6 Sep 2017 17:26:09 -0700
Subject: [R] withr::set_makevars
In-Reply-To: <41FAD8F8-1759-4793-9C1C-F78782710EC6@noaa.gov>
References: <41FAD8F8-1759-4793-9C1C-F78782710EC6@noaa.gov>
Message-ID: <CAF8bMca8Dc7BGaDb0xCPvzecFftePAJHbT-60Y+qdbbZdk60LQ@mail.gmail.com>

withr:::set_makevars() can give that error if the makefile named by the
'old_path' argument (default "~/.R/Makevars) contains more than one
definition of a variable of the form 'name=value'.  You can see what file
it is reading and its contents by using the trace() function:

trace(withr:::set_makevars, quote({ cat(old_path, "\n");
writeLines(paste0("    ", tryCatch(readLines(old_path),
error=function(e)conditionMessage(e))))}))

Then run your test and see what file set_makevars is complaining about and
what in the file might cause trouble for set_makevars.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Sep 6, 2017 at 3:41 PM, Roy Mendelssohn - NOAA Federal <
roy.mendelssohn at noaa.gov> wrote:

> Hi All;
>
> This problem has come about from trying to learn some of the review
> practices recommend by rOpensci.  One of them is to use the package
> goodpractice.  After installing goodpractice, it kept failing on my own
> packages which are under development, and I was concerned something was
> funny in my own ,  so I have a fork of the package rerddap,  and I tested
> goodpractice on that.  I get the error:
>
> > Error in set_makevars(new, path, makevars_file, assignment = assignment)
> :
> >   Multiple results for CXXFLAGS found, something is wrong.FALSE
> >
>
>
> So after some playing around that is from the very first test,  which uses
> the covr:package_coverage(), and sure enough running that produces the same
> error.  Looking at the code,  that error is being thrown by the function
> withr::set_makevars().  We are now too many layers deep into packages for
> me to follow what is going on,  but the kicker is Scott Chamberlain can run
> it without any errors on the same package.  Session_info for both of us
> follows.  If any one has any suggestions both as to what is causing this
> and a possible solution,  would appreciate it.
>
> Roy's sessionInfo is after running the commands:
>
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp(path = ".", checks = all_checks()[2:230])
>
> Scott's is after running:
>
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp()
>
>
>
>
> Roy's_session_info()
> ? Session info ??????????????????????????????
> ????????????????????????????????????????????????????????????
> ????????????????????
>  setting  value
>  version  R version 3.4.1 (2017-06-30)
>  os       macOS Sierra 10.12.6
>  system   x86_64, darwin15.6.0
>  ui       RStudio
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
>
> ? Packages  package      * version     date       source
>  assertthat     0.2.0       2017-04-11 CRAN (R 3.4.1)
>  backports      1.1.0       2017-05-22 CRAN (R 3.4.0)
>  callr          1.0.0.9000  2017-09-02 Github (r-lib/callr at 2dffbbe)
>  clisymbols     1.2.0       2017-09-02 Github (gaborcsardi/clisymbols@
> e49b4f5)
>  covr           3.0.0       2017-06-26 CRAN (R 3.4.1)
>  crayon         1.3.2.9000  2017-08-25 Github (gaborcsardi/crayon at e4dba3b)
>  cyclocomp      1.1.0       2017-09-02 Github
> (MangoTheCat/cyclocomp at 6156a12)
>  debugme        1.0.2       2017-03-01 CRAN (R 3.4.0)
>  desc           1.1.1       2017-08-03 CRAN (R 3.4.1)
>  devtools       1.13.3.9000 2017-08-31 Github (hadley/devtools at 91490d1)
>  digest         0.6.12      2017-01-27 CRAN (R 3.4.1)
>  goodpractice * 1.0.0       2017-09-02 Github (MangoTheCat/goodpractice@
> 9969799)
>  httr           1.3.1       2017-08-20 CRAN (R 3.4.1)
>  igraph         1.1.2       2017-07-21 CRAN (R 3.4.1)
>  jsonlite       1.5         2017-06-01 CRAN (R 3.4.0)
>  knitr          1.17        2017-08-10 CRAN (R 3.4.1)
>  lazyeval       0.2.0       2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1       2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5         2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0       2017-04-21 CRAN (R 3.4.0)
>  pkgbuild       0.0.0.9000  2017-08-31 Github (r-lib/pkgbuild at 6574561)
>  pkgconfig      2.0.1       2017-03-21 CRAN (R 3.4.0)
>  pkgload        0.0.0.9000  2017-08-31 Github (r-pkgs/pkgload at 80a6493)
>  praise         1.0.0       2015-08-11 CRAN (R 3.4.0)
>  processx       2.0.0.1     2017-07-30 CRAN (R 3.4.1)
>  R6             2.2.2       2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1       2016-09-28 CRAN (R 3.4.0)
>  Rcpp           0.12.12     2017-07-15 CRAN (R 3.4.1)
>  remotes        1.1.0       2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1       2016-12-05 CRAN (R 3.4.0)
>  rlang          0.1.2.9000  2017-09-05 Github (tidyverse/rlang at fd64bce)
>  rprojroot      1.2         2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6.0.9000  2017-08-31 Github (rstudio/rstudioapi at e1e466b)
>  sessioninfo    1.0.1       2017-08-31 Github (r-lib/sessioninfo at e813de4)
>  stringi        1.1.5       2017-04-07 CRAN (R 3.4.0)
>  stringr        1.2.0       2017-02-18 CRAN (R 3.4.0)
>  usethis        0.0.0.9000  2017-08-31 Github (r-lib/usethis at 12e6f95)
>  whoami         1.1.1       2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0       2017-07-28 CRAN (R 3.4.1)
>  xml2           1.1.1       2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1       2016-06-18 CRAN (R 3.4.0)
>  yaml           2.1.14      2016-11-12 CRAN (R 3.4.0)
>
>
> Scott's _ sessionInfo()
> Session info ------------------------------------------------------------
> ------
>  setting  value
>  version  R version 3.4.1 Patched (2017-07-04 r72893)
>  system   x86_64, darwin15.6.0
>  ui       X11
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
>
> Packages ------------------------------------------------------------
> ----------
>  package      * version    date       source
>  assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)
>  backports      1.1.0      2017-05-22 CRAN (R 3.4.0)
>  base         * 3.4.1      2017-07-06 local
>  callr          1.0.0.9000 2017-07-31 Github (r-lib/callr at ce3f15c)
>  clisymbols     1.2.0      2017-06-10 Github (gaborcsardi/clisymbols@
> 83b13a0)
>  compiler       3.4.1      2017-07-06 local
>  covr           3.0.0      2017-06-26 CRAN (R 3.4.0)
>  crayon         1.3.2.9000 2017-07-31 Github (gaborcsardi/crayon at 750190f)
>  cyclocomp      1.1.0      2017-05-04 Github (MangoTheCat/cyclocomp at 6156a12
> )
>  datasets     * 3.4.1      2017-07-06 local
>  debugme        1.0.2      2017-03-01 cran (@1.0.2)
>  desc           1.1.1      2017-08-03 CRAN (R 3.4.1)
>  devtools     * 1.13.3     2017-08-02 CRAN (R 3.4.1)
>  digest         0.6.12     2017-01-27 CRAN (R 3.4.0)
>  goodpractice   1.0.0      2017-06-10 Github (MangoTheCat/goodpractice@
> 9969799)
>  graphics     * 3.4.1      2017-07-06 local
>  grDevices    * 3.4.1      2017-07-06 local
>  httr           1.3.1      2017-08-20 CRAN (R 3.4.1)
>  jsonlite       1.5        2017-06-01 CRAN (R 3.4.0)
>  lazyeval       0.2.0      2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1      2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5        2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)
>  methods      * 3.4.1      2017-07-06 local
>  praise         1.0.0      2015-08-11 CRAN (R 3.4.0)
>  prettyunits    1.0.2      2015-07-13 CRAN (R 3.4.0)
>  processx       2.0.1.9000 2017-07-31 Github (r-lib/processx at c02b0f3)
>  R6             2.2.2      2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1.9000 2017-06-10 Github (r-pkgs/rcmdcheck at a18119c)
>  Rcpp           0.12.12    2017-07-15 cran (@0.12.12)
>  remotes        1.1.0      2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1      2016-03-11 CRAN (R 3.4.0)
>  rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6        2016-06-27 CRAN (R 3.4.0)
>  stats        * 3.4.1      2017-07-06 local
>  tools          3.4.1      2017-07-06 local
>  utils        * 3.4.1      2017-07-06 local
>  whoami         1.1.1      2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0      2017-09-05 Github (jimhester/withr at eff4818)
>  xml2           1.1.1      2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1      2016-06-18 cran (@1.0.1)
>
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Thu Sep  7 02:29:21 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 6 Sep 2017 17:29:21 -0700
Subject: [R] withr::set_makevars
In-Reply-To: <CAF8bMca8Dc7BGaDb0xCPvzecFftePAJHbT-60Y+qdbbZdk60LQ@mail.gmail.com>
References: <41FAD8F8-1759-4793-9C1C-F78782710EC6@noaa.gov>
 <CAF8bMca8Dc7BGaDb0xCPvzecFftePAJHbT-60Y+qdbbZdk60LQ@mail.gmail.com>
Message-ID: <BDA18BED-706B-4C05-B92E-4105AC3B906C@noaa.gov>

Perfect,  thank you very much for the tip.

-Roy
> On Sep 6, 2017, at 5:26 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> withr:::set_makevars() can give that error if the makefile named by the 'old_path' argument (default "~/.R/Makevars) contains more than one definition of a variable of the form 'name=value'.  You can see what file it is reading and its contents by using the trace() function:
> 
> trace(withr:::set_makevars, quote({ cat(old_path, "\n"); writeLines(paste0("    ", tryCatch(readLines(old_path), error=function(e)conditionMessage(e))))}))
> 
> Then run your test and see what file set_makevars is complaining about and what in the file might cause trouble for set_makevars.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> On Wed, Sep 6, 2017 at 3:41 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov <mailto:roy.mendelssohn at noaa.gov>> wrote:
> Hi All;
> 
> This problem has come about from trying to learn some of the review practices recommend by rOpensci.  One of them is to use the package goodpractice.  After installing goodpractice, it kept failing on my own packages which are under development, and I was concerned something was funny in my own ,  so I have a fork of the package rerddap,  and I tested goodpractice on that.  I get the error:
> 
> > Error in set_makevars(new, path, makevars_file, assignment = assignment) :
> >   Multiple results for CXXFLAGS found, something is wrong.FALSE
> >
> 
> 
> So after some playing around that is from the very first test,  which uses the covr:package_coverage(), and sure enough running that produces the same error.  Looking at the code,  that error is being thrown by the function withr::set_makevars().  We are now too many layers deep into packages for me to follow what is going on,  but the kicker is Scott Chamberlain can run it without any errors on the same package.  Session_info for both of us follows.  If any one has any suggestions both as to what is causing this and a possible solution,  would appreciate it.
> 
> Roy's sessionInfo is after running the commands:
> 
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp(path = ".", checks = all_checks()[2:230])
> 
> Scott's is after running:
> 
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp()
> 
> 
> 
> 
> Roy's_session_info()
> ? Session info ??????????????????????????????????????????????????????????????????????????????????????????????????????????????
>  setting  value
>  version  R version 3.4.1 (2017-06-30)
>  os       macOS Sierra 10.12.6
>  system   x86_64, darwin15.6.0
>  ui       RStudio
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
> 
> ? Packages  package      * version     date       source
>  assertthat     0.2.0       2017-04-11 CRAN (R 3.4.1)
>  backports      1.1.0       2017-05-22 CRAN (R 3.4.0)
>  callr          1.0.0.9000  2017-09-02 Github (r-lib/callr at 2dffbbe)
>  clisymbols     1.2.0       2017-09-02 Github (gaborcsardi/clisymbols at e49b4f5)
>  covr           3.0.0       2017-06-26 CRAN (R 3.4.1)
>  crayon         1.3.2.9000  2017-08-25 Github (gaborcsardi/crayon at e4dba3b)
>  cyclocomp      1.1.0       2017-09-02 Github (MangoTheCat/cyclocomp at 6156a12)
>  debugme        1.0.2       2017-03-01 CRAN (R 3.4.0)
>  desc           1.1.1       2017-08-03 CRAN (R 3.4.1)
>  devtools       1.13.3.9000 2017-08-31 Github (hadley/devtools at 91490d1)
>  digest         0.6.12      2017-01-27 CRAN (R 3.4.1)
>  goodpractice * 1.0.0       2017-09-02 Github (MangoTheCat/goodpractice at 9969799)
>  httr           1.3.1       2017-08-20 CRAN (R 3.4.1)
>  igraph         1.1.2       2017-07-21 CRAN (R 3.4.1)
>  jsonlite       1.5         2017-06-01 CRAN (R 3.4.0)
>  knitr          1.17        2017-08-10 CRAN (R 3.4.1)
>  lazyeval       0.2.0       2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1       2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5         2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0       2017-04-21 CRAN (R 3.4.0)
>  pkgbuild       0.0.0.9000  2017-08-31 Github (r-lib/pkgbuild at 6574561)
>  pkgconfig      2.0.1       2017-03-21 CRAN (R 3.4.0)
>  pkgload        0.0.0.9000  2017-08-31 Github (r-pkgs/pkgload at 80a6493)
>  praise         1.0.0       2015-08-11 CRAN (R 3.4.0)
>  processx       2.0.0.1     2017-07-30 CRAN (R 3.4.1)
>  R6             2.2.2       2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1       2016-09-28 CRAN (R 3.4.0)
>  Rcpp           0.12.12     2017-07-15 CRAN (R 3.4.1)
>  remotes        1.1.0       2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1       2016-12-05 CRAN (R 3.4.0)
>  rlang          0.1.2.9000  2017-09-05 Github (tidyverse/rlang at fd64bce)
>  rprojroot      1.2         2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6.0.9000  2017-08-31 Github (rstudio/rstudioapi at e1e466b)
>  sessioninfo    1.0.1       2017-08-31 Github (r-lib/sessioninfo at e813de4)
>  stringi        1.1.5       2017-04-07 CRAN (R 3.4.0)
>  stringr        1.2.0       2017-02-18 CRAN (R 3.4.0)
>  usethis        0.0.0.9000  2017-08-31 Github (r-lib/usethis at 12e6f95)
>  whoami         1.1.1       2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0       2017-07-28 CRAN (R 3.4.1)
>  xml2           1.1.1       2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1       2016-06-18 CRAN (R 3.4.0)
>  yaml           2.1.14      2016-11-12 CRAN (R 3.4.0)
> 
> 
> Scott's _ sessionInfo()
> Session info ------------------------------------------------------------------
>  setting  value
>  version  R version 3.4.1 Patched (2017-07-04 r72893)
>  system   x86_64, darwin15.6.0
>  ui       X11
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
> 
> Packages ----------------------------------------------------------------------
>  package      * version    date       source
>  assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)
>  backports      1.1.0      2017-05-22 CRAN (R 3.4.0)
>  base         * 3.4.1      2017-07-06 local
>  callr          1.0.0.9000 2017-07-31 Github (r-lib/callr at ce3f15c)
>  clisymbols     1.2.0      2017-06-10 Github (gaborcsardi/clisymbols at 83b13a0)
>  compiler       3.4.1      2017-07-06 local
>  covr           3.0.0      2017-06-26 CRAN (R 3.4.0)
>  crayon         1.3.2.9000 2017-07-31 Github (gaborcsardi/crayon at 750190f)
>  cyclocomp      1.1.0      2017-05-04 Github (MangoTheCat/cyclocomp at 6156a12)
>  datasets     * 3.4.1      2017-07-06 local
>  debugme        1.0.2      2017-03-01 cran (@1.0.2)
>  desc           1.1.1      2017-08-03 CRAN (R 3.4.1)
>  devtools     * 1.13.3     2017-08-02 CRAN (R 3.4.1)
>  digest         0.6.12     2017-01-27 CRAN (R 3.4.0)
>  goodpractice   1.0.0      2017-06-10 Github (MangoTheCat/goodpractice at 9969799)
>  graphics     * 3.4.1      2017-07-06 local
>  grDevices    * 3.4.1      2017-07-06 local
>  httr           1.3.1      2017-08-20 CRAN (R 3.4.1)
>  jsonlite       1.5        2017-06-01 CRAN (R 3.4.0)
>  lazyeval       0.2.0      2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1      2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5        2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)
>  methods      * 3.4.1      2017-07-06 local
>  praise         1.0.0      2015-08-11 CRAN (R 3.4.0)
>  prettyunits    1.0.2      2015-07-13 CRAN (R 3.4.0)
>  processx       2.0.1.9000 2017-07-31 Github (r-lib/processx at c02b0f3)
>  R6             2.2.2      2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1.9000 2017-06-10 Github (r-pkgs/rcmdcheck at a18119c)
>  Rcpp           0.12.12    2017-07-15 cran (@0.12.12)
>  remotes        1.1.0      2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1      2016-03-11 CRAN (R 3.4.0)
>  rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6        2016-06-27 CRAN (R 3.4.0)
>  stats        * 3.4.1      2017-07-06 local
>  tools          3.4.1      2017-07-06 local
>  utils        * 3.4.1      2017-07-06 local
>  whoami         1.1.1      2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0      2017-09-05 Github (jimhester/withr at eff4818)
>  xml2           1.1.1      2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1      2016-06-18 cran (@1.0.1)
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov <mailto:Roy.Mendelssohn at noaa.gov> www: http://www.pfeg.noaa.gov/ <http://www.pfeg.noaa.gov/>
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 


	[[alternative HTML version deleted]]


From tuechler at gmx.at  Thu Sep  7 09:08:04 2017
From: tuechler at gmx.at (Heinz Tuechler)
Date: Thu, 7 Sep 2017 09:08:04 +0200
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
Message-ID: <0471075c-15e2-4561-6f37-541805ccbd56@gmx.at>

Are you sure that you want to read in the output_file in

text <- readLines(output_file, warn = FALSE)?

best regards,

Heinz

Thierry Onkelinx wrote/hat geschrieben on/am 06.09.2017 11:41:
> Dear all,
>
> I'm trying to write a post_processor() for a custom rmarkdown format. The
> goal of the post_processor() is to modify the latex file before it is
> compiled. For some reason the post_processor() is not run. The
> post_processor() does work when I run it manually on the tex file.
>
> Any suggestions on what I'm doing wrong? Below is the relevant snippet of
> the code. The full code is available at
> https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
> https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
> is an Rmd is a MWE that fails compile because the post_processor() is not
> run.
>
> Best regards,
>
> Thierry
>
>   post_processor <- function(
>     metadata, input_file, output_file, clean, verbose
>   ) {
>     text <- readLines(output_file, warn = FALSE)
>
>     # set correct text in fmtext environment
>     end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>     if (length(end_first_page) == 1) {
>       maketitle <- grep("\\\\maketitle", text) #nolint
>       text <- c(
>         text[1:(maketitle - 1)],
>         "\\begin{fmtext}",
>         text[(maketitle + 1):(end_first_page - 1)],
>         "\\end{fmtext}",
>         "\\maketitle",
>         text[(end_first_page + 1):length(text)]
>       )
>       writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>     }
>     output_file
>   }
>
>   output_format(
>     knitr = knitr_options(
>       opts_knit = list(
>         width = 60,
>         concordance = TRUE
>       ),
>       opts_chunk = opts_chunk,
>       knit_hooks = knit_hooks
>     ),
>     pandoc = pandoc_options(
>       to = "latex",
>       latex_engine = "xelatex",
>       args = args,
>       keep_tex = keep_tex
>     ),
>     post_processor = post_processor,
>     clean_supporting = !keep_tex
>   )
>
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Heinz T?chler +436605653878


From thierry.onkelinx at inbo.be  Thu Sep  7 09:12:15 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 7 Sep 2017 09:12:15 +0200
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <0471075c-15e2-4561-6f37-541805ccbd56@gmx.at>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <0471075c-15e2-4561-6f37-541805ccbd56@gmx.at>
Message-ID: <CAJuCY5wjOEEVcrShAHDrxcrVcrVnOVGs+5brSVvsiONyU+C1eA@mail.gmail.com>

Dear Heinz,

Yes. The idea of the post_processor() is that 1) pandoc converts the .md to
.tex 2) the post_processors changes the .tex 3) the .tex is compiled into
.pdf Hence the post_processors need to read, change and overwrite the tex
output file.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-09-07 9:08 GMT+02:00 Heinz Tuechler <tuechler at gmx.at>:

> Are you sure that you want to read in the output_file in
>
> text <- readLines(output_file, warn = FALSE)?
>
> best regards,
>
> Heinz
>
>
> Thierry Onkelinx wrote/hat geschrieben on/am 06.09.2017 11:41:
>
>> Dear all,
>>
>> I'm trying to write a post_processor() for a custom rmarkdown format. The
>> goal of the post_processor() is to modify the latex file before it is
>> compiled. For some reason the post_processor() is not run. The
>> post_processor() does work when I run it manually on the tex file.
>>
>> Any suggestions on what I'm doing wrong? Below is the relevant snippet of
>> the code. The full code is available at
>> https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
>> https://github.com/inbo/INBOmd/blob/post_processor/inst/
>> rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>> is an Rmd is a MWE that fails compile because the post_processor() is not
>> run.
>>
>> Best regards,
>>
>> Thierry
>>
>>   post_processor <- function(
>>     metadata, input_file, output_file, clean, verbose
>>   ) {
>>     text <- readLines(output_file, warn = FALSE)
>>
>>     # set correct text in fmtext environment
>>     end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>>     if (length(end_first_page) == 1) {
>>       maketitle <- grep("\\\\maketitle", text) #nolint
>>       text <- c(
>>         text[1:(maketitle - 1)],
>>         "\\begin{fmtext}",
>>         text[(maketitle + 1):(end_first_page - 1)],
>>         "\\end{fmtext}",
>>         "\\maketitle",
>>         text[(end_first_page + 1):length(text)]
>>       )
>>       writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>>     }
>>     output_file
>>   }
>>
>>   output_format(
>>     knitr = knitr_options(
>>       opts_knit = list(
>>         width = 60,
>>         concordance = TRUE
>>       ),
>>       opts_chunk = opts_chunk,
>>       knit_hooks = knit_hooks
>>     ),
>>     pandoc = pandoc_options(
>>       to = "latex",
>>       latex_engine = "xelatex",
>>       args = args,
>>       keep_tex = keep_tex
>>     ),
>>     post_processor = post_processor,
>>     clean_supporting = !keep_tex
>>   )
>>
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Heinz T?chler +436605653878
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep  7 12:14:22 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 7 Sep 2017 06:14:22 -0400
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
Message-ID: <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>

On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
> Dear all,
> 
> I'm trying to write a post_processor() for a custom rmarkdown format. The
> goal of the post_processor() is to modify the latex file before it is
> compiled. For some reason the post_processor() is not run. The
> post_processor() does work when I run it manually on the tex file.
> 
> Any suggestions on what I'm doing wrong? Below is the relevant snippet of
> the code. The full code is available at
> https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
> https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
> is an Rmd is a MWE that fails compile because the post_processor() is not
> run.
> 

I installed it and tried running it using

debug(INBOmd::rsos_article)
rmarkdown::render("skeleton.Rmd")

then after post_processor was defined, I set it to debug as well, and 
could see that the post_processor was being run.

I didn't get useful output, because the LaTeXing failed (I don't have 
the rsos.cls), but perhaps you've already fixed this problem, or perhaps 
it is intermittent?

Duncan Murdoch

> Best regards,
> 
> Thierry
> 
>    post_processor <- function(
>      metadata, input_file, output_file, clean, verbose
>    ) {
>      text <- readLines(output_file, warn = FALSE)
> 
>      # set correct text in fmtext environment
>      end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>      if (length(end_first_page) == 1) {
>        maketitle <- grep("\\\\maketitle", text) #nolint
>        text <- c(
>          text[1:(maketitle - 1)],
>          "\\begin{fmtext}",
>          text[(maketitle + 1):(end_first_page - 1)],
>          "\\end{fmtext}",
>          "\\maketitle",
>          text[(end_first_page + 1):length(text)]
>        )
>        writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>      }
>      output_file
>    }
> 
>    output_format(
>      knitr = knitr_options(
>        opts_knit = list(
>          width = 60,
>          concordance = TRUE
>        ),
>        opts_chunk = opts_chunk,
>        knit_hooks = knit_hooks
>      ),
>      pandoc = pandoc_options(
>        to = "latex",
>        latex_engine = "xelatex",
>        args = args,
>        keep_tex = keep_tex
>      ),
>      post_processor = post_processor,
>      clean_supporting = !keep_tex
>    )
> 
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rainer_krug at icloud.com  Thu Sep  7 11:40:58 2017
From: rainer_krug at icloud.com (Rainer Krug)
Date: Thu, 7 Sep 2017 11:40:58 +0200
Subject: [R] Interesting behavior of lm() with small,
 problematic data sets
In-Reply-To: <c26a3987-9fc5-db90-181f-2b86cee78b08@accucom.net>
References: <BLUPR0401MB1729E3835080475556BD25A0F5960@BLUPR0401MB1729.namprd04.prod.outlook.com>
 <OF553F6200.82F1AF5A-ON85258192.005A75F1-85258192.005AC01D@srs.gov>
 <1A8C1289955EF649A09086A153E267240BD80E96B1@GBTEDVPEXCMB04.corp.lgc-group.com>
 <c26a3987-9fc5-db90-181f-2b86cee78b08@accucom.net>
Message-ID: <8119EFC2-A75F-45E1-8135-4FC65B1194A0@icloud.com>

Same version on Mac, same results.


> On 6 Sep 2017, at 15:22, JRG <loesljrg at accucom.net> wrote:
> 
> Indeed (version-specific).
> 
> With R 3.4.1 on linux, I get coefficients and residuals that are
> numerically exact, F-statistic = NaN, p-value = NA, R-squared = NaN, etc.
> 
> All of which is what ought to happen, given that the response variable
> (y) is not actually variable.
> 
> 
> ---JRG
> John R. Gleason
> 
> 
> On 09/06/2017 09:10 AM, S Ellison wrote:
>>> I think what you're seeing is
>>> https://en.wikipedia.org/wiki/Loss_of_significance.
>> 
>> Almost. 
>> All the results in the OP's summary are reflections of finite precision in the analytically exact solution, leading to residuals smaller than the double precision limit. The summary is correctly warning that it's all potentially nonsense, and indeed the only things you can trust are the coefficient values (to within .Machine$double.eps or thereabouts)
>> 
>> Interestingly, though, my current version of R (3.4.0) gives numerically exact coefficients (c(1,0) and identically zero standard errors.
>> 
>> So this particular example is apparently version-specific.
>> 
>> S Ellison
>> 
>> 
>> *******************************************************************
>> This email and any attachments are confidential. Any use...{{dropped:8}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From raphael.felber at agroscope.admin.ch  Thu Sep  7 14:49:46 2017
From: raphael.felber at agroscope.admin.ch (raphael.felber at agroscope.admin.ch)
Date: Thu, 7 Sep 2017 12:49:46 +0000
Subject: [R] extend limited dimension in netcdf
Message-ID: <B8036F3D74CF6643B5ABE2B1D9CD3FC014509500@sb00106a.adb.intra.admin.ch>

Dear all

I have to combine 3D netCDF files (lon, lat, time). The files contain data of one month and I need a year file containing all the data. Because the attributes of all files are the same, I copied the first file and appended the data of the other months. This went well until the provider of the data changed the time-dimension from UNLIMITED to LIMITED. Is there a way to change the time dimension to UNLIMITED?

I tried

ncnew$dim[[3]]$unlim <- TRUE

but this has no effect.

Thanks for any help.

Kind regards

Raphi

------------------------------------------------------------------------------------
Raphael Felber, Dr. sc.
Wissenschaftlicher Mitarbeiter, Klima und Lufthygiene

Eidgen?ssisches Departement f?r
Wirtschaft, Bildung und Forschung WBF
Agroscope
Forschungsbereich Agrar?kologie und Umwelt

Reckenholzstrasse 191, 8046 Z?rich
Tel. 058 468 75 11
Fax 058 468 72 01
raphael.felber at agroscope.admin.ch<mailto:raphael.felber at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Sep  7 16:11:59 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 7 Sep 2017 16:11:59 +0200
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
Message-ID: <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>

Dear Duncan,

Thanks for chiming in. Could you explain how you set debug() on
post_processor()? I've tried adding debug(post_processor) to rsos_article()
or adding debug(post_processor) when after post_processor was defined in
the debugger. Neither work for me.

All supporting files are available within the package. The code below
should be reproducible on your machine.

remove.packages("INBOmd")
devtools::install_github("inbo/INBOmd at post_processor")
setwd(system.file("rmarkdown/templates/rsos_article/skeleton", package =
"INBOmd"))
debug(INBOmd::rsos_article)
rmarkdown::render("skeleton.Rmd")

The sign that post_processor() fails when the tex file still contains
\EndFirstPage resulting in the compilation error "Undefined control
sequence. l.128 \EndFirstPage"

I still get the error with the current version of the code. Running the
post_processor manually works.

eval(parse(
  text = readLines(
    "
https://raw.githubusercontent.com/inbo/INBOmd/post_processor/R/rsos_article.R
"
  )[72:92]
))
post_processor(output_file = "skeleton.tex")
system("pdflatex skeleton.tex")

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-09-07 12:14 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
>
>> Dear all,
>>
>> I'm trying to write a post_processor() for a custom rmarkdown format. The
>> goal of the post_processor() is to modify the latex file before it is
>> compiled. For some reason the post_processor() is not run. The
>> post_processor() does work when I run it manually on the tex file.
>>
>> Any suggestions on what I'm doing wrong? Below is the relevant snippet of
>> the code. The full code is available at
>> https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
>> https://github.com/inbo/INBOmd/blob/post_processor/inst/
>> rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>> is an Rmd is a MWE that fails compile because the post_processor() is not
>> run.
>>
>>
> I installed it and tried running it using
>
> debug(INBOmd::rsos_article)
> rmarkdown::render("skeleton.Rmd")
>
> then after post_processor was defined, I set it to debug as well, and
> could see that the post_processor was being run.
>
> I didn't get useful output, because the LaTeXing failed (I don't have the
> rsos.cls), but perhaps you've already fixed this problem, or perhaps it is
> intermittent?
>
> Duncan Murdoch
>
> Best regards,
>>
>> Thierry
>>
>>    post_processor <- function(
>>      metadata, input_file, output_file, clean, verbose
>>    ) {
>>      text <- readLines(output_file, warn = FALSE)
>>
>>      # set correct text in fmtext environment
>>      end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>>      if (length(end_first_page) == 1) {
>>        maketitle <- grep("\\\\maketitle", text) #nolint
>>        text <- c(
>>          text[1:(maketitle - 1)],
>>          "\\begin{fmtext}",
>>          text[(maketitle + 1):(end_first_page - 1)],
>>          "\\end{fmtext}",
>>          "\\maketitle",
>>          text[(end_first_page + 1):length(text)]
>>        )
>>        writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>>      }
>>      output_file
>>    }
>>
>>    output_format(
>>      knitr = knitr_options(
>>        opts_knit = list(
>>          width = 60,
>>          concordance = TRUE
>>        ),
>>        opts_chunk = opts_chunk,
>>        knit_hooks = knit_hooks
>>      ),
>>      pandoc = pandoc_options(
>>        to = "latex",
>>        latex_engine = "xelatex",
>>        args = args,
>>        keep_tex = keep_tex
>>      ),
>>      post_processor = post_processor,
>>      clean_supporting = !keep_tex
>>    )
>>
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From dpierce at ucsd.edu  Thu Sep  7 17:33:40 2017
From: dpierce at ucsd.edu (David W. Pierce)
Date: Thu, 7 Sep 2017 08:33:40 -0700
Subject: [R] extend limited dimension in netcdf
In-Reply-To: <B8036F3D74CF6643B5ABE2B1D9CD3FC014509500@sb00106a.adb.intra.admin.ch>
References: <B8036F3D74CF6643B5ABE2B1D9CD3FC014509500@sb00106a.adb.intra.admin.ch>
Message-ID: <CAL+Zad_zxyyC+WT_gyGUaJe38LaRrkjOXDuwJiFTWYy8uhB=8Q@mail.gmail.com>

On Thu, Sep 7, 2017 at 5:49 AM, <raphael.felber at agroscope.admin.ch> wrote:

> Dear all
>
> I have to combine 3D netCDF files (lon, lat, time). The files contain data
> of one month and I need a year file containing all the data. Because the
> attributes of all files are the same, I copied the first file and appended
> the data of the other months. This went well until the provider of the data
> changed the time-dimension from UNLIMITED to LIMITED. Is there a way to
> change the time dimension to UNLIMITED?
>

?Hi Raphi,

I suggest using the netcdf operators (nco) for this function (?
http://nco.sourceforge.net/). The relevant command would involve "ncks
--mk_rec_dmn", which converts a fixed dimension to an unlimited one.

?If you have no option but to do it with the netcdf package in R, the
approach would be to remake the original file in a completely new file, one
that is the same as the original file except that the time dimension is
defined to be unlimited.

Personally I would also drop a polite email to the data provider asking
them to go back to unlimited time dimensions. Perhaps they had some good
reason for the change, but it's at least as likely that it was simply a
mistake.?

?Regards,

--Dave?

-- 
David W. Pierce
Division of Climate, Atmospheric Science, and Physical Oceanography
Scripps Institution of Oceanography, La Jolla, California, USA
(858) 534-8276 (voice)  /  (858) 534-8561 (fax)    dpierce at ucsd.edu

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep  7 19:32:12 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 7 Sep 2017 13:32:12 -0400
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
 <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
Message-ID: <76f3e34d-9942-2714-15ed-6861060fee82@gmail.com>

On 07/09/2017 10:11 AM, Thierry Onkelinx wrote:
> remove.packages("INBOmd")
> devtools::install_github("inbo/INBOmd at post_processor")
> setwd(system.file("rmarkdown/templates/rsos_article/skeleton", package = 
> "INBOmd"))
> debug(INBOmd::rsos_article)
> rmarkdown::render("skeleton.Rmd")


From murdoch.duncan at gmail.com  Thu Sep  7 20:04:25 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 7 Sep 2017 14:04:25 -0400
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
 <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
Message-ID: <40ee4068-352d-fc99-187b-27090bb72a0a@gmail.com>

On 07/09/2017 10:11 AM, Thierry Onkelinx wrote:
> Dear Duncan,
> 
> Thanks for chiming in. Could you explain how you set debug() on 
> post_processor()? I've tried adding debug(post_processor) to 
> rsos_article() or adding debug(post_processor) when after post_processor 
> was defined in the debugger. Neither work for me.

Not working for me either right now for some reason or other.  What I 
was doing was manually running debug(post_processor) in the debugger 
after single stepping past its definition.

What does show it is running is that at that same point I can execute

post_processor <- function() stop()

and it stops.

The end of the console log looks like this:


/Applications/RStudio.app/Contents/MacOS/pandoc/pandoc +RTS -K512m -RTS 
skeleton.utf8.md --to latex --from 
markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash 
--output skeleton.tex --template 
/Library/Frameworks/R.framework/Versions/3.3/Resources/library/INBOmd/rmarkdown/templates/rsos_article/resources/template.tex 
--natbib --bibliography sample.bib
Latexmk: This is Latexmk, John Collins, 19 Jan. 2017, version: 4.52c.
Error in output_format$post_processor(yaml_front_matter, utf8_input, 
output_file,  :
   unused arguments (yaml_front_matter, utf8_input, output_file, clean, 
!quiet)
Called from: output_format$post_processor(yaml_front_matter, utf8_input, 
output_file,
     clean, !quiet)

so we see pandoc being run, then Latexmk, then the post_processor call. 
It seems a little odd that Latexmk is being run.  Is that something you 
are doing, or is it pandoc asking for that?  If the latter, can you tell 
pandoc not to do so?



> 
> All supporting files are available within the package. The code below 
> should be reproducible on your machine.
> 
> remove.packages("INBOmd")
> devtools::install_github("inbo/INBOmd at post_processor")
> setwd(system.file("rmarkdown/templates/rsos_article/skeleton", package = 
> "INBOmd"))
> debug(INBOmd::rsos_article)
> rmarkdown::render("skeleton.Rmd")

I'm not sure you would normally have write access in that directory, so 
it may not be typical of what you'd see in a user directory.  I 
certainly see something different when I copy the skeleton.Rmd file (and 
nothing else) to my own temp directory.


> 
> The sign that post_processor() fails when the tex file still contains 
> \EndFirstPage resulting in the compilation error "Undefined control 
> sequence. l.128 \EndFirstPage"

That certainly indicates it isn't doing what you want, but it might be 
running and doing something else.

Duncan Murdoch

> 
> I still get the error with the current version of the code. Running the 
> post_processor manually works.
> 
> eval(parse(
>  ? text = readLines(
>      
> "https://raw.githubusercontent.com/inbo/INBOmd/post_processor/R/rsos_article.R"
>  ? )[72:92]
> ))
> post_processor(output_file = "skeleton.tex")
> system("pdflatex skeleton.tex")
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more 
> than asking him to perform a post-mortem examination: he may be able to 
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not 
> ensure that a reasonable answer can be extracted from a given body of 
> data. ~ John Tukey
> 
> 2017-09-07 12:14 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
> 
>         Dear all,
> 
>         I'm trying to write a post_processor() for a custom rmarkdown
>         format. The
>         goal of the post_processor() is to modify the latex file before
>         it is
>         compiled. For some reason the post_processor() is not run. The
>         post_processor() does work when I run it manually on the tex file.
> 
>         Any suggestions on what I'm doing wrong? Below is the relevant
>         snippet of
>         the code. The full code is available at
>         https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
>         <https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R>
>         https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>         <https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd>
>         is an Rmd is a MWE that fails compile because the
>         post_processor() is not
>         run.
> 
> 
>     I installed it and tried running it using
> 
>     debug(INBOmd::rsos_article)
>     rmarkdown::render("skeleton.Rmd")
> 
>     then after post_processor was defined, I set it to debug as well,
>     and could see that the post_processor was being run.
> 
>     I didn't get useful output, because the LaTeXing failed (I don't
>     have the rsos.cls), but perhaps you've already fixed this problem,
>     or perhaps it is intermittent?
> 
>     Duncan Murdoch
> 
>         Best regards,
> 
>         Thierry
> 
>          ? ?post_processor <- function(
>          ? ? ?metadata, input_file, output_file, clean, verbose
>          ? ?) {
>          ? ? ?text <- readLines(output_file, warn = FALSE)
> 
>          ? ? ?# set correct text in fmtext environment
>          ? ? ?end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>          ? ? ?if (length(end_first_page) == 1) {
>          ? ? ? ?maketitle <- grep("\\\\maketitle", text) #nolint
>          ? ? ? ?text <- c(
>          ? ? ? ? ?text[1:(maketitle - 1)],
>          ? ? ? ? ?"\\begin{fmtext}",
>          ? ? ? ? ?text[(maketitle + 1):(end_first_page - 1)],
>          ? ? ? ? ?"\\end{fmtext}",
>          ? ? ? ? ?"\\maketitle",
>          ? ? ? ? ?text[(end_first_page + 1):length(text)]
>          ? ? ? ?)
>          ? ? ? ?writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>          ? ? ?}
>          ? ? ?output_file
>          ? ?}
> 
>          ? ?output_format(
>          ? ? ?knitr = knitr_options(
>          ? ? ? ?opts_knit = list(
>          ? ? ? ? ?width = 60,
>          ? ? ? ? ?concordance = TRUE
>          ? ? ? ?),
>          ? ? ? ?opts_chunk = opts_chunk,
>          ? ? ? ?knit_hooks = knit_hooks
>          ? ? ?),
>          ? ? ?pandoc = pandoc_options(
>          ? ? ? ?to = "latex",
>          ? ? ? ?latex_engine = "xelatex",
>          ? ? ? ?args = args,
>          ? ? ? ?keep_tex = keep_tex
>          ? ? ?),
>          ? ? ?post_processor = post_processor,
>          ? ? ?clean_supporting = !keep_tex
>          ? ?)
> 
> 
> 
>         ir. Thierry Onkelinx
>         Instituut voor natuur- en bosonderzoek / Research Institute for
>         Nature and
>         Forest
>         team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>         Assurance
>         Kliniekstraat 25
>         1070 Anderlecht
>         Belgium
> 
>         To call in the statistician after the experiment is done may be
>         no more
>         than asking him to perform a post-mortem examination: he may be
>         able to say
>         what the experiment died of. ~ Sir Ronald Aylmer Fisher
>         The plural of anecdote is not data. ~ Roger Brinner
>         The combination of some data and an aching desire for an answer
>         does not
>         ensure that a reasonable answer can be extracted from a given
>         body of data.
>         ~ John Tukey
> 
>          ? ? ? ? [[alternative HTML version deleted]]
> 
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From dwinsemius at comcast.net  Thu Sep  7 20:13:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Sep 2017 11:13:48 -0700
Subject: [R] Geom_smooth
In-Reply-To: <CAAkwYerAUSef5sifFSL=SPhcd+PM_45RvooAa80Hcvs3D0xhMw@mail.gmail.com>
References: <CAAkwYerAUSef5sifFSL=SPhcd+PM_45RvooAa80Hcvs3D0xhMw@mail.gmail.com>
Message-ID: <CE7A1B13-C78C-474E-960F-25369E822851@comcast.net>


> On Jul 20, 2016, at 10:01 AM, Tom Subia <tgs77m at gmail.com> wrote:
> 
> Default level = 0.95.
> Does this mean +/- 0.025 from estimate?
> 
> 	[[alternative HTML version deleted]]


I would have guessed that it meant something along the lines of localized (or one might say "loess-ized") mean +/- 2* similarly localized standard error of the estimate. To find out what the base R version of loess does consult `?predict.loess` and to find out what `geom_smooth` does, you can try to find documentation on the `predictdf` fucntion, but the geom_smooth help pages warns you it is undocumented.

-- 
David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From milujisb at gmail.com  Thu Sep  7 20:36:05 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 7 Sep 2017 20:36:05 +0200
Subject: [R] ISO3 code to 7 continents names
Message-ID: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>

Dear all.

Is it possible to convert.identify iso3 country names to the seven
continent names?

# Asia, Africa, Antarctica, Australia, Europe, South America, and North
America,

I have tried the following:

###
region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')

where df is the name of my dataset with iso3 the identification variable
but there seems to be a a lot of missing values.

Thank you!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Thu Sep  7 20:50:32 2017
From: davidsmi at microsoft.com (David Smith)
Date: Thu, 7 Sep 2017 18:50:32 +0000
Subject: [R] Revolutions blog: August 2017 roundup
Message-ID: <BN6PR21MB0497FEBB3960A472D8A50DF5C8940@BN6PR21MB0497.namprd21.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests
have written about R every weekday at the Revolutions blog
(http://blog.revolutionanalytics.com) and every month I post a summary
of articles from the previous month of particular interest to readers
of r-help.

In case you missed them, here are some articles related to R from the
month of August:

Using the featurizeText function in the MicrosoftML package to extract
ngrams from unstructured text:
http://blog.revolutionanalytics.com/2017/08/text-featurization-microsoftml.html

A joyplot visualizes the probabilities associated with prases like
"highly likely" and "little chance" by a sample of 46 Redditors:
http://blog.revolutionanalytics.com/2017/08/probably-more-probably-than-probable.html

Two examples of creating 3-D animations in R: a stereo cube, and the
Charleston in motion capture data:
http://blog.revolutionanalytics.com/2017/08/3-d-animations-with-r.html

A tutorial on creating thematic maps in R, from ComputerWorld:
http://blog.revolutionanalytics.com/2017/08/maps-in-r.html

Some tips on using R to query data in Power BI:
http://blog.revolutionanalytics.com/2017/08/query-editor-tips.html

Using the Rcpp package to calculate a membership matrix for fuzzy
k-means clustering:
http://blog.revolutionanalytics.com/2017/08/kmeans-r-rcpp.html

A reimagining of Minard's chart of Napoleon's march on Russia:
http://blog.revolutionanalytics.com/2017/08/recreating-minard.html

Rankings of gender roles for men and women in film, from an analysis
of scripts using the tidytext package:
http://blog.revolutionanalytics.com/2017/08/gender-roles-in-film-direction.html

Several talks at the upcoming Ignite conference feature R:
http://blog.revolutionanalytics.com/2017/08/data-track-ignite.html

Norm Matloff's keynote at UseR!2017 discussed various obstacles to
performance in parallel programming:
http://blog.revolutionanalytics.com/2017/08/obstacles-to-performance-in-parallel-programming.html

Peter Dalgaard marks the 20th anniversary of the formation of the R
Core Group:
http://blog.revolutionanalytics.com/2017/08/20-years-of-the-r-core-group.html

Using the rxFeaturize function in the MicrosoftML package to find
images similar to a reference image:
http://blog.revolutionanalytics.com/2017/08/image-featurizer.html

Buzzfeed used R to identify possible spy planes in Flightradar24 data:
http://blog.revolutionanalytics.com/2017/08/buzzfeed-plane-tracking.html

Timo Grossenbacher offers a helpful workflow for implementing
reproducible data analysis in R:
http://blog.revolutionanalytics.com/2017/08/reproducibility-a-cautionary-tale.html

A preview of version 0.10.0 of the dplyrXdf package, featuring support
for the tidyeval framework on out-of-memory Xdf data files:
http://blog.revolutionanalytics.com/2017/08/dplyrxdf-0100-beta-prerelease.html

A tutorial on using CNTK via the keras package for forecasting:
http://blog.revolutionanalytics.com/2017/08/keras-and-cntk.html

Neils Berglund explains how to use the sqlrutils package to publish an
R function as a SQL Server stored procedure:
http://blog.revolutionanalytics.com/2017/08/tutorial-sqlrutils.html

Tomas Kalibera's presentation at UseR!2017 includes useful guidance on
getting the most out of R's byte compiler:
http://blog.revolutionanalytics.com/2017/08/take-advantage-compiler.html

The kadinsky package makes accidental aRt, deliberately:
http://blog.revolutionanalytics.com/2017/08/kandinsky.html

Angus Taylor's UseR!2017 presentation uses MXNET to categorize product
reviews on Amazon:
http://blog.revolutionanalytics.com/2017/08/text-categorization-deep-learning.html

Various solutions (with data and Microsoft R code) from the energy,
retail and shipping industries:
http://blog.revolutionanalytics.com/2017/08/gallery-solutions.html

Talks on new database interfaces from UseR!2017: Jim Hester on the
ODBC package, and Kirill M?ller on the DBI package:
http://blog.revolutionanalytics.com/2017/08/a-modern-database-interface-for-r.html

And some general interest stories (not necessarily related to R):

* Pictures and video from the recent total solar eclipse in the US:
  http://blog.revolutionanalytics.com/2017/08/because-its-friday-eclipse.html  

* A generic blockbuster movie trailer:
  http://blog.revolutionanalytics.com/2017/08/because-its-friday-movie-trailer.html

* The Shepard tone, an auditory illusion used in several movies:
  http://blog.revolutionanalytics.com/2017/08/because-its-friday-the-shepard-tone.html

* People Are Awesome, 2016-2107:
  http://blog.revolutionanalytics.com/2017/08/because-its-friday-people-remain-awesome.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft AI & Research? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From dwinsemius at comcast.net  Thu Sep  7 21:00:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Sep 2017 12:00:33 -0700
Subject: [R] ISO3 code to 7 continents names
In-Reply-To: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
References: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
Message-ID: <BFCA895C-C6F3-4B52-BE64-5C2E9ED4AE1F@comcast.net>


> On Sep 7, 2017, at 11:36 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear all.
> 
> Is it possible to convert.identify iso3 country names to the seven
> continent names?
> 
> # Asia, Africa, Antarctica, Australia, Europe, South America, and North
> America,
> 
> I have tried the following:
> 
> ###
> region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
> 
> where df is the name of my dataset with iso3 the identification variable
> but there seems to be a a lot of missing values.

Please provide a sufficient amount of the dataframe named `df` to allow a properly tested response.

> 
> 	[[alternative HTML version deleted]]

And do read the Posting Guide. This is a plain text mailing list.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From murdoch.duncan at gmail.com  Thu Sep  7 21:18:15 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 7 Sep 2017 15:18:15 -0400
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <40ee4068-352d-fc99-187b-27090bb72a0a@gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
 <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
 <40ee4068-352d-fc99-187b-27090bb72a0a@gmail.com>
Message-ID: <5670ad71-38c5-4dac-db4c-e1b7a451cb59@gmail.com>

On 07/09/2017 2:04 PM, Duncan Murdoch wrote:
> On 07/09/2017 10:11 AM, Thierry Onkelinx wrote:
>> Dear Duncan,
>>
>> Thanks for chiming in. Could you explain how you set debug() on
>> post_processor()? I've tried adding debug(post_processor) to
>> rsos_article() or adding debug(post_processor) when after post_processor
>> was defined in the debugger. Neither work for me.
> 
> Not working for me either right now for some reason or other.  What I
> was doing was manually running debug(post_processor) in the debugger
> after single stepping past its definition.
> 
> What does show it is running is that at that same point I can execute
> 
> post_processor <- function() stop()
> 
> and it stops.
> 
> The end of the console log looks like this:
> 
> 
> /Applications/RStudio.app/Contents/MacOS/pandoc/pandoc +RTS -K512m -RTS
> skeleton.utf8.md --to latex --from
> markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
> --output skeleton.tex --template
> /Library/Frameworks/R.framework/Versions/3.3/Resources/library/INBOmd/rmarkdown/templates/rsos_article/resources/template.tex
> --natbib --bibliography sample.bib
> Latexmk: This is Latexmk, John Collins, 19 Jan. 2017, version: 4.52c.
> Error in output_format$post_processor(yaml_front_matter, utf8_input,
> output_file,  :
>     unused arguments (yaml_front_matter, utf8_input, output_file, clean,
> !quiet)
> Called from: output_format$post_processor(yaml_front_matter, utf8_input,
> output_file,
>       clean, !quiet)
> 
> so we see pandoc being run, then Latexmk, then the post_processor call.
> It seems a little odd that Latexmk is being run.  Is that something you
> are doing, or is it pandoc asking for that?  If the latter, can you tell
> pandoc not to do so?
> 

I've done some debugging in rmarkdown::render.  Apparently if you need 
Bibtex (as your example does), it runs Latexmk before the post-processor.

I don't know if there's a way around this...

Duncan Murdoch

> 
> 
>>
>> All supporting files are available within the package. The code below
>> should be reproducible on your machine.
>>
>> remove.packages("INBOmd")
>> devtools::install_github("inbo/INBOmd at post_processor")
>> setwd(system.file("rmarkdown/templates/rsos_article/skeleton", package =
>> "INBOmd"))
>> debug(INBOmd::rsos_article)
>> rmarkdown::render("skeleton.Rmd")
> 
> I'm not sure you would normally have write access in that directory, so
> it may not be typical of what you'd see in a user directory.  I
> certainly see something different when I copy the skeleton.Rmd file (and
> nothing else) to my own temp directory.
> 
> 
>>
>> The sign that post_processor() fails when the tex file still contains
>> \EndFirstPage resulting in the compilation error "Undefined control
>> sequence. l.128 \EndFirstPage"
> 
> That certainly indicates it isn't doing what you want, but it might be
> running and doing something else.
> 
> Duncan Murdoch
> 
>>
>> I still get the error with the current version of the code. Running the
>> post_processor manually works.
>>
>> eval(parse(
>>   ? text = readLines(
>>       
>> "https://raw.githubusercontent.com/inbo/INBOmd/post_processor/R/rsos_article.R"
>>   ? )[72:92]
>> ))
>> post_processor(output_file = "skeleton.tex")
>> system("pdflatex skeleton.tex")
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data. ~ John Tukey
>>
>> 2017-09-07 12:14 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>>:
>>
>>      On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
>>
>>          Dear all,
>>
>>          I'm trying to write a post_processor() for a custom rmarkdown
>>          format. The
>>          goal of the post_processor() is to modify the latex file before
>>          it is
>>          compiled. For some reason the post_processor() is not run. The
>>          post_processor() does work when I run it manually on the tex file.
>>
>>          Any suggestions on what I'm doing wrong? Below is the relevant
>>          snippet of
>>          the code. The full code is available at
>>          https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
>>          <https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R>
>>          https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>>          <https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd>
>>          is an Rmd is a MWE that fails compile because the
>>          post_processor() is not
>>          run.
>>
>>
>>      I installed it and tried running it using
>>
>>      debug(INBOmd::rsos_article)
>>      rmarkdown::render("skeleton.Rmd")
>>
>>      then after post_processor was defined, I set it to debug as well,
>>      and could see that the post_processor was being run.
>>
>>      I didn't get useful output, because the LaTeXing failed (I don't
>>      have the rsos.cls), but perhaps you've already fixed this problem,
>>      or perhaps it is intermittent?
>>
>>      Duncan Murdoch
>>
>>          Best regards,
>>
>>          Thierry
>>
>>           ? ?post_processor <- function(
>>           ? ? ?metadata, input_file, output_file, clean, verbose
>>           ? ?) {
>>           ? ? ?text <- readLines(output_file, warn = FALSE)
>>
>>           ? ? ?# set correct text in fmtext environment
>>           ? ? ?end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>>           ? ? ?if (length(end_first_page) == 1) {
>>           ? ? ? ?maketitle <- grep("\\\\maketitle", text) #nolint
>>           ? ? ? ?text <- c(
>>           ? ? ? ? ?text[1:(maketitle - 1)],
>>           ? ? ? ? ?"\\begin{fmtext}",
>>           ? ? ? ? ?text[(maketitle + 1):(end_first_page - 1)],
>>           ? ? ? ? ?"\\end{fmtext}",
>>           ? ? ? ? ?"\\maketitle",
>>           ? ? ? ? ?text[(end_first_page + 1):length(text)]
>>           ? ? ? ?)
>>           ? ? ? ?writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>>           ? ? ?}
>>           ? ? ?output_file
>>           ? ?}
>>
>>           ? ?output_format(
>>           ? ? ?knitr = knitr_options(
>>           ? ? ? ?opts_knit = list(
>>           ? ? ? ? ?width = 60,
>>           ? ? ? ? ?concordance = TRUE
>>           ? ? ? ?),
>>           ? ? ? ?opts_chunk = opts_chunk,
>>           ? ? ? ?knit_hooks = knit_hooks
>>           ? ? ?),
>>           ? ? ?pandoc = pandoc_options(
>>           ? ? ? ?to = "latex",
>>           ? ? ? ?latex_engine = "xelatex",
>>           ? ? ? ?args = args,
>>           ? ? ? ?keep_tex = keep_tex
>>           ? ? ?),
>>           ? ? ?post_processor = post_processor,
>>           ? ? ?clean_supporting = !keep_tex
>>           ? ?)
>>
>>
>>
>>          ir. Thierry Onkelinx
>>          Instituut voor natuur- en bosonderzoek / Research Institute for
>>          Nature and
>>          Forest
>>          team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>          Assurance
>>          Kliniekstraat 25
>>          1070 Anderlecht
>>          Belgium
>>
>>          To call in the statistician after the experiment is done may be
>>          no more
>>          than asking him to perform a post-mortem examination: he may be
>>          able to say
>>          what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>          The plural of anecdote is not data. ~ Roger Brinner
>>          The combination of some data and an aching desire for an answer
>>          does not
>>          ensure that a reasonable answer can be extracted from a given
>>          body of data.
>>          ~ John Tukey
>>
>>           ? ? ? ? [[alternative HTML version deleted]]
>>
>>          ______________________________________________
>>          R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>          -- To UNSUBSCRIBE and more, see
>>          https://stat.ethz.ch/mailman/listinfo/r-help
>>          <https://stat.ethz.ch/mailman/listinfo/r-help>
>>          PLEASE do read the posting guide
>>          http://www.R-project.org/posting-guide.html
>>          <http://www.R-project.org/posting-guide.html>
>>          and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>


From milujisb at gmail.com  Thu Sep  7 21:21:02 2017
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 7 Sep 2017 21:21:02 +0200
Subject: [R] ISO3 code to 7 continents names
In-Reply-To: <BFCA895C-C6F3-4B52-BE64-5C2E9ED4AE1F@comcast.net>
References: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
 <BFCA895C-C6F3-4B52-BE64-5C2E9ED4AE1F@comcast.net>
Message-ID: <CAMLwc7Owm50np8LMtiRRfgeQUbwFVu5+Q7xqUPn1O1N+pTQpdg@mail.gmail.com>

df is a data frame consisting of one variable (iso3 codes) such as

USA
RUS
ARG
BGD
ITA
FRA


Some of these iso3 codes are repeated and I would like the corresponding
continent name, the countrycode package does not seem to distinguish
between North and South America. Thanks.

Sincerely,

Milu

On Thu, Sep 7, 2017 at 9:00 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 7, 2017, at 11:36 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all.
> >
> > Is it possible to convert.identify iso3 country names to the seven
> > continent names?
> >
> > # Asia, Africa, Antarctica, Australia, Europe, South America, and North
> > America,
> >
> > I have tried the following:
> >
> > ###
> > region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
> >
> > where df is the name of my dataset with iso3 the identification variable
> > but there seems to be a a lot of missing values.
>
> Please provide a sufficient amount of the dataframe named `df` to allow a
> properly tested response.
>
> >
> >       [[alternative HTML version deleted]]
>
> And do read the Posting Guide. This is a plain text mailing list.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Thu Sep  7 21:35:13 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 7 Sep 2017 12:35:13 -0700
Subject: [R] Using quantmod to obtain current Dow Jones index
In-Reply-To: <E25CCB78-CCC8-4934-8000-CF905AFD08E0@plessthan.com>
References: <E25CCB78-CCC8-4934-8000-CF905AFD08E0@plessthan.com>
Message-ID: <CAPPM_gRj9SWygJxpBUZzcJiqP_Vptfx1g1SY0hwwJvodtdqpZA@mail.gmail.com>

On Wed, Sep 6, 2017 at 8:11 AM, Dennis Fisher <fisher at plessthan.com> wrote:
> R 3.4.1
> OS X
>
> Colleagues,
>
> I am just learning to use the quantmod package and I have encountered something that I don?t understand.
>
> This works:
>         getSymbols("^DJI")
>
> This does not work:
>         getQuote("^DJI?)
> It returns only NAs:
>         Trade Time Last Change % Change Open High Low Volume
>         ^DJI <NA> N/A N/A N/A N/A N/A N/A N/A
>
It returns NAs because that's what is in the file returned by the
Yahoo server.  Also note that getSymbols() and getQuote() use
different APIs.

getQuote("SPY") works, however.  The Dow Jones Industrial index might
not work due to restrictions on real-time data distribution by the
index provider...

> Two questions:
>         1.  Is there some way to obtain the current DJI using quantmod?

No. See above.

>         2.  If not, can someone suggest alternatives?

I don't know of any free alternatives that provide real-time data...
and I wouldn't trust them (or the Yahoo data you can download) for
anything I would risk my (or others') money on.

>
> Dennis
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From dwinsemius at comcast.net  Thu Sep  7 21:56:34 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Sep 2017 12:56:34 -0700
Subject: [R] ISO3 code to 7 continents names
In-Reply-To: <CAMLwc7Owm50np8LMtiRRfgeQUbwFVu5+Q7xqUPn1O1N+pTQpdg@mail.gmail.com>
References: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
 <BFCA895C-C6F3-4B52-BE64-5C2E9ED4AE1F@comcast.net>
 <CAMLwc7Owm50np8LMtiRRfgeQUbwFVu5+Q7xqUPn1O1N+pTQpdg@mail.gmail.com>
Message-ID: <6AD2192C-11BA-4B0C-A186-20DB099F8977@comcast.net>


> On Sep 7, 2017, at 12:21 PM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> df is a data frame consisting of one variable (iso3 codes) such as
> 
> USA
> RUS
> ARG
> BGD
> ITA
> FRA
> 
> 
> Some of these iso3 codes are repeated and I would like the corresponding continent name, the countrycode package does not seem to distinguish between North and South America. Thanks.

Well it does actually: There are two different region codes:

First load the package that has countryExData. I'm presuming this is:

library(rworldmap)

> table(countryExData$EPI_regions)

   Central and Eastern Europ    East Asia and the Pacific                       Europe 
                          19                           18                           24 
   Latin America and Caribbe Middle East and North Africa                North America 
                          24                           19                            2 
                  South Asia           Sub-Saharan Africa 
                           5                           38 
> table(countryExData$GEO_subregion)

      Arabian Peninsula Australia + New Zealand               Caribbean 
                      5                       2                       5 
         Central Africa            Central Asia          Central Europe 
                      6                       5                      16 
         Eastern Africa          Eastern Europe                 Mashriq 
                      7                       7                       4 
           Meso America           North America          Northeast Asia 
                      8                       2                       5 
        Northern Africa           South America              South Asia 
                      5                      11                       6 
        South East Asia           South Pacific         Southern Africa 
                      8                       3                      10 
         Western Africa          Western Europe    Western Indian Ocean 
                     13                      19                       2 

Then create the described dataframe:

df<- data.frame(iso3=scan(what="") )
1: USA
2: RUS
3: ARG
4: BGD
5: ITA
6: FRA
7: 
Read 6 items


>  region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')$EPI_regions

> region
[1] "Latin America and Caribbe" "South Asia"                "Europe"                   
[4] "Europe"                    "Central and Eastern Europ" "North America"    

-- 
David.

> 
> Sincerely,
> 
> Milu
> 
> On Thu, Sep 7, 2017 at 9:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Sep 7, 2017, at 11:36 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all.
> >
> > Is it possible to convert.identify iso3 country names to the seven
> > continent names?
> >
> > # Asia, Africa, Antarctica, Australia, Europe, South America, and North
> > America,
> >
> > I have tried the following:
> >
> > ###
> > region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
> >
> > where df is the name of my dataset with iso3 the identification variable
> > but there seems to be a a lot of missing values.
> 
> Please provide a sufficient amount of the dataframe named `df` to allow a properly tested response.
> 
> >
> >       [[alternative HTML version deleted]]
> 
> And do read the Posting Guide. This is a plain text mailing list.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Thu Sep  7 22:11:29 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 07 Sep 2017 13:11:29 -0700
Subject: [R] ISO3 code to 7 continents names
In-Reply-To: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
References: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
Message-ID: <8C5AFD23-AB94-453F-BDED-25CC11C99225@dcn.davis.ca.us>

The unequivocal answer is that it is possible, and most likely you have bad data or are referring to an incomplete lookup table. 

For us to see what your problem is would rewquire a reproducible example, but what you have provided is not reproducible [1][2][3].

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On September 7, 2017 11:36:05 AM PDT, Miluji Sb <milujisb at gmail.com> wrote:
>Dear all.
>
>Is it possible to convert.identify iso3 country names to the seven
>continent names?
>
># Asia, Africa, Antarctica, Australia, Europe, South America, and North
>America,
>
>I have tried the following:
>
>###
>region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
>
>where df is the name of my dataset with iso3 the identification
>variable
>but there seems to be a a lot of missing values.
>
>Thank you!
>
>Sincerely,
>
>Milu
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From b88207001 at ntu.edu.tw  Fri Sep  8 04:48:19 2017
From: b88207001 at ntu.edu.tw (Yen Lee)
Date: Thu, 7 Sep 2017 21:48:19 -0500
Subject: [R] Multinomial Regression for Complex Survey
Message-ID: <000101d3284c$f05f0160$d11d0420$@ntu.edu.tw>

Hi Dear Rusers,

 

I am working on a survey data with the "survey" package. The logistic
regression and multinomial regression would be the main statistic method I
want to use. I found that the svyglm function could be used to conduct the
logistic regression with the complex design but not the multinomial
regression. I wonder if there is any package or function in the "survey"
could be used to handle this problem. Please let me know if you have any
clue. 

 

I appreciate your willingness to help! Thank you for your time!

 

Best,

Yen


	[[alternative HTML version deleted]]


From winterheart2005 at gmail.com  Fri Sep  8 07:40:08 2017
From: winterheart2005 at gmail.com (=?UTF-8?B?0JTQvNC40YLRgNC40Lkg0J/QtdGA0LXQv9C10YfQuNC9?=)
Date: Fri, 8 Sep 2017 15:40:08 +1000
Subject: [R] need help for finding related sales with R
Message-ID: <CABhmxXz_QhLKewrrnwB0y1LWn1fhEbqRZ-FkZyqRj8UsLMY+uw@mail.gmail.com>

Hello everyone. Could you please help me? I need to do some sales analysis
and i'm stuk.

I've got a dataset that contains next information:


Sales_department; sales_manager; Client; transaction ID; Product (SKU),
 Cost, Gross income, Profitability

Ineed to perfom an ABC analysis (by the Cost of sold products to this
client) to find the A clients of each manager, i'm doing it this way:

managers_ABC <- svod %>%
  group_by(Sales_department, sales_manager, Client) %>%
  summarise("Clients_cost" = sum(Cost,na.rm = TRUE)) %>%
  arrange(sales_manager, desc(Clients_cost)) %>%
  group_by(sales_manager) %>%
  mutate("total_sales_of_a_manager" = sum(Clients_cost),
            "Accumulated_sales" = cumsum(`Clients_cost`),
            "Accumulated_sales_share" =
Accumulated_sales/total_sales_of_a_manager)
%>%
  ungroup() %>%
  mutate("managers_ABC  = if_else(Accumulated_sales_share < 0.8, "A",
                                          if_else(Accumulated_sales_share <
0.95, "B","C")))


So, here we come to the main problem: i need to add 3 more columnes with
the SKU statuses:

if the the SKU is in top 20% of clients sales by Cost, Gross_income and
Profitability, than it is a "cGSKU" (clients gold SKU)

if the SKU is not gold, but occurs in 50% of transaction IDs with cGSKU,
than it is a "cMSKU" (clients must have SKU).

So i dont know how to realize this. I think it must be  some cind a cycle.
Could you please help me to write one?


And is there any more simple method perfom an ABC analysis by any criterion
(for example ABC by sales_manager or sales_department)


thank you!

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Fri Sep  8 09:56:39 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 8 Sep 2017 09:56:39 +0200
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <5670ad71-38c5-4dac-db4c-e1b7a451cb59@gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
 <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
 <40ee4068-352d-fc99-187b-27090bb72a0a@gmail.com>
 <5670ad71-38c5-4dac-db4c-e1b7a451cb59@gmail.com>
Message-ID: <CAJuCY5zbYb9w5AwYUf51vvydc=y6Njm8e_H_B0vtzPe3Nt3oqA@mail.gmail.com>

That is strange. Another function in the same package
(INBOmd::inbo_rapport) uses the same trick. I actually started by copying
the post_processor() from that function. INBOmd::inbo_rapport() works both
with and without BibTex. Working examples are source/inbo_rapport and
source/inbo_rapport_basic from https://github.com/inbo/inbomd_examples.
Note that you need some extra work after installing INBOmd to
inbo_rapport() to run. See the README at https://github.com/inbo/INBOmd

I've created an issue https://github.com/rstudio/rmarkdown/issues/1138

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2017-09-07 21:18 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 07/09/2017 2:04 PM, Duncan Murdoch wrote:
>
>> On 07/09/2017 10:11 AM, Thierry Onkelinx wrote:
>>
>>> Dear Duncan,
>>>
>>> Thanks for chiming in. Could you explain how you set debug() on
>>> post_processor()? I've tried adding debug(post_processor) to
>>> rsos_article() or adding debug(post_processor) when after post_processor
>>> was defined in the debugger. Neither work for me.
>>>
>>
>> Not working for me either right now for some reason or other.  What I
>> was doing was manually running debug(post_processor) in the debugger
>> after single stepping past its definition.
>>
>> What does show it is running is that at that same point I can execute
>>
>> post_processor <- function() stop()
>>
>> and it stops.
>>
>> The end of the console log looks like this:
>>
>>
>> /Applications/RStudio.app/Contents/MacOS/pandoc/pandoc +RTS -K512m -RTS
>> skeleton.utf8.md --to latex --from
>> markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
>> --output skeleton.tex --template
>> /Library/Frameworks/R.framework/Versions/3.3/Resources/
>> library/INBOmd/rmarkdown/templates/rsos_article/resources/template.tex
>> --natbib --bibliography sample.bib
>> Latexmk: This is Latexmk, John Collins, 19 Jan. 2017, version: 4.52c.
>> Error in output_format$post_processor(yaml_front_matter, utf8_input,
>> output_file,  :
>>     unused arguments (yaml_front_matter, utf8_input, output_file, clean,
>> !quiet)
>> Called from: output_format$post_processor(yaml_front_matter, utf8_input,
>> output_file,
>>       clean, !quiet)
>>
>> so we see pandoc being run, then Latexmk, then the post_processor call.
>> It seems a little odd that Latexmk is being run.  Is that something you
>> are doing, or is it pandoc asking for that?  If the latter, can you tell
>> pandoc not to do so?
>>
>>
> I've done some debugging in rmarkdown::render.  Apparently if you need
> Bibtex (as your example does), it runs Latexmk before the post-processor.
>
> I don't know if there's a way around this...
>
> Duncan Murdoch
>
>
>
>>
>>
>>> All supporting files are available within the package. The code below
>>> should be reproducible on your machine.
>>>
>>> remove.packages("INBOmd")
>>> devtools::install_github("inbo/INBOmd at post_processor")
>>> setwd(system.file("rmarkdown/templates/rsos_article/skeleton", package =
>>> "INBOmd"))
>>> debug(INBOmd::rsos_article)
>>> rmarkdown::render("skeleton.Rmd")
>>>
>>
>> I'm not sure you would normally have write access in that directory, so
>> it may not be typical of what you'd see in a user directory.  I
>> certainly see something different when I copy the skeleton.Rmd file (and
>> nothing else) to my own temp directory.
>>
>>
>>
>>> The sign that post_processor() fails when the tex file still contains
>>> \EndFirstPage resulting in the compilation error "Undefined control
>>> sequence. l.128 \EndFirstPage"
>>>
>>
>> That certainly indicates it isn't doing what you want, but it might be
>> running and doing something else.
>>
>> Duncan Murdoch
>>
>>
>>> I still get the error with the current version of the code. Running the
>>> post_processor manually works.
>>>
>>> eval(parse(
>>>     text = readLines(
>>>       "https://raw.githubusercontent.com/inbo/INBOmd/post_
>>> processor/R/rsos_article.R"
>>>     )[72:92]
>>> ))
>>> post_processor(output_file = "skeleton.tex")
>>> system("pdflatex skeleton.tex")
>>>
>>> Best regards,
>>>
>>>
>>> ir. Thierry Onkelinx
>>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>>> and Forest
>>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>>> Kliniekstraat 25
>>> 1070 Anderlecht
>>> Belgium
>>>
>>> To call in the statistician after the experiment is done may be no more
>>> than asking him to perform a post-mortem examination: he may be able to
>>> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does not
>>> ensure that a reasonable answer can be extracted from a given body of
>>> data. ~ John Tukey
>>>
>>> 2017-09-07 12:14 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com
>>> <mailto:murdoch.duncan at gmail.com>>:
>>>
>>>      On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
>>>
>>>          Dear all,
>>>
>>>          I'm trying to write a post_processor() for a custom rmarkdown
>>>          format. The
>>>          goal of the post_processor() is to modify the latex file before
>>>          it is
>>>          compiled. For some reason the post_processor() is not run. The
>>>          post_processor() does work when I run it manually on the tex
>>> file.
>>>
>>>          Any suggestions on what I'm doing wrong? Below is the relevant
>>>          snippet of
>>>          the code. The full code is available at
>>>          https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_
>>> article.R
>>>          <https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_
>>> article.R>
>>>          https://github.com/inbo/INBOmd/blob/post_processor/inst/
>>> rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>>>          <https://github.com/inbo/INBOmd/blob/post_processor/inst/
>>> rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd>
>>>          is an Rmd is a MWE that fails compile because the
>>>          post_processor() is not
>>>          run.
>>>
>>>
>>>      I installed it and tried running it using
>>>
>>>      debug(INBOmd::rsos_article)
>>>      rmarkdown::render("skeleton.Rmd")
>>>
>>>      then after post_processor was defined, I set it to debug as well,
>>>      and could see that the post_processor was being run.
>>>
>>>      I didn't get useful output, because the LaTeXing failed (I don't
>>>      have the rsos.cls), but perhaps you've already fixed this problem,
>>>      or perhaps it is intermittent?
>>>
>>>      Duncan Murdoch
>>>
>>>          Best regards,
>>>
>>>          Thierry
>>>
>>>              post_processor <- function(
>>>                metadata, input_file, output_file, clean, verbose
>>>              ) {
>>>                text <- readLines(output_file, warn = FALSE)
>>>
>>>                # set correct text in fmtext environment
>>>                end_first_page <- grep("\\\\EndFirstPage", text) #nolint
>>>                if (length(end_first_page) == 1) {
>>>                  maketitle <- grep("\\\\maketitle", text) #nolint
>>>                  text <- c(
>>>                    text[1:(maketitle - 1)],
>>>                    "\\begin{fmtext}",
>>>                    text[(maketitle + 1):(end_first_page - 1)],
>>>                    "\\end{fmtext}",
>>>                    "\\maketitle",
>>>                    text[(end_first_page + 1):length(text)]
>>>                  )
>>>                  writeLines(enc2utf8(text), output_file, useBytes = TRUE)
>>>                }
>>>                output_file
>>>              }
>>>
>>>              output_format(
>>>                knitr = knitr_options(
>>>                  opts_knit = list(
>>>                    width = 60,
>>>                    concordance = TRUE
>>>                  ),
>>>                  opts_chunk = opts_chunk,
>>>                  knit_hooks = knit_hooks
>>>                ),
>>>                pandoc = pandoc_options(
>>>                  to = "latex",
>>>                  latex_engine = "xelatex",
>>>                  args = args,
>>>                  keep_tex = keep_tex
>>>                ),
>>>                post_processor = post_processor,
>>>                clean_supporting = !keep_tex
>>>              )
>>>
>>>
>>>
>>>          ir. Thierry Onkelinx
>>>          Instituut voor natuur- en bosonderzoek / Research Institute for
>>>          Nature and
>>>          Forest
>>>          team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>>>          Assurance
>>>          Kliniekstraat 25
>>>          1070 Anderlecht
>>>          Belgium
>>>
>>>          To call in the statistician after the experiment is done may be
>>>          no more
>>>          than asking him to perform a post-mortem examination: he may be
>>>          able to say
>>>          what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>          The plural of anecdote is not data. ~ Roger Brinner
>>>          The combination of some data and an aching desire for an answer
>>>          does not
>>>          ensure that a reasonable answer can be extracted from a given
>>>          body of data.
>>>          ~ John Tukey
>>>
>>>                   [[alternative HTML version deleted]]
>>>
>>>          ______________________________________________
>>>          R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>          -- To UNSUBSCRIBE and more, see
>>>          https://stat.ethz.ch/mailman/listinfo/r-help
>>>          <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>          PLEASE do read the posting guide
>>>          http://www.R-project.org/posting-guide.html
>>>          <http://www.R-project.org/posting-guide.html>
>>>          and provide commented, minimal, self-contained, reproducible
>>> code.
>>>
>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From traxplayer at gmail.com  Fri Sep  8 10:48:45 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 8 Sep 2017 10:48:45 +0200
Subject: [R] Optimize code to read text-file with digits
Message-ID: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>

Hi,

  Every day I try to write some small R programs to improve my R-skills.
  Yesterday I wrote a small program to read the digits from "A Million
Random Digits" from RAND.
  My code works but it is very slow and I guess the code is not optimal.

The digits.txt file downloaded from
https://www.rand.org/pubs/monograph_reports/MR1418.html
contains 20000 lines which looks like this:
00000   10097 32533  76520 13586  34673 54876  80959 09117  39292 74945
00001   37542 04805  64894 74296  24805 24037  20636 10402  00822 91665
00002   08422 68953  19645 09303  23209 02560  15953 34764  35080 33606
00003   99019 02529  09376 70715  38311 31165  88676 74397  04436 27659
00004   12807 99970  80157 36147  64032 36653  98951 16877  12171 76833

My program which is slow looks like this:

filename <- "digits.txt"
lines <- readLines(filename)

numbers <- vector('numeric')
for (i in 1:length(lines)) {

    # remove first column
    lines[i] <- sub("[^ ]+ +","",lines[i])

    # remove spaces
    lines[i] <- gsub(" ","",lines[i])

    # split the characters and convert them into numbers
    numbers <- c(numbers,as.numeric(unlist(strsplit(lines[i],""))))
}

Thanks for any advice how this program can be improved.

Regards
Martin M. S. Pedersen

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep  8 11:25:01 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 8 Sep 2017 09:25:01 +0000
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAADF55@SRVEXCHCM301.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin
> Moller Skarbiniks Pedersen
> Sent: Friday, September 8, 2017 10:49 AM
> To: r-help at r-project.org
> Subject: [R] Optimize code to read text-file with digits
>
> Hi,
>
>   Every day I try to write some small R programs to improve my R-skills.
>   Yesterday I wrote a small program to read the digits from "A Million Random
> Digits" from RAND.
>   My code works but it is very slow and I guess the code is not optimal.
>
> The digits.txt file downloaded from
> https://www.rand.org/pubs/monograph_reports/MR1418.html
> contains 20000 lines which looks like this:
> 00000   10097 32533  76520 13586  34673 54876  80959 09117  39292 74945
> 00001   37542 04805  64894 74296  24805 24037  20636 10402  00822 91665
> 00002   08422 68953  19645 09303  23209 02560  15953 34764  35080 33606
> 00003   99019 02529  09376 70715  38311 31165  88676 74397  04436 27659
> 00004   12807 99970  80157 36147  64032 36653  98951 16877  12171 76833
>
> My program which is slow looks like this:
>
> filename <- "digits.txt"
> lines <- readLines(filename)

why you do not read a file as a whole e.g. by

lines<-read.table("digits.txt")

After that you do not need for cycle (but maybe I misunderstand what you really want)

remove first column

lines <- lines[,-1]

And now I am lost.
Do you want each row convert into a numeric vector? It probably exceed the precision of biggest number allowed.

Do you want to split each column to 5 numeric columns?
you can use something like

outer(lines[,1], 10^c(4:0), function(a, b) a %/% b %% 10)

to split the first column.

Or do you want one big numeric vector from all your numbers?

here you need to read values as character variables

lines<-read.table("digits.txt", colClasses="character")
numbers<-as.numeric(unlist(strsplit(as.character(lines[1,]),"")))
changes first row to numeric vector.

Anyway, can you explain what is your final goal?

Cheers
Petr


>
> numbers <- vector('numeric')
> for (i in 1:length(lines)) {
>
>     # remove first column
>     lines[i] <- sub("[^ ]+ +","",lines[i])
>
>     # remove spaces
>     lines[i] <- gsub(" ","",lines[i])
>
>     # split the characters and convert them into numbers
>     numbers <- c(numbers,as.numeric(unlist(strsplit(lines[i],""))))
> }
>
> Thanks for any advice how this program can be improved.
>
> Regards
> Martin M. S. Pedersen
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From traxplayer at gmail.com  Fri Sep  8 11:58:22 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 8 Sep 2017 11:58:22 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAADF55@SRVEXCHCM301.precheza.cz>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAADF55@SRVEXCHCM301.precheza.cz>
Message-ID: <CAGAA5betFciY8sDxwfUEgEDCnnzFniVNXYz0hu54Ac511O7FSg@mail.gmail.com>

On 8 September 2017 at 11:25, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> > Moller Skarbiniks Pedersen

> My program which is slow looks like this:
> >
> > filename <- "digits.txt"
> > lines <- readLines(filename)
>
> why you do not read a file as a whole e.g. by
>
> lines<-read.table("digits.txt")
>

Good idea.

>
> And now I am lost.


[...]


>  Or do you want one big numeric vector from all your numbers?

here you need to read values as character variables
>

Yes. That's what I am looking for.

>
> lines<-read.table("digits.txt", colClasses="character")
> numbers<-as.numeric(unlist(strsplit(as.character(lines[1,]),"")))
> changes first row to numeric vector.
>
>
Do I still need to loop through all lines?
It is maybe even slower now.

numbers <- vector('numeric')
for (i in 1:nrows(lines)) {
  numbers <- c(numbers, as.numeric(unlist(strsplit(as.
character(lines[i,]),""))))
}


> Anyway, can you explain what is your final goal?
>
>
A numeric vector of length 1 million. Each element should be one digit.


> Cheers
> Petr
>
>
Thanks.
/Martin

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Sep  8 12:20:17 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 08 Sep 2017 10:20:17 +0000
Subject: [R] Nested loop R code
In-Reply-To: <CAJL6Qs9Hoe9bMAieQQw8hNqFD_6MsUcFtWfy3DBCdqCzbTTNyw@mail.gmail.com>
References: <CAJL6Qs9Hoe9bMAieQQw8hNqFD_6MsUcFtWfy3DBCdqCzbTTNyw@mail.gmail.com>
Message-ID: <CAKVAULNA3ukPKDa6wSYaZmOY2MYzbTO+zPO0k275LEZvnRcF_w@mail.gmail.com>

Hi Hemant,

please write to the r-help list in the future.

Look at the cut () function to solve your problem.

Also, you have a problem in your example - 5 is placed in two different
categories.

HTH
Ulrik

On Fri, 8 Sep 2017 at 12:16 Hemant Sain <hemantsain55 at gmail.com> wrote:

> i have a vector containing values ranging from 0 to 24
> i want to create another variable which can categorize those values  like
> this
> please help me with an R code
>
> Thanks
>
> *Value       New_Var*1            0 -5
> 3            0 -5
> 5            0 -5
> 9            6-10
> 7            6-10
> 5            6-10
> 4             0-5
> 11          11-15
> 12         11-15
> 18          16-20
> 23          21 -25
>
>
> --
> hemantsain.com
>

	[[alternative HTML version deleted]]


From hemantsain55 at gmail.com  Fri Sep  8 12:15:14 2017
From: hemantsain55 at gmail.com (Hemant Sain)
Date: Fri, 8 Sep 2017 15:45:14 +0530
Subject: [R] nested loop
Message-ID: <CAJL6Qs9xxH-N7zp-h5LchJHvzLMfiqoNTvBZPvXzh4EsksO0tQ@mail.gmail.com>

i have a vector containing values ranging from 0 to 24
i want to create another variable which can categorize those values  like
this
please help me with an R code

Thanks

*Value       New_Var*1            0 -5
3            0 -5
5            0 -5
9            6-10
7            6-10
5            6-10
4             0-5
11          11-15
12         11-15
18          16-20
23          21 -25

-- 
hemantsain.com

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep  8 13:55:38 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 8 Sep 2017 07:55:38 -0400
Subject: [R] post_processor in rmarkdown not working
In-Reply-To: <CAJuCY5zbYb9w5AwYUf51vvydc=y6Njm8e_H_B0vtzPe3Nt3oqA@mail.gmail.com>
References: <CAJuCY5xOmiXjCA_DuRbw7HB7gpjOtqwRvPqE28307NGuCTE1Jw@mail.gmail.com>
 <c7aa19b9-d4be-4a07-df48-b7c39e99fe83@gmail.com>
 <CAJuCY5x-KatP6KNGwpjJBmrV3n=xQ70O5ESCZdOx1WcGwsqaVg@mail.gmail.com>
 <40ee4068-352d-fc99-187b-27090bb72a0a@gmail.com>
 <5670ad71-38c5-4dac-db4c-e1b7a451cb59@gmail.com>
 <CAJuCY5zbYb9w5AwYUf51vvydc=y6Njm8e_H_B0vtzPe3Nt3oqA@mail.gmail.com>
Message-ID: <52488ee5-8291-6812-e1f3-1f8abd933060@gmail.com>

On 08/09/2017 3:56 AM, Thierry Onkelinx wrote:
> That is strange. Another function in the same package 
> (INBOmd::inbo_rapport) uses the same trick. 

I think the issue there is that the LaTeX code is valid before the 
post-processor is run, it just re-orders things.  So rmarkdown::render 
runs Pandoc, then LaTeX (via Latexmk), then the post-processor, then 
LaTeX again.

This suggests a solution to the rsos_article problem:  somehow make sure 
that the LaTeX is valid from the start, e.g. by defining dummy versions 
of the missing macros.

Duncan Murdoch


I actually started by
> copying the post_processor() from that function. INBOmd::inbo_rapport() 
> works both with and without BibTex. Working examples are 
> source/inbo_rapport and source/inbo_rapport_basic from 
> https://github.com/inbo/inbomd_examples. Note that you need some extra 
> work after installing INBOmd to inbo_rapport() to run. See the README at 
> https://github.com/inbo/INBOmd
> 
> I've created an issue https://github.com/rstudio/rmarkdown/issues/1138
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more 
> than asking him to perform a post-mortem examination: he may be able to 
> say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not 
> ensure that a reasonable answer can be extracted from a given body of 
> data. ~ John Tukey
> 
> 2017-09-07 21:18 GMT+02:00 Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 07/09/2017 2:04 PM, Duncan Murdoch wrote:
> 
>         On 07/09/2017 10:11 AM, Thierry Onkelinx wrote:
> 
>             Dear Duncan,
> 
>             Thanks for chiming in. Could you explain how you set debug() on
>             post_processor()? I've tried adding debug(post_processor) to
>             rsos_article() or adding debug(post_processor) when after
>             post_processor
>             was defined in the debugger. Neither work for me.
> 
> 
>         Not working for me either right now for some reason or other. 
>         What I
>         was doing was manually running debug(post_processor) in the debugger
>         after single stepping past its definition.
> 
>         What does show it is running is that at that same point I can
>         execute
> 
>         post_processor <- function() stop()
> 
>         and it stops.
> 
>         The end of the console log looks like this:
> 
> 
>         /Applications/RStudio.app/Contents/MacOS/pandoc/pandoc +RTS
>         -K512m -RTS
>         skeleton.utf8.md <http://skeleton.utf8.md> --to latex --from
>         markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash
>         --output skeleton.tex --template
>         /Library/Frameworks/R.framework/Versions/3.3/Resources/library/INBOmd/rmarkdown/templates/rsos_article/resources/template.tex
>         --natbib --bibliography sample.bib
>         Latexmk: This is Latexmk, John Collins, 19 Jan. 2017, version:
>         4.52c.
>         Error in output_format$post_processor(yaml_front_matter, utf8_input,
>         output_file,? :
>          ? ? unused arguments (yaml_front_matter, utf8_input,
>         output_file, clean,
>         !quiet)
>         Called from: output_format$post_processor(yaml_front_matter,
>         utf8_input,
>         output_file,
>          ? ? ? clean, !quiet)
> 
>         so we see pandoc being run, then Latexmk, then the
>         post_processor call.
>         It seems a little odd that Latexmk is being run.? Is that
>         something you
>         are doing, or is it pandoc asking for that?? If the latter, can
>         you tell
>         pandoc not to do so?
> 
> 
>     I've done some debugging in rmarkdown::render.? Apparently if you
>     need Bibtex (as your example does), it runs Latexmk before the
>     post-processor.
> 
>     I don't know if there's a way around this...
> 
>     Duncan Murdoch
> 
> 
> 
> 
> 
>             All supporting files are available within the package. The
>             code below
>             should be reproducible on your machine.
> 
>             remove.packages("INBOmd")
>             devtools::install_github("inbo/INBOmd at post_processor")
>             setwd(system.file("rmarkdown/templates/rsos_article/skeleton",
>             package =
>             "INBOmd"))
>             debug(INBOmd::rsos_article)
>             rmarkdown::render("skeleton.Rmd")
> 
> 
>         I'm not sure you would normally have write access in that
>         directory, so
>         it may not be typical of what you'd see in a user directory.? I
>         certainly see something different when I copy the skeleton.Rmd
>         file (and
>         nothing else) to my own temp directory.
> 
> 
> 
>             The sign that post_processor() fails when the tex file still
>             contains
>             \EndFirstPage resulting in the compilation error "Undefined
>             control
>             sequence. l.128 \EndFirstPage"
> 
> 
>         That certainly indicates it isn't doing what you want, but it
>         might be
>         running and doing something else.
> 
>         Duncan Murdoch
> 
> 
>             I still get the error with the current version of the code.
>             Running the
>             post_processor manually works.
> 
>             eval(parse(
>              ? ? text = readLines(
>                   
>             "https://raw.githubusercontent.com/inbo/INBOmd/post_processor/R/rsos_article.R
>             <https://raw.githubusercontent.com/inbo/INBOmd/post_processor/R/rsos_article.R>"
>              ? ? )[72:92]
>             ))
>             post_processor(output_file = "skeleton.tex")
>             system("pdflatex skeleton.tex")
> 
>             Best regards,
> 
> 
>             ir. Thierry Onkelinx
>             Instituut voor natuur- en bosonderzoek / Research Institute
>             for Nature
>             and Forest
>             team Biometrie & Kwaliteitszorg / team Biometrics & Quality
>             Assurance
>             Kliniekstraat 25
>             1070 Anderlecht
>             Belgium
> 
>             To call in the statistician after the experiment is done may
>             be no more
>             than asking him to perform a post-mortem examination: he may
>             be able to
>             say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>             The plural of anecdote is not data. ~ Roger Brinner
>             The combination of some data and an aching desire for an
>             answer does not
>             ensure that a reasonable answer can be extracted from a
>             given body of
>             data. ~ John Tukey
> 
>             2017-09-07 12:14 GMT+02:00 Duncan Murdoch
>             <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>             <mailto:murdoch.duncan at gmail.com
>             <mailto:murdoch.duncan at gmail.com>>>:
> 
>              ? ? ?On 06/09/2017 5:41 AM, Thierry Onkelinx wrote:
> 
>              ? ? ? ? ?Dear all,
> 
>              ? ? ? ? ?I'm trying to write a post_processor() for a
>             custom rmarkdown
>              ? ? ? ? ?format. The
>              ? ? ? ? ?goal of the post_processor() is to modify the
>             latex file before
>              ? ? ? ? ?it is
>              ? ? ? ? ?compiled. For some reason the post_processor() is
>             not run. The
>              ? ? ? ? ?post_processor() does work when I run it manually
>             on the tex file.
> 
>              ? ? ? ? ?Any suggestions on what I'm doing wrong? Below is
>             the relevant
>              ? ? ? ? ?snippet of
>              ? ? ? ? ?the code. The full code is available at
>             https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R
>             <https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R>
>                     
>              ?<https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R <https://github.com/inbo/INBOmd/blob/post_processor/R/rsos_article.R>>
>             https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd
>             <https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd>
>                     
>              ?<https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd <https://github.com/inbo/INBOmd/blob/post_processor/inst/rmarkdown/templates/rsos_article/skeleton/skeleton.Rmd>>
>              ? ? ? ? ?is an Rmd is a MWE that fails compile because the
>              ? ? ? ? ?post_processor() is not
>              ? ? ? ? ?run.
> 
> 
>              ? ? ?I installed it and tried running it using
> 
>              ? ? ?debug(INBOmd::rsos_article)
>              ? ? ?rmarkdown::render("skeleton.Rmd")
> 
>              ? ? ?then after post_processor was defined, I set it to
>             debug as well,
>              ? ? ?and could see that the post_processor was being run.
> 
>              ? ? ?I didn't get useful output, because the LaTeXing
>             failed (I don't
>              ? ? ?have the rsos.cls), but perhaps you've already fixed
>             this problem,
>              ? ? ?or perhaps it is intermittent?
> 
>              ? ? ?Duncan Murdoch
> 
>              ? ? ? ? ?Best regards,
> 
>              ? ? ? ? ?Thierry
> 
>              ? ? ? ? ? ? ?post_processor <- function(
>              ? ? ? ? ? ? ? ?metadata, input_file, output_file, clean,
>             verbose
>              ? ? ? ? ? ? ?) {
>              ? ? ? ? ? ? ? ?text <- readLines(output_file, warn = FALSE)
> 
>              ? ? ? ? ? ? ? ?# set correct text in fmtext environment
>              ? ? ? ? ? ? ? ?end_first_page <- grep("\\\\EndFirstPage",
>             text) #nolint
>              ? ? ? ? ? ? ? ?if (length(end_first_page) == 1) {
>              ? ? ? ? ? ? ? ? ?maketitle <- grep("\\\\maketitle", text)
>             #nolint
>              ? ? ? ? ? ? ? ? ?text <- c(
>              ? ? ? ? ? ? ? ? ? ?text[1:(maketitle - 1)],
>              ? ? ? ? ? ? ? ? ? ?"\\begin{fmtext}",
>              ? ? ? ? ? ? ? ? ? ?text[(maketitle + 1):(end_first_page - 1)],
>              ? ? ? ? ? ? ? ? ? ?"\\end{fmtext}",
>              ? ? ? ? ? ? ? ? ? ?"\\maketitle",
>              ? ? ? ? ? ? ? ? ? ?text[(end_first_page + 1):length(text)]
>              ? ? ? ? ? ? ? ? ?)
>              ? ? ? ? ? ? ? ? ?writeLines(enc2utf8(text), output_file,
>             useBytes = TRUE)
>              ? ? ? ? ? ? ? ?}
>              ? ? ? ? ? ? ? ?output_file
>              ? ? ? ? ? ? ?}
> 
>              ? ? ? ? ? ? ?output_format(
>              ? ? ? ? ? ? ? ?knitr = knitr_options(
>              ? ? ? ? ? ? ? ? ?opts_knit = list(
>              ? ? ? ? ? ? ? ? ? ?width = 60,
>              ? ? ? ? ? ? ? ? ? ?concordance = TRUE
>              ? ? ? ? ? ? ? ? ?),
>              ? ? ? ? ? ? ? ? ?opts_chunk = opts_chunk,
>              ? ? ? ? ? ? ? ? ?knit_hooks = knit_hooks
>              ? ? ? ? ? ? ? ?),
>              ? ? ? ? ? ? ? ?pandoc = pandoc_options(
>              ? ? ? ? ? ? ? ? ?to = "latex",
>              ? ? ? ? ? ? ? ? ?latex_engine = "xelatex",
>              ? ? ? ? ? ? ? ? ?args = args,
>              ? ? ? ? ? ? ? ? ?keep_tex = keep_tex
>              ? ? ? ? ? ? ? ?),
>              ? ? ? ? ? ? ? ?post_processor = post_processor,
>              ? ? ? ? ? ? ? ?clean_supporting = !keep_tex
>              ? ? ? ? ? ? ?)
> 
> 
> 
>              ? ? ? ? ?ir. Thierry Onkelinx
>              ? ? ? ? ?Instituut voor natuur- en bosonderzoek / Research
>             Institute for
>              ? ? ? ? ?Nature and
>              ? ? ? ? ?Forest
>              ? ? ? ? ?team Biometrie & Kwaliteitszorg / team Biometrics
>             & Quality
>              ? ? ? ? ?Assurance
>              ? ? ? ? ?Kliniekstraat 25
>              ? ? ? ? ?1070 Anderlecht
>              ? ? ? ? ?Belgium
> 
>              ? ? ? ? ?To call in the statistician after the experiment
>             is done may be
>              ? ? ? ? ?no more
>              ? ? ? ? ?than asking him to perform a post-mortem
>             examination: he may be
>              ? ? ? ? ?able to say
>              ? ? ? ? ?what the experiment died of. ~ Sir Ronald Aylmer
>             Fisher
>              ? ? ? ? ?The plural of anecdote is not data. ~ Roger Brinner
>              ? ? ? ? ?The combination of some data and an aching desire
>             for an answer
>              ? ? ? ? ?does not
>              ? ? ? ? ?ensure that a reasonable answer can be extracted
>             from a given
>              ? ? ? ? ?body of data.
>              ? ? ? ? ?~ John Tukey
> 
>              ? ? ? ? ? ? ? ? ? [[alternative HTML version deleted]]
> 
>              ? ? ? ? ?______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org>
>             <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>             mailing list
>              ? ? ? ? ?-- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>              ? ? ? ? ?<https://stat.ethz.ch/mailman/listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>>
>              ? ? ? ? ?PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>              ? ? ? ? ?<http://www.R-project.org/posting-guide.html
>             <http://www.R-project.org/posting-guide.html>>
>              ? ? ? ? ?and provide commented, minimal, self-contained,
>             reproducible code.
> 
> 
> 
> 
> 
>


From pdalgd at gmail.com  Fri Sep  8 14:03:56 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Sep 2017 14:03:56 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
Message-ID: <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>

Simplest version that I can think of:

x <- scan("~/Downloads/digits.txt")
x <- x[-seq(1,220000,11)]
length(x) # 200000
hist(x)

Now, because it's Friday: 

How does one work out the theoretical distribution of the following table?

> table(table(factor(x,levels=0:99999)))

    0     1     2     3     4     5     6     7     8     9    10    11 
13497 27113 27010 18116  9122  3466  1186   366    99    22     1     1 
   12 
    1 

(I.e., out of 200000 random 5 digit numbers, 13497 numbers never occurred, 27113 numbers exactly once, and ... and 1 number occurred 12 times.)

-pd


> On 8 Sep 2017, at 10:48 , Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
> 
> Hi,
> 
>  Every day I try to write some small R programs to improve my R-skills.
>  Yesterday I wrote a small program to read the digits from "A Million
> Random Digits" from RAND.
>  My code works but it is very slow and I guess the code is not optimal.
> 
> The digits.txt file downloaded from
> https://www.rand.org/pubs/monograph_reports/MR1418.html
> contains 20000 lines which looks like this:
> 00000   10097 32533  76520 13586  34673 54876  80959 09117  39292 74945
> 00001   37542 04805  64894 74296  24805 24037  20636 10402  00822 91665
> 00002   08422 68953  19645 09303  23209 02560  15953 34764  35080 33606
> 00003   99019 02529  09376 70715  38311 31165  88676 74397  04436 27659
> 00004   12807 99970  80157 36147  64032 36653  98951 16877  12171 76833
> 
> My program which is slow looks like this:
> 
> filename <- "digits.txt"
> lines <- readLines(filename)
> 
> numbers <- vector('numeric')
> for (i in 1:length(lines)) {
> 
>    # remove first column
>    lines[i] <- sub("[^ ]+ +","",lines[i])
> 
>    # remove spaces
>    lines[i] <- gsub(" ","",lines[i])
> 
>    # split the characters and convert them into numbers
>    numbers <- c(numbers,as.numeric(unlist(strsplit(lines[i],""))))
> }
> 
> Thanks for any advice how this program can be improved.
> 
> Regards
> Martin M. S. Pedersen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Fri Sep  8 14:06:56 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 8 Sep 2017 12:06:56 +0000
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <CAGAA5betFciY8sDxwfUEgEDCnnzFniVNXYz0hu54Ac511O7FSg@mail.gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAADF55@SRVEXCHCM301.precheza.cz>
 <CAGAA5betFciY8sDxwfUEgEDCnnzFniVNXYz0hu54Ac511O7FSg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAADFCD@SRVEXCHCM301.precheza.cz>

Hi

see in line


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin
> Moller Skarbiniks Pedersen
> Sent: Friday, September 8, 2017 11:58 AM
> To: r-help at r-project.org
> Subject: Re: [R] Optimize code to read text-file with digits
>
> On 8 September 2017 at 11:25, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > > Moller Skarbiniks Pedersen
>
> > My program which is slow looks like this:
> > >
> > > filename <- "digits.txt"
> > > lines <- readLines(filename)
> >
> > why you do not read a file as a whole e.g. by
> >
> > lines<-read.table("digits.txt")
> >
>
> Good idea.
>
> >
> > And now I am lost.
>
>
> [...]
>
>
> >  Or do you want one big numeric vector from all your numbers?
>
> here you need to read values as character variables
> >
>
> Yes. That's what I am looking for.

*********************

Well, this is how you cen get your numeric vector of length 1e6

set.seed(111)
numbers0<-sample(0:9, 1e6, replace=TRUE)

If you want to get this number vector from the file it is better to use lists and lapply but maybe with loop it can be done too

First I prepare some data>

daf<-as.character(numbers0)
index<- 0:(1e6-1)
index<-index%/%5
lll<-split(daf, index)
lll<-lapply(lll, paste, collapse="")
daf<-do.call(rbind, lll)
dim(daf)<-c(20000,10)
daf<-as.data.frame(daf)

# here we have data frame similar to what you can get with read.table
head(daf)
     V1    V2    V3    V4    V5    V6    V7    V8    V9   V10
1 57353 75381 66866 52351 03707 13763 76897 67383 02972 37636
2 40540 52811 02521 18199 23236 64967 70123 46962 95347 47379
3 55001 55094 36922 08811 77704 99060 65902 28279 29131 98979
4 41936 77976 71345 84996 36865 11825 11024 90616 35653 10772
5 42339 89821 23790 62176 03266 36054 34882 06822 10087 05317
6 36275 45199 80796 54458 38836 87953 64394 02685 25788 19502
>
# now it is time transform data.frame to numeric vector
# Change to list, transform to character, split to items, unlist and make numeric
lll<- as.list(daf)
lll<-lapply(lll, as.character)
numbers<-lapply(lll, strsplit,"")
numbers <- as.numeric(unlist(numbers))
length(numbers)
[1] 1000000
> all.equal(numbers, numbers0)
[1] TRUE
>
all this is computed in less than 1 second, is it really so slow?

Cheers
Petr

******************


>
> >
> > lines<-read.table("digits.txt", colClasses="character")
> > numbers<-as.numeric(unlist(strsplit(as.character(lines[1,]),"")))
> > changes first row to numeric vector.
> >
> >
> Do I still need to loop through all lines?
> It is maybe even slower now.
>
> numbers <- vector('numeric')
> for (i in 1:nrows(lines)) {
>   numbers <- c(numbers, as.numeric(unlist(strsplit(as.
> character(lines[i,]),""))))
> }
>
>
> > Anyway, can you explain what is your final goal?
> >
> >
> A numeric vector of length 1 million. Each element should be one digit.
>
>
> > Cheers
> > Petr
> >
> >
> Thanks.
> /Martin
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pdalgd at gmail.com  Fri Sep  8 14:37:50 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Sep 2017 14:37:50 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>
Message-ID: <F562C80A-2224-43B7-AFC8-92618A03FCEF@gmail.com>


> On 8 Sep 2017, at 14:03 , peter dalgaard <pdalgd at gmail.com> wrote:
> 
> x <- scan("~/Downloads/digits.txt")
> x <- x[-seq(1,220000,11)]

...and, come to think of it, if you really want the 1000000 random digits:

xx <- c(outer(x,10^(0:4), "%/%")) %% 10 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From traxplayer at gmail.com  Fri Sep  8 15:51:21 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 8 Sep 2017 15:51:21 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <F562C80A-2224-43B7-AFC8-92618A03FCEF@gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>
 <F562C80A-2224-43B7-AFC8-92618A03FCEF@gmail.com>
Message-ID: <CAGAA5be70Rn9BAhoU7snE70a6ihDWaa=vr5eT4Rag9nBOroa4w@mail.gmail.com>

On 8 September 2017 at 14:37, peter dalgaard <pdalgd at gmail.com> wrote:
>
>
> > On 8 Sep 2017, at 14:03 , peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > x <- scan("~/Downloads/digits.txt")
> > x <- x[-seq(1,220000,11)]
>
> ...and, come to think of it, if you really want the 1000000 random digits:
>
> xx <- c(outer(x,10^(0:4), "%/%")) %% 10
>

Hi Peter,
  Thanks a lot for the answers. I can see that I need to read about outer().
  However I get a different result than expected.

R> x <- scan("digits.txt")
Read 220000 items

R> head(x)
[1]     0 10097 32533 76520 13586 34673

R> x <- x[-seq(1,220000,11)]
R> head(x)
[1] 10097 32533 76520 13586 34673 54876

R> head(c(outer(x,10^(0:4), "%/%")) %% 10, 10) #
[1] 7 3 0 6 3 6  9 7 2 5

Regards
Martin

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Sep  8 16:12:21 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 8 Sep 2017 16:12:21 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <CAGAA5be70Rn9BAhoU7snE70a6ihDWaa=vr5eT4Rag9nBOroa4w@mail.gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>
 <F562C80A-2224-43B7-AFC8-92618A03FCEF@gmail.com>
 <CAGAA5be70Rn9BAhoU7snE70a6ihDWaa=vr5eT4Rag9nBOroa4w@mail.gmail.com>
Message-ID: <D655E578-05CB-42FC-B45D-F3D4EA441218@gmail.com>


> On 8 Sep 2017, at 15:51 , Martin M?ller Skarbiniks Pedersen <traxplayer at gmail.com> wrote:
> 
> On 8 September 2017 at 14:37, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> 
>>> On 8 Sep 2017, at 14:03 , peter dalgaard <pdalgd at gmail.com> wrote:
>>> 
>>> x <- scan("~/Downloads/digits.txt")
>>> x <- x[-seq(1,220000,11)]
>> 
>> ...and, come to think of it, if you really want the 1000000 random digits:
>> 
>> xx <- c(outer(x,10^(0:4), "%/%")) %% 10
>> 
> 
> Hi Peter,
>  Thanks a lot for the answers. I can see that I need to read about outer().
>  However I get a different result than expected.
> 
> R> x <- scan("digits.txt")
> Read 220000 items
> 
> R> head(x)
> [1]     0 10097 32533 76520 13586 34673
> 
> R> x <- x[-seq(1,220000,11)]
> R> head(x)
> [1] 10097 32533 76520 13586 34673 54876
> 
> R> head(c(outer(x,10^(0:4), "%/%")) %% 10, 10) #
> [1] 7 3 0 6 3 6  9 7 2 5
> 

Ah, right. You do get all the digits, but in the order of the last digit of each 5 digit number, then all the penultimate digits, etc. To get digits in the right order, try

> xx <- c(t(outer(x,10^(4:0), "%/%"))) %% 10
> head(xx, 100)
  [1] 1 0 0 9 7 3 2 5 3 3 7 6 5 2 0 1 3 5 8 6 3 4 6 7 3 5 4 8 7 6 8 0 9 5
 [35] 9 0 9 1 1 7 3 9 2 9 2 7 4 9 4 5 3 7 5 4 2 0 4 8 0 5 6 4 8 9 4 7 4 2
 [69] 9 6 2 4 8 0 5 2 4 0 3 7 2 0 6 3 6 1 0 4 0 2 0 0 8 2 2 9 1 6 6 5

I.e., reverse the order of digit generation and transpose the matrix that outer() creates (because matrices are column-major).



> Regards
> Martin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Holger.Taschenberger at mpibpc.mpg.de  Fri Sep  8 15:17:33 2017
From: Holger.Taschenberger at mpibpc.mpg.de (Holger Taschenberger)
Date: Fri, 8 Sep 2017 15:17:33 +0200
Subject: [R] one sample permutation test using package 'coin'
Message-ID: <20170908151732.2F93.C7C4B6F9@mpibpc.mpg.de>

Using the package ?exactRankTests? one can execute a one-sample permutation test for a hypothesized location parameter of 0 like:

perm.test(rnorm(30,0))

The package ?exactRankTests? seems now to be deprecated in favor of the ?coin? package which as I understand is a superset of ?exactRankTests? in terms of functionality.

The ?coin? package allows one to run a two-sample permutation test using oneway_test(...). However, the documentation does not mention a one sample (location) permutation test? Is there a simple way to run such test with ?coin??

Thanks,
        Holger


From maechler at stat.math.ethz.ch  Fri Sep  8 17:09:00 2017
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 8 Sep 2017 17:09:00 +0200
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <D655E578-05CB-42FC-B45D-F3D4EA441218@gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
 <B82F14D4-D41C-427C-883F-947078C53E48@gmail.com>
 <F562C80A-2224-43B7-AFC8-92618A03FCEF@gmail.com>
 <CAGAA5be70Rn9BAhoU7snE70a6ihDWaa=vr5eT4Rag9nBOroa4w@mail.gmail.com>
 <D655E578-05CB-42FC-B45D-F3D4EA441218@gmail.com>
Message-ID: <22962.45708.904777.169714@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Fri, 8 Sep 2017 16:12:21 +0200 writes:

    >> On 8 Sep 2017, at 15:51 , Martin M?ller Skarbiniks
    >> Pedersen <traxplayer at gmail.com> wrote:
    >> 
    >> On 8 September 2017 at 14:37, peter dalgaard
    >> <pdalgd at gmail.com> wrote:
    >>> 
    >>> 
    >>>> On 8 Sep 2017, at 14:03 , peter dalgaard
    >>>> <pdalgd at gmail.com> wrote:
    >>>> 
    >>>> x <- scan("~/Downloads/digits.txt") x <-
    >>>> x[-seq(1,220000,11)]
    >>> 
    >>> ...and, come to think of it, if you really want the
    >>> 1000000 random digits:
    >>> 
    >>> xx <- c(outer(x,10^(0:4), "%/%")) %% 10
    >>> 
    >> 
    >> Hi Peter, Thanks a lot for the answers. I can see that I
    >> need to read about outer().  However I get a different
    >> result than expected.
    >> 
    R> x <- scan("digits.txt")
    >> Read 220000 items
    >> 
    R> head(x)
    >> [1] 0 10097 32533 76520 13586 34673
    >> 
    R> x <- x[-seq(1,220000,11)] head(x)
    >> [1] 10097 32533 76520 13586 34673 54876
    >> 
    R> head(c(outer(x,10^(0:4), "%/%")) %% 10, 10) #
    >> [1] 7 3 0 6 3 6 9 7 2 5
    >> 

    > Ah, right. You do get all the digits, but in the order of
    > the last digit of each 5 digit number, then all the
    > penultimate digits, etc. To get digits in the right order,
    > try

    >> xx <- c(t(outer(x,10^(4:0), "%/%"))) %% 10 head(xx, 100)
    >   [1] 1 0 0 9 7 3 2 5 3 3 7 6 5 2 0 1 3 5 8 6 3 4 6 7 3 5
    > 4 8 7 6 8 0 9 5 [35] 9 0 9 1 1 7 3 9 2 9 2 7 4 9 4 5 3 7 5
    > 4 2 0 4 8 0 5 6 4 8 9 4 7 4 2 [69] 9 6 2 4 8 0 5 2 4 0 3 7
    > 2 0 6 3 6 1 0 4 0 2 0 0 8 2 2 9 1 6 6 5

    > I.e., reverse the order of digit generation and transpose
    > the matrix that outer() creates (because matrices are
    > column-major).

As people are  "exercising" with R and it's Friday:

Try to use  read.fwf() instead of scan() to get to the digits directly,
and see if you get the identical digits, and if it is faster overall or not
[I have no idea of the answer to that].

another Martin.


From wdunlap at tibco.com  Fri Sep  8 17:28:15 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 8 Sep 2017 08:28:15 -0700
Subject: [R] Optimize code to read text-file with digits
In-Reply-To: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
References: <CAGAA5bcyLFRwcEz+kQOazQnEae_KEASp9S8jC38X8SZPMUhMww@mail.gmail.com>
Message-ID: <CAF8bMcaRcH7jraVw+m-ibZh5qyD2ev48Y0koTV_WC_BRYGMmuw@mail.gmail.com>

Remove the for loop and all the [i]'s in your code and it will probably go
faster.  I.e., change

f0 <- function (lines)
{
    numbers <- vector("numeric")
    for (i in 1:length(lines)) {
        lines[i] <- sub("[^ ]+ +", "", lines[i])
        lines[i] <- gsub(" ", "", lines[i])
        numbers <- c(numbers, as.numeric(unlist(strsplit(lines[i],
            ""))))
    }
    numbers
}

to

f1 <- function (lines)
{
    lines <- sub("[^ ]+ +", "", lines)
    lines <- gsub(" ", "", lines)
    as.numeric(unlist(strsplit(lines, "")))
}

I haven't measured it, but the big time sink may come from f0 growing the
'numbers' vector bit by bit.  That can cause a lot of reallocations and
garbage collections.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Sep 8, 2017 at 1:48 AM, Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> Hi,
>
>   Every day I try to write some small R programs to improve my R-skills.
>   Yesterday I wrote a small program to read the digits from "A Million
> Random Digits" from RAND.
>   My code works but it is very slow and I guess the code is not optimal.
>
> The digits.txt file downloaded from
> https://www.rand.org/pubs/monograph_reports/MR1418.html
> contains 20000 lines which looks like this:
> 00000   10097 32533  76520 13586  34673 54876  80959 09117  39292 74945
> 00001   37542 04805  64894 74296  24805 24037  20636 10402  00822 91665
> 00002   08422 68953  19645 09303  23209 02560  15953 34764  35080 33606
> 00003   99019 02529  09376 70715  38311 31165  88676 74397  04436 27659
> 00004   12807 99970  80157 36147  64032 36653  98951 16877  12171 76833
>
> My program which is slow looks like this:
>
> filename <- "digits.txt"
> lines <- readLines(filename)
>
> numbers <- vector('numeric')
> for (i in 1:length(lines)) {
>
>     # remove first column
>     lines[i] <- sub("[^ ]+ +","",lines[i])
>
>     # remove spaces
>     lines[i] <- gsub(" ","",lines[i])
>
>     # split the characters and convert them into numbers
>     numbers <- c(numbers,as.numeric(unlist(strsplit(lines[i],""))))
> }
>
> Thanks for any advice how this program can be improved.
>
> Regards
> Martin M. S. Pedersen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Sep  9 00:54:22 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Sep 2017 15:54:22 -0700
Subject: [R] ISO3 code to 7 continents names
In-Reply-To: <6AD2192C-11BA-4B0C-A186-20DB099F8977@comcast.net>
References: <CAMLwc7MWVGJZf2CQcU=oXuFbOPxzr_jWVENKRsSY=XZc-6SzMQ@mail.gmail.com>
 <BFCA895C-C6F3-4B52-BE64-5C2E9ED4AE1F@comcast.net>
 <CAMLwc7Owm50np8LMtiRRfgeQUbwFVu5+Q7xqUPn1O1N+pTQpdg@mail.gmail.com>
 <6AD2192C-11BA-4B0C-A186-20DB099F8977@comcast.net>
Message-ID: <70EF2414-4A08-466D-895D-6E3A75A81115@comcast.net>


> On Sep 7, 2017, at 12:56 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Sep 7, 2017, at 12:21 PM, Miluji Sb <milujisb at gmail.com> wrote:
>> 
>> df is a data frame consisting of one variable (iso3 codes) such as
>> 
>> USA
>> RUS
>> ARG
>> BGD
>> ITA
>> FRA
>> 
>> 
>> Some of these iso3 codes are repeated and I would like the corresponding continent name, the countrycode package does not seem to distinguish between North and South America. Thanks.
> 
> Well it does actually: There are two different region codes:
> 
> First load the package that has countryExData. I'm presuming this is:
> 
> library(rworldmap)
> 
>> table(countryExData$EPI_regions)
> 
>   Central and Eastern Europ    East Asia and the Pacific                       Europe 
>                          19                           18                           24 
>   Latin America and Caribbe Middle East and North Africa                North America 
>                          24                           19                            2 
>                  South Asia           Sub-Saharan Africa 
>                           5                           38 
>> table(countryExData$GEO_subregion)
> 
>      Arabian Peninsula Australia + New Zealand               Caribbean 
>                      5                       2                       5 
>         Central Africa            Central Asia          Central Europe 
>                      6                       5                      16 
>         Eastern Africa          Eastern Europe                 Mashriq 
>                      7                       7                       4 
>           Meso America           North America          Northeast Asia 
>                      8                       2                       5 
>        Northern Africa           South America              South Asia 
>                      5                      11                       6 
>        South East Asia           South Pacific         Southern Africa 
>                      8                       3                      10 
>         Western Africa          Western Europe    Western Indian Ocean 
>                     13                      19                       2 
> 
> Then create the described dataframe:
> 
> df<- data.frame(iso3=scan(what="") )
> 1: USA
> 2: RUS
> 3: ARG
> 4: BGD
> 5: ITA
> 6: FRA
> 7: 
> Read 6 items
> 
> 
>> region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')$EPI_regions
> 
>> region
> [1] "Latin America and Caribbe" "South Asia"                "Europe"                   
> [4] "Europe"                    "Central and Eastern Europ" "North America"    

Looking at that one might wonder about the degree of success. The ordering of the matched results was not determined by the order in the second df-object:

 merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
  ISO3V10       Country               EPI_regions  GEO_subregion Population2005
1     ARG     Argentina Latin America and Caribbe  South America        38747.2
2     BGD    Bangladesh                South Asia     South Asia       141822.3
3     FRA        France                    Europe Western Europe        60495.5
4     ITA         Italy                    Europe Western Europe        58092.7
5     RUS        Russia Central and Eastern Europ Eastern Europe       143201.6
6     USA United States             North America  North America       298212.9
  GDP_capita.MRYA landlock   landarea density  EPI ENVHEALTH ECOSYSTEM ENVHEALTH.1 AIR_E
1         13652.4        0  2736296.0     1.3 81.8      91.1      72.5        91.1  87.3
2          1916.2        0   136248.1    95.0 58.0      53.6      62.4        53.6  95.7
3         28876.5        0   547106.7    17.9 87.8      99.4      76.2        99.4  95.9
snipped

-- 
David.


> -- 
> David.
> 
>> 
>> Sincerely,
>> 
>> Milu
>> 
>> On Thu, Sep 7, 2017 at 9:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Sep 7, 2017, at 11:36 AM, Miluji Sb <milujisb at gmail.com> wrote:
>>> 
>>> Dear all.
>>> 
>>> Is it possible to convert.identify iso3 country names to the seven
>>> continent names?
>>> 
>>> # Asia, Africa, Antarctica, Australia, Europe, South America, and North
>>> America,
>>> 
>>> I have tried the following:
>>> 
>>> ###
>>> region <- merge(countryExData,df,by.x='ISO3V10',by.y='iso3')
>>> 
>>> where df is the name of my dataset with iso3 the identification variable
>>> but there seems to be a a lot of missing values.
>> 
>> Please provide a sufficient amount of the dataframe named `df` to allow a properly tested response.
>> 
>>> 
>>>      [[alternative HTML version deleted]]
>> 
>> And do read the Posting Guide. This is a plain text mailing list.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>> 
>> 
>> 
>> 
>> 
>> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From axel.urbiz at gmail.com  Sat Sep  9 01:55:01 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 8 Sep 2017 19:55:01 -0400
Subject: [R] quote()/eval() question
Message-ID: <CAAyVsXKhLgabuUjUtYtWhVkFL6L6ud8dXe5fNTS8pZqkCH7ZrQ@mail.gmail.com>

Dear list,

For a reason it would take me long to explain, I need to do something along
the lines of what's shown below -- i.e., create an object from
dplyr::summarise, and then evaluate it on a data frame.

I know I could directly do:

 df %>% dplyr::summarise(x1_mean = mean(x1))

but this is not what I'm looking for.


library(dplyr)

df <- data.frame(x1 = rnorm(100), x2 = rnorm(100))

foo <- function(df) {

  mySummary <- quote(dplyr::summarise(x1_mean = mean(x1)))

  df %>% eval(mySummary)

}

foo(df)

Error in eval(., mySummary) : invalid 'envir' argument of type 'language'

Thank you,
Axel.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Sep  9 03:55:12 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 8 Sep 2017 21:55:12 -0400
Subject: [R] quote()/eval() question
In-Reply-To: <CAAyVsXKhLgabuUjUtYtWhVkFL6L6ud8dXe5fNTS8pZqkCH7ZrQ@mail.gmail.com>
References: <CAAyVsXKhLgabuUjUtYtWhVkFL6L6ud8dXe5fNTS8pZqkCH7ZrQ@mail.gmail.com>
Message-ID: <90e90d9c-5f31-8d37-44e3-9681d29ac5dd@gmail.com>

On 08/09/2017 7:55 PM, Axel Urbiz wrote:
> Dear list,
> 
> For a reason it would take me long to explain, I need to do something along
> the lines of what's shown below -- i.e., create an object from
> dplyr::summarise, and then evaluate it on a data frame.
> 
> I know I could directly do:
> 
>   df %>% dplyr::summarise(x1_mean = mean(x1))
> 
> but this is not what I'm looking for.
> 
> 
> library(dplyr)
> 
> df <- data.frame(x1 = rnorm(100), x2 = rnorm(100))
> 
> foo <- function(df) {
> 
>    mySummary <- quote(dplyr::summarise(x1_mean = mean(x1)))
> 
>    df %>% eval(mySummary)

magrittr pipes are just syntactic sugar.  What your second line does is 
the same as

eval(df, mySummary)

which makes no sense.  These would work:

eval(df, expr = mySummary)
eval(mySummary, envir = df)

You could write the first as

df %>% eval(expr = mySummary)

and the second as

df %>% eval(mySummary, envir = .)

Duncan Murdoch

> 
> }
> 
> foo(df)
> 
> Error in eval(., mySummary) : invalid 'envir' argument of type 'language'
> 
> Thank you,
> Axel.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Sep  9 04:01:03 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Sep 2017 19:01:03 -0700
Subject: [R] quote()/eval() question
In-Reply-To: <CAAyVsXKhLgabuUjUtYtWhVkFL6L6ud8dXe5fNTS8pZqkCH7ZrQ@mail.gmail.com>
References: <CAAyVsXKhLgabuUjUtYtWhVkFL6L6ud8dXe5fNTS8pZqkCH7ZrQ@mail.gmail.com>
Message-ID: <E1320C08-C084-4F82-9B76-B96662E8E1E7@comcast.net>


> On Sep 8, 2017, at 4:55 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Dear list,
> 
> For a reason it would take me long to explain, I need to do something along
> the lines of what's shown below -- i.e., create an object from
> dplyr::summarise, and then evaluate it on a data frame.
> 
> I know I could directly do:
> 
> df %>% dplyr::summarise(x1_mean = mean(x1))
> 
> but this is not what I'm looking for.
> 
> 
> library(dplyr)
> 
> df <- data.frame(x1 = rnorm(100), x2 = rnorm(100))
> 
> foo <- function(df) {
> 
>  mySummary <- quote(dplyr::summarise(x1_mean = mean(x1)))
> 
>  df %>% eval(mySummary)
> 
> }
> 
> foo(df)
> 
> Error in eval(., mySummary) : invalid 'envir' argument of type 'language'

You might get a more informative error message if you didn't use `df` as your local variable. It's the name of a function.

-- 
David.
> 
> Thank you,
> Axel.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From lars52r at gmail.com  Sat Sep  9 12:30:03 2017
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 9 Sep 2017 06:30:03 -0400
Subject: [R] Avoid duplication in dplyr::summarise
Message-ID: <CAO7OmOixJ_1PwMDR4Aveff7KpT3=DNzFisVTQDfy0mgzDmPtUA@mail.gmail.com>

Dear group,

Is there a way I could avoid the sort of duplication illustrated below?
i.e., I have the same dplyr::summarise function on different group_by
arguments. So I'd like to create a single summarise function that could be
applied to both. My attempt below fails.

df <- data.frame(matrix(rnorm(40), 10, 4),
                 f1 = gl(3, 10, labels = letters[1:3]),
                 f2 = gl(3, 10, labels = letters[4:6]))


df %>%
  group_by(f1, f2) %>%
  summarise(x1m = mean(X1),
            x2m = mean(X2),
            x3m = mean(X3),
            x4m = mean(X4))

df %>%
  group_by(f1) %>%
  summarise(x1m = mean(X1),
            x2m = mean(X2),
            x3m = mean(X3),
            x4m = mean(X4))

# My fail attempt

s <- function() {
  dplyr::summarise(x1m = mean(X1),
                   x2m = mean(X2),
                   x3m = mean(X3),
                   x4m = mean(X4))
}

df %>%
  group_by(f1) %>% s
Error in s(.) : unused argument (.)

Regards,
Lars.

	[[alternative HTML version deleted]]


From maklawe at gmail.com  Sat Sep  9 12:52:58 2017
From: maklawe at gmail.com (Edjabou Vincent)
Date: Sat, 9 Sep 2017 12:52:58 +0200
Subject: [R] Avoid duplication in dplyr::summarise
In-Reply-To: <CAO7OmOixJ_1PwMDR4Aveff7KpT3=DNzFisVTQDfy0mgzDmPtUA@mail.gmail.com>
References: <CAO7OmOixJ_1PwMDR4Aveff7KpT3=DNzFisVTQDfy0mgzDmPtUA@mail.gmail.com>
Message-ID: <CALFkoErf4NMCHz94DZQYWoxCK9sunX8wt1U3R4nZpUkmtN2uhw@mail.gmail.com>

Hi Lars

I am not very sure what you really want. However, I am suggesting the
following code that enables (1) to obtain the full summary of your data and
(2) retrieve only mean of X values as function of factors f1 and f2.

library(tidyverse)
library(psych)
df <- data.frame(matrix(rnorm(40), 10, 4),
                 f1 = gl(3, 10, labels = letters[1:3]),
                 f2 = gl(3, 10, labels = letters[4:6]))

##To get all summary of your data
df%>% gather(X_name,X_value,X1:X4)%>%
  group_by(f1,f2,X_name)%>%
  do(describe(.$X_value))

##To obtain only means of your data
df%>% gather(X_name,X_value,X1:X4)%>%
  group_by(f1,f2,X_name)%>%
  do(describe(.$X_value))%>%
  select(mean)%>%# You select only mean value
  spread(X_name,mean)#

Vincent

Med venlig hilsen/ Best regards

Edjabou Maklawe Essonanawe Vincent
Mobile: +45 31 95 99 33

On Sat, Sep 9, 2017 at 12:30 PM, Lars Bishop <lars52r at gmail.com> wrote:

> Dear group,
>
> Is there a way I could avoid the sort of duplication illustrated below?
> i.e., I have the same dplyr::summarise function on different group_by
> arguments. So I'd like to create a single summarise function that could be
> applied to both. My attempt below fails.
>
> df <- data.frame(matrix(rnorm(40), 10, 4),
>                  f1 = gl(3, 10, labels = letters[1:3]),
>                  f2 = gl(3, 10, labels = letters[4:6]))
>
>
> df %>%
>   group_by(f1, f2) %>%
>   summarise(x1m = mean(X1),
>             x2m = mean(X2),
>             x3m = mean(X3),
>             x4m = mean(X4))
>
> df %>%
>   group_by(f1) %>%
>   summarise(x1m = mean(X1),
>             x2m = mean(X2),
>             x3m = mean(X3),
>             x4m = mean(X4))
>
> # My fail attempt
>
> s <- function() {
>   dplyr::summarise(x1m = mean(X1),
>                    x2m = mean(X2),
>                    x3m = mean(X3),
>                    x4m = mean(X4))
> }
>
> df %>%
>   group_by(f1) %>% s
> Error in s(.) : unused argument (.)
>
> Regards,
> Lars.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sat Sep  9 15:02:40 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sat, 9 Sep 2017 16:02:40 +0300
Subject: [R] Avoid duplication in dplyr::summarise
In-Reply-To: <CALFkoErf4NMCHz94DZQYWoxCK9sunX8wt1U3R4nZpUkmtN2uhw@mail.gmail.com>
References: <CAO7OmOixJ_1PwMDR4Aveff7KpT3=DNzFisVTQDfy0mgzDmPtUA@mail.gmail.com>
 <CALFkoErf4NMCHz94DZQYWoxCK9sunX8wt1U3R4nZpUkmtN2uhw@mail.gmail.com>
Message-ID: <CAGgJW75r9edEKzNukueetsi8HLY+6H6KTGm74E5CbuMP-Y5r=A@mail.gmail.com>

Hi Lars,
Two comments:
1. You can achieve what you want with a slight modification of your
definition of s(), using the hint from the error message that you need an
argument '.':
s <- function(.) {
  dplyr::summarise(., x1m = mean(X1),
                   x2m = mean(X2),
                   x3m = mean(X3),
                   x4m = mean(X4))
}

2. You have not given a great test case in how you set your two factors
because the two group_by()'s will give the identical groupings, An
alternative which confirms that the function s() does what you want might
be:

df <- data.frame(matrix(rnorm(40), 10, 4),
                 f1 = base::sample(letters[1:3],30,replace=TRUE),
                 f2 = base::sample(letters[4:6],30,replace=TRUE))

HTH,

Eric

On Sat, Sep 9, 2017 at 1:52 PM, Edjabou Vincent <maklawe at gmail.com> wrote:

> Hi Lars
>
> I am not very sure what you really want. However, I am suggesting the
> following code that enables (1) to obtain the full summary of your data and
> (2) retrieve only mean of X values as function of factors f1 and f2.
>
> library(tidyverse)
> library(psych)
> df <- data.frame(matrix(rnorm(40), 10, 4),
>                  f1 = gl(3, 10, labels = letters[1:3]),
>                  f2 = gl(3, 10, labels = letters[4:6]))
>
> ##To get all summary of your data
> df%>% gather(X_name,X_value,X1:X4)%>%
>   group_by(f1,f2,X_name)%>%
>   do(describe(.$X_value))
>
> ##To obtain only means of your data
> df%>% gather(X_name,X_value,X1:X4)%>%
>   group_by(f1,f2,X_name)%>%
>   do(describe(.$X_value))%>%
>   select(mean)%>%# You select only mean value
>   spread(X_name,mean)#
>
> Vincent
>
> Med venlig hilsen/ Best regards
>
> Edjabou Maklawe Essonanawe Vincent
> Mobile: +45 31 95 99 33
>
> On Sat, Sep 9, 2017 at 12:30 PM, Lars Bishop <lars52r at gmail.com> wrote:
>
> > Dear group,
> >
> > Is there a way I could avoid the sort of duplication illustrated below?
> > i.e., I have the same dplyr::summarise function on different group_by
> > arguments. So I'd like to create a single summarise function that could
> be
> > applied to both. My attempt below fails.
> >
> > df <- data.frame(matrix(rnorm(40), 10, 4),
> >                  f1 = gl(3, 10, labels = letters[1:3]),
> >                  f2 = gl(3, 10, labels = letters[4:6]))
> >
> >
> > df %>%
> >   group_by(f1, f2) %>%
> >   summarise(x1m = mean(X1),
> >             x2m = mean(X2),
> >             x3m = mean(X3),
> >             x4m = mean(X4))
> >
> > df %>%
> >   group_by(f1) %>%
> >   summarise(x1m = mean(X1),
> >             x2m = mean(X2),
> >             x3m = mean(X3),
> >             x4m = mean(X4))
> >
> > # My fail attempt
> >
> > s <- function() {
> >   dplyr::summarise(x1m = mean(X1),
> >                    x2m = mean(X2),
> >                    x3m = mean(X3),
> >                    x4m = mean(X4))
> > }
> >
> > df %>%
> >   group_by(f1) %>% s
> > Error in s(.) : unused argument (.)
> >
> > Regards,
> > Lars.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lars52r at gmail.com  Sat Sep  9 15:23:47 2017
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 9 Sep 2017 09:23:47 -0400
Subject: [R] Avoid duplication in dplyr::summarise
In-Reply-To: <CAGgJW75r9edEKzNukueetsi8HLY+6H6KTGm74E5CbuMP-Y5r=A@mail.gmail.com>
References: <CAO7OmOixJ_1PwMDR4Aveff7KpT3=DNzFisVTQDfy0mgzDmPtUA@mail.gmail.com>
 <CALFkoErf4NMCHz94DZQYWoxCK9sunX8wt1U3R4nZpUkmtN2uhw@mail.gmail.com>
 <CAGgJW75r9edEKzNukueetsi8HLY+6H6KTGm74E5CbuMP-Y5r=A@mail.gmail.com>
Message-ID: <CAO7OmOgB8JTQoC3K1UXrePUr=hryus3fscVJ_ELG-f4yix=icg@mail.gmail.com>

Exactly what I was looking for Eric, thanks!

I agree on your second point.

Best,
Lars.

On Sat, Sep 9, 2017 at 9:02 AM, Eric Berger <ericjberger at gmail.com> wrote:

> Hi Lars,
> Two comments:
> 1. You can achieve what you want with a slight modification of your
> definition of s(), using the hint from the error message that you need an
> argument '.':
> s <- function(.) {
>   dplyr::summarise(., x1m = mean(X1),
>                    x2m = mean(X2),
>                    x3m = mean(X3),
>                    x4m = mean(X4))
> }
>
> 2. You have not given a great test case in how you set your two factors
> because the two group_by()'s will give the identical groupings, An
> alternative which confirms that the function s() does what you want might
> be:
>
> df <- data.frame(matrix(rnorm(40), 10, 4),
>                  f1 = base::sample(letters[1:3],30,replace=TRUE),
>                  f2 = base::sample(letters[4:6],30,replace=TRUE))
>
> HTH,
>
> Eric
>
> On Sat, Sep 9, 2017 at 1:52 PM, Edjabou Vincent <maklawe at gmail.com> wrote:
>
>> Hi Lars
>>
>> I am not very sure what you really want. However, I am suggesting the
>> following code that enables (1) to obtain the full summary of your data
>> and
>> (2) retrieve only mean of X values as function of factors f1 and f2.
>>
>> library(tidyverse)
>> library(psych)
>> df <- data.frame(matrix(rnorm(40), 10, 4),
>>                  f1 = gl(3, 10, labels = letters[1:3]),
>>                  f2 = gl(3, 10, labels = letters[4:6]))
>>
>> ##To get all summary of your data
>> df%>% gather(X_name,X_value,X1:X4)%>%
>>   group_by(f1,f2,X_name)%>%
>>   do(describe(.$X_value))
>>
>> ##To obtain only means of your data
>> df%>% gather(X_name,X_value,X1:X4)%>%
>>   group_by(f1,f2,X_name)%>%
>>   do(describe(.$X_value))%>%
>>   select(mean)%>%# You select only mean value
>>   spread(X_name,mean)#
>>
>> Vincent
>>
>> Med venlig hilsen/ Best regards
>>
>> Edjabou Maklawe Essonanawe Vincent
>> Mobile: +45 31 95 99 33
>>
>> On Sat, Sep 9, 2017 at 12:30 PM, Lars Bishop <lars52r at gmail.com> wrote:
>>
>> > Dear group,
>> >
>> > Is there a way I could avoid the sort of duplication illustrated below?
>> > i.e., I have the same dplyr::summarise function on different group_by
>> > arguments. So I'd like to create a single summarise function that could
>> be
>> > applied to both. My attempt below fails.
>> >
>> > df <- data.frame(matrix(rnorm(40), 10, 4),
>> >                  f1 = gl(3, 10, labels = letters[1:3]),
>> >                  f2 = gl(3, 10, labels = letters[4:6]))
>> >
>> >
>> > df %>%
>> >   group_by(f1, f2) %>%
>> >   summarise(x1m = mean(X1),
>> >             x2m = mean(X2),
>> >             x3m = mean(X3),
>> >             x4m = mean(X4))
>> >
>> > df %>%
>> >   group_by(f1) %>%
>> >   summarise(x1m = mean(X1),
>> >             x2m = mean(X2),
>> >             x3m = mean(X3),
>> >             x4m = mean(X4))
>> >
>> > # My fail attempt
>> >
>> > s <- function() {
>> >   dplyr::summarise(x1m = mean(X1),
>> >                    x2m = mean(X2),
>> >                    x3m = mean(X3),
>> >                    x4m = mean(X4))
>> > }
>> >
>> > df %>%
>> >   group_by(f1) %>% s
>> > Error in s(.) : unused argument (.)
>> >
>> > Regards,
>> > Lars.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Sat Sep  9 14:58:31 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Sat, 9 Sep 2017 12:58:31 +0000 (UTC)
Subject: [R] error with subtree()
References: <695568331.5959980.1504961911483.ref@mail.yahoo.com>
Message-ID: <695568331.5959980.1504961911483@mail.yahoo.com>

Dear R community,
I would like to plot a partial hclust output, so I?am looking for a subtree function that would return an tree structure I can plot.
I ran the test code of subtree following the instruction on?http://finzi.psych.upenn.edu/library/extracat/html/subtree.html
However, an error message popped up:
====> library(extracat)
Attaching package: ?extracat?
The following object is masked _by_ ?.GlobalEnv?:
? ? subtreehc <- hclust(dist(USArrests), "ave")>?> hcs <- subtree(hc, k = 7)Error in subtree(hc, k = 7) : unused argument (k = 7)
===
Can anyone help me what happened here? And what should I do with it?
Thank you very much!
Ace

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Sep  9 18:35:50 2017
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 9 Sep 2017 12:35:50 -0400
Subject: [R] error with subtree()
In-Reply-To: <695568331.5959980.1504961911483@mail.yahoo.com>
References: <695568331.5959980.1504961911483.ref@mail.yahoo.com>
 <695568331.5959980.1504961911483@mail.yahoo.com>
Message-ID: <CAM_vju=rOBEr8sLwE4OJ75Dky9c1YMm+Go0oE2ZZHHZF6AkCLQ@mail.gmail.com>

You appear to already have something named subtree in your environment:

The following object is masked _by_ ?.GlobalEnv?:
    subtree


You could get rid of it, or you could specify that you want to use
subtree from extracat

hcs <- extracat::subtree(hc, k = 7)

Sarah

On Sat, Sep 9, 2017 at 8:58 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> Dear R community,
> I would like to plot a partial hclust output, so I am looking for a subtree function that would return an tree structure I can plot.
> I ran the test code of subtree following the instruction on http://finzi.psych.upenn.edu/library/extracat/html/subtree.html
> However, an error message popped up:
> ====> library(extracat)
> Attaching package: ?extracat?
> The following object is masked _by_ ?.GlobalEnv?:
>     subtreehc <- hclust(dist(USArrests), "ave")> > hcs <- subtree(hc, k = 7)Error in subtree(hc, k = 7) : unused argument (k = 7)
> ===
> Can anyone help me what happened here? And what should I do with it?
> Thank you very much!
> Ace
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From esawiek at gmail.com  Sat Sep  9 20:08:20 2017
From: esawiek at gmail.com (Ek Esawi)
Date: Sat, 9 Sep 2017 14:08:20 -0400
Subject: [R] nested loop
In-Reply-To: <CAJL6Qs9xxH-N7zp-h5LchJHvzLMfiqoNTvBZPvXzh4EsksO0tQ@mail.gmail.com>
References: <CAJL6Qs9xxH-N7zp-h5LchJHvzLMfiqoNTvBZPvXzh4EsksO0tQ@mail.gmail.com>
Message-ID: <CA+ZkTxv=WKLK5v24cGoSQmZ3uO2ND0dhxmp79=dE19V0kTeCFQ@mail.gmail.com>

I would try fininterval as well. It should do what you have asked provided
that you take care of the issue Ulrik pointed out.
Best of luck--EK

On Fri, Sep 8, 2017 at 6:15 AM, Hemant Sain <hemantsain55 at gmail.com> wrote:

> i have a vector containing values ranging from 0 to 24
> i want to create another variable which can categorize those values  like
> this
> please help me with an R code
>
> Thanks
>
> *Value       New_Var*1            0 -5
> 3            0 -5
> 5            0 -5
> 9            6-10
> 7            6-10
> 5            6-10
> 4             0-5
> 11          11-15
> 12         11-15
> 18          16-20
> 23          21 -25
>
> --
> hemantsain.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From andre_mikulec at hotmail.com  Sat Sep  9 20:45:55 2017
From: andre_mikulec at hotmail.com (Andre Mikulec)
Date: Sat, 9 Sep 2017 18:45:55 +0000
Subject: [R] list subselect by name ?
Message-ID: <SN1PR15MB05604FC732ADF3343EC78A6E9C6A0@SN1PR15MB0560.namprd15.prod.outlook.com>

list subselect by name ?
-------------------------

I have this 'list of two elements of named elements.'

> list(letters=letters, LETTERS=LETTERS)[c("letters","LETTERS")]

$letters
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
[20] "t" "u" "v" "w" "x" "y" "z"

$LETTERS
 [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S"
[20] "T" "U" "V" "W" "X" "Y" "Z"

> str( list(letters=letters, LETTERS=LETTERS)[c("letters","LETTERS")] )
List of 2
 $ letters: chr [1:26] "a" "b" "c" "d" ...
 $ LETTERS: chr [1:26] "A" "B" "C" "D" ...

What code do I need to write in place of  ??????????????????
to return a 'list of one element that is named.'

> list(letters=letters, LETTERS=LETTERS)????????????????????

$LETTERS
 [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S"
[20] "T" "U" "V" "W" "X" "Y" "Z"

> str( list(letters=letters, LETTERS=LETTERS)???????????????????? )

List of 1
 $ LETTERS: chr [1:26] "A" "B" "C" "D" ...

Thanks,

Andre Mikulec
Andre_Mikulec at Hotmail.com


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Sep  9 21:20:33 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Sep 2017 12:20:33 -0700
Subject: [R] list subselect by name ?
In-Reply-To: <SN1PR15MB05604FC732ADF3343EC78A6E9C6A0@SN1PR15MB0560.namprd15.prod.outlook.com>
References: <SN1PR15MB05604FC732ADF3343EC78A6E9C6A0@SN1PR15MB0560.namprd15.prod.outlook.com>
Message-ID: <E4D7062C-607D-45E0-BC28-ED64F26DC43B@comcast.net>


> On Sep 9, 2017, at 11:45 AM, Andre Mikulec <andre_mikulec at hotmail.com> wrote:
> 
> list subselect by name ?
> -------------------------
> 
> I have this 'list of two elements of named elements.'
> 
>> list(letters=letters, LETTERS=LETTERS)[c("letters","LETTERS")]
> 
> $letters
> [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
> [20] "t" "u" "v" "w" "x" "y" "z"
> 
> $LETTERS
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S"
> [20] "T" "U" "V" "W" "X" "Y" "Z"
> 
>> str( list(letters=letters, LETTERS=LETTERS)[c("letters","LETTERS")] )
> List of 2
> $ letters: chr [1:26] "a" "b" "c" "d" ...
> $ LETTERS: chr [1:26] "A" "B" "C" "D" ...
> 
> What code do I need to write in place of  ??????????????????
> to return a 'list of one element that is named.'
> 
>> list(letters=letters, LETTERS=LETTERS)????????????????????
> 
> $LETTERS
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N" "O" "P" "Q" "R" "S"
> [20] "T" "U" "V" "W" "X" "Y" "Z"
> 
>> str( list(letters=letters, LETTERS=LETTERS)???????????????????? )
> 
> List of 1
> $ LETTERS: chr [1:26] "A" "B" "C" "D" ...

Wouldn't this just be one of these:

#1
list(letters=letters, LETTERS=LETTERS)["LETTERS"]
#2
list(letters=letters, LETTERS=LETTERS)[2]
#3
mylist <- list(letters=letters, LETTERS=LETTERS)
mylist[ which(names(mylist) == "LETTERS") ]

-- 
David.


> 
> Thanks,
> 
> Andre Mikulec
> Andre_Mikulec at Hotmail.com
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From roy.mendelssohn at noaa.gov  Sat Sep  9 22:01:00 2017
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 9 Sep 2017 13:01:00 -0700
Subject: [R] withr::set_makevars
In-Reply-To: <CAF8bMca8Dc7BGaDb0xCPvzecFftePAJHbT-60Y+qdbbZdk60LQ@mail.gmail.com>
References: <41FAD8F8-1759-4793-9C1C-F78782710EC6@noaa.gov>
 <CAF8bMca8Dc7BGaDb0xCPvzecFftePAJHbT-60Y+qdbbZdk60LQ@mail.gmail.com>
Message-ID: <90D00792-FB93-4968-A083-2ACF9F839EEC@noaa.gov>

As a follow-up to this,  thanks to Bill Dunlap I was able to resolve what was causing this problem (I still had problems with covr::package_coverage() - but of a different sort and not directly related to this report,  I had an existing .R/Makevars file,  created in Nov. 2014 related to the installation of the rstan package. Commenting out some of the rstan specific lines removed this set of error messages.

-Roy




> On Sep 6, 2017, at 5:26 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> withr:::set_makevars() can give that error if the makefile named by the 'old_path' argument (default "~/.R/Makevars) contains more than one definition of a variable of the form 'name=value'.  You can see what file it is reading and its contents by using the trace() function:
> 
> trace(withr:::set_makevars, quote({ cat(old_path, "\n"); writeLines(paste0("    ", tryCatch(readLines(old_path), error=function(e)conditionMessage(e))))}))
> 
> Then run your test and see what file set_makevars is complaining about and what in the file might cause trouble for set_makevars.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Wed, Sep 6, 2017 at 3:41 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> Hi All;
> 
> This problem has come about from trying to learn some of the review practices recommend by rOpensci.  One of them is to use the package goodpractice.  After installing goodpractice, it kept failing on my own packages which are under development, and I was concerned something was funny in my own ,  so I have a fork of the package rerddap,  and I tested goodpractice on that.  I get the error:
> 
> > Error in set_makevars(new, path, makevars_file, assignment = assignment) :
> >   Multiple results for CXXFLAGS found, something is wrong.FALSE
> >
> 
> 
> So after some playing around that is from the very first test,  which uses the covr:package_coverage(), and sure enough running that produces the same error.  Looking at the code,  that error is being thrown by the function withr::set_makevars().  We are now too many layers deep into packages for me to follow what is going on,  but the kicker is Scott Chamberlain can run it without any errors on the same package.  Session_info for both of us follows.  If any one has any suggestions both as to what is causing this and a possible solution,  would appreciate it.
> 
> Roy's sessionInfo is after running the commands:
> 
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp(path = ".", checks = all_checks()[2:230])
> 
> Scott's is after running:
> 
> Sys.setenv(NOT_CRAN = "true")
> x = goodpractice::gp()
> 
> 
> 
> 
> Roy's_session_info()
> ? Session info ??????????????????????????????????????????????????????????????????????????????????????????????????????????????
>  setting  value
>  version  R version 3.4.1 (2017-06-30)
>  os       macOS Sierra 10.12.6
>  system   x86_64, darwin15.6.0
>  ui       RStudio
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
> 
> ? Packages  package      * version     date       source
>  assertthat     0.2.0       2017-04-11 CRAN (R 3.4.1)
>  backports      1.1.0       2017-05-22 CRAN (R 3.4.0)
>  callr          1.0.0.9000  2017-09-02 Github (r-lib/callr at 2dffbbe)
>  clisymbols     1.2.0       2017-09-02 Github (gaborcsardi/clisymbols at e49b4f5)
>  covr           3.0.0       2017-06-26 CRAN (R 3.4.1)
>  crayon         1.3.2.9000  2017-08-25 Github (gaborcsardi/crayon at e4dba3b)
>  cyclocomp      1.1.0       2017-09-02 Github (MangoTheCat/cyclocomp at 6156a12)
>  debugme        1.0.2       2017-03-01 CRAN (R 3.4.0)
>  desc           1.1.1       2017-08-03 CRAN (R 3.4.1)
>  devtools       1.13.3.9000 2017-08-31 Github (hadley/devtools at 91490d1)
>  digest         0.6.12      2017-01-27 CRAN (R 3.4.1)
>  goodpractice * 1.0.0       2017-09-02 Github (MangoTheCat/goodpractice at 9969799)
>  httr           1.3.1       2017-08-20 CRAN (R 3.4.1)
>  igraph         1.1.2       2017-07-21 CRAN (R 3.4.1)
>  jsonlite       1.5         2017-06-01 CRAN (R 3.4.0)
>  knitr          1.17        2017-08-10 CRAN (R 3.4.1)
>  lazyeval       0.2.0       2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1       2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5         2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0       2017-04-21 CRAN (R 3.4.0)
>  pkgbuild       0.0.0.9000  2017-08-31 Github (r-lib/pkgbuild at 6574561)
>  pkgconfig      2.0.1       2017-03-21 CRAN (R 3.4.0)
>  pkgload        0.0.0.9000  2017-08-31 Github (r-pkgs/pkgload at 80a6493)
>  praise         1.0.0       2015-08-11 CRAN (R 3.4.0)
>  processx       2.0.0.1     2017-07-30 CRAN (R 3.4.1)
>  R6             2.2.2       2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1       2016-09-28 CRAN (R 3.4.0)
>  Rcpp           0.12.12     2017-07-15 CRAN (R 3.4.1)
>  remotes        1.1.0       2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1       2016-12-05 CRAN (R 3.4.0)
>  rlang          0.1.2.9000  2017-09-05 Github (tidyverse/rlang at fd64bce)
>  rprojroot      1.2         2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6.0.9000  2017-08-31 Github (rstudio/rstudioapi at e1e466b)
>  sessioninfo    1.0.1       2017-08-31 Github (r-lib/sessioninfo at e813de4)
>  stringi        1.1.5       2017-04-07 CRAN (R 3.4.0)
>  stringr        1.2.0       2017-02-18 CRAN (R 3.4.0)
>  usethis        0.0.0.9000  2017-08-31 Github (r-lib/usethis at 12e6f95)
>  whoami         1.1.1       2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0       2017-07-28 CRAN (R 3.4.1)
>  xml2           1.1.1       2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1       2016-06-18 CRAN (R 3.4.0)
>  yaml           2.1.14      2016-11-12 CRAN (R 3.4.0)
> 
> 
> Scott's _ sessionInfo()
> Session info ------------------------------------------------------------------
>  setting  value
>  version  R version 3.4.1 Patched (2017-07-04 r72893)
>  system   x86_64, darwin15.6.0
>  ui       X11
>  language (EN)
>  collate  en_US.UTF-8
>  tz       America/Los_Angeles
>  date     2017-09-06
> 
> Packages ----------------------------------------------------------------------
>  package      * version    date       source
>  assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)
>  backports      1.1.0      2017-05-22 CRAN (R 3.4.0)
>  base         * 3.4.1      2017-07-06 local
>  callr          1.0.0.9000 2017-07-31 Github (r-lib/callr at ce3f15c)
>  clisymbols     1.2.0      2017-06-10 Github (gaborcsardi/clisymbols at 83b13a0)
>  compiler       3.4.1      2017-07-06 local
>  covr           3.0.0      2017-06-26 CRAN (R 3.4.0)
>  crayon         1.3.2.9000 2017-07-31 Github (gaborcsardi/crayon at 750190f)
>  cyclocomp      1.1.0      2017-05-04 Github (MangoTheCat/cyclocomp at 6156a12)
>  datasets     * 3.4.1      2017-07-06 local
>  debugme        1.0.2      2017-03-01 cran (@1.0.2)
>  desc           1.1.1      2017-08-03 CRAN (R 3.4.1)
>  devtools     * 1.13.3     2017-08-02 CRAN (R 3.4.1)
>  digest         0.6.12     2017-01-27 CRAN (R 3.4.0)
>  goodpractice   1.0.0      2017-06-10 Github (MangoTheCat/goodpractice at 9969799)
>  graphics     * 3.4.1      2017-07-06 local
>  grDevices    * 3.4.1      2017-07-06 local
>  httr           1.3.1      2017-08-20 CRAN (R 3.4.1)
>  jsonlite       1.5        2017-06-01 CRAN (R 3.4.0)
>  lazyeval       0.2.0      2016-06-12 CRAN (R 3.4.0)
>  lintr          1.0.1      2017-08-10 CRAN (R 3.4.1)
>  magrittr       1.5        2014-11-22 CRAN (R 3.4.0)
>  memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)
>  methods      * 3.4.1      2017-07-06 local
>  praise         1.0.0      2015-08-11 CRAN (R 3.4.0)
>  prettyunits    1.0.2      2015-07-13 CRAN (R 3.4.0)
>  processx       2.0.1.9000 2017-07-31 Github (r-lib/processx at c02b0f3)
>  R6             2.2.2      2017-06-17 CRAN (R 3.4.0)
>  rcmdcheck      1.2.1.9000 2017-06-10 Github (r-pkgs/rcmdcheck at a18119c)
>  Rcpp           0.12.12    2017-07-15 cran (@0.12.12)
>  remotes        1.1.0      2017-07-09 CRAN (R 3.4.1)
>  rex            1.1.1      2016-03-11 CRAN (R 3.4.0)
>  rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)
>  rstudioapi     0.6        2016-06-27 CRAN (R 3.4.0)
>  stats        * 3.4.1      2017-07-06 local
>  tools          3.4.1      2017-07-06 local
>  utils        * 3.4.1      2017-07-06 local
>  whoami         1.1.1      2015-07-13 CRAN (R 3.4.0)
>  withr          2.0.0      2017-09-05 Github (jimhester/withr at eff4818)
>  xml2           1.1.1      2017-01-24 CRAN (R 3.4.0)
>  xmlparsedata   1.0.1      2016-06-18 cran (@1.0.1)
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pmakananisa at sars.gov.za  Mon Sep 11 10:05:52 2017
From: pmakananisa at sars.gov.za (Mangalani Peter Makananisa)
Date: Mon, 11 Sep 2017 08:05:52 +0000
Subject: [R] Case statement in sqldf
Message-ID: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>

Hi all,

I am trying to create a new  variable called Fiscal Year (FY) using case expression in sqldf  and I am getting a null FY , see the code below .

Please advise me as to how I can do this mutation.

  library(zoo)
  library(lubridate)
  library(stringr)
  library(RH2)
  library(sqldf)

cr$ReportDate = as.Date(cr$ReportDate, format ='%Y-%m-%d')

> cr2 =  sqldf(" select ReportDate
+                      ,  case
+                        when ReportDate between  '2012-04-01'  and  '2013-03-31'
+                        then '2012_13'
+                        when  ReportDate between '2013-04-01'  and  '2014-03-31'
+                        then '2013_14'
+                        when  ReportDate between  '2014-04-01'  and  '2015-03-31'
+                        then'201415'
+                        when ReportDate between '2015-04-01'  and  '2016-03-31'
+                        then '2015_16'
+                        when ReportDate between '2016-04-01'  and  '2017-03-31'
+                        then '2016_17'
+                        when ReportDate between '2017-04-01'  and  '2018-03-3'
+                        then '2017_18' else null
+                        end as FY
+               from cr
+              where  ReportDate  >=  '2012-04-01'
+              ")

Thanking you in advance

Kind regards,

Mangalani Peter Makananisa (0005786)
South African Revenue Service (SARS)
Specialist: Statistical Support
TCEI_OR (Head Office)
Tell: +272 422 7357, Cell: +2782 456 4669

Please Note: This email and its contents are subject to our email legal notice which can be viewed at http://www.sars.gov.za/Pages/Email-disclaimer.aspx

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Sep 11 17:18:48 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 11 Sep 2017 08:18:48 -0700
Subject: [R] Case statement in sqldf
In-Reply-To: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
References: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
Message-ID: <D462FB85-EC13-48FB-8DBB-8ADC10BCA607@comcast.net>


> On Sep 11, 2017, at 1:05 AM, Mangalani Peter Makananisa <pmakananisa at sars.gov.za> wrote:
> 
> Hi all,
> 
> I am trying to create a new  variable called Fiscal Year (FY) using case expression in sqldf  and I am getting a null FY , see the code below .
> 
> Please advise me as to how I can do this mutation.
> 
>  library(zoo)
>  library(lubridate)
>  library(stringr)
>  library(RH2)
>  library(sqldf)
> 
> cr$ReportDate = as.Date(cr$ReportDate, format ='%Y-%m-%d')
> 
>> cr2 =  sqldf(" select ReportDate
> +                      ,  case
> +                        when ReportDate between  '2012-04-01'  and  '2013-03-31'
> +                        then '2012_13'
> +                        when  ReportDate between '2013-04-01'  and  '2014-03-31'
> +                        then '2013_14'
> +                        when  ReportDate between  '2014-04-01'  and  '2015-03-31'
> +                        then'201415'
> +                        when ReportDate between '2015-04-01'  and  '2016-03-31'
> +                        then '2015_16'
> +                        when ReportDate between '2016-04-01'  and  '2017-03-31'
> +                        then '2016_17'
> +                        when ReportDate between '2017-04-01'  and  '2018-03-3'
> +                        then '2017_18' else null
> +                        end as FY
> +               from cr
> +              where  ReportDate  >=  '2012-04-01'
> +              ")

There was no cr object in any of the package I loaded although `lubridate` and `stringr` appear unnecessary and were omitted. I get no error with your code using this test object:

 cr <- data.frame(ReportDate = seq(as.Date("1970-01-01"), as.Date("2020-01-01"), by="1 year" ))

> cr2 =  sqldf(" select ReportDate
+                      ,  case
+                        when ReportDate between  '2012-04-01'  and  '2013-03-31'
+                        then '2012_13'
+                        when  ReportDate between '2013-04-01'  and  '2014-03-31'
+                        then '2013_14'
+                        when  ReportDate between  '2014-04-01'  and  '2015-03-31'
+                        then'201415'
+                        when ReportDate between '2015-04-01'  and  '2016-03-31'
+                        then '2015_16'
+                        when ReportDate between '2016-04-01'  and  '2017-03-31'
+                        then '2016_17'
+                        when ReportDate between '2017-04-01'  and  '2018-03-3'
+                        then '2017_18' else null
+                        end as FY
+               from cr
+              where  ReportDate  >=  '2012-04-01'
+              ")
> 
> str(cr2)
'data.frame':	8 obs. of  2 variables:
 $ ReportDate: Date, format: "2013-01-01" "2014-01-01" "2015-01-01" ...
 $ FY        : chr  "2012_13" "2013_14" "201415" "2015_16" ...
> 
> 
> Thanking you in advance
> 
> Kind regards,
> 
> Mangalani Peter Makananisa (0005786)
> South African Revenue Service (SARS)
> Specialist: Statistical Support
> TCEI_OR (Head Office)
> Tell: +272 422 7357, Cell: +2782 456 4669
> 
> Please Note: This email and its contents are subject to our email legal notice which can be viewed at http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ggrothendieck at gmail.com  Mon Sep 11 18:50:15 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 11 Sep 2017 12:50:15 -0400
Subject: [R] Case statement in sqldf
In-Reply-To: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
References: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
Message-ID: <CAP01uRnz+7mehMb0vhzGjRK40mXzCU6qtcR_pn0MoOV3dVTMgQ@mail.gmail.com>

2018-03-3 in your code should be 2018-03-31.

The line
    then'201415'
needs to be fixed.

When posting please provide minimal self-contained examples. There was
no input provided and library statements not relevant to the posted
code were included.

Fixing the invalid date and bad line, getting rid of those library
statements that are unnecessary and providing some test input, it
works for me for the input shown.

(Note that it would NOT work if we omitted library(RH2) since the
default sqlite back end does not have date types and does not know
that an R date -- which is sent to sqlite as the number of days since
1970-01-01 -- corresponds to a particular character string; however,
the H2 database does have date types.  See FAQ #4 on the sqldf github
home page for more info.
    https://github.com/ggrothendieck/sqldf
)

This works:

library(sqldf)
library(RH2)

cr <- data.frame(ReportDate = as.Date("2017-09-11")) # input

cr2 =  sqldf(" select ReportDate
                     ,  case
                       when ReportDate between  '2012-04-01'  and  '2013-03-31'
                       then '2012_13'
                       when  ReportDate between '2013-04-01'  and  '2014-03-31'
                       then '2013_14'
                       when  ReportDate between  '2014-04-01'  and  '2015-03-31'
                       then '2014_15'
                       when ReportDate between '2015-04-01'  and  '2016-03-31'
                       then '2015_16'
                       when ReportDate between '2016-04-01'  and  '2017-03-31'
                       then '2016_17'
                       when ReportDate between '2017-04-01'  and  '2018-03-31'
                      then '2017_18' else null
             end as FY
             from cr
             where  ReportDate  >=  '2012-04-01'
             ")

giving:

  > cr2
    ReportDate      FY
  1 2017-09-11 2017_18

Note that using as.yearqtr from zoo this alternative could be used:

library(zoo)
cr <- data.frame(ReportDate = as.Date("2017-09-11")) # input

fy <- as.integer(as.yearqtr(cr$ReportDate) + 3/4)
transform(cr, FY = paste0(fy-1, "_", fy %% 100))

giving:

  ReportDate      FY
1 2017-09-11 2017_18


On Mon, Sep 11, 2017 at 4:05 AM, Mangalani Peter Makananisa
<pmakananisa at sars.gov.za> wrote:
> Hi all,
>
>
>
> I am trying to create a new  variable called Fiscal Year (FY) using case
> expression in sqldf  and I am getting a null FY , see the code below .
>
>
>> +                        then '2017_18' else null>> South African Revenue Service (SARS)>> Specialist: Statistical Support>> TCEI_OR (Head Office)>> Tell: +272 422 7357, Cell: +2782 456 4669>> http://www.sars.gov.za/Pages/Email-disclaimer.aspxemail: ggrothendieck at gmail.with
> Please advise me as to how I can do this mutation.
>
>
>
>   library(zoo)
>
>   library(lubridate)
>
>   library(stringr)
>
>   library(RH2)
>
>   library(sqldf)
>
>
>
> cr$ReportDate = as.Date(cr$ReportDate, format ='%Y-%m-%d')
>
>
>
>> cr2 =  sqldf(" select ReportDate
>
> +                      ,  case
>
> +                        when ReportDate between  '2012-04-01'  and
> '2013-03-31'
>
> +                        then '2012_13'
>
> +                        when  ReportDate between '2013-04-01'  and
> '2014-03-31'
>
> +                        then '2013_14'
>
> +                        when  ReportDate between  '2014-04-01'  and
> '2015-03-31'
>
> +                        then'201415'
>
> +                        when ReportDate between '2015-04-01'  and
> '2016-03-31'
>
> +                        then '2015_16'
>
> +                        when ReportDate between '2016-04-01'  and
> '2017-03-31'
>
> +                        then '2016_17'
>
> +                        when ReportDate between '2017-04-01'  and
> '2018-03-3'
>


> +                        end as FY
>
> +               from cr
>
> +              where  ReportDate  >=  '2012-04-01'
>
> +              ")
>
>
>
> Thanking you in advance
>
>
>
> Kind regards,
>
>
>
> Mangalani Peter Makananisa (0005786)
>








>
>
>
>
> Disclaimer
>
> Please Note: This email and its contents are subject to our email legal
> notice which can be viewed at




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP


From christian at echoffmann.ch  Mon Sep 11 17:31:48 2017
From: christian at echoffmann.ch (Christian)
Date: Mon, 11 Sep 2017 17:31:48 +0200
Subject: [R] M-x R gives no choice of starting dir
Message-ID: <65f0acc4-ea1c-0a62-7092-d5b071c8d62c@echoffmann.ch>

Hi,

I experienced a sudden change in the behavior of M-x R in not giving me 
the choice where to start R. May be that I botched my preferences. I am 
using Aquamacs 3.3 on MacOS 10.12.6

Christian
-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From pdalgd at gmail.com  Mon Sep 11 20:48:31 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Sep 2017 20:48:31 +0200
Subject: [R] M-x R gives no choice of starting dir
In-Reply-To: <65f0acc4-ea1c-0a62-7092-d5b071c8d62c@echoffmann.ch>
References: <65f0acc4-ea1c-0a62-7092-d5b071c8d62c@echoffmann.ch>
Message-ID: <D6A30B1F-CD39-4C16-84EC-DFE305913BB1@gmail.com>

There's an ESS mailing list... However, I'm not seeing that behaviour with a similar setup.

-pd

> On 11 Sep 2017, at 17:31 , Christian <christian at echoffmann.ch> wrote:
> 
> Hi,
> 
> I experienced a sudden change in the behavior of M-x R in not giving me the choice where to start R. May be that I botched my preferences. I am using Aquamacs 3.3 on MacOS 10.12.6
> 
> Christian
> -- 
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From liuwensui at gmail.com  Mon Sep 11 21:37:41 2017
From: liuwensui at gmail.com (Wensui Liu)
Date: Mon, 11 Sep 2017 14:37:41 -0500
Subject: [R] M-x R gives no choice of starting dir
In-Reply-To: <65f0acc4-ea1c-0a62-7092-d5b071c8d62c@echoffmann.ch>
References: <65f0acc4-ea1c-0a62-7092-d5b071c8d62c@echoffmann.ch>
Message-ID: <CAKyN3iD9WH5cWw8szQDJ0-auJOcr5meTs-9SfjyrFzU42MhAGg@mail.gmail.com>

i am using emacs on ubuntu and have no such issue.

On Mon, Sep 11, 2017 at 10:31 AM, Christian <christian at echoffmann.ch> wrote:

> Hi,
>
> I experienced a sudden change in the behavior of M-x R in not giving me
> the choice where to start R. May be that I botched my preferences. I am
> using Aquamacs 3.3 on MacOS 10.12.6
>
> Christian
> --
> Christian Hoffmann
> Rigiblickstrasse 15b
> <https://maps.google.com/?q=Rigiblickstrasse+15b&entry=gmail&source=g>
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Mon Sep 11 21:33:25 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 11 Sep 2017 19:33:25 +0000 (UTC)
Subject: [R] show 0 at y axis in xyplot lattice
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
Message-ID: <1469577140.12370527.1505158405851@mail.yahoo.com>

Dear all
I am trying to make a plot in xyplot lattice by groups. I would like to show "0" in y axis but I don't want to be aligned with the x axis. I want to be a little bit above.
I have tried many options but I don't get what I want. I also tried ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the upper boundary of the plot, respectively:
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
?????? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
?????? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
?????? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
?????? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
?????? panel = function(x, y, ...) {
???????? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")?????????????? 
???????? panel.abline(v=sdate, lwd=1, lty=3, col="grey")????????????? 
???????? panel.xyplot(x, y, ...)
???????? }
???????? )
when I use the following, 80 is a bit lower than the upper boundary of the plot, which is what I want, but 0 is not showing:?
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), 
?????? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
?????? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
?????? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
?????? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
?????? panel = function(x, y, ...) {
???????? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")?????????????? 
???????? panel.abline(v=sdate, lwd=1, lty=3, col="grey")????????????? 
???????? panel.xyplot(x, y, ...)
???????? }
???????? )I have also attached a reproducible example in case you want to see in more detail my data.?
I would very much appreciate any suggestions on this.?
Thank you in advance.
Kind regards,Maria
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: savedat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170911/9910a9f7/attachment.txt>

From bgunter.4567 at gmail.com  Mon Sep 11 23:15:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 11 Sep 2017 14:15:55 -0700
Subject: [R] show 0 at y axis in xyplot lattice
In-Reply-To: <1469577140.12370527.1505158405851@mail.yahoo.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
Message-ID: <CAGxFJbR7qyLdTPz52=1hD-CHUtcyEwW23cqM-wAAiZN0w4oYrw@mail.gmail.com>

1. Not reproducible since my.settings, dat_key, sdate not provided.

2. Why did you not try something like ylim = c(-5,80)  ?


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 11, 2017 at 12:33 PM, Maria Lathouri via R-help <
r-help at r-project.org> wrote:

> Dear all
> I am trying to make a plot in xyplot lattice by groups. I would like to
> show "0" in y axis but I don't want to be aligned with the x axis. I want
> to be a little bit above.
> I have tried many options but I don't get what I want. I also tried
> ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the
> upper boundary of the plot, respectively:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
> par.strip.text=list(col="white", font=2, lines=1.5),
>        lattice.options = modifyList(lattice.options(),
> list(skip.boundary.labels = 0)),
>        par.settings=my.settings, col=c("red", "black", "red"),
> fill=c("red", "black", "red"),
>        key=dat_key, scales = list(x = list(at = sdate, labels =
> format(sdate, "%b-%y"))), xlab="Date",
>        panel = function(x, y, ...) {
>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>          panel.xyplot(x, y, ...)
>          }
>          )
> when I use the following, 80 is a bit lower than the upper boundary of the
> plot, which is what I want, but 0 is not showing:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
> par.strip.text=list(col="white", font=2, lines=1.5),
>        lattice.options = modifyList(lattice.options(),
> list(skip.boundary.labels = 0)),
>        par.settings=my.settings, col=c("red", "black", "red"),
> fill=c("red", "black", "red"),
>        key=dat_key, scales = list(x = list(at = sdate, labels =
> format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
>        panel = function(x, y, ...) {
>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>          panel.xyplot(x, y, ...)
>          }
>          )I have also attached a reproducible example in case you want to
> see in more detail my data.
> I would very much appreciate any suggestions on this.
> Thank you in advance.
> Kind regards,Maria
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Mon Sep 11 23:38:11 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 11 Sep 2017 21:38:11 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBzaG93IDAgYXQgeSBheGlzIGluIHh5cGxv?=
 =?utf-8?q?t_lattice?=
In-Reply-To: <CAGxFJbR7qyLdTPz52=1hD-CHUtcyEwW23cqM-wAAiZN0w4oYrw@mail.gmail.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <CAGxFJbR7qyLdTPz52=1hD-CHUtcyEwW23cqM-wAAiZN0w4oYrw@mail.gmail.com>
Message-ID: <1004919432.12492194.1505165891534@mail.yahoo.com>

Dear Bert and all,
I am really sorry. This is the full code:
dat<-read.csv("example.csv")attach(dat)
sdate<-as.Date(Date, format="%Y-%m-%d")
#change the colour of the strip background
my.settings <- canonical.theme(color=FALSE)
my.settings[['strip.background']]$col <- "blue"
dat_key <- list(space="right", 
??????????????? lines = list(type = c("b", "b", "b"), pch=c(22, 21, 22), col = c("red", "black", "red"), 
???????????????????????????? fill=c("red", "black", "red"), lwd=1, lty=c(2, 1, 2)), 
??????????????? text = list((c("upper se", (expression(paste(Zn^paste(2,"+")))), "lower se"))))
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), 
?????? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
?????? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
?????? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
?????? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
?????? panel = function(x, y, ...) {
???????? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")?????????????? 
???????? panel.abline(v=sdate, lwd=1, lty=3, col="grey")????????????? 
???????? panel.xyplot(x, y, ...)
???????? }
???????? )
Hope this helps.?
Kind regards,Maria 

    ???? 10:15 ?.?. ???????, 11 ??????????? 2017, ?/? Bert Gunter <bgunter.4567 at gmail.com> ??????:
 

 1. Not reproducible since my.settings, dat_key, sdate not provided.

2. Why did you not try something like ylim = c(-5,80)? ?


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 11, 2017 at 12:33 PM, Maria Lathouri via R-help <r-help at r-project.org> wrote:

Dear all
I am trying to make a plot in xyplot lattice by groups. I would like to show "0" in y axis but I don't want to be aligned with the x axis. I want to be a little bit above.
I have tried many options but I don't get what I want. I also tried ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the upper boundary of the plot, respectively:
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
?????? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col=" white", font=2, lines=1.5),
?????? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
?????? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
?????? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
?????? panel = function(x, y, ...) {
???????? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")??????????????
???????? panel.abline(v=sdate, lwd=1, lty=3, col="grey")?????????????
???????? panel.xyplot(x, y, ...)
???????? }
???????? )
when I use the following, 80 is a bit lower than the upper boundary of the plot, which is what I want, but 0 is not showing:?
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
?????? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col=" white", font=2, lines=1.5),
?????? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
?????? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
?????? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
?????? panel = function(x, y, ...) {
???????? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")??????????????
???????? panel.abline(v=sdate, lwd=1, lty=3, col="grey")?????????????
???????? panel.xyplot(x, y, ...)
???????? }
???????? )I have also attached a reproducible example in case you want to see in more detail my data.?
I would very much appreciate any suggestions on this.?
Thank you in advance.
Kind regards,Maria
______________________________ ________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 12 00:50:29 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 11 Sep 2017 15:50:29 -0700
Subject: [R] show 0 at y axis in xyplot lattice
In-Reply-To: <1004919432.12492194.1505165891534@mail.yahoo.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <CAGxFJbR7qyLdTPz52=1hD-CHUtcyEwW23cqM-wAAiZN0w4oYrw@mail.gmail.com>
 <1004919432.12492194.1505165891534@mail.yahoo.com>
Message-ID: <CAGxFJbSOZsvO0MX+fOd9i3J2hx3pbK9yu5Z1pbD_0gtqCYjVGA@mail.gmail.com>

Not reproducible, as we have neither "example.csv" nor "Date" .

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 11, 2017 at 2:38 PM, Maria Lathouri <mlathouri at yahoo.gr> wrote:

> Dear Bert and all,
>
> I am really sorry. This is the full code:
>
> dat<-read.csv("example.csv")
> attach(dat)
>
> sdate<-as.Date(Date, format="%Y-%m-%d")
>
> #change the colour of the strip background
> my.settings <- canonical.theme(color=FALSE)
> my.settings[['strip.background']]$col <- "blue"
>
> dat_key <- list(space="right",
>                 lines = list(type = c("b", "b", "b"), pch=c(22, 21, 22),
> col = c("red", "black", "red"),
>                              fill=c("red", "black", "red"), lwd=1,
> lty=c(2, 1, 2)),
>                 text = list((c("upper se", (expression(paste(Zn^paste(2,"+")))),
> "lower se"))))
>
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
> par.strip.text=list(col="white", font=2, lines=1.5),
>        lattice.options = modifyList(lattice.options(),
> list(skip.boundary.labels = 0)),
>        par.settings=my.settings, col=c("red", "black", "red"),
> fill=c("red", "black", "red"),
>        key=dat_key, scales = list(x = list(at = sdate, labels =
> format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
>        panel = function(x, y, ...) {
>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>          panel.xyplot(x, y, ...)
>          }
>          )
>
> Hope this helps.
>
> Kind regards,
> Maria
>
>
> ???? 10:15 ?.?. ???????, 11 ??????????? 2017, ?/? Bert Gunter <
> bgunter.4567 at gmail.com> ??????:
>
>
> 1. Not reproducible since my.settings, dat_key, sdate not provided.
>
> 2. Why did you not try something like ylim = c(-5,80)  ?
>
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Sep 11, 2017 at 12:33 PM, Maria Lathouri via R-help <
> r-help at r-project.org> wrote:
>
> Dear all
> I am trying to make a plot in xyplot lattice by groups. I would like to
> show "0" in y axis but I don't want to be aligned with the x axis. I want
> to be a little bit above.
> I have tried many options but I don't get what I want. I also tried
> ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the
> upper boundary of the plot, respectively:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
> par.strip.text=list(col=" white", font=2, lines=1.5),
>        lattice.options = modifyList(lattice.options(),
> list(skip.boundary.labels = 0)),
>        par.settings=my.settings, col=c("red", "black", "red"),
> fill=c("red", "black", "red"),
>        key=dat_key, scales = list(x = list(at = sdate, labels =
> format(sdate, "%b-%y"))), xlab="Date",
>        panel = function(x, y, ...) {
>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>          panel.xyplot(x, y, ...)
>          }
>          )
> when I use the following, 80 is a bit lower than the upper boundary of the
> plot, which is what I want, but 0 is not showing:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
> par.strip.text=list(col=" white", font=2, lines=1.5),
>        lattice.options = modifyList(lattice.options(),
> list(skip.boundary.labels = 0)),
>        par.settings=my.settings, col=c("red", "black", "red"),
> fill=c("red", "black", "red"),
>        key=dat_key, scales = list(x = list(at = sdate, labels =
> format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
>        panel = function(x, y, ...) {
>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>          panel.xyplot(x, y, ...)
>          }
>          )I have also attached a reproducible example in case you want to
> see in more detail my data.
> I would very much appreciate any suggestions on this.
> Thank you in advance.
> Kind regards,Maria
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 12 01:36:58 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 11 Sep 2017 16:36:58 -0700
Subject: [R] show 0 at y axis in xyplot lattice
In-Reply-To: <CAGxFJbSOZsvO0MX+fOd9i3J2hx3pbK9yu5Z1pbD_0gtqCYjVGA@mail.gmail.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <CAGxFJbR7qyLdTPz52=1hD-CHUtcyEwW23cqM-wAAiZN0w4oYrw@mail.gmail.com>
 <1004919432.12492194.1505165891534@mail.yahoo.com>
 <CAGxFJbSOZsvO0MX+fOd9i3J2hx3pbK9yu5Z1pbD_0gtqCYjVGA@mail.gmail.com>
Message-ID: <B43E02BD-7650-418E-B135-9D1D5D5C90A8@dcn.davis.ca.us>

I recommend that Maria read [1], [2] and especially [3], since the latter helps you verify that your example is in fact reproducible before sending it out for us to have problems with and complain about. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

-- 
Sent from my phone. Please excuse my brevity.

On September 11, 2017 3:50:29 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Not reproducible, as we have neither "example.csv" nor "Date" .
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Mon, Sep 11, 2017 at 2:38 PM, Maria Lathouri <mlathouri at yahoo.gr>
>wrote:
>
>> Dear Bert and all,
>>
>> I am really sorry. This is the full code:
>>
>> dat<-read.csv("example.csv")
>> attach(dat)
>>
>> sdate<-as.Date(Date, format="%Y-%m-%d")
>>
>> #change the colour of the strip background
>> my.settings <- canonical.theme(color=FALSE)
>> my.settings[['strip.background']]$col <- "blue"
>>
>> dat_key <- list(space="right",
>>                 lines = list(type = c("b", "b", "b"), pch=c(22, 21,
>22),
>> col = c("red", "black", "red"),
>>                              fill=c("red", "black", "red"), lwd=1,
>> lty=c(2, 1, 2)),
>>                 text = list((c("upper se",
>(expression(paste(Zn^paste(2,"+")))),
>> "lower se"))))
>>
>> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
>> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
>> par.strip.text=list(col="white", font=2, lines=1.5),
>>        lattice.options = modifyList(lattice.options(),
>> list(skip.boundary.labels = 0)),
>>        par.settings=my.settings, col=c("red", "black", "red"),
>> fill=c("red", "black", "red"),
>>        key=dat_key, scales = list(x = list(at = sdate, labels =
>> format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))),
>xlab="Date",
>>        panel = function(x, y, ...) {
>>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>>          panel.xyplot(x, y, ...)
>>          }
>>          )
>>
>> Hope this helps.
>>
>> Kind regards,
>> Maria
>>
>>
>> ???? 10:15 ?.?. ???????, 11 ??????????? 2017, ?/? Bert Gunter <
>> bgunter.4567 at gmail.com> ??????:
>>
>>
>> 1. Not reproducible since my.settings, dat_key, sdate not provided.
>>
>> 2. Why did you not try something like ylim = c(-5,80)  ?
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Sep 11, 2017 at 12:33 PM, Maria Lathouri via R-help <
>> r-help at r-project.org> wrote:
>>
>> Dear all
>> I am trying to make a plot in xyplot lattice by groups. I would like
>to
>> show "0" in y axis but I don't want to be aligned with the x axis. I
>want
>> to be a little bit above.
>> I have tried many options but I don't get what I want. I also tried
>> ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and
>the
>> upper boundary of the plot, respectively:
>> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
>> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0,
>80),
>>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
>> par.strip.text=list(col=" white", font=2, lines=1.5),
>>        lattice.options = modifyList(lattice.options(),
>> list(skip.boundary.labels = 0)),
>>        par.settings=my.settings, col=c("red", "black", "red"),
>> fill=c("red", "black", "red"),
>>        key=dat_key, scales = list(x = list(at = sdate, labels =
>> format(sdate, "%b-%y"))), xlab="Date",
>>        panel = function(x, y, ...) {
>>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>>          panel.xyplot(x, y, ...)
>>          }
>>          )
>> when I use the following, 80 is a bit lower than the upper boundary
>of the
>> plot, which is what I want, but 0 is not showing:
>> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
>> as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>>        index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
>> par.strip.text=list(col=" white", font=2, lines=1.5),
>>        lattice.options = modifyList(lattice.options(),
>> list(skip.boundary.labels = 0)),
>>        par.settings=my.settings, col=c("red", "black", "red"),
>> fill=c("red", "black", "red"),
>>        key=dat_key, scales = list(x = list(at = sdate, labels =
>> format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))),
>xlab="Date",
>>        panel = function(x, y, ...) {
>>          panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>          panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>>          panel.xyplot(x, y, ...)
>>          }
>>          )I have also attached a reproducible example in case you
>want to
>> see in more detail my data.
>> I would very much appreciate any suggestions on this.
>> Thank you in advance.
>> Kind regards,Maria
>> ______________________________ ________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/ listinfo/r-help
>> <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Tue Sep 12 03:11:28 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 12 Sep 2017 11:11:28 +1000
Subject: [R] show 0 at y axis in xyplot lattice
In-Reply-To: <1469577140.12370527.1505158405851@mail.yahoo.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
Message-ID: <000001d32b64$104bbf80$30e33e80$@bigpond.com>

Hi Maria

Rule 1 make sure your data is in the right format

dat <- source("G:/1/savedat.txt")
> dat
$value
     Location       Date      Zn2 upper.zn  lower.zn
1    upstream 2016-04-27 29.92477 55.59800 13.912207
2       spill 2016-04-27 12.84040 22.07006  6.964934
3  downstream 2016-04-27 22.49673 41.60901 11.739109
4    upstream 2016-06-28 23.98425 45.60219 10.690640
5       spill 2016-06-28 41.51336 77.99893 20.142426
6  downstream 2016-06-28 15.51232 26.94059  7.044781
7    upstream 2016-08-25 21.73037 40.95852 10.354620
8       spill 2016-08-25 13.42082 22.96901  7.472893
9  downstream 2016-08-25 10.99209 20.17471  5.324318
10   upstream 2016-10-25 20.82462 40.60564  9.602007
11      spill 2016-10-25 14.01283 25.07032  7.830504
12 downstream 2016-10-25 15.67740 30.42278  6.971944
13   upstream 2016-12-21 28.14966 51.79390 14.384139
14      spill 2016-12-21 13.91587 23.94368  8.164688
15 downstream 2016-12-21 13.02749 24.46930  5.826650
16   upstream 2017-02-20 31.16736 55.51858 15.938211
17      spill 2017-02-20 12.47368 22.03830  6.725540
18 downstream 2017-02-20 17.65741 33.23577  8.519928

$visible
[1] TRUE
dat <- dat$value
dat$dDate <- as.Date(as.character(dat$Date))

str(dat)
'data.frame':   18 obs. of  6 variables:
 $ Location: Factor w/ 3 levels "downstream","spill",..: 3 2 1 3 2 1 3 2 1 3 ...
 $ Date    : Factor w/ 6 levels "2016-04-27","2016-06-28",..: 1 1 1 2 2 2 3 3 3 4 ...
 $ Zn2     : num  29.9 12.8 22.5 24 41.5 ...
 $ upper.zn: num  55.6 22.1 41.6 45.6 78 ...
 $ lower.zn: num  13.91 6.96 11.74 10.69 20.14 ...
 $ dDate   : Date, format: "2016-04-27" "2016-04-27" "2016-04-27" "2016-06-28" ...

You code to reproduce the xyplot is not reproducible as it contains user defined objects which you have not included.
Here is something to get you started,
If you want the measurement dates on the x-axis you will need to put the  required dates and format  in the scales argument.
Using par.settings for the symbols an lines will pass those values onto key

xyplot(upper.zn + Zn2 + lower.zn ~ dDate | Location, data=dat,
       type = "b",
       as.table = TRUE,
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.symbol = list( col=c("red", "black", "red"),
                                              cex = 1,
                                              pch = c(22, 21, 22)),
                           superpose.line = list (col=c("red", "black", "red"),
                                            lty = c(2, 1, 2),
                                            lwd = 1)
                      ),
       auto.key = list(points = TRUE, lines = TRUE),
       scales   = list(x = list(alternating = FALSE,
                                at = seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"),
                                label = format(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"), "%Y %b"),
                                relation    = "same",
                                rot         = 60),
                       y = list(alternating = FALSE,
                                at =  seq(0,80,20),
                                relation    = "same",
                                rot         = 0)
                  ),
#       pch=c(22, 21, 22),
#       lty=c(2, 1, 2),
       xlim = range(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter")),
       ylim=c(-5, 80),
       index.cond=list(c(3, 1, 2)),
       ylab="Percent (%)",
#       par.strip.text=list(col="white", font=2, lines=1.5),
#       lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
#       par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
#       key=dat_key,
#       scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
       panel = function(x, y, ...) {
         panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
         panel.abline(v=dat$dDate, lwd=1, lty=3, col="grey")
         panel.xyplot(x, y, ...)
         }
         )

As you have upper and lower levels of Zn you may want to look at ?panel.polygon  

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria Lathouri via R-help
Sent: Tuesday, 12 September 2017 05:33
To: R-help Mailing List
Subject: [R] show 0 at y axis in xyplot lattice

Dear all
I am trying to make a plot in xyplot lattice by groups. I would like to show "0" in y axis but I don't want to be aligned with the x axis. I want to be a little bit above.
I have tried many options but I don't get what I want. I also tried ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the upper boundary of the plot, respectively:
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
       index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
       lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
       par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
       key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
       panel = function(x, y, ...) {
         panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")               
         panel.abline(v=sdate, lwd=1, lty=3, col="grey")              
         panel.xyplot(x, y, ...)
         }
         )
when I use the following, 80 is a bit lower than the upper boundary of the plot, which is what I want, but 0 is not showing: 
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), 
       index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
       lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
       par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
       key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
       panel = function(x, y, ...) {
         panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")               
         panel.abline(v=sdate, lwd=1, lty=3, col="grey")              
         panel.xyplot(x, y, ...)
         }
         )I have also attached a reproducible example in case you want to see in more detail my data. 
I would very much appreciate any suggestions on this. 
Thank you in advance.
Kind regards,Maria


From pmakananisa at sars.gov.za  Tue Sep 12 08:20:59 2017
From: pmakananisa at sars.gov.za (Mangalani Peter Makananisa)
Date: Tue, 12 Sep 2017 06:20:59 +0000
Subject: [R] Case statement in sqldf
In-Reply-To: <D462FB85-EC13-48FB-8DBB-8ADC10BCA607@comcast.net>
References: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
 <D462FB85-EC13-48FB-8DBB-8ADC10BCA607@comcast.net>
Message-ID: <e53e7827a7da4c5ab8287b1e370cbc91@PTABREXC04.sars.gov.za>

Thanks D,

I will work on the solution you gave and give feedback.

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: 11 September 2017 05:19 PM
To: Mangalani Peter Makananisa
Cc: r-help at r-project.org
Subject: Re: [R] Case statement in sqldf


> On Sep 11, 2017, at 1:05 AM, Mangalani Peter Makananisa <pmakananisa at sars.gov.za> wrote:
> 
> Hi all,
> 
> I am trying to create a new  variable called Fiscal Year (FY) using case expression in sqldf  and I am getting a null FY , see the code below .
> 
> Please advise me as to how I can do this mutation.
> 
>  library(zoo)
>  library(lubridate)
>  library(stringr)
>  library(RH2)
>  library(sqldf)
> 
> cr$ReportDate = as.Date(cr$ReportDate, format ='%Y-%m-%d')
> 
>> cr2 =  sqldf(" select ReportDate
> +                      ,  case
> +                        when ReportDate between  '2012-04-01'  and  '2013-03-31'
> +                        then '2012_13'
> +                        when  ReportDate between '2013-04-01'  and  '2014-03-31'
> +                        then '2013_14'
> +                        when  ReportDate between  '2014-04-01'  and  '2015-03-31'
> +                        then'201415'
> +                        when ReportDate between '2015-04-01'  and  '2016-03-31'
> +                        then '2015_16'
> +                        when ReportDate between '2016-04-01'  and  '2017-03-31'
> +                        then '2016_17'
> +                        when ReportDate between '2017-04-01'  and  '2018-03-3'
> +                        then '2017_18' else null
> +                        end as FY
> +               from cr
> +              where  ReportDate  >=  '2012-04-01'
> +              ")

There was no cr object in any of the package I loaded although `lubridate` and `stringr` appear unnecessary and were omitted. I get no error with your code using this test object:

 cr <- data.frame(ReportDate = seq(as.Date("1970-01-01"), as.Date("2020-01-01"), by="1 year" ))

> cr2 =  sqldf(" select ReportDate
+                      ,  case
+                        when ReportDate between  '2012-04-01'  and  '2013-03-31'
+                        then '2012_13'
+                        when  ReportDate between '2013-04-01'  and  '2014-03-31'
+                        then '2013_14'
+                        when  ReportDate between  '2014-04-01'  and  '2015-03-31'
+                        then'201415'
+                        when ReportDate between '2015-04-01'  and  '2016-03-31'
+                        then '2015_16'
+                        when ReportDate between '2016-04-01'  and  '2017-03-31'
+                        then '2016_17'
+                        when ReportDate between '2017-04-01'  and  '2018-03-3'
+                        then '2017_18' else null
+                        end as FY
+               from cr
+              where  ReportDate  >=  '2012-04-01'
+              ")
> 
> str(cr2)
'data.frame':	8 obs. of  2 variables:
 $ ReportDate: Date, format: "2013-01-01" "2014-01-01" "2015-01-01" ...
 $ FY        : chr  "2012_13" "2013_14" "201415" "2015_16" ...
> 
> 
> Thanking you in advance
> 
> Kind regards,
> 
> Mangalani Peter Makananisa (0005786)
> South African Revenue Service (SARS)
> Specialist: Statistical Support
> TCEI_OR (Head Office)
> Tell: +272 422 7357, Cell: +2782 456 4669
> 
> Please Note: This email and its contents are subject to our email 
> legal notice which can be viewed at 
> http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law

Please Note: This email and its contents are subject to our email legal notice which can be viewed at http://www.sars.gov.za/Pages/Email-disclaimer.aspx

	[[alternative HTML version deleted]]


From zbwrnz at gmail.com  Mon Sep 11 16:59:24 2017
From: zbwrnz at gmail.com (Zebulun Arendsee)
Date: Mon, 11 Sep 2017 09:59:24 -0500
Subject: [R] [R-pkgs] rmonad
Message-ID: <CADV5-bghLtKzxU9=sy2YNQHt+Oh=M_fQ7HmycQBs-PVObL-RNQ@mail.gmail.com>

Dear Rusers,

This summer I published the package rmonad on CRAN:
https://cran.r-project.org/web/packages/rmonad

rmonad is a toolset for building stateful, branching pipelines. As
functions in the pipeline are executed, they are recorded in a graph of all
past operations. The resulting structure can be computed on to access not
only the final results, but also node documentation, intermediate results,
performance stats, and any raised messages, warnings or errors.

See the README on github (https://github.com/arendsee/rmonad) for a few
motivating examples. For more detail, see the "introduction" vignette (
https://cran.r-project.org/web/packages/rmonad/vignettes/introduction.html
).

Any thoughts, feature requests, or bug reports would be strongly
appreciated. I am also looking for collaborators (see the last section of
the github README).

Cheers,

-- 
*Zebulun Arendsee | PhD Candidate*

*Bioinformatics and Computational Biology program*
Genetics Development and Cellular Biology department

Github <https://github.com/zbwrnz> | LinkedIn
<https://www.linkedin.com/in/zebulun-arendsee-1b073138>

532 Science II
Iowa State University
Ames, IA 50011

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From pmakananisa at sars.gov.za  Tue Sep 12 08:36:50 2017
From: pmakananisa at sars.gov.za (Mangalani Peter Makananisa)
Date: Tue, 12 Sep 2017 06:36:50 +0000
Subject: [R] Case statement in sqldf
In-Reply-To: <CAP01uRnz+7mehMb0vhzGjRK40mXzCU6qtcR_pn0MoOV3dVTMgQ@mail.gmail.com>
References: <befad286341d41cd81c62fc4d7d364a7@PTABREXC04.sars.gov.za>
 <CAP01uRnz+7mehMb0vhzGjRK40mXzCU6qtcR_pn0MoOV3dVTMgQ@mail.gmail.com>
Message-ID: <0cd2424c0d914c1d9ce988b49a6379c8@PTABREXC04.sars.gov.za>

Thank you very much,

I will work on it

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: 11 September 2017 06:50 PM
To: Mangalani Peter Makananisa
Cc: r-help at r-project.org
Subject: Re: Case statement in sqldf

2018-03-3 in your code should be 2018-03-31.

The line
    then'201415'
needs to be fixed.

When posting please provide minimal self-contained examples. There was no input provided and library statements not relevant to the posted code were included.

Fixing the invalid date and bad line, getting rid of those library statements that are unnecessary and providing some test input, it works for me for the input shown.

(Note that it would NOT work if we omitted library(RH2) since the default sqlite back end does not have date types and does not know that an R date -- which is sent to sqlite as the number of days since
1970-01-01 -- corresponds to a particular character string; however, the H2 database does have date types.  See FAQ #4 on the sqldf github home page for more info.
    https://github.com/ggrothendieck/sqldf
)

This works:

library(sqldf)
library(RH2)

cr <- data.frame(ReportDate = as.Date("2017-09-11")) # input

cr2 =  sqldf(" select ReportDate
                     ,  case
                       when ReportDate between  '2012-04-01'  and  '2013-03-31'
                       then '2012_13'
                       when  ReportDate between '2013-04-01'  and  '2014-03-31'
                       then '2013_14'
                       when  ReportDate between  '2014-04-01'  and  '2015-03-31'
                       then '2014_15'
                       when ReportDate between '2015-04-01'  and  '2016-03-31'
                       then '2015_16'
                       when ReportDate between '2016-04-01'  and  '2017-03-31'
                       then '2016_17'
                       when ReportDate between '2017-04-01'  and  '2018-03-31'
                      then '2017_18' else null
             end as FY
             from cr
             where  ReportDate  >=  '2012-04-01'
             ")

giving:

  > cr2
    ReportDate      FY
  1 2017-09-11 2017_18

Note that using as.yearqtr from zoo this alternative could be used:

library(zoo)
cr <- data.frame(ReportDate = as.Date("2017-09-11")) # input

fy <- as.integer(as.yearqtr(cr$ReportDate) + 3/4) transform(cr, FY = paste0(fy-1, "_", fy %% 100))

giving:

  ReportDate      FY
1 2017-09-11 2017_18


On Mon, Sep 11, 2017 at 4:05 AM, Mangalani Peter Makananisa <pmakananisa at sars.gov.za> wrote:
> Hi all,
>
>
>
> I am trying to create a new  variable called Fiscal Year (FY) using 
> case expression in sqldf  and I am getting a null FY , see the code below .
>
>
>> +                        then '2017_18' else null>> South African 
>> + Revenue Service (SARS)>> Specialist: Statistical Support>> TCEI_OR 
>> + (Head Office)>> Tell: +272 422 7357, Cell: +2782 456 4669>> 
>> + http://www.sars.gov.za/Pages/Email-disclaimer.aspxemail: 
>> + ggrothendieck at gmail.with
> Please advise me as to how I can do this mutation.
>
>
>
>   library(zoo)
>
>   library(lubridate)
>
>   library(stringr)
>
>   library(RH2)
>
>   library(sqldf)
>
>
>
> cr$ReportDate = as.Date(cr$ReportDate, format ='%Y-%m-%d')
>
>
>
>> cr2 =  sqldf(" select ReportDate
>
> +                      ,  case
>
> +                        when ReportDate between  '2012-04-01'  and
> '2013-03-31'
>
> +                        then '2012_13'
>
> +                        when  ReportDate between '2013-04-01'  and
> '2014-03-31'
>
> +                        then '2013_14'
>
> +                        when  ReportDate between  '2014-04-01'  and
> '2015-03-31'
>
> +                        then'201415'
>
> +                        when ReportDate between '2015-04-01'  and
> '2016-03-31'
>
> +                        then '2015_16'
>
> +                        when ReportDate between '2016-04-01'  and
> '2017-03-31'
>
> +                        then '2016_17'
>
> +                        when ReportDate between '2017-04-01'  and
> '2018-03-3'
>


> +                        end as FY
>
> +               from cr
>
> +              where  ReportDate  >=  '2012-04-01'
>
> +              ")
>
>
>
> Thanking you in advance
>
>
>
> Kind regards,
>
>
>
> Mangalani Peter Makananisa (0005786)
>








>
>
>
>
> Disclaimer
>
> Please Note: This email and its contents are subject to our email 
> legal notice which can be viewed at




--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP

Please Note: This email and its contents are subject to our email legal notice which can be viewed at http://www.sars.gov.za/Pages/Email-disclaimer.aspx

	[[alternative HTML version deleted]]


From c-luescher at hispeed.ch  Tue Sep 12 12:27:35 2017
From: c-luescher at hispeed.ch (=?utf-8?Q?C=C3=A9line_L=C3=BCscher?=)
Date: Tue, 12 Sep 2017 12:27:35 +0200
Subject: [R] comparition of occurrence of multiple variables between two
 dataframes
Message-ID: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>

Hi everyone, I need your help to solve a problem with occurrence and two dataframes.
I have an excel table of 15200 lines. Each line correspond to a tree analyzed for its structures. I have all the structures in columns (48 structures). The occurrence of these structures has been counted on every tree. For example, the tree 12607 has 3 structures CV11, 1 structure IN12 and none (0) of the rest of all the other structures. The very last column is the value given to the tree, according to the structures found on it (each structure giving a number of point to the tree by its presence on it).
The question is: Are there some structures, or combination of structures, which give a high value to the tree?? Of course, according to the value of each structure, we can see which one has a higher value than the others (ex: structure CV11 has a value of 15, structure IN12 has a value of 4). But what I want to know is, if we take all the trees having a final value higher than 100 (we create a new dataframe "data100"), and we compare with the trees having a final value under 100 (we create another dataframe "data0"), can we find a significant difference in the number and occurrence of structures found on these trees? And which structure is related to trees with a higher value than 100??
For now, I have only a visual answer to the question. I did two boxplot of the data100 and data0, and I have seen some diff?rences?: 2 structures are only found in the data100, which can be caracteristic of a final value higher than 100. The problem is that I?m looking for a test to prove this.
If you have any idea or proposition for solving this problem.. it will be great!
Best wishes,
C.


Gesendet von Mail f?r Windows 10


	[[alternative HTML version deleted]]


From msuzen at gmail.com  Tue Sep 12 13:24:02 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Tue, 12 Sep 2017 13:24:02 +0200
Subject: [R] comparition of occurrence of multiple variables between two
	dataframes
In-Reply-To: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
References: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
Message-ID: <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>

Do you have a simplified example with a code? It is not clear to me
what do you mean by tree but if you refer to tree data structure,
maybe you could change the data structure to tree
(https://cran.r-project.org/web/packages/data.tree/vignettes/data.tree.html)
and try to write comparison of two tree objects. It might be easier
that data.frame alone.

On 12 September 2017 at 12:27, C?line L?scher <c-luescher at hispeed.ch> wrote:
> Hi everyone, I need your help to solve a problem with occurrence and two dataframes.
> I have an excel table of 15200 lines. Each line correspond to a tree analyzed for its structures. I have all the structures in columns (48 structures). The occurrence of these structures has been counted on every tree. For example, the tree 12607 has 3 structures CV11, 1 structure IN12 and none (0) of the rest of all the other structures. The very last column is the value given to the tree, according to the structures found on it (each structure giving a number of point to the tree by its presence on it).
> The question is: Are there some structures, or combination of structures, which give a high value to the tree ? Of course, according to the value of each structure, we can see which one has a higher value than the others (ex: structure CV11 has a value of 15, structure IN12 has a value of 4). But what I want to know is, if we take all the trees having a final value higher than 100 (we create a new dataframe "data100"), and we compare with the trees having a final value under 100 (we create another dataframe "data0"), can we find a significant difference in the number and occurrence of structures found on these trees? And which structure is related to trees with a higher value than 100 ?
> For now, I have only a visual answer to the question. I did two boxplot of the data100 and data0, and I have seen some diff?rences : 2 structures are only found in the data100, which can be caracteristic of a final value higher than 100. The problem is that I?m looking for a test to prove this.
> If you have any idea or proposition for solving this problem.. it will be great!
> Best wishes,
> C.
>
>
> Gesendet von Mail f?r Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msuzen at gmail.com  Tue Sep 12 14:10:36 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Tue, 12 Sep 2017 14:10:36 +0200
Subject: [R] comparition of occurrence of multiple variables between two
	dataframes
In-Reply-To: <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>
References: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
 <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>
 <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>
Message-ID: <CAPtbhHwKLP4gwMfXG6q2PYh6UoM9OqeW=N=qTG-CJBtGFfFiaw@mail.gmail.com>

Hi C?line,
Looks like you are looking for a statistical test between two sets of
distributions, such
as KS test, for example, generate histogram for each row in an identical
way and run KS test.
But if you are after simple difference you may use compare package (
https://cran.r-project.org/web/packages/compare/index.html).
Best,
-m
PS: Data is already plural :) datas does not exist.

On 12 September 2017 at 13:57, C?line L?scher <c-luescher at hispeed.ch> wrote:

> Yes of course, I can share this short view of the datas.
>
>
>
> Here is the head() of data100, containing all the trees with a final value
> higher than 100 :
>
> CV11
>
> CV12
>
> CV13
>
> CV14
>
> CV15
>
> CV21
>
> CV22
>
> CV23
>
> CV24
>
> CV25
>
> CV26
>
> CV31
>
> CV32
>
> CV33
>
> CV41
>
> CV42
>
> CV43
>
> CV44
>
> CV51
>
> CV52
>
> IN11
>
> IN12
>
> IN13
>
> 1291
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1083
>
> 0
>
> 4
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3919
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 14685
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 5452
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> IN14
>
> IN21
>
> IN22
>
> IN23
>
> IN31
>
> IN32
>
> IN33
>
> IN34
>
> BA11
>
> BA12
>
> BA21
>
> DE11
>
> DE12
>
> DE13
>
> DE14
>
> DE15
>
> GR11
>
> GR12
>
> GR13
>
> GR21
>
> GR22
>
> GR31
>
> GR32
>
> 1291
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 30
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1083
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3919
>
> 0
>
> 0
>
> 1
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 14685
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 5452
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> EP11
>
> EP12
>
> EP13
>
> EP14
>
> EP21
>
> EP31
>
> EP32
>
> EP33
>
> EP34
>
> EP35
>
> NE11
>
> NE12
>
> NE21
>
> OT11
>
> OT12
>
> OT21
>
> OT22
>
> ecoval
>
> 1291
>
> 0
>
> 8
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1192
>
> 1083
>
> 0
>
> 8
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 424
>
> 3919
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 380
>
> 14685
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 370
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 358
>
> 5452
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 356
>
>
>
> The columns are the possible structures found on a tree (cavity, scar?)
>
>
>
> And the same for the data0 :
>
> CV11
>
> CV12
>
> CV13
>
> CV14
>
> CV15
>
> CV21
>
> CV22
>
> CV23
>
> CV24
>
> CV25
>
> CV26
>
> CV31
>
> CV32
>
> CV33
>
> CV41
>
> CV42
>
> CV43
>
> CV44
>
> CV51
>
> CV52
>
> IN11
>
> IN12
>
> IN13
>
> 4728
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 1
>
> 0
>
> 0
>
> 5339
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 796
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> IN14
>
> IN21
>
> IN22
>
> IN23
>
> IN31
>
> IN32
>
> IN33
>
> IN34
>
> BA11
>
> BA12
>
> BA21
>
> DE11
>
> DE12
>
> DE13
>
> DE14
>
> DE15
>
> GR11
>
> GR12
>
> GR13
>
> GR21
>
> GR22
>
> GR31
>
> GR32
>
> 4728
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 5339
>
> 1
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 796
>
> 1
>
> 1
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> EP11
>
> EP12
>
> EP13
>
> EP14
>
> EP21
>
> EP31
>
> EP32
>
> EP33
>
> EP34
>
> EP35
>
> NE11
>
> NE12
>
> NE21
>
> OT11
>
> OT12
>
> OT21
>
> OT22
>
> ecoval
>
> 4728
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 99
>
> 5339
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 99
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 99
>
> 796
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 98
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 98
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 98
>
>
>
>
>
> In short, the question is about to find a test to compare the occurrence
> of the structures between the group higher than 100 and the group under 100.
>
>
>
> Thank you for your help,
>
> C.
>
>
>
>
>
>
>
> Gesendet von Mail <https://go.microsoft.com/fwlink/?LinkId=550986> f?r
> Windows 10
>
>
>
> *Von: *Suzen, Mehmet <msuzen at gmail.com>
> *Gesendet: *mardi, 12 septembre 2017 13:24
> *An: *C?line L?scher <c-luescher at hispeed.ch>
> *Cc: *r-help at r-project.org
> *Betreff: *Re: [R] comparition of occurrence of multiple variables
> between two dataframes
>
>
>
> Do you have a simplified example with a code? It is not clear to me
>
> what do you mean by tree but if you refer to tree data structure,
>
> maybe you could change the data structure to tree
>
> (https://cran.r-project.org/web/packages/data.tree/
> vignettes/data.tree.html)
>
> and try to write comparison of two tree objects. It might be easier
>
> that data.frame alone.
>
>
>
> On 12 September 2017 at 12:27, C?line L?scher <c-luescher at hispeed.ch>
> wrote:
>
> > Hi everyone, I need your help to solve a problem with occurrence and two
> dataframes.
>
> > I have an excel table of 15200 lines. Each line correspond to a tree
> analyzed for its structures. I have all the structures in columns (48
> structures). The occurrence of these structures has been counted on every
> tree. For example, the tree 12607 has 3 structures CV11, 1 structure IN12
> and none (0) of the rest of all the other structures. The very last column
> is the value given to the tree, according to the structures found on it
> (each structure giving a number of point to the tree by its presence on it).
>
> > The question is: Are there some structures, or combination of
> structures, which give a high value to the tree ? Of course, according to
> the value of each structure, we can see which one has a higher value than
> the others (ex: structure CV11 has a value of 15, structure IN12 has a
> value of 4). But what I want to know is, if we take all the trees having a
> final value higher than 100 (we create a new dataframe "data100"), and we
> compare with the trees having a final value under 100 (we create another
> dataframe "data0"), can we find a significant difference in the number and
> occurrence of structures found on these trees? And which structure is
> related to trees with a higher value than 100 ?
>
> > For now, I have only a visual answer to the question. I did two boxplot
> of the data100 and data0, and I have seen some diff?rences : 2 structures
> are only found in the data100, which can be caracteristic of a final value
> higher than 100. The problem is that I?m looking for a test to prove this.
>
> > If you have any idea or proposition for solving this problem.. it will
> be great!
>
> > Best wishes,
>
> > C.
>
> >
>
> >
>
> > Gesendet von Mail f?r Windows 10
>
> >
>
> >
>
> >         [[alternative HTML version deleted]]
>
> >
>
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Sep 12 16:32:01 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 12 Sep 2017 14:32:01 +0000
Subject: [R] comparition of occurrence of multiple variables between
	two	dataframes
In-Reply-To: <CAPtbhHwKLP4gwMfXG6q2PYh6UoM9OqeW=N=qTG-CJBtGFfFiaw@mail.gmail.com>
References: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
 <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>
 <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>
 <CAPtbhHwKLP4gwMfXG6q2PYh6UoM9OqeW=N=qTG-CJBtGFfFiaw@mail.gmail.com>
Message-ID: <b2d46a243a4e45a6a3d9129f4bcbca42@exch-2p-mbx-w2.ads.tamu.edu>

You need to learn how to send plain text messages. See below what happened to your html table when the list converted it to plain text. It is unreadable.

In your original post, you say "The very last column is the value given to the tree, according to the structures found on it (each structure giving a number of point to the tree by its presence on it)."

That suggests that the point value is based on the structures. If that is so the answer to your question is "yes", higher point values will have different numbers/combinations of structures because you computed point value from the structures. No statistical test between the two groups will be valid because the groups were not formed independently of the structures.

Looking for associations between different types of structures would be a different question that would not be based on point value at all but would use some measure of association/correlation.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Suzen, Mehmet
Sent: Tuesday, September 12, 2017 7:11 AM
To: C?line L?scher <c-luescher at hispeed.ch>
Cc: r-help at r-project.org
Subject: Re: [R] comparition of occurrence of multiple variables between two dataframes

Hi C?line,
Looks like you are looking for a statistical test between two sets of distributions, such as KS test, for example, generate histogram for each row in an identical way and run KS test.
But if you are after simple difference you may use compare package ( https://cran.r-project.org/web/packages/compare/index.html).
Best,
-m
PS: Data is already plural :) datas does not exist.

On 12 September 2017 at 13:57, C?line L?scher <c-luescher at hispeed.ch> wrote:

> Yes of course, I can share this short view of the datas.
>
>
>
> Here is the head() of data100, containing all the trees with a final 
> value higher than 100 :
>
> CV11
>
> CV12
>
> CV13
>
> CV14
>
> CV15
>
> CV21
>
> CV22
>
> CV23
>
> CV24
>
> CV25
>
> CV26
>
> CV31
>
> CV32
>
> CV33
>
> CV41
>
> CV42
>
> CV43
>
> CV44
>
> CV51
>
> CV52
>
> IN11
>
> IN12
>
> IN13
>
> 1291
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1083
>
> 0
>
> 4
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3919
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 14685
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 5452
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> IN14
>
> IN21
>
> IN22
>
> IN23
>
> IN31
>
> IN32
>
> IN33
>
> IN34
>
> BA11
>
> BA12
>
> BA21
>
> DE11
>
> DE12
>
> DE13
>
> DE14
>
> DE15
>
> GR11
>
> GR12
>
> GR13
>
> GR21
>
> GR22
>
> GR31
>
> GR32
>
> 1291
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 30
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1083
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3919
>
> 0
>
> 0
>
> 1
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 14685
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 5452
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 2
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> EP11
>
> EP12
>
> EP13
>
> EP14
>
> EP21
>
> EP31
>
> EP32
>
> EP33
>
> EP34
>
> EP35
>
> NE11
>
> NE12
>
> NE21
>
> OT11
>
> OT12
>
> OT21
>
> OT22
>
> ecoval
>
> 1291
>
> 0
>
> 8
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1192
>
> 1083
>
> 0
>
> 8
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 424
>
> 3919
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 380
>
> 14685
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 370
>
> 4021
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 358
>
> 5452
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 11
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 356
>
>
>
> The columns are the possible structures found on a tree (cavity, 
> scar?)
>
>
>
> And the same for the data0 :
>
> CV11
>
> CV12
>
> CV13
>
> CV14
>
> CV15
>
> CV21
>
> CV22
>
> CV23
>
> CV24
>
> CV25
>
> CV26
>
> CV31
>
> CV32
>
> CV33
>
> CV41
>
> CV42
>
> CV43
>
> CV44
>
> CV51
>
> CV52
>
> IN11
>
> IN12
>
> IN13
>
> 4728
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 1
>
> 0
>
> 0
>
> 5339
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 796
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> IN14
>
> IN21
>
> IN22
>
> IN23
>
> IN31
>
> IN32
>
> IN33
>
> IN34
>
> BA11
>
> BA12
>
> BA21
>
> DE11
>
> DE12
>
> DE13
>
> DE14
>
> DE15
>
> GR11
>
> GR12
>
> GR13
>
> GR21
>
> GR22
>
> GR31
>
> GR32
>
> 4728
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 5339
>
> 1
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 796
>
> 1
>
> 1
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 3
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> EP11
>
> EP12
>
> EP13
>
> EP14
>
> EP21
>
> EP31
>
> EP32
>
> EP33
>
> EP34
>
> EP35
>
> NE11
>
> NE12
>
> NE21
>
> OT11
>
> OT12
>
> OT21
>
> OT22
>
> ecoval
>
> 4728
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 99
>
> 5339
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 99
>
> 11766
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 99
>
> 796
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 98
>
> 3561
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 98
>
> 10581
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 0
>
> 1
>
> 0
>
> 98
>
>
>
>
>
> In short, the question is about to find a test to compare the 
> occurrence of the structures between the group higher than 100 and the group under 100.
>
>
>
> Thank you for your help,
>
> C.
>
>
>
>
>
>
>
> Gesendet von Mail <https://go.microsoft.com/fwlink/?LinkId=550986> f?r 
> Windows 10
>
>
>
> *Von: *Suzen, Mehmet <msuzen at gmail.com>
> *Gesendet: *mardi, 12 septembre 2017 13:24
> *An: *C?line L?scher <c-luescher at hispeed.ch>
> *Cc: *r-help at r-project.org
> *Betreff: *Re: [R] comparition of occurrence of multiple variables 
> between two dataframes
>
>
>
> Do you have a simplified example with a code? It is not clear to me
>
> what do you mean by tree but if you refer to tree data structure,
>
> maybe you could change the data structure to tree
>
> (https://cran.r-project.org/web/packages/data.tree/
> vignettes/data.tree.html)
>
> and try to write comparison of two tree objects. It might be easier
>
> that data.frame alone.
>
>
>
> On 12 September 2017 at 12:27, C?line L?scher <c-luescher at hispeed.ch>
> wrote:
>
> > Hi everyone, I need your help to solve a problem with occurrence and 
> > two
> dataframes.
>
> > I have an excel table of 15200 lines. Each line correspond to a tree
> analyzed for its structures. I have all the structures in columns (48 
> structures). The occurrence of these structures has been counted on 
> every tree. For example, the tree 12607 has 3 structures CV11, 1 
> structure IN12 and none (0) of the rest of all the other structures. 
> The very last column is the value given to the tree, according to the 
> structures found on it (each structure giving a number of point to the tree by its presence on it).
>
> > The question is: Are there some structures, or combination of
> structures, which give a high value to the tree ? Of course, according 
> to the value of each structure, we can see which one has a higher 
> value than the others (ex: structure CV11 has a value of 15, structure 
> IN12 has a value of 4). But what I want to know is, if we take all the 
> trees having a final value higher than 100 (we create a new dataframe 
> "data100"), and we compare with the trees having a final value under 
> 100 (we create another dataframe "data0"), can we find a significant 
> difference in the number and occurrence of structures found on these 
> trees? And which structure is related to trees with a higher value than 100 ?
>
> > For now, I have only a visual answer to the question. I did two 
> > boxplot
> of the data100 and data0, and I have seen some diff?rences : 2 
> structures are only found in the data100, which can be caracteristic 
> of a final value higher than 100. The problem is that I?m looking for a test to prove this.
>
> > If you have any idea or proposition for solving this problem.. it 
> > will
> be great!
>
> > Best wishes,
>
> > C.
>
> >
>
> >
>
> > Gesendet von Mail f?r Windows 10
>
> >
>
> >
>
> >         [[alternative HTML version deleted]]
>
> >
>
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
>
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From cabin21 at gmail.com  Tue Sep 12 16:57:25 2017
From: cabin21 at gmail.com (Where's YK)
Date: Tue, 12 Sep 2017 10:57:25 -0400
Subject: [R] please let me unsubscribe or remove me from mailing list.
Message-ID: <CAN46Z+ON-WQmneeYEE7Q3BSUZ95AVz6rC_cMz8yLNcE-0u8wBg@mail.gmail.com>

Thank you.

from cabin21 at gmail.com

-- 
----------------------------------------
Mr. Kim, Yuen Kwang

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 12 17:11:41 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 12 Sep 2017 08:11:41 -0700
Subject: [R] please let me unsubscribe or remove me from mailing list.
In-Reply-To: <CAN46Z+ON-WQmneeYEE7Q3BSUZ95AVz6rC_cMz8yLNcE-0u8wBg@mail.gmail.com>
References: <CAN46Z+ON-WQmneeYEE7Q3BSUZ95AVz6rC_cMz8yLNcE-0u8wBg@mail.gmail.com>
Message-ID: <91B40F07-78C5-4B39-93A9-4F888A3ED131@dcn.davis.ca.us>

No-one is preventing you from unsubscribing, and we are not empowered to do it for you. Follow the instructions at the bottom of this and every posting on this list. 
-- 
Sent from my phone. Please excuse my brevity.

On September 12, 2017 7:57:25 AM PDT, Where's YK <cabin21 at gmail.com> wrote:
>Thank you.
>
>from cabin21 at gmail.com


From paulbernal07 at gmail.com  Tue Sep 12 17:17:50 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 12 Sep 2017 10:17:50 -0500
Subject: [R] Unable to load packages RODBC and RODBCext in R
Message-ID: <CAMOcQfN6X+7PX9z6AZKEHvwkKXur5EUQRQGo_9aMRZTAywVp+g@mail.gmail.com>

Dear all,

Hope you are doing great. I am currently using R version 3.4.1 ("Single
Candle") and was trying to install packages RODBC and RODBCext using the
following steps:

> install.packages("RODBCext")
Installing package into ?C:/Users/PaulBernal/Documents/R/win-library/3.4?
(as ?lib? is unspecified)
also installing the dependency ?RODBC?

trying URL '
https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBC_1.3-15.zip'
Content type 'application/zip' length 831635 bytes (812 KB)
downloaded 812 KB

trying URL '
https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBCext_0.3.1.zip'
Content type 'application/zip' length 276687 bytes (270 KB)
downloaded 270 KB

package ?RODBC? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\filedd64ac13805\RODBC? to
?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBC? # I dont understand
this Warning message I mean why was it unable to move a previous
installation?
package ?RODBCext? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\filedd6447315795\RODBCext?
to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBCext?

The downloaded binary packages are in

C:\Users\PaulBernal\AppData\Local\Temp\Rtmpk7SkD5\downloaded_packages

> library("RODBC")
Error in library("RODBC") : there is no package called ?RODBC?

> library("RODBCext")
Error in library("RODBCext") : there is no package called ?RODBCext?

If packages RODBC and RODBCext were successfully installed, why am I not
able to load those packages?

Any help will be greatly appreciated,

Paul

	[[alternative HTML version deleted]]


From mlathouri at yahoo.gr  Tue Sep 12 13:54:43 2017
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Tue, 12 Sep 2017 11:54:43 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBzaG93IDAgYXQgeSBheGlzIGluIHh5cGxv?=
 =?utf-8?q?t_lattice?=
In-Reply-To: <000001d32b64$104bbf80$30e33e80$@bigpond.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <000001d32b64$104bbf80$30e33e80$@bigpond.com>
Message-ID: <998403893.550803.1505217283135@mail.yahoo.com>

Dear all,
Thank you very much for the help. ylim=c(-5, 80) worked.?
Regarding the reproducible example, I used dput () and saved the file as txt. It is not the first time that I used this way and normally it works. Because when I try to attach a .csv file with the data, most of the time it doesn't go through.?
I will know for the next time.?
Many thanks.
Regards,Maria 

    ???? 2:11 ?.?. ?????, 12 ??????????? 2017, ?/? Duncan Mackay <dulcalma at bigpond.com> ??????:
 

 Hi Maria

Rule 1 make sure your data is in the right format

dat <- source("G:/1/savedat.txt")
> dat
$value
? ? Location? ? ? Date? ? ? Zn2 upper.zn? lower.zn
1? ? upstream 2016-04-27 29.92477 55.59800 13.912207
2? ? ? spill 2016-04-27 12.84040 22.07006? 6.964934
3? downstream 2016-04-27 22.49673 41.60901 11.739109
4? ? upstream 2016-06-28 23.98425 45.60219 10.690640
5? ? ? spill 2016-06-28 41.51336 77.99893 20.142426
6? downstream 2016-06-28 15.51232 26.94059? 7.044781
7? ? upstream 2016-08-25 21.73037 40.95852 10.354620
8? ? ? spill 2016-08-25 13.42082 22.96901? 7.472893
9? downstream 2016-08-25 10.99209 20.17471? 5.324318
10? upstream 2016-10-25 20.82462 40.60564? 9.602007
11? ? ? spill 2016-10-25 14.01283 25.07032? 7.830504
12 downstream 2016-10-25 15.67740 30.42278? 6.971944
13? upstream 2016-12-21 28.14966 51.79390 14.384139
14? ? ? spill 2016-12-21 13.91587 23.94368? 8.164688
15 downstream 2016-12-21 13.02749 24.46930? 5.826650
16? upstream 2017-02-20 31.16736 55.51858 15.938211
17? ? ? spill 2017-02-20 12.47368 22.03830? 6.725540
18 downstream 2017-02-20 17.65741 33.23577? 8.519928

$visible
[1] TRUE
dat <- dat$value
dat$dDate <- as.Date(as.character(dat$Date))

str(dat)
'data.frame':? 18 obs. of? 6 variables:
 $ Location: Factor w/ 3 levels "downstream","spill",..: 3 2 1 3 2 1 3 2 1 3 ...
 $ Date? ? : Factor w/ 6 levels "2016-04-27","2016-06-28",..: 1 1 1 2 2 2 3 3 3 4 ...
 $ Zn2? ? : num? 29.9 12.8 22.5 24 41.5 ...
 $ upper.zn: num? 55.6 22.1 41.6 45.6 78 ...
 $ lower.zn: num? 13.91 6.96 11.74 10.69 20.14 ...
 $ dDate? : Date, format: "2016-04-27" "2016-04-27" "2016-04-27" "2016-06-28" ...

You code to reproduce the xyplot is not reproducible as it contains user defined objects which you have not included.
Here is something to get you started,
If you want the measurement dates on the x-axis you will need to put the? required dates and format? in the scales argument.
Using par.settings for the symbols an lines will pass those values onto key

xyplot(upper.zn + Zn2 + lower.zn ~ dDate | Location, data=dat,
? ? ? type = "b",
? ? ? as.table = TRUE,
? ? ? par.settings = list(strip.background = list(col = "transparent"),
? ? ? ? ? ? ? ? ? ? ? ? ? superpose.symbol = list( col=c("red", "black", "red"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cex = 1,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? pch = c(22, 21, 22)),
? ? ? ? ? ? ? ? ? ? ? ? ? superpose.line = list (col=c("red", "black", "red"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lty = c(2, 1, 2),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lwd = 1)
? ? ? ? ? ? ? ? ? ? ? ),
? ? ? auto.key = list(points = TRUE, lines = TRUE),
? ? ? scales? = list(x = list(alternating = FALSE,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at = seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? label = format(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"), "%Y %b"),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 60),
? ? ? ? ? ? ? ? ? ? ? y = list(alternating = FALSE,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at =? seq(0,80,20),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 0)
? ? ? ? ? ? ? ? ? ),
#? ? ? pch=c(22, 21, 22),
#? ? ? lty=c(2, 1, 2),
? ? ? xlim = range(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter")),
? ? ? ylim=c(-5, 80),
? ? ? index.cond=list(c(3, 1, 2)),
? ? ? ylab="Percent (%)",
#? ? ? par.strip.text=list(col="white", font=2, lines=1.5),
#? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
#? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
#? ? ? key=dat_key,
#? ? ? scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
? ? ? panel = function(x, y, ...) {
? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
? ? ? ? panel.abline(v=dat$dDate, lwd=1, lty=3, col="grey")
? ? ? ? panel.xyplot(x, y, ...)
? ? ? ? }
? ? ? ? )

As you have upper and lower levels of Zn you may want to look at ?panel.polygon? 

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria Lathouri via R-help
Sent: Tuesday, 12 September 2017 05:33
To: R-help Mailing List
Subject: [R] show 0 at y axis in xyplot lattice

Dear all
I am trying to make a plot in xyplot lattice by groups. I would like to show "0" in y axis but I don't want to be aligned with the x axis. I want to be a little bit above.
I have tried many options but I don't get what I want. I also tried ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the upper boundary of the plot, respectively:
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
? ? ? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
? ? ? panel = function(x, y, ...) {
? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")? ? ? ? ? ? ? 
? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")? ? ? ? ? ? ? 
? ? ? ? panel.xyplot(x, y, ...)
? ? ? ? }
? ? ? ? )
when I use the following, 80 is a bit lower than the upper boundary of the plot, which is what I want, but 0 is not showing: 
xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), 
? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)), 
? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"), 
? ? ? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
? ? ? panel = function(x, y, ...) {
? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")? ? ? ? ? ? ? 
? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")? ? ? ? ? ? ? 
? ? ? ? panel.xyplot(x, y, ...)
? ? ? ? }
? ? ? ? )I have also attached a reproducible example in case you want to see in more detail my data. 
I would very much appreciate any suggestions on this. 
Thank you in advance.
Kind regards,Maria


   
	[[alternative HTML version deleted]]


From c-luescher at hispeed.ch  Tue Sep 12 13:57:47 2017
From: c-luescher at hispeed.ch (=?utf-8?Q?C=C3=A9line_L=C3=BCscher?=)
Date: Tue, 12 Sep 2017 13:57:47 +0200
Subject: [R] comparition of occurrence of multiple variables between two
 dataframes
In-Reply-To: <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>
References: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
 <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>
Message-ID: <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>

Yes of course, I can share this short view of the datas.

Here is the head() of data100, containing all the trees with a final value higher than 100?:

CV11
CV12
CV13
CV14
CV15
CV21
CV22
CV23
CV24
CV25
CV26
CV31
CV32
CV33
CV41
CV42
CV43
CV44
CV51
CV52
IN11
IN12
IN13
1291
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1083
0
4
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
3919
0
0
0
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
0
0
0
14685
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
4021
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
5452
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

IN14
IN21
IN22
IN23
IN31
IN32
IN33
IN34
BA11
BA12
BA21
DE11
DE12
DE13
DE14
DE15
GR11
GR12
GR13
GR21
GR22
GR31
GR32
1291
0
0
0
0
0
0
0
0
30
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1083
3
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
3919
0
0
1
0
2
0
0
0
2
0
0
0
3
0
0
0
0
0
0
11
0
0
0
14685
0
0
0
0
0
0
0
0
11
0
0
0
0
0
0
0
0
0
0
0
0
0
0
4021
0
0
0
0
0
0
0
0
11
0
0
0
0
0
0
0
0
0
0
0
0
0
0
5452
0
0
1
0
0
0
0
0
0
0
0
2
0
0
0
0
0
0
0
0
0
0
0

EP11
EP12
EP13
EP14
EP21
EP31
EP32
EP33
EP34
EP35
NE11
NE12
NE21
OT11
OT12
OT21
OT22
ecoval





1291
0
8
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1192





1083
0
8
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
424





3919
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
380





14685
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
370





4021
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
358





5452
0
0
0
0
0
0
1
0
0
11
0
0
0
0
1
0
0
356






The columns are the possible structures found on a tree (cavity, scar?)

And the same for the data0?:

CV11
CV12
CV13
CV14
CV15
CV21
CV22
CV23
CV24
CV25
CV26
CV31
CV32
CV33
CV41
CV42
CV43
CV44
CV51
CV52
IN11
IN12
IN13
4728
0
0
0
1
0
0
0
3
0
0
0
0
0
0
0
0
0
0
0
1
1
0
0
5339
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
11766
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
796
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
3561
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
10581
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0

IN14
IN21
IN22
IN23
IN31
IN32
IN33
IN34
BA11
BA12
BA21
DE11
DE12
DE13
DE14
DE15
GR11
GR12
GR13
GR21
GR22
GR31
GR32
4728
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
5339
1
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
11766
0
0
0
0
0
0
0
0
0
0
1
1
0
0
0
0
0
0
0
0
0
0
0
796
1
1
0
0
1
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
3561
0
0
0
0
0
0
0
0
3
0
0
0
0
0
0
0
0
0
0
0
0
0
0
10581
0
0
0
1
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0

EP11
EP12
EP13
EP14
EP21
EP31
EP32
EP33
EP34
EP35
NE11
NE12
NE21
OT11
OT12
OT21
OT22
ecoval





4728
0
0
1
0
0
1
0
0
0
0
0
0
0
0
0
0
0
99





5339
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
99





11766
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
99





796
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
98





3561
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
98





10581
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
1
0
98







In short, the question is about to find a test to compare the occurrence of the structures between the group higher than 100 and the group under 100.

Thank you for your help,
C.



Gesendet von Mail f?r Windows 10

Von: Suzen, Mehmet
Gesendet: mardi, 12 septembre 2017 13:24
An: C?line L?scher
Cc: r-help at r-project.org
Betreff: Re: [R] comparition of occurrence of multiple variables between two dataframes

Do you have a simplified example with a code? It is not clear to me
what do you mean by tree but if you refer to tree data structure,
maybe you could change the data structure to tree
(https://cran.r-project.org/web/packages/data.tree/vignettes/data.tree.html)
and try to write comparison of two tree objects. It might be easier
that data.frame alone.

On 12 September 2017 at 12:27, C?line L?scher <c-luescher at hispeed.ch> wrote:
> Hi everyone, I need your help to solve a problem with occurrence and two dataframes.
> I have an excel table of 15200 lines. Each line correspond to a tree analyzed for its structures. I have all the structures in columns (48 structures). The occurrence of these structures has been counted on every tree. For example, the tree 12607 has 3 structures CV11, 1 structure IN12 and none (0) of the rest of all the other structures. The very last column is the value given to the tree, according to the structures found on it (each structure giving a number of point to the tree by its presence on it).
> The question is: Are there some structures, or combination of structures, which give a high value to the tree ? Of course, according to the value of each structure, we can see which one has a higher value than the others (ex: structure CV11 has a value of 15, structure IN12 has a value of 4). But what I want to know is, if we take all the trees having a final value higher than 100 (we create a new dataframe "data100"), and we compare with the trees having a final value under 100 (we create another dataframe "data0"), can we find a significant difference in the number and occurrence of structures found on these trees? And which structure is related to trees with a higher value than 100 ?
> For now, I have only a visual answer to the question. I did two boxplot of the data100 and data0, and I have seen some diff?rences : 2 structures are only found in the data100, which can be caracteristic of a final value higher than 100. The problem is that I?m looking for a test to prove this.
> If you have any idea or proposition for solving this problem.. it will be great!
> Best wishes,
> C.
>
>
> Gesendet von Mail f?r Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Tue Sep 12 17:07:41 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Tue, 12 Sep 2017 17:07:41 +0200
Subject: [R] please let me unsubscribe or remove me from mailing list.
In-Reply-To: <CAN46Z+ON-WQmneeYEE7Q3BSUZ95AVz6rC_cMz8yLNcE-0u8wBg@mail.gmail.com>
References: <CAN46Z+ON-WQmneeYEE7Q3BSUZ95AVz6rC_cMz8yLNcE-0u8wBg@mail.gmail.com>
Message-ID: <70bcffd4-8049-3bd7-911f-340bce6f5fdd@yahoo.fr>

Le 12/09/2017 ? 16:57, Where's YK a ?crit?:
> Thank you.
>
> from cabin21 at gmail.com
>
Google R-help at r-project.org unsubscribe

bring you to:

https://www.r-project.org/mail.html

Sincerely

Marc


From lists at dewey.myzen.co.uk  Tue Sep 12 19:22:36 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 12 Sep 2017 18:22:36 +0100
Subject: [R] =?utf-8?b?zqPPh861z4Q6IHNob3cgMCBhdCB5IGF4aXMgaW4geHlwbG90?=
 =?utf-8?q?_lattice?=
In-Reply-To: <998403893.550803.1505217283135@mail.yahoo.com>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <000001d32b64$104bbf80$30e33e80$@bigpond.com>
 <998403893.550803.1505217283135@mail.yahoo.com>
Message-ID: <d7eb85cf-126b-af1f-ccd9-af3f5f42c97c@dewey.myzen.co.uk>

Dear Maria

The file you attached to your first e-mail did come through but I think 
some people on the list must have missed it.

Michael

On 12/09/2017 12:54, Maria Lathouri via R-help wrote:
> Dear all,
> Thank you very much for the help. ylim=c(-5, 80) worked.
> Regarding the reproducible example, I used dput () and saved the file as txt. It is not the first time that I used this way and normally it works. Because when I try to attach a .csv file with the data, most of the time it doesn't go through.
> I will know for the next time.
> Many thanks.
> Regards,Maria
> 
>      ???? 2:11 ?.?. ?????, 12 ??????????? 2017, ?/? Duncan Mackay <dulcalma at bigpond.com> ??????:
>   
> 
>   Hi Maria
> 
> Rule 1 make sure your data is in the right format
> 
> dat <- source("G:/1/savedat.txt")
>> dat
> $value
>  ? ? Location? ? ? Date? ? ? Zn2 upper.zn? lower.zn
> 1? ? upstream 2016-04-27 29.92477 55.59800 13.912207
> 2? ? ? spill 2016-04-27 12.84040 22.07006? 6.964934
> 3? downstream 2016-04-27 22.49673 41.60901 11.739109
> 4? ? upstream 2016-06-28 23.98425 45.60219 10.690640
> 5? ? ? spill 2016-06-28 41.51336 77.99893 20.142426
> 6? downstream 2016-06-28 15.51232 26.94059? 7.044781
> 7? ? upstream 2016-08-25 21.73037 40.95852 10.354620
> 8? ? ? spill 2016-08-25 13.42082 22.96901? 7.472893
> 9? downstream 2016-08-25 10.99209 20.17471? 5.324318
> 10? upstream 2016-10-25 20.82462 40.60564? 9.602007
> 11? ? ? spill 2016-10-25 14.01283 25.07032? 7.830504
> 12 downstream 2016-10-25 15.67740 30.42278? 6.971944
> 13? upstream 2016-12-21 28.14966 51.79390 14.384139
> 14? ? ? spill 2016-12-21 13.91587 23.94368? 8.164688
> 15 downstream 2016-12-21 13.02749 24.46930? 5.826650
> 16? upstream 2017-02-20 31.16736 55.51858 15.938211
> 17? ? ? spill 2017-02-20 12.47368 22.03830? 6.725540
> 18 downstream 2017-02-20 17.65741 33.23577? 8.519928
> 
> $visible
> [1] TRUE
> dat <- dat$value
> dat$dDate <- as.Date(as.character(dat$Date))
> 
> str(dat)
> 'data.frame':? 18 obs. of? 6 variables:
>   $ Location: Factor w/ 3 levels "downstream","spill",..: 3 2 1 3 2 1 3 2 1 3 ...
>   $ Date? ? : Factor w/ 6 levels "2016-04-27","2016-06-28",..: 1 1 1 2 2 2 3 3 3 4 ...
>   $ Zn2? ? : num? 29.9 12.8 22.5 24 41.5 ...
>   $ upper.zn: num? 55.6 22.1 41.6 45.6 78 ...
>   $ lower.zn: num? 13.91 6.96 11.74 10.69 20.14 ...
>   $ dDate? : Date, format: "2016-04-27" "2016-04-27" "2016-04-27" "2016-06-28" ...
> 
> You code to reproduce the xyplot is not reproducible as it contains user defined objects which you have not included.
> Here is something to get you started,
> If you want the measurement dates on the x-axis you will need to put the? required dates and format? in the scales argument.
> Using par.settings for the symbols an lines will pass those values onto key
> 
> xyplot(upper.zn + Zn2 + lower.zn ~ dDate | Location, data=dat,
>  ? ? ? type = "b",
>  ? ? ? as.table = TRUE,
>  ? ? ? par.settings = list(strip.background = list(col = "transparent"),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? superpose.symbol = list( col=c("red", "black", "red"),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cex = 1,
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? pch = c(22, 21, 22)),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? superpose.line = list (col=c("red", "black", "red"),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lty = c(2, 1, 2),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lwd = 1)
>  ? ? ? ? ? ? ? ? ? ? ? ),
>  ? ? ? auto.key = list(points = TRUE, lines = TRUE),
>  ? ? ? scales? = list(x = list(alternating = FALSE,
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at = seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? label = format(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"), "%Y %b"),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 60),
>  ? ? ? ? ? ? ? ? ? ? ? y = list(alternating = FALSE,
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at =? seq(0,80,20),
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 0)
>  ? ? ? ? ? ? ? ? ? ),
> #? ? ? pch=c(22, 21, 22),
> #? ? ? lty=c(2, 1, 2),
>  ? ? ? xlim = range(seq(from = as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter")),
>  ? ? ? ylim=c(-5, 80),
>  ? ? ? index.cond=list(c(3, 1, 2)),
>  ? ? ? ylab="Percent (%)",
> #? ? ? par.strip.text=list(col="white", font=2, lines=1.5),
> #? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
> #? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
> #? ? ? key=dat_key,
> #? ? ? scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
>  ? ? ? panel = function(x, y, ...) {
>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.abline(v=dat$dDate, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.xyplot(x, y, ...)
>  ? ? ? ? }
>  ? ? ? ? )
> 
> As you have upper and lower levels of Zn you may want to look at ?panel.polygon
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria Lathouri via R-help
> Sent: Tuesday, 12 September 2017 05:33
> To: R-help Mailing List
> Subject: [R] show 0 at y axis in xyplot lattice
> 
> Dear all
> I am trying to make a plot in xyplot lattice by groups. I would like to show "0" in y axis but I don't want to be aligned with the x axis. I want to be a little bit above.
> I have tried many options but I don't get what I want. I also tried ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and the upper boundary of the plot, respectively:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0, 80),
>  ? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
>  ? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
>  ? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
>  ? ? ? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y"))), xlab="Date",
>  ? ? ? panel = function(x, y, ...) {
>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.xyplot(x, y, ...)
>  ? ? ? ? }
>  ? ? ? ? )
> when I use the following, 80 is a bit lower than the upper boundary of the plot, which is what I want, but 0 is not showing:
> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b", as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>  ? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)", par.strip.text=list(col="white", font=2, lines=1.5),
>  ? ? ? lattice.options = modifyList(lattice.options(), list(skip.boundary.labels = 0)),
>  ? ? ? par.settings=my.settings, col=c("red", "black", "red"), fill=c("red", "black", "red"),
>  ? ? ? key=dat_key, scales = list(x = list(at = sdate, labels = format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
>  ? ? ? panel = function(x, y, ...) {
>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>  ? ? ? ? panel.xyplot(x, y, ...)
>  ? ? ? ? }
>  ? ? ? ? )I have also attached a reproducible example in case you want to see in more detail my data.
> I would very much appreciate any suggestions on this.
> Thank you in advance.
> Kind regards,Maria
> 
> 
>     
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Tue Sep 12 19:50:40 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 12 Sep 2017 10:50:40 -0700
Subject: [R] =?utf-8?b?zqPPh861z4Q6IHNob3cgMCBhdCB5IGF4aXMgaW4geHlwbG90?=
	=?utf-8?q?_lattice?=
In-Reply-To: <d7eb85cf-126b-af1f-ccd9-af3f5f42c97c@dewey.myzen.co.uk>
References: <1469577140.12370527.1505158405851.ref@mail.yahoo.com>
 <1469577140.12370527.1505158405851@mail.yahoo.com>
 <000001d32b64$104bbf80$30e33e80$@bigpond.com>
 <998403893.550803.1505217283135@mail.yahoo.com>
 <d7eb85cf-126b-af1f-ccd9-af3f5f42c97c@dewey.myzen.co.uk>
Message-ID: <222D1009-3485-4C59-98A4-8FC406EB3584@dcn.davis.ca.us>

It contains the output of one call to dput, but several objects were missing and the name of the object provided in the text file was not specified. 
-- 
Sent from my phone. Please excuse my brevity.

On September 12, 2017 10:22:36 AM PDT, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>Dear Maria
>
>The file you attached to your first e-mail did come through but I think
>
>some people on the list must have missed it.
>
>Michael
>
>On 12/09/2017 12:54, Maria Lathouri via R-help wrote:
>> Dear all,
>> Thank you very much for the help. ylim=c(-5, 80) worked.
>> Regarding the reproducible example, I used dput () and saved the file
>as txt. It is not the first time that I used this way and normally it
>works. Because when I try to attach a .csv file with the data, most of
>the time it doesn't go through.
>> I will know for the next time.
>> Many thanks.
>> Regards,Maria
>> 
>>      ???? 2:11 ?.?. ?????, 12 ??????????? 2017, ?/? Duncan Mackay
><dulcalma at bigpond.com> ??????:
>>   
>> 
>>   Hi Maria
>> 
>> Rule 1 make sure your data is in the right format
>> 
>> dat <- source("G:/1/savedat.txt")
>>> dat
>> $value
>>  ? ? Location? ? ? Date? ? ? Zn2 upper.zn? lower.zn
>> 1? ? upstream 2016-04-27 29.92477 55.59800 13.912207
>> 2? ? ? spill 2016-04-27 12.84040 22.07006? 6.964934
>> 3? downstream 2016-04-27 22.49673 41.60901 11.739109
>> 4? ? upstream 2016-06-28 23.98425 45.60219 10.690640
>> 5? ? ? spill 2016-06-28 41.51336 77.99893 20.142426
>> 6? downstream 2016-06-28 15.51232 26.94059? 7.044781
>> 7? ? upstream 2016-08-25 21.73037 40.95852 10.354620
>> 8? ? ? spill 2016-08-25 13.42082 22.96901? 7.472893
>> 9? downstream 2016-08-25 10.99209 20.17471? 5.324318
>> 10? upstream 2016-10-25 20.82462 40.60564? 9.602007
>> 11? ? ? spill 2016-10-25 14.01283 25.07032? 7.830504
>> 12 downstream 2016-10-25 15.67740 30.42278? 6.971944
>> 13? upstream 2016-12-21 28.14966 51.79390 14.384139
>> 14? ? ? spill 2016-12-21 13.91587 23.94368? 8.164688
>> 15 downstream 2016-12-21 13.02749 24.46930? 5.826650
>> 16? upstream 2017-02-20 31.16736 55.51858 15.938211
>> 17? ? ? spill 2017-02-20 12.47368 22.03830? 6.725540
>> 18 downstream 2017-02-20 17.65741 33.23577? 8.519928
>> 
>> $visible
>> [1] TRUE
>> dat <- dat$value
>> dat$dDate <- as.Date(as.character(dat$Date))
>> 
>> str(dat)
>> 'data.frame':? 18 obs. of? 6 variables:
>>   $ Location: Factor w/ 3 levels "downstream","spill",..: 3 2 1 3 2 1
>3 2 1 3 ...
>>   $ Date? ? : Factor w/ 6 levels "2016-04-27","2016-06-28",..: 1 1 1
>2 2 2 3 3 3 4 ...
>>   $ Zn2? ? : num? 29.9 12.8 22.5 24 41.5 ...
>>   $ upper.zn: num? 55.6 22.1 41.6 45.6 78 ...
>>   $ lower.zn: num? 13.91 6.96 11.74 10.69 20.14 ...
>>   $ dDate? : Date, format: "2016-04-27" "2016-04-27" "2016-04-27"
>"2016-06-28" ...
>> 
>> You code to reproduce the xyplot is not reproducible as it contains
>user defined objects which you have not included.
>> Here is something to get you started,
>> If you want the measurement dates on the x-axis you will need to put
>the? required dates and format? in the scales argument.
>> Using par.settings for the symbols an lines will pass those values
>onto key
>> 
>> xyplot(upper.zn + Zn2 + lower.zn ~ dDate | Location, data=dat,
>>  ? ? ? type = "b",
>>  ? ? ? as.table = TRUE,
>>  ? ? ? par.settings = list(strip.background = list(col =
>"transparent"),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? superpose.symbol = list( col=c("red",
>"black", "red"),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? cex = 1,
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? pch = c(22, 21, 22)),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? superpose.line = list (col=c("red",
>"black", "red"),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lty = c(2, 1, 2),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? lwd = 1)
>>  ? ? ? ? ? ? ? ? ? ? ? ),
>>  ? ? ? auto.key = list(points = TRUE, lines = TRUE),
>>  ? ? ? scales? = list(x = list(alternating = FALSE,
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at = seq(from =
>as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? label = format(seq(from =
>as.Date("2016-04-01"), to = as.Date("2017-04-01"), by = "quarter"), "%Y
>%b"),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 60),
>>  ? ? ? ? ? ? ? ? ? ? ? y = list(alternating = FALSE,
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? at =? seq(0,80,20),
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? relation? ? = "same",
>>  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? rot? ? ? ? = 0)
>>  ? ? ? ? ? ? ? ? ? ),
>> #? ? ? pch=c(22, 21, 22),
>> #? ? ? lty=c(2, 1, 2),
>>  ? ? ? xlim = range(seq(from = as.Date("2016-04-01"), to =
>as.Date("2017-04-01"), by = "quarter")),
>>  ? ? ? ylim=c(-5, 80),
>>  ? ? ? index.cond=list(c(3, 1, 2)),
>>  ? ? ? ylab="Percent (%)",
>> #? ? ? par.strip.text=list(col="white", font=2, lines=1.5),
>> #? ? ? lattice.options = modifyList(lattice.options(),
>list(skip.boundary.labels = 0)),
>> #? ? ? par.settings=my.settings, col=c("red", "black", "red"),
>fill=c("red", "black", "red"),
>> #? ? ? key=dat_key,
>> #? ? ? scales = list(x = list(at = sdate, labels = format(sdate,
>"%b-%y"))), xlab="Date",
>>  ? ? ? panel = function(x, y, ...) {
>>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.abline(v=dat$dDate, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.xyplot(x, y, ...)
>>  ? ? ? ? }
>>  ? ? ? ? )
>> 
>> As you have upper and lower levels of Zn you may want to look at
>?panel.polygon
>> 
>> Regards
>> 
>> Duncan
>> 
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2350
>> 
>> 
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maria
>Lathouri via R-help
>> Sent: Tuesday, 12 September 2017 05:33
>> To: R-help Mailing List
>> Subject: [R] show 0 at y axis in xyplot lattice
>> 
>> Dear all
>> I am trying to make a plot in xyplot lattice by groups. I would like
>to show "0" in y axis but I don't want to be aligned with the x axis. I
>want to be a little bit above.
>> I have tried many options but I don't get what I want. I also tried
>ylim=c(0, 80) but both 0 and 80 are fully aligned with the x-axis and
>the upper boundary of the plot, respectively:
>> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
>as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2), ylim=c(0,
>80),
>>  ? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
>par.strip.text=list(col="white", font=2, lines=1.5),
>>  ? ? ? lattice.options = modifyList(lattice.options(),
>list(skip.boundary.labels = 0)),
>>  ? ? ? par.settings=my.settings, col=c("red", "black", "red"),
>fill=c("red", "black", "red"),
>>  ? ? ? key=dat_key, scales = list(x = list(at = sdate, labels =
>format(sdate, "%b-%y"))), xlab="Date",
>>  ? ? ? panel = function(x, y, ...) {
>>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.xyplot(x, y, ...)
>>  ? ? ? ? }
>>  ? ? ? ? )
>> when I use the following, 80 is a bit lower than the upper boundary
>of the plot, which is what I want, but 0 is not showing:
>> xyplot(upper.zn + Zn2 + lower.zn ~ sdate | Location, type="b",
>as.table=TRUE, data=dat, pch=c(22, 21, 22), lty=c(2, 1, 2),
>>  ? ? ? index.cond=list(c(3, 1, 2)), ylab="Percent (%)",
>par.strip.text=list(col="white", font=2, lines=1.5),
>>  ? ? ? lattice.options = modifyList(lattice.options(),
>list(skip.boundary.labels = 0)),
>>  ? ? ? par.settings=my.settings, col=c("red", "black", "red"),
>fill=c("red", "black", "red"),
>>  ? ? ? key=dat_key, scales = list(x = list(at = sdate, labels =
>format(sdate, "%b-%y")), y=list(at=c(0, 20, 40, 60, 80))), xlab="Date",
>>  ? ? ? panel = function(x, y, ...) {
>>  ? ? ? ? panel.grid(h = -1, v = 0, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.abline(v=sdate, lwd=1, lty=3, col="grey")
>>  ? ? ? ? panel.xyplot(x, y, ...)
>>  ? ? ? ? }
>>  ? ? ? ? )I have also attached a reproducible example in case you
>want to see in more detail my data.
>> I would very much appreciate any suggestions on this.
>> Thank you in advance.
>> Kind regards,Maria
>> 
>> 
>>     
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>> 
>
>-- 
>Michael
>http://www.dewey.myzen.co.uk/home.html
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Sep 12 19:58:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 12 Sep 2017 10:58:14 -0700
Subject: [R] Unable to load packages RODBC and RODBCext in R
In-Reply-To: <CAMOcQfN6X+7PX9z6AZKEHvwkKXur5EUQRQGo_9aMRZTAywVp+g@mail.gmail.com>
References: <CAMOcQfN6X+7PX9z6AZKEHvwkKXur5EUQRQGo_9aMRZTAywVp+g@mail.gmail.com>
Message-ID: <CAGxFJbQR0_eMXePzSArzYSCrGCO02FC2iTYu0tg-f2TzpLArnQ@mail.gmail.com>

I don't use Windows, but this looks like a Windows permissions issue, no?

You could try moving them yourself manually or create another library
directory that R can access to put them in.

... or wait and hope for advice from someone who uses Windows to give you a
definitive answer.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 12, 2017 at 8:17 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear all,
>
> Hope you are doing great. I am currently using R version 3.4.1 ("Single
> Candle") and was trying to install packages RODBC and RODBCext using the
> following steps:
>
> > install.packages("RODBCext")
> Installing package into ?C:/Users/PaulBernal/Documents/R/win-library/3.4?
> (as ?lib? is unspecified)
> also installing the dependency ?RODBC?
>
> trying URL '
> https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBC_1.3-15.zip'
> Content type 'application/zip' length 831635 bytes (812 KB)
> downloaded 812 KB
>
> trying URL '
> https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBCext_0.3.1.zip
> '
> Content type 'application/zip' length 276687 bytes (270 KB)
> downloaded 270 KB
>
> package ?RODBC? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\filedd64ac13805\RODBC? to
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBC? # I dont
> understand
> this Warning message I mean why was it unable to move a previous
> installation?
> package ?RODBCext? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
> filedd6447315795\RODBCext?
> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBCext?
>
> The downloaded binary packages are in
>
> C:\Users\PaulBernal\AppData\Local\Temp\Rtmpk7SkD5\downloaded_packages
>
> > library("RODBC")
> Error in library("RODBC") : there is no package called ?RODBC?
>
> > library("RODBCext")
> Error in library("RODBCext") : there is no package called ?RODBCext?
>
> If packages RODBC and RODBCext were successfully installed, why am I not
> able to load those packages?
>
> Any help will be greatly appreciated,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 12 20:28:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 12 Sep 2017 11:28:44 -0700
Subject: [R] Unable to load packages RODBC and RODBCext in R
In-Reply-To: <CAGxFJbQR0_eMXePzSArzYSCrGCO02FC2iTYu0tg-f2TzpLArnQ@mail.gmail.com>
References: <CAMOcQfN6X+7PX9z6AZKEHvwkKXur5EUQRQGo_9aMRZTAywVp+g@mail.gmail.com>
 <CAGxFJbQR0_eMXePzSArzYSCrGCO02FC2iTYu0tg-f2TzpLArnQ@mail.gmail.com>
Message-ID: <3E5014F4-0631-4FBB-83AB-32FB797A6D11@dcn.davis.ca.us>

The messages tell you that the package files were successfully downloaded and extracted, but could not be added to the package library. Try making sure all instances of R are closed down before running the install.packages function. Also, just to be clear, avoid running R "As Administrator" under Windows unless you plan to fix the resulting mess yourself. 
-- 
Sent from my phone. Please excuse my brevity.

On September 12, 2017 10:58:14 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I don't use Windows, but this looks like a Windows permissions issue,
>no?
>
>You could try moving them yourself manually or create another library
>directory that R can access to put them in.
>
>... or wait and hope for advice from someone who uses Windows to give
>you a
>definitive answer.
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Tue, Sep 12, 2017 at 8:17 AM, Paul Bernal <paulbernal07 at gmail.com>
>wrote:
>
>> Dear all,
>>
>> Hope you are doing great. I am currently using R version 3.4.1
>("Single
>> Candle") and was trying to install packages RODBC and RODBCext using
>the
>> following steps:
>>
>> > install.packages("RODBCext")
>> Installing package into
>?C:/Users/PaulBernal/Documents/R/win-library/3.4?
>> (as ?lib? is unspecified)
>> also installing the dependency ?RODBC?
>>
>> trying URL '
>>
>https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBC_1.3-15.zip'
>> Content type 'application/zip' length 831635 bytes (812 KB)
>> downloaded 812 KB
>>
>> trying URL '
>>
>https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBCext_0.3.1.zip
>> '
>> Content type 'application/zip' length 276687 bytes (270 KB)
>> downloaded 270 KB
>>
>> package ?RODBC? successfully unpacked and MD5 sums checked
>> Warning: unable to move temporary installation
>>
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\filedd64ac13805\RODBC?
>to
>> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBC? # I dont
>> understand
>> this Warning message I mean why was it unable to move a previous
>> installation?
>> package ?RODBCext? successfully unpacked and MD5 sums checked
>> Warning: unable to move temporary installation
>> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
>> filedd6447315795\RODBCext?
>> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBCext?
>>
>> The downloaded binary packages are in
>>
>> C:\Users\PaulBernal\AppData\Local\Temp\Rtmpk7SkD5\downloaded_packages
>>
>> > library("RODBC")
>> Error in library("RODBC") : there is no package called ?RODBC?
>>
>> > library("RODBCext")
>> Error in library("RODBCext") : there is no package called ?RODBCext?
>>
>> If packages RODBC and RODBCext were successfully installed, why am I
>not
>> able to load those packages?
>>
>> Any help will be greatly appreciated,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Tue Sep 12 20:28:44 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 12 Sep 2017 11:28:44 -0700
Subject: [R] Unable to load packages RODBC and RODBCext in R
In-Reply-To: <CAGxFJbQR0_eMXePzSArzYSCrGCO02FC2iTYu0tg-f2TzpLArnQ@mail.gmail.com>
References: <CAMOcQfN6X+7PX9z6AZKEHvwkKXur5EUQRQGo_9aMRZTAywVp+g@mail.gmail.com>
 <CAGxFJbQR0_eMXePzSArzYSCrGCO02FC2iTYu0tg-f2TzpLArnQ@mail.gmail.com>
Message-ID: <AA77941D-6657-4A61-B11A-D674B80FCEAE@dcn.davis.ca.us>

The messages tell you that the package files were successfully downloaded and extracted, but could not be added to the package library. Try making sure all instances of R are closed down before running the install.packages function. Also, just to be clear, avoid running R "As Administrator" under Windows unless you plan to fix the resulting mess yourself. 
-- 
Sent from my phone. Please excuse my brevity.

On September 12, 2017 10:58:14 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>I don't use Windows, but this looks like a Windows permissions issue,
>no?
>
>You could try moving them yourself manually or create another library
>directory that R can access to put them in.
>
>... or wait and hope for advice from someone who uses Windows to give
>you a
>definitive answer.
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Tue, Sep 12, 2017 at 8:17 AM, Paul Bernal <paulbernal07 at gmail.com>
>wrote:
>
>> Dear all,
>>
>> Hope you are doing great. I am currently using R version 3.4.1
>("Single
>> Candle") and was trying to install packages RODBC and RODBCext using
>the
>> following steps:
>>
>> > install.packages("RODBCext")
>> Installing package into
>?C:/Users/PaulBernal/Documents/R/win-library/3.4?
>> (as ?lib? is unspecified)
>> also installing the dependency ?RODBC?
>>
>> trying URL '
>>
>https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBC_1.3-15.zip'
>> Content type 'application/zip' length 831635 bytes (812 KB)
>> downloaded 812 KB
>>
>> trying URL '
>>
>https://mirrors.dotsrc.org/cran/bin/windows/contrib/3.4/RODBCext_0.3.1.zip
>> '
>> Content type 'application/zip' length 276687 bytes (270 KB)
>> downloaded 270 KB
>>
>> package ?RODBC? successfully unpacked and MD5 sums checked
>> Warning: unable to move temporary installation
>>
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\filedd64ac13805\RODBC?
>to
>> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBC? # I dont
>> understand
>> this Warning message I mean why was it unable to move a previous
>> installation?
>> package ?RODBCext? successfully unpacked and MD5 sums checked
>> Warning: unable to move temporary installation
>> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
>> filedd6447315795\RODBCext?
>> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RODBCext?
>>
>> The downloaded binary packages are in
>>
>> C:\Users\PaulBernal\AppData\Local\Temp\Rtmpk7SkD5\downloaded_packages
>>
>> > library("RODBC")
>> Error in library("RODBC") : there is no package called ?RODBC?
>>
>> > library("RODBCext")
>> Error in library("RODBCext") : there is no package called ?RODBCext?
>>
>> If packages RODBC and RODBCext were successfully installed, why am I
>not
>> able to load those packages?
>>
>> Any help will be greatly appreciated,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From abouelmakarim1962 at gmail.com  Tue Sep 12 20:46:11 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Tue, 12 Sep 2017 14:46:11 -0400
Subject: [R] Load R data files
Message-ID: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>

Dear All:

I am trying to load an R data set, but I got the following message. Please
see below. The file is there.

setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data")

datahs0csv <- read.table("hs0.csv", header=T, sep=",")
attach(datahs0csv)

detach(datahs0csv)
rm(list=ls())

Then I tried to reload the data, but I got this error message. I am not
sure what was wrong.

*> load("datahs0csv.rda")*

Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file 'datahs0csv.rda', probable reason 'No such
file or directory'


Any help will be appreciated.


with thanks
abou

______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Sep 12 20:53:38 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 12 Sep 2017 18:53:38 +0000
Subject: [R] Load R data files
In-Reply-To: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
References: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
Message-ID: <CAKVAULNOcE-te8O5hMRNHs=1DMKpvrDLLsofp6RWHoS_4ZWRjg@mail.gmail.com>

Hi Abou,

You haven't saved the datahs0csv.

When you are done manipulating datahs0csv you can use save(datahs0csv, file
= 'datahs0csv.rda'). Then you should be able to load the data.
HTH
Ulrik

On Tue, 12 Sep 2017, 20:46 AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All:
>
> I am trying to load an R data set, but I got the following message. Please
> see below. The file is there.
>
> setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data")
>
> datahs0csv <- read.table("hs0.csv", header=T, sep=",")
> attach(datahs0csv)
>
> detach(datahs0csv)
> rm(list=ls())
>
> Then I tried to reload the data, but I got this error message. I am not
> sure what was wrong.
>
> *> load("datahs0csv.rda")*
>
> Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
> In addition: Warning message:
> In readChar(con, 5L, useBytes = TRUE) :
>   cannot open compressed file 'datahs0csv.rda', probable reason 'No such
> file or directory'
>
>
> Any help will be appreciated.
>
>
> with thanks
> abou
>
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Sep 12 20:56:57 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 12 Sep 2017 19:56:57 +0100
Subject: [R] Load R data files
In-Reply-To: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
Message-ID: <20170912195657.Horde.s6ttr_YYG8cl05g3ONyqwYP@mail.sapo.pt>

Hello,

What makes you think that there is a file named "datahs0csv.rda"? You  
have not saved the file, in fact you have done nothing at all.
If you want to create a file "datahs0csv.rda", use ?save.
(And don't use 'attach', please.)

Hope this helps,

Rui Barradas


Citando AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com>:

> Dear All:
>
> I am trying to load an R data set, but I got the following message. Please
> see below. The file is there.
>
> setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data")
>
> datahs0csv <- read.table("hs0.csv", header=T, sep=",")
> attach(datahs0csv)
>
> detach(datahs0csv)
> rm(list=ls())
>
> Then I tried to reload the data, but I got this error message. I am not
> sure what was wrong.
>
> *> load("datahs0csv.rda")*
>
> Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
> In addition: Warning message:
> In readChar(con, 5L, useBytes = TRUE) :
>   cannot open compressed file 'datahs0csv.rda', probable reason 'No such
> file or directory'
>
>
> Any help will be appreciated.
>
>
> with thanks
> abou
>
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abouelmakarim1962 at gmail.com  Tue Sep 12 21:26:33 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Tue, 12 Sep 2017 15:26:33 -0400
Subject: [R] Load R data files
In-Reply-To: <CAKVAULNOcE-te8O5hMRNHs=1DMKpvrDLLsofp6RWHoS_4ZWRjg@mail.gmail.com>
References: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
 <CAKVAULNOcE-te8O5hMRNHs=1DMKpvrDLLsofp6RWHoS_4ZWRjg@mail.gmail.com>
Message-ID: <CAE9stmdtJAE0Ovm+wR6GZ-gMBLCQ1_T7NcJF22DebO35gGNkeA@mail.gmail.com>

Dear All:


It was saved, but there was a space somewhere. So it works for me now.

I do have another similar problem.

I saved an R data file


save(datahs0csv,file="
F:\Fall_2017\5-STA574\2-Notes\1-R\1-R_new\chapter4-Entering_Data/datahs0csv2
.rda")

*The new R data file "*datahs0csv2.rda*" is in the directory.*

I tried to load the file "" to R, but I got an error message. Please see
below.

>
*load(file="F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data/datahs0csv2.rda")*
>
It seems for me that the file was loaded to R. But when I typed the data
name, it says that the not found.

> *datahs0csv2*

*Error: object 'datahs0csv2' not found*


with many thanks
abou

On Tue, Sep 12, 2017 at 2:53 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> Hi Abou,
>
> You haven't saved the datahs0csv.
>
> When you are done manipulating datahs0csv you can use save(datahs0csv,
> file = 'datahs0csv.rda'). Then you should be able to load the data.
> HTH
> Ulrik
>
> On Tue, 12 Sep 2017, 20:46 AbouEl-Makarim Aboueissa <
> abouelmakarim1962 at gmail.com> wrote:
>
>> Dear All:
>>
>> I am trying to load an R data set, but I got the following message. Please
>> see below. The file is there.
>>
>> setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data")
>>
>> datahs0csv <- read.table("hs0.csv", header=T, sep=",")
>> attach(datahs0csv)
>>
>> detach(datahs0csv)
>> rm(list=ls())
>>
>> Then I tried to reload the data, but I got this error message. I am not
>> sure what was wrong.
>>
>> *> load("datahs0csv.rda")*
>>
>> Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
>> In addition: Warning message:
>> In readChar(con, 5L, useBytes = TRUE) :
>>   cannot open compressed file 'datahs0csv.rda', probable reason 'No such
>> file or directory'
>>
>>
>> Any help will be appreciated.
>>
>>
>> with thanks
>> abou
>>
>> ______________________
>> AbouEl-Makarim Aboueissa, PhD
>> Professor of Statistics
>> Department of Mathematics and Statistics
>> University of Southern Maine
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Sep 12 21:34:57 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 12 Sep 2017 19:34:57 +0000
Subject: [R] Load R data files
In-Reply-To: <CAE9stmdtJAE0Ovm+wR6GZ-gMBLCQ1_T7NcJF22DebO35gGNkeA@mail.gmail.com>
References: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
 <CAKVAULNOcE-te8O5hMRNHs=1DMKpvrDLLsofp6RWHoS_4ZWRjg@mail.gmail.com>
 <CAE9stmdtJAE0Ovm+wR6GZ-gMBLCQ1_T7NcJF22DebO35gGNkeA@mail.gmail.com>
Message-ID: <CAKVAULO_N2TsYtac-gvObps-qa602S=NqPXe7rZMYdKhDBbzag@mail.gmail.com>

The object you load has the same name as the object you saved. In this case
datahs0csv and not the name of the file sans .rda

On Di., 12. Sep. 2017, 21:26 AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All:
>
>
> It was saved, but there was a space somewhere. So it works for me now.
>
> I do have another similar problem.
>
> I saved an R data file
>
>
> save(datahs0csv,file="
> F:\Fall_2017\5-STA574\2-Notes\1-R\1-R_new\chapter4-Entering_Data/
> datahs0csv2.rda")
>
> *The new R data file "*datahs0csv2.rda*" is in the directory.*
>
> I tried to load the file "" to R, but I got an error message. Please see
> below.
>
> >
> *load(file="F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data/datahs0csv2.rda")*
> >
> It seems for me that the file was loaded to R. But when I typed the data
> name, it says that the not found.
>
> > *datahs0csv2*
>
> *Error: object 'datahs0csv2' not found*
>
>
> with many thanks
> abou
>
> On Tue, Sep 12, 2017 at 2:53 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
>> Hi Abou,
>>
>> You haven't saved the datahs0csv.
>>
>> When you are done manipulating datahs0csv you can use save(datahs0csv,
>> file = 'datahs0csv.rda'). Then you should be able to load the data.
>> HTH
>> Ulrik
>>
>> On Tue, 12 Sep 2017, 20:46 AbouEl-Makarim Aboueissa <
>> abouelmakarim1962 at gmail.com> wrote:
>>
>>> Dear All:
>>>
>>> I am trying to load an R data set, but I got the following message.
>>> Please
>>> see below. The file is there.
>>>
>>> setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data")
>>>
>>> datahs0csv <- read.table("hs0.csv", header=T, sep=",")
>>> attach(datahs0csv)
>>>
>>> detach(datahs0csv)
>>> rm(list=ls())
>>>
>>> Then I tried to reload the data, but I got this error message. I am not
>>> sure what was wrong.
>>>
>>> *> load("datahs0csv.rda")*
>>>
>>> Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
>>> In addition: Warning message:
>>> In readChar(con, 5L, useBytes = TRUE) :
>>>   cannot open compressed file 'datahs0csv.rda', probable reason 'No such
>>> file or directory'
>>>
>>>
>>> Any help will be appreciated.
>>>
>>>
>>> with thanks
>>> abou
>>>
>>> ______________________
>>> AbouEl-Makarim Aboueissa, PhD
>>> Professor of Statistics
>>> Department of Mathematics and Statistics
>>> University of Southern Maine
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
> --
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Department of Mathematics and Statistics
> University of Southern Maine
>

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Tue Sep 12 22:32:22 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Tue, 12 Sep 2017 16:32:22 -0400
Subject: [R] Load R data files
In-Reply-To: <CAKVAULO_N2TsYtac-gvObps-qa602S=NqPXe7rZMYdKhDBbzag@mail.gmail.com>
References: <CAE9stmexhd8dkqHQo0HfYafKNBXxe8FxAUehsf0Yya1VMtQY2g@mail.gmail.com>
 <CAKVAULNOcE-te8O5hMRNHs=1DMKpvrDLLsofp6RWHoS_4ZWRjg@mail.gmail.com>
 <CAE9stmdtJAE0Ovm+wR6GZ-gMBLCQ1_T7NcJF22DebO35gGNkeA@mail.gmail.com>
 <CAKVAULO_N2TsYtac-gvObps-qa602S=NqPXe7rZMYdKhDBbzag@mail.gmail.com>
Message-ID: <CAE9stmcHn5v=H9ex533VAUn8oghfygewkbD_6x2rPD3pcO9OwQ@mail.gmail.com>

Dear Ulrik:

thank you very much

abou


On Tue, Sep 12, 2017 at 3:34 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> The object you load has the same name as the object you saved. In this
> case datahs0csv and not the name of the file sans .rda
>
> On Di., 12. Sep. 2017, 21:26 AbouEl-Makarim Aboueissa <
> abouelmakarim1962 at gmail.com> wrote:
>
>> Dear All:
>>
>>
>> It was saved, but there was a space somewhere. So it works for me now.
>>
>> I do have another similar problem.
>>
>> I saved an R data file
>>
>>
>> save(datahs0csv,file=" F:\Fall_2017\5-STA574\2-Notes\
>> 1-R\1-R_new\chapter4-Entering_Data/datahs0csv2.rda")
>>
>> *The new R data file "*datahs0csv2.rda*" is in the directory.*
>>
>> I tried to load the file "" to R, but I got an error message. Please see
>> below.
>>
>> >
>> *load(file="F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-Entering_Data/datahs0csv2.rda")*
>> >
>> It seems for me that the file was loaded to R. But when I typed the data
>> name, it says that the not found.
>>
>> > *datahs0csv2*
>>
>> *Error: object 'datahs0csv2' not found*
>>
>>
>> with many thanks
>> abou
>>
>> On Tue, Sep 12, 2017 at 2:53 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
>> wrote:
>>
>>> Hi Abou,
>>>
>>> You haven't saved the datahs0csv.
>>>
>>> When you are done manipulating datahs0csv you can use save(datahs0csv,
>>> file = 'datahs0csv.rda'). Then you should be able to load the data.
>>> HTH
>>> Ulrik
>>>
>>> On Tue, 12 Sep 2017, 20:46 AbouEl-Makarim Aboueissa <
>>> abouelmakarim1962 at gmail.com> wrote:
>>>
>>>> Dear All:
>>>>
>>>> I am trying to load an R data set, but I got the following message.
>>>> Please
>>>> see below. The file is there.
>>>>
>>>> setwd("F:/Fall_2017/5-STA574/2-Notes/1-R/1-R_new/chapter4-
>>>> Entering_Data")
>>>>
>>>> datahs0csv <- read.table("hs0.csv", header=T, sep=",")
>>>> attach(datahs0csv)
>>>>
>>>> detach(datahs0csv)
>>>> rm(list=ls())
>>>>
>>>> Then I tried to reload the data, but I got this error message. I am not
>>>> sure what was wrong.
>>>>
>>>> *> load("datahs0csv.rda")*
>>>>
>>>> Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
>>>> In addition: Warning message:
>>>> In readChar(con, 5L, useBytes = TRUE) :
>>>>   cannot open compressed file 'datahs0csv.rda', probable reason 'No such
>>>> file or directory'
>>>>
>>>>
>>>> Any help will be appreciated.
>>>>
>>>>
>>>> with thanks
>>>> abou
>>>>
>>>> ______________________
>>>> AbouEl-Makarim Aboueissa, PhD
>>>> Professor of Statistics
>>>> Department of Mathematics and Statistics
>>>> University of Southern Maine
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>>
>> --
>> ______________________
>> AbouEl-Makarim Aboueissa, PhD
>> Department of Mathematics and Statistics
>> University of Southern Maine
>>
>


-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Sep 13 09:16:53 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 13 Sep 2017 07:16:53 +0000
Subject: [R] comparition of occurrence of multiple variables between two
 dataframes
In-Reply-To: <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>
References: <20170912122743.8aTh1w01C1TVWzE01aTiw4@vie01a-pemc-psmtp-pe01>
 <CAPtbhHwjbvTkx=-krUL8rT2Ose3wm-tbw41dQKaS07FEKmUCog@mail.gmail.com>
 <20170912135755.8bxt1w0221TVWzE01bxuUo@vie01a-pemc-psmtp-pe01>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAE7DE@SRVEXCHCM301.precheza.cz>

Hi

Instead of posting head(data100) try to copy output of

dput(head(data100))

directly to your post.

This can show us your exact data together with their modes.

And switch to plain text emails, HTML formating results in quite messy mails.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of C?line
> L?scher
> Sent: Tuesday, September 12, 2017 1:58 PM
> To: Suzen, Mehmet <msuzen at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] comparition of occurrence of multiple variables between two
> dataframes
>
> Yes of course, I can share this short view of the datas.
>
> Here is the head() of data100, containing all the trees with a final value higher
> than 100 :
>
> CV11
> CV12
> CV13
> CV14
> CV15
> CV21
> CV22
> CV23
> CV24
> CV25
> CV26
> CV31
> CV32
> CV33
> CV41
> CV42
> CV43
> CV44
> CV51
> CV52
> IN11
> IN12
> IN13
> 1291
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1083
> 0
> 4
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 3919
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 2
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 14685
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 4021
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 5452
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
>
> IN14
> IN21
> IN22
> IN23
> IN31
> IN32
> IN33
> IN34
> BA11
> BA12
> BA21
> DE11
> DE12
> DE13
> DE14
> DE15
> GR11
> GR12
> GR13
> GR21
> GR22
> GR31
> GR32
> 1291
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 30
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1083
> 3
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 3919
> 0
> 0
> 1
> 0
> 2
> 0
> 0
> 0
> 2
> 0
> 0
> 0
> 3
> 0
> 0
> 0
> 0
> 0
> 0
> 11
> 0
> 0
> 0
> 14685
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 11
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 4021
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 11
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 5452
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 2
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
>
> EP11
> EP12
> EP13
> EP14
> EP21
> EP31
> EP32
> EP33
> EP34
> EP35
> NE11
> NE12
> NE21
> OT11
> OT12
> OT21
> OT22
> ecoval
>
>
>
>
>
> 1291
> 0
> 8
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1192
>
>
>
>
>
> 1083
> 0
> 8
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 424
>
>
>
>
>
> 3919
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 380
>
>
>
>
>
> 14685
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 370
>
>
>
>
>
> 4021
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 358
>
>
>
>
>
> 5452
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 11
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 356
>
>
>
>
> The columns are the possible structures found on a tree (cavity, scar?)
>
> And the same for the data0 :
>
> CV11
> CV12
> CV13
> CV14
> CV15
> CV21
> CV22
> CV23
> CV24
> CV25
> CV26
> CV31
> CV32
> CV33
> CV41
> CV42
> CV43
> CV44
> CV51
> CV52
> IN11
> IN12
> IN13
> 4728
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 3
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 1
> 0
> 0
> 5339
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 11766
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 796
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 3561
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 10581
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
>
> IN14
> IN21
> IN22
> IN23
> IN31
> IN32
> IN33
> IN34
> BA11
> BA12
> BA21
> DE11
> DE12
> DE13
> DE14
> DE15
> GR11
> GR12
> GR13
> GR21
> GR22
> GR31
> GR32
> 4728
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 5339
> 1
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 11766
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 796
> 1
> 1
> 0
> 0
> 1
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 3561
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 3
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 10581
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
>
> EP11
> EP12
> EP13
> EP14
> EP21
> EP31
> EP32
> EP33
> EP34
> EP35
> NE11
> NE12
> NE21
> OT11
> OT12
> OT21
> OT22
> ecoval
>
>
>
>
>
> 4728
> 0
> 0
> 1
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 99
>
>
>
>
>
> 5339
> 0
> 1
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 99
>
>
>
>
>
> 11766
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 99
>
>
>
>
>
> 796
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 98
>
>
>
>
>
> 3561
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 98
>
>
>
>
>
> 10581
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 0
> 0
> 0
> 0
> 0
> 0
> 1
> 0
> 98
>
>
>
>
>
> In short, the question is about to find a test to compare the occurrence of the
> structures between the group higher than 100 and the group under 100.
>
> Thank you for your help,
> C.
>
>
>
> Gesendet von Mail f?r Windows 10
>
> Von: Suzen, Mehmet
> Gesendet: mardi, 12 septembre 2017 13:24
> An: C?line L?scher
> Cc: r-help at r-project.org
> Betreff: Re: [R] comparition of occurrence of multiple variables between two
> dataframes
>
> Do you have a simplified example with a code? It is not clear to me what do
> you mean by tree but if you refer to tree data structure, maybe you could
> change the data structure to tree
> (https://cran.r-project.org/web/packages/data.tree/vignettes/data.tree.html)
> and try to write comparison of two tree objects. It might be easier that
> data.frame alone.
>
> On 12 September 2017 at 12:27, C?line L?scher <c-luescher at hispeed.ch>
> wrote:
> > Hi everyone, I need your help to solve a problem with occurrence and two
> dataframes.
> > I have an excel table of 15200 lines. Each line correspond to a tree analyzed
> for its structures. I have all the structures in columns (48 structures). The
> occurrence of these structures has been counted on every tree. For example,
> the tree 12607 has 3 structures CV11, 1 structure IN12 and none (0) of the rest
> of all the other structures. The very last column is the value given to the tree,
> according to the structures found on it (each structure giving a number of point
> to the tree by its presence on it).
> > The question is: Are there some structures, or combination of structures,
> which give a high value to the tree ? Of course, according to the value of each
> structure, we can see which one has a higher value than the others (ex:
> structure CV11 has a value of 15, structure IN12 has a value of 4). But what I
> want to know is, if we take all the trees having a final value higher than 100
> (we create a new dataframe "data100"), and we compare with the trees having
> a final value under 100 (we create another dataframe "data0"), can we find a
> significant difference in the number and occurrence of structures found on
> these trees? And which structure is related to trees with a higher value than
> 100 ?
> > For now, I have only a visual answer to the question. I did two boxplot of the
> data100 and data0, and I have seen some diff?rences : 2 structures are only
> found in the data100, which can be caracteristic of a final value higher than
> 100. The problem is that I?m looking for a test to prove this.
> > If you have any idea or proposition for solving this problem.. it will be great!
> > Best wishes,
> > C.
> >
> >
> > Gesendet von Mail f?r Windows 10
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From r.turner at auckland.ac.nz  Wed Sep 13 09:37:30 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 13 Sep 2017 19:37:30 +1200
Subject: [R] [FORGED] [R-sig-Geo] circular spatial polygon
In-Reply-To: <CABFLJO=buiE_9m7Zs-33G6Wo7ado9cuG16+BEss-4HNvLimqtg@mail.gmail.com>
References: <CABFLJOmjC72tBC3kZDxjE1-Mkx3ThZ5cEzL4CC_V9NP3YPTOsg@mail.gmail.com>
 <1d336cbd-3257-9a72-148d-eb3391b8d1d5@auckland.ac.nz>
 <CABFLJO=buiE_9m7Zs-33G6Wo7ado9cuG16+BEss-4HNvLimqtg@mail.gmail.com>
Message-ID: <d09a9b7e-0a05-679a-942d-90bf4441415e@auckland.ac.nz>

On 13/09/17 13:24, K?tia Emidio wrote:
> Dear Rolf,
> 
> Thanks for your help!
> 
> What I need is a spatial window with shape equal to the figure attached. 
> This figure I made using ArcGis, but it is important to me make it in R. 
> After having this figure I will make some analysis using spatstat among 
> others. The points within figure are trees...

(1) I believe that this discussion should be kept on-list.  It is not my 
role to provide private consulting for you.  I  am therefore cc-ing the 
list in this email.

(2) It is still not completely clear what you really want; the figure 
that you attached appears to be a disc with 4 diameters superimposed. 
So you might be after a single (circular) owin object and a line segment 
pattern consisting of the 4 diameters.  Or you might be after *eight* 
owin objects, each being one the eight disc-segments into which the 
diameters divide the disc.

I shall assume the latter.  To start with define a function, say "wedge":

wedge <- function(theta1,theta2,radius,npoly=100,centre=c(0,0)){
     library(spatstat)
# Should do some checking on the values of theta1 and theta2 here,
# but I shan't bother.
     theta <- seq(theta1,theta2,length=npoly+1)
     x <- c(0,radius*cos(theta),0)
     y <- c(0,radius*sin(theta),0)
     W <- owin(poly=list(x=x,y=y))
     return(affine(W,vec=centre))
}

Then do something like:

wedgies <- vector("list",length=8)
cntr <- c(673593.21,673593.21)
for(i in 1:8) wedgies[[i]] <- wedge((i-1)*pi/4,i*pi/4,15,centre=cntr)
ttt <- tess(tiles=wedgies)
plot(ttt) # Looks OK to me.

And maybe also do:

W <- do.call(union.owin,wedgies)
plot(W)
for(i in 1:8) {
     plot(wedgies[[i]],add=TRUE,border="red")
     readline("Go? ")
}

Also looks OK to me.

Is *this* what you want?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ashimkapoor at gmail.com  Wed Sep 13 10:23:24 2017
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Wed, 13 Sep 2017 13:53:24 +0530
Subject: [R] ggmap + geom_raster
Message-ID: <CAC8=1epN7kcyfT-+p96XF4xTOqutF9dfYk0xDwbpO3QLzhZTwA@mail.gmail.com>

Dear all,

I want to :

1. Estimate a weighted 2D kernel.
2. Paint a heatmap on a ggmap.

Here is some reproducible data / code (I got it from the internet) :

s_rit <- structure(list(score = c(45, 60, 38, 98, 98, 53, 90, 42, 96,
45, 89, 18, 66, 2, 45, 98, 6, 83, 63, 86, 63, 81, 70, 8, 78,
15, 7, 86, 15, 63, 55, 13, 83, 76, 78, 70, 64, 88, 61, 78, 4,
7, 1, 70, 88, 58, 70, 58, 11, 45, 28, 42, 45, 73, 85, 86, 25,
17, 53, 95, 49, 80, 70, 35, 94, 61, 39, 76, 28, 1, 18, 93, 73,
67, 56, 38, 45, 66, 18, 76, 91, 76, 52, 60, 2, 38, 73, 95, 1,
76, 6, 25, 76, 81, 35, 49, 85, 55, 66, 90), lat = c(28.040961,
27.321633, 27.457342, 26.541129, 27.889476, 26.365284, 28.555024,
26.541129, 26.272728, 28.279994, 27.889476, 28.279994, 26.6674,
26.272728, 25.776045, 26.541129, 30.247658, 26.365284, 25.450123,
27.889476, 26.541129, 27.264513, 26.718652, 28.044369, 28.251435,
27.264513, 26.272728, 26.272728, 28.040961, 30.312239, 27.889476,
26.541129, 26.6674, 27.321633, 26.365284, 28.279994, 26.718652,
30.23286, 28.040961, 30.193704, 30.312239, 28.044369, 27.457342,
25.450123, 30.23286, 30.312239, 30.193704, 28.279994, 30.247658,
26.541129, 26.365284, 28.279994, 27.321633, 25.776045, 26.272728,
30.23286, 30.312239, 26.718652, 26.541129, 25.450123, 28.251435,
28.185751, 25.450123, 28.040961, 27.321633, 28.279994, 27.321633,
27.321633, 27.321633, 28.279994, 26.718652, 28.362308, 27.264513,
26.365284, 28.279994, 30.23286, 25.450123, 28.362308, 25.450123,
25.776045, 30.193704, 28.251435, 27.457342, 27.321633, 28.185751,
27.457342, 27.889476, 26.541129, 26.541129, 30.23286, 30.312239,
26.718652, 25.450123, 26.139258, 28.040961, 30.23286, 26.718652,
28.185751, 28.044369, 28.555024), lon = c(-82.5498, -80.376729,
-82.525985, -81.843986, -82.317701, -81.796389, -81.276464, -81.843986,
-80.207508, -81.331178, -82.317701, -81.331178, -80.072089, -80.207508,
-80.199437, -81.843986, -81.808664, -81.796389, -80.433557, -82.317701,
-81.843986, -80.432125, -80.091078, -82.394639, -81.490407, -80.432125,
-80.207508, -80.207508, -82.5498, -81.575916, -82.317701, -81.843986,
-80.072089, -80.376729, -81.796389, -81.331178, -80.091078, -81.585975,
-82.5498, -81.579846, -81.575916, -82.394639, -82.525985, -80.433557,
-81.585975, -81.575916, -81.579846, -81.331178, -81.808664, -81.843986,
-81.796389, -81.331178, -80.376729, -80.199437, -80.207508, -81.585975,
-81.575916, -80.091078, -81.843986, -80.433557, -81.490407, -81.289394,
-80.433557, -82.5498, -80.376729, -81.331178, -80.376729, -80.376729,
-80.376729, -81.331178, -80.091078, -81.428494, -80.432125, -81.796389,
-81.331178, -81.585975, -80.433557, -81.428494, -80.433557, -80.199437,
-81.579846, -81.490407, -82.525985, -80.376729, -81.289394, -82.525985,
-82.317701, -81.843986, -81.843986, -81.585975, -81.575916, -80.091078,
-80.433557, -80.238901, -82.5498, -81.585975, -80.091078, -81.289394,
-82.394639, -81.276464)), .Names = c("score", "lat", "lon"), row.names =
c(3205L,
8275L, 4645L, 8962L, 9199L, 340L, 5381L, 8998L, 5476L, 4956L,
9256L, 4940L, 6681L, 5586L, 1046L, 9017L, 1878L, 323L, 4175L,
9236L, 8968L, 6885L, 5874L, 9412L, 6434L, 7168L, 5420L, 5680L,
3202L, 1486L, 9255L, 9009L, 6833L, 8271L, 261L, 5024L, 8028L,
1774L, 3329L, 1824L, 1464L, 9468L, 4643L, 4389L, 1506L, 1441L,
1826L, 4968L, 1952L, 8803L, 339L, 4868L, 8266L, 1334L, 5483L,
1727L, 1389L, 7944L, 8943L, 4416L, 6440L, 526L, 4478L, 3117L,
8308L, 4891L, 8290L, 8299L, 8233L, 4848L, 7922L, 5795L, 6971L,
179L, 4990L, 1776L, 4431L, 5718L, 4268L, 1157L, 1854L, 6433L,
4637L, 8194L, 560L, 4694L, 9274L, 8903L, 8877L, 1586L, 1398L,
5865L, 4209L, 6075L, 3307L, 1634L, 8108L, 514L, 9453L, 5210L), class =
"data.frame")


library(ggmap)
library(RColorBrewer)
MyMap <- get_map(location= "Orlando, FL",
                 source="google",
                 maptype="roadmap", crop=FALSE, zoom=7)
YlOrBr <- c("#FFFFD4", "#FED98E", "#FE9929", "#D95F0E", "#993404")
ggmap(MyMap) + stat_density_2d(data=s_rit, aes(x=lon, y=lat,
fill=..level.., alpha=..level..),
                              geom="polygon", size=0.01, bins=16) +
  scale_fill_gradient(low="red", high="green") +
  scale_alpha(range = c(0,0.3), guide=FALSE)

The above computes 2d density but it does not take the score (the weight
into account). To do a weighted KDE I do :

library(ks)

mydensity <- kde(x = s_rit[,c(2,3)],w = s_rit$score)

This computes a weighted KDE,but the data can't be passed to geom_raster
because the x,y's are 151 each while the estimated density is a matrix 151
x 151. However this can be accepted by image as shown below.


library(reshape2)
library(ggplot2)

x <- mydensity$eval.points[[1]]
y <- mydensity$eval.points[[2]]
z <- mydensity$estimate

image(x,y,z)

How can I convert this data so that I can do ggmap + geom_raster?

Also can I define eval.points in kde in a way that is relevant to the
underlying ggmap? How can I tweak the eval.points in the context of a map ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From matteo.fasiolo at gmail.com  Tue Sep 12 15:26:27 2017
From: matteo.fasiolo at gmail.com (Matteo Fasiolo)
Date: Tue, 12 Sep 2017 14:26:27 +0100
Subject: [R] [R-pkgs]  qgam
Message-ID: <CAC_0WE8Y2crFhu0uDzGACX9eAzC6xDUxWa_Tp4_88MHWEx=RJg@mail.gmail.com>

Dear useRs,

I am happy to announce the publication on CRAN of
the qgam package:
https://cran.r-project.org/web/packages/qgam/index.html

qgam is an extension of mgcv, and provides methods for
fitting quantile additive models including parametric, random and
smooth effects.

For basic examples see the vignette:
https://cran.r-project.org/web/packages/qgam/vignettes/qgam.html

For more details on the underlying methods see the arXived paper:
https://arxiv.org/abs/1707.03307

Comments, criticisms and feature requests are more than welcome.
The package is also available on github:
https://github.com/mfasiolo/qgam

Best,

Matteo Fasiolo

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From David.Brayford at lrz.de  Wed Sep 13 11:23:34 2017
From: David.Brayford at lrz.de (Brayford, David)
Date: Wed, 13 Sep 2017 09:23:34 +0000
Subject: [R] (no subject)
Message-ID: <a9809bc001b2462798c349c62992c85a@lrz.de>

When I try to install gsl in R I get the error Need GSL version >= 1.12 . However, I have version 2.3 of gsl installed on the system, which is picked up earlier in the configure process (see below). Is it possible for someone to fix this error in the configure script?

checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
checking if GSL version >= 1.12... checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
configure: error: Need GSL version >= 1.12
ERROR: configuration failed for package ?gsl?


David


	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Wed Sep 13 14:10:00 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 13 Sep 2017 14:10:00 +0200
Subject: [R] (no subject)
In-Reply-To: <a9809bc001b2462798c349c62992c85a@lrz.de>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
Message-ID: <B68002E0-7F78-4EA4-ADF1-47FD7C3975A7@xs4all.nl>


> On 13 Sep 2017, at 11:23, Brayford, David <David.Brayford at lrz.de> wrote:
> 
> When I try to install gsl in R I get the error Need GSL version >= 1.12 . However, I have version 2.3 of gsl installed on the system, which is picked up earlier in the configure process (see below). Is it possible for someone to fix this error in the configure script?
> 
> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
> checking if GSL version >= 1.12... checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> configure: error: Need GSL version >= 1.12
> ERROR: configuration failed for package ?gsl?
> 

Why don't you send an email to the maintainer of the package?


Berend Hasselman


From msuzen at gmail.com  Wed Sep 13 14:12:14 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Wed, 13 Sep 2017 14:12:14 +0200
Subject: [R] (no subject)
In-Reply-To: <a9809bc001b2462798c349c62992c85a@lrz.de>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
Message-ID: <CAPtbhHy07WE7X5OE_J-M1cqPkCo8sa=knNpeWyESTRxOEX9k9w@mail.gmail.com>

Hello David,

As error message says you have a version dependency not satisfied.
"error: Need GSL version >= 1.12". If you are using Ubuntu for example
you could do;
sudo apt-get install libgsl2

Or you can compile by yourself, I am sure there are people in LRZ can
help you on this:)

Best,
Mehmet

On 13 September 2017 at 11:23, Brayford, David <David.Brayford at lrz.de> wrote:
> When I try to install gsl in R I get the error Need GSL version >= 1.12 . However, I have version 2.3 of gsl installed on the system, which is picked up earlier in the configure process (see below). Is it possible for someone to fix this error in the configure script?
>
> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
> checking if GSL version >= 1.12... checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> configure: error: Need GSL version >= 1.12
> ERROR: configuration failed for package ?gsl?
>
>
> David
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Sep 13 14:57:36 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Sep 2017 08:57:36 -0400
Subject: [R] (no subject)
In-Reply-To: <a9809bc001b2462798c349c62992c85a@lrz.de>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
Message-ID: <6c02a6c0-4c9a-1113-5167-74657a79890d@gmail.com>

On 13/09/2017 5:23 AM, Brayford, David wrote:
> When I try to install gsl in R I get the error Need GSL version >= 1.12 . However, I have version 2.3 of gsl installed on the system, which is picked up earlier in the configure process (see below). Is it possible for someone to fix this error in the configure script?
> 
> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
> checking if GSL version >= 1.12... checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> configure: error: Need GSL version >= 1.12
> ERROR: configuration failed for package ?gsl?
> 


As Berend said, this should be talked about with the maintainer.  It 
would be helpful if you could show more detail of the test that failed.

For example, what does

/lrz/sys/libraries/gsl/2.3/bin/gsl-config --version --cflags

print?  For me, the second line from gsl-config is

-I/usr/local/Cellar/gsl/1.16/include

and I can see using

less /usr/local/Cellar/gsl/1.16/include/gsl/gsl_version.h

that the macros are defined as

#define GSL_VERSION "1.16"
#define GSL_MAJOR_VERSION 1
#define GSL_MINOR_VERSION 16

Presumably you'll get something else...

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Sep 13 16:01:04 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Sep 2017 10:01:04 -0400
Subject: [R] (no subject)
In-Reply-To: <5c60c34b-25e5-a018-c4ad-09eefdc7be96@lrz.de>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
 <6c02a6c0-4c9a-1113-5167-74657a79890d@gmail.com>
 <5c60c34b-25e5-a018-c4ad-09eefdc7be96@lrz.de>
Message-ID: <ad2106fd-d2f2-c261-2334-cd2d906636f4@gmail.com>

On 13/09/2017 9:10 AM, David Brayford wrote:
> Hi Duncan,
> 
> The output of gsl-config --version
> 2.3
> 
> The output of gsl-config --cflags
> -I/lrz/sys/libraries/gsl/2.3/include
> 
> The output of gsl-config --libs
> -L/lrz/sys/libraries/gsl/2.3/lib -lgsl -lgslcblas -lm
> 
> gsl_version.h cat output
> #define GSL_VERSION "2.3"
> #define GSL_MAJOR_VERSION 2
> #define GSL_MINOR_VERSION 3
> 
> It's puzzling.

Sure is.  I can't see what would be going wrong.

Duncan Murdoch

> 
> David
> 
> On 09/13/2017 02:57 PM, Duncan Murdoch wrote:
>> On 13/09/2017 5:23 AM, Brayford, David wrote:
>>> When I try to install gsl in R I get the error Need GSL version >=
>>> 1.12 . However, I have version 2.3 of gsl installed on the system,
>>> which is picked up earlier in the configure process (see below). Is
>>> it possible for someone to fix this error in the configure script?
>>>
>>> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
>>> checking if GSL version >= 1.12... checking for gcc... gcc
>>> checking for C compiler default output file name... a.out
>>> checking whether the C compiler works... yes
>>> checking whether we are cross compiling... no
>>> checking for suffix of executables...
>>> checking for suffix of object files... o
>>> checking whether we are using the GNU C compiler... yes
>>> checking whether gcc accepts -g... yes
>>> checking for gcc option to accept ISO C89... none needed
>>> configure: error: Need GSL version >= 1.12
>>> ERROR: configuration failed for package ?gsl?
>>>
>>
>>
>> As Berend said, this should be talked about with the maintainer. It
>> would be helpful if you could show more detail of the test that failed.
>>
>> For example, what does
>>
>> /lrz/sys/libraries/gsl/2.3/bin/gsl-config --version --cflags
>>
>> print?  For me, the second line from gsl-config is
>>
>> -I/usr/local/Cellar/gsl/1.16/include
>>
>> and I can see using
>>
>> less /usr/local/Cellar/gsl/1.16/include/gsl/gsl_version.h
>>
>> that the macros are defined as
>>
>> #define GSL_VERSION "1.16"
>> #define GSL_MAJOR_VERSION 1
>> #define GSL_MINOR_VERSION 16
>>
>> Presumably you'll get something else...
>>
>> Duncan Murdoch
>>
>


From pdalgd at gmail.com  Wed Sep 13 17:03:07 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Wed, 13 Sep 2017 17:03:07 +0200
Subject: [R] (no subject)
In-Reply-To: <ad2106fd-d2f2-c261-2334-cd2d906636f4@gmail.com>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
 <6c02a6c0-4c9a-1113-5167-74657a79890d@gmail.com>
 <5c60c34b-25e5-a018-c4ad-09eefdc7be96@lrz.de>
 <ad2106fd-d2f2-c261-2334-cd2d906636f4@gmail.com>
Message-ID: <F449A02B-B47D-4FD8-AE4B-D646D429DD89@gmail.com>


> On 13 Sep 2017, at 16:01 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 13/09/2017 9:10 AM, David Brayford wrote:
>> Hi Duncan,
>> The output of gsl-config --version
>> 2.3
>> The output of gsl-config --cflags
>> -I/lrz/sys/libraries/gsl/2.3/include
>> The output of gsl-config --libs
>> -L/lrz/sys/libraries/gsl/2.3/lib -lgsl -lgslcblas -lm
>> gsl_version.h cat output
>> #define GSL_VERSION "2.3"
>> #define GSL_MAJOR_VERSION 2
>> #define GSL_MINOR_VERSION 3
>> It's puzzling.
> 
> Sure is.  I can't see what would be going wrong.


Two ideas: 

1. The include file might be there but not the actual library (or a different version gets picked up via an -L setting)
2. The error message can be spurious and reflect a completely different problem. It looks a little odd that the ERROR does not appear immediately after "checking if GSL version >= 1.12..." (is some sort of parallel make going on, perchance?)

If push comes to shove, you may have to learn how to decipher config.log etc. to see exactly which test is failing and why.

-pd


> 
> Duncan Murdoch
> 
>> David
>> On 09/13/2017 02:57 PM, Duncan Murdoch wrote:
>>> On 13/09/2017 5:23 AM, Brayford, David wrote:
>>>> When I try to install gsl in R I get the error Need GSL version >=
>>>> 1.12 . However, I have version 2.3 of gsl installed on the system,
>>>> which is picked up earlier in the configure process (see below). Is
>>>> it possible for someone to fix this error in the configure script?
>>>> 
>>>> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
>>>> checking if GSL version >= 1.12... checking for gcc... gcc
>>>> checking for C compiler default output file name... a.out
>>>> checking whether the C compiler works... yes
>>>> checking whether we are cross compiling... no
>>>> checking for suffix of executables...
>>>> checking for suffix of object files... o
>>>> checking whether we are using the GNU C compiler... yes
>>>> checking whether gcc accepts -g... yes
>>>> checking for gcc option to accept ISO C89... none needed
>>>> configure: error: Need GSL version >= 1.12
>>>> ERROR: configuration failed for package ?gsl?
>>>> 
>>> 
>>> 
>>> As Berend said, this should be talked about with the maintainer. It
>>> would be helpful if you could show more detail of the test that failed.
>>> 
>>> For example, what does
>>> 
>>> /lrz/sys/libraries/gsl/2.3/bin/gsl-config --version --cflags
>>> 
>>> print?  For me, the second line from gsl-config is
>>> 
>>> -I/usr/local/Cellar/gsl/1.16/include
>>> 
>>> and I can see using
>>> 
>>> less /usr/local/Cellar/gsl/1.16/include/gsl/gsl_version.h
>>> 
>>> that the macros are defined as
>>> 
>>> #define GSL_VERSION "1.16"
>>> #define GSL_MAJOR_VERSION 1
>>> #define GSL_MINOR_VERSION 16
>>> 
>>> Presumably you'll get something else...
>>> 
>>> Duncan Murdoch
>>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From David.Brayford at lrz.de  Wed Sep 13 15:10:30 2017
From: David.Brayford at lrz.de (David Brayford)
Date: Wed, 13 Sep 2017 15:10:30 +0200
Subject: [R] (no subject)
In-Reply-To: <6c02a6c0-4c9a-1113-5167-74657a79890d@gmail.com>
References: <a9809bc001b2462798c349c62992c85a@lrz.de>
 <6c02a6c0-4c9a-1113-5167-74657a79890d@gmail.com>
Message-ID: <5c60c34b-25e5-a018-c4ad-09eefdc7be96@lrz.de>

Hi Duncan,

The output of gsl-config --version
2.3

The output of gsl-config --cflags
-I/lrz/sys/libraries/gsl/2.3/include

The output of gsl-config --libs
-L/lrz/sys/libraries/gsl/2.3/lib -lgsl -lgslcblas -lm

gsl_version.h cat output
#define GSL_VERSION "2.3"
#define GSL_MAJOR_VERSION 2
#define GSL_MINOR_VERSION 3

It's puzzling.

David

On 09/13/2017 02:57 PM, Duncan Murdoch wrote:
> On 13/09/2017 5:23 AM, Brayford, David wrote:
>> When I try to install gsl in R I get the error Need GSL version >= 
>> 1.12 . However, I have version 2.3 of gsl installed on the system, 
>> which is picked up earlier in the configure process (see below). Is 
>> it possible for someone to fix this error in the configure script?
>>
>> checking for gsl-config... /lrz/sys/libraries/gsl/2.3/bin/gsl-config
>> checking if GSL version >= 1.12... checking for gcc... gcc
>> checking for C compiler default output file name... a.out
>> checking whether the C compiler works... yes
>> checking whether we are cross compiling... no
>> checking for suffix of executables...
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc accepts -g... yes
>> checking for gcc option to accept ISO C89... none needed
>> configure: error: Need GSL version >= 1.12
>> ERROR: configuration failed for package ?gsl?
>>
>
>
> As Berend said, this should be talked about with the maintainer. It 
> would be helpful if you could show more detail of the test that failed.
>
> For example, what does
>
> /lrz/sys/libraries/gsl/2.3/bin/gsl-config --version --cflags
>
> print?  For me, the second line from gsl-config is
>
> -I/usr/local/Cellar/gsl/1.16/include
>
> and I can see using
>
> less /usr/local/Cellar/gsl/1.16/include/gsl/gsl_version.h
>
> that the macros are defined as
>
> #define GSL_VERSION "1.16"
> #define GSL_MAJOR_VERSION 1
> #define GSL_MINOR_VERSION 16
>
> Presumably you'll get something else...
>
> Duncan Murdoch
>


From emorway at usgs.gov  Wed Sep 13 18:52:30 2017
From: emorway at usgs.gov (Morway, Eric)
Date: Wed, 13 Sep 2017 09:52:30 -0700
Subject: [R] compounding precipitation based on whether falls within a day
Message-ID: <CAPoqHzquF0okjL4O4gJFuVs0c=YzCAZDm90ATF2rCjjdCxHyRg@mail.gmail.com>

Using the small reproducible example below, I'm wondering how best to
complete the following task:

In the small reproducible example below, the 3D array prec has indexes that
correspond to time, x, y (i.e., prec[time, x, y]).  In this case, the time
index is hours since some predefined start time.  I'd like to add up all
the time indexes in 'prec' based on whether or not the corresponding hours
fall within a given day.  So, at the end of the small example below, there
are two variables that I'm left with, prec_idx (an hourly sequence from
beg_time to end_time) whose length is equal to the first index (the time
index) of the 3D array of precipitation called prec.  That is, I'd like to
get a 3D array called prec*_daily* that has dimension prec*_daily*[21, 3, 4],
where 21 is the number of days and the value in say prec*_daily*[1,x,y] is
equal to prec[1,x,y] + prec[2,x,y] + ... + prec[24,x,y]


ndays <- 21
base_time <- as.character('2001-12-31T23:00:00Z')
hrs_since_base <- 1

# adding an extra second to the end b/c I'm paranoid about the midnight
time stamp not being explicit
beg_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
(hrs_since_base * 60 * 60) + 1

max_hr_since <- 24 * ndays
end_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
(max_hr_since * 60 * 60) + 1

prec_idx <- seq(beg_time, end_time, by='hour')

prec <- array(abs(rnorm((24*ndays) * 3 * 4)) , dim=c(24*ndays, 3, 4))

length(prec_idx)
# 504
dim(prec)
# 504   3   4

# How do I aggregate prec to get daily sums of precipitation based on the
prec_idx array?

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Sep 13 20:06:16 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 13 Sep 2017 11:06:16 -0700
Subject: [R] compounding precipitation based on whether falls within a
	day
In-Reply-To: <CAPoqHzquF0okjL4O4gJFuVs0c=YzCAZDm90ATF2rCjjdCxHyRg@mail.gmail.com>
References: <CAPoqHzquF0okjL4O4gJFuVs0c=YzCAZDm90ATF2rCjjdCxHyRg@mail.gmail.com>
Message-ID: <CAGxFJbR04=e6ttunpHv9KbKEQoD2EK8-Z0H2v=cWu_pR41PvAA@mail.gmail.com>

Thanks for the reprex. Wouldn't have bothered without it.

The following is I believe **almost** what you want. It seems a bit clumsy
to me, so others may provide you something neater. But anyway...

## Convert POSIXct vector to dates
## There are 22 different days, not 21
date <- as.Date(prec_idx)

## Sum results by date at each i,j of the last 2 array dimensions
z <- lapply(unique(date),function(d)
   apply(prec[date==d,,],2:3,sum)
   )

## This gives a list with 22 3x4 matrices of sums.
## Convert to 3x4x22 array with

prec_daily <- array(unlist(z),dim=c(3,4,22))

## This is the **almost** part. You can use the aperm() function to reshape
the array if you like. I leave those pleasures to you.

HTH.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 13, 2017 at 9:52 AM, Morway, Eric <emorway at usgs.gov> wrote:

> Using the small reproducible example below, I'm wondering how best to
> complete the following task:
>
> In the small reproducible example below, the 3D array prec has indexes that
> correspond to time, x, y (i.e., prec[time, x, y]).  In this case, the time
> index is hours since some predefined start time.  I'd like to add up all
> the time indexes in 'prec' based on whether or not the corresponding hours
> fall within a given day.  So, at the end of the small example below, there
> are two variables that I'm left with, prec_idx (an hourly sequence from
> beg_time to end_time) whose length is equal to the first index (the time
> index) of the 3D array of precipitation called prec.  That is, I'd like to
> get a 3D array called prec*_daily* that has dimension prec*_daily*[21, 3,
> 4],
> where 21 is the number of days and the value in say prec*_daily*[1,x,y] is
> equal to prec[1,x,y] + prec[2,x,y] + ... + prec[24,x,y]
>
>
> ndays <- 21
> base_time <- as.character('2001-12-31T23:00:00Z')
> hrs_since_base <- 1
>
> # adding an extra second to the end b/c I'm paranoid about the midnight
> time stamp not being explicit
> beg_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
> (hrs_since_base * 60 * 60) + 1
>
> max_hr_since <- 24 * ndays
> end_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
> (max_hr_since * 60 * 60) + 1
>
> prec_idx <- seq(beg_time, end_time, by='hour')
>
> prec <- array(abs(rnorm((24*ndays) * 3 * 4)) , dim=c(24*ndays, 3, 4))
>
> length(prec_idx)
> # 504
> dim(prec)
> # 504   3   4
>
> # How do I aggregate prec to get daily sums of precipitation based on the
> prec_idx array?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Sep 13 20:57:12 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 13 Sep 2017 13:57:12 -0500
Subject: [R] Proxy Issues when trying to install package shinyapps
Message-ID: <CAMOcQfOBUpBfRqZ7kLwa9mVBvgdiS1pgywfJdnXS2whNmB8N8g@mail.gmail.com>

Dear all,

Hope you are doing great. I have been trying to install package shinyapps
on R studio but I get the following messages:

> devtools::install_github('rstudio/shinyapps')
Installation failed: Couldn't resolve proxy 'procuratio.canal.acp'

> githubinstall("shinyapps")
Error in curl::curl_download(input, tt, mode = "wb", quiet = !showProgress)
:
  Couldn't resolve proxy 'procuratio.canal.acp'

Does anyone know a way to bypass the proxy or make it work so I can install
R shiny packages?

Any help will be greatly appreciated,

Paul

	[[alternative HTML version deleted]]


From jetodd94 at gmail.com  Wed Sep 13 21:50:02 2017
From: jetodd94 at gmail.com (Jessie Todd)
Date: Wed, 13 Sep 2017 15:50:02 -0400
Subject: [R] Help in R
Message-ID: <F810ADDA-F7E6-4402-89CF-DBC9BA435A36@gmail.com>

I don?t know if my question is answerable, but it is worth a try. I have a data set that I am trying to analyze in R for a course and the instructions were to get a standard deviation which I already computed in R and use that number and change it to a biased standard deviation?.(I have the two equations and I understand the difference between the two and how the unbiased has the degree of freedom?..I just do not know how use my standard deviation and transform it in R to a biased one.
Thanks in advance,
Jessie

From r.turner at auckland.ac.nz  Wed Sep 13 23:16:05 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 14 Sep 2017 09:16:05 +1200
Subject: [R] [FORGED]  Help in R
In-Reply-To: <F810ADDA-F7E6-4402-89CF-DBC9BA435A36@gmail.com>
References: <F810ADDA-F7E6-4402-89CF-DBC9BA435A36@gmail.com>
Message-ID: <3fccbc56-ea44-98f1-bbe3-d227c6c2b3f4@auckland.ac.nz>


On 14/09/17 07:50, Jessie Todd wrote:

> I don?t know if my question is answerable, but it is worth a try. I
> have a data set that I am trying to analyze in R for a course and the
> instructions were to get a standard deviation which I already
> computed in R and use that number and change it to a biased standard
> deviation?.(I have the two equations and I understand the difference
> between the two and how the unbiased has the degree of freedom?..I
> just do not know how use my standard deviation and transform it in R
> to a biased one.

This list has a no-homework policy, and I would say "ask your lecturer" 
but it seems your lecturer could be a bit out to lunch, so that might be 
bad advice.

Standard deviations estimates are *always* biased!  (That might be a 
slight overstatement but it is essentially correct.)

What may be biased or unbiased are *variance* estimates.  In the 
simplest setting:

    V1 = (1/n) sum_{i=1)^n (x_i - xbar)^2 is biased.

I.e. E(V1) is not equal to sigma^2, the population variance.

    V2 = (1/(n-1)) sum_{i=1)^n (x_i - xbar)^2 is unbiased.

I.e. E(V2) *is* equal to sigma^2.

The var() function in R gives you the unbiased estimate of variance.

It's a piece of cake to obtain the biased estimate of variance from the
unbiased one --- just multiply by appropriate constant.  (Hint:  this 
constant involves n and n-1. :-) )

What your lecturer *probably* wants you to do is form the biased 
estimate of variance and then estimate the standard deviation by taking
the square root of the biased estimate.

To verify whether the foregoing conjecture is true, you'll have to ask 
your lecturer.  Good luck

Note *both* sqrt(V1) and sqrt(V2) are *biased* estimates of sigma (the 
population standard deviation).

HTH

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ruipbarradas at sapo.pt  Thu Sep 14 00:39:23 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 13 Sep 2017 23:39:23 +0100
Subject: [R] Help in R
In-Reply-To: <F810ADDA-F7E6-4402-89CF-DBC9BA435A36@gmail.com>
Message-ID: <20170913233923.Horde.Eac8M9qrsiULG4aGlRRb2rq@mail.sapo.pt>

Hello,

Post the two equations, a sample dataset and what you have tried, please.
At the bottom of every mail there's a link to the posting guide where  
you will find instructions on how to ask a good question.

Hope this helps,

Rui Barradas


Citando Jessie Todd <jetodd94 at gmail.com>:

> I don?t know if my question is answerable, but it is worth a try. I  
> have a data set that I am trying to analyze in R for a course and  
> the instructions were to get a standard deviation which I already  
> computed in R and use that number and change it to a biased standard  
> deviation?.(I have the two equations and I understand the difference  
> between the two and how the unbiased has the degree of freedom?..I  
> just do not know how use my standard deviation and transform it in R  
> to a biased one.
> Thanks in advance,
> Jessie
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From L.J.Bonnett at liverpool.ac.uk  Thu Sep 14 09:30:13 2017
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Thu, 14 Sep 2017 07:30:13 +0000
Subject: [R] Help understanding why glm and lrm.fit runs with my data,
 but lrm does not
Message-ID: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>

Dear all,

I am using the publically available GustoW dataset.  The exact version I am using is available here: https://drive.google.com/open?id=0B4oZ2TQA0PAoUm85UzBFNjZ0Ulk

I would like to produce a nomogram for 5 covariates - AGE, HYP, KILLIP, HRT and ANT.  I have successfully fitted a logistic regression model using the "glm" function as shown below.

library(rms)
gusto <- spss.get("GustoW.sav")
fit <- glm(DAY30~AGE+HYP+factor(KILLIP)+HRT+ANT,family=binomial(link="logit"),data=gusto,x=TRUE,y=TRUE)

However, my review of the literature and other websites suggest I need to use "lrm" for the purposes of producing a nomogram.  When I run the command using "lrm" (see below) I get an error message saying:
Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
  Unable to fit model using "lrm.fit"

My code is as follows:
gusto2 <- gusto[,c(1,3,5,8,9,10)]
gusto2$HYP <- factor(gusto2$HYP, labels=c("No","Yes"))
gusto2$KILLIP <- factor(gusto2$KILLIP, labels=c("1","2","3","4"))
gusto2$HRT <- factor(gusto2$HRT, labels=c("No","Yes"))
gusto2$ANT <- factor(gusto2$ANT, labels=c("No","Yes"))
var.labels=c(DAY30="30-day Mortality", AGE="Age in Years", KILLIP="Killip Class", HYP="Hypertension", HRT="Tachycardia", ANT="Anterior Infarct Location")
label(gusto2)=lapply(names(var.labels),function(x) label(gusto2[,x])=var.labels[x])

ddist = datadist(gusto2)
options(datadist='ddist')

fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT,gusto2)

Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
  Unable to fit model using "lrm.fit"

Online solutions to this problem involve checking whether any variables are redundant.  However, the results for my data suggest  that none are.
redun(~AGE+HYP+KILLIP+HRT+ANT,gusto2)

Redundancy Analysis

redun(formula = ~AGE + HYP + KILLIP + HRT + ANT, data = gusto2)

n: 2188         p: 5    nk: 3

Number of NAs:   0

Transformation of target variables forced to be linear

R-squared cutoff: 0.9   Type: ordinary

R^2 with which each variable can be predicted from all other variables:

   AGE    HYP KILLIP    HRT    ANT
 0.028  0.032  0.053  0.046  0.040

No redundant variables

I've also tried just considering "lrm.fit" and that code seems to run without error too:
lrm.fit(cbind(gusto2$AGE,gusto2$KILLIP,gusto2$HYP,gusto2$HRT,gusto2$ANT),gusto2$DAY30)

Logistic Regression Model

 lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
     gusto2$ANT), y = gusto2$DAY30)

                       Model Likelihood     Discrimination    Rank Discrim.
                          Ratio Test           Indexes           Indexes
 Obs          2188    LR chi2     233.59    R2       0.273    C       0.846
  0           2053    d.f.             5    g        1.642    Dxy     0.691
  1            135    Pr(> chi2) <0.0001    gr       5.165    gamma   0.696
 max |deriv| 4e-09                          gp       0.079    tau-a   0.080
                                            Brier    0.048

           Coef     S.E.   Wald Z Pr(>|Z|)
 Intercept -13.8515 0.9694 -14.29 <0.0001
 x[1]        0.0989 0.0103   9.58 <0.0001
 x[2]        0.9030 0.1510   5.98 <0.0001
 x[3]        1.3576 0.2570   5.28 <0.0001
 x[4]        0.6884 0.2034   3.38 0.0007
 x[5]        0.6327 0.2003   3.16 0.0016

I was therefore hoping someone would explain why the "lrm" code is producing an error message, while "lrm.fit" and "glm" do not.  In particular I would welcome a solution to ensure I can produce a nomogram.

Kind regards,
Laura

Dr Laura Bonnett
NIHR Post-Doctoral Fellow

Department of Biostatistics,
Waterhouse Building, Block F,
1-5 Brownlow Street,
University of Liverpool,
Liverpool,
L69 3GL

0151 795 9686
L.J.Bonnett at liverpool.ac.uk



	[[alternative HTML version deleted]]


From JTELLERIA at external.gamesacorp.com  Thu Sep 14 09:48:04 2017
From: JTELLERIA at external.gamesacorp.com (TELLERIA RUIZ DE AGUIRRE, JUAN)
Date: Thu, 14 Sep 2017 07:48:04 +0000
Subject: [R] Print All Warnings that Occurr in All Parallel Nodes
Message-ID: <C7D958509BBBF44A8F8F9CBE5BE940076561B395@EXDG02.usr.corp.gamesa.es>

Dear R Users,

I have developed the following code for importing a series of zipped CSV by parallel computing.

My problems are that:

A) Some ZIP Files (Which contain CSVs inside) are corrupted, and cannot be opened.
B) After executing parRapply I can only see the last.warning variable error, for knowing which CSV have failed in each node, but I cannot see all warnings, only 1 at a time.

So:

* For showing a list of all warnings in all nodes, I was thinking of using the following function in the code:

    warnings(DISPOIN_CSV_List <- parRapply(c1, DISPOIN_DIR_REL, parRaplly_Function))

    Would this work?

* And also, How could I check that a CSV can be opened before applying the function, and create an empty data.frame for those CSV.

Thank you,
Juan


CODE
################################################################################
## DISPOIN Data Import Into MariaDB
################################################################################

## -----------------------------------------------------------------------------
## Packages
## -----------------------------------------------------------------------------

# update.packages("RODBC")
# update.packages("tidyverse")

## -----------------------------------------------------------------------------
## Libraries
## -----------------------------------------------------------------------------

suppressMessages(require(RODBC))
suppressMessages(require(tidyverse))
suppressMessages(require(parallel))

## -----------------------------------------------------------------------------
## CMD: Command for DISPOIN's Directory Acquisition
## -----------------------------------------------------------------------------

# shell(cmd = 'pushd "\\srvdiscsv\data" && dir *AL*.zip /b /s > D:\DISPOIN_Data_Directories.csv && popd')

## -----------------------------------------------------------------------------
## RODBC
## -----------------------------------------------------------------------------

## A) MariaDB Connection String

con <- odbcConnect("MariaDB_Tornado24")

invisible(sqlQuery(con, "USE dispoin;"))

# B) Import R Data Directories from MariaDB

DISPOIN_DIR_REL <- as_tibble(sqlFetch(con, "dispoin.t_DISPOIN_DIR_REL"))

odbcClose(con)

# C) Import Zipped CSV data into List of Dataframes, which latter on are compiled as a single dataframe by
#    means of rbind

  # C.1) parRapply Function Initialization:

  parRaplly_Function <- function (DISPOIN_CSV_Row)
  {
    return(read_csv2(
      file = DISPOIN_CSV_Row,
      col_names = c(
        "SCADA",
        "TAG",
        "ID_del_AEG",
        "Descripcion",
        "Time_ON",
        "Time_OFF",
        "Delta_Time",
        "Comentario",
        "Es_Alarma",
        "Es_Ultima",
        "Comentarios"),
      col_types = cols(
        "SCADA" = "c",
        "TAG" = "c",
        "ID_del_AEG" = "c",
        "Descripcion" = "c",
        "Time_ON" = "c",
        "Time_OFF" = "c",
        "Delta_Time" = "c",
        "Comentario" = "c",
        "Es_Alarma" = "c",
        "Es_Ultima" = "c",
        "Comentarios" = "c"),
      locale = default_locale(),
      na = c("", " "),
      quoted_na = TRUE,
      quote = "\"",
      comment = "",
      trim_ws = TRUE,
      skip = 0,
      n_max = Inf,
      guess_max = min(1000, n_max),
      progress = FALSE))
  }

  # C.2) parallel Package: Environment Settings

  no_cores <- detectCores()

  c1 <- makeCluster(no_cores)

  invisible(clusterEvalQ(c1, library(readr)))

  setDefaultCluster(c1)

  # C.3) parRapply Function Application:

  DISPOIN_CSV_List <- parRapply(c1, DISPOIN_DIR_REL, parRaplly_Function)

  suppressWarnings(stopCluster(c1))

# D) List's Tibbles Compilation into a single Tibble:

  DISPOIN_CSV <- do.call(rbind, DISPOIN_CSV_List)

# E) Write Compiled Table into CSV:

  write_csv(
    DISPOIN_CSV,
    path = file.path("D:/MySQL/R", "DISPOIN_CSV.csv"),
    na = "\\N",
    append = FALSE,
    col_names = TRUE)

# F) Data Cleaning: Environment Variable Removal

  rm(list=ls())

	[[alternative HTML version deleted]]


From rhelp at eoos.dds.nl  Thu Sep 14 13:18:47 2017
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Thu, 14 Sep 2017 13:18:47 +0200
Subject: [R] Help understanding why glm and lrm.fit runs with my data,
 but lrm does not
In-Reply-To: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
References: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
Message-ID: <32b71051-3a3c-3ca5-c062-18f8706e94a5@eoos.dds.nl>


With lrm.fit you are fitting a completely different model. One of the 
things lrm does, is preparing the input for lrm.fit which in this case 
means that dummy variables are generated for categorical variables such 
as 'KILLIP'.

The error message means that model did not converge after the maximum 
number of iterations. One possible solution is to try to increase the 
maximum number of iterations, e.g.:

fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT, data = gusto2, maxit = 100)

HTH,

Jan



On 14-09-17 09:30, Bonnett, Laura wrote:
> Dear all,
> 
> I am using the publically available GustoW dataset.  The exact version I am using is available here: https://drive.google.com/open?id=0B4oZ2TQA0PAoUm85UzBFNjZ0Ulk
> 
> I would like to produce a nomogram for 5 covariates - AGE, HYP, KILLIP, HRT and ANT.  I have successfully fitted a logistic regression model using the "glm" function as shown below.
> 
> library(rms)
> gusto <- spss.get("GustoW.sav")
> fit <- glm(DAY30~AGE+HYP+factor(KILLIP)+HRT+ANT,family=binomial(link="logit"),data=gusto,x=TRUE,y=TRUE)
> 
> However, my review of the literature and other websites suggest I need to use "lrm" for the purposes of producing a nomogram.  When I run the command using "lrm" (see below) I get an error message saying:
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>    Unable to fit model using "lrm.fit"
> 
> My code is as follows:
> gusto2 <- gusto[,c(1,3,5,8,9,10)]
> gusto2$HYP <- factor(gusto2$HYP, labels=c("No","Yes"))
> gusto2$KILLIP <- factor(gusto2$KILLIP, labels=c("1","2","3","4"))
> gusto2$HRT <- factor(gusto2$HRT, labels=c("No","Yes"))
> gusto2$ANT <- factor(gusto2$ANT, labels=c("No","Yes"))
> var.labels=c(DAY30="30-day Mortality", AGE="Age in Years", KILLIP="Killip Class", HYP="Hypertension", HRT="Tachycardia", ANT="Anterior Infarct Location")
> label(gusto2)=lapply(names(var.labels),function(x) label(gusto2[,x])=var.labels[x])
> 
> ddist = datadist(gusto2)
> options(datadist='ddist')
> 
> fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> 
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>    Unable to fit model using "lrm.fit"
> 
> Online solutions to this problem involve checking whether any variables are redundant.  However, the results for my data suggest  that none are.
> redun(~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> 
> Redundancy Analysis
> 
> redun(formula = ~AGE + HYP + KILLIP + HRT + ANT, data = gusto2)
> 
> n: 2188         p: 5    nk: 3
> 
> Number of NAs:   0
> 
> Transformation of target variables forced to be linear
> 
> R-squared cutoff: 0.9   Type: ordinary
> 
> R^2 with which each variable can be predicted from all other variables:
> 
>     AGE    HYP KILLIP    HRT    ANT
>   0.028  0.032  0.053  0.046  0.040
> 
> No redundant variables
> 
> I've also tried just considering "lrm.fit" and that code seems to run without error too:
> lrm.fit(cbind(gusto2$AGE,gusto2$KILLIP,gusto2$HYP,gusto2$HRT,gusto2$ANT),gusto2$DAY30)
> 
> Logistic Regression Model
> 
>   lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
>       gusto2$ANT), y = gusto2$DAY30)
> 
>                         Model Likelihood     Discrimination    Rank Discrim.
>                            Ratio Test           Indexes           Indexes
>   Obs          2188    LR chi2     233.59    R2       0.273    C       0.846
>    0           2053    d.f.             5    g        1.642    Dxy     0.691
>    1            135    Pr(> chi2) <0.0001    gr       5.165    gamma   0.696
>   max |deriv| 4e-09                          gp       0.079    tau-a   0.080
>                                              Brier    0.048
> 
>             Coef     S.E.   Wald Z Pr(>|Z|)
>   Intercept -13.8515 0.9694 -14.29 <0.0001
>   x[1]        0.0989 0.0103   9.58 <0.0001
>   x[2]        0.9030 0.1510   5.98 <0.0001
>   x[3]        1.3576 0.2570   5.28 <0.0001
>   x[4]        0.6884 0.2034   3.38 0.0007
>   x[5]        0.6327 0.2003   3.16 0.0016
> 
> I was therefore hoping someone would explain why the "lrm" code is producing an error message, while "lrm.fit" and "glm" do not.  In particular I would welcome a solution to ensure I can produce a nomogram.
> 
> Kind regards,
> Laura
> 
> Dr Laura Bonnett
> NIHR Post-Doctoral Fellow
> 
> Department of Biostatistics,
> Waterhouse Building, Block F,
> 1-5 Brownlow Street,
> University of Liverpool,
> Liverpool,
> L69 3GL
> 
> 0151 795 9686
> L.J.Bonnett at liverpool.ac.uk
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ashenkin at ufl.edu  Thu Sep 14 14:58:51 2017
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Thu, 14 Sep 2017 13:58:51 +0100
Subject: [R] To implement OO or not in R package, and if so,
	how to structure it?
Message-ID: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>

Hello all,

I am trying to decide how to structure an R package.  Specifically, do I 
use OO classes, or just provide functions?  If the former, how should I 
structure the objects in relation to the type of data the package is 
intended to manage?

I have searched for, but haven't found, resources that guide one in the 
*decision* about whether to implement OO frameworks or not in one's R 
package.  I suspect I should, but the utility of the package would be 
aided by *collections* of objects.  R, however, doesn't seem to 
implement collections.

Background: I am writing an R package that will provide a framework for 
analyzing structural models of trees (as in trees made of wood, not 
statistical trees).  These models are generated from laser scanning 
instruments and model fitting algorithms, and hence may have aspects 
that are data-heavy.  Furthermore, coputing metrics based on these 
structures can be computationally heavy.  Finally, as a result, each 
tree has a number of metrics associated with it (which may be expensive 
to calculate), along with the underlying data of that tree.  It will be 
important as well to perform calculations across many of these trees, as 
one would do in a dataframe.

This last point is important: if one organizes data across potentially 
thousands of objects, how easy or hard is it to massage properties of 
those objects into a dataframe for analysis?

Thank you in advance for thoughts and pointers.

Allie


From petr.pikal at precheza.cz  Thu Sep 14 15:24:35 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 14 Sep 2017 13:24:35 +0000
Subject: [R] To implement OO or not in R package, and if so,
 how to structure it?
In-Reply-To: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>

Hi

I do not consider myself as an expert in field of R package programming but if your data are rectangular, why not use data.frames.

OTOH if they are structured in free form (something like lm result) you could use lists.

Did you read this?
https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf

Maybe it could give you some insight in how to create package.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alexander
> Shenkin
> Sent: Thursday, September 14, 2017 2:59 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] To implement OO or not in R package, and if so, how to structure
> it?
>
> Hello all,
>
> I am trying to decide how to structure an R package.  Specifically, do I use OO
> classes, or just provide functions?  If the former, how should I structure the
> objects in relation to the type of data the package is intended to manage?
>
> I have searched for, but haven't found, resources that guide one in the
> *decision* about whether to implement OO frameworks or not in one's R
> package.  I suspect I should, but the utility of the package would be aided by
> *collections* of objects.  R, however, doesn't seem to implement collections.
>
> Background: I am writing an R package that will provide a framework for
> analyzing structural models of trees (as in trees made of wood, not statistical
> trees).  These models are generated from laser scanning instruments and model
> fitting algorithms, and hence may have aspects that are data-heavy.
> Furthermore, coputing metrics based on these structures can be
> computationally heavy.  Finally, as a result, each tree has a number of metrics
> associated with it (which may be expensive to calculate), along with the
> underlying data of that tree.  It will be important as well to perform
> calculations across many of these trees, as one would do in a dataframe.
>
> This last point is important: if one organizes data across potentially thousands
> of objects, how easy or hard is it to massage properties of those objects into a
> dataframe for analysis?
>
> Thank you in advance for thoughts and pointers.
>
> Allie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From h.wickham at gmail.com  Thu Sep 14 15:29:46 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 14 Sep 2017 08:29:46 -0500
Subject: [R] To implement OO or not in R package, and if so,
 how to structure it?
In-Reply-To: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
Message-ID: <CABdHhvHZ8ZLXJXTcru5jkSRmOwunyRPGPy=80193f=j2-=sU1w@mail.gmail.com>

I just finished the first draft of the chapters on OO programming for
the 2nd edition of "Advanced R": https://adv-r.hadley.nz - you might
find them helpful.

Hadley

On Thu, Sep 14, 2017 at 7:58 AM, Alexander Shenkin <ashenkin at ufl.edu> wrote:
> Hello all,
>
> I am trying to decide how to structure an R package.  Specifically, do I use
> OO classes, or just provide functions?  If the former, how should I
> structure the objects in relation to the type of data the package is
> intended to manage?
>
> I have searched for, but haven't found, resources that guide one in the
> *decision* about whether to implement OO frameworks or not in one's R
> package.  I suspect I should, but the utility of the package would be aided
> by *collections* of objects.  R, however, doesn't seem to implement
> collections.
>
> Background: I am writing an R package that will provide a framework for
> analyzing structural models of trees (as in trees made of wood, not
> statistical trees).  These models are generated from laser scanning
> instruments and model fitting algorithms, and hence may have aspects that
> are data-heavy.  Furthermore, coputing metrics based on these structures can
> be computationally heavy.  Finally, as a result, each tree has a number of
> metrics associated with it (which may be expensive to calculate), along with
> the underlying data of that tree.  It will be important as well to perform
> calculations across many of these trees, as one would do in a dataframe.
>
> This last point is important: if one organizes data across potentially
> thousands of objects, how easy or hard is it to massage properties of those
> objects into a dataframe for analysis?
>
> Thank you in advance for thoughts and pointers.
>
> Allie
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From h.wickham at gmail.com  Thu Sep 14 15:33:01 2017
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 14 Sep 2017 08:33:01 -0500
Subject: [R] To implement OO or not in R package, and if so,
 how to structure it?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>
Message-ID: <CABdHhvHy9_71dVf3kofWDTBfAYd55n1Ty1sPPJ98oKQxNHa9Lg@mail.gmail.com>

> Did you read this?
> https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf
>
> Maybe it could give you some insight in how to create package.

That resource is ~9 years old. There are more modern treatments
available. You can read mine at http://r-pkgs.had.co.nz.

Hadley


-- 
http://hadley.nz


From petr.pikal at precheza.cz  Thu Sep 14 16:08:07 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 14 Sep 2017 14:08:07 +0000
Subject: [R] To implement OO or not in R package, and if so,
 how to structure it?
In-Reply-To: <CABdHhvHy9_71dVf3kofWDTBfAYd55n1Ty1sPPJ98oKQxNHa9Lg@mail.gmail.com>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>
 <CABdHhvHy9_71dVf3kofWDTBfAYd55n1Ty1sPPJ98oKQxNHa9Lg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAED0A@SRVEXCHCM301.precheza.cz>

Hi Hadley

Yes, I found it too quite easily by Google.

Cheers
Petr

> -----Original Message-----
> From: Hadley Wickham [mailto:h.wickham at gmail.com]
> Sent: Thursday, September 14, 2017 3:33 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Alexander Shenkin <ashenkin at ufl.edu>; r-help <r-help at r-project.org>
> Subject: Re: [R] To implement OO or not in R package, and if so, how to
> structure it?
>
> > Did you read this?
> > https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf
> >
> > Maybe it could give you some insight in how to create package.
>
> That resource is ~9 years old. There are more modern treatments available. You
> can read mine at http://r-pkgs.had.co.nz.
>
> Hadley
>
>
> --
> http://hadley.nz

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ashenkin at ufl.edu  Thu Sep 14 16:27:55 2017
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Thu, 14 Sep 2017 15:27:55 +0100
Subject: [R] To implement OO or not in R package, and if so,
 how to structure it?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAED0A@SRVEXCHCM301.precheza.cz>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>
 <CABdHhvHy9_71dVf3kofWDTBfAYd55n1Ty1sPPJ98oKQxNHa9Lg@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAED0A@SRVEXCHCM301.precheza.cz>
Message-ID: <08d87eae-82a8-09de-08cd-ebe1f3d452c8@ufl.edu>

>>> Did you read this?
>>> https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf
>>>
>>> Maybe it could give you some insight in how to create package.
>>
>> That resource is ~9 years old. There are more modern treatments available. You
>> can read mine at http://r-pkgs.had.co.nz.
>>
>> Hadley
>>

Thanks both.  I'm reading through your new book now Hadley... thanks for 
that.  I'll probably take a shot at building a class to hold one tree 
per object, and search for objects of a class (per 
https://stackoverflow.com/questions/5158830/identify-all-objects-of-given-clas-for-further-processing) 
to implement collections when necessary...

It does seem like there might be niche out there for a resource for 
folks deciding how to structure their package given what they're trying 
to provide; i.e. should they construct a collection of functions, or 
class defs, or...  Could well exist already, and I may just have missed 
it...

Thanks,
Allie


From dwinsemius at comcast.net  Thu Sep 14 17:48:21 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 Sep 2017 08:48:21 -0700
Subject: [R] Help understanding why glm and lrm.fit runs with my data,
	but lrm does not
In-Reply-To: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
References: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
Message-ID: <7235C707-F9A1-434D-B692-D6856FED202B@comcast.net>


> On Sep 14, 2017, at 12:30 AM, Bonnett, Laura <L.J.Bonnett at liverpool.ac.uk> wrote:
> 
> Dear all,
> 
> I am using the publically available GustoW dataset.  The exact version I am using is available here: https://drive.google.com/open?id=0B4oZ2TQA0PAoUm85UzBFNjZ0Ulk
> 
> I would like to produce a nomogram for 5 covariates - AGE, HYP, KILLIP, HRT and ANT.  I have successfully fitted a logistic regression model using the "glm" function as shown below.
> 
> library(rms)
> gusto <- spss.get("GustoW.sav")
> fit <- glm(DAY30~AGE+HYP+factor(KILLIP)+HRT+ANT,family=binomial(link="logit"),data=gusto,x=TRUE,y=TRUE)
> 
> However, my review of the literature and other websites suggest I need to use "lrm" for the purposes of producing a nomogram.  When I run the command using "lrm" (see below) I get an error message saying:
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>  Unable to fit model using "lrm.fit"
> 
> My code is as follows:
> gusto2 <- gusto[,c(1,3,5,8,9,10)]
> gusto2$HYP <- factor(gusto2$HYP, labels=c("No","Yes"))
> gusto2$KILLIP <- factor(gusto2$KILLIP, labels=c("1","2","3","4"))
> gusto2$HRT <- factor(gusto2$HRT, labels=c("No","Yes"))
> gusto2$ANT <- factor(gusto2$ANT, labels=c("No","Yes"))
> var.labels=c(DAY30="30-day Mortality", AGE="Age in Years", KILLIP="Killip Class", HYP="Hypertension", HRT="Tachycardia", ANT="Anterior Infarct Location")
> label(gusto2)=lapply(names(var.labels),function(x) label(gusto2[,x])=var.labels[x])
> 
> ddist = datadist(gusto2)
> options(datadist='ddist')
> 
> fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> 
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>  Unable to fit model using "lrm.fit"
> 
> Online solutions to this problem involve checking whether any variables are redundant.  However, the results for my data suggest  that none are.
> redun(~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> 
> Redundancy Analysis
> 
> redun(formula = ~AGE + HYP + KILLIP + HRT + ANT, data = gusto2)
> 
> n: 2188         p: 5    nk: 3
> 
> Number of NAs:   0
> 
> Transformation of target variables forced to be linear
> 
> R-squared cutoff: 0.9   Type: ordinary
> 
> R^2 with which each variable can be predicted from all other variables:
> 
>   AGE    HYP KILLIP    HRT    ANT
> 0.028  0.032  0.053  0.046  0.040
> 
> No redundant variables
> 
> I've also tried just considering "lrm.fit" and that code seems to run without error too:
> lrm.fit(cbind(gusto2$AGE,gusto2$KILLIP,gusto2$HYP,gusto2$HRT,gusto2$ANT),gusto2$DAY30)
> 
> Logistic Regression Model
> 
> lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
>     gusto2$ANT), y = gusto2$DAY30)
> 
>                       Model Likelihood     Discrimination    Rank Discrim.
>                          Ratio Test           Indexes           Indexes
> Obs          2188    LR chi2     233.59    R2       0.273    C       0.846
>  0           2053    d.f.             5    g        1.642    Dxy     0.691
>  1            135    Pr(> chi2) <0.0001    gr       5.165    gamma   0.696
> max |deriv| 4e-09                          gp       0.079    tau-a   0.080
>                                            Brier    0.048
> 
>           Coef     S.E.   Wald Z Pr(>|Z|)
> Intercept -13.8515 0.9694 -14.29 <0.0001
> x[1]        0.0989 0.0103   9.58 <0.0001
> x[2]        0.9030 0.1510   5.98 <0.0001
> x[3]        1.3576 0.2570   5.28 <0.0001
> x[4]        0.6884 0.2034   3.38 0.0007
> x[5]        0.6327 0.2003   3.16 0.0016
> 
> I was therefore hoping someone would explain why the "lrm" code is producing an error message, while "lrm.fit" and "glm" do not.  In particular I would welcome a solution to ensure I can produce a nomogram.

Try this:

lrm  # look at code, do a search on "fail"
?lrm.fit  # read the structure of the returned value of lrm.fit

my.fit <- lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
    gusto2$ANT), y = gusto2$DAY30)

print(my.fit$fail)  # the error message you got from the lrm call means convergence failed

Documentation bug: The documentation of the cause of the 'fail'- value incorrectly gives the name of this parameter as 'maxiter' in the  Value section.

-- 
David.



> 
> Kind regards,
> Laura
> 
> Dr Laura Bonnett
> NIHR Post-Doctoral Fellow
> 
> Department of Biostatistics,
> Waterhouse Building, Block F,
> 1-5 Brownlow Street,
> University of Liverpool,
> Liverpool,
> L69 3GL
> 
> 0151 795 9686
> L.J.Bonnett at liverpool.ac.uk
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Thu Sep 14 18:02:11 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 14 Sep 2017 09:02:11 -0700
Subject: [R] To implement OO or not in R package, and if so,
	how to structure it?
In-Reply-To: <08d87eae-82a8-09de-08cd-ebe1f3d452c8@ufl.edu>
References: <e72a5a13-714d-ac47-5ad4-bf4fc3f54a9d@ufl.edu>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAECDD@SRVEXCHCM301.precheza.cz>
 <CABdHhvHy9_71dVf3kofWDTBfAYd55n1Ty1sPPJ98oKQxNHa9Lg@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAED0A@SRVEXCHCM301.precheza.cz>
 <08d87eae-82a8-09de-08cd-ebe1f3d452c8@ufl.edu>
Message-ID: <0595441B-00F1-49FB-91D9-444D242B92F8@dcn.davis.ca.us>

I think you should consider whether the advantages of making an object-aware collections class are worth the effort... lists are the standard tool for this task in R, and are normally handled using the functional programming paradigm. Just make sure a sufficiently-complete set of methods are available for the objects you plan to make lists of. 
-- 
Sent from my phone. Please excuse my brevity.

On September 14, 2017 7:27:55 AM PDT, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>>>> Did you read this?
>>>> https://cran.r-project.org/doc/contrib/Leisch-CreatingPackages.pdf
>>>>
>>>> Maybe it could give you some insight in how to create package.
>>>
>>> That resource is ~9 years old. There are more modern treatments
>available. You
>>> can read mine at http://r-pkgs.had.co.nz.
>>>
>>> Hadley
>>>
>
>Thanks both.  I'm reading through your new book now Hadley... thanks
>for 
>that.  I'll probably take a shot at building a class to hold one tree 
>per object, and search for objects of a class (per 
>https://stackoverflow.com/questions/5158830/identify-all-objects-of-given-clas-for-further-processing)
>
>to implement collections when necessary...
>
>It does seem like there might be niche out there for a resource for 
>folks deciding how to structure their package given what they're trying
>
>to provide; i.e. should they construct a collection of functions, or 
>class defs, or...  Could well exist already, and I may just have missed
>
>it...
>
>Thanks,
>Allie
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From f.harrell at vanderbilt.edu  Thu Sep 14 18:21:52 2017
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Thu, 14 Sep 2017 11:21:52 -0500
Subject: [R] Help understanding why glm and lrm.fit runs with my data,
 but lrm does not
In-Reply-To: <7235C707-F9A1-434D-B692-D6856FED202B@comcast.net>
References: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
 <7235C707-F9A1-434D-B692-D6856FED202B@comcast.net>
Message-ID: <CAMO-wTYOahB0W_zaZWpDbx3=b5AdzegXzHXFkKEwd5fns7LBcg@mail.gmail.com>

Fixed 'maxiter' in the help file.  Thanks.

Please give the original source of that dataset.

That dataset is a tiny sample of GUSTO-I and not large enough to fit this
model very reliably.

A nomogram using the full dataset (not publicly available to my knowledge)
is already available in http://biostat.mc.vanderbilt.edu/tmp/bbr.pdf

Use lrm, not lrm.fit for this.  Adding maxit=20 will probably make it work
on the small dataset but still not clear on why you are using this dataset.

Frank


------------------------------
Frank E Harrell Jr      Professor      School of Medicine

Department of *Biostatistics*      *Vanderbilt University*

On Thu, Sep 14, 2017 at 10:48 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 14, 2017, at 12:30 AM, Bonnett, Laura <
> L.J.Bonnett at liverpool.ac.uk> wrote:
> >
> > Dear all,
> >
> > I am using the publically available GustoW dataset.  The exact version I
> am using is available here: https://na01.safelinks.
> protection.outlook.com/?url=https%3A%2F%2Fdrive.google.com%2Fopen%3Fid%
> 3D0B4oZ2TQA0PAoUm85UzBFNjZ0Ulk&data=02%7C01%7Cf.harrell%40vanderbilt.edu%
> 7Cadb58b13c3994f89209708d4fb8807f0%7Cba5a7f39e3be4ab3b45067fa80fa
> ecad%7C0%7C0%7C636410009046132507&sdata=UZgX3%2Ba%
> 2FU2Eeh8ybHMI6JnF0Npd2XJPXAzlmtEhDgOY%3D&reserved=0
> >
> > I would like to produce a nomogram for 5 covariates - AGE, HYP, KILLIP,
> HRT and ANT.  I have successfully fitted a logistic regression model using
> the "glm" function as shown below.
> >
> > library(rms)
> > gusto <- spss.get("GustoW.sav")
> > fit <- glm(DAY30~AGE+HYP+factor(KILLIP)+HRT+ANT,family=
> binomial(link="logit"),data=gusto,x=TRUE,y=TRUE)
> >
> > However, my review of the literature and other websites suggest I need
> to use "lrm" for the purposes of producing a nomogram.  When I run the
> command using "lrm" (see below) I get an error message saying:
> > Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
> >  Unable to fit model using "lrm.fit"
> >
> > My code is as follows:
> > gusto2 <- gusto[,c(1,3,5,8,9,10)]
> > gusto2$HYP <- factor(gusto2$HYP, labels=c("No","Yes"))
> > gusto2$KILLIP <- factor(gusto2$KILLIP, labels=c("1","2","3","4"))
> > gusto2$HRT <- factor(gusto2$HRT, labels=c("No","Yes"))
> > gusto2$ANT <- factor(gusto2$ANT, labels=c("No","Yes"))
> > var.labels=c(DAY30="30-day Mortality", AGE="Age in Years",
> KILLIP="Killip Class", HYP="Hypertension", HRT="Tachycardia", ANT="Anterior
> Infarct Location")
> > label(gusto2)=lapply(names(var.labels),function(x)
> label(gusto2[,x])=var.labels[x])
> >
> > ddist = datadist(gusto2)
> > options(datadist='ddist')
> >
> > fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> >
> > Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
> >  Unable to fit model using "lrm.fit"
> >
> > Online solutions to this problem involve checking whether any variables
> are redundant.  However, the results for my data suggest  that none are.
> > redun(~AGE+HYP+KILLIP+HRT+ANT,gusto2)
> >
> > Redundancy Analysis
> >
> > redun(formula = ~AGE + HYP + KILLIP + HRT + ANT, data = gusto2)
> >
> > n: 2188         p: 5    nk: 3
> >
> > Number of NAs:   0
> >
> > Transformation of target variables forced to be linear
> >
> > R-squared cutoff: 0.9   Type: ordinary
> >
> > R^2 with which each variable can be predicted from all other variables:
> >
> >   AGE    HYP KILLIP    HRT    ANT
> > 0.028  0.032  0.053  0.046  0.040
> >
> > No redundant variables
> >
> > I've also tried just considering "lrm.fit" and that code seems to run
> without error too:
> > lrm.fit(cbind(gusto2$AGE,gusto2$KILLIP,gusto2$HYP,
> gusto2$HRT,gusto2$ANT),gusto2$DAY30)
> >
> > Logistic Regression Model
> >
> > lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
> >     gusto2$ANT), y = gusto2$DAY30)
> >
> >                       Model Likelihood     Discrimination    Rank
> Discrim.
> >                          Ratio Test           Indexes           Indexes
> > Obs          2188    LR chi2     233.59    R2       0.273    C
>  0.846
> >  0           2053    d.f.             5    g        1.642    Dxy
>  0.691
> >  1            135    Pr(> chi2) <0.0001    gr       5.165    gamma
>  0.696
> > max |deriv| 4e-09                          gp       0.079    tau-a
>  0.080
> >                                            Brier    0.048
> >
> >           Coef     S.E.   Wald Z Pr(>|Z|)
> > Intercept -13.8515 0.9694 -14.29 <0.0001
> > x[1]        0.0989 0.0103   9.58 <0.0001
> > x[2]        0.9030 0.1510   5.98 <0.0001
> > x[3]        1.3576 0.2570   5.28 <0.0001
> > x[4]        0.6884 0.2034   3.38 0.0007
> > x[5]        0.6327 0.2003   3.16 0.0016
> >
> > I was therefore hoping someone would explain why the "lrm" code is
> producing an error message, while "lrm.fit" and "glm" do not.  In
> particular I would welcome a solution to ensure I can produce a nomogram.
>
> Try this:
>
> lrm  # look at code, do a search on "fail"
> ?lrm.fit  # read the structure of the returned value of lrm.fit
>
> my.fit <- lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP,
> gusto2$HRT,
>     gusto2$ANT), y = gusto2$DAY30)
>
> print(my.fit$fail)  # the error message you got from the lrm call means
> convergence failed
>
> Documentation bug: The documentation of the cause of the 'fail'- value
> incorrectly gives the name of this parameter as 'maxiter' in the  Value
> section.
>
> --
> David.
>
>
>
> >
> > Kind regards,
> > Laura
> >
> > Dr Laura Bonnett
> > NIHR Post-Doctoral Fellow
> >
> > Department of Biostatistics,
> > Waterhouse Building, Block F,
> > 1-5 Brownlow Street,
> > University of Liverpool,
> > Liverpool,
> > L69 3GL
> >
> > 0151 795 9686
> > L.J.Bonnett at liverpool.ac.uk
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://na01.safelinks.protection.outlook.com/?url=
> https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&
> data=02%7C01%7Cf.harrell%40vanderbilt.edu%7Cadb58b13c3994f89209708d4fb88
> 07f0%7Cba5a7f39e3be4ab3b45067fa80faecad%7C0%7C0%
> 7C636410009046132507&sdata=GAPis8GXCfundLz48dX66AZfVTzxs%
> 2BNBUmG1kgpx2Ro%3D&reserved=0
> > PLEASE do read the posting guide https://na01.safelinks.
> protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.
> org%2Fposting-guide.html&data=02%7C01%7Cf.harrell%40vanderbilt.edu%
> 7Cadb58b13c3994f89209708d4fb8807f0%7Cba5a7f39e3be4ab3b45067fa80fa
> ecad%7C0%7C0%7C636410009046132507&sdata=C8xd7UizYeLM6bylOyad8bumQTsYOz
> FYZu2IcMo%2BUII%3D&reserved=0
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Sep 14 21:00:48 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 Sep 2017 12:00:48 -0700
Subject: [R] Print All Warnings that Occurr in All Parallel Nodes
In-Reply-To: <C7D958509BBBF44A8F8F9CBE5BE940076561B395@EXDG02.usr.corp.gamesa.es>
References: <C7D958509BBBF44A8F8F9CBE5BE940076561B395@EXDG02.usr.corp.gamesa.es>
Message-ID: <CAF8bMcZjfW1yBkKrNxAEoh31csJ6GhhDbPSbW+86jRhq1DPtWA@mail.gmail.com>

> How could I check that a CSV can be opened before applying the function,
> and create an empty data.frame for those CSV.

Use tryCatch().  E.g., instead of
    result <- read_csv2(file)

use

    result <- tryCatch(read_csv2(file), error=function(e)
makeEmptyDataFrame(conditionMessage(e)))

where makeEmptyDataFrame(msg=NULL) is a function (which you write) that
returns a data.frame with no rows but with the proper column names and
types.  I show  it with a msg (message) argument, as you might want to
attach the error message to it as an attribute so you can see what went
wrong.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 14, 2017 at 12:48 AM, TELLERIA RUIZ DE AGUIRRE, JUAN <
JTELLERIA at external.gamesacorp.com> wrote:

> Dear R Users,
>
> I have developed the following code for importing a series of zipped CSV
> by parallel computing.
>
> My problems are that:
>
> A) Some ZIP Files (Which contain CSVs inside) are corrupted, and cannot be
> opened.
> B) After executing parRapply I can only see the last.warning variable
> error, for knowing which CSV have failed in each node, but I cannot see all
> warnings, only 1 at a time.
>
> So:
>
> * For showing a list of all warnings in all nodes, I was thinking of using
> the following function in the code:
>
>     warnings(DISPOIN_CSV_List <- parRapply(c1, DISPOIN_DIR_REL,
> parRaplly_Function))
>
>     Would this work?
>
> * And also, How could I check that a CSV can be opened before applying the
> function, and create an empty data.frame for those CSV.
>
> Thank you,
> Juan
>
>
> CODE
> ############################################################
> ####################
> ## DISPOIN Data Import Into MariaDB
> ############################################################
> ####################
>
> ## ------------------------------------------------------------
> -----------------
> ## Packages
> ## ------------------------------------------------------------
> -----------------
>
> # update.packages("RODBC")
> # update.packages("tidyverse")
>
> ## ------------------------------------------------------------
> -----------------
> ## Libraries
> ## ------------------------------------------------------------
> -----------------
>
> suppressMessages(require(RODBC))
> suppressMessages(require(tidyverse))
> suppressMessages(require(parallel))
>
> ## ------------------------------------------------------------
> -----------------
> ## CMD: Command for DISPOIN's Directory Acquisition
> ## ------------------------------------------------------------
> -----------------
>
> # shell(cmd = 'pushd "\\srvdiscsv\data" && dir *AL*.zip /b /s >
> D:\DISPOIN_Data_Directories.csv && popd')
>
> ## ------------------------------------------------------------
> -----------------
> ## RODBC
> ## ------------------------------------------------------------
> -----------------
>
> ## A) MariaDB Connection String
>
> con <- odbcConnect("MariaDB_Tornado24")
>
> invisible(sqlQuery(con, "USE dispoin;"))
>
> # B) Import R Data Directories from MariaDB
>
> DISPOIN_DIR_REL <- as_tibble(sqlFetch(con, "dispoin.t_DISPOIN_DIR_REL"))
>
> odbcClose(con)
>
> # C) Import Zipped CSV data into List of Dataframes, which latter on are
> compiled as a single dataframe by
> #    means of rbind
>
>   # C.1) parRapply Function Initialization:
>
>   parRaplly_Function <- function (DISPOIN_CSV_Row)
>   {
>     return(read_csv2(
>       file = DISPOIN_CSV_Row,
>       col_names = c(
>         "SCADA",
>         "TAG",
>         "ID_del_AEG",
>         "Descripcion",
>         "Time_ON",
>         "Time_OFF",
>         "Delta_Time",
>         "Comentario",
>         "Es_Alarma",
>         "Es_Ultima",
>         "Comentarios"),
>       col_types = cols(
>         "SCADA" = "c",
>         "TAG" = "c",
>         "ID_del_AEG" = "c",
>         "Descripcion" = "c",
>         "Time_ON" = "c",
>         "Time_OFF" = "c",
>         "Delta_Time" = "c",
>         "Comentario" = "c",
>         "Es_Alarma" = "c",
>         "Es_Ultima" = "c",
>         "Comentarios" = "c"),
>       locale = default_locale(),
>       na = c("", " "),
>       quoted_na = TRUE,
>       quote = "\"",
>       comment = "",
>       trim_ws = TRUE,
>       skip = 0,
>       n_max = Inf,
>       guess_max = min(1000, n_max),
>       progress = FALSE))
>   }
>
>   # C.2) parallel Package: Environment Settings
>
>   no_cores <- detectCores()
>
>   c1 <- makeCluster(no_cores)
>
>   invisible(clusterEvalQ(c1, library(readr)))
>
>   setDefaultCluster(c1)
>
>   # C.3) parRapply Function Application:
>
>   DISPOIN_CSV_List <- parRapply(c1, DISPOIN_DIR_REL, parRaplly_Function)
>
>   suppressWarnings(stopCluster(c1))
>
> # D) List's Tibbles Compilation into a single Tibble:
>
>   DISPOIN_CSV <- do.call(rbind, DISPOIN_CSV_List)
>
> # E) Write Compiled Table into CSV:
>
>   write_csv(
>     DISPOIN_CSV,
>     path = file.path("D:/MySQL/R", "DISPOIN_CSV.csv"),
>     na = "\\N",
>     append = FALSE,
>     col_names = TRUE)
>
> # F) Data Cleaning: Environment Variable Removal
>
>   rm(list=ls())
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ciarrochij at gmail.com  Thu Sep 14 23:26:02 2017
From: ciarrochij at gmail.com (Joseph Ciarrochi)
Date: Fri, 15 Sep 2017 07:26:02 +1000
Subject: [R] using phia with glmmTMB
Message-ID: <CAPSDof3Ao2skBf5GEAx_e_iLzueSy0RdVZ113a7S3soFd-zWig@mail.gmail.com>

Hi folks,

I love the Phia package andwant to use it with glmmTMB, but when i try to
use the interactionMeans command, i get the below error

modelrepeatedmain2 <- glmmTMB(counts ~
 cluster*nominated*nominator*junior_senior+Ltime+
                              (1|school)+(1|id),
                             data=d_shortf,
                           family=nbinom1)

interactionMeans(modelrepeatedmain2)

Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),
 :
  'data' must be of a vector type, was 'NULL'


I can get this to work with GLMER of course, but I love the speed of
glmmTMB.

Is there any way to get interactionMeans to work with glmmTMB?

best
Joseph

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Sep 15 00:45:38 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 14 Sep 2017 15:45:38 -0700
Subject: [R] using phia with glmmTMB
In-Reply-To: <CAPSDof3Ao2skBf5GEAx_e_iLzueSy0RdVZ113a7S3soFd-zWig@mail.gmail.com>
References: <CAPSDof3Ao2skBf5GEAx_e_iLzueSy0RdVZ113a7S3soFd-zWig@mail.gmail.com>
Message-ID: <CAGxFJbRGMKSgUR-9NOpnj3Kb+Ta85QBbcvHZHc+etBsbXCjuJw@mail.gmail.com>

Dunno ...

But you might do better posting this on the r-sig-mixed-models list where
it both should fit better and where you are more likely to find the
relevant expertise.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 14, 2017 at 2:26 PM, Joseph Ciarrochi <ciarrochij at gmail.com>
wrote:

> Hi folks,
>
> I love the Phia package andwant to use it with glmmTMB, but when i try to
> use the interactionMeans command, i get the below error
>
> modelrepeatedmain2 <- glmmTMB(counts ~
>  cluster*nominated*nominator*junior_senior+Ltime+
>                               (1|school)+(1|id),
>                              data=d_shortf,
>                            family=nbinom1)
>
> interactionMeans(modelrepeatedmain2)
>
> Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),
>  :
>   'data' must be of a vector type, was 'NULL'
>
>
> I can get this to work with GLMER of course, but I love the speed of
> glmmTMB.
>
> Is there any way to get interactionMeans to work with glmmTMB?
>
> best
> Joseph
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Sep 15 06:45:57 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 14 Sep 2017 21:45:57 -0700
Subject: [R] using phia with glmmTMB
In-Reply-To: <CAGxFJbRGMKSgUR-9NOpnj3Kb+Ta85QBbcvHZHc+etBsbXCjuJw@mail.gmail.com>
References: <CAPSDof3Ao2skBf5GEAx_e_iLzueSy0RdVZ113a7S3soFd-zWig@mail.gmail.com>
 <CAGxFJbRGMKSgUR-9NOpnj3Kb+Ta85QBbcvHZHc+etBsbXCjuJw@mail.gmail.com>
Message-ID: <E530FCFF-A2A9-477A-B08D-E6806DEEE29B@dcn.davis.ca.us>

Should also make the example reproducible [1][2][3] when you do post there because some mismatch between the model and the data is frequently where the problem turns out to be, and without an example that triggers the problem it is very tough to figure that out. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On September 14, 2017 3:45:38 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Dunno ...
>
>But you might do better posting this on the r-sig-mixed-models list
>where
>it both should fit better and where you are more likely to find the
>relevant expertise.
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Thu, Sep 14, 2017 at 2:26 PM, Joseph Ciarrochi
><ciarrochij at gmail.com>
>wrote:
>
>> Hi folks,
>>
>> I love the Phia package andwant to use it with glmmTMB, but when i
>try to
>> use the interactionMeans command, i get the below error
>>
>> modelrepeatedmain2 <- glmmTMB(counts ~
>>  cluster*nominated*nominator*junior_senior+Ltime+
>>                               (1|school)+(1|id),
>>                              data=d_shortf,
>>                            family=nbinom1)
>>
>> interactionMeans(modelrepeatedmain2)
>>
>> Error in array(x, c(length(x), 1L), if (!is.null(names(x)))
>list(names(x),
>>  :
>>   'data' must be of a vector type, was 'NULL'
>>
>>
>> I can get this to work with GLMER of course, but I love the speed of
>> glmmTMB.
>>
>> Is there any way to get interactionMeans to work with glmmTMB?
>>
>> best
>> Joseph
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jkkaplan6 at gmail.com  Thu Sep 14 20:01:39 2017
From: jkkaplan6 at gmail.com (Jacob Kaplan)
Date: Thu, 14 Sep 2017 14:01:39 -0400
Subject: [R] [R-pkgs] New CRAN Package Announcement: asciiSetupReader
Message-ID: <CAE-oFUffWBfbCmEzfF-oHCCKwFT-khOUssU9g7xN=91s3+j5wA@mail.gmail.com>

I'm pleased to announce that asciiSetupReader is now on CRAN:
https://cran.r-project.org/web/packages/asciiSetupReader/index.html

This package allows users to read ASCII files that have an SPSS or SAS
setup file (.sps or .sas). Datasets that come in these txt-sps and txt-sas
paris can now be accessible through R. The function has the option of
correcting value labels (e.g. 1 to Male, 2 to Female) and column names
(e.g. V1 to Sex). You may also select only certain columns to read in which
is helpful when dealing with very large data sets.

A vignette is available explaining how to use the package with SPSS setup
files. The process is the same as for SAS setup files.

Please let me know if you if you find any bugs or problems in the package.
https://github.com/jacobkap/asciiReader/issues

Jacob

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ericjberger at gmail.com  Fri Sep 15 09:42:01 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 15 Sep 2017 10:42:01 +0300
Subject: [R] compounding precipitation based on whether falls within a
	day
In-Reply-To: <CAGxFJbR04=e6ttunpHv9KbKEQoD2EK8-Z0H2v=cWu_pR41PvAA@mail.gmail.com>
References: <CAPoqHzquF0okjL4O4gJFuVs0c=YzCAZDm90ATF2rCjjdCxHyRg@mail.gmail.com>
 <CAGxFJbR04=e6ttunpHv9KbKEQoD2EK8-Z0H2v=cWu_pR41PvAA@mail.gmail.com>
Message-ID: <CAGgJW77JJg7kt25kvZ1-BN7nMPT4pX-4Sd4z3x+OJRXgddjyvg@mail.gmail.com>

Hi Eric,
Bert's solution is very elegant. His final comment prompted me to check out
the aperm() function which I have never used.
The final step to complete his response is

prec_daily2 <- aperm(prec_daily, c(3,1,2))

Regards


On Wed, Sep 13, 2017 at 9:06 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Thanks for the reprex. Wouldn't have bothered without it.
>
> The following is I believe **almost** what you want. It seems a bit clumsy
> to me, so others may provide you something neater. But anyway...
>
> ## Convert POSIXct vector to dates
> ## There are 22 different days, not 21
> date <- as.Date(prec_idx)
>
> ## Sum results by date at each i,j of the last 2 array dimensions
> z <- lapply(unique(date),function(d)
>    apply(prec[date==d,,],2:3,sum)
>    )
>
> ## This gives a list with 22 3x4 matrices of sums.
> ## Convert to 3x4x22 array with
>
> prec_daily <- array(unlist(z),dim=c(3,4,22))
>
> ## This is the **almost** part. You can use the aperm() function to reshape
> the array if you like. I leave those pleasures to you.
>
> HTH.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Sep 13, 2017 at 9:52 AM, Morway, Eric <emorway at usgs.gov> wrote:
>
> > Using the small reproducible example below, I'm wondering how best to
> > complete the following task:
> >
> > In the small reproducible example below, the 3D array prec has indexes
> that
> > correspond to time, x, y (i.e., prec[time, x, y]).  In this case, the
> time
> > index is hours since some predefined start time.  I'd like to add up all
> > the time indexes in 'prec' based on whether or not the corresponding
> hours
> > fall within a given day.  So, at the end of the small example below,
> there
> > are two variables that I'm left with, prec_idx (an hourly sequence from
> > beg_time to end_time) whose length is equal to the first index (the time
> > index) of the 3D array of precipitation called prec.  That is, I'd like
> to
> > get a 3D array called prec*_daily* that has dimension prec*_daily*[21, 3,
> > 4],
> > where 21 is the number of days and the value in say prec*_daily*[1,x,y]
> is
> > equal to prec[1,x,y] + prec[2,x,y] + ... + prec[24,x,y]
> >
> >
> > ndays <- 21
> > base_time <- as.character('2001-12-31T23:00:00Z')
> > hrs_since_base <- 1
> >
> > # adding an extra second to the end b/c I'm paranoid about the midnight
> > time stamp not being explicit
> > beg_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
> > (hrs_since_base * 60 * 60) + 1
> >
> > max_hr_since <- 24 * ndays
> > end_time <- as.POSIXct(base_time, format = "%Y-%m-%dT%H:%M:%SZ") +
> > (max_hr_since * 60 * 60) + 1
> >
> > prec_idx <- seq(beg_time, end_time, by='hour')
> >
> > prec <- array(abs(rnorm((24*ndays) * 3 * 4)) , dim=c(24*ndays, 3, 4))
> >
> > length(prec_idx)
> > # 504
> > dim(prec)
> > # 504   3   4
> >
> > # How do I aggregate prec to get daily sums of precipitation based on the
> > prec_idx array?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abhinabaroy09 at gmail.com  Fri Sep 15 11:02:31 2017
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Fri, 15 Sep 2017 14:32:31 +0530
Subject: [R] Calculating Weeks Since Last Event
Message-ID: <CANtKHPWBrzb3cMV1=5KDDn+2GHw6Z2srFWDo4nPpFF2SrGfQUg@mail.gmail.com>

Hi,

I have an input data

> dput (input)

structure(list(ScanDate = structure(c(16433, 16440, 16447, 16454,
16461, 16468, 16475, 16482, 16489, 16496, 16503, 16510, 16517,
16524, 16531, 16538, 16545, 16552, 16559, 16566, 16573, 16580,
16587, 16594, 16601, 16608, 16615, 16622), class = "Date"), OnPromotion =
c(0,
0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,
0, 0, 1, 1, 1, 1)), .Names = c("ScanDate", "OnPromotion"), sorted =
"ScanDate", class = c("data.table",
"data.frame"), row.names = c(NA, -28L))

I am looking for an output

> dput(output)

structure(list(ScanDate = structure(c(16433, 16440, 16447, 16454,
16461, 16468, 16475, 16482, 16489, 16496, 16503, 16510, 16517,
16524, 16531, 16538, 16545, 16552, 16559, 16566, 16573, 16580,
16587, 16594, 16601, 16608, 16615, 16622), class = "Date"), OnPromotion =
c(0,
0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,
0, 0, 1, 1, 1, 1), Weeks_Since_Last_Promo = c(0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 4, 1,
1, 1)), .Names = c("ScanDate", "OnPromotion", "Weeks_Since_Last_Promo"
), sorted = "ScanDate", class = c("data.table", "data.frame"), row.names =
c(NA,
-28L))

The logic :

The data is weekly.

I want to calculate the number of weeks elapsed since the last promotion
(OnPromotion : 1 indicates promotion for that week and 0 indicates no
promotion).

As, there are no promotion initially we set the value for
'Weeks_Since_Last_Promo' to 0 (zero). The first promo occurs on
'2015-03-02' and 'Weeks_Since_Last_Promo' is still 0. Moving to
'2015-03-09' there was a promotion the week before and so 1 week elapsed
after the last promo.

If we look at '2015-06-15' then there was a promo 4 weeks back in the week
of '2015-05-18' and so 'Weeks_Since_Last_Promo' = 4.

How can we do it in R?

Thanks,
Abhinaba

	[[alternative HTML version deleted]]


From yadavneog at gmail.com  Fri Sep 15 11:38:09 2017
From: yadavneog at gmail.com (yadav neog)
Date: Fri, 15 Sep 2017 15:08:09 +0530
Subject: [R] require help
Message-ID: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>

hello to all. I am working on macroeconomic data series of India, which in
a yearly basis. I am unable to convert my data frame into time series.
kindly help me.
also using zoo and xts packages. but they take only monthly observations.

'data.frame': 30 obs. of  4 variables:
 $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
 $ cnsm: num  174 175 175 172 173 ...
 $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
 $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
-- 
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

	[[alternative HTML version deleted]]


From shylashivashree at gmail.com  Fri Sep 15 12:43:14 2017
From: shylashivashree at gmail.com (Shylashree U.R)
Date: Fri, 15 Sep 2017 16:13:14 +0530
Subject: [R] Regarding Principal Component Analysis result Interpretation
Message-ID: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>

Dear Sir/Madam,

I am trying to do PCA analysis with "iris" dataset and trying to interpret
the result. Dataset contains 150 obs of 5 variables

    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species
     1             5.1                    3.5                 1.4
    0.2             setosa
     2             4.9                3.0                 1.4
0.2             setosa
     .....
     .....
    150         5.9                3.0                  5.1              18
             verginica

now I used 'prcomp' function on dataset and got result as following:
>print(pc)
Standard deviations (1, .., p=4):
[1] 1.7083611 0.9560494 0.3830886 0.1439265

Rotation (n x k) = (4 x 4):
                    PC1         PC2        PC3        PC4
Sepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863
Sepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096
Petal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492
Petal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971

I'm planning to use PCA as feature selection process and remove variables
which are corelated in my project, I have interpreted the PCA result, but
not sure is my interpretation is correct or wrong.
If you can correct me it will be of great help.
If i notice the PCs result, I found both positive and negative data.

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Fri Sep 15 13:48:04 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 15 Sep 2017 14:48:04 +0300
Subject: [R] require help
In-Reply-To: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
Message-ID: <CAGgJW77DX9Shp-8F53=1gNk=hga-ZP2G96nBJh9VCsQfZkUiGw@mail.gmail.com>

You did not provide the data frame so I will first create one and then use
it to create an xts

library(xts)
df <- data.frame( year=1980:2009, cnsm=sample(170:180,30,replace=TRUE),
                  incm=rnorm(30,53,1), wlth=rnorm(30,60,1))
dates <- as.Date(paste(df$year,"-01-01",sep=""))
myXts <- xts(df,order.by=dates)



On Fri, Sep 15, 2017 at 12:38 PM, yadav neog <yadavneog at gmail.com> wrote:

> hello to all. I am working on macroeconomic data series of India, which in
> a yearly basis. I am unable to convert my data frame into time series.
> kindly help me.
> also using zoo and xts packages. but they take only monthly observations.
>
> 'data.frame': 30 obs. of  4 variables:
>  $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
>  $ cnsm: num  174 175 175 172 173 ...
>  $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
>  $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> --
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sezenismail at gmail.com  Fri Sep 15 13:53:53 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Fri, 15 Sep 2017 14:53:53 +0300
Subject: [R] require help
In-Reply-To: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
Message-ID: <89A9AE45-4828-4310-8CA8-A1DC517EBBF7@gmail.com>


> On 15 Sep 2017, at 12:38, yadav neog <yadavneog at gmail.com> wrote:
> 
> hello to all. I am working on macroeconomic data series of India, which in
> a yearly basis. I am unable to convert my data frame into time series.


Do you really need to convert your data to time series/xts/zoo? I don?t know you try what kind of an analysis but perhaps you don?t have to.

> kindly help me.
> also using zoo and xts packages. but they take only monthly observations.

If you really have to convert to xts/zoo, why don?t yo set each year to first day of January and use it as is? For instance,

index, cnsm, incm, wlth
1980-01-01, 174, 53.4, 60.3
1981-01-01, 175, 53.7, 60.5
1982-01-01, 175, 53.5, 60.2
?..

> 
> 'data.frame': 30 obs. of  4 variables:
> $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> $ cnsm: num  174 175 175 172 173 ...
> $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> -- 
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
> 


From msuzen at gmail.com  Fri Sep 15 13:59:52 2017
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Fri, 15 Sep 2017 13:59:52 +0200
Subject: [R] Regarding Principal Component Analysis result Interpretation
In-Reply-To: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>
References: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>
Message-ID: <CAPtbhHwZSnSM2JTmHyspeSt6+GS8_SL_3cLs4MYhXyenhYCQ5w@mail.gmail.com>

Usually, PCA is used for a large number of features. FactoMineR [1]
package provides a couple of examples, check for temperature example.
But you may want to consult to basic PCA material as well, I suggest a
book from Chris Bishop [2].


[1] https://cran.r-project.org/web/packages/FactoMineR/vignettes/clustering.pdf
[2] http://www.springer.com/de/book/9780387310732?referer=www.springer.de


From traxplayer at gmail.com  Fri Sep 15 14:11:38 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 15 Sep 2017 14:11:38 +0200
Subject: [R] How to add make option to package compilation?
Message-ID: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>

Hi,

  I am installing a lot of packages to a new R installation and it takes a
long time.
  However the machine got 4 cpus and most of the packages are written in
C/C++.

  So is it possible to add a -j4 flag to the make command when I use the
install.packages() function?
  That will probably speed up the package installation process 390%.

Regards
Martin M. S. Pedersen

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep 15 14:13:55 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Sep 2017 08:13:55 -0400
Subject: [R] How to add make option to package compilation?
In-Reply-To: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>
References: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>
Message-ID: <32b4d251-25e6-fb36-b62e-d87dfb07fc59@gmail.com>

On 15/09/2017 8:11 AM, Martin M?ller Skarbiniks Pedersen wrote:
> Hi,
> 
>    I am installing a lot of packages to a new R installation and it takes a
> long time.
>    However the machine got 4 cpus and most of the packages are written in
> C/C++.
> 
>    So is it possible to add a -j4 flag to the make command when I use the
> install.packages() function?
>    That will probably speed up the package installation process 390%.

See the Ncpus argument in ?install.packages.

Duncan Murdoch


From traxplayer at gmail.com  Fri Sep 15 14:30:53 2017
From: traxplayer at gmail.com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 15 Sep 2017 14:30:53 +0200
Subject: [R] How to add make option to package compilation?
In-Reply-To: <32b4d251-25e6-fb36-b62e-d87dfb07fc59@gmail.com>
References: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>
 <32b4d251-25e6-fb36-b62e-d87dfb07fc59@gmail.com>
Message-ID: <CAGAA5bekYRgM_bV_Rpv6Dgzr2PwTcWUJePjNUbuiCe+UcwgbyQ@mail.gmail.com>

On 15 September 2017 at 14:13, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 15/09/2017 8:11 AM, Martin M?ller Skarbiniks Pedersen wrote:
>
>> Hi,
>>
>>    I am installing a lot of packages to a new R installation and it takes
>> a
>> long time.
>>    However the machine got 4 cpus and most of the packages are written in
>> C/C++.
>>
>>    So is it possible to add a -j4 flag to the make command when I use the
>> install.packages() function?
>>    That will probably speed up the package installation process 390%.
>>
>
> See the Ncpus argument in ?install.packages.


Thanks.

However it looks like Ncpus=4 tries to compile four R packages at the same
time using one cpu for each packages.

From the documentation:
"
   Ncpus: the number of parallel processes to use for a parallel
          install of more than one source package.  Values greater than
          one are supported if the ?make? command specified by
          ?Sys.getenv("MAKE", "make")? accepts argument ?-k -j Ncpus?
"

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Sep 15 14:57:41 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 15 Sep 2017 13:57:41 +0100
Subject: [R] How to add make option to package compilation?
In-Reply-To: <CAGAA5bekYRgM_bV_Rpv6Dgzr2PwTcWUJePjNUbuiCe+UcwgbyQ@mail.gmail.com>
References: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>
 <32b4d251-25e6-fb36-b62e-d87dfb07fc59@gmail.com>
 <CAGAA5bekYRgM_bV_Rpv6Dgzr2PwTcWUJePjNUbuiCe+UcwgbyQ@mail.gmail.com>
Message-ID: <52d213b9-12f1-df30-bb67-5c77cafda5e8@dewey.myzen.co.uk>

In line

On 15/09/2017 13:30, Martin M?ller Skarbiniks Pedersen wrote:
> On 15 September 2017 at 14:13, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 15/09/2017 8:11 AM, Martin M?ller Skarbiniks Pedersen wrote:
>>
>>> Hi,
>>>
>>>     I am installing a lot of packages to a new R installation and it takes
>>> a
>>> long time.
>>>     However the machine got 4 cpus and most of the packages are written in
>>> C/C++.
>>>
>>>     So is it possible to add a -j4 flag to the make command when I use the
>>> install.packages() function?
>>>     That will probably speed up the package installation process 390%.
>>>
>>
>> See the Ncpus argument in ?install.packages.
> 
> 
> Thanks.
> 
> However it looks like Ncpus=4 tries to compile four R packages at the same
> time using one cpu for each packages.
> 

But you said you had lots to install so would that not speed things up too?

>  From the documentation:
> "
>     Ncpus: the number of parallel processes to use for a parallel
>            install of more than one source package.  Values greater than
>            one are supported if the ?make? command specified by
>            ?Sys.getenv("MAKE", "make")? accepts argument ?-k -j Ncpus?
> "
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From martin.morgan at roswellpark.org  Fri Sep 15 15:13:41 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Fri, 15 Sep 2017 09:13:41 -0400
Subject: [R] How to add make option to package compilation?
In-Reply-To: <52d213b9-12f1-df30-bb67-5c77cafda5e8@dewey.myzen.co.uk>
References: <CAGAA5bfi5k3DHiShewMFmphQ+L6TbO99PnZvi0hMiA7RR0PrCw@mail.gmail.com>
 <32b4d251-25e6-fb36-b62e-d87dfb07fc59@gmail.com>
 <CAGAA5bekYRgM_bV_Rpv6Dgzr2PwTcWUJePjNUbuiCe+UcwgbyQ@mail.gmail.com>
 <52d213b9-12f1-df30-bb67-5c77cafda5e8@dewey.myzen.co.uk>
Message-ID: <68c46bab-2ac3-cae2-b935-364b3a21b40f@roswellpark.org>

On 09/15/2017 08:57 AM, Michael Dewey wrote:
> In line
> 
> On 15/09/2017 13:30, Martin M?ller Skarbiniks Pedersen wrote:
>> On 15 September 2017 at 14:13, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> On 15/09/2017 8:11 AM, Martin M?ller Skarbiniks Pedersen wrote:
>>>
>>>> Hi,
>>>>
>>>>     I am installing a lot of packages to a new R installation and it 
>>>> takes
>>>> a
>>>> long time.
>>>>     However the machine got 4 cpus and most of the packages are 
>>>> written in
>>>> C/C++.
>>>>
>>>>     So is it possible to add a -j4 flag to the make command when I 
>>>> use the
>>>> install.packages() function?
>>>>     That will probably speed up the package installation process 390%.
>>>>
>>>
>>> See the Ncpus argument in ?install.packages.
>>
>>
>> Thanks.
>>
>> However it looks like Ncpus=4 tries to compile four R packages at the 
>> same
>> time using one cpu for each packages.

The variable MAKE is defined in ${R_HOME}/etc/Renviron, and can be 
over-written with ~/.Renviron

     MAKE=make -j

There is further discussion in

 
https://cran.r-project.org/doc/manuals/r-release/R-admin.html#Configuration-variables

and ?Renviron.

One could configure a source installation to always compile with make 
-j, something like ./configure MAKE="make -j"

Martin

>>
> 
> But you said you had lots to install so would that not speed things up too?
> 
>>  From the documentation:
>> "
>>     Ncpus: the number of parallel processes to use for a parallel
>>            install of more than one source package.  Values greater than
>>            one are supported if the ?make? command specified by
>>            ?Sys.getenv("MAKE", "make")? accepts argument ?-k -j Ncpus?
>> "
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>>
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From bhh at xs4all.nl  Fri Sep 15 16:35:02 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 15 Sep 2017 16:35:02 +0200
Subject: [R] require help
In-Reply-To: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
Message-ID: <0249DE6B-4A43-463D-BD74-485239771CCC@xs4all.nl>


> On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
> 
> hello to all. I am working on macroeconomic data series of India, which in
> a yearly basis. I am unable to convert my data frame into time series.
> kindly help me.
> also using zoo and xts packages. but they take only monthly observations.
> 
> 'data.frame': 30 obs. of  4 variables:
> $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> $ cnsm: num  174 175 175 172 173 ...
> $ incm: num  53.4 53.7 53.5 53.2 53.3 ...


It shouldn't be difficult.
Example:

tsdata <- data.frame(year=c(2000,2002,2003), x=c(1,2,3),y=c(10,11,12))
xy.ts <- as.ts(tsdata)

library(zoo)

as.zoo(xy.ts)


Berend Hasselman

> $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> -- 
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Fri Sep 15 18:26:52 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 15 Sep 2017 18:26:52 +0200
Subject: [R] require help
In-Reply-To: <0249DE6B-4A43-463D-BD74-485239771CCC@xs4all.nl>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0249DE6B-4A43-463D-BD74-485239771CCC@xs4all.nl>
Message-ID: <3A6794D5-0D6E-4CE7-9798-DB34B66DD0B2@xs4all.nl>


> On 15 Sep 2017, at 16:35, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
>> 
>> hello to all. I am working on macroeconomic data series of India, which in
>> a yearly basis. I am unable to convert my data frame into time series.
>> kindly help me.
>> also using zoo and xts packages. but they take only monthly observations.
>> 
>> 'data.frame': 30 obs. of  4 variables:
>> $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
>> $ cnsm: num  174 175 175 172 173 ...
>> $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> 
> 
> It shouldn't be difficult.
> Example:
> 
> tsdata <- data.frame(year=c(2000,2002,2003), x=c(1,2,3),y=c(10,11,12))
> xy.ts <- as.ts(tsdata)
> 
> library(zoo)
> 
> as.zoo(xy.ts)


Ignore my suggestion.  Doesn't do what you need.

Berend


From jholtman at gmail.com  Fri Sep 15 18:55:54 2017
From: jholtman at gmail.com (jim holtman)
Date: Fri, 15 Sep 2017 12:55:54 -0400
Subject: [R] Calculating Weeks Since Last Event
In-Reply-To: <CANtKHPWBrzb3cMV1=5KDDn+2GHw6Z2srFWDo4nPpFF2SrGfQUg@mail.gmail.com>
References: <CANtKHPWBrzb3cMV1=5KDDn+2GHw6Z2srFWDo4nPpFF2SrGfQUg@mail.gmail.com>
Message-ID: <CAAxdm-7BXqbT86-HaTcVeyoBVNYM=PuOj43mC_xhzEZ6xVXA2g@mail.gmail.com>

Try this:

################################
# supplied data
library(zoo)  # need the 'na.locf' function

x <- structure(list(ScanDate = structure(c(16433, 16440, 16447, 16454,
                                           16461, 16468, 16475, 16482,
16489, 16496, 16503, 16510, 16517,
                                           16524, 16531, 16538, 16545,
16552, 16559, 16566, 16573, 16580,
                                           16587, 16594, 16601, 16608,
16615, 16622), class = "Date"), OnPromotion =
                      c(0,
                        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,
0, 1, 1, 1, 1, 0,
                        0, 0, 1, 1, 1, 1)), .Names = c("ScanDate",
"OnPromotion"), sorted =
                 "ScanDate", class = c("data.table",
                                       "data.frame"), row.names = c(NA, -28L))


# find where the promotions start and then create a flag that indicates when
# the previous promotion started
indx <- which(x$OnPromotion == 1)[1]  # get initial promotion
if (length(indx) == 0) stop('no promtions')  # make sure there is one
in the data

# add a column with the running total of promotions
x$count <- c(rep(0, indx - 1), seq(0, length = nrow(x) - indx + 1))
x$flag <- x$count  # save a copy

# now replace no promotions with NAs so we can use 'na.locf'
indx <- (x$OnPromotion == 0) & (x$count != 0)
x$flag[indx] <- NA
x$flag <- zoo::na.locf(x$flag)

# determine weeks since
x$weeks_since <- ifelse(x$count != 0,
                        x$count - x$flag + 1,
                        0
)

x  # print out the result


##########################


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Sep 15, 2017 at 5:02 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi,
>
> I have an input data
>
>> dput (input)
>
> structure(list(ScanDate = structure(c(16433, 16440, 16447, 16454,
> 16461, 16468, 16475, 16482, 16489, 16496, 16503, 16510, 16517,
> 16524, 16531, 16538, 16545, 16552, 16559, 16566, 16573, 16580,
> 16587, 16594, 16601, 16608, 16615, 16622), class = "Date"), OnPromotion =
> c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,
> 0, 0, 1, 1, 1, 1)), .Names = c("ScanDate", "OnPromotion"), sorted =
> "ScanDate", class = c("data.table",
> "data.frame"), row.names = c(NA, -28L))
>
> I am looking for an output
>
>> dput(output)
>
> structure(list(ScanDate = structure(c(16433, 16440, 16447, 16454,
> 16461, 16468, 16475, 16482, 16489, 16496, 16503, 16510, 16517,
> 16524, 16531, 16538, 16545, 16552, 16559, 16566, 16573, 16580,
> 16587, 16594, 16601, 16608, 16615, 16622), class = "Date"), OnPromotion =
> c(0,
> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,
> 0, 0, 1, 1, 1, 1), Weeks_Since_Last_Promo = c(0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 4, 1,
> 1, 1)), .Names = c("ScanDate", "OnPromotion", "Weeks_Since_Last_Promo"
> ), sorted = "ScanDate", class = c("data.table", "data.frame"), row.names =
> c(NA,
> -28L))
>
> The logic :
>
> The data is weekly.
>
> I want to calculate the number of weeks elapsed since the last promotion
> (OnPromotion : 1 indicates promotion for that week and 0 indicates no
> promotion).
>
> As, there are no promotion initially we set the value for
> 'Weeks_Since_Last_Promo' to 0 (zero). The first promo occurs on
> '2015-03-02' and 'Weeks_Since_Last_Promo' is still 0. Moving to
> '2015-03-09' there was a promotion the week before and so 1 week elapsed
> after the last promo.
>
> If we look at '2015-06-15' then there was a promo 4 weeks back in the week
> of '2015-05-18' and so 'Weeks_Since_Last_Promo' = 4.
>
> How can we do it in R?
>
> Thanks,
> Abhinaba
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Fri Sep 15 14:12:32 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Fri, 15 Sep 2017 15:12:32 +0300
Subject: [R] Regarding Principal Component Analysis result Interpretation
In-Reply-To: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>
References: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>
Message-ID: <7BF9CDC5-599B-40E4-91D6-12C59520E798@gmail.com>

First, see the example at https://isezen.github.io/PCA/

> On 15 Sep 2017, at 13:43, Shylashree U.R <shylashivashree at gmail.com> wrote:
> 
> Dear Sir/Madam,
> 
> I am trying to do PCA analysis with "iris" dataset and trying to interpret
> the result. Dataset contains 150 obs of 5 variables
> 
>    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species
>     1             5.1                    3.5                 1.4
>    0.2             setosa
>     2             4.9                3.0                 1.4
> 0.2             setosa
>     .....
>     .....
>    150         5.9                3.0                  5.1              18
>             verginica
> 
> now I used 'prcomp' function on dataset and got result as following:
>> print(pc)
> Standard deviations (1, .., p=4):
> [1] 1.7083611 0.9560494 0.3830886 0.1439265
> 
> Rotation (n x k) = (4 x 4):
>                    PC1         PC2        PC3        PC4
> Sepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863
> Sepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096
> Petal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492
> Petal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971
> 
> I'm planning to use PCA as feature selection process and remove variables
> which are corelated in my project, I have interpreted the PCA result, but
> not sure is my interpretation is correct or wrong.


You want to ?remove variables which are correlated?. Correlated among themselves? If so, why don?t you create a pearson correlation matrix (see ?cor) and define a threshold and remove variables which are correlated according to this threshold? Perhaps I did not understand you correctly, excuse me.

for iris dataset, each component will be as much as correlated with PC1 and remaining part will be correlated PC2 and so on. Hence, you can identify which variables are similar in terms of VARIANCE. You can understand it if you examine the example that I gave above.

In PCA, you can also calculate the correlations between variables and PCs but this shows you how PCs are affected by this variables. I don?t know how you plan to accomplish feature selection process so I hope this helps you. Also note that resources part at the end of example.

isezen

From yadavneog at gmail.com  Fri Sep 15 14:35:30 2017
From: yadavneog at gmail.com (yadav neog)
Date: Fri, 15 Sep 2017 18:05:30 +0530
Subject: [R] require help
In-Reply-To: <89A9AE45-4828-4310-8CA8-A1DC517EBBF7@gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <89A9AE45-4828-4310-8CA8-A1DC517EBBF7@gmail.com>
Message-ID: <CACdLcRz93TeVH49EMvjG8kQrTHx-KERuw0x0uNnoxmWMBrQRVA@mail.gmail.com>

thanks, eric../ actually I have the data which have not specify the months.
therefore i bound to declare is in yearly data. i also attached a sample
data set that may be helpful for you to providing suggestions. thank you

On Fri, Sep 15, 2017 at 5:23 PM, Ismail SEZEN <sezenismail at gmail.com> wrote:

>
> > On 15 Sep 2017, at 12:38, yadav neog <yadavneog at gmail.com> wrote:
> >
> > hello to all. I am working on macroeconomic data series of India, which
> in
> > a yearly basis. I am unable to convert my data frame into time series.
>
>
> Do you really need to convert your data to time series/xts/zoo? I don?t
> know you try what kind of an analysis but perhaps you don?t have to.
>
> > kindly help me.
> > also using zoo and xts packages. but they take only monthly observations.
>
> If you really have to convert to xts/zoo, why don?t yo set each year to
> first day of January and use it as is? For instance,
>
> index, cnsm, incm, wlth
> 1980-01-01, 174, 53.4, 60.3
> 1981-01-01, 175, 53.7, 60.5
> 1982-01-01, 175, 53.5, 60.2
> ?..
>
> >
> > 'data.frame': 30 obs. of  4 variables:
> > $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> > $ cnsm: num  174 175 175 172 173 ...
> > $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> > $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> > --
> > Yadawananda Neog
> > Research Scholar
> > Department of Economics
> > Banaras Hindu University
> > Mob. 9838545073
> >
>
>


-- 
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

From bgunter.4567 at gmail.com  Sat Sep 16 01:40:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 15 Sep 2017 16:40:32 -0700
Subject: [R] Regarding Principal Component Analysis result Interpretation
In-Reply-To: <7BF9CDC5-599B-40E4-91D6-12C59520E798@gmail.com>
References: <CAPvnpU9_rBuMKNH+JgbC5P8YM4OkJNUfe-MU0EzFCKAZcOqSXg@mail.gmail.com>
 <7BF9CDC5-599B-40E4-91D6-12C59520E798@gmail.com>
Message-ID: <CAGxFJbQNE7cCYfR41w0rw1hAzuK7bxPsrmyNJ3DTXyZdChiDUw@mail.gmail.com>

This list is about R programming, not statistics, although they do often
intersect. Nevertheless, this discussion seems to be all about the latter,
not the former, so I think you would do better bringing it to a statistics
list like stats.stackexchange.com rather than here.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 15, 2017 at 5:12 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:

> First, see the example at https://isezen.github.io/PCA/
>
> > On 15 Sep 2017, at 13:43, Shylashree U.R <shylashivashree at gmail.com>
> wrote:
> >
> > Dear Sir/Madam,
> >
> > I am trying to do PCA analysis with "iris" dataset and trying to
> interpret
> > the result. Dataset contains 150 obs of 5 variables
> >
> >    Sepal.Length  Sepal.Width  Petal.Length  Petal.Width  Species
> >     1             5.1                    3.5                 1.4
> >    0.2             setosa
> >     2             4.9                3.0                 1.4
> > 0.2             setosa
> >     .....
> >     .....
> >    150         5.9                3.0                  5.1
> 18
> >             verginica
> >
> > now I used 'prcomp' function on dataset and got result as following:
> >> print(pc)
> > Standard deviations (1, .., p=4):
> > [1] 1.7083611 0.9560494 0.3830886 0.1439265
> >
> > Rotation (n x k) = (4 x 4):
> >                    PC1         PC2        PC3        PC4
> > Sepal.Length  0.5210659 -0.37741762  0.7195664  0.2612863
> > Sepal.Width  -0.2693474 -0.92329566 -0.2443818 -0.1235096
> > Petal.Length  0.5804131 -0.02449161 -0.1421264 -0.8014492
> > Petal.Width   0.5648565 -0.06694199 -0.6342727  0.5235971
> >
> > I'm planning to use PCA as feature selection process and remove variables
> > which are corelated in my project, I have interpreted the PCA result, but
> > not sure is my interpretation is correct or wrong.
>
>
> You want to ?remove variables which are correlated?. Correlated among
> themselves? If so, why don?t you create a pearson correlation matrix (see
> ?cor) and define a threshold and remove variables which are correlated
> according to this threshold? Perhaps I did not understand you correctly,
> excuse me.
>
> for iris dataset, each component will be as much as correlated with PC1
> and remaining part will be correlated PC2 and so on. Hence, you can
> identify which variables are similar in terms of VARIANCE. You can
> understand it if you examine the example that I gave above.
>
> In PCA, you can also calculate the correlations between variables and PCs
> but this shows you how PCs are affected by this variables. I don?t know how
> you plan to accomplish feature selection process so I hope this helps you.
> Also note that resources part at the end of example.
>
> isezen
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sat Sep 16 08:55:33 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 16 Sep 2017 08:55:33 +0200
Subject: [R] require help
In-Reply-To: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
Message-ID: <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>


> On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
> 
> hello to all. I am working on macroeconomic data series of India, which in
> a yearly basis. I am unable to convert my data frame into time series.
> kindly help me.
> also using zoo and xts packages. but they take only monthly observations.
> 
> 'data.frame': 30 obs. of  4 variables:
> $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> $ cnsm: num  174 175 175 172 173 ...
> $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> -- 

Second try to do what you would like (I hope and think)
Using Eric's sample data

<code>
zdf <- data.frame(year=2001:2010, cnsm=sample(170:180,10,replace=TRUE),
                 incm=rnorm(10,53,1), wlth=rnorm(10,60,1))
zdf

# R ts
zts <- ts(zdf[,-1], start=zdf[1,"year"])
zts

# turn data into a zoo timeseries and an xts timeseries

library(zoo)
z.zoo <- as.zoo(zts)
z.zoo

library(xts)
z.xts <- as.xts(zts)
z.xts
</code>

Berend Hasselman

> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Sat Sep 16 10:36:28 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sat, 16 Sep 2017 11:36:28 +0300
Subject: [R] require help
In-Reply-To: <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
Message-ID: <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>

You can just use the same code that I provided before but now use your
dataset. Like this

df <- read.csv(file="data2.csv",header=TRUE)
dates <- as.Date(paste(df$year,"-01-01",sep=""))
myXts <- xts(df,order.by=dates)
head(myXts)

#The last command "head(myXts)" shows you the first few rows of the xts
object
           year     cnsm    incm    wlth
1980-01-01 1980 173.6527 53.3635 60.3013
1981-01-01 1981 175.4613 53.6929 60.4980
1982-01-01 1982 174.5724 53.4890 60.2358
1983-01-01 1983 171.5070 53.2223 60.1047
1984-01-01 1984 173.3462 53.2851 60.6946
1985-01-01 1985 171.7075 53.1596 60.7598


On Sat, Sep 16, 2017 at 9:55 AM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
> >
> > hello to all. I am working on macroeconomic data series of India, which
> in
> > a yearly basis. I am unable to convert my data frame into time series.
> > kindly help me.
> > also using zoo and xts packages. but they take only monthly observations.
> >
> > 'data.frame': 30 obs. of  4 variables:
> > $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> > $ cnsm: num  174 175 175 172 173 ...
> > $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> > $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> > --
>
> Second try to do what you would like (I hope and think)
> Using Eric's sample data
>
> <code>
> zdf <- data.frame(year=2001:2010, cnsm=sample(170:180,10,replace=TRUE),
>                  incm=rnorm(10,53,1), wlth=rnorm(10,60,1))
> zdf
>
> # R ts
> zts <- ts(zdf[,-1], start=zdf[1,"year"])
> zts
>
> # turn data into a zoo timeseries and an xts timeseries
>
> library(zoo)
> z.zoo <- as.zoo(zts)
> z.zoo
>
> library(xts)
> z.xts <- as.xts(zts)
> z.xts
> </code>
>
> Berend Hasselman
>
> > Yadawananda Neog
> > Research Scholar
> > Department of Economics
> > Banaras Hindu University
> > Mob. 9838545073
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r-packages at r-project.org  Fri Sep 15 19:44:17 2017
From: r-packages at r-project.org (sam d via R-packages)
Date: Fri, 15 Sep 2017 17:44:17 +0000
Subject: [R] [R-pkgs] revengc CRAN package
References: <736305065.2181156.1505497457824.ref@mail.yahoo.com>
Message-ID: <736305065.2181156.1505497457824@mail.yahoo.com>

Dear R community,


?
I am happy to announce the publication on CRAN of the revengc package:

https://cran.r-project.org/web/packages/revengc/index.html

The statistical package revengc was designed to reverse engineer censored, decoupledcensus data into a likely hhs x area uncensored contingency table for estimating interior residentialoccupancy.?

?
For basic examples:

https://cran.r-project.org/web/packages/revengc/revengc.pdf

?
For more details on the underlying methods:?

https://cran.r-project.org/web/packages/revengc/vignettes/methodbehind_reverseengineeringcensus.pdf

?
The package is also available on GitHub:

https://github.com/GIST-ORNL/revengc
Cheers?Samantha Duchscherer


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From lars52r at gmail.com  Sat Sep 16 15:04:49 2017
From: lars52r at gmail.com (Lars Bishop)
Date: Sat, 16 Sep 2017 09:04:49 -0400
Subject: [R] Help with shiny::reactiveFileReader()
Message-ID: <CAO7OmOgbRJj-WoyV6S1VAs0nn4Or-_boPhOmK4oxfRzVe-vXSQ@mail.gmail.com>

Hello,

Is it possible to execute functions (outside the ui and server shiny
environments) after reading data using reactiveFileReader() ?

For example, I'd like to fit a linear model on data read using
reactiveFileReader() outside ui/server.


library(shiny)
library(dplyr)

bigData <- reactiveFileReader(1000, NULL, 'data.csv', read.csv)

fit <- lm(y ~., data = bigData())

ui <- function() {

}

server <- function(input, output) {

}

Thank you,
Lars.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Sep 16 15:45:31 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 16 Sep 2017 06:45:31 -0700
Subject: [R] Help with shiny::reactiveFileReader()
In-Reply-To: <CAO7OmOgbRJj-WoyV6S1VAs0nn4Or-_boPhOmK4oxfRzVe-vXSQ@mail.gmail.com>
References: <CAO7OmOgbRJj-WoyV6S1VAs0nn4Or-_boPhOmK4oxfRzVe-vXSQ@mail.gmail.com>
Message-ID: <6370012B-E20B-48DC-9741-B697C35A111D@dcn.davis.ca.us>

No. However, you can modify the global environment from within a function if you understand how variable scoping works. [1] See `<<-`. Be warned that this leads down a perilous path of confusing code (side effects) if misused.

[1] http://adv-r.had.co.nz/Environments.html
-- 
Sent from my phone. Please excuse my brevity.

On September 16, 2017 6:04:49 AM PDT, Lars Bishop <lars52r at gmail.com> wrote:
>Hello,
>
>Is it possible to execute functions (outside the ui and server shiny
>environments) after reading data using reactiveFileReader() ?
>
>For example, I'd like to fit a linear model on data read using
>reactiveFileReader() outside ui/server.
>
>
>library(shiny)
>library(dplyr)
>
>bigData <- reactiveFileReader(1000, NULL, 'data.csv', read.csv)
>
>fit <- lm(y ~., data = bigData())
>
>ui <- function() {
>
>}
>
>server <- function(input, output) {
>
>}
>
>Thank you,
>Lars.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From yadavneog at gmail.com  Sat Sep 16 14:10:26 2017
From: yadavneog at gmail.com (yadav neog)
Date: Sat, 16 Sep 2017 17:40:26 +0530
Subject: [R] require help
In-Reply-To: <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
 <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>
Message-ID: <CACdLcRzQB5LoOFFmA-+6uvM6Uy9SCJ8tOqev5exBGCJ4aYvP7Q@mail.gmail.com>

oky.. thank you very much to all of you


On Sat, Sep 16, 2017 at 2:06 PM, Eric Berger <ericjberger at gmail.com> wrote:

> You can just use the same code that I provided before but now use your
> dataset. Like this
>
> df <- read.csv(file="data2.csv",header=TRUE)
> dates <- as.Date(paste(df$year,"-01-01",sep=""))
> myXts <- xts(df,order.by=dates)
> head(myXts)
>
> #The last command "head(myXts)" shows you the first few rows of the xts
> object
>            year     cnsm    incm    wlth
> 1980-01-01 1980 173.6527 53.3635 60.3013
> 1981-01-01 1981 175.4613 53.6929 60.4980
> 1982-01-01 1982 174.5724 53.4890 60.2358
> 1983-01-01 1983 171.5070 53.2223 60.1047
> 1984-01-01 1984 173.3462 53.2851 60.6946
> 1985-01-01 1985 171.7075 53.1596 60.7598
>
>
> On Sat, Sep 16, 2017 at 9:55 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>>
>> > On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
>> >
>> > hello to all. I am working on macroeconomic data series of India, which
>> in
>> > a yearly basis. I am unable to convert my data frame into time series.
>> > kindly help me.
>> > also using zoo and xts packages. but they take only monthly
>> observations.
>> >
>> > 'data.frame': 30 obs. of  4 variables:
>> > $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
>> > $ cnsm: num  174 175 175 172 173 ...
>> > $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
>> > $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
>> > --
>>
>> Second try to do what you would like (I hope and think)
>> Using Eric's sample data
>>
>> <code>
>> zdf <- data.frame(year=2001:2010, cnsm=sample(170:180,10,replace=TRUE),
>>                  incm=rnorm(10,53,1), wlth=rnorm(10,60,1))
>> zdf
>>
>> # R ts
>> zts <- ts(zdf[,-1], start=zdf[1,"year"])
>> zts
>>
>> # turn data into a zoo timeseries and an xts timeseries
>>
>> library(zoo)
>> z.zoo <- as.zoo(zts)
>> z.zoo
>>
>> library(xts)
>> z.xts <- as.xts(zts)
>> z.xts
>> </code>
>>
>> Berend Hasselman
>>
>> > Yadawananda Neog
>> > Research Scholar
>> > Department of Economics
>> > Banaras Hindu University
>> > Mob. 9838545073
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

	[[alternative HTML version deleted]]


From rene.j.suarez at gmail.com  Sat Sep 16 15:16:05 2017
From: rene.j.suarez at gmail.com (Rene J Suarez-Soto)
Date: Sat, 16 Sep 2017 09:16:05 -0400
Subject: [R] R_LIBS_USER not in libPaths
Message-ID: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>

I have a computer where R_LIBS_USER is not found in libPaths. This is for
Windows (x64). I ran R from the command line, RGui and RStudio and I get
the same results. I also ran R --vanilla and I still get the discrepancy.

The only thing I found interesting was that I also ran SET from the command
line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
there. Therefore these variables are being set when I start R. I have not
been able to track where does R obtain the value for these.

Aside from looking at
http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I am
not sure I have much more information that I have found useful.

Thanks

R

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Sat Sep 16 16:45:08 2017
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sat, 16 Sep 2017 07:45:08 -0700
Subject: [R] R_LIBS_USER not in libPaths
In-Reply-To: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
References: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
Message-ID: <CAFDcVCQYDE3gdmHSKAE5tg_hS+stJ4YcxRYdZSOEjDLqeWrK4w@mail.gmail.com>

I'm not sure I follow what.the problem is. Are you trying to
set R_LIBS_USER but R does not acknowledge it, or do you observe something
in R that you didn't expect to be there and you are trying to figure out
why that is / where that happens?

Henrik

On Sep 16, 2017 07:10, "Rene J Suarez-Soto" <rene.j.suarez at gmail.com> wrote:

> I have a computer where R_LIBS_USER is not found in libPaths. This is for
> Windows (x64). I ran R from the command line, RGui and RStudio and I get
> the same results. I also ran R --vanilla and I still get the discrepancy.
>
> The only thing I found interesting was that I also ran SET from the command
> line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
> there. Therefore these variables are being set when I start R. I have not
> been able to track where does R obtain the value for these.
>
> Aside from looking at
> http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I am
> not sure I have much more information that I have found useful.
>
> Thanks
>
> R
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rene.j.suarez at gmail.com  Sat Sep 16 17:29:52 2017
From: rene.j.suarez at gmail.com (Rene J Suarez-Soto)
Date: Sat, 16 Sep 2017 11:29:52 -0400
Subject: [R] R_LIBS_USER not in libPaths
In-Reply-To: <CAFDcVCQYDE3gdmHSKAE5tg_hS+stJ4YcxRYdZSOEjDLqeWrK4w@mail.gmail.com>
References: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
 <CAFDcVCQYDE3gdmHSKAE5tg_hS+stJ4YcxRYdZSOEjDLqeWrK4w@mail.gmail.com>
Message-ID: <CAKeefvt3FhrumdN1-SBOHoofNK1NTeP_OTNixJs=j6GN7UxeKA@mail.gmail.com>

I have not intentionally set R_LIBS_USER. I looked for an Renviron.site
file but did not see it in R/etc or my home directory. The strange part is
that if I print Sud.getenv I see a value for R_LIBS_USER. However, this
directory is not showing under libPaths.

I though .libPaths should contain R_LIBS_USER.

I also noticed that R related variables are not in the system or user
variables because I dont see them when I type SET from the Windows Command
line. So a related question is where does R get the system variables
(e.g., R_LIBS_USER,
R_HOME) if I dont see a Renviron.site file. Thanks

On Sep 16, 2017 10:45 AM, "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
wrote:

I'm not sure I follow what.the problem is. Are you trying to
set R_LIBS_USER but R does not acknowledge it, or do you observe something
in R that you didn't expect to be there and you are trying to figure out
why that is / where that happens?

Henrik

On Sep 16, 2017 07:10, "Rene J Suarez-Soto" <rene.j.suarez at gmail.com> wrote:

> I have a computer where R_LIBS_USER is not found in libPaths. This is for
> Windows (x64). I ran R from the command line, RGui and RStudio and I get
> the same results. I also ran R --vanilla and I still get the discrepancy.
>
> The only thing I found interesting was that I also ran SET from the command
> line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
> there. Therefore these variables are being set when I start R. I have not
> been able to track where does R obtain the value for these.
>
> Aside from looking at
> http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I am
> not sure I have much more information that I have found useful.
>
> Thanks
>
> R
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat Sep 16 17:35:56 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 16 Sep 2017 16:35:56 +0100
Subject: [R] R_LIBS_USER not in libPaths
In-Reply-To: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
References: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
Message-ID: <c8ac0033-cff8-1961-954c-16603ec30578@dewey.myzen.co.uk>

Dear Rene

I am not sure I understand your problem so this may be completely uselss 
but when I am going to run R from the command line I first of all run a 
little batch file.

set R_HOME=C:\Users\Michael\Documents\bin\R\R-3.4.1
set R_PATH=%R_HOME%\bin\x64
set PATH=%R_PATH%;%PATH%

Someone (forgotten who, sorry) posted this years ago on this site.

Michael

On 16/09/2017 14:16, Rene J Suarez-Soto wrote:
> I have a computer where R_LIBS_USER is not found in libPaths. This is for
> Windows (x64). I ran R from the command line, RGui and RStudio and I get
> the same results. I also ran R --vanilla and I still get the discrepancy.
> 
> The only thing I found interesting was that I also ran SET from the command
> line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
> there. Therefore these variables are being set when I start R. I have not
> been able to track where does R obtain the value for these.
> 
> Aside from looking at
> http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I am
> not sure I have much more information that I have found useful.
> 
> Thanks
> 
> R
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Sat Sep 16 17:57:00 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 16 Sep 2017 08:57:00 -0700
Subject: [R] R_LIBS_USER not in libPaths
In-Reply-To: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
References: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
Message-ID: <4667C913-CDFC-4829-98C7-ECA29D8797DF@dcn.davis.ca.us>

These environment variables are _inputs_ to the R startup sequence, and optional ones at that. If you don't set them then R makes default settings. Read the R Installation and Administration manual that comes with R for more information. 

You also need to understand the scope of environment variables, which is a topic specific to each operating system and is not specific to R. In a nutshell, a process (running program) that sets an environment variable can pass that setting to processes it starts, but the reverse is not true. If you want to set such variables for widespread use you can use the System control panel and logout and login so all processes will inherit them. 

Note that if you want to modify .libpaths in R you can do so without modifying environment variables. 
-- 
Sent from my phone. Please excuse my brevity.

On September 16, 2017 6:16:05 AM PDT, Rene J Suarez-Soto <rene.j.suarez at gmail.com> wrote:
>I have a computer where R_LIBS_USER is not found in libPaths. This is
>for
>Windows (x64). I ran R from the command line, RGui and RStudio and I
>get
>the same results. I also ran R --vanilla and I still get the
>discrepancy.
>
>The only thing I found interesting was that I also ran SET from the
>command
>line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
>there. Therefore these variables are being set when I start R. I have
>not
>been able to track where does R obtain the value for these.
>
>Aside from looking at
>http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I
>am
>not sure I have much more information that I have found useful.
>
>Thanks
>
>R
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From martin.morgan at roswellpark.org  Sat Sep 16 18:03:31 2017
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Sat, 16 Sep 2017 12:03:31 -0400
Subject: [R] R_LIBS_USER not in libPaths
In-Reply-To: <CAKeefvt3FhrumdN1-SBOHoofNK1NTeP_OTNixJs=j6GN7UxeKA@mail.gmail.com>
References: <CAKeefvvxtJEwqcBVYhM1pPCZ9e8POuSXsK8qtEvfMuy7JSruCA@mail.gmail.com>
 <CAFDcVCQYDE3gdmHSKAE5tg_hS+stJ4YcxRYdZSOEjDLqeWrK4w@mail.gmail.com>
 <CAKeefvt3FhrumdN1-SBOHoofNK1NTeP_OTNixJs=j6GN7UxeKA@mail.gmail.com>
Message-ID: <c1452e76-5e64-947a-94d4-32da6e630afc@roswellpark.org>

On 09/16/2017 11:29 AM, Rene J Suarez-Soto wrote:
> I have not intentionally set R_LIBS_USER. I looked for an Renviron.site
> file but did not see it in R/etc or my home directory. The strange part is
> that if I print Sud.getenv I see a value for R_LIBS_USER. However, this
> directory is not showing under libPaths.
> 
> I though .libPaths should contain R_LIBS_USER.

If the directory pointed to by R_LIBS_USER does not exist, then 
.libPaths() will not contain it. This is documented on ?.libPaths or 
?R_LIBS_USER

      Only directories
      which exist at the time will be included.

The file in the user home directory is .Renviron, rather than 
Renviron.site. This documented at, e.g,. ?Renviron

      The name of the user file
      can be specified by the 'R_ENVIRON_USER' environment variable; if
      this is unset, the files searched for are '.Renviron' in the
      current or in the user's home directory (in that order).

R environment variables are set when R starts; I can discover these, on 
linux, by invoking the relevant command-line command after running R CMD

$ env|grep "^R_"
$

(i.e., no output) versus

$ R CMD env|grep "^R_"
R_UNZIPCMD=/usr/bin/unzip
...

Generally, ?Startup describes the startup process, and most variables 
are described in R via ?R_...

Martin

> 
> I also noticed that R related variables are not in the system or user
> variables because I dont see them when I type SET from the Windows Command
> line. So a related question is where does R get the system variables
> (e.g., R_LIBS_USER,
> R_HOME) if I dont see a Renviron.site file. Thanks
> 
> On Sep 16, 2017 10:45 AM, "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
> wrote:
> 
> I'm not sure I follow what.the problem is. Are you trying to
> set R_LIBS_USER but R does not acknowledge it, or do you observe something
> in R that you didn't expect to be there and you are trying to figure out
> why that is / where that happens?
> 
> Henrik
> 
> On Sep 16, 2017 07:10, "Rene J Suarez-Soto" <rene.j.suarez at gmail.com> wrote:
> 
>> I have a computer where R_LIBS_USER is not found in libPaths. This is for
>> Windows (x64). I ran R from the command line, RGui and RStudio and I get
>> the same results. I also ran R --vanilla and I still get the discrepancy.
>>
>> The only thing I found interesting was that I also ran SET from the command
>> line and the "R related variables" (e.g.,  R_HOME; R_LIBS_USER) are not
>> there. Therefore these variables are being set when I start R. I have not
>> been able to track where does R obtain the value for these.
>>
>> Aside from looking at
>> http://stat.ethz.ch/R-manual/R-patched/library/base/html/Startup.html I am
>> not sure I have much more information that I have found useful.
>>
>> Thanks
>>
>> R
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From sofimarman at gmail.com  Sat Sep 16 17:53:49 2017
From: sofimarman at gmail.com (Sophi Marmen)
Date: Sat, 16 Sep 2017 18:53:49 +0300
Subject: [R] Help with RDA analysis, function ''varpart'' in vegan
Message-ID: <CABjqNpnZ9xaJEYRrkrAUBVFhcG1jNuTdnbXwB=oFyZhJgmgSZg@mail.gmail.com>

I'm trying to perform a RDA analysis in the vegan package using the
"varpart"  function.

I have a matrix of community structure data in different sites (rows),
which I want to explain using 3 matrices of environmental data. The 3
matrices are:

water quality parameters;

local land use variables;

total land use variables.

In each matrix, the number of the rows is the same (the sites) and there
are different column number (measured varibakes).

I use the follow script:

WQ_RDA <- read.csv("F:/Sher_sophi_new3/RDA/WQ_RDA_1.csv", row.names = 1)
LU2_loc_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_loc_RDA_1.csv",
row.names = 1)
LU2_bas_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_basin_RDA_1.csv",
row.names = 1)
comm <- read.csv("F:/Sher_sophi_new3/RDA/Final_true_OTUs_97_1.csv",
row.names = 1)

x1 = as.matrix(WQ_RDA)
x2 = as.matrix(LU2_loc_RDA)
x3 = as.matrix(LU2_bas_RDA)
comm = as.matrix(t(comm))

RDA_Ger = varpart(comm, x1, x2, x3, transfo="hellinger", scale = FALSE,
                  na.action = na.omit


I get this error message:

Error in as.vector(x, mode) :
  cannot coerce type 'closure' to vector of type 'any'

Can anyone help me figure out what am I doing wrong?

Thanks,
Sophi
-- 
Sophi Marmen
Ph.D candidate
Marine Biology Department
Leon H. Charney School of Marine Sciences
University of Haifa, Israel

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sun Sep 17 10:23:24 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 17 Sep 2017 11:23:24 +0300
Subject: [R] Help with RDA analysis, function ''varpart'' in vegan
In-Reply-To: <CABjqNpnZ9xaJEYRrkrAUBVFhcG1jNuTdnbXwB=oFyZhJgmgSZg@mail.gmail.com>
References: <CABjqNpnZ9xaJEYRrkrAUBVFhcG1jNuTdnbXwB=oFyZhJgmgSZg@mail.gmail.com>
Message-ID: <CAGgJW75N1kDSBWo__vtOHtAfUo8fVNdG8GxPVLfXkA7Xg-W3qg@mail.gmail.com>

I am not familiar with the vegan package, so I am just making a guess here.
If 'na.action=na.omit' is part of the call to varpart, try removing it from
the function call and moving it above as follows:

options(na.action="na.omit")
RDA_Ger <- varpart(comm, x1, x2, x3, transfo="hellinger", scale = FALSE)

Maybe that will help.

Regards,
Eric

On Sat, Sep 16, 2017 at 6:53 PM, Sophi Marmen <sofimarman at gmail.com> wrote:

> I'm trying to perform a RDA analysis in the vegan package using the
> "varpart"  function.
>
> I have a matrix of community structure data in different sites (rows),
> which I want to explain using 3 matrices of environmental data. The 3
> matrices are:
>
> water quality parameters;
>
> local land use variables;
>
> total land use variables.
>
> In each matrix, the number of the rows is the same (the sites) and there
> are different column number (measured varibakes).
>
> I use the follow script:
>
> WQ_RDA <- read.csv("F:/Sher_sophi_new3/RDA/WQ_RDA_1.csv", row.names = 1)
> LU2_loc_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_loc_RDA_1.csv",
> row.names = 1)
> LU2_bas_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_basin_RDA_1.csv",
> row.names = 1)
> comm <- read.csv("F:/Sher_sophi_new3/RDA/Final_true_OTUs_97_1.csv",
> row.names = 1)
>
> x1 = as.matrix(WQ_RDA)
> x2 = as.matrix(LU2_loc_RDA)
> x3 = as.matrix(LU2_bas_RDA)
> comm = as.matrix(t(comm))
>
> RDA_Ger = varpart(comm, x1, x2, x3, transfo="hellinger", scale = FALSE,
>                   na.action = na.omit
>
>
> I get this error message:
>
> Error in as.vector(x, mode) :
>   cannot coerce type 'closure' to vector of type 'any'
>
> Can anyone help me figure out what am I doing wrong?
>
> Thanks,
> Sophi
> --
> Sophi Marmen
> Ph.D candidate
> Marine Biology Department
> Leon H. Charney School of Marine Sciences
> University of Haifa, Israel
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Sep 17 16:56:21 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 17 Sep 2017 07:56:21 -0700
Subject: [R] Help with RDA analysis, function ''varpart'' in vegan
In-Reply-To: <CAGgJW75N1kDSBWo__vtOHtAfUo8fVNdG8GxPVLfXkA7Xg-W3qg@mail.gmail.com>
References: <CABjqNpnZ9xaJEYRrkrAUBVFhcG1jNuTdnbXwB=oFyZhJgmgSZg@mail.gmail.com>
 <CAGgJW75N1kDSBWo__vtOHtAfUo8fVNdG8GxPVLfXkA7Xg-W3qg@mail.gmail.com>
Message-ID: <CAGxFJbT6QhQ83MgXXauHpLkqfBWDRJVhaVud55fpY1FFgFRz6w@mail.gmail.com>

Doubt that will make any difference.

My guess is that there is a function in the environment that varpart wants
to use as an object -- i.e. there is a scoping bug in varpart. But that
could be baloney, too.

Please learn about R's debugging tools. Give us the results of traceback()
after the error.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 17, 2017 at 1:23 AM, Eric Berger <ericjberger at gmail.com> wrote:

> I am not familiar with the vegan package, so I am just making a guess here.
> If 'na.action=na.omit' is part of the call to varpart, try removing it from
> the function call and moving it above as follows:
>
> options(na.action="na.omit")
> RDA_Ger <- varpart(comm, x1, x2, x3, transfo="hellinger", scale = FALSE)
>
> Maybe that will help.
>
> Regards,
> Eric
>
> On Sat, Sep 16, 2017 at 6:53 PM, Sophi Marmen <sofimarman at gmail.com>
> wrote:
>
> > I'm trying to perform a RDA analysis in the vegan package using the
> > "varpart"  function.
> >
> > I have a matrix of community structure data in different sites (rows),
> > which I want to explain using 3 matrices of environmental data. The 3
> > matrices are:
> >
> > water quality parameters;
> >
> > local land use variables;
> >
> > total land use variables.
> >
> > In each matrix, the number of the rows is the same (the sites) and there
> > are different column number (measured varibakes).
> >
> > I use the follow script:
> >
> > WQ_RDA <- read.csv("F:/Sher_sophi_new3/RDA/WQ_RDA_1.csv", row.names = 1)
> > LU2_loc_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_loc_RDA_1.csv",
> > row.names = 1)
> > LU2_bas_RDA <- read.csv("F:/Sher_sophi_new3/RDA/LU2_basin_RDA_1.csv",
> > row.names = 1)
> > comm <- read.csv("F:/Sher_sophi_new3/RDA/Final_true_OTUs_97_1.csv",
> > row.names = 1)
> >
> > x1 = as.matrix(WQ_RDA)
> > x2 = as.matrix(LU2_loc_RDA)
> > x3 = as.matrix(LU2_bas_RDA)
> > comm = as.matrix(t(comm))
> >
> > RDA_Ger = varpart(comm, x1, x2, x3, transfo="hellinger", scale = FALSE,
> >                   na.action = na.omit
> >
> >
> > I get this error message:
> >
> > Error in as.vector(x, mode) :
> >   cannot coerce type 'closure' to vector of type 'any'
> >
> > Can anyone help me figure out what am I doing wrong?
> >
> > Thanks,
> > Sophi
> > --
> > Sophi Marmen
> > Ph.D candidate
> > Marine Biology Department
> > Leon H. Charney School of Marine Sciences
> > University of Haifa, Israel
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Sun Sep 17 19:31:12 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sun, 17 Sep 2017 13:31:12 -0400
Subject: [R] Shiny App inside R Package
Message-ID: <CAAyVsXJMdVHh_F27eb+djqw5czPK5ddFMzabOU_dCzmQwJHy2A@mail.gmail.com>

Dear List,

I have a wrapper function that creates a Shiny App, as illustrated below.

I'd like to include the function myApp() inside a package. I'd appreciate
your guidance here, as I could not find good instructions on this online.


myApp <- function(x) {
  require(shiny)
  shinyApp(
    ui = fluidPage(
      sidebarLayout(
        sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
        mainPanel(plotOutput("hist"))
      )
    ),
    server = function(input, output) {
      output$hist <- renderPlot(
        hist(x, breaks = input$n,
             col = "skyblue", border = "white")
      )
    }
  )
}

myApp(rnorm(100))

Regards,
Axel.

	[[alternative HTML version deleted]]


From jari.oksanen at oulu.fi  Sun Sep 17 20:49:07 2017
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Sun, 17 Sep 2017 18:49:07 +0000
Subject: [R] Help with RDA analysis, function ''varpart'' in vegan
Message-ID: <BC6FFC0F-D4B7-4FC2-B74A-06AAA8EBCB30@oulu.fi>

The varpart function does not have na.action argument, and all undefined arguments are regarded as explanatory data sets X (they come after ?).

Best wishes, Jari Oksnaen

From thierry.onkelinx at inbo.be  Sun Sep 17 21:13:13 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sun, 17 Sep 2017 21:13:13 +0200
Subject: [R] Shiny App inside R Package
In-Reply-To: <CAAyVsXJMdVHh_F27eb+djqw5czPK5ddFMzabOU_dCzmQwJHy2A@mail.gmail.com>
References: <CAAyVsXJMdVHh_F27eb+djqw5czPK5ddFMzabOU_dCzmQwJHy2A@mail.gmail.com>
Message-ID: <CAJuCY5ws6SnfUMZ-ute=5Ry+wskcj+-ULZkdEZSv6wx-S7=rMQ@mail.gmail.com>

Dear Axel,

I tend to place Shiny apps in the "inst" directory of the package. See
https://stackoverflow.com/questions/37830819/developing-shiny-app-as-a-package-and-deploying-it-to-shiny-server

Best regards,
ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-17 19:31 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
> Dear List,
>
> I have a wrapper function that creates a Shiny App, as illustrated below.
>
> I'd like to include the function myApp() inside a package. I'd appreciate
> your guidance here, as I could not find good instructions on this online.
>
>
> myApp <- function(x) {
>   require(shiny)
>   shinyApp(
>     ui = fluidPage(
>       sidebarLayout(
>         sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>         mainPanel(plotOutput("hist"))
>       )
>     ),
>     server = function(input, output) {
>       output$hist <- renderPlot(
>         hist(x, breaks = input$n,
>              col = "skyblue", border = "white")
>       )
>     }
>   )
> }
>
> myApp(rnorm(100))
>
> Regards,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Sun Sep 17 22:05:11 2017
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 17 Sep 2017 22:05:11 +0200
Subject: [R] Shiny App inside R Package
In-Reply-To: <CAAyVsXJMdVHh_F27eb+djqw5czPK5ddFMzabOU_dCzmQwJHy2A@mail.gmail.com>
References: <CAAyVsXJMdVHh_F27eb+djqw5czPK5ddFMzabOU_dCzmQwJHy2A@mail.gmail.com>
Message-ID: <65992c71-d193-9202-38a6-2b1dad1432d5@yahoo.fr>

I have this working in my package embryogrowth available in CRAN.

I have a function to call the shiny app:
web.tsd <- function() {

 ? if (!requireNamespace("shiny", quietly = TRUE)) {
 ??? stop("shiny package is absent; Please install it first")
 ? }

getFromNamespace("runApp", ns="shiny")(appDir = system.file("shiny", 
package="embryogrowth"),
 ?????????????????????????????????????? launch.browser =TRUE)

}

I have a folder inst and inside a folder shiny.
Within this folder inst/shiny/ I copy the two files server.R and ui.R

Marc

Le 17/09/2017 ? 19:31, Axel Urbiz a ?crit?:
> Dear List,
>
> I have a wrapper function that creates a Shiny App, as illustrated below.
>
> I'd like to include the function myApp() inside a package. I'd appreciate
> your guidance here, as I could not find good instructions on this online.
>
>
> myApp <- function(x) {
>    require(shiny)
>    shinyApp(
>      ui = fluidPage(
>        sidebarLayout(
>          sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>          mainPanel(plotOutput("hist"))
>        )
>      ),
>      server = function(input, output) {
>        output$hist <- renderPlot(
>          hist(x, breaks = input$n,
>               col = "skyblue", border = "white")
>        )
>      }
>    )
> }
>
> myApp(rnorm(100))
>
> Regards,
> Axel.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


.


From AjayArvind.Rao at gmrgroup.in  Mon Sep 18 06:24:46 2017
From: AjayArvind.Rao at gmrgroup.in (Ajay Arvind Rao)
Date: Mon, 18 Sep 2017 04:24:46 +0000
Subject: [R] Help/information required
Message-ID: <42BA9F35C6F4AB43982A10F9564AF30812F08694@HYD-VMBX-04.gmrgroup.int>

Hi,

We are using open source license of R to analyze data at our organization. The system configuration are as follows:

*        System configuration:

o   Operating System - Windows 7 Enterprise SP1, 64 bit (Desktop)

o   RAM - 8 GB

o   Processor - i5-6500 @ 3.2 Ghz

*        R Version:

o   R Studio 1.0.136

o   R 3.4.0

While trying to merge two datasets we received the following resource error message on running the code
Code: merg_data <- merge(x=Data_1Junto30Jun,y=flight_code,by.x="EB_FLNO1",by.y="EB_FLNO1",all.x = TRUE)
Error Message: Error: cannot allocate vector of size 5.8 Gb

Later we tried running the code differently but error still remained
Code: merg_data <- sqldf("Select * from Data_1Junto30Jun as a inner join flight_code as b on a.EB_FLNO1=b.EB_FLNO1")
Error Message: Error: cannot allocate vector of size 200.0 Mb

We have upgraded the RAM to 8 GB couple of months back. Can you let us know options to resolve the above issue without having to increase the RAM? The size of the datasets are as follows:

*        Data_1Junto30Jun (513476 obs of 32 variables). Data size - 172033368 bytes / 172 MB

*        flight_code (478105 obs of 2 variables). Data size - 3836304 bytes / 4 MB


Help with determining system requirement:
Is there a way to determine minimum system requirement (hardware and software) depending on size of the data, the way the data is loaded into R (directly from server or in a flat file) and the type of analysis to be run?
We have not been able to get any specific information related to this and are estimating the requirements through a trial and error method. Any information on this front will be helpful.


Thanks,
Ajay Rao
Strategy & Planning Group (SPG)
GMR Hyderabad International Airport Ltd.
Landline No: +91 40 66604051 / +91-9723465186
Email ID: AjayArvind.Rao at gmrgroup.in<mailto:AjayArvind.Rao at gmrgroup.in>


________________________________

This e-mail contains information which is confidential and/or legally privileged. If you are not the intended recipient , you are hereby notified that any disclosure, copying, distribution or the taking of any action in reliance on the contents of this e-mail is strictly prohibited. If you have received this e-mail in error, please destroy it and notify us by reply e-mail or by telephone. Internet E-mail messages may be subject to delays, non-delivery and unauthorised alterations and we shall not be responsible for the consequence(s) in such event(s). All reasonable precautions have been taken to ensure no viruses are present in this E-mail. We cannot accept responsibility for loss or damage arising from the use of this E-mail or attachments and recommend that you subject these to your virus checking procedures prior to use.

	[[alternative HTML version deleted]]


From michael.eisenring at agroscope.admin.ch  Mon Sep 18 09:51:57 2017
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Mon, 18 Sep 2017 07:51:57 +0000
Subject: [R] Data arrangement for PLSDA using the ropls package
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD149565C6@SB00112A.adb.intra.admin.ch>

Hello,
I would like to do a partial least square discriminant analysis (PLSDA) in R using the package "ropls"
Which is in R available via the R command :

source("https://bioconductor.org/biocLite.R")

When I try to do a PLSDA using my own data.
The impact of two genders (AP,C) on 5 compounds measured in persons (samples) should be illustrated.  When I try to do a PLSDA I get the warning message:

"Single component model: only 'overview' and 'permutation' (in case of single response (O)PLS(-DA)) plots available"



I assume it has something to do with the way I arrange my data into R. I tried to do it in a similar way as it has been done in the example of the package using the sacurine data set (bioconductor.org/packages/release/bioc/vignettes/ropls/inst/doc/ropls-vignette.pdf)



Can somebody maybe tell me how I correctly have to arrange my data in order to perfom a PLSDA using the "ropls" package?



Thank you very much,

Mike



Please find my code and an example data set below:



CODE:



#Input data and convert to data frame and define "Sample" as row

dta<-read.csv("Demo.csv",sep=";",header=T)

rownames(dta)<-dta$Sample

dta



#Remove non-numeric "Sample" and "Gender" rows and convert to matrix

dta.exp<-dta[,c(-1,-7)]

matrix<-as.matrix(dta.exp)

str(matrix)

matrix



#create vector with "gender" as y-component

dta.treatments<-dta[,7]

dta.treatments



dta.factor<-as.factor(dta.treatments)



dta.plsda <- opls(matrix, dta.factor)




DATA:

> dput(dta)

structure(list(Sample = structure(c(1L, 12L, 23L, 34L, 36L, 37L,

38L, 39L, 40L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L,

14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 24L, 25L, 26L, 27L,

28L, 29L, 30L, 31L, 32L, 33L, 35L), .Label = c("sa1", "sa10",

"sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",

"sa19", "sa2", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25",

"sa26", "sa27", "sa28", "sa29", "sa3", "sa30", "sa31", "sa32",

"sa33", "sa34", "sa35", "sa36", "sa37", "sa38", "sa39", "sa4",

"sa40", "sa5", "sa6", "sa7", "sa8", "sa9"), class = "factor"),

    Comp1 = c(1.7686, 0.6873, 1.2322, 1.4874, 1.8986, 1.3484,

    1.0959, 0.583, 1.039, 1.6133, 0.9595, 1.6377, 1.4538, 0.8737,

    1.3363, 1.7881, 2.3604, 1.1239, 2.1281, 2.037, 0.5314, 0.7147,

    0.5917, 0.6671, 0.6645, 0.9865, 1.019, 0.9664, 0.6966, 0.679,

    0.7976, 0.8503, 1.2566, 0.5881, 0.8838, 0.6657, 0.7399, 0.5778,

    0.7121, 1.1909), Comp2 = c(0.0284, 0.9064, 0, 0.7053, 0.7695,

    0.337, 1.0418, 0.8346, 0.3884, 1.9946, 1.3296, 0.119, 0.0106,

    0.7872, 1.0174, 0.0704, 0.0854, 0.4259, 0.0395, 0.0549, 2.4471,

    1.8418, 2.9805, 1.1181, 0.5403, 2.7181, 1.4835, 0.875, 2.2205,

    2.4106, 1.1967, 0.303, 0.1129, 2.5432, 2.328, 0.9839, 2.3583,

    1.9589, 1.9918, 1.2232), Comp3 = c(2.9976, 1.6201, 0.7497,

    1.371, 2.7035, 0.4533, 0.9927, 1.0973, 1.6702, 1.3696, 0.3392,

    1.1489, 2.1086, 1.1586, 1.3645, 1.6008, 2.9567, 1.5721, 2.9633,

    2.4623, 0.1103, 0.3137, 0.313, 0.2969, 0.5148, 0.7419, 0.5641,

    0.7871, 0.7362, 0.8754, 0.4883, 0.8504, 1.4582, 0.1934, 0.764,

    0.7515, 0.7143, 0.2139, 0.5743, 1.7305), Comp4 = c(0, 0,

    0.603, 0, 1.6524, 0, 0, 0, 0, 1.1056, 0, 0, 0, 0, 0, 0, 5.7848,

    0, 0, 0, 0, 0, 0, 0, 0, 0.7895, 3.4641, 0, 0, 1.7446, 0,

    0, 1.5165, 0, 5.9645, 4.1878, 0.7313, 5.7994, 3.0168, 0),

    Comp5 = c(18.6058, 5.6489, 12.0842, 4.2708, 3.8489, 10.2139,

    6.1149, 11.3373, 8.9013, 5.8342, 18.532, 17.9267, 8.7386,

    6.9455, 7.3044, 19.0811, 10.8809, 10.7149, 4.7057, 0, 10.3088,

    5.1514, 19.1218, 21.1768, 8.3797, 2.7146, 8.7405, 14.4817,

    8.6571, 17.4254, 17.5725, 5.1233, 13.7539, 6.7396, 2.1342,

    14.4216, 9.2952, 19.9525, 2.2317, 16.501), Gender = structure(c(1L,

    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,

    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("AP", "C"

    ), class = "factor")), .Names = c("Sample", "Comp1", "Comp2",

"Comp3", "Comp4", "Comp5", "Gender"), class = "data.frame", row.names = c("sa1",

"sa2", "sa3", "sa4", "sa5", "sa6", "sa7", "sa8", "sa9", "sa10",

"sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",

"sa19", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25", "sa26",

"sa27", "sa28", "sa29", "sa30", "sa31", "sa32", "sa33", "sa34",

"sa35", "sa36", "sa37", "sa38", "sa39", "sa40"))



Eisenring Michael, Dr.

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 58 468 7181
Fax +41 58 468 7201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From michael.eisenring at agroscope.admin.ch  Mon Sep 18 10:51:02 2017
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Mon, 18 Sep 2017 08:51:02 +0000
Subject: [R] Data arrangement for PLSDA using the ropls package
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD149565FA@SB00112A.adb.intra.admin.ch>

Hello,
I would like to do a partial least square discriminant analysis (PLSDA) in R using the package "ropls"
Which is in R available via the R command :

source("https://bioconductor.org/biocLite.R")

I try to do a PLSDA to illustrate the impact of two genders (AP,C) on 5 compounds measured in persons (samples) should be illustrated.  When I try to do a PLSDA I get the warning message:

"Single component model: only 'overview' and 'permutation' (in case of single response (O)PLS(-DA)) plots available"



I assume it has something to do with the way I arrange my data into R. I tried to do it in a similar way as it has been done in the example of the package using the sacurine data set (bioconductor.org/packages/release/bioc/vignettes/ropls/inst/doc/ropls-vignette.pdf)



Can somebody maybe tell me how I correctly have to arrange my data in order to perfom a PLSDA using the "ropls" package?



Thank you very much,

Mike



Please find my code and an example data set below:



CODE:



#Input data and convert to data frame and define "Sample" as row

dta<-read.csv("Demo.csv",sep=";",header=T)

rownames(dta)<-dta$Sample

dta



#Remove non-numeric "Sample" and "Gender" rows and convert to matrix

dta.exp<-dta[,c(-1,-7)]

matrix<-as.matrix(dta.exp)

str(matrix)

matrix



#create vector with "gender" as y-component

dta.treatments<-dta[,7]

dta.treatments



dta.factor<-as.factor(dta.treatments)



dta.plsda <- opls(matrix, dta.factor)




DATA:

> dput(dta)

structure(list(Sample = structure(c(1L, 12L, 23L, 34L, 36L, 37L,

38L, 39L, 40L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L,

14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 24L, 25L, 26L, 27L,

28L, 29L, 30L, 31L, 32L, 33L, 35L), .Label = c("sa1", "sa10",

"sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",

"sa19", "sa2", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25",

"sa26", "sa27", "sa28", "sa29", "sa3", "sa30", "sa31", "sa32",

"sa33", "sa34", "sa35", "sa36", "sa37", "sa38", "sa39", "sa4",

"sa40", "sa5", "sa6", "sa7", "sa8", "sa9"), class = "factor"),

    Comp1 = c(1.7686, 0.6873, 1.2322, 1.4874, 1.8986, 1.3484,

    1.0959, 0.583, 1.039, 1.6133, 0.9595, 1.6377, 1.4538, 0.8737,

    1.3363, 1.7881, 2.3604, 1.1239, 2.1281, 2.037, 0.5314, 0.7147,

    0.5917, 0.6671, 0.6645, 0.9865, 1.019, 0.9664, 0.6966, 0.679,

    0.7976, 0.8503, 1.2566, 0.5881, 0.8838, 0.6657, 0.7399, 0.5778,

    0.7121, 1.1909), Comp2 = c(0.0284, 0.9064, 0, 0.7053, 0.7695,

    0.337, 1.0418, 0.8346, 0.3884, 1.9946, 1.3296, 0.119, 0.0106,

    0.7872, 1.0174, 0.0704, 0.0854, 0.4259, 0.0395, 0.0549, 2.4471,

    1.8418, 2.9805, 1.1181, 0.5403, 2.7181, 1.4835, 0.875, 2.2205,

    2.4106, 1.1967, 0.303, 0.1129, 2.5432, 2.328, 0.9839, 2.3583,

    1.9589, 1.9918, 1.2232), Comp3 = c(2.9976, 1.6201, 0.7497,

    1.371, 2.7035, 0.4533, 0.9927, 1.0973, 1.6702, 1.3696, 0.3392,

    1.1489, 2.1086, 1.1586, 1.3645, 1.6008, 2.9567, 1.5721, 2.9633,

    2.4623, 0.1103, 0.3137, 0.313, 0.2969, 0.5148, 0.7419, 0.5641,

    0.7871, 0.7362, 0.8754, 0.4883, 0.8504, 1.4582, 0.1934, 0.764,

    0.7515, 0.7143, 0.2139, 0.5743, 1.7305), Comp4 = c(0, 0,

    0.603, 0, 1.6524, 0, 0, 0, 0, 1.1056, 0, 0, 0, 0, 0, 0, 5.7848,

    0, 0, 0, 0, 0, 0, 0, 0, 0.7895, 3.4641, 0, 0, 1.7446, 0,

    0, 1.5165, 0, 5.9645, 4.1878, 0.7313, 5.7994, 3.0168, 0),

    Comp5 = c(18.6058, 5.6489, 12.0842, 4.2708, 3.8489, 10.2139,

    6.1149, 11.3373, 8.9013, 5.8342, 18.532, 17.9267, 8.7386,

    6.9455, 7.3044, 19.0811, 10.8809, 10.7149, 4.7057, 0, 10.3088,

    5.1514, 19.1218, 21.1768, 8.3797, 2.7146, 8.7405, 14.4817,

    8.6571, 17.4254, 17.5725, 5.1233, 13.7539, 6.7396, 2.1342,

    14.4216, 9.2952, 19.9525, 2.2317, 16.501), Gender = structure(c(1L,

    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,

    1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("AP", "C"

    ), class = "factor")), .Names = c("Sample", "Comp1", "Comp2",

"Comp3", "Comp4", "Comp5", "Gender"), class = "data.frame", row.names = c("sa1",

"sa2", "sa3", "sa4", "sa5", "sa6", "sa7", "sa8", "sa9", "sa10",

"sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",

"sa19", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25", "sa26",

"sa27", "sa28", "sa29", "sa30", "sa31", "sa32", "sa33", "sa34",

"sa35", "sa36", "sa37", "sa38", "sa39", "sa40"))




Eisenring Michael, Dr.

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 58 468 7181
Fax +41 58 468 7201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From upananda.pani at gmail.com  Mon Sep 18 13:36:46 2017
From: upananda.pani at gmail.com (Upananda Pani)
Date: Mon, 18 Sep 2017 17:06:46 +0530
Subject: [R] Convert data into zoo object using Performance analytics package
Message-ID: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>

Dear All,

While i am trying convert data frame object to zoo object I am
getting numeric(0) error in performance analytics package.

The source code i am using from this website to learn r in finance:
https://faculty.washington.edu/ezivot/econ424/returnCalculations.r

# create zoo objects from data.frame objects
dates.sbux = as.yearmon(sbux.df$Date, format="%m/%d/%Y")
dates.msft = as.yearmon(msft.df$Date, format="%m/%d/%Y")
sbux.z = zoo(x=sbux.df$Adj.Close, order.by=dates.sbux)
msft.z = zoo(x=msft.df$Adj.Close, order.by=dates.msft)
class(sbux.z)
head(sbux.z)
> head(sbux.z)
Data:
numeric(0)

I will be grateful if anybody would like to guide me where i am making the
mistake.

With best regards,
Upananda Pani


-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Mon Sep 18 14:13:34 2017
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 18 Sep 2017 07:13:34 -0500
Subject: [R] help matching rows of a data frame
Message-ID: <9153c6$7v8l5n@ironport10.mayo.edu>

This question likely has a 1 line answer, I'm just not seeing it.  (2, 3, or 10 lines is 
fine too.)

For a vector I can do group  <- match(x, unqiue(x)) to get a vector that labels each 
element of x.
What is an equivalent if x is a data frame?

The result does not have to be fast: the data set will have < 100 elements.  Since this is 
inside the survival package, and that package is on  the 'recommended' list, I can't 
depend on any package outside the recommended list.

Terry T.


From L.J.Bonnett at liverpool.ac.uk  Mon Sep 18 14:46:19 2017
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Mon, 18 Sep 2017 12:46:19 +0000
Subject: [R] Help understanding why glm and lrm.fit runs with my data,
 but lrm does not
In-Reply-To: <CAMO-wTYOahB0W_zaZWpDbx3=b5AdzegXzHXFkKEwd5fns7LBcg@mail.gmail.com>
References: <f55814e1303146b9850e79726f8a4870@liverpool.ac.uk>
 <7235C707-F9A1-434D-B692-D6856FED202B@comcast.net>
 <CAMO-wTYOahB0W_zaZWpDbx3=b5AdzegXzHXFkKEwd5fns7LBcg@mail.gmail.com>
Message-ID: <ca36fdf14bcc4b649b9611146c89b5c8@liverpool.ac.uk>

Many thanks for the assistance.  I am using a small sample of GUSTO-1 as a teaching demonstration.  The Gusto-1 dataset in various smaller subsets is available from this website: http://clinicalpredictionmodels.org/doku.php?id=rcode_and_data:start  which is associated with the Clinical Prediction Models book by Steyerberg.

Many thanks again for your assistance.

Kind regards,
Laura

From: harrelfe at gmail.com [mailto:harrelfe at gmail.com] On Behalf Of Frank Harrell
Sent: 14 September 2017 17:22
To: David Winsemius <dwinsemius at comcast.net>
Cc: Bonnett, Laura <ljbcmshe at liverpool.ac.uk>; r-help at r-project.org
Subject: Re: [R] Help understanding why glm and lrm.fit runs with my data, but lrm does not

Fixed 'maxiter' in the help file.  Thanks.

Please give the original source of that dataset.

That dataset is a tiny sample of GUSTO-I and not large enough to fit this model very reliably.

A nomogram using the full dataset (not publicly available to my knowledge) is already available in http://biostat.mc.vanderbilt.edu/tmp/bbr.pdf

Use lrm, not lrm.fit for this.  Adding maxit=20 will probably make it work on the small dataset but still not clear on why you are using this dataset.

Frank


________________________________
Frank E Harrell Jr

Professor

School of Medicine


Department of Biostatistics

Vanderbilt University


On Thu, Sep 14, 2017 at 10:48 AM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:

> On Sep 14, 2017, at 12:30 AM, Bonnett, Laura <L.J.Bonnett at liverpool.ac.uk<mailto:L.J.Bonnett at liverpool.ac.uk>> wrote:
>
> Dear all,
>
> I am using the publically available GustoW dataset.  The exact version I am using is available here: https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdrive.google.com%2Fopen%3Fid%3D0B4oZ2TQA0PAoUm85UzBFNjZ0Ulk&data=02%7C01%7Cf.harrell%40vanderbilt.edu%7Cadb58b13c3994f89209708d4fb8807f0%7Cba5a7f39e3be4ab3b45067fa80faecad%7C0%7C0%7C636410009046132507&sdata=UZgX3%2Ba%2FU2Eeh8ybHMI6JnF0Npd2XJPXAzlmtEhDgOY%3D&reserved=0
>
> I would like to produce a nomogram for 5 covariates - AGE, HYP, KILLIP, HRT and ANT.  I have successfully fitted a logistic regression model using the "glm" function as shown below.
>
> library(rms)
> gusto <- spss.get("GustoW.sav")
> fit <- glm(DAY30~AGE+HYP+factor(KILLIP)+HRT+ANT,family=binomial(link="logit"),data=gusto,x=TRUE,y=TRUE)
>
> However, my review of the literature and other websites suggest I need to use "lrm" for the purposes of producing a nomogram.  When I run the command using "lrm" (see below) I get an error message saying:
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>  Unable to fit model using "lrm.fit"
>
> My code is as follows:
> gusto2 <- gusto[,c(1,3,5,8,9,10)]
> gusto2$HYP <- factor(gusto2$HYP, labels=c("No","Yes"))
> gusto2$KILLIP <- factor(gusto2$KILLIP, labels=c("1","2","3","4"))
> gusto2$HRT <- factor(gusto2$HRT, labels=c("No","Yes"))
> gusto2$ANT <- factor(gusto2$ANT, labels=c("No","Yes"))
> var.labels=c(DAY30="30-day Mortality", AGE="Age in Years", KILLIP="Killip Class", HYP="Hypertension", HRT="Tachycardia", ANT="Anterior Infarct Location")
> label(gusto2)=lapply(names(var.labels),function(x) label(gusto2[,x])=var.labels[x])
>
> ddist = datadist(gusto2)
> options(datadist='ddist')
>
> fit1 <- lrm(DAY30~AGE+HYP+KILLIP+HRT+ANT,gusto2)
>
> Error in lrm(DAY30 ~ AGE + HYP + KILLIP + HRT + ANT, gusto2) :
>  Unable to fit model using "lrm.fit"
>
> Online solutions to this problem involve checking whether any variables are redundant.  However, the results for my data suggest  that none are.
> redun(~AGE+HYP+KILLIP+HRT+ANT,gusto2)
>
> Redundancy Analysis
>
> redun(formula = ~AGE + HYP + KILLIP + HRT + ANT, data = gusto2)
>
> n: 2188         p: 5    nk: 3
>
> Number of NAs:   0
>
> Transformation of target variables forced to be linear
>
> R-squared cutoff: 0.9   Type: ordinary
>
> R^2 with which each variable can be predicted from all other variables:
>
>   AGE    HYP KILLIP    HRT    ANT
> 0.028  0.032  0.053  0.046  0.040
>
> No redundant variables
>
> I've also tried just considering "lrm.fit" and that code seems to run without error too:
> lrm.fit(cbind(gusto2$AGE,gusto2$KILLIP,gusto2$HYP,gusto2$HRT,gusto2$ANT),gusto2$DAY30)
>
> Logistic Regression Model
>
> lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
>     gusto2$ANT), y = gusto2$DAY30)
>
>                       Model Likelihood     Discrimination    Rank Discrim.
>                          Ratio Test           Indexes           Indexes
> Obs          2188    LR chi2     233.59    R2       0.273    C       0.846
>  0           2053    d.f.             5    g        1.642    Dxy     0.691
>  1            135    Pr(> chi2) <0.0001    gr       5.165    gamma   0.696
> max |deriv| 4e-09                          gp       0.079    tau-a   0.080
>                                            Brier    0.048
>
>           Coef     S.E.   Wald Z Pr(>|Z|)
> Intercept -13.8515 0.9694 -14.29 <0.0001
> x[1]        0.0989 0.0103   9.58 <0.0001
> x[2]        0.9030 0.1510   5.98 <0.0001
> x[3]        1.3576 0.2570   5.28 <0.0001
> x[4]        0.6884 0.2034   3.38 0.0007
> x[5]        0.6327 0.2003   3.16 0.0016
>
> I was therefore hoping someone would explain why the "lrm" code is producing an error message, while "lrm.fit" and "glm" do not.  In particular I would welcome a solution to ensure I can produce a nomogram.

Try this:

lrm  # look at code, do a search on "fail"
?lrm.fit  # read the structure of the returned value of lrm.fit

my.fit <- lrm.fit(x = cbind(gusto2$AGE, gusto2$KILLIP, gusto2$HYP, gusto2$HRT,
    gusto2$ANT), y = gusto2$DAY30)

print(my.fit$fail)  # the error message you got from the lrm call means convergence failed

Documentation bug: The documentation of the cause of the 'fail'- value incorrectly gives the name of this parameter as 'maxiter' in the  Value section.

--
David.



>
> Kind regards,
> Laura
>
> Dr Laura Bonnett
> NIHR Post-Doctoral Fellow
>
> Department of Biostatistics,
> Waterhouse Building, Block F,
> 1-5 Brownlow Street,
> University of Liverpool,
> Liverpool,
> L69 3GL
>
> 0151 795 9686
> L.J.Bonnett at liverpool.ac.uk<mailto:L.J.Bonnett at liverpool.ac.uk>
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7Cf.harrell%40vanderbilt.edu%7Cadb58b13c3994f89209708d4fb8807f0%7Cba5a7f39e3be4ab3b45067fa80faecad%7C0%7C0%7C636410009046132507&sdata=GAPis8GXCfundLz48dX66AZfVTzxs%2BNBUmG1kgpx2Ro%3D&reserved=0
> PLEASE do read the posting guide https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&data=02%7C01%7Cf.harrell%40vanderbilt.edu%7Cadb58b13c3994f89209708d4fb8807f0%7Cba5a7f39e3be4ab3b45067fa80faecad%7C0%7C0%7C636410009046132507&sdata=C8xd7UizYeLM6bylOyad8bumQTsYOzFYZu2IcMo%2BUII%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Sep 18 15:54:29 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 18 Sep 2017 16:54:29 +0300
Subject: [R] help matching rows of a data frame
In-Reply-To: <9153c6$7v8l5n@ironport10.mayo.edu>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
Message-ID: <CAGgJW77MQtzcbUmF2eZmE2CnzjbRegCu9RxAOaASOCtO8sFLfA@mail.gmail.com>

Hi Terry,
I take your question to mean how to label distinct rows of a data frame. If
that is not your question please clarify.
I found the row.match() function in the package prodlim that can be used to
solve this.
However since your request requires no additional dependencies I borrowed
the relevant code from the row.match function.
Here is some obfuscated code to provide your answer in one line, per your
request. (less obfuscated code just below that.

Assuming your data frame is called 'df':

df[,ncol(df)+1] <- match( do.call("paste", c(df[, , drop = FALSE], sep =
"\\r")), do.call("paste", c(unique(df)[, , drop = FALSE], sep = "\\r")) )

The last column of df now contains the 'label' i.e. the row number of the
first row in df that is the same as the given row.

Somewhat less obfuscated

getLabels <- function(df) {
                          match( do.call("paste", c(df[, , drop = FALSE],
sep = "\\r")),
                                     do.call("paste", c(unique(df)[, , drop
= FALSE], sep = "\\r")) )
                     }

myDataFrame$label <- getLabels(myDataFrame)


HTH,

Eric


On Mon, Sep 18, 2017 at 3:13 PM, Therneau, Terry M., Ph.D. <
therneau at mayo.edu> wrote:

> This question likely has a 1 line answer, I'm just not seeing it.  (2, 3,
> or 10 lines is fine too.)
>
> For a vector I can do group  <- match(x, unqiue(x)) to get a vector that
> labels each element of x.
> What is an equivalent if x is a data frame?
>
> The result does not have to be fast: the data set will have < 100
> elements.  Since this is inside the survival package, and that package is
> on  the 'recommended' list, I can't depend on any package outside the
> recommended list.
>
> Terry T.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From michael.eisenring at agroscope.admin.ch  Mon Sep 18 16:00:25 2017
From: michael.eisenring at agroscope.admin.ch (michael.eisenring at agroscope.admin.ch)
Date: Mon, 18 Sep 2017 14:00:25 +0000
Subject: [R] Q2/R2 ratio in PLSDA
Message-ID: <6D5C009FB51EBD41BEE57F4C002350FD1495664B@SB00112A.adb.intra.admin.ch>

Hello,

I would like to perform a Partial least square discriminate analysis (PLSDA) in R.

To do this I use the package mixOmics.

I could perform the PLSDA in R. however I would also like to perform a leave-one-out cross validation in order to assess the performance of my model. My supervisor told me that I should focus on the R2/Q2 ratios.

However when I read the instruction for running the "perf" function (mixomics.org/wp-content/uploads/2014/08/Running_perf_function4.pd) I found no test showing the R2/Q2 ratios for a PLSDA.

Following the instructions I ended up with an estimation of 3 different error rates (max.dist /centroids. Dist /mahalanobis. Dist) (page 9 of the PDF I mentioned above).

1.Are these 3 error rates different variations of R2/Q2 ratios?
2.Is there a rule telling me what values my errorates should have in order to have a good model performance
3. Is there a way to calculate R2/Q2 ratios for PLSDA using the mixOmics package

Thank you


Below I provide a simplified example data set and my code:

DATA:
> dput(dta)
structure(list(Treatment = structure(c(2L, 1L, 1L, 2L, 2L, 1L,
2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 2L,
1L, 1L, 2L, 1L, 2L, 2L, 1L, 1L), .Label = c("C", "CAT"), class = "factor"),
    comp1 = c(0, 0.5677, 0.4486, 0.1772, 0.2145, 0.0302, 0.216,
    0.0938, 0.1143, 0.6414, 0.2461, 0.0498, 0.144, 0.0953, 0.3208,
    0.296, 0.418, 0.2247, 0.1921, 0.3792, 0.1394, 0.3069, 0.1211,
    0.0355, 0.8968, 0.1981, 0.1187, 0.418, 0.4313, 0.0835), comp2 = c(1.8378,
    2.3565, 4.6184, 2.3739, 1.3595, 1.9645, 1.2066, 0.9758, 2.259,
    1.9429, 1.9797, 2.3005, 2.2246, 1.5881, 1.3051, 1.5218, 1.8931,
    1.4476, 1.2672, 1.5634, 1.9313, 1.2859, 3.9039, 2.8956, 3.7026,
    2.1356, 1.4473, 1.8477, 2.1495, 1.2323), comp3 = c(5.6652,
    4.3214, 1.8763, 1.7093, 3.6592, 1.6457, 3.4825, 2.7332, 5.1582,
    2.7374, 5.0283, 4.7604, 2.0357, 4.0205, 3.5946, 4.1626, 2.3342,
    3.5049, 3.1272, 3.328, 3.5106, 3.7209, 1.8475, 5.4776, 2.4554,
    5.1995, 3.9241, 4.5022, 4.1593, 4.3931), comp4 = c(3.7994,
    4.2763, 3.7141, 1.166, 1.8907, 4.6145, 1.8988, 1.459, 3.2,
    3.4403, 3.8283, 2.8549, 4.7747, 2.1849, 1.1687, 2.5519, 4.021,
    1.2343, 1.4335, 1.8305, 4.5704, 0.2238, 3.6566, 4.0569, 2.1626,
    3.2887, 1.4183, 2.1783, 2.6233, 3.2128), comp5 = c(1.0424,
    2.2589, 0, 1.2217, 0, 0, 0, 0, 0, 0, 1.6675, 1.7548, 0, 1.0983,
    1.2258, 1.314, 2.9437, 0, 0.9749, 0.8959, 0, 0.9189, 1.5026,
    0, 1.0831, 2.2251, 0.8419, 1.1912, 2.2912, 0), comp6 = c(4.0781,
    7.2073, 6.0885, 4.9657, 4.0133, 7.6783, 4.2064, 1.6421, 6.6831,
    6.8437, 6.5152, 1.4712, 7.048, 4.9872, 4.4658, 1.3119, 10.2047,
    4.7551, 3.7564, 4.829, 8.5836, 3.508, 6.0251, 5.1122, 2.2058,
    6.8343, 3.9664, 2.005, 6.6678, 2.8081), comp7 = c(0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9795, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0)), .Names = c("Treatment", "comp1",
"comp2", "comp3", "comp4", "comp5", "comp6", "comp7"), class = "data.frame", row.names = c(NA,
-30L))


CODE
library(mixOmics)#plsda
library(MetabolAnalyze)#scaling
#read in data & convert to matrix
dta<-read.csv("test.csv",sep=";",header=T)
head(dta)

#Scale and remove "Sample" and create matrix
dta.red<-dta[,-1]
dta.scale<-scaling(dta.red,type="pareto")
matrix<-as.matrix(dta.scale)

#create vector with "Treatment"
dta.treatments<-dta[,1]
dta.factor<-as.factor(dta.treatments)
dta.factor


#PLSDA

#Performance/Loo cross validation
res.plsda2 = plsda(dta.scale, dta.factor, ncomp = 5)
tune.plsda2 = perf(res.plsda2, dist = "all", validation = "loo", progressBar = FALSE)
tune.plsda2$error.rate

dta.plsda2<-plsda(dta.scale, dta.factor,scale=F,mode="classic")
dta.plsda2






plotIndiv(dta.plsda2, ind.names = dta.factor, ellipse = TRUE, legend =TRUE)
plotArrow(dta.plsda2, ind.names = dta.factor, legend =TRUE)
plotVar(dta.plsda2, cex = 2)



plot(dta.plsda,typeVc = "x-score",parAsColFcVn = dta.factor,parEllipsesL = TRUE)


Eisenring Michael, Dr.

Federal Department of Economic Affairs, Education and Research
EAER
Agroecology and Environment
Biosafety

Reckenholzstrasse 191, CH-8046 Z?rich
Tel. +41 58 468 7181
Fax +41 58 468 7201
michael.eisenring at agroscope.admin.ch<mailto:michael.eisenring at agroscope.admin.ch>
www.agroscope.ch<http://www.agroscope.ch/>


	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Mon Sep 18 16:08:54 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 18 Sep 2017 10:08:54 -0400
Subject: [R] Convert data into zoo object using Performance analytics
	package
In-Reply-To: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
References: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
Message-ID: <CAP01uRkiH-5ReU9F=Jhtk3_bEEnqs22ok1cDX97_dhOgUPb_9Q@mail.gmail.com>

Depending on how you created df maybe your code has the column names
wrong.  In any case these 4 alternatives all work.  Start a fresh R
session and then copy and paste this into it.

library(zoo)
u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
fmt <- "%m/%d/%Y"

# 1
sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)

# 2
df <- read.csv(u)
sbux2.z <- read.zoo(df, FUN = as.yearmon, format = fmt)

# 3
df <- read.csv(u)
names(head(df))
## [1] "Date"      "Adj.Close"
sbux3.z <- zoo(df$Adj.Close, as.yearmon(df$Date, fmt))

# 4
df <- read.csv(u)
sbux4.z <- zoo(df[[2]], as.yearmon(df[[1]], fmt))

On Mon, Sep 18, 2017 at 7:36 AM, Upananda Pani <upananda.pani at gmail.com> wrote:
> Dear All,
>
> While i am trying convert data frame object to zoo object I am
> getting numeric(0) error in performance analytics package.
>
> The source code i am using from this website to learn r in finance:
> https://faculty.washington.edu/ezivot/econ424/returnCalculations.r
>
> # create zoo objects from data.frame objects
> dates.sbux = as.yearmon(sbux.df$Date, format="%m/%d/%Y")
> dates.msft = as.yearmon(msft.df$Date, format="%m/%d/%Y")
> sbux.z = zoo(x=sbux.df$Adj.Close, order.by=dates.sbux)
> msft.z = zoo(x=msft.df$Adj.Close, order.by=dates.msft)
> class(sbux.z)
> head(sbux.z)
>> head(sbux.z)
> Data:
> numeric(0)
>
> I will be grateful if anybody would like to guide me where i am making the
> mistake.
>
> With best regards,
> Upananda Pani
>
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jdnewmil at dcn.davis.ca.us  Mon Sep 18 16:11:59 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 18 Sep 2017 07:11:59 -0700
Subject: [R] help matching rows of a data frame
In-Reply-To: <CAGgJW77MQtzcbUmF2eZmE2CnzjbRegCu9RxAOaASOCtO8sFLfA@mail.gmail.com>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
 <CAGgJW77MQtzcbUmF2eZmE2CnzjbRegCu9RxAOaASOCtO8sFLfA@mail.gmail.com>
Message-ID: <1A72B3CB-63C7-49BD-A654-290521CCAA1A@dcn.davis.ca.us>

"Label" is not a clear term for data frames,  but most data frames have rownames. If dta is a data frame, not a tibble, 

rownames( dta )[ !duplicated( dta ) ]

Or could use row indexes directly

which( !duplicated( dta ) )
-- 
Sent from my phone. Please excuse my brevity.

On September 18, 2017 6:54:29 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
>Hi Terry,
>I take your question to mean how to label distinct rows of a data
>frame. If
>that is not your question please clarify.
>I found the row.match() function in the package prodlim that can be
>used to
>solve this.
>However since your request requires no additional dependencies I
>borrowed
>the relevant code from the row.match function.
>Here is some obfuscated code to provide your answer in one line, per
>your
>request. (less obfuscated code just below that.
>
>Assuming your data frame is called 'df':
>
>df[,ncol(df)+1] <- match( do.call("paste", c(df[, , drop = FALSE], sep
>=
>"\\r")), do.call("paste", c(unique(df)[, , drop = FALSE], sep = "\\r"))
>)
>
>The last column of df now contains the 'label' i.e. the row number of
>the
>first row in df that is the same as the given row.
>
>Somewhat less obfuscated
>
>getLabels <- function(df) {
>                        match( do.call("paste", c(df[, , drop = FALSE],
>sep = "\\r")),
>                                 do.call("paste", c(unique(df)[, , drop
>= FALSE], sep = "\\r")) )
>                     }
>
>myDataFrame$label <- getLabels(myDataFrame)
>
>
>HTH,
>
>Eric
>
>
>On Mon, Sep 18, 2017 at 3:13 PM, Therneau, Terry M., Ph.D. <
>therneau at mayo.edu> wrote:
>
>> This question likely has a 1 line answer, I'm just not seeing it. 
>(2, 3,
>> or 10 lines is fine too.)
>>
>> For a vector I can do group  <- match(x, unqiue(x)) to get a vector
>that
>> labels each element of x.
>> What is an equivalent if x is a data frame?
>>
>> The result does not have to be fast: the data set will have < 100
>> elements.  Since this is inside the survival package, and that
>package is
>> on  the 'recommended' list, I can't depend on any package outside the
>> recommended list.
>>
>> Terry T.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From maillists at pp.inet.fi  Mon Sep 18 16:32:33 2017
From: maillists at pp.inet.fi (K. Elo)
Date: Mon, 18 Sep 2017 17:32:33 +0300
Subject: [R] help matching rows of a data frame
In-Reply-To: <9153c6$7v8l5n@ironport10.mayo.edu>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
Message-ID: <1505745153.1681.25.camel@pp.inet.fi>

Hi!
2017-09-18 07:13 -0500, Therneau, Terry M., Ph.D. wrote:
> This question likely has a 1 line answer, I'm just not seeing
> it.??(2, 3, or 10 lines is?
> fine too.)
> 
> For a vector I can do group??<- match(x, unqiue(x)) to get a vector
> that labels each?
> element of x.

Actually, you get a vector of indices matching 'unique(x)', not a
labelled vector.

> x<-c("A","B","C","A","C","D")
> group<-match(x, unique(x))
> group
[1] 1 2 3 1 3 4

> What is an equivalent if x is a data frame?

So you will generate an index where duplicated rows have the row index
of the first occurrence, right? This could work:

>?x<-data.frame("X0"=c("A","B","C","C","D","A"), "X1"=c(1,2,1,1,3,1))
> group<-rownames(x)
>?for (i in 1:(nrow(x)-1)) {?
? ? ?for (j in (i+1):nrow(x)) {?
? ? ? ? if (sum(as.numeric(x[i,]==x[j,]))==ncol(x)) {?
? ? ? ? ? ?group[j]<-group[i] }
? ? ?}
? ?}
> ?group
[1] "1" "2" "3" "3" "5" "1"

HTH,
Kimmo


From bgunter.4567 at gmail.com  Mon Sep 18 17:05:41 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 18 Sep 2017 08:05:41 -0700
Subject: [R] Data arrangement for PLSDA using the ropls package
In-Reply-To: <6D5C009FB51EBD41BEE57F4C002350FD149565FA@SB00112A.adb.intra.admin.ch>
References: <6D5C009FB51EBD41BEE57F4C002350FD149565FA@SB00112A.adb.intra.admin.ch>
Message-ID: <CAGxFJbQ3RjRqzQ81Et+Z1-D9X4emW-4Ph1gqj7_w4ZTZiXC-tA@mail.gmail.com>

If this is a bioconductor package, why do you not post on the bioconductor
list?

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 18, 2017 at 1:51 AM, <michael.eisenring at agroscope.admin.ch>
wrote:

> Hello,
> I would like to do a partial least square discriminant analysis (PLSDA) in
> R using the package "ropls"
> Which is in R available via the R command :
>
> source("https://bioconductor.org/biocLite.R")
>
> I try to do a PLSDA to illustrate the impact of two genders (AP,C) on 5
> compounds measured in persons (samples) should be illustrated.  When I try
> to do a PLSDA I get the warning message:
>
> "Single component model: only 'overview' and 'permutation' (in case of
> single response (O)PLS(-DA)) plots available"
>
>
>
> I assume it has something to do with the way I arrange my data into R. I
> tried to do it in a similar way as it has been done in the example of the
> package using the sacurine data set (bioconductor.org/packages/
> release/bioc/vignettes/ropls/inst/doc/ropls-vignette.pdf)
>
>
>
> Can somebody maybe tell me how I correctly have to arrange my data in
> order to perfom a PLSDA using the "ropls" package?
>
>
>
> Thank you very much,
>
> Mike
>
>
>
> Please find my code and an example data set below:
>
>
>
> CODE:
>
>
>
> #Input data and convert to data frame and define "Sample" as row
>
> dta<-read.csv("Demo.csv",sep=";",header=T)
>
> rownames(dta)<-dta$Sample
>
> dta
>
>
>
> #Remove non-numeric "Sample" and "Gender" rows and convert to matrix
>
> dta.exp<-dta[,c(-1,-7)]
>
> matrix<-as.matrix(dta.exp)
>
> str(matrix)
>
> matrix
>
>
>
> #create vector with "gender" as y-component
>
> dta.treatments<-dta[,7]
>
> dta.treatments
>
>
>
> dta.factor<-as.factor(dta.treatments)
>
>
>
> dta.plsda <- opls(matrix, dta.factor)
>
>
>
>
> DATA:
>
> > dput(dta)
>
> structure(list(Sample = structure(c(1L, 12L, 23L, 34L, 36L, 37L,
>
> 38L, 39L, 40L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 13L,
>
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 24L, 25L, 26L, 27L,
>
> 28L, 29L, 30L, 31L, 32L, 33L, 35L), .Label = c("sa1", "sa10",
>
> "sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",
>
> "sa19", "sa2", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25",
>
> "sa26", "sa27", "sa28", "sa29", "sa3", "sa30", "sa31", "sa32",
>
> "sa33", "sa34", "sa35", "sa36", "sa37", "sa38", "sa39", "sa4",
>
> "sa40", "sa5", "sa6", "sa7", "sa8", "sa9"), class = "factor"),
>
>     Comp1 = c(1.7686, 0.6873, 1.2322, 1.4874, 1.8986, 1.3484,
>
>     1.0959, 0.583, 1.039, 1.6133, 0.9595, 1.6377, 1.4538, 0.8737,
>
>     1.3363, 1.7881, 2.3604, 1.1239, 2.1281, 2.037, 0.5314, 0.7147,
>
>     0.5917, 0.6671, 0.6645, 0.9865, 1.019, 0.9664, 0.6966, 0.679,
>
>     0.7976, 0.8503, 1.2566, 0.5881, 0.8838, 0.6657, 0.7399, 0.5778,
>
>     0.7121, 1.1909), Comp2 = c(0.0284, 0.9064, 0, 0.7053, 0.7695,
>
>     0.337, 1.0418, 0.8346, 0.3884, 1.9946, 1.3296, 0.119, 0.0106,
>
>     0.7872, 1.0174, 0.0704, 0.0854, 0.4259, 0.0395, 0.0549, 2.4471,
>
>     1.8418, 2.9805, 1.1181, 0.5403, 2.7181, 1.4835, 0.875, 2.2205,
>
>     2.4106, 1.1967, 0.303, 0.1129, 2.5432, 2.328, 0.9839, 2.3583,
>
>     1.9589, 1.9918, 1.2232), Comp3 = c(2.9976, 1.6201, 0.7497,
>
>     1.371, 2.7035, 0.4533, 0.9927, 1.0973, 1.6702, 1.3696, 0.3392,
>
>     1.1489, 2.1086, 1.1586, 1.3645, 1.6008, 2.9567, 1.5721, 2.9633,
>
>     2.4623, 0.1103, 0.3137, 0.313, 0.2969, 0.5148, 0.7419, 0.5641,
>
>     0.7871, 0.7362, 0.8754, 0.4883, 0.8504, 1.4582, 0.1934, 0.764,
>
>     0.7515, 0.7143, 0.2139, 0.5743, 1.7305), Comp4 = c(0, 0,
>
>     0.603, 0, 1.6524, 0, 0, 0, 0, 1.1056, 0, 0, 0, 0, 0, 0, 5.7848,
>
>     0, 0, 0, 0, 0, 0, 0, 0, 0.7895, 3.4641, 0, 0, 1.7446, 0,
>
>     0, 1.5165, 0, 5.9645, 4.1878, 0.7313, 5.7994, 3.0168, 0),
>
>     Comp5 = c(18.6058, 5.6489, 12.0842, 4.2708, 3.8489, 10.2139,
>
>     6.1149, 11.3373, 8.9013, 5.8342, 18.532, 17.9267, 8.7386,
>
>     6.9455, 7.3044, 19.0811, 10.8809, 10.7149, 4.7057, 0, 10.3088,
>
>     5.1514, 19.1218, 21.1768, 8.3797, 2.7146, 8.7405, 14.4817,
>
>     8.6571, 17.4254, 17.5725, 5.1233, 13.7539, 6.7396, 2.1342,
>
>     14.4216, 9.2952, 19.9525, 2.2317, 16.501), Gender = structure(c(1L,
>
>     1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
>     1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
>     2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("AP", "C"
>
>     ), class = "factor")), .Names = c("Sample", "Comp1", "Comp2",
>
> "Comp3", "Comp4", "Comp5", "Gender"), class = "data.frame", row.names =
> c("sa1",
>
> "sa2", "sa3", "sa4", "sa5", "sa6", "sa7", "sa8", "sa9", "sa10",
>
> "sa11", "sa12", "sa13", "sa14", "sa15", "sa16", "sa17", "sa18",
>
> "sa19", "sa20", "sa21", "sa22", "sa23", "sa24", "sa25", "sa26",
>
> "sa27", "sa28", "sa29", "sa30", "sa31", "sa32", "sa33", "sa34",
>
> "sa35", "sa36", "sa37", "sa38", "sa39", "sa40"))
>
>
>
>
> Eisenring Michael, Dr.
>
> Federal Department of Economic Affairs, Education and Research
> EAER
> Agroecology and Environment
> Biosafety
>
> Reckenholzstrasse 191, CH-8046 Z?rich
> Tel. +41 58 468 7181
> Fax +41 58 468 7201
> michael.eisenring at agroscope.admin.ch<mailto:michael.
> eisenring at agroscope.admin.ch>
> www.agroscope.ch<http://www.agroscope.ch/>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Sep 18 17:26:23 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 18 Sep 2017 08:26:23 -0700
Subject: [R] help matching rows of a data frame
In-Reply-To: <9153c6$7v8l5n@ironport10.mayo.edu>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
Message-ID: <CAF8bMcaE-OLFKa75QU5cJKW80=jbRYmumVi1Pm5CvaJkS+Cb1g@mail.gmail.com>

You could use merge() with an ID column pasted onto the table of names, as
in

> tbl <- data.frame(FirstName=c("Abe","Abe","Bob","Chuck","Chuck"),
Surname=c("Xavier","Yates","Yates","Yates","Zapf"), Id=paste0("P",101:105))
> tbl
  FirstName Surname   Id
1       Abe  Xavier P101
2       Abe   Yates P102
3       Bob   Yates P103
4     Chuck   Yates P104
5     Chuck    Zapf P105
> merge(data.frame(FirstName=c("Abe","Chuck","Dave"),
Surname=rep("Yates",3)), tbl, all.x=TRUE)
  FirstName Surname   Id
1       Abe   Yates P102
2     Chuck   Yates P104
3      Dave   Yates <NA>


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Sep 18, 2017 at 5:13 AM, Therneau, Terry M., Ph.D. <
therneau at mayo.edu> wrote:

> This question likely has a 1 line answer, I'm just not seeing it.  (2, 3,
> or 10 lines is fine too.)
>
> For a vector I can do group  <- match(x, unqiue(x)) to get a vector that
> labels each element of x.
> What is an equivalent if x is a data frame?
>
> The result does not have to be fast: the data set will have < 100
> elements.  Since this is inside the survival package, and that package is
> on  the 'recommended' list, I can't depend on any package outside the
> recommended list.
>
> Terry T.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Sep 18 17:29:27 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Sep 2017 08:29:27 -0700
Subject: [R] help matching rows of a data frame
In-Reply-To: <9153c6$7v8l5n@ironport10.mayo.edu>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
Message-ID: <F23AF878-414E-41B1-8A88-D1CFF688272A@comcast.net>


> On Sep 18, 2017, at 5:13 AM, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:
> 
> This question likely has a 1 line answer, I'm just not seeing it.  (2, 3, or 10 lines is fine too.)
> 
> For a vector I can do group  <- match(x, unqiue(x)) to get a vector that labels each element of x.
> What is an equivalent if x is a data frame?
> 

In the past I've use apply with past to generate "group" identifiers:


x<-data.frame("X0"=c("A","B","C","C","D","A"), "X1"=c(1,2,1,1,3,1))

apply(x, 1, paste, collapse=".")
[1] "A.1" "B.2" "C.1" "C.1" "D.3" "A.1"


> The result does not have to be fast: the data set will have < 100 elements.  Since this is inside the survival package, and that package is on  the 'recommended' list, I can't depend on any package outside the recommended list.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter.4567 at gmail.com  Mon Sep 18 17:50:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 18 Sep 2017 08:50:58 -0700
Subject: [R] help matching rows of a data frame
In-Reply-To: <F23AF878-414E-41B1-8A88-D1CFF688272A@comcast.net>
References: <9153c6$7v8l5n@ironport10.mayo.edu>
 <F23AF878-414E-41B1-8A88-D1CFF688272A@comcast.net>
Message-ID: <CAGxFJbRgW6yx1JaujR77ovzHHvrCqE5fBp6FuHsp7qjGrKheiA@mail.gmail.com>

Yes. My understanding is that you want the identifier to have the same
number of rows as the data frame. A slight variant of David's solution
would then be:

do.call(paste0,x)


-- Bert



On Mon, Sep 18, 2017 at 8:29 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Sep 18, 2017, at 5:13 AM, Therneau, Terry M., Ph.D. <
> therneau at mayo.edu> wrote:
> >
> > This question likely has a 1 line answer, I'm just not seeing it.  (2,
> 3, or 10 lines is fine too.)
> >
> > For a vector I can do group  <- match(x, unqiue(x)) to get a vector that
> labels each element of x.
> > What is an equivalent if x is a data frame?
> >
>
> In the past I've use apply with past to generate "group" identifiers:
>
>
> x<-data.frame("X0"=c("A","B","C","C","D","A"), "X1"=c(1,2,1,1,3,1))
>
> apply(x, 1, paste, collapse=".")
> [1] "A.1" "B.2" "C.1" "C.1" "D.3" "A.1"
>
>
> > The result does not have to be fast: the data set will have < 100
> elements.  Since this is inside the survival package, and that package is
> on  the 'recommended' list, I can't depend on any package outside the
> recommended list.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Sep 18 17:58:36 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Sep 2017 08:58:36 -0700
Subject: [R] Help/information required
In-Reply-To: <42BA9F35C6F4AB43982A10F9564AF30812F08694@HYD-VMBX-04.gmrgroup.int>
References: <42BA9F35C6F4AB43982A10F9564AF30812F08694@HYD-VMBX-04.gmrgroup.int>
Message-ID: <2CCAC665-8ACD-46D2-BA87-71CC2045EB30@comcast.net>


> On Sep 17, 2017, at 9:24 PM, Ajay Arvind Rao <AjayArvind.Rao at gmrgroup.in> wrote:
> 
> Hi,
> 
> We are using open source license of R to analyze data at our organization. The system configuration are as follows:
> 
> *        System configuration:
> 
> o   Operating System - Windows 7 Enterprise SP1, 64 bit (Desktop)
> 
> o   RAM - 8 GB
> 
> o   Processor - i5-6500 @ 3.2 Ghz
> 
> *        R Version:
> 
> o   R Studio 1.0.136
> 
> o   R 3.4.0
> 
> While trying to merge two datasets we received the following resource error message on running the code
> Code: merg_data <- merge(x=Data_1Junto30Jun,y=flight_code,by.x="EB_FLNO1",by.y="EB_FLNO1",all.x = TRUE)
> Error Message: Error: cannot allocate vector of size 5.8 Gb
> 
> Later we tried running the code differently but error still remained
> Code: merg_data <- sqldf("Select * from Data_1Junto30Jun as a inner join flight_code as b on a.EB_FLNO1=b.EB_FLNO1")
> Error Message: Error: cannot allocate vector of size 200.0 Mb
> 
> We have upgraded the RAM to 8 GB couple of months back. Can you let us know options to resolve the above issue without having to increase the RAM? The size of the datasets are as follows:
> 
> *        Data_1Junto30Jun (513476 obs of 32 variables). Data size - 172033368 bytes / 172 MB
> 
> *        flight_code (478105 obs of 2 variables). Data size - 3836304 bytes / 4 MB
> 
> 
> Help with determining system requirement:
> Is there a way to determine minimum system requirement (hardware and software)

There are some packages for working with data "out of memory". See bigmemory and other "big*" packages. See also the data.table package which has many satisfied users.  There are also several packages for handling data through database connections. That would be probably the preferred method for your use case.

R objects are almost always copied when an assignment is made and this means that you need at a minimum at least twice as much free (and in  _continuous_ chunks) memory. You will often be breaking up the memory with other code and other out-of-R processes. Windows was in the past notorious for having poor memory management. I don't know if Windows 7 continued that tradition or whether later versions might be useful to avoid  the problem.

A dataframe will consume about 10 bytes per row for numeric columns. Factor and character vectors are hashed so the memory consumed will depend on the degree of duplication of entries. That will also affect the merge operations. Merges will give you a Cartesian product so if you merge two dataframes with lots of duplicates you will often get a message such as: "Error: cannot allocate vector of size 5.8 Gb"

The second error you cite suggests that much of your 8Gb of storage has been fragmented.

Most of this information should be available via searching in Rhelp or RSeek.


> depending on size of the data, the way the data is loaded into R (directly from server or in a flat file) and the type of analysis to be run?

No difference for the source of data but cannot comment on the type of analysis because that part of the question is too vague. (Aside from mentioning the issue of Cartesian multiplication of merge results which often trips up new users of database technology.)

> We have not been able to get any specific information related to this and are estimating the requirements through a trial and error method. Any information on this front will be helpful.

This suggests an impoverished ability for searching:

https://stackoverflow.com/search?q=%5Br%5D+memory+limitations

https://stackoverflow.com/search?q=%5Br%5D+memory+limitations+windows

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+memory+limitations+windows

-- 
David.

> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From acefix at rocketmail.com  Mon Sep 18 18:26:54 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Mon, 18 Sep 2017 16:26:54 +0000 (UTC)
Subject: [R] pheatmap: incomplete figure
References: <131866721.1747055.1505752014804.ref@mail.yahoo.com>
Message-ID: <131866721.1747055.1505752014804@mail.yahoo.com>

Dear R Community,
I tried to generate heatmap for a matrix of 1500 columns by 106 rows using the following R script:
> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,border_color=NA)
and got the graph (as attached Fig 1)

Since the column labels appear very crowded, I tried to increase the cellwidth to stretch the graph horizontally. The idea was to show the graph section by section, but with clear/readable column labels (not overlapped labels).
So I typed:
> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,cellwidth=3,cellheight=3,border_color=NA)
However, this time I only got middle part of the original heatmap (as attached Fig 2)
I wonder if there is way I could output the whole graph after such horizontal stretch. If not, how do I get the left end of the graph.
Thank you very much for any inputs!
Kind regards,
Ace
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example-graph.pdf
Type: application/pdf
Size: 132825 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170918/afb293da/attachment.pdf>

From dwinsemius at comcast.net  Mon Sep 18 21:00:21 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Sep 2017 12:00:21 -0700
Subject: [R] pheatmap: incomplete figure
In-Reply-To: <131866721.1747055.1505752014804@mail.yahoo.com>
References: <131866721.1747055.1505752014804.ref@mail.yahoo.com>
 <131866721.1747055.1505752014804@mail.yahoo.com>
Message-ID: <204337BB-AB89-45C2-8831-6B90E6292371@comcast.net>


> On Sep 18, 2017, at 9:26 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Dear R Community,
> I tried to generate heatmap for a matrix of 1500 columns by 106 rows using the following R script:
>> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,border_color=NA)
> and got the graph (as attached Fig 1)
> 
> Since the column labels appear very crowded, I tried to increase the cellwidth to stretch the graph horizontally. The idea was to show the graph section by section, but with clear/readable column labels (not overlapped labels).
> So I typed:
>> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,cellwidth=3,cellheight=3,border_color=NA)
> However, this time I only got middle part of the original heatmap (as attached Fig 2)
> I wonder if there is way I could output the whole graph after such horizontal stretch. If not, how do I get the left end of the graph.
> 

Why not define a graphics device that is wider?

-- 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From eshad002 at gmail.com  Tue Sep 19 09:27:31 2017
From: eshad002 at gmail.com (Eeusha Nafi)
Date: Tue, 19 Sep 2017 09:27:31 +0200
Subject: [R] Extracting Europe from a netCDF file
Message-ID: <CAJJq4LTX54nyqOBeJO0kx6hgW8fpgZtC6N2HYPNYyZtavRcDZg@mail.gmail.com>

Dear ALL,
I was trying to extract the data only for european region from this file
https://www.dropbox.com/s/xpo7zklcmtm3g5r/gfdl_preci.nc?dl=0
using these points (-10.375, 35.125), (43.375, 35.125), (-10.375, 71.375),
(43.375, 71.375). However, I am not sure how I can proceed further.
I have started with the following script:






*f <- "~/gfdl_preci.nc <http://gfdl_preci.nc>"library(raster)pr <-
brick(f)print(pr)pt <-as.data.frame(extract(pr, extent(-10.375, 43.375,
35.125, 71.375)), xy = TRUE)*

I would be grateful if anyone could kindly help me to proceed furhter.

Regards,
Eeusha

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Tue Sep 19 10:09:20 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Tue, 19 Sep 2017 04:09:20 -0400
Subject: [R] Graph f(x) = 1/x
Message-ID: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>

Dear All: good morning

I am trying to graph the function y=f(x)=1/x over the interval (-5,5). But
I am getting an error message. Please see below.

I am getting the error message: *Error in xy.coords(x, y, xlabel, ylabel,
log) : *
*  'x' and 'y' lengths differ*


x

x <- seq(-5, 5, 0.01)
y < 1/x

plot(x,y, type='l', xlim=c(-5, 5), ylim=c(-5, 5), xlab = "x", ylab = "f(x)
= 1/x", lwd = 2, col ="red")

abline(h=0, lty=2, col = "blue")
abline(v=0, lty=2, col = "blue")
axis(1)
axis(2)
title(main="The Graph of f(x) = 1/x")


any help will be highly appreciated.


with thanks
abou
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Tue Sep 19 10:13:52 2017
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 19 Sep 2017 10:13:52 +0200 (CEST)
Subject: [R] Graph f(x) = 1/x
In-Reply-To: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>
References: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1709191012420.2652@paninaro>



On Tue, 19 Sep 2017, AbouEl-Makarim Aboueissa wrote:

> Dear All: good morning
>
> I am trying to graph the function y=f(x)=1/x over the interval (-5,5). But
> I am getting an error message. Please see below.
>
> I am getting the error message: *Error in xy.coords(x, y, xlabel, ylabel,
> log) : *
> *  'x' and 'y' lengths differ*

You have "y < 1/x" rather than "y <- 1/x"! So "y" is not assigned and 
presumably you have some old "y" variable in your global environment that 
is used and does not match the length of "x".

>
> x
>
> x <- seq(-5, 5, 0.01)
> y < 1/x
>
> plot(x,y, type='l', xlim=c(-5, 5), ylim=c(-5, 5), xlab = "x", ylab = "f(x)
> = 1/x", lwd = 2, col ="red")
>
> abline(h=0, lty=2, col = "blue")
> abline(v=0, lty=2, col = "blue")
> axis(1)
> axis(2)
> title(main="The Graph of f(x) = 1/x")
>
>
> any help will be highly appreciated.
>
>
> with thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From abouelmakarim1962 at gmail.com  Tue Sep 19 10:19:34 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Tue, 19 Sep 2017 04:19:34 -0400
Subject: [R] Graph f(x) = 1/x
In-Reply-To: <alpine.DEB.2.20.1709191012420.2652@paninaro>
References: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>
 <alpine.DEB.2.20.1709191012420.2652@paninaro>
Message-ID: <CAE9stmdZe+dYJ5gD8fmniD0ZmTjbVvoJzovjYsE14ovUy50TUw@mail.gmail.com>

Dear Zeileis:

Thank you very much

abou

On Tue, Sep 19, 2017 at 4:13 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

>
>
> On Tue, 19 Sep 2017, AbouEl-Makarim Aboueissa wrote:
>
> Dear All: good morning
>>
>> I am trying to graph the function y=f(x)=1/x over the interval (-5,5). But
>> I am getting an error message. Please see below.
>>
>> I am getting the error message: *Error in xy.coords(x, y, xlabel, ylabel,
>> log) : *
>> *  'x' and 'y' lengths differ*
>>
>
> You have "y < 1/x" rather than "y <- 1/x"! So "y" is not assigned and
> presumably you have some old "y" variable in your global environment that
> is used and does not match the length of "x".
>
>
>> x
>>
>> x <- seq(-5, 5, 0.01)
>> y < 1/x
>>
>> plot(x,y, type='l', xlim=c(-5, 5), ylim=c(-5, 5), xlab = "x", ylab = "f(x)
>> = 1/x", lwd = 2, col ="red")
>>
>> abline(h=0, lty=2, col = "blue")
>> abline(v=0, lty=2, col = "blue")
>> axis(1)
>> axis(2)
>> title(main="The Graph of f(x) = 1/x")
>>
>>
>> any help will be highly appreciated.
>>
>>
>> with thanks
>> abou
>> ______________________
>> AbouEl-Makarim Aboueissa, PhD
>> Professor of Statistics
>> Department of Mathematics and Statistics
>> University of Southern Maine
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Tue Sep 19 10:24:28 2017
From: calandra at rgzm.de (Ivan Calandra)
Date: Tue, 19 Sep 2017 10:24:28 +0200
Subject: [R] Graph f(x) = 1/x
In-Reply-To: <CAE9stmdZe+dYJ5gD8fmniD0ZmTjbVvoJzovjYsE14ovUy50TUw@mail.gmail.com>
References: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>
 <alpine.DEB.2.20.1709191012420.2652@paninaro>
 <CAE9stmdZe+dYJ5gD8fmniD0ZmTjbVvoJzovjYsE14ovUy50TUw@mail.gmail.com>
Message-ID: <f1d23f98-8e91-5241-3183-e8e85c825c6e@rgzm.de>

It's always good to start a new session when you don't understand what's 
wrong, because sometimes your code is correct, but you use old data 
without knowing it :)

Ivan

--
Dr. Ivan Calandra
TraCEr, Laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 19/09/2017 10:19, AbouEl-Makarim Aboueissa wrote:
> Dear Zeileis:
>
> Thank you very much
>
> abou
>
> On Tue, Sep 19, 2017 at 4:13 AM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
> wrote:
>
>>
>> On Tue, 19 Sep 2017, AbouEl-Makarim Aboueissa wrote:
>>
>> Dear All: good morning
>>> I am trying to graph the function y=f(x)=1/x over the interval (-5,5). But
>>> I am getting an error message. Please see below.
>>>
>>> I am getting the error message: *Error in xy.coords(x, y, xlabel, ylabel,
>>> log) : *
>>> *  'x' and 'y' lengths differ*
>>>
>> You have "y < 1/x" rather than "y <- 1/x"! So "y" is not assigned and
>> presumably you have some old "y" variable in your global environment that
>> is used and does not match the length of "x".
>>
>>
>>> x
>>>
>>> x <- seq(-5, 5, 0.01)
>>> y < 1/x
>>>
>>> plot(x,y, type='l', xlim=c(-5, 5), ylim=c(-5, 5), xlab = "x", ylab = "f(x)
>>> = 1/x", lwd = 2, col ="red")
>>>
>>> abline(h=0, lty=2, col = "blue")
>>> abline(v=0, lty=2, col = "blue")
>>> axis(1)
>>> axis(2)
>>> title(main="The Graph of f(x) = 1/x")
>>>
>>>
>>> any help will be highly appreciated.
>>>
>>>
>>> with thanks
>>> abou
>>> ______________________
>>> AbouEl-Makarim Aboueissa, PhD
>>> Professor of Statistics
>>> Department of Mathematics and Statistics
>>> University of Southern Maine
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>


From viveksutra at gmail.com  Tue Sep 19 11:37:33 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Tue, 19 Sep 2017 11:37:33 +0200
Subject: [R] symbolic computing example with Ryacas
Message-ID: <CAHLp6SDKVT3StPA_7Lt-0hROg6i0yW_CFrpqMDTmd9iDiX4jSg@mail.gmail.com>

Hi all,
I am trying to implement the following matlab code with Ryacas :

syms U x x0 C

d1=diff(U/(1+exp(-(x-x0)/C)),x);

pretty(d1)

d2=diff(U/(1+exp(-(x-x0)/C)),x,2);

pretty(d2)

solx2 = solve(d2 == 0, x, 'Real', true)

pretty(solx2)

slope2=subs(d1,solx2)


I have tried the following :

library(Ryacas)

x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")

my_func <- function(x,U,x0,C) {

  return (U/(1+exp(-(x-x0)/C)))}

FirstDeriv <- deriv(my_func(x,U,x0,C), x)

PrettyForm(FirstDeriv)

slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")

PrettyForm(slope)


I don't understand how I should use the Subst command. I want the slope of
the first derivative at x=x0. How do I implement that?

I would appreciate any help that I can get.

Thanks,

Vivek

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Sep 19 11:59:41 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Tue, 19 Sep 2017 10:59:41 +0100
Subject: [R] Graph f(x) = 1/x
In-Reply-To: <CAE9stmefqCPosy1Jik5=JRgY1M2dhHKucG93x7VgBc5oXSk14g@mail.gmail.com>
Message-ID: <20170919105941.Horde.fnyUxVHOGvTWoFyMxJot85n@mail.sapo.pt>

Hello,

I believe that the easiest way is

curve(1/x, -5, 5)

Also, you're missing a '-' in y < 1/x, it should be y <- 1/x

Hope this helps,

Rui Barradas



Citando AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com>:

> Dear All: good morning
>
> I am trying to graph the function y=f(x)=1/x over the interval (-5,5). But
> I am getting an error message. Please see below.
>
> I am getting the error message: *Error in xy.coords(x, y, xlabel, ylabel,
> log) : *
> *  'x' and 'y' lengths differ*
>
>
> x
>
> x <- seq(-5, 5, 0.01)
> y < 1/x
>
> plot(x,y, type='l', xlim=c(-5, 5), ylim=c(-5, 5), xlab = "x", ylab = "f(x)
> = 1/x", lwd = 2, col ="red")
>
> abline(h=0, lty=2, col = "blue")
> abline(v=0, lty=2, col = "blue")
> axis(1)
> axis(2)
> title(main="The Graph of f(x) = 1/x")
>
>
> any help will be highly appreciated.
>
>
> with thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Tue Sep 19 15:47:08 2017
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 19 Sep 2017 09:47:08 -0400
Subject: [R] remove quotes from matrix
Message-ID: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>

Hi all;

I have data at 734*22 dimensions with rows and columns names are
non-numeric.When I convert this data into matrix then all values show up
with quotes. Then when I use
x1= noquotes(x) to remove the quotes from the matrix then non-numeric row
names remain all other values in matrix disappear.

Your help is greatly appreciated.

Greg

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 19 16:04:22 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Sep 2017 07:04:22 -0700
Subject: [R] symbolic computing example with Ryacas
In-Reply-To: <CAHLp6SDKVT3StPA_7Lt-0hROg6i0yW_CFrpqMDTmd9iDiX4jSg@mail.gmail.com>
References: <CAHLp6SDKVT3StPA_7Lt-0hROg6i0yW_CFrpqMDTmd9iDiX4jSg@mail.gmail.com>
Message-ID: <CAGxFJbT_x3GRL8GE28NBGjfSV_pWvw5KE+bBQmXxH9Et1X2n1w@mail.gmail.com>

Have you studied the "Introduction to Ryacas" vignette that come with the
package?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 19, 2017 at 2:37 AM, Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi all,
> I am trying to implement the following matlab code with Ryacas :
>
> syms U x x0 C
>
> d1=diff(U/(1+exp(-(x-x0)/C)),x);
>
> pretty(d1)
>
> d2=diff(U/(1+exp(-(x-x0)/C)),x,2);
>
> pretty(d2)
>
> solx2 = solve(d2 == 0, x, 'Real', true)
>
> pretty(solx2)
>
> slope2=subs(d1,solx2)
>
>
> I have tried the following :
>
> library(Ryacas)
>
> x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")
>
> my_func <- function(x,U,x0,C) {
>
>   return (U/(1+exp(-(x-x0)/C)))}
>
> FirstDeriv <- deriv(my_func(x,U,x0,C), x)
>
> PrettyForm(FirstDeriv)
>
> slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")
>
> PrettyForm(slope)
>
>
> I don't understand how I should use the Subst command. I want the slope of
> the first derivative at x=x0. How do I implement that?
>
> I would appreciate any help that I can get.
>
> Thanks,
>
> Vivek
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Sep 19 16:04:47 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Sep 2017 10:04:47 -0400
Subject: [R] remove quotes from matrix
In-Reply-To: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
Message-ID: <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>

On 19/09/2017 9:47 AM, greg holly wrote:
> Hi all;
> 
> I have data at 734*22 dimensions with rows and columns names are
> non-numeric.When I convert this data into matrix then all values show up
> with quotes. Then when I use
> x1= noquotes(x) to remove the quotes from the matrix then non-numeric row
> names remain all other values in matrix disappear.
> 
> Your help is greatly appreciated.
> 


Matrices in R can have only one type.  If you start with a dataframe and 
any columns contain character data, all entries will be converted to 
character, and the matrix will be displayed with quotes.

When you say all values disappear, it sounds as though you are 
displaying strings containing nothing (or just blanks).  Those will be 
displayed as "" normally, but if the matrix is marked to display without 
quotes, they are displayed as empty strings, so it will appear that 
nothing is displayed.

You can see the structure of the original data using the str() function, 
e.g. str(x) should display types for each column.

If this isn't enough to explain what's going on, please show us more 
detail.  For example, show us the result of

y <- x[1:5, 1:5]
dput(y)

both before and after converting x to a matrix.

Duncan Murdoch


From mak.hholly at gmail.com  Tue Sep 19 16:49:12 2017
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 19 Sep 2017 10:49:12 -0400
Subject: [R] remove quotes from matrix
In-Reply-To: <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
Message-ID: <CAM9Qe4ikb9DWfsJbdbojHD9NxuXOv7e=CMWmQUrr5G=Q8qNnpg@mail.gmail.com>

Hi Duncan and Bert;

I do appreciate for your replies. I just figured out that after x1=
noquotes(x) commend my 733*22 matrix returns into n*1 vector. Is there way
to keep this as matrix with the dimension of 733*22?

Regards,

Greg


On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/09/2017 9:47 AM, greg holly wrote:
>
>> Hi all;
>>
>> I have data at 734*22 dimensions with rows and columns names are
>> non-numeric.When I convert this data into matrix then all values show up
>> with quotes. Then when I use
>> x1= noquotes(x) to remove the quotes from the matrix then non-numeric row
>> names remain all other values in matrix disappear.
>>
>> Your help is greatly appreciated.
>>
>>
>
> Matrices in R can have only one type.  If you start with a dataframe and
> any columns contain character data, all entries will be converted to
> character, and the matrix will be displayed with quotes.
>
> When you say all values disappear, it sounds as though you are displaying
> strings containing nothing (or just blanks).  Those will be displayed as ""
> normally, but if the matrix is marked to display without quotes, they are
> displayed as empty strings, so it will appear that nothing is displayed.
>
> You can see the structure of the original data using the str() function,
> e.g. str(x) should display types for each column.
>
> If this isn't enough to explain what's going on, please show us more
> detail.  For example, show us the result of
>
> y <- x[1:5, 1:5]
> dput(y)
>
> both before and after converting x to a matrix.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Sep 19 17:11:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 19 Sep 2017 08:11:10 -0700
Subject: [R] remove quotes from matrix
In-Reply-To: <CAM9Qe4ikb9DWfsJbdbojHD9NxuXOv7e=CMWmQUrr5G=Q8qNnpg@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
 <CAM9Qe4ikb9DWfsJbdbojHD9NxuXOv7e=CMWmQUrr5G=Q8qNnpg@mail.gmail.com>
Message-ID: <86725979-8A41-4F58-BD9B-98C1674AB446@dcn.davis.ca.us>

Greg, I think you should stop using noquote, because it is doing something that will not be useful to you for preparing your data for analysis.

Please follow Duncan's advice and provide us with a sample of your data.  Also, please set your email program to send plain text rather than HTML formatted text. 
-- 
Sent from my phone. Please excuse my brevity.

On September 19, 2017 7:49:12 AM PDT, greg holly <mak.hholly at gmail.com> wrote:
>Hi Duncan and Bert;
>
>I do appreciate for your replies. I just figured out that after x1=
>noquotes(x) commend my 733*22 matrix returns into n*1 vector. Is there
>way
>to keep this as matrix with the dimension of 733*22?
>
>Regards,
>
>Greg
>
>
>On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 19/09/2017 9:47 AM, greg holly wrote:
>>
>>> Hi all;
>>>
>>> I have data at 734*22 dimensions with rows and columns names are
>>> non-numeric.When I convert this data into matrix then all values
>show up
>>> with quotes. Then when I use
>>> x1= noquotes(x) to remove the quotes from the matrix then
>non-numeric row
>>> names remain all other values in matrix disappear.
>>>
>>> Your help is greatly appreciated.
>>>
>>>
>>
>> Matrices in R can have only one type.  If you start with a dataframe
>and
>> any columns contain character data, all entries will be converted to
>> character, and the matrix will be displayed with quotes.
>>
>> When you say all values disappear, it sounds as though you are
>displaying
>> strings containing nothing (or just blanks).  Those will be displayed
>as ""
>> normally, but if the matrix is marked to display without quotes, they
>are
>> displayed as empty strings, so it will appear that nothing is
>displayed.
>>
>> You can see the structure of the original data using the str()
>function,
>> e.g. str(x) should display types for each column.
>>
>> If this isn't enough to explain what's going on, please show us more
>> detail.  For example, show us the result of
>>
>> y <- x[1:5, 1:5]
>> dput(y)
>>
>> both before and after converting x to a matrix.
>>
>> Duncan Murdoch
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Sep 19 17:20:20 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Sep 2017 08:20:20 -0700
Subject: [R] remove quotes from matrix
In-Reply-To: <CAM9Qe4ikb9DWfsJbdbojHD9NxuXOv7e=CMWmQUrr5G=Q8qNnpg@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
 <CAM9Qe4ikb9DWfsJbdbojHD9NxuXOv7e=CMWmQUrr5G=Q8qNnpg@mail.gmail.com>
Message-ID: <CAGxFJbRXaQ_5MZX+tKVm8ZEQoUnzg2XWE5Mct=VcwfT4=kSO1A@mail.gmail.com>

Your  claims are false -- or at least confused.

> d <- data.frame(a = I(letters[1:3]), b = 1:3)
## the I() is to prevent automatic conversion to factor

> d
  a b
1 a 1
2 b 2
3 c 3
> dm <- as.matrix(d)
> dm
     a   b
[1,] "a" "1"
[2,] "b" "2"
[3,] "c" "3"
> dimnames(dm)
[[1]]
NULL

[[2]]
[1] "a" "b"

## Note that there are no rownames, as d had none.
> dm <- noquote(dm)
> dm
     a b
[1,] a 1
[2,] b 2
[3,] c 3

We still need a reprex to resolve the confusion.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 19, 2017 at 7:49 AM, greg holly <mak.hholly at gmail.com> wrote:

> Hi Duncan and Bert;
>
> I do appreciate for your replies. I just figured out that after x1=
> noquotes(x) commend my 733*22 matrix returns into n*1 vector. Is there way
> to keep this as matrix with the dimension of 733*22?
>
> Regards,
>
> Greg
>
>
> On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <murdoch.duncan at gmail.com
> >
> wrote:
>
> > On 19/09/2017 9:47 AM, greg holly wrote:
> >
> >> Hi all;
> >>
> >> I have data at 734*22 dimensions with rows and columns names are
> >> non-numeric.When I convert this data into matrix then all values show up
> >> with quotes. Then when I use
> >> x1= noquotes(x) to remove the quotes from the matrix then non-numeric
> row
> >> names remain all other values in matrix disappear.
> >>
> >> Your help is greatly appreciated.
> >>
> >>
> >
> > Matrices in R can have only one type.  If you start with a dataframe and
> > any columns contain character data, all entries will be converted to
> > character, and the matrix will be displayed with quotes.
> >
> > When you say all values disappear, it sounds as though you are displaying
> > strings containing nothing (or just blanks).  Those will be displayed as
> ""
> > normally, but if the matrix is marked to display without quotes, they are
> > displayed as empty strings, so it will appear that nothing is displayed.
> >
> > You can see the structure of the original data using the str() function,
> > e.g. str(x) should display types for each column.
> >
> > If this isn't enough to explain what's going on, please show us more
> > detail.  For example, show us the result of
> >
> > y <- x[1:5, 1:5]
> > dput(y)
> >
> > both before and after converting x to a matrix.
> >
> > Duncan Murdoch
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mak.hholly at gmail.com  Tue Sep 19 17:20:40 2017
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 19 Sep 2017 11:20:40 -0400
Subject: [R] remove quotes from matrix
In-Reply-To: <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
Message-ID: <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>

Dear all;

Thanks. Here are the dput results as Duncan suggested.

Regards,

Greg

structure(list(Sub_Pathways = structure(c(3L, 3L, 3L, 3L, 3L), .Label =
c("Acetylated_Peptides",
"Advanced_Glycation_End-product", "Alanine_and_Aspartate", "Aminosugar",
"Ascorbate_and_Aldarate", "Carnitine", "Ceramides", "Creatine",
"Diacylglycerol", "Dipeptide", "Dipeptide_Derivative",
"Disaccharides_and_Oligosaccharides",
"Eicosanoid", "Endocannabinoid", "Fatty_Acid(Acyl_Carnitine)",
"Fatty_Acid(Acyl_Glycine)", "Fatty_Acid,_Amino", "Fatty_Acid,_Branched",
"Fatty_Acid,_Dicarboxylate", "Fatty_Acid,_Dihydroxy",
"Fatty_Acid,_Monohydroxy",
"Fatty_Acid_(Acyl_Choline)", "Fatty_Acid_(Acyl_Glutamine)",
"Fatty_Acid_(also_BCAA)",
"Fatty_Acid_Synthesis", "Fibrinogen_Cleavage_Peptide",
"Fructose,_Mannose_and_Galactose",
"Gamma-glutamyl_Amino_Acid", "Glutamate", "Glutathione", "Glycerolipid",
"Glycine,_Serine_and_Threonine", "Glycogen",
"Glycolysis,_Gluconeogenesis,_and_Pyruvate",
"Guanidino_and_Acetamido", "Hemoglobin_and_Porphyrin", "Histidine",
"Inositol", "Ketone_Bodies", "Leucine,_Isoleucine_and_Valine",
"Long_Chain_Fatty_Acid", "Lysine", "Lyso-phospho-ether", "Lysolipid",
"Lysoplasmalogen", "Medium_Chain_Fatty_Acid",
"Methionine,_Cysteine,_SAM_and_Taurine",
"Mevalonate", "Monoacylglycerol", "Nicotinate_and_Nicotinamide",
"Oxidative_Phosphorylation", "Pantothenate_and_CoA", "Pentose",
"Phenylalanine_and_Tyrosine", "Phospholipid", "Plasmalogen",
"Polyamine", "Polypeptide", "Polyunsaturated_Fatty_Acid_(n3_and_n6)",
"Primary_Bile_Acid", "Purine,_(Hypo)Xanthine/Inosine_containing",
"Purine,_Adenine_containing", "Purine,_Guanine_containing",
"Pyrimidine,_Cytidine_containing",
"Pyrimidine,_Orotate_containing", "Pyrimidine,_Thymine_containing",
"Pyrimidine,_Uracil_containing", "Riboflavin", "Secondary_Bile_Acid",
"Short_Chain_Fatty_Acid", "Sphingolipid", "Steroid", "Sterol",
"TCA_Cycle", "Tocopherol", "Tryptophan",
"Urea_cycle;_Arginine_and_Proline",
"Vitamin_A", "Vitamin_B6"), class = "factor"), BMI_beta = c(0.2382,
-0.313, 0.1238, 0.3035, -0.00982), SAT_beta = c(-0.02409, -1.9751,
0.4095, 0.4861, 0.3293), VAT_beta = c(0.9418, -2.2204, 0.6805,
0.7083, 0.01597), VSR_beta = c(0.2469, -0.2354, 0.05539, 0.01337,
-0.04353)), .Names = c("Sub_Pathways", "BMI_beta", "SAT_beta",
"VAT_beta", "VSR_beta"), row.names = c(NA, 5L), class = "data.frame")

On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/09/2017 9:47 AM, greg holly wrote:
>
>> Hi all;
>>
>> I have data at 734*22 dimensions with rows and columns names are
>> non-numeric.When I convert this data into matrix then all values show up
>> with quotes. Then when I use
>> x1= noquotes(x) to remove the quotes from the matrix then non-numeric row
>> names remain all other values in matrix disappear.
>>
>> Your help is greatly appreciated.
>>
>>
>
> Matrices in R can have only one type.  If you start with a dataframe and
> any columns contain character data, all entries will be converted to
> character, and the matrix will be displayed with quotes.
>
> When you say all values disappear, it sounds as though you are displaying
> strings containing nothing (or just blanks).  Those will be displayed as ""
> normally, but if the matrix is marked to display without quotes, they are
> displayed as empty strings, so it will appear that nothing is displayed.
>
> You can see the structure of the original data using the str() function,
> e.g. str(x) should display types for each column.
>
> If this isn't enough to explain what's going on, please show us more
> detail.  For example, show us the result of
>
> y <- x[1:5, 1:5]
> dput(y)
>
> both before and after converting x to a matrix.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 19 17:32:19 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 19 Sep 2017 08:32:19 -0700
Subject: [R] remove quotes from matrix
In-Reply-To: <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
 <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>
Message-ID: <CAGxFJbRVLYTXaVQtcBv7gZ9-p-sTAKSyuLDQsu8JxcuMq=dpCg@mail.gmail.com>

Works fine for me. What do you object to in the following?

Calling the above df "d",

> dm <- as.matrix(d)
> dm
  Sub_Pathways            BMI_beta   SAT_beta   VAT_beta
1 "Alanine_and_Aspartate" " 0.23820" "-0.02409" " 0.94180"
2 "Alanine_and_Aspartate" "-0.31300" "-1.97510" "-2.22040"
3 "Alanine_and_Aspartate" " 0.12380" " 0.40950" " 0.68050"
4 "Alanine_and_Aspartate" " 0.30350" " 0.48610" " 0.70830"
5 "Alanine_and_Aspartate" "-0.00982" " 0.32930" " 0.01597"
  VSR_beta
1 " 0.24690"
2 "-0.23540"
3 " 0.05539"
4 " 0.01337"
5 "-0.04353"
> dimnames(dm)
[[1]]
[1] "1" "2" "3" "4" "5"

[[2]]
[1] "Sub_Pathways" "BMI_beta"     "SAT_beta"     "VAT_beta"
[5] "VSR_beta"

> dm <- noquote(dm)
> dm
  Sub_Pathways          BMI_beta SAT_beta VAT_beta VSR_beta
1 Alanine_and_Aspartate  0.23820 -0.02409  0.94180  0.24690
2 Alanine_and_Aspartate -0.31300 -1.97510 -2.22040 -0.23540
3 Alanine_and_Aspartate  0.12380  0.40950  0.68050  0.05539
4 Alanine_and_Aspartate  0.30350  0.48610  0.70830  0.01337
5 Alanine_and_Aspartate -0.00982  0.32930  0.01597 -0.04353
> dimnames(dm)
[[1]]
[1] "1" "2" "3" "4" "5"

[[2]]
[1] "Sub_Pathways" "BMI_beta"     "SAT_beta"     "VAT_beta"
[5] "VSR_beta"


Perhaps you need to read ?noquote or ?matrix.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Sep 19, 2017 at 8:20 AM, greg holly <mak.hholly at gmail.com> wrote:

> Dear all;
>
> Thanks. Here are the dput results as Duncan suggested.
>
> Regards,
>
> Greg
>
> structure(list(Sub_Pathways = structure(c(3L, 3L, 3L, 3L, 3L), .Label =
> c("Acetylated_Peptides",
> "Advanced_Glycation_End-product", "Alanine_and_Aspartate", "Aminosugar",
> "Ascorbate_and_Aldarate", "Carnitine", "Ceramides", "Creatine",
> "Diacylglycerol", "Dipeptide", "Dipeptide_Derivative",
> "Disaccharides_and_Oligosaccharides",
> "Eicosanoid", "Endocannabinoid", "Fatty_Acid(Acyl_Carnitine)",
> "Fatty_Acid(Acyl_Glycine)", "Fatty_Acid,_Amino", "Fatty_Acid,_Branched",
> "Fatty_Acid,_Dicarboxylate", "Fatty_Acid,_Dihydroxy",
> "Fatty_Acid,_Monohydroxy",
> "Fatty_Acid_(Acyl_Choline)", "Fatty_Acid_(Acyl_Glutamine)",
> "Fatty_Acid_(also_BCAA)",
> "Fatty_Acid_Synthesis", "Fibrinogen_Cleavage_Peptide",
> "Fructose,_Mannose_and_Galactose",
> "Gamma-glutamyl_Amino_Acid", "Glutamate", "Glutathione", "Glycerolipid",
> "Glycine,_Serine_and_Threonine", "Glycogen",
> "Glycolysis,_Gluconeogenesis,_and_Pyruvate",
> "Guanidino_and_Acetamido", "Hemoglobin_and_Porphyrin", "Histidine",
> "Inositol", "Ketone_Bodies", "Leucine,_Isoleucine_and_Valine",
> "Long_Chain_Fatty_Acid", "Lysine", "Lyso-phospho-ether", "Lysolipid",
> "Lysoplasmalogen", "Medium_Chain_Fatty_Acid",
> "Methionine,_Cysteine,_SAM_and_Taurine",
> "Mevalonate", "Monoacylglycerol", "Nicotinate_and_Nicotinamide",
> "Oxidative_Phosphorylation", "Pantothenate_and_CoA", "Pentose",
> "Phenylalanine_and_Tyrosine", "Phospholipid", "Plasmalogen",
> "Polyamine", "Polypeptide", "Polyunsaturated_Fatty_Acid_(n3_and_n6)",
> "Primary_Bile_Acid", "Purine,_(Hypo)Xanthine/Inosine_containing",
> "Purine,_Adenine_containing", "Purine,_Guanine_containing",
> "Pyrimidine,_Cytidine_containing",
> "Pyrimidine,_Orotate_containing", "Pyrimidine,_Thymine_containing",
> "Pyrimidine,_Uracil_containing", "Riboflavin", "Secondary_Bile_Acid",
> "Short_Chain_Fatty_Acid", "Sphingolipid", "Steroid", "Sterol",
> "TCA_Cycle", "Tocopherol", "Tryptophan",
> "Urea_cycle;_Arginine_and_Proline",
> "Vitamin_A", "Vitamin_B6"), class = "factor"), BMI_beta = c(0.2382,
> -0.313, 0.1238, 0.3035, -0.00982), SAT_beta = c(-0.02409, -1.9751,
> 0.4095, 0.4861, 0.3293), VAT_beta = c(0.9418, -2.2204, 0.6805,
> 0.7083, 0.01597), VSR_beta = c(0.2469, -0.2354, 0.05539, 0.01337,
> -0.04353)), .Names = c("Sub_Pathways", "BMI_beta", "SAT_beta",
> "VAT_beta", "VSR_beta"), row.names = c(NA, 5L), class = "data.frame")
>
> On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <murdoch.duncan at gmail.com
> >
> wrote:
>
> > On 19/09/2017 9:47 AM, greg holly wrote:
> >
> >> Hi all;
> >>
> >> I have data at 734*22 dimensions with rows and columns names are
> >> non-numeric.When I convert this data into matrix then all values show up
> >> with quotes. Then when I use
> >> x1= noquotes(x) to remove the quotes from the matrix then non-numeric
> row
> >> names remain all other values in matrix disappear.
> >>
> >> Your help is greatly appreciated.
> >>
> >>
> >
> > Matrices in R can have only one type.  If you start with a dataframe and
> > any columns contain character data, all entries will be converted to
> > character, and the matrix will be displayed with quotes.
> >
> > When you say all values disappear, it sounds as though you are displaying
> > strings containing nothing (or just blanks).  Those will be displayed as
> ""
> > normally, but if the matrix is marked to display without quotes, they are
> > displayed as empty strings, so it will appear that nothing is displayed.
> >
> > You can see the structure of the original data using the str() function,
> > e.g. str(x) should display types for each column.
> >
> > If this isn't enough to explain what's going on, please show us more
> > detail.  For example, show us the result of
> >
> > y <- x[1:5, 1:5]
> > dput(y)
> >
> > both before and after converting x to a matrix.
> >
> > Duncan Murdoch
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Sep 19 17:38:13 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 19 Sep 2017 15:38:13 +0000
Subject: [R] remove quotes from matrix
In-Reply-To: <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
 <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>
Message-ID: <089ead4b02f44f9db46496d71ed1d815@exch-2p-mbx-w2.ads.tamu.edu>

Your description was confusing. You do not have row names that are non-numeric:

> str(dta)
'data.frame':   5 obs. of  5 variables:
 $ Sub_Pathways: Factor w/ 79 levels "Acetylated_Peptides",..: 3 3 3 3 3
 $ BMI_beta    : num  0.2382 -0.313 0.1238 0.3035 -0.00982
 $ SAT_beta    : num  -0.0241 -1.9751 0.4095 0.4861 0.3293
 $ VAT_beta    : num  0.942 -2.22 0.68 0.708 0.016
 $ VSR_beta    : num  0.2469 -0.2354 0.0554 0.0134 -0.0435

You have a column that is a factor with 79 levels. That cannot be row names because you indicated that the original data was 734*22 dimensions and row names cannot have duplications. If you want numeric values, you need to strip off the first column:

> as.matrix(dta[ , -1])
  BMI_beta SAT_beta VAT_beta VSR_beta
1  0.23820 -0.02409  0.94180  0.24690
2 -0.31300 -1.97510 -2.22040 -0.23540
3  0.12380  0.40950  0.68050  0.05539
4  0.30350  0.48610  0.70830  0.01337
5 -0.00982  0.32930  0.01597 -0.04353

If you just want to print the character values without quotes:

> print(as.matrix(dta), quote=FALSE)
  Sub_Pathways          BMI_beta SAT_beta VAT_beta VSR_beta
1 Alanine_and_Aspartate  0.23820 -0.02409  0.94180  0.24690
2 Alanine_and_Aspartate -0.31300 -1.97510 -2.22040 -0.23540
3 Alanine_and_Aspartate  0.12380  0.40950  0.68050  0.05539
4 Alanine_and_Aspartate  0.30350  0.48610  0.70830  0.01337
5 Alanine_and_Aspartate -0.00982  0.32930  0.01597 -0.04353

But do not forget that they are still character strings.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of greg holly
Sent: Tuesday, September 19, 2017 10:21 AM
To: Duncan Murdoch <murdoch.duncan at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] remove quotes from matrix

Dear all;

Thanks. Here are the dput results as Duncan suggested.

Regards,

Greg

structure(list(Sub_Pathways = structure(c(3L, 3L, 3L, 3L, 3L), .Label = c("Acetylated_Peptides", "Advanced_Glycation_End-product", "Alanine_and_Aspartate", "Aminosugar", "Ascorbate_and_Aldarate", "Carnitine", "Ceramides", "Creatine", "Diacylglycerol", "Dipeptide", "Dipeptide_Derivative", "Disaccharides_and_Oligosaccharides",
"Eicosanoid", "Endocannabinoid", "Fatty_Acid(Acyl_Carnitine)", "Fatty_Acid(Acyl_Glycine)", "Fatty_Acid,_Amino", "Fatty_Acid,_Branched", "Fatty_Acid,_Dicarboxylate", "Fatty_Acid,_Dihydroxy", "Fatty_Acid,_Monohydroxy", "Fatty_Acid_(Acyl_Choline)", "Fatty_Acid_(Acyl_Glutamine)", "Fatty_Acid_(also_BCAA)", "Fatty_Acid_Synthesis", "Fibrinogen_Cleavage_Peptide", "Fructose,_Mannose_and_Galactose",
"Gamma-glutamyl_Amino_Acid", "Glutamate", "Glutathione", "Glycerolipid", "Glycine,_Serine_and_Threonine", "Glycogen", "Glycolysis,_Gluconeogenesis,_and_Pyruvate",
"Guanidino_and_Acetamido", "Hemoglobin_and_Porphyrin", "Histidine", "Inositol", "Ketone_Bodies", "Leucine,_Isoleucine_and_Valine", "Long_Chain_Fatty_Acid", "Lysine", "Lyso-phospho-ether", "Lysolipid", "Lysoplasmalogen", "Medium_Chain_Fatty_Acid", "Methionine,_Cysteine,_SAM_and_Taurine",
"Mevalonate", "Monoacylglycerol", "Nicotinate_and_Nicotinamide", "Oxidative_Phosphorylation", "Pantothenate_and_CoA", "Pentose", "Phenylalanine_and_Tyrosine", "Phospholipid", "Plasmalogen", "Polyamine", "Polypeptide", "Polyunsaturated_Fatty_Acid_(n3_and_n6)",
"Primary_Bile_Acid", "Purine,_(Hypo)Xanthine/Inosine_containing",
"Purine,_Adenine_containing", "Purine,_Guanine_containing", "Pyrimidine,_Cytidine_containing",
"Pyrimidine,_Orotate_containing", "Pyrimidine,_Thymine_containing", "Pyrimidine,_Uracil_containing", "Riboflavin", "Secondary_Bile_Acid", "Short_Chain_Fatty_Acid", "Sphingolipid", "Steroid", "Sterol", "TCA_Cycle", "Tocopherol", "Tryptophan", "Urea_cycle;_Arginine_and_Proline",
"Vitamin_A", "Vitamin_B6"), class = "factor"), BMI_beta = c(0.2382, -0.313, 0.1238, 0.3035, -0.00982), SAT_beta = c(-0.02409, -1.9751, 0.4095, 0.4861, 0.3293), VAT_beta = c(0.9418, -2.2204, 0.6805, 0.7083, 0.01597), VSR_beta = c(0.2469, -0.2354, 0.05539, 0.01337, -0.04353)), .Names = c("Sub_Pathways", "BMI_beta", "SAT_beta", "VAT_beta", "VSR_beta"), row.names = c(NA, 5L), class = "data.frame")

On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/09/2017 9:47 AM, greg holly wrote:
>
>> Hi all;
>>
>> I have data at 734*22 dimensions with rows and columns names are 
>> non-numeric.When I convert this data into matrix then all values show 
>> up with quotes. Then when I use x1= noquotes(x) to remove the quotes 
>> from the matrix then non-numeric row names remain all other values in 
>> matrix disappear.
>>
>> Your help is greatly appreciated.
>>
>>
>
> Matrices in R can have only one type.  If you start with a dataframe 
> and any columns contain character data, all entries will be converted 
> to character, and the matrix will be displayed with quotes.
>
> When you say all values disappear, it sounds as though you are 
> displaying strings containing nothing (or just blanks).  Those will be displayed as ""
> normally, but if the matrix is marked to display without quotes, they 
> are displayed as empty strings, so it will appear that nothing is displayed.
>
> You can see the structure of the original data using the str() 
> function, e.g. str(x) should display types for each column.
>
> If this isn't enough to explain what's going on, please show us more 
> detail.  For example, show us the result of
>
> y <- x[1:5, 1:5]
> dput(y)
>
> both before and after converting x to a matrix.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mak.hholly at gmail.com  Tue Sep 19 17:38:41 2017
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 19 Sep 2017 11:38:41 -0400
Subject: [R] remove quotes from matrix
In-Reply-To: <CAGxFJbRVLYTXaVQtcBv7gZ9-p-sTAKSyuLDQsu8JxcuMq=dpCg@mail.gmail.com>
References: <CAM9Qe4i+31jF7hHJCKM6CZRigj+uEFJzEXyVJOW0zs3KRnDb4Q@mail.gmail.com>
 <40869459-d0c2-5235-18d1-c22bec2d70da@gmail.com>
 <CAM9Qe4j=XM5+q41R_2V9DUj_u4ZnZFgkpRdcok_RdJhU0uEbpg@mail.gmail.com>
 <CAGxFJbRVLYTXaVQtcBv7gZ9-p-sTAKSyuLDQsu8JxcuMq=dpCg@mail.gmail.com>
Message-ID: <CAM9Qe4i+X8PcAubGaX5UrxDEMOxtBQ0_-HDKY+pe9Y4q2kCtuQ@mail.gmail.com>

Hi Bert;

I sincerely appreciate for this. When I follow your way I have got
dimnames(dm)
[[1]]
NULL

I think this is the reason why the matrix is being converted into  a column
vector.

Regards,

Greg

On Tue, Sep 19, 2017 at 11:32 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> Works fine for me. What do you object to in the following?
>
> Calling the above df "d",
>
> > dm <- as.matrix(d)
> > dm
>   Sub_Pathways            BMI_beta   SAT_beta   VAT_beta
> 1 "Alanine_and_Aspartate" " 0.23820" "-0.02409" " 0.94180"
> 2 "Alanine_and_Aspartate" "-0.31300" "-1.97510" "-2.22040"
> 3 "Alanine_and_Aspartate" " 0.12380" " 0.40950" " 0.68050"
> 4 "Alanine_and_Aspartate" " 0.30350" " 0.48610" " 0.70830"
> 5 "Alanine_and_Aspartate" "-0.00982" " 0.32930" " 0.01597"
>   VSR_beta
> 1 " 0.24690"
> 2 "-0.23540"
> 3 " 0.05539"
> 4 " 0.01337"
> 5 "-0.04353"
> > dimnames(dm)
> [[1]]
> [1] "1" "2" "3" "4" "5"
>
> [[2]]
> [1] "Sub_Pathways" "BMI_beta"     "SAT_beta"     "VAT_beta"
> [5] "VSR_beta"
>
> > dm <- noquote(dm)
> > dm
>   Sub_Pathways          BMI_beta SAT_beta VAT_beta VSR_beta
> 1 Alanine_and_Aspartate  0.23820 -0.02409  0.94180  0.24690
> 2 Alanine_and_Aspartate -0.31300 -1.97510 -2.22040 -0.23540
> 3 Alanine_and_Aspartate  0.12380  0.40950  0.68050  0.05539
> 4 Alanine_and_Aspartate  0.30350  0.48610  0.70830  0.01337
> 5 Alanine_and_Aspartate -0.00982  0.32930  0.01597 -0.04353
> > dimnames(dm)
> [[1]]
> [1] "1" "2" "3" "4" "5"
>
> [[2]]
> [1] "Sub_Pathways" "BMI_beta"     "SAT_beta"     "VAT_beta"
> [5] "VSR_beta"
>
>
> Perhaps you need to read ?noquote or ?matrix.
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Sep 19, 2017 at 8:20 AM, greg holly <mak.hholly at gmail.com> wrote:
>
>> Dear all;
>>
>> Thanks. Here are the dput results as Duncan suggested.
>>
>> Regards,
>>
>> Greg
>>
>> structure(list(Sub_Pathways = structure(c(3L, 3L, 3L, 3L, 3L), .Label =
>> c("Acetylated_Peptides",
>> "Advanced_Glycation_End-product", "Alanine_and_Aspartate", "Aminosugar",
>> "Ascorbate_and_Aldarate", "Carnitine", "Ceramides", "Creatine",
>> "Diacylglycerol", "Dipeptide", "Dipeptide_Derivative",
>> "Disaccharides_and_Oligosaccharides",
>> "Eicosanoid", "Endocannabinoid", "Fatty_Acid(Acyl_Carnitine)",
>> "Fatty_Acid(Acyl_Glycine)", "Fatty_Acid,_Amino", "Fatty_Acid,_Branched",
>> "Fatty_Acid,_Dicarboxylate", "Fatty_Acid,_Dihydroxy",
>> "Fatty_Acid,_Monohydroxy",
>> "Fatty_Acid_(Acyl_Choline)", "Fatty_Acid_(Acyl_Glutamine)",
>> "Fatty_Acid_(also_BCAA)",
>> "Fatty_Acid_Synthesis", "Fibrinogen_Cleavage_Peptide",
>> "Fructose,_Mannose_and_Galactose",
>> "Gamma-glutamyl_Amino_Acid", "Glutamate", "Glutathione", "Glycerolipid",
>> "Glycine,_Serine_and_Threonine", "Glycogen",
>> "Glycolysis,_Gluconeogenesis,_and_Pyruvate",
>> "Guanidino_and_Acetamido", "Hemoglobin_and_Porphyrin", "Histidine",
>> "Inositol", "Ketone_Bodies", "Leucine,_Isoleucine_and_Valine",
>> "Long_Chain_Fatty_Acid", "Lysine", "Lyso-phospho-ether", "Lysolipid",
>> "Lysoplasmalogen", "Medium_Chain_Fatty_Acid",
>> "Methionine,_Cysteine,_SAM_and_Taurine",
>> "Mevalonate", "Monoacylglycerol", "Nicotinate_and_Nicotinamide",
>> "Oxidative_Phosphorylation", "Pantothenate_and_CoA", "Pentose",
>> "Phenylalanine_and_Tyrosine", "Phospholipid", "Plasmalogen",
>> "Polyamine", "Polypeptide", "Polyunsaturated_Fatty_Acid_(n3_and_n6)",
>> "Primary_Bile_Acid", "Purine,_(Hypo)Xanthine/Inosine_containing",
>> "Purine,_Adenine_containing", "Purine,_Guanine_containing",
>> "Pyrimidine,_Cytidine_containing",
>> "Pyrimidine,_Orotate_containing", "Pyrimidine,_Thymine_containing",
>> "Pyrimidine,_Uracil_containing", "Riboflavin", "Secondary_Bile_Acid",
>> "Short_Chain_Fatty_Acid", "Sphingolipid", "Steroid", "Sterol",
>> "TCA_Cycle", "Tocopherol", "Tryptophan",
>> "Urea_cycle;_Arginine_and_Proline",
>> "Vitamin_A", "Vitamin_B6"), class = "factor"), BMI_beta = c(0.2382,
>> -0.313, 0.1238, 0.3035, -0.00982), SAT_beta = c(-0.02409, -1.9751,
>> 0.4095, 0.4861, 0.3293), VAT_beta = c(0.9418, -2.2204, 0.6805,
>> 0.7083, 0.01597), VSR_beta = c(0.2469, -0.2354, 0.05539, 0.01337,
>> -0.04353)), .Names = c("Sub_Pathways", "BMI_beta", "SAT_beta",
>> "VAT_beta", "VSR_beta"), row.names = c(NA, 5L), class = "data.frame")
>>
>> On Tue, Sep 19, 2017 at 10:04 AM, Duncan Murdoch <
>> murdoch.duncan at gmail.com>
>> wrote:
>>
>> > On 19/09/2017 9:47 AM, greg holly wrote:
>> >
>> >> Hi all;
>> >>
>> >> I have data at 734*22 dimensions with rows and columns names are
>> >> non-numeric.When I convert this data into matrix then all values show
>> up
>> >> with quotes. Then when I use
>> >> x1= noquotes(x) to remove the quotes from the matrix then non-numeric
>> row
>> >> names remain all other values in matrix disappear.
>> >>
>> >> Your help is greatly appreciated.
>> >>
>> >>
>> >
>> > Matrices in R can have only one type.  If you start with a dataframe and
>> > any columns contain character data, all entries will be converted to
>> > character, and the matrix will be displayed with quotes.
>> >
>> > When you say all values disappear, it sounds as though you are
>> displaying
>> > strings containing nothing (or just blanks).  Those will be displayed
>> as ""
>> > normally, but if the matrix is marked to display without quotes, they
>> are
>> > displayed as empty strings, so it will appear that nothing is displayed.
>> >
>> > You can see the structure of the original data using the str() function,
>> > e.g. str(x) should display types for each column.
>> >
>> > If this isn't enough to explain what's going on, please show us more
>> > detail.  For example, show us the result of
>> >
>> > y <- x[1:5, 1:5]
>> > dput(y)
>> >
>> > both before and after converting x to a matrix.
>> >
>> > Duncan Murdoch
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From viveksutra at gmail.com  Tue Sep 19 20:08:18 2017
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Tue, 19 Sep 2017 20:08:18 +0200
Subject: [R] symbolic computing example with Ryacas
In-Reply-To: <CAGxFJbT_x3GRL8GE28NBGjfSV_pWvw5KE+bBQmXxH9Et1X2n1w@mail.gmail.com>
References: <CAHLp6SDKVT3StPA_7Lt-0hROg6i0yW_CFrpqMDTmd9iDiX4jSg@mail.gmail.com>
 <CAGxFJbT_x3GRL8GE28NBGjfSV_pWvw5KE+bBQmXxH9Et1X2n1w@mail.gmail.com>
Message-ID: <CAHLp6SA7Uux-C=bt0iVbgqizWwfkAxsb59uHQ6yH4z2593kW+A@mail.gmail.com>

Thanks for the response. Yes, I did study the vignette but did not
understand it fully. Anyway, I have tried once again now. I am happy to say
that I have got what I wanted.

library(Ryacas)
x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")
my_func <- function(x,U,x0,C) {
  return (U/(1+exp(-(x-x0)/C)))}
FirstDeriv <- deriv(my_func(x,U,x0,C), x)
PrettyForm(FirstDeriv)
#slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")
slope <- Subst(FirstDeriv,x,x0)
#PrettyForm(slope) - gives errors
PrettyForm(Simplify(slope))

I was confused by the references to the yacas command.  Now, I have chosen
to omit it. Then I get what I want.
Thanks,
Vivek

2017-09-19 16:04 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:

> Have you studied the "Introduction to Ryacas" vignette that come with the
> package?
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Sep 19, 2017 at 2:37 AM, Vivek Sutradhara <viveksutra at gmail.com>
> wrote:
>
>> Hi all,
>> I am trying to implement the following matlab code with Ryacas :
>>
>> syms U x x0 C
>>
>> d1=diff(U/(1+exp(-(x-x0)/C)),x);
>>
>> pretty(d1)
>>
>> d2=diff(U/(1+exp(-(x-x0)/C)),x,2);
>>
>> pretty(d2)
>>
>> solx2 = solve(d2 == 0, x, 'Real', true)
>>
>> pretty(solx2)
>>
>> slope2=subs(d1,solx2)
>>
>>
>> I have tried the following :
>>
>> library(Ryacas)
>>
>> x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")
>>
>> my_func <- function(x,U,x0,C) {
>>
>>   return (U/(1+exp(-(x-x0)/C)))}
>>
>> FirstDeriv <- deriv(my_func(x,U,x0,C), x)
>>
>> PrettyForm(FirstDeriv)
>>
>> slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")
>>
>> PrettyForm(slope)
>>
>>
>> I don't understand how I should use the Subst command. I want the slope of
>> the first derivative at x=x0. How do I implement that?
>>
>> I would appreciate any help that I can get.
>>
>> Thanks,
>>
>> Vivek
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Wed Sep 20 00:49:41 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 19 Sep 2017 18:49:41 -0400
Subject: [R] symbolic computing example with Ryacas
In-Reply-To: <CAHLp6SA7Uux-C=bt0iVbgqizWwfkAxsb59uHQ6yH4z2593kW+A@mail.gmail.com>
References: <CAHLp6SDKVT3StPA_7Lt-0hROg6i0yW_CFrpqMDTmd9iDiX4jSg@mail.gmail.com>
 <CAGxFJbT_x3GRL8GE28NBGjfSV_pWvw5KE+bBQmXxH9Et1X2n1w@mail.gmail.com>
 <CAHLp6SA7Uux-C=bt0iVbgqizWwfkAxsb59uHQ6yH4z2593kW+A@mail.gmail.com>
Message-ID: <CAP01uRnwtDxW=Mthct8n8j0Qu2-8mCi2BHhjq3RPRCos8uaURQ@mail.gmail.com>

Here are some more examples:

library(Ryacas)

x <- Sym("x")
yacas("x:=2")
Eval(x*x)
## [1] 4

# vignette has similar example
y <- Sym("y")
Eval(Subst(y*y, y, 3))
## [1] 9

# demo("Ryacas-Function") has similar example to this
f <- function(z) {}
body(f) <- yacas(expression(z*z))[[1]]
f(4)
## [1] 16



On Tue, Sep 19, 2017 at 2:08 PM, Vivek Sutradhara <viveksutra at gmail.com> wrote:
> Thanks for the response. Yes, I did study the vignette but did not
> understand it fully. Anyway, I have tried once again now. I am happy to say
> that I have got what I wanted.
>
> library(Ryacas)
> x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")
> my_func <- function(x,U,x0,C) {
>   return (U/(1+exp(-(x-x0)/C)))}
> FirstDeriv <- deriv(my_func(x,U,x0,C), x)
> PrettyForm(FirstDeriv)
> #slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")
> slope <- Subst(FirstDeriv,x,x0)
> #PrettyForm(slope) - gives errors
> PrettyForm(Simplify(slope))
>
> I was confused by the references to the yacas command.  Now, I have chosen
> to omit it. Then I get what I want.
> Thanks,
> Vivek
>
> 2017-09-19 16:04 GMT+02:00 Bert Gunter <bgunter.4567 at gmail.com>:
>
>> Have you studied the "Introduction to Ryacas" vignette that come with the
>> package?
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Tue, Sep 19, 2017 at 2:37 AM, Vivek Sutradhara <viveksutra at gmail.com>
>> wrote:
>>
>>> Hi all,
>>> I am trying to implement the following matlab code with Ryacas :
>>>
>>> syms U x x0 C
>>>
>>> d1=diff(U/(1+exp(-(x-x0)/C)),x);
>>>
>>> pretty(d1)
>>>
>>> d2=diff(U/(1+exp(-(x-x0)/C)),x,2);
>>>
>>> pretty(d2)
>>>
>>> solx2 = solve(d2 == 0, x, 'Real', true)
>>>
>>> pretty(solx2)
>>>
>>> slope2=subs(d1,solx2)
>>>
>>>
>>> I have tried the following :
>>>
>>> library(Ryacas)
>>>
>>> x <- Sym("x");U <- Sym("U");x0 <- Sym("x0");C <- Sym("C")
>>>
>>> my_func <- function(x,U,x0,C) {
>>>
>>>   return (U/(1+exp(-(x-x0)/C)))}
>>>
>>> FirstDeriv <- deriv(my_func(x,U,x0,C), x)
>>>
>>> PrettyForm(FirstDeriv)
>>>
>>> slope <- yacas("Subst(x,x0),deriv(my_func(x,U,x0,C), x)")
>>>
>>> PrettyForm(slope)
>>>
>>>
>>> I don't understand how I should use the Subst command. I want the slope of
>>> the first derivative at x=x0. How do I implement that?
>>>
>>> I would appreciate any help that I can get.
>>>
>>> Thanks,
>>>
>>> Vivek
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From justinthong93 at gmail.com  Wed Sep 20 04:33:34 2017
From: justinthong93 at gmail.com (Justin Thong)
Date: Tue, 19 Sep 2017 22:33:34 -0400
Subject: [R] igraph problem
Message-ID: <CAEtAGeon=-Ep8kKfCot-GmiJM=V7_-srNbR=hKRJ5rCt8H1xDQ@mail.gmail.com>

Run this code

tree<-graph_from_literal(1-+2:3,3-+5,1-+4);
graph.bfs(tree,root=1, neimode="out",father=TRUE,order=TRUE,unreachable =
FALSE)

I do not understand why the father values will give NA 1 1 3 1 rather than NA
1 1 1 3

The reason I am doing this is to obtain the values(by vertex names) or some
index of each individual branch in tree. Does anyone have any ideas on how
to do this?

Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419 <07938%20674419>(UK)
or +60125056192 <+60%2012-505%206192>(Malaysia)*

	[[alternative HTML version deleted]]


From sherief_ghozy at yahoo.com  Wed Sep 20 03:18:20 2017
From: sherief_ghozy at yahoo.com (Sherief Ghozy)
Date: Wed, 20 Sep 2017 01:18:20 +0000 (UTC)
Subject: [R] Network meta-analysis help
References: <984833616.9272449.1505870300887.ref@mail.yahoo.com>
Message-ID: <984833616.9272449.1505870300887@mail.yahoo.com>

Greetings. I hope my message finds you well.

I know this question may be silly for some experts like you but it's a very important matter for me so, sorry for that.

I was trying to make a network meta-analysis using R for the attached data set which shows the association between breast feeding and autism spectrum disorder (the event here is bad).

I've searched a lot through the internet but no clear guidelines on how to do network meta-analysis and produce the related figures (Forest plot, Network plot, Heat map .... ect).

I've installed "netmeta" pack successfully.

Can you help me in this matter ? or even guide me where to find help ?

I really need to finish this analysis.

Sorry for any inconvenience.

Thanks in advance.

From dwinsemius at comcast.net  Wed Sep 20 08:17:39 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 19 Sep 2017 23:17:39 -0700
Subject: [R] Network meta-analysis help
In-Reply-To: <984833616.9272449.1505870300887@mail.yahoo.com>
References: <984833616.9272449.1505870300887.ref@mail.yahoo.com>
 <984833616.9272449.1505870300887@mail.yahoo.com>
Message-ID: <8DB0D400-72A0-4947-8928-132ADA1DC458@comcast.net>


> On Sep 19, 2017, at 6:18 PM, Sherief Ghozy via R-help <r-help at r-project.org> wrote:
> 
> Greetings. I hope my message finds you well.
> 
> I know this question may be silly for some experts like you but it's a very important matter for me so, sorry for that.
> 
> I was trying to make a network meta-analysis using R for the attached data set

Nope. It probably wasn't a MIME-text file.


> which shows the association between breast feeding and autism spectrum disorder (the event here is bad).
> 
> I've searched a lot through the internet but no clear guidelines on how to do network meta-analysis and produce the related figures (Forest plot, Network plot, Heat map .... ect).
> 
> I've installed "netmeta" pack successfully.
> 
> Can you help me in this matter ? or even guide me where to find help ?
> 
> I really need to finish this analysis.

I think that if you read the Posting Guide you will find that your question is rather off-topic for rhelp. I think it may be more on-topic at https://crossvalidated.com/

> 
> Sorry for any inconvenience.


-- 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From niharikasinghal1990 at gmail.com  Wed Sep 20 10:14:34 2017
From: niharikasinghal1990 at gmail.com (niharika singhal)
Date: Wed, 20 Sep 2017 10:14:34 +0200
Subject: [R] How to use depmix for HMM with intial parameters
Message-ID: <CADe9EtQiadA6UQ9Q9sWe9AEtafughs0k-8e14NQvTe+uRB-1vQ@mail.gmail.com>

Hello,

I have initial parameters for HMM model and I want to use depmixS4 package.
The parameters are in the form

intial_prob_matrix=matrix(c(0.07614213, 0.45177665, 0.47208122), nrow=1,
ncol=3, byrow = TRUE)

transition_matrix=matrix(c(0.46666667,0.46666667,0.06666667,
                     0.06741573,0.5617978,0.37078652,
                     0.02173913,0.3478261,0.63043478), nrow = 3, ncol = 3,
byrow = TRUE)

meanval_matrix=matrix(c(545.1737,545.1737,803.5235,
                        565.7763,673.8019,797.5283,
                        733.9332,1006.3571,1383.5395), nrow = 3, ncol = 3,
byrow = TRUE)

sigmaval_matrix=matrix(c(82.19592,13.64243,57.07868,
                         65.32724,13.38910,81.66209,
                         97.62573,71.09579,115.55612), nrow = 3, ncol = 3,
byrow = TRUE)

coeffval_matrix=matrix(c(0.1295604,0.6464059,0.2240336,
                         0.2091671,0.5267220,0.2641110,
                         0.3430697,0.3350215,0.3219088), nrow = 3, ncol =
3, byrow = TRUE)

emission_matrix=list(meanval_matrix,sigmaval_matrix,coeffval_matrix)

powerdf is a column from my dataset which look like something = 19.0, 18.0,
24.0...............it has some 30 thousand rows

I tried  using the code below and got an error

mod= depmix( response = power~1, data = powerdf, nstates=3,
                           instart=intial_prob_matrix,
trstart=transition_matrix, respstart=emission_matrix)

 Error in makeResponseModels(response = response, data = data, nstates =
nstates,  :
  'respstart' has incorrect length, it should be 6

I cannot change my emission matrix, it would always be list of matrix (mean
, sigma and weighted coefficient mixture)

I thought to change the response but I am unable to figure out the right
response

Can someone guide me how can I solve this problem, by giving the
parameters defined above?

Thanks & Regards
Niharika Singhal

	[[alternative HTML version deleted]]


From donald.jackson at bms.com  Tue Sep 19 14:23:52 2017
From: donald.jackson at bms.com (Jackson (Genomics), Donald)
Date: Tue, 19 Sep 2017 12:23:52 +0000
Subject: [R] [R-pkgs] Update to R package envDocument
Message-ID: <BN6P135MB0049D035FC650E943571FEC19A600@BN6P135MB0049.NAMP135.PROD.OUTLOOK.COM>

An updated version of my envDocument package is now available on CRAN at  https://CRAN.R-project.org/package=envDocument with code at https://github.com/dgJacks0n/envDocument/tree/V_2.4.0

The main function from this package, env_doc(), provides a detailed, automated report on the environment in which an analysis was run.  In addition to everything provided by sessionInfo() it also includes the path to the R script or Rmarkdown file that ran the analysis and that file's Git repository, branch, commit and status.  Version 2.4.0 adds information on Domino Datalab runs including the run URL and ID, project name, run user, and hardware tier.  The code detects whether it's run in a Domino environment (by checking for Domino-specific environment variables); if so, it will automatically include this section - otherwise it's skipped.  I also enhanced the git repo information.  The release also includes a number of bugfixes, mostly related to error handling.


Donald Jackson, PhD
Principal Scientist,
Translational Bioinformatics Group / Translational Medicine Department
Bristol-Myers Squibb R&D

________________________________
This message (including any attachments) may contain con...{{dropped:7}}


From upananda.pani at gmail.com  Wed Sep 20 11:05:47 2017
From: upananda.pani at gmail.com (Upananda Pani)
Date: Wed, 20 Sep 2017 14:35:47 +0530
Subject: [R] Convert data into zoo object using Performance analytics
	package
In-Reply-To: <CAEezrQSeMLpHA_RHz3QEZhqZdPO=RS=Gq22fKdfRLQdZtWvEWQ@mail.gmail.com>
References: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
 <CAP01uRkiH-5ReU9F=Jhtk3_bEEnqs22ok1cDX97_dhOgUPb_9Q@mail.gmail.com>
 <CAEezrQSeMLpHA_RHz3QEZhqZdPO=RS=Gq22fKdfRLQdZtWvEWQ@mail.gmail.com>
Message-ID: <CAEezrQT6FA5s9X9zz69sRgoeTENZYTFrhFXFhRM5AcH6Ht1i8g@mail.gmail.com>

Dear Sir,

Thanks for your mail and help. I got this error while trying to run your
code.

sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
Error in read.table(file = file, header = header, sep = sep, quote = quote,
 :
  'file' must be a character string or connection

Thanks and Regards,
Upananda Pani

On Tue, Sep 19, 2017 at 4:31 PM, Upananda Pani <upananda.pani at gmail.com>
wrote:

> Dear Sir,
>
> Thanks for your mail and help. I got this error while trying to run your
> code.
>
> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
> Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> Thanks and Regards,
> Upananda Pani
>
> On Mon, Sep 18, 2017 at 7:38 PM, Gabor Grothendieck <
> ggrothendieck at gmail.com> wrote:
>
>> Depending on how you created df maybe your code has the column names
>> wrong.  In any case these 4 alternatives all work.  Start a fresh R
>> session and then copy and paste this into it.
>>
>> library(zoo)
>> u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
>> fmt <- "%m/%d/%Y"
>>
>> # 1
>> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
>>
>> # 2
>> df <- read.csv(u)
>> sbux2.z <- read.zoo(df, FUN = as.yearmon, format = fmt)
>>
>> # 3
>> df <- read.csv(u)
>> names(head(df))
>> ## [1] "Date"      "Adj.Close"
>> sbux3.z <- zoo(df$Adj.Close, as.yearmon(df$Date, fmt))
>>
>> # 4
>> df <- read.csv(u)
>> sbux4.z <- zoo(df[[2]], as.yearmon(df[[1]], fmt))
>>
>> On Mon, Sep 18, 2017 at 7:36 AM, Upananda Pani <upananda.pani at gmail.com>
>> wrote:
>> > Dear All,
>> >
>> > While i am trying convert data frame object to zoo object I am
>> > getting numeric(0) error in performance analytics package.
>> >
>> > The source code i am using from this website to learn r in finance:
>> > https://faculty.washington.edu/ezivot/econ424/returnCalculations.r
>> >
>> > # create zoo objects from data.frame objects
>> > dates.sbux = as.yearmon(sbux.df$Date, format="%m/%d/%Y")
>> > dates.msft = as.yearmon(msft.df$Date, format="%m/%d/%Y")
>> > sbux.z = zoo(x=sbux.df$Adj.Close, order.by=dates.sbux)
>> > msft.z = zoo(x=msft.df$Adj.Close, order.by=dates.msft)
>> > class(sbux.z)
>> > head(sbux.z)
>> >> head(sbux.z)
>> > Data:
>> > numeric(0)
>> >
>> > I will be grateful if anybody would like to guide me where i am making
>> the
>> > mistake.
>> >
>> > With best regards,
>> > Upananda Pani
>> >
>> >
>> > --
>> >
>> >
>> > You may delay, but time will not.
>> >
>> >
>> > Research Scholar
>> > alternative mail id: upani at iitkgp.ac.in
>> > Department of HSS, IIT KGP
>> > KGP
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>>
>
>
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
>



-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Sep 20 11:52:16 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 20 Sep 2017 09:52:16 +0000
Subject: [R] Convert data into zoo object using Performance
	analytics	package
In-Reply-To: <CAEezrQT6FA5s9X9zz69sRgoeTENZYTFrhFXFhRM5AcH6Ht1i8g@mail.gmail.com>
References: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
 <CAP01uRkiH-5ReU9F=Jhtk3_bEEnqs22ok1cDX97_dhOgUPb_9Q@mail.gmail.com>
 <CAEezrQSeMLpHA_RHz3QEZhqZdPO=RS=Gq22fKdfRLQdZtWvEWQ@mail.gmail.com>
 <CAEezrQT6FA5s9X9zz69sRgoeTENZYTFrhFXFhRM5AcH6Ht1i8g@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAFA0B@SRVEXCHCM301.precheza.cz>

Hi

Gabor's code works as expeceted without error.
What is "u" in your case?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Upananda
> Pani
> Sent: Wednesday, September 20, 2017 11:06 AM
> To: Gabor Grothendieck <ggrothendieck at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Convert data into zoo object using Performance analytics
> package
>
> Dear Sir,
>
> Thanks for your mail and help. I got this error while trying to run your code.
>
> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> read.table(file = file, header = header, sep = sep, quote = quote,
>  :
>   'file' must be a character string or connection
>
> Thanks and Regards,
> Upananda Pani
>
> On Tue, Sep 19, 2017 at 4:31 PM, Upananda Pani <upananda.pani at gmail.com>
> wrote:
>
> > Dear Sir,
> >
> > Thanks for your mail and help. I got this error while trying to run
> > your code.
> >
> > sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> > read.table(file = file, header = header, sep = sep, quote = quote,  :
> >   'file' must be a character string or connection
> >
> > Thanks and Regards,
> > Upananda Pani
> >
> > On Mon, Sep 18, 2017 at 7:38 PM, Gabor Grothendieck <
> > ggrothendieck at gmail.com> wrote:
> >
> >> Depending on how you created df maybe your code has the column names
> >> wrong.  In any case these 4 alternatives all work.  Start a fresh R
> >> session and then copy and paste this into it.
> >>
> >> library(zoo)
> >> u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
> >> fmt <- "%m/%d/%Y"
> >>
> >> # 1
> >> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
> >>
> >> # 2
> >> df <- read.csv(u)
> >> sbux2.z <- read.zoo(df, FUN = as.yearmon, format = fmt)
> >>
> >> # 3
> >> df <- read.csv(u)
> >> names(head(df))
> >> ## [1] "Date"      "Adj.Close"
> >> sbux3.z <- zoo(df$Adj.Close, as.yearmon(df$Date, fmt))
> >>
> >> # 4
> >> df <- read.csv(u)
> >> sbux4.z <- zoo(df[[2]], as.yearmon(df[[1]], fmt))
> >>
> >> On Mon, Sep 18, 2017 at 7:36 AM, Upananda Pani
> >> <upananda.pani at gmail.com>
> >> wrote:
> >> > Dear All,
> >> >
> >> > While i am trying convert data frame object to zoo object I am
> >> > getting numeric(0) error in performance analytics package.
> >> >
> >> > The source code i am using from this website to learn r in finance:
> >> > https://faculty.washington.edu/ezivot/econ424/returnCalculations.r
> >> >
> >> > # create zoo objects from data.frame objects dates.sbux =
> >> > as.yearmon(sbux.df$Date, format="%m/%d/%Y") dates.msft =
> >> > as.yearmon(msft.df$Date, format="%m/%d/%Y") sbux.z =
> >> > zoo(x=sbux.df$Adj.Close, order.by=dates.sbux) msft.z =
> >> > zoo(x=msft.df$Adj.Close, order.by=dates.msft)
> >> > class(sbux.z)
> >> > head(sbux.z)
> >> >> head(sbux.z)
> >> > Data:
> >> > numeric(0)
> >> >
> >> > I will be grateful if anybody would like to guide me where i am
> >> > making
> >> the
> >> > mistake.
> >> >
> >> > With best regards,
> >> > Upananda Pani
> >> >
> >> >
> >> > --
> >> >
> >> >
> >> > You may delay, but time will not.
> >> >
> >> >
> >> > Research Scholar
> >> > alternative mail id: upani at iitkgp.ac.in Department of HSS, IIT KGP
> >> > KGP
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com
> >>
> >
> >
> >
> > --
> >
> >
> > You may delay, but time will not.
> >
> >
> > Research Scholar
> > alternative mail id: upani at iitkgp.ac.in Department of HSS, IIT KGP KGP
> >
>
>
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From abouelmakarim1962 at gmail.com  Wed Sep 20 12:03:48 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 20 Sep 2017 06:03:48 -0400
Subject: [R] Install the Package "ISwR"
Message-ID: <CAE9stmcRaz4ZJXCKcwOi-k+oZpc4ONhq9E4OMcn7K7XK7a80UQ@mail.gmail.com>

Dear All: good morning

I am trying to install the "" package, but I am getting this error message.


*> utils:::menuInstallPkgs()*
*Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
= type) :*
*  'lib = "C:/Program Files/R/R-3.4.1/library"' is not writable*
*Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) : *
*  unable to install packages*
*>*

When I select the ISwR package from the list I got I message saying "*Question?
Would you like to use a personal library instead?*" I answered by No. Then
it gives me the above message.


Thank you for your time.


with thanks
abou
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Sep 20 12:09:44 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 20 Sep 2017 13:09:44 +0300
Subject: [R] Install the Package "ISwR"
In-Reply-To: <CAE9stmcRaz4ZJXCKcwOi-k+oZpc4ONhq9E4OMcn7K7XK7a80UQ@mail.gmail.com>
References: <CAE9stmcRaz4ZJXCKcwOi-k+oZpc4ONhq9E4OMcn7K7XK7a80UQ@mail.gmail.com>
Message-ID: <CAGgJW75f2nghVHMMZ1-s=CUS_XcEMBLrvCcfs8bANBGXzE4OAA@mail.gmail.com>

What if you answer 'Yes' ?

On Wed, Sep 20, 2017 at 1:03 PM, AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All: good morning
>
> I am trying to install the "" package, but I am getting this error message.
>
>
> *> utils:::menuInstallPkgs()*
> *Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
> = type) :*
> *  'lib = "C:/Program Files/R/R-3.4.1/library"' is not writable*
> *Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) : *
> *  unable to install packages*
> *>*
>
> When I select the ISwR package from the list I got I message saying
> "*Question?
> Would you like to use a personal library instead?*" I answered by No. Then
> it gives me the above message.
>
>
> Thank you for your time.
>
>
> with thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Wed Sep 20 12:18:55 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Wed, 20 Sep 2017 06:18:55 -0400
Subject: [R] Install the Package "ISwR"
In-Reply-To: <CAGgJW75f2nghVHMMZ1-s=CUS_XcEMBLrvCcfs8bANBGXzE4OAA@mail.gmail.com>
References: <CAE9stmcRaz4ZJXCKcwOi-k+oZpc4ONhq9E4OMcn7K7XK7a80UQ@mail.gmail.com>
 <CAGgJW75f2nghVHMMZ1-s=CUS_XcEMBLrvCcfs8bANBGXzE4OAA@mail.gmail.com>
Message-ID: <CAE9stmeFLVxt8n5ePAVHyLfsZ_BxQ37DomBuuJBsV34_9YDp3w@mail.gmail.com>

I simply answered Yes, Yes, Yes. It works now.

thank you very much

abou

On Wed, Sep 20, 2017 at 6:09 AM, Eric Berger <ericjberger at gmail.com> wrote:

> What if you answer 'Yes' ?
>
> On Wed, Sep 20, 2017 at 1:03 PM, AbouEl-Makarim Aboueissa <
> abouelmakarim1962 at gmail.com> wrote:
>
>> Dear All: good morning
>>
>> I am trying to install the "" package, but I am getting this error
>> message.
>>
>>
>> *> utils:::menuInstallPkgs()*
>> *Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA,
>> type
>> = type) :*
>> *  'lib = "C:/Program Files/R/R-3.4.1/library"' is not writable*
>> *Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
>> =
>> type) : *
>> *  unable to install packages*
>> *>*
>>
>> When I select the ISwR package from the list I got I message saying
>> "*Question?
>> Would you like to use a personal library instead?*" I answered by No. Then
>> it gives me the above message.
>>
>>
>> Thank you for your time.
>>
>>
>> with thanks
>> abou
>> ______________________
>> AbouEl-Makarim Aboueissa, PhD
>> Professor of Statistics
>> Department of Mathematics and Statistics
>> University of Southern Maine
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Wed Sep 20 14:19:20 2017
From: acefix at rocketmail.com (Fix Ace)
Date: Wed, 20 Sep 2017 12:19:20 +0000 (UTC)
Subject: [R] pheatmap: incomplete figure
In-Reply-To: <204337BB-AB89-45C2-8831-6B90E6292371@comcast.net>
References: <131866721.1747055.1505752014804.ref@mail.yahoo.com>
 <131866721.1747055.1505752014804@mail.yahoo.com>
 <204337BB-AB89-45C2-8831-6B90E6292371@comcast.net>
Message-ID: <272902206.108639.1505909960376@mail.yahoo.com>

Thank you so much for the reply! I thought the file would automatically adjust accordingly. But I just checked and found pheatmap does has width as parameter!
Ace 

    On Monday, September 18, 2017 3:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 

 
> On Sep 18, 2017, at 9:26 AM, Fix Ace via R-help <r-help at r-project.org> wrote:
> 
> Dear R Community,
> I tried to generate heatmap for a matrix of 1500 columns by 106 rows using the following R script:
>> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,border_color=NA)
> and got the graph (as attached Fig 1)
> 
> Since the column labels appear very crowded, I tried to increase the cellwidth to stretch the graph horizontally. The idea was to show the graph section by section, but with clear/readable column labels (not overlapped labels).
> So I typed:
>> pheatmap(tf.vs.DE.1.removeAllZeroCol, fontsize=3,cellwidth=3,cellheight=3,border_color=NA)
> However, this time I only got middle part of the original heatmap (as attached Fig 2)
> I wonder if there is way I could output the whole graph after such horizontal stretch. If not, how do I get the left end of the graph.
> 

Why not define a graphics device that is wider?

-- 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law






   
	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Sep 20 16:16:56 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 20 Sep 2017 09:16:56 -0500
Subject: [R] Keep on getting message errors when trying to install and load
	packages
Message-ID: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>

Dear R friends,

I am currently using Windows 8, 64-bit operating system, x64-based
processor. I have installed R version 3.4.1 "Single Candle".

Also, I have several packages installed in this path:

C:\Users\PaulBernal\Documents\R\win-library\3.4

Plus some other packages installed in this other path:

C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW


And I have installed R in the following path:

C:\Program Files\R\R-3.4.1

Whenever I try to install an R package the following error messages are
displayed in the R console:

> utils:::menuInstallLocal()
package ?readstata13? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f747105765\readstata13?
to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?

> utils:::menuInstallLocal()
package ?Hmisc? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc? to
?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?

package ?readr? successfully unpacked and MD5 sums checked
package ?hms? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms? to
?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
package ?Hmisc? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc? to
?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
package ?haven? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven? to
?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
package ?readstata13? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f741507f27\readstata13?
to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
package ?readxl? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74271b1a7a\readxl?
to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
package ?RcmdrMisc? successfully unpacked and MD5 sums checked
Warning: unable to move temporary installation
?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7419e243c1\RcmdrMisc?
to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?

Do I have to put all the packages in the same path where I installed R?
Could this be happening because I have packages installed in several
folders with several paths? Should I consolidate and put all packages in a
single location?

Any help will be greatly appreciated,

Cheers,

Paul

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Wed Sep 20 16:26:35 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 20 Sep 2017 09:26:35 -0500
Subject: [R] Keep on getting message errors when trying to install and load
 packages 2
Message-ID: <CAMOcQfOBBS7ChGs0RCpipqvdu_2n9Xjdy9inGmv4QDw3CqFJQw@mail.gmail.com>

Dear all,

Is it normal for R to store installed packages in paths like the following?

C:\Users\PaulBernal\AppData\Local\Temp\RtmpgXA5VS\downloaded_packages

Regards,

Paul

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Wed Sep 20 17:07:20 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 20 Sep 2017 20:37:20 +0530
Subject: [R] arguments imply differing number of rows
Message-ID: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>

Hi Team,

I using the syntax as:

data.df<- data.frame(
  city= c(rep(c("Delhi", "Bangalore","Chandigarh"),each=5)),
  population= c(4000:6000,3500:4300,3000:3200)
)

But i am getting the error as arguments imply differing number of rows: 15,
3003.

Tried searching google but could not understand & find the solution.

Thanks, Shivi

	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Wed Sep 20 17:11:12 2017
From: rni.boh at gmail.com (Bob O'Hara)
Date: Wed, 20 Sep 2017 17:11:12 +0200
Subject: [R] arguments imply differing number of rows
In-Reply-To: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
References: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
Message-ID: <CAN-Z0xV4WL3-FSs2ve+m+48MmTH6xsPyHzcTShJSd0=34QkOYQ@mail.gmail.com>

4000:6000 gives you 4000, 4001, ..., 6000. I suspect you want
population= c(seq(4000, 6000, length=5), seq(3500, 4300, length=5),
seq(3000, 3200, length=5))

Bob

On 20 September 2017 at 17:07, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> Hi Team,
>
> I using the syntax as:
>
> data.df<- data.frame(
>   city= c(rep(c("Delhi", "Bangalore","Chandigarh"),each=5)),
>   population= c(4000:6000,3500:4300,3000:3200)
> )
>
> But i am getting the error as arguments imply differing number of rows: 15,
> 3003.
>
> Tried searching google but could not understand & find the solution.
>
> Thanks, Shivi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara
NOTE NEW ADDRESS!!!
Institutt for matematiske fag
NTNU
7491 Trondheim
Norway

Mobile: +49 1515 888 5440
Journal of Negative Results - EEB: www.jnr-eeb.org


From bgunter.4567 at gmail.com  Wed Sep 20 17:11:12 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 20 Sep 2017 08:11:12 -0700
Subject: [R] arguments imply differing number of rows
In-Reply-To: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
References: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
Message-ID: <CAGxFJbTF9XgXAs2r1DP_guhxvgijxZo-tXkkGB1-AjYNHL0LbA@mail.gmail.com>

What do you think

4000:6000

means?

Perhaps you need to spend time with an R tutorial or two and stop searching
google.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 20, 2017 at 8:07 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi Team,
>
> I using the syntax as:
>
> data.df<- data.frame(
>   city= c(rep(c("Delhi", "Bangalore","Chandigarh"),each=5)),
>   population= c(4000:6000,3500:4300,3000:3200)
> )
>
> But i am getting the error as arguments imply differing number of rows: 15,
> 3003.
>
> Tried searching google but could not understand & find the solution.
>
> Thanks, Shivi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Sep 20 17:17:36 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Wed, 20 Sep 2017 16:17:36 +0100
Subject: [R] arguments imply differing number of rows
In-Reply-To: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
Message-ID: <20170920161736.Horde.IliRFIQhJC39SCgluso0Cjc@mail.sapo.pt>

Hello,

Just count:
   city is 3*5 == 15,
   population is length(4000:6000) + length(3500:4300) + length(3000:3200)
                 == 2001 + 801 + 201 == 3003
Hope this helps,

Rui Barradas



Citando Shivi Bhatia <shivipmp82 at gmail.com>:

> Hi Team,
>
> I using the syntax as:
>
> data.df<- data.frame(
>   city= c(rep(c("Delhi", "Bangalore","Chandigarh"),each=5)),
>   population= c(4000:6000,3500:4300,3000:3200)
> )
>
> But i am getting the error as arguments imply differing number of rows: 15,
> 3003.
>
> Tried searching google but could not understand & find the solution.
>
> Thanks, Shivi
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sezenismail at gmail.com  Wed Sep 20 17:19:11 2017
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Wed, 20 Sep 2017 18:19:11 +0300
Subject: [R] How to use depmix for HMM with intial parameters
In-Reply-To: <CADe9EtQiadA6UQ9Q9sWe9AEtafughs0k-8e14NQvTe+uRB-1vQ@mail.gmail.com>
References: <CADe9EtQiadA6UQ9Q9sWe9AEtafughs0k-8e14NQvTe+uRB-1vQ@mail.gmail.com>
Message-ID: <C0D4DFD0-7FD9-426D-8DEF-78950E505FC9@gmail.com>


> On 20 Sep 2017, at 11:14, niharika singhal <niharikasinghal1990 at gmail.com> wrote:
> 
> Hello,
> 
> I have initial parameters for HMM model and I want to use depmixS4 package.
> The parameters are in the form
> 
> intial_prob_matrix=matrix(c(0.07614213, 0.45177665, 0.47208122), nrow=1,
> ncol=3, byrow = TRUE)
> 
> transition_matrix=matrix(c(0.46666667,0.46666667,0.06666667,
>                     0.06741573,0.5617978,0.37078652,
>                     0.02173913,0.3478261,0.63043478), nrow = 3, ncol = 3,
> byrow = TRUE)
> 
> meanval_matrix=matrix(c(545.1737,545.1737,803.5235,
>                        565.7763,673.8019,797.5283,
>                        733.9332,1006.3571,1383.5395), nrow = 3, ncol = 3,
> byrow = TRUE)
> 
> sigmaval_matrix=matrix(c(82.19592,13.64243,57.07868,
>                         65.32724,13.38910,81.66209,
>                         97.62573,71.09579,115.55612), nrow = 3, ncol = 3,
> byrow = TRUE)
> 
> coeffval_matrix=matrix(c(0.1295604,0.6464059,0.2240336,
>                         0.2091671,0.5267220,0.2641110,
>                         0.3430697,0.3350215,0.3219088), nrow = 3, ncol =
> 3, byrow = TRUE)
> 
> emission_matrix=list(meanval_matrix,sigmaval_matrix,coeffval_matrix)
> 
> powerdf is a column from my dataset which look like something = 19.0, 18.0,
> 24.0...............it has some 30 thousand rows
> 
> I tried  using the code below and got an error
> 
> mod= depmix( response = power~1, data = powerdf, nstates=3,
>                           instart=intial_prob_matrix,
> trstart=transition_matrix, respstart=emission_matrix)
> 
> Error in makeResponseModels(response = response, data = data, nstates =
> nstates,  :
>  'respstart' has incorrect length, it should be 6
> 
> I cannot change my emission matrix, it would always be list of matrix (mean
> , sigma and weighted coefficient mixture)
> 
> I thought to change the response but I am unable to figure out the right
> response
> 
> Can someone guide me how can I solve this problem, by giving the
> parameters defined above?
> 
> Thanks & Regards
> Niharika Singhal

Hello Niharika,

As this is a very specific statistical question, you also should ask this kind of a question at [1]. You may get faster response.

1- https://stats.stackexchange.com


From sergio.ferreira-cardoso at umontpellier.fr  Wed Sep 20 18:44:03 2017
From: sergio.ferreira-cardoso at umontpellier.fr (Sergio Ferreira Cardoso)
Date: Wed, 20 Sep 2017 18:44:03 +0200 (CEST)
Subject: [R] phylo.pca
Message-ID: <393301728.6193841.1505925843570.JavaMail.zimbra@umontpellier.fr>

Dear all, 

I'm trying to use phylo.pca function from phytools for the first time. I'm using an ultrametric tree with 167 tips and all branch lengths transformed to 1. 
I lunched the pPCA like this: 

pPCA<-phyl.pca(tree,data,method = "lambda") 


For some reason it takes for ever and never reaches the end of the process. I tried with method="BM" and the process runs normally. Has this happened to anyone here? How can I go around this? 

Thanks in advance, 
S?rgio. 

-- 
Institut des Sciences de l'Evolution 
UMR5554, CNRS, IRD, EPHE 
Universit? de Montpellier 
Place Eug?ne Bataillon 
34095 Montpellier Cedex 05 
France 
Email: sergio.ferreira-cardoso at umontpellier.fr 
Tel: +33 (4 ) 67 14 46 52 

	[[alternative HTML version deleted]]


From shivipmp82 at gmail.com  Wed Sep 20 19:02:41 2017
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Wed, 20 Sep 2017 22:32:41 +0530
Subject: [R] arguments imply differing number of rows
In-Reply-To: <CAN-Z0xV4WL3-FSs2ve+m+48MmTH6xsPyHzcTShJSd0=34QkOYQ@mail.gmail.com>
References: <CAB=p7Spn4gbO_5U=9iw=POxV5ZravSRUJ9VTnL9LzcQ1Nvfgxw@mail.gmail.com>
 <CAN-Z0xV4WL3-FSs2ve+m+48MmTH6xsPyHzcTShJSd0=34QkOYQ@mail.gmail.com>
Message-ID: <CAB=p7Sq=8gdZhaV+GW2D1=ussUTteJ2aYr2crQBKZFwpthy+WQ@mail.gmail.com>

Thank you Bob, this is what i was looking for. Really appreciate.

Regards, Shivi

On Wed, Sep 20, 2017 at 8:41 PM, Bob O'Hara <rni.boh at gmail.com> wrote:

> 4000:6000 gives you 4000, 4001, ..., 6000. I suspect you want
> population= c(seq(4000, 6000, length=5), seq(3500, 4300, length=5),
> seq(3000, 3200, length=5))
>
> Bob
>
> On 20 September 2017 at 17:07, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> > Hi Team,
> >
> > I using the syntax as:
> >
> > data.df<- data.frame(
> >   city= c(rep(c("Delhi", "Bangalore","Chandigarh"),each=5)),
> >   population= c(4000:6000,3500:4300,3000:3200)
> > )
> >
> > But i am getting the error as arguments imply differing number of rows:
> 15,
> > 3003.
> >
> > Tried searching google but could not understand & find the solution.
> >
> > Thanks, Shivi
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Bob O'Hara
> NOTE NEW ADDRESS!!!
> Institutt for matematiske fag
> NTNU
> 7491 Trondheim
> Norway
>
> Mobile: +49 1515 888 5440
> Journal of Negative Results - EEB: www.jnr-eeb.org
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Sep 21 00:11:07 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 21 Sep 2017 08:11:07 +1000
Subject: [R] Network meta-analysis help
In-Reply-To: <984833616.9272449.1505870300887@mail.yahoo.com>
References: <984833616.9272449.1505870300887.ref@mail.yahoo.com>
 <984833616.9272449.1505870300887@mail.yahoo.com>
Message-ID: <CA+8X3fUMsfT0HV__RC_h76GLXjpiGbbSkvDeCbixa1-88P2gYw@mail.gmail.com>

Hi Sherief,
First thing is your data set did not make it  If it is not too large,
perhaps you could send the output of "dput" in the body of the message
or send a CSV file with the extension changed to ".txt". If the data
set is very large, perhaps you could send a subset as described above.

Jim


On Wed, Sep 20, 2017 at 11:18 AM, Sherief Ghozy via R-help
<r-help at r-project.org> wrote:
> Greetings. I hope my message finds you well.
>
> I know this question may be silly for some experts like you but it's a very important matter for me so, sorry for that.
>
> I was trying to make a network meta-analysis using R for the attached data set which shows the association between breast feeding and autism spectrum disorder (the event here is bad).
>
> I've searched a lot through the internet but no clear guidelines on how to do network meta-analysis and produce the related figures (Forest plot, Network plot, Heat map .... ect).
>
> I've installed "netmeta" pack successfully.
>
> Can you help me in this matter ? or even guide me where to find help ?
>
> I really need to finish this analysis.
>
> Sorry for any inconvenience.
>
> Thanks in advance.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wheatlab42 at gmail.com  Thu Sep 21 00:13:19 2017
From: wheatlab42 at gmail.com (Kulvinder Gill)
Date: Wed, 20 Sep 2017 15:13:19 -0700
Subject: [R] i keep getting a check data: there are more than 3 classes for
 f2 error and I am not sure how to fix it i am using onemap
Message-ID: <668AD7AE-D3C0-4485-B8F4-86124E25162F@gmail.com>

SNP <- read.mapmaker(dir = "~/desktop", "1674_SNP.raw?)

--please do not edit the information below--

R Version:
platform = x86_64-apple-darwin15.6.0
arch = x86_64
os = darwin15.6.0
system = x86_64, darwin15.6.0
status = 
major = 3
minor = 4.1
year = 2017
month = 06
day = 30
svn rev = 72865
language = R
version.string = R version 3.4.1 (2017-06-30)
nickname = Single Candle

GUI:
R-GUI 1.70 (7375)

Locale:
en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

Search Path:
.GlobalEnv, tools:RGUI, package:stats, package:graphics,
package:grDevices, package:utils, package:datasets, package:methods,
Autoloads, package:base


From bgunter.4567 at gmail.com  Thu Sep 21 00:23:11 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 20 Sep 2017 15:23:11 -0700
Subject: [R] Network meta-analysis help
In-Reply-To: <CA+8X3fUMsfT0HV__RC_h76GLXjpiGbbSkvDeCbixa1-88P2gYw@mail.gmail.com>
References: <984833616.9272449.1505870300887.ref@mail.yahoo.com>
 <984833616.9272449.1505870300887@mail.yahoo.com>
 <CA+8X3fUMsfT0HV__RC_h76GLXjpiGbbSkvDeCbixa1-88P2gYw@mail.gmail.com>
Message-ID: <CAGxFJbTYsK-YdJDq3riFv_m8pLz9Mw=9PFL16hGZDEW1EJiqNA@mail.gmail.com>

No "clear guidelines" ??!!

A google search on "network meta-analysis" produced a whole bunch of hits,
including this:

https://www.ncbi.nlm.nih.gov/pubmed/23674332

While "clear" is undefined (what is clear to you may be opaque to me), it
is hard for me to believe that none of the search results suit. But be that
as it may, I think your query would be better posted on a statistics list
like stats.stackexchange.com . There someone may be able to help guide you
to appropriate statistical resources. Once you've figured out the concepts,
you should have a much easier time with the relevant R package(s).


Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Sep 20, 2017 at 3:11 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Sherief,
> First thing is your data set did not make it  If it is not too large,
> perhaps you could send the output of "dput" in the body of the message
> or send a CSV file with the extension changed to ".txt". If the data
> set is very large, perhaps you could send a subset as described above.
>
> Jim
>
>
> On Wed, Sep 20, 2017 at 11:18 AM, Sherief Ghozy via R-help
> <r-help at r-project.org> wrote:
> > Greetings. I hope my message finds you well.
> >
> > I know this question may be silly for some experts like you but it's a
> very important matter for me so, sorry for that.
> >
> > I was trying to make a network meta-analysis using R for the attached
> data set which shows the association between breast feeding and autism
> spectrum disorder (the event here is bad).
> >
> > I've searched a lot through the internet but no clear guidelines on how
> to do network meta-analysis and produce the related figures (Forest plot,
> Network plot, Heat map .... ect).
> >
> > I've installed "netmeta" pack successfully.
> >
> > Can you help me in this matter ? or even guide me where to find help ?
> >
> > I really need to finish this analysis.
> >
> > Sorry for any inconvenience.
> >
> > Thanks in advance.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Sep 21 01:39:14 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Sep 2017 16:39:14 -0700
Subject: [R] Keep on getting message errors when trying to install and
	load packages 2
In-Reply-To: <CAMOcQfOBBS7ChGs0RCpipqvdu_2n9Xjdy9inGmv4QDw3CqFJQw@mail.gmail.com>
References: <CAMOcQfOBBS7ChGs0RCpipqvdu_2n9Xjdy9inGmv4QDw3CqFJQw@mail.gmail.com>
Message-ID: <E2934108-4CCB-49BA-AE3F-B6820BE9AC2B@comcast.net>


> On Sep 20, 2017, at 7:26 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear all,
> 
> Is it normal for R to store installed packages in paths like the following?
> 
> C:\Users\PaulBernal\AppData\Local\Temp\RtmpgXA5VS\downloaded_packages

Yes. Packages are first built or unpacked in a temporary directory and then moved to their "final resting place", assuming that yours has the needed permissions.

This is all explained in the R Admin/Install document which is part of every distribution these days:

On my machine it's here:

http://localhost:30946/doc/manual/R-admin.html#Running-R

> 
> Regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From thierry.onkelinx at inbo.be  Thu Sep 21 09:22:30 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 21 Sep 2017 09:22:30 +0200
Subject: [R] Keep on getting message errors when trying to install and
 load packages
In-Reply-To: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
References: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
Message-ID: <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>

Dear Paul,

Maybe some of the packages were installed by a user with admin rights
and you are installing them with a user how has no admin rights. Thus
you have no rights to remove the files created by the admin user.

We made clear to our IT departement that they only may install R and
not additional packages. We also tell them to set the environment
variable R_LIBS_USER to C:/R/library and make sure that the user has
full rights to that folder. All user installed packages will go in
that folder. A side effect is that all packages remain available after
an upgrade of R.

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-20 16:16 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
> Dear R friends,
>
> I am currently using Windows 8, 64-bit operating system, x64-based
> processor. I have installed R version 3.4.1 "Single Candle".
>
> Also, I have several packages installed in this path:
>
> C:\Users\PaulBernal\Documents\R\win-library\3.4
>
> Plus some other packages installed in this other path:
>
> C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
> C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW
>
>
> And I have installed R in the following path:
>
> C:\Program Files\R\R-3.4.1
>
> Whenever I try to install an R package the following error messages are
> displayed in the R console:
>
>> utils:::menuInstallLocal()
> package ?readstata13? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f747105765\readstata13?
> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>
>> utils:::menuInstallLocal()
> package ?Hmisc? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc? to
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>
> package ?readr? successfully unpacked and MD5 sums checked
> package ?hms? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms? to
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
> package ?Hmisc? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc? to
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
> package ?haven? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven? to
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
> package ?readstata13? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f741507f27\readstata13?
> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
> package ?readxl? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74271b1a7a\readxl?
> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
> package ?RcmdrMisc? successfully unpacked and MD5 sums checked
> Warning: unable to move temporary installation
> ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7419e243c1\RcmdrMisc?
> to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?
>
> Do I have to put all the packages in the same path where I installed R?
> Could this be happening because I have packages installed in several
> folders with several paths? Should I consolidate and put all packages in a
> single location?
>
> Any help will be greatly appreciated,
>
> Cheers,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leslie.rutkowski at gmail.com  Thu Sep 21 10:41:49 2017
From: leslie.rutkowski at gmail.com (Leslie Rutkowski)
Date: Thu, 21 Sep 2017 10:41:49 +0200
Subject: [R] Keep on getting message errors when trying to install and
 load packages
In-Reply-To: <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>
References: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
 <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>
Message-ID: <CAA0F9kUPrQmUvfboSXo-iPD-L=p54FsWC7s8Vexfum5kV+P6cg@mail.gmail.com>

Hi Paul,

I recently ran into file path conflicts and found the following useful
(looks like you already know the answer to 1.):

1.       Use .libPaths() to find where packages are being stored.

2.       To change this path: Control Panel > search ?View advanced system
settings? > Environment Variables *button *>

a.       *Edit* current R_LIBS_USER to new file path

b.      *New* R_LIBS_USER with desired file path

3.       Restart machine.

Good luck!

Leslie

On Thu, Sep 21, 2017 at 9:22 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear Paul,
>
> Maybe some of the packages were installed by a user with admin rights
> and you are installing them with a user how has no admin rights. Thus
> you have no rights to remove the files created by the admin user.
>
> We made clear to our IT departement that they only may install R and
> not additional packages. We also tell them to set the environment
> variable R_LIBS_USER to C:/R/library and make sure that the user has
> full rights to that folder. All user installed packages will go in
> that folder. A side effect is that all packages remain available after
> an upgrade of R.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus/ Statiscian
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
> Brussel.
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
> 2017-09-20 16:16 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
> > Dear R friends,
> >
> > I am currently using Windows 8, 64-bit operating system, x64-based
> > processor. I have installed R version 3.4.1 "Single Candle".
> >
> > Also, I have several packages installed in this path:
> >
> > C:\Users\PaulBernal\Documents\R\win-library\3.4
> >
> > Plus some other packages installed in this other path:
> >
> > C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
> > C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW
> >
> >
> > And I have installed R in the following path:
> >
> > C:\Program Files\R\R-3.4.1
> >
> > Whenever I try to install an R package the following error messages are
> > displayed in the R console:
> >
> >> utils:::menuInstallLocal()
> > package ?readstata13? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
> file2f747105765\readstata13?
> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
> >
> >> utils:::menuInstallLocal()
> > package ?Hmisc? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc?
> to
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
> >
> > package ?readr? successfully unpacked and MD5 sums checked
> > package ?hms? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms?
> to
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
> > package ?Hmisc? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc?
> to
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
> > package ?haven? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven?
> to
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
> > package ?readstata13? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
> file2f741507f27\readstata13?
> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
> > package ?readxl? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
> file2f74271b1a7a\readxl?
> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
> > package ?RcmdrMisc? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation
> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\
> file2f7419e243c1\RcmdrMisc?
> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?
> >
> > Do I have to put all the packages in the same path where I installed R?
> > Could this be happening because I have packages installed in several
> > folders with several paths? Should I consolidate and put all packages in
> a
> > single location?
> >
> > Any help will be greatly appreciated,
> >
> > Cheers,
> >
> > Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Thu Sep 21 15:02:46 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 21 Sep 2017 09:02:46 -0400
Subject: [R] Add wrapper to Shiny in R package
Message-ID: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>

Dear List,

I'm trying to add a function that calls a Shiny App in my R package. The
issue is that within my function, I'm creating objects that I'd like to
pass to the app. For instance, from the example below, I'm getting
"Error: object
'xs' not found". How can I pass "xs" explicitly to shinyApp()?


*Under R directory:*

myApp <- function(x, ...) {
  require(shiny)

  xs <- scale(x)

  shiny::runApp(appDir = system.file("application", package =
"my_package"), ...)

}

*Under inst/application directory a file named app.R with the following
content:*

shinyApp(
  ui = fluidPage(
    sidebarLayout(
      sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
      mainPanel(plotOutput("hist"))
    )
  ),
  server = function(input, output) {
    output$hist <- renderPlot(
      hist(xs, breaks = input$n,
           col = "skyblue", border = "white")
    )
  }
)

Thank you,
Axel.

	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Thu Sep 21 15:08:30 2017
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 21 Sep 2017 08:08:30 -0500
Subject: [R] Keep on getting message errors when trying to install and
 load packages
In-Reply-To: <CAA0F9kUPrQmUvfboSXo-iPD-L=p54FsWC7s8Vexfum5kV+P6cg@mail.gmail.com>
References: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
 <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>
 <CAA0F9kUPrQmUvfboSXo-iPD-L=p54FsWC7s8Vexfum5kV+P6cg@mail.gmail.com>
Message-ID: <CAMOcQfMCC-eN86Q4Sh5pus=9bhJ2e0dDa7=Y+74hf1tOGQ+O3g@mail.gmail.com>

Dear Leslie and Thierry,

Thank you so much for your kind and extremely valuable replies. Only one
doubt remains, which path do you think is the best option to store
downloaded packages? Should I set it up so that all installed packages are
in the same folder (path) that I installed R? Or can I simply set it up so
that all installed packages are stored in a different path?

Again, thank you guys for all your support,

Have an amazing day,

Paul

2017-09-21 3:41 GMT-05:00 Leslie Rutkowski <leslie.rutkowski at gmail.com>:

> Hi Paul,
>
> I recently ran into file path conflicts and found the following useful
> (looks like you already know the answer to 1.):
>
> 1.       Use .libPaths() to find where packages are being stored.
>
> 2.       To change this path: Control Panel > search ?View advanced
> system settings? > Environment Variables *button *>
>
> a.       *Edit* current R_LIBS_USER to new file path
>
> b.      *New* R_LIBS_USER with desired file path
>
> 3.       Restart machine.
>
> Good luck!
>
> Leslie
>
> On Thu, Sep 21, 2017 at 9:22 AM, Thierry Onkelinx <
> thierry.onkelinx at inbo.be> wrote:
>
>> Dear Paul,
>>
>> Maybe some of the packages were installed by a user with admin rights
>> and you are installing them with a user how has no admin rights. Thus
>> you have no rights to remove the files created by the admin user.
>>
>> We made clear to our IT departement that they only may install R and
>> not additional packages. We also tell them to set the environment
>> variable R_LIBS_USER to C:/R/library and make sure that the user has
>> full rights to that folder. All user installed packages will go in
>> that folder. A side effect is that all packages remain available after
>> an upgrade of R.
>>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus/ Statiscian
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Kliniekstraat 25, B-1070 Brussel
>> <https://maps.google.com/?q=Kliniekstraat+25,+B-1070+Brussel&entry=gmail&source=g>
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88
>> <https://maps.google.com/?q=Havenlaan+88&entry=gmail&source=g> bus 73,
>> 1000 Brussel.
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>>
>> 2017-09-20 16:16 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
>> > Dear R friends,
>> >
>> > I am currently using Windows 8, 64-bit operating system, x64-based
>> > processor. I have installed R version 3.4.1 "Single Candle".
>> >
>> > Also, I have several packages installed in this path:
>> >
>> > C:\Users\PaulBernal\Documents\R\win-library\3.4
>> >
>> > Plus some other packages installed in this other path:
>> >
>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW
>> >
>> >
>> > And I have installed R in the following path:
>> >
>> > C:\Program Files\R\R-3.4.1
>> >
>> > Whenever I try to install an R package the following error messages are
>> > displayed in the R console:
>> >
>> >> utils:::menuInstallLocal()
>> > package ?readstata13? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74710
>> 5765\readstata13?
>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>> >
>> >> utils:::menuInstallLocal()
>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc?
>> to
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>> >
>> > package ?readr? successfully unpacked and MD5 sums checked
>> > package ?hms? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms?
>> to
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc?
>> to
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>> > package ?haven? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven?
>> to
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
>> > package ?readstata13? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74150
>> 7f27\readstata13?
>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>> > package ?readxl? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74271
>> b1a7a\readxl?
>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
>> > package ?RcmdrMisc? successfully unpacked and MD5 sums checked
>> > Warning: unable to move temporary installation
>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7419e
>> 243c1\RcmdrMisc?
>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?
>> >
>> > Do I have to put all the packages in the same path where I installed R?
>> > Could this be happening because I have packages installed in several
>> > folders with several paths? Should I consolidate and put all packages
>> in a
>> > single location?
>> >
>> > Any help will be greatly appreciated,
>> >
>> > Cheers,
>> >
>> > Paul
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From ferri.leberl at gmx.at  Thu Sep 21 15:01:23 2017
From: ferri.leberl at gmx.at (Ferri Leberl)
Date: Thu, 21 Sep 2017 15:01:23 +0200
Subject: [R] List of occuring values
Message-ID: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>


Dear all,
ftable produces a list of the frequencies of all occuring values.
But how about the occuring values?
How can I retrieve a list of occuring values?
How can I retrieve a table with both the list of occuring values and their respective frequencies?
Thank you in advance,
Yours, Ferri


From thierry.onkelinx at inbo.be  Thu Sep 21 16:02:38 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 21 Sep 2017 16:02:38 +0200
Subject: [R] Keep on getting message errors when trying to install and
 load packages
In-Reply-To: <CAMOcQfMCC-eN86Q4Sh5pus=9bhJ2e0dDa7=Y+74hf1tOGQ+O3g@mail.gmail.com>
References: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
 <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>
 <CAA0F9kUPrQmUvfboSXo-iPD-L=p54FsWC7s8Vexfum5kV+P6cg@mail.gmail.com>
 <CAMOcQfMCC-eN86Q4Sh5pus=9bhJ2e0dDa7=Y+74hf1tOGQ+O3g@mail.gmail.com>
Message-ID: <CAJuCY5wN+PXxWqbecGGZEfs_+TcJm-nqLf_zTgDWgq=YfB2Ctw@mail.gmail.com>

Dear Paul,

We install R in C:/R/R-x.y.z and packages in C:/R/library. This makes
the packages location independent from the R version.

Best regards,

ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-21 15:08 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
> Dear Leslie and Thierry,
>
> Thank you so much for your kind and extremely valuable replies. Only one
> doubt remains, which path do you think is the best option to store
> downloaded packages? Should I set it up so that all installed packages are
> in the same folder (path) that I installed R? Or can I simply set it up so
> that all installed packages are stored in a different path?
>
> Again, thank you guys for all your support,
>
> Have an amazing day,
>
> Paul
>
> 2017-09-21 3:41 GMT-05:00 Leslie Rutkowski <leslie.rutkowski at gmail.com>:
>>
>> Hi Paul,
>>
>> I recently ran into file path conflicts and found the following useful
>> (looks like you already know the answer to 1.):
>>
>> 1.       Use .libPaths() to find where packages are being stored.
>>
>> 2.       To change this path: Control Panel > search ?View advanced system
>> settings? > Environment Variables button >
>>
>> a.       Edit current R_LIBS_USER to new file path
>>
>> b.      New R_LIBS_USER with desired file path
>>
>> 3.       Restart machine.
>>
>> Good luck!
>>
>> Leslie
>>
>>
>> On Thu, Sep 21, 2017 at 9:22 AM, Thierry Onkelinx
>> <thierry.onkelinx at inbo.be> wrote:
>>>
>>> Dear Paul,
>>>
>>> Maybe some of the packages were installed by a user with admin rights
>>> and you are installing them with a user how has no admin rights. Thus
>>> you have no rights to remove the files created by the admin user.
>>>
>>> We made clear to our IT departement that they only may install R and
>>> not additional packages. We also tell them to set the environment
>>> variable R_LIBS_USER to C:/R/library and make sure that the user has
>>> full rights to that folder. All user installed packages will go in
>>> that folder. A side effect is that all packages remain available after
>>> an upgrade of R.
>>>
>>> Best regards,
>>>
>>> ir. Thierry Onkelinx
>>> Statisticus/ Statiscian
>>>
>>> Vlaamse Overheid / Government of Flanders
>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>>> AND FOREST
>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>>> thierry.onkelinx at inbo.be
>>> Kliniekstraat 25, B-1070 Brussel
>>> www.inbo.be
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>> To call in the statistician after the experiment is done may be no
>>> more than asking him to perform a post-mortem examination: he may be
>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>> The plural of anecdote is not data. ~ Roger Brinner
>>> The combination of some data and an aching desire for an answer does
>>> not ensure that a reasonable answer can be extracted from a given body
>>> of data. ~ John Tukey
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>>
>>> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>>> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>>> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
>>> Brussel.
>>>
>>>
>>> ///////////////////////////////////////////////////////////////////////////////////////////
>>>
>>>
>>>
>>> 2017-09-20 16:16 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
>>> > Dear R friends,
>>> >
>>> > I am currently using Windows 8, 64-bit operating system, x64-based
>>> > processor. I have installed R version 3.4.1 "Single Candle".
>>> >
>>> > Also, I have several packages installed in this path:
>>> >
>>> > C:\Users\PaulBernal\Documents\R\win-library\3.4
>>> >
>>> > Plus some other packages installed in this other path:
>>> >
>>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
>>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW
>>> >
>>> >
>>> > And I have installed R in the following path:
>>> >
>>> > C:\Program Files\R\R-3.4.1
>>> >
>>> > Whenever I try to install an R package the following error messages are
>>> > displayed in the R console:
>>> >
>>> >> utils:::menuInstallLocal()
>>> > package ?readstata13? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f747105765\readstata13?
>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>>> >
>>> >> utils:::menuInstallLocal()
>>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc? to
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>>> >
>>> > package ?readr? successfully unpacked and MD5 sums checked
>>> > package ?hms? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms?
>>> > to
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
>>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc? to
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>>> > package ?haven? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven? to
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
>>> > package ?readstata13? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f741507f27\readstata13?
>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>>> > package ?readxl? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74271b1a7a\readxl?
>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
>>> > package ?RcmdrMisc? successfully unpacked and MD5 sums checked
>>> > Warning: unable to move temporary installation
>>> >
>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7419e243c1\RcmdrMisc?
>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?
>>> >
>>> > Do I have to put all the packages in the same path where I installed R?
>>> > Could this be happening because I have packages installed in several
>>> > folders with several paths? Should I consolidate and put all packages
>>> > in a
>>> > single location?
>>> >
>>> > Any help will be greatly appreciated,
>>> >
>>> > Cheers,
>>> >
>>> > Paul
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From dcarlson at tamu.edu  Thu Sep 21 16:08:22 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 21 Sep 2017 14:08:22 +0000
Subject: [R] List of occuring values
In-Reply-To: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
References: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
Message-ID: <0ae9fb42241249a680a2b1920fb3fa49@exch-2p-mbx-w2.ads.tamu.edu>

Your question does not make sense. Show us what you have tried. If you cannot include part of the data you are using, try the Titanic data set included with R:

> data(Titanic)
> str(Titanic)
 table [1:4, 1:2, 1:2, 1:2] 0 0 35 0 0 0 17 0 118 154 ...
 - attr(*, "dimnames")=List of 4
  ..$ Class   : chr [1:4] "1st" "2nd" "3rd" "Crew"
  ..$ Sex     : chr [1:2] "Male" "Female"
  ..$ Age     : chr [1:2] "Child" "Adult"
  ..$ Survived: chr [1:2] "No" "Yes"
> ftable(Titanic, row.vars=c(1, 4), colvars=c(2, 3))
               Sex  Male       Female      
               Age Child Adult  Child Adult
Class Survived                             
1st   No               0   118      0     4
      Yes              5    57      1   140
2nd   No               0   154      0    13
      Yes             11    14     13    80
3rd   No              35   387     17    89
      Yes             13    75     14    76
Crew  No               0   670      0     3
      Yes              0   192      0    20

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ferri Leberl
Sent: Thursday, September 21, 2017 8:01 AM
To: r-help at r-project.org
Subject: [R] List of occuring values


Dear all,
ftable produces a list of the frequencies of all occuring values.
But how about the occuring values?
How can I retrieve a list of occuring values?
How can I retrieve a table with both the list of occuring values and their respective frequencies?
Thank you in advance,
Yours, Ferri

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Sep 21 16:38:32 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 Sep 2017 07:38:32 -0700
Subject: [R] List of occuring values
In-Reply-To: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
References: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
Message-ID: <CAF8bMcZWViEc55313v7i+W65J0BR=9L8brJSR3m=ZqptWDnK9w@mail.gmail.com>

unique(x) will give you the distinct values in x.  table(x) will give you
the distrinct values and their frequencies as an array with dimnames.
 data.frame(table(x)) will give you a 2-column data.frame with the distinct
values and their frequencies.

> values <- c("Small", "Large", "Large", "Large")
> unique(values)
[1] "Small" "Large"
> tblValues <- table(values)
> tblValues
values
Large Small
    3     1
> tblValues[tblValues > 2, drop=FALSE]
values
Large
    3
>
> dfValues <- data.frame(tblValues)
> dfValues
  values Freq
1  Large    3
2  Small    1
> subset(dfValues, Freq > 2)
  values Freq
1  Large    3
>
> factorValues <- factor(values,
levels=c("Small","Medium","Large","XLarge"))
> data.frame(table(factorValues))
  factorValues Freq
1        Small    1
2       Medium    0
3        Large    3
4       XLarge    0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 21, 2017 at 6:01 AM, Ferri Leberl <ferri.leberl at gmx.at> wrote:

>
> Dear all,
> ftable produces a list of the frequencies of all occuring values.
> But how about the occuring values?
> How can I retrieve a list of occuring values?
> How can I retrieve a table with both the list of occuring values and their
> respective frequencies?
> Thank you in advance,
> Yours, Ferri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Sep 21 16:56:27 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 21 Sep 2017 07:56:27 -0700
Subject: [R] Keep on getting message errors when trying to install and
	load packages
In-Reply-To: <CAJuCY5wN+PXxWqbecGGZEfs_+TcJm-nqLf_zTgDWgq=YfB2Ctw@mail.gmail.com>
References: <CAMOcQfN8JyK0kcBws+yihdth7GHNghZ+vBAgws9wtKD8z=mZ5Q@mail.gmail.com>
 <CAJuCY5zxDsr6tjdmeZoHhXq4UBj4cg4vcANMEJRWbbWwukAQvQ@mail.gmail.com>
 <CAA0F9kUPrQmUvfboSXo-iPD-L=p54FsWC7s8Vexfum5kV+P6cg@mail.gmail.com>
 <CAMOcQfMCC-eN86Q4Sh5pus=9bhJ2e0dDa7=Y+74hf1tOGQ+O3g@mail.gmail.com>
 <CAJuCY5wN+PXxWqbecGGZEfs_+TcJm-nqLf_zTgDWgq=YfB2Ctw@mail.gmail.com>
Message-ID: <D8C5A84F-2860-4945-994A-CC2194B4027B@dcn.davis.ca.us>

This practice is not portable, as not everyone's default file creation permissions allow others to read those files, so putting them outside your home directory isn't necessarily helpful. It is much better to use the default user library within your home directory as suggested by the R install program.

For clarity, the location where packages are DOWNLOADED is generally unimportant... it is the place where they are INSTALLED that is important. That is,  don't worry about the messages telling you about downloaded files being in temporary directories.

Also note that your USER package library is referred to first in the default .libPaths setup so it really doesn't mattter whether a few packages get installed in the system package library because updates you install without Administrator permissions should end up in your user package library.

I recommend using the default behavior that the setup program offers and not trying to fine tune things, unless you are setting up a special configuration like a remote HPC cluster, in which case you should be reading (and having the background to understand) the R Installation and Administration manual.
-- 
Sent from my phone. Please excuse my brevity.

On September 21, 2017 7:02:38 AM PDT, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>Dear Paul,
>
>We install R in C:/R/R-x.y.z and packages in C:/R/library. This makes
>the packages location independent from the R version.
>
>Best regards,
>
>ir. Thierry Onkelinx
>Statisticus/ Statiscian
>
>Vlaamse Overheid / Government of Flanders
>INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>AND FOREST
>Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>thierry.onkelinx at inbo.be
>Kliniekstraat 25, B-1070 Brussel
>www.inbo.be
>
>///////////////////////////////////////////////////////////////////////////////////////////
>To call in the statistician after the experiment is done may be no
>more than asking him to perform a post-mortem examination: he may be
>able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner
>The combination of some data and an aching desire for an answer does
>not ensure that a reasonable answer can be extracted from a given body
>of data. ~ John Tukey
>///////////////////////////////////////////////////////////////////////////////////////////
>
>
>Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
>Brussel.
>
>///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>2017-09-21 15:08 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
>> Dear Leslie and Thierry,
>>
>> Thank you so much for your kind and extremely valuable replies. Only
>one
>> doubt remains, which path do you think is the best option to store
>> downloaded packages? Should I set it up so that all installed
>packages are
>> in the same folder (path) that I installed R? Or can I simply set it
>up so
>> that all installed packages are stored in a different path?
>>
>> Again, thank you guys for all your support,
>>
>> Have an amazing day,
>>
>> Paul
>>
>> 2017-09-21 3:41 GMT-05:00 Leslie Rutkowski
><leslie.rutkowski at gmail.com>:
>>>
>>> Hi Paul,
>>>
>>> I recently ran into file path conflicts and found the following
>useful
>>> (looks like you already know the answer to 1.):
>>>
>>> 1.       Use .libPaths() to find where packages are being stored.
>>>
>>> 2.       To change this path: Control Panel > search ?View advanced
>system
>>> settings? > Environment Variables button >
>>>
>>> a.       Edit current R_LIBS_USER to new file path
>>>
>>> b.      New R_LIBS_USER with desired file path
>>>
>>> 3.       Restart machine.
>>>
>>> Good luck!
>>>
>>> Leslie
>>>
>>>
>>> On Thu, Sep 21, 2017 at 9:22 AM, Thierry Onkelinx
>>> <thierry.onkelinx at inbo.be> wrote:
>>>>
>>>> Dear Paul,
>>>>
>>>> Maybe some of the packages were installed by a user with admin
>rights
>>>> and you are installing them with a user how has no admin rights.
>Thus
>>>> you have no rights to remove the files created by the admin user.
>>>>
>>>> We made clear to our IT departement that they only may install R
>and
>>>> not additional packages. We also tell them to set the environment
>>>> variable R_LIBS_USER to C:/R/library and make sure that the user
>has
>>>> full rights to that folder. All user installed packages will go in
>>>> that folder. A side effect is that all packages remain available
>after
>>>> an upgrade of R.
>>>>
>>>> Best regards,
>>>>
>>>> ir. Thierry Onkelinx
>>>> Statisticus/ Statiscian
>>>>
>>>> Vlaamse Overheid / Government of Flanders
>>>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>NATURE
>>>> AND FOREST
>>>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>Assurance
>>>> thierry.onkelinx at inbo.be
>>>> Kliniekstraat 25, B-1070 Brussel
>>>> www.inbo.be
>>>>
>>>>
>>>>
>///////////////////////////////////////////////////////////////////////////////////////////
>>>> To call in the statistician after the experiment is done may be no
>>>> more than asking him to perform a post-mortem examination: he may
>be
>>>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>>>> The plural of anecdote is not data. ~ Roger Brinner
>>>> The combination of some data and an aching desire for an answer
>does
>>>> not ensure that a reasonable answer can be extracted from a given
>body
>>>> of data. ~ John Tukey
>>>>
>>>>
>///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>
>>>> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging
>in
>>>> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>>>> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73,
>1000
>>>> Brussel.
>>>>
>>>>
>>>>
>///////////////////////////////////////////////////////////////////////////////////////////
>>>>
>>>>
>>>>
>>>> 2017-09-20 16:16 GMT+02:00 Paul Bernal <paulbernal07 at gmail.com>:
>>>> > Dear R friends,
>>>> >
>>>> > I am currently using Windows 8, 64-bit operating system,
>x64-based
>>>> > processor. I have installed R version 3.4.1 "Single Candle".
>>>> >
>>>> > Also, I have several packages installed in this path:
>>>> >
>>>> > C:\Users\PaulBernal\Documents\R\win-library\3.4
>>>> >
>>>> > Plus some other packages installed in this other path:
>>>> >
>>>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\R Books
>>>> > C:\Users\PaulBernal\Desktop\DESTOP FILES\RPackagesNEW
>>>> >
>>>> >
>>>> > And I have installed R in the following path:
>>>> >
>>>> > C:\Program Files\R\R-3.4.1
>>>> >
>>>> > Whenever I try to install an R package the following error
>messages are
>>>> > displayed in the R console:
>>>> >
>>>> >> utils:::menuInstallLocal()
>>>> > package ?readstata13? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f747105765\readstata13?
>>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>>>> >
>>>> >> utils:::menuInstallLocal()
>>>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f744781797d\Hmisc?
>to
>>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>>>> >
>>>> > package ?readr? successfully unpacked and MD5 sums checked
>>>> > package ?hms? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f742a8422fe\hms?
>>>> > to
>>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\hms?
>>>> > package ?Hmisc? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7456645222\Hmisc?
>to
>>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\Hmisc?
>>>> > package ?haven? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f746f04773d\haven?
>to
>>>> > ?C:\Users\PaulBernal\Documents\R\win-library\3.4\haven?
>>>> > package ?readstata13? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f741507f27\readstata13?
>>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readstata13?
>>>> > package ?readxl? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f74271b1a7a\readxl?
>>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\readxl?
>>>> > package ?RcmdrMisc? successfully unpacked and MD5 sums checked
>>>> > Warning: unable to move temporary installation
>>>> >
>>>> >
>?C:\Users\PaulBernal\Documents\R\win-library\3.4\file2f7419e243c1\RcmdrMisc?
>>>> > to ?C:\Users\PaulBernal\Documents\R\win-library\3.4\RcmdrMisc?
>>>> >
>>>> > Do I have to put all the packages in the same path where I
>installed R?
>>>> > Could this be happening because I have packages installed in
>several
>>>> > folders with several paths? Should I consolidate and put all
>packages
>>>> > in a
>>>> > single location?
>>>> >
>>>> > Any help will be greatly appreciated,
>>>> >
>>>> > Cheers,
>>>> >
>>>> > Paul
>>>> >
>>>> >         [[alternative HTML version deleted]]
>>>> >
>>>> > ______________________________________________
>>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>>> > PLEASE do read the posting guide
>>>> > http://www.R-project.org/posting-guide.html
>>>> > and provide commented, minimal, self-contained, reproducible
>code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Thu Sep 21 17:13:15 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 21 Sep 2017 17:13:15 +0200
Subject: [R] Add wrapper to Shiny in R package
In-Reply-To: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>
References: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>
Message-ID: <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>

Dear Axel,

I've used environment for such problems.

assign("xs", xs, envir = my.env) in the myApp function
get("xs", envir = my.env) in the server function

Best regards,


ir. Thierry Onkelinx
Statisticus/ Statiscian

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
AND FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no
more than asking him to perform a post-mortem examination: he may be
able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does
not ensure that a reasonable answer can be extracted from a given body
of data. ~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.

///////////////////////////////////////////////////////////////////////////////////////////



2017-09-21 15:02 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
> Dear List,
>
> I'm trying to add a function that calls a Shiny App in my R package. The
> issue is that within my function, I'm creating objects that I'd like to
> pass to the app. For instance, from the example below, I'm getting
> "Error: object
> 'xs' not found". How can I pass "xs" explicitly to shinyApp()?
>
>
> *Under R directory:*
>
> myApp <- function(x, ...) {
>   require(shiny)
>
>   xs <- scale(x)
>
>   shiny::runApp(appDir = system.file("application", package =
> "my_package"), ...)
>
> }
>
> *Under inst/application directory a file named app.R with the following
> content:*
>
> shinyApp(
>   ui = fluidPage(
>     sidebarLayout(
>       sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>       mainPanel(plotOutput("hist"))
>     )
>   ),
>   server = function(input, output) {
>     output$hist <- renderPlot(
>       hist(xs, breaks = input$n,
>            col = "skyblue", border = "white")
>     )
>   }
> )
>
> Thank you,
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Sep 21 17:31:34 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 21 Sep 2017 08:31:34 -0700
Subject: [R] Add wrapper to Shiny in R package
In-Reply-To: <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>
References: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>
 <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>
Message-ID: <3E97873B-D032-47BF-BC47-597B8C67B5EA@dcn.davis.ca.us>

... which begs the question... how does the my.env variable get from the myApp function into the server function? 

Perhaps read [1]?

[1] https://shiny.rstudio.com/articles/function.html
-- 
Sent from my phone. Please excuse my brevity.

On September 21, 2017 8:13:15 AM PDT, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
>Dear Axel,
>
>I've used environment for such problems.
>
>assign("xs", xs, envir = my.env) in the myApp function
>get("xs", envir = my.env) in the server function
>
>Best regards,
>
>
>ir. Thierry Onkelinx
>Statisticus/ Statiscian
>
>Vlaamse Overheid / Government of Flanders
>INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>AND FOREST
>Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>thierry.onkelinx at inbo.be
>Kliniekstraat 25, B-1070 Brussel
>www.inbo.be
>
>///////////////////////////////////////////////////////////////////////////////////////////
>To call in the statistician after the experiment is done may be no
>more than asking him to perform a post-mortem examination: he may be
>able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>The plural of anecdote is not data. ~ Roger Brinner
>The combination of some data and an aching desire for an answer does
>not ensure that a reasonable answer can be extracted from a given body
>of data. ~ John Tukey
>///////////////////////////////////////////////////////////////////////////////////////////
>
>
>Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
>Brussel.
>
>///////////////////////////////////////////////////////////////////////////////////////////
>
>
>
>2017-09-21 15:02 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
>> Dear List,
>>
>> I'm trying to add a function that calls a Shiny App in my R package.
>The
>> issue is that within my function, I'm creating objects that I'd like
>to
>> pass to the app. For instance, from the example below, I'm getting
>> "Error: object
>> 'xs' not found". How can I pass "xs" explicitly to shinyApp()?
>>
>>
>> *Under R directory:*
>>
>> myApp <- function(x, ...) {
>>   require(shiny)
>>
>>   xs <- scale(x)
>>
>>   shiny::runApp(appDir = system.file("application", package =
>> "my_package"), ...)
>>
>> }
>>
>> *Under inst/application directory a file named app.R with the
>following
>> content:*
>>
>> shinyApp(
>>   ui = fluidPage(
>>     sidebarLayout(
>>       sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>>       mainPanel(plotOutput("hist"))
>>     )
>>   ),
>>   server = function(input, output) {
>>     output$hist <- renderPlot(
>>       hist(xs, breaks = input$n,
>>            col = "skyblue", border = "white")
>>     )
>>   }
>> )
>>
>> Thank you,
>> Axel.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Thu Sep 21 17:30:47 2017
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 21 Sep 2017 11:30:47 -0400
Subject: [R] Add wrapper to Shiny in R package
In-Reply-To: <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>
References: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>
 <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>
Message-ID: <CAAyVsXKp7F3WGFMTqqnmQ=n=taszWgPJTMbC4bZAPmbajafiMw@mail.gmail.com>

Thank you Thierry. I'm trying to following your suggestion in the example
below, but getting:

Error in get("xs", envir = my.env) : object 'my.env' not found.


library(shiny)
library(shinydashboard)

myApp <- function(x, ...) {

  xs <- scale(x)

  my.env <- new.env()
  assign("xs", xs, envir = my.env)

  shiny::runApp(app)

}

app = shinyApp(

  ui = fluidPage(
    sidebarLayout(
      sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
      mainPanel(plotOutput("hist"))
    )
  ),
  server = function(input, output) {

    get("xs", envir = my.env)

    output$hist <- renderPlot(
      hist(xs, breaks = input$n,
           col = "skyblue", border = "white")
    )
  }
)

myApp(rnorm(100))

Axel.


On Thu, Sep 21, 2017 at 11:13 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> wrote:

> Dear Axel,
>
> I've used environment for such problems.
>
> assign("xs", xs, envir = my.env) in the myApp function
> get("xs", envir = my.env) in the server function
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Statisticus/ Statiscian
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Kliniekstraat 25, B-1070 Brussel
> www.inbo.be
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
> To call in the statistician after the experiment is done may be no
> more than asking him to perform a post-mortem examination: he may be
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does
> not ensure that a reasonable answer can be extracted from a given body
> of data. ~ John Tukey
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
> Brussel.
>
> ////////////////////////////////////////////////////////////
> ///////////////////////////////
>
>
>
> 2017-09-21 15:02 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
> > Dear List,
> >
> > I'm trying to add a function that calls a Shiny App in my R package. The
> > issue is that within my function, I'm creating objects that I'd like to
> > pass to the app. For instance, from the example below, I'm getting
> > "Error: object
> > 'xs' not found". How can I pass "xs" explicitly to shinyApp()?
> >
> >
> > *Under R directory:*
> >
> > myApp <- function(x, ...) {
> >   require(shiny)
> >
> >   xs <- scale(x)
> >
> >   shiny::runApp(appDir = system.file("application", package =
> > "my_package"), ...)
> >
> > }
> >
> > *Under inst/application directory a file named app.R with the following
> > content:*
> >
> > shinyApp(
> >   ui = fluidPage(
> >     sidebarLayout(
> >       sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
> >       mainPanel(plotOutput("hist"))
> >     )
> >   ),
> >   server = function(input, output) {
> >     output$hist <- renderPlot(
> >       hist(xs, breaks = input$n,
> >            col = "skyblue", border = "white")
> >     )
> >   }
> > )
> >
> > Thank you,
> > Axel.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep 21 18:12:03 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 21 Sep 2017 12:12:03 -0400
Subject: [R] Add wrapper to Shiny in R package
In-Reply-To: <CAAyVsXKp7F3WGFMTqqnmQ=n=taszWgPJTMbC4bZAPmbajafiMw@mail.gmail.com>
References: <CAAyVsX+U60wesxUtqppmX7V8ssjeDNZr=qjUuXY0Q4T6KGxyzQ@mail.gmail.com>
 <CAJuCY5ytHG8ohoFchW9dTtz5e6EQLzwAYa14rXoZCqYH0fiwwg@mail.gmail.com>
 <CAAyVsXKp7F3WGFMTqqnmQ=n=taszWgPJTMbC4bZAPmbajafiMw@mail.gmail.com>
Message-ID: <f967f201-7017-1763-1899-3d4528e55314@gmail.com>

On 21/09/2017 11:30 AM, Axel Urbiz wrote:
> Thank you Thierry. I'm trying to following your suggestion in the example
> below, but getting:
> 
> Error in get("xs", envir = my.env) : object 'my.env' not found.
> 
> 
> library(shiny)
> library(shinydashboard)
> 
> myApp <- function(x, ...) {
> 
>    xs <- scale(x)
> 
>    my.env <- new.env()
>    assign("xs", xs, envir = my.env)
> 
>    shiny::runApp(app)
> 
> }

I don't know Shiny's setup very well, but I don't see how the server 
function could see my.env here.  my.env is local to myApp, and the 
server function is defined outside of that.

So you should move my.env to the global environment where the server can 
see it, or define the app within myApp, where its functions can see 
locals for that function.

Duncan Murdoch

> 
> app = shinyApp(
> 
>    ui = fluidPage(
>      sidebarLayout(
>        sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>        mainPanel(plotOutput("hist"))
>      )
>    ),
>    server = function(input, output) {
> 
>      get("xs", envir = my.env)
> 
>      output$hist <- renderPlot(
>        hist(xs, breaks = input$n,
>             col = "skyblue", border = "white")
>      )
>    }
> )
> 
> myApp(rnorm(100))
> 
> Axel.
> 
> 
> On Thu, Sep 21, 2017 at 11:13 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
>> wrote:
> 
>> Dear Axel,
>>
>> I've used environment for such problems.
>>
>> assign("xs", xs, envir = my.env) in the myApp function
>> get("xs", envir = my.env) in the server function
>>
>> Best regards,
>>
>>
>> ir. Thierry Onkelinx
>> Statisticus/ Statiscian
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be
>> Kliniekstraat 25, B-1070 Brussel
>> www.inbo.be
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>> To call in the statistician after the experiment is done may be no
>> more than asking him to perform a post-mortem examination: he may be
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does
>> not ensure that a reasonable answer can be extracted from a given body
>> of data. ~ John Tukey
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>> Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
>> Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
>> Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
>> Brussel.
>>
>> ////////////////////////////////////////////////////////////
>> ///////////////////////////////
>>
>>
>>
>> 2017-09-21 15:02 GMT+02:00 Axel Urbiz <axel.urbiz at gmail.com>:
>>> Dear List,
>>>
>>> I'm trying to add a function that calls a Shiny App in my R package. The
>>> issue is that within my function, I'm creating objects that I'd like to
>>> pass to the app. For instance, from the example below, I'm getting
>>> "Error: object
>>> 'xs' not found". How can I pass "xs" explicitly to shinyApp()?
>>>
>>>
>>> *Under R directory:*
>>>
>>> myApp <- function(x, ...) {
>>>    require(shiny)
>>>
>>>    xs <- scale(x)
>>>
>>>    shiny::runApp(appDir = system.file("application", package =
>>> "my_package"), ...)
>>>
>>> }
>>>
>>> *Under inst/application directory a file named app.R with the following
>>> content:*
>>>
>>> shinyApp(
>>>    ui = fluidPage(
>>>      sidebarLayout(
>>>        sidebarPanel(sliderInput("n", "Bins", 5, 100, 20)),
>>>        mainPanel(plotOutput("hist"))
>>>      )
>>>    ),
>>>    server = function(input, output) {
>>>      output$hist <- renderPlot(
>>>        hist(xs, breaks = input$n,
>>>             col = "skyblue", border = "white")
>>>      )
>>>    }
>>> )
>>>
>>> Thank you,
>>> Axel.
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Thu Sep 21 18:16:49 2017
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 21 Sep 2017 09:16:49 -0700
Subject: [R] List of occuring values
In-Reply-To: <CAF8bMcZWViEc55313v7i+W65J0BR=9L8brJSR3m=ZqptWDnK9w@mail.gmail.com>
References: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
 <CAF8bMcZWViEc55313v7i+W65J0BR=9L8brJSR3m=ZqptWDnK9w@mail.gmail.com>
Message-ID: <CAF8bMcbEmiP7x_JtW4XOLnoPzrrmgqrWro29Z9Vr9vqAC8rKOg@mail.gmail.com>

Note that this data.frame(table(...)) makes a column for each argument to
table(...), plus a column for the frequencies so you can easily deal with
multiway tabulations.

> rawData <- data.frame(
+     sizes = c("Small", "Large", "Large", "Large"),
+     colors = c("Red", "Blue", "Blue", "Red"),
+     condition = c("Good", "Poor", "Poor", "Poor"))
> data.frame(with(rawData, table(sizes, colors, condition)))
  sizes colors condition Freq
1 Large   Blue      Good    0
2 Small   Blue      Good    0
3 Large    Red      Good    0
4 Small    Red      Good    1
5 Large   Blue      Poor    2
6 Small   Blue      Poor    0
7 Large    Red      Poor    1
8 Small    Red      Poor    0
> subset(.Last.value, Freq>0)
  sizes colors condition Freq
4 Small    Red      Good    1
5 Large   Blue      Poor    2
7 Large    Red      Poor    1


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Sep 21, 2017 at 7:38 AM, William Dunlap <wdunlap at tibco.com> wrote:

> unique(x) will give you the distinct values in x.  table(x) will give you
> the distrinct values and their frequencies as an array with dimnames.
>  data.frame(table(x)) will give you a 2-column data.frame with the distinct
> values and their frequencies.
>
> > values <- c("Small", "Large", "Large", "Large")
> > unique(values)
> [1] "Small" "Large"
> > tblValues <- table(values)
> > tblValues
> values
> Large Small
>     3     1
> > tblValues[tblValues > 2, drop=FALSE]
> values
> Large
>     3
> >
> > dfValues <- data.frame(tblValues)
> > dfValues
>   values Freq
> 1  Large    3
> 2  Small    1
> > subset(dfValues, Freq > 2)
>   values Freq
> 1  Large    3
> >
> > factorValues <- factor(values, levels=c("Small","Medium","
> Large","XLarge"))
> > data.frame(table(factorValues))
>   factorValues Freq
> 1        Small    1
> 2       Medium    0
> 3        Large    3
> 4       XLarge    0
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Sep 21, 2017 at 6:01 AM, Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
>>
>> Dear all,
>> ftable produces a list of the frequencies of all occuring values.
>> But how about the occuring values?
>> How can I retrieve a list of occuring values?
>> How can I retrieve a table with both the list of occuring values and
>> their respective frequencies?
>> Thank you in advance,
>> Yours, Ferri
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Sep 21 18:56:26 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 21 Sep 2017 17:56:26 +0100
Subject: [R] rcorr error in R stat
In-Reply-To: <BN3PR0501MB1635E658B5C1B3BEDFBE60D2E7660@BN3PR0501MB1635.namprd05.prod.outlook.com>
References: <BN3PR0501MB16358C249C88BA8412EFB492E7610@BN3PR0501MB1635.namprd05.prod.outlook.com>
 <20170920222104.Horde.xoTawi9yeP7UnIxsevFNWov@mail.sapo.pt>
 <BN3PR0501MB1635E658B5C1B3BEDFBE60D2E7660@BN3PR0501MB1635.namprd05.prod.outlook.com>
Message-ID: <20170921175626.Horde.LKrx9SQSgY80juPYNNAuPl3@mail.sapo.pt>

Hello,

Please keep this on the list, always cc r-help.
One of the files in your attachment is empty:

y <- read.csv(file.choose("GT.csv"))
Error in read.table(file = file, header = header, sep = sep, quote = quote,? :
? no lines available in input

Rui Barradas
?

Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:

> Thank you so much for your input.
>
> I am relatively new to R and I don't understand this "read.csv  
> returns data.frames". Sorry.
>
> This however did not work. "unlist(x) and unlist(y)". I got a series  
> of 43 warnings:
>
> Warning messages:
> 1: In doTryCatch(return(expr), name, parentenv, handler) :
> ? "method" is not a graphical parameter
> 2: In doTryCatch(return(expr), name, parentenv, handler) :
> ? "method" is not a graphical parameter
> .
> .
> .
> .
> .
>
> ? "method" is not a graphical parameter
> 42: In doTryCatch(return(expr), name, parentenv, handler) :
> ? "method" is not a graphical parameter
> 43: In cbind(x, y) :
> ? number of rows of result is not a multiple of vector length (arg 2)
> ?
> Would it help if I send the two csv files to you? I'd really  
> appreciate your help.
>
> Thanking you
> ?
>
> -------------------------
> FROM: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
> SENT: Wednesday, September 20, 2017 5:21:04 PM
> TO: Chaitanya Ganne
> SUBJECT: Re: rcorr error in R stat
>
> Hello,
>
> Maybe I'm completely off, but read.csv returns data.frames, which  
> are lists with a dim attribute.
> Instead of as.vector try unlist(x) and unlist(y).
>
> Note that if 'df' is a data.frame, class(as.vector(df)) returns "data.frame".
>
> Hope this helps,
>
> Rui Barradas
> ?
>
> Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:
>
>> Good afternoon,?
>>
>> I have two variables x and y. I am trying to run a correlation  
>> between them as vectors.?
>> x <- read.csv(file.choose(NPA.csv))
>> y <- read.csv(file.choose(GT.csv))
>> res <- cor(as.vector(x), as.vector(y))
>> round(res, 2)
>> install.packages("Hmisc")
>> library(Hmisc)
>> res2 <- rcorr(as.vector(x), as.vector(y))
>> res2 <- rcorr(as.vector(x), as.vector(y))
>> Error in storage.mode(x) <- "double" :?
>> ?(list) object cannot be coerced to type 'double'
>> ?
>> ---------------------------------------------------
>>
>> In fact I find this is something to do with the way the matrices  
>> are being considered for rcorr to be different from the way the  
>> matrices are being considered for 'cor'. The cor function gave me  
>> this output as mentioned below. However I am using the rcorr  
>> function to build the correlplots later on.
>> ? ? ? ? ? ?
>>
>>
>>   BC_11L_parstriangularis_1 	BC_12L_rostralmiddlefrontal_2  
>> 	BC_20L_fusiform_4 	BC_21L_inferiortemporal_3  
>> 	BC_23L_middletemporal_1 	vw_12L_rostralmiddlefrontal_2  
>> 	vw_19L_inferiorparietal_1
>>   CVLT_T4 	-0.23 	0.13 	-0.01 	-0.24 	-0.14 	0.02 	0.06
>>   CVLT_T5 	-0.28 	0.12 	0.04 	-0.25 	-0.19 	0.15 	0.11
>>   CVLT_Total 	-0.25 	0.07 	0.13 	-0.25 	-0.22 	0.05 	-0.05
>>   CVLT_LDF 	-0.16 	0.04 	0.16 	-0.23 	-0.32 	0.16 	0.01
>>   CVLT_RoF 	-0.12 	0.02 	0.06 	-0.04 	-0.14 	0.16 	-0.06
>>   CVLT_TDR 	-0.11 	0.1 	0.13 	-0.24 	-0.25 	0.25 	-0.06
>>   LM_I 	-0.46 	-0.19 	-0.11 	-0.06 	-0.24 	-0.01 	0.1
>>   LM_II 	-0.35 	0.06 	0.05 	-0.11 	-0.31 	0.22 	0.05
>>   p_REC 	-0.12 	-0.27 	0.36 	-0.19 	-0.09 	-0.17 	-0.21
>>   TF 	-0.01 	-0.01 	-0.21 	-0.2 	-0.27 	-0.07 	0.06
>>
>> ?
>> Please help.
>>
>> /DR. GANNE CHAITANYA MD, PHD/
>>
>> /PDF?//NEUROLOGY/
>>
>> /TJU,?//PHILADELPHIA, 19107, PA/
>>
>>
>>   The information contained in this transmission contains  
>> privileged and confidential information. It is intended only for  
>> the use of the person named above. If you are not the intended  
>> recipient, you are hereby notified that any review, dissemination,  
>> distribution or duplication of this communication is strictly  
>> prohibited. If you are not the intended recipient, please contact  
>> the sender by reply email and destroy all copies of the original  
>> message.
>>
>> _CAUTION_: Intended recipients should NOT use email communication  
>> for emergent or urgent health care matters.
>
> ?

?

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Sep 21 19:21:22 2017
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 21 Sep 2017 18:21:22 +0100
Subject: [R] rcorr error in R stat
In-Reply-To: <20170921175626.Horde.LKrx9SQSgY80juPYNNAuPl3@mail.sapo.pt>
References: <BN3PR0501MB16358C249C88BA8412EFB492E7610@BN3PR0501MB1635.namprd05.prod.outlook.com>
 <20170920222104.Horde.xoTawi9yeP7UnIxsevFNWov@mail.sapo.pt>
 <BN3PR0501MB1635E658B5C1B3BEDFBE60D2E7660@BN3PR0501MB1635.namprd05.prod.outlook.com>
 <20170921175626.Horde.LKrx9SQSgY80juPYNNAuPl3@mail.sapo.pt>
Message-ID: <20170921182122.Horde.2JU85K0nWljXSu2u8uTvTbl@mail.sapo.pt>

Hello,

Also, the other file, NPA.csv, is not in tabular form. Can you please  
reformat it?

Rui Barradas


Citando ruipbarradas at sapo.pt:
> Hello,
>
> Please keep this on the list, always cc r-help.
> One of the files in your attachment is empty:
>
> y <- read.csv(file.choose("GT.csv"))
> Error in read.table(file = file, header = header, sep = sep, quote =  
> quote,? :
> ? no lines available in input
>
> Rui Barradas
> ?
>
> Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:
>
>> Thank you so much for your input.
>>
>> I am relatively new to R and I don't understand this "read.csv
>> returns data.frames". Sorry.
>>
>> This however did not work. "unlist(x) and unlist(y)". I got a series
>> of 43 warnings:
>>
>> Warning messages:
>> 1: In doTryCatch(return(expr), name, parentenv, handler) :
>> ? "method" is not a graphical parameter
>> 2: In doTryCatch(return(expr), name, parentenv, handler) :
>> ? "method" is not a graphical parameter
>> .
>> .
>> .
>> .
>> .
>>
>> ? "method" is not a graphical parameter
>> 42: In doTryCatch(return(expr), name, parentenv, handler) :
>> ? "method" is not a graphical parameter
>> 43: In cbind(x, y) :
>> ? number of rows of result is not a multiple of vector length (arg 2)
>> ?
>> Would it help if I send the two csv files to you? I'd really
>> appreciate your help.
>>
>> Thanking you
>> ?
>>
>> -------------------------
>> FROM: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
>> SENT: Wednesday, September 20, 2017 5:21:04 PM
>> TO: Chaitanya Ganne
>> SUBJECT: Re: rcorr error in R stat
>>
>> Hello,
>>
>> Maybe I'm completely off, but read.csv returns data.frames, which
>> are lists with a dim attribute.
>> Instead of as.vector try unlist(x) and unlist(y).
>>
>> Note that if 'df' is a data.frame, class(as.vector(df)) returns  
>> "data.frame".
>>
>> Hope this helps,
>>
>> Rui Barradas
>> ?
>>
>> Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:
>>
>>> Good afternoon,?
>>>
>>> I have two variables x and y. I am trying to run a correlation
>>> between them as vectors.?
>>> x <- read.csv(file.choose(NPA.csv))
>>> y <- read.csv(file.choose(GT.csv))
>>> res <- cor(as.vector(x), as.vector(y))
>>> round(res, 2)
>>> install.packages("Hmisc")
>>> library(Hmisc)
>>> res2 <- rcorr(as.vector(x), as.vector(y))
>>> res2 <- rcorr(as.vector(x), as.vector(y))
>>> Error in storage.mode(x) <- "double" :?
>>> ?(list) object cannot be coerced to type 'double'
>>> ?
>>> ---------------------------------------------------
>>>
>>> In fact I find this is something to do with the way the matrices
>>> are being considered for rcorr to be different from the way the
>>> matrices are being considered for 'cor'. The cor function gave me
>>> this output as mentioned below. However I am using the rcorr
>>> function to build the correlplots later on.
>>> ? ? ? ? ? ?
>>>
>>>
>>>   BC_11L_parstriangularis_1 	BC_12L_rostralmiddlefrontal_2
>>> 	BC_20L_fusiform_4 	BC_21L_inferiortemporal_3
>>> 	BC_23L_middletemporal_1 	vw_12L_rostralmiddlefrontal_2
>>> 	vw_19L_inferiorparietal_1
>>>   CVLT_T4 	-0.23 	0.13 	-0.01 	-0.24 	-0.14 	0.02 	0.06
>>>   CVLT_T5 	-0.28 	0.12 	0.04 	-0.25 	-0.19 	0.15 	0.11
>>>   CVLT_Total 	-0.25 	0.07 	0.13 	-0.25 	-0.22 	0.05 	-0.05
>>>   CVLT_LDF 	-0.16 	0.04 	0.16 	-0.23 	-0.32 	0.16 	0.01
>>>   CVLT_RoF 	-0.12 	0.02 	0.06 	-0.04 	-0.14 	0.16 	-0.06
>>>   CVLT_TDR 	-0.11 	0.1 	0.13 	-0.24 	-0.25 	0.25 	-0.06
>>>   LM_I 	-0.46 	-0.19 	-0.11 	-0.06 	-0.24 	-0.01 	0.1
>>>   LM_II 	-0.35 	0.06 	0.05 	-0.11 	-0.31 	0.22 	0.05
>>>   p_REC 	-0.12 	-0.27 	0.36 	-0.19 	-0.09 	-0.17 	-0.21
>>>   TF 	-0.01 	-0.01 	-0.21 	-0.2 	-0.27 	-0.07 	0.06
>>>
>>> ?
>>> Please help.
>>>
>>> /DR. GANNE CHAITANYA MD, PHD/
>>>
>>> /PDF?//NEUROLOGY/
>>>
>>> /TJU,?//PHILADELPHIA, 19107, PA/
>>>
>>>
>>>   The information contained in this transmission contains
>>> privileged and confidential information. It is intended only for
>>> the use of the person named above. If you are not the intended
>>> recipient, you are hereby notified that any review, dissemination,
>>> distribution or duplication of this communication is strictly
>>> prohibited. If you are not the intended recipient, please contact
>>> the sender by reply email and destroy all copies of the original
>>> message.
>>>
>>> _CAUTION_: Intended recipients should NOT use email communication
>>> for emergent or urgent health care matters.
>>
>> ?
>
> ?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Sep 22 00:05:22 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 22 Sep 2017 08:05:22 +1000
Subject: [R] List of occuring values
In-Reply-To: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
References: <trinity-5a6447af-3a31-4b0c-88d1-0d7da705991e-1505998883548@3c-app-gmx-bs68>
Message-ID: <CA+8X3fXo23v5br4=e75TYJmPaccgC5mT_WBWi=w5=npcqqMx+g@mail.gmail.com>

Hi Ferri,
Do you mean getting something like the vector of original values back?

boodat<-sample(LETTERS[1:4],100,TRUE)
bootab<-table(boodat)
untab<-function(x) {
 lenx<-length(x)
 newx<-NULL
 for(i in 1:lenx) newx<-c(newx,rep(names(x)[i],x[i]))
 return(newx)
}
untab(bootab)

Jim

On Thu, Sep 21, 2017 at 11:01 PM, Ferri Leberl <ferri.leberl at gmx.at> wrote:
>
> Dear all,
> ftable produces a list of the frequencies of all occuring values.
> But how about the occuring values?
> How can I retrieve a list of occuring values?
> How can I retrieve a table with both the list of occuring values and their respective frequencies?
> Thank you in advance,
> Yours, Ferri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Sep 22 02:32:47 2017
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 21 Sep 2017 20:32:47 -0400
Subject: [R] require help
In-Reply-To: <CACdLcRzQB5LoOFFmA-+6uvM6Uy9SCJ8tOqev5exBGCJ4aYvP7Q@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
 <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>
 <CACdLcRzQB5LoOFFmA-+6uvM6Uy9SCJ8tOqev5exBGCJ4aYvP7Q@mail.gmail.com>
Message-ID: <CAP01uRkFag6hkDkT7y=Fn4u6Lm5QJdve2ONoP6P8LZL_yCGzgw@mail.gmail.com>

Assuming the input data.frame, DF, is of the form  shown reproducibly
in the Note below, to convert the series to zoo or ts:

library(zoo)

# convert to zoo
z <- read.zoo(DF)

# convert to ts
as.ts(z) #


Note:

DF <- structure(list(year = c(1980, 1981, 1982, 1983, 1984), cnsm = c(174,
175, 175, 172, 173), incm = c(53.4, 53.7, 53.5, 53.2, 53.3),
    with = c(60.3, 60.5, 60.2, 60.1, 60.7)), .Names = c("year",
"cnsm", "incm", "with"), row.names = c(NA, -5L), class = "data.frame")


On Sat, Sep 16, 2017 at 8:10 AM, yadav neog <yadavneog at gmail.com> wrote:
> oky.. thank you very much to all of you
>
>
> On Sat, Sep 16, 2017 at 2:06 PM, Eric Berger <ericjberger at gmail.com> wrote:
>
>> You can just use the same code that I provided before but now use your
>> dataset. Like this
>>
>> df <- read.csv(file="data2.csv",header=TRUE)
>> dates <- as.Date(paste(df$year,"-01-01",sep=""))
>> myXts <- xts(df,order.by=dates)
>> head(myXts)
>>
>> #The last command "head(myXts)" shows you the first few rows of the xts
>> object
>>            year     cnsm    incm    wlth
>> 1980-01-01 1980 173.6527 53.3635 60.3013
>> 1981-01-01 1981 175.4613 53.6929 60.4980
>> 1982-01-01 1982 174.5724 53.4890 60.2358
>> 1983-01-01 1983 171.5070 53.2223 60.1047
>> 1984-01-01 1984 173.3462 53.2851 60.6946
>> 1985-01-01 1985 171.7075 53.1596 60.7598
>>
>>
>> On Sat, Sep 16, 2017 at 9:55 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>
>>>
>>> > On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
>>> >
>>> > hello to all. I am working on macroeconomic data series of India, which
>>> in
>>> > a yearly basis. I am unable to convert my data frame into time series.
>>> > kindly help me.
>>> > also using zoo and xts packages. but they take only monthly
>>> observations.
>>> >
>>> > 'data.frame': 30 obs. of  4 variables:
>>> > $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
>>> > $ cnsm: num  174 175 175 172 173 ...
>>> > $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
>>> > $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
>>> > --
>>>
>>> Second try to do what you would like (I hope and think)
>>> Using Eric's sample data
>>>
>>> <code>
>>> zdf <- data.frame(year=2001:2010, cnsm=sample(170:180,10,replace=TRUE),
>>>                  incm=rnorm(10,53,1), wlth=rnorm(10,60,1))
>>> zdf
>>>
>>> # R ts
>>> zts <- ts(zdf[,-1], start=zdf[1,"year"])
>>> zts
>>>
>>> # turn data into a zoo timeseries and an xts timeseries
>>>
>>> library(zoo)
>>> z.zoo <- as.zoo(zts)
>>> z.zoo
>>>
>>> library(xts)
>>> z.xts <- as.xts(zts)
>>> z.xts
>>> </code>
>>>
>>> Berend Hasselman
>>>
>>> > Yadawananda Neog
>>> > Research Scholar
>>> > Department of Economics
>>> > Banaras Hindu University
>>> > Mob. 9838545073
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From upananda.pani at gmail.com  Fri Sep 22 11:45:04 2017
From: upananda.pani at gmail.com (Upananda Pani)
Date: Fri, 22 Sep 2017 15:15:04 +0530
Subject: [R] Treating NA in timeSeries package
Message-ID: <CAEezrQSjJuFWNV5YnwFQ0eid7TD21xT62PX=3gE=nMXxieTj7Q@mail.gmail.com>

Dear All,

I am facing problem with NA treatment in my financial time series data.

# data reading

aluminum = read.csv(file="alu.csv", header=T, sep=",")

fut = aluminum [,2]
spt = aluminum [,3]


# Missing Value Treatment (Linear Interpolation)
spt = interpNA(spt, method = c("linear"))
fut = interpNA(fut, method = c("linear"))


fut=fut[,1]
spt =spt[,1]

spt = interpNA(spt, method = c("linear"))
Error in interpNA(spt, method = c("linear")) : spt is not a tis object
> fut = interpNA(fut, method = c("linear"))
Error in interpNA(fut, method = c("linear")) : fut is not a tis object

Then i want to convert my data into time series as following
# Making Time Series
fut = ts(fut, start=c(2006,4), frequency=305)
spt = ts(spt, start=c(2006,4), frequency=305)

Would you please guide me what is the problem with my code?

With best regards,
Upananda Pani

From upananda.pani at gmail.com  Fri Sep 22 11:53:06 2017
From: upananda.pani at gmail.com (Upananda Pani)
Date: Fri, 22 Sep 2017 15:23:06 +0530
Subject: [R] Convert data into zoo object using Performance analytics
	package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAFA0B@SRVEXCHCM301.precheza.cz>
References: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
 <CAP01uRkiH-5ReU9F=Jhtk3_bEEnqs22ok1cDX97_dhOgUPb_9Q@mail.gmail.com>
 <CAEezrQSeMLpHA_RHz3QEZhqZdPO=RS=Gq22fKdfRLQdZtWvEWQ@mail.gmail.com>
 <CAEezrQT6FA5s9X9zz69sRgoeTENZYTFrhFXFhRM5AcH6Ht1i8g@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAFA0B@SRVEXCHCM301.precheza.cz>
Message-ID: <CAEezrQQR5uV8QrOJqPOYrrOcs4hMwzVER+eYvy5MQOOePobXuQ@mail.gmail.com>

Dear All,

Thanks a lot for your help. Would you please let me know if i want to read
a csv file as zoo object from my local file rather than directly from the
website, how to do that?

library(zoo)
u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
fmt <- "%m/%d/%Y"

With sincere regards,
Upananda Pani

On Wed, Sep 20, 2017 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Gabor's code works as expeceted without error.
> What is "u" in your case?
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Upananda
> > Pani
> > Sent: Wednesday, September 20, 2017 11:06 AM
> > To: Gabor Grothendieck <ggrothendieck at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Convert data into zoo object using Performance analytics
> > package
> >
> > Dear Sir,
> >
> > Thanks for your mail and help. I got this error while trying to run your
> code.
> >
> > sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> > read.table(file = file, header = header, sep = sep, quote = quote,
> >  :
> >   'file' must be a character string or connection
> >
> > Thanks and Regards,
> > Upananda Pani
> >
> > On Tue, Sep 19, 2017 at 4:31 PM, Upananda Pani <upananda.pani at gmail.com>
> > wrote:
> >
> > > Dear Sir,
> > >
> > > Thanks for your mail and help. I got this error while trying to run
> > > your code.
> > >
> > > sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> > > read.table(file = file, header = header, sep = sep, quote = quote,  :
> > >   'file' must be a character string or connection
> > >
> > > Thanks and Regards,
> > > Upananda Pani
> > >
> > > On Mon, Sep 18, 2017 at 7:38 PM, Gabor Grothendieck <
> > > ggrothendieck at gmail.com> wrote:
> > >
> > >> Depending on how you created df maybe your code has the column names
> > >> wrong.  In any case these 4 alternatives all work.  Start a fresh R
> > >> session and then copy and paste this into it.
> > >>
> > >> library(zoo)
> > >> u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
> > >> fmt <- "%m/%d/%Y"
> > >>
> > >> # 1
> > >> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
> > >>
> > >> # 2
> > >> df <- read.csv(u)
> > >> sbux2.z <- read.zoo(df, FUN = as.yearmon, format = fmt)
> > >>
> > >> # 3
> > >> df <- read.csv(u)
> > >> names(head(df))
> > >> ## [1] "Date"      "Adj.Close"
> > >> sbux3.z <- zoo(df$Adj.Close, as.yearmon(df$Date, fmt))
> > >>
> > >> # 4
> > >> df <- read.csv(u)
> > >> sbux4.z <- zoo(df[[2]], as.yearmon(df[[1]], fmt))
> > >>
> > >> On Mon, Sep 18, 2017 at 7:36 AM, Upananda Pani
> > >> <upananda.pani at gmail.com>
> > >> wrote:
> > >> > Dear All,
> > >> >
> > >> > While i am trying convert data frame object to zoo object I am
> > >> > getting numeric(0) error in performance analytics package.
> > >> >
> > >> > The source code i am using from this website to learn r in finance:
> > >> > https://faculty.washington.edu/ezivot/econ424/returnCalculations.r
> > >> >
> > >> > # create zoo objects from data.frame objects dates.sbux =
> > >> > as.yearmon(sbux.df$Date, format="%m/%d/%Y") dates.msft =
> > >> > as.yearmon(msft.df$Date, format="%m/%d/%Y") sbux.z =
> > >> > zoo(x=sbux.df$Adj.Close, order.by=dates.sbux) msft.z =
> > >> > zoo(x=msft.df$Adj.Close, order.by=dates.msft)
> > >> > class(sbux.z)
> > >> > head(sbux.z)
> > >> >> head(sbux.z)
> > >> > Data:
> > >> > numeric(0)
> > >> >
> > >> > I will be grateful if anybody would like to guide me where i am
> > >> > making
> > >> the
> > >> > mistake.
> > >> >
> > >> > With best regards,
> > >> > Upananda Pani
> > >> >
> > >> >
> > >> > --
> > >> >
> > >> >
> > >> > You may delay, but time will not.
> > >> >
> > >> >
> > >> > Research Scholar
> > >> > alternative mail id: upani at iitkgp.ac.in Department of HSS, IIT KGP
> > >> > KGP
> > >> >
> > >> >         [[alternative HTML version deleted]]
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide http://www.R-project.org/posti
> > >> ng-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >>
> > >> --
> > >> Statistics & Software Consulting
> > >> GKX Group, GKX Associates Inc.
> > >> tel: 1-877-GKX-GROUP
> > >> email: ggrothendieck at gmail.com
> > >>
> > >
> > >
> > >
> > > --
> > >
> > >
> > > You may delay, but time will not.
> > >
> > >
> > > Research Scholar
> > > alternative mail id: upani at iitkgp.ac.in Department of HSS, IIT KGP KGP
> > >
> >
> >
> >
> > --
> >
> >
> > You may delay, but time will not.
> >
> >
> > Research Scholar
> > alternative mail id: upani at iitkgp.ac.in
> > Department of HSS, IIT KGP
> > KGP
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Sep 22 12:11:54 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 22 Sep 2017 10:11:54 +0000
Subject: [R] Treating NA in timeSeries package
In-Reply-To: <CAEezrQSjJuFWNV5YnwFQ0eid7TD21xT62PX=3gE=nMXxieTj7Q@mail.gmail.com>
References: <CAEezrQSjJuFWNV5YnwFQ0eid7TD21xT62PX=3gE=nMXxieTj7Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB01F3@SRVEXCHCM301.precheza.cz>

Hi

see in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Upananda
> Pani
> Sent: Friday, September 22, 2017 11:45 AM
> To: r-help <r-help at r-project.org>
> Subject: [R] Treating NA in timeSeries package
>
> Dear All,
>
> I am facing problem with NA treatment in my financial time series data.

probably not only with this

>
> # data reading
>
> aluminum = read.csv(file="alu.csv", header=T, sep=",")
>
> fut = aluminum [,2]
> spt = aluminum [,3]
>
here fut and spt are already vectors

> is.vector(iris[,1])
[1] TRUE

>
> # Missing Value Treatment (Linear Interpolation) spt = interpNA(spt, method =
> c("linear")) fut = interpNA(fut, method = c("linear"))
>
>
> fut=fut[,1]
> spt =spt[,1]

so this should give you error similar to this
> iii<-(iris[,1])
> iii[,1]
Error in iii[, 1] : incorrect number of dimensions

>
> spt = interpNA(spt, method = c("linear")) Error in interpNA(spt, method =
> c("linear")) : spt is not a tis object
> > fut = interpNA(fut, method = c("linear"))
> Error in interpNA(fut, method = c("linear")) : fut is not a tis object

here you want to apply function requiring tis object (see documentation  for the function) but fut or spt are only vectors.

>
> Then i want to convert my data into time series as following # Making Time
> Series fut = ts(fut, start=c(2006,4), frequency=305) spt = ts(spt, start=c(2006,4),
> frequency=305)

here you combine start and frequency by weird way. You want to start your time series at April 2006 and you want it to have 305 items which means that it starts at April, 2006 and ends in month 103 in 2006.

> gnp <- ts(cumsum(1 + round(rnorm(100), 2)),  start = c(2006, 4), frequency = 305)
> gnp
Time Series:
Start = c(2006, 4)
End = c(2006, 103)
Frequency = 305
  [1]   1.08   1.17   1.23   1.89   3.70   4.33   4.45   4.88   6.59   6.71
 [11]

All this info I got reading documentation.

>
> Would you please guide me what is the problem with my code?

So my best advice is

?ts
?interpNA
and
reading R-intro.

Cheers
Petr


>
> With best regards,
> Upananda Pani
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Sep 22 12:16:42 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 22 Sep 2017 10:16:42 +0000
Subject: [R] Convert data into zoo object using Performance analytics
 package
In-Reply-To: <CAEezrQQR5uV8QrOJqPOYrrOcs4hMwzVER+eYvy5MQOOePobXuQ@mail.gmail.com>
References: <CAEezrQSaE9DgAThEe0qGo5_sQ8raByOz+MV5qzt5V3rZ4zxOKA@mail.gmail.com>
 <CAP01uRkiH-5ReU9F=Jhtk3_bEEnqs22ok1cDX97_dhOgUPb_9Q@mail.gmail.com>
 <CAEezrQSeMLpHA_RHz3QEZhqZdPO=RS=Gq22fKdfRLQdZtWvEWQ@mail.gmail.com>
 <CAEezrQT6FA5s9X9zz69sRgoeTENZYTFrhFXFhRM5AcH6Ht1i8g@mail.gmail.com>
 <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAAFA0B@SRVEXCHCM301.precheza.cz>
 <CAEezrQQR5uV8QrOJqPOYrrOcs4hMwzVER+eYvy5MQOOePobXuQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB0216@SRVEXCHCM301.precheza.cz>

Hi

From: Upananda Pani [mailto:upananda.pani at gmail.com]
Sent: Friday, September 22, 2017 11:53 AM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: r-help <r-help at r-project.org>; Gabor Grothendieck <ggrothendieck at gmail.com>
Subject: Re: [R] Convert data into zoo object using Performance analytics package

Dear All,

Thanks a lot for your help. Would you please let me know if i want to read a csv file as

No, you probably need to read R basics (R-intro). I had no problem using Gabor?s code version 1 for reading directly. You obviously lack basic understanding how R works with objects.

Cheers
Petr


zoo object from my local file rather than directly from the website, how to do that?

library(zoo)
u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
fmt <- "%m/%d/%Y"

With sincere regards,
Upananda Pani

On Wed, Sep 20, 2017 at 3:22 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Gabor's code works as expeceted without error.
What is "u" in your case?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Upananda
> Pani
> Sent: Wednesday, September 20, 2017 11:06 AM
> To: Gabor Grothendieck <ggrothendieck at gmail.com<mailto:ggrothendieck at gmail.com>>
> Cc: r-help <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Convert data into zoo object using Performance analytics
> package
>
> Dear Sir,
>
> Thanks for your mail and help. I got this error while trying to run your code.
>
> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> read.table(file = file, header = header, sep = sep, quote = quote,
>  :
>   'file' must be a character string or connection
>
> Thanks and Regards,
> Upananda Pani
>
> On Tue, Sep 19, 2017 at 4:31 PM, Upananda Pani <upananda.pani at gmail.com<mailto:upananda.pani at gmail.com>>
> wrote:
>
> > Dear Sir,
> >
> > Thanks for your mail and help. I got this error while trying to run
> > your code.
> >
> > sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt) Error in
> > read.table(file = file, header = header, sep = sep, quote = quote,  :
> >   'file' must be a character string or connection
> >
> > Thanks and Regards,
> > Upananda Pani
> >
> > On Mon, Sep 18, 2017 at 7:38 PM, Gabor Grothendieck <
> > ggrothendieck at gmail.com<mailto:ggrothendieck at gmail.com>> wrote:
> >
> >> Depending on how you created df maybe your code has the column names
> >> wrong.  In any case these 4 alternatives all work.  Start a fresh R
> >> session and then copy and paste this into it.
> >>
> >> library(zoo)
> >> u  <- "https://faculty.washington.edu/ezivot/econ424/sbuxPrices.csv"
> >> fmt <- "%m/%d/%Y"
> >>
> >> # 1
> >> sbux1.z <- read.csv.zoo(u, FUN = as.yearmon, format = fmt)
> >>
> >> # 2
> >> df <- read.csv(u)
> >> sbux2.z <- read.zoo(df, FUN = as.yearmon, format = fmt)
> >>
> >> # 3
> >> df <- read.csv(u)
> >> names(head(df))
> >> ## [1] "Date"      "Adj.Close"
> >> sbux3.z <- zoo(df$Adj.Close, as.yearmon(df$Date, fmt))
> >>
> >> # 4
> >> df <- read.csv(u)
> >> sbux4.z <- zoo(df[[2]], as.yearmon(df[[1]], fmt))
> >>
> >> On Mon, Sep 18, 2017 at 7:36 AM, Upananda Pani
> >> <upananda.pani at gmail.com<mailto:upananda.pani at gmail.com>>
> >> wrote:
> >> > Dear All,
> >> >
> >> > While i am trying convert data frame object to zoo object I am
> >> > getting numeric(0) error in performance analytics package.
> >> >
> >> > The source code i am using from this website to learn r in finance:
> >> > https://faculty.washington.edu/ezivot/econ424/returnCalculations.r
> >> >
> >> > # create zoo objects from data.frame objects dates.sbux =
> >> > as.yearmon(sbux.df$Date, format="%m/%d/%Y") dates.msft =
> >> > as.yearmon(msft.df$Date, format="%m/%d/%Y") sbux.z =
> >> > zoo(x=sbux.df$Adj.Close, order.by<http://order.by>=dates.sbux) msft.z =
> >> > zoo(x=msft.df$Adj.Close, order.by<http://order.by>=dates.msft)
> >> > class(sbux.z)
> >> > head(sbux.z)
> >> >> head(sbux.z)
> >> > Data:
> >> > numeric(0)
> >> >
> >> > I will be grateful if anybody would like to guide me where i am
> >> > making
> >> the
> >> > mistake.
> >> >
> >> > With best regards,
> >> > Upananda Pani
> >> >
> >> >
> >> > --
> >> >
> >> >
> >> > You may delay, but time will not.
> >> >
> >> >
> >> > Research Scholar
> >> > alternative mail id: upani at iitkgp.ac.in<mailto:upani at iitkgp.ac.in> Department of HSS, IIT KGP
> >> > KGP
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Statistics & Software Consulting
> >> GKX Group, GKX Associates Inc.
> >> tel: 1-877-GKX-GROUP
> >> email: ggrothendieck at gmail.com<http://gmail.com>
> >>
> >
> >
> >
> > --
> >
> >
> > You may delay, but time will not.
> >
> >
> > Research Scholar
> > alternative mail id: upani at iitkgp.ac.in<mailto:upani at iitkgp.ac.in> Department of HSS, IIT KGP KGP
> >
>
>
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in<mailto:upani at iitkgp.ac.in>
> Department of HSS, IIT KGP
> KGP
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
________________________________



You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in<mailto:upani at iitkgp.ac.in>
Department of HSS, IIT KGP
KGP

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From marongiu.luigi at gmail.com  Fri Sep 22 13:52:38 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 22 Sep 2017 12:52:38 +0100
Subject: [R] Lattice stacked barplot vertical bars
Message-ID: <CAMk+s2Tc4yT9hce7fGHQz9oXGes4+29QvDNJSmcsUohMD9J9tQ@mail.gmail.com>

Dear all,
I have made a barplot using lattice in which the bars are stacked
horizontally. I would like to stack them vertically, but if I use the
parameter 'horizontal = FALSE' I get the error: 'Error in FUN(X[[i]],
...) : invalid 'type' (character) of argument'. The problem I face is
that, in drawing the bars vertically, the y variable becomes numeric
rather than categorical and vice-versa for the x variable.
How can I solve this issue?
Thank you
Luigi

>>>

A <- c('a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'b', 'c', 'd', 'b', 'c', 'd')
B <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
C <- c(0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1)
D <- c(4, 120, 7, 23, 4, 24, 3, 12, 7, 1, 1, 5, 0, 0)
E <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)
DF <- data.frame(A, B, C, D, E, stringsAsFactors = FALSE)
library(lattice)
barchart(
    A ~ D|E,
    DF,
    groups = C,
    stack = TRUE,
    horizontal = TRUE,
    main = "Comparison of test results",
    xlab = "Count",
    col = c("yellow", "orange"),
    par.settings = list(
        strip.background = list(col="light grey"),
        superpose.polygon=list(col= c("yellow", "orange"))
    ),
    scales = list(
        alternating = FALSE
    ),
    key = list(
        space="top",
        columns=2,
        text=list(c("Single infections", "Multiple infections"), col="black"),
        rectangles=list(col=c("yellow", "orange"))
    ),
    strip = strip.custom(factor.levels = c("Cases","Controls"),
                         strip.levels=TRUE,
                         strip.names=FALSE,
                         par.strip.text = list(cex = 1)
    )
)


From yadavneog at gmail.com  Fri Sep 22 14:28:35 2017
From: yadavneog at gmail.com (yadav neog)
Date: Fri, 22 Sep 2017 17:58:35 +0530
Subject: [R] require help
In-Reply-To: <CAP01uRkFag6hkDkT7y=Fn4u6Lm5QJdve2ONoP6P8LZL_yCGzgw@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
 <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>
 <CACdLcRzQB5LoOFFmA-+6uvM6Uy9SCJ8tOqev5exBGCJ4aYvP7Q@mail.gmail.com>
 <CAP01uRkFag6hkDkT7y=Fn4u6Lm5QJdve2ONoP6P8LZL_yCGzgw@mail.gmail.com>
Message-ID: <CACdLcRzR6Bd4wP3bxUBEA+U54MMSji=ZAy2x_VHnB71D0YyE+Q@mail.gmail.com>

thankx to everyone for your valuable suggestions. one query regarding the
GARCH model.
I have applied the GARCH model for the same data that I send you all . and
my results coming like

Error in .sgarchfit(spec = spec, data = data, out.sample = out.sample,  :

ugarchfit-->error: function requires at least 100 data
 points to run

can you suggest something on it.

On Fri, Sep 22, 2017 at 6:02 AM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> Assuming the input data.frame, DF, is of the form  shown reproducibly
> in the Note below, to convert the series to zoo or ts:
>
> library(zoo)
>
> # convert to zoo
> z <- read.zoo(DF)
>
> # convert to ts
> as.ts(z) #
>
>
> Note:
>
> DF <- structure(list(year = c(1980, 1981, 1982, 1983, 1984), cnsm = c(174,
> 175, 175, 172, 173), incm = c(53.4, 53.7, 53.5, 53.2, 53.3),
>     with = c(60.3, 60.5, 60.2, 60.1, 60.7)), .Names = c("year",
> "cnsm", "incm", "with"), row.names = c(NA, -5L), class = "data.frame")
>
>
> On Sat, Sep 16, 2017 at 8:10 AM, yadav neog <yadavneog at gmail.com> wrote:
> > oky.. thank you very much to all of you
> >
> >
> > On Sat, Sep 16, 2017 at 2:06 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
> >
> >> You can just use the same code that I provided before but now use your
> >> dataset. Like this
> >>
> >> df <- read.csv(file="data2.csv",header=TRUE)
> >> dates <- as.Date(paste(df$year,"-01-01",sep=""))
> >> myXts <- xts(df,order.by=dates)
> >> head(myXts)
> >>
> >> #The last command "head(myXts)" shows you the first few rows of the xts
> >> object
> >>            year     cnsm    incm    wlth
> >> 1980-01-01 1980 173.6527 53.3635 60.3013
> >> 1981-01-01 1981 175.4613 53.6929 60.4980
> >> 1982-01-01 1982 174.5724 53.4890 60.2358
> >> 1983-01-01 1983 171.5070 53.2223 60.1047
> >> 1984-01-01 1984 173.3462 53.2851 60.6946
> >> 1985-01-01 1985 171.7075 53.1596 60.7598
> >>
> >>
> >> On Sat, Sep 16, 2017 at 9:55 AM, Berend Hasselman <bhh at xs4all.nl>
> wrote:
> >>
> >>>
> >>> > On 15 Sep 2017, at 11:38, yadav neog <yadavneog at gmail.com> wrote:
> >>> >
> >>> > hello to all. I am working on macroeconomic data series of India,
> which
> >>> in
> >>> > a yearly basis. I am unable to convert my data frame into time
> series.
> >>> > kindly help me.
> >>> > also using zoo and xts packages. but they take only monthly
> >>> observations.
> >>> >
> >>> > 'data.frame': 30 obs. of  4 variables:
> >>> > $ year: int  1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ...
> >>> > $ cnsm: num  174 175 175 172 173 ...
> >>> > $ incm: num  53.4 53.7 53.5 53.2 53.3 ...
> >>> > $ wlth: num  60.3 60.5 60.2 60.1 60.7 ...
> >>> > --
> >>>
> >>> Second try to do what you would like (I hope and think)
> >>> Using Eric's sample data
> >>>
> >>> <code>
> >>> zdf <- data.frame(year=2001:2010, cnsm=sample(170:180,10,
> replace=TRUE),
> >>>                  incm=rnorm(10,53,1), wlth=rnorm(10,60,1))
> >>> zdf
> >>>
> >>> # R ts
> >>> zts <- ts(zdf[,-1], start=zdf[1,"year"])
> >>> zts
> >>>
> >>> # turn data into a zoo timeseries and an xts timeseries
> >>>
> >>> library(zoo)
> >>> z.zoo <- as.zoo(zts)
> >>> z.zoo
> >>>
> >>> library(xts)
> >>> z.xts <- as.xts(zts)
> >>> z.xts
> >>> </code>
> >>>
> >>> Berend Hasselman
> >>>
> >>> > Yadawananda Neog
> >>> > Research Scholar
> >>> > Department of Economics
> >>> > Banaras Hindu University
> >>> > Mob. 9838545073
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >
> > --
> > Yadawananda Neog
> > Research Scholar
> > Department of Economics
> > Banaras Hindu University
> > Mob. 9838545073
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Yadawananda Neog
Research Scholar
Department of Economics
Banaras Hindu University
Mob. 9838545073

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Fri Sep 22 15:47:50 2017
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 22 Sep 2017 08:47:50 -0500
Subject: [R] require help
In-Reply-To: <CACdLcRzR6Bd4wP3bxUBEA+U54MMSji=ZAy2x_VHnB71D0YyE+Q@mail.gmail.com>
References: <CACdLcRy9Jqe0UMRCzHW5wcDk2zGoc-7SQ0SFO6M-jmAgXrHyRg@mail.gmail.com>
 <0A8976AF-C481-4883-94CF-18D00FF61A1F@xs4all.nl>
 <CAGgJW757V2CotHBo7-qc9eeAiSNi0xC_eLe18C7-dgDVOg6djw@mail.gmail.com>
 <CACdLcRzQB5LoOFFmA-+6uvM6Uy9SCJ8tOqev5exBGCJ4aYvP7Q@mail.gmail.com>
 <CAP01uRkFag6hkDkT7y=Fn4u6Lm5QJdve2ONoP6P8LZL_yCGzgw@mail.gmail.com>
 <CACdLcRzR6Bd4wP3bxUBEA+U54MMSji=ZAy2x_VHnB71D0YyE+Q@mail.gmail.com>
Message-ID: <CAPPM_gS1d98OzqryE9MpjYaF=xrwOvpLRp1QftGRqsLMW5-9OA@mail.gmail.com>

On Fri, Sep 22, 2017 at 7:28 AM, yadav neog <yadavneog at gmail.com> wrote:
> thankx to everyone for your valuable suggestions. one query regarding the
> GARCH model.
> I have applied the GARCH model for the same data that I send you all . and
> my results coming like
>
> Error in .sgarchfit(spec = spec, data = data, out.sample = out.sample,  :
>
> ugarchfit-->error: function requires at least 100 data
>  points to run
>
> can you suggest something on it.
>
The error is protecting you from the unreliable results that you would
get by running the model on too few observations.  You either need
more data, or a different algorithm (not GARCH).

>
>
>
> --
> Yadawananda Neog
> Research Scholar
> Department of Economics
> Banaras Hindu University
> Mob. 9838545073
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2017 | www.rinfinance.com


From dulcalma at bigpond.com  Fri Sep 22 15:48:56 2017
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 22 Sep 2017 23:48:56 +1000
Subject: [R] Lattice stacked barplot vertical bars
In-Reply-To: <CAMk+s2Tc4yT9hce7fGHQz9oXGes4+29QvDNJSmcsUohMD9J9tQ@mail.gmail.com>
References: <CAMk+s2Tc4yT9hce7fGHQz9oXGes4+29QvDNJSmcsUohMD9J9tQ@mail.gmail.com>
Message-ID: <000401d333a9$8975ba80$9c612f80$@bigpond.com>

Hi Luigi

will this do

barchart(
    D ~ A|E,
    DF,
    groups = C,
    stack = TRUE,
    horizontal = F,
    main = "Comparison of test results",
    xlab = "Count",
    col = c("yellow", "orange"),
    par.settings = list(
        strip.background = list(col="light grey"),
        superpose.polygon=list(col= c("yellow", "orange"))
    ),
    scales = list(
        alternating = FALSE
    ),
    key = list(
        space="top",
        columns=2,
        text=list(c("Single infections", "Multiple infections"),
col="black"),
        rectangles=list(col=c("yellow", "orange"))
    ),
    strip = strip.custom(factor.levels = c("Cases","Controls"),
                         strip.levels=TRUE,
                         strip.names=FALSE,
                         par.strip.text = list(cex = 1)
    )
)

Too late to do anything more

Regards 

Duncan Macka

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Friday, 22 September 2017 21:53
To: r-help
Subject: [R] Lattice stacked barplot vertical bars

Dear all,
I have made a barplot using lattice in which the bars are stacked
horizontally. I would like to stack them vertically, but if I use the
parameter 'horizontal = FALSE' I get the error: 'Error in FUN(X[[i]],
...) : invalid 'type' (character) of argument'. The problem I face is
that, in drawing the bars vertically, the y variable becomes numeric
rather than categorical and vice-versa for the x variable.
How can I solve this issue?
Thank you
Luigi

>>>

A <- c('a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'b', 'c', 'd', 'b', 'c', 'd')
B <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
C <- c(0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1)
D <- c(4, 120, 7, 23, 4, 24, 3, 12, 7, 1, 1, 5, 0, 0)
E <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)
DF <- data.frame(A, B, C, D, E, stringsAsFactors = FALSE)
library(lattice)
barchart(
    A ~ D|E,
    DF,
    groups = C,
    stack = TRUE,
    horizontal = TRUE,
    main = "Comparison of test results",
    xlab = "Count",
    col = c("yellow", "orange"),
    par.settings = list(
        strip.background = list(col="light grey"),
        superpose.polygon=list(col= c("yellow", "orange"))
    ),
    scales = list(
        alternating = FALSE
    ),
    key = list(
        space="top",
        columns=2,
        text=list(c("Single infections", "Multiple infections"),
col="black"),
        rectangles=list(col=c("yellow", "orange"))
    ),
    strip = strip.custom(factor.levels = c("Cases","Controls"),
                         strip.levels=TRUE,
                         strip.names=FALSE,
                         par.strip.text = list(cex = 1)
    )
)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Fri Sep 22 16:34:12 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 22 Sep 2017 10:34:12 -0400
Subject: [R] update numeric values of list with new values...
Message-ID: <6469ae30-a9a2-4b4b-996c-e4322b3c5d93@gmail.com>

Suppose I have the following:

test <- list(a=1,b=2,c=3)

I also have a vector (or list, or something else...) with new numbers

new <- c(4,5,6)

What I'm trying to figure out is how to take the list, and update the 
numbers from {1,2,3} to {4,5,6}

So, in the end,I want the 'update' test list to look like

(a=4,a=5,a=6)

I tried a bunch of obvious things I know about 'replacing' things 
(without success), but the problem in this instance seems to be the fact 
that the list contains elements that are expressions (a=1, a=2,...), 
while the new vector is simply a set of numbers.

So, I want to change the numbers in the list, but retain the character 
parts of the expressions in the list (I need to have the list of 
expressions as is for other purposes).

Doable?

Thanks in advance...


From evan.cooch at gmail.com  Fri Sep 22 16:51:32 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 22 Sep 2017 10:51:32 -0400
Subject: [R] update numeric values of list with new values...
In-Reply-To: <6469ae30-a9a2-4b4b-996c-e4322b3c5d93@gmail.com>
References: <6469ae30-a9a2-4b4b-996c-e4322b3c5d93@gmail.com>
Message-ID: <dfe49177-404f-20dd-406b-ff44b102d70e@gmail.com>

Solved it:

test <- list(a=1,b=2,c=3)
new <- c(4,5,6)

hold <- as.list(new)
updated_test <- replace(test,c(1:3),hold)

$a
[1] 4

$b
[1] 5

$c
[1] 6



mean.parms <- as.list(mean.parms)

mm.parms <- replace(far.parms,c(1:length(far.parms)),mean.parms)

On 9/22/2017 10:34 AM, Evan Cooch wrote:
> Suppose I have the following:
>
> test <- list(a=1,b=2,c=3)
>
> I also have a vector (or list, or something else...) with new numbers
>
> new <- c(4,5,6)
>
> What I'm trying to figure out is how to take the list, and update the 
> numbers from {1,2,3} to {4,5,6}
>
> So, in the end,I want the 'update' test list to look like
>
> (a=4,a=5,a=6)
>
> I tried a bunch of obvious things I know about 'replacing' things 
> (without success), but the problem in this instance seems to be the 
> fact that the list contains elements that are expressions (a=1, 
> a=2,...), while the new vector is simply a set of numbers.
>
> So, I want to change the numbers in the list, but retain the character 
> parts of the expressions in the list (I need to have the list of 
> expressions as is for other purposes).
>
> Doable?
>
> Thanks in advance...
>
>


From marongiu.luigi at gmail.com  Fri Sep 22 17:06:28 2017
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Fri, 22 Sep 2017 16:06:28 +0100
Subject: [R] Lattice stacked barplot vertical bars
In-Reply-To: <000401d333a9$8975ba80$9c612f80$@bigpond.com>
References: <CAMk+s2Tc4yT9hce7fGHQz9oXGes4+29QvDNJSmcsUohMD9J9tQ@mail.gmail.com>
 <000401d333a9$8975ba80$9c612f80$@bigpond.com>
Message-ID: <CAMk+s2TCZ5ndV0aimMXXkQEb7aF6hVDymwkxU4jZPWhk3OKYOQ@mail.gmail.com>

Yes, perfect!
Thank you
L

On Fri, Sep 22, 2017 at 2:48 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi Luigi
>
> will this do
>
> barchart(
>     D ~ A|E,
>     DF,
>     groups = C,
>     stack = TRUE,
>     horizontal = F,
>     main = "Comparison of test results",
>     xlab = "Count",
>     col = c("yellow", "orange"),
>     par.settings = list(
>         strip.background = list(col="light grey"),
>         superpose.polygon=list(col= c("yellow", "orange"))
>     ),
>     scales = list(
>         alternating = FALSE
>     ),
>     key = list(
>         space="top",
>         columns=2,
>         text=list(c("Single infections", "Multiple infections"),
> col="black"),
>         rectangles=list(col=c("yellow", "orange"))
>     ),
>     strip = strip.custom(factor.levels = c("Cases","Controls"),
>                          strip.levels=TRUE,
>                          strip.names=FALSE,
>                          par.strip.text = list(cex = 1)
>     )
> )
>
> Too late to do anything more
>
> Regards
>
> Duncan Macka
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> Sent: Friday, 22 September 2017 21:53
> To: r-help
> Subject: [R] Lattice stacked barplot vertical bars
>
> Dear all,
> I have made a barplot using lattice in which the bars are stacked
> horizontally. I would like to stack them vertically, but if I use the
> parameter 'horizontal = FALSE' I get the error: 'Error in FUN(X[[i]],
> ...) : invalid 'type' (character) of argument'. The problem I face is
> that, in drawing the bars vertically, the y variable becomes numeric
> rather than categorical and vice-versa for the x variable.
> How can I solve this issue?
> Thank you
> Luigi
>
>>>>
>
> A <- c('a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'b', 'c', 'd', 'b', 'c', 'd')
> B <- c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
> C <- c(0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1)
> D <- c(4, 120, 7, 23, 4, 24, 3, 12, 7, 1, 1, 5, 0, 0)
> E <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1)
> DF <- data.frame(A, B, C, D, E, stringsAsFactors = FALSE)
> library(lattice)
> barchart(
>     A ~ D|E,
>     DF,
>     groups = C,
>     stack = TRUE,
>     horizontal = TRUE,
>     main = "Comparison of test results",
>     xlab = "Count",
>     col = c("yellow", "orange"),
>     par.settings = list(
>         strip.background = list(col="light grey"),
>         superpose.polygon=list(col= c("yellow", "orange"))
>     ),
>     scales = list(
>         alternating = FALSE
>     ),
>     key = list(
>         space="top",
>         columns=2,
>         text=list(c("Single infections", "Multiple infections"),
> col="black"),
>         rectangles=list(col=c("yellow", "orange"))
>     ),
>     strip = strip.custom(factor.levels = c("Cases","Controls"),
>                          strip.levels=TRUE,
>                          strip.names=FALSE,
>                          par.strip.text = list(cex = 1)
>     )
> )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Chaitanya.Ganne at jefferson.edu  Fri Sep 22 17:06:18 2017
From: Chaitanya.Ganne at jefferson.edu (Chaitanya Ganne)
Date: Fri, 22 Sep 2017 15:06:18 +0000
Subject: [R] rcorr error in R stat
In-Reply-To: <20170921182122.Horde.2JU85K0nWljXSu2u8uTvTbl@mail.sapo.pt>
References: <BN3PR0501MB16358C249C88BA8412EFB492E7610@BN3PR0501MB1635.namprd05.prod.outlook.com>
 <20170920222104.Horde.xoTawi9yeP7UnIxsevFNWov@mail.sapo.pt>
 <BN3PR0501MB1635E658B5C1B3BEDFBE60D2E7660@BN3PR0501MB1635.namprd05.prod.outlook.com>
 <20170921175626.Horde.LKrx9SQSgY80juPYNNAuPl3@mail.sapo.pt>,
 <20170921182122.Horde.2JU85K0nWljXSu2u8uTvTbl@mail.sapo.pt>
Message-ID: <BN3PR0501MB163558B364D9E5AAD94A0915E7660@BN3PR0501MB1635.namprd05.prod.outlook.com>

My apologies for the late reply. I had scans after I last messaged you yesterday.


Please find attached the ms-dos CSV file which I prepared using microsoft excel. there should be GT1.csv and NPA1.csv.


Thanking you

________________________________
From: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
Sent: Thursday, September 21, 2017 1:21:22 PM
To: Chaitanya Ganne; r-help
Subject: Re: [R] rcorr error in R stat

Hello,

Also, the other file, NPA.csv, is not in tabular form. Can you please
reformat it?

Rui Barradas


Citando ruipbarradas at sapo.pt:
> Hello,
>
> Please keep this on the list, always cc r-help.
> One of the files in your attachment is empty:
>
> y <- read.csv(file.choose("GT.csv"))
> Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   no lines available in input
>
> Rui Barradas
>
>
> Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:
>
>> Thank you so much for your input.
>>
>> I am relatively new to R and I don't understand this "read.csv
>> returns data.frames". Sorry.
>>
>> This however did not work. "unlist(x) and unlist(y)". I got a series
>> of 43 warnings:
>>
>> Warning messages:
>> 1: In doTryCatch(return(expr), name, parentenv, handler) :
>>   "method" is not a graphical parameter
>> 2: In doTryCatch(return(expr), name, parentenv, handler) :
>>   "method" is not a graphical parameter
>> .
>> .
>> .
>> .
>> .
>>
>>   "method" is not a graphical parameter
>> 42: In doTryCatch(return(expr), name, parentenv, handler) :
>>   "method" is not a graphical parameter
>> 43: In cbind(x, y) :
>>   number of rows of result is not a multiple of vector length (arg 2)
>>
>> Would it help if I send the two csv files to you? I'd really
>> appreciate your help.
>>
>> Thanking you
>>
>>
>> -------------------------
>> FROM: ruipbarradas at sapo.pt <ruipbarradas at sapo.pt>
>> SENT: Wednesday, September 20, 2017 5:21:04 PM
>> TO: Chaitanya Ganne
>> SUBJECT: Re: rcorr error in R stat
>>
>> Hello,
>>
>> Maybe I'm completely off, but read.csv returns data.frames, which
>> are lists with a dim attribute.
>> Instead of as.vector try unlist(x) and unlist(y).
>>
>> Note that if 'df' is a data.frame, class(as.vector(df)) returns
>> "data.frame".
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>> Citando Chaitanya Ganne <Chaitanya.Ganne at jefferson.edu>:
>>
>>> Good afternoon,
>>>
>>> I have two variables x and y. I am trying to run a correlation
>>> between them as vectors.
>>> x <- read.csv(file.choose(NPA.csv))
>>> y <- read.csv(file.choose(GT.csv))
>>> res <- cor(as.vector(x), as.vector(y))
>>> round(res, 2)
>>> install.packages("Hmisc")
>>> library(Hmisc)
>>> res2 <- rcorr(as.vector(x), as.vector(y))
>>> res2 <- rcorr(as.vector(x), as.vector(y))
>>> Error in storage.mode(x) <- "double" :
>>>  (list) object cannot be coerced to type 'double'
>>>
>>> ---------------------------------------------------
>>>
>>> In fact I find this is something to do with the way the matrices
>>> are being considered for rcorr to be different from the way the
>>> matrices are being considered for 'cor'. The cor function gave me
>>> this output as mentioned below. However I am using the rcorr
>>> function to build the correlplots later on.
>>>
>>>
>>>
>>>   BC_11L_parstriangularis_1  BC_12L_rostralmiddlefrontal_2
>>>      BC_20L_fusiform_4        BC_21L_inferiortemporal_3
>>>      BC_23L_middletemporal_1  vw_12L_rostralmiddlefrontal_2
>>>      vw_19L_inferiorparietal_1
>>>   CVLT_T4    -0.23    0.13     -0.01    -0.24    -0.14    0.02     0.06
>>>   CVLT_T5    -0.28    0.12     0.04     -0.25    -0.19    0.15     0.11
>>>   CVLT_Total         -0.25    0.07     0.13     -0.25    -0.22    0.05     -0.05
>>>   CVLT_LDF   -0.16    0.04     0.16     -0.23    -0.32    0.16     0.01
>>>   CVLT_RoF   -0.12    0.02     0.06     -0.04    -0.14    0.16     -0.06
>>>   CVLT_TDR   -0.11    0.1      0.13     -0.24    -0.25    0.25     -0.06
>>>   LM_I       -0.46    -0.19    -0.11    -0.06    -0.24    -0.01    0.1
>>>   LM_II      -0.35    0.06     0.05     -0.11    -0.31    0.22     0.05
>>>   p_REC      -0.12    -0.27    0.36     -0.19    -0.09    -0.17    -0.21
>>>   TF         -0.01    -0.01    -0.21    -0.2     -0.27    -0.07    0.06
>>>
>>>
>>> Please help.
>>>
>>> /DR. GANNE CHAITANYA MD, PHD/
>>>
>>> /PDF //NEUROLOGY/
>>>
>>> /TJU, //PHILADELPHIA, 19107, PA/
>>>
>>>
>>>   The information contained in this transmission contains
>>> privileged and confidential information. It is intended only for
>>> the use of the person named above. If you are not the intended
>>> recipient, you are hereby notified that any review, dissemination,
>>> distribution or duplication of this communication is strictly
>>> prohibited. If you are not the intended recipient, please contact
>>> the sender by reply email and destroy all copies of the original
>>> message.
>>>
>>> _CAUTION_: Intended recipients should NOT use email communication
>>> for emergent or urgent health care matters.
>>
>>
>
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=02%7C01%7CChaitanya.Ganne%40jefferson.edu%7C2294ae18fd7e4a3b9fcd08d501153840%7C55a89906c710436bbc444c590cb67c4a%7C0%7C0%7C636416113005878432&sdata=QZ6qfoYeF2NGwDcQ2ASnZQCAI0OnYDQ%2FhBBQzhN7fJQ%3D&reserved=0
> PLEASE do read the posting guide https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&data=02%7C01%7CChaitanya.Ganne%40jefferson.edu%7C2294ae18fd7e4a3b9fcd08d501153840%7C55a89906c710436bbc444c590cb67c4a%7C0%7C0%7C636416113005878432&sdata=1fr2Lpgsa7T0Y%2BjD%2FO35d%2FezFGKMdzdO0WE4RTNG7Po%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.




The information contained in this transmission contains privileged and confidential information. It is intended only for the use of the person named above. If you are not the intended recipient, you are hereby notified that any review, dissemination, distribution or duplication of this communication is strictly prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.

CAUTION: Intended recipients should NOT use email communication for emergent or urgent health care matters.


From careyshan at gmail.com  Fri Sep 22 17:48:51 2017
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 22 Sep 2017 16:48:51 +0100
Subject: [R] Subset
Message-ID: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>

Hi,

How do I extract just numbers from the following list:

a=c("<0.1",NA,0.3,5,Nil)

so I want to obtain: 0.3 and 5 from the above list

Thanks


-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Sep 22 17:57:44 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 22 Sep 2017 11:57:44 -0400
Subject: [R] Subset
In-Reply-To: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
Message-ID: <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>

> a <- c("<0.1", NA, 0.3, 5, "Nil")
> a
[1] "<0.1" NA     "0.3"  "5"    "Nil" 

> b <- as.numeric(a)
Warning message:
NAs introduced by coercion 
> b
[1]  NA  NA 0.3 5.0  NA

> b[! is.na(b)]
[1] 0.3 5.0


B.


> On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
> 
> Hi,
> 
> How do I extract just numbers from the following list:
> 
> a=c("<0.1",NA,0.3,5,Nil)
> 
> so I want to obtain: 0.3 and 5 from the above list
> 
> Thanks
> 
> 
> -- 
> Le gach dea ghui,
> *Shane Carey*
> *GIS and Data Solutions Consultant*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Fri Sep 22 18:04:22 2017
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 22 Sep 2017 17:04:22 +0100
Subject: [R] Subset
In-Reply-To: <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
Message-ID: <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>

Super,

Thanks

On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > a
> [1] "<0.1" NA     "0.3"  "5"    "Nil"
>
> > b <- as.numeric(a)
> Warning message:
> NAs introduced by coercion
> > b
> [1]  NA  NA 0.3 5.0  NA
>
> > b[! is.na(b)]
> [1] 0.3 5.0
>
>
> B.
>
>
> > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
> >
> > Hi,
> >
> > How do I extract just numbers from the following list:
> >
> > a=c("<0.1",NA,0.3,5,Nil)
> >
> > so I want to obtain: 0.3 and 5 from the above list
> >
> > Thanks
> >
> >
> > --
> > Le gach dea ghui,
> > *Shane Carey*
> > *GIS and Data Solutions Consultant*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Sep 22 18:34:38 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 22 Sep 2017 09:34:38 -0700
Subject: [R] update numeric values of list with new values...
In-Reply-To: <dfe49177-404f-20dd-406b-ff44b102d70e@gmail.com>
References: <6469ae30-a9a2-4b4b-996c-e4322b3c5d93@gmail.com>
 <dfe49177-404f-20dd-406b-ff44b102d70e@gmail.com>
Message-ID: <CAGxFJbQhE=UXC9YM7X3qWA03NRDcVz7jYFwKKkry=xUeeiBuUw@mail.gmail.com>

Well,  that's a bit like driving from Boston to New York by way of Chicago.

See ?structure

test <- list(a=1,b=2,c=3)
new <- c(4,5,6)
test.new <- structure(as.list(new), names=names(test))
test.new
$a
[1] 4

$b
[1] 5

$c
[1] 6

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 22, 2017 at 7:51 AM, Evan Cooch <evan.cooch at gmail.com> wrote:

> Solved it:
>
> test <- list(a=1,b=2,c=3)
> new <- c(4,5,6)
>
> hold <- as.list(new)
> updated_test <- replace(test,c(1:3),hold)
>
> $a
> [1] 4
>
> $b
> [1] 5
>
> $c
> [1] 6
>
>
>
> mean.parms <- as.list(mean.parms)
>
> mm.parms <- replace(far.parms,c(1:length(far.parms)),mean.parms)
>
>
> On 9/22/2017 10:34 AM, Evan Cooch wrote:
>
>> Suppose I have the following:
>>
>> test <- list(a=1,b=2,c=3)
>>
>> I also have a vector (or list, or something else...) with new numbers
>>
>> new <- c(4,5,6)
>>
>> What I'm trying to figure out is how to take the list, and update the
>> numbers from {1,2,3} to {4,5,6}
>>
>> So, in the end,I want the 'update' test list to look like
>>
>> (a=4,a=5,a=6)
>>
>> I tried a bunch of obvious things I know about 'replacing' things
>> (without success), but the problem in this instance seems to be the fact
>> that the list contains elements that are expressions (a=1, a=2,...), while
>> the new vector is simply a set of numbers.
>>
>> So, I want to change the numbers in the list, but retain the character
>> parts of the expressions in the list (I need to have the list of
>> expressions as is for other purposes).
>>
>> Doable?
>>
>> Thanks in advance...
>>
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fisher at plessthan.com  Fri Sep 22 19:21:59 2017
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 22 Sep 2017 10:21:59 -0700
Subject: [R] Embedding PDF into RTF document via R language
Message-ID: <67A944D3-3EFF-4C87-9668-624279F3074E@plessthan.com>

R 3.4.1
OS X and Windows

Colleagues

I have a complicated problem that includes several components:
	R
	RTF
	PDF

Using R (and a slew of RTF commands), I assemble a text document with an RTF extension.  The document contains text, tables, and images (JPEG format, previously created with R).  
To ?import? the JPEG images into the document, I use the following R code:
	cat("\\pard\\qc {\\pict\\jpegblip\n", file=TEMPREPORT, append=T)
	cat(toupper(readBin(IMAGEFILE, "raw", 10000000)), fill=64, sep="",file=TEMPREPORT, append=T)
	cat("\n}\\par\\ql", file=TEMPREPORT, append=T)
The critical text is:
	jpegblip ? which presumably informs the RTF reader that what follows is a JPEG 
	readBin ? which reads the JPEG file

When the JPEG images are created, I also create identical PDF versions.  I would like, if possible, to ?import? the PDF versions (instead of the JPEG versions) into the RTF document.
I see two issues:
1.  It is not obvious what should replace the jpegblip command
2.  Is readBin the appropriate command to embed the PDF

I realize that this is not strictly an R issue but support for R is far better than that for RTF.

Any help would be appreciated.

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From bgunter.4567 at gmail.com  Fri Sep 22 19:38:58 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 22 Sep 2017 10:38:58 -0700
Subject: [R] Embedding PDF into RTF document via R language
In-Reply-To: <67A944D3-3EFF-4C87-9668-624279F3074E@plessthan.com>
References: <67A944D3-3EFF-4C87-9668-624279F3074E@plessthan.com>
Message-ID: <CAGxFJbQLc2SR95stVnp0suUq8=DAXeKZgdc3GwBRDUV1WfTp+w@mail.gmail.com>

An obvious question is: why mess with RTF at all, as R and RStudio provide
support for document creation with embedded R content (i.e. through knitr
and associated)?

But be that as it may (i.e. don't answer that), have you tried posting on:

https://stackoverflow.com/      ?

Seems like this sort of question might fit better there.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 22, 2017 at 10:21 AM, Fisher Dennis <fisher at plessthan.com>
wrote:

> R 3.4.1
> OS X and Windows
>
> Colleagues
>
> I have a complicated problem that includes several components:
>         R
>         RTF
>         PDF
>
> Using R (and a slew of RTF commands), I assemble a text document with an
> RTF extension.  The document contains text, tables, and images (JPEG
> format, previously created with R).
> To ?import? the JPEG images into the document, I use the following R code:
>         cat("\\pard\\qc {\\pict\\jpegblip\n", file=TEMPREPORT, append=T)
>         cat(toupper(readBin(IMAGEFILE, "raw", 10000000)), fill=64,
> sep="",file=TEMPREPORT, append=T)
>         cat("\n}\\par\\ql", file=TEMPREPORT, append=T)
> The critical text is:
>         jpegblip ? which presumably informs the RTF reader that what
> follows is a JPEG
>         readBin ? which reads the JPEG file
>
> When the JPEG images are created, I also create identical PDF versions.  I
> would like, if possible, to ?import? the PDF versions (instead of the JPEG
> versions) into the RTF document.
> I see two issues:
> 1.  It is not obvious what should replace the jpegblip command
> 2.  Is readBin the appropriate command to embed the PDF
>
> I realize that this is not strictly an R issue but support for R is far
> better than that for RTF.
>
> Any help would be appreciated.
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone / Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Fri Sep 22 20:47:49 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Fri, 22 Sep 2017 14:47:49 -0400
Subject: [R] update numeric values of list with new values...
In-Reply-To: <CAGxFJbQhE=UXC9YM7X3qWA03NRDcVz7jYFwKKkry=xUeeiBuUw@mail.gmail.com>
References: <6469ae30-a9a2-4b4b-996c-e4322b3c5d93@gmail.com>
 <dfe49177-404f-20dd-406b-ff44b102d70e@gmail.com>
 <CAGxFJbQhE=UXC9YM7X3qWA03NRDcVz7jYFwKKkry=xUeeiBuUw@mail.gmail.com>
Message-ID: <f754767d-95bf-f4f2-da32-78e7a666c030@gmail.com>

Thanks!

On 9/22/2017 12:34 PM, Bert Gunter wrote:
> Well,? that's a bit like driving from Boston to New York by way of 
> Chicago.
>
> See ?structure
>
> test <- list(a=1,b=2,c=3)
> new <- c(4,5,6)
> test.new <- structure(as.list(new), names=names(test))
> test.new
> $a
> [1] 4
>
> $b
> [1] 5
>
> $c
> [1] 6
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Sep 22, 2017 at 7:51 AM, Evan Cooch <evan.cooch at gmail.com 
> <mailto:evan.cooch at gmail.com>> wrote:
>
>     Solved it:
>
>     test <- list(a=1,b=2,c=3)
>     new <- c(4,5,6)
>
>     hold <- as.list(new)
>     updated_test <- replace(test,c(1:3),hold)
>
>     $a
>     [1] 4
>
>     $b
>     [1] 5
>
>     $c
>     [1] 6
>
>
>
>     mean.parms <- as.list(mean.parms)
>
>     mm.parms <- replace(far.parms,c(1:length(far.parms)),mean.parms)
>
>
>     On 9/22/2017 10:34 AM, Evan Cooch wrote:
>
>         Suppose I have the following:
>
>         test <- list(a=1,b=2,c=3)
>
>         I also have a vector (or list, or something else...) with new
>         numbers
>
>         new <- c(4,5,6)
>
>         What I'm trying to figure out is how to take the list, and
>         update the numbers from {1,2,3} to {4,5,6}
>
>         So, in the end,I want the 'update' test list to look like
>
>         (a=4,a=5,a=6)
>
>         I tried a bunch of obvious things I know about 'replacing'
>         things (without success), but the problem in this instance
>         seems to be the fact that the list contains elements that are
>         expressions (a=1, a=2,...), while the new vector is simply a
>         set of numbers.
>
>         So, I want to change the numbers in the list, but retain the
>         character parts of the expressions in the list (I need to have
>         the list of expressions as is for other purposes).
>
>         Doable?
>
>         Thanks in advance...
>
>
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Sat Sep 23 05:04:39 2017
From: miaojpm at gmail.com (John)
Date: Fri, 22 Sep 2017 20:04:39 -0700
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
Message-ID: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>

Hi,

   I tried to read xlsx files by "XLConnect" packages, but the dates are
one day earlier than it is supposed to be. I moved from California to
Taiwan (Eastern Asia), and it worked well in California, but not in Taiwan.
Even if I adjust my Mac time to California time zone, it gives the wrong
dates. I don't know which part of the setting (in RStudio or in my Mac?) I
should adjust. The codes and the data are attached.

   My data are on weekdays, Monday to Friday every week, but they are read
as Sunday to Thursday.

Data:
2004-01-01 (Th)
2004-01-02 (F)
2004-01-05 (M)
2004-01-06 (T)
2004-01-07 (W)
2004-01-08 (Th)
2004-01-09 (F)

The data are read as:
"2003-12-31" (W)
"2004-01-01" (Th)
"2004-01-04" (Su)
"2004-01-05" (M)
"2004-01-06" (Tu)
"2004-01-07" (W)
 "2004-01-08" (Th)



The codes are (also attached):


rm(list=ls())
library(XLConnect)
library(xlsx)

fl<-paste("allData_out3.xlsx")
a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
a_col<-readWorksheetFromFile(fl, sheet="first")
date11<-as.Date(a_col$date, format="%Y-%m-%d")


The output:
> date11
 [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
"2004-01-07"
 [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
"2004-01-15"
[13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
"2004-01-25"
[19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
>


Thanks!!

From arrayprofile at yahoo.com  Sat Sep 23 01:32:02 2017
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 22 Sep 2017 23:32:02 +0000 (UTC)
Subject: [R] gsDesign Pocock & OBF boundary
References: <1357854377.611471.1506123122758.ref@mail.yahoo.com>
Message-ID: <1357854377.611471.1506123122758@mail.yahoo.com>

Hi, 

I am learning to use your gsDesign package!?I have a question about Pocock and OBF boundary. As far as Iunderstand, these 2 boundaries require equal spacing between interim analyses(maybe this is not correct?). But I can still use gsDesign to run an analysisbased on unequal spacing:?gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')Symmetrictwo-sided group sequential design with90 %power and 5 % Type I Error.Spendingcomputations assume trial stops if a bound is crossed.???????????Sample???????????Size ??AnalysisRatio*? Z?? Nominal p? Spend????????1? 0.796 1.82??? 0.0346 0.0346????????2? 1.061 1.82??? 0.0346 0.0154????Total??????????????????????0.0500 ?++alpha spending:Pocockboundary.*Sample size ratio compared to fixed design with no interim?Can anyone share some light whether the above analysis is stillvalid? Or for unequal spacing, I have to use Lan-Demet?s error spendingfunction approximations??Thank you,
	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sat Sep 23 08:46:15 2017
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 23 Sep 2017 08:46:15 +0200
Subject: [R] gsDesign Pocock & OBF boundary
In-Reply-To: <1357854377.611471.1506123122758@mail.yahoo.com>
References: <1357854377.611471.1506123122758.ref@mail.yahoo.com>
 <1357854377.611471.1506123122758@mail.yahoo.com>
Message-ID: <CC8B71CE-08B2-4E21-8D11-F06DD27C72F7@xs4all.nl>


> On 23 Sep 2017, at 01:32, array chip via R-help <r-help at r-project.org> wrote:
> 
> Hi, 
> 
> I am learning to use your gsDesign package! I have a question about Pocock and OBF boundary. As far as Iunderstand, these 2 boundaries require equal spacing between interim analyses(maybe this is not correct?). But I can still use gsDesign to run an analysisbased on unequal spacing: gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')Symmetrictwo-sided group sequential design with90 %power and 5 % Type I Error.Spendingcomputations assume trial stops if a bound is crossed.           Sample           Size   AnalysisRatio*  Z   Nominal p  Spend        1  0.796 1.82    0.0346 0.0346        2  1.061 1.82    0.0346 0.0154    Total                      0.0500  ++alpha spending:Pocockboundary.*Sample size ratio compared to fixed design with no interim Can anyone share some light whether the above analysis is stillvalid? Or for unequal spacing, I have to use Lan-Demet?s error spendingfunction approximations? Thank you,
> 	[[alternative HTML version deleted]]
> 

Your example code is a complete mess.
Do NOT post in html. This is a plain text mailing list.
Read the Posting Guide (https://www.r-project.org/posting-guide.html).

Berend Hasselman]

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Sep 23 12:30:35 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 23 Sep 2017 20:30:35 +1000
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
Message-ID: <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>

Hi John,
It could be due to this:

https://support.microsoft.com/en-au/help/214330/differences-between-the-1900-and-the-1904-date-system-in-excel

Jim


On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
> Hi,
>
>    I tried to read xlsx files by "XLConnect" packages, but the dates are
> one day earlier than it is supposed to be. I moved from California to
> Taiwan (Eastern Asia), and it worked well in California, but not in Taiwan.
> Even if I adjust my Mac time to California time zone, it gives the wrong
> dates. I don't know which part of the setting (in RStudio or in my Mac?) I
> should adjust. The codes and the data are attached.
>
>    My data are on weekdays, Monday to Friday every week, but they are read
> as Sunday to Thursday.
>
> Data:
> 2004-01-01 (Th)
> 2004-01-02 (F)
> 2004-01-05 (M)
> 2004-01-06 (T)
> 2004-01-07 (W)
> 2004-01-08 (Th)
> 2004-01-09 (F)
>
> The data are read as:
> "2003-12-31" (W)
> "2004-01-01" (Th)
> "2004-01-04" (Su)
> "2004-01-05" (M)
> "2004-01-06" (Tu)
> "2004-01-07" (W)
>  "2004-01-08" (Th)
>
>
>
> The codes are (also attached):
>
>
> rm(list=ls())
> library(XLConnect)
> library(xlsx)
>
> fl<-paste("allData_out3.xlsx")
> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
> a_col<-readWorksheetFromFile(fl, sheet="first")
> date11<-as.Date(a_col$date, format="%Y-%m-%d")
>
>
> The output:
>> date11
>  [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
> "2004-01-07"
>  [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
> "2004-01-15"
> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
> "2004-01-25"
> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
>>
>
>
> Thanks!!
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Sat Sep 23 15:30:22 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sat, 23 Sep 2017 16:30:22 +0300
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
Message-ID: <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>

Jim,
I don't see how that link could be related to John's issue. Symptoms
related to your link involve discrepancies of four years whereas John is
seeing discrepancies of one day.

John,
I do not see any attached files.

Regards

On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi John,
> It could be due to this:
>
> https://support.microsoft.com/en-au/help/214330/differences-
> between-the-1900-and-the-1904-date-system-in-excel
>
> Jim
>
>
> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
> > Hi,
> >
> >    I tried to read xlsx files by "XLConnect" packages, but the dates are
> > one day earlier than it is supposed to be. I moved from California to
> > Taiwan (Eastern Asia), and it worked well in California, but not in
> Taiwan.
> > Even if I adjust my Mac time to California time zone, it gives the wrong
> > dates. I don't know which part of the setting (in RStudio or in my Mac?)
> I
> > should adjust. The codes and the data are attached.
> >
> >    My data are on weekdays, Monday to Friday every week, but they are
> read
> > as Sunday to Thursday.
> >
> > Data:
> > 2004-01-01 (Th)
> > 2004-01-02 (F)
> > 2004-01-05 (M)
> > 2004-01-06 (T)
> > 2004-01-07 (W)
> > 2004-01-08 (Th)
> > 2004-01-09 (F)
> >
> > The data are read as:
> > "2003-12-31" (W)
> > "2004-01-01" (Th)
> > "2004-01-04" (Su)
> > "2004-01-05" (M)
> > "2004-01-06" (Tu)
> > "2004-01-07" (W)
> >  "2004-01-08" (Th)
> >
> >
> >
> > The codes are (also attached):
> >
> >
> > rm(list=ls())
> > library(XLConnect)
> > library(xlsx)
> >
> > fl<-paste("allData_out3.xlsx")
> > a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
> > b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
> > a_col<-readWorksheetFromFile(fl, sheet="first")
> > date11<-as.Date(a_col$date, format="%Y-%m-%d")
> >
> >
> > The output:
> >> date11
> >  [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
> > "2004-01-07"
> >  [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
> > "2004-01-15"
> > [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
> > "2004-01-25"
> > [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
> >>
> >
> >
> > Thanks!!
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Sep 24 07:29:57 2017
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Sep 2017 22:29:57 -0700
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
 <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
Message-ID: <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>


> On Sep 23, 2017, at 6:30 AM, Eric Berger <ericjberger at gmail.com> wrote:
> 
> Jim,
> I don't see how that link could be related to John's issue. Symptoms
> related to your link involve discrepancies of four years whereas John is
> seeing discrepancies of one day.
> 

The MS Excel starting point was off by one day. R does not repeat that error. MS claims that their  error is justified by needing to copy the error made by Lotus123 and then because they wanted backward compatibility.

I'm not sure why the XLConnect package does not fix the error. They just use the integer from Excel and let R apply it correctly.
-- 
David.


> John,
> I do not see any attached files.
> 
> Regards
> 
> On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi John,
>> It could be due to this:
>> 
>> https://support.microsoft.com/en-au/help/214330/differences-
>> between-the-1900-and-the-1904-date-system-in-excel
>> 
>> Jim
>> 
>> 
>> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
>>> Hi,
>>> 
>>>   I tried to read xlsx files by "XLConnect" packages, but the dates are
>>> one day earlier than it is supposed to be. I moved from California to
>>> Taiwan (Eastern Asia), and it worked well in California, but not in
>> Taiwan.
>>> Even if I adjust my Mac time to California time zone, it gives the wrong
>>> dates. I don't know which part of the setting (in RStudio or in my Mac?)
>> I
>>> should adjust. The codes and the data are attached.
>>> 
>>>   My data are on weekdays, Monday to Friday every week, but they are
>> read
>>> as Sunday to Thursday.
>>> 
>>> Data:
>>> 2004-01-01 (Th)
>>> 2004-01-02 (F)
>>> 2004-01-05 (M)
>>> 2004-01-06 (T)
>>> 2004-01-07 (W)
>>> 2004-01-08 (Th)
>>> 2004-01-09 (F)
>>> 
>>> The data are read as:
>>> "2003-12-31" (W)
>>> "2004-01-01" (Th)
>>> "2004-01-04" (Su)
>>> "2004-01-05" (M)
>>> "2004-01-06" (Tu)
>>> "2004-01-07" (W)
>>> "2004-01-08" (Th)
>>> 
>>> 
>>> 
>>> The codes are (also attached):
>>> 
>>> 
>>> rm(list=ls())
>>> library(XLConnect)
>>> library(xlsx)
>>> 
>>> fl<-paste("allData_out3.xlsx")
>>> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
>>> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
>>> a_col<-readWorksheetFromFile(fl, sheet="first")
>>> date11<-as.Date(a_col$date, format="%Y-%m-%d")
>>> 
>>> 
>>> The output:
>>>> date11
>>> [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
>>> "2004-01-07"
>>> [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
>>> "2004-01-15"
>>> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
>>> "2004-01-25"
>>> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
>>>> 
>>> 
>>> 
>>> Thanks!!
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From arrayprofile at yahoo.com  Sun Sep 24 06:53:05 2017
From: arrayprofile at yahoo.com (array chip)
Date: Sun, 24 Sep 2017 04:53:05 +0000 (UTC)
Subject: [R] gsDesign Pocock & OBF boundary
In-Reply-To: <CC8B71CE-08B2-4E21-8D11-F06DD27C72F7@xs4all.nl>
References: <1357854377.611471.1506123122758.ref@mail.yahoo.com>
 <1357854377.611471.1506123122758@mail.yahoo.com>
 <CC8B71CE-08B2-4E21-8D11-F06DD27C72F7@xs4all.nl>
Message-ID: <533519797.1008471.1506228785048@mail.yahoo.com>

Sorry for messed up text. Here it goes again:
I am learning to use the gsDesign package.
I have a question about Pocock and OBF boundary. As far as I can understand, these 2 boundaries require equal spacing between interim analyses (maybe this is not correct?). But looks like I can still use gsDesign to run an analysis based on unequal spacing:?
> gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')
Symmetric two-sided group sequential design with 90 %power and 5 % Type I Error.Spending computations assume trial stops if a bound is crossed.? ? ? ? ? Sample? ? ? ? ? Size? Analysis Ratio*? Z? Nominal p? Spend? ? ? ? 1? 0.796 1.82? ? 0.0346 0.0346? ? ? ? 2? 1.061 1.82? ? 0.0346 0.0154? ? Total? ? ? ? ? ? ? ? ? ? ? 0.0500?++alpha spending: Pocock boundary.*Sample size ratio compared to fixed design with no interim?
Can anyone share some light whether the above analysis is still valid? Or for unequal spacing, I have to use Lan-Demet?s error spending function approximations? Thank you,



      From: Berend Hasselman <bhh at xs4all.nl>
 To: array chip <arrayprofile at yahoo.com> 
Cc: R-help Mailing List <r-help at r-project.org>
 Sent: Friday, September 22, 2017 11:46 PM
 Subject: Re: [R] gsDesign Pocock & OBF boundary
   

> On 23 Sep 2017, at 01:32, array chip via R-help <r-help at r-project.org> wrote:
> 
> Hi, 
> 
> I am learning to use your gsDesign package! I have a question about Pocock and OBF boundary. As far as Iunderstand, these 2 boundaries require equal spacing between interim analyses(maybe this is not correct?). But I can still use gsDesign to run an analysisbased on unequal spacing: gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')Symmetrictwo-sided group sequential design with90 %power and 5 % Type I Error.Spendingcomputations assume trial stops if a bound is crossed.? ? ? ? ? Sample? ? ? ? ? Size? AnalysisRatio*? Z? Nominal p? Spend? ? ? ? 1? 0.796 1.82? ? 0.0346 0.0346? ? ? ? 2? 1.061 1.82? ? 0.0346 0.0154? ? Total? ? ? ? ? ? ? ? ? ? ? 0.0500? ++alpha spending:Pocockboundary.*Sample size ratio compared to fixed design with no interim Can anyone share some light whether the above analysis is stillvalid? Or for unequal spacing, I have to use Lan-Demet?s error spendingfunction approximations? Thank you,
> ??? [[alternative HTML version deleted]]
> 

Your example code is a complete mess.
Do NOT post in html. This is a plain text mailing list.
Read the Posting Guide (https://www.r-project.org/posting-guide.html).

Berend Hasselman]

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Sun Sep 24 07:51:16 2017
From: miaojpm at gmail.com (John)
Date: Sat, 23 Sep 2017 22:51:16 -0700
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
 <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
 <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>
Message-ID: <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>

Hi,

   Thank you for all your responses.
   For Eric, The files are attached. (I believe it was also attached in my
first message)
   For David, Could you send me the link regarding possible solutions or a
more comprehensive description of the problem?

   Thanks,

John


2017-09-23 22:29 GMT-07:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Sep 23, 2017, at 6:30 AM, Eric Berger <ericjberger at gmail.com> wrote:
> >
> > Jim,
> > I don't see how that link could be related to John's issue. Symptoms
> > related to your link involve discrepancies of four years whereas John is
> > seeing discrepancies of one day.
> >
>
> The MS Excel starting point was off by one day. R does not repeat that
> error. MS claims that their  error is justified by needing to copy the
> error made by Lotus123 and then because they wanted backward compatibility.
>
> I'm not sure why the XLConnect package does not fix the error. They just
> use the integer from Excel and let R apply it correctly.
> --
> David.
>
>
> > John,
> > I do not see any attached files.
> >
> > Regards
> >
> > On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi John,
> >> It could be due to this:
> >>
> >> https://support.microsoft.com/en-au/help/214330/differences-
> >> between-the-1900-and-the-1904-date-system-in-excel
> >>
> >> Jim
> >>
> >>
> >> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
> >>> Hi,
> >>>
> >>>   I tried to read xlsx files by "XLConnect" packages, but the dates are
> >>> one day earlier than it is supposed to be. I moved from California to
> >>> Taiwan (Eastern Asia), and it worked well in California, but not in
> >> Taiwan.
> >>> Even if I adjust my Mac time to California time zone, it gives the
> wrong
> >>> dates. I don't know which part of the setting (in RStudio or in my
> Mac?)
> >> I
> >>> should adjust. The codes and the data are attached.
> >>>
> >>>   My data are on weekdays, Monday to Friday every week, but they are
> >> read
> >>> as Sunday to Thursday.
> >>>
> >>> Data:
> >>> 2004-01-01 (Th)
> >>> 2004-01-02 (F)
> >>> 2004-01-05 (M)
> >>> 2004-01-06 (T)
> >>> 2004-01-07 (W)
> >>> 2004-01-08 (Th)
> >>> 2004-01-09 (F)
> >>>
> >>> The data are read as:
> >>> "2003-12-31" (W)
> >>> "2004-01-01" (Th)
> >>> "2004-01-04" (Su)
> >>> "2004-01-05" (M)
> >>> "2004-01-06" (Tu)
> >>> "2004-01-07" (W)
> >>> "2004-01-08" (Th)
> >>>
> >>>
> >>>
> >>> The codes are (also attached):
> >>>
> >>>
> >>> rm(list=ls())
> >>> library(XLConnect)
> >>> library(xlsx)
> >>>
> >>> fl<-paste("allData_out3.xlsx")
> >>> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
> >>> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
> >>> a_col<-readWorksheetFromFile(fl, sheet="first")
> >>> date11<-as.Date(a_col$date, format="%Y-%m-%d")
> >>>
> >>>
> >>> The output:
> >>>> date11
> >>> [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
> >>> "2004-01-07"
> >>> [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
> >>> "2004-01-15"
> >>> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
> >>> "2004-01-25"
> >>> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
> >>>>
> >>>
> >>>
> >>> Thanks!!
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From ericjberger at gmail.com  Sun Sep 24 09:19:14 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 24 Sep 2017 10:19:14 +0300
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
 <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
 <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>
 <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>
Message-ID: <CAGgJW77H_r32TQLqsLBACURErcyMCjvG4QYdQ6=X2TvipGbUpw@mail.gmail.com>

Hi John,
I was able to reproduce your problem in my environment.
I modified the statement
date11<-as.Date(a_col$date, format="%Y-%m-%d")
to
date11<-as.Date(as.POSIXlt(a_col$date),format="%Y-%m-%d")
which then gives the output you would like to see (at least on my system)

> date11
[1] "2004-01-01" "2004-01-02" "2004-01-05" "2004-01-06" "2004-01-07"
"2004-01-08" "2004-01-09" "2004-01-12"
 [9] "2004-01-13" "2004-01-14" "2004-01-15" "2004-01-16" "2004-01-19"
"2004-01-20" "2004-01-21" "2004-01-22"
[17] "2004-01-23" "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29"
"2004-01-30" "2004-02-02"

HTH,

Eric

p.s.
you can also just use the shorter
date11<-as.Date(as.POSIXlt(a_col$date))



On Sun, Sep 24, 2017 at 8:51 AM, John <miaojpm at gmail.com> wrote:

> Hi,
>
>    Thank you for all your responses.
>    For Eric, The files are attached. (I believe it was also attached in my
> first message)
>    For David, Could you send me the link regarding possible solutions or a
> more comprehensive description of the problem?
>
>    Thanks,
>
> John
>
>
> 2017-09-23 22:29 GMT-07:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> > On Sep 23, 2017, at 6:30 AM, Eric Berger <ericjberger at gmail.com> wrote:
>> >
>> > Jim,
>> > I don't see how that link could be related to John's issue. Symptoms
>> > related to your link involve discrepancies of four years whereas John is
>> > seeing discrepancies of one day.
>> >
>>
>> The MS Excel starting point was off by one day. R does not repeat that
>> error. MS claims that their  error is justified by needing to copy the
>> error made by Lotus123 and then because they wanted backward compatibility.
>>
>> I'm not sure why the XLConnect package does not fix the error. They just
>> use the integer from Excel and let R apply it correctly.
>> --
>> David.
>>
>>
>> > John,
>> > I do not see any attached files.
>> >
>> > Regards
>> >
>> > On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com>
>> wrote:
>> >
>> >> Hi John,
>> >> It could be due to this:
>> >>
>> >> https://support.microsoft.com/en-au/help/214330/differences-
>> >> between-the-1900-and-the-1904-date-system-in-excel
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
>> >>> Hi,
>> >>>
>> >>>   I tried to read xlsx files by "XLConnect" packages, but the dates
>> are
>> >>> one day earlier than it is supposed to be. I moved from California to
>> >>> Taiwan (Eastern Asia), and it worked well in California, but not in
>> >> Taiwan.
>> >>> Even if I adjust my Mac time to California time zone, it gives the
>> wrong
>> >>> dates. I don't know which part of the setting (in RStudio or in my
>> Mac?)
>> >> I
>> >>> should adjust. The codes and the data are attached.
>> >>>
>> >>>   My data are on weekdays, Monday to Friday every week, but they are
>> >> read
>> >>> as Sunday to Thursday.
>> >>>
>> >>> Data:
>> >>> 2004-01-01 (Th)
>> >>> 2004-01-02 (F)
>> >>> 2004-01-05 (M)
>> >>> 2004-01-06 (T)
>> >>> 2004-01-07 (W)
>> >>> 2004-01-08 (Th)
>> >>> 2004-01-09 (F)
>> >>>
>> >>> The data are read as:
>> >>> "2003-12-31" (W)
>> >>> "2004-01-01" (Th)
>> >>> "2004-01-04" (Su)
>> >>> "2004-01-05" (M)
>> >>> "2004-01-06" (Tu)
>> >>> "2004-01-07" (W)
>> >>> "2004-01-08" (Th)
>> >>>
>> >>>
>> >>>
>> >>> The codes are (also attached):
>> >>>
>> >>>
>> >>> rm(list=ls())
>> >>> library(XLConnect)
>> >>> library(xlsx)
>> >>>
>> >>> fl<-paste("allData_out3.xlsx")
>> >>> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
>> >>> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
>> >>> a_col<-readWorksheetFromFile(fl, sheet="first")
>> >>> date11<-as.Date(a_col$date, format="%Y-%m-%d")
>> >>>
>> >>>
>> >>> The output:
>> >>>> date11
>> >>> [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
>> >>> "2004-01-07"
>> >>> [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
>> >>> "2004-01-15"
>> >>> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
>> >>> "2004-01-25"
>> >>> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
>> >>>>
>> >>>
>> >>>
>> >>> Thanks!!
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>  -Gehm's Corollary to Clarke's Third Law
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Sep 24 09:33:56 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 24 Sep 2017 00:33:56 -0700
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
 <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
 <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>
 <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>
Message-ID: <F77CB0EE-DCFC-4826-B706-5CD1F4BE3A48@dcn.davis.ca.us>

FYI: Most files you might attach to an email sent to the mailing list will not transmitted to us due to virus propagation policies of the mailing list (they are removed.... see the Posting Guide). The best method for sharing binary files is to to put them on a website like Dropbox or Google Drive. For most R questions the best possible solution would be to use the dput function to create an R statement that we can execute to get the object in our R session.  [1][2][3] This technique allows you to send your entire question in the email body, with no risk of losing pieces. Obviously this would be difficult with this particular question. 

The mailing list is also a plain text mailing list, so when you send HTML it often gets mangled... take the time to set your email format to plain text before sending to the list. 

---

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On September 23, 2017 10:51:16 PM PDT, John <miaojpm at gmail.com> wrote:
>Hi,
>
>   Thank you for all your responses.
>For Eric, The files are attached. (I believe it was also attached in my
>first message)
>For David, Could you send me the link regarding possible solutions or a
>more comprehensive description of the problem?
>
>   Thanks,
>
>John
>
>
>2017-09-23 22:29 GMT-07:00 David Winsemius <dwinsemius at comcast.net>:
>
>>
>> > On Sep 23, 2017, at 6:30 AM, Eric Berger <ericjberger at gmail.com>
>wrote:
>> >
>> > Jim,
>> > I don't see how that link could be related to John's issue.
>Symptoms
>> > related to your link involve discrepancies of four years whereas
>John is
>> > seeing discrepancies of one day.
>> >
>>
>> The MS Excel starting point was off by one day. R does not repeat
>that
>> error. MS claims that their  error is justified by needing to copy
>the
>> error made by Lotus123 and then because they wanted backward
>compatibility.
>>
>> I'm not sure why the XLConnect package does not fix the error. They
>just
>> use the integer from Excel and let R apply it correctly.
>> --
>> David.
>>
>>
>> > John,
>> > I do not see any attached files.
>> >
>> > Regards
>> >
>> > On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com>
>wrote:
>> >
>> >> Hi John,
>> >> It could be due to this:
>> >>
>> >> https://support.microsoft.com/en-au/help/214330/differences-
>> >> between-the-1900-and-the-1904-date-system-in-excel
>> >>
>> >> Jim
>> >>
>> >>
>> >> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
>> >>> Hi,
>> >>>
>> >>>   I tried to read xlsx files by "XLConnect" packages, but the
>dates are
>> >>> one day earlier than it is supposed to be. I moved from
>California to
>> >>> Taiwan (Eastern Asia), and it worked well in California, but not
>in
>> >> Taiwan.
>> >>> Even if I adjust my Mac time to California time zone, it gives
>the
>> wrong
>> >>> dates. I don't know which part of the setting (in RStudio or in
>my
>> Mac?)
>> >> I
>> >>> should adjust. The codes and the data are attached.
>> >>>
>> >>>   My data are on weekdays, Monday to Friday every week, but they
>are
>> >> read
>> >>> as Sunday to Thursday.
>> >>>
>> >>> Data:
>> >>> 2004-01-01 (Th)
>> >>> 2004-01-02 (F)
>> >>> 2004-01-05 (M)
>> >>> 2004-01-06 (T)
>> >>> 2004-01-07 (W)
>> >>> 2004-01-08 (Th)
>> >>> 2004-01-09 (F)
>> >>>
>> >>> The data are read as:
>> >>> "2003-12-31" (W)
>> >>> "2004-01-01" (Th)
>> >>> "2004-01-04" (Su)
>> >>> "2004-01-05" (M)
>> >>> "2004-01-06" (Tu)
>> >>> "2004-01-07" (W)
>> >>> "2004-01-08" (Th)
>> >>>
>> >>>
>> >>>
>> >>> The codes are (also attached):
>> >>>
>> >>>
>> >>> rm(list=ls())
>> >>> library(XLConnect)
>> >>> library(xlsx)
>> >>>
>> >>> fl<-paste("allData_out3.xlsx")
>> >>> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
>> >>> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
>> >>> a_col<-readWorksheetFromFile(fl, sheet="first")
>> >>> date11<-as.Date(a_col$date, format="%Y-%m-%d")
>> >>>
>> >>>
>> >>> The output:
>> >>>> date11
>> >>> [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05"
>"2004-01-06"
>> >>> "2004-01-07"
>> >>> [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13"
>"2004-01-14"
>> >>> "2004-01-15"
>> >>> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21"
>"2004-01-22"
>> >>> "2004-01-25"
>> >>> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29"
>"2004-02-01"
>> >>>>
>> >>>
>> >>>
>> >>> Thanks!!
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> 'Any technology distinguishable from magic is insufficiently
>advanced.'
>>  -Gehm's Corollary to Clarke's Third Law
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Sep 24 09:41:06 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 24 Sep 2017 00:41:06 -0700
Subject: [R] gsDesign Pocock & OBF boundary
In-Reply-To: <533519797.1008471.1506228785048@mail.yahoo.com>
References: <1357854377.611471.1506123122758.ref@mail.yahoo.com>
 <1357854377.611471.1506123122758@mail.yahoo.com>
 <CC8B71CE-08B2-4E21-8D11-F06DD27C72F7@xs4all.nl>
 <533519797.1008471.1506228785048@mail.yahoo.com>
Message-ID: <D258B2BF-8636-4C17-A021-80703B90F979@dcn.davis.ca.us>

Still failed. 

The first secret is in your email program settings, to use Plain Text format (at least for emails you send to this mailing list).

The second secret tool to use is the reprex package to let you verify that your code example will do on our computers what it is doing on your computer before you send it to us. That will also involve giving us some sample data or referencing some data already available to us in a relevant package. See [1], [2] and [3] for more discussion of how to succeed at communicating on the Internet regarding R. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.

On September 23, 2017 9:53:05 PM PDT, array chip via R-help <r-help at r-project.org> wrote:
>Sorry for messed up text. Here it goes again:
>I am learning to use the gsDesign package.
>I have a question about Pocock and OBF boundary. As far as I can
>understand, these 2 boundaries require equal spacing between interim
>analyses (maybe this is not correct?). But looks like I can still use
>gsDesign to run an analysis based on unequal spacing:?
>> gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')
>Symmetric two-sided group sequential design with 90 %power and 5 % Type
>I Error.Spending computations assume trial stops if a bound is
>crossed.? ? ? ? ? Sample? ? ? ? ? Size? Analysis Ratio*? Z? Nominal p?
>Spend? ? ? ? 1? 0.796 1.82? ? 0.0346 0.0346? ? ? ? 2? 1.061 1.82? ?
>0.0346 0.0154? ? Total? ? ? ? ? ? ? ? ? ? ? 0.0500?++alpha spending:
>Pocock boundary.*Sample size ratio compared to fixed design with no
>interim?
>Can anyone share some light whether the above analysis is still valid?
>Or for unequal spacing, I have to use Lan-Demet?s error spending
>function approximations? Thank you,
>
>
>
>      From: Berend Hasselman <bhh at xs4all.nl>
> To: array chip <arrayprofile at yahoo.com> 
>Cc: R-help Mailing List <r-help at r-project.org>
> Sent: Friday, September 22, 2017 11:46 PM
> Subject: Re: [R] gsDesign Pocock & OBF boundary
>   
>
>> On 23 Sep 2017, at 01:32, array chip via R-help
><r-help at r-project.org> wrote:
>> 
>> Hi, 
>> 
>> I am learning to use your gsDesign package! I have a question about
>Pocock and OBF boundary. As far as Iunderstand, these 2 boundaries
>require equal spacing between interim analyses(maybe this is not
>correct?). But I can still use gsDesign to run an analysisbased on
>unequal spacing:
>gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')Symmetrictwo-sided
>group sequential design with90 %power and 5 % Type I
>Error.Spendingcomputations assume trial stops if a bound is crossed.? ?
>? ? ? Sample? ? ? ? ? Size? AnalysisRatio*? Z? Nominal p? Spend? ? ? ?
>1? 0.796 1.82? ? 0.0346 0.0346? ? ? ? 2? 1.061 1.82? ? 0.0346 0.0154? ?
>Total? ? ? ? ? ? ? ? ? ? ? 0.0500? ++alpha
>spending:Pocockboundary.*Sample size ratio compared to fixed design
>with no interim Can anyone share some light whether the above analysis
>is stillvalid? Or for unequal spacing, I have to use Lan-Demet?s error
>spendingfunction approximations? Thank you,
>> ??? [[alternative HTML version deleted]]
>> 
>
>Your example code is a complete mess.
>Do NOT post in html. This is a plain text mailing list.
>Read the Posting Guide (https://www.r-project.org/posting-guide.html).
>
>Berend Hasselman]
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>   
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Sun Sep 24 09:52:11 2017
From: miaojpm at gmail.com (John)
Date: Sun, 24 Sep 2017 00:52:11 -0700
Subject: [R] "XLConnect" packages; Excel dates read incorrectly
In-Reply-To: <CAGgJW77H_r32TQLqsLBACURErcyMCjvG4QYdQ6=X2TvipGbUpw@mail.gmail.com>
References: <CABcx46Chzs=FRpW445V7ZGxUw_Li7=rNbQs-yGer96KE3qKHdQ@mail.gmail.com>
 <CA+8X3fV_hCHE25v64Y_DAzh4uJp991SzOoqbXK3+Fbn7GXBwtw@mail.gmail.com>
 <CAGgJW75PfJUBsGpwj+e4LWhVeEf48c=mp0PcGWm1sX6ZxPM+Mw@mail.gmail.com>
 <7C4272E7-8282-4077-98B3-55CA7D1E5F40@comcast.net>
 <CABcx46CbtEQVLgdgv6bTemRrcNuejh2bbDZa4cmUo-BHX3cRAA@mail.gmail.com>
 <CAGgJW77H_r32TQLqsLBACURErcyMCjvG4QYdQ6=X2TvipGbUpw@mail.gmail.com>
Message-ID: <CABcx46AJee0wfNNnhS=wY3eb-ZdWeo-fMOddRYZ=Yvm1oWZkzQ@mail.gmail.com>

Hi Eric,

   Thank you for your message! It does work in my system!!
   I follow you by typing it:
date11<-as.Date(as.POSIXlt(a_col$date),format="%Y-%m-%d")

   Then I typed it:
   date12<-as.Date(a_col$date, format="%Y-%m-%d")
   date12 yields exactly the same results as date11.

   Then my system time zone has changed:  (I reset my Mac time zone to
California time when I found the problem a few days ago, but I did not
restart the system until the last night, so I am not sure whether your line
changes it or restarting my Mac changes it)
> Sys.time()
[1] "2017-09-24 00:41:32 PDT"

   If it worked as it did yesterday, then system time should return
"2017-09-24 15:41:32 CST". 15:41:32 is my local time (In Taiwan, same time
zone as Singapore, China, and Malaysia), but CST is a time zone int the US.

John



2017-09-24 0:19 GMT-07:00 Eric Berger <ericjberger at gmail.com>:

> Hi John,
> I was able to reproduce your problem in my environment.
> I modified the statement
> date11<-as.Date(a_col$date, format="%Y-%m-%d")
> to
> date11<-as.Date(as.POSIXlt(a_col$date),format="%Y-%m-%d")
> which then gives the output you would like to see (at least on my system)
>
> > date11
> [1] "2004-01-01" "2004-01-02" "2004-01-05" "2004-01-06" "2004-01-07"
> "2004-01-08" "2004-01-09" "2004-01-12"
>  [9] "2004-01-13" "2004-01-14" "2004-01-15" "2004-01-16" "2004-01-19"
> "2004-01-20" "2004-01-21" "2004-01-22"
> [17] "2004-01-23" "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29"
> "2004-01-30" "2004-02-02"
>
> HTH,
>
> Eric
>
> p.s.
> you can also just use the shorter
> date11<-as.Date(as.POSIXlt(a_col$date))
>
>
>
> On Sun, Sep 24, 2017 at 8:51 AM, John <miaojpm at gmail.com> wrote:
>
>> Hi,
>>
>>    Thank you for all your responses.
>>    For Eric, The files are attached. (I believe it was also attached in
>> my first message)
>>    For David, Could you send me the link regarding possible solutions or
>> a more comprehensive description of the problem?
>>
>>    Thanks,
>>
>> John
>>
>>
>> 2017-09-23 22:29 GMT-07:00 David Winsemius <dwinsemius at comcast.net>:
>>
>>>
>>> > On Sep 23, 2017, at 6:30 AM, Eric Berger <ericjberger at gmail.com>
>>> wrote:
>>> >
>>> > Jim,
>>> > I don't see how that link could be related to John's issue. Symptoms
>>> > related to your link involve discrepancies of four years whereas John
>>> is
>>> > seeing discrepancies of one day.
>>> >
>>>
>>> The MS Excel starting point was off by one day. R does not repeat that
>>> error. MS claims that their  error is justified by needing to copy the
>>> error made by Lotus123 and then because they wanted backward compatibility.
>>>
>>> I'm not sure why the XLConnect package does not fix the error. They just
>>> use the integer from Excel and let R apply it correctly.
>>> --
>>> David.
>>>
>>>
>>> > John,
>>> > I do not see any attached files.
>>> >
>>> > Regards
>>> >
>>> > On Sat, Sep 23, 2017 at 1:30 PM, Jim Lemon <drjimlemon at gmail.com>
>>> wrote:
>>> >
>>> >> Hi John,
>>> >> It could be due to this:
>>> >>
>>> >> https://support.microsoft.com/en-au/help/214330/differences-
>>> >> between-the-1900-and-the-1904-date-system-in-excel
>>> >>
>>> >> Jim
>>> >>
>>> >>
>>> >> On Sat, Sep 23, 2017 at 1:04 PM, John <miaojpm at gmail.com> wrote:
>>> >>> Hi,
>>> >>>
>>> >>>   I tried to read xlsx files by "XLConnect" packages, but the dates
>>> are
>>> >>> one day earlier than it is supposed to be. I moved from California to
>>> >>> Taiwan (Eastern Asia), and it worked well in California, but not in
>>> >> Taiwan.
>>> >>> Even if I adjust my Mac time to California time zone, it gives the
>>> wrong
>>> >>> dates. I don't know which part of the setting (in RStudio or in my
>>> Mac?)
>>> >> I
>>> >>> should adjust. The codes and the data are attached.
>>> >>>
>>> >>>   My data are on weekdays, Monday to Friday every week, but they are
>>> >> read
>>> >>> as Sunday to Thursday.
>>> >>>
>>> >>> Data:
>>> >>> 2004-01-01 (Th)
>>> >>> 2004-01-02 (F)
>>> >>> 2004-01-05 (M)
>>> >>> 2004-01-06 (T)
>>> >>> 2004-01-07 (W)
>>> >>> 2004-01-08 (Th)
>>> >>> 2004-01-09 (F)
>>> >>>
>>> >>> The data are read as:
>>> >>> "2003-12-31" (W)
>>> >>> "2004-01-01" (Th)
>>> >>> "2004-01-04" (Su)
>>> >>> "2004-01-05" (M)
>>> >>> "2004-01-06" (Tu)
>>> >>> "2004-01-07" (W)
>>> >>> "2004-01-08" (Th)
>>> >>>
>>> >>>
>>> >>>
>>> >>> The codes are (also attached):
>>> >>>
>>> >>>
>>> >>> rm(list=ls())
>>> >>> library(XLConnect)
>>> >>> library(xlsx)
>>> >>>
>>> >>> fl<-paste("allData_out3.xlsx")
>>> >>> a1<-readWorksheetFromFile(fl, sheet="first", colTypes="numeric")
>>> >>> b1<-readWorksheetFromFile(fl, sheet="second", colTypes="numeric")
>>> >>> a_col<-readWorksheetFromFile(fl, sheet="first")
>>> >>> date11<-as.Date(a_col$date, format="%Y-%m-%d")
>>> >>>
>>> >>>
>>> >>> The output:
>>> >>>> date11
>>> >>> [1] "2003-12-31" "2004-01-01" "2004-01-04" "2004-01-05" "2004-01-06"
>>> >>> "2004-01-07"
>>> >>> [7] "2004-01-08" "2004-01-11" "2004-01-12" "2004-01-13" "2004-01-14"
>>> >>> "2004-01-15"
>>> >>> [13] "2004-01-18" "2004-01-19" "2004-01-20" "2004-01-21" "2004-01-22"
>>> >>> "2004-01-25"
>>> >>> [19] "2004-01-26" "2004-01-27" "2004-01-28" "2004-01-29" "2004-02-01"
>>> >>>>
>>> >>>
>>> >>>
>>> >>> Thanks!!
>>> >>> ______________________________________________
>>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >>> PLEASE do read the posting guide http://www.R-project.org/
>>> >> posting-guide.html
>>> >>> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide http://www.R-project.org/
>>> >> posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> 'Any technology distinguishable from magic is insufficiently advanced.'
>>>  -Gehm's Corollary to Clarke's Third Law
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From arrayprofile at yahoo.com  Sun Sep 24 20:02:27 2017
From: arrayprofile at yahoo.com (array chip)
Date: Sun, 24 Sep 2017 18:02:27 +0000 (UTC)
Subject: [R] gsDesign Pocock & OBF boundary
In-Reply-To: <D258B2BF-8636-4C17-A021-80703B90F979@dcn.davis.ca.us>
References: <1357854377.611471.1506123122758.ref@mail.yahoo.com>
 <1357854377.611471.1506123122758@mail.yahoo.com>
 <CC8B71CE-08B2-4E21-8D11-F06DD27C72F7@xs4all.nl>
 <533519797.1008471.1506228785048@mail.yahoo.com>
 <D258B2BF-8636-4C17-A021-80703B90F979@dcn.davis.ca.us>
Message-ID: <393069830.1145853.1506276147425@mail.yahoo.com>

Sorry it didn 't work again. I am on yahoo mail, and just found a switch to change from Rick text to Plain text, so here it goes again:


I am learning to use the gsDesign package. 

I have a question about Pocock and OBF boundary. As far as I can understand, these 2 boundaries require equal spacing between interim analyses (maybe this is not correct?). But looks like I can still use gsDesign to run an analysis based on unequal spacing: 

> library(gsDesign)
> gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock') 


Symmetric two-sided group sequential design with 
90 % power and 5 % Type I Error. 
Spending computations assume trial stops 
if a bound is crossed. 

         Sample 
         Size 
Analysis Ratio*  Z   Nominal p  Spend 
       1  0.796  1.82   0.0346 0.0346 
       2  1.061  1.82   0.0346 0.0154 
   Total                      0.0500 

++ alpha spending: 
Pocock boundary. 
* Sample size ratio compared to fixed design with no interim 
  

Can anyone share some light whether the above analysis is still valid? Or for unequal spacing, I have to use Lan-Demet?s error spending function approximations? Thank you,




________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>

oject.org>; Berend Hasselman <bhh at xs4all.nl> 
Cc: R-help Mailing List <r-help at r-project.org>
Sent: Sunday, September 24, 2017 12:41 AM
Subject: Re: [R] gsDesign Pocock & OBF boundary



Still failed. 

The first secret is in your email program settings, to use Plain Text format (at least for emails you send to this mailing list).

The second secret tool to use is the reprex package to let you verify that your code example will do on our computers what it is doing on your computer before you send it to us. That will also involve giving us some sample data or referencing some data already available to us in a relevant package. See [1], [2] and [3] for more discussion of how to succeed at communicating on the Internet regarding R. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 
-- 
Sent from my phone. Please excuse my brevity.


On September 23, 2017 9:53:05 PM PDT, array chip via R-help <r-help at r-project.org> wrote:
>Sorry for messed up text. Here it goes again:
>I am learning to use the gsDesign package.
>I have a question about Pocock and OBF boundary. As far as I can
>understand, these 2 boundaries require equal spacing between interim
>analyses (maybe this is not correct?). But looks like I can still use
>gsDesign to run an analysis based on unequal spacing: 
>> gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')
>Symmetric two-sided group sequential design with 90 %power and 5 % Type
>I Error.Spending computations assume trial stops if a bound is
>crossed.          Sample          Size  Analysis Ratio*  Z  Nominal p 
>Spend        1  0.796 1.82    0.0346 0.0346        2  1.061 1.82   
>0.0346 0.0154    Total                      0.0500 ++alpha spending:
>Pocock boundary.*Sample size ratio compared to fixed design with no
>interim 
>Can anyone share some light whether the above analysis is still valid?
>Or for unequal spacing, I have to use Lan-Demet?s error spending
>function approximations? Thank you,
>
>
>
>      From: Berend Hasselman <bhh at xs4all.nl>

>Cc: R-help Mailing List <r-help at r-project.org>
> Sent: Friday, September 22, 2017 11:46 PM
> Subject: Re: [R] gsDesign Pocock & OBF boundary
>  
>
>> On 23 Sep 2017, at 01:32, array chip via R-help
><r-help at r-project.org> wrote:
>> 
>> Hi, 
>> 
>> I am learning to use your gsDesign package! I have a question about
>Pocock and OBF boundary. As far as Iunderstand, these 2 boundaries
>require equal spacing between interim analyses(maybe this is not
>correct?). But I can still use gsDesign to run an analysisbased on
>unequal spacing:
>gsDesign(k=2,test.type=2,timing=c(0.75,1),alpha=0.05,sfu='Pocock')Symmetrictwo-sided
>group sequential design with90 %power and 5 % Type I
>Error.Spendingcomputations assume trial stops if a bound is crossed.   
>      Sample          Size  AnalysisRatio*  Z  Nominal p  Spend       
>1  0.796 1.82    0.0346 0.0346        2  1.061 1.82    0.0346 0.0154   
>Total                      0.0500  ++alpha
>spending:Pocockboundary.*Sample size ratio compared to fixed design
>with no interim Can anyone share some light whether the above analysis
>is stillvalid? Or for unequal spacing, I have to use Lan-Demet?s error
>spendingfunction approximations? Thank you,
>>     [[alternative HTML version deleted]]
>> 
>
>Your example code is a complete mess.
>Do NOT post in html. This is a plain text mailing list.
>Read the Posting Guide (https://www.r-project.org/posting-guide.html).
>
>Berend Hasselman]
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>  
>    [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From saubhagya at gatech.edu  Sun Sep 24 22:12:42 2017
From: saubhagya at gatech.edu (Rathore, Saubhagya Singh)
Date: Sun, 24 Sep 2017 20:12:42 +0000
Subject: [R] R version 3.3.2,
 Windows 10: gstat package: Error in fitting a variogram model using
 'fit.variogram' function
Message-ID: <DM5PR07MB317952131F551755A6A65BD7CF650@DM5PR07MB3179.namprd07.prod.outlook.com>

Dear Members,



I am trying to fit a variogram model using fit.variogram function from the gstat package. The figure showing my experimental variogram can be seen here: https://i.stack.imgur.com/UZXw4.png

My code line for this operation is:

> c2.vgm.fit<-fit.variogram(c2.vgm.exp,vgm(nugget=0, psill=400,model="Exp",range =40000),fit.method = 7)

The system throws following error message:

Error in switch(model, exponential = fit.exponential(v.object, c0 = nugget,  :

  EXPR must be a length 1 vector

Any help to know the cause of the error and avoiding it would be highly appreciated.

Thank you very much
Saubhagya Singh Rathore
PhD Candidate
Civil and Environmental Engineering
Georgia Institute of Technology



	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Sun Sep 24 22:58:38 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Sun, 24 Sep 2017 16:58:38 -0400
Subject: [R] Remove spacing at the top and bottom of a plot
Message-ID: <CAE9stmcWq2K=Pneyz_crTHMS=vc3wrs_Yd+0wf22WaBGFG0azg@mail.gmail.com>

Dear All:

Is there is away to remove spacing at the top and the bottom of a plot? If
so, any help will be appreciated.


Please use this code as an example:


par(mfrow=c(1,2))


lizard <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6,8.8, 8.8,
9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)

n.draw <- 100
mu <- 9
n <- 24
SD <- sd(lizard)
draws <- matrix(rnorm(n.draw * n, mu, SD), n)

get.conf.int <- function(x) {
  t.test(x)$conf.int
}

conf.int <- apply(draws, 2, get.conf.int)

plot(range(conf.int), c(0, 1 + n.draw), type = "n", xlab = "mean tail
length", ylab = "sample run")

for (i in 1:n.draw)  {
  if(conf.int[1,i] <= mu & conf.int[2,i] >= mu ){
####    lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'green')
    lines(conf.int[, i], rep(i, 2), lwd = 2)
  }
  else {
    lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'red')
  }
}

abline(v = 9, lwd = 3, col='blue')   #### lty = 2,





Thank you very much for your help.


with many thanks
abou
______________________
AbouEl-Makarim Aboueissa, PhD

Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Sep 24 23:02:09 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 24 Sep 2017 14:02:09 -0700
Subject: [R] R version 3.3.2,
 Windows 10: gstat package: Error in fitting a variogram model using
 'fit.variogram' function
In-Reply-To: <DM5PR07MB317952131F551755A6A65BD7CF650@DM5PR07MB3179.namprd07.prod.outlook.com>
References: <DM5PR07MB317952131F551755A6A65BD7CF650@DM5PR07MB3179.namprd07.prod.outlook.com>
Message-ID: <CAGxFJbRF6xNdLPtLBci7azHJMGr29W3AqWnZxH5woAVZS=KETA@mail.gmail.com>

No reproducible example makes it difficult to diagnose the source of the
error.

Did you try using traceback() after the error? That might give you a hint.

I am unfamiliar with the package and function, but check the "range"
argument to make sure it's supposed to be a single value and not a vector
(just a wild guess on my party -- therefore likely wrong).

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 24, 2017 at 1:12 PM, Rathore, Saubhagya Singh <
saubhagya at gatech.edu> wrote:

> Dear Members,
>
>
>
> I am trying to fit a variogram model using fit.variogram function from the
> gstat package. The figure showing my experimental variogram can be seen
> here: https://i.stack.imgur.com/UZXw4.png
>
> My code line for this operation is:
>
> > c2.vgm.fit<-fit.variogram(c2.vgm.exp,vgm(nugget=0,
> psill=400,model="Exp",range =40000),fit.method = 7)
>
> The system throws following error message:
>
> Error in switch(model, exponential = fit.exponential(v.object, c0 =
> nugget,  :
>
>   EXPR must be a length 1 vector
>
> Any help to know the cause of the error and avoiding it would be highly
> appreciated.
>
> Thank you very much
> Saubhagya Singh Rathore
> PhD Candidate
> Civil and Environmental Engineering
> Georgia Institute of Technology
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Sun Sep 24 23:28:45 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 24 Sep 2017 21:28:45 +0000
Subject: [R] Remove spacing at the top and bottom of a plot
In-Reply-To: <CAE9stmcWq2K=Pneyz_crTHMS=vc3wrs_Yd+0wf22WaBGFG0azg@mail.gmail.com>
References: <CAE9stmcWq2K=Pneyz_crTHMS=vc3wrs_Yd+0wf22WaBGFG0azg@mail.gmail.com>
Message-ID: <1a26ef609bbc4b8aaa0b4f5ad1242024@exch-2p-mbx-w2.ads.tamu.edu>

The default margins are set as lines below, left, top, and right using mar=c(5.1, 4.1, 4.1, 2.1). Just change the top margin something like 1.1:

par(mfrow=c(1,2), mar=c(5.1, 4.1, 1.1, 2.1))

---------------------------
David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of AbouEl-Makarim Aboueissa
Sent: Sunday, September 24, 2017 3:59 PM
To: R mailing list <r-help at r-project.org>
Subject: [R] Remove spacing at the top and bottom of a plot

Dear All:

Is there is away to remove spacing at the top and the bottom of a plot? If
so, any help will be appreciated.


Please use this code as an example:


par(mfrow=c(1,2))


lizard <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6,8.8, 8.8,
9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)

n.draw <- 100
mu <- 9
n <- 24
SD <- sd(lizard)
draws <- matrix(rnorm(n.draw * n, mu, SD), n)

get.conf.int <- function(x) {
  t.test(x)$conf.int
}

conf.int <- apply(draws, 2, get.conf.int)

plot(range(conf.int), c(0, 1 + n.draw), type = "n", xlab = "mean tail
length", ylab = "sample run")

for (i in 1:n.draw)  {
  if(conf.int[1,i] <= mu & conf.int[2,i] >= mu ){
####    lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'green')
    lines(conf.int[, i], rep(i, 2), lwd = 2)
  }
  else {
    lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'red')
  }
}

abline(v = 9, lwd = 3, col='blue')   #### lty = 2,





Thank you very much for your help.


with many thanks
abou
______________________
AbouEl-Makarim Aboueissa, PhD

Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From abouelmakarim1962 at gmail.com  Mon Sep 25 01:28:55 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Sun, 24 Sep 2017 19:28:55 -0400
Subject: [R] Remove spacing at the top and bottom of a plot
In-Reply-To: <1a26ef609bbc4b8aaa0b4f5ad1242024@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAE9stmcWq2K=Pneyz_crTHMS=vc3wrs_Yd+0wf22WaBGFG0azg@mail.gmail.com>
 <1a26ef609bbc4b8aaa0b4f5ad1242024@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAE9stmebdAbsMu7ZRCNyLbRS1JzXMCh5WHJmSenT0A2Mf=A+HQ@mail.gmail.com>

Dear David:

Thank you very much.

with thanks
abou

On Sun, Sep 24, 2017 at 5:28 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> The default margins are set as lines below, left, top, and right using
> mar=c(5.1, 4.1, 4.1, 2.1). Just change the top margin something like 1.1:
>
> par(mfrow=c(1,2), mar=c(5.1, 4.1, 1.1, 2.1))
>
> ---------------------------
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> AbouEl-Makarim Aboueissa
> Sent: Sunday, September 24, 2017 3:59 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] Remove spacing at the top and bottom of a plot
>
> Dear All:
>
> Is there is away to remove spacing at the top and the bottom of a plot? If
> so, any help will be appreciated.
>
>
> Please use this code as an example:
>
>
> par(mfrow=c(1,2))
>
>
> lizard <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5, 8.6,8.8, 8.8,
> 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)
>
> n.draw <- 100
> mu <- 9
> n <- 24
> SD <- sd(lizard)
> draws <- matrix(rnorm(n.draw * n, mu, SD), n)
>
> get.conf.int <- function(x) {
>   t.test(x)$conf.int
> }
>
> conf.int <- apply(draws, 2, get.conf.int)
>
> plot(range(conf.int), c(0, 1 + n.draw), type = "n", xlab = "mean tail
> length", ylab = "sample run")
>
> for (i in 1:n.draw)  {
>   if(conf.int[1,i] <= mu & conf.int[2,i] >= mu ){
> ####    lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'green')
>     lines(conf.int[, i], rep(i, 2), lwd = 2)
>   }
>   else {
>     lines(conf.int[, i], rep(i, 2), lwd = 2, col = 'red')
>   }
> }
>
> abline(v = 9, lwd = 3, col='blue')   #### lty = 2,
>
>
>
>
>
> Thank you very much for your help.
>
>
> with many thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
>
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From abouelmakarim1962 at gmail.com  Mon Sep 25 01:35:28 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Sun, 24 Sep 2017 19:35:28 -0400
Subject: [R] Shift the normal curve to the top or near to the top of the
	histogram
Message-ID: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>

Dear All:

One more thing.

I want to add the normal curve to the histogram. Is there away to stretch
the peak of the curve to the top of the histogram or at least near to the
top of the histogram.

Please see the code below.


Lizard.tail.lengths <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5,
8.6,8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)

x<-seq(5,12, 0.001)

hist(Lizard.tail.lengths, main = "Normal Probability Plot of Lizard Tail
Lengths")

curve(dnorm(x ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
add=TRUE, col=2, lwd = 2)



with many thanks
abou
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Sep 25 02:18:01 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 25 Sep 2017 10:18:01 +1000
Subject: [R] Shift the normal curve to the top or near to the top of the
	histogram
In-Reply-To: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>
References: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>
Message-ID: <CA+8X3fWvkt6d0gsajPSGrHXJ73GwG_J8f_kbh2WEYzz5-XKsXg@mail.gmail.com>

Hi Abou,
Try this:

library(plotrix)
 curve(rescale(dnorm(x
,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
c(0,6)),add=TRUE, col=2, lwd = 2)

Jim


On Mon, Sep 25, 2017 at 9:35 AM, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
> Dear All:
>
> One more thing.
>
> I want to add the normal curve to the histogram. Is there away to stretch
> the peak of the curve to the top of the histogram or at least near to the
> top of the histogram.
>
> Please see the code below.
>
>
> Lizard.tail.lengths <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5,
> 8.6,8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)
>
> x<-seq(5,12, 0.001)
>
> hist(Lizard.tail.lengths, main = "Normal Probability Plot of Lizard Tail
> Lengths")
>
> curve(dnorm(x ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
> add=TRUE, col=2, lwd = 2)
>
>
>
> with many thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abouelmakarim1962 at gmail.com  Mon Sep 25 02:26:38 2017
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Sun, 24 Sep 2017 20:26:38 -0400
Subject: [R] Shift the normal curve to the top or near to the top of the
	histogram
In-Reply-To: <CA+8X3fWvkt6d0gsajPSGrHXJ73GwG_J8f_kbh2WEYzz5-XKsXg@mail.gmail.com>
References: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>
 <CA+8X3fWvkt6d0gsajPSGrHXJ73GwG_J8f_kbh2WEYzz5-XKsXg@mail.gmail.com>
Message-ID: <CAE9stmfYBX5zd7+L4LTiVGCi18ntMUDSiyaNByYGKZJaJh-dMg@mail.gmail.com>

Dear Jim:

Thank you very much

abou

On Sun, Sep 24, 2017 at 8:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Abou,
> Try this:
>
> library(plotrix)
>  curve(rescale(dnorm(x
> ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
> c(0,6)),add=TRUE, col=2, lwd = 2)
>
> Jim
>
>
> On Mon, Sep 25, 2017 at 9:35 AM, AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> > Dear All:
> >
> > One more thing.
> >
> > I want to add the normal curve to the histogram. Is there away to stretch
> > the peak of the curve to the top of the histogram or at least near to the
> > top of the histogram.
> >
> > Please see the code below.
> >
> >
> > Lizard.tail.lengths <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5,
> > 8.6,8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)
> >
> > x<-seq(5,12, 0.001)
> >
> > hist(Lizard.tail.lengths, main = "Normal Probability Plot of Lizard Tail
> > Lengths")
> >
> > curve(dnorm(x ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.
> lengths)),
> > add=TRUE, col=2, lwd = 2)
> >
> >
> >
> > with many thanks
> > abou
> > ______________________
> > AbouEl-Makarim Aboueissa, PhD
> > Professor of Statistics
> > Department of Mathematics and Statistics
> > University of Southern Maine
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
______________________
AbouEl-Makarim Aboueissa, PhD
Professor of Statistics
Department of Mathematics and Statistics
University of Southern Maine

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Mon Sep 25 12:00:45 2017
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 25 Sep 2017 11:00:45 +0100
Subject: [R] Shift the normal curve to the top or near to the top of the
 histogram
In-Reply-To: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>
References: <CAE9stmfnw+-9T6iJrwPjVMKs2jzb1QdWqe4fKUYvn4ZUzerEkw@mail.gmail.com>
Message-ID: <59C8D3CD.9050403@sapo.pt>

Hello,

Try using hist argument 'prob = TRUE' or, which is equivalent, 'freq = 
FALSE'.

hist(..., prob = TRUE)   # or hist(..., freq = FALSE)

This is because like this you will have a density, comparable to a 
parametric density. Note that the peak of the normal will be outside the 
plot area so you will have to adjust the plot area dimensions. In this 
case I've set 'ylim = c(0, 0.35)'.


hist(Lizard.tail.lengths, main = "Normal Probability Plot of Lizard Tail
Lengths", ylim = c(0, 0.35), prob = TRUE)

curve(dnorm(x ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
add=TRUE, col=2, lwd = 2)


Hope this helps,

Rui Barradas

Em 25-09-2017 00:35, AbouEl-Makarim Aboueissa escreveu:
> Dear All:
>
> One more thing.
>
> I want to add the normal curve to the histogram. Is there away to stretch
> the peak of the curve to the top of the histogram or at least near to the
> top of the histogram.
>
> Please see the code below.
>
>
> Lizard.tail.lengths <- c(6.2, 6.6, 7.1, 7.4, 7.6, 7.9, 8, 8.3, 8.4, 8.5,
> 8.6,8.8, 8.8, 9.1, 9.2, 9.4, 9.4, 9.7, 9.9, 10.2, 10.4, 10.8,11.3, 11.9)
>
> x<-seq(5,12, 0.001)
>
> hist(Lizard.tail.lengths, main = "Normal Probability Plot of Lizard Tail
> Lengths")
>
> curve(dnorm(x ,mean=mean(Lizard.tail.lengths),sd=sd(Lizard.tail.lengths)),
> add=TRUE, col=2, lwd = 2)
>
>
>
> with many thanks
> abou
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> Professor of Statistics
> Department of Mathematics and Statistics
> University of Southern Maine
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From careyshan at gmail.com  Mon Sep 25 13:30:49 2017
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 25 Sep 2017 12:30:49 +0100
Subject: [R] Subset
In-Reply-To: <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
Message-ID: <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>

Hi,

Lets say this was a dataframe where I had two columns

a <- c("<0.1", NA, 0.3, 5, "Nil")
b <- c("<0.1", 1, 0.3, 5, "Nil")

And I just want to remove the rows from the dataframe where there were NAs
in the b column, what is the syntax for doing that?

Thanks in advance

On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com> wrote:

> Super,
>
> Thanks
>
> On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
>> > a <- c("<0.1", NA, 0.3, 5, "Nil")
>> > a
>> [1] "<0.1" NA     "0.3"  "5"    "Nil"
>>
>> > b <- as.numeric(a)
>> Warning message:
>> NAs introduced by coercion
>> > b
>> [1]  NA  NA 0.3 5.0  NA
>>
>> > b[! is.na(b)]
>> [1] 0.3 5.0
>>
>>
>> B.
>>
>>
>> > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
>> >
>> > Hi,
>> >
>> > How do I extract just numbers from the following list:
>> >
>> > a=c("<0.1",NA,0.3,5,Nil)
>> >
>> > so I want to obtain: 0.3 and 5 from the above list
>> >
>> > Thanks
>> >
>> >
>> > --
>> > Le gach dea ghui,
>> > *Shane Carey*
>> > *GIS and Data Solutions Consultant*
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
> --
> Le gach dea ghui,
> *Shane Carey*
> *GIS and Data Solutions Consultant*
>



-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Sep 25 13:41:41 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 25 Sep 2017 07:41:41 -0400
Subject: [R] Subset
In-Reply-To: <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
 <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
Message-ID: <F44BE879-8640-458F-B01F-133DED1B9CD0@utoronto.ca>

myDF <- data.frame(a = c("<0.1", NA, 0.3, 5, "Nil"),
                   b = c("<0.1", 1, 0.3, 5, "Nil"),
                   stringsAsFactors = FALSE)

# you can subset the b-column in several ways

myDF[ , 2]
myDF[ , "b"]
myDF$b

# using the column, you make a logical vector
! is.na(as.numeric(myDF$b))


# This can be used to select the rows you want

myDF[! is.na(as.numeric(myDF$b)), ]



B.


> On Sep 25, 2017, at 7:30 AM, Shane Carey <careyshan at gmail.com> wrote:
> 
> Hi,
> 
> Lets say this was a dataframe where I had two columns
> 
> a <- c("<0.1", NA, 0.3, 5, "Nil")
> b <- c("<0.1", 1, 0.3, 5, "Nil")
> 
> And I just want to remove the rows from the dataframe where there were NAs in the b column, what is the syntax for doing that?
> 
> Thanks in advance
> 
> On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com> wrote:
> Super,
> 
> Thanks
> 
> On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > a
> [1] "<0.1" NA     "0.3"  "5"    "Nil"
> 
> > b <- as.numeric(a)
> Warning message:
> NAs introduced by coercion
> > b
> [1]  NA  NA 0.3 5.0  NA
> 
> > b[! is.na(b)]
> [1] 0.3 5.0
> 
> 
> B.
> 
> 
> > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
> >
> > Hi,
> >
> > How do I extract just numbers from the following list:
> >
> > a=c("<0.1",NA,0.3,5,Nil)
> >
> > so I want to obtain: 0.3 and 5 from the above list
> >
> > Thanks
> >
> >
> > --
> > Le gach dea ghui,
> > *Shane Carey*
> > *GIS and Data Solutions Consultant*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> -- 
> Le gach dea ghui,
> Shane Carey
> GIS and Data Solutions Consultant
> 
> 
> 
> -- 
> Le gach dea ghui,
> Shane Carey
> GIS and Data Solutions Consultant


From careyshan at gmail.com  Mon Sep 25 14:00:22 2017
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 25 Sep 2017 13:00:22 +0100
Subject: [R] Subset
In-Reply-To: <F44BE879-8640-458F-B01F-133DED1B9CD0@utoronto.ca>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
 <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
 <F44BE879-8640-458F-B01F-133DED1B9CD0@utoronto.ca>
Message-ID: <CA+jRDxBHaAJ-Po9Yp92ALMtUhhKXnDjvnO1_wx1iS5XFyP0FUQ@mail.gmail.com>

This is super, really helpfull. Sorry, one final question, lets say I
wanted to remove 0's rather than NAs , what would it be?

Thanks

On Mon, Sep 25, 2017 at 12:41 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> myDF <- data.frame(a = c("<0.1", NA, 0.3, 5, "Nil"),
>                    b = c("<0.1", 1, 0.3, 5, "Nil"),
>                    stringsAsFactors = FALSE)
>
> # you can subset the b-column in several ways
>
> myDF[ , 2]
> myDF[ , "b"]
> myDF$b
>
> # using the column, you make a logical vector
> ! is.na(as.numeric(myDF$b))
>
>
> # This can be used to select the rows you want
>
> myDF[! is.na(as.numeric(myDF$b)), ]
>
>
>
> B.
>
>
> > On Sep 25, 2017, at 7:30 AM, Shane Carey <careyshan at gmail.com> wrote:
> >
> > Hi,
> >
> > Lets say this was a dataframe where I had two columns
> >
> > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > b <- c("<0.1", 1, 0.3, 5, "Nil")
> >
> > And I just want to remove the rows from the dataframe where there were
> NAs in the b column, what is the syntax for doing that?
> >
> > Thanks in advance
> >
> > On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com>
> wrote:
> > Super,
> >
> > Thanks
> >
> > On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> > > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > > a
> > [1] "<0.1" NA     "0.3"  "5"    "Nil"
> >
> > > b <- as.numeric(a)
> > Warning message:
> > NAs introduced by coercion
> > > b
> > [1]  NA  NA 0.3 5.0  NA
> >
> > > b[! is.na(b)]
> > [1] 0.3 5.0
> >
> >
> > B.
> >
> >
> > > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
> > >
> > > Hi,
> > >
> > > How do I extract just numbers from the following list:
> > >
> > > a=c("<0.1",NA,0.3,5,Nil)
> > >
> > > so I want to obtain: 0.3 and 5 from the above list
> > >
> > > Thanks
> > >
> > >
> > > --
> > > Le gach dea ghui,
> > > *Shane Carey*
> > > *GIS and Data Solutions Consultant*
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Le gach dea ghui,
> > Shane Carey
> > GIS and Data Solutions Consultant
> >
> >
> >
> > --
> > Le gach dea ghui,
> > Shane Carey
> > GIS and Data Solutions Consultant
>
>


-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Sep 25 14:05:10 2017
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 25 Sep 2017 08:05:10 -0400
Subject: [R] Subset
In-Reply-To: <CA+jRDxBHaAJ-Po9Yp92ALMtUhhKXnDjvnO1_wx1iS5XFyP0FUQ@mail.gmail.com>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
 <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
 <F44BE879-8640-458F-B01F-133DED1B9CD0@utoronto.ca>
 <CA+jRDxBHaAJ-Po9Yp92ALMtUhhKXnDjvnO1_wx1iS5XFyP0FUQ@mail.gmail.com>
Message-ID: <FAFD2810-07D3-48F6-847D-25AE0D2F26FB@utoronto.ca>

Always via logical expressions. In this case you can use the logical expression

myDF$b  != "0"

to give you a vector of TRUE/FALSE 



B.


> On Sep 25, 2017, at 8:00 AM, Shane Carey <careyshan at gmail.com> wrote:
> 
> This is super, really helpfull. Sorry, one final question, lets say I wanted to remove 0's rather than NAs , what would it be?
> 
> Thanks
> 
> On Mon, Sep 25, 2017 at 12:41 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> myDF <- data.frame(a = c("<0.1", NA, 0.3, 5, "Nil"),
>                    b = c("<0.1", 1, 0.3, 5, "Nil"),
>                    stringsAsFactors = FALSE)
> 
> # you can subset the b-column in several ways
> 
> myDF[ , 2]
> myDF[ , "b"]
> myDF$b
> 
> # using the column, you make a logical vector
> ! is.na(as.numeric(myDF$b))
> 
> 
> # This can be used to select the rows you want
> 
> myDF[! is.na(as.numeric(myDF$b)), ]
> 
> 
> 
> B.
> 
> 
> > On Sep 25, 2017, at 7:30 AM, Shane Carey <careyshan at gmail.com> wrote:
> >
> > Hi,
> >
> > Lets say this was a dataframe where I had two columns
> >
> > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > b <- c("<0.1", 1, 0.3, 5, "Nil")
> >
> > And I just want to remove the rows from the dataframe where there were NAs in the b column, what is the syntax for doing that?
> >
> > Thanks in advance
> >
> > On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com> wrote:
> > Super,
> >
> > Thanks
> >
> > On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > > a
> > [1] "<0.1" NA     "0.3"  "5"    "Nil"
> >
> > > b <- as.numeric(a)
> > Warning message:
> > NAs introduced by coercion
> > > b
> > [1]  NA  NA 0.3 5.0  NA
> >
> > > b[! is.na(b)]
> > [1] 0.3 5.0
> >
> >
> > B.
> >
> >
> > > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com> wrote:
> > >
> > > Hi,
> > >
> > > How do I extract just numbers from the following list:
> > >
> > > a=c("<0.1",NA,0.3,5,Nil)
> > >
> > > so I want to obtain: 0.3 and 5 from the above list
> > >
> > > Thanks
> > >
> > >
> > > --
> > > Le gach dea ghui,
> > > *Shane Carey*
> > > *GIS and Data Solutions Consultant*
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Le gach dea ghui,
> > Shane Carey
> > GIS and Data Solutions Consultant
> >
> >
> >
> > --
> > Le gach dea ghui,
> > Shane Carey
> > GIS and Data Solutions Consultant
> 
> 
> 
> 
> -- 
> Le gach dea ghui,
> Shane Carey
> GIS and Data Solutions Consultant


From careyshan at gmail.com  Mon Sep 25 15:02:21 2017
From: careyshan at gmail.com (Shane Carey)
Date: Mon, 25 Sep 2017 14:02:21 +0100
Subject: [R] Subset
In-Reply-To: <FAFD2810-07D3-48F6-847D-25AE0D2F26FB@utoronto.ca>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
 <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
 <F44BE879-8640-458F-B01F-133DED1B9CD0@utoronto.ca>
 <CA+jRDxBHaAJ-Po9Yp92ALMtUhhKXnDjvnO1_wx1iS5XFyP0FUQ@mail.gmail.com>
 <FAFD2810-07D3-48F6-847D-25AE0D2F26FB@utoronto.ca>
Message-ID: <CA+jRDxDemzqS6tZ+uU0gUTcBvOjF4g7iru_NLV1jDr=M=Nm9Kw@mail.gmail.com>

Super, thanks Boris. Top notch :-)

On Mon, Sep 25, 2017 at 1:05 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Always via logical expressions. In this case you can use the logical
> expression
>
> myDF$b  != "0"
>
> to give you a vector of TRUE/FALSE
>
>
>
> B.
>
>
> > On Sep 25, 2017, at 8:00 AM, Shane Carey <careyshan at gmail.com> wrote:
> >
> > This is super, really helpfull. Sorry, one final question, lets say I
> wanted to remove 0's rather than NAs , what would it be?
> >
> > Thanks
> >
> > On Mon, Sep 25, 2017 at 12:41 PM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> > myDF <- data.frame(a = c("<0.1", NA, 0.3, 5, "Nil"),
> >                    b = c("<0.1", 1, 0.3, 5, "Nil"),
> >                    stringsAsFactors = FALSE)
> >
> > # you can subset the b-column in several ways
> >
> > myDF[ , 2]
> > myDF[ , "b"]
> > myDF$b
> >
> > # using the column, you make a logical vector
> > ! is.na(as.numeric(myDF$b))
> >
> >
> > # This can be used to select the rows you want
> >
> > myDF[! is.na(as.numeric(myDF$b)), ]
> >
> >
> >
> > B.
> >
> >
> > > On Sep 25, 2017, at 7:30 AM, Shane Carey <careyshan at gmail.com> wrote:
> > >
> > > Hi,
> > >
> > > Lets say this was a dataframe where I had two columns
> > >
> > > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > > b <- c("<0.1", 1, 0.3, 5, "Nil")
> > >
> > > And I just want to remove the rows from the dataframe where there were
> NAs in the b column, what is the syntax for doing that?
> > >
> > > Thanks in advance
> > >
> > > On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com>
> wrote:
> > > Super,
> > >
> > > Thanks
> > >
> > > On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <
> boris.steipe at utoronto.ca> wrote:
> > > > a <- c("<0.1", NA, 0.3, 5, "Nil")
> > > > a
> > > [1] "<0.1" NA     "0.3"  "5"    "Nil"
> > >
> > > > b <- as.numeric(a)
> > > Warning message:
> > > NAs introduced by coercion
> > > > b
> > > [1]  NA  NA 0.3 5.0  NA
> > >
> > > > b[! is.na(b)]
> > > [1] 0.3 5.0
> > >
> > >
> > > B.
> > >
> > >
> > > > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com>
> wrote:
> > > >
> > > > Hi,
> > > >
> > > > How do I extract just numbers from the following list:
> > > >
> > > > a=c("<0.1",NA,0.3,5,Nil)
> > > >
> > > > so I want to obtain: 0.3 and 5 from the above list
> > > >
> > > > Thanks
> > > >
> > > >
> > > > --
> > > > Le gach dea ghui,
> > > > *Shane Carey*
> > > > *GIS and Data Solutions Consultant*
> > > >
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > >
> > > --
> > > Le gach dea ghui,
> > > Shane Carey
> > > GIS and Data Solutions Consultant
> > >
> > >
> > >
> > > --
> > > Le gach dea ghui,
> > > Shane Carey
> > > GIS and Data Solutions Consultant
> >
> >
> >
> >
> > --
> > Le gach dea ghui,
> > Shane Carey
> > GIS and Data Solutions Consultant
>
>


-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep 25 16:32:55 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 07:32:55 -0700
Subject: [R] Subset
In-Reply-To: <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
References: <CA+jRDxCb8jfA9SwAoogfa-GqsXG=JYV2bvx5fcAt-qtey_NRTw@mail.gmail.com>
 <519380DF-14BD-43AA-9FA0-E3F659AE6F88@utoronto.ca>
 <CA+jRDxDMG_zG4VaXXBZ7hmCkSTuOU+N-djDu76JD+MRr5rGRTQ@mail.gmail.com>
 <CA+jRDxBhTVUGLO0pz8gb7RavD-k6BA-UL24c-iddvkqZZAyM9g@mail.gmail.com>
Message-ID: <CAGxFJbRKxSARzgrm9gmp029CpP4ULtMqEsDwMhQRj3G5TkR2-Q@mail.gmail.com>

 You realize, do you not, that in fact there are no numbers in your "list"
(actually a vector).

It looks like you would do well to spend some time with an R tutorial or
two before posting further to this list. We can help, but cannot substitute
for the basic knowledge that you would gain from doing this.

Cheers,

Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 4:30 AM, Shane Carey <careyshan at gmail.com> wrote:

> Hi,
>
> Lets say this was a dataframe where I had two columns
>
> a <- c("<0.1", NA, 0.3, 5, "Nil")
> b <- c("<0.1", 1, 0.3, 5, "Nil")
>
> And I just want to remove the rows from the dataframe where there were NAs
> in the b column, what is the syntax for doing that?
>
> Thanks in advance
>
> On Fri, Sep 22, 2017 at 5:04 PM, Shane Carey <careyshan at gmail.com> wrote:
>
> > Super,
> >
> > Thanks
> >
> > On Fri, Sep 22, 2017 at 4:57 PM, Boris Steipe <boris.steipe at utoronto.ca>
> > wrote:
> >
> >> > a <- c("<0.1", NA, 0.3, 5, "Nil")
> >> > a
> >> [1] "<0.1" NA     "0.3"  "5"    "Nil"
> >>
> >> > b <- as.numeric(a)
> >> Warning message:
> >> NAs introduced by coercion
> >> > b
> >> [1]  NA  NA 0.3 5.0  NA
> >>
> >> > b[! is.na(b)]
> >> [1] 0.3 5.0
> >>
> >>
> >> B.
> >>
> >>
> >> > On Sep 22, 2017, at 11:48 AM, Shane Carey <careyshan at gmail.com>
> wrote:
> >> >
> >> > Hi,
> >> >
> >> > How do I extract just numbers from the following list:
> >> >
> >> > a=c("<0.1",NA,0.3,5,Nil)
> >> >
> >> > so I want to obtain: 0.3 and 5 from the above list
> >> >
> >> > Thanks
> >> >
> >> >
> >> > --
> >> > Le gach dea ghui,
> >> > *Shane Carey*
> >> > *GIS and Data Solutions Consultant*
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >
> > --
> > Le gach dea ghui,
> > *Shane Carey*
> > *GIS and Data Solutions Consultant*
> >
>
>
>
> --
> Le gach dea ghui,
> *Shane Carey*
> *GIS and Data Solutions Consultant*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From asafaneh at yahoo.com  Mon Sep 25 14:40:43 2017
From: asafaneh at yahoo.com (Ashraf Afana)
Date: Mon, 25 Sep 2017 12:40:43 +0000 (UTC)
Subject: [R] build a SpatialLines object from a list
References: <519351839.14900419.1506343243044.ref@mail.yahoo.com>
Message-ID: <519351839.14900419.1506343243044@mail.yahoo.com>

Hi all,I'm trying to build a SpatialLines object from a list that contains 124 river segments. Each segment in the list contains the x,y coordinates. I'm using the following code to create the SpatialLines object, but it just retrieves one segment. Any suggestions?

test.func = function(x){
 ??? for (i in 1:length(x)) {??????? tt[[i]] <- x[i]; tt[[i]]? = Line(tt[[i]]); tt[[i]]? = Lines(list(tt[[i]] ), 'i')??????? tt1 = SpatialLines(list(tt[[i]]))? ? ? ?? ? }????return(tt1)? }
Ashraf,
	[[alternative HTML version deleted]]


From dibya at umich.edu  Mon Sep 25 16:54:25 2017
From: dibya at umich.edu (Dibyadeep Paul)
Date: Mon, 25 Sep 2017 07:54:25 -0700
Subject: [R] How to propose changes to R documentation
Message-ID: <CABtAzjaj4Y=m-1vMRmRMdEp_Ux-sYW1m8pGA6sED1urwzKEAxw@mail.gmail.com>

Hi all,

I noticed that there was some confusion regarding a few statements in the R
documentation. There are multiple questions on Stackoverflow regarding
this. So I thought it may be helpful for other new users to add a small
example to clarify the statements.

I am wondering how I can suggest these changes to the R manual? Is there a
github like interface to R/R manual?

-- 
Thanks

Dr. Dibyadeep Paul

	[[alternative HTML version deleted]]


From grantbeanblossom2015 at hotmail.com  Mon Sep 25 16:21:15 2017
From: grantbeanblossom2015 at hotmail.com (Grant Beanblossom)
Date: Mon, 25 Sep 2017 14:21:15 +0000
Subject: [R] Random Variable Generation
Message-ID: <DM5PR14MB172325B8E9F925F354A8119CCC7A0@DM5PR14MB1723.namprd14.prod.outlook.com>

I am attempting to write a code that will generate a win probability for a hockey team. To do this, I have a code built that will generate a number of random variables between two standard deviations, and then weight them and add them together. However, when I attempt to assign this code to a variable, any time I use the variable, it will always give me the same numbers instead of being random every time. Is there a way I can do this so that it is random every time?


Here is the code I am currently using: .35*(runif(1, min=.81, max=1.03)+runif(1, min=1.06, max=1.17)+runif(1, min=-.26, max=1.38))+.3*(runif(1, min=.36, max=.98)+runif(1, min=.76, max=.93)+runif(1, min=.52, max=1.03))+.2*(runif(1, min=.36, max=.75)+runif(1, min=.1, max=.67)+runif(1, min=.9, max=.96))+.15*(runif(1, min=.03, max=.2)+runif(1, min=.27, max=.51)+runif(1, min=.49, max=.55))+.4*(runif(1, min=.33, max=.39)+runif(1, min=.84, max=1.35))+.35*(runif(1, min=.16, max=.58)+runif(1, min=.05, max=1.29))+.25*(runif(1, min=.21, max=.52)+runif(1, min=.20, max=.68))+.5*(runif(1, min=1.26, max=1.38)).


The reason I want to assign it to a variable is because I want to run this code 1000 times and then get a mean value for it, which I believe might be easier if there's a variable assigned to it. However, if there is an easier way to do that, that could work as well.


	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Sep 25 17:56:37 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 25 Sep 2017 18:56:37 +0300
Subject: [R] build a SpatialLines object from a list
In-Reply-To: <519351839.14900419.1506343243044@mail.yahoo.com>
References: <519351839.14900419.1506343243044.ref@mail.yahoo.com>
 <519351839.14900419.1506343243044@mail.yahoo.com>
Message-ID: <CAGgJW774FXX3RyWH6W3oaokBw1ZsqeSuScsSoPV4YWAHeP-zwQ@mail.gmail.com>

Hi Ashraf,
It is not obvious to me what your structures are but one problem in your
function is the assignment tt1 <- SpatialLines(list(tt[[i]])).

This will set tt1 to just have one item.

Consider the following

test.func <- function(x) {
    tt1 <- list()
    for ( i in ... )  {
       ...
       tt1[[i]] <- SpatialLines(tt[[i]])
    }
    return(tt1)
}

HTH,
Eric


On Mon, Sep 25, 2017 at 3:40 PM, Ashraf Afana via R-help <
r-help at r-project.org> wrote:

> Hi all,I'm trying to build a SpatialLines object from a list that contains
> 124 river segments. Each segment in the list contains the x,y coordinates.
> I'm using the following code to create the SpatialLines object, but it just
> retrieves one segment. Any suggestions?
>
> test.func = function(x){
>      for (i in 1:length(x)) {        tt[[i]] <- x[i]; tt[[i]]  =
> Line(tt[[i]]); tt[[i]]  = Lines(list(tt[[i]] ), 'i')        tt1 =
> SpatialLines(list(tt[[i]]))           }    return(tt1)  }
> Ashraf,
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Sep 25 18:01:08 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Sep 2017 16:01:08 +0000
Subject: [R] Random Variable Generation
In-Reply-To: <DM5PR14MB172325B8E9F925F354A8119CCC7A0@DM5PR14MB1723.namprd14.prod.outlook.com>
References: <DM5PR14MB172325B8E9F925F354A8119CCC7A0@DM5PR14MB1723.namprd14.prod.outlook.com>
Message-ID: <444ec238566047c485df626eef465b1a@exch-2p-mbx-w2.ads.tamu.edu>

Once you have assigned the variable, it does not change unless you change it. If you want to draw random numbers repeatedly, put the code into a function:

rnd <- function() {.35 * (runif(1, min=.81, max=1.03) + runif(1, min=1.06, max=1.17) + runif(1, min=-.26, max=1.38)) + 
   .30 * (runif(1, min=.36, max=.98) + runif(1, min=.76, max=.93) + runif(1, min=.52, max=1.03)) + 
   .20 * (runif(1, min=.36, max=.75) + runif(1, min=.1, max=.67) + runif(1, min=.9, max=.96)) + 
   .15 * (runif(1, min=.03, max=.20) + runif(1, min=.27, max=.51) + runif(1, min=.49, max=.55)) + 
   .40 * (runif(1, min=.33, max=.39) + runif(1, min=.84, max=1.35)) + 
   .35 * (runif(1, min=.16, max=.58) + runif(1, min=.05, max=1.29)) + 
   .25 * (runif(1, min=.21, max=.52) + runif(1, min=.20, max=.68)) + 
   .50 * (runif(1, min=1.26, max=1.38))
}

Now every time you access the function, you will get a new random number:

> rnd()
[1] 4.036111
> rnd()
[1] 3.88048
> rnd()
[1] 3.984268
> rnd()
[1] 3.808441
> rnd()
[1] 4.219925

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Grant Beanblossom
Sent: Monday, September 25, 2017 9:21 AM
To: r-help at r-project.org
Subject: [R] Random Variable Generation

I am attempting to write a code that will generate a win probability for a hockey team. To do this, I have a code built that will generate a number of random variables between two standard deviations, and then weight them and add them together. However, when I attempt to assign this code to a variable, any time I use the variable, it will always give me the same numbers instead of being random every time. Is there a way I can do this so that it is random every time?


Here is the code I am currently using: .35*(runif(1, min=.81, max=1.03)+runif(1, min=1.06, max=1.17)+runif(1, min=-.26, max=1.38))+.3*(runif(1, min=.36, max=.98)+runif(1, min=.76, max=.93)+runif(1, min=.52, max=1.03))+.2*(runif(1, min=.36, max=.75)+runif(1, min=.1, max=.67)+runif(1, min=.9, max=.96))+.15*(runif(1, min=.03, max=.2)+runif(1, min=.27, max=.51)+runif(1, min=.49, max=.55))+.4*(runif(1, min=.33, max=.39)+runif(1, min=.84, max=1.35))+.35*(runif(1, min=.16, max=.58)+runif(1, min=.05, max=1.29))+.25*(runif(1, min=.21, max=.52)+runif(1, min=.20, max=.68))+.5*(runif(1, min=1.26, max=1.38)).


The reason I want to assign it to a variable is because I want to run this code 1000 times and then get a mean value for it, which I believe might be easier if there's a variable assigned to it. However, if there is an easier way to do that, that could work as well.


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep 25 18:12:24 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 09:12:24 -0700
Subject: [R] How to propose changes to R documentation
In-Reply-To: <CABtAzjaj4Y=m-1vMRmRMdEp_Ux-sYW1m8pGA6sED1urwzKEAxw@mail.gmail.com>
References: <CABtAzjaj4Y=m-1vMRmRMdEp_Ux-sYW1m8pGA6sED1urwzKEAxw@mail.gmail.com>
Message-ID: <CAGxFJbSWJcxxWUHq0Jve-Oxha+4unpeXT5YFHWo6gjDp+uS4xQ@mail.gmail.com>

1. Familiarize yourself with CRAN and the R homeage:
https://www.r-project.org/

2. https://www.r-project.org/bugs.html


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 7:54 AM, Dibyadeep Paul <dibya at umich.edu> wrote:

> Hi all,
>
> I noticed that there was some confusion regarding a few statements in the R
> documentation. There are multiple questions on Stackoverflow regarding
> this. So I thought it may be helpful for other new users to add a small
> example to clarify the statements.
>
> I am wondering how I can suggest these changes to the R manual? Is there a
> github like interface to R/R manual?
>
> --
> Thanks
>
> Dr. Dibyadeep Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From studerov at gmail.com  Mon Sep 25 19:27:47 2017
From: studerov at gmail.com (David Studer)
Date: Mon, 25 Sep 2017 19:27:47 +0200
Subject: [R] Sample of a subsample
Message-ID: <CAA1twZQy=AdAYycyu-ySmvWF9WV2e6D+4SvMaCQi9EN6reJ+-w@mail.gmail.com>

Hello everybody!

I have the following problem: I'd like to select a sample from a subsample
in a dataset. Actually, I don't want to select it, but to create a new
variable sampleNo that indicates to which sample (one or two) a case
belongs to.

Lets suppose I have a dataset containing 40 cases:

data <- data.frame(var1=seq(1:40), var2=seq(40,1))

The first sample (n=10) I drew like this:

data$sampleNo <- 0
idx <- sample(seq(1,nrow(data)), size=10, replace=F)
data[idx,]$sampleNo <- 1

Now, (and here my problems start) I'd like to draw a second sample (n=10).
But this sample should be drawn from the cases that don't belong to the
first sample only. *Additionally, "var1" should be an even number.*

So sampleNo should be 0 for cases that were not drawn at all, 1 for cases
that belong to the first sample and 2 for cases belonging to the second
sample (= sampleNo equals 0 and var1 is even).

I was trying to solve it like this:

idx2<-data$var1%%2 & data$sampleNo==0
sample(data[idx2,], size=10, replace=F)

But how can I set sampleNo to 2?


Thank you very much for your help!

David

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Sep 25 20:03:32 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 11:03:32 -0700
Subject: [R] Sample of a subsample
In-Reply-To: <CAA1twZQy=AdAYycyu-ySmvWF9WV2e6D+4SvMaCQi9EN6reJ+-w@mail.gmail.com>
References: <CAA1twZQy=AdAYycyu-ySmvWF9WV2e6D+4SvMaCQi9EN6reJ+-w@mail.gmail.com>
Message-ID: <CAGxFJbRvdu5FZ3YbYc10Wv-5FdMSa2ZimQqMCxoaR7=cQR0jrg@mail.gmail.com>

For personal aesthetic reasons, I changed the name "data" to "dat".

Your code, with a slight modification:

set.seed (1357)  ## for reproducibility
dat <- data.frame(var1=seq(1:40), var2=seq(40,1))
dat$sampleNo <- 0
idx <- sample(seq(1,nrow(dat)), size=10, replace=F)
dat[idx,"sampleNo"] <-1

## yielding
> dat

   var1 var2 sampleNo
1     1   40        0
2     2   39        1
3     3   38        0
4     4   37        0
5     5   36        0
6     6   35        1
7     7   34        0
8     8   33        0
9     9   32        0
10   10   31        0
11   11   30        0
12   12   29        0
13   13   28        0
14   14   27        0
15   15   26        1
16   16   25        1
17   17   24        0
18   18   23        0
19   19   22        0
20   20   21        1
21   21   20        0
22   22   19        1
23   23   18        0
24   24   17        1
25   25   16        0
26   26   15        1
27   27   14        0
28   28   13        0
29   29   12        0
30   30   11        0
31   31   10        0
32   32    9        0
33   33    8        0
34   34    7        0
35   35    6        1
36   36    5        0
37   37    4        1
38   38    3        0
39   39    2        0
40   40    1        0

## This is basically a transcription of your specification into indexing
logic

dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
sampleNo==0],10,rep=FALSE)] <- 2)

##yielding
> dat

   var1 var2 sampleNo
1     1   40        0
2     2   39        1
3     3   38        0
4     4   37        2
5     5   36        0
6     6   35        1
7     7   34        0
8     8   33        2
9     9   32        0
10   10   31        2
11   11   30        0
12   12   29        0
13   13   28        0
14   14   27        2
15   15   26        1
16   16   25        1
17   17   24        0
18   18   23        2
19   19   22        0
20   20   21        1
21   21   20        0
22   22   19        1
23   23   18        0
24   24   17        1
25   25   16        0
26   26   15        1
27   27   14        0
28   28   13        2
29   29   12        0
30   30   11        2
31   31   10        0
32   32    9        2
33   33    8        0
34   34    7        2
35   35    6        1
36   36    5        2
37   37    4        1
38   38    3        0
39   39    2        0
40   40    1        0





dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
sampleNo==0],10,rep=FALSE)] <- 2)




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 10:27 AM, David Studer <studerov at gmail.com> wrote:

> Hello everybody!
>
> I have the following problem: I'd like to select a sample from a subsample
> in a dataset. Actually, I don't want to select it, but to create a new
> variable sampleNo that indicates to which sample (one or two) a case
> belongs to.
>
> Lets suppose I have a dataset containing 40 cases:
>
> data <- data.frame(var1=seq(1:40), var2=seq(40,1))
>
> The first sample (n=10) I drew like this:
>
> data$sampleNo <- 0
> idx <- sample(seq(1,nrow(data)), size=10, replace=F)
> data[idx,]$sampleNo <- 1
>
> Now, (and here my problems start) I'd like to draw a second sample (n=10).
> But this sample should be drawn from the cases that don't belong to the
> first sample only. *Additionally, "var1" should be an even number.*
>
> So sampleNo should be 0 for cases that were not drawn at all, 1 for cases
> that belong to the first sample and 2 for cases belonging to the second
> sample (= sampleNo equals 0 and var1 is even).
>
> I was trying to solve it like this:
>
> idx2<-data$var1%%2 & data$sampleNo==0
> sample(data[idx2,], size=10, replace=F)
>
> But how can I set sampleNo to 2?
>
>
> Thank you very much for your help!
>
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Mon Sep 25 20:43:36 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Mon, 25 Sep 2017 21:43:36 +0300
Subject: [R] Sample of a subsample
In-Reply-To: <CAGxFJbRvdu5FZ3YbYc10Wv-5FdMSa2ZimQqMCxoaR7=cQR0jrg@mail.gmail.com>
References: <CAA1twZQy=AdAYycyu-ySmvWF9WV2e6D+4SvMaCQi9EN6reJ+-w@mail.gmail.com>
 <CAGxFJbRvdu5FZ3YbYc10Wv-5FdMSa2ZimQqMCxoaR7=cQR0jrg@mail.gmail.com>
Message-ID: <CAGgJW76OYcVb3u3E+tH8Qw7R8-hBByP5_9aeB2ccr4FtUvzCZQ@mail.gmail.com>

Hi David,
I was about to post a reply when Bert responded. His answer is good
and his comment to use the name 'dat' rather than 'data' is instructive.
I am providing my suggestion as well because I think it may address
what was causing you some confusion (mainly to use "which", but also
the missing !)

idx2 <- sample( which( (!data$var1%%2) & data$sampleNo==0 ), size=10,
replace=F)
data[idx2,]$sampleNo <- 2

Eric



On Mon, Sep 25, 2017 at 9:03 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> For personal aesthetic reasons, I changed the name "data" to "dat".
>
> Your code, with a slight modification:
>
> set.seed (1357)  ## for reproducibility
> dat <- data.frame(var1=seq(1:40), var2=seq(40,1))
> dat$sampleNo <- 0
> idx <- sample(seq(1,nrow(dat)), size=10, replace=F)
> dat[idx,"sampleNo"] <-1
>
> ## yielding
> > dat
>
>    var1 var2 sampleNo
> 1     1   40        0
> 2     2   39        1
> 3     3   38        0
> 4     4   37        0
> 5     5   36        0
> 6     6   35        1
> 7     7   34        0
> 8     8   33        0
> 9     9   32        0
> 10   10   31        0
> 11   11   30        0
> 12   12   29        0
> 13   13   28        0
> 14   14   27        0
> 15   15   26        1
> 16   16   25        1
> 17   17   24        0
> 18   18   23        0
> 19   19   22        0
> 20   20   21        1
> 21   21   20        0
> 22   22   19        1
> 23   23   18        0
> 24   24   17        1
> 25   25   16        0
> 26   26   15        1
> 27   27   14        0
> 28   28   13        0
> 29   29   12        0
> 30   30   11        0
> 31   31   10        0
> 32   32    9        0
> 33   33    8        0
> 34   34    7        0
> 35   35    6        1
> 36   36    5        0
> 37   37    4        1
> 38   38    3        0
> 39   39    2        0
> 40   40    1        0
>
> ## This is basically a transcription of your specification into indexing
> logic
>
> dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
> sampleNo==0],10,rep=FALSE)] <- 2)
>
> ##yielding
> > dat
>
>    var1 var2 sampleNo
> 1     1   40        0
> 2     2   39        1
> 3     3   38        0
> 4     4   37        2
> 5     5   36        0
> 6     6   35        1
> 7     7   34        0
> 8     8   33        2
> 9     9   32        0
> 10   10   31        2
> 11   11   30        0
> 12   12   29        0
> 13   13   28        0
> 14   14   27        2
> 15   15   26        1
> 16   16   25        1
> 17   17   24        0
> 18   18   23        2
> 19   19   22        0
> 20   20   21        1
> 21   21   20        0
> 22   22   19        1
> 23   23   18        0
> 24   24   17        1
> 25   25   16        0
> 26   26   15        1
> 27   27   14        0
> 28   28   13        2
> 29   29   12        0
> 30   30   11        2
> 31   31   10        0
> 32   32    9        2
> 33   33    8        0
> 34   34    7        2
> 35   35    6        1
> 36   36    5        2
> 37   37    4        1
> 38   38    3        0
> 39   39    2        0
> 40   40    1        0
>
>
>
>
>
> dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
> sampleNo==0],10,rep=FALSE)] <- 2)
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Sep 25, 2017 at 10:27 AM, David Studer <studerov at gmail.com> wrote:
>
> > Hello everybody!
> >
> > I have the following problem: I'd like to select a sample from a
> subsample
> > in a dataset. Actually, I don't want to select it, but to create a new
> > variable sampleNo that indicates to which sample (one or two) a case
> > belongs to.
> >
> > Lets suppose I have a dataset containing 40 cases:
> >
> > data <- data.frame(var1=seq(1:40), var2=seq(40,1))
> >
> > The first sample (n=10) I drew like this:
> >
> > data$sampleNo <- 0
> > idx <- sample(seq(1,nrow(data)), size=10, replace=F)
> > data[idx,]$sampleNo <- 1
> >
> > Now, (and here my problems start) I'd like to draw a second sample
> (n=10).
> > But this sample should be drawn from the cases that don't belong to the
> > first sample only. *Additionally, "var1" should be an even number.*
> >
> > So sampleNo should be 0 for cases that were not drawn at all, 1 for cases
> > that belong to the first sample and 2 for cases belonging to the second
> > sample (= sampleNo equals 0 and var1 is even).
> >
> > I was trying to solve it like this:
> >
> > idx2<-data$var1%%2 & data$sampleNo==0
> > sample(data[idx2,], size=10, replace=F)
> >
> > But how can I set sampleNo to 2?
> >
> >
> > Thank you very much for your help!
> >
> > David
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From richard.k.evans at nasa.gov  Mon Sep 25 21:28:28 2017
From: richard.k.evans at nasa.gov (Evans, Richard K. (GRC-H000))
Date: Mon, 25 Sep 2017 19:28:28 +0000
Subject: [R] bowed linear approximations
Message-ID: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>

Hello,

Please run the following code snippet and note the resulting plot:

x <- c(10, 50)
y <- c(0.9444483, 0.7680123)
plot(x,y,type="b",log="x")
for(i in 1:50){
 xx <- exp(runif(1,log(min(x)),log(max(x)) ))
yy <- approx(x,y,xout=xx, method = "linear")
points(xx,yy$y)
}

notice the "log=x" plot parameter and the resulting "bow" in the linear approximation.

This makes sense when I realized that the plot command is first making the plot and then drawing straight lines between points on a log plot AFTER the plot is generated and that that's why the line is straight. I get that.
.. and it also makes sense that the bowed points are a result of the linear approximations being made BEFORE plotted in a logarithmic plot. I get that..

My goal is to make approximations that lie on the line produced on the plot as shown, so I realize that what I want to do is NOT linear approximations, but maybe "log" approximations?
However, the approximation methods are only "linear" and "constant" .. there isn't a "log" method to approximate with.

So can anyone tell me how to fix the code such that he approximated points DO lie on the line as plotted with the "log=x" plot parameter?
Oh, and they have to be uniformly distributed along the Log=x axis.. I think that's the tricky part.

Any help and/or insight would be greatly appreciated.

Thank you!
-Rich


	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Sep 25 22:36:00 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 25 Sep 2017 20:36:00 +0000
Subject: [R] bowed linear approximations
In-Reply-To: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rich,

Assuming that I understand what you want to do, try adding the following to your script (which, by the way, is more complicated that it needs to be):

xx <- 10:50
m <- lm(y ~ x)
yy <- predict(m, data.frame(x=xx))
lines(spline(xx, yy), col="blue")

m <- lm(y ~ log(x))
yy <- predict(m, data.frame(x=xx))
points(xx, yy, col="magenta")

The first set of commands adds a line corresponding to the points that you plotted, which if I understand right, is *not* what you want. The second set of commands shows how to find points along the diagonal straight line that you plotted, given their x-values, which is what I think you want.

If you examine the linear models fit, you'll see that they just interpolate between the two points, albeit differently.

I hope this helps,
 John

-----------------------------
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Evans,
> Richard K. (GRC-H000)
> Sent: Monday, September 25, 2017 3:28 PM
> To: r-help at r-project.org
> Subject: [R] bowed linear approximations
> 
> Hello,
> 
> Please run the following code snippet and note the resulting plot:
> 
> x <- c(10, 50)
> y <- c(0.9444483, 0.7680123)
> plot(x,y,type="b",log="x")
> for(i in 1:50){
>  xx <- exp(runif(1,log(min(x)),log(max(x)) )) yy <- approx(x,y,xout=xx, method =
> "linear")
> points(xx,yy$y)
> }
> 
> notice the "log=x" plot parameter and the resulting "bow" in the linear
> approximation.
> 
> This makes sense when I realized that the plot command is first making the
> plot and then drawing straight lines between points on a log plot AFTER the
> plot is generated and that that's why the line is straight. I get that.
> .. and it also makes sense that the bowed points are a result of the linear
> approximations being made BEFORE plotted in a logarithmic plot. I get that..
> 
> My goal is to make approximations that lie on the line produced on the plot as
> shown, so I realize that what I want to do is NOT linear approximations, but
> maybe "log" approximations?
> However, the approximation methods are only "linear" and "constant" .. there
> isn't a "log" method to approximate with.
> 
> So can anyone tell me how to fix the code such that he approximated points
> DO lie on the line as plotted with the "log=x" plot parameter?
> Oh, and they have to be uniformly distributed along the Log=x axis.. I think
> that's the tricky part.
> 
> Any help and/or insight would be greatly appreciated.
> 
> Thank you!
> -Rich
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Sep 25 23:09:59 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 14:09:59 -0700
Subject: [R] Sample of a subsample
In-Reply-To: <CAGgJW76OYcVb3u3E+tH8Qw7R8-hBByP5_9aeB2ccr4FtUvzCZQ@mail.gmail.com>
References: <CAA1twZQy=AdAYycyu-ySmvWF9WV2e6D+4SvMaCQi9EN6reJ+-w@mail.gmail.com>
 <CAGxFJbRvdu5FZ3YbYc10Wv-5FdMSa2ZimQqMCxoaR7=cQR0jrg@mail.gmail.com>
 <CAGgJW76OYcVb3u3E+tH8Qw7R8-hBByP5_9aeB2ccr4FtUvzCZQ@mail.gmail.com>
Message-ID: <CAGxFJbSQuRitg=GwjixbPHkNj6i63D9wX7haVse8Wym2n8gjng@mail.gmail.com>

Yes.

Beating a pretty weary horse, a slightly cleaner version of my prior
offering using with(), instead of within() is:

with(dat,
dat[sampleNo[sample(var1[!var1%%2 & !sampleNo], 10, rep=FALSE)],
"sampleNo"] <- 2)

with() and within() are convenient ways to avoid having to repeatedly name
the columns via $  . Note also the use of logical subscripting of the data
frame in which numeric 0 is coerced to FALSE and any nonzero value to TRUE
(which I should have done previously).

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 11:43 AM, Eric Berger <ericjberger at gmail.com> wrote:

> Hi David,
> I was about to post a reply when Bert responded. His answer is good
> and his comment to use the name 'dat' rather than 'data' is instructive.
> I am providing my suggestion as well because I think it may address
> what was causing you some confusion (mainly to use "which", but also
> the missing !)
>
> idx2 <- sample( which( (!data$var1%%2) & data$sampleNo==0 ), size=10,
> replace=F)
> data[idx2,]$sampleNo <- 2
>
> Eric
>
>
>
> On Mon, Sep 25, 2017 at 9:03 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> For personal aesthetic reasons, I changed the name "data" to "dat".
>>
>> Your code, with a slight modification:
>>
>> set.seed (1357)  ## for reproducibility
>> dat <- data.frame(var1=seq(1:40), var2=seq(40,1))
>> dat$sampleNo <- 0
>> idx <- sample(seq(1,nrow(dat)), size=10, replace=F)
>> dat[idx,"sampleNo"] <-1
>>
>> ## yielding
>> > dat
>>
>>    var1 var2 sampleNo
>> 1     1   40        0
>> 2     2   39        1
>> 3     3   38        0
>> 4     4   37        0
>> 5     5   36        0
>> 6     6   35        1
>> 7     7   34        0
>> 8     8   33        0
>> 9     9   32        0
>> 10   10   31        0
>> 11   11   30        0
>> 12   12   29        0
>> 13   13   28        0
>> 14   14   27        0
>> 15   15   26        1
>> 16   16   25        1
>> 17   17   24        0
>> 18   18   23        0
>> 19   19   22        0
>> 20   20   21        1
>> 21   21   20        0
>> 22   22   19        1
>> 23   23   18        0
>> 24   24   17        1
>> 25   25   16        0
>> 26   26   15        1
>> 27   27   14        0
>> 28   28   13        0
>> 29   29   12        0
>> 30   30   11        0
>> 31   31   10        0
>> 32   32    9        0
>> 33   33    8        0
>> 34   34    7        0
>> 35   35    6        1
>> 36   36    5        0
>> 37   37    4        1
>> 38   38    3        0
>> 39   39    2        0
>> 40   40    1        0
>>
>> ## This is basically a transcription of your specification into indexing
>> logic
>>
>> dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
>> sampleNo==0],10,rep=FALSE)] <- 2)
>>
>> ##yielding
>> > dat
>>
>>    var1 var2 sampleNo
>> 1     1   40        0
>> 2     2   39        1
>> 3     3   38        0
>> 4     4   37        2
>> 5     5   36        0
>> 6     6   35        1
>> 7     7   34        0
>> 8     8   33        2
>> 9     9   32        0
>> 10   10   31        2
>> 11   11   30        0
>> 12   12   29        0
>> 13   13   28        0
>> 14   14   27        2
>> 15   15   26        1
>> 16   16   25        1
>> 17   17   24        0
>> 18   18   23        2
>> 19   19   22        0
>> 20   20   21        1
>> 21   21   20        0
>> 22   22   19        1
>> 23   23   18        0
>> 24   24   17        1
>> 25   25   16        0
>> 26   26   15        1
>> 27   27   14        0
>> 28   28   13        2
>> 29   29   12        0
>> 30   30   11        2
>> 31   31   10        0
>> 32   32    9        2
>> 33   33    8        0
>> 34   34    7        2
>> 35   35    6        1
>> 36   36    5        2
>> 37   37    4        1
>> 38   38    3        0
>> 39   39    2        0
>> 40   40    1        0
>>
>>
>>
>>
>>
>> dat <- within(dat,sampleNo[sample(var1[(var1%%2 == 0) &
>> sampleNo==0],10,rep=FALSE)] <- 2)
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Mon, Sep 25, 2017 at 10:27 AM, David Studer <studerov at gmail.com>
>> wrote:
>>
>> > Hello everybody!
>> >
>> > I have the following problem: I'd like to select a sample from a
>> subsample
>> > in a dataset. Actually, I don't want to select it, but to create a new
>> > variable sampleNo that indicates to which sample (one or two) a case
>> > belongs to.
>> >
>> > Lets suppose I have a dataset containing 40 cases:
>> >
>> > data <- data.frame(var1=seq(1:40), var2=seq(40,1))
>> >
>> > The first sample (n=10) I drew like this:
>> >
>> > data$sampleNo <- 0
>> > idx <- sample(seq(1,nrow(data)), size=10, replace=F)
>> > data[idx,]$sampleNo <- 1
>> >
>> > Now, (and here my problems start) I'd like to draw a second sample
>> (n=10).
>> > But this sample should be drawn from the cases that don't belong to the
>> > first sample only. *Additionally, "var1" should be an even number.*
>> >
>> > So sampleNo should be 0 for cases that were not drawn at all, 1 for
>> cases
>> > that belong to the first sample and 2 for cases belonging to the second
>> > sample (= sampleNo equals 0 and var1 is even).
>> >
>> > I was trying to solve it like this:
>> >
>> > idx2<-data$var1%%2 & data$sampleNo==0
>> > sample(data[idx2,], size=10, replace=F)
>> >
>> > But how can I set sampleNo to 2?
>> >
>> >
>> > Thank you very much for your help!
>> >
>> > David
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From farnoosh_81 at yahoo.com  Mon Sep 25 23:16:48 2017
From: farnoosh_81 at yahoo.com (Farnoosh Sheikhi)
Date: Mon, 25 Sep 2017 21:16:48 +0000 (UTC)
Subject: [R] Fw: passing different sample sizes
In-Reply-To: <660523758.9492109.1506358173230@mail.yahoo.com>
References: <660523758.9492109.1506358173230.ref@mail.yahoo.com>
 <660523758.9492109.1506358173230@mail.yahoo.com>
Message-ID: <1840065314.9753578.1506374208329@mail.yahoo.com>





Hi,?
I have the below function which returns confidence intervals.?I wanted to pass different sample sizes through the function, but for some reason it's not working.?n ? <- seq(from=40, to=300, by=2o)

I was also wondering how I can return a plot for different sample sizes.?plot(m~d, main="n(i)")?
Any help or suggestion is appreciated.


############################f<-function(n){? m = runif(n,50,200)? d = ?rnorm(n,0,1)?? ci.u<-mean(d)+1.96*sd(d)? ci.l<-mean(d)-1.96*sd(d)? ci.w<-ci.u-ci.l??? se=sd(d)/sqrt(n)? w.ci.uu<-ci.u+(qt(.975, df=n-1))*1.71*se? w.ci.ul<-ci.u-(qt(.975, df=n-1))*1.71*se? w.ci.upper<-w.ci.uu- w.ci.ul????w.ci.lu<-ci.l+(qt(.975, df=n-1))*1.71*se? w.ci.ll<-ci.l-(qt(.975, df=n-1))*1.71*se? w.ci.lower<-w.ci.lu- w.ci.ll??? res<-as.data.frame(cbind(n, ci.u, ci.l, ci.w, w.ci.upper, w.ci.lower))? return(res)}?Best,Nooshi





	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 26 00:00:08 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 15:00:08 -0700
Subject: [R] Fw: passing different sample sizes
In-Reply-To: <1840065314.9753578.1506374208329@mail.yahoo.com>
References: <660523758.9492109.1506358173230.ref@mail.yahoo.com>
 <660523758.9492109.1506358173230@mail.yahoo.com>
 <1840065314.9753578.1506374208329@mail.yahoo.com>
Message-ID: <CAGxFJbRS5CjNNj+35YzuWotahbpWs8mZFWcNLjVjaStJX85A3w@mail.gmail.com>

1. 2o is gibberish; 20 is the number of fingers and toes most of us have.

2. This is a plain text list. Your code became gibberish with your HTML
post.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 2:16 PM, Farnoosh Sheikhi via R-help <
r-help at r-project.org> wrote:

>
>
>
>
> Hi,
> I have the below function which returns confidence intervals. I wanted to
> pass different sample sizes through the function, but for some reason it's
> not working. n   <- seq(from=40, to=300, by=2o)
>
> I was also wondering how I can return a plot for different sample
> sizes. plot(m~d, main="n(i)")
> Any help or suggestion is appreciated.
>
>
> ############################f<-function(n){  m = runif(n,50,200)  d =
>  rnorm(n,0,1)   ci.u<-mean(d)+1.96*sd(d)  ci.l<-mean(d)-1.96*sd(d)
> ci.w<-ci.u-ci.l    se=sd(d)/sqrt(n)  w.ci.uu<-ci.u+(qt(.975,
> df=n-1))*1.71*se  w.ci.ul<-ci.u-(qt(.975, df=n-1))*1.71*se
> w.ci.upper<-w.ci.uu- w.ci.ul    w.ci.lu<-ci.l+(qt(.975, df=n-1))*1.71*se
> w.ci.ll<-ci.l-(qt(.975, df=n-1))*1.71*se  w.ci.lower<-w.ci.lu- w.ci.ll
> res<-as.data.frame(cbind(n, ci.u, ci.l, ci.w, w.ci.upper, w.ci.lower))
> return(res)} Best,Nooshi
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Sep 26 01:08:00 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 25 Sep 2017 16:08:00 -0700
Subject: [R] Fw: passing different sample sizes
In-Reply-To: <418294893.4301018.1506378524525@mail.yahoo.com>
References: <660523758.9492109.1506358173230.ref@mail.yahoo.com>
 <660523758.9492109.1506358173230@mail.yahoo.com>
 <1840065314.9753578.1506374208329@mail.yahoo.com>
 <CAGxFJbRS5CjNNj+35YzuWotahbpWs8mZFWcNLjVjaStJX85A3w@mail.gmail.com>
 <418294893.4301018.1506378524525@mail.yahoo.com>
Message-ID: <CAGxFJbT9BWr+tm_=9odYy_sh4iVGyu6C3eX0mkRgLOETEVFeBw@mail.gmail.com>

Your code is full of syntactic errors. What do you think 1.71(se) means?

After you clean up your code, something like this might be what you want:

out <- lapply(seq(40,500,by = 25), f)

To get plots, just stick in a plot statement after you define m and d.

Have you gone through any R tutorials? You seem to be confused about basics
that tutorials could help you with.  This list is not meant to replace such
homework on your own.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 25, 2017 at 3:28 PM, Farnoosh Sheikhi <farnoosh_81 at yahoo.com>
wrote:

> Hi Bert,
>
> Here is the code:
> f<-function(n){
> m=runif(n, 50, 100)
> d=rnorm(n, 0, 1)
> se=sd(d)/sqrt (n)
>
> ci.u<-mean(d)+1.96*sd(d)
> ci.l<-mean(d)-1.96*sd(d)
> ci.w<-ci.u-ci.l
>
> w.ci.uu<-ci.u+(qt (0.975, df=n-1)*1.71(se)
> w.ci.ul<-ci.u-(qt (0.975, df=n-1)*1.71(se)
> w.ci.upper<-w.ci.uu-w.ci.ul
>
> w.ci.lu<-ci.l+(qt (0.975, df=n-1)*1.71(se)
> w.ci.ll<-ci.l-(qt (0.975, df=n-1)*1.71(se)
> w.ci.lower<-w.ci.lu-w.ci.ll
>
>   res<-as.data.frame(cbind(n, ci.u, ci.l, ci.w, w.ci.upper, w.ci.lower))
>   return(res)
> }
>
>
> I would like to pass different sample sizes n<-seq(40, 500, by=25) and add
> a scatter plot for each n.
> plot(m~d)
>
> Thanks.
>
>
>
> On Monday, September 25, 2017 3:00 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>
> 1. 2o is gibberish; 20 is the number of fingers and toes most of us have.
>
> 2. This is a plain text list. Your code became gibberish with your HTML
> post.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Sep 25, 2017 at 2:16 PM, Farnoosh Sheikhi via R-help <
> r-help at r-project.org> wrote:
>
>
>
>
>
> Hi,
> I have the below function which returns confidence intervals. I wanted to
> pass different sample sizes through the function, but for some reason it's
> not working. n   <- seq(from=40, to=300, by=2o)
>
> I was also wondering how I can return a plot for different sample
> sizes. plot(m~d, main="n(i)")
> Any help or suggestion is appreciated.
>
>
> ############################f< -function(n){  m = runif(n,50,200)  d =
>  rnorm(n,0,1)   ci.u<-mean(d)+1.96*sd(d)  ci.l<-mean(d)-1.96*sd(d)
> ci.w<-ci.u-ci.l    se=sd(d)/sqrt(n)  w.ci.uu<-ci.u+(qt(.975,
> df=n-1))*1.71*se  w.ci.ul<-ci.u-(qt(.975, df=n-1))*1.71*se
> w.ci.upper<-w.ci.uu- w.ci.ul    w.ci.lu<-ci.l+(qt(. 975,
> df=n-1))*1.71*se  w.ci.ll<-ci.l-(qt(.975, df=n-1))*1.71*se
> w.ci.lower<-w.ci.lu- w.ci.ll    res<-as.data.frame(cbind(n, ci.u, ci.l,
> ci.w, w.ci.upper, w.ci.lower))  return(res)} Best,Nooshi
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From chrishold at psyctc.org  Tue Sep 26 08:53:07 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Tue, 26 Sep 2017 07:53:07 +0100 (BST)
Subject: [R] Surprising message "Error in FUN(newX[, i],
 ...) : all arguments must have the same length"
Message-ID: <1067618350.28759442.1506408787214.JavaMail.zimbra@psyctc.org>

I am hitting an odd message "Error in FUN(newX[, i], ...) : all arguments must have the same length".  I can't supply the data as it's a huge data frame but I think this has enough diagnostic information to show the issue.  I am sure I am missing something obvious.  I've put some extra comments in but otherwise this is cut and pasted from Rstudio.

### I wanted a table of the values in four columns:
> apply(datTAF[,75:78],2,table,na.rm=TRUE)
Error in FUN(newX[, i], ...) : all arguments must have the same length

### odd, surely as it's a data frame all x going into table() should be same length. Check:
> apply(datTAF[,75:78],2,length)
 RiskSuicide RiskSelfHarm  RiskHarmOth    RiskLegal 
        3009         3009         3009         3009 

### I has reasons to think the tables should all be the same length.  Check:
> apply(datTAF[,75:78],2,function(x){length(table(x))})
 RiskSuicide RiskSelfHarm  RiskHarmOth    RiskLegal 
           6            6            6            6 

### Now I'm a bit baffled.  Try str:
> apply(datTAF[,75:78],2,str)
 Named chr [1:3009] "." "." "." "0" "0" "0" "0" "0" "0" "3" "0" "0" "0" "." "0" "0" "0" "0" "0" "." ...
 - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
 Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "1" "0" "0" "0" "0" "0" "." "0" "0" "0" "0" "0" "." ...
 - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
 Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "3" "0" "0" "0" "." "0" "0" "0" "0" "0" "." ...
 - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
 Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1" "." "0" "0" "0" "0" "0" "." ...
 - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
NULL

### Not sure where that trailing "NULL" came from:
> str(datTAF[,78])
 chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1" "." "0" "0" "0" "0" "0" "." "0" ...

> Sys.info()
       sysname        release        version       nodename        machine          login 
     "Windows"     ">= 8 x64"   "build 9200"      "HPLP166"       "x86-64"  "Chris.Evans" 
          user effective_user 
 "Chris.Evans"  "Chris.Evans" 

Anyone see what I'm missing?  TIA,

Chris


From ericjberger at gmail.com  Tue Sep 26 09:27:20 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 26 Sep 2017 10:27:20 +0300
Subject: [R] bowed linear approximations
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com>

Hi Rich,
If I understand your comment about "uniformly distributed along the log=x
axis" then I think John's (second) set of commands needs a change to the
definition of xx, as follows:

xx <- exp(seq(from=log(min(x)),to=log(max(x)),length=50))
m <- lm(y ~ log(x))
yy <- predict(m, data.frame(x=xx))
points(xx, yy, col="red")

HTH,

Eric


On Mon, Sep 25, 2017 at 11:36 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Rich,
>
> Assuming that I understand what you want to do, try adding the following
> to your script (which, by the way, is more complicated that it needs to be):
>
> xx <- 10:50
> m <- lm(y ~ x)
> yy <- predict(m, data.frame(x=xx))
> lines(spline(xx, yy), col="blue")
>
> m <- lm(y ~ log(x))
> yy <- predict(m, data.frame(x=xx))
> points(xx, yy, col="magenta")
>
> The first set of commands adds a line corresponding to the points that you
> plotted, which if I understand right, is *not* what you want. The second
> set of commands shows how to find points along the diagonal straight line
> that you plotted, given their x-values, which is what I think you want.
>
> If you examine the linear models fit, you'll see that they just
> interpolate between the two points, albeit differently.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: socserv.mcmaster.ca/jfox
>
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Evans,
> > Richard K. (GRC-H000)
> > Sent: Monday, September 25, 2017 3:28 PM
> > To: r-help at r-project.org
> > Subject: [R] bowed linear approximations
> >
> > Hello,
> >
> > Please run the following code snippet and note the resulting plot:
> >
> > x <- c(10, 50)
> > y <- c(0.9444483, 0.7680123)
> > plot(x,y,type="b",log="x")
> > for(i in 1:50){
> >  xx <- exp(runif(1,log(min(x)),log(max(x)) )) yy <- approx(x,y,xout=xx,
> method =
> > "linear")
> > points(xx,yy$y)
> > }
> >
> > notice the "log=x" plot parameter and the resulting "bow" in the linear
> > approximation.
> >
> > This makes sense when I realized that the plot command is first making
> the
> > plot and then drawing straight lines between points on a log plot AFTER
> the
> > plot is generated and that that's why the line is straight. I get that.
> > .. and it also makes sense that the bowed points are a result of the
> linear
> > approximations being made BEFORE plotted in a logarithmic plot. I get
> that..
> >
> > My goal is to make approximations that lie on the line produced on the
> plot as
> > shown, so I realize that what I want to do is NOT linear approximations,
> but
> > maybe "log" approximations?
> > However, the approximation methods are only "linear" and "constant" ..
> there
> > isn't a "log" method to approximate with.
> >
> > So can anyone tell me how to fix the code such that he approximated
> points
> > DO lie on the line as plotted with the "log=x" plot parameter?
> > Oh, and they have to be uniformly distributed along the Log=x axis.. I
> think
> > that's the tricky part.
> >
> > Any help and/or insight would be greatly appreciated.
> >
> > Thank you!
> > -Rich
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Sep 26 09:41:33 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 26 Sep 2017 10:41:33 +0300
Subject: [R] Surprising message "Error in FUN(newX[, i],
 ...) : all arguments must have the same length"
In-Reply-To: <1067618350.28759442.1506408787214.JavaMail.zimbra@psyctc.org>
References: <1067618350.28759442.1506408787214.JavaMail.zimbra@psyctc.org>
Message-ID: <CAGgJW76ZjBEyaVd5ZUaiQJj8ijS8xG+xjJH2+JNGnaeMoGn5Vg@mail.gmail.com>

Hi Chris,
Maybe the na.rm=TRUE is affecting things. Try this
apply(datTAF[,75:78],2,function(x){ sum(!is.na(x)) })

HTH,
Eric


On Tue, Sep 26, 2017 at 9:53 AM, Chris Evans <chrishold at psyctc.org> wrote:

> I am hitting an odd message "Error in FUN(newX[, i], ...) : all arguments
> must have the same length".  I can't supply the data as it's a huge data
> frame but I think this has enough diagnostic information to show the
> issue.  I am sure I am missing something obvious.  I've put some extra
> comments in but otherwise this is cut and pasted from Rstudio.
>
> ### I wanted a table of the values in four columns:
> > apply(datTAF[,75:78],2,table,na.rm=TRUE)
> Error in FUN(newX[, i], ...) : all arguments must have the same length
>
> ### odd, surely as it's a data frame all x going into table() should be
> same length. Check:
> > apply(datTAF[,75:78],2,length)
>  RiskSuicide RiskSelfHarm  RiskHarmOth    RiskLegal
>         3009         3009         3009         3009
>
> ### I has reasons to think the tables should all be the same length.
> Check:
> > apply(datTAF[,75:78],2,function(x){length(table(x))})
>  RiskSuicide RiskSelfHarm  RiskHarmOth    RiskLegal
>            6            6            6            6
>
> ### Now I'm a bit baffled.  Try str:
> > apply(datTAF[,75:78],2,str)
>  Named chr [1:3009] "." "." "." "0" "0" "0" "0" "0" "0" "3" "0" "0" "0"
> "." "0" "0" "0" "0" "0" "." ...
>  - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>  Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "1" "0" "0" "0" "0" "0"
> "." "0" "0" "0" "0" "0" "." ...
>  - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>  Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "3" "0" "0" "0"
> "." "0" "0" "0" "0" "0" "." ...
>  - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>  Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1"
> "." "0" "0" "0" "0" "0" "." ...
>  - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
> NULL
>
> ### Not sure where that trailing "NULL" came from:
> > str(datTAF[,78])
>  chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1" "." "0"
> "0" "0" "0" "0" "." "0" ...
>
> > Sys.info()
>        sysname        release        version       nodename
> machine          login
>      "Windows"     ">= 8 x64"   "build 9200"      "HPLP166"
>  "x86-64"  "Chris.Evans"
>           user effective_user
>  "Chris.Evans"  "Chris.Evans"
>
> Anyone see what I'm missing?  TIA,
>
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chrishold at psyctc.org  Tue Sep 26 10:14:58 2017
From: chrishold at psyctc.org (Chris Evans)
Date: Tue, 26 Sep 2017 09:14:58 +0100 (BST)
Subject: [R] Surprising message "Error in FUN(newX[, i],
 ...) : all arguments must have the same length"
In-Reply-To: <CAGgJW76ZjBEyaVd5ZUaiQJj8ijS8xG+xjJH2+JNGnaeMoGn5Vg@mail.gmail.com>
References: <1067618350.28759442.1506408787214.JavaMail.zimbra@psyctc.org>
 <CAGgJW76ZjBEyaVd5ZUaiQJj8ijS8xG+xjJH2+JNGnaeMoGn5Vg@mail.gmail.com>
Message-ID: <411585871.28793137.1506413698236.JavaMail.zimbra@psyctc.org>

Quite so. Very sorry everyone. I realised that I meant "useNA="always"" not "na.rm=TRUE" within minutes of sending that Email ... by which time I was travelling and no longer had internet to beat you to this Eric. 

Clear evidence that I should never touch the keyboard without the first coffee of the day. 

Thanks! 

Chris 

> From: "Eric Berger" <ericjberger at gmail.com>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "R. Help" <r-help at r-project.org>
> Sent: Tuesday, 26 September, 2017 08:41:33
> Subject: Re: [R] Surprising message "Error in FUN(newX[, i], ...) : all
> arguments must have the same length"

> Hi Chris,
> Maybe the na.rm=TRUE is affecting things. Try this
> apply(datTAF[,75:78],2, function(x){ sum(! is.na (x)) })

> HTH,
> Eric

> On Tue, Sep 26, 2017 at 9:53 AM, Chris Evans < chrishold at psyctc.org > wrote:

>> I am hitting an odd message "Error in FUN(newX[, i], ...) : all arguments must
>> have the same length". I can't supply the data as it's a huge data frame but I
>> think this has enough diagnostic information to show the issue. I am sure I am
>> missing something obvious. I've put some extra comments in but otherwise this
>> is cut and pasted from Rstudio.

>> ### I wanted a table of the values in four columns:
>> > apply(datTAF[,75:78],2,table,na.rm=TRUE)
>> Error in FUN(newX[, i], ...) : all arguments must have the same length

>> ### odd, surely as it's a data frame all x going into table() should be same
>> length. Check:
>> > apply(datTAF[,75:78],2,length)
>> RiskSuicide RiskSelfHarm RiskHarmOth RiskLegal
>> 3009 3009 3009 3009

>> ### I has reasons to think the tables should all be the same length. Check:
>> > apply(datTAF[,75:78],2,function(x){length(table(x))})
>> RiskSuicide RiskSelfHarm RiskHarmOth RiskLegal
>> 6 6 6 6

>> ### Now I'm a bit baffled. Try str:
>> > apply(datTAF[,75:78],2,str)
>> Named chr [1:3009] "." "." "." "0" "0" "0" "0" "0" "0" "3" "0" "0" "0" "." "0"
>> "0" "0" "0" "0" "." ...
>> - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>> Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "1" "0" "0" "0" "0" "0" "." "0"
>> "0" "0" "0" "0" "." ...
>> - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>> Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "3" "0" "0" "0" "." "0"
>> "0" "0" "0" "0" "." ...
>> - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>> Named chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1" "." "0"
>> "0" "0" "0" "0" "." ...
>> - attr(*, "names")= chr [1:3009] "1" "2" "3" "4" ...
>> NULL

>> ### Not sure where that trailing "NULL" came from:
>> > str(datTAF[,78])
>> chr [1:3009] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "1" "." "0" "0" "0"
>> "0" "0" "." "0" ...

>> > Sys.info()
>> sysname release version nodename machine login
>> "Windows" ">= 8 x64" "build 9200" "HPLP166" "x86-64" "Chris.Evans"
>> user effective_user
>> "Chris.Evans" "Chris.Evans"

>> Anyone see what I'm missing? TIA,

>> Chris

>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Tue Sep 26 12:02:51 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 26 Sep 2017 13:02:51 +0300
Subject: [R] build a SpatialLines object from a list
In-Reply-To: <654001554.16044448.1506418572223@mail.yahoo.com>
References: <519351839.14900419.1506343243044.ref@mail.yahoo.com>
 <519351839.14900419.1506343243044@mail.yahoo.com>
 <CAGgJW774FXX3RyWH6W3oaokBw1ZsqeSuScsSoPV4YWAHeP-zwQ@mail.gmail.com>
 <654001554.16044448.1506418572223@mail.yahoo.com>
Message-ID: <CAGgJW77pNQz-vore8d4wSot9uiJUZ_ZsDkaptO+6_098fT6v4Q@mail.gmail.com>

Hi Ashraf,
In that case I think you may need to structure the code to first build the
list and only at the end supply that to the SpatialLines function,
something like

test.func <- function(x) {
    tt <- list()
    for ( i in ... )  {
       ...
       tt[[i]] <- (whatever)
    }
    return(SpatialLines(tt))
}

Eric


On Tue, Sep 26, 2017 at 12:36 PM, Ashraf Afana <asafaneh at yahoo.com> wrote:

> Hi Eric,
>
> Thanks for the help.But this will not solve the problem as it will
> generate a list and what I need is an object of class sp using SpatialLine
> function from sp package.So, I need to convert each matrix to coordinates
> and then to a line and then to a spatial line as figured in the code.
>
> My data structure is a list of 141 matrices.Each matrix represents
> coordinates of the river lines position.
>
> Ashraf, cheers
>
>
> On Monday, 25 September 2017, 16:56, Eric Berger <ericjberger at gmail.com>
> wrote:
>
>
> Hi Ashraf,
> It is not obvious to me what your structures are but one problem in your
> function is the assignment tt1 <- SpatialLines(list(tt[[i]])).
>
> This will set tt1 to just have one item.
>
> Consider the following
>
> test.func <- function(x) {
>     tt1 <- list()
>     for ( i in ... )  {
>        ...
>        tt1[[i]] <- SpatialLines(tt[[i]])
>     }
>     return(tt1)
> }
>
> HTH,
> Eric
>
>
> On Mon, Sep 25, 2017 at 3:40 PM, Ashraf Afana via R-help <
> r-help at r-project.org> wrote:
>
> Hi all,I'm trying to build a SpatialLines object from a list that contains
> 124 river segments. Each segment in the list contains the x,y coordinates.
> I'm using the following code to create the SpatialLines object, but it just
> retrieves one segment. Any suggestions?
>
> test.func = function(x){
>      for (i in 1:length(x)) {        tt[[i]] <- x[i]; tt[[i]]  =
> Line(tt[[i]]); tt[[i]]  = Lines(list(tt[[i]] ), 'i')        tt1 =
> SpatialLines(list(tt[[i]]))           }    return(tt1)  }
> Ashraf,
>         [[alternative HTML version deleted]]
>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/ listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From asafaneh at yahoo.com  Tue Sep 26 11:36:12 2017
From: asafaneh at yahoo.com (Ashraf Afana)
Date: Tue, 26 Sep 2017 09:36:12 +0000 (UTC)
Subject: [R] build a SpatialLines object from a list
In-Reply-To: <CAGgJW774FXX3RyWH6W3oaokBw1ZsqeSuScsSoPV4YWAHeP-zwQ@mail.gmail.com>
References: <519351839.14900419.1506343243044.ref@mail.yahoo.com>
 <519351839.14900419.1506343243044@mail.yahoo.com>
 <CAGgJW774FXX3RyWH6W3oaokBw1ZsqeSuScsSoPV4YWAHeP-zwQ@mail.gmail.com>
Message-ID: <654001554.16044448.1506418572223@mail.yahoo.com>

Hi Eric,

Thanks for the help.But this will not solve the problem as it will generate a list and what I need is an object of class sp using SpatialLine function from sp package.So, I need to convert each matrix to coordinates and then to a line and then to a spatial line as figured in the code.

My data structure is a list of 141 matrices.Each matrix represents coordinates of the river lines position.

Ashraf, cheers 

    On Monday, 25 September 2017, 16:56, Eric Berger <ericjberger at gmail.com> wrote:
 

 Hi Ashraf,It is not obvious to me what your structures are but one problem in your function is the assignment tt1 <- SpatialLines(list(tt[[i]])).
This will set tt1 to just have one item.
Consider the following
test.func <- function(x) {? ? tt1 <- list()? ? for ( i in ... )? {? ? ? ?...? ? ? ?tt1[[i]] <- SpatialLines(tt[[i]])? ? }? ? return(tt1)}

HTH,Eric? ??
On Mon, Sep 25, 2017 at 3:40 PM, Ashraf Afana via R-help <r-help at r-project.org> wrote:

Hi all,I'm trying to build a SpatialLines object from a list that contains 124 river segments. Each segment in the list contains the x,y coordinates. I'm using the following code to create the SpatialLines object, but it just retrieves one segment. Any suggestions?

test.func = function(x){
???? for (i in 1:length(x)) {??????? tt[[i]] <- x[i]; tt[[i]]? = Line(tt[[i]]); tt[[i]]? = Lines(list(tt[[i]] ), 'i')??????? tt1 = SpatialLines(list(tt[[i]]))? ? ? ?? ? }????return(tt1)? }
Ashraf,
? ? ? ? [[alternative HTML version deleted]]

______________________________ ________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/ listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



   
	[[alternative HTML version deleted]]


From sardinibayan at gmail.com  Tue Sep 26 11:50:00 2017
From: sardinibayan at gmail.com (bayan sardini)
Date: Tue, 26 Sep 2017 11:50:00 +0200
Subject: [R] Cleaning data
Message-ID: <3D4A5B70-7735-40A0-984B-AA0C34FD7FB4@gmail.com>

Hi 

I want to clean my data frame, based on the age column, whereas i want to delete the rows that the difference between its elements (i+1)-i= integer. i used 

a <- diff(df$age)
for(i in a){if(is.integer(a) == true){df <- df[-a,]
}}

but, it doesn?t work, any ideas

Thanks in advance
Bayan

From ericjberger at gmail.com  Tue Sep 26 13:03:40 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Tue, 26 Sep 2017 14:03:40 +0300
Subject: [R] Cleaning data
In-Reply-To: <3D4A5B70-7735-40A0-984B-AA0C34FD7FB4@gmail.com>
References: <3D4A5B70-7735-40A0-984B-AA0C34FD7FB4@gmail.com>
Message-ID: <CAGgJW74kxcrUY84W+RGyd5H6uuy9UXTDdBXmB9ELugvYoX=djA@mail.gmail.com>

Hi Bayan,
In your code, 'a' is a vector and is.integer(a) is a logical of length 1 -
most likely FALSE if even one element of a is not an integer. (Since R will
coerce all the elements of a to the same type.)
You need to decide whether something "close enough" to an integer is to be
considered an integer - e.g. a distance of 0.000001 = 1e-6.

 a <- df$age
df <- df[ c( TRUE, abs( a - round(a,0) )%%1 ) > 1e-6 ), ]

I added the 'TRUE' at the beginning to always keep the first row of df. If
you prefer to always keep the last row then move the TRUE to the end.

HTH,

Eric




On Tue, Sep 26, 2017 at 12:50 PM, bayan sardini <sardinibayan at gmail.com>
wrote:

> Hi
>
> I want to clean my data frame, based on the age column, whereas i want to
> delete the rows that the difference between its elements (i+1)-i= integer.
> i used
>
> a <- diff(df$age)
> for(i in a){if(is.integer(a) == true){df <- df[-a,]
> }}
>
> but, it doesn?t work, any ideas
>
> Thanks in advance
> Bayan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From careyshan at gmail.com  Tue Sep 26 13:11:11 2017
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 26 Sep 2017 12:11:11 +0100
Subject: [R] censtats from the NADA package
Message-ID: <CA+jRDxCYgj2rmoV__VJZ_ifrRJZRX6pn9pKjJdPUyVd4VOnucA@mail.gmail.com>

Hi,

Has anyone ever used the censtats from the nada package and carried it out
per group on a dataframe?

I have it working on the entire dataframe but I need to do it by group.

Thanks

-- 
Le gach dea ghui,
*Shane Carey*
*GIS and Data Solutions Consultant*

	[[alternative HTML version deleted]]


From richard.k.evans at nasa.gov  Tue Sep 26 15:10:49 2017
From: richard.k.evans at nasa.gov (Evans, Richard K. (GRC-H000))
Date: Tue, 26 Sep 2017 13:10:49 +0000
Subject: [R] bowed linear approximations
In-Reply-To: <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com>
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
 <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com>
Message-ID: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87B444@NDJSMBX203.ndc.nasa.gov>

Eric, John, thank you both very much for responding.

Ok.. I suppose I need to show more of the actual data. 
I have this data:

freq <- c(2, 3, 5, 10, 50, 100, 200, 300, 500, 750, 1000, 1300, 1800, 2450, 2900, 3000, 4000, 5000, 6000, 7000, 8200, 9300, 10000, 11000, 18000, 26500, 33000, 40000)
mag <- c(1.9893038, 1.5088071, 1.1851947, 0.9444483, 0.7680123, 0.7458169, 0.7069638, 0.6393066, 0.6261539, 0.6263381, 0.7053774, 0.6900626, 0.6953527, 0.7843036, 0.9056359, 0.8867276, 0.8937421, 0.9492288, 0.9629118, 1.1972268, 1.0010515, 0.9945838, 1.0564356, 0.8733333, 1.1666667, 1.5366667, 1.4666667, 1.3166667)

that must be displayed this way:

plot(freq,mag,type="b",log="x")

Essentially, I just want to show that I can reliably approximate the magnitudes of new data for additional random frequencies uniformly lying on the frequency axis. And so I write the following:

for(i in 1:200){ 
xx <- exp(runif(1,log(min(freq)),log(max(freq)) ))
yy <- approx(freq,mag,xout=xx, method = "linear")
points(xx,yy$y,col=rgb(1,0,0)) 
}

And I have been puzzling over why the approximated points don't lie linearly over the original data set (especially prominent  in the bow between freq=10 and 50). Once I realized (and concurred with) why this bow exists, I have been struggling with how to make these approximations as expected.. In my original post, I think I oversimplified it too much by implying that my application was just 2 data points.

Are your suggestions still valid do you think?
-Rich

From richard.k.evans at nasa.gov  Tue Sep 26 16:01:14 2017
From: richard.k.evans at nasa.gov (Evans, Richard K. (GRC-H000))
Date: Tue, 26 Sep 2017 14:01:14 +0000
Subject: [R] bowed linear approximations
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
 <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com> 
Message-ID: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87B973@NDJSMBX203.ndc.nasa.gov>

My apologies for the typos in the code. 
Here is a corrected version you can copy/paste in R to see the issue.

freq <- c(2, 3, 5, 10, 50, 100, 200, 300, 500, 750, 1000, 1300, 1800, 2450, 2900, 3000, 4000, 5000, 6000, 7000, 8200, 9300, 10000, 11000, 18000, 26500, 33000, 40000); 
mag <- c(1.9893038, 1.5088071, 1.1851947, 0.9444483, 0.7680123, 0.7458169, 0.7069638, 0.6393066, 0.6261539, 0.6263381, 0.7053774, 0.6900626, 0.6953527, 0.7843036, 0.9056359, 0.8867276, 0.8937421, 0.9492288, 0.9629118, 1.1972268, 1.0010515, 0.9945838, 1.0564356, 0.8733333, 1.1666667, 1.5366667, 1.4666667, 1.3166667);
plot(freq,mag,type="b",log="x");
for(i in 1:200){
xx <- exp(runif(1,log(min(freq)),log(max(freq)) ));
yy <- approx(freq,mag,xout=xx, method = "linear");
points(xx,yy$y,col=rgb(1,0,0));
}

For completeness, I have been puzzling over why the approximated points don't lie linearly over the original data set (especially prominent  in the bow between freq=10 and 50). Once I realized (and concurred with) why this bow exists, I have been struggling with how to make these approximations as expected.. In my original post, I think I oversimplified it too much by implying that my application was just 2 data points.

Are your suggestions still valid do you think?
-Rich

From jfox at mcmaster.ca  Tue Sep 26 16:21:49 2017
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 26 Sep 2017 14:21:49 +0000
Subject: [R] bowed linear approximations
In-Reply-To: <25744_1506434711_v8QE5AVi014915_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87B973@NDJSMBX203.ndc.nasa.gov>
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
 <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com>
 <25744_1506434711_v8QE5AVi014915_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87B973@NDJSMBX203.ndc.nasa.gov>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8366D369E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Rich,

I think that it's generally a bad idea to give statistical (as opposed to simply technical) advice by email without knowing the context of the research. I think that you'd do well to seek help from a statistician, and not just do what I suggest below.

Interpolating the data only makes sense if there's no random component to the response (mag in your data). Otherwise, it makes more sense to get "predictions" from a statistical model that has an explicit error component for the response. In your case, a simple quadratic model in log(freq) seems to fit the data reasonably well. 

To see what I mean, try

plot(log(freq), mag)
mod <- lm(mag ~ poly(log(freq), 2))
summary(mod)
points(log(freq), fitted(mod), pch=16)
lines(spline(log(freq), fitted(mod)))

Some basic regression diagnostics suggest that we can do better by taking the log of mag as well, producing a closer fit to the data and stabilizing the error variance:

plot(log(freq), log(mag))
mod2 <- lm(log(mag) ~ poly(log(freq), 2))
summary(mod2)
points(log(freq), fitted(mod2), pch=16)
lines(spline(log(freq), fitted(mod2)))

I have no idea whether this makes substantive sense in the context of your problem.

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Evans,
> Richard K. (GRC-H000)
> Sent: Tuesday, September 26, 2017 10:01 AM
> To: Eric Berger <ericjberger at gmail.com>; Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] bowed linear approximations
> 
> My apologies for the typos in the code.
> Here is a corrected version you can copy/paste in R to see the issue.
> 
> freq <- c(2, 3, 5, 10, 50, 100, 200, 300, 500, 750, 1000, 1300, 1800, 2450, 2900,
> 3000, 4000, 5000, 6000, 7000, 8200, 9300, 10000, 11000, 18000, 26500, 33000,
> 40000); mag <- c(1.9893038, 1.5088071, 1.1851947, 0.9444483, 0.7680123,
> 0.7458169, 0.7069638, 0.6393066, 0.6261539, 0.6263381, 0.7053774,
> 0.6900626, 0.6953527, 0.7843036, 0.9056359, 0.8867276, 0.8937421,
> 0.9492288, 0.9629118, 1.1972268, 1.0010515, 0.9945838, 1.0564356,
> 0.8733333, 1.1666667, 1.5366667, 1.4666667, 1.3166667);
> plot(freq,mag,type="b",log="x"); for(i in 1:200){ xx <-
> exp(runif(1,log(min(freq)),log(max(freq)) )); yy <- approx(freq,mag,xout=xx,
> method = "linear"); points(xx,yy$y,col=rgb(1,0,0)); }
> 
> For completeness, I have been puzzling over why the approximated points
> don't lie linearly over the original data set (especially prominent  in the bow
> between freq=10 and 50). Once I realized (and concurred with) why this bow
> exists, I have been struggling with how to make these approximations as
> expected.. In my original post, I think I oversimplified it too much by implying
> that my application was just 2 data points.
> 
> Are your suggestions still valid do you think?
> -Rich
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From richard.k.evans at nasa.gov  Tue Sep 26 17:18:03 2017
From: richard.k.evans at nasa.gov (Evans, Richard K. (GRC-H000))
Date: Tue, 26 Sep 2017 15:18:03 +0000
Subject: [R] bowed linear approximations
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8366D369E@FHSDB2D11-2.csu.mcmaster.ca>
References: <15654_1506368026_v8PJXjxc000484_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87AF35@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D322D@FHSDB2D11-2.csu.mcmaster.ca>
 <CAGgJW75tkdwuO+EiMiosQzzGw0Boy8gcvT0Dk-LajG2qyo+w_A@mail.gmail.com>
 <25744_1506434711_v8QE5AVi014915_DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87B973@NDJSMBX203.ndc.nasa.gov>
 <ACD1644AA6C67E4FBD0C350625508EC8366D369E@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <DC3FB55EE7FEFD409A6FC1EA00D50D0B0F87C290@NDJSMBX203.ndc.nasa.gov>

[solved] -- As always, the solution is simple and I always feel foolish for not having seen it right away. 

Thank you, John, for showing that the frequency data can be "converted" to log before the linear approximations are made.. once the linear approximations are done with log data, the approximations can be plotted into the "log=x" plot and everything is spot on :-) 

Here is the updated code that does exactly what I had originally wanted:

freq <- c(2, 3, 5, 10, 50, 100, 200, 300, 500, 750, 1000, 1300, 1800, 2450, 2900, 3000, 4000, 5000, 6000, 7000, 8200, 9300, 10000, 11000, 18000, 26500, 33000, 40000); 
mag <- c(1.9893038, 1.5088071, 1.1851947,  0.9444483, 0.7680123, 0.7458169, 0.7069638, 0.6393066, 0.6261539, 0.6263381, 0.7053774, 0.6900626, 0.6953527, 0.7843036, 0.9056359, 0.8867276, 0.8937421, 0.9492288, 0.9629118, 1.1972268, 1.0010515, 0.9945838, 1.0564356, 0.8733333, 1.1666667, 1.5366667, 1.4666667, 1.3166667); 
flog <- log(freq);
plot(exp(flog),mag,type="b",log="x"); 
for(i in 1:2000){ 
xx <- runif(1,min(flog),max(flog)); 
yy <- approx(flog,mag,xout=xx, method = "linear"); 
points(exp(xx),yy$y,col=rgb(1,0,0)); 
}

Thank you!
-Rich


From jixwang at celgene.com  Tue Sep 26 17:14:35 2017
From: jixwang at celgene.com (Jixian (Jason) Wang)
Date: Tue, 26 Sep 2017 15:14:35 +0000
Subject: [R] Any package which takes the likelihood function and do Lasso
 fitting?
Message-ID: <261ACF392252FB408D74466DAB73EF4E0126BCA883@CHBDYSPEXCMBX04.celgene.com>

Dear all,

I am looking for a package that takes the likelihood function and use the L1 penalty for MLE.  More specifically I would like to fit the Hawke process model using the function likelihoodHawkes() in package "hawkes" https://cran.r-project.org/web/packages/hawkes/hawkes.pdf.  Had a look at lasso packages at CRAN and couldn't find a general purpose one.  Although I can use an optimizer, I guess it may be less efficient than specific ones for Lasso.  I would be grateful for suggestions on packages or on how to efficiently use a general optimizer.

Best wishes

Jason





	[[alternative HTML version deleted]]


From kydaviddoyle at gmail.com  Tue Sep 26 21:51:32 2017
From: kydaviddoyle at gmail.com (David Doyle)
Date: Tue, 26 Sep 2017 14:51:32 -0500
Subject: [R] Adding non-data line to legend ggplot2 Maximum Contaminant Level
Message-ID: <CACftpvrcJea_P-3VqBS5c7s5Mxk=BfSREOia3TFk6ZtAN92sDA@mail.gmail.com>

Hello everyone,

I have a plot showing chloride concentrations for various point over time.
I also have a dotted line that show the Secondary Maximum Contaminant Level
(my screening limit) on the graphs at 250 mg/L.  But I can not figure out
how to include the dotted line / Secondary Maximum Contaminant Level in
the legend.  Any thoughts?  My code is as following and is linked to my
data on the net.

Thank you in advance
David


#Loads the ggplot2 package.
library(ggplot2)

##This loads your data from your worksheet
MyData <-read.csv("http://doylesdartden.com/Stats/TimeSeriesExample.csv",
sep=",")


#Sets which are detections and nondetects

MyData$Detections <- ifelse(MyData$D_Chloride ==1, "Detected", "NonDetect")

#does the plot
p <- ggplot(data = MyData, aes(x=Year, y=Chloride , col=Detections)) +
  geom_point(aes(shape=Detections)) +

  #sets the detect vs. non-detect colors
  scale_colour_manual(values=c("black","red")) +

  #sets the y scale and log base 10
  scale_y_log10() +

  ##adds line
  geom_hline(aes(yintercept=250),linetype="dashed")+

  #location of the legend
  theme(legend.position=c("right")) +

  #sets the line color, type and size
  geom_line(colour="black", linetype="dotted", size=0.5) +
  ylab("Chloride (mg/L)")

## does the graph using the Location IDs as the different Locations.
p + facet_grid(Location ~ .)

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Sep 27 00:13:23 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 27 Sep 2017 08:13:23 +1000
Subject: [R] Cleaning data
In-Reply-To: <3D4A5B70-7735-40A0-984B-AA0C34FD7FB4@gmail.com>
References: <3D4A5B70-7735-40A0-984B-AA0C34FD7FB4@gmail.com>
Message-ID: <CA+8X3fUt-P6asg6fPJpQJDFJD141sZDpjzFFhjNec8=7Kz8ZnA@mail.gmail.com>

Hi Bayan,
Your question seems to imply that the "age" column contains floating
point numbers, e.g.

df
height  weight  age
170      72         21.5
...

If this is so, you will only find an integer in diff(age) if two
adjacent numbers happen to have the same decimal fraction _and_ the
subtraction does not produce a very small decimal remainder due to one
or both of the numbers being unable to be represented exactly in
binary notation as Eric pointed out. This seems an unusual criterion
for discarding values. Perhaps if you explain why an integer result is
undesirable it would help. It can be done:

badrows<-which(is.integer(diff(df$age)))
df<-df[-badrows,]

OR

df<-df[badrows+1,]

if you want to delete the second rather than the first age.

Jim

On Tue, Sep 26, 2017 at 7:50 PM, bayan sardini <sardinibayan at gmail.com> wrote:
> Hi
>
> I want to clean my data frame, based on the age column, whereas i want to delete the rows that the difference between its elements (i+1)-i= integer. i used
>
> a <- diff(df$age)
> for(i in a){if(is.integer(a) == true){df <- df[-a,]
> }}
>
> but, it doesn?t work, any ideas
>
> Thanks in advance
> Bayan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tring at gvdnet.dk  Wed Sep 27 08:51:05 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 27 Sep 2017 08:51:05 +0200
Subject: [R] disturbed legend in ggplot2
Message-ID: <040c830f-2935-651b-7be3-7c097dc06166@gvdnet.dk>

Dear friends - below is a subset of a much larger material showing two 
ways of generating two "lines". The intention is to have the colour 
reflect a variable, pH, but the legend is disturbed. The little part 
marked "3" above the colour scale is unwelcome. Why did it appear? How 
could I avoid it?

I'm on Windows 7, R version 3.4.1 (2017-06-30) -- "Single Candle"

All best wishes

Troels Ring
Aalborg, Denmark

library(ggplot2)
DF1 <-
structure(list(P = c(0, 0.00222222222222222, 0.00444444444444444,
0.00666666666666667, 0.00888888888888889, 0.0111111111111111,
0.0133333333333333, 0.0155555555555556, 0.0177777777777778, 0.02,
0, 0.00222222222222222, 0.00444444444444444, 0.00666666666666667,
0.00888888888888889, 0.0111111111111111, 0.0133333333333333,
0.0155555555555556, 0.0177777777777778, 0.02), pH = c(12.3979595548431,
12.3129161148613, 12.2070984076445, 12.0669463736967, 11.8586790792785,
11.4437319273717, 7.64497330556925, 6.98905682614207, 6.63520883742788,
6.3229313658492, 12.176061323132, 12.0234712172719, 11.7861230637902,
11.2219147985144, 7.14240749824074, 6.53119941380901, 5.95522932117427,
3.25184520894594, 2.55614400932465, 2.30097494287507), BC = 
c(0.0576574111386315,
0.047331331067055, 0.037206026657832, 0.0268607893098731, 
0.0166183791472022,
0.00639593998967551, 0.00335972794444094, 0.00854377959176608,
0.00987464693654883, 0.00863636089604445, 0.0343718830720469,
0.0242985554593397, 0.0140710602077036, 0.00383913993097999,
0.00439784065436743, 0.00582135949288444, 0.00336240952299985,
0.00129948001017736, 0.00640073762860721, 0.0115158433720248),
     SID = c(25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 15, 15,
     15, 15, 15, 15, 15, 15, 15)), .Names = c("P", "pH", "BC",
"SID"), row.names = c(NA, -20L), class = "data.frame")

df1 <- subset(DF1,SID==25)
df2 <- subset(DF1,SID==15)
v <- ggplot()
v <- v + geom_line(data=df1, aes(x=P, y=BC,col=pH,size=3))
v1 <- v + geom_line(data=df2, aes(x=P, y=BC,col=pH,size=3))

v <- ggplot()
v <- v + geom_line(data=DF1, aes(x=P, y=BC,group=SID,col=pH,size=3))


From ulrik.stervbo at gmail.com  Wed Sep 27 09:31:41 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 27 Sep 2017 07:31:41 +0000
Subject: [R] disturbed legend in ggplot2
In-Reply-To: <040c830f-2935-651b-7be3-7c097dc06166@gvdnet.dk>
References: <040c830f-2935-651b-7be3-7c097dc06166@gvdnet.dk>
Message-ID: <CAKVAULPGOh_wD6C+D=xvxah_SNr6ka4SYU8FTqhqc5fttMTmnQ@mail.gmail.com>

Hi Troels,

Try to move the size argument out of the aesthetic.

Best wishes,
Ulrik

On Mi., 27. Sep. 2017, 08:51 Troels Ring <tring at gvdnet.dk> wrote:

> Dear friends - below is a subset of a much larger material showing two
> ways of generating two "lines". The intention is to have the colour
> reflect a variable, pH, but the legend is disturbed. The little part
> marked "3" above the colour scale is unwelcome. Why did it appear? How
> could I avoid it?
>
> I'm on Windows 7, R version 3.4.1 (2017-06-30) -- "Single Candle"
>
> All best wishes
>
> Troels Ring
> Aalborg, Denmark
>
> library(ggplot2)
> DF1 <-
> structure(list(P = c(0, 0.00222222222222222, 0.00444444444444444,
> 0.00666666666666667, 0.00888888888888889, 0.0111111111111111,
> 0.0133333333333333, 0.0155555555555556, 0.0177777777777778, 0.02,
> 0, 0.00222222222222222, 0.00444444444444444, 0.00666666666666667,
> 0.00888888888888889, 0.0111111111111111, 0.0133333333333333,
> 0.0155555555555556, 0.0177777777777778, 0.02), pH = c(12.3979595548431,
> 12.3129161148613, 12.2070984076445, 12.0669463736967, 11.8586790792785,
> 11.4437319273717, 7.64497330556925, 6.98905682614207, 6.63520883742788,
> 6.3229313658492, 12.176061323132, 12.0234712172719, 11.7861230637902,
> 11.2219147985144, 7.14240749824074, 6.53119941380901, 5.95522932117427,
> 3.25184520894594, 2.55614400932465, 2.30097494287507), BC =
> c(0.0576574111386315,
> 0.047331331067055, 0.037206026657832, 0.0268607893098731,
> 0.0166183791472022,
> 0.00639593998967551, 0.00335972794444094, 0.00854377959176608,
> 0.00987464693654883, 0.00863636089604445, 0.0343718830720469,
> 0.0242985554593397, 0.0140710602077036, 0.00383913993097999,
> 0.00439784065436743, 0.00582135949288444, 0.00336240952299985,
> 0.00129948001017736, 0.00640073762860721, 0.0115158433720248),
>      SID = c(25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 15, 15,
>      15, 15, 15, 15, 15, 15, 15)), .Names = c("P", "pH", "BC",
> "SID"), row.names = c(NA, -20L), class = "data.frame")
>
> df1 <- subset(DF1,SID==25)
> df2 <- subset(DF1,SID==15)
> v <- ggplot()
> v <- v + geom_line(data=df1, aes(x=P, y=BC,col=pH,size=3))
> v1 <- v + geom_line(data=df2, aes(x=P, y=BC,col=pH,size=3))
>
> v <- ggplot()
> v <- v + geom_line(data=DF1, aes(x=P, y=BC,group=SID,col=pH,size=3))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tring at gvdnet.dk  Wed Sep 27 09:38:43 2017
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 27 Sep 2017 09:38:43 +0200
Subject: [R] disturbed legend in ggplot2
In-Reply-To: <040c830f-2935-651b-7be3-7c097dc06166@gvdnet.dk>
References: <040c830f-2935-651b-7be3-7c097dc06166@gvdnet.dk>
Message-ID: <35fbb9c8-1cb3-b7c1-4faf-94ae823918d6@gvdnet.dk>

Hi Ulrik - thanks a lot for pointing out this blunder - now it is fine!

Best wishes

Troels


Den 27-09-2017 kl. 09:31 skrev Ulrik Stervbo:
> Hi Troels,
>
> Try to move the size argument out of the aesthetic.
>
> Best wishes,
> Ulrik
>
> On Mi., 27. Sep. 2017, 08:51 Troels Ring <tring at gvdnet.dk> wrote:
>
>> Dear friends - below is a subset of a much larger material showing two
>> ways of generating two "lines". The intention is to have the colour
>> reflect a variable, pH, but the legend is disturbed. The little part
>> marked "3" above the colour scale is unwelcome. Why did it appear? How
>> could I avoid it?
>>
>> I'm on Windows 7, R version 3.4.1 (2017-06-30) -- "Single Candle"
>>
>> All best wishes
>>
>> Troels Ring
>> Aalborg, Denmark
>>
>> library(ggplot2)
>> DF1 <-
>> structure(list(P = c(0, 0.00222222222222222, 0.00444444444444444,
>> 0.00666666666666667, 0.00888888888888889, 0.0111111111111111,
>> 0.0133333333333333, 0.0155555555555556, 0.0177777777777778, 0.02,
>> 0, 0.00222222222222222, 0.00444444444444444, 0.00666666666666667,
>> 0.00888888888888889, 0.0111111111111111, 0.0133333333333333,
>> 0.0155555555555556, 0.0177777777777778, 0.02), pH = c(12.3979595548431,
>> 12.3129161148613, 12.2070984076445, 12.0669463736967, 11.8586790792785,
>> 11.4437319273717, 7.64497330556925, 6.98905682614207, 6.63520883742788,
>> 6.3229313658492, 12.176061323132, 12.0234712172719, 11.7861230637902,
>> 11.2219147985144, 7.14240749824074, 6.53119941380901, 5.95522932117427,
>> 3.25184520894594, 2.55614400932465, 2.30097494287507), BC =
>> c(0.0576574111386315,
>> 0.047331331067055, 0.037206026657832, 0.0268607893098731,
>> 0.0166183791472022,
>> 0.00639593998967551, 0.00335972794444094, 0.00854377959176608,
>> 0.00987464693654883, 0.00863636089604445, 0.0343718830720469,
>> 0.0242985554593397, 0.0140710602077036, 0.00383913993097999,
>> 0.00439784065436743, 0.00582135949288444, 0.00336240952299985,
>> 0.00129948001017736, 0.00640073762860721, 0.0115158433720248),
>>       SID = c(25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 15, 15, 15,
>>       15, 15, 15, 15, 15, 15, 15)), .Names = c("P", "pH", "BC",
>> "SID"), row.names = c(NA, -20L), class = "data.frame")
>>
>> df1 <- subset(DF1,SID==25)
>> df2 <- subset(DF1,SID==15)
>> v <- ggplot()
>> v <- v + geom_line(data=df1, aes(x=P, y=BC,col=pH,size=3))
>> v1 <- v + geom_line(data=df2, aes(x=P, y=BC,col=pH,size=3))
>>
>> v <- ggplot()
>> v <- v + geom_line(data=DF1, aes(x=P, y=BC,group=SID,col=pH,size=3))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From arabianahmad at googlemail.com  Wed Sep 27 09:22:10 2017
From: arabianahmad at googlemail.com (ah a)
Date: Wed, 27 Sep 2017 10:52:10 +0330
Subject: [R] MSBVAR Package
Message-ID: <CALjW5cL7OUFAJcWJSO66MN_dtrdJzgkcKbPH=d5QAbCzegokRw@mail.gmail.com>

dear sirs or madam,

As I'm interested to search about the monetary transmission channel in our
country by MSVAR model, I would be grateful if you help me and tell me how
can I run MSVAR in R or send me the related code to run this model .
Actually, I'm new user of R and I don't know how to run Markov Switching
Var Model in R.

Thank you very much in advance for your help.

Best Regards,
Ahmad Arabian

	[[alternative HTML version deleted]]


From istiyak.mba at gmail.com  Wed Sep 27 23:31:27 2017
From: istiyak.mba at gmail.com (istiyak ahamad)
Date: Thu, 28 Sep 2017 03:01:27 +0530
Subject: [R] need held in r coding.
Message-ID: <CAPJo3pQOM1+utXCW7H1GFGzgQLkJFd_oOD5V0Dgz1o5_oAXL-w@mail.gmail.com>

Need Help in Debugging below script:--------------------------------



dat <- get_majorlandmarks(dat,Dmin,Per)
fit_xts <- xts(dat$fit,order.by = dat$Date,frequency = 365)
close_xts <- xts(dat$Close, order.by = dat$Date, frequency = 365 )
majorlandmarks_xts <-xts(dat$Close[dat$majorlandmarks==TRUE], order.by =
dat$Date[dat$majorlandmarks==TRUE], frequency = 365 )
minorlandmarks_xts <-  xts(dat$Close[dat$minorlandmarks==TRUE], order.by =
dat$Date[dat$minorlandmarks==TRUE], frequency = 365 )
landmarkschart_data <-
cbind(close_xts,fit_xts,majorlandmarks_xts,minorlandmarks_xts)



Error:------------- order.by requires an appropriate time-based object

dygraphs::dygraph(landmarkschart_data, xlab = "Time",ylab = "Price") %>%
  dySeries("..1",label = "Close", drawPoints = FALSE,  strokeWidth = 1,
color = "black") %>%
  dySeries("..2",label = "Fit", drawPoints = FALSE,  strokeWidth = 1, color
= "red") %>%
  dySeries("..3",label = "Major LandMarks", drawPoints = TRUE, pointSize =
5, strokeWidth = 0, color = "darkorange") %>%
  dySeries("..4",label = "Minor LandMarks", drawPoints = TRUE, pointSize =
1, strokeWidth = 0, color = "darkblue") %>%
  dyRangeSelector()
###Estimating error with different parameters
# RMSE <- vector()
# for(i in seq(0.01,0.1,0.01)){
#   dat <- get_majorlandmarks(dat,i,0.01)
#   RMSE[i] <- sqrt(sum((dat$fit-dat$Close)^2)/nrow(dat))
# }
# plot(RMSE)

	[[alternative HTML version deleted]]


From istiyak.mba at gmail.com  Wed Sep 27 23:34:07 2017
From: istiyak.mba at gmail.com (istiyak ahamad)
Date: Thu, 28 Sep 2017 03:04:07 +0530
Subject: [R] Need Help in Debugging
Message-ID: <CAPJo3pRWzpZkZiF9RG404yC=ACZCdN-wsbaohvdFphmmNYLCyw@mail.gmail.com>

I am getting following error when running this script :------------Error in
length(runsum) : object 'runsum' not found


##error function
dat$fit <- NULL
dat$fit[dat$majorlandmarks] <- dat$Close[dat$majorlandmarks]
run <- rle(dat$majorlandmarks)
runvalue <- run$values
runsum <- cumsum(run$lengths)
run <- run$lengths
for(i in 1:(length(runsum)-1)){
  if (runvalue[i]==FALSE){
    left <- runsum[i-1]
    right <- runsum[i+1]-(run[i+1]-1)

    slope <- (dat$Close[dat$seq==right]-dat$Close[dat$seq==left])/(run[i]+1)
    dat$fit[(left+1):(right-1)] <- seq(1:run[i])*slope+dat$Close[left]

  }
return(dat)
}

Error in length(runsum) : object 'runsum' not found


Error in length(runsum) : object 'runsum' not found

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Sep 27 23:35:38 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 28 Sep 2017 07:35:38 +1000
Subject: [R] MSBVAR Package
In-Reply-To: <CALjW5cL7OUFAJcWJSO66MN_dtrdJzgkcKbPH=d5QAbCzegokRw@mail.gmail.com>
References: <CALjW5cL7OUFAJcWJSO66MN_dtrdJzgkcKbPH=d5QAbCzegokRw@mail.gmail.com>
Message-ID: <CA+8X3fVyj7MCPQOQr7jYDOVzRadOaK+uH60WZ2dG7+oxcM9csQ@mail.gmail.com>

Hi Ahmed,
You seem to know about the package, so I would suggest downloading:

https://cran.r-project.org/web/packages/MSBVAR/MSBVAR.pdf

getting a big cup of coffee and going through the examples to see how
the package works. If you can't make any sense out of that, you will
probably have to contact someone who does know how to use the package
and is willing to provide a tutorial (that is not me).

Jim

On Wed, Sep 27, 2017 at 5:22 PM, ah a via R-help <r-help at r-project.org> wrote:
> dear sirs or madam,
>
> As I'm interested to search about the monetary transmission channel in our
> country by MSVAR model, I would be grateful if you help me and tell me how
> can I run MSVAR in R or send me the related code to run this model .
> Actually, I'm new user of R and I don't know how to run Markov Switching
> Var Model in R.
>
> Thank you very much in advance for your help.
>
> Best Regards,
> Ahmad Arabian
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Sep 28 01:24:19 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 27 Sep 2017 23:24:19 +0000
Subject: [R] need held in r coding.
In-Reply-To: <CAPJo3pQOM1+utXCW7H1GFGzgQLkJFd_oOD5V0Dgz1o5_oAXL-w@mail.gmail.com>
References: <CAPJo3pQOM1+utXCW7H1GFGzgQLkJFd_oOD5V0Dgz1o5_oAXL-w@mail.gmail.com>
Message-ID: <F17A6BC3-C3E3-46D9-B84F-9177320E8F4D@llnl.gov>

It's pretty clear from the error message that dat$Date is not an appropriate time-based object.

Since dat$Date is created by the get_majorlandmarks() function, and your question provides no information about that, it's hard to be more specific.

However, I would suggest looking at the output of
  class(dat$Date)
and
  str(dat$Date)
The results should indicate that dat$Date somehow indicates a time-based ordering. 

I wouldn't be surprised if dat$Date is a factor (the class() function will tell you if it is), in which case something is wrong with how dat is constructed. For example, there might be invalid values in an input file.

The other thing is whether dates are acceptable to xts() for the order.by argument. I don't know.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 9/27/17, 2:31 PM, "R-help on behalf of istiyak ahamad" <r-help-bounces at r-project.org on behalf of istiyak.mba at gmail.com> wrote:

    Need Help in Debugging below script:--------------------------------
    
    
    
    dat <- get_majorlandmarks(dat,Dmin,Per)
    fit_xts <- xts(dat$fit,order.by = dat$Date,frequency = 365)
    close_xts <- xts(dat$Close, order.by = dat$Date, frequency = 365 )
    majorlandmarks_xts <-xts(dat$Close[dat$majorlandmarks==TRUE], order.by =
    dat$Date[dat$majorlandmarks==TRUE], frequency = 365 )
    minorlandmarks_xts <-  xts(dat$Close[dat$minorlandmarks==TRUE], order.by =
    dat$Date[dat$minorlandmarks==TRUE], frequency = 365 )
    landmarkschart_data <-
    cbind(close_xts,fit_xts,majorlandmarks_xts,minorlandmarks_xts)
    
    
    
    Error:------------- order.by requires an appropriate time-based object
    
    dygraphs::dygraph(landmarkschart_data, xlab = "Time",ylab = "Price") %>%
      dySeries("..1",label = "Close", drawPoints = FALSE,  strokeWidth = 1,
    color = "black") %>%
      dySeries("..2",label = "Fit", drawPoints = FALSE,  strokeWidth = 1, color
    = "red") %>%
      dySeries("..3",label = "Major LandMarks", drawPoints = TRUE, pointSize =
    5, strokeWidth = 0, color = "darkorange") %>%
      dySeries("..4",label = "Minor LandMarks", drawPoints = TRUE, pointSize =
    1, strokeWidth = 0, color = "darkblue") %>%
      dyRangeSelector()
    ###Estimating error with different parameters
    # RMSE <- vector()
    # for(i in seq(0.01,0.1,0.01)){
    #   dat <- get_majorlandmarks(dat,i,0.01)
    #   RMSE[i] <- sqrt(sum((dat$fit-dat$Close)^2)/nrow(dat))
    # }
    # plot(RMSE)
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From macqueen1 at llnl.gov  Thu Sep 28 01:29:16 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 27 Sep 2017 23:29:16 +0000
Subject: [R] build a SpatialLines object from a list
In-Reply-To: <654001554.16044448.1506418572223@mail.yahoo.com>
References: <519351839.14900419.1506343243044.ref@mail.yahoo.com>
 <519351839.14900419.1506343243044@mail.yahoo.com>
 <CAGgJW774FXX3RyWH6W3oaokBw1ZsqeSuScsSoPV4YWAHeP-zwQ@mail.gmail.com>
 <654001554.16044448.1506418572223@mail.yahoo.com>
Message-ID: <B6B60E33-49C5-4D2C-AA30-794724429913@llnl.gov>

Have you tried following the example in

  ?'SpatialLines-class'

You'll probably get better help from R-sig-geo

And please don't send html email, it makes your email hard to read.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 9/26/17, 2:36 AM, "R-help on behalf of Ashraf Afana via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    Hi Eric,
    
    Thanks for the help.But this will not solve the problem as it will generate a list and what I need is an object of class sp using SpatialLine function from sp package.So, I need to convert each matrix to coordinates and then to a line and then to a spatial line as figured in the code.
    
    My data structure is a list of 141 matrices.Each matrix represents coordinates of the river lines position.
    
    Ashraf, cheers 
    
        On Monday, 25 September 2017, 16:56, Eric Berger <ericjberger at gmail.com> wrote:
     
    
     Hi Ashraf,It is not obvious to me what your structures are but one problem in your function is the assignment tt1 <- SpatialLines(list(tt[[i]])).
    This will set tt1 to just have one item.
    Consider the following
    test.func <- function(x) {    tt1 <- list()    for ( i in ... )  {       ...       tt1[[i]] <- SpatialLines(tt[[i]])    }    return(tt1)}
    
    HTH,Eric    
    On Mon, Sep 25, 2017 at 3:40 PM, Ashraf Afana via R-help <r-help at r-project.org> wrote:
    
    Hi all,I'm trying to build a SpatialLines object from a list that contains 124 river segments. Each segment in the list contains the x,y coordinates. I'm using the following code to create the SpatialLines object, but it just retrieves one segment. Any suggestions?
    
    test.func = function(x){
         for (i in 1:length(x)) {        tt[[i]] <- x[i]; tt[[i]]  = Line(tt[[i]]); tt[[i]]  = Lines(list(tt[[i]] ), 'i')        tt1 = SpatialLines(list(tt[[i]]))           }    return(tt1)  }
    Ashraf,
            [[alternative HTML version deleted]]
    
    ______________________________ ________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/ listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/ posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    
    
    
       
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.


From evan.cooch at gmail.com  Thu Sep 28 02:47:49 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 27 Sep 2017 20:47:49 -0400
Subject: [R] building random matrices from vectors of random parameters
Message-ID: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>

Suppose I have interest in a matrix with the following symbolic 
structure (specified by 3 parameters: sa, so, m):

matrix(c(0,sa*m,so,sa),2,2,byrow=T)

What I can't figure out is how to construct a series of matrices, where 
the elements/parameters are rnorm values. I'd like to construct separate 
matrices, with each matrix in the series using the 'next random 
parameter value'. While the following works (for generating, say, 5 such 
random matrices)

replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))

its inelegant, and a real pain if the matrix gets large (say, 20 x 20).

I'm wondering if there is an easier way. I tried

 > sa <- rnorm(5,0.8,0.1)
 > so <- rnorm(5,0.5,0.1)
 > m <- rnorm(5,1.2,0.1)

matrix(c(0,sa*m,so,sa),2,2,byrow=T)

but that only returns a single matrix, not 5 matrices as I'd like. I 
also tried several variants of the 'replicate' approach (above), but 
didn't stumble across anything that seemed to work.

So, is there a better way than something like:

replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))

Many thanks in advance...


From peter.langfelder at gmail.com  Thu Sep 28 06:19:54 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 27 Sep 2017 21:19:54 -0700
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
Message-ID: <CA+hbrhUiASq-4ryXWdezJe6f3vev2Ma-RvNXbbN4R-CPtRHhgQ@mail.gmail.com>

I would try something like

n = 5
a <- rnorm(n,0.8,0.1)
so <- rnorm(n,0.5,0.1)
m <- rnorm(n,1.2,0.1)
mats = mapply(function(sa1, so1, m1) matrix(c(0,sa1*m1,so1,sa1),2,2,byrow=T),
                       a, so, m, SIMPLIFY = FALSE)

> mats
[[1]]
          [,1]      [,2]
[1,] 0.0000000 0.9129962
[2,] 0.4963598 0.7067311

[[2]]
          [,1]      [,2]
[1,] 0.0000000 1.0150316
[2,] 0.5489887 0.8469046

[[3]]
          [,1]      [,2]
[1,] 0.0000000 0.9516137
[2,] 0.3724521 0.8306535

[[4]]
          [,1]      [,2]
[1,] 0.0000000 1.0525355
[2,] 0.8075108 0.8314638

[[5]]
          [,1]      [,2]
[1,] 0.0000000 0.9400074
[2,] 0.4803386 0.7901753

On Wed, Sep 27, 2017 at 5:47 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
> Suppose I have interest in a matrix with the following symbolic structure
> (specified by 3 parameters: sa, so, m):
>
> matrix(c(0,sa*m,so,sa),2,2,byrow=T)
>
> What I can't figure out is how to construct a series of matrices, where the
> elements/parameters are rnorm values. I'd like to construct separate
> matrices, with each matrix in the series using the 'next random parameter
> value'. While the following works (for generating, say, 5 such random
> matrices)
>
> replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))
>
> its inelegant, and a real pain if the matrix gets large (say, 20 x 20).
>
> I'm wondering if there is an easier way. I tried
>
>> sa <- rnorm(5,0.8,0.1)
>> so <- rnorm(5,0.5,0.1)
>> m <- rnorm(5,1.2,0.1)
>
> matrix(c(0,sa*m,so,sa),2,2,byrow=T)
>
> but that only returns a single matrix, not 5 matrices as I'd like. I also
> tried several variants of the 'replicate' approach (above), but didn't
> stumble across anything that seemed to work.
>
> So, is there a better way than something like:
>
> replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))
>
> Many thanks in advance...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Sep 28 06:23:46 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 28 Sep 2017 14:23:46 +1000
Subject: [R] MSBVAR Package
In-Reply-To: <CALjW5cJ3+FGcuQeoET6fu=hwh0Ke2ETd4mWweetnHqHxDMtGjw@mail.gmail.com>
References: <CALjW5cL7OUFAJcWJSO66MN_dtrdJzgkcKbPH=d5QAbCzegokRw@mail.gmail.com>
 <CA+8X3fVyj7MCPQOQr7jYDOVzRadOaK+uH60WZ2dG7+oxcM9csQ@mail.gmail.com>
 <CALjW5cJ3+FGcuQeoET6fu=hwh0Ke2ETd4mWweetnHqHxDMtGjw@mail.gmail.com>
Message-ID: <CA+8X3fWvxG=tFO9tFnUa7taGYJBAs1GWRNs+yk8phTxn1s47EA@mail.gmail.com>

Hi Ahmad,
I don't know of any, but this might help:

http://maths-people.anu.edu.au/~johnm/courses/r/ASC2008/pdf/Rtimeseries-ohp.pdf

Jim

On Thu, Sep 28, 2017 at 2:12 PM, ah a <arabianahmad at googlemail.com> wrote:
> Hi Jim
>
> Thank you very much for your reply and your help.
> By the way, where can I find some tutorial videos?
> Thanks again for your help.
>
> Best regards
> Ahmad
>


From unwin at math.uni-augsburg.de  Wed Sep 27 18:21:57 2017
From: unwin at math.uni-augsburg.de (Antony Unwin)
Date: Wed, 27 Sep 2017 17:21:57 +0100
Subject: [R] [R-pkgs] The OutliersO3 package is now on CRAN
Message-ID: <B9E0C2E1-B744-4122-BE8F-3DE95A9339A4@math.uni-augsburg.de>

Dear all,

The new package OutliersO3 is now available on CRAN:
<https://cran.r-project.org/web/packages/OutliersO3/index.html>.

The aim is to graphically compare results of outlier analyses for all possible combinations of variables in a dataset.

Various kinds of O3 (Overview of Outliers) plots can be drawn to show which cases are classified as outliers for which combinations of variables.
Up to five different methods can be used to identify the potential outliers in a dataset.

There is a vignette:
https://cran.r-project.org/web/packages/OutliersO3/vignettes/O3-vignette.html

and a video of a talk on O3 plots from useR!:

https://channel9.msdn.com/events/useR-international-R-User-conferences/useR-International-R-User-2017-Conference/When-is-an-Outlier-an-Outlier-The-O3-plot?term=unwin

Queries, comments, suggestions are welcome.

Regards

Antony

Professor Antony Unwin
Mathematics Institute,
University of Augsburg, 
86135 Augsburg, Germany




	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From pdalgd at gmail.com  Thu Sep 28 11:07:57 2017
From: pdalgd at gmail.com (Peter Dalgaard)
Date: Thu, 28 Sep 2017 11:07:57 +0200
Subject: [R] R 3.4.2 is released
Message-ID: <589AFDAF-C1DA-4F84-8FF5-F4344385AF51@cbs.dk>

The build system rolled up R-3.4.2.tar.gz (codename "Short Summer") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.4.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard



These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 8c65d9a0af345a185d3770c9876f1d51
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = cb4138554f53e2653b2aa0ba639284a2
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 71562183d75dd2080d86c42bbf733bb7
MD5 (R-latest.tar.gz) = 1cd6d37850188e7f190f1eb94a24ca1f
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = 374ac20771d06d2d92646e0b3ad2471b
MD5 (R-3/R-3.4.2.tar.gz) = 1cd6d37850188e7f190f1eb94a24ca1f

6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
f0d18e22b9bdfe1dd91547d401b4ef5c8828b2c956a51dc54e7476196b48f87e  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
5f6073eb77b3cd5bb075850958060b7317ac37044de4c299789b02bec2112fa7  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
a10f84be31f897456a31d31690df2fdc3f21a197f28b4d04332cc85005dcd0d2  NEWS.2
971e30c2436cf645f58552905105d75788bd9733bddbcb7c4fbff4c1a6d80c64  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
971e30c2436cf645f58552905105d75788bd9733bddbcb7c4fbff4c1a6d80c64  R-3/R-3.4.2.tar.gz



This is the relevant part of the NEWS file

CHANGES IN R 3.4.2:

  NEW FEATURES:

    * Setting the LC_ALL category in Sys.setlocale() invalidates any
      cached locale-specific day/month names and the AM/PM indicator
      for strptime() (as setting LC_TIME has since R 3.1.0).

    * The version of LAPACK included in the sources has been updated to
      3.7.1, a bug-fix release.

    * The default for tools::write_PACKAGES(rds_compress=) has been
      changed to "xz" to match the compression used by CRAN.

    * c() and unlist() are now more efficient in constructing the
      names(.) of their return value, thanks to a proposal by Suharto
      Anggono.  (PR#17284)

  UTILITIES:

    * R CMD check checks for and R CMD build corrects CRLF line endings
      in shell scripts configure and cleanup (even on Windows).

  INSTALLATION on a UNIX-ALIKE:

    * The order of selection of OpenMP flags has been changed: Oracle
      Developer Studio 12.5 accepts -fopenmp and -xopenmp but only the
      latter enables OpenMP so it is now tried first.

  BUG FIXES:

    * within(List, rm(x1, x2)) works correctly again, including when
      List[["x2"]] is NULL.

    * regexec(pattern, text, *) now applies as.character(.) to its
      first two arguments, as documented.

    * write.table() and related functions, writeLines(), and perhaps
      other functions writing text to connections did not signal errors
      when the writes failed, e.g. due to a disk being full.  Errors
      will now be signalled if detected during the write, warnings if
      detected when the connection is closed.  (PR#17243)

    * rt() assumed the ncp parameter was a scalar.  (PR#17306)

    * menu(choices) with more than 10 choices which easily fit into one
      getOption("width")-line no longer erroneously repeats choices.
      (PR#17312)

    * length()<- on a pairlist succeeds.  (<URL:
      https://stat.ethz.ch/pipermail/r-devel/2017-July/074680.html>)

    * Language objects such as quote(("\n")) or R functions are
      correctly printed again, where R 3.4.1 accidentally duplicated
      the backslashes.

    * Construction of names() for very large objects in c() and
      unlist() now works, thanks to Suharto Anggono's patch proposals
      in PR#17292.

    * Resource leaks (and similar) reported by Steve Grubb fixed.
      (PR#17314, PR#17316, PR#17317, PR#17318, PR#17319, PR#17320)

    * model.matrix(~1, mf) now gets the row names from mf also when
      they differ from 1:nrow(mf), fixing PR#14992 thanks to the
      suggestion by Sebastian Meyer.

    * sigma(fm) now takes the correct denominator degrees of freedom
      for a fitted model with NA coefficients.  (PR#17313)

    * hist(x, "FD") no longer "dies" with a somewhat cryptic error
      message when x has extreme outliers or IQR() zero: nclass.FD(x)
      tries harder to find a robust bin width h in the latter case, and
      hist.default(*, breaks) now checks and corrects a too large
      breaks number.  (PR#17274)

    * callNextMethod() works for ... methods.

    * qr.coef(qd, y) now has correct names also when qd is a complex QR
      or stems from qr(*, LAPACK=TRUE).

    * Setting options(device = *) to an invalid function no longer
      segfaults when plotting is initiated.  (PR#15883)

    * encodeString(<very large string>) no longer segfaults.
      (PR#15885)

    * It is again possible to use configure --enable-maintainer-mode
      without having installed notangle (it was required in R
      3.4.[01]).

    * S4 method dispatch on ... calls the method by name instead of
      .Method (for consistency with default dispatch), and only
      attempts to pass non-missing arguments from the generic.

    * readRDS(textConnection(.)) works again.  (PR#17325)

    * (1:n)[-n] no longer segfaults for n <- 2.2e9 (on a platform with
      enough RAM).

    * x <- 1:2; tapply(x, list(x, x), function(x) "")[1,2] now
      correctly returns NA.  (PR#17333)

    * Running of finalizers after explicit GC request moved from the R
      interface do_gc to the C interface R_gc.  This helps with
      reclaiming inaccessible connections.

    * help.search(topic) and ??topic matching topics in vignettes with
      multiple file name extensions (e.g., *.md.rsp but not *.Rmd)
      failed with an error when using options(help_type = "html").

    * The X11 device no longer uses the Xlib backing store (PR#16497).

    * array(character(), 1) now gives (a 1D array with) NA as has been
      documented for a long time as in the other cases of zero-length
      array initialization and also compatibly with matrix(character(),
      *).  As mentioned there, this also fixes PR#17333.

    * splineDesign(.., derivs = 4) no longer segfaults.

    * fisher.test(*, hybrid=TRUE) now (again) will use the hybrid
      method when Cochran's conditions are met, fixing PR#16654.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From murdoch.duncan at gmail.com  Thu Sep 28 11:11:09 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 Sep 2017 05:11:09 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
Message-ID: <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>

On 27/09/2017 8:47 PM, Evan Cooch wrote:
> Suppose I have interest in a matrix with the following symbolic
> structure (specified by 3 parameters: sa, so, m):
> 
> matrix(c(0,sa*m,so,sa),2,2,byrow=T)
> 
> What I can't figure out is how to construct a series of matrices, where
> the elements/parameters are rnorm values. I'd like to construct separate
> matrices, with each matrix in the series using the 'next random
> parameter value'. While the following works (for generating, say, 5 such
> random matrices)
> 
> replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))
> 
> its inelegant, and a real pain if the matrix gets large (say, 20 x 20).
> 
> I'm wondering if there is an easier way. I tried
> 
>   > sa <- rnorm(5,0.8,0.1)
>   > so <- rnorm(5,0.5,0.1)
>   > m <- rnorm(5,1.2,0.1)
> 
> matrix(c(0,sa*m,so,sa),2,2,byrow=T)
> 
> but that only returns a single matrix, not 5 matrices as I'd like. I
> also tried several variants of the 'replicate' approach (above), but
> didn't stumble across anything that seemed to work.
> 
> So, is there a better way than something like:
> 
> replicate(5,matrix(c(0,rnorm(1,0.8,0.1)*rnorm(1,1.2,0.1),rnorm(1,0.5,0.1),rnorm(1,0.8,0.1)),2,2,byrow=T))
> 

Peter's mapply solution is probably the best.  Another that might be a 
little faster (but more obscure) is to use a 3-index array.  I think 
this is what you'd want, with sa, so, and m as defined above:

ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2))

Then matrix i will be stored as ms[i,,].

Duncan Murdoch


From miaojpm at gmail.com  Thu Sep 28 11:37:04 2017
From: miaojpm at gmail.com (John)
Date: Thu, 28 Sep 2017 02:37:04 -0700
Subject: [R] rename multiple files by file.rename or other functions
Message-ID: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>

Hi,

   I have 50 files whose names are

XYZW01Genesis_ABC.mp3
XYZW02Genesis_ABC.mp3
.......
XYZW50Genesis_ABC.mp3

   As you can tell, the only difference across the files are 01, 02,
03,....50.

   I would like to rename them to
01Gen01.mp3
01Gen02.mp3
.......
01Gen50.mp3

  If I store them in one folder and write an R code in that folder, how can
it be done?

   Thanks,

John

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Sep 28 11:42:42 2017
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 28 Sep 2017 09:42:42 +0000
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
Message-ID: <CAKVAULMiR+sGbyRGqiEt4ewYUjcO49g9VQZhq=+632V-TqdTzw@mail.gmail.com>

Hi John,

I don't know how to do this with R, but on Linux I'd use rename (or maybe
even by hand if it's a one time event). On Windows I believe there is a
tool called Bulk Rename.

HTH
Ulrik

On Thu, 28 Sep 2017 at 11:37 John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I have 50 files whose names are
>
> XYZW01Genesis_ABC.mp3
> XYZW02Genesis_ABC.mp3
> .......
> XYZW50Genesis_ABC.mp3
>
>    As you can tell, the only difference across the files are 01, 02,
> 03,....50.
>
>    I would like to rename them to
> 01Gen01.mp3
> 01Gen02.mp3
> .......
> 01Gen50.mp3
>
>   If I store them in one folder and write an R code in that folder, how can
> it be done?
>
>    Thanks,
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Sep 28 12:25:59 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 28 Sep 2017 20:25:59 +1000
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
Message-ID: <CA+8X3fWPqsXnEwDn_t2p8roOFNeBCkAMtoKDtgknJL20BoR_-Q@mail.gmail.com>

Hi John,
Maybe this:

filenames<-c("XYZW01Genesis_ABC.mp3","XYZW02Genesis_ABC.mp3")
for(filename in filenames) {
 filefirst<-sapply(strsplit(filename,"[.]"),"[",1)
 fileno<-sub("_","",gsub("[[:alpha:]]","",filefirst))
 file.rename(filename,paste("01Gen",fileno,".mp3",sep=""))
}

Jim

On Thu, Sep 28, 2017 at 7:37 PM, John <miaojpm at gmail.com> wrote:
> Hi,
>
>    I have 50 files whose names are
>
> XYZW01Genesis_ABC.mp3
> XYZW02Genesis_ABC.mp3
> .......
> XYZW50Genesis_ABC.mp3
>
>    As you can tell, the only difference across the files are 01, 02,
> 03,....50.
>
>    I would like to rename them to
> 01Gen01.mp3
> 01Gen02.mp3
> .......
> 01Gen50.mp3
>
>   If I store them in one folder and write an R code in that folder, how can
> it be done?
>
>    Thanks,
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Sep 28 12:27:03 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 Sep 2017 06:27:03 -0400
Subject: [R] R 3.4.2 is released
In-Reply-To: <589AFDAF-C1DA-4F84-8FF5-F4344385AF51@cbs.dk>
References: <589AFDAF-C1DA-4F84-8FF5-F4344385AF51@cbs.dk>
Message-ID: <2364ab53-f06d-5e55-636c-bd402bf58568@gmail.com>

I've just finished the Windows build of R 3.4.2.  It will make it to 
CRAN and its mirrors over the next few hours.

This is the last binary release that I will be producing.  I've been 
building them for about 15 years, and it's time to retire.  Builds using 
different tools and scripts are available from 
https://mran.microsoft.com/download/.  I'll be putting my own scripts on 
CRAN soon in case anyone wants to duplicate them.

Nightly builds of R-patched and R-devel will continue to run on 
autopilot for the time being, without maintenance.

I will also be retiring from maintenance of the Rtools collection.

Duncan Murdoch

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ericjberger at gmail.com  Thu Sep 28 12:57:24 2017
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 28 Sep 2017 13:57:24 +0300
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CA+8X3fWPqsXnEwDn_t2p8roOFNeBCkAMtoKDtgknJL20BoR_-Q@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
 <CA+8X3fWPqsXnEwDn_t2p8roOFNeBCkAMtoKDtgknJL20BoR_-Q@mail.gmail.com>
Message-ID: <CAGgJW74FqiE9aGYf1aU3ZHU+KsDki3uYU2pSw+59zuSRbFNFzA@mail.gmail.com>

Hi John,
Thanks to Jim for pointing out the file.rename() function. You can try this:

# define the filename templates
strIn  <- "XYZW--Genesis_ABC.mp3"
strOut <- "01Gen--.mp3"

# create the strings "01", "02", ..., "50"
v <- sapply(1:50, function(i) sprintf("%02d",i) )

# perform all the file renames
for ( s in v ) { file.rename(sub("--",s,strIn), sub("--",s,strOut) ) }

HTH,
Eric









On Thu, Sep 28, 2017 at 1:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi John,
> Maybe this:
>
> filenames<-c("XYZW01Genesis_ABC.mp3","XYZW02Genesis_ABC.mp3")
> for(filename in filenames) {
>  filefirst<-sapply(strsplit(filename,"[.]"),"[",1)
>  fileno<-sub("_","",gsub("[[:alpha:]]","",filefirst))
>  file.rename(filename,paste("01Gen",fileno,".mp3",sep=""))
> }
>
> Jim
>
> On Thu, Sep 28, 2017 at 7:37 PM, John <miaojpm at gmail.com> wrote:
> > Hi,
> >
> >    I have 50 files whose names are
> >
> > XYZW01Genesis_ABC.mp3
> > XYZW02Genesis_ABC.mp3
> > .......
> > XYZW50Genesis_ABC.mp3
> >
> >    As you can tell, the only difference across the files are 01, 02,
> > 03,....50.
> >
> >    I would like to rename them to
> > 01Gen01.mp3
> > 01Gen02.mp3
> > .......
> > 01Gen50.mp3
> >
> >   If I store them in one folder and write an R code in that folder, how
> can
> > it be done?
> >
> >    Thanks,
> >
> > John
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Sep 28 13:32:47 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 28 Sep 2017 13:32:47 +0200
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CAGgJW74FqiE9aGYf1aU3ZHU+KsDki3uYU2pSw+59zuSRbFNFzA@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
 <CA+8X3fWPqsXnEwDn_t2p8roOFNeBCkAMtoKDtgknJL20BoR_-Q@mail.gmail.com>
 <CAGgJW74FqiE9aGYf1aU3ZHU+KsDki3uYU2pSw+59zuSRbFNFzA@mail.gmail.com>
Message-ID: <7C8A48E8-0ECA-4174-9375-E6188DAB222D@gmail.com>


> On 28 Sep 2017, at 12:57 , Eric Berger <ericjberger at gmail.com> wrote:
> 
> Hi John,
> Thanks to Jim for pointing out the file.rename() function. You can try this:
> 
> # define the filename templates
> strIn  <- "XYZW--Genesis_ABC.mp3"
> strOut <- "01Gen--.mp3"
> 
> # create the strings "01", "02", ..., "50"
> v <- sapply(1:50, function(i) sprintf("%02d",i) )
> 
> # perform all the file renames
> for ( s in v ) { file.rename(sub("--",s,strIn), sub("--",s,strOut) ) }
> 
> HTH,
> Eric
> 
> 

I think you can even do this:

strIn <- sprintf("XYZW%02dGenesis_ABC.mp3", 1:50)
strOut <- sprintf("01Gen%02d.mp3", 1:50)
## perhaps try cbind(strIn,strOut) first
file.rename(strIn, strOut)

-pd

> 
> 
> 
> 
> 
> 
> 
> On Thu, Sep 28, 2017 at 1:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi John,
>> Maybe this:
>> 
>> filenames<-c("XYZW01Genesis_ABC.mp3","XYZW02Genesis_ABC.mp3")
>> for(filename in filenames) {
>> filefirst<-sapply(strsplit(filename,"[.]"),"[",1)
>> fileno<-sub("_","",gsub("[[:alpha:]]","",filefirst))
>> file.rename(filename,paste("01Gen",fileno,".mp3",sep=""))
>> }
>> 
>> Jim
>> 
>> On Thu, Sep 28, 2017 at 7:37 PM, John <miaojpm at gmail.com> wrote:
>>> Hi,
>>> 
>>>   I have 50 files whose names are
>>> 
>>> XYZW01Genesis_ABC.mp3
>>> XYZW02Genesis_ABC.mp3
>>> .......
>>> XYZW50Genesis_ABC.mp3
>>> 
>>>   As you can tell, the only difference across the files are 01, 02,
>>> 03,....50.
>>> 
>>>   I would like to rename them to
>>> 01Gen01.mp3
>>> 01Gen02.mp3
>>> .......
>>> 01Gen50.mp3
>>> 
>>>  If I store them in one folder and write an R code in that folder, how
>> can
>>> it be done?
>>> 
>>>   Thanks,
>>> 
>>> John
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thierry.onkelinx at inbo.be  Thu Sep 28 12:09:03 2017
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 28 Sep 2017 12:09:03 +0200
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
Message-ID: <CAJuCY5zdDkrgTEm1hhm8sHcyFZ0jWpkZhZ5NmOg2uHRhu4Bwow@mail.gmail.com>

The combination of list.files(), gsub() and file.rename() should to the
trick.


ir. Thierry Onkelinx
Statisticus/ Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Kliniekstraat 25, B-1070 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

[image: Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging
in Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis. Vanaf
dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000 Brussel.]
<https://overheid.vlaanderen.be/mobiliteitsplan-herman-teirlinckgebouw>
Van 14 tot en met 19 december 2017 verhuizen we uit onze vestiging in
Brussel naar het Herman Teirlinckgebouw op de site Thurn & Taxis.
Vanaf dan ben je welkom op het nieuwe adres: Havenlaan 88 bus 73, 1000
Brussel.

///////////////////////////////////////////////////////////////////////////////////////////
<https://www.inbo.be>

2017-09-28 11:37 GMT+02:00 John <miaojpm at gmail.com>:

> Hi,
>
>    I have 50 files whose names are
>
> XYZW01Genesis_ABC.mp3
> XYZW02Genesis_ABC.mp3
> .......
> XYZW50Genesis_ABC.mp3
>
>    As you can tell, the only difference across the files are 01, 02,
> 03,....50.
>
>    I would like to rename them to
> 01Gen01.mp3
> 01Gen02.mp3
> .......
> 01Gen50.mp3
>
>   If I store them in one folder and write an R code in that folder, how can
> it be done?
>
>    Thanks,
>
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Sep 28 15:10:10 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 28 Sep 2017 09:10:10 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
Message-ID: <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>

Thanks for both the mapply and array approaches! However, although 
intended to generate the same result, they don't:

# mapply approach

n = 3
sa <- rnorm(n,0.8,0.1)
so <- rnorm(n,0.5,0.1)
m <- rnorm(n,1.2,0.1)
mats = mapply(function(sa1, so1, m1) 
matrix(c(0,sa1*m1,so1,sa1),2,2,byrow=T), sa, so, m, SIMPLIFY = FALSE)

print(mats)

[[1]]
 ????????? [,1]????? [,2]
[1,] 0.0000000 0.8643679
[2,] 0.4731249 0.7750431

[[2]]
 ????????? [,1]????? [,2]
[1,] 0.0000000 0.8838286
[2,] 0.5895258 0.7880983

[[3]]
 ????????? [,1]????? [,2]
[1,] 0.0000000 1.1491560
[2,] 0.4947322 0.9744166


Now, the array approach:

# array approach

ms <- array(c(rep(0, 3),sa*m,so,sa), c(3, 2, 2))

for (i in 1:n) { print(ms[i,,])

 ????????? [,1]????? [,2]
[1,] 0.0000000 0.4731249
[2,] 0.8643679 0.7750431

 ????????? [,1]????? [,2]
[1,] 0.0000000 0.5895258
[2,] 0.8838286 0.7880983

 ???????? [,1]????? [,2]
[1,] 0.000000 0.4947322
[2,] 1.149156 0.9744166


These matrices are the transpose of those returned by the mapply 
approach. To see if one approach or the other is 'confused', I simply 
rerun setting sd=0 for the parameters -- thus, every matrix will be the 
same. The correct matrix would be:

 ???? [,1] [,2]
[1,]? 0.0 0.96
[2,]? 0.5 0.80


In fact, this is what is returned by the mapply approach, while the 
array approach returns the transpose. I gather the 'missing step' is to 
use aperm, but haven't figured out how to get that to work...yet.


On 9/28/2017 5:11 AM, Duncan Murdoch wrote:
> ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2)) 


	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Sep 28 15:14:08 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 28 Sep 2017 09:14:08 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
 <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
Message-ID: <3b505982-0c4c-b7a3-30d8-4579d46ac3dd@gmail.com>


>
> In fact, this is what is returned by the mapply approach, while the 
> array approach returns the transpose. I gather the 'missing step' is 
> to use aperm, but haven't figured out how to get that to work...yet.

ms <- array(c(rep(0, 3),sa*m,so,sa), c(3, 2, 2))

ms_new <- aperm(ms,c(1,3,2));

for (i in 1:n) { print(ms_new[i,,]) }

 ???? [,1] [,2]
[1,]? 0.0 0.96
[2,]? 0.5 0.80

 ???? [,1] [,2]
[1,]? 0.0 0.96
[2,]? 0.5 0.80

 ???? [,1] [,2]
[1,]? 0.0 0.96
[2,]? 0.5 0.80


>
>
> On 9/28/2017 5:11 AM, Duncan Murdoch wrote:
>> ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2)) 
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Sep 28 17:55:17 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 Sep 2017 11:55:17 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
 <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
Message-ID: <3cd9414a-c194-bddc-b55e-ce74cf1d32a9@gmail.com>

On 28/09/2017 9:10 AM, Evan Cooch wrote:
> Thanks for both the mapply and array approaches! However, although 
> intended to generate the same result, they don't:
> 
> # mapply approach
> 
> n = 3
> sa <- rnorm(n,0.8,0.1)
> so <- rnorm(n,0.5,0.1)
> m <- rnorm(n,1.2,0.1)
> mats = mapply(function(sa1, so1, m1) 
> matrix(c(0,sa1*m1,so1,sa1),2,2,byrow=T), sa, so, m, SIMPLIFY = FALSE)
> 
> print(mats)
> 
> [[1]]
>  ????????? [,1]????? [,2]
> [1,] 0.0000000 0.8643679
> [2,] 0.4731249 0.7750431
> 
> [[2]]
>  ????????? [,1]????? [,2]
> [1,] 0.0000000 0.8838286
> [2,] 0.5895258 0.7880983
> 
> [[3]]
>  ????????? [,1]????? [,2]
> [1,] 0.0000000 1.1491560
> [2,] 0.4947322 0.9744166
> 
> 
> Now, the array approach:
> 
> # array approach
> 
> ms <- array(c(rep(0, 3),sa*m,so,sa), c(3, 2, 2))
> 
> for (i in 1:n) { print(ms[i,,])
> 
>  ????????? [,1]????? [,2]
> [1,] 0.0000000 0.4731249
> [2,] 0.8643679 0.7750431
> 
>  ????????? [,1]????? [,2]
> [1,] 0.0000000 0.5895258
> [2,] 0.8838286 0.7880983
> 
>  ???????? [,1]????? [,2]
> [1,] 0.000000 0.4947322
> [2,] 1.149156 0.9744166
> 
> 
> These matrices are the transpose of those returned by the mapply 
> approach. To see if one approach or the other is 'confused', I simply 
> rerun setting sd=0 for the parameters -- thus, every matrix will be the 
> same. The correct matrix would be:
> 
>  ???? [,1] [,2]
> [1,]? 0.0 0.96
> [2,]? 0.5 0.80
> 
> 
> In fact, this is what is returned by the mapply approach, while the 
> array approach returns the transpose. I gather the 'missing step' is to 
> use aperm, but haven't figured out how to get that to work...yet.
> 
> 
> On 9/28/2017 5:11 AM, Duncan Murdoch wrote:
>> ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2)) 
> 


Sorry about that -- I didn't notice the "byrow = T" in your original.

Duncan Murdoch


From shylashivashree at gmail.com  Thu Sep 28 14:00:31 2017
From: shylashivashree at gmail.com (Shylashree U.R)
Date: Thu, 28 Sep 2017 17:30:31 +0530
Subject: [R] Efficient Package for Huge datasets in R
Message-ID: <CAPvnpU8b1qDT=yED9WiSL-gUD6MFOoCG=4QSZ3XLaLqN=fGzRA@mail.gmail.com>

Dear Sir/Madam,

I have a large data set of 10,17,289 observations of 10,830 variables. I
need to use PCA to reduce the dimension of dataset. I have already tried
irlba, prcomp and nsprcomp packages in R but couldn't do for huge data
sets.

i.e pc <- prcomp_irlba(sparseYY[1:5000,], n=50, retx = TRUE, center = TRUE,
scale. = FALSE)
able to get only few PCs for 5000 rows only

so can you please help me what package can i use to do PCA in R for large
dataset?


Thanks and Regards

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Sep 28 18:10:26 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 28 Sep 2017 12:10:26 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <3cd9414a-c194-bddc-b55e-ce74cf1d32a9@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
 <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
 <3cd9414a-c194-bddc-b55e-ce74cf1d32a9@gmail.com>
Message-ID: <89a12ee8-8582-63ac-794e-87fbdc121bc2@gmail.com>

Sure -- thanks -- only took me 3-4 attempts to get aperm to work (as 
opposed to really thinking hard about how it works ;-)

On 9/28/2017 11:55 AM, Duncan Murdoch wrote:
> On 28/09/2017 9:10 AM, Evan Cooch wrote:
>> Thanks for both the mapply and array approaches! However, although 
>> intended to generate the same result, they don't:
>>
>> # mapply approach
>>
>> n = 3
>> sa <- rnorm(n,0.8,0.1)
>> so <- rnorm(n,0.5,0.1)
>> m <- rnorm(n,1.2,0.1)
>> mats = mapply(function(sa1, so1, m1) 
>> matrix(c(0,sa1*m1,so1,sa1),2,2,byrow=T), sa, so, m, SIMPLIFY = FALSE)
>>
>> print(mats)
>>
>> [[1]]
>> ?????????? [,1]????? [,2]
>> [1,] 0.0000000 0.8643679
>> [2,] 0.4731249 0.7750431
>>
>> [[2]]
>> ?????????? [,1]????? [,2]
>> [1,] 0.0000000 0.8838286
>> [2,] 0.5895258 0.7880983
>>
>> [[3]]
>> ?????????? [,1]????? [,2]
>> [1,] 0.0000000 1.1491560
>> [2,] 0.4947322 0.9744166
>>
>>
>> Now, the array approach:
>>
>> # array approach
>>
>> ms <- array(c(rep(0, 3),sa*m,so,sa), c(3, 2, 2))
>>
>> for (i in 1:n) { print(ms[i,,])
>>
>> ?????????? [,1]????? [,2]
>> [1,] 0.0000000 0.4731249
>> [2,] 0.8643679 0.7750431
>>
>> ?????????? [,1]????? [,2]
>> [1,] 0.0000000 0.5895258
>> [2,] 0.8838286 0.7880983
>>
>> ????????? [,1]????? [,2]
>> [1,] 0.000000 0.4947322
>> [2,] 1.149156 0.9744166
>>
>>
>> These matrices are the transpose of those returned by the mapply 
>> approach. To see if one approach or the other is 'confused', I simply 
>> rerun setting sd=0 for the parameters -- thus, every matrix will be 
>> the same. The correct matrix would be:
>>
>> ????? [,1] [,2]
>> [1,]? 0.0 0.96
>> [2,]? 0.5 0.80
>>
>>
>> In fact, this is what is returned by the mapply approach, while the 
>> array approach returns the transpose. I gather the 'missing step' is 
>> to use aperm, but haven't figured out how to get that to work...yet.
>>
>>
>> On 9/28/2017 5:11 AM, Duncan Murdoch wrote:
>>> ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2)) 
>>
>
>
> Sorry about that -- I didn't notice the "byrow = T" in your original.
>
> Duncan Murdoch
>


	[[alternative HTML version deleted]]


From ebs15242 at gmail.com  Thu Sep 28 18:40:01 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 28 Sep 2017 11:40:01 -0500
Subject: [R] Boxplot, formula interface, and labels.
Message-ID: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>

I have data I'd like to plot using the formula interface to boxplot.
I call boxplot like so:

with(mydata, boxplot(count ~ geno * tissue))

I get a boxplot with x axis labels like "wt.kidney".  I would like
to change the '.' to a newline.  Where is this separator configured?

Thanks,
-Ed


From ebs15242 at gmail.com  Thu Sep 28 19:06:57 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 28 Sep 2017 12:06:57 -0500
Subject: [R] Boxplot, formula interface, and labels.
In-Reply-To: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
References: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
Message-ID: <CALRb-odDTARatDFT0A=0PpRQ70gpqUwBeU5ESqY58CgbXEUO2g@mail.gmail.com>

Another way to think of this problem.  If I could get my hands on the
vector of names boxplot()
is creating, I could use gsub() to replace '.' with '\n'.

Is there something I could run before boxplot() that would give me
that vector of names which
I could then pass to boxplot()?

On Thu, Sep 28, 2017 at 11:40 AM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I have data I'd like to plot using the formula interface to boxplot.
> I call boxplot like so:
>
> with(mydata, boxplot(count ~ geno * tissue))
>
> I get a boxplot with x axis labels like "wt.kidney".  I would like
> to change the '.' to a newline.  Where is this separator configured?
>
> Thanks,
> -Ed


From jdnewmil at dcn.davis.ca.us  Thu Sep 28 19:22:10 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 28 Sep 2017 10:22:10 -0700
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <89a12ee8-8582-63ac-794e-87fbdc121bc2@gmail.com>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
 <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
 <3cd9414a-c194-bddc-b55e-ce74cf1d32a9@gmail.com>
 <89a12ee8-8582-63ac-794e-87fbdc121bc2@gmail.com>
Message-ID: <C50C6DB5-0049-4808-9832-30930FFD5082@dcn.davis.ca.us>

The use of aperm is unnecessary if you call array() properly. 

ms <- array(c(rep(0, 5),so,sa*m,sa), c(5, 2, 2))
-- 
Sent from my phone. Please excuse my brevity.

On September 28, 2017 9:10:26 AM PDT, Evan Cooch <evan.cooch at gmail.com> wrote:
>Sure -- thanks -- only took me 3-4 attempts to get aperm to work (as 
>opposed to really thinking hard about how it works ;-)
>
>On 9/28/2017 11:55 AM, Duncan Murdoch wrote:
>> On 28/09/2017 9:10 AM, Evan Cooch wrote:
>>> Thanks for both the mapply and array approaches! However, although 
>>> intended to generate the same result, they don't:
>>>
>>> # mapply approach
>>>
>>> n = 3
>>> sa <- rnorm(n,0.8,0.1)
>>> so <- rnorm(n,0.5,0.1)
>>> m <- rnorm(n,1.2,0.1)
>>> mats = mapply(function(sa1, so1, m1) 
>>> matrix(c(0,sa1*m1,so1,sa1),2,2,byrow=T), sa, so, m, SIMPLIFY =
>FALSE)
>>>
>>> print(mats)
>>>
>>> [[1]]
>>> ?????????? [,1]????? [,2]
>>> [1,] 0.0000000 0.8643679
>>> [2,] 0.4731249 0.7750431
>>>
>>> [[2]]
>>> ?????????? [,1]????? [,2]
>>> [1,] 0.0000000 0.8838286
>>> [2,] 0.5895258 0.7880983
>>>
>>> [[3]]
>>> ?????????? [,1]????? [,2]
>>> [1,] 0.0000000 1.1491560
>>> [2,] 0.4947322 0.9744166
>>>
>>>
>>> Now, the array approach:
>>>
>>> # array approach
>>>
>>> ms <- array(c(rep(0, 3),sa*m,so,sa), c(3, 2, 2))
>>>
>>> for (i in 1:n) { print(ms[i,,])
>>>
>>> ?????????? [,1]????? [,2]
>>> [1,] 0.0000000 0.4731249
>>> [2,] 0.8643679 0.7750431
>>>
>>> ?????????? [,1]????? [,2]
>>> [1,] 0.0000000 0.5895258
>>> [2,] 0.8838286 0.7880983
>>>
>>> ????????? [,1]????? [,2]
>>> [1,] 0.000000 0.4947322
>>> [2,] 1.149156 0.9744166
>>>
>>>
>>> These matrices are the transpose of those returned by the mapply 
>>> approach. To see if one approach or the other is 'confused', I
>simply 
>>> rerun setting sd=0 for the parameters -- thus, every matrix will be 
>>> the same. The correct matrix would be:
>>>
>>> ????? [,1] [,2]
>>> [1,]? 0.0 0.96
>>> [2,]? 0.5 0.80
>>>
>>>
>>> In fact, this is what is returned by the mapply approach, while the 
>>> array approach returns the transpose. I gather the 'missing step' is
>
>>> to use aperm, but haven't figured out how to get that to work...yet.
>>>
>>>
>>> On 9/28/2017 5:11 AM, Duncan Murdoch wrote:
>>>> ms <- array(c(rep(0, 5),sa*m,so,sa), c(5, 2, 2)) 
>>>
>>
>>
>> Sorry about that -- I didn't notice the "byrow = T" in your original.
>>
>> Duncan Murdoch
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Sep 28 19:27:00 2017
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 28 Sep 2017 13:27:00 -0400
Subject: [R] Boxplot, formula interface, and labels.
In-Reply-To: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
References: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
Message-ID: <CA+vqiLHjT7cZg4KeGpNR5T9PUN8rmhWMkV_fvbkspAa7zkcWug@mail.gmail.com>

mybp <- boxplot(count ~ geno * tissue, data = mydata, plot = FALSE)
mybp$names <- gsub("\\.", "\n", mybp$names)
bxp(mybp)

See ?boxplot for details.

Best,
Ista

On Thu, Sep 28, 2017 at 12:40 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I have data I'd like to plot using the formula interface to boxplot.
> I call boxplot like so:
>
> with(mydata, boxplot(count ~ geno * tissue))
>
> I get a boxplot with x axis labels like "wt.kidney".  I would like
> to change the '.' to a newline.  Where is this separator configured?
>
> Thanks,
> -Ed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Sep 28 19:30:13 2017
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 28 Sep 2017 17:30:13 +0000
Subject: [R] Boxplot, formula interface, and labels.
In-Reply-To: <CA+vqiLHjT7cZg4KeGpNR5T9PUN8rmhWMkV_fvbkspAa7zkcWug@mail.gmail.com>
References: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
 <CA+vqiLHjT7cZg4KeGpNR5T9PUN8rmhWMkV_fvbkspAa7zkcWug@mail.gmail.com>
Message-ID: <e28ce4d7374d4a3dad45b6482791a930@exch-2p-mbx-w2.ads.tamu.edu>

Just change the separator:

data(Titanic)
Titanic.df <- as.data.frame(Titanic)
boxplot(Freq~Class*Sex, Titanic.df, cex.axis=.6, sep="\n")

See attached .png.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn
Sent: Thursday, September 28, 2017 12:27 PM
To: Ed Siefker <ebs15242 at gmail.com>
Cc: r-help <r-help at r-project.org>
Subject: Re: [R] Boxplot, formula interface, and labels.

mybp <- boxplot(count ~ geno * tissue, data = mydata, plot = FALSE) mybp$names <- gsub("\\.", "\n", mybp$names)
bxp(mybp)

See ?boxplot for details.

Best,
Ista

On Thu, Sep 28, 2017 at 12:40 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
> I have data I'd like to plot using the formula interface to boxplot.
> I call boxplot like so:
>
> with(mydata, boxplot(count ~ geno * tissue))
>
> I get a boxplot with x axis labels like "wt.kidney".  I would like to 
> change the '.' to a newline.  Where is this separator configured?
>
> Thanks,
> -Ed
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Titanic.png
Type: image/png
Size: 4773 bytes
Desc: Titanic.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170928/b11652c1/attachment.png>

From ebs15242 at gmail.com  Thu Sep 28 19:45:12 2017
From: ebs15242 at gmail.com (Ed Siefker)
Date: Thu, 28 Sep 2017 12:45:12 -0500
Subject: [R] Fwd:  Boxplot, formula interface, and labels.
In-Reply-To: <e28ce4d7374d4a3dad45b6482791a930@exch-2p-mbx-w2.ads.tamu.edu>
References: <CALRb-oftAuf9X2KVLtiO_mcXVAjSGXKt=BR93T_E+aOtNg796Q@mail.gmail.com>
 <CA+vqiLHjT7cZg4KeGpNR5T9PUN8rmhWMkV_fvbkspAa7zkcWug@mail.gmail.com>
 <e28ce4d7374d4a3dad45b6482791a930@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CALRb-odDUm9MB_F6r=_-aNkb7imqyv2=DrR1OYR6g_zfOt1xMw@mail.gmail.com>

I knew I was making harder than it needed to be.  I see it now in ?boxplot
Thanks!

On Thu, Sep 28, 2017 at 12:30 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Just change the separator:
>
> data(Titanic)
> Titanic.df <- as.data.frame(Titanic)
> boxplot(Freq~Class*Sex, Titanic.df, cex.axis=.6, sep="\n")
>
> See attached .png.
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ista Zahn
> Sent: Thursday, September 28, 2017 12:27 PM
> To: Ed Siefker <ebs15242 at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Boxplot, formula interface, and labels.
>
> mybp <- boxplot(count ~ geno * tissue, data = mydata, plot = FALSE) mybp$names <- gsub("\\.", "\n", mybp$names)
> bxp(mybp)
>
> See ?boxplot for details.
>
> Best,
> Ista
>
> On Thu, Sep 28, 2017 at 12:40 PM, Ed Siefker <ebs15242 at gmail.com> wrote:
>> I have data I'd like to plot using the formula interface to boxplot.
>> I call boxplot like so:
>>
>> with(mydata, boxplot(count ~ geno * tissue))
>>
>> I get a boxplot with x axis labels like "wt.kidney".  I would like to
>> change the '.' to a newline.  Where is this separator configured?
>>
>> Thanks,
>> -Ed
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Titanic.png
Type: image/png
Size: 4773 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20170928/a5b62dee/attachment.png>

From evan.cooch at gmail.com  Thu Sep 28 21:33:52 2017
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 28 Sep 2017 15:33:52 -0400
Subject: [R] building random matrices from vectors of random parameters
In-Reply-To: <C50C6DB5-0049-4808-9832-30930FFD5082@dcn.davis.ca.us>
References: <b74ac3d0-ac90-9784-1621-cc9044adce08@gmail.com>
 <49de83f2-722c-d4dc-cd07-2048794bac52@gmail.com>
 <eb60fbb6-c469-bfa0-f85f-b517350c75d7@gmail.com>
 <3cd9414a-c194-bddc-b55e-ce74cf1d32a9@gmail.com>
 <89a12ee8-8582-63ac-794e-87fbdc121bc2@gmail.com>
 <C50C6DB5-0049-4808-9832-30930FFD5082@dcn.davis.ca.us>
Message-ID: <d0eb33d7-e0e3-ef5f-3452-8c025c8dc76e@gmail.com>

Makes sense, although (re-)learning what aperm does wasn't a wasted 
exercise.

Thanks!

On 9/28/2017 1:22 PM, Jeff Newmiller wrote:
> The use of aperm is unnecessary if you call array() properly.
>
> ms <- array(c(rep(0, 5),so,sa*m,sa), c(5, 2, 2))


	[[alternative HTML version deleted]]


From dan.abner99 at gmail.com  Thu Sep 28 22:25:36 2017
From: dan.abner99 at gmail.com (Dan Abner)
Date: Thu, 28 Sep 2017 16:25:36 -0400
Subject: [R] Searching for Enumerated Items using str_count() from the
	stringr package
Message-ID: <CAPRGo-m6PhxNRXE+ZHAhZFxfS6myt7xGymwODR7Fs0Ch91GrGg@mail.gmail.com>

Hi all,

I have a large number of text strings to search for enumerated items.
However, I am receiving this error message even though I thought that I
properly escaped the special character closed parenthesis:


> Count<-str_count(text3,keywords)
Error in stri_count_regex(string, pattern, opts_regex = opts(pattern)) :
  Syntax error in regexp pattern. (U_REGEX_RULE_SYNTAX)


===

Here is example code:


text1<-"This is a list:
1) Number 1
2) Etc
3) Etc"

text2<-"This is NOT a list:
Blah, blah, blah
Blah, blah, blah"

text3<-c(text1,text2)
text3

{keywords<-c(paste(0:9,"\\)"),paste(0:9,"\\)",sep=""),
paste(0:9,"."),paste(0:9,".",sep=""),"-","*")}

keywords

Count<-str_count(text3,keywords)

===

I am looking for Count<-c(3,0)

Any suggestions?

Thanks!

Dan

	[[alternative HTML version deleted]]


From toth.denes at kogentum.hu  Fri Sep 29 00:02:45 2017
From: toth.denes at kogentum.hu (=?UTF-8?B?VMOzdGggRMOpbmVz?=)
Date: Fri, 29 Sep 2017 00:02:45 +0200
Subject: [R] Searching for Enumerated Items using str_count() from the
 stringr package
In-Reply-To: <CAPRGo-m6PhxNRXE+ZHAhZFxfS6myt7xGymwODR7Fs0Ch91GrGg@mail.gmail.com>
References: <CAPRGo-m6PhxNRXE+ZHAhZFxfS6myt7xGymwODR7Fs0Ch91GrGg@mail.gmail.com>
Message-ID: <fc3d2606-1009-1783-f7eb-c27ec59e9464@kogentum.hu>



On 09/28/2017 10:25 PM, Dan Abner wrote:
> Hi all,
> 
> I have a large number of text strings to search for enumerated items.
> However, I am receiving this error message even though I thought that I
> properly escaped the special character closed parenthesis:
> 
> 
>> Count<-str_count(text3,keywords)
> Error in stri_count_regex(string, pattern, opts_regex = opts(pattern)) :
>    Syntax error in regexp pattern. (U_REGEX_RULE_SYNTAX)
> 
> 
> ===
> 
> Here is example code:
> 
> 
> text1<-"This is a list:
> 1) Number 1
> 2) Etc
> 3) Etc"
> 
> text2<-"This is NOT a list:
> Blah, blah, blah
> Blah, blah, blah"
> 
> text3<-c(text1,text2)
> text3
> 
> {keywords<-c(paste(0:9,"\\)"),paste(0:9,"\\)",sep=""),
> paste(0:9,"."),paste(0:9,".",sep=""),"-","*")}
> 

You should carefully read the docs, see ?regexp.
You really do not want to pass a multi-element vector as 'keywords' in 
this case, but instead:

stri_count_regex(text3, "[0-9]+\\) ")

or:

stri_count_regex(text3, "[[:digit:]]+\\) ")

BTW, I do not understand why to use the stringr package if it is just a 
wrapper around the stringi package.

Regards,
Denes




> keywords
> 
> Count<-str_count(text3,keywords)
> 
> ===
> 
> I am looking for Count<-c(3,0)
> 
> Any suggestions?
> 
> Thanks!
> 
> Dan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr. T?th D?nes ?gyvezet?
Kogentum Kft.
Tel.: 06-30-2583723
Web: www.kogentum.hu


From toth.denes at kogentum.hu  Fri Sep 29 00:14:30 2017
From: toth.denes at kogentum.hu (=?UTF-8?B?VMOzdGggRMOpbmVz?=)
Date: Fri, 29 Sep 2017 00:14:30 +0200
Subject: [R] Searching for Enumerated Items using str_count() from the
 stringr package
In-Reply-To: <fc3d2606-1009-1783-f7eb-c27ec59e9464@kogentum.hu>
References: <CAPRGo-m6PhxNRXE+ZHAhZFxfS6myt7xGymwODR7Fs0Ch91GrGg@mail.gmail.com>
 <fc3d2606-1009-1783-f7eb-c27ec59e9464@kogentum.hu>
Message-ID: <72d3ad5a-17db-a69e-a5e9-7ae421ee1667@kogentum.hu>



On 09/29/2017 12:02 AM, T?th D?nes wrote:
> 
> 
> On 09/28/2017 10:25 PM, Dan Abner wrote:
>> Hi all,
>>
>> I have a large number of text strings to search for enumerated items.
>> However, I am receiving this error message even though I thought that I
>> properly escaped the special character closed parenthesis:
>>
>>
>>> Count<-str_count(text3,keywords)
>> Error in stri_count_regex(string, pattern, opts_regex = opts(pattern)) :
>>    Syntax error in regexp pattern. (U_REGEX_RULE_SYNTAX)
>>
>>
>> ===
>>
>> Here is example code:
>>
>>
>> text1<-"This is a list:
>> 1) Number 1
>> 2) Etc
>> 3) Etc"
>>
>> text2<-"This is NOT a list:
>> Blah, blah, blah
>> Blah, blah, blah"
>>
>> text3<-c(text1,text2)
>> text3
>>
>> {keywords<-c(paste(0:9,"\\)"),paste(0:9,"\\)",sep=""),
>> paste(0:9,"."),paste(0:9,".",sep=""),"-","*")}
>>
> 
> You should carefully read the docs, see ?regexp.
> You really do not want to pass a multi-element vector as 'keywords' in 
> this case, but instead:
> 
> stri_count_regex(text3, "[0-9]+\\) ")
> 
> or:
> 
> stri_count_regex(text3, "[[:digit:]]+\\) ")
> 

Ah, now I see what you were after: enumerations are not in a standard 
format, so "1) " can be "1)", "1.", "1 .".

In this case:
text <- "1)Hello\n2.Hi\n3 .Cheers"
keywords <- "[0-9]+(\\)| *?\\.)"
stri_count_regex(text, keywords)

Note the '|' sign in the keyword definition. It means OR in this 
context. So literally the regexp expression above can be translated as:
A digit or a digit string followed by a parenthesis, or by arbitrary 
number of spaces (even 0) before a dot.

HTH,
Denes

> BTW, I do not understand why to use the stringr package if it is just a 
> wrapper around the stringi package.
> 
> Regards,
> Denes
> 
> 
> 
> 
>> keywords
>>
>> Count<-str_count(text3,keywords)
>>
>> ===
>>
>> I am looking for Count<-c(3,0)
>>
>> Any suggestions?
>>
>> Thanks!
>>
>> Dan
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 

-- 
Dr. T?th D?nes ?gyvezet?
Kogentum Kft.
Tel.: 06-30-2583723
Web: www.kogentum.hu


From drjimlemon at gmail.com  Fri Sep 29 00:22:28 2017
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 29 Sep 2017 08:22:28 +1000
Subject: [R] rename multiple files by file.rename or other functions
In-Reply-To: <CAJuCY5zdDkrgTEm1hhm8sHcyFZ0jWpkZhZ5NmOg2uHRhu4Bwow@mail.gmail.com>
References: <CABcx46Aj712=szdjCCWvgpm-6srRt4uRA8q3vYPvsHSNWSAAbw@mail.gmail.com>
 <CAJuCY5zdDkrgTEm1hhm8sHcyFZ0jWpkZhZ5NmOg2uHRhu4Bwow@mail.gmail.com>
Message-ID: <CA+8X3fWO756FjGyoAi9+fmx0+Qh+43PfXr54=JzFqAeqzShH=A@mail.gmail.com>

Hi John,
After a bit of thinking:

# fill in the appropriate path and pattern
filenames<-list.files(path=???,pattern=???)
for(filename in filenames) {
 filefirst<-sapply(strsplit(filename,"[.]"),"[",1)
 # delete all non-digits
 fileno<-gsub("[^[:digit:]]","",filefirst)
 file.rename(filename,paste("01Gen",fileno,".mp3",sep=""))
}

Jim


From kw.stat at gmail.com  Fri Sep 29 01:15:51 2017
From: kw.stat at gmail.com (Kevin Wright)
Date: Thu, 28 Sep 2017 18:15:51 -0500
Subject: [R] rgl crash on windows 7
Message-ID: <CAKFxdiR10tb6LqvuGo9p8e3uLLRcBOkWbn9_uXWxiUPrUXp3Mw@mail.gmail.com>

I have a co-worker who has installed R 3.4.2 on Windows 7.  When this
person tries to load the rgl package with
library(rgl)
A dialog box appears with the message:
R for windows gui frontend has stopped working

I suspect a conflict problem with a dll, but I'm not sure how to identify
if this is the problem since R is crashing immediately.

Interestingly, when we start R and do NOT load rgl, but type this WITHOUT
parentheses:
rgl:::.onUnload
We get the same crash.

On my laptop I can load rgl just fine, after loading rgl I see:

R> getLoadedDLLs()

 Filename Dynamic.Lookup
base
base          FALSE
methods       C:/Program
Files/R/R-3.4.1/library/methods/libs/x64/methods.dll          FALSE
utils             C:/Program
Files/R/R-3.4.1/library/utils/libs/x64/utils.dll          FALSE
digest
c:/kw/R/win-library/3.4/digest/libs/x64/digest.dll           TRUE
grDevices C:/Program
Files/R/R-3.4.1/library/grDevices/libs/x64/grDevices.dll          FALSE
graphics    C:/Program
Files/R/R-3.4.1/library/graphics/libs/x64/graphics.dll          FALSE
stats             C:/Program
Files/R/R-3.4.1/library/stats/libs/x64/stats.dll          FALSE
Rcpp
c:/kw/R/win-library/3.4/Rcpp/libs/x64/Rcpp.dll           TRUE
htmltools
 c:/kw/R/win-library/3.4/htmltools/libs/x64/htmltools.dll          FALSE
jsonlite
c:/kw/R/win-library/3.4/jsonlite/libs/x64/jsonlite.dll           TRUE
tools             C:/Program
Files/R/R-3.4.1/library/tools/libs/x64/tools.dll          FALSE
httpuv
c:/kw/R/win-library/3.4/httpuv/libs/x64/httpuv.dll           TRUE
mime
c:/kw/R/win-library/3.4/mime/libs/x64/mime.dll           TRUE
rgl
 c:/kw/R/win-library/3.4/rgl/libs/x64/rgl.dll          FALSE

Can I manually load the DLLs and then load rgl?

Any tips on how to proceed would be appreciated.

-- 
Kevin Wright

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Sep 29 01:50:39 2017
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 28 Sep 2017 19:50:39 -0400
Subject: [R] rgl crash on windows 7
In-Reply-To: <CAKFxdiR10tb6LqvuGo9p8e3uLLRcBOkWbn9_uXWxiUPrUXp3Mw@mail.gmail.com>
References: <CAKFxdiR10tb6LqvuGo9p8e3uLLRcBOkWbn9_uXWxiUPrUXp3Mw@mail.gmail.com>
Message-ID: <ab3c378e-03d0-35a4-3c6a-e149ff4977fc@gmail.com>

On 28/09/2017 7:15 PM, Kevin Wright wrote:
> 
> I have a co-worker who has installed R 3.4.2 on Windows 7.? When this 
> person tries to load the rgl package with
> library(rgl)
> A dialog box appears with the message:
> R for windows gui frontend has stopped working
> 
> I suspect a conflict problem with a dll, but I'm not sure how to 
> identify if this is the problem since R is crashing immediately.
> 
> Interestingly, when we start R and do NOT load rgl, but type this 
> WITHOUT parentheses:
> rgl:::.onUnload
> We get the same crash.

That will trigger a load of rgl, which will try to load the DLL.
> 
> On my laptop I can load rgl just fine, after loading rgl I see:
> 
> R> getLoadedDLLs()
>                                                                      
>  ?Filename Dynamic.Lookup
> base                                                                     
> base ? ? ? ? ?FALSE
> methods ? ? ? C:/Program 
> Files/R/R-3.4.1/library/methods/libs/x64/methods.dll ? ? ? ? ?FALSE
> utils ? ? ? ? ? ? C:/Program 
> Files/R/R-3.4.1/library/utils/libs/x64/utils.dll ? ? ? ? ?FALSE
> digest                     
> c:/kw/R/win-library/3.4/digest/libs/x64/digest.dll ? ? ? ? ? TRUE
> grDevices C:/Program 
> Files/R/R-3.4.1/library/grDevices/libs/x64/grDevices.dll ? ? ? ? ?FALSE
> graphics ? ?C:/Program 
> Files/R/R-3.4.1/library/graphics/libs/x64/graphics.dll ? ? ? ? ?FALSE
> stats ? ? ? ? ? ? C:/Program 
> Files/R/R-3.4.1/library/stats/libs/x64/stats.dll ? ? ? ? ?FALSE
> Rcpp                           
> c:/kw/R/win-library/3.4/Rcpp/libs/x64/Rcpp.dll ? ? ? ? ? TRUE
> htmltools           
>  ?c:/kw/R/win-library/3.4/htmltools/libs/x64/htmltools.dll ? ? ? ? ?FALSE
> jsonlite               
> c:/kw/R/win-library/3.4/jsonlite/libs/x64/jsonlite.dll ? ? ? ? ? TRUE
> tools ? ? ? ? ? ? C:/Program 
> Files/R/R-3.4.1/library/tools/libs/x64/tools.dll ? ? ? ? ?FALSE
> httpuv                     
> c:/kw/R/win-library/3.4/httpuv/libs/x64/httpuv.dll ? ? ? ? ? TRUE
> mime                           
> c:/kw/R/win-library/3.4/mime/libs/x64/mime.dll ? ? ? ? ? TRUE
> rgl                             
>  ?c:/kw/R/win-library/3.4/rgl/libs/x64/rgl.dll ? ? ? ? ?FALSE
> 
> Can I manually load the DLLs and then load rgl?
> 
> Any tips on how to proceed would be appreciated.


I don't have access to Windows 7, but just tried the new R 3.4.2 with 
Windows 10, and like you, had no problems.

I'd suggest running update.packages(checkBuilt = TRUE) to make sure 
everything is current.  If that doesn't fix the problem, you probably 
need to run Rgui under a debugger like gdb to identify what the issue is 
--- but that's not a trivial thing to do.

If you want to just make random changes hoping that something might 
help, updating the graphics driver (or disabling hardware acceleration 
if that's something that it can do) could make a difference.

Duncan Murdoch


From petr.pikal at precheza.cz  Fri Sep 29 08:18:02 2017
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 29 Sep 2017 06:18:02 +0000
Subject: [R] Need Help in Debugging
In-Reply-To: <CAPJo3pRWzpZkZiF9RG404yC=ACZCdN-wsbaohvdFphmmNYLCyw@mail.gmail.com>
References: <CAPJo3pRWzpZkZiF9RG404yC=ACZCdN-wsbaohvdFphmmNYLCyw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88FFAB1082@SRVEXCHCM301.precheza.cz>

Hi

I am just guessing, can it be that object runsum does not exist in your environment?

Try

ls()

to see all objects.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of istiyak
> ahamad
> Sent: Wednesday, September 27, 2017 11:34 PM
> To: r-help at r-project.org
> Subject: [R] Need Help in Debugging
>
> I am getting following error when running this script :------------Error in
> length(runsum) : object 'runsum' not found
>
>
> ##error function
> dat$fit <- NULL
> dat$fit[dat$majorlandmarks] <- dat$Close[dat$majorlandmarks] run <-
> rle(dat$majorlandmarks) runvalue <- run$values runsum <-
> cumsum(run$lengths) run <- run$lengths for(i in 1:(length(runsum)-1)){
>   if (runvalue[i]==FALSE){
>     left <- runsum[i-1]
>     right <- runsum[i+1]-(run[i+1]-1)
>
>     slope <- (dat$Close[dat$seq==right]-dat$Close[dat$seq==left])/(run[i]+1)
>     dat$fit[(left+1):(right-1)] <- seq(1:run[i])*slope+dat$Close[left]
>
>   }
> return(dat)
> }
>
> Error in length(runsum) : object 'runsum' not found
>
>
> Error in length(runsum) : object 'runsum' not found
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From andrewharmon42 at gmail.com  Fri Sep 29 14:47:37 2017
From: andrewharmon42 at gmail.com (Andrew Harmon)
Date: Fri, 29 Sep 2017 07:47:37 -0500
Subject: [R] Converting SAS Code
Message-ID: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>

Hello all,

My statistical analysis training up until this point has been entirely done
in SAS. The code I frequently used was:

*Yield Champagin;

data yield;

set stress;

if field='YV' then delete;

if field='HB' then delete;

if barcode='16187DD4015' then delete;

if barcode='16187DD6002' then delete;

if barcode='16187DD2007' then delete;

if barcode='16187DD5016' then delete;

if barcode='16187DD8007' then delete;

if barcode='16187DD7010' then delete;

if barcode='16187DD7007' then delete;

if barcode='16187DD8005' then delete;

if barcode='16187DD6004' then delete;

if barcode='16187DD5008' then delete;

if barcode='16187DD7012' then delete;

if barcode='16187DD6010' then delete;

run; quit;



Title'2016 Asilomar Stress Relief champagin yield';

proc mixed method=reml data=yield;

class rep Management Foliar_Fungicide Chemical_Treatment;

model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;

random rep rep*Management rep*Management*Foliar_Fungicide;

lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;

ods output diffs=ppp lsmeans=means;

ods listing exclude diffs lsmeans;

run; quit;

%include'C:\Users\harmon12\Desktop\pdmix800.sas';

%pdmix800(ppp,means,alpha=0.10,sort=yes);

ods graphics off;

run; quit;

proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
pearsonresid; var resid;
proc print data=resids (obs=3);run;

Can someone please help me convert my code to R? Any help would be much
appreciated.


Thanks,


Andrew Harmon

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Sep 29 15:51:02 2017
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 29 Sep 2017 14:51:02 +0100
Subject: [R] Converting SAS Code
In-Reply-To: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
Message-ID: <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>

You might get better answers if you

1 - break this down into separate issues
2 - tell us what you want to achieve in words rather than SAS, we all 
read English but few of us speak SAS
3 - post in plain text not HTML as HTML mangles your post

On 29/09/2017 13:47, Andrew Harmon wrote:
> Hello all,
> 
> My statistical analysis training up until this point has been entirely done
> in SAS. The code I frequently used was:
> 
> *Yield Champagin;
> 
> data yield;
> 
> set stress;
> 
> if field='YV' then delete;
> 
> if field='HB' then delete;
> 
> if barcode='16187DD4015' then delete;
> 
> if barcode='16187DD6002' then delete;
> 
> if barcode='16187DD2007' then delete;
> 
> if barcode='16187DD5016' then delete;
> 
> if barcode='16187DD8007' then delete;
> 
> if barcode='16187DD7010' then delete;
> 
> if barcode='16187DD7007' then delete;
> 
> if barcode='16187DD8005' then delete;
> 
> if barcode='16187DD6004' then delete;
> 
> if barcode='16187DD5008' then delete;
> 
> if barcode='16187DD7012' then delete;
> 
> if barcode='16187DD6010' then delete;
> 
> run; quit;
> 
> 
> 
> Title'2016 Asilomar Stress Relief champagin yield';
> 
> proc mixed method=reml data=yield;
> 
> class rep Management Foliar_Fungicide Chemical_Treatment;
> 
> model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
> 
> random rep rep*Management rep*Management*Foliar_Fungicide;
> 
> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
> 
> ods output diffs=ppp lsmeans=means;
> 
> ods listing exclude diffs lsmeans;
> 
> run; quit;
> 
> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
> 
> %pdmix800(ppp,means,alpha=0.10,sort=yes);
> 
> ods graphics off;
> 
> run; quit;
> 
> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
> pearsonresid; var resid;
> proc print data=resids (obs=3);run;
> 
> Can someone please help me convert my code to R? Any help would be much
> appreciated.
> 
> 
> Thanks,
> 
> 
> Andrew Harmon
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> http://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tobby at htu.at  Fri Sep 29 15:43:41 2017
From: tobby at htu.at (Tobias Fellinger)
Date: Fri, 29 Sep 2017 15:43:41 +0200
Subject: [R] Converting SAS Code
In-Reply-To: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
Message-ID: <1506692621.2690.19.camel@htu.at>

Hello, 

in my experience the most direct path of converting SAS code to R is by
using dplyr. dplyr provides the filter function, the first part of your
code could look like this, assuming your datasets are stored as
data.frames:

library(dplyr)

yield <- filter(stress,
  field != "YV",
  field != "HV",
  barcode != "16187DD4015",
  barcode != "16187DD6002")

(and so on for the other barcodes.)

For mixed effects look into the lme4 package, lmer should use the reml
criterion per default, the model specifications work very different in
R. Look into the vingette [1] of the lme4 package chapter 2.1. gives an
explanation of the used model formulas.

You should get the coeficients of the fitted glmer model with the coef
function. 

The Plots and univariate statistics work very different in R, have a
look at the functions group_by and summarise provided by the dplyr
package for calculating univariate statistics by groups, and the ggplot
2 package for plotting. 

Tobi

[1] https://cran.r-project.org/web/packages/lme4/vignettes/lmer.pdf


On Fri, 2017-09-29 at 07:47 -0500, Andrew Harmon wrote:
> Hello all,
> 
> My statistical analysis training up until this point has been entirely done
> in SAS. The code I frequently used was:
> 
> *Yield Champagin;
> 
> data yield;
> 
> set stress;
> 
> if field='YV' then delete;
> 
> if field='HB' then delete;
> 
> if barcode='16187DD4015' then delete;
> 
> if barcode='16187DD6002' then delete;
> 
> if barcode='16187DD2007' then delete;
> 
> if barcode='16187DD5016' then delete;
> 
> if barcode='16187DD8007' then delete;
> 
> if barcode='16187DD7010' then delete;
> 
> if barcode='16187DD7007' then delete;
> 
> if barcode='16187DD8005' then delete;
> 
> if barcode='16187DD6004' then delete;
> 
> if barcode='16187DD5008' then delete;
> 
> if barcode='16187DD7012' then delete;
> 
> if barcode='16187DD6010' then delete;
> 
> run; quit;
> 
> 
> 
> Title'2016 Asilomar Stress Relief champagin yield';
> 
> proc mixed method=reml data=yield;
> 
> class rep Management Foliar_Fungicide Chemical_Treatment;
> 
> model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
> 
> random rep rep*Management rep*Management*Foliar_Fungicide;
> 
> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
> 
> ods output diffs=ppp lsmeans=means;
> 
> ods listing exclude diffs lsmeans;
> 
> run; quit;
> 
> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
> 
> %pdmix800(ppp,means,alpha=0.10,sort=yes);
> 
> ods graphics off;
> 
> run; quit;
> 
> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
> pearsonresid; var resid;
> proc print data=resids (obs=3);run;
> 
> Can someone please help me convert my code to R? Any help would be much
> appreciated.
> 
> 
> Thanks,
> 
> 
> Andrew Harmon
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kevin.thorpe at utoronto.ca  Fri Sep 29 19:21:50 2017
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 29 Sep 2017 13:21:50 -0400
Subject: [R] Converting SAS Code
In-Reply-To: <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
Message-ID: <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>

Regarding point 3, as a moderator I have been helping Andrew get this 
post out to the list over the past week. His previous attempts were 
encoded in some way that the listserv rejected. He sent me the post via 
his gmail account and viewing the source I saw it had at least both 
plain test and HTML an I said it was worth a try to post it. Certainly 
on my mail client his post displays acceptably with the notice that the 
HTML alternative was removed.

Kevin

On 09/29/2017 09:51 AM, Michael Dewey wrote:
> You might get better answers if you
>
> 1 - break this down into separate issues
> 2 - tell us what you want to achieve in words rather than SAS, we all 
> read English but few of us speak SAS
> 3 - post in plain text not HTML as HTML mangles your post
>
> On 29/09/2017 13:47, Andrew Harmon wrote:
>> Hello all,
>>
>> My statistical analysis training up until this point has been 
>> entirely done
>> in SAS. The code I frequently used was:
>>
>> *Yield Champagin;
>>
>> data yield;
>>
>> set stress;
>>
>> if field='YV' then delete;
>>
>> if field='HB' then delete;
>>
>> if barcode='16187DD4015' then delete;
>>
>> if barcode='16187DD6002' then delete;
>>
>> if barcode='16187DD2007' then delete;
>>
>> if barcode='16187DD5016' then delete;
>>
>> if barcode='16187DD8007' then delete;
>>
>> if barcode='16187DD7010' then delete;
>>
>> if barcode='16187DD7007' then delete;
>>
>> if barcode='16187DD8005' then delete;
>>
>> if barcode='16187DD6004' then delete;
>>
>> if barcode='16187DD5008' then delete;
>>
>> if barcode='16187DD7012' then delete;
>>
>> if barcode='16187DD6010' then delete;
>>
>> run; quit;
>>
>>
>>
>> Title'2016 Asilomar Stress Relief champagin yield';
>>
>> proc mixed method=reml data=yield;
>>
>> class rep Management Foliar_Fungicide Chemical_Treatment;
>>
>> model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
>> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
>>
>> random rep rep*Management rep*Management*Foliar_Fungicide;
>>
>> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
>>
>> ods output diffs=ppp lsmeans=means;
>>
>> ods listing exclude diffs lsmeans;
>>
>> run; quit;
>>
>> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
>>
>> %pdmix800(ppp,means,alpha=0.10,sort=yes);
>>
>> ods graphics off;
>>
>> run; quit;
>>
>> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
>> pearsonresid; var resid;
>> proc print data=resids (obs=3);run;
>>
>> Can someone please help me convert my code to R? Any help would be much
>> appreciated.
>>
>>
>> Thanks,
>>
>>
>> Andrew Harmon
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ---
>> This email has been checked for viruses by AVG.
>> http://www.avg.com
>>
>>
>

-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From bgunter.4567 at gmail.com  Fri Sep 29 20:09:14 2017
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 29 Sep 2017 11:09:14 -0700
Subject: [R] Converting SAS Code
In-Reply-To: <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
Message-ID: <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>

I will offer an opinion, with which others may fairly take issue.

If you are coming from SAS and wish to learn R, you should forget about SAS
entirely; it is ancient and convoluted. But more to the point, as others
have already suggested, you will only confuse and hamstring yourself trying
to convert the programming paradigms of one language into another. Better
to consider the **tasks** you wish to accomplish and learn how to approach
them in the new language. I would add that this especially includes
learning about R's varied data structures for which there is no cognate in
SAS I think (correction requested if I'm wrong about this).

If this is a one-off, just finding a local resource to do the job for you
might be the best approach.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 29, 2017 at 10:21 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
wrote:

> Regarding point 3, as a moderator I have been helping Andrew get this post
> out to the list over the past week. His previous attempts were encoded in
> some way that the listserv rejected. He sent me the post via his gmail
> account and viewing the source I saw it had at least both plain test and
> HTML an I said it was worth a try to post it. Certainly on my mail client
> his post displays acceptably with the notice that the HTML alternative was
> removed.
>
> Kevin
>
> On 09/29/2017 09:51 AM, Michael Dewey wrote:
>
>> You might get better answers if you
>>
>> 1 - break this down into separate issues
>> 2 - tell us what you want to achieve in words rather than SAS, we all
>> read English but few of us speak SAS
>> 3 - post in plain text not HTML as HTML mangles your post
>>
>> On 29/09/2017 13:47, Andrew Harmon wrote:
>>
>>> Hello all,
>>>
>>> My statistical analysis training up until this point has been entirely
>>> done
>>> in SAS. The code I frequently used was:
>>>
>>> *Yield Champagin;
>>>
>>> data yield;
>>>
>>> set stress;
>>>
>>> if field='YV' then delete;
>>>
>>> if field='HB' then delete;
>>>
>>> if barcode='16187DD4015' then delete;
>>>
>>> if barcode='16187DD6002' then delete;
>>>
>>> if barcode='16187DD2007' then delete;
>>>
>>> if barcode='16187DD5016' then delete;
>>>
>>> if barcode='16187DD8007' then delete;
>>>
>>> if barcode='16187DD7010' then delete;
>>>
>>> if barcode='16187DD7007' then delete;
>>>
>>> if barcode='16187DD8005' then delete;
>>>
>>> if barcode='16187DD6004' then delete;
>>>
>>> if barcode='16187DD5008' then delete;
>>>
>>> if barcode='16187DD7012' then delete;
>>>
>>> if barcode='16187DD6010' then delete;
>>>
>>> run; quit;
>>>
>>>
>>>
>>> Title'2016 Asilomar Stress Relief champagin yield';
>>>
>>> proc mixed method=reml data=yield;
>>>
>>> class rep Management Foliar_Fungicide Chemical_Treatment;
>>>
>>> model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
>>> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
>>>
>>> random rep rep*Management rep*Management*Foliar_Fungicide;
>>>
>>> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
>>>
>>> ods output diffs=ppp lsmeans=means;
>>>
>>> ods listing exclude diffs lsmeans;
>>>
>>> run; quit;
>>>
>>> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
>>>
>>> %pdmix800(ppp,means,alpha=0.10,sort=yes);
>>>
>>> ods graphics off;
>>>
>>> run; quit;
>>>
>>> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
>>> pearsonresid; var resid;
>>> proc print data=resids (obs=3);run;
>>>
>>> Can someone please help me convert my code to R? Any help would be much
>>> appreciated.
>>>
>>>
>>> Thanks,
>>>
>>>
>>> Andrew Harmon
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ---
>>> This email has been checked for viruses by AVG.
>>> http://www.avg.com
>>>
>>>
>>>
>>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From JLucke at ria.buffalo.edu  Fri Sep 29 20:45:49 2017
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Fri, 29 Sep 2017 14:45:49 -0400
Subject: [R] Converting SAS Code
In-Reply-To: <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
Message-ID: <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>

I wish to second this approach to learning R. 

I tried for several years to translate other stat programs  or provide 
parallel analyses with R. 
This dabbling-in-R approach did not work
. 
When a transferred to a research unit  that could ill afford commercial 
software, I devoted my entire time to doing everything in R. 
This was a difficult learning process, but I eventually became proficient 
in R. 

The conceptual paradigm for R is only marginally commensurate with that of 
standard statistical software. 
You must immerse yourself in R to become proficient. 

Good luck,
Joe
 


Bert Gunter <bgunter.4567 at gmail.com> 
Sent by: "R-help" <r-help-bounces at r-project.org>
09/29/2017 02:09 PM

To
"Kevin E. Thorpe" <kevin.thorpe at utoronto.ca>, 
cc
R-help <r-help at r-project.org>, Andrew Harmon <andrewharmon42 at gmail.com>
Subject
Re: [R] Converting SAS Code






I will offer an opinion, with which others may fairly take issue.

If you are coming from SAS and wish to learn R, you should forget about 
SAS
entirely; it is ancient and convoluted. But more to the point, as others
have already suggested, you will only confuse and hamstring yourself 
trying
to convert the programming paradigms of one language into another. Better
to consider the **tasks** you wish to accomplish and learn how to approach
them in the new language. I would add that this especially includes
learning about R's varied data structures for which there is no cognate in
SAS I think (correction requested if I'm wrong about this).

If this is a one-off, just finding a local resource to do the job for you
might be the best approach.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Sep 29, 2017 at 10:21 AM, Kevin E. Thorpe 
<kevin.thorpe at utoronto.ca>
wrote:

> Regarding point 3, as a moderator I have been helping Andrew get this 
post
> out to the list over the past week. His previous attempts were encoded 
in
> some way that the listserv rejected. He sent me the post via his gmail
> account and viewing the source I saw it had at least both plain test and
> HTML an I said it was worth a try to post it. Certainly on my mail 
client
> his post displays acceptably with the notice that the HTML alternative 
was
> removed.
>
> Kevin
>
> On 09/29/2017 09:51 AM, Michael Dewey wrote:
>
>> You might get better answers if you
>>
>> 1 - break this down into separate issues
>> 2 - tell us what you want to achieve in words rather than SAS, we all
>> read English but few of us speak SAS
>> 3 - post in plain text not HTML as HTML mangles your post
>>
>> On 29/09/2017 13:47, Andrew Harmon wrote:
>>
>>> Hello all,
>>>
>>> My statistical analysis training up until this point has been entirely
>>> done
>>> in SAS. The code I frequently used was:
>>>
>>> *Yield Champagin;
>>>
>>> data yield;
>>>
>>> set stress;
>>>
>>> if field='YV' then delete;
>>>
>>> if field='HB' then delete;
>>>
>>> if barcode='16187DD4015' then delete;
>>>
>>> if barcode='16187DD6002' then delete;
>>>
>>> if barcode='16187DD2007' then delete;
>>>
>>> if barcode='16187DD5016' then delete;
>>>
>>> if barcode='16187DD8007' then delete;
>>>
>>> if barcode='16187DD7010' then delete;
>>>
>>> if barcode='16187DD7007' then delete;
>>>
>>> if barcode='16187DD8005' then delete;
>>>
>>> if barcode='16187DD6004' then delete;
>>>
>>> if barcode='16187DD5008' then delete;
>>>
>>> if barcode='16187DD7012' then delete;
>>>
>>> if barcode='16187DD6010' then delete;
>>>
>>> run; quit;
>>>
>>>
>>>
>>> Title'2016 Asilomar Stress Relief champagin yield';
>>>
>>> proc mixed method=reml data=yield;
>>>
>>> class rep Management Foliar_Fungicide Chemical_Treatment;
>>>
>>> model Grain_Yield__Mg_h_ 
=Management|Foliar_Fungicide|Chemical_Treatment
>>> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
>>>
>>> random rep rep*Management rep*Management*Foliar_Fungicide;
>>>
>>> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
>>>
>>> ods output diffs=ppp lsmeans=means;
>>>
>>> ods listing exclude diffs lsmeans;
>>>
>>> run; quit;
>>>
>>> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
>>>
>>> %pdmix800(ppp,means,alpha=0.10,sort=yes);
>>>
>>> ods graphics off;
>>>
>>> run; quit;
>>>
>>> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
>>> pearsonresid; var resid;
>>> proc print data=resids (obs=3);run;
>>>
>>> Can someone please help me convert my code to R? Any help would be 
much
>>> appreciated.
>>>
>>>
>>> Thanks,
>>>
>>>
>>> Andrew Harmon
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ---
>>> This email has been checked for viruses by AVG.
>>> http://www.avg.com
>>>
>>>
>>>
>>
> --
> Kevin E. Thorpe
> Head of Biostatistics,  Applied Health Research Centre (AHRC)
> Li Ka Shing Knowledge Institute of St. Michael's Hospital
> Assistant Professor, Dalla Lana School of Public Health
> University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

                 [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Sep 29 20:51:42 2017
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 29 Sep 2017 11:51:42 -0700
Subject: [R] Converting SAS Code
In-Reply-To: <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
Message-ID: <42ED50E9-6A9B-4FB0-B879-0AEEFE0D84A7@dcn.davis.ca.us>

All HTML emails have a plain text part along with the HTML part... but it is usually invisible to the author and is automatically generated by the email composing software and some software is better than others at that job (by a lot). However, without a doubt, sending the email in text form at least means the sender saw the plain text part before it was sent, which removes a potentially huge barrier to communication.  And GMail definitely can send plain text. 
-- 
Sent from my phone. Please excuse my brevity.

On September 29, 2017 10:21:50 AM PDT, "Kevin E. Thorpe" <kevin.thorpe at utoronto.ca> wrote:
>Regarding point 3, as a moderator I have been helping Andrew get this 
>post out to the list over the past week. His previous attempts were 
>encoded in some way that the listserv rejected. He sent me the post via
>
>his gmail account and viewing the source I saw it had at least both 
>plain test and HTML an I said it was worth a try to post it. Certainly 
>on my mail client his post displays acceptably with the notice that the
>
>HTML alternative was removed.
>
>Kevin
>
>On 09/29/2017 09:51 AM, Michael Dewey wrote:
>> You might get better answers if you
>>
>> 1 - break this down into separate issues
>> 2 - tell us what you want to achieve in words rather than SAS, we all
>
>> read English but few of us speak SAS
>> 3 - post in plain text not HTML as HTML mangles your post
>>
>> On 29/09/2017 13:47, Andrew Harmon wrote:
>>> Hello all,
>>>
>>> My statistical analysis training up until this point has been 
>>> entirely done
>>> in SAS. The code I frequently used was:
>>>
>>> *Yield Champagin;
>>>
>>> data yield;
>>>
>>> set stress;
>>>
>>> if field='YV' then delete;
>>>
>>> if field='HB' then delete;
>>>
>>> if barcode='16187DD4015' then delete;
>>>
>>> if barcode='16187DD6002' then delete;
>>>
>>> if barcode='16187DD2007' then delete;
>>>
>>> if barcode='16187DD5016' then delete;
>>>
>>> if barcode='16187DD8007' then delete;
>>>
>>> if barcode='16187DD7010' then delete;
>>>
>>> if barcode='16187DD7007' then delete;
>>>
>>> if barcode='16187DD8005' then delete;
>>>
>>> if barcode='16187DD6004' then delete;
>>>
>>> if barcode='16187DD5008' then delete;
>>>
>>> if barcode='16187DD7012' then delete;
>>>
>>> if barcode='16187DD6010' then delete;
>>>
>>> run; quit;
>>>
>>>
>>>
>>> Title'2016 Asilomar Stress Relief champagin yield';
>>>
>>> proc mixed method=reml data=yield;
>>>
>>> class rep Management Foliar_Fungicide Chemical_Treatment;
>>>
>>> model Grain_Yield__Mg_h_
>=Management|Foliar_Fungicide|Chemical_Treatment
>>> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
>>>
>>> random rep rep*Management rep*Management*Foliar_Fungicide;
>>>
>>> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
>>>
>>> ods output diffs=ppp lsmeans=means;
>>>
>>> ods listing exclude diffs lsmeans;
>>>
>>> run; quit;
>>>
>>> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
>>>
>>> %pdmix800(ppp,means,alpha=0.10,sort=yes);
>>>
>>> ods graphics off;
>>>
>>> run; quit;
>>>
>>> proc univariate data=resids normal plot; id Barcode
>Grain_Yield__Mg_h_
>>> pearsonresid; var resid;
>>> proc print data=resids (obs=3);run;
>>>
>>> Can someone please help me convert my code to R? Any help would be
>much
>>> appreciated.
>>>
>>>
>>> Thanks,
>>>
>>>
>>> Andrew Harmon
>>>
>>> ????[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ---
>>> This email has been checked for viruses by AVG.
>>> http://www.avg.com
>>>
>>>
>>
>
>-- 
>Kevin E. Thorpe
>Head of Biostatistics,  Applied Health Research Centre (AHRC)
>Li Ka Shing Knowledge Institute of St. Michael's Hospital
>Assistant Professor, Dalla Lana School of Public Health
>University of Toronto
>email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Sep 29 21:39:45 2017
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 29 Sep 2017 15:39:45 -0400
Subject: [R] Converting SAS Code
In-Reply-To: <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
Message-ID: <6580D55A-3B62-4411-99CD-3F68AEA54478@me.com>

Hi,

I would echo Bert's comments below.

The last thing that you want to try to do is to convert SAS code to R code on a "line for line" basis. The programming paradigm of R, which is built upon vectorized operations, takes a "whole object" approach for efficiency. SAS does not, since it is generally based upon 1970's era, main frame style, programming techniques using macros, etc.

If this is not a one off and something that you might find yourself doing with some frequency, you might consider investing in Bob Muenchen's book, R for SAS and SPSS Users:

  https://www.amazon.com/gp/product/1461406846/ <https://www.amazon.com/gp/product/1461406846/>

While it is now a few years old, it is still relevant in terms of pointing you in the direction of basic and conceptual linkages between the languages.

Regards,

Marc Schwartz


> On Sep 29, 2017, at 2:09 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I will offer an opinion, with which others may fairly take issue.
> 
> If you are coming from SAS and wish to learn R, you should forget about SAS
> entirely; it is ancient and convoluted. But more to the point, as others
> have already suggested, you will only confuse and hamstring yourself trying
> to convert the programming paradigms of one language into another. Better
> to consider the **tasks** you wish to accomplish and learn how to approach
> them in the new language. I would add that this especially includes
> learning about R's varied data structures for which there is no cognate in
> SAS I think (correction requested if I'm wrong about this).
> 
> If this is a one-off, just finding a local resource to do the job for you
> might be the best approach.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Fri, Sep 29, 2017 at 10:21 AM, Kevin E. Thorpe <kevin.thorpe at utoronto.ca>
> wrote:
> 
>> Regarding point 3, as a moderator I have been helping Andrew get this post
>> out to the list over the past week. His previous attempts were encoded in
>> some way that the listserv rejected. He sent me the post via his gmail
>> account and viewing the source I saw it had at least both plain test and
>> HTML an I said it was worth a try to post it. Certainly on my mail client
>> his post displays acceptably with the notice that the HTML alternative was
>> removed.
>> 
>> Kevin
>> 
>> On 09/29/2017 09:51 AM, Michael Dewey wrote:
>> 
>>> You might get better answers if you
>>> 
>>> 1 - break this down into separate issues
>>> 2 - tell us what you want to achieve in words rather than SAS, we all
>>> read English but few of us speak SAS
>>> 3 - post in plain text not HTML as HTML mangles your post
>>> 
>>> On 29/09/2017 13:47, Andrew Harmon wrote:
>>> 
>>>> Hello all,
>>>> 
>>>> My statistical analysis training up until this point has been entirely
>>>> done
>>>> in SAS. The code I frequently used was:
>>>> 
>>>> *Yield Champagin;
>>>> 
>>>> data yield;
>>>> 
>>>> set stress;
>>>> 
>>>> if field='YV' then delete;
>>>> 
>>>> if field='HB' then delete;
>>>> 
>>>> if barcode='16187DD4015' then delete;
>>>> 
>>>> if barcode='16187DD6002' then delete;
>>>> 
>>>> if barcode='16187DD2007' then delete;
>>>> 
>>>> if barcode='16187DD5016' then delete;
>>>> 
>>>> if barcode='16187DD8007' then delete;
>>>> 
>>>> if barcode='16187DD7010' then delete;
>>>> 
>>>> if barcode='16187DD7007' then delete;
>>>> 
>>>> if barcode='16187DD8005' then delete;
>>>> 
>>>> if barcode='16187DD6004' then delete;
>>>> 
>>>> if barcode='16187DD5008' then delete;
>>>> 
>>>> if barcode='16187DD7012' then delete;
>>>> 
>>>> if barcode='16187DD6010' then delete;
>>>> 
>>>> run; quit;
>>>> 
>>>> 
>>>> 
>>>> Title'2016 Asilomar Stress Relief champagin yield';
>>>> 
>>>> proc mixed method=reml data=yield;
>>>> 
>>>> class rep Management Foliar_Fungicide Chemical_Treatment;
>>>> 
>>>> model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
>>>> Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
>>>> 
>>>> random rep rep*Management rep*Management*Foliar_Fungicide;
>>>> 
>>>> lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
>>>> 
>>>> ods output diffs=ppp lsmeans=means;
>>>> 
>>>> ods listing exclude diffs lsmeans;
>>>> 
>>>> run; quit;
>>>> 
>>>> %include'C:\Users\harmon12\Desktop\pdmix800.sas';
>>>> 
>>>> %pdmix800(ppp,means,alpha=0.10,sort=yes);
>>>> 
>>>> ods graphics off;
>>>> 
>>>> run; quit;
>>>> 
>>>> proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
>>>> pearsonresid; var resid;
>>>> proc print data=resids (obs=3);run;
>>>> 
>>>> Can someone please help me convert my code to R? Any help would be much
>>>> appreciated.
>>>> 
>>>> 
>>>> Thanks,
>>>> 
>>>> 
>>>> Andrew Harmon
>>>> 
>>>>    [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From cb.terwee at vumc.nl  Fri Sep 29 20:56:44 2017
From: cb.terwee at vumc.nl (Terwee, CB)
Date: Fri, 29 Sep 2017 18:56:44 +0000
Subject: [R] Error in Lordif: slope is missing or negative
Message-ID: <0748D9E1E5B5D04DBB0A8E34A1019BF2011359524D@sp-mx-mbx2>

Hi all

I am not an experienced user of R.
I am trying to perform DIF analysis using Lordif and I get the follow error:

> GroupDIF <- lordif(resp.data=Resp, group=Group, criterion="R2", pseudo.R2="McFadden", R2.change=0.02)
Iteration: 500, Log-Lik: -137340.437, Max-Change: 0.00119
EM cycles terminated after 500 iterations.
 (mirt) | Iteration: 1, 14 items flagged for DIF (22,25,34,60,64,71,73,75,81,82,83,86,94,95)
Iteration: 500, Log-Lik: -131933.514, Max-Change: 0.00033
EM cycles terminated after 500 iterations.
ERROR: The following items had negative slope parameters.
87,89,91,93,95,99ERROR: The following items had negative slope parameters (87,89,91,93,95,99).

Error in probgrm(theta, DISC[i], CB[i, ]) : slope is missing or negative

Does anlyone knows what the poblem might be? Any help is appreciated!

Best regards
Caroline




	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Sep 29 22:37:00 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 30 Sep 2017 09:37:00 +1300
Subject: [R] Converting SAS Code
In-Reply-To: <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
 <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>
Message-ID: <e63c816a-d27a-6ecd-29e6-ea79d7fa34b3@auckland.ac.nz>

On 30/09/17 07:45, JLucke at ria.buffalo.edu wrote:

<SNIP>

> 
> The conceptual paradigm for R is only marginally commensurate with that of
> standard statistical software.
> You must immerse yourself in R to become proficient.

Fortune nomination.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From macqueen1 at llnl.gov  Fri Sep 29 22:43:52 2017
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 29 Sep 2017 20:43:52 +0000
Subject: [R] Converting SAS Code
In-Reply-To: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
Message-ID: <469F9E30-3203-4D35-823E-C9B6F7EA8367@llnl.gov>

For the initial data step, assuming a data frame named stress already exists, and using base R, you can start with something like this:

barcodes.to.delete <- c('16187DD4015', '16187DD6002',   {complete the comma-delimited vector of barcodes you don't want}  )

yield <- subset(stress,  !(barcode %in% barcodes.to.delete) )
yield <- subset(yield , !(field %in% c('YY','HB') )

## the above three lines could be done in a single line, but it would be long, ugly, hard to read, and hard to validate.
## easier to split it into a few steps

## another way, still using base R, and with a different syntax for the subsetting
records.to.drop <- stress$barcode %in% barcodes.to.delete | stress$yield %in% c('YY', 'HB')
yield <- stress[ !records.to.drop , ]

I think these are examples of doing it "the R way", not thinking in terms of directly translating SAS code to R code.

I used to use SAS a lot, but I don't know what the line
  *Yield Champagin;
does.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

On 9/29/17, 5:47 AM, "R-help on behalf of Andrew Harmon" <r-help-bounces at r-project.org on behalf of andrewharmon42 at gmail.com> wrote:

    Hello all,
    
    My statistical analysis training up until this point has been entirely done
    in SAS. The code I frequently used was:
    
    *Yield Champagin;
    
    data yield;
    
    set stress;
    
    if field='YV' then delete;
    
    if field='HB' then delete;
    
    if barcode='16187DD4015' then delete;
    
    if barcode='16187DD6002' then delete;
    
    if barcode='16187DD2007' then delete;
    
    if barcode='16187DD5016' then delete;
    
    if barcode='16187DD8007' then delete;
    
    if barcode='16187DD7010' then delete;
    
    if barcode='16187DD7007' then delete;
    
    if barcode='16187DD8005' then delete;
    
    if barcode='16187DD6004' then delete;
    
    if barcode='16187DD5008' then delete;
    
    if barcode='16187DD7012' then delete;
    
    if barcode='16187DD6010' then delete;
    
    run; quit;
    
    
    
    Title'2016 Asilomar Stress Relief champagin yield';
    
    proc mixed method=reml data=yield;
    
    class rep Management Foliar_Fungicide Chemical_Treatment;
    
    model Grain_Yield__Mg_h_ =Management|Foliar_Fungicide|Chemical_Treatment
    Final_Stand__Plants_A_ / outpred=resids residual ddfm=kr;
    
    random rep rep*Management rep*Management*Foliar_Fungicide;
    
    lsmeans Management|Foliar_Fungicide|Chemical_Treatment / pdiff;
    
    ods output diffs=ppp lsmeans=means;
    
    ods listing exclude diffs lsmeans;
    
    run; quit;
    
    %include'C:\Users\harmon12\Desktop\pdmix800.sas';
    
    %pdmix800(ppp,means,alpha=0.10,sort=yes);
    
    ods graphics off;
    
    run; quit;
    
    proc univariate data=resids normal plot; id Barcode Grain_Yield__Mg_h_
    pearsonresid; var resid;
    proc print data=resids (obs=3);run;
    
    Can someone please help me convert my code to R? Any help would be much
    appreciated.
    
    
    Thanks,
    
    
    Andrew Harmon
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From pdalgd at gmail.com  Fri Sep 29 23:32:15 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 29 Sep 2017 23:32:15 +0200
Subject: [R] Converting SAS Code
In-Reply-To: <469F9E30-3203-4D35-823E-C9B6F7EA8367@llnl.gov>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <469F9E30-3203-4D35-823E-C9B6F7EA8367@llnl.gov>
Message-ID: <6605F6C6-D9D3-464F-A680-CD78366F3C74@gmail.com>


> On 29 Sep 2017, at 22:43 , MacQueen, Don <macqueen1 at llnl.gov> wrote:
> 
> I used to use SAS a lot, but I don't know what the line
>  *Yield Champagin;
> does.

Nothing. It's a comment...

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.langfelder at gmail.com  Fri Sep 29 23:47:21 2017
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 29 Sep 2017 14:47:21 -0700
Subject: [R] Converting SAS Code
In-Reply-To: <6605F6C6-D9D3-464F-A680-CD78366F3C74@gmail.com>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <469F9E30-3203-4D35-823E-C9B6F7EA8367@llnl.gov>
 <6605F6C6-D9D3-464F-A680-CD78366F3C74@gmail.com>
Message-ID: <CA+hbrhUpmbSwwAYoN3pu8A2diHfVauXXgdGT+j=+ZaY0z+iAyQ@mail.gmail.com>

On Fri, Sep 29, 2017 at 2:32 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 29 Sep 2017, at 22:43 , MacQueen, Don <macqueen1 at llnl.gov> wrote:
>>
>> I used to use SAS a lot, but I don't know what the line
>>  *Yield Champagin;
>> does.
>
> Nothing. It's a comment...

Fortune nomination!

Peter


From rbaer at atsu.edu  Sat Sep 30 14:22:14 2017
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 30 Sep 2017 07:22:14 -0500
Subject: [R] Converting SAS Code
In-Reply-To: <e63c816a-d27a-6ecd-29e6-ea79d7fa34b3@auckland.ac.nz>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
 <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>
 <e63c816a-d27a-6ecd-29e6-ea79d7fa34b3@auckland.ac.nz>
Message-ID: <598ed67a-d3c0-5cb3-e242-bc04948919eb@atsu.edu>



On 9/29/2017 3:37 PM, Rolf Turner wrote:
> On 30/09/17 07:45, JLucke at ria.buffalo.edu wrote:
>
> <SNIP>
>
>>
>> The conceptual paradigm for R is only marginally commensurate with 
>> that of
>> standard statistical software.
>> You must immerse yourself in R to become proficient.
>
> Fortune nomination.
For newer list members wondering what Rolf is talking about try:

library(fortunes) fortune() to get a flavor! There are many pearls of 
wisdom.


>
> cheers,
>
> Rolf
>


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Sep 30 15:54:12 2017
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 30 Sep 2017 15:54:12 +0200
Subject: [R] Converting SAS Code
In-Reply-To: <598ed67a-d3c0-5cb3-e242-bc04948919eb@atsu.edu>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
 <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>
 <e63c816a-d27a-6ecd-29e6-ea79d7fa34b3@auckland.ac.nz>
 <598ed67a-d3c0-5cb3-e242-bc04948919eb@atsu.edu>
Message-ID: <89F13DAC-95BB-4D81-B1B1-B511B25A529D@gmail.com>


> On 30 Sep 2017, at 14:22 , Robert Baer <rbaer at atsu.edu> wrote:
> 
> 
> 
> On 9/29/2017 3:37 PM, Rolf Turner wrote:
>> On 30/09/17 07:45, JLucke at ria.buffalo.edu wrote:
>> 
>> <SNIP>
>> 
>>> 
>>> The conceptual paradigm for R is only marginally commensurate with 
>>> that of
>>> standard statistical software.
>>> You must immerse yourself in R to become proficient.
>> 
>> Fortune nomination.
> For newer list members wondering what Rolf is talking about try:
> 
> library(fortunes) fortune() to get a flavor! There are many pearls of 
> wisdom.
> 

Also, to get roughly back on topic, try

fortune("SAS")

several times, or more quickly

fortune("reverse the procedure")
fortune("Poalis")

-pd

> 
>> 
>> cheers,
>> 
>> Rolf
>> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r.turner at auckland.ac.nz  Sat Sep 30 22:57:02 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 1 Oct 2017 09:57:02 +1300
Subject: [R] Converting SAS Code
In-Reply-To: <598ed67a-d3c0-5cb3-e242-bc04948919eb@atsu.edu>
References: <CAB4=Ug=V22G+J2bgEwf0Cd0LnKnb2DKCa5K47=sdk5eE8jtZgw@mail.gmail.com>
 <872874c5-21e4-47f0-5627-96f1a3c129cc@dewey.myzen.co.uk>
 <e529f831-92b1-5cf4-8d33-ba41da80f173@utoronto.ca>
 <CAGxFJbTa_4jCdhNVZ1SP3W_N_5Pgx_e6VUc7bWxiND_zGeXp2Q@mail.gmail.com>
 <OF3C6E5C21.F89996C3-ON852581AA.0066237F-852581AA.006711B9@ria.buffalo.edu>
 <e63c816a-d27a-6ecd-29e6-ea79d7fa34b3@auckland.ac.nz>
 <598ed67a-d3c0-5cb3-e242-bc04948919eb@atsu.edu>
Message-ID: <6ae9e890-dfe0-5028-a956-0e1d8ea0eab9@auckland.ac.nz>

On 01/10/17 01:22, Robert Baer wrote:
> 
> 
> On 9/29/2017 3:37 PM, Rolf Turner wrote:
>> On 30/09/17 07:45, JLucke at ria.buffalo.edu wrote:
>>
>> <SNIP>
>>
>>>
>>> The conceptual paradigm for R is only marginally commensurate with 
>>> that of
>>> standard statistical software.
>>> You must immerse yourself in R to become proficient.
>>
>> Fortune nomination.
> For newer list members wondering what Rolf is talking about try:
> 
> library(fortunes) fortune() to get a flavor! There are many pearls of 
> wisdom.

For the *really* new members, note that you may have to *install* the 
fortunes package first:

 > install.packages("fortunes",lib=<wherever you keep added-on packages>)

Note that the package is "fortunes" (with an "s") but the function is
fortune() (no "s").

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From amrrs.data at gmail.com  Fri Sep 29 19:12:44 2017
From: amrrs.data at gmail.com (AMR RS)
Date: Fri, 29 Sep 2017 22:42:44 +0530
Subject: [R] [R-pkgs] 'coinmarketcapr' R Package to access coinmarketcap API
In-Reply-To: <CAE6U0BYLyEtNVnTNkZtbT2cVLy6zLhdmQm2M27WLCS8wxwfTWg@mail.gmail.com>
References: <CAE6U0BYLyEtNVnTNkZtbT2cVLy6zLhdmQm2M27WLCS8wxwfTWg@mail.gmail.com>
Message-ID: <CAE6U0BbbKWm4aDiPiZWDdCtGZCvDutStSfyjTu4=4kXsq=Fi6A@mail.gmail.com>

Hello Rusers, 'coinmarketcapr' R Package to extract bitcoin and other
cryptocurrencies market cap and prices from coinmarketcap API.

Welcoming Suggestions and Contributions!

https://github.com/amrrs/coinmarketcapr

https://cran.r-project.org/package=coinmarketcapr

Thanks and Regards,
Abdul

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


