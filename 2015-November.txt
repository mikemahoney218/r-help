From drjimlemon at gmail.com  Sun Nov  1 00:45:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 1 Nov 2015 10:45:43 +1100
Subject: [R] If else
In-Reply-To: <56353A87.706@gmail.com>
References: <XFMail.20151031193001.Ted.Harding@wlandres.net>
	<56353A87.706@gmail.com>
Message-ID: <CA+8X3fWg3WB-gJbcFrvEBVMn-JEzRt+BySHQCh4Mm7X3f4M9Fw@mail.gmail.com>

Having had to face this problem myself more than once, I sympathize with
Ted's argument. First let me confess that I regard sex as a measure of the
reproductive phenotype. Given the ongoing experimentation with both sex and
gender, I have had to add "U" (Unstated - includes all those acronyms that
can be mistaken for gamma hydroxy butyrate) to "M" and "F" in a dataset or
two.

Even worse is the crap shoot of sex chromosomes. While XYY is not much of a
problem at all, Turner's Syndrome (XO) is neither female (although they
appear to be) nor male. Given a reasonably large sample (the dream of
some), nature usually provides a few permutations that, while we know what
they are, don't really fit comfortably in either "M" or "F".

Jim


On Sun, Nov 1, 2015 at 9:02 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 31/10/2015 3:47 PM, (Ted Harding) wrote:
> > [Apologies if the message below should arrive twice. When first
> > sent there was apparently something wrong with the email address
> > to r-help, and it was held for moderation because "Message has
> > implicit destination" (whatever that means). I have made sure
> > that this time the email address is correct.]
> >
> > John Fox has given a neat expression to achieve the desired result!
> >
> > I would like to comment, however, on the somewhat insistent criticism
> > of Val's request from several people.
> >
> > It can make sense to have three "sex"es. Suppose, for example,
> > that the data are records of street crime reported by victims.
> > The victim may be able to identify the sex of the preprator
> > as definitely "M", or definitely "F". One of the aims of the
> > analysis is to investgate whether there is an association
> > between the gender of the offender and the type of crime.
> >
> > But in some cases the victim may not have been able to recognise
> > the offender's sex. Then it would have to go in the record as "NA"
> > (or equivalent). There can be two kinds of reason why the victim
> > was unable to recognise the sex. One kind is where the victim
> > simply did not see the offender (e.g. their purse was stolen
> > while they were concentrating on something else, and they only
> > found out later). Another kind is where the offender deliberately
> > disguises their gender, so that it cannot be determined from their
> > appearance. This second kind could be associated with a particular
> > category of crime (and I leave it to people's lurid imaginations
> > to think of possible examples ... ).
>
> I'm not convinced by your example.  I'm quite happy to say that the sex
> is M or F or unobserved, but unobserved is not a third sex, under that
> model it just means "M or F but I don't know which".  It is an
> incomplete observation, it's not a third sex.
>
> I can imagine 3 sexes in a case of multiple individuals:  "all M", "all
> F", "mixed".
>
> I can also imagine more complicated definitions of "sex" that include
> more than 2 categories, but I think that's not what we're talking about
> here.
>
> >
> > Then one indeed has three "sex"es: Male, Female, and Indeterminate,
> > for each of which there is a potential assoctiation with type of crime.
> > With most analyses, however, a category of "NA" would be ignored
> > (at least by R).
>
> That claim is nonsense.  R never ignores *anything* unless the analyst
> tells it to.  The analyst may choose to ignore something, but don't
> blame R if the analyst makes a bad decision.
>
> Duncan Murdoch
>
>
> > And then one has a variable which is a factor with 3 levels, all
> > of which can (as above) be meaningful), and "NA" would not be
> > ignored.
> >
> > Hoping this helps to clarify! (And, Val, does the above somehow
> > correspond to your objectives).
> >
> > Best wishes to all,
> > Ted.
> >
> > On 31-Oct-2015 17:41:02 Jeff Newmiller wrote:
> >> Rolf gave you two ways. There are others. They all misrepresent the data
> >> (there are only two sexes but you are effectively acting as if there are
> >> three); hence the inquisition in hopes of diverting you to a more
> correct
> >> method of analysis. However, this is not the support forum for whatever
> other
> >> software you plan to proceed with so never mind.
> >>
> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >>                                       Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >>
> ---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On October 31, 2015 10:15:33 AM PDT, Val <valkremk at gmail.com> wrote:
> >>> Hi Jeff,
> >>>
> >>> I thought I answered. Yes I was not clear about it.  The further
> >>> analysis
> >>> will no  be done by R.  It is another software that will not accept a
> >>> character response variable.
> >>>
> >>> Why R is so complicated to do that.  If it is SAS then I can do it on
> >>> one
> >>> statement. .
> >>>
> >>>
> >>> On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
> >>> <jdnewmil at dcn.davis.ca.us>
> >>> wrote:
> >>>
> >>>> You haven't actually answered John's question as to the type of
> >>> analysis
> >>>> you plan to do. It still looks from here like you should be using
> >>> factor
> >>>> data rather than numeric, but since you are not being clear we cannot
> >>> give
> >>>> specifics as to how to proceed.
> >>>>
> >>>
> ---------------------------------------------------------------------------
> >>>> Jeff Newmiller                        The     .....       .....  Go
> >>> Live...
> >>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>>> Go...
> >>>>                                       Live:   OO#.. Dead: OO#..
> >>> Playing
> >>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>> rocks...1k
> >>>>
> >>>
> ---------------------------------------------------------------------------
> >>>> Sent from my phone. Please excuse my brevity.
> >>>>
> >>>> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
> >>>>> Hi All,
> >>>>>
> >>>>>
> >>>>> Yes I need  to change to numeric  because I am preparing a data set
> >>>>> for
> >>>>> further  analysis. The variable to be changed  from character to
> >>>>> numeric
> >>>>> (in this case, sex) will be a response variable.  Some records have
> >>>>> missing
> >>>>> observation on sex and it is blank.
> >>>>>     id  sex
> >>>>>      1
> >>>>>      2
> >>>>>      3  M
> >>>>>      4  F
> >>>>>      5  M
> >>>>>      6  F
> >>>>>      7  F
> >>>>>
> >>>>> I am reading the data like this
> >>>>>
> >>>>> mydata <- read.csv(header=TRUE, text=', sep=", ")
> >>>>>     id  sex
> >>>>>      1   NA
> >>>>>      2  NA
> >>>>>      3  M
> >>>>>      4  F
> >>>>>      5  M
> >>>>>      6  F
> >>>>>      7  F
> >>>>>
> >>>>> The  data set is huge   (>250,000)
> >>>>>
> >>>>>
> >>>>> I want the output like this
> >>>>>
> >>>>>     id  sex    sex1
> >>>>>      1   NA    0
> >>>>>      2  NA     0
> >>>>>      3  M       1
> >>>>>      4  F       2
> >>>>>      5  M      1
> >>>>>      6  F       2
> >>>>>      7  F       2
> >>>>>
> >>>>> Thank you in advance
> >>>>>
> >>>>>
> >>>>> On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
> >>> wrote:
> >>>>>
> >>>>>> In line.
> >>>>>>
> >>>>>> John Kane
> >>>>>> Kingston ON Canada
> >>>>>>
> >>>>>>
> >>>>>>> -----Original Message-----
> >>>>>>> From: valkremk at gmail.com
> >>>>>>> Sent: Fri, 30 Oct 2015 20:40:03 -0500
> >>>>>>> To: istazahn at gmail.com
> >>>>>>> Subject: Re: [R] If else
> >>>>>>>
> >>>>>>> I am trying to change the mydata$sex  from character to numeric
> >>>>>>
> >>>>>> Why?
> >>>>>>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
> >>>>> this is
> >>>>>> a very unusual thing to do in R.
> >>>>>>
> >>>>>> Is there a very specific reason for doing this in your analysis.
> >>>>>> Otherwise it may better to leave the coding as NA. Some of the
> >>> data
> >>>>> mungers
> >>>>>> here may be able to suggest which is the best strategy in R.
> >>>>>>
> >>>>>> R is 'weird' compared to more mundane stats packages such as SAS
> >>> or
> >>>>> SPSS
> >>>>>> and common techniques that one would use with them often are not
> >>>>>> appropriate in R.
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>>> I want teh out put like
> >>>>>>>    id  sex
> >>>>>>>       1  NA   0
> >>>>>>>       2  NA   0
> >>>>>>>       3  M     1
> >>>>>>>       4  F     2
> >>>>>>>       5  M    1
> >>>>>>>       6  F     2
> >>>>>>>       7  F    2
> >>>>>>>
> >>>>>>> mydata$sex1 <- 0
> >>>>>>> if(mydata$sex =="M " ){
> >>>>>>>   mydata$sex1<-1
> >>>>>>> } else {
> >>>>>>>   mydata$sex1<-2
> >>>>>>> }
> >>>>>>>
> >>>>>>> mydata$sex1
> >>>>>>>
> >>>>>>> Warning message:In if (mydata$sex == "M ") { :
> >>>>>>>   the condition has length > 1 and only the first element will
> >>> be
> >>>>>>> used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> >>>>>>>
> >>>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
> >>>>> wrote:
> >>>>>>>
> >>>>>>>> Using numeric for missing sounds like asking for trouble. But
> >>> if
> >>>>> you
> >>>>>>>> must, something like
> >>>>>>>>
> >>>>>>>> mydata$confusingWillCauseProblemsLater <-
> >>>>>>>>   ifelse(
> >>>>>>>>     is.na(mydata$sex),
> >>>>>>>>     0,
> >>>>>>>>     as.numeric(factor(mydata$sex,
> >>>>>>>>                       levels = c("M", "F"))))
> >>>>>>>>
> >>>>>>>> should do it.
> >>>>>>>>
> >>>>>>>> Best,
> >>>>>>>> Ista
> >>>>>>>>
> >>>>>>>> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com>
> >>> wrote:
> >>>>>>>>> Hi all,
> >>>>>>>>> Iam trying to change character  to numeric but have probelm
> >>>>>>>>>
> >>>>>>>>> mydata <- read.table(header=TRUE, text=', sep=" "
> >>>>>>>>>      id  sex
> >>>>>>>>>       1  NA
> >>>>>>>>>       2  NA
> >>>>>>>>>       3  M
> >>>>>>>>>       4  F
> >>>>>>>>>       5  M
> >>>>>>>>>       6  F
> >>>>>>>>>       7  F
> >>>>>>>>>        ')
> >>>>>>>>>
> >>>>>>>>> if sex is missing then sex=0;
> >>>>>>>>> if sex is"M" then sex=1;
> >>>>>>>>> if sex is"F" then sex=2;
> >>>>>>>>>
> >>>>>>>>> Any help please ?
> >>>>>>>>>
> >>>>>>>>>         [[alternative HTML version deleted]]
> >>>>>>>>>
> >>>>>>>>> ______________________________________________
> >>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>>>> code.
> >>>>>>>>
> >>>>>>>
> >>>>>>>       [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>
> >>>>>> ____________________________________________________________
> >>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
> >>> orcas
> >>>>> on
> >>>>>> your desktop!
> >>>>>> Check it out at http://www.inbox.com/marineaquarium
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>
> >>>>>       [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > -------------------------------------------------
> > E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> > Date: 31-Oct-2015  Time: 19:29:50
> > This message was sent by XFMail
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Nov  1 00:59:28 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 1 Nov 2015 12:59:28 +1300
Subject: [R] If else
In-Reply-To: <XFMail.20151031193001.Ted.Harding@wlandres.net>
References: <XFMail.20151031193001.Ted.Harding@wlandres.net>
Message-ID: <563555E0.3040805@auckland.ac.nz>


Ted:  You are either being deliberately obtuse or playing Devil's 
advocate or just stirring.  It is clear from his/her posts that the OP 
has limited understanding of both R and statistics.  Your sophisticated 
philosophising about the possibility of "three sexes" is very unlikely 
to have anything to do with what the OP wishes to accomplish.

The advice requested was not about how to treat "NA" as a "third sex"
but about how to convert categorical data coded as NA, "M", and "F" to 
numeric.  Which cannot possibly be a good idea.

It is not productive to encourage the OP to persist with wrong-headed 
notions.  Instead he or she should be encouraged to get to grips with 
the real issues of the analysis and to understand that treating 
categorical data as numeric is a recipe for disaster.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 01/11/15 08:47, Ted Harding wrote:

> [Apologies if the message below should arrive twice. When first
> sent there was apparently something wrong with the email address
> to r-help, and it was held for moderation because "Message has
> implicit destination" (whatever that means). I have made sure
> that this time the email address is correct.]
>
> John Fox has given a neat expression to achieve the desired result!
>
> I would like to comment, however, on the somewhat insistent criticism
> of Val's request from several people.
>
> It can make sense to have three "sex"es. Suppose, for example,
> that the data are records of street crime reported by victims.
> The victim may be able to identify the sex of the preprator
> as definitely "M", or definitely "F". One of the aims of the
> analysis is to investgate whether there is an association
> between the gender of the offender and the type of crime.
>
> But in some cases the victim may not have been able to recognise
> the offender's sex. Then it would have to go in the record as "NA"
> (or equivalent). There can be two kinds of reason why the victim
> was unable to recognise the sex. One kind is where the victim
> simply did not see the offender (e.g. their purse was stolen
> while they were concentrating on something else, and they only
> found out later). Another kind is where the offender deliberately
> disguises their gender, so that it cannot be determined from their
> appearance. This second kind could be associated with a particular
> category of crime (and I leave it to people's lurid imaginations
> to think of possible examples ... ).
>
> Then one indeed has three "sex"es: Male, Female, and Indeterminate,
> for each of which there is a potential assoctiation with type of crime.
> With most analyses, however, a category of "NA" would be ignored
> (at least by R).
>
> And then one has a variable which is a factor with 3 levels, all
> of which can (as above) be meaningful), and "NA" would not be
> ignored.
>
> Hoping this helps to clarify! (And, Val, does the above somehow
> correspond to your objectives).
>
> Best wishes to all,
> Ted


From r.turner at auckland.ac.nz  Sun Nov  1 01:06:31 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 1 Nov 2015 13:06:31 +1300
Subject: [R] [FORGED] Re:  If else
In-Reply-To: <CA+8X3fWg3WB-gJbcFrvEBVMn-JEzRt+BySHQCh4Mm7X3f4M9Fw@mail.gmail.com>
References: <XFMail.20151031193001.Ted.Harding@wlandres.net>
	<56353A87.706@gmail.com>
	<CA+8X3fWg3WB-gJbcFrvEBVMn-JEzRt+BySHQCh4Mm7X3f4M9Fw@mail.gmail.com>
Message-ID: <56355787.8060209@auckland.ac.nz>


Jim: I'm sure that this is much more sophisticated than anything that 
the OP ever dreamed of dealing with.  And irrespective of that, the 
issue is not about there being more than two sexes in some contexts but 
rather of the folly of treating categorical data as numeric.

Moreover your "neither male nor female" sexes have nothing whatever to 
do with missing values.  Missing means that the value wasn't *observed*, 
not the values was weird/strange/unfamiliar.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 01/11/15 12:45, Jim Lemon wrote:
> Having had to face this problem myself more than once, I sympathize with
> Ted's argument. First let me confess that I regard sex as a measure of the
> reproductive phenotype. Given the ongoing experimentation with both sex and
> gender, I have had to add "U" (Unstated - includes all those acronyms that
> can be mistaken for gamma hydroxy butyrate) to "M" and "F" in a dataset or
> two.
>
> Even worse is the crap shoot of sex chromosomes. While XYY is not much of a
> problem at all, Turner's Syndrome (XO) is neither female (although they
> appear to be) nor male. Given a reasonably large sample (the dream of
> some), nature usually provides a few permutations that, while we know what
> they are, don't really fit comfortably in either "M" or "F".


From valkremk at gmail.com  Sun Nov  1 01:19:46 2015
From: valkremk at gmail.com (Val)
Date: Sat, 31 Oct 2015 19:19:46 -0500
Subject: [R] [FORGED] Re: If else
In-Reply-To: <56355787.8060209@auckland.ac.nz>
References: <XFMail.20151031193001.Ted.Harding@wlandres.net>
	<56353A87.706@gmail.com>
	<CA+8X3fWg3WB-gJbcFrvEBVMn-JEzRt+BySHQCh4Mm7X3f4M9Fw@mail.gmail.com>
	<56355787.8060209@auckland.ac.nz>
Message-ID: <CAJOiR6bYq6aeQBz6qW6AnBqtEbt1c3jaT83YT=8aJC5f9qtvgA@mail.gmail.com>

Hi All,

I am sorry for the confusion  and yes I understand  this due to limited
knowledge of  R. I am working on that.

Thank you again.




On Sat, Oct 31, 2015 at 7:06 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> Jim: I'm sure that this is much more sophisticated than anything that the
> OP ever dreamed of dealing with.  And irrespective of that, the issue is
> not about there being more than two sexes in some contexts but rather of
> the folly of treating categorical data as numeric.
>
> Moreover your "neither male nor female" sexes have nothing whatever to do
> with missing values.  Missing means that the value wasn't *observed*, not
> the values was weird/strange/unfamiliar.
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> On 01/11/15 12:45, Jim Lemon wrote:
>
>> Having had to face this problem myself more than once, I sympathize with
>> Ted's argument. First let me confess that I regard sex as a measure of the
>> reproductive phenotype. Given the ongoing experimentation with both sex
>> and
>> gender, I have had to add "U" (Unstated - includes all those acronyms that
>> can be mistaken for gamma hydroxy butyrate) to "M" and "F" in a dataset or
>> two.
>>
>> Even worse is the crap shoot of sex chromosomes. While XYY is not much of
>> a
>> problem at all, Turner's Syndrome (XO) is neither female (although they
>> appear to be) nor male. Given a reasonably large sample (the dream of
>> some), nature usually provides a few permutations that, while we know what
>> they are, don't really fit comfortably in either "M" or "F".
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sun Nov  1 01:24:55 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 1 Nov 2015 00:24:55 +0000
Subject: [R] If else
In-Reply-To: <CAJOiR6Y7EEzvJP2haG2g9r5jR7R9o4-fqST4O6NBcdTAHjgMwQ@mail.gmail.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
	<F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
	<CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F350A0@FHSDB2D11-2.csu.mcmaster.ca>
	<CAJOiR6Y7EEzvJP2haG2g9r5jR7R9o4-fqST4O6NBcdTAHjgMwQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3519D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Val,

> -----Original Message-----
> From: Val [mailto:valkremk at gmail.com]
> Sent: October 31, 2015 5:57 PM
> To: Fox, John <jfox at mcmaster.ca>
> Subject: Re: [R] If else
> 
> Dear Professor John,
> 
> 
> Thank you very much for your elegant answer.
> 
> This one dump it on the screen. How can I send it to a a file?

There are several ways to do this; one is

mydata <- within(mydata, sex1 <- ifelse(is.na(sex), 0, ifelse(sex == "M", 1, 2)))
write.table(mydata, "mydata.txt", quote=FALSE, row.names=FALSE)

This assumes that you want a space-separated data file with variable names but not case names.

A couple of more general points:

(1) Since you originally asked the question on the r-help list, I've cc'd this response to the list.

(2) If you're going to use R beyond this one application, you'll probably want to learn some more about it.

Best,
 John

> 
> 
> within(mydata, sex1 <- ifelse(is.na <http://is.na> (sex), 0, ifelse(sex == "M", 1,
> 2)))
>   id  sex sex1
> 1  1 <NA>    0
> 2  2 <NA>    0
> 3  3    M    1
> 4  4    F    2
> 5  5    M    1
> 6  6    F    2
> 7  7    F    2
> 
> 
> Thank you in advance,
> 
> Val
> 
> 
> 
> 
> On Sat, Oct 31, 2015 at 1:44 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Val,
> 
> 	I haven't been following this thread, but there are several ways to do
> what you want, for example,
> 
> 	> within(mydata, sex1 <- ifelse(is.na <http://is.na> (sex), 0, ifelse(sex
> == "M", 1, 2)))
> 	  id  sex sex1
> 	1  1 <NA>    0
> 	2  2 <NA>    0
> 	3  3    M    1
> 	4  4    F    2
> 	5  5    M    1
> 	6  6    F    2
> 	7  7    F    2
> 
> 	My apologies if someone has already suggested that.
> 
> 	Best,
> 	 John
> 
> 	-----------------------------------------------
> 	John Fox, Professor
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 	http://socserv.socsci.mcmaster.ca/jfox/
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Val
> 	> Sent: Saturday, October 31, 2015 1:16 PM
> 	> To: Jeff Newmiller
> 	> Cc: r-help at R-project.org (r-help at r-project.org <mailto:r-help at r-
> project.org> )
> 	> Subject: Re: [R] If else
> 	>
> 
> 	> Hi Jeff,
> 	>
> 	> I thought I answered. Yes I was not clear about it.  The further
> 	> analysis
> 	> will no  be done by R.  It is another software that will not accept a
> 	> character response variable.
> 	>
> 	> Why R is so complicated to do that.  If it is SAS then I can do it on
> 	> one
> 	> statement. .
> 	>
> 	>
> 	> On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
> 	> <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> >
> 	> wrote:
> 	>
> 	> > You haven't actually answered John's question as to the type of
> 	> analysis
> 	> > you plan to do. It still looks from here like you should be using
> 	> factor
> 	> > data rather than numeric, but since you are not being clear we
> cannot
> 	> give
> 	> > specifics as to how to proceed.
> 	> > ----------------------------------------------------------------------
> 	> -----
> 	> > Jeff Newmiller                        The     .....       .....  Go
> 	> Live...
> 	> > DCN:<jdnewmil at dcn.davis.ca.us
> <mailto:jdnewmil at dcn.davis.ca.us> >        Basics: ##.#.       ##.#.  Live
> 	> > Go...
> 	> >                                       Live:   OO#.. Dead: OO#..
> 	> Playing
> 	> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> 	> > /Software/Embedded Controllers)               .OO#.       .OO#.
> 	> rocks...1k
> 	> > ----------------------------------------------------------------------
> 	> -----
> 	> > Sent from my phone. Please excuse my brevity.
> 	> >
> 	> > On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com
> <mailto:valkremk at gmail.com> > wrote:
> 	> > >Hi All,
> 	> > >
> 	> > >
> 	> > >Yes I need  to change to numeric  because I am preparing a data
> set
> 	> > >for
> 	> > >further  analysis. The variable to be changed  from character to
> 	> > >numeric
> 	> > >(in this case, sex) will be a response variable.  Some records
> have
> 	> > >missing
> 	> > >observation on sex and it is blank.
> 	> > >     id  sex
> 	> > >      1
> 	> > >      2
> 	> > >      3  M
> 	> > >      4  F
> 	> > >      5  M
> 	> > >      6  F
> 	> > >      7  F
> 	> > >
> 	> > >I am reading the data like this
> 	> > >
> 	> > >mydata <- read.csv(header=TRUE, text=', sep=", ")
> 	> > >     id  sex
> 	> > >      1   NA
> 	> > >      2  NA
> 	> > >      3  M
> 	> > >      4  F
> 	> > >      5  M
> 	> > >      6  F
> 	> > >      7  F
> 	> > >
> 	> > >The  data set is huge   (>250,000)
> 	> > >
> 	> > >
> 	> > >I want the output like this
> 	> > >
> 	> > >     id  sex    sex1
> 	> > >      1   NA    0
> 	> > >      2  NA     0
> 	> > >      3  M       1
> 	> > >      4  F       2
> 	> > >      5  M      1
> 	> > >      6  F       2
> 	> > >      7  F       2
> 	> > >
> 	> > >Thank you in advance
> 	> > >
> 	> > >
> 	> > >On Sat, Oct 31, 2015 at 5:59 AM, John Kane
> <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com> >
> 	> wrote:
> 	> > >
> 	> > >> In line.
> 	> > >>
> 	> > >> John Kane
> 	> > >> Kingston ON Canada
> 	> > >>
> 	> > >>
> 	> > >> > -----Original Message-----
> 	> > >> > From: valkremk at gmail.com <mailto:valkremk at gmail.com>
> 	> > >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> 	> > >> > To: istazahn at gmail.com <mailto:istazahn at gmail.com>
> 	> > >> > Subject: Re: [R] If else
> 	> > >> >
> 	> > >> > I am trying to change the mydata$sex  from character to
> numeric
> 	> > >>
> 	> > >> Why?
> 	> > >>  As Ista (mydata$confusingWillCauseProblemsLater) has
> pointed out
> 	> > >this is
> 	> > >> a very unusual thing to do in R.
> 	> > >>
> 	> > >> Is there a very specific reason for doing this in your analysis.
> 	> > >> Otherwise it may better to leave the coding as NA. Some of
> the data
> 	> > >mungers
> 	> > >> here may be able to suggest which is the best strategy in R.
> 	> > >>
> 	> > >> R is 'weird' compared to more mundane stats packages such
> as SAS or
> 	> > >SPSS
> 	> > >> and common techniques that one would use with them often
> are not
> 	> > >> appropriate in R.
> 	> > >>
> 	> > >>
> 	> > >>
> 	> > >>
> 	> > >> > I want teh out put like
> 	> > >> >    id  sex
> 	> > >> >       1  NA   0
> 	> > >> >       2  NA   0
> 	> > >> >       3  M     1
> 	> > >> >       4  F     2
> 	> > >> >       5  M    1
> 	> > >> >       6  F     2
> 	> > >> >       7  F    2
> 	> > >> >
> 	> > >> > mydata$sex1 <- 0
> 	> > >> > if(mydata$sex =="M " ){
> 	> > >> >   mydata$sex1<-1
> 	> > >> > } else {
> 	> > >> >   mydata$sex1<-2
> 	> > >> > }
> 	> > >> >
> 	> > >> > mydata$sex1
> 	> > >> >
> 	> > >> > Warning message:In if (mydata$sex == "M ") { :
> 	> > >> >   the condition has length > 1 and only the first element will
> be
> 	> > >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> 	> > >> >
> 	> > >> >>
> 	> > >> >
> 	> > >> >
> 	> > >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn
> <istazahn at gmail.com <mailto:istazahn at gmail.com> >
> 	> > >wrote:
> 	> > >> >
> 	> > >> >> Using numeric for missing sounds like asking for trouble.
> But if
> 	> > >you
> 	> > >> >> must, something like
> 	> > >> >>
> 	> > >> >> mydata$confusingWillCauseProblemsLater <-
> 	> > >> >>   ifelse(
> 	> > >> >>     is.na <http://is.na> (mydata$sex),
> 	> > >> >>     0,
> 	> > >> >>     as.numeric(factor(mydata$sex,
> 	> > >> >>                       levels = c("M", "F"))))
> 	> > >> >>
> 	> > >> >> should do it.
> 	> > >> >>
> 	> > >> >> Best,
> 	> > >> >> Ista
> 	> > >> >>
> 	> > >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com
> <mailto:valkremk at gmail.com> > wrote:
> 	> > >> >>> Hi all,
> 	> > >> >>> Iam trying to change character  to numeric but have
> probelm
> 	> > >> >>>
> 	> > >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> 	> > >> >>>      id  sex
> 	> > >> >>>       1  NA
> 	> > >> >>>       2  NA
> 	> > >> >>>       3  M
> 	> > >> >>>       4  F
> 	> > >> >>>       5  M
> 	> > >> >>>       6  F
> 	> > >> >>>       7  F
> 	> > >> >>>        ')
> 	> > >> >>>
> 	> > >> >>> if sex is missing then sex=0;
> 	> > >> >>> if sex is"M" then sex=1;
> 	> > >> >>> if sex is"F" then sex=2;
> 	> > >> >>>
> 	> > >> >>> Any help please ?
> 	> > >> >>>
> 	> > >> >>>         [[alternative HTML version deleted]]
> 	> > >> >>>
> 	> > >> >>> ______________________________________________
> 	> > >> >>> R-help at r-project.org <mailto:R-help at r-project.org>
> mailing list -- To UNSUBSCRIBE and more,
> 	> see
> 	> > >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> > >> >>> PLEASE do read the posting guide
> 	> > >> >> http://www.R-project.org/posting-guide.html
> 	> > >> >>> and provide commented, minimal, self-contained,
> reproducible
> 	> > >code.
> 	> > >> >>
> 	> > >> >
> 	> > >> >       [[alternative HTML version deleted]]
> 	> > >> >
> 	> > >> > ______________________________________________
> 	> > >> > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list -- To UNSUBSCRIBE and more, see
> 	> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> 	> > >> > PLEASE do read the posting guide
> 	> > >> > http://www.R-project.org/posting-guide.html
> 	> > >> > and provide commented, minimal, self-contained,
> reproducible
> 	> code.
> 	> > >>
> 	> > >>
> ____________________________________________________________
> 	> > >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins,
> sharks &
> 	> orcas
> 	> > >on
> 	> > >> your desktop!
> 	> > >> Check it out at http://www.inbox.com/marineaquarium
> 	> > >>
> 	> > >>
> 	> > >>
> 	> > >
> 	> > >       [[alternative HTML version deleted]]
> 	> > >
> 	> > >______________________________________________
> 	> > >R-help at r-project.org <mailto:R-help at r-project.org>  mailing list
> -- To UNSUBSCRIBE and more, see
> 	> > >https://stat.ethz.ch/mailman/listinfo/r-help
> 	> > >PLEASE do read the posting guide
> 	> > >http://www.R-project.org/posting-guide.html
> 	> > >and provide commented, minimal, self-contained, reproducible
> code.
> 	> >
> 	> >
> 	>
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list --
> To UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 	> guide.html
> 	> and provide commented, minimal, self-contained, reproducible
> code.
> 
> 


From valkremk at gmail.com  Sun Nov  1 01:37:13 2015
From: valkremk at gmail.com (Val)
Date: Sat, 31 Oct 2015 19:37:13 -0500
Subject: [R] If else
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F3519D@FHSDB2D11-2.csu.mcmaster.ca>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
	<F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
	<CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F350A0@FHSDB2D11-2.csu.mcmaster.ca>
	<CAJOiR6Y7EEzvJP2haG2g9r5jR7R9o4-fqST4O6NBcdTAHjgMwQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F3519D@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAJOiR6ZLxFcBSeSwuaHVUd_e6TZt89+KjwXN=vj7e+fL==rbCw@mail.gmail.com>

Thank you Professor John,

After I clicked the send button, I tried and the following also worked for
me.

mydata$sex1  <- ifelse(is.na(mydata$sex), 0, ifelse(mydata$sex == "M", 1,
2)))

Thank you  all again!






On Sat, Oct 31, 2015 at 7:24 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Val,
>
> > -----Original Message-----
> > From: Val [mailto:valkremk at gmail.com]
> > Sent: October 31, 2015 5:57 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Subject: Re: [R] If else
> >
> > Dear Professor John,
> >
> >
> > Thank you very much for your elegant answer.
> >
> > This one dump it on the screen. How can I send it to a a file?
>
> There are several ways to do this; one is
>
> mydata <- within(mydata, sex1 <- ifelse(is.na(sex), 0, ifelse(sex == "M",
> 1, 2)))
> write.table(mydata, "mydata.txt", quote=FALSE, row.names=FALSE)
>
> This assumes that you want a space-separated data file with variable names
> but not case names.
>
> A couple of more general points:
>
> (1) Since you originally asked the question on the r-help list, I've cc'd
> this response to the list.
>
> (2) If you're going to use R beyond this one application, you'll probably
> want to learn some more about it.
>
> Best,
>  John
>
> >
> >
> > within(mydata, sex1 <- ifelse(is.na <http://is.na> (sex), 0, ifelse(sex
> == "M", 1,
> > 2)))
> >   id  sex sex1
> > 1  1 <NA>    0
> > 2  2 <NA>    0
> > 3  3    M    1
> > 4  4    F    2
> > 5  5    M    1
> > 6  6    F    2
> > 7  7    F    2
> >
> >
> > Thank you in advance,
> >
> > Val
> >
> >
> >
> >
> > On Sat, Oct 31, 2015 at 1:44 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Val,
> >
> >       I haven't been following this thread, but there are several ways
> to do
> > what you want, for example,
> >
> >       > within(mydata, sex1 <- ifelse(is.na <http://is.na> (sex), 0,
> ifelse(sex
> > == "M", 1, 2)))
> >         id  sex sex1
> >       1  1 <NA>    0
> >       2  2 <NA>    0
> >       3  3    M    1
> >       4  4    F    2
> >       5  5    M    1
> >       6  6    F    2
> >       7  7    F    2
> >
> >       My apologies if someone has already suggested that.
> >
> >       Best,
> >        John
> >
> >       -----------------------------------------------
> >       John Fox, Professor
> >       McMaster University
> >       Hamilton, Ontario, Canada
> >       http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Val
> >       > Sent: Saturday, October 31, 2015 1:16 PM
> >       > To: Jeff Newmiller
> >       > Cc: r-help at R-project.org (r-help at r-project.org <mailto:r-help at r-
> > project.org> )
> >       > Subject: Re: [R] If else
> >       >
> >
> >       > Hi Jeff,
> >       >
> >       > I thought I answered. Yes I was not clear about it.  The further
> >       > analysis
> >       > will no  be done by R.  It is another software that will not
> accept a
> >       > character response variable.
> >       >
> >       > Why R is so complicated to do that.  If it is SAS then I can do
> it on
> >       > one
> >       > statement. .
> >       >
> >       >
> >       > On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
> >       > <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us> >
> >       > wrote:
> >       >
> >       > > You haven't actually answered John's question as to the type of
> >       > analysis
> >       > > you plan to do. It still looks from here like you should be
> using
> >       > factor
> >       > > data rather than numeric, but since you are not being clear we
> > cannot
> >       > give
> >       > > specifics as to how to proceed.
> >       > >
> ----------------------------------------------------------------------
> >       > -----
> >       > > Jeff Newmiller                        The     .....
>  .....  Go
> >       > Live...
> >       > > DCN:<jdnewmil at dcn.davis.ca.us
> > <mailto:jdnewmil at dcn.davis.ca.us> >        Basics: ##.#.       ##.#.
> Live
> >       > > Go...
> >       > >                                       Live:   OO#.. Dead: OO#..
> >       > Playing
> >       > > Research Engineer (Solar/Batteries            O.O#.
>  #.O#.  with
> >       > > /Software/Embedded Controllers)               .OO#.       .OO#.
> >       > rocks...1k
> >       > >
> ----------------------------------------------------------------------
> >       > -----
> >       > > Sent from my phone. Please excuse my brevity.
> >       > >
> >       > > On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com
> > <mailto:valkremk at gmail.com> > wrote:
> >       > > >Hi All,
> >       > > >
> >       > > >
> >       > > >Yes I need  to change to numeric  because I am preparing a
> data
> > set
> >       > > >for
> >       > > >further  analysis. The variable to be changed  from character
> to
> >       > > >numeric
> >       > > >(in this case, sex) will be a response variable.  Some records
> > have
> >       > > >missing
> >       > > >observation on sex and it is blank.
> >       > > >     id  sex
> >       > > >      1
> >       > > >      2
> >       > > >      3  M
> >       > > >      4  F
> >       > > >      5  M
> >       > > >      6  F
> >       > > >      7  F
> >       > > >
> >       > > >I am reading the data like this
> >       > > >
> >       > > >mydata <- read.csv(header=TRUE, text=', sep=", ")
> >       > > >     id  sex
> >       > > >      1   NA
> >       > > >      2  NA
> >       > > >      3  M
> >       > > >      4  F
> >       > > >      5  M
> >       > > >      6  F
> >       > > >      7  F
> >       > > >
> >       > > >The  data set is huge   (>250,000)
> >       > > >
> >       > > >
> >       > > >I want the output like this
> >       > > >
> >       > > >     id  sex    sex1
> >       > > >      1   NA    0
> >       > > >      2  NA     0
> >       > > >      3  M       1
> >       > > >      4  F       2
> >       > > >      5  M      1
> >       > > >      6  F       2
> >       > > >      7  F       2
> >       > > >
> >       > > >Thank you in advance
> >       > > >
> >       > > >
> >       > > >On Sat, Oct 31, 2015 at 5:59 AM, John Kane
> > <jrkrideau at inbox.com <mailto:jrkrideau at inbox.com> >
> >       > wrote:
> >       > > >
> >       > > >> In line.
> >       > > >>
> >       > > >> John Kane
> >       > > >> Kingston ON Canada
> >       > > >>
> >       > > >>
> >       > > >> > -----Original Message-----
> >       > > >> > From: valkremk at gmail.com <mailto:valkremk at gmail.com>
> >       > > >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> >       > > >> > To: istazahn at gmail.com <mailto:istazahn at gmail.com>
> >       > > >> > Subject: Re: [R] If else
> >       > > >> >
> >       > > >> > I am trying to change the mydata$sex  from character to
> > numeric
> >       > > >>
> >       > > >> Why?
> >       > > >>  As Ista (mydata$confusingWillCauseProblemsLater) has
> > pointed out
> >       > > >this is
> >       > > >> a very unusual thing to do in R.
> >       > > >>
> >       > > >> Is there a very specific reason for doing this in your
> analysis.
> >       > > >> Otherwise it may better to leave the coding as NA. Some of
> > the data
> >       > > >mungers
> >       > > >> here may be able to suggest which is the best strategy in R.
> >       > > >>
> >       > > >> R is 'weird' compared to more mundane stats packages such
> > as SAS or
> >       > > >SPSS
> >       > > >> and common techniques that one would use with them often
> > are not
> >       > > >> appropriate in R.
> >       > > >>
> >       > > >>
> >       > > >>
> >       > > >>
> >       > > >> > I want teh out put like
> >       > > >> >    id  sex
> >       > > >> >       1  NA   0
> >       > > >> >       2  NA   0
> >       > > >> >       3  M     1
> >       > > >> >       4  F     2
> >       > > >> >       5  M    1
> >       > > >> >       6  F     2
> >       > > >> >       7  F    2
> >       > > >> >
> >       > > >> > mydata$sex1 <- 0
> >       > > >> > if(mydata$sex =="M " ){
> >       > > >> >   mydata$sex1<-1
> >       > > >> > } else {
> >       > > >> >   mydata$sex1<-2
> >       > > >> > }
> >       > > >> >
> >       > > >> > mydata$sex1
> >       > > >> >
> >       > > >> > Warning message:In if (mydata$sex == "M ") { :
> >       > > >> >   the condition has length > 1 and only the first element
> will
> > be
> >       > > >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> >       > > >> >
> >       > > >> >>
> >       > > >> >
> >       > > >> >
> >       > > >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn
> > <istazahn at gmail.com <mailto:istazahn at gmail.com> >
> >       > > >wrote:
> >       > > >> >
> >       > > >> >> Using numeric for missing sounds like asking for trouble.
> > But if
> >       > > >you
> >       > > >> >> must, something like
> >       > > >> >>
> >       > > >> >> mydata$confusingWillCauseProblemsLater <-
> >       > > >> >>   ifelse(
> >       > > >> >>     is.na <http://is.na> (mydata$sex),
> >       > > >> >>     0,
> >       > > >> >>     as.numeric(factor(mydata$sex,
> >       > > >> >>                       levels = c("M", "F"))))
> >       > > >> >>
> >       > > >> >> should do it.
> >       > > >> >>
> >       > > >> >> Best,
> >       > > >> >> Ista
> >       > > >> >>
> >       > > >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com
> > <mailto:valkremk at gmail.com> > wrote:
> >       > > >> >>> Hi all,
> >       > > >> >>> Iam trying to change character  to numeric but have
> > probelm
> >       > > >> >>>
> >       > > >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> >       > > >> >>>      id  sex
> >       > > >> >>>       1  NA
> >       > > >> >>>       2  NA
> >       > > >> >>>       3  M
> >       > > >> >>>       4  F
> >       > > >> >>>       5  M
> >       > > >> >>>       6  F
> >       > > >> >>>       7  F
> >       > > >> >>>        ')
> >       > > >> >>>
> >       > > >> >>> if sex is missing then sex=0;
> >       > > >> >>> if sex is"M" then sex=1;
> >       > > >> >>> if sex is"F" then sex=2;
> >       > > >> >>>
> >       > > >> >>> Any help please ?
> >       > > >> >>>
> >       > > >> >>>         [[alternative HTML version deleted]]
> >       > > >> >>>
> >       > > >> >>> ______________________________________________
> >       > > >> >>> R-help at r-project.org <mailto:R-help at r-project.org>
> > mailing list -- To UNSUBSCRIBE and more,
> >       > see
> >       > > >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >       > > >> >>> PLEASE do read the posting guide
> >       > > >> >> http://www.R-project.org/posting-guide.html
> >       > > >> >>> and provide commented, minimal, self-contained,
> > reproducible
> >       > > >code.
> >       > > >> >>
> >       > > >> >
> >       > > >> >       [[alternative HTML version deleted]]
> >       > > >> >
> >       > > >> > ______________________________________________
> >       > > >> > R-help at r-project.org <mailto:R-help at r-project.org>
> mailing
> > list -- To UNSUBSCRIBE and more, see
> >       > > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > > >> > PLEASE do read the posting guide
> >       > > >> > http://www.R-project.org/posting-guide.html
> >       > > >> > and provide commented, minimal, self-contained,
> > reproducible
> >       > code.
> >       > > >>
> >       > > >>
> > ____________________________________________________________
> >       > > >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins,
> > sharks &
> >       > orcas
> >       > > >on
> >       > > >> your desktop!
> >       > > >> Check it out at http://www.inbox.com/marineaquarium
> >       > > >>
> >       > > >>
> >       > > >>
> >       > > >
> >       > > >       [[alternative HTML version deleted]]
> >       > > >
> >       > > >______________________________________________
> >       > > >R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list
> > -- To UNSUBSCRIBE and more, see
> >       > > >https://stat.ethz.ch/mailman/listinfo/r-help
> >       > > >PLEASE do read the posting guide
> >       > > >http://www.R-project.org/posting-guide.html
> >       > > >and provide commented, minimal, self-contained, reproducible
> > code.
> >       > >
> >       > >
> >       >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list --
> > To UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide http://www.R-
> > project.org/posting-
> >       > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> > code.
> >
> >
>
>

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Sun Nov  1 13:31:03 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 1 Nov 2015 14:31:03 +0200
Subject: [R] Alternatives for explicit for() loops
Message-ID: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>

Hi All,

I'm writing a long code that takes long time to execute. So I used the
Rprof() function and found out that the function that takes about 80% of
the time is the incomb () fucntion (below), and this is most probably
because of the many explicit for() loops I'm using.

n=18;m=4;p=0.3;alpha=0.2;beta=2
x=c(3,0,0)
LD<-list()
   for (i in 1:(m-1))  {
   LD[[i]]<-seq(0,x[i],1)
   }
   LD[[m]]<-seq(0,(n-m-sum(x)),1)
   LED<-expand.grid (LD)
   LED<-as.matrix(LED)
   store1<-numeric(nrow(LED))
    h<- numeric(m-1)
    lm<- numeric(m-1)
     for (j in 1:length(store1) )
         {
            incomb<-function(x,alpha,beta) {

 g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
                  for (i in 1:(m-1))  {
                       h[i]<- choose(x[i],LED[j,i])
                       }
                 ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
                for (i in 1:(m-1)) {
                       lm[i]<-(sum(LED[j,1:i])) + i
                     }
                plm<-prod(lm)
               gil<-g*ik/(plm)
             hlm<-numeric(sum(LED[j,])+(m-1))
             dsa<-length(hlm)
              for (i in 1:dsa)
                {
                 ppp<- sum(LED[j,])+(m-1)
                  hlm[i]<-
 (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
                 }
          shl<-gil*(sum(hlm)+1)
          return (shl)
          }
       store1[j]<-incomb(x,alpha=0.2,beta=2)
      }


I'm trying to use alternatives (for ex. to vectorize things) to the
explicit for() loops, but things don't work out.

Any suggestions that can help me to speed up the execution of the incomb()
function are much appreciated.

Thanks a lot in advance.

Maram Salem

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Nov  1 14:22:10 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 1 Nov 2015 08:22:10 -0500
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
Message-ID: <56361202.3080707@gmail.com>

On 01/11/2015 7:31 AM, Maram SAlem wrote:
> Hi All,
> 
> I'm writing a long code that takes long time to execute. So I used the
> Rprof() function and found out that the function that takes about 80% of
> the time is the incomb () fucntion (below), and this is most probably
> because of the many explicit for() loops I'm using.
> 
> n=18;m=4;p=0.3;alpha=0.2;beta=2
> x=c(3,0,0)
> LD<-list()
>    for (i in 1:(m-1))  {
>    LD[[i]]<-seq(0,x[i],1)
>    }
>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>    LED<-expand.grid (LD)
>    LED<-as.matrix(LED)
>    store1<-numeric(nrow(LED))
>     h<- numeric(m-1)
>     lm<- numeric(m-1)
>      for (j in 1:length(store1) )
>          {
>             incomb<-function(x,alpha,beta) {
> 
>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>                   for (i in 1:(m-1))  {
>                        h[i]<- choose(x[i],LED[j,i])
>                        }
>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>                 for (i in 1:(m-1)) {
>                        lm[i]<-(sum(LED[j,1:i])) + i
>                      }
>                 plm<-prod(lm)
>                gil<-g*ik/(plm)
>              hlm<-numeric(sum(LED[j,])+(m-1))
>              dsa<-length(hlm)
>               for (i in 1:dsa)
>                 {
>                  ppp<- sum(LED[j,])+(m-1)
>                   hlm[i]<-
>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>                  }
>           shl<-gil*(sum(hlm)+1)
>           return (shl)
>           }
>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>       }
> 
> 
> I'm trying to use alternatives (for ex. to vectorize things) to the
> explicit for() loops, but things don't work out.
> 
> Any suggestions that can help me to speed up the execution of the incomb()
> function are much appreciated.
> 

Generally I'd suggest starting with your innermost loops, and vectorize
those.  Continue outwards from there if you can.  For example, you have

>                   for (i in 1:(m-1))  {
>                        h[i]<- choose(x[i],LED[j,i])
>                        }

which could be vectorized as

  i <- 1:(m-1)
  h[i] <- choose(x[i], LED[j, i])

and maybe as

  h <- choose(x, LED[j, ])

(but I haven't read your code closely enough to know if those are
equivalent).

If m is large, this will make a big difference to that part of the code.

Duncan Murdoch


From cs258 at msstate.edu  Sun Nov  1 02:40:19 2015
From: cs258 at msstate.edu (Sun, Changyou)
Date: Sun, 1 Nov 2015 01:40:19 +0000
Subject: [R] ts.intersect() not working
Message-ID: <cf12d4ae7279473dbb94cac1a0d6591f@mail01.ad.msstate.edu>

Hi all,

I am trying to combine a single time series with a multivariate ts using ts.intersect(). However, depending on the month, the function may or may not work. Is this a bug or something I missed? Thank you for the help.

Edwin Sun
=================

> # Example 1: work well
> a2 <- ts(data = c(10, 20), start = c(2009, 1), frequency = 12); a2
     Jan Feb
2009  10  20

> a3 <- ts(data = matrix(data = 4:6, nrow = 1), start = c(2009, 2),
+          frequency = 12); a3
         Series 1 Series 2 Series 3
Feb 2009        4        5        6

> aa <- ts.intersect(a2, a3); aa
         a2 a3.Series 1 a3.Series 2 a3.Series 3
Feb 2009 20           4           5           6


> # Example 2: does not work
> b2 <- ts(data = c(10, 20), start = c(2009, 8), frequency = 12); b2
     Aug Sep
2009  10  20

> b3 <- ts(data = matrix(data = 4:6, nrow = 1), start = c(2009, 9),
+          frequency = 12); b3
         Series 1 Series 2 Series 3
Sep 2009        4        5        6

> bb <- ts.intersect(b2, b3); bb
Warning message:
In .cbind.ts(list(...), .makeNamesTs(...), dframe = dframe, union = FALSE) :
  non-intersecting series
NULL


	[[alternative HTML version deleted]]


From martincmd at hotmail.com  Sun Nov  1 14:29:44 2015
From: martincmd at hotmail.com (=?iso-8859-1?B?TWFydO1uIENh8fNu?=)
Date: Sun, 1 Nov 2015 08:29:44 -0500
Subject: [R] model.matrix and missing values
Message-ID: <COL126-W36E1963CF817949EEE3942A82D0@phx.gbl>

Hi to all.

I want to create a model matrix with variables that have missing values.

Recently I learned that na.pass/na.exclude and naresid are of great help in these type of cases (thanks, W. Dunlap).

Here's an example:

y <- c(1:5)
x1 <- c(1, 0, 1, 0, 1)
x2 <- c(1, NA, 1, NA, 1)
x3 <- c(NA, 0, 1, 0, NA)

mf <- model.frame(y ~ x1 + x2 + x3, na.action = "na.pass") 

mf

y x1 x2 x3
1 1  1  1 NA
2 2  0 NA  0
3 3  1  1  1
4 4  0 NA  0
5 5  1  1 NA

mm <- model.matrix(mf)

mm

 (Intercept) x1 x2 x3
3           1  1  1  1

attr(,"assign")
[1] 0 1 2 3

mm2 <- naresid(attr(mf, "na.action"), mm)

mm2

 (Intercept) x1 x2 x3
3           1  1  1  1

attr(,"assign")
[1] 0 1 2 3

As you can see, model.frame respects NA's. 

However, after model.matrix,  it doesn't work when I try to insert them in the right place with naresid.

Am I doing something wrong?

Thanks,


Martin

 		 	   		  
	[[alternative HTML version deleted]]


From alexierino at hotmail.com  Sun Nov  1 19:38:48 2015
From: alexierino at hotmail.com (Alex I)
Date: Sun, 1 Nov 2015 18:38:48 +0000
Subject: [R] =?utf-8?q?Adding_country-pair_fixed_effects_to_regression_ana?=
	=?utf-8?q?lyses?=
Message-ID: <BLU406-EAS3903EF322E5DC2395B3DE95C92D0@phx.gbl>

How does one go about including country-pair fixed effects in plm package regressions (OLS, RE, FE, and Hausman-Taylor estimators)? I am hoping to use plm because it is very easy and I'm baby-new to R. 

I have received the following code from a kind professor who I don't actually know: 

pairid <- paste(isoex,isoim) 
isoexyear <- paste(isoex,year) 
isoimyear <- paste(isoim,year) 

# do not worry about the other variables, focus on the G() portion which is using Pair FE, exporter-year, and importer-year 
felm(ln_trade~bc_o + l_bc_o  + bc_d + l_bc_d + G(pairid) + G(isoexyear) + G(isoimyear), 
            clustervar=as.factor(pairid), data=gravity_data) 

I have no idea how to implement that code at all and figure there has to be some simpler way than using a complicated method in felm. 

Be well. I appreciate your time.
	[[alternative HTML version deleted]]


From alexierino at hotmail.com  Sun Nov  1 19:40:36 2015
From: alexierino at hotmail.com (Alex I)
Date: Sun, 1 Nov 2015 18:40:36 +0000
Subject: [R] =?utf-8?q?Fixed_effects_estimators_doesn=27t_drop_or_omit?=
Message-ID: <BLU406-EAS28F28F7B72E2F1490F0810C92D0@phx.gbl>

The title says it all, really. Fixed effects in the plm package still estimates coefficients for time invariant variables. Now, if this isn't normal, you might think this is a data entry issue, but I don't think it is a data entry issue. Hausman-Taylor in the plm package correctly distinguishes the time invariants from the time variants using the same data. 

So, is this normal? Am I supposed to omit them myself? Do I run the regression including them but excluding their results when I display it to my reader? See below for the code I am using.


library(plm)
mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")


Y <- cbind(mydata$lnTRADE) 
X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi, mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG, mydata$EUZ) 


# Fixed effects panel regression 
fixed <- plm(Y ~ X, data=pdata, model= "within") 
summary(fixed) 
pbgtest(fixed)
coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))


library(plm)
mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")

Y <- cbind(mydata$lnTRADE) 
X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi, mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG, mydata$EUZ) 

# Fixed effects panel regression 
fixed <- plm(Y ~ X, data=pdata, model= "within") 
summary(fixed) 
pbgtest(fixed)
coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Nov  1 23:06:32 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 1 Nov 2015 14:06:32 -0800
Subject: [R] How to get variable name while doing series of regressions
 in an automated manner?
In-Reply-To: <CAGxFJbRHsVfPTSyVHn19Ai=dbOC4C15TDOw4AwRX6n_SX382Rg@mail.gmail.com>
References: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
	<CAGxFJbRHsVfPTSyVHn19Ai=dbOC4C15TDOw4AwRX6n_SX382Rg@mail.gmail.com>
Message-ID: <CAGxFJbR-a0z=d0McNr77cbZDDUonZU8F9xXih651CDXc19r7iA@mail.gmail.com>

Ravi et. al:

My prior "solution" nagged at me, as I thought it was pretty clumsy --
I was hoping someone would show how to fix it up. As no one did, I
finally realized how to do it myself. Here's how to do the iteration
to get the right labeling with no pasting or formula() call  by using
as.name() to substitute via bquote() directly into the (parsed) lm()
call. As one can see, it's a general approach to this sort of thing.
(It's also been offered in the past by others, but I forgot it).

z <- list(y1=rnorm(10,5),y2=rnorm(10,8),x=runif(10))

lapply(names(z)[-3],function(u) {
  eval(bquote(lm(log(.(y)) ~ x, data=z), list(y=as.name(u))))
})


There -- now I feel better. No need to respond.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Oct 27, 2015 at 10:50 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Marc,Ravi:
>
> I may misunderstand, but I think Marc's solution labels the list
> components but not necessarily the summary() outputs. This might be
> sufficient, as in:
>
>> z <- list(y1=rnorm(10,5),y2 = rnorm(10,8),x=1:10)
>>
>> ##1
>> results1<-lapply(z[-3],function(y)lm(log(y)~x,data=z))
>> lapply(results1,summary)
> $y1
>
> Call:
> lm(formula = log(y) ~ x, data = z)
>
> Residuals:
>     Min      1Q  Median      3Q     Max
> -0.2185 -0.1259 -0.0643  0.1340  0.3988
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
> x           -0.01495    0.02317  -0.645    0.537
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.2104 on 8 degrees of freedom
> Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
> F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369
>
>
> $y2
>
> Call:
> lm(formula = log(y) ~ x, data = z)
>
> Residuals:
>       Min        1Q    Median        3Q       Max
> -0.229072 -0.094579 -0.006498  0.134303  0.188158
>
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
> x           -0.006226   0.016778  -0.371     0.72
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.1524 on 8 degrees of freedom
> Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
> F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202
>
>
> ## 2
>
> Alternatively, if you want output with the correct variable names,
> bquote() can be used, as in:
>
>> results2 <-lapply(names(z)[1:2],
> +        function(nm){
> +          fo <-formula(paste0("log(",nm,")~x"))
> +           eval(bquote(lm(.(u),data=z),list(u=fo)))
> +        })
>> lapply(results2,summary)
> [[1]]
>
> Call:
> lm(formula = log(y1) ~ x, data = z)
>
> Residuals:
>     Min      1Q  Median      3Q     Max
> -0.2185 -0.1259 -0.0643  0.1340  0.3988
>
> Coefficients:
>             Estimate Std. Error t value Pr(>|t|)
> (Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
> x           -0.01495    0.02317  -0.645    0.537
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.2104 on 8 degrees of freedom
> Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
> F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369
>
>
> [[2]]
>
> Call:
> lm(formula = log(y2) ~ x, data = z)
>
> Residuals:
>       Min        1Q    Median        3Q       Max
> -0.229072 -0.094579 -0.006498  0.134303  0.188158
>
> Coefficients:
>              Estimate Std. Error t value Pr(>|t|)
> (Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
> x           -0.006226   0.016778  -0.371     0.72
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 0.1524 on 8 degrees of freedom
> Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
> F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202
>
>
> HTH or apologies if I've missed the point and broadcasted noise.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Tue, Oct 27, 2015 at 8:19 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
>> Hi,
>>
>> I am running through a series of regression in a loop as follows:
>>
>> results <- vector("list", length(mydata$varnames))
>>
>> for (i in 1:length(mydata$varnames)) {
>> results[[i]] <- summary(lm(log(eval(parse(text=varnames[i]))) ~ age + sex + CMV.status, data=mydata))
>> }
>>
>> Now, when I look at the results[i]] objects, I won't be able to see the original variable names.  Obviously, I will only see the following:
>>
>> Call:
>> lm(formula = log(eval(parse(text = varnames[i]))) ~ age + sex + CMV.status,
>>     data = mydata)
>>
>>
>> Is there a way to display the original variable names on the LHS?  In addition, is there a better paradigm for doing these type of series of regressions in an automatic fashion?
>>
>> Thank you very much,
>> Ravi
>>
>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
>> Associate Professor,  Department of Oncology
>> Division of Biostatistics & Bionformatics
>> Sidney Kimmel Comprehensive Cancer Center
>> Johns Hopkins University
>> 550 N. Broadway, Suite 1111-E
>> Baltimore, MD 21205
>> 410-502-2619
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Nov  1 23:27:48 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 1 Nov 2015 17:27:48 -0500
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
Message-ID: <CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>

Why are you recreating the incomb function within the loop instead of
defining it outside the loop?  Also you are referencing several variables
that are global (e.g., m & j); you should be passing these in as parameters
to the function.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
wrote:

> Hi All,
>
> I'm writing a long code that takes long time to execute. So I used the
> Rprof() function and found out that the function that takes about 80% of
> the time is the incomb () fucntion (below), and this is most probably
> because of the many explicit for() loops I'm using.
>
> n=18;m=4;p=0.3;alpha=0.2;beta=2
> x=c(3,0,0)
> LD<-list()
>    for (i in 1:(m-1))  {
>    LD[[i]]<-seq(0,x[i],1)
>    }
>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>    LED<-expand.grid (LD)
>    LED<-as.matrix(LED)
>    store1<-numeric(nrow(LED))
>     h<- numeric(m-1)
>     lm<- numeric(m-1)
>      for (j in 1:length(store1) )
>          {
>             incomb<-function(x,alpha,beta) {
>
>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>                   for (i in 1:(m-1))  {
>                        h[i]<- choose(x[i],LED[j,i])
>                        }
>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>                 for (i in 1:(m-1)) {
>                        lm[i]<-(sum(LED[j,1:i])) + i
>                      }
>                 plm<-prod(lm)
>                gil<-g*ik/(plm)
>              hlm<-numeric(sum(LED[j,])+(m-1))
>              dsa<-length(hlm)
>               for (i in 1:dsa)
>                 {
>                  ppp<- sum(LED[j,])+(m-1)
>                   hlm[i]<-
>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>                  }
>           shl<-gil*(sum(hlm)+1)
>           return (shl)
>           }
>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>       }
>
>
> I'm trying to use alternatives (for ex. to vectorize things) to the
> explicit for() loops, but things don't work out.
>
> Any suggestions that can help me to speed up the execution of the incomb()
> function are much appreciated.
>
> Thanks a lot in advance.
>
> Maram Salem
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Nov  1 23:41:13 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 1 Nov 2015 14:41:13 -0800
Subject: [R] Fixed effects estimators doesn't drop or omit
In-Reply-To: <BLU406-EAS28F28F7B72E2F1490F0810C92D0@phx.gbl>
References: <BLU406-EAS28F28F7B72E2F1490F0810C92D0@phx.gbl>
Message-ID: <CAF8bMcbHD42MQW_-+Hb==3EnZwOKLb7ajX5Xoc0pfJiS8Pf1=w@mail.gmail.com>

You might get better or quicker answers if you ask package-specific
questions
to the maintainer of the package
  > maintainer("plm")
  [1] "Yves Croissant <yves.croissant at univ-reunion.fr>"
or to the authors listed in
  > packageDescription("plm")
  Package: plm
  Version: 1.4-0
  Date: 2013-12-24
  Title: Linear Models for Panel Data
  Authors at R: c(person(given = "Yves", family = "Croissant", role = c("aut",
"cre"), email =
             "yves.croissant at univ-reunion.fr"), person(given = "Giovanni",
family = "Millo", role =
             "aut", email = "Giovanni_Millo at Generali.com"), person(given =
"Arne", family =
             "Henningsen", role = "ctb", email = "
arne.henningsen at googlemail.com"), person(given =
             "Ott", family = "Toomet", role = "ctb", email = "
otoomet at gmail.com"), person(given =
             "Christian", family = "Kleiber", role = "ctb", email = "
Christian.Kleiber at unibas.ch"),
             person(given = "Achim", family = "Zeileis", role = "ctb",
email =
             "Achim.Zeileis at R-project.org"))


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Nov 1, 2015 at 10:40 AM, Alex I <alexierino at hotmail.com> wrote:

> The title says it all, really. Fixed effects in the plm package still
> estimates coefficients for time invariant variables. Now, if this isn't
> normal, you might think this is a data entry issue, but I don't think it is
> a data entry issue. Hausman-Taylor in the plm package correctly
> distinguishes the time invariants from the time variants using the same
> data.
>
> So, is this normal? Am I supposed to omit them myself? Do I run the
> regression including them but excluding their results when I display it to
> my reader? See below for the code I am using.
>
>
> library(plm)
> mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")
>
>
> Y <- cbind(mydata$lnTRADE)
> X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi,
> mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG, mydata$EUZ)
>
>
> # Fixed effects panel regression
> fixed <- plm(Y ~ X, data=pdata, model= "within")
> summary(fixed)
> pbgtest(fixed)
> coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))
>
>
> library(plm)
> mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")
>
> Y <- cbind(mydata$lnTRADE)
> X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi,
> mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG, mydata$EUZ)
>
> # Fixed effects panel regression
> fixed <- plm(Y ~ X, data=pdata, model= "within")
> summary(fixed)
> pbgtest(fixed)
> coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Mon Nov  2 01:26:34 2015
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 2 Nov 2015 00:26:34 +0000
Subject: [R] Works on Mac,
 but not Windows: Using tempdir() to determine image location works
 with .tex file
In-Reply-To: <CAHjK6++KAKc7n-V1rrNGJ1Mr9kborG+=YNepjU8G7OidGGTe6g@mail.gmail.com>
References: <CAHjK6++KAKc7n-V1rrNGJ1Mr9kborG+=YNepjU8G7OidGGTe6g@mail.gmail.com>
Message-ID: <99336873-31F1-4A7C-AD7A-AEB23932FAFA@txbiomed.org>

Did you look at file.path()?


R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org







> On Oct 31, 2015, at 3:28 PM, Green Stone <greenstone1114 at gmail.com> wrote:
> 
> I am writing an R package that generates a .pdf file for users that outputs
> summarizations of data. I have a .Rnw script in the package (here, my MWE
> of it is called test.Rnw). The user can do:
> 
> knit2pdf("test.Rnw", clean=T)
> 
> This makes the process easy for them, because it automatically creates the
> .pdf file from the .tex file, and it erases unnecessary files for them
> (.aux and .log, for example). It also stores any images into a temporary
> directory (using tempdir()), which will then be erased routinely by the
> system after they have been incorporated into the .tex and .pdf file. This
> means they do not have to erase image files either.
> 
> Below is my test.Rnw MWE:
> 
> \documentclass[nohyper]{tufte-handout}
> \usepackage{tabularx}
> \usepackage{longtable}
> 
> \setcaptionfont{% changes caption font characteristics
>  \normalfont\footnotesize
>  \color{black}% <-- set color here}
> 
> \begin{document}
> <<setup, echo=FALSE>>=
> library(knitr)
> library(xtable)
> library(ggplot2)# Specify directory for figure output in a temporary directory
> temppath <- tempdir()
> opts_chunk$set(fig.path = temppath)@
> 
>  <<diamondData, echo=FALSE, fig.env = "marginfigure",
> out.width="0.95\\linewidth", fig.cap = "The diamond dataset has
> varibles depth and price.",fig.lp="mar:">>=
>  print(qplot(depth,price,data=diamonds))@
> 
>  <<echo=FALSE,results='asis'>>=
>  myDF <- data.frame(a = rnorm(1:10), b = letters[1:10])
> print(xtable(myDF, caption= 'This data frame shows ten random
> variables from the distribution and a corresponding letter',
> label='tab:dataFrame'), floating = FALSE, tabular.environment =
> "longtable", include.rownames=FALSE)@
> 
>  Figure \ref{mar:diamondData} shows the diamonds data set, with the
> variables price and depth.Table \ref{tab:dataFrame} shows letters a through j
> corresponding to a random variable from a normal distribution.
> 
> \end{document}
> 
> I should note that, in reality, there is another .Rnw file in my package
> that calls the test.Rnw file via:
> 
> knit2pdf("/inst/Rnw/test.Rnw","/path/test.tex",clean=T)
> 
> In any case, I am trying to get this package ready to be submitted to CRAN
> and have run across two problems:
> 
> 1) The more perplexing question first: The MWE code above seems to work on
> Mac Systems, but does not seem to work on Windows Systems! On Windows, the
> .pdf file that is generated does not contain the images. After
> troubleshooting, I think I have figured out the problem, but still cannot
> find a solution.
> 
> Basically, on Windows, it seems that the tempdir() command will create a
> pathway with double back-slashes, such as \this\is\myPath. Then, in the
> .tex file, the pathway to the temporary directory (that contains the
> images) are single back-slashes, such as \this\is\myPath. However, these
> should be single forward-slashes, such as /this/is/myPath.
> 
> Indeed, if I manually the change the backslashes to forward slashes in the
> .tex file in Windows, then I can successfully convert it to .pdf file that
> successfully contains the images.
> 
> I am unsure how to solve this in my syntax, however. If I simply do
> something like:
> 
> # Specify directory for figure output in a temporary directory
> temppath <- tempdir()
> gsub("\\\\", "/", temppath)
> 
> Then the images cannot be stored into the pathway on the Windows in the
> first place, even if the .tex file will contain the correct single forward
> slashes needed.
> 
> 2) I am wondering if it would acceptable for me to, in my other .Rnw file,
> add a second line to call:
> 
> knit2pdf("/inst/Rnw/test.Rnw","/path/test.tex",clean=T)
> system(sprintf("%s", paste0("rm -r ", "/path/myFile.tex")))
> 
> So that the .tex file can also be automatically erased. I am trying to
> confirm that such syntax would be acceptable by CRAN standards, as it does
> involve erasing a file from the user's computer (which could seem like
> dangerous/malware), although it points specifically at the .tex file it
> just generated, and so it should not be deleting anything important for
> them.
> 
> *Note: I am by default erasing all intermediary files so the user only
> deals with the .pdf file. However, I am still allowing users the option to
> go against this default, and keep these intermediary files, if needed.
> 
> I am grateful to hear any suggestions...
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wagenadl at uc.edu  Mon Nov  2 01:14:57 2015
From: wagenadl at uc.edu (Daniel Wagenaar)
Date: Sun, 1 Nov 2015 19:14:57 -0500
Subject: [R] (no subject)
In-Reply-To: <CAKFxdiQTR4uopMRte+J1T6hd8_DhRD9vyZbWsvyZnF_4_K-3EQ@mail.gmail.com>
References: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>
	<CAKFxdiQTR4uopMRte+J1T6hd8_DhRD9vyZbWsvyZnF_4_K-3EQ@mail.gmail.com>
Message-ID: <5636AB01.8030408@uc.edu>

Thank you all for your helpful responses. I apologize for the lack of 
subject line. That is certainly not my habit. It happened because my 
first email was refused because it was sent using an incorrect "From:" 
line (an aliases email address, daniel.wagenaar at uc.edu) instead of the 
address I subscribed to the list with. When I resent it, I failed to 
copy the subject line. My apologies.

- Daniel

On 10/30/2015 03:12 PM, Kevin Wright wrote:
> Maybe you want
>
> summary(aov(Y ~ A + Error(A:B)))
>
> Kevin
>
>
> On Fri, Oct 30, 2015 at 9:32 AM, Wagenaar, Daniel (wagenadl)
> <wagenadl at ucmail.uc.edu <mailto:wagenadl at ucmail.uc.edu>> wrote:
>
>     Dear R users:
>
>     All textbook references that I consult say that in a nested ANOVA
>     (e.g., A/B), the F statistic for factor A should be calculated as
>     F_A = MS_A / MS_(B within A). But when I run this simple example:
>
>     set.seed(1)
>     A = factor(rep(1:3, each=4))
>     B = factor(rep(1:2, 3, each=2))
>     Y = rnorm(12)
>     anova(lm(Y ~ A/B))
>
>     I get this result:
>
>     Analysis of Variance Table
>
>     Response: Y
>                Df Sum Sq Mean Sq F value Pr(>F)
>     A          2 0.4735 0.23675  0.2845 0.7620
>     A:B        3 1.7635 0.58783  0.7064 0.5823
>     Residuals  6 4.9931 0.83218
>
>     Evidently, R calculates the F value for A as MS_A / MS_Residuals.
>     While it is straightforward enough to calculate what I think is the
>     correct result from the table, I am surprised that R doesn't give me
>     that answer directly. Does anybody know if R's behavior is
>     intentional, and if so, why? And, perhaps most importantly, how to
>     get the "textbook" result in the most straightforward way? (I'd like
>     to be able to give me students a simple procedure...)
>
>     Thanks,
>
>     Daniel Wagenaar
>
>     --
>     Daniel A. Wagenaar, PhD
>     Assistant Professor
>     Department of Biological Sciences
>     McMicken College of Arts and Sciences
>     University of Cincinnati
>     Cincinnati, OH 45221
>     Phone: +1 (513) 556-9757
>     Email: daniel.wagenaar at uc.edu <mailto:daniel.wagenaar at uc.edu>
>     Web: http://www.danielwagenaar.net
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Kevin Wright


From damion at contexti.com  Mon Nov  2 01:34:29 2015
From: damion at contexti.com (Damion Reeves)
Date: Mon, 2 Nov 2015 11:04:29 +1030
Subject: [R] CentOS 6.5 x86_64 R installation throwing "Error in
 download.file(url, destfile = f,
 quiet = TRUE) : unsupported URL scheme" error
Message-ID: <CAA1Qt5-0URz0bnKAOQwOVdpzPE+EDpZ=ZhGnAbgbRGzw1grr_Q@mail.gmail.com>

Just wondering if any CRAN or "R" guru out there might have seen something
like this....and could advise a potential fix (or advise what, if anything
I've missed) ?


I've installed pre-req packages without an issue:

[hostname ]#  *yum install libxml2-devel git svn gtk+-devel gtk2-devel
gnutls-devel openssl-devel mysql-devel*

[hostname ]#  *yum install R-core*

[hostname ]#  *yum install R-core-devel*

[hostname ]#  *yum groupinstall "Development Tools"*


I can start "R":


[hostname ]# *R*

     R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
     Copyright (C) 2015 The R Foundation for Statistical Computing
     Platform: x86_64-redhat-linux-gnu (64-bit)

     R is free software and comes with ABSOLUTELY NO WARRANTY.
     You are welcome to redistribute it under certain conditions.
     Type 'license()' or 'licence()' for distribution details.

     Natural language support but running in an English locale

     R is a collaborative project with many contributors.
     Type 'contributors()' for more information and
     'citation()' on how to cite R or R packages in publications.

     Type 'demo()' for some demos, 'help()' for on-line help, or
     'help.start()' for an HTML browser interface to help.
     Type 'q()' to quit R.

     > q()
     Save workspace image? [y/n/c]: n




But when I try and install packages, I get the following (and it doesn't
show the Australian CRAN mirror which I think is normally option 5 and 6):


[hostname ]# *R*

     R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
     Copyright (C) 2015 The R Foundation for Statistical Computing
     Platform: x86_64-redhat-linux-gnu (64-bit)

     R is free software and comes with ABSOLUTELY NO WARRANTY.
     You are welcome to redistribute it under certain conditions.
     Type 'license()' or 'licence()' for distribution details.

     Natural language support but running in an English locale

     R is a collaborative project with many contributors.
     Type 'contributors()' for more information and
     'citation()' on how to cite R or R packages in publications.

     Type 'demo()' for some demos, 'help()' for on-line help, or
     'help.start()' for an HTML browser interface to help.
     Type 'q()' to quit R.

     >  *install.packages(c('rJava','RJDBC','sqldf','forecast','ggplot2','plyr','dplyr','tidyr','Rcpp','devtools','googleVis','arules','RCurl','corrgram','base64enc','lubridate','randomForest','shiny','oz','WDI','Hmisc'))*



Installing packages into ?/usr/lib64/R/library?
(as ?lib? is unspecified)

--- Please select a CRAN mirror for use in this session ---

*Error in download.file(url, destfile = f, quiet = TRUE) : unsupported URL
scheme*

HTTPS CRAN mirror

 1: 0-Cloud [https]             2: Austria [https]
 3: China (Beijing 4) [https]   4: China (Hefei) [https]
 5: Colombia (Cali) [https]     6: France (Lyon 2) [https]
 7: Iceland [https]             8: Russia (Moscow 1) [https]
 9: Switzerland [https]        10: UK (Bristol) [https]
11: UK (Cambridge) [https]     12: USA (CA 1) [https]
13: USA (KS) [https]           14: USA (MI 1) [https]
15: USA (TN) [https]           16: USA (TX) [https]
17: USA (WA) [https]           18: (HTTP mirrors)


Selection: 0
Error in contrib.url(repos, type) :
  trying to use CRAN without setting a mirror

> *q()*
Save workspace image? [y/n/c]: *n*






-- 
*Regards,*

*Damion Reeves* | Platform Engineer

*Contexti | Big Data Analytics*
Level 4, 80 Clarence Street Sydney NSW
damion at contexti.com | +61 422 927 757 | http://www.contexti.com

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Nov  2 08:57:01 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 2 Nov 2015 08:57:01 +0100
Subject: [R] CentOS 6.5 x86_64 R installation throwing "Error in
	download.file(url, destfile = f,
	quiet = TRUE) : unsupported URL scheme" error
In-Reply-To: <CAA1Qt5-0URz0bnKAOQwOVdpzPE+EDpZ=ZhGnAbgbRGzw1grr_Q@mail.gmail.com>
References: <CAA1Qt5-0URz0bnKAOQwOVdpzPE+EDpZ=ZhGnAbgbRGzw1grr_Q@mail.gmail.com>
Message-ID: <EB66D5B3-0F56-4F2E-9E5C-8B10315817DB@gmail.com>

3.2.0 is the problem. Support for HTTPS was streamlined in 3.2.2. 

You either need to choose an HTTP mirror (if you can trust your communication lines -- the reason for the change is that it was a security hole for people with untrusted connections: free wifi, etc.), or figure out how to install 3.2.2 on CentOS. For the latter, I suppose that you need a different YUM repo, but I've gone too rusty on the RedHat/Fedora/CentOS specifics.

-pd

> On 02 Nov 2015, at 01:34 , Damion Reeves <damion at contexti.com> wrote:
> 
> Just wondering if any CRAN or "R" guru out there might have seen something
> like this....and could advise a potential fix (or advise what, if anything
> I've missed) ?
> 
> 
> I've installed pre-req packages without an issue:
> 
> [hostname ]#  *yum install libxml2-devel git svn gtk+-devel gtk2-devel
> gnutls-devel openssl-devel mysql-devel*
> 
> [hostname ]#  *yum install R-core*
> 
> [hostname ]#  *yum install R-core-devel*
> 
> [hostname ]#  *yum groupinstall "Development Tools"*
> 
> 
> I can start "R":
> 
> 
> [hostname ]# *R*
> 
>     R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
>     Copyright (C) 2015 The R Foundation for Statistical Computing
>     Platform: x86_64-redhat-linux-gnu (64-bit)
> 
>     R is free software and comes with ABSOLUTELY NO WARRANTY.
>     You are welcome to redistribute it under certain conditions.
>     Type 'license()' or 'licence()' for distribution details.
> 
>     Natural language support but running in an English locale
> 
>     R is a collaborative project with many contributors.
>     Type 'contributors()' for more information and
>     'citation()' on how to cite R or R packages in publications.
> 
>     Type 'demo()' for some demos, 'help()' for on-line help, or
>     'help.start()' for an HTML browser interface to help.
>     Type 'q()' to quit R.
> 
>> q()
>     Save workspace image? [y/n/c]: n
> 
> 
> 
> 
> But when I try and install packages, I get the following (and it doesn't
> show the Australian CRAN mirror which I think is normally option 5 and 6):
> 
> 
> [hostname ]# *R*
> 
>     R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
>     Copyright (C) 2015 The R Foundation for Statistical Computing
>     Platform: x86_64-redhat-linux-gnu (64-bit)
> 
>     R is free software and comes with ABSOLUTELY NO WARRANTY.
>     You are welcome to redistribute it under certain conditions.
>     Type 'license()' or 'licence()' for distribution details.
> 
>     Natural language support but running in an English locale
> 
>     R is a collaborative project with many contributors.
>     Type 'contributors()' for more information and
>     'citation()' on how to cite R or R packages in publications.
> 
>     Type 'demo()' for some demos, 'help()' for on-line help, or
>     'help.start()' for an HTML browser interface to help.
>     Type 'q()' to quit R.
> 
>> *install.packages(c('rJava','RJDBC','sqldf','forecast','ggplot2','plyr','dplyr','tidyr','Rcpp','devtools','googleVis','arules','RCurl','corrgram','base64enc','lubridate','randomForest','shiny','oz','WDI','Hmisc'))*
> 
> 
> 
> Installing packages into ?/usr/lib64/R/library?
> (as ?lib? is unspecified)
> 
> --- Please select a CRAN mirror for use in this session ---
> 
> *Error in download.file(url, destfile = f, quiet = TRUE) : unsupported URL
> scheme*
> 
> HTTPS CRAN mirror
> 
> 1: 0-Cloud [https]             2: Austria [https]
> 3: China (Beijing 4) [https]   4: China (Hefei) [https]
> 5: Colombia (Cali) [https]     6: France (Lyon 2) [https]
> 7: Iceland [https]             8: Russia (Moscow 1) [https]
> 9: Switzerland [https]        10: UK (Bristol) [https]
> 11: UK (Cambridge) [https]     12: USA (CA 1) [https]
> 13: USA (KS) [https]           14: USA (MI 1) [https]
> 15: USA (TN) [https]           16: USA (TX) [https]
> 17: USA (WA) [https]           18: (HTTP mirrors)
> 
> 
> Selection: 0
> Error in contrib.url(repos, type) :
>  trying to use CRAN without setting a mirror
> 
>> *q()*
> Save workspace image? [y/n/c]: *n*
> 
> 
> 
> 
> 
> 
> -- 
> *Regards,*
> 
> *Damion Reeves* | Platform Engineer
> 
> *Contexti | Big Data Analytics*
> Level 4, 80 Clarence Street Sydney NSW
> damion at contexti.com | +61 422 927 757 | http://www.contexti.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Mon Nov  2 12:34:01 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 2 Nov 2015 03:34:01 -0800
Subject: [R] Fixed effects estimators doesn't drop or omit
In-Reply-To: <BLU406-EAS28F28F7B72E2F1490F0810C92D0@phx.gbl>
Message-ID: <336736DC34B.00000161jrkrideau@inbox.com>

Hi Alex,
 Welcome to the R-help list. 

This is of no help with your question but a general suggestion. Including your code was great but it probably would help if you also included some sample data. 

The best way to supply data is to use dput(). See ?dput or have a look athttp://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz   for information on it and other suggestions for asking questions on R-help.

dput() provides a 'perfect' copy of your data and ensures that R-help readers see the data exactly as you do on your computer.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: alexierino at hotmail.com
> Sent: Sun, 1 Nov 2015 18:40:36 +0000
> To: r-help at r-project.org
> Subject: [R] Fixed effects estimators doesn't drop or omit
> 
> The title says it all, really. Fixed effects in the plm package still
> estimates coefficients for time invariant variables. Now, if this isn't
> normal, you might think this is a data entry issue, but I don't think it
> is a data entry issue. Hausman-Taylor in the plm package correctly
> distinguishes the time invariants from the time variants using the same
> data.
> 
> So, is this normal? Am I supposed to omit them myself? Do I run the
> regression including them but excluding their results when I display it
> to my reader? See below for the code I am using.
> 
> 
> library(plm)
> mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")
> 
> 
> Y <- cbind(mydata$lnTRADE)
> X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi,
> mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG,
> mydata$EUZ)
> 
> 
> # Fixed effects panel regression
> fixed <- plm(Y ~ X, data=pdata, model= "within")
> summary(fixed)
> pbgtest(fixed)
> coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))
> 
> 
> library(plm)
> mydata <- read.csv(file="FILE.csv",head=TRUE,sep=",")
> 
> Y <- cbind(mydata$lnTRADE)
> X <- cbind(mydata$lnGDPi, mydata$lnGDPj, mydata$lnDIST, mydata$lnIPRi,
> mydata$lnIPRj, mydata$lnGDP.SIM, mydata$C.BORD, mydata$C.LANG,
> mydata$EUZ)
> 
> # Fixed effects panel regression
> fixed <- plm(Y ~ X, data=pdata, model= "within")
> summary(fixed)
> pbgtest(fixed)
> coeftest(fixed, vcov = vcovHC(fixed, type = "HC0"))
> 	[[alternative HTML version deleted]]

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From jrkrideau at inbox.com  Mon Nov  2 13:00:16 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 2 Nov 2015 04:00:16 -0800
Subject: [R] What happened to Canada?
Message-ID: <33A1DD6DCF8.00000188jrkrideau@inbox.com>

A rather silly question but I went to install a new package this morning and as usual a list of CRAN mirrors appeared but the Canadian ones had disappeared.  

Is this some peculiarity of my system (Ubuntu 14.10 with R version 3.2.2)  or a new policy for R? 


John Kane
Kingston ON Canada

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From axel.urbiz at gmail.com  Mon Nov  2 13:13:59 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 2 Nov 2015 07:13:59 -0500
Subject: [R] dplyr instead of plyr: Help
Message-ID: <CAAyVsXJetTZBKXX_Qpw4meZ90=Jr73cOT_d08xeDVzsHm+5G8A@mail.gmail.com>

Sorry, this is *related* to a recent post, but not the same. I'd appreciate
your help in getting the same results with the two methods below (the first
using plyr and the second using dplyr. The former works, but not the
latter.)


### Sample data
set.seed(4)df <- data.frame(pred = rnorm(100), y = sample(c(0,1), 100,
replace = TRUE),                 models = gl(2, 50, 100, labels =
c("model1", "model2")))
### using plyr
fooFun <- function(x) {  xcuts <- unique(x$pred)  x$bin <- cut(x$pred,
breaks = xcuts, include.lowest = TRUE)  x <-
dplyr::summarize(dplyr::group_by(x, bin), sumY = sum(y))
x}head(plyr::ddply(df, plyr::.(models), fooFun))

### Using dplyr
fooFun2 <- function(pred, y) {  xcuts <- unique(pred)  bin <- cut(pred,
breaks = xcuts, include.lowest = TRUE)  dft <- data.frame(bin, pred, y)
dft <- dplyr::summarize(dplyr::group_by(dft, bin), sumY = sum(y))  dft}
res_dplyr <- dplyr::mutate(dplyr::group_by(df, models), fooFun2(pred,
y))Error: incompatible size (2), expecting 50 (the group size) or 1
head(res_dplyr)
Thank you.
Axel.

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon Nov  2 13:29:23 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 2 Nov 2015 13:29:23 +0100
Subject: [R] dplyr instead of plyr: Help
In-Reply-To: <CAAyVsXJetTZBKXX_Qpw4meZ90=Jr73cOT_d08xeDVzsHm+5G8A@mail.gmail.com>
References: <CAAyVsXJetTZBKXX_Qpw4meZ90=Jr73cOT_d08xeDVzsHm+5G8A@mail.gmail.com>
Message-ID: <CAJuCY5yxJpm_xL9hHzknJ6bc-JBc=vPU75HBsfsDhaEOM1ivxg@mail.gmail.com>

Please don't post in HTML. It makes your code unreadable.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-02 13:13 GMT+01:00 Axel Urbiz <axel.urbiz at gmail.com>:

> Sorry, this is *related* to a recent post, but not the same. I'd appreciate
> your help in getting the same results with the two methods below (the first
> using plyr and the second using dplyr. The former works, but not the
> latter.)
>
>
> ### Sample data
> set.seed(4)df <- data.frame(pred = rnorm(100), y = sample(c(0,1), 100,
> replace = TRUE),                 models = gl(2, 50, 100, labels =
> c("model1", "model2")))
> ### using plyr
> fooFun <- function(x) {  xcuts <- unique(x$pred)  x$bin <- cut(x$pred,
> breaks = xcuts, include.lowest = TRUE)  x <-
> dplyr::summarize(dplyr::group_by(x, bin), sumY = sum(y))
> x}head(plyr::ddply(df, plyr::.(models), fooFun))
>
> ### Using dplyr
> fooFun2 <- function(pred, y) {  xcuts <- unique(pred)  bin <- cut(pred,
> breaks = xcuts, include.lowest = TRUE)  dft <- data.frame(bin, pred, y)
> dft <- dplyr::summarize(dplyr::group_by(dft, bin), sumY = sum(y))  dft}
> res_dplyr <- dplyr::mutate(dplyr::group_by(df, models), fooFun2(pred,
> y))Error: incompatible size (2), expecting 50 (the group size) or 1
> head(res_dplyr)
> Thank you.
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Mon Nov  2 13:33:48 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 2 Nov 2015 12:33:48 +0000 (GMT)
Subject: [R] Creating "Envelope" around a plot
Message-ID: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>

Hi  I am plotting various strands of information, and I want to create an
"envelope" around each line, so that the locus of the envelope is the boundary
points no more than a fixed maximum distance from the plotted line, a bit like
drawing a larger rectangle with paralle sides and curved compass corners around
a smaller rectangle.  Obviously I can work out how to do this in code
(eventually) but I suspect it would take me a while and i was wondering whether
there was some R function which I don't know about which creates sets of of
points at a given maximal distance

the lines are simple vectors, ie like this noddy example

veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
plot(veca,type="l",lwd=2)

then I want to plot the locus of the boundary of all points no more than (say) 1
unit from the line  I imagine that one would have to provide a larger set of
interpolated points between the actual points of veca, but I can do that no
problem

I'd be grateful if anyone out there in the R-ethervoid has any ideas

Thanks, Nick Wray
	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Mon Nov  2 13:41:11 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 02 Nov 2015 06:41:11 -0600
Subject: [R] What happened to Canada?
In-Reply-To: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
Message-ID: <0C963D47-71C1-455A-939E-BF44EA219D64@me.com>


> On Nov 2, 2015, at 6:00 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
> A rather silly question but I went to install a new package this morning and as usual a list of CRAN mirrors appeared but the Canadian ones had disappeared.  
> 
> Is this some peculiarity of my system (Ubuntu 14.10 with R version 3.2.2)  or a new policy for R? 
> 
> 
> John Kane
> Kingston ON Canada


Hi John,

Presuming that the CRAN mirror list online is current, there do not appear to be any CRAN mirrors in Canada which support secure HTTP (HTTPS), which is now the default in 3.2.2.

See the announcement from August 14 (SIGNIFICANT USER-VISIBLE CHANGES and NEW FEATURES):

 https://stat.ethz.ch/pipermail/r-announce/2015/000589.html

See ?chooseCRANmirror for more information.

When you get a list of mirrors to select, by default the top of the list will include mirrors that support HTTPS. The last entry on the list should be (HTTP mirrors). Click that and it will bring up a list of additional mirrors, including Canadian locations, that support HTTP.

Regards,

Marc Schwartz


From axel.urbiz at gmail.com  Mon Nov  2 13:18:11 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 2 Nov 2015 07:18:11 -0500
Subject: [R] dplyr instead of plyr: Help
Message-ID: <CAAyVsXKZM0nHJqe=-rcXPwUvtqruMtVPLAqv43sPm3RKBvgOeg@mail.gmail.com>

 Sorry, this is *related* to a recent post, but not the same. I'd
appreciate your help in getting the same results with the two methods below
(the first using plyr and the second using dplyr. The former works, but not
the latter.)

### Sample data

set.seed(4)

df <- data.frame(pred = rnorm(100), y = sample(c(0,1), 100, replace = TRUE),

                 models = gl(2, 50, 100, labels = c("model1", "model2")))

### using plyr


fooFun <- function(x) {

  xcuts <- unique(x$pred)

  x$bin <- cut(x$pred, breaks = xcuts, include.lowest = TRUE)

  x <- dplyr::summarize(dplyr::group_by(x, bin), sumY = sum(y))

  x

}

head(plyr::ddply(df, plyr::.(models), fooFun))


### Using dplyr


fooFun2 <- function(pred, y) {

  xcuts <- unique(pred)

  bin <- cut(pred, breaks = xcuts, include.lowest = TRUE)

  dft <- data.frame(bin, pred, y)

  dft <- dplyr::summarize(dplyr::group_by(dft, bin), sumY = sum(y))

  dft

}

res_dplyr <- dplyr::mutate(dplyr::group_by(df, models), fooFun2(pred, y))

head(res_dplyr)


Thanks

Axel.

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Mon Nov  2 15:37:22 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 2 Nov 2015 14:37:22 +0000 (GMT)
Subject: [R] Creating "Envelope" around a plot
In-Reply-To: <CADv2QyG+mwOGAxz+uvRbCxcu3D4yBP6HqNUY0uHHkHFdSk57HA@mail.gmail.com>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<CADv2QyG+mwOGAxz+uvRbCxcu3D4yBP6HqNUY0uHHkHFdSk57HA@mail.gmail.com>
Message-ID: <359610514.13343.1446475042126.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>

Hi Dennis thanks, but I'd already tried something like this -- the dashed lines
are parallel to the original plot vector, and not at a fixed maximal distance to
the original vector, where for example they would have curves around the peaks.
 The boundary line points would only be parallel to the original vector line if
there is a straight stretch longer than 1 unit (if that is the minimal distance)
 As I say it's the kind of thing one does at school using compass and ruler but
writing an R routine to do it is tricky and several times in the past I have
re-invented the R wheel, writing code for whose purpose it then turns out there
already is a R function, so I'd thought I'd ask...

But thanks for your time Nick


> 
>     On 02 November 2015 at 14:22 Dennis Murphy <djmuser at gmail.com> wrote:
> 
> 
>     Hi:
> 
>     To produce the boundary lines one unit apart, this ought to work:
> 
>     veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
>     plot(veca,type="l",lwd=2)
>     lines(veca + 1, type = "l", lty = "dashed")
>     lines(veca - 1, type = "l", lty = "dashed")
> 
>     If this is what you want, I suggest that you consult ?polygon to draw
>     a shaded region between the boundary lines. I'll leave that as
>     homework for you - see the examples section to see how to close the
>     polygon.
> 
>     Dennis
> 
>     On Mon, Nov 2, 2015 at 4:33 AM, WRAY NICHOLAS
>     <nicholas.wray at ntlworld.com> wrote:
>     > Hi I am plotting various strands of information, and I want to create an
>     > "envelope" around each line, so that the locus of the envelope is the
>     > boundary
>     > points no more than a fixed maximum distance from the plotted line, a
>     > bit like
>     > drawing a larger rectangle with paralle sides and curved compass corners
>     > around
>     > a smaller rectangle. Obviously I can work out how to do this in code
>     > (eventually) but I suspect it would take me a while and i was wondering
>     > whether
>     > there was some R function which I don't know about which creates sets of
>     > of
>     > points at a given maximal distance
>     >
>     > the lines are simple vectors, ie like this noddy example
>     >
>     > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
>     > plot(veca,type="l",lwd=2)
>     >
>     > then I want to plot the locus of the boundary of all points no more than
>     > (say) 1
>     > unit from the line I imagine that one would have to provide a larger set
>     > of
>     > interpolated points between the actual points of veca, but I can do that
>     > no
>     > problem
>     >
>     > I'd be grateful if anyone out there in the R-ethervoid has any ideas
>     >
>     > Thanks, Nick Wray
>     > [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
> 
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Nov  2 16:03:39 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 2 Nov 2015 10:03:39 -0500
Subject: [R] Creating "Envelope" around a plot
In-Reply-To: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
Message-ID: <56377B4B.8030207@gmail.com>

On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> Hi  I am plotting various strands of information, and I want to create an
> "envelope" around each line, so that the locus of the envelope is the boundary
> points no more than a fixed maximum distance from the plotted line, a bit like
> drawing a larger rectangle with paralle sides and curved compass corners around
> a smaller rectangle.  Obviously I can work out how to do this in code
> (eventually) but I suspect it would take me a while and i was wondering whether
> there was some R function which I don't know about which creates sets of of
> points at a given maximal distance
>
> the lines are simple vectors, ie like this noddy example
>
> veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> plot(veca,type="l",lwd=2)
>
> then I want to plot the locus of the boundary of all points no more than (say) 1
> unit from the line  I imagine that one would have to provide a larger set of
> interpolated points between the actual points of veca, but I can do that no
> problem
>
> I'd be grateful if anyone out there in the R-ethervoid has any ideas

The graphics system will do this for you automatically if your 
coordinate system has the same scale in x and y, and you use a really 
huge line width.  For example,

veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray", type="l")lines(veca, lwd=2)


If you want to be 1 unit away in user coordinates and the x and y scales 
are different, it will be a lot harder.

Duncan Murdoch


From nicholas.wray at ntlworld.com  Mon Nov  2 16:19:10 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 2 Nov 2015 15:19:10 +0000 (GMT)
Subject: [R] Fwd: Re:  Creating "Envelope" around a plot
In-Reply-To: <1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<56377B4B.8030207@gmail.com>
	<1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
Message-ID: <1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>


> ---------- Original Message ----------
>     From: WRAY NICHOLAS <nicholas.wray at ntlworld.com>
>     To: Duncan Murdoch <murdoch.duncan at gmail.com>, r-help
> <r-help at missing_domain>
>     Date: at
>     Subject: Re: [R] Creating "Envelope" around a plot
> 
> 
>     Hi Dennis again, I see what you're getting at and it looks rather groovy
>  but unfortunately what I actually need is the vector of the points on the
> boundary (the graphics just being a way of checking that everything's as it
> should be) and so it rather looks like I need to do a lot of calculating of
> orthogonal vectors along straight stretches and circles round peaks
> 
>     I'm looking to do an algorithmic filtration of strands which lie within
> the "envelope" of other strands -- your method would allow visual "by hand"
> inspection but unfortunately I've got hundreds of strands to compare!
> 
>     But thanks again -- useful thoughts  Nick
> 
>         > > 
> >         On 02 November 2015 at 15:03 Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> > 
> > 
> >         On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> >         > Hi I am plotting various strands of information, and I want to
> >         > create an
> >         > "envelope" around each line, so that the locus of the envelope is
> >         > the boundary
> >         > points no more than a fixed maximum distance from the plotted
> >         > line, a bit like
> >         > drawing a larger rectangle with paralle sides and curved compass
> >         > corners around
> >         > a smaller rectangle. Obviously I can work out how to do this in
> >         > code
> >         > (eventually) but I suspect it would take me a while and i was
> >         > wondering whether
> >         > there was some R function which I don't know about which creates
> >         > sets of of
> >         > points at a given maximal distance
> >         >
> >         > the lines are simple vectors, ie like this noddy example
> >         >
> >         > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> >         > plot(veca,type="l",lwd=2)
> >         >
> >         > then I want to plot the locus of the boundary of all points no
> >         > more than (say) 1
> >         > unit from the line I imagine that one would have to provide a
> >         > larger set of
> >         > interpolated points between the actual points of veca, but I can
> >         > do that no
> >         > problem
> >         >
> >         > I'd be grateful if anyone out there in the R-ethervoid has any
> >         > ideas
> > 
> >         The graphics system will do this for you automatically if your
> >         coordinate system has the same scale in x and y, and you use a
> > really
> >         huge line width. For example,
> > 
> >         veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray",
> > type="l")lines(veca, lwd=2)
> > 
> > 
> >         If you want to be 1 unit away in user coordinates and the x and y
> > scales
> >         are different, it will be a lot harder.
> > 
> >         Duncan Murdoch
> > 
> >     > 
>     >
> 


 
	[[alternative HTML version deleted]]


From isra4884 at gmail.com  Mon Nov  2 17:27:21 2015
From: isra4884 at gmail.com (Israel Ortiz)
Date: Mon, 2 Nov 2015 10:27:21 -0600
Subject: [R] Error survreg: Density function returned an invalid matrix
Message-ID: <CAMESY2htAzDtg9c2RMPFDry=cgJoHo26AiiTxttn_w5trAANcA@mail.gmail.com>

Hi, I want to perform a survival analysis using survreg procedure from
survival library in R for a pareto distribution for a time variable, so I
set the new distribution using the following sintax:

    library(foreign)
    library(survival)
    library(VGAM)

    mypareto <- list(name='Pareto',
                 init= function(x, weights,parms){
                   alpha <-
length(x)/(sum(log(x))-length(x)*log(min(x)))#this is a MLE for alpha
                   c(media <-(alpha*min(x)/(alpha-1)),varianza <-
((min(x)/alpha)^2)*(alpha/(alpha-2)))},
                 density= function(x,weights) {
                   alpha <- length(x)/(sum(log(x))-length(x)*log(min(x)))
                   cdf1 <- function(x, alpha) ifelse(x > min(x) , 1 -
(min(x)/x)**alpha, 0 )
                         cdf2 <- function(x, alpha) ifelse(x > min(x),
(min(x)/x)**alpha ,0)
                         distribution <- function(x, alpha) ifelse(x >
min(x) , alpha*min(x)**alpha/(x**(alpha+1)), 0)
                         firstdev <- function(x, alpha) ifelse(x > min(x),
-(alpha+x)/x, 0)
                         seconddev <- function(x, alpha) ifelse(x > min(x),
(alpha+1)*(alpha+2)/x^2,0)
                   cbind(cdf1(x,alpha),cdf2(x, alpha),
distribution(x,alpha),firstdev(x,alpha),seconddev(x,alpha))},
                 deviance=function(x) {stop('deviance residuals not
defined')},
                 quantile= function(p, alpha) ifelse(p < 0 | p > 1, NaN,
min(x)*(1-p)**(-1/alpha)))

I tested new distribution using survregDtest and it was successful:

    survregDtest(mypareto, TRUE)
    #TRUE

But I get the following error when I use it:

    set.seed(1)
    a <- rpareto(100, 1, 6)
    b <- rnorm(100,5,1)
    c <- rep(1,100)
    base <- cbind.data.frame(a,b,c)

    mod1<-survreg(Surv(a, c) ~ b, base, dist = mypareto)

    Error in survreg.fit(X, Y, weights, offset, init = init,
    controlvals =   control,  :  Density function returned an invalid matrix

Why this happened even when the test was successful? and how can I solve
that?

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Nov  2 17:51:54 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Nov 2015 08:51:54 -0800
Subject: [R] Fwd: Re: Creating "Envelope" around a plot
In-Reply-To: <1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<56377B4B.8030207@gmail.com>
	<1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
Message-ID: <CAF8bMcZGR2XoZcdJmi3B+Ufqi0B22M3qvkZQt+qQtaj9wJk5gQ@mail.gmail.com>

Instead of computing the envelopes (of various radii) of paths and seeing
if they intersect
you could compute distances between paths and seeing if they are smaller
than a given
distance.  Computing the distance between 2 polylines is not difficult,
although computing
it quickly for very long sequences of line segments is more difficult.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 2, 2015 at 7:19 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

>
> > ---------- Original Message ----------
> >     From: WRAY NICHOLAS <nicholas.wray at ntlworld.com>
> >     To: Duncan Murdoch <murdoch.duncan at gmail.com>, r-help
> > <r-help at missing_domain>
> >     Date: at
> >     Subject: Re: [R] Creating "Envelope" around a plot
> >
> >
> >     Hi Dennis again, I see what you're getting at and it looks rather
> groovy
> >  but unfortunately what I actually need is the vector of the points on
> the
> > boundary (the graphics just being a way of checking that everything's as
> it
> > should be) and so it rather looks like I need to do a lot of calculating
> of
> > orthogonal vectors along straight stretches and circles round peaks
> >
> >     I'm looking to do an algorithmic filtration of strands which lie
> within
> > the "envelope" of other strands -- your method would allow visual "by
> hand"
> > inspection but unfortunately I've got hundreds of strands to compare!
> >
> >     But thanks again -- useful thoughts  Nick
> >
> >         > >
> > >         On 02 November 2015 at 15:03 Duncan Murdoch
> > > <murdoch.duncan at gmail.com> wrote:
> > >
> > >
> > >         On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> > >         > Hi I am plotting various strands of information, and I want
> to
> > >         > create an
> > >         > "envelope" around each line, so that the locus of the
> envelope is
> > >         > the boundary
> > >         > points no more than a fixed maximum distance from the plotted
> > >         > line, a bit like
> > >         > drawing a larger rectangle with paralle sides and curved
> compass
> > >         > corners around
> > >         > a smaller rectangle. Obviously I can work out how to do this
> in
> > >         > code
> > >         > (eventually) but I suspect it would take me a while and i was
> > >         > wondering whether
> > >         > there was some R function which I don't know about which
> creates
> > >         > sets of of
> > >         > points at a given maximal distance
> > >         >
> > >         > the lines are simple vectors, ie like this noddy example
> > >         >
> > >         > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> > >         > plot(veca,type="l",lwd=2)
> > >         >
> > >         > then I want to plot the locus of the boundary of all points
> no
> > >         > more than (say) 1
> > >         > unit from the line I imagine that one would have to provide a
> > >         > larger set of
> > >         > interpolated points between the actual points of veca, but I
> can
> > >         > do that no
> > >         > problem
> > >         >
> > >         > I'd be grateful if anyone out there in the R-ethervoid has
> any
> > >         > ideas
> > >
> > >         The graphics system will do this for you automatically if your
> > >         coordinate system has the same scale in x and y, and you use a
> > > really
> > >         huge line width. For example,
> > >
> > >         veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray",
> > > type="l")lines(veca, lwd=2)
> > >
> > >
> > >         If you want to be 1 unit away in user coordinates and the x
> and y
> > > scales
> > >         are different, it will be a lot harder.
> > >
> > >         Duncan Murdoch
> > >
> > >     >
> >     >
> >
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Mon Nov  2 18:29:55 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Mon, 2 Nov 2015 17:29:55 +0000 (GMT)
Subject: [R] Fwd: Re: Creating "Envelope" around a plot
In-Reply-To: <CAF8bMcZGR2XoZcdJmi3B+Ufqi0B22M3qvkZQt+qQtaj9wJk5gQ@mail.gmail.com>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<56377B4B.8030207@gmail.com>
	<1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<CAF8bMcZGR2XoZcdJmi3B+Ufqi0B22M3qvkZQt+qQtaj9wJk5gQ@mail.gmail.com>
Message-ID: <1311500866.3480.1446485395532.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>

Hi Bill I have been doing exactly that, ie summing the Euclidean distances
between points in the strands   Although with small sets of strands this
technique allows me to group the strands into various sets, which I can assume
are the same, unfortunately once I have a larger number of strands the distances
between groups become on the same order as the distances within groups as so
it's no longer clear cut.  I have tried various approaches, include a kind of
Monte Carlo sampling to create the distinct groups but the best approach seems
to be a kind of "kinship" idea, where if two one strand lies within the
"envelope" of another I can set them together.  But as said, creating the
envelope in R is not straightforward

Thanks Nick

> On 02 November 2015 at 16:51 William Dunlap <wdunlap at tibco.com> wrote:
> 
>     Instead of computing the envelopes (of various radii) of paths and seeing
> if they intersect
>     you could compute distances between paths and seeing if they are smaller
> than a given
>     distance. Computing the distance between 2 polylines is not difficult,
> although computing
>     it quickly for very long sequences of line segments is more difficult.
> 
>     Bill Dunlap
>     TIBCO Software
>     wdunlap<http://tibco.com>
> 
>     On Mon, Nov 2, 2015 at 7:19 AM, WRAY NICHOLAS < nicholas.wray at ntlworld.com
> <mailto:nicholas.wray at ntlworld.com> > wrote:
> 
>         > >         > ---------- Original Message ----------
> >         > From: WRAY NICHOLAS < nicholas.wray at ntlworld.com
> >         > <mailto:nicholas.wray at ntlworld.com> >
> >         > To: Duncan Murdoch < murdoch.duncan at gmail.com
> >         > <mailto:murdoch.duncan at gmail.com> >, r-help
> >         > <r-help at missing_domain>
> >         > Date: at
> >         > Subject: Re: [R] Creating "Envelope" around a plot
> >         >
> >         >
> >         > Hi Dennis again, I see what you're getting at and it looks rather
> >         > groovy
> >         > but unfortunately what I actually need is the vector of the points
> >         > on the
> >         > boundary (the graphics just being a way of checking that
> >         > everything's as it
> >         > should be) and so it rather looks like I need to do a lot of
> >         > calculating of
> >         > orthogonal vectors along straight stretches and circles round
> >         > peaks
> >         >
> >         > I'm looking to do an algorithmic filtration of strands which lie
> >         > within
> >         > the "envelope" of other strands -- your method would allow visual
> >         > "by hand"
> >         > inspection but unfortunately I've got hundreds of strands to
> >         > compare!
> >         >
> >         > But thanks again -- useful thoughts Nick
> >         >
> >         > > >
> >         > > On 02 November 2015 at 15:03 Duncan Murdoch
> >         > > < murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com> >
> >         > > wrote:
> >         > >
> >         > >
> >         > > On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> >         > > > Hi I am plotting various strands of information, and I want to
> >         > > > create an
> >         > > > "envelope" around each line, so that the locus of the envelope
> >         > > > is
> >         > > > the boundary
> >         > > > points no more than a fixed maximum distance from the plotted
> >         > > > line, a bit like
> >         > > > drawing a larger rectangle with paralle sides and curved
> >         > > > compass
> >         > > > corners around
> >         > > > a smaller rectangle. Obviously I can work out how to do this
> >         > > > in
> >         > > > code
> >         > > > (eventually) but I suspect it would take me a while and i was
> >         > > > wondering whether
> >         > > > there was some R function which I don't know about which
> >         > > > creates
> >         > > > sets of of
> >         > > > points at a given maximal distance
> >         > > >
> >         > > > the lines are simple vectors, ie like this noddy example
> >         > > >
> >         > > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> >         > > > plot(veca,type="l",lwd=2)
> >         > > >
> >         > > > then I want to plot the locus of the boundary of all points no
> >         > > > more than (say) 1
> >         > > > unit from the line I imagine that one would have to provide a
> >         > > > larger set of
> >         > > > interpolated points between the actual points of veca, but I
> >         > > > can
> >         > > > do that no
> >         > > > problem
> >         > > >
> >         > > > I'd be grateful if anyone out there in the R-ethervoid has any
> >         > > > ideas
> >         > >
> >         > > The graphics system will do this for you automatically if your
> >         > > coordinate system has the same scale in x and y, and you use a
> >         > > really
> >         > > huge line width. For example,
> >         > >
> >         > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray",
> >         > > type="l")lines(veca, lwd=2)
> >         > >
> >         > >
> >         > > If you want to be 1 unit away in user coordinates and the x and
> >         > > y
> >         > > scales
> >         > > are different, it will be a lot harder.
> >         > >
> >         > > Duncan Murdoch
> >         > >
> >         > > >
> >         > >
> >         >
> > 
> > 
> > 
> >         [[alternative HTML version deleted]]
> > 
> >         ______________________________________________
> >         R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> > To UNSUBSCRIBE and more, see
> >         https://stat.ethz.ch/mailman/listinfo/r-help
> >         PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >         and provide commented, minimal, self-contained, reproducible code.
> > 
> >     > 
> 


 
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Nov  2 18:35:13 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Nov 2015 09:35:13 -0800
Subject: [R] Fwd: Re: Creating "Envelope" around a plot
In-Reply-To: <1311500866.3480.1446485395532.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<56377B4B.8030207@gmail.com>
	<1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<CAF8bMcZGR2XoZcdJmi3B+Ufqi0B22M3qvkZQt+qQtaj9wJk5gQ@mail.gmail.com>
	<1311500866.3480.1446485395532.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
Message-ID: <CAF8bMcb7q8yG2YUH5EgxHUB77i3WrSxLeC-0dL69DECjEi0FGg@mail.gmail.com>

> summing the Euclidean distances between points in the strands
> ... if two one strand lies within the "envelope" of another I can set
them together

Use the max instead of the sum.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 2, 2015 at 9:29 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

> Hi Bill I have been doing exactly that, ie summing the Euclidean distances
> between points in the strands   Although with small sets of strands this
> technique allows me to group the strands into various sets, which I can
> assume are the same, unfortunately once I have a larger number of strands
> the distances between groups become on the same order as the distances
> within groups as so it's no longer clear cut.  I have tried various
> approaches, include a kind of Monte Carlo sampling to create the distinct
> groups but the best approach seems to be a kind of "kinship" idea, where if
> two one strand lies within the "envelope" of another I can set them
> together.  But as said, creating the envelope in R is not straightforward
>
> Thanks Nick
>
> On 02 November 2015 at 16:51 William Dunlap <wdunlap at tibco.com> wrote:
>
> Instead of computing the envelopes (of various radii) of paths and seeing
> if they intersect
> you could compute distances between paths and seeing if they are smaller
> than a given
> distance. Computing the distance between 2 polylines is not difficult,
> although computing
> it quickly for very long sequences of line segments is more difficult.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Nov 2, 2015 at 7:19 AM, WRAY NICHOLAS < nicholas.wray at ntlworld.com>
> wrote:
>
>
> > ---------- Original Message ----------
> > From: WRAY NICHOLAS < nicholas.wray at ntlworld.com>
> > To: Duncan Murdoch < murdoch.duncan at gmail.com>, r-help
> > <r-help at missing_domain>
> > Date: at
> > Subject: Re: [R] Creating "Envelope" around a plot
> >
> >
> > Hi Dennis again, I see what you're getting at and it looks rather groovy
> > but unfortunately what I actually need is the vector of the points on
> the
> > boundary (the graphics just being a way of checking that everything's as
> it
> > should be) and so it rather looks like I need to do a lot of calculating
> of
> > orthogonal vectors along straight stretches and circles round peaks
> >
> > I'm looking to do an algorithmic filtration of strands which lie within
> > the "envelope" of other strands -- your method would allow visual "by
> hand"
> > inspection but unfortunately I've got hundreds of strands to compare!
> >
> > But thanks again -- useful thoughts Nick
> >
> > > >
> > > On 02 November 2015 at 15:03 Duncan Murdoch
> > > < murdoch.duncan at gmail.com> wrote:
> > >
> > >
> > > On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> > > > Hi I am plotting various strands of information, and I want to
> > > > create an
> > > > "envelope" around each line, so that the locus of the envelope is
> > > > the boundary
> > > > points no more than a fixed maximum distance from the plotted
> > > > line, a bit like
> > > > drawing a larger rectangle with paralle sides and curved compass
> > > > corners around
> > > > a smaller rectangle. Obviously I can work out how to do this in
> > > > code
> > > > (eventually) but I suspect it would take me a while and i was
> > > > wondering whether
> > > > there was some R function which I don't know about which creates
> > > > sets of of
> > > > points at a given maximal distance
> > > >
> > > > the lines are simple vectors, ie like this noddy example
> > > >
> > > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> > > > plot(veca,type="l",lwd=2)
> > > >
> > > > then I want to plot the locus of the boundary of all points no
> > > > more than (say) 1
> > > > unit from the line I imagine that one would have to provide a
> > > > larger set of
> > > > interpolated points between the actual points of veca, but I can
> > > > do that no
> > > > problem
> > > >
> > > > I'd be grateful if anyone out there in the R-ethervoid has any
> > > > ideas
> > >
> > > The graphics system will do this for you automatically if your
> > > coordinate system has the same scale in x and y, and you use a
> > > really
> > > huge line width. For example,
> > >
> > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray",
> > > type="l")lines(veca, lwd=2)
> > >
> > >
> > > If you want to be 1 unit away in user coordinates and the x and y
> > > scales
> > > are different, it will be a lot harder.
> > >
> > > Duncan Murdoch
> > >
> > > >
> > >
> >
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From plessthanpointohfive at gmail.com  Mon Nov  2 19:39:05 2015
From: plessthanpointohfive at gmail.com (Jennifer Sabatier)
Date: Mon, 02 Nov 2015 18:39:05 +0000
Subject: [R] Locating the starting position of the first number in a string
Message-ID: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>

Hi,


So, I've got a vector of strings that look like this:
ID <- c("IBBS3_MSM_HN01209","IBBS3_MSM_HN01210","IBBS3_MSM_HN01211",
"IBBS3_MSM_HN10212","IBBS3_MSM_HN104213","IBBS3_MSM_HN10214",
"IBBS3_MSM_HN44215","IBBS3_MSM_HN44216","IBBS3_MSM_HN44217",
"IBBS3_MSM_HN44218","IBBS3_MSM_HN44219","IBBS3_MSM_HN44220",
"IBBS3_MSM_HN44221","IBBS3_MSM_HN44222","IBBS3_MSM_HN44223",
"IBBS3_MSM_HN44224","IBBS3_MSM_HN44225","IBBS3_MSM_HN44226",
"IBBS3_MSM_HN44227","IBBS3_MSM_HN12228","IBBS3_MSM_HN12229",
"IBBS3_MSM_HN12230","IBBS3_MSM_HN12231","IBBS3_MSM_HN12232",
"IBBS3_MSM_HN12233","IBBS3_MSM_HN12234","IBBS3_MSM_HN12235",
"IBBS3_MSM_HN12236","IBBS3_MSM_HN12237","IBBS3_MSM_HN12238",
"IBBS3_MSM_HN12239","IBBS3_MSM_HN12240","IBBS3_MSM_HN12241",
"IBBS3_MSM_HN12242","IBBS3_MSM_HN12243","IBBS3_MSM_HN12244",
 "IBBS3_MSM_HN12245","IBBS3_MSM_HN12246","IBBS3_MSM_HN12247",
 "IBBS3_MSM_HN12248","IBBS3_MSM_HN12249","IBBS3_MSM_HN12250",
 "IBBS3_MSM_HN12251","IBBS3_MSM_HN12252","IBBS3_MSM_HN12253",
 "IBBS3_MSM_HN12254","IBBS3_MSM_HN12255","IBBS3_MSM_HN25256",
 "IBBS3_MSM_HN25257","IBBS3_MSM_HN25258","IBBS3_MSM_HN25259",
"IBBS3_MSM_HN25260","IBBS3_MSM_HN25261","IBBS3_MSM_HN25262",
"IBBS3_MSM_HN25263","IBBS3_MSM_HN25264","IBBS3_MSM_HN25265",
"IBBS3_MSM_HN25266","IBBS3_MSM_HN25267","IBBS3_MSM_HN25268",
"IBBS3_MSM_HN25269","IBBS3_MSM_HN25270","IBBS3_MSM_HN25271",
"IBBS3_MSM_HN25272","IBBS3_MSM_HN25273","IBBS3_MSM_HN25274",
"IBBS3_MSM_HN25275","IBBS3_MSM_HN25276", "IBBS3_MSM_HN25277",
"IBBS3_MSM_HN25278","IBBS3_MSM_HN25279","IBBS3_MSM_HN25280",
"IBBS3_MSM_HN25281","IBBS3_MSM_HN25282","IBBS3_MSM_HN25283",
"IBBS3_MSM_HN25284","IBBS3_MSM_HMC44285",  "IBBS3_MSM_HMC44286",
"IBBS3_MSM_HMC44287","IBBS3_MSM_HMC44288","IBBS3_MSM_HMC44289",
"IBBS3_MSM_HMC44290","IBBS3_MSM_HMC44291","IBBS3_MSM_HMC44292",
"IBBS3_MSM_HMC44293","IBBS3_MSM_HMC44294","IBBS3_MSM_HMC44295",
"IBBS3_MSM_HMC44296","IBBS3_MSM_HMC44297","IBBS3_MSM_HMC44298",
"IBBS3_MSM_HMC44299","IBBS3_MSM_HMC44300","IBBS3_MSM_HMC44301",
"IBBS3_MSM_HMC44302","IBBS3_MSM_HMC44303","IBBS3_MSM_HMC44304",
"IBBS3_MSM_HMC44305","IBBS3_MSM_HMC44306","IBBS3_MSM_HMC44307",
"IBBS3_MSM_HMC44309")




This is an ID that is in the following format:  IBBS3_Type_Group#####


What I want to do is locate the starting position of Type, which is
anywhere from 3 to 4 letters long (in this example it's either MSM or
PWID), the starting position of Group which is 2-3 letters long (either HN
or HMC), and finally the starting position of the 5-digit number.


I'm able to get Type and Group using the following:


TYPE_s <- sapply(c("MSM", "PWID"), regexpr, ID, ignore.case=T)

GROUP_s <- (sapply(c("HN", "HMC"), regexpr, ID, ignore.case=T))


What I am having trouble with is getting the starting position of the
5-digit number.


I am trying:


DIGITS_s <- sapply("([0:9])", regexpr, ID, ignore.case=T)


But that just seems to look for the position of the first 0.:


> DIGITS_s

       ([0:9])

  [1,]      13

  [2,]      13

  [3,]      13

  [4,]      14

  [5,]      14

  [6,]      14

  [7,]      -1

  [8,]      -1

  [9,]      -1

 [10,]      -1

 [11,]      17

 [12,]      17

 [13,]      -1

 [14,]      -1

 [15,]      -1

 [16,]      -1

 [17,]      -1

 [18,]      -1

 [19,]      -1

 [20,]      -1

 [21,]      17

 [22,]      17

 [23,]      -1

 [24,]      -1

 [25,]      -1

 [26,]      -1

 [27,]      -1

 [28,]      -1

 [29,]      -1

 [30,]      -1

 [31,]      17

 [32,]      17

 [33,]      -1

 [34,]      -1

 [35,]      -1

 [36,]      -1

 [37,]      -1

 [38,]      -1

 [39,]      -1

 [40,]      -1

 [41,]      17

 [42,]      17

 [43,]      -1

 [44,]      -1

 [45,]      -1

 [46,]      -1

 [47,]      -1

 [48,]      -1

 [49,]      -1

 [50,]      -1

 [51,]      17

 [52,]      17

 [53,]      -1

 [54,]      -1

 [55,]      -1

 [56,]      -1

 [57,]      -1

 [58,]      -1

 [59,]      -1

 [60,]      -1

 [61,]      17

 [62,]      17

 [63,]      -1

 [64,]      -1

 [65,]      -1

 [66,]      -1

 [67,]      -1

 [68,]      -1

 [69,]      -1

 [70,]      -1

 [71,]      17

 [72,]      17

 [73,]      -1

 [74,]      -1

 [75,]      -1

 [76,]      -1

 [77,]      -1

 [78,]      -1

 [79,]      -1

 [80,]      -1

 [81,]      18

 [82,]      17

 [83,]      17

 [84,]      17

 [85,]      17

 [86,]      17

 [87,]      17

 [88,]      17

 [89,]      17

 [90,]      17

 [91,]      17

 [92,]      17

 [93,]      17

 [94,]      17

 [95,]      17

 [96,]      17

 [97,]      17

 [98,]      17

 [99,]      17

[100,]      17


So, clearly, this is wrong.  I just would like to find the starting
position of the first digit, no matter what it is.

It's probably easy, isn't it?

Best,

Jen

	[[alternative HTML version deleted]]


From Peter.Alspach at plantandfood.co.nz  Mon Nov  2 21:32:50 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Tue, 3 Nov 2015 09:32:50 +1300
Subject: [R] Locating the starting position of the first number in a
 string
In-Reply-To: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>
References: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B7545067CBF011F@AKLEXM01.PFR.CO.NZ>

Tena koe Jen

Not answering your question: if you are after these locations in order to split the IDs in columns, then you might like to consider strsplit; e.g.,

t(sapply(strsplit(ID, '_'), rbind))

You could then split the last column.  You state that there is a 5-digit number at the end.  If this is correct, then use this feature (i.e., nchar(ID)-4) as you'd want "IBBS3_MSM_HN104213" (the fifth element in ID) to split to IBBS3, MSM, HN1 and 04213.  However, if it isn't always 5 digits then split at the first number (i.e., HN and 104213).

HTH .....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jennifer Sabatier
Sent: Tuesday, 3 November 2015 7:39 a.m.
To: r-help at r-project.org
Subject: [R] Locating the starting position of the first number in a string

Hi,


So, I've got a vector of strings that look like this:
ID <- c("IBBS3_MSM_HN01209","IBBS3_MSM_HN01210","IBBS3_MSM_HN01211",
"IBBS3_MSM_HN10212","IBBS3_MSM_HN104213","IBBS3_MSM_HN10214",
"IBBS3_MSM_HN44215","IBBS3_MSM_HN44216","IBBS3_MSM_HN44217",
"IBBS3_MSM_HN44218","IBBS3_MSM_HN44219","IBBS3_MSM_HN44220",
"IBBS3_MSM_HN44221","IBBS3_MSM_HN44222","IBBS3_MSM_HN44223",
"IBBS3_MSM_HN44224","IBBS3_MSM_HN44225","IBBS3_MSM_HN44226",
"IBBS3_MSM_HN44227","IBBS3_MSM_HN12228","IBBS3_MSM_HN12229",
"IBBS3_MSM_HN12230","IBBS3_MSM_HN12231","IBBS3_MSM_HN12232",
"IBBS3_MSM_HN12233","IBBS3_MSM_HN12234","IBBS3_MSM_HN12235",
"IBBS3_MSM_HN12236","IBBS3_MSM_HN12237","IBBS3_MSM_HN12238",
"IBBS3_MSM_HN12239","IBBS3_MSM_HN12240","IBBS3_MSM_HN12241",
"IBBS3_MSM_HN12242","IBBS3_MSM_HN12243","IBBS3_MSM_HN12244",
 "IBBS3_MSM_HN12245","IBBS3_MSM_HN12246","IBBS3_MSM_HN12247",
 "IBBS3_MSM_HN12248","IBBS3_MSM_HN12249","IBBS3_MSM_HN12250",
 "IBBS3_MSM_HN12251","IBBS3_MSM_HN12252","IBBS3_MSM_HN12253",
 "IBBS3_MSM_HN12254","IBBS3_MSM_HN12255","IBBS3_MSM_HN25256",
 "IBBS3_MSM_HN25257","IBBS3_MSM_HN25258","IBBS3_MSM_HN25259",
"IBBS3_MSM_HN25260","IBBS3_MSM_HN25261","IBBS3_MSM_HN25262",
"IBBS3_MSM_HN25263","IBBS3_MSM_HN25264","IBBS3_MSM_HN25265",
"IBBS3_MSM_HN25266","IBBS3_MSM_HN25267","IBBS3_MSM_HN25268",
"IBBS3_MSM_HN25269","IBBS3_MSM_HN25270","IBBS3_MSM_HN25271",
"IBBS3_MSM_HN25272","IBBS3_MSM_HN25273","IBBS3_MSM_HN25274",
"IBBS3_MSM_HN25275","IBBS3_MSM_HN25276", "IBBS3_MSM_HN25277", "IBBS3_MSM_HN25278","IBBS3_MSM_HN25279","IBBS3_MSM_HN25280",
"IBBS3_MSM_HN25281","IBBS3_MSM_HN25282","IBBS3_MSM_HN25283",
"IBBS3_MSM_HN25284","IBBS3_MSM_HMC44285",  "IBBS3_MSM_HMC44286", "IBBS3_MSM_HMC44287","IBBS3_MSM_HMC44288","IBBS3_MSM_HMC44289",
"IBBS3_MSM_HMC44290","IBBS3_MSM_HMC44291","IBBS3_MSM_HMC44292",
"IBBS3_MSM_HMC44293","IBBS3_MSM_HMC44294","IBBS3_MSM_HMC44295",
"IBBS3_MSM_HMC44296","IBBS3_MSM_HMC44297","IBBS3_MSM_HMC44298",
"IBBS3_MSM_HMC44299","IBBS3_MSM_HMC44300","IBBS3_MSM_HMC44301",
"IBBS3_MSM_HMC44302","IBBS3_MSM_HMC44303","IBBS3_MSM_HMC44304",
"IBBS3_MSM_HMC44305","IBBS3_MSM_HMC44306","IBBS3_MSM_HMC44307",
"IBBS3_MSM_HMC44309")




This is an ID that is in the following format:  IBBS3_Type_Group#####


What I want to do is locate the starting position of Type, which is anywhere from 3 to 4 letters long (in this example it's either MSM or PWID), the starting position of Group which is 2-3 letters long (either HN or HMC), and finally the starting position of the 5-digit number.


I'm able to get Type and Group using the following:


TYPE_s <- sapply(c("MSM", "PWID"), regexpr, ID, ignore.case=T)

GROUP_s <- (sapply(c("HN", "HMC"), regexpr, ID, ignore.case=T))


What I am having trouble with is getting the starting position of the 5-digit number.


I am trying:


DIGITS_s <- sapply("([0:9])", regexpr, ID, ignore.case=T)


But that just seems to look for the position of the first 0.:


> DIGITS_s

       ([0:9])

  [1,]      13

  [2,]      13

  [3,]      13

  [4,]      14

  [5,]      14

  [6,]      14

  [7,]      -1

  [8,]      -1

  [9,]      -1

 [10,]      -1

 [11,]      17

 [12,]      17

 [13,]      -1

 [14,]      -1

 [15,]      -1

 [16,]      -1

 [17,]      -1

 [18,]      -1

 [19,]      -1

 [20,]      -1

 [21,]      17

 [22,]      17

 [23,]      -1

 [24,]      -1

 [25,]      -1

 [26,]      -1

 [27,]      -1

 [28,]      -1

 [29,]      -1

 [30,]      -1

 [31,]      17

 [32,]      17

 [33,]      -1

 [34,]      -1

 [35,]      -1

 [36,]      -1

 [37,]      -1

 [38,]      -1

 [39,]      -1

 [40,]      -1

 [41,]      17

 [42,]      17

 [43,]      -1

 [44,]      -1

 [45,]      -1

 [46,]      -1

 [47,]      -1

 [48,]      -1

 [49,]      -1

 [50,]      -1

 [51,]      17

 [52,]      17

 [53,]      -1

 [54,]      -1

 [55,]      -1

 [56,]      -1

 [57,]      -1

 [58,]      -1

 [59,]      -1

 [60,]      -1

 [61,]      17

 [62,]      17

 [63,]      -1

 [64,]      -1

 [65,]      -1

 [66,]      -1

 [67,]      -1

 [68,]      -1

 [69,]      -1

 [70,]      -1

 [71,]      17

 [72,]      17

 [73,]      -1

 [74,]      -1

 [75,]      -1

 [76,]      -1

 [77,]      -1

 [78,]      -1

 [79,]      -1

 [80,]      -1

 [81,]      18

 [82,]      17

 [83,]      17

 [84,]      17

 [85,]      17

 [86,]      17

 [87,]      17

 [88,]      17

 [89,]      17

 [90,]      17

 [91,]      17

 [92,]      17

 [93,]      17

 [94,]      17

 [95,]      17

 [96,]      17

 [97,]      17

 [98,]      17

 [99,]      17

[100,]      17


So, clearly, this is wrong.  I just would like to find the starting position of the first digit, no matter what it is.

It's probably easy, isn't it?

Best,

Jen

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From captiva24 at yahoo.com  Mon Nov  2 20:49:01 2015
From: captiva24 at yahoo.com (Zahra)
Date: Mon, 2 Nov 2015 11:49:01 -0800
Subject: [R] replace NA's with row means for specific columns
Message-ID: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>

Hi there,

I am looking for some help replacing missing values in R with the row mean. This is survey data and I am trying to impute values for missing variables in each set of questions separately using the mean of the scores for the other questions within that set. 

I have a dataset that looks like this

ID      A1    A2    A3          B1     B2     B3         C1   C2   C3    C4
b        4       5      NA          2       NA      4          5      1        3      NA
c        4       5      1            NA      3        4          5      1        3      2
d       NA     5      1            1        NA      4          5      1        3      2
e        4       5      4            5       NA      4           5      1        3      2


I want to replace any NA's in columns A1:A3 with the row mean for those columns only. So for ID=b, I want the NA in A3[ID=b] to be (4+5)/2 which is the average of the values in A1 and A2 for that row. 
Same thing for columns B1:B3 - I want the NA in B2[ID=b] to be the mean of the values of B1 and B3 in row ID=b so that B2[ID=b] becomes 3 which is (2+4)/2. And same in C1:C4, I want C4[ID=b] to become (5+1+3)/3 which is the mean of C1:C3. 

Then I want to go to row ID=c and do the same thing and so on.

Can anybody help me do this? I have tried using rowMeans and subsetting but can't figure out the right code to do it. 

Thanks so much.
Zahra


From cute_loomaa at hotmail.com  Mon Nov  2 20:58:56 2015
From: cute_loomaa at hotmail.com (hms Dreams)
Date: Mon, 2 Nov 2015 22:58:56 +0300
Subject: [R] estimate reliability and hazard using MOM and Baysian methods
Message-ID: <DUB128-W68BCC768E4F4DD1121B3A1962C0@phx.gbl>

Hi,
I estimate 3 paramters using MOM and Bayesian methods 
How can I estimate the reliability(R) and hazard(h) functions??
Is it correct if I estimated R and h like MLE by substitute the estimators and put any value for x in the formula of R and h??
I need help please
thank you
noor
 
 

 
 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Nov  2 22:33:56 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 2 Nov 2015 13:33:56 -0800 (PST)
Subject: [R] Locating the starting position of the first number in a
 string
In-Reply-To: <E41B375B7520DE4A8C60781AC60B7545067CBF011F@AKLEXM01.PFR.CO.NZ>
References: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>
	<E41B375B7520DE4A8C60781AC60B7545067CBF011F@AKLEXM01.PFR.CO.NZ>
Message-ID: <alpine.BSF.2.00.1511021330030.26362@pedal.dcn.davis.ca.us>

Also not answering your question directly, but may be provide some useful 
ideas or results:

> library( gsubfn )
>
> DF <- setNames( data.frame( t( strapply( ID
+                                        , "^[^_]+_([A-Z]+)_([A-Z]+)([0-9]+)$"
+                                        , c
+                                        , simplify=TRUE
+                                        )
+                              )
+                           , stringsAsFactors = FALSE
+                           )
+               , c( "Type", "Group", "Number" )
+               )
> str( DF )
'data.frame':   100 obs. of  3 variables:
  $ Type  : chr  "MSM" "MSM" "MSM" "MSM" ...
  $ Group : chr  "HN" "HN" "HN" "HN" ...
  $ Number: chr  "01209" "01210" "01211" "10212" ...

On Tue, 3 Nov 2015, Peter Alspach wrote:

> Tena koe Jen
>
> Not answering your question: if you are after these locations in order to split the IDs in columns, then you might like to consider strsplit; e.g.,
>
> t(sapply(strsplit(ID, '_'), rbind))
>
> You could then split the last column.  You state that there is a 5-digit number at the end.  If this is correct, then use this feature (i.e., nchar(ID)-4) as you'd want "IBBS3_MSM_HN104213" (the fifth element in ID) to split to IBBS3, MSM, HN1 and 04213.  However, if it isn't always 5 digits then split at the first number (i.e., HN and 104213).
>
> HTH .....
>
> Peter Alspach
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jennifer Sabatier
> Sent: Tuesday, 3 November 2015 7:39 a.m.
> To: r-help at r-project.org
> Subject: [R] Locating the starting position of the first number in a string
>
> Hi,
>
>
> So, I've got a vector of strings that look like this:
> ID <- c("IBBS3_MSM_HN01209","IBBS3_MSM_HN01210","IBBS3_MSM_HN01211",
> "IBBS3_MSM_HN10212","IBBS3_MSM_HN104213","IBBS3_MSM_HN10214",
> "IBBS3_MSM_HN44215","IBBS3_MSM_HN44216","IBBS3_MSM_HN44217",
> "IBBS3_MSM_HN44218","IBBS3_MSM_HN44219","IBBS3_MSM_HN44220",
> "IBBS3_MSM_HN44221","IBBS3_MSM_HN44222","IBBS3_MSM_HN44223",
> "IBBS3_MSM_HN44224","IBBS3_MSM_HN44225","IBBS3_MSM_HN44226",
> "IBBS3_MSM_HN44227","IBBS3_MSM_HN12228","IBBS3_MSM_HN12229",
> "IBBS3_MSM_HN12230","IBBS3_MSM_HN12231","IBBS3_MSM_HN12232",
> "IBBS3_MSM_HN12233","IBBS3_MSM_HN12234","IBBS3_MSM_HN12235",
> "IBBS3_MSM_HN12236","IBBS3_MSM_HN12237","IBBS3_MSM_HN12238",
> "IBBS3_MSM_HN12239","IBBS3_MSM_HN12240","IBBS3_MSM_HN12241",
> "IBBS3_MSM_HN12242","IBBS3_MSM_HN12243","IBBS3_MSM_HN12244",
> "IBBS3_MSM_HN12245","IBBS3_MSM_HN12246","IBBS3_MSM_HN12247",
> "IBBS3_MSM_HN12248","IBBS3_MSM_HN12249","IBBS3_MSM_HN12250",
> "IBBS3_MSM_HN12251","IBBS3_MSM_HN12252","IBBS3_MSM_HN12253",
> "IBBS3_MSM_HN12254","IBBS3_MSM_HN12255","IBBS3_MSM_HN25256",
> "IBBS3_MSM_HN25257","IBBS3_MSM_HN25258","IBBS3_MSM_HN25259",
> "IBBS3_MSM_HN25260","IBBS3_MSM_HN25261","IBBS3_MSM_HN25262",
> "IBBS3_MSM_HN25263","IBBS3_MSM_HN25264","IBBS3_MSM_HN25265",
> "IBBS3_MSM_HN25266","IBBS3_MSM_HN25267","IBBS3_MSM_HN25268",
> "IBBS3_MSM_HN25269","IBBS3_MSM_HN25270","IBBS3_MSM_HN25271",
> "IBBS3_MSM_HN25272","IBBS3_MSM_HN25273","IBBS3_MSM_HN25274",
> "IBBS3_MSM_HN25275","IBBS3_MSM_HN25276", "IBBS3_MSM_HN25277", "IBBS3_MSM_HN25278","IBBS3_MSM_HN25279","IBBS3_MSM_HN25280",
> "IBBS3_MSM_HN25281","IBBS3_MSM_HN25282","IBBS3_MSM_HN25283",
> "IBBS3_MSM_HN25284","IBBS3_MSM_HMC44285",  "IBBS3_MSM_HMC44286", "IBBS3_MSM_HMC44287","IBBS3_MSM_HMC44288","IBBS3_MSM_HMC44289",
> "IBBS3_MSM_HMC44290","IBBS3_MSM_HMC44291","IBBS3_MSM_HMC44292",
> "IBBS3_MSM_HMC44293","IBBS3_MSM_HMC44294","IBBS3_MSM_HMC44295",
> "IBBS3_MSM_HMC44296","IBBS3_MSM_HMC44297","IBBS3_MSM_HMC44298",
> "IBBS3_MSM_HMC44299","IBBS3_MSM_HMC44300","IBBS3_MSM_HMC44301",
> "IBBS3_MSM_HMC44302","IBBS3_MSM_HMC44303","IBBS3_MSM_HMC44304",
> "IBBS3_MSM_HMC44305","IBBS3_MSM_HMC44306","IBBS3_MSM_HMC44307",
> "IBBS3_MSM_HMC44309")
>
>
>
>
> This is an ID that is in the following format:  IBBS3_Type_Group#####
>
>
> What I want to do is locate the starting position of Type, which is anywhere from 3 to 4 letters long (in this example it's either MSM or PWID), the starting position of Group which is 2-3 letters long (either HN or HMC), and finally the starting position of the 5-digit number.
>
>
> I'm able to get Type and Group using the following:
>
>
> TYPE_s <- sapply(c("MSM", "PWID"), regexpr, ID, ignore.case=T)
>
> GROUP_s <- (sapply(c("HN", "HMC"), regexpr, ID, ignore.case=T))
>
>
> What I am having trouble with is getting the starting position of the 5-digit number.
>
>
> I am trying:
>
>
> DIGITS_s <- sapply("([0:9])", regexpr, ID, ignore.case=T)
>
>
> But that just seems to look for the position of the first 0.:
>
>
>> DIGITS_s
>
>       ([0:9])
>
>  [1,]      13
>
>  [2,]      13
>
>  [3,]      13
>
>  [4,]      14
>
>  [5,]      14
>
>  [6,]      14
>
>  [7,]      -1
>
>  [8,]      -1
>
>  [9,]      -1
>
> [10,]      -1
>
> [11,]      17
>
> [12,]      17
>
> [13,]      -1
>
> [14,]      -1
>
> [15,]      -1
>
> [16,]      -1
>
> [17,]      -1
>
> [18,]      -1
>
> [19,]      -1
>
> [20,]      -1
>
> [21,]      17
>
> [22,]      17
>
> [23,]      -1
>
> [24,]      -1
>
> [25,]      -1
>
> [26,]      -1
>
> [27,]      -1
>
> [28,]      -1
>
> [29,]      -1
>
> [30,]      -1
>
> [31,]      17
>
> [32,]      17
>
> [33,]      -1
>
> [34,]      -1
>
> [35,]      -1
>
> [36,]      -1
>
> [37,]      -1
>
> [38,]      -1
>
> [39,]      -1
>
> [40,]      -1
>
> [41,]      17
>
> [42,]      17
>
> [43,]      -1
>
> [44,]      -1
>
> [45,]      -1
>
> [46,]      -1
>
> [47,]      -1
>
> [48,]      -1
>
> [49,]      -1
>
> [50,]      -1
>
> [51,]      17
>
> [52,]      17
>
> [53,]      -1
>
> [54,]      -1
>
> [55,]      -1
>
> [56,]      -1
>
> [57,]      -1
>
> [58,]      -1
>
> [59,]      -1
>
> [60,]      -1
>
> [61,]      17
>
> [62,]      17
>
> [63,]      -1
>
> [64,]      -1
>
> [65,]      -1
>
> [66,]      -1
>
> [67,]      -1
>
> [68,]      -1
>
> [69,]      -1
>
> [70,]      -1
>
> [71,]      17
>
> [72,]      17
>
> [73,]      -1
>
> [74,]      -1
>
> [75,]      -1
>
> [76,]      -1
>
> [77,]      -1
>
> [78,]      -1
>
> [79,]      -1
>
> [80,]      -1
>
> [81,]      18
>
> [82,]      17
>
> [83,]      17
>
> [84,]      17
>
> [85,]      17
>
> [86,]      17
>
> [87,]      17
>
> [88,]      17
>
> [89,]      17
>
> [90,]      17
>
> [91,]      17
>
> [92,]      17
>
> [93,]      17
>
> [94,]      17
>
> [95,]      17
>
> [96,]      17
>
> [97,]      17
>
> [98,]      17
>
> [99,]      17
>
> [100,]      17
>
>
> So, clearly, this is wrong.  I just would like to find the starting position of the first digit, no matter what it is.
>
> It's probably easy, isn't it?
>
> Best,
>
> Jen
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be ...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bgunter.4567 at gmail.com  Mon Nov  2 23:09:12 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 2 Nov 2015 14:09:12 -0800
Subject: [R] estimate reliability and hazard using MOM and Baysian
	methods
In-Reply-To: <DUB128-W68BCC768E4F4DD1121B3A1962C0@phx.gbl>
References: <DUB128-W68BCC768E4F4DD1121B3A1962C0@phx.gbl>
Message-ID: <CAGxFJbRp2Tn0G7-q0bKqPx78H3f1ZkYUb6ToxCsbZ0qzj=t8-A@mail.gmail.com>

I suggest you seek local assistance. I find your question to be
completely incoherent (perhaps others will do better). You also seem
to be pretty ignorant of basic statistics. Apologies if I have
misunderstood, but if I am close to right in these matters, you will
need to find local help, as internet advice is likely to be
inadequate, subject to your misunderstanding, and likely to result in
incorrect analysis.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 2, 2015 at 11:58 AM, hms Dreams <cute_loomaa at hotmail.com> wrote:
> Hi,
> I estimate 3 paramters using MOM and Bayesian methods
> How can I estimate the reliability(R) and hazard(h) functions??
> Is it correct if I estimated R and h like MLE by substitute the estimators and put any value for x in the formula of R and h??
> I need help please
> thank you
> noor
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Mon Nov  2 23:36:37 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Nov 2015 11:36:37 +1300
Subject: [R] What happened to Canada?
In-Reply-To: <0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
Message-ID: <5637E575.7040306@auckland.ac.nz>


On 03/11/15 01:41, Marc Schwartz wrote:

>
>> On Nov 2, 2015, at 6:00 AM, John Kane <jrkrideau at inbox.com> wrote:
>>
>> A rather silly question but I went to install a new package this
>> morning and as usual a list of CRAN mirrors appeared but the
>> Canadian ones had disappeared.
>>
>> Is this some peculiarity of my system (Ubuntu 14.10 with R version
>> 3.2.2)  or a new policy for R?
>>
>>
>> John Kane Kingston ON Canada
>
>
> Hi John,
>
> Presuming that the CRAN mirror list online is current, there do not
> appear to be any CRAN mirrors in Canada which support secure HTTP
> (HTTPS), which is now the default in 3.2.2.
>
> See the announcement from August 14 (SIGNIFICANT USER-VISIBLE CHANGES
> and NEW FEATURES):
>
> https://stat.ethz.ch/pipermail/r-announce/2015/000589.html
>
> See ?chooseCRANmirror for more information.
>
> When you get a list of mirrors to select, by default the top of the
> list will include mirrors that support HTTPS. The last entry on the
> list should be (HTTP mirrors). Click that and it will bring up a list
> of additional mirrors, including Canadian locations, that support
> HTTP.

Out of idle curiosity I started playing around with this stuff and ran 
into a puzzling phenomenon.

When I execute

     chooseCRANmirror()

I get an error message:

> Error in download.file(url, destfile = f, quiet = TRUE) :
>   unsupported URL scheme

Nevertheless a menu appears, with "(HTTP mirrors)" at the bottom, just 
as you said.

I don't understand why chooseCRANmirror() still works despite the error 
being thrown.

Tracing through what chooseCRANmirror() does I reduced the problem to:

     u <- "https://cran.r-project.org/CRAN_mirrors.csv"
     download.file(u,destfile="junk")

which throws the error

> Error in download.file(u, destfile = "junk") : unsupported URL scheme

If I replace the "https" in the url by "http" then things run without an 
error being thrown.

There is no immediate problem for me, since I can install packages from 
CRAN OK, using my usual New Zealand mirror (which is an http mirror).

If I try to use one of the https mirrors that are shown by 
chooseCRANmirror() (e.g. Austria) then I get a warning:

> Warning: unable to access index for repository
> https://cran.r-project.org/src/contrib

and the install goes back to using the New Zealand mirror.

So there seems to be something not quite right with my system or with my 
installation of R.  Although, as I said, there is no immediate problem, 
the fact that something is not quite right worries me.

Can you (Marc) or anyone else suggest what might be the problem and how 
to fix it, or at least track it down a bit more explicitly?

Here's my

 > sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Fedora 17 (Beefy Miracle)

locale:
  [1] LC_CTYPE=en_NZ.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.utf8        LC_COLLATE=en_NZ.utf8
  [5] LC_MONETARY=en_NZ.utf8    LC_MESSAGES=en_NZ.utf8
  [7] LC_PAPER=en_NZ.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] misc_0.0-16

loaded via a namespace (and not attached):
  [1] deldir_0.1-9        Matrix_1.1-4        mgcv_1.8-7
  [4] abind_1.4-0         spatstat_1.43-0.007 nlme_3.1-121
  [7] grid_3.2.2          polyclip_1.3-1      lattice_0.20-33
[10] goftest_1.0-2       tensor_1.5

Ta.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From marc_schwartz at me.com  Tue Nov  3 00:09:14 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 02 Nov 2015 17:09:14 -0600
Subject: [R] What happened to Canada?
In-Reply-To: <5637E575.7040306@auckland.ac.nz>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>
Message-ID: <A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>


> On Nov 2, 2015, at 4:36 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 03/11/15 01:41, Marc Schwartz wrote:
> 
>> 
>>> On Nov 2, 2015, at 6:00 AM, John Kane <jrkrideau at inbox.com> wrote:
>>> 
>>> A rather silly question but I went to install a new package this
>>> morning and as usual a list of CRAN mirrors appeared but the
>>> Canadian ones had disappeared.
>>> 
>>> Is this some peculiarity of my system (Ubuntu 14.10 with R version
>>> 3.2.2)  or a new policy for R?
>>> 
>>> 
>>> John Kane Kingston ON Canada
>> 
>> 
>> Hi John,
>> 
>> Presuming that the CRAN mirror list online is current, there do not
>> appear to be any CRAN mirrors in Canada which support secure HTTP
>> (HTTPS), which is now the default in 3.2.2.
>> 
>> See the announcement from August 14 (SIGNIFICANT USER-VISIBLE CHANGES
>> and NEW FEATURES):
>> 
>> https://stat.ethz.ch/pipermail/r-announce/2015/000589.html
>> 
>> See ?chooseCRANmirror for more information.
>> 
>> When you get a list of mirrors to select, by default the top of the
>> list will include mirrors that support HTTPS. The last entry on the
>> list should be (HTTP mirrors). Click that and it will bring up a list
>> of additional mirrors, including Canadian locations, that support
>> HTTP.
> 
> Out of idle curiosity I started playing around with this stuff and ran into a puzzling phenomenon.
> 
> When I execute
> 
>    chooseCRANmirror()
> 
> I get an error message:
> 
>> Error in download.file(url, destfile = f, quiet = TRUE) :
>>  unsupported URL scheme
> 
> Nevertheless a menu appears, with "(HTTP mirrors)" at the bottom, just as you said.
> 
> I don't understand why chooseCRANmirror() still works despite the error being thrown.
> 
> Tracing through what chooseCRANmirror() does I reduced the problem to:
> 
>    u <- "https://cran.r-project.org/CRAN_mirrors.csv"
>    download.file(u,destfile="junk")
> 
> which throws the error
> 
>> Error in download.file(u, destfile = "junk") : unsupported URL scheme
> 
> If I replace the "https" in the url by "http" then things run without an error being thrown.
> 
> There is no immediate problem for me, since I can install packages from CRAN OK, using my usual New Zealand mirror (which is an http mirror).
> 
> If I try to use one of the https mirrors that are shown by chooseCRANmirror() (e.g. Austria) then I get a warning:
> 
>> Warning: unable to access index for repository
>> https://cran.r-project.org/src/contrib
> 
> and the install goes back to using the New Zealand mirror.
> 
> So there seems to be something not quite right with my system or with my installation of R.  Although, as I said, there is no immediate problem, the fact that something is not quite right worries me.
> 
> Can you (Marc) or anyone else suggest what might be the problem and how to fix it, or at least track it down a bit more explicitly?
> 
> Here's my

<snip>

> 
> 
> Ta.
> 
> cheers,
> 
> Rolf


Rolf,

What do:

  getOption("CRAN")

  getOption("repos")

show?

Is there any chance that you have something set in ~/.Rprofile pertaining to CRAN mirrors or are loading some packages that might conflict?

I would try it with a vanilla R session (e.g. 'R --vanilla').

If it works then, there is something getting loaded or set at session start that may be conflicting.

Here is my default sessionInfo() when I first start R from the CLI:

R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.1 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     


Regards,

Marc


From drjimlemon at gmail.com  Tue Nov  3 00:26:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Nov 2015 10:26:57 +1100
Subject: [R] replace NA's with row means for specific columns
In-Reply-To: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
References: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
Message-ID: <CA+8X3fW41q0FnPbg40dHpsrTrR-CmC_JvmbAtGdStuXDOZViRw@mail.gmail.com>

Hi Zahra,
I can't think of an "apply" function that will do this, but:

Zdf<-read.table(text="ID  A1 A2 A3   B1 B2  B3   C1 C2  C3   C4
b      4     5      NA        2       NA      4         5      1        3
   NA
c      4     5      1          NA      3        4         5      1        3
     2
d     NA   5      1          1        NA      4         5      1        3
   2
e      4     5      4          5       NA      4          5      1        3
     2",
header=TRUE)

Zdf

replace_NAs<-function(x,group_lab=c("A","B","C")) {
 for(lab in group_lab) {
  indices<-grep(lab,names(x),fixed=TRUE)
  na_indices<-is.na(x[indices])
  if(any(indices))
   x[indices][na_indices]<-rowMeans(x[indices],na.rm=TRUE)
 }
 return(x)
}

for(row in 1:dim(Zdf)[1]) Zdf[row,]<-replace_NAs(Zdf[row,])

Zdf

Jim

On Tue, Nov 3, 2015 at 6:49 AM, Zahra via R-help <r-help at r-project.org>
wrote:

> Hi there,
>
> I am looking for some help replacing missing values in R with the row
> mean. This is survey data and I am trying to impute values for missing
> variables in each set of questions separately using the mean of the scores
> for the other questions within that set.
>
> I have a dataset that looks like this
>
> ID      A1    A2    A3          B1     B2     B3         C1   C2   C3    C4
> b        4       5      NA          2       NA      4          5      1
>     3      NA
> c        4       5      1            NA      3        4          5      1
>       3      2
> d       NA     5      1            1        NA      4          5      1
>     3      2
> e        4       5      4            5       NA      4           5      1
>       3      2
>
>
> I want to replace any NA's in columns A1:A3 with the row mean for those
> columns only. So for ID=b, I want the NA in A3[ID=b] to be (4+5)/2 which is
> the average of the values in A1 and A2 for that row.
> Same thing for columns B1:B3 - I want the NA in B2[ID=b] to be the mean of
> the values of B1 and B3 in row ID=b so that B2[ID=b] becomes 3 which is
> (2+4)/2. And same in C1:C4, I want C4[ID=b] to become (5+1+3)/3 which is
> the mean of C1:C3.
>
> Then I want to go to row ID=c and do the same thing and so on.
>
> Can anybody help me do this? I have tried using rowMeans and subsetting
> but can't figure out the right code to do it.
>
> Thanks so much.
> Zahra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Martin.Morgan at roswellpark.org  Tue Nov  3 00:30:48 2015
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Mon, 2 Nov 2015 23:30:48 +0000
Subject: [R] What happened to Canada?
In-Reply-To: <A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>,
	<A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
Message-ID: <DF23DAC5A53912408040FF04D8B780AAE231EC@EXMB3RSC.roswellpark.org>

The first error, about 'unsupported scheme' is saying that you (your R) does not have SSL support (as you tracked down, the problem is trying to read the online repositories using https://, and the 'unsupported scheme' is https). The code then goes on and uses the snapshot of mirrors available at the time your R was installed by reading a local file.

Your R may be using the 'internal' method (which does not support https) or a libcurl without SSL support. I have

> capabilities()["libcurl"]   # ok, using libcurl
libcurl 
   TRUE 

and my libcurl supports SSL

$ curl-config --features
SSL
IPv6
libz
AsynchDNS
IDN
NTLM
NTLM_WB
TLS-SRP

I got SSL capability through the package

$ dpkg --get-selections |grep libcurl4
libcurl4-openssl-dev:amd64			install

Your R might have been compiled without libcurl  (depending on how you installed R and the libraries present at installation time), or with a libcurl that does not have SSL. In the mean time, you can quieten things (and live insecurely) with options(useHTTPS=FALSE).

There is some discussion in ?download.file for the `method` argument.

Martin Morgan
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Marc Schwartz [marc_schwartz at me.com]
Sent: Monday, November 02, 2015 6:09 PM
To: Rolf Turner
Cc: R-help
Subject: Re: [R] What happened to Canada?

> On Nov 2, 2015, at 4:36 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On 03/11/15 01:41, Marc Schwartz wrote:
>
>>
>>> On Nov 2, 2015, at 6:00 AM, John Kane <jrkrideau at inbox.com> wrote:
>>>
>>> A rather silly question but I went to install a new package this
>>> morning and as usual a list of CRAN mirrors appeared but the
>>> Canadian ones had disappeared.
>>>
>>> Is this some peculiarity of my system (Ubuntu 14.10 with R version
>>> 3.2.2)  or a new policy for R?
>>>
>>>
>>> John Kane Kingston ON Canada
>>
>>
>> Hi John,
>>
>> Presuming that the CRAN mirror list online is current, there do not
>> appear to be any CRAN mirrors in Canada which support secure HTTP
>> (HTTPS), which is now the default in 3.2.2.
>>
>> See the announcement from August 14 (SIGNIFICANT USER-VISIBLE CHANGES
>> and NEW FEATURES):
>>
>> https://stat.ethz.ch/pipermail/r-announce/2015/000589.html
>>
>> See ?chooseCRANmirror for more information.
>>
>> When you get a list of mirrors to select, by default the top of the
>> list will include mirrors that support HTTPS. The last entry on the
>> list should be (HTTP mirrors). Click that and it will bring up a list
>> of additional mirrors, including Canadian locations, that support
>> HTTP.
>
> Out of idle curiosity I started playing around with this stuff and ran into a puzzling phenomenon.
>
> When I execute
>
>    chooseCRANmirror()
>
> I get an error message:
>
>> Error in download.file(url, destfile = f, quiet = TRUE) :
>>  unsupported URL scheme
>
> Nevertheless a menu appears, with "(HTTP mirrors)" at the bottom, just as you said.
>
> I don't understand why chooseCRANmirror() still works despite the error being thrown.
>
> Tracing through what chooseCRANmirror() does I reduced the problem to:
>
>    u <- "https://cran.r-project.org/CRAN_mirrors.csv"
>    download.file(u,destfile="junk")
>
> which throws the error
>
>> Error in download.file(u, destfile = "junk") : unsupported URL scheme
>
> If I replace the "https" in the url by "http" then things run without an error being thrown.
>
> There is no immediate problem for me, since I can install packages from CRAN OK, using my usual New Zealand mirror (which is an http mirror).
>
> If I try to use one of the https mirrors that are shown by chooseCRANmirror() (e.g. Austria) then I get a warning:
>
>> Warning: unable to access index for repository
>> https://cran.r-project.org/src/contrib
>
> and the install goes back to using the New Zealand mirror.
>
> So there seems to be something not quite right with my system or with my installation of R.  Although, as I said, there is no immediate problem, the fact that something is not quite right worries me.
>
> Can you (Marc) or anyone else suggest what might be the problem and how to fix it, or at least track it down a bit more explicitly?
>
> Here's my

<snip>

>
>
> Ta.
>
> cheers,
>
> Rolf


Rolf,

What do:

  getOption("CRAN")

  getOption("repos")

show?

Is there any chance that you have something set in ~/.Rprofile pertaining to CRAN mirrors or are loading some packages that might conflict?

I would try it with a vanilla R session (e.g. 'R --vanilla').

If it works then, there is something getting loaded or set at session start that may be conflicting.

Here is my default sessionInfo() when I first start R from the CLI:

R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11.1 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods
[7] base


Regards,

Marc

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From drjimlemon at gmail.com  Tue Nov  3 00:33:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Nov 2015 10:33:23 +1100
Subject: [R] replace NA's with row means for specific columns
In-Reply-To: <CA+8X3fW41q0FnPbg40dHpsrTrR-CmC_JvmbAtGdStuXDOZViRw@mail.gmail.com>
References: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
	<CA+8X3fW41q0FnPbg40dHpsrTrR-CmC_JvmbAtGdStuXDOZViRw@mail.gmail.com>
Message-ID: <CA+8X3fVeeCGE3-gBui2rHL5ka=-v3K-FfKnJ9Zymai9g9SL9Ag@mail.gmail.com>

Hi again,
Small typo in line 5 - should be

replace_NAs<-function(x,group_lab=c("A","B","C")) {
 for(lab in group_lab) {
  indices<-grep(lab,names(x),fixed=TRUE)
  na_indices<-is.na(x[indices])
  if(any(na_indices))
   x[indices][na_indices]<-rowMeans(x[indices],na.rm=TRUE)
 }
 return(x)
}

Jim

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Nov  3 00:40:37 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Nov 2015 12:40:37 +1300
Subject: [R] What happened to Canada?
In-Reply-To: <A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>
	<A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
Message-ID: <5637F475.7000600@auckland.ac.nz>


Thanks for the reply, Marc.

On 03/11/15 12:09, Marc Schwartz wrote:

<SNIP>

>
> Rolf,
>
> What do:
>
>    getOption("CRAN")
>
>    getOption("repos")
>
> show?

The first shows "NULL", the second shows

> "http://cran.stat.auckland.ac.nz"

> Is there any chance that you have something set in ~/.Rprofile
> pertaining to CRAN mirrors or are loading some packages that might conflict?

Indeed.  I have "repos" set (as seen above) in my .Rprofile.

> I would try it with a vanilla R session (e.g. 'R --vanilla').

I had already tried "R --vanilla" and got the same effect.  I.e. I got 
the same error from chooseCRANmirror() but nevertheless the menu 
appeared, just as before.

This time, at your prompting, I tried to install a package under
"R --vanilla":

> install.packages("circular",lib="/home/rolf/Rlib")

I got the following warning message(s):

> Warning: unable to access index for repository
> https://cran.r-project.org/src/contrib
> Warning message:
> package ?circular? is not available (for R version 3.2.2)

(That last warning is certainly not true.)

Note that this was *after* having chosen the Austria mirror from the 
menu presented by chooseCRANmirror().

Before running chooseCRANmirror(), getOption("repos") produced:

>     CRAN
> "@CRAN@"

After running chooseCRANmirror(), getOption("repos") produced:

>                         CRAN
> "https://cran.r-project.org"

> If it works then, there is something getting loaded or set at session
> start that may be conflicting.

Well, it *doesn't* work, so setting "repos" in my .Rprofile was not the 
problem, or at least not the essence of the problem.

Any other ideas?  Ta.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From marc_schwartz at me.com  Tue Nov  3 00:52:54 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 02 Nov 2015 17:52:54 -0600
Subject: [R] What happened to Canada?
In-Reply-To: <5637F475.7000600@auckland.ac.nz>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>
	<A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
	<5637F475.7000600@auckland.ac.nz>
Message-ID: <B08DF06A-C717-4AD7-9960-CA7BD3993901@me.com>

Hi Rolf,

See below.


> On Nov 2, 2015, at 5:40 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> Thanks for the reply, Marc.
> 
> On 03/11/15 12:09, Marc Schwartz wrote:
> 
> <SNIP>
> 
>> 
>> Rolf,
>> 
>> What do:
>> 
>>   getOption("CRAN")
>> 
>>   getOption("repos")
>> 
>> show?
> 
> The first shows "NULL", the second shows
> 
>> "http://cran.stat.auckland.ac.nz"
> 
>> Is there any chance that you have something set in ~/.Rprofile
>> pertaining to CRAN mirrors or are loading some packages that might conflict?
> 
> Indeed.  I have "repos" set (as seen above) in my .Rprofile.
> 
>> I would try it with a vanilla R session (e.g. 'R --vanilla').
> 
> I had already tried "R --vanilla" and got the same effect.  I.e. I got the same error from chooseCRANmirror() but nevertheless the menu appeared, just as before.
> 
> This time, at your prompting, I tried to install a package under
> "R --vanilla":
> 
>> install.packages("circular",lib="/home/rolf/Rlib")
> 
> I got the following warning message(s):
> 
>> Warning: unable to access index for repository
>> https://cran.r-project.org/src/contrib
>> Warning message:
>> package ?circular? is not available (for R version 3.2.2)
> 
> (That last warning is certainly not true.)
> 
> Note that this was *after* having chosen the Austria mirror from the menu presented by chooseCRANmirror().
> 
> Before running chooseCRANmirror(), getOption("repos") produced:
> 
>>    CRAN
>> "@CRAN@"
> 
> After running chooseCRANmirror(), getOption("repos") produced:
> 
>>                        CRAN
>> "https://cran.r-project.org"
> 
>> If it works then, there is something getting loaded or set at session
>> start that may be conflicting.
> 
> Well, it *doesn't* work, so setting "repos" in my .Rprofile was not the problem, or at least not the essence of the problem.
> 
> Any other ideas?  Ta.
> 
> cheers,
> 
> Rolf


Martin Morgan's reply seems like it is on point.

I would follow his logic regarding libcurl and https support, but it would be helpful to know how you installed R.

Fedora 17 has been EOL'd for >2 years, so I am guessing that you installed from source, since the EPEL and most Fedora repos would not typically support EOL'd distros due to the risk of dated dependencies and version related incompatibilities.

That might suggest that the config/compilation incantation may not have used libcurl or not a version with https support enabled.

There are references/pointers pertaining to libcurl in the Installation and Administration manual.

Regards,

Marc


From boris.steipe at utoronto.ca  Tue Nov  3 01:18:02 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 2 Nov 2015 19:18:02 -0500
Subject: [R] Locating the starting position of the first number in a
	string
In-Reply-To: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>
References: <CAOxgQ=VZ6m9zn4UxqdOzTqQw4V_Bx=mgqA+JNAsjkNfjg0Nx9A@mail.gmail.com>
Message-ID: <71A36432-9886-48DB-883C-741B9BB82331@utoronto.ca>

The regular expression you are looking for is
  \d{5}
... a "digit" repeated five times.
Note that you have to escape the escape in an R string.

But your example does not conform to the description: you have examples with six digit numbers: IBBS3_MSM_HN104213.

If there is length variation, I would just search for 
   \d+     (at least one) or 
   \d{5,}  (at least five)


And even though you send a vector with some hundred elements, it doesn't actually contain the choices you are asking for ???
Finally, I'm not sure why you want the "starting" positions, rather than the keys you find.

Your sample code is not at all how one does this. Define the three elements that you want to capture, put them in parentheses and evaluate the matches that regexec() returns. Also give us a smaller example, but one that contains all of the relevant cases.


ID <- c(
"IBBS3_MSM_HN01209",
"IBBS3_PWID_HN01210",
"IBBS3_MSM_HMC01211",
"IBBS3_PWID_HMC10212")

# now consider the regular expression:
regexec(".+((MSM)|(PWID))_((HN)|(HMC))(\\d+)", ID[1])

# This is:
#   any character one or more times,
#   followed by either MSM OR PWID,
#   followed by an underscore, 
#   followed by either HN OR HMC,
#   followed by one or more digits

# Look at the result: it's a list. The first vector of each list element
# gives you the starting positions, the second one gives you the match lengths.

# Compare:
regexec(".+((MSM)|(PWID))_((HN)|(HMC))(\\d+)", ID[3])


# Following the logic of the nested parentheses,
# you are looking for matches in position 2, 5 and
# 8 of your expression.


result <- matrix(numeric(3 * length(ID)), ncol=3)
colnames(result) <- c("TYPE", "GROUP", "ID")

for (i in 1:length(ID)) {
     m <- regexec(".+((MSM)|(PWID))_((HN)|(HMC))(\\d+)", ID[i])
     result[i,] <- m[[1]][c(2, 5, 8)] # write the three starting
                                      # positions into a row
                                      # of your matrix 
}


# of course its trivial now to actually capture
# the keys but that's not what you asked for...



B.





On Nov 2, 2015, at 1:39 PM, Jennifer Sabatier <plessthanpointohfive at gmail.com> wrote:

> Hi,
> 
> 
> So, I've got a vector of strings that look like this:
> ID <- c("IBBS3_MSM_HN01209","IBBS3_MSM_HN01210","IBBS3_MSM_HN01211",
> "IBBS3_MSM_HN10212","IBBS3_MSM_HN104213","IBBS3_MSM_HN10214",
> "IBBS3_MSM_HN44215","IBBS3_MSM_HN44216","IBBS3_MSM_HN44217",
> "IBBS3_MSM_HN44218","IBBS3_MSM_HN44219","IBBS3_MSM_HN44220",
> "IBBS3_MSM_HN44221","IBBS3_MSM_HN44222","IBBS3_MSM_HN44223",
> "IBBS3_MSM_HN44224","IBBS3_MSM_HN44225","IBBS3_MSM_HN44226",
> "IBBS3_MSM_HN44227","IBBS3_MSM_HN12228","IBBS3_MSM_HN12229",
> "IBBS3_MSM_HN12230","IBBS3_MSM_HN12231","IBBS3_MSM_HN12232",
> "IBBS3_MSM_HN12233","IBBS3_MSM_HN12234","IBBS3_MSM_HN12235",
> "IBBS3_MSM_HN12236","IBBS3_MSM_HN12237","IBBS3_MSM_HN12238",
> "IBBS3_MSM_HN12239","IBBS3_MSM_HN12240","IBBS3_MSM_HN12241",
> "IBBS3_MSM_HN12242","IBBS3_MSM_HN12243","IBBS3_MSM_HN12244",
> "IBBS3_MSM_HN12245","IBBS3_MSM_HN12246","IBBS3_MSM_HN12247",
> "IBBS3_MSM_HN12248","IBBS3_MSM_HN12249","IBBS3_MSM_HN12250",
> "IBBS3_MSM_HN12251","IBBS3_MSM_HN12252","IBBS3_MSM_HN12253",
> "IBBS3_MSM_HN12254","IBBS3_MSM_HN12255","IBBS3_MSM_HN25256",
> "IBBS3_MSM_HN25257","IBBS3_MSM_HN25258","IBBS3_MSM_HN25259",
> "IBBS3_MSM_HN25260","IBBS3_MSM_HN25261","IBBS3_MSM_HN25262",
> "IBBS3_MSM_HN25263","IBBS3_MSM_HN25264","IBBS3_MSM_HN25265",
> "IBBS3_MSM_HN25266","IBBS3_MSM_HN25267","IBBS3_MSM_HN25268",
> "IBBS3_MSM_HN25269","IBBS3_MSM_HN25270","IBBS3_MSM_HN25271",
> "IBBS3_MSM_HN25272","IBBS3_MSM_HN25273","IBBS3_MSM_HN25274",
> "IBBS3_MSM_HN25275","IBBS3_MSM_HN25276", "IBBS3_MSM_HN25277",
> "IBBS3_MSM_HN25278","IBBS3_MSM_HN25279","IBBS3_MSM_HN25280",
> "IBBS3_MSM_HN25281","IBBS3_MSM_HN25282","IBBS3_MSM_HN25283",
> "IBBS3_MSM_HN25284","IBBS3_MSM_HMC44285",  "IBBS3_MSM_HMC44286",
> "IBBS3_MSM_HMC44287","IBBS3_MSM_HMC44288","IBBS3_MSM_HMC44289",
> "IBBS3_MSM_HMC44290","IBBS3_MSM_HMC44291","IBBS3_MSM_HMC44292",
> "IBBS3_MSM_HMC44293","IBBS3_MSM_HMC44294","IBBS3_MSM_HMC44295",
> "IBBS3_MSM_HMC44296","IBBS3_MSM_HMC44297","IBBS3_MSM_HMC44298",
> "IBBS3_MSM_HMC44299","IBBS3_MSM_HMC44300","IBBS3_MSM_HMC44301",
> "IBBS3_MSM_HMC44302","IBBS3_MSM_HMC44303","IBBS3_MSM_HMC44304",
> "IBBS3_MSM_HMC44305","IBBS3_MSM_HMC44306","IBBS3_MSM_HMC44307",
> "IBBS3_MSM_HMC44309")
> 
> 
> 
> 
> This is an ID that is in the following format:  IBBS3_Type_Group#####
> 
> 
> What I want to do is locate the starting position of Type, which is
> anywhere from 3 to 4 letters long (in this example it's either MSM or
> PWID), the starting position of Group which is 2-3 letters long (either HN
> or HMC), and finally the starting position of the 5-digit number.
> 
> 
> I'm able to get Type and Group using the following:
> 
> 
> TYPE_s <- sapply(c("MSM", "PWID"), regexpr, ID, ignore.case=T)
> 
> GROUP_s <- (sapply(c("HN", "HMC"), regexpr, ID, ignore.case=T))
> 
> 
> What I am having trouble with is getting the starting position of the
> 5-digit number.
> 
> 
> I am trying:
> 
> 
> DIGITS_s <- sapply("([0:9])", regexpr, ID, ignore.case=T)
> 
> 
> But that just seems to look for the position of the first 0.:
> 
> 
>> DIGITS_s
> 
>       ([0:9])
> 
>  [1,]      13
> 
>  [2,]      13
> 
>  [3,]      13
> 
>  [4,]      14
> 
>  [5,]      14
> 
>  [6,]      14
> 
>  [7,]      -1
> 
>  [8,]      -1
> 
>  [9,]      -1
> 
> [10,]      -1
> 
> [11,]      17
> 
> [12,]      17
> 
> [13,]      -1
> 
> [14,]      -1
> 
> [15,]      -1
> 
> [16,]      -1
> 
> [17,]      -1
> 
> [18,]      -1
> 
> [19,]      -1
> 
> [20,]      -1
> 
> [21,]      17
> 
> [22,]      17
> 
> [23,]      -1
> 
> [24,]      -1
> 
> [25,]      -1
> 
> [26,]      -1
> 
> [27,]      -1
> 
> [28,]      -1
> 
> [29,]      -1
> 
> [30,]      -1
> 
> [31,]      17
> 
> [32,]      17
> 
> [33,]      -1
> 
> [34,]      -1
> 
> [35,]      -1
> 
> [36,]      -1
> 
> [37,]      -1
> 
> [38,]      -1
> 
> [39,]      -1
> 
> [40,]      -1
> 
> [41,]      17
> 
> [42,]      17
> 
> [43,]      -1
> 
> [44,]      -1
> 
> [45,]      -1
> 
> [46,]      -1
> 
> [47,]      -1
> 
> [48,]      -1
> 
> [49,]      -1
> 
> [50,]      -1
> 
> [51,]      17
> 
> [52,]      17
> 
> [53,]      -1
> 
> [54,]      -1
> 
> [55,]      -1
> 
> [56,]      -1
> 
> [57,]      -1
> 
> [58,]      -1
> 
> [59,]      -1
> 
> [60,]      -1
> 
> [61,]      17
> 
> [62,]      17
> 
> [63,]      -1
> 
> [64,]      -1
> 
> [65,]      -1
> 
> [66,]      -1
> 
> [67,]      -1
> 
> [68,]      -1
> 
> [69,]      -1
> 
> [70,]      -1
> 
> [71,]      17
> 
> [72,]      17
> 
> [73,]      -1
> 
> [74,]      -1
> 
> [75,]      -1
> 
> [76,]      -1
> 
> [77,]      -1
> 
> [78,]      -1
> 
> [79,]      -1
> 
> [80,]      -1
> 
> [81,]      18
> 
> [82,]      17
> 
> [83,]      17
> 
> [84,]      17
> 
> [85,]      17
> 
> [86,]      17
> 
> [87,]      17
> 
> [88,]      17
> 
> [89,]      17
> 
> [90,]      17
> 
> [91,]      17
> 
> [92,]      17
> 
> [93,]      17
> 
> [94,]      17
> 
> [95,]      17
> 
> [96,]      17
> 
> [97,]      17
> 
> [98,]      17
> 
> [99,]      17
> 
> [100,]      17
> 
> 
> So, clearly, this is wrong.  I just would like to find the starting
> position of the first digit, no matter what it is.
> 
> It's probably easy, isn't it?
> 
> Best,
> 
> Jen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Nov  3 01:25:29 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Nov 2015 13:25:29 +1300
Subject: [R] What happened to Canada?
In-Reply-To: <DF23DAC5A53912408040FF04D8B780AAE231EC@EXMB3RSC.roswellpark.org>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>
	<A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
	<DF23DAC5A53912408040FF04D8B780AAE231EC@EXMB3RSC.roswellpark.org>
Message-ID: <5637FEF9.1030604@auckland.ac.nz>


Thanks Martin.  This is illuminating.

On 03/11/15 12:30, Morgan, Martin wrote:
> The first error, about 'unsupported scheme' is saying that you (your
> R) does not have SSL support (as you tracked down, the problem is
> trying to read the online repositories using https://, and the
> 'unsupported scheme' is https). The code then goes on and uses the
> snapshot of mirrors available at the time your R was installed by
> reading a local file.
>
> Your R may be using the 'internal' method (which does not support
> https) or a libcurl without SSL support. I have
>
>>   # ok, using libcurl
> libcurl TRUE

That seems to be the crux of the matter.  When I do

  capabilities()["libcurl"]

I get

libcurl
   FALSE

>
> and my libcurl supports SSL
>
> $ curl-config --features SSL IPv6 libz AsynchDNS IDN NTLM NTLM_WB
> TLS-SRP

It would seem that I have libcurl on my system.  When I do

$ curl-config --features

I get the same results that you show *except* for "TLS-SRP".

(Does the latter matter?)

>
> I got SSL capability through the package
>
> $ dpkg --get-selections |grep libcurl4 libcurl4-openssl-dev:amd64
> install
>
> Your R might have been compiled without libcurl  (depending on how
> you installed R and the libraries present at installation time), or
> with a libcurl that does not have SSL.

Well, I would seem to have installed R without libcurl capabilities.
So how *do* I get libcurl capabilities?

I would have thought something like

    ./configure --with-libcurl

would be called for, but doing ./configure --help produced nothing that 
involved "curl" at all.

Can you enlighten me? Ta.

In the mean time, you can
> quieten things (and live insecurely) with options(useHTTPS=FALSE).
>
> There is some discussion in ?download.file for the `method`
> argument.

As I have previously said, there are no real problems at the moment --- 
*except* for the fact that I am "living insecurely".  I don't like that,
and would prefer to do something about it.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From axel.urbiz at gmail.com  Tue Nov  3 02:38:53 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 2 Nov 2015 20:38:53 -0500
Subject: [R] User-defined functions in dplyr
In-Reply-To: <CAF8bMcY-wSUZt0bHnmpCxsttr6OZ2KFe5xtAP86YkB7LdYQmbQ@mail.gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
	<CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
	<CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>
	<CAF8bMcY-wSUZt0bHnmpCxsttr6OZ2KFe5xtAP86YkB7LdYQmbQ@mail.gmail.com>
Message-ID: <E14D4A95-8C52-48A5-9ADF-B6A0A9E0FEA2@gmail.com>

Actually, the results are not the same. Looks like in the code below (see "using dplyr?), the function create_bins2 is not being applied separately to each "group_by" variable. That is surprising to me, or I'm misunderstanding dplyr.

### Create some data

set.seed(4)
df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1", "model2")))

### This is the code using plyr, which I'd like to change using dplyr

create_bins <- function(x, nBins) {
  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
  dfB <-  data.frame(pred = x$pred,
                                bin = cut(x$pred, breaks = Breaks, include.lowest = TRUE))
  dfB
}

nBins = 10
res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
head(res_plyr)

### Attempt using dplyr

create_bins2 <- function (pred, nBins) {
  Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
  bin <- cut(pred, breaks = Breaks, include.lowest = TRUE)
  bin
}

res_dplyr <- dplyr::mutate(dplyr::group_by(df, models),
                                          bin=create_bins2(pred, nBins))


identical(res_plyr, as.data.frame(res_dplyr))
[1] FALSE
#levels(res_dplyr$bin) == levels(res_plyr$bin)

Thanks,
Axel.



> On Oct 30, 2015, at 12:19 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> dplyr::mutate is probably what you want instead of dplyr::summarize:
> 
> create_bins3 <- function (xpred, nBins) 
> {
>     Breaks <- unique(quantile(xpred, probs = seq(0, 1, 1/nBins)))
>     bin <- cut(xpred, breaks = Breaks, include.lowest = TRUE)
>     bin
> }
> dplyr::group_by(df, models) %>% dplyr::mutate(Bin=create_bins3(pred,nBins))
> #Source: local data frame [100 x 3]
> #Groups: models [2]
> #
> #         pred models               Bin
> #        (dbl) (fctr)            (fctr)
> #1   0.2167549 model1     (0.167,0.577]
> #2  -0.5424926 model1   (-0.869,-0.481]
> ...
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> On Fri, Oct 30, 2015 at 9:06 AM, William Dunlap <wdunlap at tibco.com <mailto:wdunlap at tibco.com>> wrote:
> The error message is not very helpful and the stack trace is pretty inscrutable as well
> > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
> Error: not a vector
> > traceback()
> 14: stop(list(message = "not a vector", call = NULL, cppstack = NULL))
> 13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
> 12: summarise_impl(.data, dots)
> 11: summarise_.tbl_df(.data, .dots = lazyeval::lazy_dots(...))
> 10: summarise_(.data, .dots = lazyeval::lazy_dots(...))
> 9: dplyr::summarize(., create_bins)
> 8: function_list[[k]](value)
> 7: withVisible(function_list[[k]](value))
> 6: freduce(value, `_function_list`)
> 5: `_fseq`(`_lhs`)
> 4: eval(expr, envir, enclos)
> 3: eval(quote(`_fseq`(`_lhs`)), env, env)
> 2: withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
> 1: dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
> 
> 
> It does not mean that your function, create_bins, does not return a vector --
> the sum function gives the same result. help(summarize,package="dplyr")
> says:
>      ...: Name-value pairs of summary functions like ?min()?, ?mean()?,
>           ?max()? etc.
> It apparently means calls to summary functions, not summary functions
> themselves.  The examples in the help file show the proper usage.
> 
> Use a call to your function and you will see it works better
>    > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins(pred,nBins))
>    Error: $ operator is invalid for atomic vectors
> The traceback again is not very useful, because the call information was
> stripped by dplyr (by the call=NULL in the call to stop()):  
>   > traceback()
>   14: stop(list(message = "$ operator is invalid for atomic vectors", 
>           call = NULL, cppstack = NULL))
>   13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
> However it is clear that the fault is in your function, which is expecting a
> data.frame x with a column called pred but gets pred itself.  Change x to xpred
> in the argument list and x$pred to xpred in the body of the function.
> 
> You will run into more problems because your function returns a vector
> the length of its input but summarize expects a summary function - one
> that returns a scalar for any size vector input.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> 
> On Fri, Oct 30, 2015 at 4:04 AM, Axel Urbiz <axel.urbiz at gmail.com <mailto:axel.urbiz at gmail.com>> wrote:
> So in this case, "create_bins" returns a vector and I still get the same
> error.
> 
> 
> create_bins <- function(x, nBins)
> {
>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>   bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
>   bin
> }
> 
> 
> ### Using dplyr (fails)
> nBins = 10
> by_group <- dplyr::group_by(df, models)
> res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
> Error: not a vector
> 
> On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
> wrote:
> 
> > You are jumping the gun (your other email did get through) and you are
> > posting using HTML (which does not come through on the list). Some time
> > (re)reading the Posting Guide mentioned at the bottom of all emails on this
> > list seems to be in order.
> >
> > The error is actually quite clear. You should return a vector from your
> > function, not a data frame.
> > ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go Live...
> > DCN:<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> > ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com <mailto:axel.urbiz at gmail.com>>
> > wrote:
> > >Hello,
> > >
> > >Sorry, resending this question as the prior was not sent properly.
> > >
> > >I?m using the plyr package below to add a variable named "bin" to my
> > >original data frame "df" with the user-defined function "create_bins".
> > >I'd
> > >like to get similar results using dplyr instead, but failing to do so.
> > >
> > >set.seed(4)
> > >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
> > >c("model1", "model2")))
> > >
> > >
> > >### Using plyr (works fine)
> > >create_bins <- function(x, nBins)
> > >{
> > >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
> > >  dfB <-  data.frame(pred = x$pred,
> > >                    bin = cut(x$pred, breaks = Breaks, include.lowest =
> > >TRUE))
> > >  dfB
> > >}
> > >
> > >nBins = 10
> > >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
> > >head(res_plyr)
> > >
> > >### Using dplyr (fails)
> > >
> > >by_group <- dplyr::group_by(df, models)
> > >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
> > >Error: not a vector
> > >
> > >
> > >Any help would be much appreciated.
> > >
> > >Best,
> > >Axel.
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> 


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Nov  3 02:58:17 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 2 Nov 2015 17:58:17 -0800
Subject: [R] User-defined functions in dplyr
In-Reply-To: <E14D4A95-8C52-48A5-9ADF-B6A0A9E0FEA2@gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
	<CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
	<CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>
	<CAF8bMcY-wSUZt0bHnmpCxsttr6OZ2KFe5xtAP86YkB7LdYQmbQ@mail.gmail.com>
	<E14D4A95-8C52-48A5-9ADF-B6A0A9E0FEA2@gmail.com>
Message-ID: <CAF8bMcaAQZWhjW1PR3+HSMnigmVBkPB95RyEaQL-36F42G-rYw@mail.gmail.com>

dplyr::mutate does not collapse factor variables well.  They seem to get
their levels from the levels
computed for the first group and mutate does not check for them having
different levels.

> data.frame(group=rep(c("A","B","C"),each=2),
value=rep(c("X","Y","Z"),3:1)) %>% dplyr::group_by(group) %>%
dplyr::mutate(fv=factor(value))
Source: local data frame [6 x 3]
Groups: group [3]

   group  value     fv
  (fctr) (fctr) (fctr)
1      A      X      X
2      A      X      X
3      B      X      X
4      B      Y     NA
5      C      Y      X
6      C      Z     NA
> levels(.Last.value$fv)
[1] "X"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Nov 2, 2015 at 5:38 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Actually, the results are not the same. Looks like in the code below (see
> "using dplyr?), the function create_bins2 is not being applied separately
> to each "group_by" variable. That is surprising to me, or I'm
> misunderstanding dplyr.
>
> ### Create some data
>
> set.seed(4)
> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
> c("model1", "model2")))
>
> ### This is the code using plyr, which I'd like to change using dplyr
>
> create_bins <- function(x, nBins) {
>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>   dfB <-  data.frame(pred = x$pred,
>                                 bin = cut(x$pred, breaks = Breaks,
> include.lowest = TRUE))
>   dfB
> }
>
> nBins = 10
> res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
> head(res_plyr)
>
> ### Attempt using dplyr
>
> create_bins2 <- function (pred, nBins) {
>   Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>   bin <- cut(pred, breaks = Breaks, include.lowest = TRUE)
>   bin
> }
>
> res_dplyr <- dplyr::mutate(dplyr::group_by(df, models),
>                                           bin=create_bins2(pred, nBins))
>
>
> identical(res_plyr, as.data.frame(res_dplyr))
> [1] FALSE
> #levels(res_dplyr$bin) == levels(res_plyr$bin)
>
> Thanks,
> Axel.
>
>
>
> On Oct 30, 2015, at 12:19 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
> dplyr::mutate is probably what you want instead of dplyr::summarize:
>
> create_bins3 <- function (xpred, nBins)
> {
>     Breaks <- unique(quantile(xpred, probs = seq(0, 1, 1/nBins)))
>     bin <- cut(xpred, breaks = Breaks, include.lowest = TRUE)
>     bin
> }
> dplyr::group_by(df, models) %>% dplyr::mutate(Bin=create_bins3(pred,nBins))
> #Source: local data frame [100 x 3]
> #Groups: models [2]
> #
> #         pred models               Bin
> #        (dbl) (fctr)            (fctr)
> #1   0.2167549 model1     (0.167,0.577]
> #2  -0.5424926 model1   (-0.869,-0.481]
> ...
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 30, 2015 at 9:06 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> The error message is not very helpful and the stack trace is pretty
>> inscrutable as well
>> > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
>> Error: not a vector
>> > traceback()
>> 14: stop(list(message = "not a vector", call = NULL, cppstack = NULL))
>> 13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
>> 12: summarise_impl(.data, dots)
>> 11: summarise_.tbl_df(.data, .dots = lazyeval::lazy_dots(...))
>> 10: summarise_(.data, .dots = lazyeval::lazy_dots(...))
>> 9: dplyr::summarize(., create_bins)
>> 8: function_list[[k]](value)
>> 7: withVisible(function_list[[k]](value))
>> 6: freduce(value, `_function_list`)
>> 5: `_fseq`(`_lhs`)
>> 4: eval(expr, envir, enclos)
>> 3: eval(quote(`_fseq`(`_lhs`)), env, env)
>> 2: withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
>> 1: dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
>>
>>
>> It does not mean that your function, create_bins, does not return a
>> vector --
>> the sum function gives the same result. help(summarize,package="dplyr")
>> says:
>>      ...: Name-value pairs of summary functions like ?min()?, ?mean()?,
>>           ?max()? etc.
>> It apparently means calls to summary functions, not summary functions
>> themselves.  The examples in the help file show the proper usage.
>>
>> Use a call to your function and you will see it works better
>>    > dplyr::group_by(df, models) %>%
>> dplyr::summarize(create_bins(pred,nBins))
>>    Error: $ operator is invalid for atomic vectors
>> The traceback again is not very useful, because the call information was
>> stripped by dplyr (by the call=NULL in the call to stop()):
>>   > traceback()
>>   14: stop(list(message = "$ operator is invalid for atomic vectors",
>>           call = NULL, cppstack = NULL))
>>   13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
>> However it is clear that the fault is in your function, which is
>> expecting a
>> data.frame x with a column called pred but gets pred itself.  Change x to
>> xpred
>> in the argument list and x$pred to xpred in the body of the function.
>>
>> You will run into more problems because your function returns a vector
>> the length of its input but summarize expects a summary function - one
>> that returns a scalar for any size vector input.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Oct 30, 2015 at 4:04 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>>
>>> So in this case, "create_bins" returns a vector and I still get the same
>>> error.
>>>
>>>
>>> create_bins <- function(x, nBins)
>>> {
>>>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>>>   bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
>>>   bin
>>> }
>>>
>>>
>>> ### Using dplyr (fails)
>>> nBins = 10
>>> by_group <- dplyr::group_by(df, models)
>>> res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>>> Error: not a vector
>>>
>>> On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>> > You are jumping the gun (your other email did get through) and you are
>>> > posting using HTML (which does not come through on the list). Some time
>>> > (re)reading the Posting Guide mentioned at the bottom of all emails on
>>> this
>>> > list seems to be in order.
>>> >
>>> > The error is actually quite clear. You should return a vector from your
>>> > function, not a data frame.
>>> >
>>> ---------------------------------------------------------------------------
>>> > Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> > Go...
>>> >                                       Live:   OO#.. Dead: OO#..
>>> Playing
>>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> >
>>> ---------------------------------------------------------------------------
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>> > On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com>
>>> > wrote:
>>> > >Hello,
>>> > >
>>> > >Sorry, resending this question as the prior was not sent properly.
>>> > >
>>> > >I?m using the plyr package below to add a variable named "bin" to my
>>> > >original data frame "df" with the user-defined function "create_bins".
>>> > >I'd
>>> > >like to get similar results using dplyr instead, but failing to do so.
>>> > >
>>> > >set.seed(4)
>>> > >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>>> > >c("model1", "model2")))
>>> > >
>>> > >
>>> > >### Using plyr (works fine)
>>> > >create_bins <- function(x, nBins)
>>> > >{
>>> > >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>>> > >  dfB <-  data.frame(pred = x$pred,
>>> > >                    bin = cut(x$pred, breaks = Breaks, include.lowest
>>> =
>>> > >TRUE))
>>> > >  dfB
>>> > >}
>>> > >
>>> > >nBins = 10
>>> > >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
>>> > >head(res_plyr)
>>> > >
>>> > >### Using dplyr (fails)
>>> > >
>>> > >by_group <- dplyr::group_by(df, models)
>>> > >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>>> > >Error: not a vector
>>> > >
>>> > >
>>> > >Any help would be much appreciated.
>>> > >
>>> > >Best,
>>> > >Axel.
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> > >
>>> > >______________________________________________
>>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>>> > >PLEASE do read the posting guide
>>> > >http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> > >and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Tue Nov  3 03:07:51 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Mon, 2 Nov 2015 21:07:51 -0500
Subject: [R] User-defined functions in dplyr
In-Reply-To: <CAF8bMcaAQZWhjW1PR3+HSMnigmVBkPB95RyEaQL-36F42G-rYw@mail.gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
	<CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
	<CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>
	<CAF8bMcY-wSUZt0bHnmpCxsttr6OZ2KFe5xtAP86YkB7LdYQmbQ@mail.gmail.com>
	<E14D4A95-8C52-48A5-9ADF-B6A0A9E0FEA2@gmail.com>
	<CAF8bMcaAQZWhjW1PR3+HSMnigmVBkPB95RyEaQL-36F42G-rYw@mail.gmail.com>
Message-ID: <EDE081B6-E9C5-4B5D-A8F0-AAC09157487C@gmail.com>

Nice example of the issue Bill. Thank you.

Is this a known issue? Plans to be fixed?

Thanks again,
Axel.


> On Nov 2, 2015, at 8:58 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> dplyr::mutate does not collapse factor variables well.  They seem to get their levels from the levels
> computed for the first group and mutate does not check for them having different levels.
> 
> > data.frame(group=rep(c("A","B","C"),each=2), value=rep(c("X","Y","Z"),3:1)) %>% dplyr::group_by(group) %>% dplyr::mutate(fv=factor(value)) 
> Source: local data frame [6 x 3]
> Groups: group [3]
> 
>    group  value     fv
>   (fctr) (fctr) (fctr)
> 1      A      X      X
> 2      A      X      X
> 3      B      X      X
> 4      B      Y     NA
> 5      C      Y      X
> 6      C      Z     NA
> > levels(.Last.value$fv)
> [1] "X"
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> On Mon, Nov 2, 2015 at 5:38 PM, Axel Urbiz <axel.urbiz at gmail.com <mailto:axel.urbiz at gmail.com>> wrote:
> Actually, the results are not the same. Looks like in the code below (see "using dplyr?), the function create_bins2 is not being applied separately to each "group_by" variable. That is surprising to me, or I'm misunderstanding dplyr.
> 
> ### Create some data
> 
> set.seed(4)
> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1", "model2")))
> 
> ### This is the code using plyr, which I'd like to change using dplyr
> 
> create_bins <- function(x, nBins) {
>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>   dfB <-  data.frame(pred = x$pred,
>                                 bin = cut(x$pred, breaks = Breaks, include.lowest = TRUE))
>   dfB
> }
> 
> nBins = 10
> res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
> head(res_plyr)
> 
> ### Attempt using dplyr
> 
> create_bins2 <- function (pred, nBins) {
>   Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>   bin <- cut(pred, breaks = Breaks, include.lowest = TRUE)
>   bin
> }
> 
> res_dplyr <- dplyr::mutate(dplyr::group_by(df, models),
>                                           bin=create_bins2(pred, nBins))
> 
> 
> identical(res_plyr, as.data.frame(res_dplyr))
> [1] FALSE
> #levels(res_dplyr$bin) == levels(res_plyr$bin)
> 
> Thanks,
> Axel.
> 
> 
> 
>> On Oct 30, 2015, at 12:19 PM, William Dunlap <wdunlap at tibco.com <mailto:wdunlap at tibco.com>> wrote:
>> 
>> dplyr::mutate is probably what you want instead of dplyr::summarize:
>> 
>> create_bins3 <- function (xpred, nBins) 
>> {
>>     Breaks <- unique(quantile(xpred, probs = seq(0, 1, 1/nBins)))
>>     bin <- cut(xpred, breaks = Breaks, include.lowest = TRUE)
>>     bin
>> }
>> dplyr::group_by(df, models) %>% dplyr::mutate(Bin=create_bins3(pred,nBins))
>> #Source: local data frame [100 x 3]
>> #Groups: models [2]
>> #
>> #         pred models               Bin
>> #        (dbl) (fctr)            (fctr)
>> #1   0.2167549 model1     (0.167,0.577]
>> #2  -0.5424926 model1   (-0.869,-0.481]
>> ...
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com/>
>> On Fri, Oct 30, 2015 at 9:06 AM, William Dunlap <wdunlap at tibco.com <mailto:wdunlap at tibco.com>> wrote:
>> The error message is not very helpful and the stack trace is pretty inscrutable as well
>> > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
>> Error: not a vector
>> > traceback()
>> 14: stop(list(message = "not a vector", call = NULL, cppstack = NULL))
>> 13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
>> 12: summarise_impl(.data, dots)
>> 11: summarise_.tbl_df(.data, .dots = lazyeval::lazy_dots(...))
>> 10: summarise_(.data, .dots = lazyeval::lazy_dots(...))
>> 9: dplyr::summarize(., create_bins)
>> 8: function_list[[k]](value)
>> 7: withVisible(function_list[[k]](value))
>> 6: freduce(value, `_function_list`)
>> 5: `_fseq`(`_lhs`)
>> 4: eval(expr, envir, enclos)
>> 3: eval(quote(`_fseq`(`_lhs`)), env, env)
>> 2: withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
>> 1: dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
>> 
>> 
>> It does not mean that your function, create_bins, does not return a vector --
>> the sum function gives the same result. help(summarize,package="dplyr")
>> says:
>>      ...: Name-value pairs of summary functions like ?min()?, ?mean()?,
>>           ?max()? etc.
>> It apparently means calls to summary functions, not summary functions
>> themselves.  The examples in the help file show the proper usage.
>> 
>> Use a call to your function and you will see it works better
>>    > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins(pred,nBins))
>>    Error: $ operator is invalid for atomic vectors
>> The traceback again is not very useful, because the call information was
>> stripped by dplyr (by the call=NULL in the call to stop()):  
>>   > traceback()
>>   14: stop(list(message = "$ operator is invalid for atomic vectors", 
>>           call = NULL, cppstack = NULL))
>>   13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
>> However it is clear that the fault is in your function, which is expecting a
>> data.frame x with a column called pred but gets pred itself.  Change x to xpred
>> in the argument list and x$pred to xpred in the body of the function.
>> 
>> You will run into more problems because your function returns a vector
>> the length of its input but summarize expects a summary function - one
>> that returns a scalar for any size vector input.
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com/>
>> 
>> On Fri, Oct 30, 2015 at 4:04 AM, Axel Urbiz <axel.urbiz at gmail.com <mailto:axel.urbiz at gmail.com>> wrote:
>> So in this case, "create_bins" returns a vector and I still get the same
>> error.
>> 
>> 
>> create_bins <- function(x, nBins)
>> {
>>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>>   bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
>>   bin
>> }
>> 
>> 
>> ### Using dplyr (fails)
>> nBins = 10
>> by_group <- dplyr::group_by(df, models)
>> res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>> Error: not a vector
>> 
>> On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>
>> wrote:
>> 
>> > You are jumping the gun (your other email did get through) and you are
>> > posting using HTML (which does not come through on the list). Some time
>> > (re)reading the Posting Guide mentioned at the bottom of all emails on this
>> > list seems to be in order.
>> >
>> > The error is actually quite clear. You should return a vector from your
>> > function, not a data frame.
>> > ---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>>        Basics: ##.#.       ##.#.  Live
>> > Go...
>> >                                       Live:   OO#.. Dead: OO#..  Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> > ---------------------------------------------------------------------------
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com <mailto:axel.urbiz at gmail.com>>
>> > wrote:
>> > >Hello,
>> > >
>> > >Sorry, resending this question as the prior was not sent properly.
>> > >
>> > >I?m using the plyr package below to add a variable named "bin" to my
>> > >original data frame "df" with the user-defined function "create_bins".
>> > >I'd
>> > >like to get similar results using dplyr instead, but failing to do so.
>> > >
>> > >set.seed(4)
>> > >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>> > >c("model1", "model2")))
>> > >
>> > >
>> > >### Using plyr (works fine)
>> > >create_bins <- function(x, nBins)
>> > >{
>> > >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>> > >  dfB <-  data.frame(pred = x$pred,
>> > >                    bin = cut(x$pred, breaks = Breaks, include.lowest =
>> > >TRUE))
>> > >  dfB
>> > >}
>> > >
>> > >nBins = 10
>> > >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
>> > >head(res_plyr)
>> > >
>> > >### Using dplyr (fails)
>> > >
>> > >by_group <- dplyr::group_by(df, models)
>> > >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>> > >Error: not a vector
>> > >
>> > >
>> > >Any help would be much appreciated.
>> > >
>> > >Best,
>> > >Axel.
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 


	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Nov  3 00:08:45 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 3 Nov 2015 10:08:45 +1100
Subject: [R] Fwd: Re: Creating "Envelope" around a plot
In-Reply-To: <CAF8bMcb7q8yG2YUH5EgxHUB77i3WrSxLeC-0dL69DECjEi0FGg@mail.gmail.com>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<56377B4B.8030207@gmail.com>
	<1078037469.15600.1446477526526.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<1772496658.15628.1446477550548.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
	<CAF8bMcZGR2XoZcdJmi3B+Ufqi0B22M3qvkZQt+qQtaj9wJk5gQ@mail.gmail.com>
	<1311500866.3480.1446485395532.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAF8bMcb7q8yG2YUH5EgxHUB77i3WrSxLeC-0dL69DECjEi0FGg@mail.gmail.com>
Message-ID: <CA+8X3fWf8ATmrgG5bz9PibBv1SKoJeCKe41x2J6X5-bAnvhYyQ@mail.gmail.com>

Hi Nick,
I don't think it will do all that you have described, but the "dispersion"
function in the plotrix package will draw an "envelope" around a line if
you specify type="l" and fill=<some_color>. If you pass ulim=<some_value>,
the "envelope" will extend that far from the original line. See the second
example on the help page to overplot the original line.

Jim


On Tue, Nov 3, 2015 at 4:35 AM, William Dunlap <wdunlap at tibco.com> wrote:

> > summing the Euclidean distances between points in the strands
> > ... if two one strand lies within the "envelope" of another I can set
> them together
>
> Use the max instead of the sum.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Nov 2, 2015 at 9:29 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
> wrote:
>
> > Hi Bill I have been doing exactly that, ie summing the Euclidean
> distances
> > between points in the strands   Although with small sets of strands this
> > technique allows me to group the strands into various sets, which I can
> > assume are the same, unfortunately once I have a larger number of strands
> > the distances between groups become on the same order as the distances
> > within groups as so it's no longer clear cut.  I have tried various
> > approaches, include a kind of Monte Carlo sampling to create the distinct
> > groups but the best approach seems to be a kind of "kinship" idea, where
> if
> > two one strand lies within the "envelope" of another I can set them
> > together.  But as said, creating the envelope in R is not straightforward
> >
> > Thanks Nick
> >
> > On 02 November 2015 at 16:51 William Dunlap <wdunlap at tibco.com> wrote:
> >
> > Instead of computing the envelopes (of various radii) of paths and seeing
> > if they intersect
> > you could compute distances between paths and seeing if they are smaller
> > than a given
> > distance. Computing the distance between 2 polylines is not difficult,
> > although computing
> > it quickly for very long sequences of line segments is more difficult.
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Mon, Nov 2, 2015 at 7:19 AM, WRAY NICHOLAS <
> nicholas.wray at ntlworld.com>
> > wrote:
> >
> >
> > > ---------- Original Message ----------
> > > From: WRAY NICHOLAS < nicholas.wray at ntlworld.com>
> > > To: Duncan Murdoch < murdoch.duncan at gmail.com>, r-help
> > > <r-help at missing_domain>
> > > Date: at
> > > Subject: Re: [R] Creating "Envelope" around a plot
> > >
> > >
> > > Hi Dennis again, I see what you're getting at and it looks rather
> groovy
> > > but unfortunately what I actually need is the vector of the points on
> > the
> > > boundary (the graphics just being a way of checking that everything's
> as
> > it
> > > should be) and so it rather looks like I need to do a lot of
> calculating
> > of
> > > orthogonal vectors along straight stretches and circles round peaks
> > >
> > > I'm looking to do an algorithmic filtration of strands which lie within
> > > the "envelope" of other strands -- your method would allow visual "by
> > hand"
> > > inspection but unfortunately I've got hundreds of strands to compare!
> > >
> > > But thanks again -- useful thoughts Nick
> > >
> > > > >
> > > > On 02 November 2015 at 15:03 Duncan Murdoch
> > > > < murdoch.duncan at gmail.com> wrote:
> > > >
> > > >
> > > > On 02/11/2015 7:33 AM, WRAY NICHOLAS wrote:
> > > > > Hi I am plotting various strands of information, and I want to
> > > > > create an
> > > > > "envelope" around each line, so that the locus of the envelope is
> > > > > the boundary
> > > > > points no more than a fixed maximum distance from the plotted
> > > > > line, a bit like
> > > > > drawing a larger rectangle with paralle sides and curved compass
> > > > > corners around
> > > > > a smaller rectangle. Obviously I can work out how to do this in
> > > > > code
> > > > > (eventually) but I suspect it would take me a while and i was
> > > > > wondering whether
> > > > > there was some R function which I don't know about which creates
> > > > > sets of of
> > > > > points at a given maximal distance
> > > > >
> > > > > the lines are simple vectors, ie like this noddy example
> > > > >
> > > > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> > > > > plot(veca,type="l",lwd=2)
> > > > >
> > > > > then I want to plot the locus of the boundary of all points no
> > > > > more than (say) 1
> > > > > unit from the line I imagine that one would have to provide a
> > > > > larger set of
> > > > > interpolated points between the actual points of veca, but I can
> > > > > do that no
> > > > > problem
> > > > >
> > > > > I'd be grateful if anyone out there in the R-ethervoid has any
> > > > > ideas
> > > >
> > > > The graphics system will do this for you automatically if your
> > > > coordinate system has the same scale in x and y, and you use a
> > > > really
> > > > huge line width. For example,
> > > >
> > > > veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)plot(veca, lwd=150, col="gray",
> > > > type="l")lines(veca, lwd=2)
> > > >
> > > >
> > > > If you want to be 1 unit away in user coordinates and the x and y
> > > > scales
> > > > are different, it will be a lot harder.
> > > >
> > > > Duncan Murdoch
> > > >
> > > > >
> > > >
> > >
> >
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Nov  3 04:16:11 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 3 Nov 2015 16:16:11 +1300
Subject: [R] What happened to Canada?
In-Reply-To: <B08DF06A-C717-4AD7-9960-CA7BD3993901@me.com>
References: <33A1DD6DCF8.00000188jrkrideau@inbox.com>
	<0C963D47-71C1-455A-939E-BF44EA219D64@me.com>
	<5637E575.7040306@auckland.ac.nz>
	<A205CFBE-F58D-4F13-A3C5-B309D01022E7@me.com>
	<5637F475.7000600@auckland.ac.nz>
	<B08DF06A-C717-4AD7-9960-CA7BD3993901@me.com>
Message-ID: <563826FB.5000404@auckland.ac.nz>

On 03/11/15 12:52, Marc Schwartz wrote:
> Hi Rolf,
>
> See below.

<SNIP>

> Martin Morgan's reply seems like it is on point.

Indeed.  The problem arises from a lack of "libcurl" capabilities.

> I would follow his logic regarding libcurl and https support, but it
> would be helpful to know how you installed R.
>
> Fedora 17 has been EOL'd for >2 years, so I am guessing that you
> installed from source, since the EPEL and most Fedora repos would not
> typically support EOL'd distros due to the risk of dated dependencies
> and version related incompatibilities.

Yes.  I installed from source.

> That might suggest that the config/compilation incantation may not
> have used libcurl or not a version with https support enabled.

After digging around a bit in config.log I see an indication that
the version of libcurl needs to be >= 7.28.0.

The version that I have, which seems to be the latest that is available 
for my poor old Fedora 17, is 7.24.0.  So therein lies the problem.

(Goes away and beats the keyboard to death for an hour or two ....)

I have now managed to install a recent version of libcurl --- from 
source; no recent version is available for Fedora 17 via yum --- and 
after considerable travail got R to configure and build using the new 
libcurl.

Strangely, the configure.log for R showed no sign of problems after I 
installed the new libcurl, but then "make check" threw an error --- 
apparently R could not find the new version.  The default install for 
libcurl put it in /usr/local/share/... and R looked in /usr/share/... 
There must be a way to tell R to look in /usr/local/share but I couldn't 
figure it out and re-installed libcurl, telling the install to use /usr 
as the install directory.

Then I configured, made and installed R and, mirabile dictu, it is now 
the case that chooseCRANmirror() works as advertised without throwing 
any error.

Supplementary question:  Given that I want to be "secure" I can/should 
no longer use my local New Zealand mirror.  Does anyone reading this 
know if, and if so, when the New Zealand mirror will be reconfigured to 
provide https rather than http protocol?

Ta.

cheers,

Rolf

P. S.  You wrote:

> There are references/pointers pertaining to libcurl in the
> Installation and Administration manual.

Yes, but these (as far as I can discern) relate only to *Windoze* which 
civilised people such as my very good self do not use.

R.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From javier.villacampa.gonzalez at gmail.com  Tue Nov  3 11:47:15 2015
From: javier.villacampa.gonzalez at gmail.com (=?UTF-8?Q?Javier_Villacampa_Gonz=C3=A1lez?=)
Date: Tue, 3 Nov 2015 11:47:15 +0100
Subject: [R] R in UNIX OS
Message-ID: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>

Hello,

I have a silly questions:

is possilbe to install R in a AIX OS Machine?
Where can I found the download files?

Thank you in advance

Javier
--

	[[alternative HTML version deleted]]


From Katja.Haavanlammi at bof.fi  Tue Nov  3 13:46:30 2015
From: Katja.Haavanlammi at bof.fi (Katja.Haavanlammi at bof.fi)
Date: Tue, 3 Nov 2015 12:46:30 +0000
Subject: [R] Package 'var' and standard errors for the impulse response
 coefficients?
Message-ID: <e1251d79a0b2484c9cb871c385d44f31@KUSTI-C.bofnet.fi>

Dear R-specialists,

I'm using package 'vars' and especially irf-command for a basic VAR-model. How can I compute standard errors for the received impulse response coefficients? I've read that one option could be bootstrapped standard errors but I cannot find any information how to perform that with R.

data(Canada)
## For VAR
var.2c <- VAR(Canada, p = 2, type = "const")
irf.Canada <- irf(var.2c, impulse = "e", response = c("prod", "rw", "U"), boot = TRUE)
##Then I print the results:
print(irf.Canada)

Printing makes a list of responses and their lower and upper bounds. However, I'd also like to have the standard errors (or bootstrapped standard errors) for these response coefficients.
Thank you, in advance!

With best regards,

Katja Haavanlammi
Statistics Specialist

Bank of Finland
Snellmaninaukio
P.O. Box 160, 00101 Helsinki, Finland
Tel. +358 10 831 2415/ +358 50 4914 298
katja.haavanlammi at bof.fi<mailto:katja.haavanlammi at bof.fi>


www.bof.fi
www.bofbulletin.fi

	[[alternative HTML version deleted]]


From simon.gingins at unine.ch  Tue Nov  3 14:58:04 2015
From: simon.gingins at unine.ch (GINGINS Simon)
Date: Tue, 3 Nov 2015 13:58:04 +0000
Subject: [R] Color & pch functionalities in dotchart()
Message-ID: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>

Hi,

I am currently building graphs using dochart(). I plotted the points in two different colors according to specific criteria from my dataset. Later, I decided to also give them different symbols, for easier reading if printed. I got quite a surprise when I realized that, even though I gave the same variable to both color= and pch= , I got a mix of the colors and symbols. I wanted one type of symbol to be only one color, and the second only the other color, and it is clearly not what happened. From my data, I would say that the pch= argument is not dealing properly with the variable I gave it. I tried using a dataset from R to see if this was only in my dataset, and it did the same. here?s a reproducible example, using beaver1:

dotchart(beaver1$temp, groups=factor(beaver1$day), color=as.factor(beaver1$activ), pch=beaver1$activ)

Does anyone know why, with the same variable, the arguments color & pch give different results? 

That would be of great help, since now I am no longer sure which one isthe correct representation of my data.

Best regards & many thanks for the help

Simon Gingins

From loris.bennett at fu-berlin.de  Tue Nov  3 16:10:50 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Tue, 3 Nov 2015 16:10:50 +0100
Subject: [R] R in UNIX OS
References: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
Message-ID: <87611jyv7p.fsf@hornfels.zedat.fu-berlin.de>

Javier Villacampa Gonz?lez <javier.villacampa.gonzalez at gmail.com>
writes:

> Hello,
>
> I have a silly questions:
>
> is possilbe to install R in a AIX OS Machine?
> Where can I found the download files?
>
> Thank you in advance
>
> Javier

It may be difficult to find a version pre-packaged for AIX, but you can
always compile R yourself from the sources.  If your AIX machine has
some optimised maths library, such as IBM's MASS or Intel's MKL, then
you probably want to do this anyway.

Cheers,

Loris

-- 
This signature is currently under construction.


From dcarlson at tamu.edu  Tue Nov  3 16:30:22 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 3 Nov 2015 15:30:22 +0000
Subject: [R] replace NA's with row means for specific columns
In-Reply-To: <CA+8X3fVeeCGE3-gBui2rHL5ka=-v3K-FfKnJ9Zymai9g9SL9Ag@mail.gmail.com>
References: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
	<CA+8X3fW41q0FnPbg40dHpsrTrR-CmC_JvmbAtGdStuXDOZViRw@mail.gmail.com>
	<CA+8X3fVeeCGE3-gBui2rHL5ka=-v3K-FfKnJ9Zymai9g9SL9Ag@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D84CD@mb02.ads.tamu.edu>

This should be a bit quicker since it just loops through the column blocks:

> Zdf <- structure(list(ID = structure(1:4, .Label = c("b", "c", "d", 
+ "e"), class = "factor"), A1 = c(4L, 4L, NA, 4L), A2 = c(5L, 5L, 
+ 5L, 5L), A3 = c(NA, 1L, 1L, 4L), B1 = c(2L, NA, 1L, 5L), B2 = c(NA, 
+ 3L, NA, NA), B3 = c(4L, 4L, 4L, 4L), C1 = c(5L, 5L, 5L, 5L), 
+     C2 = c(1L, 1L, 1L, 1L), C3 = c(3L, 3L, 3L, 3L), C4 = c(NA, 
+     2L, 2L, 2L)), .Names = c("ID", "A1", "A2", "A3", "B1", "B2", 
+ "B3", "C1", "C2", "C3", "C4"), class = "data.frame", row.names = c(NA, 
+ -4L))
> 
> Zdf
  ID A1 A2 A3 B1 B2 B3 C1 C2 C3 C4
1  b  4  5 NA  2 NA  4  5  1  3 NA
2  c  4  5  1 NA  3  4  5  1  3  2
3  d NA  5  1  1 NA  4  5  1  3  2
4  e  4  5  4  5 NA  4  5  1  3  2
> 
> A <- grep("^A", colnames(Zdf))
> B <- grep("^B", colnames(Zdf))
> C <- grep("^C", colnames(Zdf))
> 
> for (i in list(A, B, C)) {
+      mn <- rowMeans(Zdf[, i], na.rm=TRUE)
+      miss <- which(is.na(Zdf[, i]), arr.ind=TRUE)
+      Zdf[, i][miss]<- mn[miss[, 1]]
+ }
> 
> Zdf
  ID A1 A2  A3  B1  B2 B3 C1 C2 C3 C4
1  b  4  5 4.5 2.0 3.0  4  5  1  3  3
2  c  4  5 1.0 3.5 3.0  4  5  1  3  2
3  d  3  5 1.0 1.0 2.5  4  5  1  3  2
4  e  4  5 4.0 5.0 4.5  4  5  1  3  2

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Monday, November 2, 2015 5:33 PM
To: Zahra
Cc: r-help mailing list
Subject: Re: [R] replace NA's with row means for specific columns

Hi again,
Small typo in line 5 - should be

replace_NAs<-function(x,group_lab=c("A","B","C")) {
 for(lab in group_lab) {
  indices<-grep(lab,names(x),fixed=TRUE)
  na_indices<-is.na(x[indices])
  if(any(na_indices))
   x[indices][na_indices]<-rowMeans(x[indices],na.rm=TRUE)
 }
 return(x)
}

Jim

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Nov  3 16:42:11 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Nov 2015 07:42:11 -0800
Subject: [R] Color & pch functionalities in dotchart()
In-Reply-To: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>
References: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>
Message-ID: <CAGxFJbTSAkGUjpDDFZW_hOqbQCkEnt-ANjd7nHXqZmh8Rr55Bw@mail.gmail.com>

Look at your code!

color was specified as "as.factor..."
and pch was specifed as "..." (no as.factor() )

Read an R tutorial on how factors are coded for why this would make a
difference.

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 3, 2015 at 5:58 AM, GINGINS Simon <simon.gingins at unine.ch> wrote:
> Hi,
>
> I am currently building graphs using dochart(). I plotted the points in two different colors according to specific criteria from my dataset. Later, I decided to also give them different symbols, for easier reading if printed. I got quite a surprise when I realized that, even though I gave the same variable to both color= and pch= , I got a mix of the colors and symbols. I wanted one type of symbol to be only one color, and the second only the other color, and it is clearly not what happened. From my data, I would say that the pch= argument is not dealing properly with the variable I gave it. I tried using a dataset from R to see if this was only in my dataset, and it did the same. here?s a reproducible example, using beaver1:
>
> dotchart(beaver1$temp, groups=factor(beaver1$day), color=as.factor(beaver1$activ), pch=beaver1$activ)
>
> Does anyone know why, with the same variable, the arguments color & pch give different results?
>
> That would be of great help, since now I am no longer sure which one isthe correct representation of my data.
>
> Best regards & many thanks for the help
>
> Simon Gingins
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Nov  3 16:46:52 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 3 Nov 2015 10:46:52 -0500
Subject: [R] Color & pch functionalities in dotchart()
In-Reply-To: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>
References: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>
Message-ID: <5638D6EC.4050004@gmail.com>

On 03/11/2015 8:58 AM, GINGINS Simon wrote:
> Hi,
>
> I am currently building graphs using dochart(). I plotted the points in two different colors according to specific criteria from my dataset. Later, I decided to also give them different symbols, for easier reading if printed. I got quite a surprise when I realized that, even though I gave the same variable to both color= and pch= , I got a mix of the colors and symbols. I wanted one type of symbol to be only one color, and the second only the other color, and it is clearly not what happened. From my data, I would say that the pch= argument is not dealing properly with the variable I gave it. I tried using a dataset from R to see if this was only in my dataset, and it did the same. here?s a reproducible example, using beaver1:
>
> dotchart(beaver1$temp, groups=factor(beaver1$day), color=as.factor(beaver1$activ), pch=beaver1$activ)
>
> Does anyone know why, with the same variable, the arguments color & pch give different results?
>
> That would be of great help, since now I am no longer sure which one isthe correct representation of my data.
>
> Best regards & many thanks for the help

Looks like a bug in dotchart.  When you specify groups, it sorts the 
data to put it into groups.  It also sorts the colors, but it doesn't 
sort the pch values, so they end up associated with the wrong points.

A workaround would be for you to do the sorting in advance.  For example,

groups <- factor(beaver1$day)

o <- sort.list(as.numeric(groups), decreasing = TRUE)
tmp <- beaver1[o,]

dotchart(tmp$temp, groups=factor(tmp$day), color=as.factor(tmp$activ), pch=tmp$activ)

Duncan Murdoch


From alaios at yahoo.com  Tue Nov  3 16:47:47 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 3 Nov 2015 15:47:47 +0000 (UTC)
Subject: [R] merging-binning data
References: <1606891114.1236050.1446565667523.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1606891114.1236050.1446565667523.JavaMail.yahoo@mail.yahoo.com>

Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
I have a vector that looks like
?binDistance
?????????? [,1]
?[1,] 238.95162
?[2,] 143.08590
?[3,]? 88.50923
?[4,] 177.67884
?[5,] 277.54116
?[6,] 342.94689
?[7,] 241.60905
?[8,] 177.81969
?[9,] 211.25559
[10,] 279.72702
[11,] 381.95738
[12,] 483.76363
[13,] 480.98841
[14,] 369.75241
[15,] 267.73650
[16,] 138.55959
[17,] 137.93181
[18,] 184.75200
[19,] 254.64359
[20,] 328.87785
[21,] 273.15577
[22,] 252.52830
[23,] 252.52830
[24,] 252.52830
[25,] 262.20084
[26,] 314.93064
[27,] 366.02996
[28,] 442.77467
[29,] 521.20323
[30,] 465.33071
[31,] 366.60582
[32,]? 13.69540
so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut


Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
Browse[2]> test
?[1] (217,318]? (115,217]? (13.7,115] (115,217]? (217,318]? (318,420] 
?[7] (217,318]? (115,217]? (115,217]? (217,318]? (318,420]? (420,521] 
[13] (420,521]? (318,420]? (217,318]? (115,217]? (115,217]? (115,217] 
[19] (217,318]? (318,420]? (217,318]? (217,318]? (217,318]? (217,318] 
[25] (217,318]? (217,318]? (318,420]? (420,521]? (420,521]? (420,521] 
[31] (318,420]? (13.7,115]
Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]


I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
How I can do that effectively in R?
I would like to thank you for your replyRegardsAlex

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov  3 16:48:30 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Nov 2015 07:48:30 -0800
Subject: [R] Color & pch functionalities in dotchart()
In-Reply-To: <CAGxFJbTSAkGUjpDDFZW_hOqbQCkEnt-ANjd7nHXqZmh8Rr55Bw@mail.gmail.com>
References: <458BA4E0-A148-4F41-8EE8-4623A2B6D0C0@unine.ch>
	<CAGxFJbTSAkGUjpDDFZW_hOqbQCkEnt-ANjd7nHXqZmh8Rr55Bw@mail.gmail.com>
Message-ID: <CAGxFJbRr3V4ON7-GVYBwL4sMfHdxv906-9AgGiDAw6NuFh1c8w@mail.gmail.com>

... and see also the "color specification" info in ?par as well as the
linked  ?palette. You may be wrapping around if yu have more
categories than colors in your palette.

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 3, 2015 at 7:42 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Look at your code!
>
> color was specified as "as.factor..."
> and pch was specifed as "..." (no as.factor() )
>
> Read an R tutorial on how factors are coded for why this would make a
> difference.
>
> -- Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Tue, Nov 3, 2015 at 5:58 AM, GINGINS Simon <simon.gingins at unine.ch> wrote:
>> Hi,
>>
>> I am currently building graphs using dochart(). I plotted the points in two different colors according to specific criteria from my dataset. Later, I decided to also give them different symbols, for easier reading if printed. I got quite a surprise when I realized that, even though I gave the same variable to both color= and pch= , I got a mix of the colors and symbols. I wanted one type of symbol to be only one color, and the second only the other color, and it is clearly not what happened. From my data, I would say that the pch= argument is not dealing properly with the variable I gave it. I tried using a dataset from R to see if this was only in my dataset, and it did the same. here?s a reproducible example, using beaver1:
>>
>> dotchart(beaver1$temp, groups=factor(beaver1$day), color=as.factor(beaver1$activ), pch=beaver1$activ)
>>
>> Does anyone know why, with the same variable, the arguments color & pch give different results?
>>
>> That would be of great help, since now I am no longer sure which one isthe correct representation of my data.
>>
>> Best regards & many thanks for the help
>>
>> Simon Gingins
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Nov  3 17:05:22 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 3 Nov 2015 11:05:22 -0500
Subject: [R] merging-binning data
In-Reply-To: <1606891114.1236050.1446565667523.JavaMail.yahoo@mail.yahoo.com>
References: <1606891114.1236050.1446565667523.JavaMail.yahoo@mail.yahoo.com>
	<1606891114.1236050.1446565667523.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+vqiLHycoRq5GR0p5oZG7bRT7NAcJszCrOZxPOHuBUaPMntTw@mail.gmail.com>

Probably

split(binDistance, test).

Best,
Ista

On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> I have a vector that looks like
>  binDistance
>            [,1]
>  [1,] 238.95162
>  [2,] 143.08590
>  [3,]  88.50923
>  [4,] 177.67884
>  [5,] 277.54116
>  [6,] 342.94689
>  [7,] 241.60905
>  [8,] 177.81969
>  [9,] 211.25559
> [10,] 279.72702
> [11,] 381.95738
> [12,] 483.76363
> [13,] 480.98841
> [14,] 369.75241
> [15,] 267.73650
> [16,] 138.55959
> [17,] 137.93181
> [18,] 184.75200
> [19,] 254.64359
> [20,] 328.87785
> [21,] 273.15577
> [22,] 252.52830
> [23,] 252.52830
> [24,] 252.52830
> [25,] 262.20084
> [26,] 314.93064
> [27,] 366.02996
> [28,] 442.77467
> [29,] 521.20323
> [30,] 465.33071
> [31,] 366.60582
> [32,]  13.69540
> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
>
>
> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> Browse[2]> test
>  [1] (217,318]  (115,217]  (13.7,115] (115,217]  (217,318]  (318,420]
>  [7] (217,318]  (115,217]  (115,217]  (217,318]  (318,420]  (420,521]
> [13] (420,521]  (318,420]  (217,318]  (115,217]  (115,217]  (115,217]
> [19] (217,318]  (318,420]  (217,318]  (217,318]  (217,318]  (217,318]
> [25] (217,318]  (217,318]  (318,420]  (420,521]  (420,521]  (420,521]
> [31] (318,420]  (13.7,115]
> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
>
>
> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> How I can do that effectively in R?
> I would like to thank you for your replyRegardsAlex
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Nov  3 18:18:50 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 3 Nov 2015 09:18:50 -0800
Subject: [R] R in UNIX OS
In-Reply-To: <87611jyv7p.fsf@hornfels.zedat.fu-berlin.de>
References: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
	<87611jyv7p.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <D01EEB73-6BD3-4D54-B1F6-683DF9DFD077@comcast.net>


> On Nov 3, 2015, at 7:10 AM, Loris Bennett <loris.bennett at fu-berlin.de> wrote:
> 
> Javier Villacampa Gonz?lez <javier.villacampa.gonzalez at gmail.com>
> writes:
> 
>> Hello,
>> 
>> I have a silly questions:
>> 
>> is possilbe to install R in a AIX OS Machine?
>> Where can I found the download files?
>> 
>> Thank you in advance
>> 
>> Javier
> 
> It may be difficult to find a version pre-packaged for AIX, but you can
> always compile R yourself from the sources.  If your AIX machine has
> some optimised maths library, such as IBM's MASS or Intel's MKL, then
> you probably want to do this anyway.

There?s even a section in the Installation and Administration Guide. On my machine it gets pulled up with help, and it should be shipped with every installation of R.


http://127.0.0.1:30169/doc/manual/R-admin.html#AIX

? 
David.


> 
> Cheers,
> 
> Loris
> 
> -- 
> This signature is currently under construction.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Nov  3 19:13:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 03 Nov 2015 10:13:00 -0800
Subject: [R] R in UNIX OS
In-Reply-To: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
References: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
Message-ID: <BDE31430-C813-4B5F-AFC7-D76C70DAEDC4@dcn.davis.CA.us>

You are in the hinterlands of operating systems. If you Google for R and AIX you should find an R-forge project that purports to offer some assistance, but I suspect that a copy of the R source code and the R Installation and Administration document will be your best friends. Your success will probably strongly depend on how much of the GNU software development chain that you already have working.  If you have more questions then you should read the Posting Guide mentioned at the bottom of this message which directs you to the R-devel mailing list for questions on compiling R. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 3, 2015 2:47:15 AM PST, "Javier Villacampa Gonz?lez" <javier.villacampa.gonzalez at gmail.com> wrote:
>Hello,
>
>I have a silly questions:
>
>is possilbe to install R in a AIX OS Machine?
>Where can I found the download files?
>
>Thank you in advance
>
>Javier
>--
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From typhenn at yahoo.com  Tue Nov  3 23:00:28 2015
From: typhenn at yahoo.com (Typhenn Brichieri-Colombi)
Date: Tue, 3 Nov 2015 22:00:28 +0000 (UTC)
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>

Hello,
I am using the "activity" package developed by Marcus Rowcliffe (released in February, 2015). This package uses time in radians to estimate activity. I have camera trap data in 24 hour times (hh:mm) - how do I convert these into radians? (e.g. My time-of-detection at 19:44, how do I convert this into radians?)
Thank you for your time and your help
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov  3 23:52:07 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Nov 2015 14:52:07 -0800
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>

Hint: 24 hours = 24x60 = 1440 minutes = 2 pi radians.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 3, 2015 at 2:00 PM, Typhenn Brichieri-Colombi via R-help
<r-help at r-project.org> wrote:
> Hello,
> I am using the "activity" package developed by Marcus Rowcliffe (released in February, 2015). This package uses time in radians to estimate activity. I have camera trap data in 24 hour times (hh:mm) - how do I convert these into radians? (e.g. My time-of-detection at 19:44, how do I convert this into radians?)
> Thank you for your time and your help
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Nov  3 23:54:46 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Nov 2015 14:54:46 -0800
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
Message-ID: <CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>

... should have said: with a 24 hour "clock".

-- Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 3, 2015 at 2:52 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Hint: 24 hours = 24x60 = 1440 minutes = 2 pi radians.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Tue, Nov 3, 2015 at 2:00 PM, Typhenn Brichieri-Colombi via R-help
> <r-help at r-project.org> wrote:
>> Hello,
>> I am using the "activity" package developed by Marcus Rowcliffe (released in February, 2015). This package uses time in radians to estimate activity. I have camera trap data in 24 hour times (hh:mm) - how do I convert these into radians? (e.g. My time-of-detection at 19:44, how do I convert this into radians?)
>> Thank you for your time and your help
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Wed Nov  4 01:26:34 2015
From: rsherry8 at comcast.net (Robert Sherry)
Date: Tue, 3 Nov 2015 19:26:34 -0500
Subject: [R] Working with Data Frames
Message-ID: <563950BA.8030901@comcast.net>

I have created what I believe to be a data frame. It is called 
env1$SPY.  The r statement head( env1$SPY ) produces the following output:

            SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted
1995-01-03  45.7031  45.8437 45.6875   45.7812     324300 31.55312
1995-01-04  45.9843  46.0000 45.7500   46.0000     351800 31.70392
1995-01-05  46.0312  46.1093 45.9531   46.0000      89800 31.70392
1995-01-06  46.0937  46.2500 45.9062   46.0468     448400 31.73617
1995-01-09  46.0312  46.0937 46.0000   46.0937      36800 31.76850
1995-01-10  46.2031  46.3906 46.1406   46.1406     229800 31.80082

The above data from was created by the following commands:
     library( quantmod )
     env1 <- new.env()
     getSymbols("SPY", src = 'yahoo', from = '1995-01-01', env = env1, 
auto.assign = T)

Now, what I want to do is to loo through the data look for when the 
month changes. What is the proper way of writing a for loop in
R and access the date field?

Bob


From Peter.Alspach at plantandfood.co.nz  Wed Nov  4 01:46:29 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 4 Nov 2015 13:46:29 +1300
Subject: [R] Working with Data Frames
In-Reply-To: <563950BA.8030901@comcast.net>
References: <563950BA.8030901@comcast.net>
Message-ID: <E41B375B7520DE4A8C60781AC60B7545067F037FD4@AKLEXM01.PFR.CO.NZ>

Tena koe Robert

Many times in R one can do things without a loop.  In this case, see ?rle.  You might also need to check substring or months depending on how you dates are stored.

HTH ....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Robert Sherry
Sent: Wednesday, 4 November 2015 1:27 p.m.
To: r-help at r-project.org
Subject: [R] Working with Data Frames

I have created what I believe to be a data frame. It is called env1$SPY.  The r statement head( env1$SPY ) produces the following output:

            SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted
1995-01-03  45.7031  45.8437 45.6875   45.7812     324300 31.55312
1995-01-04  45.9843  46.0000 45.7500   46.0000     351800 31.70392
1995-01-05  46.0312  46.1093 45.9531   46.0000      89800 31.70392
1995-01-06  46.0937  46.2500 45.9062   46.0468     448400 31.73617
1995-01-09  46.0312  46.0937 46.0000   46.0937      36800 31.76850
1995-01-10  46.2031  46.3906 46.1406   46.1406     229800 31.80082

The above data from was created by the following commands:
     library( quantmod )
     env1 <- new.env()
     getSymbols("SPY", src = 'yahoo', from = '1995-01-01', env = env1, auto.assign = T)

Now, what I want to do is to loo through the data look for when the month changes. What is the proper way of writing a for loop in R and access the date field?

Bob

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From josh.m.ulrich at gmail.com  Wed Nov  4 01:56:59 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 3 Nov 2015 18:56:59 -0600
Subject: [R] Working with Data Frames
In-Reply-To: <563950BA.8030901@comcast.net>
References: <563950BA.8030901@comcast.net>
Message-ID: <CAPPM_gSefHOAW=fiY+mzrHwqyV+2MNeQ73Z9a3RPR6=9-gWwOw@mail.gmail.com>

On Tue, Nov 3, 2015 at 6:26 PM, Robert Sherry <rsherry8 at comcast.net> wrote:
> I have created what I believe to be a data frame. It is called env1$SPY.

It's not a data.frame.  You can use str() to look at the *str*ucture
of an object:

R> str(env1$SPY)
An ?xts? object on 1995-01-03/2015-11-02 containing:
  Data: num [1:5247, 1:6] 45.7 46 46 46.1 46 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:6] "SPY.Open" "SPY.High" "SPY.Low" "SPY.Close" ...
  Indexed by objects of class: [Date] TZ: UTC
  xts Attributes:
List of 2
 $ src    : chr "yahoo"
 $ updated: POSIXct[1:1], format: "2015-11-03 18:51:48"

> The r statement head( env1$SPY ) produces the following output:
>
>            SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted
> 1995-01-03  45.7031  45.8437 45.6875   45.7812     324300 31.55312
> 1995-01-04  45.9843  46.0000 45.7500   46.0000     351800 31.70392
> 1995-01-05  46.0312  46.1093 45.9531   46.0000      89800 31.70392
> 1995-01-06  46.0937  46.2500 45.9062   46.0468     448400 31.73617
> 1995-01-09  46.0312  46.0937 46.0000   46.0937      36800 31.76850
> 1995-01-10  46.2031  46.3906 46.1406   46.1406     229800 31.80082
>
> The above data from was created by the following commands:
>     library( quantmod )
>     env1 <- new.env()
>     getSymbols("SPY", src = 'yahoo', from = '1995-01-01', env = env1,
> auto.assign = T)
>
> Now, what I want to do is to loo through the data look for when the month
> changes. What is the proper way of writing a for loop in
> R and access the date field?
>
Since the above is an xts object, there is no "date field".  There's
an index attribute.  It would probably help you a lot to read the xts
and zoo vignettes/FAQ.

You would also get better help if you were more specific about what
you're trying to do.  There's probably an easier way to do what you
intend to do with a loop.

> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From bgunter.4567 at gmail.com  Wed Nov  4 01:57:30 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 3 Nov 2015 16:57:30 -0800
Subject: [R] Working with Data Frames
In-Reply-To: <563950BA.8030901@comcast.net>
References: <563950BA.8030901@comcast.net>
Message-ID: <CAGxFJbSQwWSEPqa9+ov-DxtBzpzPxYCYuhVnMZ-185madDagaQ@mail.gmail.com>

Have you gone through any R tutorials? There are innumerable good ones
on the web -- and one that ships with R (An Intro to R). Don't you
think you should make an effort to learn some basics on your own
before posting here?

... or do I misinterpret your question? (And if so, my apologies --
feel free to chastise me appropriately).

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 3, 2015 at 4:26 PM, Robert Sherry <rsherry8 at comcast.net> wrote:
> I have created what I believe to be a data frame. It is called env1$SPY.
> The r statement head( env1$SPY ) produces the following output:
>
>            SPY.Open SPY.High SPY.Low SPY.Close SPY.Volume SPY.Adjusted
> 1995-01-03  45.7031  45.8437 45.6875   45.7812     324300 31.55312
> 1995-01-04  45.9843  46.0000 45.7500   46.0000     351800 31.70392
> 1995-01-05  46.0312  46.1093 45.9531   46.0000      89800 31.70392
> 1995-01-06  46.0937  46.2500 45.9062   46.0468     448400 31.73617
> 1995-01-09  46.0312  46.0937 46.0000   46.0937      36800 31.76850
> 1995-01-10  46.2031  46.3906 46.1406   46.1406     229800 31.80082
>
> The above data from was created by the following commands:
>     library( quantmod )
>     env1 <- new.env()
>     getSymbols("SPY", src = 'yahoo', from = '1995-01-01', env = env1,
> auto.assign = T)
>
> Now, what I want to do is to loo through the data look for when the month
> changes. What is the proper way of writing a for loop in
> R and access the date field?
>
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Nov  4 02:10:24 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 Nov 2015 12:10:24 +1100
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fV6dxeBBm6O0+KijPxzyoEfFX4D+7SvF0iB=_sxew2JTA@mail.gmail.com>

Hi Typhenn,
Have a look at clock24.plot in the plotrix package.

Jim


On Wed, Nov 4, 2015 at 9:00 AM, Typhenn Brichieri-Colombi via R-help <
r-help at r-project.org> wrote:

> Hello,
> I am using the "activity" package developed by Marcus Rowcliffe (released
> in February, 2015). This package uses time in radians to estimate activity.
> I have camera trap data in 24 hour times (hh:mm) - how do I convert these
> into radians? (e.g. My time-of-detection at 19:44, how do I convert this
> into radians?)
> Thank you for your time and your help
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Wed Nov  4 04:02:55 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 4 Nov 2015 06:02:55 +0300
Subject: [R] problem in R-code
Message-ID: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>

Dear R-users

I have a problem in the code below, the problem is because i want to change
the variable BZ which is a vector with 200x1 dimension to the var. W which
is categorical variable with same dimension of BZ but with categorical
values with 4 categories but i got on only zero values in w why?  any help
would be appreciated.

N<-200;P<-9                       #Sample size
BZ=numeric(N)

W<-numeric(N)

for (t in 1:1) {
  #Generate the data for the simulation study
  for (i in 1:N) {

    #transform theta to ordered categorical variables


    for(j in 1:1){
      if(BZ[j] < 0.25){
        W[j] = 1
      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
        W[j] = 2
      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
        W[j] = 3
      }else{
        W[j] = 4
      }}


    #Input data set
    data<-list(N=200,P=9,Q=W)

  }} #end

W




Regards


-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Nov  4 04:35:37 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 4 Nov 2015 16:35:37 +1300
Subject: [R] [FORGED]  problem in R-code
In-Reply-To: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
Message-ID: <56397D09.3020105@auckland.ac.nz>


I have not mustered the stamina to go through your code in detail, but 
it looks to me like the "1:1" constructions are typos and should perhaps 
be "1:N".

Aside from that, I conjecture that what you want to accomplish could be 
very simply done with the cut() function.  This is not entirely clear 
since it is not really clear what you want to accomplish.

Note that you appear to evince a misunderstanding of R data structures;
a vector of length 200 is subtly different from a 200 x 1 array.

I think you should study up on some basic R (e.g. read "An Introduction 
to R") before proceeding further.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 04/11/15 16:02, thanoon younis wrote:
> Dear R-users
>
> I have a problem in the code below, the problem is because i want to change
> the variable BZ which is a vector with 200x1 dimension to the var. W which
> is categorical variable with same dimension of BZ but with categorical
> values with 4 categories but i got on only zero values in w why?  any help
> would be appreciated.
>
> N<-200;P<-9                       #Sample size
> BZ=numeric(N)
>
> W<-numeric(N)
>
> for (t in 1:1) {
>    #Generate the data for the simulation study
>    for (i in 1:N) {
>
>      #transform theta to ordered categorical variables
>
>
>      for(j in 1:1){
>        if(BZ[j] < 0.25){
>          W[j] = 1
>        }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>          W[j] = 2
>        }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>          W[j] = 3
>        }else{
>          W[j] = 4
>        }}
>
>
>      #Input data set
>      data<-list(N=200,P=9,Q=W)
>
>    }} #end


From boris.steipe at utoronto.ca  Wed Nov  4 04:35:01 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 3 Nov 2015 22:35:01 -0500
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
Message-ID: <483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>

Why don't you just multiply by four, round, and add one?



B.
On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Dear R-users
> 
> I have a problem in the code below, the problem is because i want to change
> the variable BZ which is a vector with 200x1 dimension to the var. W which
> is categorical variable with same dimension of BZ but with categorical
> values with 4 categories but i got on only zero values in w why?  any help
> would be appreciated.
> 
> N<-200;P<-9                       #Sample size
> BZ=numeric(N)
> 
> W<-numeric(N)
> 
> for (t in 1:1) {
>  #Generate the data for the simulation study
>  for (i in 1:N) {
> 
>    #transform theta to ordered categorical variables
> 
> 
>    for(j in 1:1){
>      if(BZ[j] < 0.25){
>        W[j] = 1
>      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>        W[j] = 2
>      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>        W[j] = 3
>      }else{
>        W[j] = 4
>      }}
> 
> 
>    #Input data set
>    data<-list(N=200,P=9,Q=W)
> 
>  }} #end
> 
> W
> 
> 
> 
> 
> Regards
> 
> 
> -- 
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Nov  4 04:40:14 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 3 Nov 2015 22:40:14 -0500
Subject: [R] problem in R-code
In-Reply-To: <483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
Message-ID: <4F00AA4E-1E45-4859-83A3-DE6FEE3254C9@utoronto.ca>

Sorry, not round. floor()


B.

On Nov 3, 2015, at 10:35 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> Why don't you just multiply by four, round, and add one?
> 
> 
> 
> B.
> On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
>> Dear R-users
>> 
>> I have a problem in the code below, the problem is because i want to change
>> the variable BZ which is a vector with 200x1 dimension to the var. W which
>> is categorical variable with same dimension of BZ but with categorical
>> values with 4 categories but i got on only zero values in w why?  any help
>> would be appreciated.
>> 
>> N<-200;P<-9                       #Sample size
>> BZ=numeric(N)
>> 
>> W<-numeric(N)
>> 
>> for (t in 1:1) {
>> #Generate the data for the simulation study
>> for (i in 1:N) {
>> 
>>   #transform theta to ordered categorical variables
>> 
>> 
>>   for(j in 1:1){
>>     if(BZ[j] < 0.25){
>>       W[j] = 1
>>     }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>>       W[j] = 2
>>     }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>>       W[j] = 3
>>     }else{
>>       W[j] = 4
>>     }}
>> 
>> 
>>   #Input data set
>>   data<-list(N=200,P=9,Q=W)
>> 
>> }} #end
>> 
>> W
>> 
>> 
>> 
>> 
>> Regards
>> 
>> 
>> -- 
>> Thanoon Y. Thanoon
>> PhD Candidate
>> Department of Mathematical Sciences
>> Faculty of Science
>> University Technology Malaysia, UTM
>> E.Mail: Thanoon.younis80 at gmail.com
>> E.Mail: dawn_prayer80 at yahoo.com
>> Facebook:Thanoon Younis AL-Shakerchy
>> Twitter: Thanoon Alshakerchy
>> H.P:00601127550205
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From thanoon.younis80 at gmail.com  Wed Nov  4 04:43:07 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 4 Nov 2015 06:43:07 +0300
Subject: [R] problem in R-code
In-Reply-To: <483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
Message-ID: <CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>

Thank you for your response

I have a vector of unknown values BZ which is defined already BZ=numeric(N)
 and i want to transfer BZ to ordered categorical variable with 4
categories W but when i write this code

  for(j in 1:1){
      if(BZ[j] < 0.25){
        W[j] = 1
      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
        W[j] = 2
      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
        W[j] = 3
      }else{
        W[j] = 4
      }}

i found the values of W are only 0, but if i change  for(j in 1:N) the
values of W will be only 1. how can i solve this problem?
Regards

On 4 November 2015 at 06:35, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> Why don't you just multiply by four, round, and add one?
>
>
>
> B.
> On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com>
> wrote:
>
> > Dear R-users
> >
> > I have a problem in the code below, the problem is because i want to
> change
> > the variable BZ which is a vector with 200x1 dimension to the var. W
> which
> > is categorical variable with same dimension of BZ but with categorical
> > values with 4 categories but i got on only zero values in w why?  any
> help
> > would be appreciated.
> >
> > N<-200;P<-9                       #Sample size
> > BZ=numeric(N)
> >
> > W<-numeric(N)
> >
> > for (t in 1:1) {
> >  #Generate the data for the simulation study
> >  for (i in 1:N) {
> >
> >    #transform theta to ordered categorical variables
> >
> >
> >    for(j in 1:1){
> >      if(BZ[j] < 0.25){
> >        W[j] = 1
> >      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
> >        W[j] = 2
> >      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
> >        W[j] = 3
> >      }else{
> >        W[j] = 4
> >      }}
> >
> >
> >    #Input data set
> >    data<-list(N=200,P=9,Q=W)
> >
> >  }} #end
> >
> > W
> >
> >
> >
> >
> > Regards
> >
> >
> > --
> > Thanoon Y. Thanoon
> > PhD Candidate
> > Department of Mathematical Sciences
> > Faculty of Science
> > University Technology Malaysia, UTM
> > E.Mail: Thanoon.younis80 at gmail.com
> > E.Mail: dawn_prayer80 at yahoo.com
> > Facebook:Thanoon Younis AL-Shakerchy
> > Twitter: Thanoon Alshakerchy
> > H.P:00601127550205
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From brown at fastmail.com  Tue Nov  3 22:35:49 2015
From: brown at fastmail.com (Eric Brown)
Date: Tue, 03 Nov 2015 15:35:49 -0600
Subject: [R] R in UNIX OS
In-Reply-To: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
	("Javier Villacampa \=\?utf-8\?Q\?Gonz\=C3\=A1lez\=22's\?\= message of
	"Tue, 3 Nov 2015 11:47:15 +0100")
References: <CAOZ+RxEFOyX-7TtST+Oyd60n=Zu+DhLBXM22=oSfEd+JYmbRXw@mail.gmail.com>
Message-ID: <m2wptyzryi.fsf@fastmail.com>

Javier Villacampa Gonz?lez <javier.villacampa.gonzalez at gmail.com> 
writes:
>
> is possilbe to install R in a AIX OS Machine?
> Where can I found the download files?
>

Hi Javier,

I tried to install on AIX using xlc/xlf and the native stack, but 
it did
not work.  In the bowels of Google, there are some patches 
proposed for
the 2.x series, and I was unable to get them to work.

My recollection is that the Freeware for AIX (i.e. GNU stack) is 
rather
old, and you would have a hard time getting newer versions of R to
compile with those due to version dependencies.

It's really tough to get GNU R to run, unless your machine happens 
to be
running GNU/Linux on Power.

Good luck,
Eric


From boris.steipe at utoronto.ca  Wed Nov  4 05:02:18 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 3 Nov 2015 23:02:18 -0500
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
Message-ID: <832AE656-A483-4F88-B14E-5B6FF83516B3@utoronto.ca>

Your approach does not make sense.

If you initialize a vector as say ...

   BZ <- numeric(5)
... what do you _expect BZ contains?

Also: if you run a loop like you do
for (j in 1:1) {
   print(j)
}
... what do you _expect_ will happen?


B.

On Nov 3, 2015, at 10:43 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Thank you for your response
> 
> I have a vector of unknown values BZ which is defined already BZ=numeric(N)  and i want to transfer BZ to ordered categorical variable with 4 categories W but when i write this code
> 
>   for(j in 1:1){
>       if(BZ[j] < 0.25){
>         W[j] = 1
>       }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>         W[j] = 2
>       }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>         W[j] = 3
>       }else{
>         W[j] = 4
>       }}
> 
> i found the values of W are only 0, but if i change  for(j in 1:N) the values of W will be only 1. how can i solve this problem?
> Regards
> 
> On 4 November 2015 at 06:35, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Why don't you just multiply by four, round, and add one?
> 
> 
> 
> B.
> On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> > Dear R-users
> >
> > I have a problem in the code below, the problem is because i want to change
> > the variable BZ which is a vector with 200x1 dimension to the var. W which
> > is categorical variable with same dimension of BZ but with categorical
> > values with 4 categories but i got on only zero values in w why?  any help
> > would be appreciated.
> >
> > N<-200;P<-9                       #Sample size
> > BZ=numeric(N)
> >
> > W<-numeric(N)
> >
> > for (t in 1:1) {
> >  #Generate the data for the simulation study
> >  for (i in 1:N) {
> >
> >    #transform theta to ordered categorical variables
> >
> >
> >    for(j in 1:1){
> >      if(BZ[j] < 0.25){
> >        W[j] = 1
> >      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
> >        W[j] = 2
> >      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
> >        W[j] = 3
> >      }else{
> >        W[j] = 4
> >      }}
> >
> >
> >    #Input data set
> >    data<-list(N=200,P=9,Q=W)
> >
> >  }} #end
> >
> > W
> >
> >
> >
> >
> > Regards
> >
> >
> > --
> > Thanoon Y. Thanoon
> > PhD Candidate
> > Department of Mathematical Sciences
> > Faculty of Science
> > University Technology Malaysia, UTM
> > E.Mail: Thanoon.younis80 at gmail.com
> > E.Mail: dawn_prayer80 at yahoo.com
> > Facebook:Thanoon Younis AL-Shakerchy
> > Twitter: Thanoon Alshakerchy
> > H.P:00601127550205
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> -- 
> Thanoon Y. Thanoon
> PhD Candidate 
> Department of Mathematical Sciences 
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205


From boris.steipe at utoronto.ca  Wed Nov  4 05:09:48 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 3 Nov 2015 23:09:48 -0500
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nG36jX3vKjT=G5qiY7zkTBSRqXixjfOQY=ik-uvo4hs0g@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
	<832AE656-A483-4F88-B14E-5B6FF83516B3@utoronto.ca>
	<CABLo8nG36jX3vKjT=G5qiY7zkTBSRqXixjfOQY=ik-uvo4hs0g@mail.gmail.com>
Message-ID: <5028F632-32B5-40B9-91D1-8A2E8941A583@utoronto.ca>

Are you telling me it contains only zeros? Or is it a vector of length zero?

B.


On Nov 3, 2015, at 11:07 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> BZ is hidden variable with zero values.
> 
> On 4 November 2015 at 07:02, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Your approach does not make sense.
> 
> If you initialize a vector as say ...
> 
>    BZ <- numeric(5)
> ... what do you _expect BZ contains?
> 
> Also: if you run a loop like you do
> for (j in 1:1) {
>    print(j)
> }
> ... what do you _expect_ will happen?
> 
> 
> B.
> 
> On Nov 3, 2015, at 10:43 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> > Thank you for your response
> >
> > I have a vector of unknown values BZ which is defined already BZ=numeric(N)  and i want to transfer BZ to ordered categorical variable with 4 categories W but when i write this code
> >
> >   for(j in 1:1){
> >       if(BZ[j] < 0.25){
> >         W[j] = 1
> >       }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
> >         W[j] = 2
> >       }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
> >         W[j] = 3
> >       }else{
> >         W[j] = 4
> >       }}
> >
> > i found the values of W are only 0, but if i change  for(j in 1:N) the values of W will be only 1. how can i solve this problem?
> > Regards
> >
> > On 4 November 2015 at 06:35, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > Why don't you just multiply by four, round, and add one?
> >
> >
> >
> > B.
> > On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> >
> > > Dear R-users
> > >
> > > I have a problem in the code below, the problem is because i want to change
> > > the variable BZ which is a vector with 200x1 dimension to the var. W which
> > > is categorical variable with same dimension of BZ but with categorical
> > > values with 4 categories but i got on only zero values in w why?  any help
> > > would be appreciated.
> > >
> > > N<-200;P<-9                       #Sample size
> > > BZ=numeric(N)
> > >
> > > W<-numeric(N)
> > >
> > > for (t in 1:1) {
> > >  #Generate the data for the simulation study
> > >  for (i in 1:N) {
> > >
> > >    #transform theta to ordered categorical variables
> > >
> > >
> > >    for(j in 1:1){
> > >      if(BZ[j] < 0.25){
> > >        W[j] = 1
> > >      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
> > >        W[j] = 2
> > >      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
> > >        W[j] = 3
> > >      }else{
> > >        W[j] = 4
> > >      }}
> > >
> > >
> > >    #Input data set
> > >    data<-list(N=200,P=9,Q=W)
> > >
> > >  }} #end
> > >
> > > W
> > >
> > >
> > >
> > >
> > > Regards
> > >
> > >
> > > --
> > > Thanoon Y. Thanoon
> > > PhD Candidate
> > > Department of Mathematical Sciences
> > > Faculty of Science
> > > University Technology Malaysia, UTM
> > > E.Mail: Thanoon.younis80 at gmail.com
> > > E.Mail: dawn_prayer80 at yahoo.com
> > > Facebook:Thanoon Younis AL-Shakerchy
> > > Twitter: Thanoon Alshakerchy
> > > H.P:00601127550205
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Thanoon Y. Thanoon
> > PhD Candidate
> > Department of Mathematical Sciences
> > Faculty of Science
> > University Technology Malaysia, UTM
> > E.Mail: Thanoon.younis80 at gmail.com
> > E.Mail: dawn_prayer80 at yahoo.com
> > Facebook:Thanoon Younis AL-Shakerchy
> > Twitter: Thanoon Alshakerchy
> > H.P:00601127550205
> 
> 
> 
> 
> -- 
> Thanoon Y. Thanoon
> PhD Candidate 
> Department of Mathematical Sciences 
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205


From boris.steipe at utoronto.ca  Wed Nov  4 05:17:15 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 3 Nov 2015 23:17:15 -0500
Subject: [R] problem in R-code
In-Reply-To: <5028F632-32B5-40B9-91D1-8A2E8941A583@utoronto.ca>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
	<832AE656-A483-4F88-B14E-5B6FF83516B3@utoronto.ca>
	<CABLo8nG36jX3vKjT=G5qiY7zkTBSRqXixjfOQY=ik-uvo4hs0g@mail.gmail.com>
	<5028F632-32B5-40B9-91D1-8A2E8941A583@utoronto.ca>
Message-ID: <B949C360-A823-4754-B9BE-86E5CB83423D@utoronto.ca>

Whatever -
just type:

W <- floor(BZ * 4) + 1



B.

On Nov 3, 2015, at 11:09 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> Are you telling me it contains only zeros? Or is it a vector of length zero?
> 
> B.
> 
> 
> On Nov 3, 2015, at 11:07 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
>> BZ is hidden variable with zero values.
>> 
>> On 4 November 2015 at 07:02, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Your approach does not make sense.
>> 
>> If you initialize a vector as say ...
>> 
>>   BZ <- numeric(5)
>> ... what do you _expect BZ contains?
>> 
>> Also: if you run a loop like you do
>> for (j in 1:1) {
>>   print(j)
>> }
>> ... what do you _expect_ will happen?
>> 
>> 
>> B.
>> 
>> On Nov 3, 2015, at 10:43 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
>> 
>>> Thank you for your response
>>> 
>>> I have a vector of unknown values BZ which is defined already BZ=numeric(N)  and i want to transfer BZ to ordered categorical variable with 4 categories W but when i write this code
>>> 
>>>  for(j in 1:1){
>>>      if(BZ[j] < 0.25){
>>>        W[j] = 1
>>>      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>>>        W[j] = 2
>>>      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>>>        W[j] = 3
>>>      }else{
>>>        W[j] = 4
>>>      }}
>>> 
>>> i found the values of W are only 0, but if i change  for(j in 1:N) the values of W will be only 1. how can i solve this problem?
>>> Regards
>>> 
>>> On 4 November 2015 at 06:35, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> Why don't you just multiply by four, round, and add one?
>>> 
>>> 
>>> 
>>> B.
>>> On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:
>>> 
>>>> Dear R-users
>>>> 
>>>> I have a problem in the code below, the problem is because i want to change
>>>> the variable BZ which is a vector with 200x1 dimension to the var. W which
>>>> is categorical variable with same dimension of BZ but with categorical
>>>> values with 4 categories but i got on only zero values in w why?  any help
>>>> would be appreciated.
>>>> 
>>>> N<-200;P<-9                       #Sample size
>>>> BZ=numeric(N)
>>>> 
>>>> W<-numeric(N)
>>>> 
>>>> for (t in 1:1) {
>>>> #Generate the data for the simulation study
>>>> for (i in 1:N) {
>>>> 
>>>>   #transform theta to ordered categorical variables
>>>> 
>>>> 
>>>>   for(j in 1:1){
>>>>     if(BZ[j] < 0.25){
>>>>       W[j] = 1
>>>>     }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>>>>       W[j] = 2
>>>>     }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>>>>       W[j] = 3
>>>>     }else{
>>>>       W[j] = 4
>>>>     }}
>>>> 
>>>> 
>>>>   #Input data set
>>>>   data<-list(N=200,P=9,Q=W)
>>>> 
>>>> }} #end
>>>> 
>>>> W
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Regards
>>>> 
>>>> 
>>>> --
>>>> Thanoon Y. Thanoon
>>>> PhD Candidate
>>>> Department of Mathematical Sciences
>>>> Faculty of Science
>>>> University Technology Malaysia, UTM
>>>> E.Mail: Thanoon.younis80 at gmail.com
>>>> E.Mail: dawn_prayer80 at yahoo.com
>>>> Facebook:Thanoon Younis AL-Shakerchy
>>>> Twitter: Thanoon Alshakerchy
>>>> H.P:00601127550205
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> --
>>> Thanoon Y. Thanoon
>>> PhD Candidate
>>> Department of Mathematical Sciences
>>> Faculty of Science
>>> University Technology Malaysia, UTM
>>> E.Mail: Thanoon.younis80 at gmail.com
>>> E.Mail: dawn_prayer80 at yahoo.com
>>> Facebook:Thanoon Younis AL-Shakerchy
>>> Twitter: Thanoon Alshakerchy
>>> H.P:00601127550205
>> 
>> 
>> 
>> 
>> -- 
>> Thanoon Y. Thanoon
>> PhD Candidate 
>> Department of Mathematical Sciences 
>> Faculty of Science
>> University Technology Malaysia, UTM
>> E.Mail: Thanoon.younis80 at gmail.com
>> E.Mail: dawn_prayer80 at yahoo.com
>> Facebook:Thanoon Younis AL-Shakerchy
>> Twitter: Thanoon Alshakerchy
>> H.P:00601127550205
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Nov  4 05:20:41 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 Nov 2015 15:20:41 +1100
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
Message-ID: <CA+8X3fVNUUxvC7hShLd57gK-5LqhgQk4bR+uqwL0+2hAfX1+Ew@mail.gmail.com>

Hi thanoon,
The problem may lie in your definition of BZ (which I see Boris has also
noticed). Given your code, it will be a vector containing 200 zeros. Your
code will generate 200 ones as zero is less than 0.25. Try defining BZ as
follows:

BZ<-runif(200)

You should get something more interesting from your code or that suggested
by Boris, or even this:

W<-as.numeric(cut(BZ,breaks=c(0,0.25,0.5,0.75,1)))

Jim

On Wed, Nov 4, 2015 at 2:43 PM, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Thank you for your response
>
> I have a vector of unknown values BZ which is defined already BZ=numeric(N)
>  and i want to transfer BZ to ordered categorical variable with 4
> categories W but when i write this code
>
>   for(j in 1:1){
>       if(BZ[j] < 0.25){
>         W[j] = 1
>       }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
>         W[j] = 2
>       }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
>         W[j] = 3
>       }else{
>         W[j] = 4
>       }}
>
> i found the values of W are only 0, but if i change  for(j in 1:N) the
> values of W will be only 1. how can i solve this problem?
> Regards
>
> On 4 November 2015 at 06:35, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
>
> > Why don't you just multiply by four, round, and add one?
> >
> >
> >
> > B.
> > On Nov 3, 2015, at 10:02 PM, thanoon younis <thanoon.younis80 at gmail.com>
> > wrote:
> >
> > > Dear R-users
> > >
> > > I have a problem in the code below, the problem is because i want to
> > change
> > > the variable BZ which is a vector with 200x1 dimension to the var. W
> > which
> > > is categorical variable with same dimension of BZ but with categorical
> > > values with 4 categories but i got on only zero values in w why?  any
> > help
> > > would be appreciated.
> > >
> > > N<-200;P<-9                       #Sample size
> > > BZ=numeric(N)
> > >
> > > W<-numeric(N)
> > >
> > > for (t in 1:1) {
> > >  #Generate the data for the simulation study
> > >  for (i in 1:N) {
> > >
> > >    #transform theta to ordered categorical variables
> > >
> > >
> > >    for(j in 1:1){
> > >      if(BZ[j] < 0.25){
> > >        W[j] = 1
> > >      }else if(BZ[j] >=0.25 & BZ[j] < 0.5){
> > >        W[j] = 2
> > >      }else if(BZ[j] >=0.5 & BZ[j] < 0.75){
> > >        W[j] = 3
> > >      }else{
> > >        W[j] = 4
> > >      }}
> > >
> > >
> > >    #Input data set
> > >    data<-list(N=200,P=9,Q=W)
> > >
> > >  }} #end
> > >
> > > W
> > >
> > >
> > >
> > >
> > > Regards
> > >
> > >
> > > --
> > > Thanoon Y. Thanoon
> > > PhD Candidate
> > > Department of Mathematical Sciences
> > > Faculty of Science
> > > University Technology Malaysia, UTM
> > > E.Mail: Thanoon.younis80 at gmail.com
> > > E.Mail: dawn_prayer80 at yahoo.com
> > > Facebook:Thanoon Younis AL-Shakerchy
> > > Twitter: Thanoon Alshakerchy
> > > H.P:00601127550205
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Nov  4 09:02:46 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 4 Nov 2015 09:02:46 +0100
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
	<CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>
Message-ID: <22073.48038.134876.110551@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Tue, 3 Nov 2015 14:54:46 -0800 writes:

    > ... should have said: with a 24 hour "clock".
    > -- Bert
    > Bert Gunter

Hmm,  thank you Bert.

I know nothing about measuring time in radians, and for me,
'radians' are angles, and hence we are talking about
analogue watches when measuring time with them, and now, as a
citizen from  "the watch maker country" I do like analogue
watches or let's nowadays say "graphical" watches, i.e., with clock
faces and short and long (hour and minute) hands, and I think I
have only ever seen 12 h watches at least on church towers (yes,
here in CH) or wrist watches...
(?)

Martin
(Maechler, ETH Zurich, Switzerland)

    > On Tue, Nov 3, 2015 at 2:52 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    >> Hint: 24 hours = 24x60 = 1440 minutes = 2 pi radians.
    >> 
    >> Cheers,
    >> Bert
    >> Bert Gunter
    >> 
    >> "Data is not information. Information is not knowledge. And knowledge
    >> is certainly not wisdom."
    >> -- Clifford Stoll
    >> 
    >> 
    >> On Tue, Nov 3, 2015 at 2:00 PM, Typhenn Brichieri-Colombi via R-help
    >> <r-help at r-project.org> wrote:
    >>> Hello,
    >>> I am using the "activity" package developed by Marcus Rowcliffe (released in February, 2015). This package uses time in radians to estimate activity. I have camera trap data in 24 hour times (hh:mm) - how do I convert these into radians? (e.g. My time-of-detection at 19:44, how do I convert this into radians?)
    >>> Thank you for your time and your help
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From thanoon.younis80 at gmail.com  Wed Nov  4 10:02:40 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 4 Nov 2015 12:02:40 +0300
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nGa+gXTmP7cYDN6-C_fa-stvGf+3AipMJbOLW8q5_0FVg@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
	<CA+8X3fVNUUxvC7hShLd57gK-5LqhgQk4bR+uqwL0+2hAfX1+Ew@mail.gmail.com>
	<CABLo8nGa+gXTmP7cYDN6-C_fa-stvGf+3AipMJbOLW8q5_0FVg@mail.gmail.com>
Message-ID: <CABLo8nHmdYOh1jpMx75w7dvspDsrpBcejXJFmbphCpsmPsSAew@mail.gmail.com>

Dear R-Users

After correct some errors in the code below i have only this error

"Error in if (BZ[i] < 0.25) { : missing value where TRUE/FALSE needed"

how can i solve this problem please?



N<-200;P<-9                       #Sample size
BZ=matrix(NA, nrow=N, ncol=1)


W=matrix(NA, nrow=N, ncol=1)


for (t in 1:100) {
  #Generate the data for the simulation study
  for (i in 1:N) {

    #transform theta to ordered categorical variables


    for(j in 1:1){
      if(BZ[i] < 0.25){
        W[i] = 1
      }else if(BZ[i] >=0.25 & BZ[i] < 0.5){
        W[i] = 2
      }else if(BZ[i] >=0.5 & BZ[i] < 0.75){
        W[i] = 3
      }else{
        W[i] = 4
      }}}}

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Nov  4 11:24:40 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 Nov 2015 21:24:40 +1100
Subject: [R] problem in R-code
In-Reply-To: <CABLo8nHmdYOh1jpMx75w7dvspDsrpBcejXJFmbphCpsmPsSAew@mail.gmail.com>
References: <CABLo8nGqTVBi_=g7pf34tgwZhgLmyiDuEctq=QkJjwQkYWPr-w@mail.gmail.com>
	<483507C0-C54D-4905-AC92-6D68A216D5B7@utoronto.ca>
	<CABLo8nFT5X6w7z7QPOA6c_tAedX2xFt2TDKrGpTiyUadRdEAzw@mail.gmail.com>
	<CA+8X3fVNUUxvC7hShLd57gK-5LqhgQk4bR+uqwL0+2hAfX1+Ew@mail.gmail.com>
	<CABLo8nGa+gXTmP7cYDN6-C_fa-stvGf+3AipMJbOLW8q5_0FVg@mail.gmail.com>
	<CABLo8nHmdYOh1jpMx75w7dvspDsrpBcejXJFmbphCpsmPsSAew@mail.gmail.com>
Message-ID: <CA+8X3fVVuXenYHwsMr1Z2CJfN8rddyq4-_Q8gZDS9xk8NnXvpQ@mail.gmail.com>

Hi thanoon,
Well, you have generated a one column matrix of missing values (NA) and
then tried to use those values in a logical test...

Jim

On Wed, Nov 4, 2015 at 8:02 PM, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Dear R-Users
>
> After correct some errors in the code below i have only this error
>
> "Error in if (BZ[i] < 0.25) { : missing value where TRUE/FALSE needed"
>
> how can i solve this problem please?
>
>
>
> N<-200;P<-9                       #Sample size
> BZ=matrix(NA, nrow=N, ncol=1)
>
>
> W=matrix(NA, nrow=N, ncol=1)
>
>
> for (t in 1:100) {
>   #Generate the data for the simulation study
>   for (i in 1:N) {
>
>     #transform theta to ordered categorical variables
>
>
>     for(j in 1:1){
>       if(BZ[i] < 0.25){
>         W[i] = 1
>       }else if(BZ[i] >=0.25 & BZ[i] < 0.5){
>         W[i] = 2
>       }else if(BZ[i] >=0.5 & BZ[i] < 0.75){
>         W[i] = 3
>       }else{
>         W[i] = 4
>       }}}}
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Nov  4 11:35:19 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 4 Nov 2015 21:35:19 +1100
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <22073.48038.134876.110551@stat.math.ethz.ch>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
	<CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>
	<22073.48038.134876.110551@stat.math.ethz.ch>
Message-ID: <CA+8X3fW5+-LKAn4qghaEhbuNmDMRPiYm=gU43h0gYZ2mXkgusQ@mail.gmail.com>

Ah, Martin, how is it possible that you have never encountered the 24 hour
cuckoo clock?

http://www.lutececreations.com/fiche-schneider_black_forest_cuckoo_clock__24_hour_cuckoo_clock_mt_1139_9++de+la+marque-4297.html

Jim

On Wed, Nov 4, 2015 at 7:02 PM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>     on Tue, 3 Nov 2015 14:54:46 -0800 writes:
>
>     > ... should have said: with a 24 hour "clock".
>     > -- Bert
>     > Bert Gunter
>
> Hmm,  thank you Bert.
>
> I know nothing about measuring time in radians, and for me,
> 'radians' are angles, and hence we are talking about
> analogue watches when measuring time with them, and now, as a
> citizen from  "the watch maker country" I do like analogue
> watches or let's nowadays say "graphical" watches, i.e., with clock
> faces and short and long (hour and minute) hands, and I think I
> have only ever seen 12 h watches at least on church towers (yes,
> here in CH) or wrist watches...
> (?)
>
> Martin
> (Maechler, ETH Zurich, Switzerland)
>
>     > On Tue, Nov 3, 2015 at 2:52 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>     >> Hint: 24 hours = 24x60 = 1440 minutes = 2 pi radians.
>     >>
>     >> Cheers,
>     >> Bert
>     >> Bert Gunter
>     >>
>     >> "Data is not information. Information is not knowledge. And
> knowledge
>     >> is certainly not wisdom."
>     >> -- Clifford Stoll
>     >>
>     >>
>     >> On Tue, Nov 3, 2015 at 2:00 PM, Typhenn Brichieri-Colombi via R-help
>     >> <r-help at r-project.org> wrote:
>     >>> Hello,
>     >>> I am using the "activity" package developed by Marcus Rowcliffe
> (released in February, 2015). This package uses time in radians to estimate
> activity. I have camera trap data in 24 hour times (hh:mm) - how do I
> convert these into radians? (e.g. My time-of-detection at 19:44, how do I
> convert this into radians?)
>     >>> Thank you for your time and your help
>     >>> [[alternative HTML version deleted]]
>     >>>
>     >>> ______________________________________________
>     >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >>> https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     >>> and provide commented, minimal, self-contained, reproducible code.
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Wed Nov  4 12:40:03 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 4 Nov 2015 11:40:03 +0000 (UTC)
Subject: [R] merging-binning data
In-Reply-To: <CA+vqiLHycoRq5GR0p5oZG7bRT7NAcJszCrOZxPOHuBUaPMntTw@mail.gmail.com>
References: <CA+vqiLHycoRq5GR0p5oZG7bRT7NAcJszCrOZxPOHuBUaPMntTw@mail.gmail.com>
Message-ID: <592548905.632452.1446637203703.JavaMail.yahoo@mail.yahoo.com>

Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
 


     On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
   

 Probably

split(binDistance, test).

Best,
Ista

On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> I have a vector that looks like
>? binDistance
>? ? ? ? ? ? [,1]
>? [1,] 238.95162
>? [2,] 143.08590
>? [3,]? 88.50923
>? [4,] 177.67884
>? [5,] 277.54116
>? [6,] 342.94689
>? [7,] 241.60905
>? [8,] 177.81969
>? [9,] 211.25559
> [10,] 279.72702
> [11,] 381.95738
> [12,] 483.76363
> [13,] 480.98841
> [14,] 369.75241
> [15,] 267.73650
> [16,] 138.55959
> [17,] 137.93181
> [18,] 184.75200
> [19,] 254.64359
> [20,] 328.87785
> [21,] 273.15577
> [22,] 252.52830
> [23,] 252.52830
> [24,] 252.52830
> [25,] 262.20084
> [26,] 314.93064
> [27,] 366.02996
> [28,] 442.77467
> [29,] 521.20323
> [30,] 465.33071
> [31,] 366.60582
> [32,]? 13.69540
> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
>
>
> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> Browse[2]> test
>? [1] (217,318]? (115,217]? (13.7,115] (115,217]? (217,318]? (318,420]
>? [7] (217,318]? (115,217]? (115,217]? (217,318]? (318,420]? (420,521]
> [13] (420,521]? (318,420]? (217,318]? (115,217]? (115,217]? (115,217]
> [19] (217,318]? (318,420]? (217,318]? (217,318]? (217,318]? (217,318]
> [25] (217,318]? (217,318]? (318,420]? (420,521]? (420,521]? (420,521]
> [31] (318,420]? (13.7,115]
> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
>
>
> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> How I can do that effectively in R?
> I would like to thank you for your replyRegardsAlex
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Nov  4 13:00:45 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 4 Nov 2015 07:00:45 -0500
Subject: [R] merging-binning data
In-Reply-To: <592548905.632452.1446637203703.JavaMail.yahoo@mail.yahoo.com>
References: <CA+vqiLHycoRq5GR0p5oZG7bRT7NAcJszCrOZxPOHuBUaPMntTw@mail.gmail.com>
	<592548905.632452.1446637203703.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <21031DD8-C95B-43C6-9DF4-B60373A9F38E@utoronto.ca>

I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.

Example: assume your input vector is dBin

nGroups <- 5  # number of groups
groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
groups <- floor(groups * nGroups) + 1   # discretize to nGroups integers

Now you can eg. get the indices for group 2

groups[groups == 2]

Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.

Cheers,
Boris






On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:

> Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> 
> 
> 
>     On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> 
> Probably
> 
> split(binDistance, test).
> 
> Best,
> Ista
> 
> On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
>> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
>> I have a vector that looks like
>>   binDistance
>>             [,1]
>>   [1,] 238.95162
>>   [2,] 143.08590
>>   [3,]  88.50923
>>   [4,] 177.67884
>>   [5,] 277.54116
>>   [6,] 342.94689
>>   [7,] 241.60905
>>   [8,] 177.81969
>>   [9,] 211.25559
>> [10,] 279.72702
>> [11,] 381.95738
>> [12,] 483.76363
>> [13,] 480.98841
>> [14,] 369.75241
>> [15,] 267.73650
>> [16,] 138.55959
>> [17,] 137.93181
>> [18,] 184.75200
>> [19,] 254.64359
>> [20,] 328.87785
>> [21,] 273.15577
>> [22,] 252.52830
>> [23,] 252.52830
>> [24,] 252.52830
>> [25,] 262.20084
>> [26,] 314.93064
>> [27,] 366.02996
>> [28,] 442.77467
>> [29,] 521.20323
>> [30,] 465.33071
>> [31,] 366.60582
>> [32,]  13.69540
>> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
>> 
>> 
>> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
>> Browse[2]> test
>>   [1] (217,318]  (115,217]  (13.7,115] (115,217]  (217,318]  (318,420]
>>   [7] (217,318]  (115,217]  (115,217]  (217,318]  (318,420]  (420,521]
>> [13] (420,521]  (318,420]  (217,318]  (115,217]  (115,217]  (115,217]
>> [19] (217,318]  (318,420]  (217,318]  (217,318]  (217,318]  (217,318]
>> [25] (217,318]  (217,318]  (318,420]  (420,521]  (420,521]  (420,521]
>> [31] (318,420]  (13.7,115]
>> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
>> 
>> 
>> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
>> How I can do that effectively in R?
>> I would like to thank you for your replyRegardsAlex
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bxc at steno.dk  Wed Nov  4 13:52:55 2015
From: bxc at steno.dk (BXC (Bendix Carstensen))
Date: Wed, 4 Nov 2015 12:52:55 +0000
Subject: [R] Splines with more restrictions
Message-ID: <D48624DDDF1E874FBD20BC5C1FE08FA440730BD6@NNEXMRDK001.corp.novocorp.net>

I would like to generate a natural spline where the slope beyond the last knot (the right outer knot) is constrained to be 0.
Is that available in some package around?
_____________________

Bendix Carstensen
Senior Statistician
Steno Diabetes Center
Clinical Epidemiology
Niels Steensens Vej 2-4
DK-2820 Gentofte
Denmark
phone: +45 30 75 87 38
bxc at steno.dk   http://BendixCarstensen.com


From alaios at yahoo.com  Wed Nov  4 13:57:43 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 4 Nov 2015 12:57:43 +0000 (UTC)
Subject: [R] merging-binning data
In-Reply-To: <21031DD8-C95B-43C6-9DF4-B60373A9F38E@utoronto.ca>
References: <21031DD8-C95B-43C6-9DF4-B60373A9F38E@utoronto.ca>
Message-ID: <1222950282.1674216.1446641863419.JavaMail.yahoo@mail.yahoo.com>

Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
RegardsAlex
 


     On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
   

 I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.

Example: assume your input vector is dBin

nGroups <- 5? # number of groups
groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
groups <- floor(groups * nGroups) + 1? # discretize to nGroups integers

Now you can eg. get the indices for group 2

groups[groups == 2]

Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.

Cheers,
Boris






On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:

> Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> 
> 
> 
>? ? On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
> 
> Probably
> 
> split(binDistance, test).
> 
> Best,
> Ista
> 
> On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
>> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
>> I have a vector that looks like
>>? binDistance
>>? ? ? ? ? ? [,1]
>>? [1,] 238.95162
>>? [2,] 143.08590
>>? [3,]? 88.50923
>>? [4,] 177.67884
>>? [5,] 277.54116
>>? [6,] 342.94689
>>? [7,] 241.60905
>>? [8,] 177.81969
>>? [9,] 211.25559
>> [10,] 279.72702
>> [11,] 381.95738
>> [12,] 483.76363
>> [13,] 480.98841
>> [14,] 369.75241
>> [15,] 267.73650
>> [16,] 138.55959
>> [17,] 137.93181
>> [18,] 184.75200
>> [19,] 254.64359
>> [20,] 328.87785
>> [21,] 273.15577
>> [22,] 252.52830
>> [23,] 252.52830
>> [24,] 252.52830
>> [25,] 262.20084
>> [26,] 314.93064
>> [27,] 366.02996
>> [28,] 442.77467
>> [29,] 521.20323
>> [30,] 465.33071
>> [31,] 366.60582
>> [32,]? 13.69540
>> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
>> 
>> 
>> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
>> Browse[2]> test
>>? [1] (217,318]? (115,217]? (13.7,115] (115,217]? (217,318]? (318,420]
>>? [7] (217,318]? (115,217]? (115,217]? (217,318]? (318,420]? (420,521]
>> [13] (420,521]? (318,420]? (217,318]? (115,217]? (115,217]? (115,217]
>> [19] (217,318]? (318,420]? (217,318]? (217,318]? (217,318]? (217,318]
>> [25] (217,318]? (217,318]? (318,420]? (420,521]? (420,521]? (420,521]
>> [31] (318,420]? (13.7,115]
>> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
>> 
>> 
>> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
>> How I can do that effectively in R?
>> I would like to thank you for your replyRegardsAlex
>> 
>>? ? ? ? [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Nov  4 14:09:48 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 4 Nov 2015 08:09:48 -0500
Subject: [R] merging-binning data
In-Reply-To: <1222950282.1674216.1446641863419.JavaMail.yahoo@mail.yahoo.com>
References: <21031DD8-C95B-43C6-9DF4-B60373A9F38E@utoronto.ca>
	<1222950282.1674216.1446641863419.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <0A99E228-DD27-4244-8FAF-B1E7D126BAEE@utoronto.ca>

I don't understand: 
 - where does the "label" come from? (It's not an element of your data that I see.)
 - what do you want to do with this "label" i.e. how does it need to be associated with the data?


B.



On Nov 4, 2015, at 7:57 AM, Alaios <alaios at yahoo.com> wrote:

> Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
> 
> Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
> 
> Regards
> Alex
> 
> 
> 
> On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.
> 
> Example: assume your input vector is dBin
> 
> nGroups <- 5  # number of groups
> groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
> groups <- floor(groups * nGroups) + 1  # discretize to nGroups integers
> 
> Now you can eg. get the indices for group 2
> 
> groups[groups == 2]
> 
> Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.
> 
> Cheers,
> Boris
> 
> 
> 
> 
> 
> 
> On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:
> 
> > Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> > 
> > 
> > 
> >    On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > 
> > 
> > Probably
> > 
> > split(binDistance, test).
> > 
> > Best,
> > Ista
> > 
> > On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> >> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> >> I have a vector that looks like
> >>  binDistance
> >>            [,1]
> >>  [1,] 238.95162
> >>  [2,] 143.08590
> >>  [3,]  88.50923
> >>  [4,] 177.67884
> >>  [5,] 277.54116
> >>  [6,] 342.94689
> >>  [7,] 241.60905
> >>  [8,] 177.81969
> >>  [9,] 211.25559
> >> [10,] 279.72702
> >> [11,] 381.95738
> >> [12,] 483.76363
> >> [13,] 480.98841
> >> [14,] 369.75241
> >> [15,] 267.73650
> >> [16,] 138.55959
> >> [17,] 137.93181
> >> [18,] 184.75200
> >> [19,] 254.64359
> >> [20,] 328.87785
> >> [21,] 273.15577
> >> [22,] 252.52830
> >> [23,] 252.52830
> >> [24,] 252.52830
> >> [25,] 262.20084
> >> [26,] 314.93064
> >> [27,] 366.02996
> >> [28,] 442.77467
> >> [29,] 521.20323
> >> [30,] 465.33071
> >> [31,] 366.60582
> >> [32,]  13.69540
> >> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
> >> 
> >> 
> >> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> >> Browse[2]> test
> >>  [1] (217,318]  (115,217]  (13.7,115] (115,217]  (217,318]  (318,420]
> >>  [7] (217,318]  (115,217]  (115,217]  (217,318]  (318,420]  (420,521]
> >> [13] (420,521]  (318,420]  (217,318]  (115,217]  (115,217]  (115,217]
> >> [19] (217,318]  (318,420]  (217,318]  (217,318]  (217,318]  (217,318]
> >> [25] (217,318]  (217,318]  (318,420]  (420,521]  (420,521]  (420,521]
> >> [31] (318,420]  (13.7,115]
> >> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
> >> 
> >> 
> >> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> >> How I can do that effectively in R?
> >> I would like to thank you for your replyRegardsAlex
> >> 
> >>        [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From alaios at yahoo.com  Wed Nov  4 14:45:27 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 4 Nov 2015 13:45:27 +0000 (UTC)
Subject: [R] merging-binning data
In-Reply-To: <0A99E228-DD27-4244-8FAF-B1E7D126BAEE@utoronto.ca>
References: <0A99E228-DD27-4244-8FAF-B1E7D126BAEE@utoronto.ca>
Message-ID: <222565868.1710154.1446644727289.JavaMail.yahoo@mail.yahoo.com>

you are right.by labels I mean the "categories", "breaks" that my data fall in.To be part of group 2 for example you have to be in the range of [110,223) I need to keep those for my plots.
Did I describe it more precisely now?Alex
 


     On Wednesday, November 4, 2015 2:09 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
   

 I don't understand: 
 - where does the "label" come from? (It's not an element of your data that I see.)
 - what do you want to do with this "label" i.e. how does it need to be associated with the data?


B.



On Nov 4, 2015, at 7:57 AM, Alaios <alaios at yahoo.com> wrote:

> Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
> 
> Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
> 
> Regards
> Alex
> 
> 
> 
> On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.
> 
> Example: assume your input vector is dBin
> 
> nGroups <- 5? # number of groups
> groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
> groups <- floor(groups * nGroups) + 1? # discretize to nGroups integers
> 
> Now you can eg. get the indices for group 2
> 
> groups[groups == 2]
> 
> Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.
> 
> Cheers,
> Boris
> 
> 
> 
> 
> 
> 
> On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:
> 
> > Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> > 
> > 
> > 
> >? ? On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > 
> > 
> > Probably
> > 
> > split(binDistance, test).
> > 
> > Best,
> > Ista
> > 
> > On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> >> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> >> I have a vector that looks like
> >>? binDistance
> >>? ? ? ? ? ? [,1]
> >>? [1,] 238.95162
> >>? [2,] 143.08590
> >>? [3,]? 88.50923
> >>? [4,] 177.67884
> >>? [5,] 277.54116
> >>? [6,] 342.94689
> >>? [7,] 241.60905
> >>? [8,] 177.81969
> >>? [9,] 211.25559
> >> [10,] 279.72702
> >> [11,] 381.95738
> >> [12,] 483.76363
> >> [13,] 480.98841
> >> [14,] 369.75241
> >> [15,] 267.73650
> >> [16,] 138.55959
> >> [17,] 137.93181
> >> [18,] 184.75200
> >> [19,] 254.64359
> >> [20,] 328.87785
> >> [21,] 273.15577
> >> [22,] 252.52830
> >> [23,] 252.52830
> >> [24,] 252.52830
> >> [25,] 262.20084
> >> [26,] 314.93064
> >> [27,] 366.02996
> >> [28,] 442.77467
> >> [29,] 521.20323
> >> [30,] 465.33071
> >> [31,] 366.60582
> >> [32,]? 13.69540
> >> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
> >> 
> >> 
> >> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> >> Browse[2]> test
> >>? [1] (217,318]? (115,217]? (13.7,115] (115,217]? (217,318]? (318,420]
> >>? [7] (217,318]? (115,217]? (115,217]? (217,318]? (318,420]? (420,521]
> >> [13] (420,521]? (318,420]? (217,318]? (115,217]? (115,217]? (115,217]
> >> [19] (217,318]? (318,420]? (217,318]? (217,318]? (217,318]? (217,318]
> >> [25] (217,318]? (217,318]? (318,420]? (420,521]? (420,521]? (420,521]
> >> [31] (318,420]? (13.7,115]
> >> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
> >> 
> >> 
> >> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> >> How I can do that effectively in R?
> >> I would like to thank you for your replyRegardsAlex
> >> 
> >>? ? ? ? [[alternative HTML version deleted]]
> >> 
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> >? ? [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


  
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Nov  4 14:52:35 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 04 Nov 2015 07:52:35 -0600
Subject: [R] Error survreg: Density function returned an an invalid
	matrix
In-Reply-To: <mailman.5.1446548402.29982.r-help@r-project.org>
References: <mailman.5.1446548402.29982.r-help@r-project.org>
Message-ID: <c10f8b$1pjtre@ironport10.mayo.edu>

> Hi, I want to perform a survival analysis using survreg procedure from
> survival library in R for a pareto distribution for a time variable, so I
> set the new distribution using the following sintax:
>
>      library(foreign)
>      library(survival)
>      library(VGAM)
>
>      mypareto <- list(name='Pareto',
>                   init= function(x, weights,parms){
etc.

The survreg routine fits location-scale distributions such that (t(y) - Xb)/s ~ F, where t 
is an optional transformation, F is some fixed distribution and X is a matrix of 
covariates.  For any distribution the questions to ask before trying to add the 
distribution to survreg are
   - can it be written in a location-scale form?
   - if so, how do the parameters of the distribution map to the location (Xb) and scale (s).

In fitting data we normally have per-subject location (X b) but an intercept-only model is 
of course possible.

If y is Weibull then log(y) fits into the framework, which is how survreg fits it.  The 
transformation of parameters location and scale parameters for log(y) back to the usual 
Weibull parameterization for y often trips people up (see comments in the Examples section 
of ?survreg).

The log of a Pareto can be written in this form (I think?).  The two parameters are the 
scale a and lower limit b, with survival function of S(x)= (b/x)^a, for x >= b.  If y = 
log(x) the survival function for y is
S(y) = (b/exp(y))^a = exp[-(y - log(b))/(1/a)], which has location log(b) and scale 1/a. 
But even if I am correct the discontinuity at b will cause the underlying Newton-Raphson 
method to fail.

  Terry Therneau


From boris.steipe at utoronto.ca  Wed Nov  4 15:06:43 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 4 Nov 2015 09:06:43 -0500
Subject: [R] merging-binning data
In-Reply-To: <222565868.1710154.1446644727289.JavaMail.yahoo@mail.yahoo.com>
References: <0A99E228-DD27-4244-8FAF-B1E7D126BAEE@utoronto.ca>
	<222565868.1710154.1446644727289.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <4F5A88FD-C908-4D04-A741-A210372A6C63@utoronto.ca>

The breaks are just the min() and max() in your groups. Something like

  sprintf("[%5.2f,%5.2f]", min(dBin[groups==2]), max(dBin[groups==2]))

... should achieve what you need.


B.



On Nov 4, 2015, at 8:45 AM, Alaios <alaios at yahoo.com> wrote:

> you are right.
> by labels I mean the "categories", "breaks" that my data fall in.
> To be part of group 2 for example you have to be in the range of [110,223) I need to keep those for my plots.
> 
> Did I describe it more precisely now?
> Alex
> 
> 
> 
> On Wednesday, November 4, 2015 2:09 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> I don't understand: 
> - where does the "label" come from? (It's not an element of your data that I see.)
> - what do you want to do with this "label" i.e. how does it need to be associated with the data?
> 
> 
> B.
> 
> 
> 
> On Nov 4, 2015, at 7:57 AM, Alaios <alaios at yahoo.com> wrote:
> 
> > Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
> > 
> > Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
> > 
> > Regards
> > Alex
> > 
> > 
> > 
> > On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > 
> > 
> > I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.
> > 
> > Example: assume your input vector is dBin
> > 
> > nGroups <- 5  # number of groups
> > groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
> > groups <- floor(groups * nGroups) + 1  # discretize to nGroups integers
> > 
> > Now you can eg. get the indices for group 2
> > 
> > groups[groups == 2]
> > 
> > Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.
> > 
> > Cheers,
> > Boris
> > 
> > 
> > 
> > 
> > 
> > 
> > On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > 
> > > Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> > > 
> > > 
> > > 
> > >    On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > > 
> > > 
> > > Probably
> > > 
> > > split(binDistance, test).
> > > 
> > > Best,
> > > Ista
> > > 
> > > On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > >> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> > >> I have a vector that looks like
> > >>  binDistance
> > >>            [,1]
> > >>  [1,] 238.95162
> > >>  [2,] 143.08590
> > >>  [3,]  88.50923
> > >>  [4,] 177.67884
> > >>  [5,] 277.54116
> > >>  [6,] 342.94689
> > >>  [7,] 241.60905
> > >>  [8,] 177.81969
> > >>  [9,] 211.25559
> > >> [10,] 279.72702
> > >> [11,] 381.95738
> > >> [12,] 483.76363
> > >> [13,] 480.98841
> > >> [14,] 369.75241
> > >> [15,] 267.73650
> > >> [16,] 138.55959
> > >> [17,] 137.93181
> > >> [18,] 184.75200
> > >> [19,] 254.64359
> > >> [20,] 328.87785
> > >> [21,] 273.15577
> > >> [22,] 252.52830
> > >> [23,] 252.52830
> > >> [24,] 252.52830
> > >> [25,] 262.20084
> > >> [26,] 314.93064
> > >> [27,] 366.02996
> > >> [28,] 442.77467
> > >> [29,] 521.20323
> > >> [30,] 465.33071
> > >> [31,] 366.60582
> > >> [32,]  13.69540
> > >> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
> > >> 
> > >> 
> > >> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> > >> Browse[2]> test
> > >>  [1] (217,318]  (115,217]  (13.7,115] (115,217]  (217,318]  (318,420]
> > >>  [7] (217,318]  (115,217]  (115,217]  (217,318]  (318,420]  (420,521]
> > >> [13] (420,521]  (318,420]  (217,318]  (115,217]  (115,217]  (115,217]
> > >> [19] (217,318]  (318,420]  (217,318]  (217,318]  (217,318]  (217,318]
> > >> [25] (217,318]  (217,318]  (318,420]  (420,521]  (420,521]  (420,521]
> > >> [31] (318,420]  (13.7,115]
> > >> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
> > >> 
> > >> 
> > >> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> > >> How I can do that effectively in R?
> > >> I would like to thank you for your replyRegardsAlex
> > >> 
> > >>        [[alternative HTML version deleted]]
> > >> 
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > 
> > >    [[alternative HTML version deleted]]
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> 
> 


From marammagdysalem at gmail.com  Wed Nov  4 15:09:20 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Wed, 4 Nov 2015 16:09:20 +0200
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
Message-ID: <CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>

Hi Jim,

Thanks a lot for replying.

In fact I'm trying to run a simulation study that enables me to calculate
the Bayes risk of a sampling plan selected from progressively type-II
censored Weibull model. One of the steps involves evaluating the expected
test time, which is a rather complicated formula that involves nested
multiple summations where the counters of the summation signs are
dependent, that's why I thought of I should create the incomb() function
inside the loop, or may be I didn't figure out how to relate its arguments
to the ones inside the loop had I created it outside it.  I'm trying to
create a matrix of all the possible combinations involved in the summations
and then use the apply() function on each row of that matrix. The problem
is that the code I wrote works perfectly well for rather small values of
the sample size,n, and the censoring number, m (for example, n=8,m=4),but
when n and m are increased (say, n=25,m=15) the code keeps on running for
days with no output. That's why I thought I should try to avoid explicit
loops as much as possible, so I did my best in this regard but still the
code takes too long to execute,(more than three days), thus, i believe
there must be something wrong.

Here's the full code:

library(pbapply)
f1 <- function(n, m) {
   stopifnot(n > m)
   r0 <- t(diff(combn(n-1, m-1)) - 1L)
   r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1, len=n-m+1),
m-2))
   cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
}
simpfun<- function (x,n,m,p,alpha,beta)
  {
  a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
  b <-  ((m-1):1)
  c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
d <- n - cumsum(x) - (1:(m-1))
  e<- n*(prod(d))*c
LD<-list()
   for (i in 1:(m-1))  {
   LD[[i]]<-seq(0,x[i],1)
   }
   LD[[m]]<-seq(0,(n-m-sum(x)),1)
   LED<-expand.grid (LD)
   LED<-as.matrix(LED)
   store1<-numeric(nrow(LED))
for (j in 1:length(store1) )
         {
            incomb<-function(x,alpha,beta) {

 g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
                    h <- choose(x, LED[j,-m])
                   ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
                lm<-cumsum(LED[j,-m]) + (1:(m-1))
                plm<-prod(lm)
               gil<-g*ik/(plm)
             hlm<-numeric(sum(LED[j,])+(m-1))
             dsa<-length(hlm)
              for (i in 1:dsa)
                {
                 ppp<- sum(LED[j,])+(m-1)
                  hlm[i]<-
 (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
                 }
          shl<-gil*(sum(hlm)+1)
          return (shl)
          }
       store1[j]<-incomb(x,alpha=0.2,beta=2)
      }
val1<- sum(store1)*e
return(val1)
}

va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
EXP<-sum(va)



Any help would be greatly appreciated.
Thanks a lot  for your time.

Best Regards,
Maram Salem


On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:

> Why are you recreating the incomb function within the loop instead of
> defining it outside the loop?  Also you are referencing several variables
> that are global (e.g., m & j); you should be passing these in as parameters
> to the function.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
>> Hi All,
>>
>> I'm writing a long code that takes long time to execute. So I used the
>> Rprof() function and found out that the function that takes about 80% of
>> the time is the incomb () fucntion (below), and this is most probably
>> because of the many explicit for() loops I'm using.
>>
>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>> x=c(3,0,0)
>> LD<-list()
>>    for (i in 1:(m-1))  {
>>    LD[[i]]<-seq(0,x[i],1)
>>    }
>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>    LED<-expand.grid (LD)
>>    LED<-as.matrix(LED)
>>    store1<-numeric(nrow(LED))
>>     h<- numeric(m-1)
>>     lm<- numeric(m-1)
>>      for (j in 1:length(store1) )
>>          {
>>             incomb<-function(x,alpha,beta) {
>>
>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>                   for (i in 1:(m-1))  {
>>                        h[i]<- choose(x[i],LED[j,i])
>>                        }
>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>                 for (i in 1:(m-1)) {
>>                        lm[i]<-(sum(LED[j,1:i])) + i
>>                      }
>>                 plm<-prod(lm)
>>                gil<-g*ik/(plm)
>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>              dsa<-length(hlm)
>>               for (i in 1:dsa)
>>                 {
>>                  ppp<- sum(LED[j,])+(m-1)
>>                   hlm[i]<-
>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>                  }
>>           shl<-gil*(sum(hlm)+1)
>>           return (shl)
>>           }
>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>       }
>>
>>
>> I'm trying to use alternatives (for ex. to vectorize things) to the
>> explicit for() loops, but things don't work out.
>>
>> Any suggestions that can help me to speed up the execution of the incomb()
>> function are much appreciated.
>>
>> Thanks a lot in advance.
>>
>> Maram Salem
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Nov  4 15:33:59 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 4 Nov 2015 09:33:59 -0500
Subject: [R] merging-binning data
In-Reply-To: <1228940853.1685309.1446646780613.JavaMail.yahoo@mail.yahoo.com>
References: <4F5A88FD-C908-4D04-A741-A210372A6C63@utoronto.ca>
	<1228940853.1685309.1446646780613.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D5533A4E-C726-45B0-8256-0FCF0FD957E5@utoronto.ca>

Whatever approach is "best" to define subsets depends completely on the semantics of the data. Your approach (a fixed number of equally spaced breaks) is the right one if the absolute ranges of the data is important. It should be obvious that either the top or the bottom group could contain only a single element, and also that any or all of the intermediate groups could be empty. 

If you want to control the number of elements in your groups, use quantiles instead. 

Your application may require to define the breaks in other ways. The code I have given you doesn't generalize well, as it depends on the equal spacing of breaks. As I mentioned earlier, I would not store the groups at all - but would define a function that returns a vector of elements in the group, and in the function body I would clearly and explicitly define the conditions for group membership (and comment it). That is how you make code for a task like this explicit and _maintainable_.


Cheers,
Boris


On Nov 4, 2015, at 9:19 AM, Alaios <alaios at yahoo.com> wrote:

> Thanks everything is solved and I was even able to plot boxplots as needed.
> The only minor is that the max element falls in the last category and is only the single one element. Perhaps this can be from the way my data look like.
> Retgards
> Alex
> 
> 
> 
> On Wednesday, November 4, 2015 3:06 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> The breaks are just the min() and max() in your groups. Something like
> 
>   sprintf("[%5.2f,%5.2f]", min(dBin[groups==2]), max(dBin[groups==2]))
> 
> ... should achieve what you need.
> 
> 
> B.
> 
> 
> 
> On Nov 4, 2015, at 8:45 AM, Alaios <alaios at yahoo.com> wrote:
> 
> > you are right.
> > by labels I mean the "categories", "breaks" that my data fall in.
> > To be part of group 2 for example you have to be in the range of [110,223) I need to keep those for my plots.
> > 
> > Did I describe it more precisely now?
> > Alex
> > 
> > 
> > 
> > On Wednesday, November 4, 2015 2:09 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > 
> > 
> > I don't understand: 
> > - where does the "label" come from? (It's not an element of your data that I see.)
> > - what do you want to do with this "label" i.e. how does it need to be associated with the data?
> > 
> > 
> > B.
> > 
> > 
> > 
> > On Nov 4, 2015, at 7:57 AM, Alaios <alaios at yahoo.com> wrote:
> > 
> > > Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
> > > 
> > > Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
> > > 
> > > Regards
> > > Alex
> > > 
> > > 
> > > 
> > > On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > > 
> > > 
> > > I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.
> > > 
> > > Example: assume your input vector is dBin
> > > 
> > > nGroups <- 5  # number of groups
> > > groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
> > > groups <- floor(groups * nGroups) + 1  # discretize to nGroups integers
> > > 
> > > Now you can eg. get the indices for group 2
> > > 
> > > groups[groups == 2]
> > > 
> > > Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.
> > > 
> > > Cheers,
> > > Boris
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > > 
> > > > Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> > > > 
> > > > 
> > > > 
> > > >    On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > > > 
> > > > 
> > > > Probably
> > > > 
> > > > split(binDistance, test).
> > > > 
> > > > Best,
> > > > Ista
> > > > 
> > > > On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > > >> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> > > >> I have a vector that looks like
> > > >>  binDistance
> > > >>            [,1]
> > > >>  [1,] 238.95162
> > > >>  [2,] 143.08590
> > > >>  [3,]  88.50923
> > > >>  [4,] 177.67884
> > > >>  [5,] 277.54116
> > > >>  [6,] 342.94689
> > > >>  [7,] 241.60905
> > > >>  [8,] 177.81969
> > > >>  [9,] 211.25559
> > > >> [10,] 279.72702
> > > >> [11,] 381.95738
> > > >> [12,] 483.76363
> > > >> [13,] 480.98841
> > > >> [14,] 369.75241
> > > >> [15,] 267.73650
> > > >> [16,] 138.55959
> > > >> [17,] 137.93181
> > > >> [18,] 184.75200
> > > >> [19,] 254.64359
> > > >> [20,] 328.87785
> > > >> [21,] 273.15577
> > > >> [22,] 252.52830
> > > >> [23,] 252.52830
> > > >> [24,] 252.52830
> > > >> [25,] 262.20084
> > > >> [26,] 314.93064
> > > >> [27,] 366.02996
> > > >> [28,] 442.77467
> > > >> [29,] 521.20323
> > > >> [30,] 465.33071
> > > >> [31,] 366.60582
> > > >> [32,]  13.69540
> > > >> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
> > > >> 
> > > >> 
> > > >> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> > > >> Browse[2]> test
> > > >>  [1] (217,318]  (115,217]  (13.7,115] (115,217]  (217,318]  (318,420]
> > > >>  [7] (217,318]  (115,217]  (115,217]  (217,318]  (318,420]  (420,521]
> > > >> [13] (420,521]  (318,420]  (217,318]  (115,217]  (115,217]  (115,217]
> > > >> [19] (217,318]  (318,420]  (217,318]  (217,318]  (217,318]  (217,318]
> > > >> [25] (217,318]  (217,318]  (318,420]  (420,521]  (420,521]  (420,521]
> > > >> [31] (318,420]  (13.7,115]
> > > >> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
> > > >> 
> > > >> 
> > > >> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> > > >> How I can do that effectively in R?
> > > >> I would like to thank you for your replyRegardsAlex
> > > >> 
> > > >>        [[alternative HTML version deleted]]
> > > >> 
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > 
> > > >    [[alternative HTML version deleted]]
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > 
> > 
> > 
> 
> 


From alaasindi at gmail.com  Wed Nov  4 16:18:25 2015
From: alaasindi at gmail.com (Alaa Sindi)
Date: Wed, 4 Nov 2015 10:18:25 -0500
Subject: [R] Error in eval(expr, envir, enclos)
Message-ID: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>

Hi All,

I am receiving this error

Error in eval(expr, envir, enclos) : could not find function ?LL?

the following is in a for loop and all the variables are defined and have values. 

Prob[i,1]=log(((((sigma)^((1-M[i,1]))))* factorial(M[i,1]-1))*(Fmul[i,1])*(Fsum[i,1])*(EV1[i,1])/((EV2[i,1])^(M[i,1]))) 
                                                      
                                                      LL=LL*Prob[i,1]

thanks 


From jdnewmil at dcn.davis.CA.us  Wed Nov  4 16:48:56 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 04 Nov 2015 07:48:56 -0800
Subject: [R] Error in eval(expr, envir, enclos)
In-Reply-To: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>
References: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>
Message-ID: <611237A8-42F3-4537-978B-9FE0E062DF5B@dcn.davis.CA.us>

You assert "all the variables are defined and have values" but something is wrong that you are not showing us. Please read  [1] and make your example reproducible. 

Also post in plain text (a setting in your email software) so we don't have to decipher a mangled version of what you write on this plain-text-only mailing list. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 4, 2015 7:18:25 AM PST, Alaa Sindi <alaasindi at gmail.com> wrote:
>Hi All,
>
>I am receiving this error
>
>Error in eval(expr, envir, enclos) : could not find function ?LL?
>
>the following is in a for loop and all the variables are defined and
>have values. 
>
>Prob[i,1]=log(((((sigma)^((1-M[i,1]))))*
>factorial(M[i,1]-1))*(Fmul[i,1])*(Fsum[i,1])*(EV1[i,1])/((EV2[i,1])^(M[i,1])))
>
>                                                      
>                                                      LL=LL*Prob[i,1]
>
>thanks 
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Wed Nov  4 16:51:43 2015
From: jwd at surewest.net (jwd)
Date: Wed, 4 Nov 2015 07:51:43 -0800
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
 into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <22073.48038.134876.110551@stat.math.ethz.ch>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
	<CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>
	<22073.48038.134876.110551@stat.math.ethz.ch>
Message-ID: <20151104075143.5a09a305@Draco.site>

On Wed, 4 Nov 2015 09:02:46 +0100
Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> >>>>> Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>     on Tue, 3 Nov 2015 14:54:46 -0800 writes:
> 
>     > ... should have said: with a 24 hour "clock".
>     > -- Bert
>     > Bert Gunter
> 
> Hmm,  thank you Bert.
> 
> I know nothing about measuring time in radians, and for me,
> 'radians' are angles, and hence we are talking about
> analogue watches when measuring time with them, and now, as a
> citizen from  "the watch maker country" I do like analogue
> watches or let's nowadays say "graphical" watches, i.e., with clock
> faces and short and long (hour and minute) hands, and I think I
> have only ever seen 12 h watches at least on church towers (yes,
> here in CH) or wrist watches...
> (?)
> 
> Martin

The issue is apparently to analyze activity over a 24 hour cycle.  The
OP mentions the use of a camera trap so they are evidently analyzing
trap events by time of event.  The radian constraint is mentioned in
the Activity package docs.  

JWDougherty


From jdnewmil at dcn.davis.CA.us  Wed Nov  4 16:53:07 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 04 Nov 2015 07:53:07 -0800
Subject: [R] CRAN - Package "activity" - how do you convert time (hh:mm)
	into radians in R 3.1.2 on Windows 7 OS 64bit
In-Reply-To: <22073.48038.134876.110551@stat.math.ethz.ch>
References: <565053134.1761011.1446588028918.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbSQDsihzbeHbF5RttaHiuZhxR9qsj_J_DORGaGWUOKkNQ@mail.gmail.com>
	<CAGxFJbSJ4pSbU999_MDBGjjUu4fb4W7KCnz8idJV58xgZDpf2A@mail.gmail.com>
	<22073.48038.134876.110551@stat.math.ethz.ch>
Message-ID: <0D701322-CB3F-45BA-9FF1-F8E85DF17578@dcn.davis.CA.us>

Think astronomy. 

https://en.m.wikipedia.org/wiki/Hour_angle
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 4, 2015 12:02:46 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>     on Tue, 3 Nov 2015 14:54:46 -0800 writes:
>
>    > ... should have said: with a 24 hour "clock".
>    > -- Bert
>    > Bert Gunter
>
>Hmm,  thank you Bert.
>
>I know nothing about measuring time in radians, and for me,
>'radians' are angles, and hence we are talking about
>analogue watches when measuring time with them, and now, as a
>citizen from  "the watch maker country" I do like analogue
>watches or let's nowadays say "graphical" watches, i.e., with clock
>faces and short and long (hour and minute) hands, and I think I
>have only ever seen 12 h watches at least on church towers (yes,
>here in CH) or wrist watches...
>(?)
>
>Martin
>(Maechler, ETH Zurich, Switzerland)
>
>> On Tue, Nov 3, 2015 at 2:52 PM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>    >> Hint: 24 hours = 24x60 = 1440 minutes = 2 pi radians.
>    >> 
>    >> Cheers,
>    >> Bert
>    >> Bert Gunter
>    >> 
>>> "Data is not information. Information is not knowledge. And
>knowledge
>    >> is certainly not wisdom."
>    >> -- Clifford Stoll
>    >> 
>    >> 
>>> On Tue, Nov 3, 2015 at 2:00 PM, Typhenn Brichieri-Colombi via R-help
>    >> <r-help at r-project.org> wrote:
>    >>> Hello,
>>>> I am using the "activity" package developed by Marcus Rowcliffe
>(released in February, 2015). This package uses time in radians to
>estimate activity. I have camera trap data in 24 hour times (hh:mm) -
>how do I convert these into radians? (e.g. My time-of-detection at
>19:44, how do I convert this into radians?)
>    >>> Thank you for your time and your help
>    >>> [[alternative HTML version deleted]]
>    >>> 
>    >>> ______________________________________________
>  >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>
>    > ______________________________________________
>    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>    > https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>   > and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Nov  4 16:56:12 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Nov 2015 07:56:12 -0800
Subject: [R] Error in eval(expr, envir, enclos)
In-Reply-To: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>
References: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>
Message-ID: <CAF8bMcZn9Bi0G+yiQSo559c3D49wFWu3gbx+fDWsp30U47BNeg@mail.gmail.com>

You need to show more (e.g., the entire function, the output of traceback()
after the error) to get a definitive answer, but that error message can
occur
if you mistakenly use parentheses instead of square brackets when
subscripting
LL.  E.g.,
  > LL <- 11:20
  > LL[3:4]
  [1] 13 14
  > LL(3:4)
  Error: could not find function "LL"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 4, 2015 at 7:18 AM, Alaa Sindi <alaasindi at gmail.com> wrote:

> Hi All,
>
> I am receiving this error
>
> Error in eval(expr, envir, enclos) : could not find function ?LL?
>
> the following is in a for loop and all the variables are defined and have
> values.
>
> Prob[i,1]=log(((((sigma)^((1-M[i,1]))))*
> factorial(M[i,1]-1))*(Fmul[i,1])*(Fsum[i,1])*(EV1[i,1])/((EV2[i,1])^(M[i,1])))
>
>                                                       LL=LL*Prob[i,1]
>
> thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Wed Nov  4 17:14:58 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 4 Nov 2015 16:14:58 +0000 (UTC)
Subject: [R] merging-binning data
In-Reply-To: <D5533A4E-C726-45B0-8256-0FCF0FD957E5@utoronto.ca>
References: <D5533A4E-C726-45B0-8256-0FCF0FD957E5@utoronto.ca>
Message-ID: <152763221.1772460.1446653698567.JavaMail.yahoo@mail.yahoo.com>

Thanks for your comments. Actually only the last group has a single element. The first group is always "full" of members and as that it works fine. Some constant spacing between the groups would be good as well and thus I will check quantiles.
Thanks for the great support and time invested on thisRegardsAlex



     On Wednesday, November 4, 2015 3:34 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
   

 Whatever approach is "best" to define subsets depends completely on the semantics of the data. Your approach (a fixed number of equally spaced breaks) is the right one if the absolute ranges of the data is important. It should be obvious that either the top or the bottom group could contain only a single element, and also that any or all of the intermediate groups could be empty. 

If you want to control the number of elements in your groups, use quantiles instead. 

Your application may require to define the breaks in other ways. The code I have given you doesn't generalize well, as it depends on the equal spacing of breaks. As I mentioned earlier, I would not store the groups at all - but would define a function that returns a vector of elements in the group, and in the function body I would clearly and explicitly define the conditions for group membership (and comment it). That is how you make code for a task like this explicit and _maintainable_.


Cheers,
Boris


On Nov 4, 2015, at 9:19 AM, Alaios <alaios at yahoo.com> wrote:

> Thanks everything is solved and I was even able to plot boxplots as needed.
> The only minor is that the max element falls in the last category and is only the single one element. Perhaps this can be from the way my data look like.
> Retgards
> Alex
> 
> 
> 
> On Wednesday, November 4, 2015 3:06 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> The breaks are just the min() and max() in your groups. Something like
> 
>? sprintf("[%5.2f,%5.2f]", min(dBin[groups==2]), max(dBin[groups==2]))
> 
> ... should achieve what you need.
> 
> 
> B.
> 
> 
> 
> On Nov 4, 2015, at 8:45 AM, Alaios <alaios at yahoo.com> wrote:
> 
> > you are right.
> > by labels I mean the "categories", "breaks" that my data fall in.
> > To be part of group 2 for example you have to be in the range of [110,223) I need to keep those for my plots.
> > 
> > Did I describe it more precisely now?
> > Alex
> > 
> > 
> > 
> > On Wednesday, November 4, 2015 2:09 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > 
> > 
> > I don't understand: 
> > - where does the "label" come from? (It's not an element of your data that I see.)
> > - what do you want to do with this "label" i.e. how does it need to be associated with the data?
> > 
> > 
> > B.
> > 
> > 
> > 
> > On Nov 4, 2015, at 7:57 AM, Alaios <alaios at yahoo.com> wrote:
> > 
> > > Thanks it works great and gives me group numbers as integers and thus I can with which group the elements as needed (which (groups== 2))
> > > 
> > > Question though is how to keep also the labels for each group. For example that my first group is the [13,206)
> > > 
> > > Regards
> > > Alex
> > > 
> > > 
> > > 
> > > On Wednesday, November 4, 2015 1:00 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> > > 
> > > 
> > > I would transform the original numbers into integers which you can use as group labels. The row numbers of the group labels are the indexes of your values.
> > > 
> > > Example: assume your input vector is dBin
> > > 
> > > nGroups <- 5? # number of groups
> > > groups <- (dBin - min(dBin)) / (max(dBin) - min(dBin)) # rescale to the range [0,1]
> > > groups <- floor(groups * nGroups) + 1? # discretize to nGroups integers
> > > 
> > > Now you can eg. get the indices for group 2
> > > 
> > > groups[groups == 2]
> > > 
> > > Depending on the nature of your input data, it may be better to keep these groups in a column adjacent to your values, rather than in a separate vector, or even better to just calculate the groups on the fly in your downstream analysis with the approach given above in a function, rather than storing them at all. These are simple operations that should not add perceptibly to execution time.
> > > 
> > > Cheers,
> > > Boris
> > > 
> > > 
> > > 
> > > 
> > > 
> > > 
> > > On Nov 4, 2015, at 6:40 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > > 
> > > > Thanks for the answer. Split does not give me the indexes though but only in which group they fall in. I also need the index of the group. Is the first, the second .. group?Alex
> > > > 
> > > > 
> > > > 
> > > >? ? On Tuesday, November 3, 2015 5:05 PM, Ista Zahn <istazahn at gmail.com> wrote:
> > > > 
> > > > 
> > > > Probably
> > > > 
> > > > split(binDistance, test).
> > > > 
> > > > Best,
> > > > Ista
> > > > 
> > > > On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
> > > >> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
> > > >> I have a vector that looks like
> > > >>? binDistance
> > > >>? ? ? ? ? ? [,1]
> > > >>? [1,] 238.95162
> > > >>? [2,] 143.08590
> > > >>? [3,]? 88.50923
> > > >>? [4,] 177.67884
> > > >>? [5,] 277.54116
> > > >>? [6,] 342.94689
> > > >>? [7,] 241.60905
> > > >>? [8,] 177.81969
> > > >>? [9,] 211.25559
> > > >> [10,] 279.72702
> > > >> [11,] 381.95738
> > > >> [12,] 483.76363
> > > >> [13,] 480.98841
> > > >> [14,] 369.75241
> > > >> [15,] 267.73650
> > > >> [16,] 138.55959
> > > >> [17,] 137.93181
> > > >> [18,] 184.75200
> > > >> [19,] 254.64359
> > > >> [20,] 328.87785
> > > >> [21,] 273.15577
> > > >> [22,] 252.52830
> > > >> [23,] 252.52830
> > > >> [24,] 252.52830
> > > >> [25,] 262.20084
> > > >> [26,] 314.93064
> > > >> [27,] 366.02996
> > > >> [28,] 442.77467
> > > >> [29,] 521.20323
> > > >> [30,] 465.33071
> > > >> [31,] 366.60582
> > > >> [32,]? 13.69540
> > > >> so numbers that start from 13 and go up to maximum 522 (I have also many other similar sets).I want to put these numbers into 5 categories and thus I have tried cut
> > > >> 
> > > >> 
> > > >> Browse[2]> test<-cut(binDistance,seq(min(binDistance)-0.00001,max(binDistance),length.out=scaleLength+1))
> > > >> Browse[2]> test
> > > >>? [1] (217,318]? (115,217]? (13.7,115] (115,217]? (217,318]? (318,420]
> > > >>? [7] (217,318]? (115,217]? (115,217]? (217,318]? (318,420]? (420,521]
> > > >> [13] (420,521]? (318,420]? (217,318]? (115,217]? (115,217]? (115,217]
> > > >> [19] (217,318]? (318,420]? (217,318]? (217,318]? (217,318]? (217,318]
> > > >> [25] (217,318]? (217,318]? (318,420]? (420,521]? (420,521]? (420,521]
> > > >> [31] (318,420]? (13.7,115]
> > > >> Levels: (13.7,115] (115,217] (217,318] (318,420] (420,521]
> > > >> 
> > > >> 
> > > >> I want then for the numbers of my initial vector that fall within the same "category" lets say the (318,420] to be collected on a vector.I rephrase it the indexes of my initial vector that have a value between 318 to 420 to be put in a same vector that I can process then as I want.
> > > >> How I can do that effectively in R?
> > > >> I would like to thank you for your replyRegardsAlex
> > > >> 
> > > >>? ? ? ? [[alternative HTML version deleted]]
> > > >> 
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > > 
> > > > 
> > > >? ? [[alternative HTML version deleted]]
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > > 
> > > 
> > 
> > 
> 
> 


  
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Nov  4 17:36:26 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 4 Nov 2015 08:36:26 -0800
Subject: [R] Error in eval(expr, envir, enclos)
In-Reply-To: <53225DFE-AFA3-40F5-8C09-1154E751C75C@gmail.com>
References: <D8C8B957-4C22-485F-8DD3-8E56F87EA749@gmail.com>
	<CAF8bMcZn9Bi0G+yiQSo559c3D49wFWu3gbx+fDWsp30U47BNeg@mail.gmail.com>
	<53225DFE-AFA3-40F5-8C09-1154E751C75C@gmail.com>
Message-ID: <CAF8bMcagzkPeC5vZ=uXG1i8kZo9j=xqtd8AVnkHxvR8inWsSWw@mail.gmail.com>

No, I meant for you to
  (a) show an example that anyone could run and reproduce your problem
  (b) show the output you get when calling traceback() after you ran into
the error.
The lines and error messages you show now are different than the ones you
showed before, but I see you are call mlogit.optim, which I assume comes
from the mlogit pacakge.  help(mlogit.optim) shows
       mlogit.optim(logLik, start, method = c("bfgs", "nr", "bhhh"),
iterlim = 2000,
                    tol = 1E-06, ftol = 1e-08, steptol = 1e-10,
                    print.level = 0, constPar = NULL, ...)

  Arguments:

    logLik: the likelihood function to be maximized,

It looks like your LL is a numeric vector and mlogit.optim expects a
function,
so the original error message may come from there.

By the way, you should stop at the first error message and straighten
things out
before proceeding.  Otherwise all is likely to be garbage.




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Nov 4, 2015 at 8:05 AM, Alaa Sindi <alaasindi at gmail.com> wrote:

> Do you mean these lines? Thanks
>
> Prob[i,1]=log(((((sigma)^((1-M[i,1]))))*
> factorial(M[i,1]-1))*(Fmul[i,1])*(Fsum[i,1])*(EV1[i,1])/((EV2[i,1])^(M[i,1])))
> +
> +                                                       LL=LL*Prob[i,1]
> +                                                     }
> Error in HICKSEXP[i, 1] : incorrect number of dimensions
> >
> >
> Start=c(1,1,1,1,1,1,1,1,1,1,1,1)
> >
> >
> >                                                     semsem=mlogit.optim
> ( LL  , Start, method = 'nr', iterlim = 2000, tol = 1E-06, ftol = 1e-08,
> steptol = 1e-10, print.level = 0)
> Error in eval(expr, envir, enclos) : could not find function ?LL"
>
>
> On Nov 4, 2015, at 10:56 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
> You need to show more (e.g., the entire function, the output of traceback()
> after the error) to get a definitive answer, but that error message can
> occur
> if you mistakenly use parentheses instead of square brackets when
> subscripting
> LL.  E.g.,
>   > LL <- 11:20
>   > LL[3:4]
>   [1] 13 14
>   > LL(3:4)
>   Error: could not find function "LL"
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Nov 4, 2015 at 7:18 AM, Alaa Sindi <alaasindi at gmail.com> wrote:
>
>> Hi All,
>>
>> I am receiving this error
>>
>> Error in eval(expr, envir, enclos) : could not find function ?LL?
>>
>> the following is in a for loop and all the variables are defined and have
>> values.
>>
>> Prob[i,1]=log(((((sigma)^((1-M[i,1]))))*
>> factorial(M[i,1]-1))*(Fmul[i,1])*(Fsum[i,1])*(EV1[i,1])/((EV2[i,1])^(M[i,1])))
>>
>>                                                       LL=LL*Prob[i,1]
>>
>> thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>

	[[alternative HTML version deleted]]


From madlene.nussbaum at env.ethz.ch  Wed Nov  4 16:29:16 2015
From: madlene.nussbaum at env.ethz.ch (Nussbaum  Madlene)
Date: Wed, 4 Nov 2015 15:29:16 +0000
Subject: [R] Group Lasso for Proportional Odds Model
Message-ID: <847D4A28424E3F4BB8E890216D28B996342595BF@MBX211.d.ethz.ch>


Dear R experts,

Having an ordinal response (3 levels) and factors in the predictors set, 
I would like to fit Proportional Odds Group Lasso.

I found several packages that fit the group lasso:
grplasso, grpreg, gglasso and ordPens.

However, they vary penalty and implementation in several ways, but none 
of them is able to fit a proportional odds model.

Did I overlook something? Is there an R package available?

Many thanks for your help!

Madlene Nussbaum

-- 

ETH Z?rich
Institut f?r Terrestrische ?kosysteme
madlene.nussbaum at env.ethz.ch
www.step.ethz.ch




From tacsunday at yahoo.fr  Wed Nov  4 16:34:38 2015
From: tacsunday at yahoo.fr (Robert U)
Date: Wed, 4 Nov 2015 15:34:38 +0000 (UTC)
Subject: [R] Count of included observations in sp.correlogram
References: <598326801.3329310.1446651278052.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <598326801.3329310.1446651278052.JavaMail.yahoo@mail.yahoo.com>

Dear Rusers,
I?m tryingto figure out what I think is a pretty simple thing for anyone who knows about correlograms.I?ve a regular grid (say 5*5 points) with some quantity associated to eachpoint (count data). I?m trying to verify whether this quantity is regularly /randomly or ?clusterdly? distributed on the grid. I?ve decided to give a shotto the sp.correlogram {spdep}. 

I first createda grid using cell2nb:? 

grid <- cell2nb(5,5)xyc <- attr(grid,"region.id")xy <-matrix(as.integer(unlist(strsplit(xyc, ":"))), ncol=2, byrow=TRUE)plot(grid,xy)?>gridNeighbour list object:Number of regions: 25 Number of nonzero links: 80 Percentage nonzero weights: 12.8 Average number of links: 3.2?I then usedsp.correlogram, and specified ?order = 4? since I figured the maximum lagbetween 2 points on a 5 by 5 grid is 4? In sp.correlogram we do not have tospecify a ?style? as in moran.test, not sure why so far? anyway. 

results<- sp.correlogram(grid, data$quantity, order=4, method = "I")? print(results,"bonferroni")?In the ?print? tbale, the count ofobservation per lag order (in brakets) is 25 for each lag. This is what I donot understand, should not this count be changing with lags? ?I mean, when you look at the graph of ?grid? Iwould have expected a lower number for lag 4 (say only 15 pairs of observationare ?that far?) and a way higher number for lag 1? Does that make sens toanyone??regards
	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Wed Nov  4 18:19:01 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Wed, 4 Nov 2015 12:19:01 -0500
Subject: [R] Extract entries from matrix
In-Reply-To: <2AEAE5DE-666D-41E9-AE29-411455C87213@utoronto.ca>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>
	<CAKL8G3F1rfcYXfq8n2YkYjDW=67My9z9uu2LpC07WK4vbtYdCg@mail.gmail.com>
	<CAKL8G3Gde6OyMP+oC=snwWcZES7qn=4zJz_SGKGry8mUqUMHGQ@mail.gmail.com>
	<2AEAE5DE-666D-41E9-AE29-411455C87213@utoronto.ca>
Message-ID: <CAKL8G3Fe4Gs_27B5VaZ99s-j_-EfpLmAPwPayjD9nfhr1uS7QQ@mail.gmail.com>

Dear Dr. Steipe,

Thank you for the code.  It does exactly what I needed.

Best regards,
Jorge.-


On Wed, Oct 28, 2015 at 1:18 PM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Your code does not produce the matrix in your image.
> The first three rows contain all-zeros and the last row is missing.
> The following line fixes that:
>
> m <- rbind(m[-(1:3), ], 1:5)
>
> Given that matrix, the following code produces the output
> you have illustrated. It's so trivial however that I suspect
> something must be missing in your problem description.
>
>
>
> v <- numeric(nrow(m))
> j <- 1
> for (i in 1:nrow(m)) {
>     if (j > ncol(m) || m[i,j] == 0) {
>         j <- 1
>     }
>     v[i] <- m[i,j]
>     j <- j+1
> }
>
> v
>
> Note that this puts 0 in the output if
> there is a zero in your first column and
> the "diagonal". Your example didn't have that.
>
>
>
> B.
>
>
> On Oct 28, 2015, at 1:17 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
>
> > Dear all,
> >
> > I thought I would better send an image illustrating that the problem is
> > (hope the file gets through).  In the picture, the matrix "m" is given by
> >
> > ## input
> > m <- structure(c(0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2,
> > 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,
> > 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5,
> > 5), .Dim = c(12L, 5L))
> >
> > We start from the entry [1,1] and select all values in the diagonal until
> > we find the first zero. That is, we select the values in purple.  Because
> > the first zero is found in [4,4], the next matrix begins in the 4th row.
> > The values of interest would be 1, 2, 3, 4, 5 (light blue).  The last
> value
> > in this resulting vector is entry m[8,5], which is located at the maximum
> > number of columns of m. Hence, the next matrix to work with starts at
> row 9
> > and the values of interest are 1, 2 (in orange).
> >
> > The output vector would then be of the same length as the number of rows
> in
> > "m", and would contain the elements previously selected.
> >
> > Any ideas on how to proceed?
> >
> > Thank you very much in advance.
> >
> > Best regards,
> > Jorge Velez.-
> >
> >
> >
> > On Tue, Oct 27, 2015 at 4:38 PM, Jorge I Velez <jorgeivanvelez at gmail.com
> >
> > wrote:
> >
> >> Thank you all for your solutions and comments.
> >>
> >> As Dr. Carlson mentioned, we leave rows 1 to 3 out as they are all
> zeroes.
> >> Then, the entries I need to select from m are
> >>
> >> ----------------
> >> entry     value
> >> ----------------
> >> 4,1  ---> 1
> >> 5,2  ---> 2
> >> 6,3  ---> 3
> >> 7,1  ---> 1
> >> 8,2  ---> 2
> >> 9,3  ---> 3
> >> 10,4  ---> 4
> >> 11,5  ---> 5
> >> 12,1  ---> 1
> >>
> >> Note that the entry [7,4] is zero, so we start from the first column in
> >> the 7th row and then select entry [7,1] instead.  That's what I meant
> by  "...
> >> the idea is to extract the diagonal elements until a zero is found."  I
> >> should have said *entries* instead of  _diagonal elements_. I am sorry
> Dr.
> >> Turner for the confusion.
> >>
> >> Starting with m
> >>
> >> R> m
> >> #       [,1] [,2] [,3] [,4] [,5]
> >> # [1,]    0    0    0    0    0
> >> # [2,]    0    0    0    0    0
> >> # [3,]    0    0    0    0    0
> >> # [4,]    1    2    3    0    0
> >> # [5,]    1    2    3    0    0
> >> # [6,]    1    2    3    0    0
> >> # [7,]    1    2    3    0    0
> >> # [8,]    1    2    3    0    0
> >> # [9,]    1    2    3    4    0
> >> #[10,]    1    2    3    4    0
> >> #[11,]    1    2    3    4    5
> >> #[12,]    1    2    3    4    5
> >>
> >> the first submatrix to work with is
> >>
> >> # [4,]    1    2    3    0    0
> >> # [5,]    1    2    3    0    0
> >> # [6,]    1    2    3    0    0
> >>
> >> from which the elements of interest are 1, 2, 3.  Note that the 7th row
> of
> >> m is not included here because m[7, 5] = 0.
> >>
> >> Further, the second submatrix is
> >>
> >> # [7,]    1    2    3    0    0
> >> # [8,]    1    2    3    0    0
> >> # [9,]    1    2    3    4    0
> >> #[10,]    1    2    3    4    0
> >> #[11,]    1    2    3    4    5
> >>
> >> and the corresponding elements are 1, 2, 3, 4, 5.
> >>
> >> And the last matrix is
> >>
> >> #[12,]    1    2    3    4    5
> >>
> >> from which the position [12,1] is selected.
> >>
> >> So, the resulting entries from this process are 1, 2, 3, 1, 2, 3, 4, 5,
> 1.
> >>
> >> Thank you in advance for any additional insight you may provide.
> >>
> >> Regards,
> >> Jorge Velez.-
> >>
> >>
> >>
> >> On Tue, Oct 27, 2015 at 4:06 PM, David L Carlson <dcarlson at tamu.edu>
> >> wrote:
> >>
> >>> I don't see how you are getting the result you provide.
> >>>
> >>>> m
> >>>      [,1] [,2] [,3] [,4] [,5]
> >>> [1,]    0    0    0    0    0
> >>> [2,]    0    0    0    0    0
> >>> [3,]    0    0    0    0    0
> >>> [4,]    1    2    3    0    0
> >>> [5,]    1    2    3    0    0
> >>> [6,]    1    2    3    0    0
> >>> [7,]    1    2    3    0    0
> >>> [8,]    1    2    3    0    0
> >>> [9,]    1    2    3    4    0
> >>> [10,]    1    2    3    4    0
> >>> [11,]    1    2    3    4    5
> >>> [12,]    1    2    3    4    5
> >>>> t(sapply(1:8, function(x) diag(m[x:12, ])))
> >>>     [,1] [,2] [,3] [,4] [,5]
> >>> [1,]    0    0    0    0    0
> >>> [2,]    0    0    3    0    0
> >>> [3,]    0    2    3    0    0
> >>> [4,]    1    2    3    0    0
> >>> [5,]    1    2    3    0    0
> >>> [6,]    1    2    3    4    0
> >>> [7,]    1    2    3    4    5
> >>> [8,]    1    2    3    4    5
> >>>
> >>> These are all of the diagonals from the 1st through 8th rows. The
> first 3
> >>> begin with 0 so we leave them out, but then we have 4th: 1, 2, 3; 5th:
> 1,
> >>> 2, 3; 6th: 1, 2, 3, 4, etc so you must have some additional rule in
> mind to
> >>> get your answer.
> >>>
> >>> -------------------------------------
> >>> David L Carlson
> >>> Department of Anthropology
> >>> Texas A&M University
> >>> College Station, TX 77840-4352
> >>>
> >>>
> >>>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge
> I
> >>> Velez
> >>> Sent: Tuesday, October 27, 2015 2:44 PM
> >>> To: jim holtman
> >>> Cc: R-help
> >>> Subject: Re: [R] Extract entries from matrix
> >>>
> >>> Dear Jim,
> >>>
> >>> Thank you very much for your quick reply.
> >>>
> >>> I am sorry for the confusion it may have caused, but I messed up the
> >>> indexes in my example.  I would like, from the following matrix "m"
> >>>
> >>> ## input
> >>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> >>> 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
> >>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
> >>> 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim =
> c(12L,
> >>> 5L))
> >>>
> >>> to obtain
> >>>
> >>> 1 2 3 1 2 3 4 5 1
> >>>
> >>> Sure using m[idx] will give the desired result.  The problem is that
> idx
> >>> is
> >>> not known and needs to be determined from "m".  I would like to use
> >>> something like
> >>>
> >>> extractDiagonals(m)
> >>> ## [1]  1 2 3 1 2 3 4 5 1
> >>>
> >>> I look forward to your reply.  Thanks in advance.
> >>>
> >>> Best regards,
> >>> Jorge Velez.-
> >>>
> >>>
> >>>
> >>> On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com>
> wrote:
> >>>
> >>>> If you want to use the numbers you gave a the index into the matrix,
> >>> then
> >>>> you can create a matrix with the values and then index into 'm'.  I
> >>> don't
> >>>> see a '4' in the output example you gave using your index values:
> >>>>
> >>>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >>>> +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> >>>> +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> >>>> +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>> +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> >>>> +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> >>>> +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> >>>> +  5L), .Dim = c(22L, 5L))
> >>>>> # create index matrix
> >>>>> indx <- matrix(c(4, 1,
> >>>> +  5, 2,
> >>>> +  6, 3,
> >>>> +  7, 1,
> >>>> +  8, 2,
> >>>> +  9, 3,
> >>>> +  10, 1,
> >>>> +  11, 2,
> >>>> +  12, 3), ncol = 2, byrow = TRUE)
> >>>>>
> >>>>>
> >>>>> m
> >>>>      [,1] [,2] [,3] [,4] [,5]
> >>>> [1,]    0    0    0    0    0
> >>>> [2,]    0    0    0    0    0
> >>>> [3,]    0    0    0    0    0
> >>>> [4,]    1    2    3    0    0
> >>>> [5,]    1    2    3    0    0
> >>>> [6,]    1    2    3    0    0
> >>>> [7,]    1    2    3    0    0
> >>>> [8,]    1    2    3    0    0
> >>>> [9,]    1    2    3    4    0
> >>>> [10,]    1    2    3    4    0
> >>>> [11,]    1    2    3    4    5
> >>>> [12,]    1    2    3    4    5
> >>>> [13,]    1    2    3    4    5
> >>>> [14,]    1    2    3    4    5
> >>>> [15,]    1    2    3    4    5
> >>>> [16,]    1    2    3    4    5
> >>>> [17,]    1    2    3    4    5
> >>>> [18,]    1    2    3    4    5
> >>>> [19,]    1    2    3    4    5
> >>>> [20,]    1    2    3    4    5
> >>>> [21,]    1    2    3    4    5
> >>>> [22,]    1    2    3    4    5
> >>>>> indx
> >>>>      [,1] [,2]
> >>>> [1,]    4    1
> >>>> [2,]    5    2
> >>>> [3,]    6    3
> >>>> [4,]    7    1
> >>>> [5,]    8    2
> >>>> [6,]    9    3
> >>>> [7,]   10    1
> >>>> [8,]   11    2
> >>>> [9,]   12    3
> >>>>> m[indx]
> >>>> [1] 1 2 3 1 2 3 1 2 3
> >>>>
> >>>>
> >>>> Jim Holtman
> >>>> Data Munger Guru
> >>>>
> >>>> What is the problem that you are trying to solve?
> >>>> Tell me what you want to do, not how you want to do it.
> >>>>
> >>>> On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <
> >>> jorgeivanvelez at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> Dear R-help,
> >>>>>
> >>>>> I am working with a matrix "m" from which I would like to extract
> some
> >>>>> elements.  An toy example is as follows:
> >>>>>
> >>>>> ## input matrix
> >>>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >>>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> >>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> >>>>> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >>>>> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> >>>>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> >>>>> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> >>>>> 5L), .Dim = c(22L, 5L))
> >>>>>
> >>>>> R> m
> >>>>> #         [,1]  [,2] [,3] [,4] [,5]
> >>>>> #  [1,]    0    0    0    0    0
> >>>>> #  [2,]    0    0    0    0    0
> >>>>> #  [3,]    0    0    0    0    0
> >>>>> #  [4,]    1    2    3    0    0
> >>>>> #  [5,]    1    2    3    0    0
> >>>>> #  [6,]    1    2    3    0    0
> >>>>> #  [7,]    1    2    3    0    0
> >>>>> #  [8,]    1    2    3    0    0
> >>>>> #  [9,]    1    2    3    4    0
> >>>>> # [10,]   1    2    3    4    0
> >>>>> # [11,]   1    2    3    4    5
> >>>>> # [12,]   1    2    3    4    5
> >>>>>
> >>>>>> From "m", I would like to extract the entries
> >>>>>
> >>>>> 4, 1
> >>>>> 5, 2
> >>>>> 6, 3
> >>>>> 7, 1
> >>>>> 8, 2
> >>>>> 9, 3
> >>>>> 10, 1
> >>>>> 11, 2
> >>>>> 12, 3
> >>>>>
> >>>>> so at the end of applying a function "f" to "m" I get
> >>>>>
> >>>>> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
> >>>>>
> >>>>>
> >>>>> Basically the idea is to extract the diagonal elements until a zero
> is
> >>>>> found.
> >>>>>
> >>>>> In the real problem the dimensions of "m" are much bigger, but this
> >>>>> smaller
> >>>>> version of "m" illustrate what needs to be done.
> >>>>>
> >>>>> I would greatly appreciate any ideas on how to do this.
> >>>>>
> >>>>> Thanks in advance,
> >>>>> Jorge Velez.-
> >>>>>
> >>>>>        [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> > <example.png>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Wed Nov  4 19:32:55 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 4 Nov 2015 12:32:55 -0600
Subject: [R] R Consortium projects
Message-ID: <CABdHhvHb2-GOAYO4tY8VfpdNH5Xz9TXo4T9_hVarvSQO=fKMmg@mail.gmail.com>

Hi all,

I'm very pleased to announce that the Infrastructure Steering
Committee (ISC) of the R consortium is calling for proposals:

https://www.r-consortium.org/about/isc/proposals

In brief:

* We want to fund projects that help the R community, broadly construed.

* Currently, we are mostly focussed on funding people who have the
  skills to solve a problem. In the future, we will explore how to
  match up people with skills and people with problems.

* Proposals are due Jan 10.

Please let me know if you have any questions!

Hadley Wickham
Chair, ISC

-- 
http://had.co.nz/


From evan.cooch at gmail.com  Wed Nov  4 20:08:47 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 4 Nov 2015 14:08:47 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
Message-ID: <563A57BF.4090106@gmail.com>

Greetings --

This has also been posted on the jags forum, but since I suspect the 
problem is more 'R-related' than jags, will aos post here.

Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux 
boxes (which run latest RHEL). Here are the basic details:

1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other 
than the fact that I used OpenBLAS instead of 'generic'. Works fine.

2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy, 
./configure & make & make install) -- no errors. Runs fine as a 
standalone app from CLI.


3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R -- 
usual R CMD INSTALL approach). Again, no errors reported.


However, when I fire up R, and try something simple like

library(R2jags)

I get a whole slew of error messages - following is reproducible on all 
my machines:

Loading required package: rjags
Loading required package: coda
Error : .onLoad failed in loadNamespace() for 'rjags', details:
call: dyn.load(file, DLLpath = DLLpath, ...)
error: unable to load shared object 
'/usr/lib64/R/library/rjags/libs/rjags.so':
libjags.so.3: cannot open shared object file: No such file or directory
Error: package ?rjags? could not be loaded


Meaning, what? I checked, and rjags.so is where its supposed to be.If I run

  R CMD ldd /usr/lib64/R/library/rjags/libs/rjags.so

no failures at any point.

Suggestions? Pointers to the obvious?

Thanks very much in advance.


From rhurlin at gwdg.de  Wed Nov  4 21:05:05 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Wed, 4 Nov 2015 21:05:05 +0100
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A57BF.4090106@gmail.com>
References: <563A57BF.4090106@gmail.com>
Message-ID: <563A64F1.6050706@gwdg.de>

Am 04.11.2015 um 20:08 schrieb Evan Cooch:
> Greetings --
> 
> This has also been posted on the jags forum, but since I suspect the
> problem is more 'R-related' than jags, will aos post here.
> 
> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux
> boxes (which run latest RHEL). Here are the basic details:
> 
> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other
> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
> 
> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy,
> ./configure & make & make install) -- no errors. Runs fine as a
> standalone app from CLI.
> 
> 
> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R --
> usual R CMD INSTALL approach). Again, no errors reported.
> 
> 
> However, when I fire up R, and try something simple like
> 
> library(R2jags)


On FreeBSD, I get the following, when I try to load package R2jags:

library(R2jags)
Lade n?tiges Paket: rjags
Lade n?tiges Paket: coda
Linked to JAGS 4.0.0
Loaded modules: basemod,bugs
Attache Paket: ?R2jags?
The following object is masked from ?package:coda?:
    traceplot

So, in principle, it should work on Unix alike platforms.

I suggest, your next step should be to rebuild packages coda, basemod
and bugs, and of course, package R2jags_0.5-7?

Sorry, no other clue so far.

Greetings,
Rainer


> 
> I get a whole slew of error messages - following is reproducible on all
> my machines:
> 
> Loading required package: rjags
> Loading required package: coda
> Error : .onLoad failed in loadNamespace() for 'rjags', details:
> call: dyn.load(file, DLLpath = DLLpath, ...)
> error: unable to load shared object
> '/usr/lib64/R/library/rjags/libs/rjags.so':
> libjags.so.3: cannot open shared object file: No such file or directory
> Error: package ?rjags? could not be loaded
> 
> 
> Meaning, what? I checked, and rjags.so is where its supposed to be.If I run
> 
>  R CMD ldd /usr/lib64/R/library/rjags/libs/rjags.so
> 
> no failures at any point.
> 
> Suggestions? Pointers to the obvious?
> 
> Thanks very much in advance.


From yvan at dragonfly.co.nz  Wed Nov  4 21:31:37 2015
From: yvan at dragonfly.co.nz (Yvan Richard)
Date: Thu, 5 Nov 2015 09:31:37 +1300
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A64F1.6050706@gwdg.de>
References: <563A57BF.4090106@gmail.com> <563A64F1.6050706@gwdg.de>
Message-ID: <CAMrYPbE0TXj23vJd9gVkqedPosSpVRsLPotRCj0=qtALe7odtA@mail.gmail.com>

Hi Evan

The last version of rjags on CRAN is 4.4. Have you tried it?
http://cran.stat.auckland.ac.nz/web/packages/rjags/index.html
I did have the same problem before updating it, but it now works on my
Ubuntu with the new JAGS version.

Cheers,
-Yvan


From yvan at dragonfly.co.nz  Wed Nov  4 22:24:17 2015
From: yvan at dragonfly.co.nz (Yvan Richard)
Date: Thu, 5 Nov 2015 10:24:17 +1300
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A7435.5080408@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A64F1.6050706@gwdg.de>
	<CAMrYPbE0TXj23vJd9gVkqedPosSpVRsLPotRCj0=qtALe7odtA@mail.gmail.com>
	<563A6DAA.1050807@gmail.com> <563A7435.5080408@gmail.com>
Message-ID: <CAMrYPbFxxq=mM=wAjPsw9xm=j3vM4D+pixgyLQHbDx8e4j996A@mail.gmail.com>

According to the README file in the rjags source code (in the tar.gz
file), you can apparently pass options to the configure script to
specify where JAGS is installed.
I'm confident you can solve your problem by following the instructions
in that README file.


On 5 November 2015 at 10:10, Evan Cooch <evan.cooch at gmail.com> wrote:
> I wonder if this is the problem -- on my system(s), R is installed to
> /usr/lib64/R, whereas JAGS and associated files is in /usr/local/lib/JAGS. I
> have a hunch that the problem relates to where  rjags expects to find things
> during install/compile, given how R was compiled, and where it is installed.
>
> Seem reasonable? Not sure what to do about it, but...
>
>
> On 11/4/2015 3:42 PM, Evan Cooch wrote:
>>
>>
>>
>> On 11/4/2015 3:31 PM, Yvan Richard wrote:
>>>
>>> Hi Evan
>>>
>>> The last version of rjags on CRAN is 4.4. Have you tried it?
>>> http://cran.stat.auckland.ac.nz/web/packages/rjags/index.html
>>> I did have the same problem before updating it, but it now works on my
>>> Ubuntu with the new JAGS version.
>>>
>>> Cheers,
>>> -Yvan
>>>
>>
>> yes, but when I do, I get the following during the install (which fails).
>>
>> checking version of JAGS library... wrong version
>> configure: error: rjags requires JAGS version 4.x.y
>> ERROR: configuration failed for package ?rjags?
>> * removing ?/usr/lib64/R/library/rjags?
>> * restoring previous ?/usr/lib64/R/library/rjags?
>>
>>
>> which makes no sense, because I have JAGS 4.0.01 on the system, and in the
>> path
>>
>> Welcome to JAGS 4.0.1 on Wed Nov  4 15:41:46 2015
>> JAGS is free software and comes with ABSOLUTELY NO WARRANTY
>> Loading module: basemod: ok
>> Loading module: bugs: ok
>> .
>>
>>
>



-- 
Yvan Richard

      DRAGONFLY Science

Physical address: Level 5, 158 Victoria St, Te Aro, Wellington
Postal address: PO Box 27535, Wellington 6141
New Zealand
Ph: 04.385.9285
web page


From r.turner at auckland.ac.nz  Wed Nov  4 23:20:06 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 5 Nov 2015 11:20:06 +1300
Subject: [R] [FORGED] Re:  merging-binning data
In-Reply-To: <152763221.1772460.1446653698567.JavaMail.yahoo@mail.yahoo.com>
References: <D5533A4E-C726-45B0-8256-0FCF0FD957E5@utoronto.ca>
	<152763221.1772460.1446653698567.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <563A8496.1040004@auckland.ac.nz>


I have been vaguely following this thread and have become very confused 
given the complications that seem to have appeared.

The original question was:

>>>>> On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
>>>>>> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
>>>>>> I have a vector that looks like

Actually you appear to have a 32 x 1 *matrix* (NOT the same thing!) that 
looks like:

>>>>>>    binDistance
>>>>>>              [,1]
>>>>>>    [1,] 238.95162
>>>>>>    [2,] 143.08590
>>>>>>    [3,]  88.50923
>>>>>>    [4,] 177.67884
>>>>>>    [5,] 277.54116
>>>>>>    [6,] 342.94689
>>>>>>    [7,] 241.60905
>>>>>>    [8,] 177.81969
>>>>>>    [9,] 211.25559
>>>>>> [10,] 279.72702
>>>>>> [11,] 381.95738
>>>>>> [12,] 483.76363
>>>>>> [13,] 480.98841
>>>>>> [14,] 369.75241
>>>>>> [15,] 267.73650
>>>>>> [16,] 138.55959
>>>>>> [17,] 137.93181
>>>>>> [18,] 184.75200
>>>>>> [19,] 254.64359
>>>>>> [20,] 328.87785
>>>>>> [21,] 273.15577
>>>>>> [22,] 252.52830
>>>>>> [23,] 252.52830
>>>>>> [24,] 252.52830
>>>>>> [25,] 262.20084
>>>>>> [26,] 314.93064
>>>>>> [27,] 366.02996
>>>>>> [28,] 442.77467
>>>>>> [29,] 521.20323
>>>>>> [30,] 465.33071
>>>>>> [31,] 366.60582
>>>>>> [32,]  13.69540

A later addendum to the question indicated that the OP wanted labels for 
the result consisting of the endpoints of the intervals into which the 
data were subdivided.  Unless I am misunderstanding, this is trivial to 
accomplish using cut() and split():

x <- c(238.95162, 143.0859, 88.50923, 177.67884, 277.54116, 342.94689,
241.60905, 177.81969, 211.25559, 279.72702, 381.95738, 483.76363,
480.98841, 369.75241, 267.7365, 138.55959, 137.93181, 184.752,
254.64359, 328.87785, 273.15577, 252.5283, 252.5283, 252.5283,
262.20084, 314.93064, 366.02996, 442.77467, 521.20323, 465.33071,
366.60582, 13.6954)

f <- cut(x,5)

y <- split(x,f)

y

$`(13.2,115]`
[1] 88.50923 13.69540

$`(115,217]`
[1] 143.0859 177.6788 177.8197 211.2556 138.5596 137.9318 184.7520

$`(217,318]`
  [1] 238.9516 277.5412 241.6090 279.7270 267.7365 254.6436 273.1558 
252.5283
  [9] 252.5283 252.5283 262.2008 314.9306

$`(318,420]`
[1] 342.9469 381.9574 369.7524 328.8779 366.0300 366.6058

$`(420,522]`
[1] 483.7636 480.9884 442.7747 521.2032 465.3307


Is this not the result that you want?  If not, what *is* the result that 
you want?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From evan.cooch at gmail.com  Wed Nov  4 21:36:01 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 4 Nov 2015 15:36:01 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A57BF.4090106@gmail.com>
References: <563A57BF.4090106@gmail.com>
Message-ID: <563A6C31.3070704@gmail.com>



On 11/4/2015 2:08 PM, Evan Cooch wrote:
> Greetings --
>
> This has also been posted on the jags forum, but since I suspect the 
> problem is more 'R-related' than jags, will aos post here.
>
> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux 
> boxes (which run latest RHEL). Here are the basic details:
>
> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other 
> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
>
> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy, 
> ./configure & make & make install) -- no errors. Runs fine as a 
> standalone app from CLI.
>
>
> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R -- 
> usual R CMD INSTALL approach). Again, no errors reported.
>
>
> However, when I fire up R, and try something simple like
>
> library(R2jags)
>
> I get a whole slew of error messages - following is reproducible on 
> all my machines:
>
> Loading required package: rjags
> Loading required package: coda
> Error : .onLoad failed in loadNamespace() for 'rjags', details:
> call: dyn.load(file, DLLpath = DLLpath, ...)
> error: unable to load shared object 
> '/usr/lib64/R/library/rjags/libs/rjags.so':
> libjags.so.3: cannot open shared object file: No such file or directory
> Error: package ?rjags? could not be loaded
>
>

Further puzzlement -- I uninstalled R2jags and rjags, with the idea that 
re-installing them (ostensibly with the 'latest and greatest') would do 
the trick. While the process went fine for R2jags, when I tried to 
re-install rjags, got the following error messages:

checking for gcc -m64 -std=gnu99 option to accept ISO C89... none needed
checking for jags_version in -ljags... yes
checking version of JAGS library... wrong version
configure: error: rjags requires JAGS version 4.x.y
ERROR: configuration failed for package ?rjags?
* removing ?/usr/lib64/R/library/rjags?
* restoring previous ?/usr/lib64/R/library/rjags?


I'm confused as to how it is not finding JAGS 4.x.y, which is not only 
most definitely on the system, but in the path:

[root at euler egc]# jags
Welcome to JAGS 4.0.1 on Wed Nov  4 15:35:12 2015
JAGS is free software and comes with ABSOLUTELY NO WARRANTY
Loading module: basemod: ok
Loading module: bugs: ok


From evan.cooch at gmail.com  Wed Nov  4 21:42:18 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 4 Nov 2015 15:42:18 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <CAMrYPbE0TXj23vJd9gVkqedPosSpVRsLPotRCj0=qtALe7odtA@mail.gmail.com>
References: <563A57BF.4090106@gmail.com> <563A64F1.6050706@gwdg.de>
	<CAMrYPbE0TXj23vJd9gVkqedPosSpVRsLPotRCj0=qtALe7odtA@mail.gmail.com>
Message-ID: <563A6DAA.1050807@gmail.com>



On 11/4/2015 3:31 PM, Yvan Richard wrote:
> Hi Evan
>
> The last version of rjags on CRAN is 4.4. Have you tried it?
> http://cran.stat.auckland.ac.nz/web/packages/rjags/index.html
> I did have the same problem before updating it, but it now works on my
> Ubuntu with the new JAGS version.
>
> Cheers,
> -Yvan
>

yes, but when I do, I get the following during the install (which fails).

checking version of JAGS library... wrong version
configure: error: rjags requires JAGS version 4.x.y
ERROR: configuration failed for package ?rjags?
* removing ?/usr/lib64/R/library/rjags?
* restoring previous ?/usr/lib64/R/library/rjags?


which makes no sense, because I have JAGS 4.0.01 on the system, and in 
the path

Welcome to JAGS 4.0.1 on Wed Nov  4 15:41:46 2015
JAGS is free software and comes with ABSOLUTELY NO WARRANTY
Loading module: basemod: ok
Loading module: bugs: ok
.


From evan.cooch at gmail.com  Wed Nov  4 22:10:13 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 4 Nov 2015 16:10:13 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A6DAA.1050807@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A64F1.6050706@gwdg.de>
	<CAMrYPbE0TXj23vJd9gVkqedPosSpVRsLPotRCj0=qtALe7odtA@mail.gmail.com>
	<563A6DAA.1050807@gmail.com>
Message-ID: <563A7435.5080408@gmail.com>

I wonder if this is the problem -- on my system(s), R is installed to 
/usr/lib64/R, whereas JAGS and associated files is in 
/usr/local/lib/JAGS. I have a hunch that the problem relates to where  
rjags expects to find things during install/compile, given how R was 
compiled, and where it is installed.

Seem reasonable? Not sure what to do about it, but...

On 11/4/2015 3:42 PM, Evan Cooch wrote:
>
>
> On 11/4/2015 3:31 PM, Yvan Richard wrote:
>> Hi Evan
>>
>> The last version of rjags on CRAN is 4.4. Have you tried it?
>> http://cran.stat.auckland.ac.nz/web/packages/rjags/index.html
>> I did have the same problem before updating it, but it now works on my
>> Ubuntu with the new JAGS version.
>>
>> Cheers,
>> -Yvan
>>
>
> yes, but when I do, I get the following during the install (which fails).
>
> checking version of JAGS library... wrong version
> configure: error: rjags requires JAGS version 4.x.y
> ERROR: configuration failed for package ?rjags?
> * removing ?/usr/lib64/R/library/rjags?
> * restoring previous ?/usr/lib64/R/library/rjags?
>
>
> which makes no sense, because I have JAGS 4.0.01 on the system, and in 
> the path
>
> Welcome to JAGS 4.0.1 on Wed Nov  4 15:41:46 2015
> JAGS is free software and comes with ABSOLUTELY NO WARRANTY
> Loading module: basemod: ok
> Loading module: bugs: ok
> .
>
>


From SHARONLOUISE.EVERY at cdu.edu.au  Thu Nov  5 07:14:15 2015
From: SHARONLOUISE.EVERY at cdu.edu.au (Sharon Louise Every)
Date: Thu, 5 Nov 2015 06:14:15 +0000
Subject: [R] mysterious error message not sure if its from within package?
Message-ID: <F07C4828-417D-4C4D-A0F9-C5716D394BE9@cdu.edu.au>

Hi everyone,

  Sorry if this is not appropriate through this email list but I wanted to check if this was something wrong with R in my computer rather than within a package I?m using. I am using SIAR - SIBER and have for a few months now. I went back to check some figures with code that I had previously used without a problem. I have since ran the sample data within the package and somebody else?s data and code yet  theirs works and I get the same error Error: not a matrix when bayesian stats are about to be used. I have recently update my osx system to El captain - but everything that I have recently tried works. Does anyone have any suggestions. I have updated, and reinstalled R.




Cheers
Sharon Every

CDU & ANU (NAMRA) PhD Candidate

ATRF
23 Ellengowan Drive
Brinkin, NT
Ph:    8920 9212
M:      +61 409 862 464
PO Box: 41775, Casuarina, NT 0811
sharonlouise.every at cdu.edu.au<mailto:sharonlouise.every at cdu.edu.au>







	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Nov  5 09:59:37 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Nov 2015 02:59:37 -0600
Subject: [R] mysterious error message not sure if its from within
	package?
In-Reply-To: <F07C4828-417D-4C4D-A0F9-C5716D394BE9@cdu.edu.au>
References: <F07C4828-417D-4C4D-A0F9-C5716D394BE9@cdu.edu.au>
Message-ID: <563B1A79.9030907@gmail.com>

On 05/11/2015 12:14 AM, Sharon Louise Every wrote:
> Hi everyone,
> 
>   Sorry if this is not appropriate through this email list but I wanted to check if this was something wrong with R in my computer rather than within a package I?m using. I am using SIAR - SIBER and have for a few months now. I went back to check some figures with code that I had previously used without a problem. I have since ran the sample data within the package and somebody else?s data and code yet  theirs works and I get the same error Error: not a matrix when bayesian stats are about to be used. I have recently update my osx system to El captain - but everything that I have recently tried works. Does anyone have any suggestions. I have updated, and reinstalled R.

After you get the error, call traceback().  That will usually tell you
where the error occurred by listing the call stack at the time of the
error.

Duncan Murdoch


From stefano.sofia at regione.marche.it  Thu Nov  5 10:26:24 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 5 Nov 2015 09:26:24 +0000
Subject: [R] How to change name of pdf output of function windRose in
 openair package
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3D4977B8@ESINO.regionemarche.intra>

Dear r-list users,
I am using windRose within the openair package.
Automatically the wind rose is saved in a pdf file called Rplots.pdf .

I need to apply this function to different data frames, and each time I need to change automatically the name of the pdf output.
I am not able to do it, I read the manual quite carefully but I didn't find any hint about it.

Would somebody be able to help me?
Thank you for your attention
Stefano


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Thu Nov  5 10:49:55 2015
From: alaios at yahoo.com (Alaios)
Date: Thu, 5 Nov 2015 09:49:55 +0000 (UTC)
Subject: [R] [FORGED] Re:  merging-binning data
In-Reply-To: <563A8496.1040004@auckland.ac.nz>
References: <563A8496.1040004@auckland.ac.nz>
Message-ID: <1801810490.132981.1446716995774.JavaMail.yahoo@mail.yahoo.com>

Thanks.That is what I want. It is more that I do not know how to read factors that these two functions return
Browse[1]> y
$`13.6954016405008`
[1] (13.2,115]
Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]

$`88.5092280867206`
[1] (13.2,115]
Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]

$`137.931810364616`
[1] (115,217]
Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]

?str(y)
List of 30
?$ 13.6954016405008: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 1
?$ 88.5092280867206: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 1
?$ 137.931810364616: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 138.559590072838: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 143.085897171535: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 177.678839068735: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 177.819693807561: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 184.752000138622: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 211.255591076421: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
?$ 238.951618624679: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3
?$ 241.609050762905: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3
?$ 252.528297510773: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3 3 3
?$ 254.643586371518: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3

I need to be able to keep the items within their groups and at the same time to keep the label of the group so to be able to use it for plotting purposes.
How I can do that?RegardsAlex
 


     On Wednesday, November 4, 2015 11:20 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
   

 
I have been vaguely following this thread and have become very confused 
given the complications that seem to have appeared.

The original question was:

>>>>> On Tue, Nov 3, 2015 at 10:47 AM, Alaios via R-help <r-help at r-project.org> wrote:
>>>>>> Dear all,I am not exactly sure on what is the proper name of what I am trying to do.
>>>>>> I have a vector that looks like

Actually you appear to have a 32 x 1 *matrix* (NOT the same thing!) that 
looks like:

>>>>>>? ? binDistance
>>>>>>? ? ? ? ? ? ? [,1]
>>>>>>? ? [1,] 238.95162
>>>>>>? ? [2,] 143.08590
>>>>>>? ? [3,]? 88.50923
>>>>>>? ? [4,] 177.67884
>>>>>>? ? [5,] 277.54116
>>>>>>? ? [6,] 342.94689
>>>>>>? ? [7,] 241.60905
>>>>>>? ? [8,] 177.81969
>>>>>>? ? [9,] 211.25559
>>>>>> [10,] 279.72702
>>>>>> [11,] 381.95738
>>>>>> [12,] 483.76363
>>>>>> [13,] 480.98841
>>>>>> [14,] 369.75241
>>>>>> [15,] 267.73650
>>>>>> [16,] 138.55959
>>>>>> [17,] 137.93181
>>>>>> [18,] 184.75200
>>>>>> [19,] 254.64359
>>>>>> [20,] 328.87785
>>>>>> [21,] 273.15577
>>>>>> [22,] 252.52830
>>>>>> [23,] 252.52830
>>>>>> [24,] 252.52830
>>>>>> [25,] 262.20084
>>>>>> [26,] 314.93064
>>>>>> [27,] 366.02996
>>>>>> [28,] 442.77467
>>>>>> [29,] 521.20323
>>>>>> [30,] 465.33071
>>>>>> [31,] 366.60582
>>>>>> [32,]? 13.69540

A later addendum to the question indicated that the OP wanted labels for 
the result consisting of the endpoints of the intervals into which the 
data were subdivided.? Unless I am misunderstanding, this is trivial to 
accomplish using cut() and split():

x <- c(238.95162, 143.0859, 88.50923, 177.67884, 277.54116, 342.94689,
241.60905, 177.81969, 211.25559, 279.72702, 381.95738, 483.76363,
480.98841, 369.75241, 267.7365, 138.55959, 137.93181, 184.752,
254.64359, 328.87785, 273.15577, 252.5283, 252.5283, 252.5283,
262.20084, 314.93064, 366.02996, 442.77467, 521.20323, 465.33071,
366.60582, 13.6954)

f <- cut(x,5)

y <- split(x,f)

y

$`(13.2,115]`
[1] 88.50923 13.69540

$`(115,217]`
[1] 143.0859 177.6788 177.8197 211.2556 138.5596 137.9318 184.7520

$`(217,318]`
? [1] 238.9516 277.5412 241.6090 279.7270 267.7365 254.6436 273.1558 
252.5283
? [9] 252.5283 252.5283 262.2008 314.9306

$`(318,420]`
[1] 342.9469 381.9574 369.7524 328.8779 366.0300 366.6058

$`(420,522]`
[1] 483.7636 480.9884 442.7747 521.2032 465.3307


Is this not the result that you want?? If not, what *is* the result that 
you want?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


  
	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Thu Nov  5 12:25:02 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 5 Nov 2015 22:25:02 +1100
Subject: [R] How to change name of pdf output of function windRose in
 openair package
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F3D4977B8@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F3D4977B8@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fUToSY10O03WBRNSGfaqTssHcCypqN2zTRq46UGcGuqrQ@mail.gmail.com>

Hi Stefano,
Just start the PDF device, do the plot, then close the PDF device:

library(openair)
...
data(mydata)
pdf("windRose.pdf")
windRose(mydata)
dev.off()

This is from the first example for the windRose function. It will produce a
file named "windRose.pdf" in the working directory of R.

Jim



On Thu, Nov 5, 2015 at 8:26 PM, Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear r-list users,
> I am using windRose within the openair package.
> Automatically the wind rose is saved in a pdf file called Rplots.pdf .
>
> I need to apply this function to different data frames, and each time I
> need to change automatically the name of the pdf output.
> I am not able to do it, I read the manual quite carefully but I didn't
> find any hint about it.
>
> Would somebody be able to help me?
> Thank you for your attention
> Stefano
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov  5 15:02:38 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 5 Nov 2015 14:02:38 +0000
Subject: [R] How to change name of pdf output of function windRose in
 openair package
In-Reply-To: <CA+8X3fUToSY10O03WBRNSGfaqTssHcCypqN2zTRq46UGcGuqrQ@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F3D4977B8@ESINO.regionemarche.intra>
	<CA+8X3fUToSY10O03WBRNSGfaqTssHcCypqN2zTRq46UGcGuqrQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFFC72@SRVEXCHMBX.precheza.cz>

Hi

if you need to do naming automagically you can use ls for creating object consisting from names of objects and use it for naming inside a cycle.

obj <- ls()
for (i in 1:n) {
pdf(paste(obj[i], "pdf", sep="."))
...
do the plotting
dev.off()
}

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim
> Lemon
> Sent: Thursday, November 05, 2015 12:25 PM
> To: Stefano Sofia
> Cc: r-help at r-project.org
> Subject: Re: [R] How to change name of pdf output of function windRose
> in openair package
>
> Hi Stefano,
> Just start the PDF device, do the plot, then close the PDF device:
>
> library(openair)
> ...
> data(mydata)
> pdf("windRose.pdf")
> windRose(mydata)
> dev.off()
>
> This is from the first example for the windRose function. It will
> produce a file named "windRose.pdf" in the working directory of R.
>
> Jim
>
>
>
> On Thu, Nov 5, 2015 at 8:26 PM, Stefano Sofia <
> stefano.sofia at regione.marche.it> wrote:
>
> > Dear r-list users,
> > I am using windRose within the openair package.
> > Automatically the wind rose is saved in a pdf file called Rplots.pdf
> .
> >
> > I need to apply this function to different data frames, and each time
> > I need to change automatically the name of the pdf output.
> > I am not able to do it, I read the manual quite carefully but I
> didn't
> > find any hint about it.
> >
> > Would somebody be able to help me?
> > Thank you for your attention
> > Stefano
> >
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
> contenere
> > informazioni confidenziali, pertanto ? destinato solo a persone
> > autorizzate alla ricezione. I messaggi di posta elettronica per i
> > client di Regione Marche possono contenere informazioni confidenziali
> e con privilegi legali.
> > Se non si ? il destinatario specificato, non leggere, copiare,
> > inoltrare o archiviare questo messaggio. Se si ? ricevuto questo
> > messaggio per errore, inoltrarlo al mittente ed eliminarlo
> > completamente dal sistema del proprio computer. Ai sensi dell?art. 6
> > della DGR n. 1394/2008 si segnala che, in caso di necessit? ed
> > urgenza, la risposta al presente messaggio di posta elettronica pu?
> essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only
> > by persons entitled to receive the confidential information it may
> contain.
> > E-mail messages to clients of Regione Marche may contain information
> > that is confidential and legally privileged. Please do not read,
> copy,
> > forward, or store this message unless you are an intended recipient
> of
> > it. If you have received this message in error, please forward it to
> > the sender and delete it completely from your computer system.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From rhurlin at gwdg.de  Thu Nov  5 15:45:52 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Thu, 5 Nov 2015 15:45:52 +0100
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563A6C31.3070704@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
Message-ID: <563B6BA0.6090608@gwdg.de>

Am 04.11.2015 um 21:36 schrieb Evan Cooch:
>
>
> On 11/4/2015 2:08 PM, Evan Cooch wrote:
>> Greetings --
>>
>> This has also been posted on the jags forum, but since I suspect the
>> problem is more 'R-related' than jags, will aos post here.
>>
>> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux
>> boxes (which run latest RHEL). Here are the basic details:
>>
>> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other
>> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
>>
>> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy,
>> ./configure & make & make install) -- no errors. Runs fine as a
>> standalone app from CLI.
>>
>>
>> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R --
>> usual R CMD INSTALL approach). Again, no errors reported.
>>
>>
>> However, when I fire up R, and try something simple like
>>
>> library(R2jags)
>>
>> I get a whole slew of error messages - following is reproducible on
>> all my machines:
>>
>> Loading required package: rjags
>> Loading required package: coda
>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>> call: dyn.load(file, DLLpath = DLLpath, ...)
>> error: unable to load shared object
>> '/usr/lib64/R/library/rjags/libs/rjags.so':
>> libjags.so.3: cannot open shared object file: No such file or directory
>> Error: package ?rjags? could not be loaded
>>
>>
>
> Further puzzlement -- I uninstalled R2jags and rjags, with the idea that
> re-installing them (ostensibly with the 'latest and greatest') would do
> the trick. While the process went fine for R2jags, when I tried to
> re-install rjags, got the following error messages:
>
> checking for gcc -m64 -std=gnu99 option to accept ISO C89... none needed
> checking for jags_version in -ljags... yes
> checking version of JAGS library... wrong version
> configure: error: rjags requires JAGS version 4.x.y
> ERROR: configuration failed for package ?rjags?
> * removing ?/usr/lib64/R/library/rjags?
> * restoring previous ?/usr/lib64/R/library/rjags?

Hmm, is it possible, that your JAGS 4.x.y installation is fine, but an 
old libjags.so library is lying around from a not fully completed 
deinstallation? Could you have a look for older libjags.so versions, please?

Just a thought.

>
>
> I'm confused as to how it is not finding JAGS 4.x.y, which is not only
> most definitely on the system, but in the path:
>
> [root at euler egc]# jags
> Welcome to JAGS 4.0.1 on Wed Nov  4 15:35:12 2015
> JAGS is free software and comes with ABSOLUTELY NO WARRANTY
> Loading module: basemod: ok
> Loading module: bugs: ok


From evan.cooch at gmail.com  Thu Nov  5 15:44:00 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 5 Nov 2015 09:44:00 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux -- solved
In-Reply-To: <563A6C31.3070704@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
Message-ID: <563B6B30.1000900@gmail.com>

Well, sort of. I got sufficiently frustrated that I completely 
uninstalled R, jags, and everything related. Did a re-install using only 
versions of R nd JAGS found in the epel repo. No muss, no muss -- all 
works.

Out of curiosity, uninstalled again, and tried my usual sequence of 
manually compile R from source, same with JAGS. R works, JAGS works, but 
can't get any R package linking the two (say, rjags, R2jags), to 
recognize that JAGS is installed.

Ah well, at least the 'install from repos' approach works. I'll have to 
make do with that.


From ezgis76 at gmail.com  Thu Nov  5 16:00:18 2015
From: ezgis76 at gmail.com (Ezra Boyd)
Date: Thu, 5 Nov 2015 09:00:18 -0600
Subject: [R] Attempting to plot two different time series together
Message-ID: <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=Qg@mail.gmail.com>

Hello,

I am trying to create a plot (I guess two plots) using two different time
series datasets, but I'm not sure of the best approach.  The data is from a
tidal surge due to a hurricane and I would like to show the relationship
between stage and windspeed/direction.

One dataset is the tidal stage and it is sampled in 30 minutes intervals.
The other dataset is windspeed and direction and it is sampled every 6
minutes.  I would like to display the tidal hydrograph and then also show
windspeed and direction as a banner above it.  They would be two separate
plots, but with identical x-axis (as opposed to one plot that has both tide
& wind.)

Should I combine the two time series into one dataframe (with lots of NAs)
so that I can create the plots together, for example using pairs or
ggpairs? Or should I keep them separate, make the individual plots, and
then work on the layout in graphic design software? I would prefer the
former, but I just can't figure out how to make that work out.

Also, is it possible to depict wind direction (which is given in degree
clockwise from due north) with an arrow?

Thank you very much,

Ezra

-- 
Ezra Boyd, PhD
DisasterMap.net, LLC <http://DisasterMap.net>
ezgis <ezgis76 at gmail.com>76 at gmail.com <ezgis76 at gmail.com>
(504)533-4447

	[[alternative HTML version deleted]]


From luke.gaylor at live.com.au  Thu Nov  5 15:34:56 2015
From: luke.gaylor at live.com.au (Luke Gaylor)
Date: Fri, 6 Nov 2015 01:34:56 +1100
Subject: [R] post a message - R help. Surivival analysis and goodness of fit
Message-ID: <BLU173-W2607B0293FB11135512550AE290@phx.gbl>

Hello there,

I have registered for both through nabble and R-help-request with this email.

I want to post the following question:

I want to implement a Hosmer Lemeshow Goodness of Fit test to my survival analysis.
In R we can use the hoslem.test() function.
The x values are our observations, and y are our fitted probabilities.

So we can take the following data:

s <- Surv(ovarian$futime, ovarian$fustat)
sWei <- survreg(s ~ age,dist='weibull',data=ovarian)

so here we assume a weibull distribution. I want to do a HL GOF test to see, if this is an invalid assumption.
Now how do we get our predicted probabilities. I assume it is with the predict() function.
I have tried the code, but it is not correct

predict(sWei, newdata=list(ovarian$age), type = 'response')
 		 	   		  
	[[alternative HTML version deleted]]


From rhurlin at gwdg.de  Thu Nov  5 18:25:19 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Thu, 5 Nov 2015 18:25:19 +0100
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux -- solved
In-Reply-To: <563B6B30.1000900@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
	<563B6B30.1000900@gmail.com>
Message-ID: <563B90FF.7050901@gwdg.de>

Am 05.11.2015 um 15:44 schrieb Evan Cooch:
> Well, sort of. I got sufficiently frustrated that I completely
> uninstalled R, jags, and everything related. Did a re-install using only
> versions of R nd JAGS found in the epel repo. No muss, no muss -- all
> works.
> 
> Out of curiosity, uninstalled again, and tried my usual sequence of
> manually compile R from source, same with JAGS. R works, JAGS works, but
> can't get any R package linking the two (say, rjags, R2jags), to
> recognize that JAGS is installed.
> 
> Ah well, at least the 'install from repos' approach works. I'll have to
> make do with that.


Just took another look in my installation call, I made some time ago.
What I did to get it work on FreeBSD was:


R CMD INSTALL rjags_4-4.tar.gz --configure-args='CPPFLAGS="-fPIC"
LDFLAGS="-L/usr/local/lib -ljags"
--with-jags-include=/usr/local/include/JAGS --with-jags-lib=/usr/local/lib'


So I used --configure-args, LDFLAGS, --with-jags-inlcue and
--with-jags-lib in my installation procedure. Perhaps it is worth
another try?


From evan.cooch at gmail.com  Thu Nov  5 18:28:38 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 5 Nov 2015 12:28:38 -0500
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563B6BA0.6090608@gwdg.de>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
	<563B6BA0.6090608@gwdg.de>
Message-ID: <563B91C6.4080303@gmail.com>



On 11/5/2015 9:45 AM, Rainer Hurling wrote:
> Am 04.11.2015 um 21:36 schrieb Evan Cooch:
>>
>>
>> On 11/4/2015 2:08 PM, Evan Cooch wrote:
>>> Greetings --
>>>
>>> This has also been posted on the jags forum, but since I suspect the
>>> problem is more 'R-related' than jags, will aos post here.
>>>
>>> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux
>>> boxes (which run latest RHEL). Here are the basic details:
>>>
>>> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other
>>> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
>>>
>>> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy,
>>> ./configure & make & make install) -- no errors. Runs fine as a
>>> standalone app from CLI.
>>>
>>>
>>> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R --
>>> usual R CMD INSTALL approach). Again, no errors reported.
>>>
>>>
>>> However, when I fire up R, and try something simple like
>>>
>>> library(R2jags)
>>>
>>> I get a whole slew of error messages - following is reproducible on
>>> all my machines:
>>>
>>> Loading required package: rjags
>>> Loading required package: coda
>>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>>> call: dyn.load(file, DLLpath = DLLpath, ...)
>>> error: unable to load shared object
>>> '/usr/lib64/R/library/rjags/libs/rjags.so':
>>> libjags.so.3: cannot open shared object file: No such file or directory
>>> Error: package ?rjags? could not be loaded
>>>
>>>
>>
>> Further puzzlement -- I uninstalled R2jags and rjags, with the idea that
>> re-installing them (ostensibly with the 'latest and greatest') would do
>> the trick. While the process went fine for R2jags, when I tried to
>> re-install rjags, got the following error messages:
>>
>> checking for gcc -m64 -std=gnu99 option to accept ISO C89... none needed
>> checking for jags_version in -ljags... yes
>> checking version of JAGS library... wrong version
>> configure: error: rjags requires JAGS version 4.x.y
>> ERROR: configuration failed for package ?rjags?
>> * removing ?/usr/lib64/R/library/rjags?
>> * restoring previous ?/usr/lib64/R/library/rjags?
>
> Hmm, is it possible, that your JAGS 4.x.y installation is fine, but an 
> old libjags.so library is lying around from a not fully completed 
> deinstallation? Could you have a look for older libjags.so versions, 
> please?
>
> Just a thought.
>


I suppose thats possible -- I'll go through the sequence again at some 
point, and report back.


From lorenzo.isella at gmail.com  Thu Nov  5 18:38:23 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 5 Nov 2015 18:38:23 +0100
Subject: [R] Caret Internal Data Representation
Message-ID: <20151105173823.GC3206@localhost.localdomain>

Dear All,
I have a data set which contains both categorical and numerical
variables which I analyze using Cubist+the caret framework.
Now, from the generated rules, it is clear that cubist does something
to the categorical variables and probably uses some dummy coding for
them.
However, I cannot right now access the data the way it is transformed
by cubist.
If caret (or the package) need to do some dummy coding of the factors,
how can I access the newly encoded data set?
I suppose this applies to plenty of other packages.
Any suggestion is welcome.
Cheers

Lorenzo


From 538280 at gmail.com  Thu Nov  5 19:01:13 2015
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 5 Nov 2015 11:01:13 -0700
Subject: [R] Creating "Envelope" around a plot
In-Reply-To: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
References: <1840867613.6756.1446467628780.JavaMail.open-xchange@oxbe19.tb.ukmail.iss.as9143.net>
Message-ID: <CAFEqCdwQUUzB4m0xLoKdYwxEu_Fuc-SiYGH3KFJzMG8nX7HfqQ@mail.gmail.com>

Look at the polylineoffset function in the polyclip package.  It looks
like it does what you are asking for.

On Mon, Nov 2, 2015 at 5:33 AM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> Hi  I am plotting various strands of information, and I want to create an
> "envelope" around each line, so that the locus of the envelope is the boundary
> points no more than a fixed maximum distance from the plotted line, a bit like
> drawing a larger rectangle with paralle sides and curved compass corners around
> a smaller rectangle.  Obviously I can work out how to do this in code
> (eventually) but I suspect it would take me a while and i was wondering whether
> there was some R function which I don't know about which creates sets of of
> points at a given maximal distance
>
> the lines are simple vectors, ie like this noddy example
>
> veca<-c(4,3,6,5,7,3,2,3,3,6,8,7)
> plot(veca,type="l",lwd=2)
>
> then I want to plot the locus of the boundary of all points no more than (say) 1
> unit from the line  I imagine that one would have to provide a larger set of
> interpolated points between the actual points of veca, but I can do that no
> problem
>
> I'd be grateful if anyone out there in the R-ethervoid has any ideas
>
> Thanks, Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From bgunter.4567 at gmail.com  Thu Nov  5 19:10:57 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 5 Nov 2015 10:10:57 -0800
Subject: [R] Caret Internal Data Representation
In-Reply-To: <20151105173823.GC3206@localhost.localdomain>
References: <20151105173823.GC3206@localhost.localdomain>
Message-ID: <CAGxFJbQBsXbMHgUYDfo9OMOO=v0erg3r-EU96auNu9dSnne0bQ@mail.gmail.com>

I am not familiar with caret/Cubist, but assuming they follow the
usual R procedures that encode categorical factors for conditional
fitting, you need to do some homework on your own by reading up on the
use of contrasts in regression.

See ?factor and ?contrasts (and other linked Help as necessary) to see
what are R's usual procedures, but you will undoubtedly need to
consult outside statistical references -- the help files will point
you to some -- to fully understand what's going on. It is not trivial.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Nov 5, 2015 at 9:38 AM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> Dear All,
> I have a data set which contains both categorical and numerical
> variables which I analyze using Cubist+the caret framework.
> Now, from the generated rules, it is clear that cubist does something
> to the categorical variables and probably uses some dummy coding for
> them.
> However, I cannot right now access the data the way it is transformed
> by cubist.
> If caret (or the package) need to do some dummy coding of the factors,
> how can I access the newly encoded data set?
> I suppose this applies to plenty of other packages.
> Any suggestion is welcome.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Thu Nov  5 20:00:42 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 5 Nov 2015 14:00:42 -0500
Subject: [R] A bunch of packages keeps wanting to get updated
Message-ID: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>

I am using a windows laptop, R 3.2.2

I am using R-gui.

When I go to Packages -> Update packages and then select a Cran mirror
(in the US) - it tells me to update the following packages:

GLMMGibbs
RDCOMClient
Rstem
survnnet
yags

I click OK and then I get successful update messages, like:

trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/survnnet_1.1-3.zip'
Content type 'application/zip' length 235981 bytes (230 KB)
downloaded 230 KB

trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/yags_4.0-2.2.zip'
Content type 'application/zip' length 205372 bytes (200 KB)
downloaded 200 KB

package ?survnnet? successfully unpacked and MD5 sums checked
package ?yags? successfully unpacked and MD5 sums checked

Then I to to Packages -> Update packages, and exactly the same
packages as before appear - as if I didn't just update them.

What could be the reason? I tried to totally delete the folders of
those packages, install them from scratch (successfully), still - they
keep appearing in Update Pacakges widnow.

Any advice?
Thank you!

-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Thu Nov  5 20:31:52 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 5 Nov 2015 14:31:52 -0500
Subject: [R] A bunch of packages keeps wanting to get updated
In-Reply-To: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>
References: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>
Message-ID: <CAN2xGJb7YiZb5+OGTndTZ_qsTjpmgP3ALkV2Lt9QXKh=hLaH4A@mail.gmail.com>

Just in case:

> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.2.2    lavaan_0.5-19  mnormt_1.5-3   pbivnorm_0.6.0 stats4_3.2.2
[6] quadprog_1.5-5

On Thu, Nov 5, 2015 at 2:00 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I am using a windows laptop, R 3.2.2
>
> I am using R-gui.
>
> When I go to Packages -> Update packages and then select a Cran mirror
> (in the US) - it tells me to update the following packages:
>
> GLMMGibbs
> RDCOMClient
> Rstem
> survnnet
> yags
>
> I click OK and then I get successful update messages, like:
>
> trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/survnnet_1.1-3.zip'
> Content type 'application/zip' length 235981 bytes (230 KB)
> downloaded 230 KB
>
> trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/yags_4.0-2.2.zip'
> Content type 'application/zip' length 205372 bytes (200 KB)
> downloaded 200 KB
>
> package ?survnnet? successfully unpacked and MD5 sums checked
> package ?yags? successfully unpacked and MD5 sums checked
>
> Then I to to Packages -> Update packages, and exactly the same
> packages as before appear - as if I didn't just update them.
>
> What could be the reason? I tried to totally delete the folders of
> those packages, install them from scratch (successfully), still - they
> keep appearing in Update Pacakges widnow.
>
> Any advice?
> Thank you!
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From murdoch.duncan at gmail.com  Thu Nov  5 20:40:57 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 5 Nov 2015 13:40:57 -0600
Subject: [R] A bunch of packages keeps wanting to get updated
In-Reply-To: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>
References: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>
Message-ID: <563BB0C9.6020208@gmail.com>

On 05/11/2015 1:00 PM, Dimitri Liakhovitski wrote:
> I am using a windows laptop, R 3.2.2
>
> I am using R-gui.
>
> When I go to Packages -> Update packages and then select a Cran mirror
> (in the US) - it tells me to update the following packages:
>
> GLMMGibbs
> RDCOMClient
> Rstem
> survnnet
> yags
>
> I click OK and then I get successful update messages, like:
>
> trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/survnnet_1.1-3.zip'
> Content type 'application/zip' length 235981 bytes (230 KB)
> downloaded 230 KB
>
> trying URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/yags_4.0-2.2.zip'
> Content type 'application/zip' length 205372 bytes (200 KB)
> downloaded 200 KB
>
> package ?survnnet? successfully unpacked and MD5 sums checked
> package ?yags? successfully unpacked and MD5 sums checked
>
> Then I to to Packages -> Update packages, and exactly the same
> packages as before appear - as if I didn't just update them.
>
> What could be the reason? I tried to totally delete the folders of
> those packages, install them from scratch (successfully), still - they
> keep appearing in Update Pacakges widnow.
>
> Any advice?

It may be installing them to a personal library rather than the system 
one (to which you typically don't have write permission).

You should be getting messages about this, but they might be hidden; if 
you run

update.packages()

it might be easier to see the messages.  You can also try running 
.libPaths() to see what libraries are searched.

Duncan Murdoch


From dimitri.liakhovitski at gmail.com  Thu Nov  5 21:12:37 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 5 Nov 2015 15:12:37 -0500
Subject: [R] A bunch of packages keeps wanting to get updated
In-Reply-To: <563BB0C9.6020208@gmail.com>
References: <CAN2xGJaCV0kUFW35o56DBJ9kLTYm_gx6BwnMpFmt=Gs2EsOoig@mail.gmail.com>
	<563BB0C9.6020208@gmail.com>
Message-ID: <CAN2xGJZw9SJnc0sZfve1M5TW2Y8UN=p8k8e-WDk4D48Fbu8DRg@mail.gmail.com>

Thank you, Duncan.
Indeed those packages were sitting in a temp directory.
I had to install them manually from a 'zip file.

On Thu, Nov 5, 2015 at 2:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 05/11/2015 1:00 PM, Dimitri Liakhovitski wrote:
>>
>> I am using a windows laptop, R 3.2.2
>>
>> I am using R-gui.
>>
>> When I go to Packages -> Update packages and then select a Cran mirror
>> (in the US) - it tells me to update the following packages:
>>
>> GLMMGibbs
>> RDCOMClient
>> Rstem
>> survnnet
>> yags
>>
>> I click OK and then I get successful update messages, like:
>>
>> trying URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/survnnet_1.1-3.zip'
>> Content type 'application/zip' length 235981 bytes (230 KB)
>> downloaded 230 KB
>>
>> trying URL
>> 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.2/yags_4.0-2.2.zip'
>> Content type 'application/zip' length 205372 bytes (200 KB)
>> downloaded 200 KB
>>
>> package ?survnnet? successfully unpacked and MD5 sums checked
>> package ?yags? successfully unpacked and MD5 sums checked
>>
>> Then I to to Packages -> Update packages, and exactly the same
>> packages as before appear - as if I didn't just update them.
>>
>> What could be the reason? I tried to totally delete the folders of
>> those packages, install them from scratch (successfully), still - they
>> keep appearing in Update Pacakges widnow.
>>
>> Any advice?
>
>
> It may be installing them to a personal library rather than the system one
> (to which you typically don't have write permission).
>
> You should be getting messages about this, but they might be hidden; if you
> run
>
> update.packages()
>
> it might be easier to see the messages.  You can also try running
> .libPaths() to see what libraries are searched.
>
> Duncan Murdoch
>



-- 
Dimitri Liakhovitski


From r.turner at auckland.ac.nz  Thu Nov  5 22:29:51 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 6 Nov 2015 10:29:51 +1300
Subject: [R] [FORGED] Re:  merging-binning data
In-Reply-To: <1801810490.132981.1446716995774.JavaMail.yahoo@mail.yahoo.com>
References: <563A8496.1040004@auckland.ac.nz>
	<1801810490.132981.1446716995774.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <563BCA4F.6070104@auckland.ac.nz>

On 05/11/15 22:49, Alaios wrote:
> Thanks.That is what I want. It is more that I do not know how to read
> factors that these two functions return
>
> Browse[1]> y
> $`13.6954016405008`
> [1] (13.2,115]
> Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]
>
> $`88.5092280867206`
> [1] (13.2,115]
> Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]
>
> $`137.931810364616`
> [1] (115,217]
> Levels: (13.2,115] (115,217] (217,318] (318,420] (420,522]
>
>   str(y)
> List of 30
>   $ 13.6954016405008: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 1
>   $ 88.5092280867206: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 1
>   $ 137.931810364616: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 138.559590072838: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 143.085897171535: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 177.678839068735: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 177.819693807561: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 184.752000138622: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 211.255591076421: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 2
>   $ 238.951618624679: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3
>   $ 241.609050762905: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3
>   $ 252.528297510773: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3 3 3
>   $ 254.643586371518: Factor w/ 5 levels "(13.2,115]","(115,217]",..: 3
>
> I need to be able to keep the items within their groups and at the same
> time to keep the label of the group so to be able to use it for plotting
> purposes.
>
> How I can do that?

(1) I am afraid that I have no idea what you're asking.  It seems to me 
that you need to learn how to "do R".

(2) I'm puzzled by your "str(y)" output given above.  If the "y" in 
question is that from the commands that I sent you, then it should be a 
list with *5* entries, not 30!

Note that y is a *list* of 5 vectors, the first of which consists of all 
those entries of your original data vector that lie between 13.2 and 
115, the second of which consists of all those entries of your original 
data vector that lie between 115 and 217, and so on.

It doesn't seem very complicated to me.  What is it that you don't 
understand?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From chris.barker at barkerstats.com  Thu Nov  5 23:30:51 2015
From: chris.barker at barkerstats.com (Chris)
Date: Thu, 5 Nov 2015 22:30:51 +0000 (UTC)
Subject: [R] creating a jpeg from xyplot with openbugs
References: <28553658.423545.1446762651409.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <28553658.423545.1446762651409.JavaMail.yahoo@mail.yahoo.com>

?I'm using xyplot to plot MCMC results generated via R2openbugs and coda and trying to create jpeg outputs. the jpegs are blank
I can plot the MCMC object with xyplot at the command line
however, when I use a function to send the ?plot to a jpeg (or to a bmp, or png or pdf) the file is created and the plot is blank
>>>>>example commands
cond.out10c <- bugs(data.cond, inits, params, model.file,codaPkg=TRUE, n.iter=50000)cond.out.coda10c <- read.bugs(cond.out10c)?
>>>>the following command displays the xyplotxyplot(cond.out.coda10c)
>>>>The following command creates a jpeg inside a function, but the jpeg is blankxysendit <- function(mcmcobj){jpeg(file="C:\\testplot.jpg")xyplot(mcmcobj)dev.off()}xysendit(cond.out.coda10c)

Chris Barker, Ph.D.
Adjunct Associate Professor of Biostatistics - UIC-SPH
415 609 7473 
skype: barkerstats


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Nov  6 00:48:19 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 5 Nov 2015 15:48:19 -0800
Subject: [R] creating a jpeg from xyplot with openbugs
In-Reply-To: <28553658.423545.1446762651409.JavaMail.yahoo@mail.yahoo.com>
References: <28553658.423545.1446762651409.JavaMail.yahoo.ref@mail.yahoo.com>
	<28553658.423545.1446762651409.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTWc_Lr7dOu94eftTjcxtGNp43CZ_L4uPFzZU=mwH0nUg@mail.gmail.com>

Please post i plain text, as request by the posting guide. As you can
see, HTML can come out a mess.

Answer: FAQ 7.22

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Nov 5, 2015 at 2:30 PM, Chris <chris.barker at barkerstats.com> wrote:
>  I'm using xyplot to plot MCMC results generated via R2openbugs and coda and trying to create jpeg outputs. the jpegs are blank
> I can plot the MCMC object with xyplot at the command line
> however, when I use a function to send the  plot to a jpeg (or to a bmp, or png or pdf) the file is created and the plot is blank
>>>>>>example commands
> cond.out10c <- bugs(data.cond, inits, params, model.file,codaPkg=TRUE, n.iter=50000)cond.out.coda10c <- read.bugs(cond.out10c)
>>>>>the following command displays the xyplotxyplot(cond.out.coda10c)
>>>>>The following command creates a jpeg inside a function, but the jpeg is blankxysendit <- function(mcmcobj){jpeg(file="C:\\testplot.jpg")xyplot(mcmcobj)dev.off()}xysendit(cond.out.coda10c)
>
> Chris Barker, Ph.D.
> Adjunct Associate Professor of Biostatistics - UIC-SPH
> 415 609 7473
> skype: barkerstats
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Fri Nov  6 00:59:10 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 5 Nov 2015 18:59:10 -0500
Subject: [R] Help with dplyr
Message-ID: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>

Hello, 
 
Is there a way to avoid the warning below in dplyr. I?m performing an operation within groups, and the warning says that the factors created from each group do not have the same levels, and so it coerces the factor to character. I?m using this inside a package I?m developing. I?d appreciate your recommendation on how to handle this.
 
library(dplyr)
 
set.seed(4)
df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1", "model2")))
 
create_bins <- function (pred, nBins) {
  Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
  bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks, include.lowest = TRUE))
  bin
}
 
res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
Warning message:
  In rbind_all(out[[1]]) : Unequal factor levels: coercing to character
 
Thank you,
Axel.


	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Nov  6 01:44:49 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 6 Nov 2015 01:44:49 +0100
Subject: [R] Help with dplyr
In-Reply-To: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
Message-ID: <C15299AC-189D-4258-91C5-D91110B532C5@gmail.com>


> On 06 Nov 2015, at 00:59 , Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello, 
> 
> Is there a way to avoid the warning below in dplyr. I?m performing an operation within groups, and the warning says that the factors created from each group do not have the same levels, and so it coerces the factor to character. I?m using this inside a package I?m developing. I?d appreciate your recommendation on how to handle this.

Well, what did you intend? If you cut according to quantiles, the levels of the result will reflect the value of the quantiles, as in

> y <- runif(10)
> cut(y, quantile(y,c(0,.25,.5,.75, 1)), include.lowest=T)
 [1] (0.65,0.765]  [0.108,0.281] [0.108,0.281] (0.65,0.765]  (0.281,0.528]
 [6] [0.108,0.281] (0.528,0.65]  (0.281,0.528] (0.65,0.765]  (0.528,0.65] 
Levels: [0.108,0.281] (0.281,0.528] (0.528,0.65] (0.65,0.765]

If you do it in different groups, the quantiles will differ, hence the factor levels too. Concatenating the resulting factors will get you in trouble.

If you don't mind losing the information about that the quantile intervals are, you could consider standardizing the levels with somthing like levels(bin$bin) <- 1:nBins.

-pd

> 
> library(dplyr)
> 
> set.seed(4)
> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1", "model2")))
> 
> create_bins <- function (pred, nBins) {
>  Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>  bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks, include.lowest = TRUE))
>  bin
> }
> 
> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
> Warning message:
>  In rbind_all(out[[1]]) : Unequal factor levels: coercing to character
> 
> Thank you,
> Axel.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Fri Nov  6 01:50:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Nov 2015 16:50:11 -0800
Subject: [R] Help with dplyr
In-Reply-To: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
Message-ID: <4332CDA7-7ECE-4B49-8D33-24524E3E1624@comcast.net>


> On Nov 5, 2015, at 3:59 PM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello, 
> 
> Is there a way to avoid the warning below in dplyr.

There is an option that lets you turn off warnings. There also a wrapper function called, not surprisingly, ? `suppressWarnings`. This is all descibed on:

?warning

? 
David.


> I?m performing an operation within groups, and the warning says that the factors created from each group do not have the same levels, and so it coerces the factor to character. I?m using this inside a package I?m developing. I?d appreciate your recommendation on how to handle this.
> 
> library(dplyr)
> 
> set.seed(4)
> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1", "model2")))
> 
> create_bins <- function (pred, nBins) {
>  Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>  bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks, include.lowest = TRUE))
>  bin
> }
> 
> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
> Warning message:
>  In rbind_all(out[[1]]) : Unequal factor levels: coercing to character
> 
> Thank you,
> Axel.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cynthia.yeung at noaa.gov  Fri Nov  6 00:17:54 2015
From: cynthia.yeung at noaa.gov (Cynthia Yeung - NOAA Federal)
Date: Thu, 5 Nov 2015 15:17:54 -0800
Subject: [R] cannot install RWinEdt
Message-ID: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>

I am an intermediate R user with little understanding of the working of R
packages.
My problem is with the package RWinEdt.

I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7 rather
smoothly.
Then I got a brand new computer,still running windows 7.
I installed R 3.1.3, no new packages except the base packages.
I installed WinEdt 6.
I cannot get RWinEdt to install.
I tried:
RWinEdt_2.0-4.tar.gz
RWinEdt2.0-0.zip
RWinEdt_1.6-2.zip
nothing worked.

Error messages from trying different strategies include:

******* 1 ********
> install.packages("RWinEdt", type="source")
trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
Content type 'application/x-gzip' length 590307 bytes (576 KB)
opened URL
downloaded 576 KB

* installing *source* package 'RWinEdt' ...
** package 'RWinEdt' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f
"C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
"C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'

The downloaded source packages are in
        ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
"C:\Program Files\R\R-3.1.3\library"
C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
had status 1
2: In install.packages("RWinEdt", type = "source") :
  installation of package ?RWinEdt? had non-zero exit status
> library(RWinEdt)
Error in library(RWinEdt) : there is no package called ?RWinEdt?
> utils:::menuInstallPkgs()
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) :
  no packages were specified

******************

******* 2 ********
> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos =
NULL, type="source")
* installing *source* package 'RWinEdt' ...
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f
"C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
"C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
Warning messages:
1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
"C:\Program Files\R\R-3.1.3\library"
"D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
  installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz? had
non-zero exit status
> utils:::menuInstallLocal()
package ?RWinEdt? successfully unpacked and MD5 sums checked
> library(RWinEdt)
Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
> install.packages('RWinEdt')

   package ?RWinEdt? is available as a source package but not as a binary

Warning message:
package ?RWinEdt? is not available (as a binary package for R version
3.1.3)

******************

******* 3 ********
> install.packages('RWinEdt')
Warning: unable to access index for repository
http://www.rforge.net/bin/windows/contrib/3.1

   package ?RWinEdt? is available as a source package but not as a binary

******************

Appreciate any help.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Nov  6 01:58:29 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 5 Nov 2015 16:58:29 -0800
Subject: [R] creating a jpeg from xyplot with openbugs
In-Reply-To: <28553658.423545.1446762651409.JavaMail.yahoo@mail.yahoo.com>
References: <28553658.423545.1446762651409.JavaMail.yahoo.ref@mail.yahoo.com>
	<28553658.423545.1446762651409.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTuD-Yqb7b7vf2Jp=c-gj41beWKwKUbsR0po85D1tQoxA@mail.gmail.com>

Oh, and incidentally, you appear to be mixing base graphics -- the
jpeg() call -- with lattice graphics, xyplot(). See ?trellis.device
for lattice details.

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Nov 5, 2015 at 2:30 PM, Chris <chris.barker at barkerstats.com> wrote:
>  I'm using xyplot to plot MCMC results generated via R2openbugs and coda and trying to create jpeg outputs. the jpegs are blank
> I can plot the MCMC object with xyplot at the command line
> however, when I use a function to send the  plot to a jpeg (or to a bmp, or png or pdf) the file is created and the plot is blank
>>>>>>example commands
> cond.out10c <- bugs(data.cond, inits, params, model.file,codaPkg=TRUE, n.iter=50000)cond.out.coda10c <- read.bugs(cond.out10c)
>>>>>the following command displays the xyplotxyplot(cond.out.coda10c)
>>>>>The following command creates a jpeg inside a function, but the jpeg is blankxysendit <- function(mcmcobj){jpeg(file="C:\\testplot.jpg")xyplot(mcmcobj)dev.off()}xysendit(cond.out.coda10c)
>
> Chris Barker, Ph.D.
> Adjunct Associate Professor of Biostatistics - UIC-SPH
> 415 609 7473
> skype: barkerstats
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Nov  6 01:58:27 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Nov 2015 16:58:27 -0800
Subject: [R] Help with dplyr
In-Reply-To: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
Message-ID: <4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>

Solution is to always use the stringsAsFactors=TRUE option in your data.frame() function calls. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 5, 2015 3:59:10 PM PST, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>Hello, 
> 
>Is there a way to avoid the warning below in dplyr. I?m performing an
>operation within groups, and the warning says that the factors created
>from each group do not have the same levels, and so it coerces the
>factor to character. I?m using this inside a package I?m developing.
>I?d appreciate your recommendation on how to handle this.
> 
>library(dplyr)
> 
>set.seed(4)
>df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>c("model1", "model2")))
> 
>create_bins <- function (pred, nBins) {
>  Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks,
>include.lowest = TRUE))
>  bin
>}
> 
>res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
>Warning message:
>  In rbind_all(out[[1]]) : Unequal factor levels: coercing to character
> 
>Thank you,
>Axel.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Fri Nov  6 02:06:31 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 6 Nov 2015 01:06:31 +0000
Subject: [R] cannot install RWinEdt
In-Reply-To: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
References: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662EDB286A@WAXMXOLYMB025.WAX.wa.lcl>

You might want to upgrade to R-3.2.2 as there appears to be a RWinEdt binary available for it.

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cynthia Yeung - NOAA Federal
Sent: Thursday, November 05, 2015 3:18 PM
To: r-help at r-project.org
Subject: [R] cannot install RWinEdt

I am an intermediate R user with little understanding of the working of R packages.
My problem is with the package RWinEdt.

I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7 rather smoothly.
Then I got a brand new computer,still running windows 7.
I installed R 3.1.3, no new packages except the base packages.
I installed WinEdt 6.
I cannot get RWinEdt to install.
I tried:
RWinEdt_2.0-4.tar.gz
RWinEdt2.0-0.zip
RWinEdt_1.6-2.zip
nothing worked.

Error messages from trying different strategies include:

******* 1 ********
> install.packages("RWinEdt", type="source")
trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
Content type 'application/x-gzip' length 590307 bytes (576 KB) opened URL downloaded 576 KB

* installing *source* package 'RWinEdt' ...
** package 'RWinEdt' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'

The downloaded source packages are in
        ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
had status 1
2: In install.packages("RWinEdt", type = "source") :
  installation of package ?RWinEdt? had non-zero exit status
> library(RWinEdt)
Error in library(RWinEdt) : there is no package called ?RWinEdt?
> utils:::menuInstallPkgs()
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) :
  no packages were specified

******************

******* 2 ********
> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos 
> =
NULL, type="source")
* installing *source* package 'RWinEdt' ...
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
Warning messages:
1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
"D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
  installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz? had non-zero exit status
> utils:::menuInstallLocal()
package ?RWinEdt? successfully unpacked and MD5 sums checked
> library(RWinEdt)
Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
> install.packages('RWinEdt')

   package ?RWinEdt? is available as a source package but not as a binary

Warning message:
package ?RWinEdt? is not available (as a binary package for R version
3.1.3)

******************

******* 3 ********
> install.packages('RWinEdt')
Warning: unable to access index for repository
http://www.rforge.net/bin/windows/contrib/3.1

   package ?RWinEdt? is available as a source package but not as a binary

******************

Appreciate any help.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Fri Nov  6 02:23:38 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Nov 2015 17:23:38 -0800
Subject: [R] Help with dplyr
In-Reply-To: <4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
	<4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>
Message-ID: <8867AA24-8557-4640-BF69-53BB69E1C930@comcast.net>


> On Nov 5, 2015, at 4:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Solution is to always use the stringsAsFactors=TRUE option in your data.frame() function calls. 

Since that is the default, I?m wondering if you meant to say FALSE?

? 
David.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 5, 2015 3:59:10 PM PST, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>> Hello, 
>> 
>> Is there a way to avoid the warning below in dplyr. I?m performing an
>> operation within groups, and the warning says that the factors created
>> from each group do not have the same levels, and so it coerces the
>> factor to character. I?m using this inside a package I?m developing.
>> I?d appreciate your recommendation on how to handle this.
>> 
>> library(dplyr)
>> 
>> set.seed(4)
>> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>> c("model1", "model2")))
>> 
>> create_bins <- function (pred, nBins) {
>> Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>> bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks,
>> include.lowest = TRUE))
>> bin
>> }
>> 
>> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
>> Warning message:
>> In rbind_all(out[[1]]) : Unequal factor levels: coercing to character
>> 
>> Thank you,
>> Axel.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Fri Nov  6 02:25:55 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Nov 2015 17:25:55 -0800
Subject: [R] Attempting to plot two different time series together
In-Reply-To: <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=Qg@mail.gmail.com>
References: <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=Qg@mail.gmail.com>
Message-ID: <C79C97DE-8D48-4E3C-9F24-F72053C8E705@dcn.davis.CA.us>

Seems like you would benefit from reading about long and wide data... perhaps  [1]. 

If I am understanding what you want,  ggplot facetting should be able to do what you want.  You first have to put the data in long form (e.g. variable, timestamp, value) before you give it to ggplot.

If you want more specific help then you should provide a small sample data set as one or more  R dputs as the Posting Guide recommends (see footer, and  [2]).

[1] https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html

[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 5, 2015 7:00:18 AM PST, Ezra Boyd <ezgis76 at gmail.com> wrote:
>Hello,
>
>I am trying to create a plot (I guess two plots) using two different
>time
>series datasets, but I'm not sure of the best approach.  The data is
>from a
>tidal surge due to a hurricane and I would like to show the
>relationship
>between stage and windspeed/direction.
>
>One dataset is the tidal stage and it is sampled in 30 minutes
>intervals.
>The other dataset is windspeed and direction and it is sampled every 6
>minutes.  I would like to display the tidal hydrograph and then also
>show
>windspeed and direction as a banner above it.  They would be two
>separate
>plots, but with identical x-axis (as opposed to one plot that has both
>tide
>& wind.)
>
>Should I combine the two time series into one dataframe (with lots of
>NAs)
>so that I can create the plots together, for example using pairs or
>ggpairs? Or should I keep them separate, make the individual plots, and
>then work on the layout in graphic design software? I would prefer the
>former, but I just can't figure out how to make that work out.
>
>Also, is it possible to depict wind direction (which is given in degree
>clockwise from due north) with an arrow?
>
>Thank you very much,
>
>Ezra


From drjimlemon at gmail.com  Fri Nov  6 02:31:18 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 6 Nov 2015 12:31:18 +1100
Subject: [R] problem in R
In-Reply-To: <CABLo8nG69euPzPe-fn=2-d9cWOT7UP3c6UZpv9xKhD0bbPVW4Q@mail.gmail.com>
References: <CABLo8nG69euPzPe-fn=2-d9cWOT7UP3c6UZpv9xKhD0bbPVW4Q@mail.gmail.com>
Message-ID: <CA+8X3fXRvfcMqMgsRTJjf5Ey8YZ3A6YvJ=g6AOyVKmNrSAao8g@mail.gmail.com>

Hi thanoon,
When I run your code, I get two error messages. Those error messages tell
you all you need to know to solve the first part of your problem (i.e. that
none of the values in W1 and W2 are changed from NA). The second part of
your problem is that even if you attend to those error messages, you will
only change the first values in W1 and W2. The fundamental problem that has
emerged in this discussion is that you seem to be applying the method of
post-modernist deconstruction to programming in R. I see no future in this
enterprise.

Jim


On Fri, Nov 6, 2015 at 1:10 AM, thanoon younis <thanoon.younis80 at gmail.com>
wrote:

> Dear Dr. Lemon
>
> I have a problem in the code below same the previous problem but the data
> now is dichotomous with two categories 0,1. I want to transfer the vector
> BZ with missing data to vector W with dichotomous data but the result is NA
> for W how can i solve this problem please?
>
> Mnay thanks in advance
>
>
>
>
> N1<-200;N2<-200;P<-9
> BZ1=matrix(NA, nrow=N1, ncol=1)
> BZ2=matrix(NA, nrow=N2, ncol=1)
> W1=matrix(NA, nrow=N1, ncol=1)
> W2=matrix(NA, nrow=N2, ncol=1)
>
> BZ1=rbinom(200,1,0.7)
>
>
>     for (j in 1:1) { if (BZ1[i]>=0) W1[i]<-1 else W1[i]<-0 }
>
>  BZ2=rbinom(200,1,0.7)
>
>
>
>  for (j in 1:1) { if (BZ2[i]>=0) W2[i]<-1 else W2[i]<-0 }
>
>
>   #Input data set for OpenBUGS
>   data<-list(N1=200,N2=200,P=9,R=Ro,W1,W2)
>
>
> #end
>
> W1
> W2
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Nov  6 02:45:12 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 05 Nov 2015 17:45:12 -0800
Subject: [R] Help with dplyr
In-Reply-To: <8867AA24-8557-4640-BF69-53BB69E1C930@comcast.net>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
	<4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>
	<8867AA24-8557-4640-BF69-53BB69E1C930@comcast.net>
Message-ID: <4552EB20-1A4E-429C-BFDC-6D22FAF1E8DA@dcn.davis.CA.us>

Yes,  that was my intention, but it appears I may not have read his code carefully enough. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 5, 2015 5:23:38 PM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Nov 5, 2015, at 4:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> Solution is to always use the stringsAsFactors=TRUE option in your
>data.frame() function calls. 
>
>Since that is the default, I?m wondering if you meant to say FALSE?
>
>? 
>David.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> On November 5, 2015 3:59:10 PM PST, Axel Urbiz <axel.urbiz at gmail.com>
>wrote:
>>> Hello, 
>>> 
>>> Is there a way to avoid the warning below in dplyr. I?m performing
>an
>>> operation within groups, and the warning says that the factors
>created
>>> from each group do not have the same levels, and so it coerces the
>>> factor to character. I?m using this inside a package I?m developing.
>>> I?d appreciate your recommendation on how to handle this.
>>> 
>>> library(dplyr)
>>> 
>>> set.seed(4)
>>> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>>> c("model1", "model2")))
>>> 
>>> create_bins <- function (pred, nBins) {
>>> Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>>> bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks,
>>> include.lowest = TRUE))
>>> bin
>>> }
>>> 
>>> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
>>> Warning message:
>>> In rbind_all(out[[1]]) : Unequal factor levels: coercing to
>character
>>> 
>>> Thank you,
>>> Axel.
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA


From wdunlap at tibco.com  Fri Nov  6 03:07:40 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 5 Nov 2015 18:07:40 -0800
Subject: [R] Help with dplyr
In-Reply-To: <4552EB20-1A4E-429C-BFDC-6D22FAF1E8DA@dcn.davis.CA.us>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
	<4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>
	<8867AA24-8557-4640-BF69-53BB69E1C930@comcast.net>
	<4552EB20-1A4E-429C-BFDC-6D22FAF1E8DA@dcn.davis.CA.us>
Message-ID: <CAF8bMcb+TaBkt8nrP+AwOCW8pVeemjXs1jwohKvUxSsO5WdA-A@mail.gmail.com>

Did you mean to add stringsAsFactors=FALSE to the following call to
data.frame?
   bin <- data.frame(
      pred = pred,
      bin = cut(pred, breaks = Breaks, include.lowest = TRUE))
Since cut() produces a factor you would also have to convert it to character
to make stringAsFactors=FALSE to have an effect.
   bin <- data.frame(stringsAsFactors=FALSE,
      pred = pred,
      bin = as.character(cut(pred, breaks = Breaks, include.lowest = TRUE)))

However, I suspect that things would work out better if all the calls to
cut used the same breaks and then leaving it as a factor would be fine.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Nov 5, 2015 at 5:45 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Yes,  that was my intention, but it appears I may not have read his code
> carefully enough.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 5, 2015 5:23:38 PM PST, David Winsemius <
> dwinsemius at comcast.net> wrote:
> >
> >> On Nov 5, 2015, at 4:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> >wrote:
> >>
> >> Solution is to always use the stringsAsFactors=TRUE option in your
> >data.frame() function calls.
> >
> >Since that is the default, I?m wondering if you meant to say FALSE?
> >
> >?
> >David.
> >>
>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                      Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
>
> >---------------------------------------------------------------------------
> >
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On November 5, 2015 3:59:10 PM PST, Axel Urbiz <axel.urbiz at gmail.com>
> >wrote:
> >>> Hello,
> >>>
> >>> Is there a way to avoid the warning below in dplyr. I?m performing
> >an
> >>> operation within groups, and the warning says that the factors
> >created
> >>> from each group do not have the same levels, and so it coerces the
> >>> factor to character. I?m using this inside a package I?m developing.
> >>> I?d appreciate your recommendation on how to handle this.
> >>>
> >>> library(dplyr)
> >>>
> >>> set.seed(4)
> >>> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
> >>> c("model1", "model2")))
> >>>
> >>> create_bins <- function (pred, nBins) {
> >>> Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
> >>> bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks,
> >>> include.lowest = TRUE))
> >>> bin
> >>> }
> >>>
> >>> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
> >>> Warning message:
> >>> In rbind_all(out[[1]]) : Unequal factor levels: coercing to
> >character
> >>>
> >>> Thank you,
> >>> Axel.
> >>>
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >David Winsemius
> >Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Fri Nov  6 03:26:03 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 5 Nov 2015 21:26:03 -0500
Subject: [R] Help with dplyr
In-Reply-To: <CAF8bMcb+TaBkt8nrP+AwOCW8pVeemjXs1jwohKvUxSsO5WdA-A@mail.gmail.com>
References: <FE735731-9BEB-4467-A6D0-97115809D0F1@gmail.com>
	<4FC53BE6-E4B7-4F3E-93F4-80E2EF47516E@dcn.davis.CA.us>
	<8867AA24-8557-4640-BF69-53BB69E1C930@comcast.net>
	<4552EB20-1A4E-429C-BFDC-6D22FAF1E8DA@dcn.davis.CA.us>
	<CAF8bMcb+TaBkt8nrP+AwOCW8pVeemjXs1jwohKvUxSsO5WdA-A@mail.gmail.com>
Message-ID: <F5908729-15F6-4207-B96E-E74CD4EE10DE@gmail.com>

Thank you all!


> On Nov 5, 2015, at 9:07 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Did you mean to add stringsAsFactors=FALSE to the following call to
> data.frame?
>   bin <- data.frame(
>      pred = pred,
>      bin = cut(pred, breaks = Breaks, include.lowest = TRUE))
> Since cut() produces a factor you would also have to convert it to character
> to make stringAsFactors=FALSE to have an effect.
>   bin <- data.frame(stringsAsFactors=FALSE,
>      pred = pred,
>      bin = as.character(cut(pred, breaks = Breaks, include.lowest = TRUE)))
> 
> However, I suspect that things would work out better if all the calls to
> cut used the same breaks and then leaving it as a factor would be fine.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Nov 5, 2015 at 5:45 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
>> Yes,  that was my intention, but it appears I may not have read his code
>> carefully enough.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On November 5, 2015 5:23:38 PM PST, David Winsemius <
>> dwinsemius at comcast.net> wrote:
>>> 
>>>> On Nov 5, 2015, at 4:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>> 
>>>> Solution is to always use the stringsAsFactors=TRUE option in your
>>> data.frame() function calls.
>>> 
>>> Since that is the default, I?m wondering if you meant to say FALSE?
>>> 
>>> ?
>>> David.
>>>> 
>> 
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>>                                     Live:   OO#.. Dead: OO#..
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>> 
>> 
>>> ---------------------------------------------------------------------------
>>> 
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On November 5, 2015 3:59:10 PM PST, Axel Urbiz <axel.urbiz at gmail.com>
>>> wrote:
>>>>> Hello,
>>>>> 
>>>>> Is there a way to avoid the warning below in dplyr. I?m performing
>>> an
>>>>> operation within groups, and the warning says that the factors
>>> created
>>>>> from each group do not have the same levels, and so it coerces the
>>>>> factor to character. I?m using this inside a package I?m developing.
>>>>> I?d appreciate your recommendation on how to handle this.
>>>>> 
>>>>> library(dplyr)
>>>>> 
>>>>> set.seed(4)
>>>>> df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>>>>> c("model1", "model2")))
>>>>> 
>>>>> create_bins <- function (pred, nBins) {
>>>>> Breaks <- unique(quantile(pred, probs = seq(0, 1, 1/nBins)))
>>>>> bin <- data.frame(pred = pred, bin = cut(pred, breaks = Breaks,
>>>>> include.lowest = TRUE))
>>>>> bin
>>>>> }
>>>>> 
>>>>> res_dplyr <- df %>% group_by(models) %>% do(create_bins(.$pred, 10))
>>>>> Warning message:
>>>>> In rbind_all(out[[1]]) : Unequal factor levels: coercing to
>>> character
>>>>> 
>>>>> Thank you,
>>>>> Axel.
>>>>> 
>>>>> 
>>>>>    [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Fri Nov  6 03:34:06 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 6 Nov 2015 15:34:06 +1300
Subject: [R] problem in R
In-Reply-To: <CA+8X3fXRvfcMqMgsRTJjf5Ey8YZ3A6YvJ=g6AOyVKmNrSAao8g@mail.gmail.com>
References: <CABLo8nG69euPzPe-fn=2-d9cWOT7UP3c6UZpv9xKhD0bbPVW4Q@mail.gmail.com>
	<CA+8X3fXRvfcMqMgsRTJjf5Ey8YZ3A6YvJ=g6AOyVKmNrSAao8g@mail.gmail.com>
Message-ID: <563C119E.4070109@auckland.ac.nz>


On 06/11/15 14:31, Jim Lemon wrote:

<SNIP>

> The fundamental problem that has emerged in this discussion is that
> you seem to be applying the method of post-modernist deconstruction
> to programming in R. I see no future in this enterprise.

<SNIP>

*Gotta* be a fortune!!!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Fri Nov  6 06:16:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 5 Nov 2015 21:16:33 -0800
Subject: [R] post a message - R help. Surivival analysis and goodness of
	fit
In-Reply-To: <BLU173-W2607B0293FB11135512550AE290@phx.gbl>
References: <BLU173-W2607B0293FB11135512550AE290@phx.gbl>
Message-ID: <C27E955A-5F1C-4841-BB7F-FC509D415BF1@comcast.net>


> On Nov 5, 2015, at 6:34 AM, Luke Gaylor <luke.gaylor at live.com.au> wrote:
> 
> Hello there,
> 
> I have registered for both through nabble and R-help-request with this email.
> 
> I want to post the following question:
> 
> I want to implement a Hosmer Lemeshow Goodness of Fit test to my survival analysis.
> In R we can use the hoslem.test() function.
> The x values are our observations, and y are our fitted probabilities.
> 
> So we can take the following data:
> 
> s <- Surv(ovarian$futime, ovarian$fustat)
> sWei <- survreg(s ~ age,dist='weibull',data=ovarian)
> 
> so here we assume a weibull distribution. I want to do a HL GOF test to see, if this is an invalid assumption.
> Now how do we get our predicted probabilities. I assume it is with the predict() function.
> I have tried the code, but it is not correct

(It would be better to post the reason for your conclusion of ?incorrectitude?. Error? Unexpected result? )


> predict(sWei, newdata=list(ovarian$age), type = 'response?)

This code had an unmatched single quote because the flanking character was a?smart-quote. I?m side-stepping the wisdom of using an HL GOF test of a distrubutional assumption. I suspect that the argument to newdata will not have a name. Try:

 predict(sWei, newdata=list(age = ovarian$age), type = ?response')

Or, since you jsut want the original data to be the basis:

 predict(sWei,  type = ?response')

? 
David.

> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ligges at statistik.tu-dortmund.de  Fri Nov  6 07:19:52 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 6 Nov 2015 07:19:52 +0100
Subject: [R] cannot install RWinEdt
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27662EDB286A@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA27662EDB286A@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <563C4688.8000502@statistik.tu-dortmund.de>



On 06.11.2015 02:06, Nordlund, Dan (DSHS/RDA) wrote:
> You might want to upgrade to R-3.2.2 as there appears to be a RWinEdt binary available for it.

There is also a binary for the R-3.1.x series, hence 
install.packages("RWinEdt") should do the trick.


Anyway, if you want to install from sources, please instal the Rtools 
and also install with the --no-test-load flag (RWinEdt complains if 
called non-interactively).

Best,
Uwe Ligges




> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cynthia Yeung - NOAA Federal
> Sent: Thursday, November 05, 2015 3:18 PM
> To: r-help at r-project.org
> Subject: [R] cannot install RWinEdt
>
> I am an intermediate R user with little understanding of the working of R packages.
> My problem is with the package RWinEdt.
>
> I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7 rather smoothly.
> Then I got a brand new computer,still running windows 7.
> I installed R 3.1.3, no new packages except the base packages.
> I installed WinEdt 6.
> I cannot get RWinEdt to install.
> I tried:
> RWinEdt_2.0-4.tar.gz
> RWinEdt2.0-0.zip
> RWinEdt_1.6-2.zip
> nothing worked.
>
> Error messages from trying different strategies include:
>
> ******* 1 ********
>> install.packages("RWinEdt", type="source")
> trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
> Content type 'application/x-gzip' length 590307 bytes (576 KB) opened URL downloaded 576 KB
>
> * installing *source* package 'RWinEdt' ...
> ** package 'RWinEdt' successfully unpacked and MD5 sums checked
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
>
> The downloaded source packages are in
>          ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
> C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
> had status 1
> 2: In install.packages("RWinEdt", type = "source") :
>    installation of package ?RWinEdt? had non-zero exit status
>> library(RWinEdt)
> Error in library(RWinEdt) : there is no package called ?RWinEdt?
>> utils:::menuInstallPkgs()
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>    no packages were specified
>
> ******************
>
> ******* 2 ********
>> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos
>> =
> NULL, type="source")
> * installing *source* package 'RWinEdt' ...
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
> "D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
> 2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
>    installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz? had non-zero exit status
>> utils:::menuInstallLocal()
> package ?RWinEdt? successfully unpacked and MD5 sums checked
>> library(RWinEdt)
> Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
>> install.packages('RWinEdt')
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> Warning message:
> package ?RWinEdt? is not available (as a binary package for R version
> 3.1.3)
>
> ******************
>
> ******* 3 ********
>> install.packages('RWinEdt')
> Warning: unable to access index for repository
> http://www.rforge.net/bin/windows/contrib/3.1
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> ******************
>
> Appreciate any help.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Fri Nov  6 07:20:21 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 6 Nov 2015 07:20:21 +0100
Subject: [R] cannot install RWinEdt
In-Reply-To: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
References: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
Message-ID: <563C46A5.3070405@statistik.tu-dortmund.de>

There is also a binary for the R-3.1.x series, hence 
install.packages("RWinEdt") should do the trick.


Anyway, if you want to install from sources, please instal the Rtools 
and also install with the --no-test-load flag (RWinEdt complains if 
called non-interactively).

Best,
Uwe Ligges




On 06.11.2015 00:17, Cynthia Yeung - NOAA Federal wrote:
> I am an intermediate R user with little understanding of the working of R
> packages.
> My problem is with the package RWinEdt.
>
> I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7 rather
> smoothly.
> Then I got a brand new computer,still running windows 7.
> I installed R 3.1.3, no new packages except the base packages.
> I installed WinEdt 6.
> I cannot get RWinEdt to install.
> I tried:
> RWinEdt_2.0-4.tar.gz
> RWinEdt2.0-0.zip
> RWinEdt_1.6-2.zip
> nothing worked.
>
> Error messages from trying different strategies include:
>
> ******* 1 ********
>> install.packages("RWinEdt", type="source")
> trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
> Content type 'application/x-gzip' length 590307 bytes (576 KB)
> opened URL
> downloaded 576 KB
>
> * installing *source* package 'RWinEdt' ...
> ** package 'RWinEdt' successfully unpacked and MD5 sums checked
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f
> "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
> "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
>
> The downloaded source packages are in
>          ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.1.3\library"
> C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
> had status 1
> 2: In install.packages("RWinEdt", type = "source") :
>    installation of package ?RWinEdt? had non-zero exit status
>> library(RWinEdt)
> Error in library(RWinEdt) : there is no package called ?RWinEdt?
>> utils:::menuInstallPkgs()
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>    no packages were specified
>
> ******************
>
> ******* 2 ********
>> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos =
> NULL, type="source")
> * installing *source* package 'RWinEdt' ...
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f
> "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
> "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.1.3\library"
> "D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
> 2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
>    installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz? had
> non-zero exit status
>> utils:::menuInstallLocal()
> package ?RWinEdt? successfully unpacked and MD5 sums checked
>> library(RWinEdt)
> Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
>> install.packages('RWinEdt')
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> Warning message:
> package ?RWinEdt? is not available (as a binary package for R version
> 3.1.3)
>
> ******************
>
> ******* 3 ********
>> install.packages('RWinEdt')
> Warning: unable to access index for repository
> http://www.rforge.net/bin/windows/contrib/3.1
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> ******************
>
> Appreciate any help.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ajdamico at gmail.com  Fri Nov  6 09:39:33 2015
From: ajdamico at gmail.com (Anthony Damico)
Date: Fri, 6 Nov 2015 03:39:33 -0500
Subject: [R] 32 bit windows version of r 3.2.2 crashes a lot at first
 internet connection attempts
Message-ID: <CAOwvMDwr1QAZWF=jz1+buQRXP9ZfqktDW2=UFJUDp6cQYrppow@mail.gmail.com>

hi, just throwing this out there.  it's not clear to me how to reproduce
the crashes, because they are sporadic (but common)

guessing it's related to the switched default of setInternet2(TRUE) but not
sure

here's a semi-absurd screenshot

http://s17.postimg.org/70omgtmi7/early_crashes.png


i had already submitted one (reproducible) bug on the topic, but not sure
of the best ways to find others lurking

https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16513

thanks

	[[alternative HTML version deleted]]


From frymor at gmail.com  Fri Nov  6 11:40:26 2015
From: frymor at gmail.com (Assa Yeroslaviz)
Date: Fri, 6 Nov 2015 11:40:26 +0100
Subject: [R] subsetting a data.frame based on a specific group of columns
Message-ID: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>

Hi,

I have a data frame with multiple columns, which are belong to several
groups
like that:
X1    X2    X3    Y1    Y2    Y3
1232    357    23    0    9871    72
0    71    9    811    795    743
43    919    1111    0    76    14

I would like to filter such rows out, where the sums in one group is lower
than a specifc value. For example, I would like to set all the values in a
group of cloums to zero, if the sum in one group is less than 100
In my example table I would like to set the values in the second row for
the three X-columns to 0, so that the table looks like that:

X1    X2    X3    Y1    Y2    Y3
1232    357    23    0    9871    72
0    0    0    811    795    743
43    919    1111    0    0    0

the same apply also for the Y-values in the last column.
Is there a more efficient way of doing it than going row by row and use the
apply function on each of the subgroups I have in the columns?

thanks
Assa

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Nov  6 14:29:32 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 6 Nov 2015 08:29:32 -0500
Subject: [R] subsetting a data.frame based on a specific group of columns
In-Reply-To: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>
References: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>
Message-ID: <CAAxdm-6kOQHt9p-LWA9ZxBWrNpjhLr-Rv5Ptw8hw-bWrRPvx4g@mail.gmail.com>

Is this what you want:

> x <- read.table(text = "X1    X2    X3    Y1    Y2    Y3
+ 1232    357    23    0    9871    72
+ 0    71    9    811    795    743
+ 43    919    1111    0    76    14", header = TRUE)
> x
    X1  X2   X3  Y1   Y2  Y3
1 1232 357   23   0 9871  72
2    0  71    9 811  795 743
3   43 919 1111   0   76  14
>
> # create indices of columns that start with the same character
> indx <- split(seq(ncol(x)), substring(colnames(x), 1, 1))
> names(indx) <- NULL  # remove names so output not messed up
>
> result <- lapply(indx, function(a){
+     row_sum <- rowSums(x[, a])
+     x[row_sum < 100, a] <- 0
+     x[, a]
+ })
> # combine back together
> do.call(cbind, result)
    X1  X2   X3  Y1   Y2  Y3
1 1232 357   23   0 9871  72
2    0   0    0 811  795 743
3   43 919 1111   0    0   0


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Nov 6, 2015 at 5:40 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:

> Hi,
>
> I have a data frame with multiple columns, which are belong to several
> groups
> like that:
> X1    X2    X3    Y1    Y2    Y3
> 1232    357    23    0    9871    72
> 0    71    9    811    795    743
> 43    919    1111    0    76    14
>
> I would like to filter such rows out, where the sums in one group is lower
> than a specifc value. For example, I would like to set all the values in a
> group of cloums to zero, if the sum in one group is less than 100
> In my example table I would like to set the values in the second row for
> the three X-columns to 0, so that the table looks like that:
>
> X1    X2    X3    Y1    Y2    Y3
> 1232    357    23    0    9871    72
> 0    0    0    811    795    743
> 43    919    1111    0    0    0
>
> the same apply also for the Y-values in the last column.
> Is there a more efficient way of doing it than going row by row and use the
> apply function on each of the subgroups I have in the columns?
>
> thanks
> Assa
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From frymor at gmail.com  Fri Nov  6 14:53:27 2015
From: frymor at gmail.com (Assa Yeroslaviz)
Date: Fri, 6 Nov 2015 14:53:27 +0100
Subject: [R] subsetting a data.frame based on a specific group of columns
In-Reply-To: <CAAxdm-6kOQHt9p-LWA9ZxBWrNpjhLr-Rv5Ptw8hw-bWrRPvx4g@mail.gmail.com>
References: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>
	<CAAxdm-6kOQHt9p-LWA9ZxBWrNpjhLr-Rv5Ptw8hw-bWrRPvx4g@mail.gmail.com>
Message-ID: <CA+8Xemz+THWLHHPn=MzzdaFo_npqJctiE2TGphMDL2uQTwtsTg@mail.gmail.com>

sorry, for the misunderstanding. here is a more elaborate description of
what i would like to achieve.

I have a data set of counts from a RNA-Seq experiment and would like to
filter reads with low counts. I don't want to set everything to 0
automatically.

I would like to set each categorical group (e.g. condition) to 0, if and
only if all replica in the group together have less than 100 reads.
in my examples I used X and Y to represents the categories. Ususally they
have a more distinct names like "control", "knockout1", "dKo" etc.

So what I really like to do is to check if the sum of all the "control"
samples is lower than 100. If so, set all control sample to 0. This I would
like to check *for each category* of every row of the data set.

I hope it is more clear now

thanks
Assa


On Fri, Nov 6, 2015 at 2:29 PM, jim holtman <jholtman at gmail.com> wrote:

> Is this what you want:
>
> > x <- read.table(text = "X1    X2    X3    Y1    Y2    Y3
> + 1232    357    23    0    9871    72
> + 0    71    9    811    795    743
> + 43    919    1111    0    76    14", header = TRUE)
> > x
>     X1  X2   X3  Y1   Y2  Y3
> 1 1232 357   23   0 9871  72
> 2    0  71    9 811  795 743
> 3   43 919 1111   0   76  14
> >
> > # create indices of columns that start with the same character
> > indx <- split(seq(ncol(x)), substring(colnames(x), 1, 1))
> > names(indx) <- NULL  # remove names so output not messed up
> >
> > result <- lapply(indx, function(a){
> +     row_sum <- rowSums(x[, a])
> +     x[row_sum < 100, a] <- 0
> +     x[, a]
> + })
> > # combine back together
> > do.call(cbind, result)
>     X1  X2   X3  Y1   Y2  Y3
> 1 1232 357   23   0 9871  72
> 2    0   0    0 811  795 743
> 3   43 919 1111   0    0   0
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Fri, Nov 6, 2015 at 5:40 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:
>
>> Hi,
>>
>> I have a data frame with multiple columns, which are belong to several
>> groups
>> like that:
>> X1    X2    X3    Y1    Y2    Y3
>> 1232    357    23    0    9871    72
>> 0    71    9    811    795    743
>> 43    919    1111    0    76    14
>>
>> I would like to filter such rows out, where the sums in one group is lower
>> than a specifc value. For example, I would like to set all the values in a
>> group of cloums to zero, if the sum in one group is less than 100
>> In my example table I would like to set the values in the second row for
>> the three X-columns to 0, so that the table looks like that:
>>
>> X1    X2    X3    Y1    Y2    Y3
>> 1232    357    23    0    9871    72
>> 0    0    0    811    795    743
>> 43    919    1111    0    0    0
>>
>> the same apply also for the Y-values in the last column.
>> Is there a more efficient way of doing it than going row by row and use
>> the
>> apply function on each of the subgroups I have in the columns?
>>
>> thanks
>> Assa
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Nov  6 15:54:04 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 6 Nov 2015 09:54:04 -0500
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
Message-ID: <CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>

If you have code that is running for a long time, then take a small case
that only runs for 5-10 minutes and turn on the RProfiler so that you can
see where you are spending your time.  In most cases, it is probably not
the 'for' loops that are causing the problem, but some function/calculation
you are doing within the loop that is consuming the time, and until you
determine what section of code that is, is it hard to tell exactly what the
problem is, much less the solution.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com>
wrote:

> Hi Jim,
>
> Thanks a lot for replying.
>
> In fact I'm trying to run a simulation study that enables me to calculate
> the Bayes risk of a sampling plan selected from progressively type-II
> censored Weibull model. One of the steps involves evaluating the expected
> test time, which is a rather complicated formula that involves nested
> multiple summations where the counters of the summation signs are
> dependent, that's why I thought of I should create the incomb() function
> inside the loop, or may be I didn't figure out how to relate its arguments
> to the ones inside the loop had I created it outside it.  I'm trying to
> create a matrix of all the possible combinations involved in the summations
> and then use the apply() function on each row of that matrix. The problem
> is that the code I wrote works perfectly well for rather small values of
> the sample size,n, and the censoring number, m (for example, n=8,m=4),but
> when n and m are increased (say, n=25,m=15) the code keeps on running for
> days with no output. That's why I thought I should try to avoid explicit
> loops as much as possible, so I did my best in this regard but still the
> code takes too long to execute,(more than three days), thus, i believe
> there must be something wrong.
>
> Here's the full code:
>
> library(pbapply)
> f1 <- function(n, m) {
>    stopifnot(n > m)
>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> len=n-m+1), m-2))
>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
> }
> simpfun<- function (x,n,m,p,alpha,beta)
>   {
>   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>   b <-  ((m-1):1)
>   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
> d <- n - cumsum(x) - (1:(m-1))
>   e<- n*(prod(d))*c
> LD<-list()
>    for (i in 1:(m-1))  {
>    LD[[i]]<-seq(0,x[i],1)
>    }
>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>    LED<-expand.grid (LD)
>    LED<-as.matrix(LED)
>    store1<-numeric(nrow(LED))
> for (j in 1:length(store1) )
>          {
>             incomb<-function(x,alpha,beta) {
>
>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>                     h <- choose(x, LED[j,-m])
>                    ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>                 lm<-cumsum(LED[j,-m]) + (1:(m-1))
>                 plm<-prod(lm)
>                gil<-g*ik/(plm)
>              hlm<-numeric(sum(LED[j,])+(m-1))
>              dsa<-length(hlm)
>               for (i in 1:dsa)
>                 {
>                  ppp<- sum(LED[j,])+(m-1)
>                   hlm[i]<-
>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>                  }
>           shl<-gil*(sum(hlm)+1)
>           return (shl)
>           }
>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>       }
> val1<- sum(store1)*e
> return(val1)
> }
>
> va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
> EXP<-sum(va)
>
>
>
> Any help would be greatly appreciated.
> Thanks a lot  for your time.
>
> Best Regards,
> Maram Salem
>
>
> On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
>
>> Why are you recreating the incomb function within the loop instead of
>> defining it outside the loop?  Also you are referencing several variables
>> that are global (e.g., m & j); you should be passing these in as parameters
>> to the function.
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
>> wrote:
>>
>>> Hi All,
>>>
>>> I'm writing a long code that takes long time to execute. So I used the
>>> Rprof() function and found out that the function that takes about 80% of
>>> the time is the incomb () fucntion (below), and this is most probably
>>> because of the many explicit for() loops I'm using.
>>>
>>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>>> x=c(3,0,0)
>>> LD<-list()
>>>    for (i in 1:(m-1))  {
>>>    LD[[i]]<-seq(0,x[i],1)
>>>    }
>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>    LED<-expand.grid (LD)
>>>    LED<-as.matrix(LED)
>>>    store1<-numeric(nrow(LED))
>>>     h<- numeric(m-1)
>>>     lm<- numeric(m-1)
>>>      for (j in 1:length(store1) )
>>>          {
>>>             incomb<-function(x,alpha,beta) {
>>>
>>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>                   for (i in 1:(m-1))  {
>>>                        h[i]<- choose(x[i],LED[j,i])
>>>                        }
>>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>                 for (i in 1:(m-1)) {
>>>                        lm[i]<-(sum(LED[j,1:i])) + i
>>>                      }
>>>                 plm<-prod(lm)
>>>                gil<-g*ik/(plm)
>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>              dsa<-length(hlm)
>>>               for (i in 1:dsa)
>>>                 {
>>>                  ppp<- sum(LED[j,])+(m-1)
>>>                   hlm[i]<-
>>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>                  }
>>>           shl<-gil*(sum(hlm)+1)
>>>           return (shl)
>>>           }
>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>       }
>>>
>>>
>>> I'm trying to use alternatives (for ex. to vectorize things) to the
>>> explicit for() loops, but things don't work out.
>>>
>>> Any suggestions that can help me to speed up the execution of the
>>> incomb()
>>> function are much appreciated.
>>>
>>> Thanks a lot in advance.
>>>
>>> Maram Salem
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From ssefick at gmail.com  Fri Nov  6 16:45:05 2015
From: ssefick at gmail.com (stephen sefick)
Date: Fri, 6 Nov 2015 09:45:05 -0600
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
	<CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
Message-ID: <CADKEMqjTYt7O0JDSVRqvD5vi7mH4Da2DS-NFpQxuDA_PDv9mOA@mail.gmail.com>

If you have multiple cores, you could try the foreach package. Jim's advice
still holds, but you would be farming the work out.
FWIW,

Stephen

On Fri, Nov 6, 2015 at 8:54 AM, jim holtman <jholtman at gmail.com> wrote:

> If you have code that is running for a long time, then take a small case
> that only runs for 5-10 minutes and turn on the RProfiler so that you can
> see where you are spending your time.  In most cases, it is probably not
> the 'for' loops that are causing the problem, but some function/calculation
> you are doing within the loop that is consuming the time, and until you
> determine what section of code that is, is it hard to tell exactly what the
> problem is, much less the solution.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
> > Hi Jim,
> >
> > Thanks a lot for replying.
> >
> > In fact I'm trying to run a simulation study that enables me to calculate
> > the Bayes risk of a sampling plan selected from progressively type-II
> > censored Weibull model. One of the steps involves evaluating the expected
> > test time, which is a rather complicated formula that involves nested
> > multiple summations where the counters of the summation signs are
> > dependent, that's why I thought of I should create the incomb() function
> > inside the loop, or may be I didn't figure out how to relate its
> arguments
> > to the ones inside the loop had I created it outside it.  I'm trying to
> > create a matrix of all the possible combinations involved in the
> summations
> > and then use the apply() function on each row of that matrix. The problem
> > is that the code I wrote works perfectly well for rather small values of
> > the sample size,n, and the censoring number, m (for example, n=8,m=4),but
> > when n and m are increased (say, n=25,m=15) the code keeps on running for
> > days with no output. That's why I thought I should try to avoid explicit
> > loops as much as possible, so I did my best in this regard but still the
> > code takes too long to execute,(more than three days), thus, i believe
> > there must be something wrong.
> >
> > Here's the full code:
> >
> > library(pbapply)
> > f1 <- function(n, m) {
> >    stopifnot(n > m)
> >    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> >    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > len=n-m+1), m-2))
> >    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
> > }
> > simpfun<- function (x,n,m,p,alpha,beta)
> >   {
> >   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
> >   b <-  ((m-1):1)
> >   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
> > d <- n - cumsum(x) - (1:(m-1))
> >   e<- n*(prod(d))*c
> > LD<-list()
> >    for (i in 1:(m-1))  {
> >    LD[[i]]<-seq(0,x[i],1)
> >    }
> >    LD[[m]]<-seq(0,(n-m-sum(x)),1)
> >    LED<-expand.grid (LD)
> >    LED<-as.matrix(LED)
> >    store1<-numeric(nrow(LED))
> > for (j in 1:length(store1) )
> >          {
> >             incomb<-function(x,alpha,beta) {
> >
> >  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
> >                     h <- choose(x, LED[j,-m])
> >                    ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
> >                 lm<-cumsum(LED[j,-m]) + (1:(m-1))
> >                 plm<-prod(lm)
> >                gil<-g*ik/(plm)
> >              hlm<-numeric(sum(LED[j,])+(m-1))
> >              dsa<-length(hlm)
> >               for (i in 1:dsa)
> >                 {
> >                  ppp<- sum(LED[j,])+(m-1)
> >                   hlm[i]<-
> >  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
> >                  }
> >           shl<-gil*(sum(hlm)+1)
> >           return (shl)
> >           }
> >        store1[j]<-incomb(x,alpha=0.2,beta=2)
> >       }
> > val1<- sum(store1)*e
> > return(val1)
> > }
> >
> > va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
> > EXP<-sum(va)
> >
> >
> >
> > Any help would be greatly appreciated.
> > Thanks a lot  for your time.
> >
> > Best Regards,
> > Maram Salem
> >
> >
> > On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
> >
> >> Why are you recreating the incomb function within the loop instead of
> >> defining it outside the loop?  Also you are referencing several
> variables
> >> that are global (e.g., m & j); you should be passing these in as
> parameters
> >> to the function.
> >>
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
> >> wrote:
> >>
> >>> Hi All,
> >>>
> >>> I'm writing a long code that takes long time to execute. So I used the
> >>> Rprof() function and found out that the function that takes about 80%
> of
> >>> the time is the incomb () fucntion (below), and this is most probably
> >>> because of the many explicit for() loops I'm using.
> >>>
> >>> n=18;m=4;p=0.3;alpha=0.2;beta=2
> >>> x=c(3,0,0)
> >>> LD<-list()
> >>>    for (i in 1:(m-1))  {
> >>>    LD[[i]]<-seq(0,x[i],1)
> >>>    }
> >>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
> >>>    LED<-expand.grid (LD)
> >>>    LED<-as.matrix(LED)
> >>>    store1<-numeric(nrow(LED))
> >>>     h<- numeric(m-1)
> >>>     lm<- numeric(m-1)
> >>>      for (j in 1:length(store1) )
> >>>          {
> >>>             incomb<-function(x,alpha,beta) {
> >>>
> >>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
> >>>                   for (i in 1:(m-1))  {
> >>>                        h[i]<- choose(x[i],LED[j,i])
> >>>                        }
> >>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
> >>>                 for (i in 1:(m-1)) {
> >>>                        lm[i]<-(sum(LED[j,1:i])) + i
> >>>                      }
> >>>                 plm<-prod(lm)
> >>>                gil<-g*ik/(plm)
> >>>              hlm<-numeric(sum(LED[j,])+(m-1))
> >>>              dsa<-length(hlm)
> >>>               for (i in 1:dsa)
> >>>                 {
> >>>                  ppp<- sum(LED[j,])+(m-1)
> >>>                   hlm[i]<-
> >>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
> >>>                  }
> >>>           shl<-gil*(sum(hlm)+1)
> >>>           return (shl)
> >>>           }
> >>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
> >>>       }
> >>>
> >>>
> >>> I'm trying to use alternatives (for ex. to vectorize things) to the
> >>> explicit for() loops, but things don't work out.
> >>>
> >>> Any suggestions that can help me to speed up the execution of the
> >>> incomb()
> >>> function are much appreciated.
> >>>
> >>> Thanks a lot in advance.
> >>>
> >>> Maram Salem
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Nov  6 16:45:18 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 6 Nov 2015 10:45:18 -0500
Subject: [R] subsetting a data.frame based on a specific group of columns
In-Reply-To: <CA+8Xemz+THWLHHPn=MzzdaFo_npqJctiE2TGphMDL2uQTwtsTg@mail.gmail.com>
References: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>
	<CAAxdm-6kOQHt9p-LWA9ZxBWrNpjhLr-Rv5Ptw8hw-bWrRPvx4g@mail.gmail.com>
	<CA+8Xemz+THWLHHPn=MzzdaFo_npqJctiE2TGphMDL2uQTwtsTg@mail.gmail.com>
Message-ID: <0AF6AA80-F3F3-4A4C-A82B-75F26B28CAF6@utoronto.ca>

Please learn to use dput() to post example data.

# This is your data:
data <- structure(c(1232, 0, 43, 357, 71, 919, 23, 9, 1111, 0, 811, 0, 
9871, 795, 76, 72, 743, 14), .Dim = c(3L, 6L), .Dimnames = list(
    NULL, c("X1", "X2", "X3", "Y1", "Y2", "Y3")))

data

# define groups and threshold explicitly
groupA <- c(1, 2, 3)
groupB <- c(4, 5, 6)
thrsh  <- 100


# Here's how you evaluate your condition on the member elements of your group
rowSums(data[ , groupA]) > thrsh

# note that you can cast a logical TRUE/FALSE into an integer 0/1
as.numeric(rowSums(data[ , groupA]) >= thrsh)

# ... which you can multiply with your data (*)
data[ , groupA] * as.numeric(rowSums(data[ , groupA]) > thrsh)

#  now you could write this into your matrix
data[ , groupA] <- data[ , groupA] * as.numeric(rowSums(data[ , groupA]) > thrsh)
# data[ , groupB] etc ... 

data

# ... but you would be repeating code, therefore better to write this
# as a function:

clearReadsBelowThreshold <- function(m, g, t) {
	m[ , g] <- m[ , g] * as.numeric(rowSums(m[ , g]) >= t)
     return(m)
}

data <- clearReadsBelowThreshold(data, groupA, thrsh)
data <- clearReadsBelowThreshold(data, groupB, thrsh)

data




(*) Note that R would do this conversion implicitly but omitting
    the conversion will cause confusion for those who read the code
    later. 



Cheers,
Boris





On Nov 6, 2015, at 8:53 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:

> sorry, for the misunderstanding. here is a more elaborate description of
> what i would like to achieve.
> 
> I have a data set of counts from a RNA-Seq experiment and would like to
> filter reads with low counts. I don't want to set everything to 0
> automatically.
> 
> I would like to set each categorical group (e.g. condition) to 0, if and
> only if all replica in the group together have less than 100 reads.
> in my examples I used X and Y to represents the categories. Ususally they
> have a more distinct names like "control", "knockout1", "dKo" etc.
> 
> So what I really like to do is to check if the sum of all the "control"
> samples is lower than 100. If so, set all control sample to 0. This I would
> like to check *for each category* of every row of the data set.
> 
> I hope it is more clear now
> 
> thanks
> Assa
> 
> 
> On Fri, Nov 6, 2015 at 2:29 PM, jim holtman <jholtman at gmail.com> wrote:
> 
>> Is this what you want:
>> 
>>> x <- read.table(text = "X1    X2    X3    Y1    Y2    Y3
>> + 1232    357    23    0    9871    72
>> + 0    71    9    811    795    743
>> + 43    919    1111    0    76    14", header = TRUE)
>>> x
>>    X1  X2   X3  Y1   Y2  Y3
>> 1 1232 357   23   0 9871  72
>> 2    0  71    9 811  795 743
>> 3   43 919 1111   0   76  14
>>> 
>>> # create indices of columns that start with the same character
>>> indx <- split(seq(ncol(x)), substring(colnames(x), 1, 1))
>>> names(indx) <- NULL  # remove names so output not messed up
>>> 
>>> result <- lapply(indx, function(a){
>> +     row_sum <- rowSums(x[, a])
>> +     x[row_sum < 100, a] <- 0
>> +     x[, a]
>> + })
>>> # combine back together
>>> do.call(cbind, result)
>>    X1  X2   X3  Y1   Y2  Y3
>> 1 1232 357   23   0 9871  72
>> 2    0   0    0 811  795 743
>> 3   43 919 1111   0    0   0
>> 
>> 
>> Jim Holtman
>> Data Munger Guru
>> 
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>> On Fri, Nov 6, 2015 at 5:40 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:
>> 
>>> Hi,
>>> 
>>> I have a data frame with multiple columns, which are belong to several
>>> groups
>>> like that:
>>> X1    X2    X3    Y1    Y2    Y3
>>> 1232    357    23    0    9871    72
>>> 0    71    9    811    795    743
>>> 43    919    1111    0    76    14
>>> 
>>> I would like to filter such rows out, where the sums in one group is lower
>>> than a specifc value. For example, I would like to set all the values in a
>>> group of cloums to zero, if the sum in one group is less than 100
>>> In my example table I would like to set the values in the second row for
>>> the three X-columns to 0, so that the table looks like that:
>>> 
>>> X1    X2    X3    Y1    Y2    Y3
>>> 1232    357    23    0    9871    72
>>> 0    0    0    811    795    743
>>> 43    919    1111    0    0    0
>>> 
>>> the same apply also for the Y-values in the last column.
>>> Is there a more efficient way of doing it than going row by row and use
>>> the
>>> apply function on each of the subgroups I have in the columns?
>>> 
>>> thanks
>>> Assa
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mxkuhn at gmail.com  Fri Nov  6 17:04:27 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Fri, 6 Nov 2015 11:04:27 -0500
Subject: [R] Caret Internal Data Representation
In-Reply-To: <CAGxFJbQBsXbMHgUYDfo9OMOO=v0erg3r-EU96auNu9dSnne0bQ@mail.gmail.com>
References: <20151105173823.GC3206@localhost.localdomain>
	<CAGxFJbQBsXbMHgUYDfo9OMOO=v0erg3r-EU96auNu9dSnne0bQ@mail.gmail.com>
Message-ID: <CAJ9CoWnnwwfjxVfYZcwco-cgRASAkDOUCJpmU6gSe0k7sUOc7w@mail.gmail.com>

Providing a reproducible example and the results of `sessionInfo` will help
get your question answered.  For example, did you use the formula or
non-formula interface to `train` and so on

On Thu, Nov 5, 2015 at 1:10 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I am not familiar with caret/Cubist, but assuming they follow the
> usual R procedures that encode categorical factors for conditional
> fitting, you need to do some homework on your own by reading up on the
> use of contrasts in regression.
>
> See ?factor and ?contrasts (and other linked Help as necessary) to see
> what are R's usual procedures, but you will undoubtedly need to
> consult outside statistical references -- the help files will point
> you to some -- to fully understand what's going on. It is not trivial.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Thu, Nov 5, 2015 at 9:38 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
> wrote:
> > Dear All,
> > I have a data set which contains both categorical and numerical
> > variables which I analyze using Cubist+the caret framework.
> > Now, from the generated rules, it is clear that cubist does something
> > to the categorical variables and probably uses some dummy coding for
> > them.
> > However, I cannot right now access the data the way it is transformed
> > by cubist.
> > If caret (or the package) need to do some dummy coding of the factors,
> > how can I access the newly encoded data set?
> > I suppose this applies to plenty of other packages.
> > Any suggestion is welcome.
> > Cheers
> >
> > Lorenzo
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Fri Nov  6 17:23:33 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Nov 2015 10:23:33 -0600
Subject: [R] using Fortran with R
Message-ID: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>

Hello everyone!

Could someone recommend a good reference for Fortran with R, please?  I
know that Dirk has an excellent book for C/C++, but I feel more comfortable
with Fortran (I'm old school, maybe just old!)

Thank you very much in advance,
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From adgarza at live.com  Fri Nov  6 04:42:11 2015
From: adgarza at live.com (Adam Garza)
Date: Thu, 5 Nov 2015 21:42:11 -0600
Subject: [R] Trouble Installing R packages
Message-ID: <BAY403-EAS314E9BF11D771FE2F29EBEDC9280@phx.gbl>

Trying to install vcd package but can?t
It seems like it tries but runs into some kind of error and so quits.

Maybe it has something to do with the ?dependencies? ? not sure what that means
Also think it might have something to do with Windows 10 keeping Documents folder synced with OneDrive.

Can anyone help?


> install.packages("vcd")
Installing package into ?C:/Users/adgar/OneDrive/Documents/R/win-library/3.2?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
also installing the dependencies ?zoo?, ?colorspace?, ?lmtest?

Packages which are only available in source form, and may need
  compilation of C/C++/Fortran: ?zoo? ?colorspace? ?lmtest?
  These will not be installed
installing the source package ?vcd?

trying URL 'https://cran.revolutionanalytics.com/src/contrib/vcd_1.4-1.tar.gz'
Content type 'application/octet-stream' length 883913 bytes (863 KB)
downloaded 863 KB

ERROR: dependencies 'colorspace', 'lmtest' are not available for package 'vcd'
* removing 'C:/Users/adgar/OneDrive/Documents/R/win-library/3.2/vcd'

The downloaded source packages are in
        ?C:\Users\adgar\AppData\Local\Temp\RtmpymmKaM\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\adgar\OneDrive\Documents\R\win-library\3.2" C:\Users\adgar\AppData\Local\Temp\RtmpymmKaM/downloaded_packages/vcd_1.4-1.tar.gz' had status 1 
2: In install.packages("vcd") :
  installation of package ?vcd? had non-zero exit status

Sent from Mail for Windows 10

	[[alternative HTML version deleted]]


From bolseiro.raiz.csilva at portucelsoporcel.com  Fri Nov  6 11:41:18 2015
From: bolseiro.raiz.csilva at portucelsoporcel.com (Catarina Silva)
Date: Fri, 6 Nov 2015 10:41:18 -0000
Subject: [R] [GGplot] Geom_smooth with formula "power"?
Message-ID: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>

Hi,

It's possible to use ggplot and geom_smooth to adjust a power curve to the
data?

Initially i have done the adjustement with nls and the formula 'a*x^b', but
resulted the singular matrix error for start solution. Alternatively I used
the log transformation and i had correct results, but I can't draw a power
curve on the graphic.

Someone know how to solve this problem?

 

Ty,

 

Catarina Silva  


Imprima no nosso papel - Cuide do ambiente
--------------------------
Print on our paper - Care for the environment.
--------------------------
http://backoffice.portucelsoporcel.net/dynamic-media/files/utilizar_papel_e_promover_o_desenvolvimento_da_floresta.pdf


From josip.2000 at gmail.com  Fri Nov  6 12:28:05 2015
From: josip.2000 at gmail.com (Karl)
Date: Fri, 6 Nov 2015 13:28:05 +0200
Subject: [R] Calculating distance between words in string
Message-ID: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>

Hi All,

Using R for text processing is quite new to me, while I have found a lot of
useful functions and I'm beginning to learn regex, I need help with the
following task. How do I calculate the distance between words?

That is, given a specific keyword, I need to assign labels to the other
words based on the distance (number of words) to this keyword.

For example, if the keyword is "amet" and the string of words is:
 "Lorem ipsum dolor sit amet, consectetur adipiscing elit."
 -> "dolor" would get a value of -2
 -> "elit" would get a value of 3

If the sentence contains more than one instance of the keyword, I need
values for each instance. Moreover, one can assume that I can split my data
into sentences, so there is no need to search and recognize sentences (this
is a separate problem).

Thank you!

Best regards,
Jay

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Nov  6 15:10:42 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 6 Nov 2015 09:10:42 -0500
Subject: [R] subsetting a data.frame based on a specific group of columns
In-Reply-To: <CA+8Xemz+THWLHHPn=MzzdaFo_npqJctiE2TGphMDL2uQTwtsTg@mail.gmail.com>
References: <CA+8XemwfxbS=u7EKH8aChEa7WNPdRZ=oPK7AgJXLC7VaUS-UFw@mail.gmail.com>
	<CAAxdm-6kOQHt9p-LWA9ZxBWrNpjhLr-Rv5Ptw8hw-bWrRPvx4g@mail.gmail.com>
	<CA+8Xemz+THWLHHPn=MzzdaFo_npqJctiE2TGphMDL2uQTwtsTg@mail.gmail.com>
Message-ID: <CAAxdm-5eYh94AZVmpg5cJap0QWhqzxMQ3-GzH5+ofrozfGS5VQ@mail.gmail.com>

I assume the solution is somewhat the same; you just have to define how to
determine what the "distinctive" names are to create the groupings.  My
solution assumed it was the first character.  If the group names end in a
unique sequence, you can use this to form the groups, or you can provide a
list of the first part of the names to match on to form the groups.  You
need to provide a reasonable subset of the data so that we can exactly
understand what the data is and how it should be grouped.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Nov 6, 2015 at 8:53 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:

> sorry, for the misunderstanding. here is a more elaborate description of
> what i would like to achieve.
>
> I have a data set of counts from a RNA-Seq experiment and would like to
> filter reads with low counts. I don't want to set everything to 0
> automatically.
>
> I would like to set each categorical group (e.g. condition) to 0, if and
> only if all replica in the group together have less than 100 reads.
> in my examples I used X and Y to represents the categories. Ususally they
> have a more distinct names like "control", "knockout1", "dKo" etc.
>
> So what I really like to do is to check if the sum of all the "control"
> samples is lower than 100. If so, set all control sample to 0. This I would
> like to check *for each category* of every row of the data set.
>
> I hope it is more clear now
>
> thanks
> Assa
>
>
> On Fri, Nov 6, 2015 at 2:29 PM, jim holtman <jholtman at gmail.com> wrote:
>
>> Is this what you want:
>>
>> > x <- read.table(text = "X1    X2    X3    Y1    Y2    Y3
>> + 1232    357    23    0    9871    72
>> + 0    71    9    811    795    743
>> + 43    919    1111    0    76    14", header = TRUE)
>> > x
>>     X1  X2   X3  Y1   Y2  Y3
>> 1 1232 357   23   0 9871  72
>> 2    0  71    9 811  795 743
>> 3   43 919 1111   0   76  14
>> >
>> > # create indices of columns that start with the same character
>> > indx <- split(seq(ncol(x)), substring(colnames(x), 1, 1))
>> > names(indx) <- NULL  # remove names so output not messed up
>> >
>> > result <- lapply(indx, function(a){
>> +     row_sum <- rowSums(x[, a])
>> +     x[row_sum < 100, a] <- 0
>> +     x[, a]
>> + })
>> > # combine back together
>> > do.call(cbind, result)
>>     X1  X2   X3  Y1   Y2  Y3
>> 1 1232 357   23   0 9871  72
>> 2    0   0    0 811  795 743
>> 3   43 919 1111   0    0   0
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Fri, Nov 6, 2015 at 5:40 AM, Assa Yeroslaviz <frymor at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I have a data frame with multiple columns, which are belong to several
>>> groups
>>> like that:
>>> X1    X2    X3    Y1    Y2    Y3
>>> 1232    357    23    0    9871    72
>>> 0    71    9    811    795    743
>>> 43    919    1111    0    76    14
>>>
>>> I would like to filter such rows out, where the sums in one group is
>>> lower
>>> than a specifc value. For example, I would like to set all the values in
>>> a
>>> group of cloums to zero, if the sum in one group is less than 100
>>> In my example table I would like to set the values in the second row for
>>> the three X-columns to 0, so that the table looks like that:
>>>
>>> X1    X2    X3    Y1    Y2    Y3
>>> 1232    357    23    0    9871    72
>>> 0    0    0    811    795    743
>>> 43    919    1111    0    0    0
>>>
>>> the same apply also for the Y-values in the last column.
>>> Is there a more efficient way of doing it than going row by row and use
>>> the
>>> apply function on each of the subgroups I have in the columns?
>>>
>>> thanks
>>> Assa
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From julian831 at yahoo.com  Fri Nov  6 15:20:22 2015
From: julian831 at yahoo.com (=?UTF-8?Q?Corach_Juli=C3=A1n?=)
Date: Fri, 6 Nov 2015 14:20:22 +0000 (UTC)
Subject: [R] Help scatterplot3d
References: <633022433.875402.1446819622602.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <633022433.875402.1446819622602.JavaMail.yahoo@mail.yahoo.com>

Hi, I'm running this script:
library(scatterplot3d)datos<-read.csv("C:\\prueba.csv",sep=",",header=TRUE)str(datos)scatterplot3d(datos)
s3d<- scatterplot3d(datos, type = "h", color = "blue", angle = 55, scale.y = 0.7, pch = 16, main = "title?)
my.lm <- lm(datos$Bx ~ datos$e + datos$t)?s3d$plane3d(my.lm)
?I need to plot the experimental data ("datos") and the regression plane given by "my.lm" in the same figure.The script plots "datos" but it doesn't add the plot of the regression plane.?Sometimes I get a message like "s3d objet not found".
Thanks a lot.
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Nov  6 17:36:42 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 06 Nov 2015 08:36:42 -0800
Subject: [R] Attempting to plot two different time series together
In-Reply-To: <CAKa8D7TL436FctYL636QsZcicdLut1ewLyHrhkRfotFCc0yPuQ@mail.gmail.com>
References: <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=Qg@mail.gmail.com>
	<C79C97DE-8D48-4E3C-9F24-F72053C8E705@dcn.davis.CA.us>
	<CAKa8D7TL436FctYL636QsZcicdLut1ewLyHrhkRfotFCc0yPuQ@mail.gmail.com>
Message-ID: <8DD3AF3B-ACA8-4C1E-81BC-2F756250B265@dcn.davis.CA.us>

Please keep the list in the conversation. 

Yes stacking was my intention, since the graphical presentation does not need the same time basis.  However, your other analyses may indeed require that you interpolate or decimate to obtain aligned data records. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2015 8:01:55 AM PST, Ezra Boyd <ezgis76 at gmail.com> wrote:
>Jeff,
>
>Thank you very much for responding.  I actually read and worked through
>most of ggplot2 and ggplot2 Essentials for this task, but was starting
>to
>think they were not what I needed.
>
>The problem that I cannot get over is that my two timeseries datasets
>are
>based on different samplings, 30-mins for the tidal and 6-mins for the
>meteorological:
>
>Tidal Data
>TS Stage_ft 1/9/2001 16:00 -0.41 1/9/2001 16:30 -0.43 1/9/2001 17:00
>-0.44 1/9/2001
>17:30 -0.43 1/9/2001 18:00 -0.4
>Meteorological
>DATETIME  WINDSPEED           DIR 8/15/2012 0:00 5.05 228 8/15/2012
>0:06
>4.08 225 8/15/2012 0:12 4.08 216 8/15/2012 0:18 4.47 222 8/15/2012 0:24
>5.05
>219 8/15/2012 0:30 3.5 226
>
>Do I understand your suggestion correctly that I should tidy up the
>dataset
>by stacking them in the dataframe, and then facet them using a type
>column?
>TS Stage_ft  WINDSPEED  DIR Type 1/9/2001 16:00 -0.41    T 1/9/2001
>16:30
>-0.43    T 1/9/2001 17:00 -0.44    T 1/9/2001 17:30 -0.43    T 1/9/2001
>18:00 -0.4    T 8/15/2012 0:00 5.05 228    M 8/15/2012 0:06 4.08 225
> M 8/15/2012
>0:12 4.08 216    M 8/15/2012 0:18 4.47 222    M 8/15/2012 0:24 5.05
>219    M 8/15/2012
>0:30 3.5 226    M
>Or, do I need to look into timeseries methods for combining datasets
>with
>different samplings?
>
>Thanks again and I appreciate you taking the time to share your
>knowledge.
>
>Regards,
>
>Ezra
>
>
>
>
>
>
>
>
>On Thu, Nov 5, 2015 at 7:25 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Seems like you would benefit from reading about long and wide data...
>> perhaps  [1].
>>
>> If I am understanding what you want,  ggplot facetting should be able
>to
>> do what you want.  You first have to put the data in long form (e.g.
>> variable, timestamp, value) before you give it to ggplot.
>>
>> If you want more specific help then you should provide a small sample
>data
>> set as one or more  R dputs as the Posting Guide recommends (see
>footer,
>> and  [2]).
>>
>> [1]
>https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html
>>
>> [2]
>>
>http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 5, 2015 7:00:18 AM PST, Ezra Boyd <ezgis76 at gmail.com>
>wrote:
>> >Hello,
>> >
>> >I am trying to create a plot (I guess two plots) using two different
>> >time
>> >series datasets, but I'm not sure of the best approach.  The data is
>> >from a
>> >tidal surge due to a hurricane and I would like to show the
>> >relationship
>> >between stage and windspeed/direction.
>> >
>> >One dataset is the tidal stage and it is sampled in 30 minutes
>> >intervals.
>> >The other dataset is windspeed and direction and it is sampled every
>6
>> >minutes.  I would like to display the tidal hydrograph and then also
>> >show
>> >windspeed and direction as a banner above it.  They would be two
>> >separate
>> >plots, but with identical x-axis (as opposed to one plot that has
>both
>> >tide
>> >& wind.)
>> >
>> >Should I combine the two time series into one dataframe (with lots
>of
>> >NAs)
>> >so that I can create the plots together, for example using pairs or
>> >ggpairs? Or should I keep them separate, make the individual plots,
>and
>> >then work on the layout in graphic design software? I would prefer
>the
>> >former, but I just can't figure out how to make that work out.
>> >
>> >Also, is it possible to depict wind direction (which is given in
>degree
>> >clockwise from due north) with an arrow?
>> >
>> >Thank you very much,
>> >
>> >Ezra
>>
>>


From murdoch.duncan at gmail.com  Fri Nov  6 17:43:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 6 Nov 2015 10:43:17 -0600
Subject: [R] Trouble Installing R packages
In-Reply-To: <BAY403-EAS314E9BF11D771FE2F29EBEDC9280@phx.gbl>
References: <BAY403-EAS314E9BF11D771FE2F29EBEDC9280@phx.gbl>
Message-ID: <563CD8A5.70805@gmail.com>

On 05/11/2015 9:42 PM, Adam Garza wrote:
> Trying to install vcd package but can?t
> It seems like it tries but runs into some kind of error and so quits.
>
> Maybe it has something to do with the ?dependencies? ? not sure what that means

Most packages depend on other packages.  The vcd package depends on some 
standard packages which you likely already have, plus colorspace and 
lmtest.    But the site (cran.revolutionanalytics.com) where you're 
trying to download those doesn't have them.  (It also seems to be 
missing the Windows binary.  I'd try setting a different mirror.)

Duncan Muroch

> Also think it might have something to do with Windows 10 keeping Documents folder synced with OneDrive.
>
> Can anyone help?
>
>
>> install.packages("vcd")
> Installing package into ?C:/Users/adgar/OneDrive/Documents/R/win-library/3.2?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> also installing the dependencies ?zoo?, ?colorspace?, ?lmtest?
>
> Packages which are only available in source form, and may need
>    compilation of C/C++/Fortran: ?zoo? ?colorspace? ?lmtest?
>    These will not be installed
> installing the source package ?vcd?
>
> trying URL 'https://cran.revolutionanalytics.com/src/contrib/vcd_1.4-1.tar.gz'
> Content type 'application/octet-stream' length 883913 bytes (863 KB)
> downloaded 863 KB
>
> ERROR: dependencies 'colorspace', 'lmtest' are not available for package 'vcd'
> * removing 'C:/Users/adgar/OneDrive/Documents/R/win-library/3.2/vcd'
>
> The downloaded source packages are in
>          ?C:\Users\adgar\AppData\Local\Temp\RtmpymmKaM\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l "C:\Users\adgar\OneDrive\Documents\R\win-library\3.2" C:\Users\adgar\AppData\Local\Temp\RtmpymmKaM/downloaded_packages/vcd_1.4-1.tar.gz' had status 1
> 2: In install.packages("vcd") :
>    installation of package ?vcd? had non-zero exit status
>
> Sent from Mail for Windows 10
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ezgis76 at gmail.com  Fri Nov  6 17:49:34 2015
From: ezgis76 at gmail.com (Ezra Boyd)
Date: Fri, 6 Nov 2015 10:49:34 -0600
Subject: [R] Attempting to plot two different time series together
In-Reply-To: <8DD3AF3B-ACA8-4C1E-81BC-2F756250B265@dcn.davis.CA.us>
References: <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=Qg@mail.gmail.com>
	<C79C97DE-8D48-4E3C-9F24-F72053C8E705@dcn.davis.CA.us>
	<CAKa8D7TL436FctYL636QsZcicdLut1ewLyHrhkRfotFCc0yPuQ@mail.gmail.com>
	<8DD3AF3B-ACA8-4C1E-81BC-2F756250B265@dcn.davis.CA.us>
Message-ID: <CAKa8D7RysP+F=dZAcNr=XB3-Gp=p4K89QVBpWsAsgHdtroYk7Q@mail.gmail.com>

Jeff -- Thank you for the clarification.

Ezra


On Fri, Nov 6, 2015 at 10:36 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please keep the list in the conversation.
>
> Yes stacking was my intention, since the graphical presentation does not
> need the same time basis.  However, your other analyses may indeed require
> that you interpolate or decimate to obtain aligned data records.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 6, 2015 8:01:55 AM PST, Ezra Boyd <ezgis76 at gmail.com> wrote:
> >Jeff,
> >
> >Thank you very much for responding.  I actually read and worked through
> >most of ggplot2 and ggplot2 Essentials for this task, but was starting
> >to
> >think they were not what I needed.
> >
> >The problem that I cannot get over is that my two timeseries datasets
> >are
> >based on different samplings, 30-mins for the tidal and 6-mins for the
> >meteorological:
> >
> >Tidal Data
> >TS Stage_ft 1/9/2001 16:00 -0.41 1/9/2001 16:30 -0.43 1/9/2001 17:00
> >-0.44 1/9/2001
> >17:30 -0.43 1/9/2001 18:00 -0.4
> >Meteorological
> >DATETIME  WINDSPEED           DIR 8/15/2012 0:00 5.05 228 8/15/2012
> >0:06
> >4.08 225 8/15/2012 0:12 4.08 216 8/15/2012 0:18 4.47 222 8/15/2012 0:24
> >5.05
> >219 8/15/2012 0:30 3.5 226
> >
> >Do I understand your suggestion correctly that I should tidy up the
> >dataset
> >by stacking them in the dataframe, and then facet them using a type
> >column?
> >TS Stage_ft  WINDSPEED  DIR Type 1/9/2001 16:00 -0.41    T 1/9/2001
> >16:30
> >-0.43    T 1/9/2001 17:00 -0.44    T 1/9/2001 17:30 -0.43    T 1/9/2001
> >18:00 -0.4    T 8/15/2012 0:00 5.05 228    M 8/15/2012 0:06 4.08 225
> > M 8/15/2012
> >0:12 4.08 216    M 8/15/2012 0:18 4.47 222    M 8/15/2012 0:24 5.05
> >219    M 8/15/2012
> >0:30 3.5 226    M
> >Or, do I need to look into timeseries methods for combining datasets
> >with
> >different samplings?
> >
> >Thanks again and I appreciate you taking the time to share your
> >knowledge.
> >
> >Regards,
> >
> >Ezra
> >
> >
> >
> >
> >
> >
> >
> >
> >On Thu, Nov 5, 2015 at 7:25 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> Seems like you would benefit from reading about long and wide data...
> >> perhaps  [1].
> >>
> >> If I am understanding what you want,  ggplot facetting should be able
> >to
> >> do what you want.  You first have to put the data in long form (e.g.
> >> variable, timestamp, value) before you give it to ggplot.
> >>
> >> If you want more specific help then you should provide a small sample
> >data
> >> set as one or more  R dputs as the Posting Guide recommends (see
> >footer,
> >> and  [2]).
> >>
> >> [1]
> >https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html
> >>
> >> [2]
> >>
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> >>
>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >> Go...
> >>                                       Live:   OO#.. Dead: OO#..
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >>
>
> >---------------------------------------------------------------------------
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On November 5, 2015 7:00:18 AM PST, Ezra Boyd <ezgis76 at gmail.com>
> >wrote:
> >> >Hello,
> >> >
> >> >I am trying to create a plot (I guess two plots) using two different
> >> >time
> >> >series datasets, but I'm not sure of the best approach.  The data is
> >> >from a
> >> >tidal surge due to a hurricane and I would like to show the
> >> >relationship
> >> >between stage and windspeed/direction.
> >> >
> >> >One dataset is the tidal stage and it is sampled in 30 minutes
> >> >intervals.
> >> >The other dataset is windspeed and direction and it is sampled every
> >6
> >> >minutes.  I would like to display the tidal hydrograph and then also
> >> >show
> >> >windspeed and direction as a banner above it.  They would be two
> >> >separate
> >> >plots, but with identical x-axis (as opposed to one plot that has
> >both
> >> >tide
> >> >& wind.)
> >> >
> >> >Should I combine the two time series into one dataframe (with lots
> >of
> >> >NAs)
> >> >so that I can create the plots together, for example using pairs or
> >> >ggpairs? Or should I keep them separate, make the individual plots,
> >and
> >> >then work on the layout in graphic design software? I would prefer
> >the
> >> >former, but I just can't figure out how to make that work out.
> >> >
> >> >Also, is it possible to depict wind direction (which is given in
> >degree
> >> >clockwise from due north) with an arrow?
> >> >
> >> >Thank you very much,
> >> >
> >> >Ezra
> >>
> >>
>
>


-- 
Ezra Boyd, PhD
DisasterMap.net, LLC <http://DisasterMap.net>
ezgis <ezgis76 at gmail.com>76 at gmail.com <ezgis76 at gmail.com>
(504)533-4447

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Nov  6 17:56:53 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 6 Nov 2015 08:56:53 -0800
Subject: [R] Calculating distance between words in string
In-Reply-To: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>
References: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>
Message-ID: <2C995EB4-DBBA-4D89-A22B-4EDB7B658DA7@comcast.net>


> On Nov 6, 2015, at 3:28 AM, Karl <josip.2000 at gmail.com> wrote:
> 
> Hi All,
> 
> Using R for text processing is quite new to me, while I have found a lot of
> useful functions and I'm beginning to learn regex, I need help with the
> following task. How do I calculate the distance between words?
> 
> That is, given a specific keyword, I need to assign labels to the other
> words based on the distance (number of words) to this keyword.
> 
> For example, if the keyword is "amet" and the string of words is


strng <- "Lorem ipsum dolor sit amet, consectetur adipiscing elit.?

> -> "dolor" would get a value of -2
> -> "elit" would get a value of 3

words <- unlist(strsplit(strng, "\\W"))
words[words != ""]
#[1] "Lorem"       "ipsum"       "dolor"       "sit"        
#[5] "amet"        "consectetur" "adipiscing"  "elit"       
real <- words[words != ?"]

which(real == "amet")
#[1] 5
length(real)
#[1] 8
 vec <- 1:length(real) - which(real == "amet")
 names(vec) <- real

 vec["dolor"]
#dolor 
#   -2 


> #
> If the sentence contains more than one instance of the keyword, I need
> values for each instance. Moreover, one can assume that I can split my data
> into sentences, so there is no need to search and recognize sentences (this
> is a separate problem).
> 
> Thank you!
> 
> Best regards,
> Jay
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bhh at xs4all.nl  Fri Nov  6 17:59:50 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 6 Nov 2015 17:59:50 +0100
Subject: [R] using Fortran with R
In-Reply-To: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
Message-ID: <ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>


> On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> Hello everyone!
> 
> Could someone recommend a good reference for Fortran with R, please?  I
> know that Dirk has an excellent book for C/C++, but I feel more comfortable
> with Fortran (I'm old school, maybe just old!)
> 

I don't know about a book.
The best you can do is read Writing R Extensions.
And have a look at packages using Fortran:  nleqslv, geigen, QZ, deSolve, minpack.lm, PEIP
That should give you a good idea how to use Fortran.
There are surely more but these are the ones I know about.

Berend

> Thank you very much in advance,
> Sincerely,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Fri Nov  6 18:17:56 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Nov 2015 11:17:56 -0600
Subject: [R] using Fortran with R
In-Reply-To: <ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
	<ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
Message-ID: <CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>

Great..thanks for the package names.  I was going to use the "Writing R
Extensions" but wanted some more material as well.  Looking at the other
packages might just do the trick.

Thanks,
Erin


On Fri, Nov 6, 2015 at 10:59 AM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >
> > Hello everyone!
> >
> > Could someone recommend a good reference for Fortran with R, please?  I
> > know that Dirk has an excellent book for C/C++, but I feel more
> comfortable
> > with Fortran (I'm old school, maybe just old!)
> >
>
> I don't know about a book.
> The best you can do is read Writing R Extensions.
> And have a look at packages using Fortran:  nleqslv, geigen, QZ, deSolve,
> minpack.lm, PEIP
> That should give you a good idea how to use Fortran.
> There are surely more but these are the ones I know about.
>
> Berend
>
> > Thank you very much in advance,
> > Sincerely,
> > Erin
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From emammendes at gmail.com  Fri Nov  6 21:09:53 2015
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Fri, 6 Nov 2015 18:09:53 -0200
Subject: [R] using Fortran with R
In-Reply-To: <CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
	<ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
	<CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
Message-ID: <7B818341-9E17-480B-9A62-26C8B072B4C7@gmail.com>

Dear Erin

I have written some packages using my old fortran source codes.   Nothing fancy as the ones in CRAN but they do what they suppose to do.  If you are interested in checking a very simple package using a fortran code, please look at https://github.com/emammendes/mittagleffler <https://github.com/emammendes/mittagleffler> , an R-package to deal with Mittag-Leffler functions (fractional differential equations). 

Cheers

Ed



> On Nov 6, 2015, at 3:17 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> 
> Great..thanks for the package names.  I was going to use the "Writing R
> Extensions" but wanted some more material as well.  Looking at the other
> packages might just do the trick.
> 
> Thanks,
> Erin
> 
> 
> On Fri, Nov 6, 2015 at 10:59 AM, Berend Hasselman <bhh at xs4all.nl <mailto:bhh at xs4all.nl>> wrote:
> 
>> 
>>> On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>> 
>>> Hello everyone!
>>> 
>>> Could someone recommend a good reference for Fortran with R, please?  I
>>> know that Dirk has an excellent book for C/C++, but I feel more
>> comfortable
>>> with Fortran (I'm old school, maybe just old!)
>>> 
>> 
>> I don't know about a book.
>> The best you can do is read Writing R Extensions.
>> And have a look at packages using Fortran:  nleqslv, geigen, QZ, deSolve,
>> minpack.lm, PEIP
>> That should give you a good idea how to use Fortran.
>> There are surely more but these are the ones I know about.
>> 
>> Berend
>> 
>>> Thank you very much in advance,
>>> Sincerely,
>>> Erin
>>> 
>>> 
>>> --
>>> Erin Hodgess
>>> Associate Professor
>>> Department of Mathematical and Statistics
>>> University of Houston - Downtown
>>> mailto: erinm.hodgess at gmail.com
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com <mailto:erinm.hodgess at gmail.com>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Fri Nov  6 21:13:44 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Fri, 6 Nov 2015 15:13:44 -0500
Subject: [R] using Fortran with R
In-Reply-To: <CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
	<ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
	<CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
Message-ID: <563D09F8.9090908@gmail.com>

It's not a full book on the issue, but I have some material in "speeding
things up" in my book on Nonlinear parameter estimation tools in R. I
suspect the examples are the useful bit.

JN

On 15-11-06 12:17 PM, Erin Hodgess wrote:
> Great..thanks for the package names.  I was going to use the "Writing R
> Extensions" but wanted some more material as well.  Looking at the other
> packages might just do the trick.
> 
> Thanks,
> Erin
> 
> 
> On Fri, Nov 6, 2015 at 10:59 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>>
>>> On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>>
>>> Hello everyone!
>>>
>>> Could someone recommend a good reference for Fortran with R, please?  I
>>> know that Dirk has an excellent book for C/C++, but I feel more
>> comfortable
>>> with Fortran (I'm old school, maybe just old!)
>>>
>>
>> I don't know about a book.
>> The best you can do is read Writing R Extensions.
>> And have a look at packages using Fortran:  nleqslv, geigen, QZ, deSolve,
>> minpack.lm, PEIP
>> That should give you a good idea how to use Fortran.
>> There are surely more but these are the ones I know about.
>>
>> Berend
>>
>>> Thank you very much in advance,
>>> Sincerely,
>>> Erin
>>>
>>>
>>> --
>>> Erin Hodgess
>>> Associate Professor
>>> Department of Mathematical and Statistics
>>> University of Houston - Downtown
>>> mailto: erinm.hodgess at gmail.com
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
>


From erinm.hodgess at gmail.com  Fri Nov  6 21:15:36 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Nov 2015 14:15:36 -0600
Subject: [R] using Fortran with R
In-Reply-To: <7B818341-9E17-480B-9A62-26C8B072B4C7@gmail.com>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
	<ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
	<CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
	<7B818341-9E17-480B-9A62-26C8B072B4C7@gmail.com>
Message-ID: <CACxE24=TDRdjgHijXcBV3PQFzvqy9tP8WqSysUoZZ3LbgBqSTw@mail.gmail.com>

Awesome!
Thanks!


On Fri, Nov 6, 2015 at 2:09 PM, Eduardo M. A. M.Mendes <emammendes at gmail.com
> wrote:

> Dear Erin
>
> I have written some packages using my old fortran source codes.   Nothing
> fancy as the ones in CRAN but they do what they suppose to do.  If you are
> interested in checking a very simple package using a fortran code, please
> look at https://github.com/emammendes/mittagleffler , an R-package to
> deal with Mittag-Leffler functions (fractional differential equations).
>
> Cheers
>
> Ed
>
>
>
> On Nov 6, 2015, at 3:17 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Great..thanks for the package names.  I was going to use the "Writing R
> Extensions" but wanted some more material as well.  Looking at the other
> packages might just do the trick.
>
> Thanks,
> Erin
>
>
> On Fri, Nov 6, 2015 at 10:59 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>
> On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> Hello everyone!
>
> Could someone recommend a good reference for Fortran with R, please?  I
> know that Dirk has an excellent book for C/C++, but I feel more
>
> comfortable
>
> with Fortran (I'm old school, maybe just old!)
>
>
> I don't know about a book.
> The best you can do is read Writing R Extensions.
> And have a look at packages using Fortran:  nleqslv, geigen, QZ, deSolve,
> minpack.lm, PEIP
> That should give you a good idea how to use Fortran.
> There are surely more but these are the ones I know about.
>
> Berend
>
> Thank you very much in advance,
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
>
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From erinm.hodgess at gmail.com  Fri Nov  6 21:16:21 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 6 Nov 2015 14:16:21 -0600
Subject: [R] using Fortran with R
In-Reply-To: <563D09F8.9090908@gmail.com>
References: <CACxE24m08Cs190YJs+LNu-cJ+0UdHBQ8=M+b_YpyEiPz1ZMfYQ@mail.gmail.com>
	<ECFC3EE6-8D25-4464-95E8-9765920916EF@xs4all.nl>
	<CACxE24kq55r+rHJ85SL0-Yf5CxD3QsHzESDaAvE1dfa30gZfGQ@mail.gmail.com>
	<563D09F8.9090908@gmail.com>
Message-ID: <CACxE24myaFx4EF8Vr-k_pvd3KO_7sqNe7e-4DL=e23O4Qf1fKw@mail.gmail.com>

This is great....I have wonderful ideas/examples to work with.

Thanks to all!


On Fri, Nov 6, 2015 at 2:13 PM, ProfJCNash <profjcnash at gmail.com> wrote:

> It's not a full book on the issue, but I have some material in "speeding
> things up" in my book on Nonlinear parameter estimation tools in R. I
> suspect the examples are the useful bit.
>
> JN
>
> On 15-11-06 12:17 PM, Erin Hodgess wrote:
> > Great..thanks for the package names.  I was going to use the "Writing R
> > Extensions" but wanted some more material as well.  Looking at the other
> > packages might just do the trick.
> >
> > Thanks,
> > Erin
> >
> >
> > On Fri, Nov 6, 2015 at 10:59 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
> >
> >>
> >>> On 6 Nov 2015, at 17:23, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >>>
> >>> Hello everyone!
> >>>
> >>> Could someone recommend a good reference for Fortran with R, please?  I
> >>> know that Dirk has an excellent book for C/C++, but I feel more
> >> comfortable
> >>> with Fortran (I'm old school, maybe just old!)
> >>>
> >>
> >> I don't know about a book.
> >> The best you can do is read Writing R Extensions.
> >> And have a look at packages using Fortran:  nleqslv, geigen, QZ,
> deSolve,
> >> minpack.lm, PEIP
> >> That should give you a good idea how to use Fortran.
> >> There are surely more but these are the ones I know about.
> >>
> >> Berend
> >>
> >>> Thank you very much in advance,
> >>> Sincerely,
> >>> Erin
> >>>
> >>>
> >>> --
> >>> Erin Hodgess
> >>> Associate Professor
> >>> Department of Mathematical and Statistics
> >>> University of Houston - Downtown
> >>> mailto: erinm.hodgess at gmail.com
> >>>
> >>>       [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
> >
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From kydaviddoyle at gmail.com  Fri Nov  6 23:04:54 2015
From: kydaviddoyle at gmail.com (David Doyle)
Date: Fri, 6 Nov 2015 16:04:54 -0600
Subject: [R] ggplot2 different Y axis scales
Message-ID: <CACftpvqaZkYhy3rS+v6pOO01RmNQELBSkCC9++VpOEuRddWyxA@mail.gmail.com>

Hello Everyone,

I'm using the following code to plot sulfate concentrations vs. time for
several groundwater wells at one time.  Normally I need the scales to all
be the same but in the case of sulfate I need to use a different scale for
each well.  This is because some of my wells have very high / wide ranges
(MW04 ranges from 4 - 3,000) where some have very small ranges (MW06 ranges
from 13 - 34).

Is there a way that I can  have qqplot2 automatically scale each well or a
way I could enter a scale range.?  For example I would like MW04 to have a
Y axis scale from 0 - 3,000 and MW06 to have a Y axis scale from 0 - 40

I am using
RStudio version 0.99.484
R i386 3.2.2
ggplott2 ver 1.0.1
in a Windows 7 environment.

Thank you for your time
David Doyle


library(ggplot2)
SS <-read.csv("http://doylesdartden.com/Stats/SS.csv", sep=",")

#Sets whic are detections and nondetects
SS$Detections <- ifelse(SS$D_Sulfate==1, "Detected", "NonDetect")
png(file="Sulfate.png",width=2400,height=3000,res=300)
#does the plot
p <- ggplot(data = SS, aes(x=Year, y=Sulfate, col=Detections)) +
  geom_point(aes(shape=Detections))  +

  ##sets the colors
  scale_colour_manual(values=c("black","red")) +

  #location of the legend
  theme(legend.position=c("none")) +

  #sets the line color, type and size
  geom_line(colour="black", linetype="dotted", size=0.5) +
  ylab("Sulfate (mg/L)") +
  ##Graph title
  ggtitle("Figure 6-30
          Sandstone Sulfate Time Series")

## does the graph using the Well IDs as the different wells.
p + facet_grid(Well ~ .)
dev.off()

	[[alternative HTML version deleted]]


From NordlDJ at dshs.wa.gov  Fri Nov  6 23:19:43 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 6 Nov 2015 22:19:43 +0000
Subject: [R] cannot install RWinEdt
In-Reply-To: <563C4688.8000502@statistik.tu-dortmund.de>
References: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA27662EDB286A@WAXMXOLYMB025.WAX.wa.lcl>
	<563C4688.8000502@statistik.tu-dortmund.de>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662EDB2B7B@WAXMXOLYMB025.WAX.wa.lcl>

Uwe,

When I tried to install RWinEdt (R-3.2.2 installed from CRAN binary, Win 7), I got the following message:

> utils:::menuInstallPkgs()
Package which is only available in source form, and may need
  compilation of C/C++/Fortran: ?RWinEdt?
Do you want to attempt to install these from sources?


So, I find the package listed on CRAN but there appears to be only source there, not a binary. I tried a few different mirrors with the same result.  What have I missed?


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de] 
Sent: Thursday, November 05, 2015 10:20 PM
To: Nordlund, Dan (DSHS/RDA); r-help at r-project.org
Subject: Re: [R] cannot install RWinEdt



On 06.11.2015 02:06, Nordlund, Dan (DSHS/RDA) wrote:
> You might want to upgrade to R-3.2.2 as there appears to be a RWinEdt binary available for it.

There is also a binary for the R-3.1.x series, hence 
install.packages("RWinEdt") should do the trick.


Anyway, if you want to install from sources, please instal the Rtools 
and also install with the --no-test-load flag (RWinEdt complains if 
called non-interactively).

Best,
Uwe Ligges




> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cynthia Yeung - NOAA Federal
> Sent: Thursday, November 05, 2015 3:18 PM
> To: r-help at r-project.org
> Subject: [R] cannot install RWinEdt
>
> I am an intermediate R user with little understanding of the working of R packages.
> My problem is with the package RWinEdt.
>
> I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7 rather smoothly.
> Then I got a brand new computer,still running windows 7.
> I installed R 3.1.3, no new packages except the base packages.
> I installed WinEdt 6.
> I cannot get RWinEdt to install.
> I tried:
> RWinEdt_2.0-4.tar.gz
> RWinEdt2.0-0.zip
> RWinEdt_1.6-2.zip
> nothing worked.
>
> Error messages from trying different strategies include:
>
> ******* 1 ********
>> install.packages("RWinEdt", type="source")
> trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
> Content type 'application/x-gzip' length 590307 bytes (576 KB) opened URL downloaded 576 KB
>
> * installing *source* package 'RWinEdt' ...
> ** package 'RWinEdt' successfully unpacked and MD5 sums checked
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
>
> The downloaded source packages are in
>          ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
> C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
> had status 1
> 2: In install.packages("RWinEdt", type = "source") :
>    installation of package ?RWinEdt? had non-zero exit status
>> library(RWinEdt)
> Error in library(RWinEdt) : there is no package called ?RWinEdt?
>> utils:::menuInstallPkgs()
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>    no packages were specified
>
> ******************
>
> ******* 2 ********
>> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos
>> =
> NULL, type="source")
> * installing *source* package 'RWinEdt' ...
> ** libs
>
> *** arch - i386
> Warning: running command 'make -f "Makevars.win" -f "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> OBJECTS="ismdi.o"' had status 127
> ERROR: compilation failed for package 'RWinEdt'
> * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l "C:\Program Files\R\R-3.1.3\library"
> "D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
> 2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
>    installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz? had non-zero exit status
>> utils:::menuInstallLocal()
> package ?RWinEdt? successfully unpacked and MD5 sums checked
>> library(RWinEdt)
> Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
>> install.packages('RWinEdt')
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> Warning message:
> package ?RWinEdt? is not available (as a binary package for R version
> 3.1.3)
>
> ******************
>
> ******* 3 ********
>> install.packages('RWinEdt')
> Warning: unable to access index for repository
> http://www.rforge.net/bin/windows/contrib/3.1
>
>     package ?RWinEdt? is available as a source package but not as a binary
>
> ******************
>
> Appreciate any help.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From cynthia.yeung at noaa.gov  Fri Nov  6 23:57:35 2015
From: cynthia.yeung at noaa.gov (Cynthia Yeung - NOAA Federal)
Date: Fri, 6 Nov 2015 14:57:35 -0800
Subject: [R] cannot install RWinEdt
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27662EDB2B7B@WAXMXOLYMB025.WAX.wa.lcl>
References: <CAP6z9nk4mDHAnOE=Nn6Xe6kA2_re8AiOaWW=GRyiuOLg8-8r=Q@mail.gmail.com>
	<F7E6D18CC2877149AB5296CE54EA27662EDB286A@WAXMXOLYMB025.WAX.wa.lcl>
	<563C4688.8000502@statistik.tu-dortmund.de>
	<F7E6D18CC2877149AB5296CE54EA27662EDB2B7B@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <CAP6z9nnqoipyAkoGVMBt7DzSmba=TLLMBEbDeqmzMO10jHYE1w@mail.gmail.com>

I have tried all different options - compile from source, Rtools, binary,
RWinEdt versions <2.0 and current - on both R 3.1.2 and R 3.2.2.  All have
failed with error
messages as follows:

--------------------------------- 1-------------------------------------
install from binary from drop down menu in Rconsole
> utils:::menuInstallPkgs()
Package which is only available in source form, and may need
  compilation of C/C++/Fortran: ?RWinEdt?
  These will not be installed

---------------------------------- 2 --------------------------------------
from CRAN

> install.packages("RWinEdt", type="source")
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
Content type 'application/x-gzip' length 590307 bytes (576 KB)
downloaded 576 KB

* installing *source* package 'RWinEdt' ...
** package 'RWinEdt' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f
"C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f
"C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.2.2/library/RWinEdt'

The downloaded source packages are in

?C:\Users\cynthia.yeung\AppData\Local\Temp\Rtmps197CM\downloaded_packages?
Warning messages:
1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l
"C:\Program Files\R\R-3.2.2\library"
C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\Rtmps197CM/downloaded_packages/RWinEdt_2.0-5.tar.gz'
had status 1
2: In install.packages("RWinEdt", type = "source") :
  installation of package ?RWinEdt? had non-zero exit status

---------------------------------- 3 --------------------------------------
from local directory


install.packages("D:/Documents/Downloads/RWinEdt_2.0-4.tar.gz", repos =
NULL, type="source")
* installing *source* package 'RWinEdt' ...
** package 'RWinEdt' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
Warning: running command 'make -f "Makevars.win" -f
"C:/PROGRA~1/R/R-32~1.2/etc/i386/Makeconf" -f
"C:/PROGRA~1/R/R-32~1.2/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
OBJECTS="ismdi.o"' had status 127
ERROR: compilation failed for package 'RWinEdt'
* removing 'C:/Program Files/R/R-3.2.2/library/RWinEdt'
Warning messages:
1: running command '"C:/PROGRA~1/R/R-32~1.2/bin/x64/R" CMD INSTALL -l
"C:\Program Files\R\R-3.2.2\library"
"D:/Documents/Downloads/RWinEdt_2.0-4.tar.gz"' had status 1
2: In install.packages("D:/Documents/Downloads/RWinEdt_2.0-4.tar.gz",  :
  installation of package ?D:/Documents/Downloads/RWinEdt_2.0-4.tar.gz? had
non-zero

On Fri, Nov 6, 2015 at 2:19 PM, Nordlund, Dan (DSHS/RDA) <
NordlDJ at dshs.wa.gov> wrote:

> Uwe,
>
> When I tried to install RWinEdt (R-3.2.2 installed from CRAN binary, Win
> 7), I got the following message:
>
> > utils:::menuInstallPkgs()
> Package which is only available in source form, and may need
>   compilation of C/C++/Fortran: ?RWinEdt?
> Do you want to attempt to install these from sources?
>
>
> So, I find the package listed on CRAN but there appears to be only source
> there, not a binary. I tried a few different mirrors with the same result.
> What have I missed?
>
>
> Dan
>
> Daniel Nordlund, PhD
> Research and Data Analysis Division
> Services & Enterprise Support Administration
> Washington State Department of Social and Health Services
>
>
> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de]
> Sent: Thursday, November 05, 2015 10:20 PM
> To: Nordlund, Dan (DSHS/RDA); r-help at r-project.org
> Subject: Re: [R] cannot install RWinEdt
>
>
>
> On 06.11.2015 02:06, Nordlund, Dan (DSHS/RDA) wrote:
> > You might want to upgrade to R-3.2.2 as there appears to be a RWinEdt
> binary available for it.
>
> There is also a binary for the R-3.1.x series, hence
> install.packages("RWinEdt") should do the trick.
>
>
> Anyway, if you want to install from sources, please instal the Rtools
> and also install with the --no-test-load flag (RWinEdt complains if
> called non-interactively).
>
> Best,
> Uwe Ligges
>
>
>
>
> > Dan
> >
> > Daniel Nordlund, PhD
> > Research and Data Analysis Division
> > Services & Enterprise Support Administration
> > Washington State Department of Social and Health Services
> >
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cynthia
> Yeung - NOAA Federal
> > Sent: Thursday, November 05, 2015 3:18 PM
> > To: r-help at r-project.org
> > Subject: [R] cannot install RWinEdt
> >
> > I am an intermediate R user with little understanding of the working of
> R packages.
> > My problem is with the package RWinEdt.
> >
> > I was using using WinEdt 6 with R 3.1.3 and R-Sweave-6 in Windows 7
> rather smoothly.
> > Then I got a brand new computer,still running windows 7.
> > I installed R 3.1.3, no new packages except the base packages.
> > I installed WinEdt 6.
> > I cannot get RWinEdt to install.
> > I tried:
> > RWinEdt_2.0-4.tar.gz
> > RWinEdt2.0-0.zip
> > RWinEdt_1.6-2.zip
> > nothing worked.
> >
> > Error messages from trying different strategies include:
> >
> > ******* 1 ********
> >> install.packages("RWinEdt", type="source")
> > trying URL 'http://cran.fhcrc.org/src/contrib/RWinEdt_2.0-5.tar.gz'
> > Content type 'application/x-gzip' length 590307 bytes (576 KB) opened
> URL downloaded 576 KB
> >
> > * installing *source* package 'RWinEdt' ...
> > ** package 'RWinEdt' successfully unpacked and MD5 sums checked
> > ** libs
> >
> > *** arch - i386
> > Warning: running command 'make -f "Makevars.win" -f
> "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
> "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> > OBJECTS="ismdi.o"' had status 127
> > ERROR: compilation failed for package 'RWinEdt'
> > * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
> >
> > The downloaded source packages are in
> >          ?C:\Users\cy\AppData\Local\Temp\RtmpgdAJ2x\downloaded_packages?
> > Warning messages:
> > 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.1.3\library"
> >
> C:\Users\CYNTHI~1.YEU\AppData\Local\Temp\RtmpgdAJ2x/downloaded_packages/RWinEdt_2.0-5.tar.gz'
> > had status 1
> > 2: In install.packages("RWinEdt", type = "source") :
> >    installation of package ?RWinEdt? had non-zero exit status
> >> library(RWinEdt)
> > Error in library(RWinEdt) : there is no package called ?RWinEdt?
> >> utils:::menuInstallPkgs()
> > Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
> =
> > type) :
> >    no packages were specified
> >
> > ******************
> >
> > ******* 2 ********
> >> install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz", repos
> >> =
> > NULL, type="source")
> > * installing *source* package 'RWinEdt' ...
> > ** libs
> >
> > *** arch - i386
> > Warning: running command 'make -f "Makevars.win" -f
> "C:/PROGRA~1/R/R-31~1.3/etc/i386/Makeconf" -f
> "C:/PROGRA~1/R/R-31~1.3/share/make/winshlib.mk" SHLIB="RWinEdt.dll"
> > OBJECTS="ismdi.o"' had status 127
> > ERROR: compilation failed for package 'RWinEdt'
> > * removing 'C:/Program Files/R/R-3.1.3/library/RWinEdt'
> > Warning messages:
> > 1: running command '"C:/PROGRA~1/R/R-31~1.3/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.1.3\library"
> > "D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz"' had status 1
> > 2: In install.packages("D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz",  :
> >    installation of package ?D:/Documents/Downloads/RWinEdt_1.8-3.tar.gz?
> had non-zero exit status
> >> utils:::menuInstallLocal()
> > package ?RWinEdt? successfully unpacked and MD5 sums checked
> >> library(RWinEdt)
> > Error: package ?RWinEdt? was built before R 3.0.0: please re-install it
> >> install.packages('RWinEdt')
> >
> >     package ?RWinEdt? is available as a source package but not as a
> binary
> >
> > Warning message:
> > package ?RWinEdt? is not available (as a binary package for R version
> > 3.1.3)
> >
> > ******************
> >
> > ******* 3 ********
> >> install.packages('RWinEdt')
> > Warning: unable to access index for repository
> > http://www.rforge.net/bin/windows/contrib/3.1
> >
> >     package ?RWinEdt? is available as a source package but not as a
> binary
> >
> > ******************
> >
> > Appreciate any help.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From clark.richards at gmail.com  Fri Nov  6 20:42:42 2015
From: clark.richards at gmail.com (clark richards)
Date: Fri, 6 Nov 2015 14:42:42 -0500
Subject: [R] Attempting to plot two different time series together
Message-ID: <CAJx09A=VW5hJ0tSBbgp3QvfvFP_X+o7vVv-Cm6Br2NUOsaWSSw@mail.gmail.com>

Hi Ezra,

Since each dataset is for a different variable, I think your best bet is to
make a "two-panel" plot, but stacked so the time axes line up. This doesn't
require anything fancy to do with the fact the series are sampled at
different intervals. You may need to decimate or interpolate for other
analysis, but at least for plotting, I'd do something like the following.

Note my example uses the `oce` package both for specific plotting methods
(met and sealevel objects) as well as a couple of example datasets. For the
wind plot, I wrote a simple little function that makes an "arrow" plot,
where the length of the arrow is the wind speed and the angle is the
direction (be careful of meteorological vs oceanographic convention on
direction):

library(oce)
data(sealevelTuktoyaktuk)
data(met)

windArrow <- function(x, scale=1, xlim, ylim, ylab, type=1, cex=0.1, ...) {
    oce.plot.ts(x[['time']], x[['v']], type='n',
                ylab=if (missing(ylab)) 'Wind speed' else ylab,
                xlim=xlim, ylim=ylim, xaxs='i')
    drawDirectionField(x[['time']], rep(0, length(x[['time']])),
                       x[['u']], x[['v']], scaley=scale, add=TRUE,
                       type=type, cex=cex, ...)
}

## change the met times to line up with sealevel
met[['time']] <- met[['time']] - met[['time']][1] +
sealevelTuktoyaktuk[['time']][1]

par(mfrow=c(2, 1))
windArrow(met)
plot(sealevelTuktoyaktuk, which=1, xlim=range(met[['time']]))



> Message: 5
> Date: Thu, 5 Nov 2015 09:00:18 -0600
> From: Ezra Boyd <ezgis76 at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Attempting to plot two different time series together
> Message-ID:
>         <CAKa8D7RVg-TfD0PipNA2Q9LixahLMF21cEQ0axHYq1KyWH6=
> Qg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Hello,
>
> I am trying to create a plot (I guess two plots) using two different time
> series datasets, but I'm not sure of the best approach.  The data is from a
> tidal surge due to a hurricane and I would like to show the relationship
> between stage and windspeed/direction.
>
> One dataset is the tidal stage and it is sampled in 30 minutes intervals.
> The other dataset is windspeed and direction and it is sampled every 6
> minutes.  I would like to display the tidal hydrograph and then also show
> windspeed and direction as a banner above it.  They would be two separate
> plots, but with identical x-axis (as opposed to one plot that has both tide
> & wind.)
>
> Should I combine the two time series into one dataframe (with lots of NAs)
> so that I can create the plots together, for example using pairs or
> ggpairs? Or should I keep them separate, make the individual plots, and
> then work on the layout in graphic design software? I would prefer the
> former, but I just can't figure out how to make that work out.
>
> Also, is it possible to depict wind direction (which is given in degree
> clockwise from due north) with an arrow?
>
> Thank you very much,
>
> Ezra
>
> --
> Ezra Boyd, PhD
> DisasterMap.net, LLC <http://DisasterMap.net>
> ezgis <ezgis76 at gmail.com>76 at gmail.com <ezgis76 at gmail.com>
> (504)533-4447
>
>

	[[alternative HTML version deleted]]


From sch298 at g.uky.edu  Fri Nov  6 20:22:13 2015
From: sch298 at g.uky.edu (Chattopadhyay, Somsubhra)
Date: Fri, 6 Nov 2015 14:22:13 -0500
Subject: [R] Changing text file to .r format
Message-ID: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>

Dear all,

I am a beginner in R and want to ask a simple question. I have a code file
in text format which I need to change to .r format only. For example now it
is RHtestsV4.r.txt which needs to be changed to just RHtestsV4.r. I tried
this

sub("^([^.]*).*", "\\1", 'RHtestsV4.r.txt')
[1] "RHtestsV4"

But this didn't seem to work as again when I try to call the function using
source("RHtestsV4.r")
The error message is

Error in file(filename, "r", encoding = encoding) :
  cannot open the connection
In addition: Warning message:
In file(filename, "r", encoding = encoding) :
  cannot open file 'RHtestsV4.r': No such file or directory

I think it is due to the format of the file. Please help me to convert the
file to .r format.

Thanks
Som
-- 
Somsubhra Chattopadhyay
Graduate Research Assistant
Biosystem and Agricultural Engineering Department
University of Kentucky, Lexington, KY 40546
Email: schattop14 at uky.edu
Cell: 9198026951

	[[alternative HTML version deleted]]


From deepthitheresa at gmail.com  Fri Nov  6 22:26:21 2015
From: deepthitheresa at gmail.com (Deepthi Theresa)
Date: Fri, 6 Nov 2015 14:26:21 -0700
Subject: [R] Dataframes - Integer and decimal in same column?
Message-ID: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>

Hi all,

My question is about R dataframes. I am making html reports using R
datframe tables and RMarkdown.

I have a dataframe with integer values on it and I had to rbind another
dataframe with decimal values with the first dataframe.

After the rbind function all values changed to decimal values.  Can we keep
integer and decimal numbers in the same column?  Or at least round some of
the decimal rows to zero decimal point.  anything works.  I just want to
show the integer rows as integer values and decimal rows as decimal
values.

Thanks,
Deepthi
----------------------------------------------------------------------------------------------------------------

Deepthi Theresa Thomas Kannanayakal
Email: deepthitheresa at gmail.com

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Nov  7 00:28:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 06 Nov 2015 15:28:10 -0800
Subject: [R] ggplot2 different Y axis scales
In-Reply-To: <CACftpvqaZkYhy3rS+v6pOO01RmNQELBSkCC9++VpOEuRddWyxA@mail.gmail.com>
References: <CACftpvqaZkYhy3rS+v6pOO01RmNQELBSkCC9++VpOEuRddWyxA@mail.gmail.com>
Message-ID: <84DCDFF5-3187-4562-8121-B12A3F950F67@dcn.davis.CA.us>

Read the help for facet_grid, in particular about the scale parameter. I don't think you can individually control it though. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2015 2:04:54 PM PST, David Doyle <kydaviddoyle at gmail.com> wrote:
>Hello Everyone,
>
>I'm using the following code to plot sulfate concentrations vs. time
>for
>several groundwater wells at one time.  Normally I need the scales to
>all
>be the same but in the case of sulfate I need to use a different scale
>for
>each well.  This is because some of my wells have very high / wide
>ranges
>(MW04 ranges from 4 - 3,000) where some have very small ranges (MW06
>ranges
>from 13 - 34).
>
>Is there a way that I can  have qqplot2 automatically scale each well
>or a
>way I could enter a scale range.?  For example I would like MW04 to
>have a
>Y axis scale from 0 - 3,000 and MW06 to have a Y axis scale from 0 - 40
>
>I am using
>RStudio version 0.99.484
>R i386 3.2.2
>ggplott2 ver 1.0.1
>in a Windows 7 environment.
>
>Thank you for your time
>David Doyle
>
>
>library(ggplot2)
>SS <-read.csv("http://doylesdartden.com/Stats/SS.csv", sep=",")
>
>#Sets whic are detections and nondetects
>SS$Detections <- ifelse(SS$D_Sulfate==1, "Detected", "NonDetect")
>png(file="Sulfate.png",width=2400,height=3000,res=300)
>#does the plot
>p <- ggplot(data = SS, aes(x=Year, y=Sulfate, col=Detections)) +
>  geom_point(aes(shape=Detections))  +
>
>  ##sets the colors
>  scale_colour_manual(values=c("black","red")) +
>
>  #location of the legend
>  theme(legend.position=c("none")) +
>
>  #sets the line color, type and size
>  geom_line(colour="black", linetype="dotted", size=0.5) +
>  ylab("Sulfate (mg/L)") +
>  ##Graph title
>  ggtitle("Figure 6-30
>          Sandstone Sulfate Time Series")
>
>## does the graph using the Well IDs as the different wells.
>p + facet_grid(Well ~ .)
>dev.off()
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Sat Nov  7 00:38:44 2015
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 6 Nov 2015 15:38:44 -0800
Subject: [R] Changing text file to .r format
In-Reply-To: <CAFDcVCSh2UvyndDhXx2q+GwNn1BQvQat0VZoOeLk1OiZKKnZaw@mail.gmail.com>
References: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
	<CAFDcVCSh2UvyndDhXx2q+GwNn1BQvQat0VZoOeLk1OiZKKnZaw@mail.gmail.com>
Message-ID: <CAFDcVCToFPxNh4J_nGdKSrinOUEh_R9OYB3nGps6FEqdRBpOsw@mail.gmail.com>

My guess is that your on Windows. If so, make sure to change settings in
Explorer to always show filename extensions, because now I think it drops
.txt when it lists/displays your files (this is one of the most annoying
features in Windows).

Also, some basic editors add .txt extension when you save a file the first
time. You can try to put quotation marks to force it not to, e.g.
"RHtestsV4.r".

Henrik
On Nov 6, 2015 15:23, "Chattopadhyay, Somsubhra" <sch298 at g.uky.edu> wrote:

Dear all,

I am a beginner in R and want to ask a simple question. I have a code file
in text format which I need to change to .r format only. For example now it
is RHtestsV4.r.txt which needs to be changed to just RHtestsV4.r. I tried
this

sub("^([^.]*).*", "\\1", 'RHtestsV4.r.txt')
[1] "RHtestsV4"

But this didn't seem to work as again when I try to call the function using
source("RHtestsV4.r")
The error message is

Error in file(filename, "r", encoding = encoding) :
  cannot open the connection
In addition: Warning message:
In file(filename, "r", encoding = encoding) :
  cannot open file 'RHtestsV4.r': No such file or directory

I think it is due to the format of the file. Please help me to convert the
file to .r format.

Thanks
Som
--
Somsubhra Chattopadhyay
Graduate Research Assistant
Biosystem and Agricultural Engineering Department
University of Kentucky, Lexington, KY 40546
Email: schattop14 at uky.edu
Cell: 9198026951

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Nov  7 00:44:52 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 6 Nov 2015 17:44:52 -0600
Subject: [R] Dataframes - Integer and decimal in same column?
In-Reply-To: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>
References: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>
Message-ID: <563D3B74.5050201@gmail.com>

On 06/11/2015 3:26 PM, Deepthi Theresa wrote:
> Hi all,
>
> My question is about R dataframes. I am making html reports using R
> datframe tables and RMarkdown.
>
> I have a dataframe with integer values on it and I had to rbind another
> dataframe with decimal values with the first dataframe.
>
> After the rbind function all values changed to decimal values.  Can we keep
> integer and decimal numbers in the same column?  Or at least round some of
> the decimal rows to zero decimal point.  anything works.  I just want to
> show the integer rows as integer values and decimal rows as decimal
> values.
>

There are two issues here.

There is the type of the value, and the format for displaying it.

You can't mix integer type data and floating point data in the same 
column.  The integer values will be converted to floating point.

R by default displays floating point values with the same number of 
decimal places throughout the column, so data.frame(x = c(1, 1.1)) will 
display as

     x
1 1.0
2 1.1

and I think this is what you want to avoid.  There are a few ways to do 
this, but the easiest is to convert the column to character using 
whatever format you want, e.g.

data.frame(y = c(as.character(1), as.character(1.1)))

will display as

     y
1   1
2 1.1

If the numbers are already in the same column, you could do it as

data.frame(z = sprintf("%g", c(1, 1.1)))

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Sat Nov  7 00:45:49 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 06 Nov 2015 15:45:49 -0800
Subject: [R] Dataframes - Integer and decimal in same column?
In-Reply-To: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>
References: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>
Message-ID: <822FC54D-3A51-48DE-BEC6-D210BC5FAE75@dcn.davis.CA.us>

It is a very fundamental fact about data frames that they are COLUMNS of like data. If you have specific row-oriented requirements then you will need to build a data frame or matrix of character strings of formatted data. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2015 1:26:21 PM PST, Deepthi Theresa <deepthitheresa at gmail.com> wrote:
>Hi all,
>
>My question is about R dataframes. I am making html reports using R
>datframe tables and RMarkdown.
>
>I have a dataframe with integer values on it and I had to rbind another
>dataframe with decimal values with the first dataframe.
>
>After the rbind function all values changed to decimal values.  Can we
>keep
>integer and decimal numbers in the same column?  Or at least round some
>of
>the decimal rows to zero decimal point.  anything works.  I just want
>to
>show the integer rows as integer values and decimal rows as decimal
>values.
>
>Thanks,
>Deepthi
>----------------------------------------------------------------------------------------------------------------
>
>Deepthi Theresa Thomas Kannanayakal
>Email: deepthitheresa at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Nov  7 00:48:55 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 06 Nov 2015 15:48:55 -0800
Subject: [R] Changing text file to .r format
In-Reply-To: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
References: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
Message-ID: <7A50AD02-4FF6-4971-842C-F1B4ACB46F04@dcn.davis.CA.us>

Perhaps this would be a good time to use your operating system capabilities to change the name of the file.  All you have been doing is mucking with data in R without affecting the actual file name. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2015 11:22:13 AM PST, "Chattopadhyay, Somsubhra" <sch298 at g.uky.edu> wrote:
>Dear all,
>
>I am a beginner in R and want to ask a simple question. I have a code
>file
>in text format which I need to change to .r format only. For example
>now it
>is RHtestsV4.r.txt which needs to be changed to just RHtestsV4.r. I
>tried
>this
>
>sub("^([^.]*).*", "\\1", 'RHtestsV4.r.txt')
>[1] "RHtestsV4"
>
>But this didn't seem to work as again when I try to call the function
>using
>source("RHtestsV4.r")
>The error message is
>
>Error in file(filename, "r", encoding = encoding) :
>  cannot open the connection
>In addition: Warning message:
>In file(filename, "r", encoding = encoding) :
>  cannot open file 'RHtestsV4.r': No such file or directory
>
>I think it is due to the format of the file. Please help me to convert
>the
>file to .r format.
>
>Thanks
>Som


From deepthitheresa at gmail.com  Sat Nov  7 00:54:39 2015
From: deepthitheresa at gmail.com (Deepthi Theresa)
Date: Fri, 6 Nov 2015 16:54:39 -0700
Subject: [R] Dataframes - Integer and decimal in same column?
In-Reply-To: <563D3B74.5050201@gmail.com>
References: <CALoQ5XxqFCd63=FUfC1RXAwEqzmA9McbxNcvJ8h8hpUnhmOtxg@mail.gmail.com>
	<563D3B74.5050201@gmail.com>
Message-ID: <CALoQ5XwU9EEgkbEJ=zVKLpYxvd-g_V45iiHCEJ+yONH4iq62Ag@mail.gmail.com>

Hello Duncan,

Thank you.

I completed the task using the exact way you described here.  Changed the
data frame in to a character type using apply function and complicated the
task.

Thanks,
Deepthi
On Nov 6, 2015 4:44 PM, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:

> On 06/11/2015 3:26 PM, Deepthi Theresa wrote:
>
>> Hi all,
>>
>> My question is about R dataframes. I am making html reports using R
>> datframe tables and RMarkdown.
>>
>> I have a dataframe with integer values on it and I had to rbind another
>> dataframe with decimal values with the first dataframe.
>>
>> After the rbind function all values changed to decimal values.  Can we
>> keep
>> integer and decimal numbers in the same column?  Or at least round some of
>> the decimal rows to zero decimal point.  anything works.  I just want to
>> show the integer rows as integer values and decimal rows as decimal
>> values.
>>
>>
> There are two issues here.
>
> There is the type of the value, and the format for displaying it.
>
> You can't mix integer type data and floating point data in the same
> column.  The integer values will be converted to floating point.
>
> R by default displays floating point values with the same number of
> decimal places throughout the column, so data.frame(x = c(1, 1.1)) will
> display as
>
>     x
> 1 1.0
> 2 1.1
>
> and I think this is what you want to avoid.  There are a few ways to do
> this, but the easiest is to convert the column to character using whatever
> format you want, e.g.
>
> data.frame(y = c(as.character(1), as.character(1.1)))
>
> will display as
>
>     y
> 1   1
> 2 1.1
>
> If the numbers are already in the same column, you could do it as
>
> data.frame(z = sprintf("%g", c(1, 1.1)))
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Sat Nov  7 01:18:39 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 6 Nov 2015 16:18:39 -0800
Subject: [R] Help scatterplot3d
In-Reply-To: <633022433.875402.1446819622602.JavaMail.yahoo@mail.yahoo.com>
References: <633022433.875402.1446819622602.javamail.yahoo.ref@mail.yahoo.com>
Message-ID: <6C5EE9A9CEA.00000C6Djrkrideau@inbox.com>


Please do not post in HTML. Your post is gibberish.

Also please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html  for some suggestions on asking questions in R-help.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: r-help at r-project.org
> Sent: Fri, 6 Nov 2015 14:20:22 +0000 (UTC)
> To: r-help at r-project.org
> Subject: [R] Help scatterplot3d
> 
> Hi, I'm running this script:
> library(scatterplot3d)datos<-read.csv("C:\\prueba.csv",sep=",",header=TRUE)str(datos)scatterplot3d(datos)
> s3d<- scatterplot3d(datos, type = "h", color = "blue", angle = 55,
> scale.y = 0.7, pch = 16, main = "title?)
> my.lm <- lm(datos$Bx ~ datos$e + datos$t)?s3d$plane3d(my.lm)
> ?I need to plot the experimental data ("datos") and the regression plane
> given by "my.lm" in the same figure.The script plots "datos" but it
> doesn't add the plot of the regression plane.?Sometimes I get a message
> like "s3d objet not found".
> Thanks a lot.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE 5GB EMAIL - Check out spam free email with many cool features!
Visit http://www.inbox.com/email to find out more!


From jdnewmil at dcn.davis.CA.us  Sat Nov  7 02:08:36 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 06 Nov 2015 17:08:36 -0800
Subject: [R] [GGplot] Geom_smooth with formula "power"?
In-Reply-To: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>
References: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>
Message-ID: <01E6DEB6-7F33-45B9-8C01-8BCF6D9906C5@dcn.davis.CA.us>

Does  [1] help? 

[1] http://stackoverflow.com/questions/10528631/add-exp-power-trend-line-to-a-ggplot
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 6, 2015 2:41:18 AM PST, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
>Hi,
>
>It's possible to use ggplot and geom_smooth to adjust a power curve to
>the
>data?
>
>Initially i have done the adjustement with nls and the formula 'a*x^b',
>but
>resulted the singular matrix error for start solution. Alternatively I
>used
>the log transformation and i had correct results, but I can't draw a
>power
>curve on the graphic.
>
>Someone know how to solve this problem?
>
> 
>
>Ty,
>
> 
>
>Catarina Silva  
>
>
>Imprima no nosso papel - Cuide do ambiente
>--------------------------
>Print on our paper - Care for the environment.
>--------------------------
>http://backoffice.portucelsoporcel.net/dynamic-media/files/utilizar_papel_e_promover_o_desenvolvimento_da_floresta.pdf
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Sat Nov  7 02:42:05 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Sat, 7 Nov 2015 10:42:05 +0900
Subject: [R] Changing text file to .r format
In-Reply-To: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
References: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
Message-ID: <CAAcyNCzTRwux3Z4NDtMk3Fmx0fah8BZWq28aHWWE-Hz7ezY+=g@mail.gmail.com>

For reference, also asked here:
http://stackoverflow.com/questions/33569737/unable-to-call-a-function-in-r


On Sat, Nov 7, 2015 at 4:22 AM, Chattopadhyay, Somsubhra
<sch298 at g.uky.edu> wrote:
> Dear all,
>
> I am a beginner in R and want to ask a simple question. I have a code file
> in text format which I need to change to .r format only. For example now it
> is RHtestsV4.r.txt which needs to be changed to just RHtestsV4.r. I tried
> this
>
> sub("^([^.]*).*", "\\1", 'RHtestsV4.r.txt')
> [1] "RHtestsV4"
>
> But this didn't seem to work as again when I try to call the function using
> source("RHtestsV4.r")
> The error message is
>
> Error in file(filename, "r", encoding = encoding) :
>   cannot open the connection
> In addition: Warning message:
> In file(filename, "r", encoding = encoding) :
>   cannot open file 'RHtestsV4.r': No such file or directory
>
> I think it is due to the format of the file. Please help me to convert the
> file to .r format.
>
> Thanks
> Som
> --
> Somsubhra Chattopadhyay
> Graduate Research Assistant
> Biosystem and Agricultural Engineering Department
> University of Kentucky, Lexington, KY 40546
> Email: schattop14 at uky.edu
> Cell: 9198026951
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From mashranga at yahoo.com  Sat Nov  7 04:56:53 2015
From: mashranga at yahoo.com (Mohammad Tanvir Ahamed)
Date: Sat, 7 Nov 2015 03:56:53 +0000 (UTC)
Subject: [R] Read a file on every 0.5 (or less) second intervall
References: <692911305.1199682.1446868613705.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <692911305.1199682.1446868613705.JavaMail.yahoo@mail.yahoo.com>

Hi,
i want to read a file on every 0.5 (or less) second.?How can i set this time loop to read a file ?
Any idea will be appreciated .?Thanks .??Tanvir Ahamed 
   G?teborg, Sweden     |  mashranga at yahoo.com
	[[alternative HTML version deleted]]


From spencer at spencerboucher.com  Sat Nov  7 00:34:16 2015
From: spencer at spencerboucher.com (Spencer Boucher)
Date: Fri, 06 Nov 2015 15:34:16 -0800
Subject: [R] Changing text file to .r format
In-Reply-To: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
References: <CAEZ46x+tJ6y=LaoY8+4yTnHf4HRt4SLAJ1EaPEeYwm5Z_jdf1w@mail.gmail.com>
Message-ID: <m2vb9ezoqv.fsf@spencerboucher.com>

 
There is no fundamental difference between an .R file and a .txt 
file. They are both just text files; all you are doing is changing 
the name. This Stack Overflow question shows how to use 
`file.rename` to do 
so. http://stackoverflow.com/a/10759083/1850696. 

Chattopadhyay, Somsubhra writes:

> Dear all, 
> 
> I am a beginner in R and want to ask a simple question. I have a 
> code file in text format which I need to change to .r format 
> only. For example now it is RHtestsV4.r.txt which needs to be 
> changed to just RHtestsV4.r. I tried this 
> 
> sub("^([^.]*).*", "\\1", 'RHtestsV4.r.txt') [1] "RHtestsV4" 
> 
> But this didn't seem to work as again when I try to call the 
> function using source("RHtestsV4.r") The error message is 
> 
> Error in file(filename, "r", encoding = encoding) : 
>   cannot open the connection 
> In addition: Warning message: In file(filename, "r", encoding = 
> encoding) : 
>   cannot open file 'RHtestsV4.r': No such file or directory 
> 
> I think it is due to the format of the file. Please help me to 
> convert the file to .r format. 
> 
> Thanks Som


From merricks.merricks at gmail.com  Sat Nov  7 04:48:04 2015
From: merricks.merricks at gmail.com (Margaret Donald)
Date: Sat, 7 Nov 2015 14:48:04 +1100
Subject: [R] Existence of an object
Message-ID: <CAM=LvPzhLYpzo5ue3J0fYv0tMHYt3c76ZcO3i1LWwkmMvEqVuw@mail.gmail.com>

I have a variable meanedf which may sometimes not be defined due to a
complex set of circumstances.
I would like to be able to find out whether or not it exists, and then
branch appropriately in my code.

I had hoped to be able to use is.null() or exists() but neither of these
returns TRUE or FALSE which is the behaviour I would like, so that I can
write some appropriate branching code.

is.null(meanedf)
Error: object 'meanedf' not found
No suitable frames for recover()

exists(meanedf)
Error in exists(meanedf) : object 'meanedf' not found

I would like some code which returns TRUE when meanedf exists and FALSE
when it doesn't.

Thanks, and regards,
Margaret Donald


-- 
Margaret Donald
Post Doctoral researcher
University of New South Wales
margaret.donald at unsw.edu.au
0405 834 550

	[[alternative HTML version deleted]]


From rainer.schuermann at gmx.net  Sat Nov  7 06:25:36 2015
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 7 Nov 2015 06:25:36 +0100
Subject: [R] Existence of an object
In-Reply-To: <CAM=LvPzhLYpzo5ue3J0fYv0tMHYt3c76ZcO3i1LWwkmMvEqVuw@mail.gmail.com>
References: <CAM=LvPzhLYpzo5ue3J0fYv0tMHYt3c76ZcO3i1LWwkmMvEqVuw@mail.gmail.com>
Message-ID: <201511070625.37187.rainer.schuermann@gmx.net>

For me,

"meanedf" %in% ls()

works:

meanedf <- 1
"meanedf" %in% ls()
[1] TRUE

rm( meanedf )
"meanedf" %in% ls()
[1] FALSE

Rgds,
Rainer


On Saturday 07 November 2015 04:48:04 Margaret Donald wrote:
> I have a variable meanedf which may sometimes not be defined due to a
> complex set of circumstances.
> I would like to be able to find out whether or not it exists, and then
> branch appropriately in my code.
> 
> I had hoped to be able to use is.null() or exists() but neither of these
> returns TRUE or FALSE which is the behaviour I would like, so that I can
> write some appropriate branching code.
> 
> is.null(meanedf)
> Error: object 'meanedf' not found
> No suitable frames for recover()
> 
> exists(meanedf)
> Error in exists(meanedf) : object 'meanedf' not found
> 
> I would like some code which returns TRUE when meanedf exists and FALSE
> when it doesn't.
> 
> Thanks, and regards,
> Margaret Donald
> 
> 
>


From rainer.schuermann at gmx.net  Sat Nov  7 06:27:35 2015
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 7 Nov 2015 06:27:35 +0100
Subject: [R] Existence of an object
In-Reply-To: <CAM=LvPzhLYpzo5ue3J0fYv0tMHYt3c76ZcO3i1LWwkmMvEqVuw@mail.gmail.com>
References: <CAM=LvPzhLYpzo5ue3J0fYv0tMHYt3c76ZcO3i1LWwkmMvEqVuw@mail.gmail.com>
Message-ID: <201511070627.35336.rainer.schuermann@gmx.net>

Quotation marks help also for exists():

exists( "meanedf" )
[1] TRUE


On Saturday 07 November 2015 04:48:04 Margaret Donald wrote:
> I have a variable meanedf which may sometimes not be defined due to a
> complex set of circumstances.
> I would like to be able to find out whether or not it exists, and then
> branch appropriately in my code.
> 
> I had hoped to be able to use is.null() or exists() but neither of these
> returns TRUE or FALSE which is the behaviour I would like, so that I can
> write some appropriate branching code.
> 
> is.null(meanedf)
> Error: object 'meanedf' not found
> No suitable frames for recover()
> 
> exists(meanedf)
> Error in exists(meanedf) : object 'meanedf' not found
> 
> I would like some code which returns TRUE when meanedf exists and FALSE
> when it doesn't.
> 
> Thanks, and regards,
> Margaret Donald
> 
> 
>


From jholtman at gmail.com  Sat Nov  7 11:17:39 2015
From: jholtman at gmail.com (jim holtman)
Date: Sat, 7 Nov 2015 05:17:39 -0500
Subject: [R] Read a file on every 0.5 (or less) second intervall
In-Reply-To: <692911305.1199682.1446868613705.JavaMail.yahoo@mail.yahoo.com>
References: <692911305.1199682.1446868613705.JavaMail.yahoo.ref@mail.yahoo.com>
	<692911305.1199682.1446868613705.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-5qnzPaGMGgiVgEPN7gair-vYT8FN3nMQi2uhOY7CtOaQ@mail.gmail.com>

?Sys.sleep


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Nov 6, 2015 at 10:56 PM, Mohammad Tanvir Ahamed via R-help <
r-help at r-project.org> wrote:

> Hi,
> i want to read a file on every 0.5 (or less) second. How can i set this
> time loop to read a file ?
> Any idea will be appreciated . Thanks .  Tanvir Ahamed
>    G?teborg, Sweden     |  mashranga at yahoo.com
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Nov  7 11:22:23 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 7 Nov 2015 11:22:23 +0100
Subject: [R] Read a file on every 0.5 (or less) second intervall
In-Reply-To: <692911305.1199682.1446868613705.JavaMail.yahoo@mail.yahoo.com>
References: <692911305.1199682.1446868613705.JavaMail.yahoo.ref@mail.yahoo.com>
	<692911305.1199682.1446868613705.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <AE26959C-EAE2-4531-84DB-794A6BF25DC0@gmail.com>


> On 07 Nov 2015, at 04:56 , Mohammad Tanvir Ahamed via R-help <r-help at r-project.org> wrote:
> 
> Hi,
> i want to read a file on every 0.5 (or less) second. How can i set this time loop to read a file ?
> Any idea will be appreciated . Thanks .  Tanvir Ahamed 

Sys.sleep() if exact timing is not too critical. Otherwise, using the tcltk packages, you can interface to the "after" Tcl command. The generic pattern is 

boo <- function() {if (running) tcl("after", 500, boo) ; cat("boo!\n")}
running <- TRUE; boo()

-pd



>   G?teborg, Sweden     |  mashranga at yahoo.com
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ragia11 at hotmail.com  Sat Nov  7 15:32:12 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 7 Nov 2015 16:32:12 +0200
Subject: [R] group by function
Message-ID: <DUB125-W32092764DFA9519D3E4946B3170@phx.gbl>

Dear group,
kindly, I have the following data frame

structure(c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 
3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1.5, 2, 1, 0, 2, 2, 1.5, 
0, 0, 1, 1, 2, 0, 1, 2), .Dim = c(15L, 3L), .Dimnames = list(
    NULL, c("i", "Measure_id", "value")))



it has 3 coulmns
I used 
    df$newcoulmn <-  ave(df$value, paste( df$i, df$Measure_id), FUN= function(x)   x/max(x) )


to get x /max(x) and calc probability.. but I want to do that for each source measure_id" separately  that means that rows 4,7,13 ..their value should be divided by 1.5 not 2..

rows 1,5,11 will be divided by  2 the max of their same group grouped by measure id 
 how to make such grouping

thanks in advance
Ragia 		 	   		  
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Nov  7 16:48:36 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 7 Nov 2015 07:48:36 -0800
Subject: [R] group by function
In-Reply-To: <DUB125-W32092764DFA9519D3E4946B3170@phx.gbl>
References: <DUB125-W32092764DFA9519D3E4946B3170@phx.gbl>
Message-ID: <CAGxFJbRhn4e1QMcV7XwkE=Hti25tsCxVwMeprKdrqWFxvkoJhw@mail.gmail.com>

??
 Row 4 has i = 2 and Measure_id =4 and therefore has value divided by
the max of all values with that i and Measure_id, which is 1. Row 7
has i =2 and Measure_id =2, and so is divided by the max value in all
rows with those values of i and Measure_id, which is 2. etc. So either
you do not understand ave() or you are incorrectly stating what you
want.

Incidentally, read ?ave, ?with and ?within. paste() is not needed and
the call can be shortened to

df <- within(df,newcol<-ave(value,i,Measure_id,FUN=function(x)x/max(x)))

Finally, I suggest you learn to post in plain text (as the posting
guide requests) to avoid possible mangling of your posts.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 7, 2015 at 6:32 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> Dear group,
> kindly, I have the following data frame
>
> structure(c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
> 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1.5, 2, 1, 0, 2, 2, 1.5,
> 0, 0, 1, 1, 2, 0, 1, 2), .Dim = c(15L, 3L), .Dimnames = list(
>     NULL, c("i", "Measure_id", "value")))
>
>
>
> it has 3 coulmns
> I used
>     df$newcoulmn <-  ave(df$value, paste( df$i, df$Measure_id), FUN= function(x)   x/max(x) )
>
>
> to get x /max(x) and calc probability.. but I want to do that for each source measure_id" separately  that means that rows 4,7,13 ..their value should be divided by 1.5 not 2..
>
> rows 1,5,11 will be divided by  2 the max of their same group grouped by measure id
>  how to make such grouping
>
> thanks in advance
> Ragia
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Sat Nov  7 16:58:28 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 7 Nov 2015 17:58:28 +0200
Subject: [R] group by function
In-Reply-To: <CAGxFJbRhn4e1QMcV7XwkE=Hti25tsCxVwMeprKdrqWFxvkoJhw@mail.gmail.com>
References: <DUB125-W32092764DFA9519D3E4946B3170@phx.gbl>,
	<CAGxFJbRhn4e1QMcV7XwkE=Hti25tsCxVwMeprKdrqWFxvkoJhw@mail.gmail.com>
Message-ID: <DUB125-W479C6BD0E00D16CF95528AB3170@phx.gbl>

many thanks for replying,
yes I am kindly accept my pardon, I mistaken the rows from each other.... many thanks I will read them.
Ragia?

----------------------------------------
> Date: Sat, 7 Nov 2015 07:48:36 -0800
> Subject: Re: [R] group by function
> From: bgunter.4567 at gmail.com
> To: ragia11 at hotmail.com
> CC: r-help at r-project.org
>
> ??
> Row 4 has i = 2 and Measure_id =4 and therefore has value divided by
> the max of all values with that i and Measure_id, which is 1. Row 7
> has i =2 and Measure_id =2, and so is divided by the max value in all
> rows with those values of i and Measure_id, which is 2. etc. So either
> you do not understand ave() or you are incorrectly stating what you
> want.
>
> Incidentally, read ?ave, ?with and ?within. paste() is not needed and
> the call can be shortened to
>
> df <- within(df,newcol<-ave(value,i,Measure_id,FUN=function(x)x/max(x)))
>
> Finally, I suggest you learn to post in plain text (as the posting
> guide requests) to avoid possible mangling of your posts.
>
> Cheers,
> Bert
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> -- Clifford Stoll
>
>
> On Sat, Nov 7, 2015 at 6:32 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>> Dear group,
>> kindly, I have the following data frame
>>
>> structure(c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,
>> 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1.5, 2, 1, 0, 2, 2, 1.5,
>> 0, 0, 1, 1, 2, 0, 1, 2), .Dim = c(15L, 3L), .Dimnames = list(
>> NULL, c("i", "Measure_id", "value")))
>>
>>
>>
>> it has 3 coulmns
>> I used
>> df$newcoulmn <- ave(df$value, paste( df$i, df$Measure_id), FUN= function(x) x/max(x) )
>>
>>
>> to get x /max(x) and calc probability.. but I want to do that for each source measure_id" separately that means that rows 4,7,13 ..their value should be divided by 1.5 not 2..
>>
>> rows 1,5,11 will be divided by 2 the max of their same group grouped by measure id
>> how to make such grouping
>>
>> thanks in advance
>> Ragia
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  

From stefano.sofia at regione.marche.it  Sat Nov  7 17:57:51 2015
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Sat, 7 Nov 2015 16:57:51 +0000
Subject: [R] How to change name of pdf output of function windRose in
 openair package
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFFC72@SRVEXCHMBX.precheza.cz>
References: <8B435C9568170B469AE31E8891E8CC4F3D4977B8@ESINO.regionemarche.intra>
	<CA+8X3fUToSY10O03WBRNSGfaqTssHcCypqN2zTRq46UGcGuqrQ@mail.gmail.com>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFFC72@SRVEXCHMBX.precheza.cz>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F3D497A40@ESINO.regionemarche.intra>

Thanks to Jim and to Petr for their suggestion.
Stefano

________________________________________
Da: PIKAL Petr [petr.pikal at precheza.cz]
Inviato: gioved? 5 novembre 2015 15.02
A: Stefano Sofia
Cc: r-help at r-project.org
Oggetto: RE: [R] How to change name of pdf output of function windRose in openair package

Hi

if you need to do naming automagically you can use ls for creating object consisting from names of objects and use it for naming inside a cycle.

obj <- ls()
for (i in 1:n) {
pdf(paste(obj[i], "pdf", sep="."))
...
do the plotting
dev.off()
}

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim
> Lemon
> Sent: Thursday, November 05, 2015 12:25 PM
> To: Stefano Sofia
> Cc: r-help at r-project.org
> Subject: Re: [R] How to change name of pdf output of function windRose
> in openair package
>
> Hi Stefano,
> Just start the PDF device, do the plot, then close the PDF device:
>
> library(openair)
> ...
> data(mydata)
> pdf("windRose.pdf")
> windRose(mydata)
> dev.off()
>
> This is from the first example for the windRose function. It will
> produce a file named "windRose.pdf" in the working directory of R.
>
> Jim
>
>
>
> On Thu, Nov 5, 2015 at 8:26 PM, Stefano Sofia <
> stefano.sofia at regione.marche.it> wrote:
>
> > Dear r-list users,
> > I am using windRose within the openair package.
> > Automatically the wind rose is saved in a pdf file called Rplots.pdf
> .
> >
> > I need to apply this function to different data frames, and each time
> > I need to change automatically the name of the pdf output.
> > I am not able to do it, I read the manual quite carefully but I
> didn't
> > find any hint about it.
> >
> > Would somebody be able to help me?
> > Thank you for your attention
> > Stefano
> >
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
> contenere
> > informazioni confidenziali, pertanto ? destinato solo a persone
> > autorizzate alla ricezione. I messaggi di posta elettronica per i
> > client di Regione Marche possono contenere informazioni confidenziali
> e con privilegi legali.
> > Se non si ? il destinatario specificato, non leggere, copiare,
> > inoltrare o archiviare questo messaggio. Se si ? ricevuto questo
> > messaggio per errore, inoltrarlo al mittente ed eliminarlo
> > completamente dal sistema del proprio computer. Ai sensi dell?art. 6
> > della DGR n. 1394/2008 si segnala che, in caso di necessit? ed
> > urgenza, la risposta al presente messaggio di posta elettronica pu?
> essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only
> > by persons entitled to receive the confidential information it may
> contain.
> > E-mail messages to clients of Regione Marche may contain information
> > that is confidential and legally privileged. Please do not read,
> copy,
> > forward, or store this message unless you are an intended recipient
> of
> > it. If you have received this message in error, please forward it to
> > the sender and delete it completely from your computer system.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From denizozonur at gazi.edu.tr  Sat Nov  7 18:12:32 2015
From: denizozonur at gazi.edu.tr (Deniz OZONUR)
Date: Sat, 7 Nov 2015 19:12:32 +0200 (EET)
Subject: [R] About error: L-BFGS-B needs finite values of 'fn'
Message-ID: <1309076219.1419596.1446916352477.JavaMail.root@gazi.edu.tr>

Hi,

I am trying to obtain power of Likelihood ratio test for comparing gamma distribution against generalized gamma distribution. And so I need maximum likelihood estimates of Generalized gamma distribution with three parameters. I wrote code as follows.

 require(bbmle)
 library("bbmle")

require(flexsurv)
library("flexsurv")

 sig=0.05
 den=1000
 n=30
 apar=2 ###alpha
 bpar=3 ##beta
 cpar=2 ##c parameter


 LRatio=function(den,n,par=c(cpar,apar,bpar)){

 LR2=rep(0,den)

 count=rep(0,den)

 cpar=par[1]
 apar=par[2]
 bpar=par[3]

 for(i in 1:den){

 y=rgengamma.orig(n,shape=cpar,scale=bpar,k=apar)

 gamma4 = function(shape, scale) {
  -sum(dgamma(y, shape = shape, scale = scale,log = TRUE))
 }

 gm = mean(y)
 cv = var(y)/mean(y)

 m5 = mle2(gamma4, start = list(shape = gm/cv, scale = cv),method = "L-BFGS-B", lower =c(.00001,.00001),upper = c(Inf,Inf))


 gengamma3 = function(shape, scale,k) {
 -sum(dgengamma.orig(y, shape = shape, scale = scale,k=k,log =TRUE))
 }

 ci=mean(y)            #c initial value
 a1=ci*mean(y)^(ci-1)
 a2=ci*(ci-1)*(mean(y)^(ci-1))/2
 mu1=mean(y)^ci+a2*mean(y^2)
 mu2=(a1^2)*mean(y^2)+2*a1*a2*mean(y^3)+(a2^2)*(mean(y^4)-mean(y^2)^2)
 alp =(mu1^2)/mu2                            #alpha initial value
 bet=mean(y)*gamma(alp)/gamma(alp+(1/ci))       #beta initial value

 m6 = mle2(gengamma3, start = list(shape = ci, scale = bet, k=alp),method = "L-BFGS-B", lower = c(.00001,.00001,.00001),upper = c(Inf, Inf, nf))


 LR2[i]=2*(logLik(m6)-logLik(m5))
 count[i]=LR2[i]>=qchisq(1-sig, df=1)

 }

 pow=sum(count)/den
 print(i)
 print(pow)
 }

 But I got error : optim(par = c(3.88907163215354, 3.62005456122935, 1.66499331462506 :  L-BFGS-B needs finite values of 'fn'


What is wrong? Can you hep me, thanks..
Deniz...


From profjcnash at gmail.com  Sat Nov  7 19:53:54 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Sat, 7 Nov 2015 13:53:54 -0500
Subject: [R] About error: L-BFGS-B needs finite values of 'fn'
In-Reply-To: <1309076219.1419596.1446916352477.JavaMail.root@gazi.edu.tr>
References: <1309076219.1419596.1446916352477.JavaMail.root@gazi.edu.tr>
Message-ID: <563E48C2.1080906@gmail.com>

Numerical gradient approximations are being used in your call, so my
guess is that the "epsilon" has made (parameter + epsilon) an
inadmissible argument for your likelihood. If you can supply analytical
gradients, the issue has a good chance of going away. Otherwise, you'll
need to use bounds or transformations to avoid the parameter region
giving undefined results.

JN

On 15-11-07 12:12 PM, Deniz OZONUR wrote:
> Hi,
> 
> I am trying to obtain power of Likelihood ratio test for comparing gamma distribution against generalized gamma distribution. And so I need maximum likelihood estimates of Generalized gamma distribution with three parameters. I wrote code as follows.
> 
>  require(bbmle)
>  library("bbmle")
> 
> require(flexsurv)
> library("flexsurv")
> 
>  sig=0.05
>  den=1000
>  n=30
>  apar=2 ###alpha
>  bpar=3 ##beta
>  cpar=2 ##c parameter
> 
> 
>  LRatio=function(den,n,par=c(cpar,apar,bpar)){
> 
>  LR2=rep(0,den)
> 
>  count=rep(0,den)
> 
>  cpar=par[1]
>  apar=par[2]
>  bpar=par[3]
> 
>  for(i in 1:den){
> 
>  y=rgengamma.orig(n,shape=cpar,scale=bpar,k=apar)
> 
>  gamma4 = function(shape, scale) {
>   -sum(dgamma(y, shape = shape, scale = scale,log = TRUE))
>  }
> 
>  gm = mean(y)
>  cv = var(y)/mean(y)
> 
>  m5 = mle2(gamma4, start = list(shape = gm/cv, scale = cv),method = "L-BFGS-B", lower =c(.00001,.00001),upper = c(Inf,Inf))
> 
> 
>  gengamma3 = function(shape, scale,k) {
>  -sum(dgengamma.orig(y, shape = shape, scale = scale,k=k,log =TRUE))
>  }
> 
>  ci=mean(y)            #c initial value
>  a1=ci*mean(y)^(ci-1)
>  a2=ci*(ci-1)*(mean(y)^(ci-1))/2
>  mu1=mean(y)^ci+a2*mean(y^2)
>  mu2=(a1^2)*mean(y^2)+2*a1*a2*mean(y^3)+(a2^2)*(mean(y^4)-mean(y^2)^2)
>  alp =(mu1^2)/mu2                            #alpha initial value
>  bet=mean(y)*gamma(alp)/gamma(alp+(1/ci))       #beta initial value
> 
>  m6 = mle2(gengamma3, start = list(shape = ci, scale = bet, k=alp),method = "L-BFGS-B", lower = c(.00001,.00001,.00001),upper = c(Inf, Inf, nf))
> 
> 
>  LR2[i]=2*(logLik(m6)-logLik(m5))
>  count[i]=LR2[i]>=qchisq(1-sig, df=1)
> 
>  }
> 
>  pow=sum(count)/den
>  print(i)
>  print(pow)
>  }
> 
>  But I got error : optim(par = c(3.88907163215354, 3.62005456122935, 1.66499331462506 :  L-BFGS-B needs finite values of 'fn'
> 
> 
> What is wrong? Can you hep me, thanks..
> Deniz...
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rsherry8 at comcast.net  Sun Nov  8 00:27:30 2015
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sat, 7 Nov 2015 18:27:30 -0500
Subject: [R] QuantMod and XML
Message-ID: <563E88E2.8080008@comcast.net>


I am trying to use the package quantmod to get option quotes in R. 
Therefore, I executed the following two commands:
         library ("quantmod" )
         getOptionChain("AAPL")
The first one worked but the second one produced the following error 
message:
         Error in getOptionChain.yahoo(Symbols = "AAPL") :
         package:?XML?cannot be loaded.
Therefore, I am thinking I need to install the package XML. To do so, I 
executed the following command:
         install.packages( "XML" )
However, that command failed because it could not find the package XML. 
The following URL:
         https://cran.r-project.org/web/packages/XML/XML.pdf
indicates to me that it does exist.

I am hoping somebody can tell me what I am doing wrong.

Thanks
Bob


From hasan.diwan at gmail.com  Sun Nov  8 00:41:39 2015
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Sat, 7 Nov 2015 15:41:39 -0800
Subject: [R] QuantMod and XML
In-Reply-To: <563E88E2.8080008@comcast.net>
References: <563E88E2.8080008@comcast.net>
Message-ID: <CAP+bYWB5aayp6xSwNqBuEO=pg-bf0nJ5aF=rbpDjzhRxYr0QuQ@mail.gmail.com>

Bob,

On 7 November 2015 at 15:27, Robert Sherry <rsherry8 at comcast.net> wrote:

>
> I am trying to use the package quantmod to get option quotes in R.
> Therefore, I executed the following two commands:
>         library ("quantmod" )
>         getOptionChain("AAPL")
> The first one worked but the second one produced the following error
> message:
>         Error in getOptionChain.yahoo(Symbols = "AAPL") :
>         package:?XML?cannot be loaded.
> Therefore, I am thinking I need to install the package XML. To do so, I
> executed the following command:
>         install.packages( "XML" )
> However, that command failed because it could not find the package XML.
> The following URL:
>         https://cran.r-project.org/web/packages/XML/XML.pdf
> indicates to me that it does exist.
>

It also shows its webpage to be at http://www.omegahat.org/RSXML. On the
root of the site -- http://www.omegahat.org -- the installation command is
given as install.packages(packageName, repos = "http://www.omegahat.org/R").
So perhaps, you should try install.packages("XML", repos = "
http://www.omegahat.org/R") or install.packages("RSXML", repos = "
http://www.omegahat.org/R") as one of those two should get you what you
want. Hope that helped... -- H

>
> I am hoping somebody can tell me what I am doing wrong.
>
> Thanks
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
OpenPGP: https://hasan.d8u.us/gpg.key
Sent from my mobile device
Envoy? de mon portable

	[[alternative HTML version deleted]]


From rsherry8 at comcast.net  Sun Nov  8 01:37:37 2015
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sat, 7 Nov 2015 19:37:37 -0500
Subject: [R] QuantMod and XML
In-Reply-To: <CAP+bYWB5aayp6xSwNqBuEO=pg-bf0nJ5aF=rbpDjzhRxYr0QuQ@mail.gmail.com>
References: <563E88E2.8080008@comcast.net>
	<CAP+bYWB5aayp6xSwNqBuEO=pg-bf0nJ5aF=rbpDjzhRxYr0QuQ@mail.gmail.com>
Message-ID: <563E9951.4020802@comcast.net>

Thanks for the response. I am currently using Windows 7. I tried the 
following command:
     install.packages("XML", repos = "http://www.omegahat.org/R")
and I got:
     Installing package into ?C:/Users/Bob/Documents/R/win-library/3.1?
     (as ?lib? is unspecified)
     Warning: unable to access index for repository 
http://www.omegahat.org/R/bin/windows/contrib/3.1

        package ?XML? is available as a source package but not as a binary

     Warning message: package ?XML? is not available (for R version 3.1.2)

I also tried this command:
     install.packages("RSXML", repos = "http://www.omegahat.org/R")
and I got:
     Installing package into ?C:/Users/Bob/Documents/R/win-library/3.1?
     (as ?lib? is unspecified)
     Warning: unable to access index for repository 
http://www.omegahat.org/R/bin/windows/contrib/3.1
     Warning message:
     package ?RSXML? is not available (for R version 3.1.2)

I am wondering why it is not work. Please help.

Thanks
Bob


On 11/7/2015 6:41 PM, Hasan Diwan wrote:
> Bob,
>
> On 7 November 2015 at 15:27, Robert Sherry <rsherry8 at comcast.net 
> <mailto:rsherry8 at comcast.net>> wrote:
>
>
>     I am trying to use the package quantmod to get option quotes in R.
>     Therefore, I executed the following two commands:
>             library ("quantmod" )
>             getOptionChain("AAPL")
>     The first one worked but the second one produced the following
>     error message:
>             Error in getOptionChain.yahoo(Symbols = "AAPL") :
>             package:?XML?cannot be loaded.
>     Therefore, I am thinking I need to install the package XML. To do
>     so, I executed the following command:
>             install.packages( "XML" )
>     However, that command failed because it could not find the package
>     XML. The following URL:
>     https://cran.r-project.org/web/packages/XML/XML.pdf
>     indicates to me that it does exist.
>
>
> It also shows its webpage to be at http://www.omegahat.org/RSXML. On 
> the root of the site -- http://www.omegahat.org -- the installation 
> command is given as install.packages(packageName, repos = 
> "http://www.omegahat.org/R"). So perhaps, you should try 
> install.packages("XML", repos = "http://www.omegahat.org/R") or 
> install.packages("RSXML", repos = "http://www.omegahat.org/R") as one 
> of those two should get you what you want. Hope that helped... -- H
>
>
>     I am hoping somebody can tell me what I am doing wrong.
>
>     Thanks
>     Bob
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> -- 
> OpenPGP: https://hasan.d8u.us/gpg.key
> Sent from my mobile device
> Envoy? de mon portable


	[[alternative HTML version deleted]]


From edd at debian.org  Sun Nov  8 01:57:11 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 7 Nov 2015 18:57:11 -0600
Subject: [R] QuantMod and XML
In-Reply-To: <563E9951.4020802@comcast.net>
References: <563E88E2.8080008@comcast.net>
	<CAP+bYWB5aayp6xSwNqBuEO=pg-bf0nJ5aF=rbpDjzhRxYr0QuQ@mail.gmail.com>
	<563E9951.4020802@comcast.net>
Message-ID: <22078.40423.393085.984926@max.nulle.part>


On 7 November 2015 at 19:37, Robert Sherry wrote:
|      Warning message: package ?XML? is not available (for R version 3.1.2)

That is your problem.

You are running R 3.1.2.  That is old and outdated.  CRAN has packages --
which may on occassion impose a '>=' relation. That is the case here.

You can see at the CRAN package page https://cran.rstudio.com/package=XML
that the package is fine.

In short, either update R to 3.2.2 (good, more work) or pick an older XML
from the Archive section at https://cran.rstudio.com/src/contrib/Archive/XML/

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From oma.gonzales at gmail.com  Sun Nov  8 05:42:58 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sat, 7 Nov 2015 23:42:58 -0500
Subject: [R] regex not working for some entries in for loop
In-Reply-To: <1A8C1289955EF649A09086A153E2672403C79B452B@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CAM-xyZhnaDRLDp7S=Ln-9dNs=4jdZjRdUh2aKkHkpJLqwhrK0g@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403C79B452B@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAM-xyZjPF1CYrvNHNTDJ4pKrkiyXUDGaX-oYtjnK_yrmLAC95A@mail.gmail.com>

Thanks S. Ellison.

Finally, Ihad some time to test it. Thanks for your clarification.

Just one more question:

You say:

Your regexes are on multiple lines and include whitespace and linefeeds.
For example you are not testing for
" .*forum.*|.*buy.*"; you are testing for
" .*forum.*|
                      .*buy.*"


But, the ".*", as far as I understand, means: any character, 0 or more
times. So I should cover the blank and break lines. May you explain this
further, this is not making click on my head.




2015-10-26 7:29 GMT-05:00 S Ellison <S.Ellison at lgcgroup.com>:

>
>
> > From: Omar Andr? Gonz?les D?az
> > Subject: [R] regex not working for some entries in for loop
> >
> > I'm using some regex in a for loop to check for some values in column
> "source",
> > and put a result in column "fuente".
>
> Your regexes are on multiple lines and include whitespace and linefeeds.
> For example you are not testing for
> " .*forum.*|.*buy.*"; you are testing for
> " .*forum.*|
>                       .*buy.*"
> (which among other things includes a \n)
> Don?t do that. Keep it to one line with no white space.
> if you must have line breaks in the code, form the pattern using paste, as
> in
> pat1 <- paste(c("site.*", ".*event.*", ".*free.*", ".*theguardlan.*",
>         ".*guardlink.*", ".*torture.*", ".*forum.*", ".*buy.*",
>         ".*share.*", ".*buttons.*", ".*pyme\\.lavoztx\\.com\\.*",
>         ".*amezon.*", "computrabajo.com.pe", ".*porn.*", "quality"),
>         collapse="|")
>
> spam <- grepl(pat1, sf$source,ignore.case = T)
>
> Also, it's not immediately clear why you?re looping. grepl returns a
> vector of logicals; you have a vector of character strings. Consider
> replacing 'if' constructs with 'ifelse' - albeit a complicated ifelse() -
> and doing the whole thing without a loop.
>
> S Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:17}}


From sreckojoksimovic at gmail.com  Sun Nov  8 10:28:34 2015
From: sreckojoksimovic at gmail.com (srecko joksimovic)
Date: Sun, 8 Nov 2015 09:28:34 +0000
Subject: [R] LDA select number of topics
Message-ID: <CAM8BP_moGUtfbQmtZmgU+a_tehuvRxr+qKQ+UkA=f9WciQroNA@mail.gmail.com>

Hi all,

I've seen recently this great post by Nikita Murzintcev
http://rpubs.com/nikita-moor/107657. If I understood correctly, according
to Griffiths (2004) I should select 11 topics? But, it seems that other
metrics suggest quite different number of topics?

I mean, 11 topics is about the right number, however, besides it works
better in my case, how do I know which metric to rely on? That is, if I
want to report this in a paper, can I simply say that I relied on Griffiths
(2004), without explaining why not Arun (2010), for example?

Thanks,
-------------- next part --------------
A non-text attachment was scrubbed...
Name: dda_topics.pdf
Type: application/pdf
Size: 6272 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151108/e75038d1/attachment.pdf>

From marammagdysalem at gmail.com  Sun Nov  8 10:48:10 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 8 Nov 2015 11:48:10 +0200
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
	<CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
Message-ID: <CAPLSCn0WLK8uVQe5H=ZqKjwBBdFNENPxQ2HrzOcbX+w4fdp38Q@mail.gmail.com>

Thanks all for replying.

In fact I've used the the Rprof() function and found out that the incomb()
function (in my code above)  takes about 80% of the time, but I didn't
figure out which part of the function is causing the delay. So I thought
that this may be due to the for() loops.
I MUST run this code for rather large values of n and m, so is there any
way that can help me do that without having to wait for more than three
days to reach an output. N.B. I'll have to repeat these runs for may be 70
or 80 times , and this means HUGE time

I'd appreciate any sort of help.
Thanks in advance.

Maram Salem

On 6 November 2015 at 16:54, jim holtman <jholtman at gmail.com> wrote:

> If you have code that is running for a long time, then take a small case
> that only runs for 5-10 minutes and turn on the RProfiler so that you can
> see where you are spending your time.  In most cases, it is probably not
> the 'for' loops that are causing the problem, but some function/calculation
> you are doing within the loop that is consuming the time, and until you
> determine what section of code that is, is it hard to tell exactly what the
> problem is, much less the solution.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
>> Hi Jim,
>>
>> Thanks a lot for replying.
>>
>> In fact I'm trying to run a simulation study that enables me to calculate
>> the Bayes risk of a sampling plan selected from progressively type-II
>> censored Weibull model. One of the steps involves evaluating the expected
>> test time, which is a rather complicated formula that involves nested
>> multiple summations where the counters of the summation signs are
>> dependent, that's why I thought of I should create the incomb() function
>> inside the loop, or may be I didn't figure out how to relate its arguments
>> to the ones inside the loop had I created it outside it.  I'm trying to
>> create a matrix of all the possible combinations involved in the summations
>> and then use the apply() function on each row of that matrix. The problem
>> is that the code I wrote works perfectly well for rather small values of
>> the sample size,n, and the censoring number, m (for example, n=8,m=4),but
>> when n and m are increased (say, n=25,m=15) the code keeps on running for
>> days with no output. That's why I thought I should try to avoid explicit
>> loops as much as possible, so I did my best in this regard but still the
>> code takes too long to execute,(more than three days), thus, i believe
>> there must be something wrong.
>>
>> Here's the full code:
>>
>> library(pbapply)
>> f1 <- function(n, m) {
>>    stopifnot(n > m)
>>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
>> len=n-m+1), m-2))
>>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
>> }
>> simpfun<- function (x,n,m,p,alpha,beta)
>>   {
>>   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>>   b <-  ((m-1):1)
>>   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
>> d <- n - cumsum(x) - (1:(m-1))
>>   e<- n*(prod(d))*c
>> LD<-list()
>>    for (i in 1:(m-1))  {
>>    LD[[i]]<-seq(0,x[i],1)
>>    }
>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>    LED<-expand.grid (LD)
>>    LED<-as.matrix(LED)
>>    store1<-numeric(nrow(LED))
>> for (j in 1:length(store1) )
>>          {
>>             incomb<-function(x,alpha,beta) {
>>
>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>                     h <- choose(x, LED[j,-m])
>>                    ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>                 lm<-cumsum(LED[j,-m]) + (1:(m-1))
>>                 plm<-prod(lm)
>>                gil<-g*ik/(plm)
>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>              dsa<-length(hlm)
>>               for (i in 1:dsa)
>>                 {
>>                  ppp<- sum(LED[j,])+(m-1)
>>                   hlm[i]<-
>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>                  }
>>           shl<-gil*(sum(hlm)+1)
>>           return (shl)
>>           }
>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>       }
>> val1<- sum(store1)*e
>> return(val1)
>> }
>>
>> va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
>> EXP<-sum(va)
>>
>>
>>
>> Any help would be greatly appreciated.
>> Thanks a lot  for your time.
>>
>> Best Regards,
>> Maram Salem
>>
>>
>> On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
>>
>>> Why are you recreating the incomb function within the loop instead of
>>> defining it outside the loop?  Also you are referencing several variables
>>> that are global (e.g., m & j); you should be passing these in as parameters
>>> to the function.
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
>>> wrote:
>>>
>>>> Hi All,
>>>>
>>>> I'm writing a long code that takes long time to execute. So I used the
>>>> Rprof() function and found out that the function that takes about 80% of
>>>> the time is the incomb () fucntion (below), and this is most probably
>>>> because of the many explicit for() loops I'm using.
>>>>
>>>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>>>> x=c(3,0,0)
>>>> LD<-list()
>>>>    for (i in 1:(m-1))  {
>>>>    LD[[i]]<-seq(0,x[i],1)
>>>>    }
>>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>    LED<-expand.grid (LD)
>>>>    LED<-as.matrix(LED)
>>>>    store1<-numeric(nrow(LED))
>>>>     h<- numeric(m-1)
>>>>     lm<- numeric(m-1)
>>>>      for (j in 1:length(store1) )
>>>>          {
>>>>             incomb<-function(x,alpha,beta) {
>>>>
>>>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>                   for (i in 1:(m-1))  {
>>>>                        h[i]<- choose(x[i],LED[j,i])
>>>>                        }
>>>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>>                 for (i in 1:(m-1)) {
>>>>                        lm[i]<-(sum(LED[j,1:i])) + i
>>>>                      }
>>>>                 plm<-prod(lm)
>>>>                gil<-g*ik/(plm)
>>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>>              dsa<-length(hlm)
>>>>               for (i in 1:dsa)
>>>>                 {
>>>>                  ppp<- sum(LED[j,])+(m-1)
>>>>                   hlm[i]<-
>>>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>>                  }
>>>>           shl<-gil*(sum(hlm)+1)
>>>>           return (shl)
>>>>           }
>>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>       }
>>>>
>>>>
>>>> I'm trying to use alternatives (for ex. to vectorize things) to the
>>>> explicit for() loops, but things don't work out.
>>>>
>>>> Any suggestions that can help me to speed up the execution of the
>>>> incomb()
>>>> function are much appreciated.
>>>>
>>>> Thanks a lot in advance.
>>>>
>>>> Maram Salem
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Nov  8 09:00:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 8 Nov 2015 19:00:22 +1100
Subject: [R] Help scatterplot3d
In-Reply-To: <6C5EE9A9CEA.00000C6Djrkrideau@inbox.com>
References: <633022433.875402.1446819622602.javamail.yahoo.ref@mail.yahoo.com>
	<633022433.875402.1446819622602.JavaMail.yahoo@mail.yahoo.com>
	<6C5EE9A9CEA.00000C6Djrkrideau@inbox.com>
Message-ID: <CA+8X3fXvmvtTUdZwBv1w29_CCHOJdPdbqtNqhNCGUzG2MYSO-w@mail.gmail.com>

Hi Julian,
As I don't have access to "datos", I had to make it up. The following does
what I expected.

library(scatterplot3d)
#datos<-read.csv("C:\\prueba.csv",sep=",",header=TRUE)
#str(datos)
datos<-data.frame(Bx=runif(40),e=runif(40),t=runif(40))
scatterplot3d(datos)
s3d<- scatterplot3d(datos, type = "h", color = "blue", angle = 55,
 scale.y = 0.7, pch = 16, main = "title")
my.lm <- lm(datos$Bx ~ datos$e + datos$t)
s3d$plane3d(my.lm)

Jim


On Sat, Nov 7, 2015 at 11:18 AM, John Kane <jrkrideau at inbox.com> wrote:

>
> Please do not post in HTML. Your post is gibberish.
>
> Also please have a look at
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> and/or http://adv-r.had.co.nz/Reproducibility.html  for some suggestions
> on asking questions in R-help.
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: r-help at r-project.org
> > Sent: Fri, 6 Nov 2015 14:20:22 +0000 (UTC)
> > To: r-help at r-project.org
> > Subject: [R] Help scatterplot3d
> >
> > Hi, I'm running this script:
> >
> library(scatterplot3d)datos<-read.csv("C:\\prueba.csv",sep=",",header=TRUE)str(datos)scatterplot3d(datos)
> > s3d<- scatterplot3d(datos, type = "h", color = "blue", angle = 55,
> > scale.y = 0.7, pch = 16, main = "title?)
> > my.lm <- lm(datos$Bx ~ datos$e + datos$t) s3d$plane3d(my.lm)
> >  I need to plot the experimental data ("datos") and the regression plane
> > given by "my.lm" in the same figure.The script plots "datos" but it
> > doesn't add the plot of the regression plane. Sometimes I get a message
> > like "s3d objet not found".
> > Thanks a lot.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> GET FREE 5GB EMAIL - Check out spam free email with many cool features!
> Visit http://www.inbox.com/email to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Nov  9 00:13:05 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 8 Nov 2015 18:13:05 -0500
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAPLSCn0WLK8uVQe5H=ZqKjwBBdFNENPxQ2HrzOcbX+w4fdp38Q@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
	<CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
	<CAPLSCn0WLK8uVQe5H=ZqKjwBBdFNENPxQ2HrzOcbX+w4fdp38Q@mail.gmail.com>
Message-ID: <CAAxdm-5ha0iCfJdkeEkvdeVXTKkDifVnJBBO-Mw8JV7LA1EyYw@mail.gmail.com>

You need to take a close look at the function incomb that you are
creating.  I see what appears to be a constant value ("*(
gamma((1/beta)+1))*((alpha)^(-(1/beta)))") being computed that you might
only have to compute once before the function.  You are also referencing
many variables (m, LED, j, ...) that are not being passed in that are in
the global environment; it is probably better to pass them in to the
function.  I am not sure what 'pbapply' is doing for you since I see this
is new to the code that you first sent out.

I would be good it you told us what the function is trying to do; you are
showing us how you want to do it, not what you want to do.  Are there other
ways of doing it?  If speed is your problem, then consider the "Rcpp"
package and write the function is C++ which might be faster, but again,
take a look at what you are doing to see if there are other ways.  I don't
have time to dig into the code, since there is a lack of comments, to
understand why you are using, e.g., 'choose', 'prod', etc.).  There are
probably a lot of ways of speeding up the code, if could tell us what you
want to accomplish.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Nov 8, 2015 at 4:48 AM, Maram SAlem <marammagdysalem at gmail.com>
wrote:

> Thanks all for replying.
>
> In fact I've used the the Rprof() function and found out that the
> incomb() function (in my code above)  takes about 80% of the time, but I
> didn't figure out which part of the function is causing the delay. So I
> thought that this may be due to the for() loops.
> I MUST run this code for rather large values of n and m, so is there any
> way that can help me do that without having to wait for more than three
> days to reach an output. N.B. I'll have to repeat these runs for may be 70
> or 80 times , and this means HUGE time
>
> I'd appreciate any sort of help.
> Thanks in advance.
>
> Maram Salem
>
> On 6 November 2015 at 16:54, jim holtman <jholtman at gmail.com> wrote:
>
>> If you have code that is running for a long time, then take a small case
>> that only runs for 5-10 minutes and turn on the RProfiler so that you can
>> see where you are spending your time.  In most cases, it is probably not
>> the 'for' loops that are causing the problem, but some function/calculation
>> you are doing within the loop that is consuming the time, and until you
>> determine what section of code that is, is it hard to tell exactly what the
>> problem is, much less the solution.
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com>
>> wrote:
>>
>>> Hi Jim,
>>>
>>> Thanks a lot for replying.
>>>
>>> In fact I'm trying to run a simulation study that enables me to
>>> calculate the Bayes risk of a sampling plan selected from progressively
>>> type-II censored Weibull model. One of the steps involves evaluating the
>>> expected test time, which is a rather complicated formula that involves
>>> nested multiple summations where the counters of the summation signs are
>>> dependent, that's why I thought of I should create the incomb() function
>>> inside the loop, or may be I didn't figure out how to relate its arguments
>>> to the ones inside the loop had I created it outside it.  I'm trying to
>>> create a matrix of all the possible combinations involved in the summations
>>> and then use the apply() function on each row of that matrix. The problem
>>> is that the code I wrote works perfectly well for rather small values of
>>> the sample size,n, and the censoring number, m (for example, n=8,m=4),but
>>> when n and m are increased (say, n=25,m=15) the code keeps on running for
>>> days with no output. That's why I thought I should try to avoid explicit
>>> loops as much as possible, so I did my best in this regard but still the
>>> code takes too long to execute,(more than three days), thus, i believe
>>> there must be something wrong.
>>>
>>> Here's the full code:
>>>
>>> library(pbapply)
>>> f1 <- function(n, m) {
>>>    stopifnot(n > m)
>>>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
>>> len=n-m+1), m-2))
>>>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
>>> }
>>> simpfun<- function (x,n,m,p,alpha,beta)
>>>   {
>>>   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>>>   b <-  ((m-1):1)
>>>   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
>>> d <- n - cumsum(x) - (1:(m-1))
>>>   e<- n*(prod(d))*c
>>> LD<-list()
>>>    for (i in 1:(m-1))  {
>>>    LD[[i]]<-seq(0,x[i],1)
>>>    }
>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>    LED<-expand.grid (LD)
>>>    LED<-as.matrix(LED)
>>>    store1<-numeric(nrow(LED))
>>> for (j in 1:length(store1) )
>>>          {
>>>             incomb<-function(x,alpha,beta) {
>>>
>>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>                     h <- choose(x, LED[j,-m])
>>>                    ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>                 lm<-cumsum(LED[j,-m]) + (1:(m-1))
>>>                 plm<-prod(lm)
>>>                gil<-g*ik/(plm)
>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>              dsa<-length(hlm)
>>>               for (i in 1:dsa)
>>>                 {
>>>                  ppp<- sum(LED[j,])+(m-1)
>>>                   hlm[i]<-
>>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>                  }
>>>           shl<-gil*(sum(hlm)+1)
>>>           return (shl)
>>>           }
>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>       }
>>> val1<- sum(store1)*e
>>> return(val1)
>>> }
>>>
>>> va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
>>> EXP<-sum(va)
>>>
>>>
>>>
>>> Any help would be greatly appreciated.
>>> Thanks a lot  for your time.
>>>
>>> Best Regards,
>>> Maram Salem
>>>
>>>
>>> On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
>>>
>>>> Why are you recreating the incomb function within the loop instead of
>>>> defining it outside the loop?  Also you are referencing several variables
>>>> that are global (e.g., m & j); you should be passing these in as parameters
>>>> to the function.
>>>>
>>>>
>>>> Jim Holtman
>>>> Data Munger Guru
>>>>
>>>> What is the problem that you are trying to solve?
>>>> Tell me what you want to do, not how you want to do it.
>>>>
>>>> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi All,
>>>>>
>>>>> I'm writing a long code that takes long time to execute. So I used the
>>>>> Rprof() function and found out that the function that takes about 80%
>>>>> of
>>>>> the time is the incomb () fucntion (below), and this is most probably
>>>>> because of the many explicit for() loops I'm using.
>>>>>
>>>>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>>>>> x=c(3,0,0)
>>>>> LD<-list()
>>>>>    for (i in 1:(m-1))  {
>>>>>    LD[[i]]<-seq(0,x[i],1)
>>>>>    }
>>>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>>    LED<-expand.grid (LD)
>>>>>    LED<-as.matrix(LED)
>>>>>    store1<-numeric(nrow(LED))
>>>>>     h<- numeric(m-1)
>>>>>     lm<- numeric(m-1)
>>>>>      for (j in 1:length(store1) )
>>>>>          {
>>>>>             incomb<-function(x,alpha,beta) {
>>>>>
>>>>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>>                   for (i in 1:(m-1))  {
>>>>>                        h[i]<- choose(x[i],LED[j,i])
>>>>>                        }
>>>>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>>>                 for (i in 1:(m-1)) {
>>>>>                        lm[i]<-(sum(LED[j,1:i])) + i
>>>>>                      }
>>>>>                 plm<-prod(lm)
>>>>>                gil<-g*ik/(plm)
>>>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>>>              dsa<-length(hlm)
>>>>>               for (i in 1:dsa)
>>>>>                 {
>>>>>                  ppp<- sum(LED[j,])+(m-1)
>>>>>                   hlm[i]<-
>>>>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>>>                  }
>>>>>           shl<-gil*(sum(hlm)+1)
>>>>>           return (shl)
>>>>>           }
>>>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>>       }
>>>>>
>>>>>
>>>>> I'm trying to use alternatives (for ex. to vectorize things) to the
>>>>> explicit for() loops, but things don't work out.
>>>>>
>>>>> Any suggestions that can help me to speed up the execution of the
>>>>> incomb()
>>>>> function are much appreciated.
>>>>>
>>>>> Thanks a lot in advance.
>>>>>
>>>>> Maram Salem
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Nov  9 00:32:00 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 8 Nov 2015 18:32:00 -0500
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAAxdm-5ha0iCfJdkeEkvdeVXTKkDifVnJBBO-Mw8JV7LA1EyYw@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
	<CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
	<CAPLSCn0WLK8uVQe5H=ZqKjwBBdFNENPxQ2HrzOcbX+w4fdp38Q@mail.gmail.com>
	<CAAxdm-5ha0iCfJdkeEkvdeVXTKkDifVnJBBO-Mw8JV7LA1EyYw@mail.gmail.com>
Message-ID: <72C6DD08-EC39-498E-B4BC-FF90DAE18274@utoronto.ca>

While I fully agree with Jim's comments, you may also need to understand the notion of time complexity in algorithm analysis. All the mentioned speed-ups are basically linear, in the sense that they accelerate a single step of your algorithm. However if your algorithm has combinatorial complexity, any amount of linear speed-up may only increase the tractable problem size by a trivial amount. I had proposed earlier that you write a small set of test examples and properly analyze the complexity - how does run time scale with your problem size. That gives you a rational basis to analyze 
 - how the improvements in your code affect the run time
 - how the improvements in your code affect the tractable problem size.

If this shows you that the problem won't go away, then some thoughts about optimization for computationally hard problems will be in order. These may include substituting a heuristic for an exact algorithm, or approximating solutions by stochastic sampling in large spaces.


B.
PS: and for real now: format your code, add comments, don't post in HTML, create an MWE ...




On Nov 8, 2015, at 6:13 PM, jim holtman <jholtman at gmail.com> wrote:

> You need to take a close look at the function incomb that you are
> creating.  I see what appears to be a constant value ("*(
> gamma((1/beta)+1))*((alpha)^(-(1/beta)))") being computed that you might
> only have to compute once before the function.  You are also referencing
> many variables (m, LED, j, ...) that are not being passed in that are in
> the global environment; it is probably better to pass them in to the
> function.  I am not sure what 'pbapply' is doing for you since I see this
> is new to the code that you first sent out.
> 
> I would be good it you told us what the function is trying to do; you are
> showing us how you want to do it, not what you want to do.  Are there other
> ways of doing it?  If speed is your problem, then consider the "Rcpp"
> package and write the function is C++ which might be faster, but again,
> take a look at what you are doing to see if there are other ways.  I don't
> have time to dig into the code, since there is a lack of comments, to
> understand why you are using, e.g., 'choose', 'prod', etc.).  There are
> probably a lot of ways of speeding up the code, if could tell us what you
> want to accomplish.
> 
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> On Sun, Nov 8, 2015 at 4:48 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
> 
>> Thanks all for replying.
>> 
>> In fact I've used the the Rprof() function and found out that the
>> incomb() function (in my code above)  takes about 80% of the time, but I
>> didn't figure out which part of the function is causing the delay. So I
>> thought that this may be due to the for() loops.
>> I MUST run this code for rather large values of n and m, so is there any
>> way that can help me do that without having to wait for more than three
>> days to reach an output. N.B. I'll have to repeat these runs for may be 70
>> or 80 times , and this means HUGE time
>> 
>> I'd appreciate any sort of help.
>> Thanks in advance.
>> 
>> Maram Salem
>> 
>> On 6 November 2015 at 16:54, jim holtman <jholtman at gmail.com> wrote:
>> 
>>> If you have code that is running for a long time, then take a small case
>>> that only runs for 5-10 minutes and turn on the RProfiler so that you can
>>> see where you are spending your time.  In most cases, it is probably not
>>> the 'for' loops that are causing the problem, but some function/calculation
>>> you are doing within the loop that is consuming the time, and until you
>>> determine what section of code that is, is it hard to tell exactly what the
>>> problem is, much less the solution.
>>> 
>>> 
>>> Jim Holtman
>>> Data Munger Guru
>>> 
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>> 
>>> On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com>
>>> wrote:
>>> 
>>>> Hi Jim,
>>>> 
>>>> Thanks a lot for replying.
>>>> 
>>>> In fact I'm trying to run a simulation study that enables me to
>>>> calculate the Bayes risk of a sampling plan selected from progressively
>>>> type-II censored Weibull model. One of the steps involves evaluating the
>>>> expected test time, which is a rather complicated formula that involves
>>>> nested multiple summations where the counters of the summation signs are
>>>> dependent, that's why I thought of I should create the incomb() function
>>>> inside the loop, or may be I didn't figure out how to relate its arguments
>>>> to the ones inside the loop had I created it outside it.  I'm trying to
>>>> create a matrix of all the possible combinations involved in the summations
>>>> and then use the apply() function on each row of that matrix. The problem
>>>> is that the code I wrote works perfectly well for rather small values of
>>>> the sample size,n, and the censoring number, m (for example, n=8,m=4),but
>>>> when n and m are increased (say, n=25,m=15) the code keeps on running for
>>>> days with no output. That's why I thought I should try to avoid explicit
>>>> loops as much as possible, so I did my best in this regard but still the
>>>> code takes too long to execute,(more than three days), thus, i believe
>>>> there must be something wrong.
>>>> 
>>>> Here's the full code:
>>>> 
>>>> library(pbapply)
>>>> f1 <- function(n, m) {
>>>>   stopifnot(n > m)
>>>>   r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>>>   r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
>>>> len=n-m+1), m-2))
>>>>   cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
>>>> }
>>>> simpfun<- function (x,n,m,p,alpha,beta)
>>>>  {
>>>>  a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>>>>  b <-  ((m-1):1)
>>>>  c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
>>>> d <- n - cumsum(x) - (1:(m-1))
>>>>  e<- n*(prod(d))*c
>>>> LD<-list()
>>>>   for (i in 1:(m-1))  {
>>>>   LD[[i]]<-seq(0,x[i],1)
>>>>   }
>>>>   LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>   LED<-expand.grid (LD)
>>>>   LED<-as.matrix(LED)
>>>>   store1<-numeric(nrow(LED))
>>>> for (j in 1:length(store1) )
>>>>         {
>>>>            incomb<-function(x,alpha,beta) {
>>>> 
>>>> g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>                    h <- choose(x, LED[j,-m])
>>>>                   ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>>                lm<-cumsum(LED[j,-m]) + (1:(m-1))
>>>>                plm<-prod(lm)
>>>>               gil<-g*ik/(plm)
>>>>             hlm<-numeric(sum(LED[j,])+(m-1))
>>>>             dsa<-length(hlm)
>>>>              for (i in 1:dsa)
>>>>                {
>>>>                 ppp<- sum(LED[j,])+(m-1)
>>>>                  hlm[i]<-
>>>> (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>>                 }
>>>>          shl<-gil*(sum(hlm)+1)
>>>>          return (shl)
>>>>          }
>>>>       store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>      }
>>>> val1<- sum(store1)*e
>>>> return(val1)
>>>> }
>>>> 
>>>> va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
>>>> EXP<-sum(va)
>>>> 
>>>> 
>>>> 
>>>> Any help would be greatly appreciated.
>>>> Thanks a lot  for your time.
>>>> 
>>>> Best Regards,
>>>> Maram Salem
>>>> 
>>>> 
>>>> On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
>>>> 
>>>>> Why are you recreating the incomb function within the loop instead of
>>>>> defining it outside the loop?  Also you are referencing several variables
>>>>> that are global (e.g., m & j); you should be passing these in as parameters
>>>>> to the function.
>>>>> 
>>>>> 
>>>>> Jim Holtman
>>>>> Data Munger Guru
>>>>> 
>>>>> What is the problem that you are trying to solve?
>>>>> Tell me what you want to do, not how you want to do it.
>>>>> 
>>>>> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> Hi All,
>>>>>> 
>>>>>> I'm writing a long code that takes long time to execute. So I used the
>>>>>> Rprof() function and found out that the function that takes about 80%
>>>>>> of
>>>>>> the time is the incomb () fucntion (below), and this is most probably
>>>>>> because of the many explicit for() loops I'm using.
>>>>>> 
>>>>>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>>>>>> x=c(3,0,0)
>>>>>> LD<-list()
>>>>>>   for (i in 1:(m-1))  {
>>>>>>   LD[[i]]<-seq(0,x[i],1)
>>>>>>   }
>>>>>>   LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>>>   LED<-expand.grid (LD)
>>>>>>   LED<-as.matrix(LED)
>>>>>>   store1<-numeric(nrow(LED))
>>>>>>    h<- numeric(m-1)
>>>>>>    lm<- numeric(m-1)
>>>>>>     for (j in 1:length(store1) )
>>>>>>         {
>>>>>>            incomb<-function(x,alpha,beta) {
>>>>>> 
>>>>>> g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>>>                  for (i in 1:(m-1))  {
>>>>>>                       h[i]<- choose(x[i],LED[j,i])
>>>>>>                       }
>>>>>>                 ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>>>>                for (i in 1:(m-1)) {
>>>>>>                       lm[i]<-(sum(LED[j,1:i])) + i
>>>>>>                     }
>>>>>>                plm<-prod(lm)
>>>>>>               gil<-g*ik/(plm)
>>>>>>             hlm<-numeric(sum(LED[j,])+(m-1))
>>>>>>             dsa<-length(hlm)
>>>>>>              for (i in 1:dsa)
>>>>>>                {
>>>>>>                 ppp<- sum(LED[j,])+(m-1)
>>>>>>                  hlm[i]<-
>>>>>> (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>>>>                 }
>>>>>>          shl<-gil*(sum(hlm)+1)
>>>>>>          return (shl)
>>>>>>          }
>>>>>>       store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>>>      }
>>>>>> 
>>>>>> 
>>>>>> I'm trying to use alternatives (for ex. to vectorize things) to the
>>>>>> explicit for() loops, but things don't work out.
>>>>>> 
>>>>>> Any suggestions that can help me to speed up the execution of the
>>>>>> incomb()
>>>>>> function are much appreciated.
>>>>>> 
>>>>>> Thanks a lot in advance.
>>>>>> 
>>>>>> Maram Salem
>>>>>> 
>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>> 
>>>>> 
>>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Mon Nov  9 01:05:18 2015
From: valkremk at gmail.com (Val)
Date: Sun, 8 Nov 2015 18:05:18 -0600
Subject: [R] Prefix
Message-ID: <CAJOiR6ZTawsgqQn3GV_R52-ezZrDJUhOuiMd52mC5kROwKt0yQ@mail.gmail.com>

HI all,

DF <- read.table(textConnection(" X1   X2 X3   TIME
Alex1      0         0       1960
Alexa      0         0        1920
Abbot      0         0          0
Smith     Alex1  Alexa    2012
Carla     Alex1      0        1996
Jacky    Smith   Abbot    2013
Jack       0         Jacky    2014
Almo     Jack     Carla     2015   "),header = TRUE)


I want to add the time  variable as prefix to the first column  (X1)
and I did it as follow,

DF$X4 <- as.character(paste(DF$TIME,DF$X1 ,sep="_"))
DF

All names in column two (X1) and three  (X3) are in column one. so I just
want bring that prefix to column three and two, as well but I could not do
that one.

Here is the final output  that  I would like to have.

              X1                   X2                     X3
1960_Alex                      0                       0
1920_Alexa                     0                      0
 0_Abbot                          0                      0
2012_Smith     1960_Alex     1920_Alexa
1996_Carla      1960_Alex                     0
 2013_Jacky    2012_Smith         0_Abbot
 2014_Jack                       0      2013_Jacky
 2015_Almo        2014_Jack      1996_Carla


Your help is appreciated in advance

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov  9 01:38:28 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 8 Nov 2015 16:38:28 -0800
Subject: [R] Prefix
In-Reply-To: <CAJOiR6ZTawsgqQn3GV_R52-ezZrDJUhOuiMd52mC5kROwKt0yQ@mail.gmail.com>
References: <CAJOiR6ZTawsgqQn3GV_R52-ezZrDJUhOuiMd52mC5kROwKt0yQ@mail.gmail.com>
Message-ID: <49B1E1F4-0AA5-4CF8-A866-EA14E2E364E5@comcast.net>


> On Nov 8, 2015, at 4:05 PM, Val <valkremk at gmail.com> wrote:
> 
> HI all,
> 
> DF <- read.table(textConnection(" X1   X2 X3   TIME
> Alex1      0         0       1960
> Alexa      0         0        1920
> Abbot      0         0          0
> Smith     Alex1  Alexa    2012
> Carla     Alex1      0        1996
> Jacky    Smith   Abbot    2013
> Jack       0         Jacky    2014
> Almo     Jack     Carla     2015   "),header = TRUE)

I would suggests using stringsAsFactors=FALSE
> 
> 
> I want to add the time  variable as prefix to the first column  (X1)
> and I did it as follow,
> 
> DF$X4 <- as.character(paste(DF$TIME,DF$X1 ,sep="_"))
> DF
> 
> All names in column two (X1) and three  (X3) are in column one. so I just
> want bring that prefix to column three and two, as well but I could not do
> that one.
> 
> Here is the final output  that  I would like to have.
> 
>              X1                   X2                     X3
> 1960_Alex                      0                       0
> 1920_Alexa                     0                      0
> 0_Abbot                          0                      0
> 2012_Smith     1960_Alex     1920_Alexa
> 1996_Carla      1960_Alex                     0
> 2013_Jacky    2012_Smith         0_Abbot
> 2014_Jack                       0      2013_Jacky
> 2015_Almo        2014_Jack      1996_Carla

If you follow my suggestion above, tehn these two lines produce vectors that may be of some use:

> paste(DF$TIME[match(DF$X2,DF$X1)], DF$X2, sep="_")
[1] "NA_0"       "NA_0"       "NA_0"       "1960_Alex1" "1960_Alex1"
[6] "2012_Smith" "NA_0"       "2014_Jack" 
> paste(DF$TIME[match(DF$X3,DF$X1)], DF$X3, sep="_")
[1] "NA_0"       "NA_0"       "NA_0"       "1920_Alexa" "NA_0"      
[6] "0_Abbot"    "2013_Jacky" ?1996_Carla"


> 
> 
> Your help is appreciated in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kydaviddoyle at gmail.com  Mon Nov  9 02:57:20 2015
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sun, 8 Nov 2015 19:57:20 -0600
Subject: [R] ggplot2 different Y axis scales
In-Reply-To: <CADv2QyFycNM5g_njLMNNL_oryS=zgWD3StgWVEDN__4BPvDGYA@mail.gmail.com>
References: <CACftpvqaZkYhy3rS+v6pOO01RmNQELBSkCC9++VpOEuRddWyxA@mail.gmail.com>
	<CADv2QyFycNM5g_njLMNNL_oryS=zgWD3StgWVEDN__4BPvDGYA@mail.gmail.com>
Message-ID: <CACftpvrPaAX8kp5TugLEt+2HgzTTXbbGk74on3ixJ7TJVN1M1Q@mail.gmail.com>

Thank you to Dennis and Jeff,

The scales = "free_y" did exactly what I needed.  Just in case some one
else has the same problem, the code is below.

Take Care
David

p <- ggplot(data = SS, aes(x=Year, y=Sulfate, col=Detections)) +
  geom_point(aes(shape=Detections))  +

  ##sets the colors
  scale_colour_manual(values=c("black","red")) +

  #location of the legend
  theme(legend.position=c("none")) +

  #sets the line color, type and size
  geom_line(colour="black", linetype="dotted", size=0.5) +
  ylab("Sulfate (mg/L)") +
  ##Graph title
  ggtitle("Figure 6-30
          Sandstone Sulfate Time Series")

## does the graph using the Well IDs as the different wells.
p + facet_grid(scales = "free_y",Well ~ .)


On Sat, Nov 7, 2015 at 7:48 AM, Dennis Murphy <djmuser at gmail.com> wrote:

> As Jeff mentioned, you can use scales = "free_y" to allow different
> y-scales for the response in each facet, but you do not have the
> ability to control the ranges of the y-scales in each facet. That is
> controlled by the training process for scales in ggplot2. Generally
> speaking, it should be pretty close to what you want, but may not be
> ideal.
>
> Dennis
>
> On Fri, Nov 6, 2015 at 2:04 PM, David Doyle <kydaviddoyle at gmail.com>
> wrote:
> > Hello Everyone,
> >
> > I'm using the following code to plot sulfate concentrations vs. time for
> > several groundwater wells at one time.  Normally I need the scales to all
> > be the same but in the case of sulfate I need to use a different scale
> for
> > each well.  This is because some of my wells have very high / wide ranges
> > (MW04 ranges from 4 - 3,000) where some have very small ranges (MW06
> ranges
> > from 13 - 34).
> >
> > Is there a way that I can  have qqplot2 automatically scale each well or
> a
> > way I could enter a scale range.?  For example I would like MW04 to have
> a
> > Y axis scale from 0 - 3,000 and MW06 to have a Y axis scale from 0 - 40
> >
> > I am using
> > RStudio version 0.99.484
> > R i386 3.2.2
> > ggplott2 ver 1.0.1
> > in a Windows 7 environment.
> >
> > Thank you for your time
> > David Doyle
> >
> >
> > library(ggplot2)
> > SS <-read.csv("http://doylesdartden.com/Stats/SS.csv", sep=",")
> >
> > #Sets whic are detections and nondetects
> > SS$Detections <- ifelse(SS$D_Sulfate==1, "Detected", "NonDetect")
> > png(file="Sulfate.png",width=2400,height=3000,res=300)
> > #does the plot
> > p <- ggplot(data = SS, aes(x=Year, y=Sulfate, col=Detections)) +
> >   geom_point(aes(shape=Detections))  +
> >
> >   ##sets the colors
> >   scale_colour_manual(values=c("black","red")) +
> >
> >   #location of the legend
> >   theme(legend.position=c("none")) +
> >
> >   #sets the line color, type and size
> >   geom_line(colour="black", linetype="dotted", size=0.5) +
> >   ylab("Sulfate (mg/L)") +
> >   ##Graph title
> >   ggtitle("Figure 6-30
> >           Sandstone Sulfate Time Series")
> >
> > ## does the graph using the Well IDs as the different wells.
> > p + facet_grid(Well ~ .)
> > dev.off()
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Mon Nov  9 05:03:32 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Sun, 8 Nov 2015 22:03:32 -0600
Subject: [R] NULL dev.lis()
Message-ID: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>

All,

I have previous built R from source many times, generally, without
problems. However on my new Ubuntu 15.04 Linux system with R 3.2.2 when I
run the command dev.list() I get:

> dev.list()
NULL

At the completion of running ./configure, I have

R is now configured for x86_64-pc-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       gfortran  -g -O2

  C++ compiler:              g++  -g -O2
  C++ 11 compiler:           g++  -std=c++11 -g -O2
  Fortran 90/95 compiler:    gfortran -g -O2
  Obj-C compiler:

  Interfaces supported:      X11
  External libraries:        readline, zlib, lzma, PCRE, curl
  Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
  Options enabled:           shared BLAS, R profiling

  Capabilities skipped:
  Options not enabled:       memory profiling

  Recommended packages:      yes

This issue is causing me problems with spplot, which I have posted on
r-sig-geo. R and the display of all other graphics seems to be fine,
otherwise. My previous installations of R would yield:

> dev.list()
X11cairo
       2

And I had no problems with spplot. Any thoughts?

Regards,
Tom

	[[alternative HTML version deleted]]


From kridox at ymail.com  Mon Nov  9 06:18:37 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 9 Nov 2015 14:18:37 +0900
Subject: [R] NULL dev.lis()
In-Reply-To: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>
References: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>
Message-ID: <CAAcyNCzxhvzJOKTNHt00NBn6v_5hbHpziMc6WefHLsLVdDWn7Q@mail.gmail.com>

Dear Tom,

Running R 3.2.2 on Ubuntu 15.04, if I run dev.list(), I get NULL. And
I guess it is the expected behavior, as per the help page, it "returns
the numbers of all open devices, except device 1, the null device".
So, if I run

x11()
dev.list()

I get

X11cairo
       2

HTH,
Pascal

On Mon, Nov 9, 2015 at 1:03 PM, Thomas Adams <tea3rd at gmail.com> wrote:
> All,
>
> I have previous built R from source many times, generally, without
> problems. However on my new Ubuntu 15.04 Linux system with R 3.2.2 when I
> run the command dev.list() I get:
>
>> dev.list()
> NULL
>
> At the completion of running ./configure, I have
>
> R is now configured for x86_64-pc-linux-gnu
>
>   Source directory:          .
>   Installation directory:    /usr/local
>
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
>
>   C++ compiler:              g++  -g -O2
>   C++ 11 compiler:           g++  -std=c++11 -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:
>
>   Interfaces supported:      X11
>   External libraries:        readline, zlib, lzma, PCRE, curl
>   Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
>   Options enabled:           shared BLAS, R profiling
>
>   Capabilities skipped:
>   Options not enabled:       memory profiling
>
>   Recommended packages:      yes
>
> This issue is causing me problems with spplot, which I have posted on
> r-sig-geo. R and the display of all other graphics seems to be fine,
> otherwise. My previous installations of R would yield:
>
>> dev.list()
> X11cairo
>        2
>
> And I had no problems with spplot. Any thoughts?
>
> Regards,
> Tom
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From maechler at stat.math.ethz.ch  Mon Nov  9 10:19:24 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 9 Nov 2015 10:19:24 +0100
Subject: [R] NULL dev.lis()
In-Reply-To: <CAAcyNCzxhvzJOKTNHt00NBn6v_5hbHpziMc6WefHLsLVdDWn7Q@mail.gmail.com>
References: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>
	<CAAcyNCzxhvzJOKTNHt00NBn6v_5hbHpziMc6WefHLsLVdDWn7Q@mail.gmail.com>
Message-ID: <22080.25884.348506.616193@stat.math.ethz.ch>

>>>>> Pascal Oettli via R-help <r-help at r-project.org>
>>>>>     on Mon, 9 Nov 2015 14:18:37 +0900 writes:

    > Dear Tom,
    > Running R 3.2.2 on Ubuntu 15.04, if I run dev.list(), I get NULL.

Yes, indeed with all "regular" / "default" versions of R.

I you don't get that, you must have set something user-specific,
or possibly site-specific if you have a particularly customized site
maintainer setup.

Read
   ?Startup
   ?options

etc.

    > And I guess it is the expected behavior, as per the help page, it "returns
    > the numbers of all open devices, except device 1, the null device".
    > So, if I run

    > x11()
    > dev.list()

    > I get

    > X11cairo
    > 2

    > HTH,
    > Pascal

    > On Mon, Nov 9, 2015 at 1:03 PM, Thomas Adams <tea3rd at gmail.com> wrote:
    >> All,
    >> 
    >> I have previous built R from source many times, generally, without
    >> problems. However on my new Ubuntu 15.04 Linux system with R 3.2.2 when I
    >> run the command dev.list() I get:
    >> 
    >>> dev.list()
    >> NULL
    >> 
    >> At the completion of running ./configure, I have
    >> 
    >> R is now configured for x86_64-pc-linux-gnu
    >> 
    >> Source directory:          .
    >> Installation directory:    /usr/local
    >> 
    >> C compiler:                gcc -std=gnu99  -g -O2
    >> Fortran 77 compiler:       gfortran  -g -O2
    >> 
    >> C++ compiler:              g++  -g -O2
    >> C++ 11 compiler:           g++  -std=c++11 -g -O2
    >> Fortran 90/95 compiler:    gfortran -g -O2
    >> Obj-C compiler:
    >> 
    >> Interfaces supported:      X11
    >> External libraries:        readline, zlib, lzma, PCRE, curl
    >> Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
    >> Options enabled:           shared BLAS, R profiling
    >> 
    >> Capabilities skipped:
    >> Options not enabled:       memory profiling
    >> 
    >> Recommended packages:      yes
    >> 
    >> This issue is causing me problems with spplot, which I have posted on
    >> r-sig-geo. R and the display of all other graphics seems to be fine,
    >> otherwise. My previous installations of R would yield:
    >> 
    >>> dev.list()
    >> X11cairo
    >> 2
    >> 
    >> And I had no problems with spplot. Any thoughts?
    >> 
    >> Regards,
    >> Tom
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.



    > -- 
    > Pascal Oettli
    > Project Scientist
    > JAMSTEC
    > Yokohama, Japan

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Mon Nov  9 11:10:12 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 9 Nov 2015 19:10:12 +0900
Subject: [R] NULL dev.lis()
In-Reply-To: <22080.25884.348506.616193@stat.math.ethz.ch>
References: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>
	<CAAcyNCzxhvzJOKTNHt00NBn6v_5hbHpziMc6WefHLsLVdDWn7Q@mail.gmail.com>
	<22080.25884.348506.616193@stat.math.ethz.ch>
Message-ID: <CAAcyNCyipVR370fsAA2K5AgL8C4p+TnaiUmAtN=kRmnTo+808w@mail.gmail.com>

Martin,

Sorry, but what are you talking about ? Of course I know it is normal
to get this result. It is what I explained in my message!

Regards,
Pascal

On Mon, Nov 9, 2015 at 6:19 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Pascal Oettli via R-help <r-help at r-project.org>
>>>>>>     on Mon, 9 Nov 2015 14:18:37 +0900 writes:
>
>     > Dear Tom,
>     > Running R 3.2.2 on Ubuntu 15.04, if I run dev.list(), I get NULL.
>
> Yes, indeed with all "regular" / "default" versions of R.
>
> I you don't get that, you must have set something user-specific,
> or possibly site-specific if you have a particularly customized site
> maintainer setup.
>
> Read
>    ?Startup
>    ?options
>
> etc.
>
>     > And I guess it is the expected behavior, as per the help page, it "returns
>     > the numbers of all open devices, except device 1, the null device".
>     > So, if I run
>
>     > x11()
>     > dev.list()
>
>     > I get
>
>     > X11cairo
>     > 2
>
>     > HTH,
>     > Pascal
>
>     > On Mon, Nov 9, 2015 at 1:03 PM, Thomas Adams <tea3rd at gmail.com> wrote:
>     >> All,
>     >>
>     >> I have previous built R from source many times, generally, without
>     >> problems. However on my new Ubuntu 15.04 Linux system with R 3.2.2 when I
>     >> run the command dev.list() I get:
>     >>
>     >>> dev.list()
>     >> NULL
>     >>
>     >> At the completion of running ./configure, I have
>     >>
>     >> R is now configured for x86_64-pc-linux-gnu
>     >>
>     >> Source directory:          .
>     >> Installation directory:    /usr/local
>     >>
>     >> C compiler:                gcc -std=gnu99  -g -O2
>     >> Fortran 77 compiler:       gfortran  -g -O2
>     >>
>     >> C++ compiler:              g++  -g -O2
>     >> C++ 11 compiler:           g++  -std=c++11 -g -O2
>     >> Fortran 90/95 compiler:    gfortran -g -O2
>     >> Obj-C compiler:
>     >>
>     >> Interfaces supported:      X11
>     >> External libraries:        readline, zlib, lzma, PCRE, curl
>     >> Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
>     >> Options enabled:           shared BLAS, R profiling
>     >>
>     >> Capabilities skipped:
>     >> Options not enabled:       memory profiling
>     >>
>     >> Recommended packages:      yes
>     >>
>     >> This issue is causing me problems with spplot, which I have posted on
>     >> r-sig-geo. R and the display of all other graphics seems to be fine,
>     >> otherwise. My previous installations of R would yield:
>     >>
>     >>> dev.list()
>     >> X11cairo
>     >> 2
>     >>
>     >> And I had no problems with spplot. Any thoughts?
>     >>
>     >> Regards,
>     >> Tom
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     > --
>     > Pascal Oettli
>     > Project Scientist
>     > JAMSTEC
>     > Yokohama, Japan
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ragia11 at hotmail.com  Mon Nov  9 11:55:27 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 9 Nov 2015 12:55:27 +0200
Subject: [R] get maximum 3 rows by column elements in data frame
Message-ID: <DUB125-W6176C8E51EE1E84A21F1C0B3150@phx.gbl>

Dear group,

I have the following data freame

dput(df_all_nodes)

structure(list(Measure_id = c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1,?
2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2,?
3, 4, 5, 1, 2, 3, 4, 5), i = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2,?
2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7,?
7, 7, 7, 7, 7, 7, 7, 7, 7), j = c(1, 1, 1, 1, 1, 3, 3, 3, 3,?
3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,?
3, 3, 3, 3, 3, 5, 5, 5, 5, 5), value = c(1.5, 2, 1, 0, 2, 2,?
1.5, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0.5, 1, 0, 2, 2, 1.5, 0, 0, 1,?
1.5, 2.5, 0, 1, 2, 1.5, 1, 0, 0, 1, 1, 2, 0, 0, 1), rank = c(0.75,?
1, 1, 0, 1, 1, 0.75, 0, 0, 0.5, 0.5, 1, 0, 1, 1, 1, 1, 1, NaN,?
1, 1, 0.6, NaN, 0, 0.5, 0.75, 1, NaN, 1, 1, 1, 0.5, NaN, NaN,?
1, 0.666666666666667, 1, NaN, NaN, 1)), .Names = c("Measure_id",?
"i", "j", "value", "rank"), row.names = c(NA, 40L), class = "data.frame")
>?

I want to get maximum 3 rows in each group of Measure_id. e.g. for measure_id 1 get the max ranks ?(select the max for each measure depending on the rank column).

how to do that
Best regards,
Ragia


 		 	   		  

From jholtman at gmail.com  Mon Nov  9 14:34:18 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 9 Nov 2015 08:34:18 -0500
Subject: [R] get maximum 3 rows by column elements in data frame
In-Reply-To: <DUB125-W6176C8E51EE1E84A21F1C0B3150@phx.gbl>
References: <DUB125-W6176C8E51EE1E84A21F1C0B3150@phx.gbl>
Message-ID: <CAAxdm-6XgWf39wGiAJAeOhY_jXCEtosiW86SNT75tKnLrCvBtQ@mail.gmail.com>

It is not entirely clear what you are asking for.  Can you provide a sample
of the output that you want from the data.  Here is the data split by
Measure_id, but not sure what to do with it:

> split(x, x$Measure_id)
$`1`
   Measure_id i j value      rank
1           1 2 1   1.5 0.7500000
6           1 2 3   2.0 1.0000000
11          1 2 4   1.0 0.5000000
16          1 4 3   2.0 1.0000000
21          1 5 1   2.0 1.0000000
26          1 5 2   1.5 0.7500000
31          1 7 3   1.5 1.0000000
36          1 7 5   1.0 0.6666667

$`2`
   Measure_id i j value rank
2           2 2 1   2.0 1.00
7           2 2 3   1.5 0.75
12          2 2 4   2.0 1.00
17          2 4 3   0.5 1.00
22          2 5 1   1.5 0.60
27          2 5 2   2.5 1.00
32          2 7 3   1.0 0.50
37          2 7 5   2.0 1.00

$`3`
   Measure_id i j value rank
3           3 2 1     1    1
8           3 2 3     0    0
13          3 2 4     0    0
18          3 4 3     1    1
23          3 5 1     0  NaN
28          3 5 2     0  NaN
33          3 7 3     0  NaN
38          3 7 5     0  NaN

$`4`
   Measure_id i j value rank
4           4 2 1     0    0
9           4 2 3     0    0
14          4 2 4     1    1
19          4 4 3     0  NaN
24          4 5 1     0    0
29          4 5 2     1    1
34          4 7 3     0  NaN
39          4 7 5     0  NaN

$`5`
   Measure_id i j value rank
5           5 2 1     2  1.0
10          5 2 3     1  0.5
15          5 2 4     2  1.0
20          5 4 3     2  1.0
25          5 5 1     1  0.5
30          5 5 2     2  1.0
35          5 7 3     1  1.0
40          5 7 5     1  1.0

>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 9, 2015 at 5:55 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:

> Dear group,
>
> I have the following data freame
>
> dput(df_all_nodes)
>
> structure(list(Measure_id = c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1,
> 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2,
> 3, 4, 5, 1, 2, 3, 4, 5), i = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7,
> 7, 7, 7, 7, 7, 7, 7, 7, 7), j = c(1, 1, 1, 1, 1, 3, 3, 3, 3,
> 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,
> 3, 3, 3, 3, 3, 5, 5, 5, 5, 5), value = c(1.5, 2, 1, 0, 2, 2,
> 1.5, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0.5, 1, 0, 2, 2, 1.5, 0, 0, 1,
> 1.5, 2.5, 0, 1, 2, 1.5, 1, 0, 0, 1, 1, 2, 0, 0, 1), rank = c(0.75,
> 1, 1, 0, 1, 1, 0.75, 0, 0, 0.5, 0.5, 1, 0, 1, 1, 1, 1, 1, NaN,
> 1, 1, 0.6, NaN, 0, 0.5, 0.75, 1, NaN, 1, 1, 1, 0.5, NaN, NaN,
> 1, 0.666666666666667, 1, NaN, NaN, 1)), .Names = c("Measure_id",
> "i", "j", "value", "rank"), row.names = c(NA, 40L), class = "data.frame")
> >
>
> I want to get maximum 3 rows in each group of Measure_id. e.g. for
> measure_id 1 get the max ranks  (select the max for each measure depending
> on the rank column).
>
> how to do that
> Best regards,
> Ragia
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Nov  9 14:37:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 9 Nov 2015 13:37:43 +0000
Subject: [R] get maximum 3 rows by column elements in data frame
In-Reply-To: <DUB125-W6176C8E51EE1E84A21F1C0B3150@phx.gbl>
References: <DUB125-W6176C8E51EE1E84A21F1C0B3150@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000163@SRVEXCHMBX.precheza.cz>

Hi

I am not completely sure what do you want, so here is my guess.

> dat<-structure(list(Measure_id = c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5), i = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7), j = c(1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5), value = c(1.5, 2, 1, 0, 2, 2, 1.5, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0.5, 1, 0, 2, 2, 1.5, 0, 0, 1, 1.5, 2.5, 0, 1, 2, 1.5, 1, 0, 0, 1, 1, 2, 0, 0, 1), rank = c(0.75, 1, 1, 0, 1, 1, 0.75, 0, 0, 0.5, 0.5, 1, 0, 1, 1, 1, 1, 1, NaN, 1, 1, 0.6, NaN, 0, 0.5, 0.75, 1, NaN, 1, 1, 1, 0.5, NaN, NaN, 1, 0.666666666666667, 1, NaN, NaN, 1)), .Names = c("Measure_id", "i", "j", "value", "rank"), row.names = c(NA, 40L), class = "data.frame")

I named your data dat. First I set decreasing order for Measure Id and rank.

> ooo<-order(dat[,1], dat[,5], decreasing=T)

I than changed order of rows.
> dat<-dat[ooo,]

And finally with this oneliner selected 3 rows in each measure_id by rank

> do.call(rbind, lapply(split(dat, dat[,1]), head, 3))
     Measure_id i j value rank
1.6           1 2 3   2.0    1
1.16          1 4 3   2.0    1
1.21          1 5 1   2.0    1
2.2           2 2 1   2.0    1
2.12          2 2 4   2.0    1
2.17          2 4 3   0.5    1
3.3           3 2 1   1.0    1
3.18          3 4 3   1.0    1
3.8           3 2 3   0.0    0
4.14          4 2 4   1.0    1
4.29          4 5 2   1.0    1
4.4           4 2 1   0.0    0
5.5           5 2 1   2.0    1
5.15          5 2 4   2.0    1
5.20          5 4 3   2.0    1

Is this what you wanted?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ragia
> Ibrahim
> Sent: Monday, November 09, 2015 11:55 AM
> To: r-help at r-project.org
> Subject: [R] get maximum 3 rows by column elements in data frame
>
> Dear group,
>
> I have the following data freame
>
> dput(df_all_nodes)
>
> structure(list(Measure_id = c(1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4,
> 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3,
> 4, 5), i = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,
> 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7), j =
> c(1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 1, 1, 1,
> 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5), value = c(1.5, 2,
> 1, 0, 2, 2, 1.5, 0, 0, 1, 1, 2, 0, 1, 2, 2, 0.5, 1, 0, 2, 2, 1.5, 0, 0,
> 1, 1.5, 2.5, 0, 1, 2, 1.5, 1, 0, 0, 1, 1, 2, 0, 0, 1), rank = c(0.75,
> 1, 1, 0, 1, 1, 0.75, 0, 0, 0.5, 0.5, 1, 0, 1, 1, 1, 1, 1, NaN, 1, 1,
> 0.6, NaN, 0, 0.5, 0.75, 1, NaN, 1, 1, 1, 0.5, NaN, NaN, 1,
> 0.666666666666667, 1, NaN, NaN, 1)), .Names = c("Measure_id", "i", "j",
> "value", "rank"), row.names = c(NA, 40L), class = "data.frame")
> >
>
> I want to get maximum 3 rows in each group of Measure_id. e.g. for
> measure_id 1 get the max ranks  (select the max for each measure
> depending on the rank column).
>
> how to do that
> Best regards,
> Ragia
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From studerov at gmail.com  Mon Nov  9 15:41:54 2015
From: studerov at gmail.com (David Studer)
Date: Mon, 9 Nov 2015 15:41:54 +0100
Subject: [R] calculate factor scores
Message-ID: <CAA1twZQ=7pmJoAi17aivoz2H0S8sirw_o5kJ+UHkmottYONKuQ@mail.gmail.com>

Hello everybody,

I have a problem regarding factor analysis:
As I am using the hetmat()-function from the polycor-package in order to
calculate different kinds of correlation coefficients automatically* I
cannot obtain
factor scores using fit$scores. The problem is that I am using the
fa()-function
with a correlation table (structural level) instead of raw data.

Can anyone help me in calculating factor scores ex post?

Thank you for any hints!
David

--
Here's the code:

# select variables
df<-data[c("var1", "var2", "var3", "var4", "var5", "var6")]

# compute heterogenous correlation matrix
library(polycor)
hetmat<-hetcor(df)$cor

# factor analysis
library(psych)

fa.parallel(hetmat) # number of factors?

fit<-fa(hetmat, nfactors=4, fm="ml", rotate="varimax") # factor analysis
colnames(fit$loadings)<-c("Factor1","Factor2","Factor3","Factor4")

fit$scores???

	[[alternative HTML version deleted]]


From mhrashidbau at yahoo.com  Mon Nov  9 14:26:24 2015
From: mhrashidbau at yahoo.com (Harun Rashid)
Date: Mon, 9 Nov 2015 22:26:24 +0900
Subject: [R] Subsetting dataframe by the nearest values of a vector elements
Message-ID: <56409F00.7010600@yahoo.com>

Hello,
I have a dataset with two columns 1. cross_section (range: 0~635), and 
2. elevation. The dataset has more than 100 rows. Now I want to make a 
subset on the condition that the 'cross_section' column will pick up the 
nearest cell from another vector (say 0, 50,100,150,200,.....,650).
How can I do this? I would really appreciate a solution.
Regards,
Harun
-- 

<mailto:mhrashidbau at yahoo.com>
<mailto:mhrashidbau at yahoo.com>

	[[alternative HTML version deleted]]


From PDalgd at gmail.com  Mon Nov  9 11:38:31 2015
From: PDalgd at gmail.com (peter dalgaard)
Date: Mon, 9 Nov 2015 11:38:31 +0100
Subject: [R] NULL dev.lis()
In-Reply-To: <CAAcyNCyipVR370fsAA2K5AgL8C4p+TnaiUmAtN=kRmnTo+808w@mail.gmail.com>
References: <CAGxgkWjF+O7xsL8gttyF=6YfABpA45BP6q6UKE+KDvz1qAF+BQ@mail.gmail.com>
	<CAAcyNCzxhvzJOKTNHt00NBn6v_5hbHpziMc6WefHLsLVdDWn7Q@mail.gmail.com>
	<22080.25884.348506.616193@stat.math.ethz.ch>
	<CAAcyNCyipVR370fsAA2K5AgL8C4p+TnaiUmAtN=kRmnTo+808w@mail.gmail.com>
Message-ID: <ED213E09-8FA4-45B5-AFBC-900A18F9A157@gmail.com>


On 09 Nov 2015, at 11:10 , Pascal Oettli via R-help <r-help at r-project.org> wrote:

> Martin,
> 
> Sorry, but what are you talking about ? Of course I know it is normal
> to get this result. It is what I explained in my message!

And Martin agreed/confirmed. Notice that "you" in English does not necessarily refer to you, personally...

-pd

> 
> Regards,
> Pascal
> 
> On Mon, Nov 9, 2015 at 6:19 PM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>>>>>> Pascal Oettli via R-help <r-help at r-project.org>
>>>>>>>    on Mon, 9 Nov 2015 14:18:37 +0900 writes:
>> 
>>> Dear Tom,
>>> Running R 3.2.2 on Ubuntu 15.04, if I run dev.list(), I get NULL.
>> 
>> Yes, indeed with all "regular" / "default" versions of R.
>> 
>> I you don't get that, you must have set something user-specific,
>> or possibly site-specific if you have a particularly customized site
>> maintainer setup.
>> 
>> Read
>>   ?Startup
>>   ?options
>> 
>> etc.
>> 
>>> And I guess it is the expected behavior, as per the help page, it "returns
>>> the numbers of all open devices, except device 1, the null device".
>>> So, if I run
>> 
>>> x11()
>>> dev.list()
>> 
>>> I get
>> 
>>> X11cairo
>>> 2
>> 
>>> HTH,
>>> Pascal
>> 
>>> On Mon, Nov 9, 2015 at 1:03 PM, Thomas Adams <tea3rd at gmail.com> wrote:
>>>> All,
>>>> 
>>>> I have previous built R from source many times, generally, without
>>>> problems. However on my new Ubuntu 15.04 Linux system with R 3.2.2 when I
>>>> run the command dev.list() I get:
>>>> 
>>>>> dev.list()
>>>> NULL
>>>> 
>>>> At the completion of running ./configure, I have
>>>> 
>>>> R is now configured for x86_64-pc-linux-gnu
>>>> 
>>>> Source directory:          .
>>>> Installation directory:    /usr/local
>>>> 
>>>> C compiler:                gcc -std=gnu99  -g -O2
>>>> Fortran 77 compiler:       gfortran  -g -O2
>>>> 
>>>> C++ compiler:              g++  -g -O2
>>>> C++ 11 compiler:           g++  -std=c++11 -g -O2
>>>> Fortran 90/95 compiler:    gfortran -g -O2
>>>> Obj-C compiler:
>>>> 
>>>> Interfaces supported:      X11
>>>> External libraries:        readline, zlib, lzma, PCRE, curl
>>>> Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
>>>> Options enabled:           shared BLAS, R profiling
>>>> 
>>>> Capabilities skipped:
>>>> Options not enabled:       memory profiling
>>>> 
>>>> Recommended packages:      yes
>>>> 
>>>> This issue is causing me problems with spplot, which I have posted on
>>>> r-sig-geo. R and the display of all other graphics seems to be fine,
>>>> otherwise. My previous installations of R would yield:
>>>> 
>>>>> dev.list()
>>>> X11cairo
>>>> 2
>>>> 
>>>> And I had no problems with spplot. Any thoughts?
>>>> 
>>>> Regards,
>>>> Tom
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>>> --
>>> Pascal Oettli
>>> Project Scientist
>>> JAMSTEC
>>> Yokohama, Japan
>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Pascal Oettli
> Project Scientist
> JAMSTEC
> Yokohama, Japan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luizernesto at gmail.com  Mon Nov  9 12:52:05 2015
From: luizernesto at gmail.com (Luiz Ernesto Costa Schmidt)
Date: Mon, 9 Nov 2015 09:52:05 -0200
Subject: [R] Plotting a glmmADMB model
Message-ID: <444F17D0-A6F1-48F7-9329-85C2E814C8CE@gmail.com>

Dear users,
Thanks for your attention. I?m running a glmm model using the glmmadmb function provided in the package glmmADMB.
My dependent variable is the number of individuals belonging to a single species of an aquatic insect, sampled throughout two non-consecutive years. The samples were classified by the following fixed factors:
- year: two levels (2004, 2009);
- hydroperiod (hyd): classified in two levels (high and low flow);
- daytime (time): two levels, night or day;
- stratification (str): two levels, bottom and surface
- water current velocity (vel): quantitative variable used as an offset, since the sampling method is very sensitive for the amount of water filtered, which has a strong correlation with water current velocity.
A single random term was added to the model, named as sampleID, since sampling at the bottom and at the surface were performed at the same moment (as far as understand, the inclusion of such random factor will treta them as a sampling block). I also added two interaction terms (hydroperiod:daytime, hydroperiod:stratification).

The model that I tested was a confirmatory one, based on a very precise biological hypothesis, resulting in the following output:

-----------
glmmadmb(formula = Count ~ year + hyd * (time + str) + offset(vel) + (1 | sampleID),
			family = ?nbinom?, zeroInflation = T)

AIC: 1484.1 

Coefficients:
                               Estimate	Std. Error z value	Pr(>|z|)    
(Intercept)		-0.339	0.229	-1.48	0.13756    
year2009			-0.164	0.148	-1.11	0.26852    
hydlow			 0.197	0.259	 0.76	0.44747    
timenight			-0.556	0.254	-2.19	0.02851 *  
strsurf			 0.808	0.215	 3.75	0.00017 ***
hydlow:timenight	 0.709	0.311	 2.28	0.02270 *  
hydlow:strsurf		-0.195	0.263	-0.74	0.45832    
? 
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Number of observations: total=366, sample=183 
Random effect variance(s):
Group=sampleID
            Variance StdDev
(Intercept)   0.2813 0.5304

Negative binomial dispersion parameter: 1.3265 (std. err.: 0.25595)
Zero-inflation: 1.0003e-06  (std. err.:  6.2823e-06 )

Log-likelihood: -732.046 
---------------

One graphical output that I opted to use shows the estimates provided by the model and their respective confidence intervals (I used the coefplot2 function).

Now I?m (desperately) trying to provide a better graphical representation about the predicted values from the model, in order to express graphically the magnitude and direction of variation explained by the model. However, I?m not sure if the data that I should use for such description comes from the following indexation 

model$fitted

or if I could use the command:

plot(interactionMeans(model))

Thank you so much for your attention,

Tch?


-- 
Luiz Ernesto Costa-Schmidt
http://lattes.cnpq.br/1402956553786728 <http://lattes.cnpq.br/1402956553786728>
P?s-doutorando - PNPD/CAPES
Universidade do Vale do Rio dos Sinos - UNISINOS
Programa de P?s-Gradua??o em Biologia
Avenida Unisinos, 950 - Sala E04 235
CEP 93022-000
S?o Leopoldo/RS - Brasil
Telefone: +55 51 3590.8477
http://www.unisinos.br/mestrado-e-doutorado/biologia <http://www.unisinos.br/mestrado-e-doutorado/biologia>

	[[alternative HTML version deleted]]


From bolseiro.raiz.csilva at portucelsoporcel.com  Mon Nov  9 16:19:40 2015
From: bolseiro.raiz.csilva at portucelsoporcel.com (Catarina Silva)
Date: Mon, 9 Nov 2015 15:19:40 -0000
Subject: [R] [GGplot] Geom_smooth with formula "power"?
In-Reply-To: <01E6DEB6-7F33-45B9-8C01-8BCF6D9906C5@dcn.davis.CA.us>
References: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>
	<01E6DEB6-7F33-45B9-8C01-8BCF6D9906C5@dcn.davis.CA.us>
Message-ID: <001501d11b02$0eb7b4e0$2c271ea0$@portucelsoporcel.com>

I've tried others initial solutions and the adjustement was done to power model in ggplot - geom_smooth.
But, with "nls" I can't do the confidence interval with ggplot - geom_smooth? I read that with "nls" we have to force "se=FALSE". Is this true?
How can I draw confidence interval in the plot?

I've done this:
> ggplot(data,aes(x = idade,y = v_mt)) +
+   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) + 
+   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2),se=FALSE) 
>
And then I don't have the confidence interval.

If I do:
> ggplot(data,aes(x = idade,y = v_mt)) +
+   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) + 
+   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2)) 
Error in pred$fit : $ operator is invalid for atomic vectors
>

Return error...

Ty,
Catarina Silva  

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: s?bado, 7 de Novembro de 2015 01:09
To: bolseiro.raiz.csilva at portucelsoporcel.com; R mailling list
Subject: Re: [R] [GGplot] Geom_smooth with formula "power"?

Does  [1] help? 

[1] http://stackoverflow.com/questions/10528631/add-exp-power-trend-line-to-a-ggplot
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On November 6, 2015 2:41:18 AM PST, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
>Hi,
>
>It's possible to use ggplot and geom_smooth to adjust a power curve to 
>the data?
>
>Initially i have done the adjustement with nls and the formula 'a*x^b', 
>but resulted the singular matrix error for start solution. 
>Alternatively I used the log transformation and i had correct results, 
>but I can't draw a power curve on the graphic.
>
>Someone know how to solve this problem?
>
> 
>
>Ty,
>
> 
>
>Catarina Silva
>
>
>Imprima no nosso papel - Cuide do ambiente
>--------------------------
>Print on our paper - Care for the environment.
>--------------------------
>http://backoffice.portucelsoporcel.net/dynamic-media/files/utilizar_papel_e_promover_o_desenvolvimento_da_floresta.pdf
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


Imprima no nosso papel - Cuide do ambiente
--------------------------
Print on our paper - Care for the environment.
--------------------------
http://backoffice.portucelsoporcel.net/dynamic-media/files/utilizar_papel_e_promover_o_desenvolvimento_da_floresta.pdf


From choi.jae.seok at gmail.com  Mon Nov  9 17:18:02 2015
From: choi.jae.seok at gmail.com (Jae Choi)
Date: Mon, 9 Nov 2015 12:18:02 -0400
Subject: [R] raster::cellFromXY behaviour
Message-ID: <CACrpLcWubkL_UQQaY569cyyZhT_iqQguc4PW1xAPwF-CgEsAUA@mail.gmail.com>

Hi users of raster:

When a point lands within a raster cell, the cell is correctly identified.
But when a point lands on the border between two adjacent raster cells,
cell identity seems to be inconsistent. We are wondering if this is an
error?

Example code follows to demonstrate our question:


require(raster)

xmn=-62
ymn=40
xmx=-60
ymx=42
res=.1

# simple raster with integers fill
r0 <- raster( xmn=xmn, ymn=ymn, xmx=xmx, ymx=ymx, res=res )
r0[] <- 1:ncell(r0)

# choose points along a horizontal band:
locx = seq(xmn, xmx, res)
xy1 <- cbind( locx + res/2, rep(ymn+res+res/2, dim(r)[1] ) ) # center of a
raster cell
xy2 <- cbind( locx,         rep(ymn+res+res/2, dim(r)[1] ) ) # on x-boundary
xy3 <- cbind( locx + res/2, rep(ymn+res, dim(r)[1] ) ) # on y-boundary
xy4 <- cbind( locx,         rep(ymn+res, dim(r)[1] ) ) # on a corner

# plots to visualize selected points
cid1 = cellFromXY(r, xy1); r = r0; r[cid1] <- NA; plot(r)
cid2 = cellFromXY(r, xy2); r = r0; r[cid2] <- NA; plot(r)
cid3 = cellFromXY(r, xy3); r = r0; r[cid3] <- NA; plot(r)
cid4 = cellFromXY(r, xy4); r = r0; r[cid4] <- NA; plot(r)

The expectation would have been to see no banding as seen in xy1 and xy3.
But xy2 and xy4 seem to skip a few cells. Not sure why?

Thanks!

	[[alternative HTML version deleted]]


From jandeleeuw6 at gmail.com  Mon Nov  9 17:23:18 2015
From: jandeleeuw6 at gmail.com (Jan Deleeuw)
Date: Mon, 9 Nov 2015 08:23:18 -0800
Subject: [R] homals pre-upgrade
Message-ID: <3AFE1685-885C-4B81-AD72-1FDB900F9DCD@gmail.com>


We are preparing an upgrade of the homals package on CRAN. The current non-packaged version of the code, with theory and examples, is at http://rpubs.com/deleeuw/87298. The new version implements principal component analysis, (multiset) canonical correlation analysis, multiple regression analysis, canonical discriminant analysis. multiple correspondence analysis, all with spline/polynomial x monotone/non-monotone x single/multiple optimal transformations of the variables. The article has a link to a small repository with html, pdf, Rmd versions and with R code, C code, and bib file. The iterative algorithm is now quite different from the original Gifi algorithm. It uses majorization to simplify the update steps and to make the problem embarrassingly parellel.


From jvadams at usgs.gov  Mon Nov  9 18:19:38 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 9 Nov 2015 11:19:38 -0600
Subject: [R] Subsetting dataframe by the nearest values of a vector
	elements
In-Reply-To: <56409F00.7010600@yahoo.com>
References: <56409F00.7010600@yahoo.com>
Message-ID: <CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>

Harun,

Can you give a simple example?

If your cross_section looked like this
c(144, 179, 214, 39, 284, 109, 74, 4, 249)
and your other vector looked like this
c(0, 50, 100, 150, 200, 250, 300, 350)
what would you want your subset to look like?

Jean

On Mon, Nov 9, 2015 at 7:26 AM, Harun Rashid via R-help <
r-help at r-project.org> wrote:

> Hello,
> I have a dataset with two columns 1. cross_section (range: 0~635), and
> 2. elevation. The dataset has more than 100 rows. Now I want to make a
> subset on the condition that the 'cross_section' column will pick up the
> nearest cell from another vector (say 0, 50,100,150,200,.....,650).
> How can I do this? I would really appreciate a solution.
> Regards,
> Harun
> --
>
> <mailto:mhrashidbau at yahoo.com>
> <mailto:mhrashidbau at yahoo.com>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Nov  9 18:57:16 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 9 Nov 2015 12:57:16 -0500
Subject: [R] Subsetting dataframe by the nearest values of a vector
	elements
In-Reply-To: <CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>
References: <56409F00.7010600@yahoo.com>
	<CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>
Message-ID: <CAAxdm-5nnU4v1UPdgQdsoJgJSqNBYTTdJvOsHSdbojT78qHwhA@mail.gmail.com>

Do you want the "closest" or what range it is in?  If you want the range,
then use 'cut':

> x <- c(144, 179, 214, 39, 284, 109, 74, 4, 249)
> range <- c(0, 50, 100, 150, 200, 250, 300, 350)
> result <- cut(x, breaks = range)
> cbind(x, as.character(result))
      x
 [1,] "144" "(100,150]"
 [2,] "179" "(150,200]"
 [3,] "214" "(200,250]"
 [4,] "39"  "(0,50]"
 [5,] "284" "(250,300]"
 [6,] "109" "(100,150]"
 [7,] "74"  "(50,100]"
 [8,] "4"   "(0,50]"
 [9,] "249" "(200,250]"



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 9, 2015 at 12:19 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Harun,
>
> Can you give a simple example?
>
> If your cross_section looked like this
> c(144, 179, 214, 39, 284, 109, 74, 4, 249)
> and your other vector looked like this
> c(0, 50, 100, 150, 200, 250, 300, 350)
> what would you want your subset to look like?
>
> Jean
>
> On Mon, Nov 9, 2015 at 7:26 AM, Harun Rashid via R-help <
> r-help at r-project.org> wrote:
>
> > Hello,
> > I have a dataset with two columns 1. cross_section (range: 0~635), and
> > 2. elevation. The dataset has more than 100 rows. Now I want to make a
> > subset on the condition that the 'cross_section' column will pick up the
> > nearest cell from another vector (say 0, 50,100,150,200,.....,650).
> > How can I do this? I would really appreciate a solution.
> > Regards,
> > Harun
> > --
> >
> > <mailto:mhrashidbau at yahoo.com>
> > <mailto:mhrashidbau at yahoo.com>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Nov  9 22:26:07 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 9 Nov 2015 21:26:07 +0000
Subject: [R] calculate factor scores
In-Reply-To: <CAA1twZQ=7pmJoAi17aivoz2H0S8sirw_o5kJ+UHkmottYONKuQ@mail.gmail.com>
References: <CAA1twZQ=7pmJoAi17aivoz2H0S8sirw_o5kJ+UHkmottYONKuQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DAE8E@mb02.ads.tamu.edu>

I think you can use predict.psych() in package psych. Since you analyzed a correlation matrix with fa() it does not have access to the original data. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Studer
Sent: Monday, November 9, 2015 8:42 AM
To: r-help at r-project.org
Subject: [R] calculate factor scores

Hello everybody,

I have a problem regarding factor analysis:
As I am using the hetmat()-function from the polycor-package in order to
calculate different kinds of correlation coefficients automatically* I
cannot obtain
factor scores using fit$scores. The problem is that I am using the
fa()-function
with a correlation table (structural level) instead of raw data.

Can anyone help me in calculating factor scores ex post?

Thank you for any hints!
David

--
Here's the code:

# select variables
df<-data[c("var1", "var2", "var3", "var4", "var5", "var6")]

# compute heterogenous correlation matrix
library(polycor)
hetmat<-hetcor(df)$cor

# factor analysis
library(psych)

fa.parallel(hetmat) # number of factors?

fit<-fa(hetmat, nfactors=4, fm="ml", rotate="varimax") # factor analysis
colnames(fit$loadings)<-c("Factor1","Factor2","Factor3","Factor4")

fit$scores???

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Tue Nov 10 02:09:52 2015
From: valkremk at gmail.com (Val)
Date: Mon, 9 Nov 2015 19:09:52 -0600
Subject: [R] Prefix
In-Reply-To: <CADv2QyGXwsTQt9A7UpGiLkMtf4GU6s5GBZyzG-d2kQAmUFzASg@mail.gmail.com>
References: <CAJOiR6ZTawsgqQn3GV_R52-ezZrDJUhOuiMd52mC5kROwKt0yQ@mail.gmail.com>
	<CADv2QyGXwsTQt9A7UpGiLkMtf4GU6s5GBZyzG-d2kQAmUFzASg@mail.gmail.com>
Message-ID: <CAJOiR6bhRLwjUjVvyb5ZzP1=mWM8kRJovvjdmtkOOQoX8M1+ow@mail.gmail.com>

HI  Dennis and David

Thank you very much! I really appreciate that.

Now I am half way from my final goal.  At the end what I would like is the
following output.


New_X1 New_X2  New_X3       Old X1
         1          0           0             0_Abbot
         2          0           0       1920_Alexa
         3          0           0       1960_Alex1
         4          1           2        2012_Smith
         5          1           0        1996_Carlo
         6          4           1         2013_Jacky
         7           0           6         2014_Jack
         8           7           5         2015_Almo


The idea here is that to order the individual based on time and creating a
unique individual and indexing it.  At the end I want them merge the
original X1 values to  the new values

I tried but I did not reach to my final goal.

v1  <-  DF$X4 <- as.character(paste(DF$TIME,DF$X1 ,sep="_"))
v2  <-  paste(DF$TIME[match(DF$X2,DF$X1)], DF$X2, sep="_")
v3  <-  paste(DF$TIME[match(DF$X3,DF$X1)], DF$X3, sep="_")

v11 <- matrix(v1, nrow = length(v1), byrow = TRUE)
v12 <- matrix(v2, nrow = length(v2), byrow = TRUE)
v13 <- matrix(v3, nrow = length(v3), byrow = TRUE)
v4  <-  cbind(v11,v12,v13)
v5  <-  as.matrix(v4)
v5  <-  replace(x, x == "NA_0", 0)       # repalce the "NA_0"
v6  <-  sort(unique(as.vector(v5)))

My problem is how to merge  the original unique Old_X1 values to  newly
created  values in the matrix

Thank you.






On Mon, Nov 9, 2015 at 2:49 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> Hi:
>
> Here's a way to do it with apply().
>
> DF <- read.table(textConnection(" X1   X2 X3   TIME
> Alex1      0         0       1960
> Alexa      0         0        1920
> Abbot      0         0          0
> Smith     Alex1  Alexa    2012
> Carla     Alex1      0        1996
> Jacky    Smith   Abbot    2013
> Jack       0         Jacky    2014
> Almo     Jack     Carla     2015   "),header = TRUE, stringsAsFactors =
> FALSE)
>
>
> refcol <- with(DF, paste(TIME, X1, sep = "_"))
>
> f <- function(x)
> {
>     r <- DF[, 1]          # reference column for names
>     u <- match(x, r)   # match positions of names in vector x with those
> in r
>     v <- refcol[u]       # substitute original names with those in refcol
>     v[is.na(v)] <- "0"  # set NAs in v to "0"
>     v
> }
>
> apply(DF[, grep("^X", names(DF))], 2, f)   # grep() selects out
> columns starting with "X"
>
> Dennis
>
> On Sun, Nov 8, 2015 at 4:05 PM, Val <valkremk at gmail.com> wrote:
> > HI all,
> >
> > DF <- read.table(textConnection(" X1   X2 X3   TIME
> > Alex1      0         0       1960
> > Alexa      0         0        1920
> > Abbot      0         0          0
> > Smith     Alex1  Alexa    2012
> > Carla     Alex1      0        1996
> > Jacky    Smith   Abbot    2013
> > Jack       0         Jacky    2014
> > Almo     Jack     Carla     2015   "),header = TRUE)
> >
> >
> > I want to add the time  variable as prefix to the first column  (X1)
> > and I did it as follow,
> >
> > DF$X4 <- as.character(paste(DF$TIME,DF$X1 ,sep="_"))
> > DF
> >
> > All names in column two (X1) and three  (X3) are in column one. so I just
> > want bring that prefix to column three and two, as well but I could not
> do
> > that one.
> >
> > Here is the final output  that  I would like to have.
> >
> >               X1                   X2                     X3
> > 1960_Alex                      0                       0
> > 1920_Alexa                     0                      0
> >  0_Abbot                          0                      0
> > 2012_Smith     1960_Alex     1920_Alexa
> > 1996_Carla      1960_Alex                     0
> >  2013_Jacky    2012_Smith         0_Abbot
> >  2014_Jack                       0      2013_Jacky
> >  2015_Almo        2014_Jack      1996_Carla
> >
> >
> > Your help is appreciated in advance
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Nov 10 03:17:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 9 Nov 2015 18:17:18 -0800
Subject: [R] Subsetting dataframe by the nearest values of a vector
	elements
In-Reply-To: <CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>
References: <56409F00.7010600@yahoo.com>
	<CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>
Message-ID: <2F4F896A-593C-4223-B516-F25D74664B65@comcast.net>


> On Nov 9, 2015, at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:
> 
> Harun,
> 
> Can you give a simple example?
> 
> If your cross_section looked like this
> c(144, 179, 214, 39, 284, 109, 74, 4, 249)
> and your other vector looked like this
> c(0, 50, 100, 150, 200, 250, 300, 350)
> what would you want your subset to look like?
> 
> Jean
> 
> On Mon, Nov 9, 2015 at 7:26 AM, Harun Rashid via R-help <
> r-help at r-project.org> wrote:
> 
>> Hello,
>> I have a dataset with two columns 1. cross_section (range: 0~635), and
>> 2. elevation. The dataset has more than 100 rows. Now I want to make a
>> subset on the condition that the 'cross_section' column will pick up the
>> nearest cell from another vector (say 0, 50,100,150,200,.....,650).
>> How can I do this? I would really appreciate a solution.

If you what the "other vector" to define the ?cell? boundaries, and using Jean?s example, it is a simple application of `findInterval`:

> inp <- c(144, 179, 214, 39, 284, 109, 74, 4, 249)
> mids <- c(0, 50, 100, 150, 200, 250, 300, 350)

> findInterval( inp, c(mids) )
[1] 3 4 5 1 6 3 2 1 5

On the other hand ...

To find the number of "closest point", this might help:


> findInterval(inp, c( mids[1]-.001, head(mids,-1)+diff(mids)/2, tail(mids,1)+.001 ) )
[1] 4 5 5 2 7 3 2 1 6



? 
David Winsemius
Alameda, CA, USA


From gudrun.gygli at wur.nl  Tue Nov 10 09:15:43 2015
From: gudrun.gygli at wur.nl (Gygli, Gudrun)
Date: Tue, 10 Nov 2015 08:15:43 +0000
Subject: [R] R units of margins, text and points in a figure
Message-ID: <1447143345602.18825@wur.nl>

Dear R-help,


I am trying to plot some data in a plot where I leave a big margin free to add other information, namely text and points.

I am now struggling with keeping the size of the margin, text and points in a fixed ratio. I want this so that the layout of the figure does not change every time I plot new data.

I have:

a<-8
counter<-1
spacing<-a/(3*a)
adding<-a/(3*a)
start<-a*(a/3)

alphabet<-c("A","A","A","A","A","A","A","A")
x<-c(1,2,3,4,5,6,7,8)
y<-c(10,20,30,40,50,60,70,80)
png(file="TESTING.png", units="in", width=a, height=a, res=a*100)
par(xpd=NA,mar=c(0,0,0,0),oma=c(0,0,0,(3*a))) #bottom, left,top, right

plot.new()
plot(x,y)
points(pch=20,10, 10, cex=5)
text(10,10, alphabet, cex=5, col="blue")

What I do not understand is why the size of the point and the text is not the same and why the margin can be "bigger" than the width of the figure.

BASICALLY, the units of the margins, the points and the text are not the same...

What I need is a way to make the size of the point and text AND the margin independent of the data I plot so that the figure always looks the same although there is more data in it in some cases (for example 10 or 20 points with text in the margin).

This could be done by setting the units of points, text and margin to inches so that a is the same for all of them... Or to know the ratio between the different units used by R for margin, points and text...

Any ideas on how to solve that?

Please let me know if clarifications are needed!


Gudrun







Gudrun Gygli, MSc

PhD candidate

Wageningen University
Laboratory of Biochemistry
Dreijenlaan 3
6703 HA Wageningen
The Netherlands

Phone  31 317483387
e-mail: gudrun.gygli at wur.nl

- - - - - - - - - - - - - - - - - -

Project information: http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm


From mhrashidbau at yahoo.com  Tue Nov 10 09:39:12 2015
From: mhrashidbau at yahoo.com (Harun Rashid)
Date: Tue, 10 Nov 2015 17:39:12 +0900
Subject: [R] Subsetting dataframe by the nearest values of a vector
 elements
In-Reply-To: <2F4F896A-593C-4223-B516-F25D74664B65@comcast.net>
References: <56409F00.7010600@yahoo.com>
	<CAN5YmCHmKOt86ijEm6JxQAzQCfEgBb7zcivSHtUORA=Hc96ZPA@mail.gmail.com>
	<2F4F896A-593C-4223-B516-F25D74664B65@comcast.net>
Message-ID: <5641AD30.6070206@yahoo.com>

HI Jean,
Here is part of my data. As you can see, I have cross-section point and 
corresponding elevation of a river. Now I want to select cross-section 
points by 50m interval. But the real cross-section data might not have 
exact points say 0, 50, 100,?and so on. Therefore, I need to take points 
closest to those values.

    cross_section elevation
    1: 5.608 12.765
    2: 11.694 10.919
    3: 14.784 10.274
    4: 20.437 7.949
    5: 22.406 7.180
    101: 594.255 7.710
    102: 595.957 7.717
    103: 597.144 7.495
    104: 615.925 7.513
    105: 615.890 7.751

I checked for some suggestions [particularly here 
<http://stackoverflow.com/questions/20133344/find-closest-value-in-a-vector-with-binary-search>] 
and finally did like this.

    intervals <- c(5,50,100,150,200,250,300,350,400,450,500,550,600)
    dt = data.table(real.val = w$cross_section, w)
    setattr(dt,?sorted?,?cross_section?)
    dt[J(intervals), roll = ?nearest?]

And it gave me what I wanted.

    dt[J(intervals), roll = ?nearest?]
    cross_section real.val elevation
    1: 5 5.608 12.765
    2: 50 49.535 6.744
    3: 100 115.614 8.026
    4: 150 152.029 7.206
    5: 200 198.201 6.417
    6: 250 247.855 4.497
    7: 300 298.450 11.299
    8: 350 352.473 11.534
    9: 400 401.287 10.550
    10: 450 447.768 9.371
    11: 500 501.284 8.984
    12: 550 550.650 16.488
    13: 600 597.144 7.495

I don?t know whether there is a smarter to accomplish this!
Thanks in advance.
Regards,
Harun

On 11/10/15 11:17 AM, David Winsemius wrote:

>> On Nov 9, 2015, at 9:19 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>>
>> Harun,
>>
>> Can you give a simple example?
>>
>> If your cross_section looked like this
>> c(144, 179, 214, 39, 284, 109, 74, 4, 249)
>> and your other vector looked like this
>> c(0, 50, 100, 150, 200, 250, 300, 350)
>> what would you want your subset to look like?
>>
>> Jean
>>
>> On Mon, Nov 9, 2015 at 7:26 AM, Harun Rashid via R-help <
>> r-help at r-project.org> wrote:
>>
>>> Hello,
>>> I have a dataset with two columns 1. cross_section (range: 0~635), and
>>> 2. elevation. The dataset has more than 100 rows. Now I want to make a
>>> subset on the condition that the 'cross_section' column will pick up the
>>> nearest cell from another vector (say 0, 50,100,150,200,.....,650).
>>> How can I do this? I would really appreciate a solution.
> If you what the "other vector" to define the ?cell? boundaries, and using Jean?s example, it is a simple application of `findInterval`:
>
>> inp <- c(144, 179, 214, 39, 284, 109, 74, 4, 249)
>> mids <- c(0, 50, 100, 150, 200, 250, 300, 350)
>> findInterval( inp, c(mids) )
> [1] 3 4 5 1 6 3 2 1 5
>
> On the other hand ...
>
> To find the number of "closest point", this might help:
>
>
>> findInterval(inp, c( mids[1]-.001, head(mids,-1)+diff(mids)/2, tail(mids,1)+.001 ) )
> [1] 4 5 5 2 7 3 2 1 6
>
>
>
> ?
> David Winsemius
> Alameda, CA, USA
>
?

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Nov 10 09:48:59 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 10 Nov 2015 19:48:59 +1100
Subject: [R] R units of margins, text and points in a figure
In-Reply-To: <1447143345602.18825@wur.nl>
References: <1447143345602.18825@wur.nl>
Message-ID: <CA+8X3fU=OeYoeiWLdTfBBH_RLXQO8SwVMm6wXjFXCtqY=h1rVw@mail.gmail.com>

Hi Gudrun,
Let's see. First, the "cex" argument means character _expansion_, not an
absolute size. So as the symbols and letters start out different sizes,
that proportional difference remains as they are expanded. The size of text
depends a bit upon the font that is being used. Perhaps if you determine
the expansions necessary to get the "A" the same size as the pch=20 symbol
(I get about two and one half times the expansion for the symbol as for the
letter) you can write this into your code.

Margins are another unit, the number of lines (vertical space required for
a line of text). This is somewhat larger than the actual vertical extent of
the letters as there is a space left between lines. If you change the
device (eg from PNG to PDF) you will probably encounter yet another change
in the apparent size of things. I suggest using the eyeball method to work
out the proportions for the device you want to use and be prepared to
change things if you move to another graphics device.

Jim


On Tue, Nov 10, 2015 at 7:15 PM, Gygli, Gudrun <gudrun.gygli at wur.nl> wrote:

> Dear R-help,
>
>
> I am trying to plot some data in a plot where I leave a big margin free to
> add other information, namely text and points.
>
> I am now struggling with keeping the size of the margin, text and points
> in a fixed ratio. I want this so that the layout of the figure does not
> change every time I plot new data.
>
> I have:
>
> a<-8
> counter<-1
> spacing<-a/(3*a)
> adding<-a/(3*a)
> start<-a*(a/3)
>
> alphabet<-c("A","A","A","A","A","A","A","A")
> x<-c(1,2,3,4,5,6,7,8)
> y<-c(10,20,30,40,50,60,70,80)
> png(file="TESTING.png", units="in", width=a, height=a, res=a*100)
> par(xpd=NA,mar=c(0,0,0,0),oma=c(0,0,0,(3*a))) #bottom, left,top, right
>
> plot.new()
> plot(x,y)
> points(pch=20,10, 10, cex=5)
> text(10,10, alphabet, cex=5, col="blue")
>
> What I do not understand is why the size of the point and the text is not
> the same and why the margin can be "bigger" than the width of the figure.
>
> BASICALLY, the units of the margins, the points and the text are not the
> same...
>
> What I need is a way to make the size of the point and text AND the margin
> independent of the data I plot so that the figure always looks the same
> although there is more data in it in some cases (for example 10 or 20
> points with text in the margin).
>
> This could be done by setting the units of points, text and margin to
> inches so that a is the same for all of them... Or to know the ratio
> between the different units used by R for margin, points and text...
>
> Any ideas on how to solve that?
>
> Please let me know if clarifications are needed!
>
>
> Gudrun
>
>
>
>
>
>
>
> Gudrun Gygli, MSc
>
> PhD candidate
>
> Wageningen University
> Laboratory of Biochemistry
> Dreijenlaan 3
> 6703 HA Wageningen
> The Netherlands
>
> Phone  31 317483387
> e-mail: gudrun.gygli at wur.nl
>
> - - - - - - - - - - - - - - - - - -
>
> Project information:
> http://www.wageningenur.nl/en/show/Bioinformatics-structural-biology-and-molecular-modeling-of-Vanillyl-Alcohol-Oxidases-VAOs.htm
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wewolski at gmail.com  Tue Nov 10 11:40:35 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 10 Nov 2015 11:40:35 +0100
Subject: [R] conditionally disable evaluation of chunks in Rmarkdown...
Message-ID: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>

I do have an Rmd where I would like to conditionally evaluate the second part.

So far I am working with :

```{r}
if(length(specLibrary at ionlibrary) ==0){
  library(knitr)
  opts_chunk$set(eval=FALSE, message=FALSE, echo=FALSE)
}
```

Which disables the evaluation of subsequent chunks.

However my RMD file contains also these kind of snippets : `r `

How do I disable them?

regards



-- 
Witold Eryk Wolski


From bgunter.4567 at gmail.com  Tue Nov 10 15:44:16 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 Nov 2015 06:44:16 -0800
Subject: [R] conditionally disable evaluation of chunks in Rmarkdown...
In-Reply-To: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
References: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
Message-ID: <CAGxFJbSYeOtYLPQwBc4Y0gRfY9M3VVZ=L061RptDx-xwpaWVSw@mail.gmail.com>

Strictly speaking, wrong email list.

Markdown is R Studio software, and you should post on their support site.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 10, 2015 at 2:40 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> I do have an Rmd where I would like to conditionally evaluate the second part.
>
> So far I am working with :
>
> ```{r}
> if(length(specLibrary at ionlibrary) ==0){
>   library(knitr)
>   opts_chunk$set(eval=FALSE, message=FALSE, echo=FALSE)
> }
> ```
>
> Which disables the evaluation of subsequent chunks.
>
> However my RMD file contains also these kind of snippets : `r `
>
> How do I disable them?
>
> regards
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Nov 10 16:20:59 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 10 Nov 2015 07:20:59 -0800
Subject: [R] conditionally disable evaluation of chunks in Rmarkdown...
In-Reply-To: <CAGxFJbSYeOtYLPQwBc4Y0gRfY9M3VVZ=L061RptDx-xwpaWVSw@mail.gmail.com>
References: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
	<CAGxFJbSYeOtYLPQwBc4Y0gRfY9M3VVZ=L061RptDx-xwpaWVSw@mail.gmail.com>
Message-ID: <1D73CAF0-EC93-40C8-A857-AE3F7CC2F949@dcn.davis.CA.us>

Well, strictly speaking knitr and rmarkdown are a contributed packages and the official contact for any contributed package is found via the maintainer() function. The Posting Guide indicates that R-help should only be used as a backup if that avenue is a dead end.

To be fair to the OP, there are a lot of useful contributed packages that get discussed here anyway. But Bert is right that if there is a forum more appropriate for a contributed package then it should be preferred and any question posed here should mention any dead ends encountered and good netiquette would be to link to any publicly-visible record of those attempts.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 10, 2015 6:44:16 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Strictly speaking, wrong email list.
>
>Markdown is R Studio software, and you should post on their support
>site.
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Tue, Nov 10, 2015 at 2:40 AM, Witold E Wolski <wewolski at gmail.com>
>wrote:
>> I do have an Rmd where I would like to conditionally evaluate the
>second part.
>>
>> So far I am working with :
>>
>> ```{r}
>> if(length(specLibrary at ionlibrary) ==0){
>>   library(knitr)
>>   opts_chunk$set(eval=FALSE, message=FALSE, echo=FALSE)
>> }
>> ```
>>
>> Which disables the evaluation of subsequent chunks.
>>
>> However my RMD file contains also these kind of snippets : `r `
>>
>> How do I disable them?
>>
>> regards
>>
>>
>>
>> --
>> Witold Eryk Wolski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From denis.francisci at gmail.com  Tue Nov 10 17:26:08 2015
From: denis.francisci at gmail.com (Denis Francisci)
Date: Tue, 10 Nov 2015 17:26:08 +0100
Subject: [R] alignments in random points
Message-ID: <CAJMcJMAqGuhaX+y3QeFmR=ad5NUjqenAtWO9QA=gLksgzPkZiQ@mail.gmail.com>

Dear forum,
I have a number of random point in a polygon. I would like to find those
points lying on the same lines.
Is there an R function to find alignments in points (something like this:
https://en.wikipedia.org/wiki/Alignments_of_random_points)?
And is it possible to do the same thing but changing the width of lines?

If it could be useful, I attached an example of R code that I'm using.

Thank's in advance,

DF


CODE:

library(sp)
poly<-matrix(c(16,17,25,22,16,58,55,55,61,58),ncol=2,nrow=5)

> poly
     [,1] [,2]
[1,]   16   58
[2,]   17   55
[3,]   25   55
[4,]   22   61
[5,]   16   58

p=Polygon(poly)
ps=Polygons(list(p),1)
sps=SpatialPolygons(list(ps))

p.rd=spsample(sps,n=150,"random")
plot(sps)
points(p.rd,pch=16, col='blue',cex=0.3)

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Tue Nov 10 17:47:51 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Tue, 10 Nov 2015 16:47:51 +0000
Subject: [R] ts.intersect() not working
Message-ID: <248E6FA047A8C746BA491485764190F526608230@ESESSMB207.ericsson.se>

It appears to be a numerical precision issue introduced while computing the "end" value of a time series,
if not already specified at ts() input parameter level.

You may want to download the R source code:

  https://cran.r-project.org/src/base/R-3/R-3.2.2.tar.gz

and look into R-3.2.2\src\library\stats\R\ts.R, specifically at code block lines 52..64,
where "end" is handled.

Then look at block code 140-142 ts.R, where a comparison is performed in order to determine if
the time series are overlapping.

In your second scenario (b2, b3) it happens that:

> tsps
                   [,1]               [,2]
[1,] 2009.5833333333333 2009.6666666666667
[2,] 2009.6666666666665 2009.6666666666667
[3,]   12.0000000000000   12.0000000000000
> st <- max(tsps[1,])
> en <- min(tsps[2,])
> st
[1] 2009.6666666666667
> en
[1] 2009.6666666666665

And (st > en) triggers the "non-intersecting series" warning.

That issue has origin inside the ts() function in the "end" computation based on start, ndata and frequency.

What basically happens can be so replicated:

start = c(2009, 8)
end = c(2009,9)
frequency=12
ndata=2

start <- start[1L] + (start[2L] - 1)/frequency
start
[1] 2009.5833333333333

end <- end[1L] + (end[2L] - 1)/frequency
end
[1] 2009.6666666666667

end <- start + (ndata - 1)/frequency
end
[1] 2009.6666666666665

Note the difference between the two "end" values above.

As workaround, you can specify the "end" parameter in the ts() call.


> b2 <- ts(data = c(10, 20), start = c(2009, 8), end = c(2009,9), frequency = 12);
> b2
     Aug Sep
2009  10  20
>
> b3 <- ts(data = matrix(data = 4:6, nrow = 1), start = c(2009, 9), end = c(2009,9), frequency = 12);
> b3
         Series 1 Series 2 Series 3
Sep 2009        4        5        6
>
> bb <- ts.intersect(b2, b3);
> bb
         b2 b3.Series 1 b3.Series 2 b3.Series 3
Sep 2009 20           4           5           6


Hope this helps

--
GG

	[[alternative HTML version deleted]]


From xie at yihui.name  Tue Nov 10 18:00:53 2015
From: xie at yihui.name (Yihui Xie)
Date: Tue, 10 Nov 2015 11:00:53 -0600
Subject: [R] conditionally disable evaluation of chunks in Rmarkdown...
In-Reply-To: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
References: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
Message-ID: <CANROs4egfYufZVdH2u6rdqky0aBBA_dMprwNqhtiMc4csXFOkw@mail.gmail.com>

The short answer is you cannot. Inline R code is always evaluated.
When it is not evaluated, I doubt if your output still makes sense,
e.g. "The value of x is `r x`." becomes "The value of x is ." That
sounds odd to me.

If you want to disable the evaluate of inline code anyway, you may use
a custom function to do it. e.g.

cond_eval = function(x) {
  if (isTRUE(knitr::opts_chunk$get('eval'))) x
}

Then `r cond_eval(x)` instead of `r x`.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, Nov 10, 2015 at 4:40 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> I do have an Rmd where I would like to conditionally evaluate the second part.
>
> So far I am working with :
>
> ```{r}
> if(length(specLibrary at ionlibrary) ==0){
>   library(knitr)
>   opts_chunk$set(eval=FALSE, message=FALSE, echo=FALSE)
> }
> ```
>
> Which disables the evaluation of subsequent chunks.
>
> However my RMD file contains also these kind of snippets : `r `
>
> How do I disable them?
>
> regards
>
>
>
> --
> Witold Eryk Wolski


From kushlevk at gmail.com  Tue Nov 10 09:14:42 2015
From: kushlevk at gmail.com (Kostadin Kushlev)
Date: Tue, 10 Nov 2015 03:14:42 -0500
Subject: [R] MAc-pakcage,
	on OS-X 10.11.1: Warning Message In sqrt(var.T.agg.tau) : NaNs
	produced
Message-ID: <1F98F046-ECDF-482C-A0A7-356511B0C848@gmail.com>

Hi there, 

I am trying to run a mini meta-analysis for three studies within one of my papers. I am using the Mac package for meta-analyzing correlation coefficients. 

I am using the following command: omni(es = z, var = var.z, data = dat, type="weighted", method = "fixed", ztor = TRUE)

This produces the expected values, but also a warning message: In sqrt(var.T.agg.tau) : NaNs produced

This message is repeated twice.

I am wondering how to interpret this error message. Is this because the program can?t estimate certain parameters due to the small number of correlation coefficients I am trying to analyze (only 3)? 

Most importantly, can I report and interpret the output despite those messages? 

Kosta 
 


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Nov 10 18:47:58 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 10 Nov 2015 09:47:58 -0800
Subject: [R] [GGplot] Geom_smooth with formula "power"?
In-Reply-To: <001501d11b02$0eb7b4e0$2c271ea0$@portucelsoporcel.com>
References: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>
	<01E6DEB6-7F33-45B9-8C01-8BCF6D9906C5@dcn.davis.CA.us>
	<001501d11b02$0eb7b4e0$2c271ea0$@portucelsoporcel.com>
Message-ID: <F8F783E4-A056-446A-A390-0D9F2D9828FE@comcast.net>


> On Nov 9, 2015, at 7:19 AM, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
> 
> I've tried others initial solutions and the adjustement was done to power model in ggplot - geom_smooth.
> But, with "nls" I can't do the confidence interval with ggplot - geom_smooth? I read that with "nls" we have to force "se=FALSE". Is this true?

Well, sort of. Setting `se = FALSE` prevents the ggplot2 functions from trying to force nls and nls.predict to do something that is not in their design.

> How can I draw confidence interval in the plot?
> 
> I've done this:
>> ggplot(data,aes(x = idade,y = v_mt)) +
> +   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) + 
> +   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2),se=FALSE) 
>> 
> And then I don't have the confidence interval.
> 
> If I do:
>> ggplot(data,aes(x = idade,y = v_mt)) +
> +   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) + 
> +   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2)) 
> Error in pred$fit : $ operator is invalid for atomic vectors
>> 
> 
> Return error?
> 
Read the help page for nls. The ?se.fit' parameter is set to FALSE and efforts to make it TRUE will be ignored. So `predict.nls` simply does not return std-error estimates in the typical manner of other predict.* functions. I believe this is because the authors of `nls` did not think there was a clear answer to the question of what confidence bounds should be returned. 

 If you want to add confidence bounds to an nls, then you need to decide what bounds to add, and then use the ggplot2 line-drawing functions to overlay them on your own. I found posts in Rhelp that pointed me to the ?nls2' package, but when I tried to run the code I got messages saying that the `as.lm` function could not be found. 

http://markmail.org/message/7kvolf5zzpqyb7l2?q=list:org%2Er-project%2Er-help+as%2Elm+is+a+linear+model+between+the+response+variable+and+the+gradient

> require(nls2)
Loading required package: nls2
Loading required package: proto
> fm <- nls(demand ~ SSasympOrig(Time, A, lrc), data = BOD)
> predict(as.lm(fm), interval = "confidence")
Error in predict(as.lm(fm), interval = "confidence") : 
  could not find function "as.lm"
> getAnywhere(as.lm)
no object named ?as.lm? was found


I also found a couple of posts on R-bloggers pointing me to the ?propagate' package which has two different methods for constructing confidence intervals.

http://rmazing.wordpress.com/2013/08/14/predictnls-part-1-monte-carlo-simulation-confidence-intervals-for-nls-models/
http://rmazing.wordpress.com/2013/08/26/predictnls-part-2-taylor-approximation-confidence-intervals-for-nls-models/



? 
David.

> Ty,
> Catarina Silva  
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
> Sent: s?bado, 7 de Novembro de 2015 01:09
> To: bolseiro.raiz.csilva at portucelsoporcel.com; R mailling list
> Subject: Re: [R] [GGplot] Geom_smooth with formula "power"?
> 
> Does  [1] help? 
> 
> [1] http://stackoverflow.com/questions/10528631/add-exp-power-trend-line-to-a-ggplot
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On November 6, 2015 2:41:18 AM PST, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
>> Hi,
>> 
>> It's possible to use ggplot and geom_smooth to adjust a power curve to 
>> the data?
>> 
>> Initially i have done the adjustement with nls and the formula 'a*x^b', 
>> but resulted the singular matrix error for start solution. 
>> Alternatively I used the log transformation and i had correct results, 
>> but I can't draw a power curve on the graphic.
>> 
>> Someone know how to solve this problem?
>> 
>> 

David Winsemius
Alameda, CA, USA


From lists at dewey.myzen.co.uk  Tue Nov 10 19:16:02 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 10 Nov 2015 18:16:02 +0000
Subject: [R] MAc-pakcage,
 on OS-X 10.11.1: Warning Message In sqrt(var.T.agg.tau) : NaNs
 produced
In-Reply-To: <1F98F046-ECDF-482C-A0A7-356511B0C848@gmail.com>
References: <1F98F046-ECDF-482C-A0A7-356511B0C848@gmail.com>
Message-ID: <56423462.3030505@dewey.myzen.co.uk>

Dear Kostadin

You could give us the data (after all there are only three studies) so 
we can run it through a different package or you could look at the code 
for omni and see where it is computing sqrt(var.T.agg.tau) and how it 
computed that in the first place.

And you could turn off HTML in your mailer as otherwise your mail can 
get corrupted.

On 10/11/2015 08:14, Kostadin Kushlev wrote:
> Hi there,
>
> I am trying to run a mini meta-analysis for three studies within one of my papers. I am using the Mac package for meta-analyzing correlation coefficients.
>
> I am using the following command: omni(es = z, var = var.z, data = dat, type="weighted", method = "fixed", ztor = TRUE)
>
> This produces the expected values, but also a warning message: In sqrt(var.T.agg.tau) : NaNs produced
>
> This message is repeated twice.
>
> I am wondering how to interpret this error message. Is this because the program can?t estimate certain parameters due to the small number of correlation coefficients I am trying to analyze (only 3)?
>
> Most importantly, can I report and interpret the output despite those messages?
>
> Kosta
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Tue Nov 10 20:04:33 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 10 Nov 2015 11:04:33 -0800
Subject: [R] [GGplot] Geom_smooth with formula "power"?
In-Reply-To: <F8F783E4-A056-446A-A390-0D9F2D9828FE@comcast.net>
References: <000301d1187f$abcbabe0$036303a0$@portucelsoporcel.com>
	<01E6DEB6-7F33-45B9-8C01-8BCF6D9906C5@dcn.davis.CA.us>
	<001501d11b02$0eb7b4e0$2c271ea0$@portucelsoporcel.com>
	<F8F783E4-A056-446A-A390-0D9F2D9828FE@comcast.net>
Message-ID: <CAGxFJbTSS6W8w+=eys=q3QYnBceo1YYpcCWwQCtFG9B0eqfiBw@mail.gmail.com>

See section 8.4-8.5 of MASS 4th Ed. (the book) and the use of
profile.nls() and friends for profiling the log likelihhood surface.

Warning: standard F,t approximations may be poor if the log likelihood
is not nearly enough quadratic. The whole issue of what df to use is
also contentious/unresolved.

-- Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 10, 2015 at 9:47 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Nov 9, 2015, at 7:19 AM, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
>>
>> I've tried others initial solutions and the adjustement was done to power model in ggplot - geom_smooth.
>> But, with "nls" I can't do the confidence interval with ggplot - geom_smooth? I read that with "nls" we have to force "se=FALSE". Is this true?
>
> Well, sort of. Setting `se = FALSE` prevents the ggplot2 functions from trying to force nls and nls.predict to do something that is not in their design.
>
>> How can I draw confidence interval in the plot?
>>
>> I've done this:
>>> ggplot(data,aes(x = idade,y = v_mt)) +
>> +   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) +
>> +   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2),se=FALSE)
>>>
>> And then I don't have the confidence interval.
>>
>> If I do:
>>> ggplot(data,aes(x = idade,y = v_mt)) +
>> +   geom_point(alpha=2/10, shape=21,fill="darkgray", colour="black", size=3) +
>> +   geom_smooth(method = 'nls', formula = y ~ a * x^b, start = list(a=1,b=2))
>> Error in pred$fit : $ operator is invalid for atomic vectors
>>>
>>
>> Return error?
>>
> Read the help page for nls. The ?se.fit' parameter is set to FALSE and efforts to make it TRUE will be ignored. So `predict.nls` simply does not return std-error estimates in the typical manner of other predict.* functions. I believe this is because the authors of `nls` did not think there was a clear answer to the question of what confidence bounds should be returned.
>
>  If you want to add confidence bounds to an nls, then you need to decide what bounds to add, and then use the ggplot2 line-drawing functions to overlay them on your own. I found posts in Rhelp that pointed me to the ?nls2' package, but when I tried to run the code I got messages saying that the `as.lm` function could not be found.
>
> http://markmail.org/message/7kvolf5zzpqyb7l2?q=list:org%2Er-project%2Er-help+as%2Elm+is+a+linear+model+between+the+response+variable+and+the+gradient
>
>> require(nls2)
> Loading required package: nls2
> Loading required package: proto
>> fm <- nls(demand ~ SSasympOrig(Time, A, lrc), data = BOD)
>> predict(as.lm(fm), interval = "confidence")
> Error in predict(as.lm(fm), interval = "confidence") :
>   could not find function "as.lm"
>> getAnywhere(as.lm)
> no object named ?as.lm? was found
>
>
> I also found a couple of posts on R-bloggers pointing me to the ?propagate' package which has two different methods for constructing confidence intervals.
>
> http://rmazing.wordpress.com/2013/08/14/predictnls-part-1-monte-carlo-simulation-confidence-intervals-for-nls-models/
> http://rmazing.wordpress.com/2013/08/26/predictnls-part-2-taylor-approximation-confidence-intervals-for-nls-models/
>
>
>
> ?
> David.
>
>> Ty,
>> Catarina Silva
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>> Sent: s?bado, 7 de Novembro de 2015 01:09
>> To: bolseiro.raiz.csilva at portucelsoporcel.com; R mailling list
>> Subject: Re: [R] [GGplot] Geom_smooth with formula "power"?
>>
>> Does  [1] help?
>>
>> [1] http://stackoverflow.com/questions/10528631/add-exp-power-trend-line-to-a-ggplot
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On November 6, 2015 2:41:18 AM PST, Catarina Silva <bolseiro.raiz.csilva at portucelsoporcel.com> wrote:
>>> Hi,
>>>
>>> It's possible to use ggplot and geom_smooth to adjust a power curve to
>>> the data?
>>>
>>> Initially i have done the adjustement with nls and the formula 'a*x^b',
>>> but resulted the singular matrix error for start solution.
>>> Alternatively I used the log transformation and i had correct results,
>>> but I can't draw a power curve on the graphic.
>>>
>>> Someone know how to solve this problem?
>>>
>>>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Tue Nov 10 20:51:39 2015
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 10 Nov 2015 11:51:39 -0800
Subject: [R] conditionally disable evaluation of chunks in Rmarkdown...
In-Reply-To: <CANROs4egfYufZVdH2u6rdqky0aBBA_dMprwNqhtiMc4csXFOkw@mail.gmail.com>
References: <CAAjnpdjvq3iphi06gDxFNuiRXg_e059b_2T6vP2yTqEofu1X5g@mail.gmail.com>
	<CANROs4egfYufZVdH2u6rdqky0aBBA_dMprwNqhtiMc4csXFOkw@mail.gmail.com>
Message-ID: <CAFDcVCQYdyg0FFwMva1aYOQ4w+3Qd2jsgrbC9+aD003+eZ+-Kw@mail.gmail.com>

On Tue, Nov 10, 2015 at 9:00 AM, Yihui Xie <xie at yihui.name> wrote:
> The short answer is you cannot. Inline R code is always evaluated.
> When it is not evaluated, I doubt if your output still makes sense,
> e.g. "The value of x is `r x`." becomes "The value of x is ." That
> sounds odd to me.
>
> If you want to disable the evaluate of inline code anyway, you may use
> a custom function to do it. e.g.
>
> cond_eval = function(x) {
>   if (isTRUE(knitr::opts_chunk$get('eval'))) x
> }
>
> Then `r cond_eval(x)` instead of `r x`.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Tue, Nov 10, 2015 at 4:40 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>> I do have an Rmd where I would like to conditionally evaluate the second part.
>>
>> So far I am working with :
>>
>> ```{r}
>> if(length(specLibrary at ionlibrary) ==0){
>>   library(knitr)
>>   opts_chunk$set(eval=FALSE, message=FALSE, echo=FALSE)
>> }
>> ```
>>
>> Which disables the evaluation of subsequent chunks.
>>
>> However my RMD file contains also these kind of snippets : `r `
>>
>> How do I disable them?

Just a FYI and maybe/maybe not a option for you; this is one of the
use cases where RSP (https://cran.r-project.org/package=R.rsp) is
handy because it does not require that code snippets (aka "code
chunks" as originally defined by weave/tangle literate programming) to
contain complete expressions.  With RSP-embedded documents, you can do
things such

    <% if (length(specLibrary at ionlibrary) > 0) { %>

    [... code and text blocks to conditionally include ...]

    <% } # if (length(specLibrary at ionlibrary) > 0) %>

or include from a separate file, e.g.

    <% if (length(specLibrary at ionlibrary) > 0) { %> <%@include
file="extras.md.rsp"%> <% } %>

You can also use loops over a mixture of code and text blocks etc.

Depending on when 'specLibrary at ionlibrary' gets assigned, you could
preprocess you R Markdown file with RSP, but for this to work out of
the box you basically need to know the value
length(specLibrary at ionlibrary) before your R Markdown code is
evaluated, i.e. before you compile the Rmd file.  Your build pipeline
would then look something like:

    rmd <- R.rsp::rfile("report.rmd.rsp")
    rmarkdown::render(rmd)

/Henrik
(author of R.rsp)

>>
>> regards
>>
>>
>>
>> --
>> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From proebuck at mdanderson.org  Tue Nov 10 22:00:25 2015
From: proebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 10 Nov 2015 21:00:25 +0000
Subject: [R] MAc-package,
 on OS-X 10.11.1: Warning Message In sqrt(var.T.agg.tau) :
 NaNs	produced
Message-ID: <F9D8FADAB1DB8447B03EE30D076C1AC2132D4FBB@D1PWPEXMBX06.mdanderson.edu>

Maybe change the warnings to errors temporarily, and decide for yourself about the problem.

...
R> options(warn=2)        # Turn warnings into errors
R> omni(es=z, var=var.z, data=dat, type="weighted", method="fixed", ztor=TRUE)
R> traceback()


________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Kostadin Kushlev [kushlevk at gmail.com]
Sent: Tuesday, November 10, 2015 2:14 AM
To: r-help at r-project.org
Subject: [R] MAc-pakcage,       on OS-X 10.11.1: Warning Message In sqrt(var.T.agg.tau) : NaNs  produced

I am trying to run a mini meta-analysis for three studies within one of my papers. I am using the Mac package for meta-analyzing correlation coefficients.

I am using the following command: omni(es = z, var = var.z, data = dat, type="weighted", method = "fixed", ztor = TRUE)

This produces the expected values, but also a warning message: In sqrt(var.T.agg.tau) : NaNs produced

This message is repeated twice.

I am wondering how to interpret this error message. Is this because the program can?t estimate certain parameters due to the small number of correlation coefficients I am trying to analyze (only 3)?

Most importantly, can I report and interpret the output despite those messages?
The information contained in this e-mail message may be privileged, confidential, and/or protected from disclosure. This e-mail message may contain protected health information (PHI); dissemination of PHI should comply with applicable federal and state laws. If you are not the intended recipient, or an authorized representative of the intended recipient, any further review, disclosure, use, dissemination, distribution, or copying of this message or any attachment (or the information contained therein) is strictly prohibited. If you think that you have received this e-mail message in error, please notify the sender by return e-mail and delete all references to it and its contents from your systems.


From alaasindi at icloud.com  Tue Nov 10 20:47:23 2015
From: alaasindi at icloud.com (Alaa Sindi)
Date: Tue, 10 Nov 2015 14:47:23 -0500
Subject: [R] no results
Message-ID: <5921B9F2-A4FC-4F25-AF12-72285E807A82@icloud.com>

Hi All,

I am not getting any summary results and I do not have any error. what would be the problem? 



sem=mlogit.optim ( LL  , Start, method = 'nr', iterlim = 2000, tol = 1E-05, ftol = 1e-08, steptol = 1e-10, print.level = 0)
summary(sem)

thanks


From davidsmi at microsoft.com  Wed Nov 11 00:45:02 2015
From: davidsmi at microsoft.com (David Smith)
Date: Tue, 10 Nov 2015 23:45:02 +0000
Subject: [R] Revolutions blog: October 2015 roundup
Message-ID: <DM2PR0301MB08488BF7D9635F091BDF0F80C8140@DM2PR0301MB0848.namprd03.prod.outlook.com>

Since 2008, Revolution Analytics (and now Microsoft) staff and guests have written about R every weekday at the
Revolutions blog:
http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the month of October:

A way of dealing with confounding variables in experiments: instrumental variable analysis with the ivmodel package for
R: http://blog.revolutionanalytics.com/2015/10/instrumental-variables.html

The new dplyrXdf package http://blog.revolutionanalytics.com/2015/10/the-dplyrxdf-package.html allows you to manipulate
large, out-of-memory data sets in the XDF format (used by the RevoScaleR package) using dplyr syntax:
http://blog.revolutionanalytics.com/2015/10/using-the-dplyrxdf-package.html

Some guidelines for using explicit parallel programming (e.g. the parallel package) with the implicit multithreading
provided by Revolution R Open:
http://blog.revolutionanalytics.com/2015/10/edge-cases-in-using-the-intel-mkl-and-parallel-programming.html

Ross Ihaka was featured in a full-page advertisement for the University of Auckland in The Economist:
http://blog.revolutionanalytics.com/2015/10/ross-ihaka-in-the-economist.html

A video from the PASS 2015 conference in Seattle shows R running within SQL Server 2016:
http://blog.revolutionanalytics.com/215/10/demo-r-in-sql-server-2016.html . The preview for SQL Server 2016 includes
Revolution R Enterprise (as SQL Server R Services)
http://blog.revolutionanalytics.com/2015/10/revolution-r-now-available-with-sql-server-community-preview.html

A comparison of fitting decision trees in R with the party and rpart packages:
http://blog.revolutionanalytics.com/2015/10/party-with-the-first-tribe.html

The foreach suite of packages for parallel programming in R has been updated, and now includes support for progress bars
when using doSNOW: http://blog.revolutionanalytics.com/2015/10/updates-to-the-foreach-package-and-its-friends.html

The "reach" package allows you to call Matlab functions directly from R:
http://blog.revolutionanalytics.com/2015/10/reach-for-your-matlab-data-with-r.html

A review of support vector machines (SVMs) in R:
http://blog.revolutionanalytics.com/2015/10/the-5th-tribe-support-vector-machines-and-caret.html

A presentation (with sample code) shows how to call Revolution R Enterprise from SQL Server 2016:
http://blog.revolutionanalytics.com/2015/10/previewing-using-revolution-r-enterprise-inside-sql-server.html

A tutorial on using the miniCRAN package to set up packages for use with R in Azure ML:
http://blog.revolutionanalytics.com/2015/10/using-minicran-in-azure-ml.html

Asif Salam shows how to use the RDCOMClient package to construct interactive Powerpoint slide shows with R:
http://blog.revolutionanalytics.com/2015/10/programmatically-create-interactive-powerpoint-slides-with-r.html

A directory of online R courses for all skill levels:
http://blog.revolutionanalytics.com/2015/10/learning-r-oct-2015.html

Using R's nls() optimizer to solve a problem in Bayesian inference:
http://blog.revolutionanalytics.com/2015/10/parameters-and-percentiles-the-gamma-distribution.html

A professor uses the miniCRAN package to deliver R packages to offline facilities in Turkey and Iran:
http://blog.revolutionanalytics.com/2015/10/using-minicran-on-site-in-iran.html

Amanda Cox, graphics editor at the New York Times, calls R "the greatest software on Earth" in a podcast:
http://blog.revolutionanalytics.com/2015/10/amanda-cox-on-using-r-at-the-nyt.html

Hadley Wickham answered many questions in a Reddit "Ask Me Anything" session:
http://blog.revolutionanalytics.com/2015/10/hadley-wickhams-ask-me-anything-on-reddit.html

A roundup of several talks given at R user group meetings around the world:
http://blog.revolutionanalytics.com/2015/10/r-user-groups-highlight-r-creativity.html

General interest stories (not related to R) in the past month included: visualizing the movements of chess pieces
(http://blog.revolutionanalytics.com/2015/10/chess-piece-moves.html), real-time face replication
(http://blog.revolutionanalytics.com/2015/10/because-its-friday-faceon.html), a world map of antineutrinos
(http://blog.revolutionanalytics.com/2015/10/because-its-friday-mapping-antineutrinos.html), a transformation
(http://blog.revolutionanalytics.com/2015/10/because-its-friday-a-transformation.html), and a warning about "big data"
applications (http://blog.revolutionanalytics.com/2015/10/because-its-friday-are-we-selling-radium-underpants.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the
updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at http://revolutionanalytics.com/newsletter to be alerted
to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Revolution Analytics (a Microsoft company)? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From nevil.amos at gmail.com  Wed Nov 11 01:30:08 2015
From: nevil.amos at gmail.com (nevil amos)
Date: Wed, 11 Nov 2015 11:30:08 +1100
Subject: [R] Identifying attributes of specific foreach task on error.
Message-ID: <CAN9eD7mzE1PL57xWjecL224h_4C7ZzMCAZRbaTMZZgU0eyfESQ@mail.gmail.com>

I am running foreach to reclassify a large number of rasters.

I am getting the Error in { : task 1359 failed - "cannot open the
connection"

How do I get the attributes ( in this case files being read and written)
for that specific task?


It runs fine until that point presumably there is a problem with the input
or output file name, but I cannot determine which file it refers to.

cheers

Nevil Amos

	[[alternative HTML version deleted]]


From johannes at huesing.name  Wed Nov 11 05:34:41 2015
From: johannes at huesing.name (Johannes Huesing)
Date: Wed, 11 Nov 2015 05:34:41 +0100
Subject: [R] no results
In-Reply-To: <5921B9F2-A4FC-4F25-AF12-72285E807A82@icloud.com>
References: <5921B9F2-A4FC-4F25-AF12-72285E807A82@icloud.com>
Message-ID: <20151111043441.GB27969@huesing.name>

Alaa Sindi <alaasindi at icloud.com> [Tue, Nov 10, 2015 at 08:47:23PM CET]:
>Hi All,
>
>I am not getting any summary results and I do not have any error. what would be the problem?
>


>
>
>sem=mlogit.optim ( LL  , Start, method = 'nr', iterlim = 2000, tol = 1E-05, ftol = 1e-08, steptol = 1e-10, print.level = 0)

I see some expressions which are undefined. For instance mlogit.optim, LL, Start. 

This causes the code not to run on my machine.

> R.Version()
$platform
[1] "i686-pc-linux-gnu"

$arch
[1] "i686"

$os
[1] "linux-gnu"

$system
[1] "i686, linux-gnu"

$status
[1] ""

$major
[1] "3"

$minor
[1] "0.2"

$year
[1] "2013"

$month
[1] "09"

$day
[1] "25"

$`svn rev`
[1] "63987"

$language
[1] "R"

$version.string
[1] "R version 3.0.2 (2013-09-25)"

$nickname
[1] "Frisbee Sailing"
-- 
Johannes H?sing               
http://derwisch.wikidot.com
Threema-ID: VHVJYH3H


From josip.2000 at gmail.com  Wed Nov 11 10:02:07 2015
From: josip.2000 at gmail.com (Karl)
Date: Wed, 11 Nov 2015 11:02:07 +0200
Subject: [R] Using regex to truncate repeating characters
Message-ID: <CACs_9v8YpKK87fQPRJr6yKM1gPy1XvekCM8hkOss=PEFJRLC+A@mail.gmail.com>

Hi all,

I'm trying to learn how to use regex inside R. I'm far from an expert when
it comes to this, but google is my friend when it comes to finding suitable
pieces of syntax to start building from. For example, this post seems to do
what I want:

http://stackoverflow.com/questions/12258622/regular-expression-to-check-for-repeating-characters
However, how do I implement this in R? gsub()?
For example, with Perl-style regex, are there syntax modifications that
need to be done before it will work with R?

My task is that I want to truncate/limit repeated characters to 3. If I
have the string:
"Looooorem ipsum dolor sit ammmmmmet, consectetur adipiscing eliiiiiiiit"

I want to truncate it to:
"Looorem ipsum dolor sit ammmet, consectetur adipiscing eliiit"

Thank you!

BR,
Josip

	[[alternative HTML version deleted]]


From highstat at highstat.com  Wed Nov 11 10:44:30 2015
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Wed, 11 Nov 2015 09:44:30 +0000
Subject: [R] Mixed modelling course, Lisbon, Portugal
Message-ID: <56430DFE.3080402@highstat.com>

We would like to announce the following statistics course:

Course: Introduction to Linear mixed effects models,  GLMM and MCMC with R
Where:  Lisbon, Portugal
When:   15-19 February 2016

Course website: http://www.highstat.com/statscourse.htm
Course flyer: 
http://highstat.com/Courses/Flyers/Flyer2016_02Lisbon_GLMM.pdf



Kind regards,

Alain Zuur


-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From marongiu.luigi at gmail.com  Wed Nov 11 12:26:25 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 11 Nov 2015 11:26:25 +0000
Subject: [R] How to calculate variance on multiple numbers at once?
Message-ID: <CAMk+s2SvWmoXi76pg72_GB40Ny1E-RQC5WZOH=njZXtxO=KA6w@mail.gmail.com>

Dear all,

if I have a sample set of the following numbers x1=0.09, x2=0.94,
x3=0.48, x4=0.74, x5=0.04 I can calculate the variance easily.
But if each x is actually a subset of multiple values, what would be
the formula to calculate the variance? and it is possible to implement
such mathematical function in R?

For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26,
0.89, 0.58), x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and
x5=(0.65, 0.16, 0.72) how can i calculate the variance for each x?

Thank you


From S.Ellison at LGCGroup.com  Wed Nov 11 13:58:13 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 11 Nov 2015 12:58:13 +0000
Subject: [R] How to calculate variance on multiple numbers at once?
In-Reply-To: <CAMk+s2SvWmoXi76pg72_GB40Ny1E-RQC5WZOH=njZXtxO=KA6w@mail.gmail.com>
References: <CAMk+s2SvWmoXi76pg72_GB40Ny1E-RQC5WZOH=njZXtxO=KA6w@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C7CA2E3F@GBTEDVPEXCMB04.corp.lgc-group.com>



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
> Marongiu
> if I have a sample set of the following numbers x1=0.09, x2=0.94, x3=0.48,
> x4=0.74, x5=0.04 I can calculate the variance easily.
Not without concatenating them into a vector, you can't. You need them in a vector, as in
var( c(x1, x2, x3, x4, x5) )

> But if each x is actually a subset of multiple values, what would be the formula
> to calculate the variance? and it is possible to implement such mathematical
> function in R?
This is what R wants anyway, so the function you are looking for is var()

> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26, 0.89, 0.58),
> x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and x5=(0.65, 0.16, 0.72) how can i
> calculate the variance for each x?
var(x1)
var(x2)
....

or, if you want to be a bit more slick about it and do it in one line

lapply(list( x1, x2, x3, ...), var  ) 

(or sapply() if you want a vector result)






*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jrkrideau at inbox.com  Wed Nov 11 14:04:59 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 11 Nov 2015 05:04:59 -0800
Subject: [R] How to calculate variance on multiple numbers at once?
In-Reply-To: <CAMk+s2SvWmoXi76pg72_GB40Ny1E-RQC5WZOH=njZXtxO=KA6w@mail.gmail.com>
Message-ID: <A55A64C8F90.00000DCAjrkrideau@inbox.com>

I really don't understand what you are looking for but if S. Ellison's answer is not what you want what about this where your various x vectors are in a data frame

ibrary(reshape2)
library(plyr)

dat1  <-  structure(list(x1 = c(0.77, 0.22, 0.44), x2 = c(0.26, 0.89, 0.58
), x3 = c(0.2, 0.25, 0.91), x4 = c(0.06, 0.13, 0.26), x5 = c(0.65, 
0.16, 0.72)), .Names = c("x1", "x2", "x3", "x4", "x5"), row.names = c(NA, 
-3L), class = "data.frame")

m1  <-   melt(dat1)

ddply(m1, .(variable), summarize, variance = var(value))

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marongiu.luigi at gmail.com
> Sent: Wed, 11 Nov 2015 11:26:25 +0000
> To: r-help at r-project.org
> Subject: [R] How to calculate variance on multiple numbers at once?
> 
> Dear all,
> 
> if I have a sample set of the following numbers x1=0.09, x2=0.94,
> x3=0.48, x4=0.74, x5=0.04 I can calculate the variance easily.
> But if each x is actually a subset of multiple values, what would be
> the formula to calculate the variance? and it is possible to implement
> such mathematical function in R?
> 
> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26,
> 0.89, 0.58), x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and
> x5=(0.65, 0.16, 0.72) how can i calculate the variance for each x?
> 
> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From S.Ellison at LGCGroup.com  Wed Nov 11 14:15:24 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 11 Nov 2015 13:15:24 +0000
Subject: [R] Calculating distance between words in string
In-Reply-To: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>
References: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C7CA2E49@GBTEDVPEXCMB04.corp.lgc-group.com>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl
> Subject: [R] Calculating distance between words in string
>
> .. given a specific keyword, I need to assign labels to the other words
> based on the distance (number of words) to this keyword.
> 
>...
> If the sentence contains more than one instance of the keyword, I need values
> for each instance. 

What would you like to happen when the sentence contains more than one instance of other words and more than one instance of both?

e.g. what output do you want from 
" amet is not the only instance of 'amet', and there is more than one instance of 'instance', 'is', 'of' and 'and'."


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From marc_schwartz at me.com  Wed Nov 11 16:06:50 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 11 Nov 2015 09:06:50 -0600
Subject: [R] Using regex to truncate repeating characters
In-Reply-To: <CACs_9v8YpKK87fQPRJr6yKM1gPy1XvekCM8hkOss=PEFJRLC+A@mail.gmail.com>
References: <CACs_9v8YpKK87fQPRJr6yKM1gPy1XvekCM8hkOss=PEFJRLC+A@mail.gmail.com>
Message-ID: <9E1B4CF8-E41B-4939-A8FA-DA800DFA1E08@me.com>


> On Nov 11, 2015, at 3:02 AM, Karl <josip.2000 at gmail.com> wrote:
> 
> Hi all,
> 
> I'm trying to learn how to use regex inside R. I'm far from an expert when
> it comes to this, but google is my friend when it comes to finding suitable
> pieces of syntax to start building from. For example, this post seems to do
> what I want:
> 
> http://stackoverflow.com/questions/12258622/regular-expression-to-check-for-repeating-characters
> However, how do I implement this in R? gsub()?
> For example, with Perl-style regex, are there syntax modifications that
> need to be done before it will work with R?
> 
> My task is that I want to truncate/limit repeated characters to 3. If I
> have the string:
> "Looooorem ipsum dolor sit ammmmmmet, consectetur adipiscing eliiiiiiiit"
> 
> I want to truncate it to:
> "Looorem ipsum dolor sit ammmet, consectetur adipiscing eliiit"
> 
> Thank you!
> 
> BR,
> Josip


Hi,

Not extensively tested, but something like this should work:

text <- "Looooorem ipsum dolor sit ammmmmmet, consectetur adipiscing eliiiiiiiit"

> gsub("([[:alnum:]])\\1{3,}", "\\1\\1\\1", text)
[1] "Looorem ipsum dolor sit ammmet, consectetur adipiscing eliiit"


The regex is looking for any alphanumeric character as a group, which is represented by:

  ([[:alnum:]])

That is followed by a backreference:

  \\1{3,}

which says find repeated characters in the prior alphanumeric character group of at least 3 repeats and return just the unique character.

The returned expression:

  \\1\\1\\1

says repeat the unique character 3 times.

See ?gsub and ?regex for some additional information.


Regards,

Marc Schwartz


From wdunlap at tibco.com  Wed Nov 11 16:31:10 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 11 Nov 2015 07:31:10 -0800
Subject: [R] no results
In-Reply-To: <5921B9F2-A4FC-4F25-AF12-72285E807A82@icloud.com>
References: <5921B9F2-A4FC-4F25-AF12-72285E807A82@icloud.com>
Message-ID: <CAF8bMcYKUDw4UZdnZ-NKaWRfThZ4_WwAQH1RGkM+-3PvvhAs7w@mail.gmail.com>

If you are running these commands from a file using source() then
replacing 'summary(sem)' with 'print(summary(sem))' would help,
as would adding echo=TRUE or print.eval=TRUE to the source()
command.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Nov 10, 2015 at 11:47 AM, Alaa Sindi <alaasindi at icloud.com> wrote:

> Hi All,
>
> I am not getting any summary results and I do not have any error. what
> would be the problem?
>
>
>
> sem=mlogit.optim ( LL  , Start, method = 'nr', iterlim = 2000, tol =
> 1E-05, ftol = 1e-08, steptol = 1e-10, print.level = 0)
> summary(sem)
>
> thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From zamani_mst at yahoo.com  Wed Nov 11 09:38:34 2015
From: zamani_mst at yahoo.com (leila zamani)
Date: Wed, 11 Nov 2015 08:38:34 +0000 (UTC)
Subject: [R] random number generation
References: <1939198688.2530056.1447231114038.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1939198688.2530056.1447231114038.JavaMail.yahoo@mail.yahoo.com>

Hi every one,
I'm new to R. I read about R and search all the packages but I couldn't find the package that I want. I want to generate 2D (matrices) random numbers that have correlation between them. One of my friends said that R has a function in geor like rand...(spherical (correlation coefficient=0.5)), but I read all packages with geo,like geor,geoRlgm,georob and etc, but I didn't find this! Can you help me? Thanks.


	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Wed Nov 11 15:36:30 2015
From: eliza_botto at outlook.com (Eliza Botto)
Date: Wed, 11 Nov 2015 14:36:30 +0000
Subject: [R] TRMM download loop
Message-ID: <SNT152-W949A607BD26535615633719A130@phx.gbl>

Dear Users of R,
I have this following confusion.
Some months ago I use to download 3 hourly TRMM data from NASA website by using the R from the following website

http://giovanni.gsfc.nasa.gov/giovanni/#service=ArAvTs&starttime=2008-12-31T00:00:00Z&endtime=2009-12-31T23:59:59Z&bbox=67,-50,67,-50&data=TRMM_3B42_007_precipitation

bbox=67,-50,67,-50 show the point where I want to download the data in the form of CSV file. The problem is that I have a vector of such points, a small of which is below
structure(c(72, 71, 54, 67, 50, 53, 30, -50), .Dim = c(4L, 2L), .Dimnames = list(c("d", "e", "f", "g"), NULL))
How can I make a loop to download the data on given points automatically?
Thankyou very much in advance.
Eliza
 		 	   		  
	[[alternative HTML version deleted]]


From eliza_botto at outlook.com  Wed Nov 11 15:37:17 2015
From: eliza_botto at outlook.com (Eliza Botto)
Date: Wed, 11 Nov 2015 14:37:17 +0000
Subject: [R] TRMM download loop
Message-ID: <SNT152-W42449E95CE687B5185A7B79A130@phx.gbl>

Dear Users of R,
I have this following confusion.
Some months ago I use to download 3 hourly TRMM data from NASA website by using the R from the following website

http://giovanni.gsfc.nasa.gov/giovanni/#service=ArAvTs&starttime=2008-12-31T00:00:00Z&endtime=2009-12-31T23:59:59Z&bbox=67,-50,67,-50&data=TRMM_3B42_007_precipitation

bbox=67,-50,67,-50 show the point where I want to download the data in the form of CSV file. The problem is that I have a vector of such points, a small of which is below
structure(c(72, 71, 54, 67, 50, 53, 30, -50), .Dim = c(4L, 2L), .Dimnames = list(c("d", "e", "f", "g"), NULL))
How can I make a loop to download the data on given points automatically?
Thankyou very much in advance.
Eliza
 		 	   		  
	[[alternative HTML version deleted]]


From glennmschultz at me.com  Wed Nov 11 16:16:44 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Wed, 11 Nov 2015 15:16:44 +0000 (GMT)
Subject: [R] Advice collating an R package
Message-ID: <b26943b4-5aca-484d-bfe0-bf539208f4cf@me.com>

Hi All,
When collating a package - where does the file of constants go?

I have an R package that defines 36 new classes and the AllClasses file is getting quite long. ?I would like to re-organize the files the following way - which is also easier for my personal mental map of what is going on.

#' @includes foo1.R foo2.R
setClass
setGeneric
setMethod(initialize)
constructor function

I also have a file fooC.R which defines the constants like days.in.month etc. ?So should every file be?
#' @includes fooC. R foo1.R foo2.R
setClass
setGeneric
setMethod(initialize)
constructor function

Thanks,
Glenn

From murdoch.duncan at gmail.com  Wed Nov 11 17:09:25 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 11 Nov 2015 08:09:25 -0800
Subject: [R] Advice collating an R package
In-Reply-To: <b26943b4-5aca-484d-bfe0-bf539208f4cf@me.com>
References: <b26943b4-5aca-484d-bfe0-bf539208f4cf@me.com>
Message-ID: <56436835.7090301@gmail.com>

On 11/11/2015 7:16 AM, Glenn Schultz wrote:
> Hi All,
> When collating a package - where does the file of constants go?
>
> I have an R package that defines 36 new classes and the AllClasses file is getting quite long.  I would like to re-organize the files the following way - which is also easier for my personal mental map of what is going on.
>
> #' @includes foo1.R foo2.R
> setClass
> setGeneric
> setMethod(initialize)
> constructor function
>
> I also have a file fooC.R which defines the constants like days.in.month etc.  So should every file be
> #' @includes fooC. R foo1.R foo2.R
> setClass
> setGeneric
> setMethod(initialize)
> constructor function
>

Scoping in R doesn't care about the order of declaration.  The times 
when collation order matters are when you need to use one object in the 
package to build another one.  (You should be thinking of the source 
files as executable scripts that create a collection of objects, not as 
declarations.)

So just make sure that if you use object A from your package when 
building object B, that the source to build A is executed first.  Most 
people do this by naming the files:  they'll be executed in C collation 
order by default.  (You can list the files in the Collate field of your 
DESCRIPTION file if you want a different order; see Writing R Extensions 
for details).

Duncan Murdoch


From kmezhoud at gmail.com  Wed Nov 11 17:50:03 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 11 Nov 2015 17:50:03 +0100
Subject: [R] random number generation
In-Reply-To: <1939198688.2530056.1447231114038.JavaMail.yahoo@mail.yahoo.com>
References: <1939198688.2530056.1447231114038.JavaMail.yahoo.ref@mail.yahoo.com>
	<1939198688.2530056.1447231114038.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CALJKBv-zs-24iARoc3gZk_=cV_7KNLPzyqeo9g+pYhRkatCtdg@mail.gmail.com>

Hi,
This generate matrix:
matrix( rnorm(5*4,mean=0,sd=1), 5, 4)

for correlated matrix please see this link:
http://stackoverflow.com/questions/10680658/how-can-i-create-a-correlation-matrix-in-r
Karim


On Wed, Nov 11, 2015 at 9:38 AM, leila zamani via R-help <
r-help at r-project.org> wrote:

> Hi every one,
> I'm new to R. I read about R and search all the packages but I couldn't
> find the package that I want. I want to generate 2D (matrices) random
> numbers that have correlation between them. One of my friends said that R
> has a function in geor like rand...(spherical (correlation
> coefficient=0.5)), but I read all packages with geo,like
> geor,geoRlgm,georob and etc, but I didn't find this! Can you help me?
> Thanks.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Wed Nov 11 17:58:57 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 11 Nov 2015 16:58:57 +0000
Subject: [R] random number generation
In-Reply-To: <1939198688.2530056.1447231114038.JavaMail.yahoo@mail.yahoo.com>
References: <1939198688.2530056.1447231114038.JavaMail.yahoo.ref@mail.yahoo.com>
	<1939198688.2530056.1447231114038.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <564373D1.1010800@dewey.myzen.co.uk>

Dear Leila

Does the function mvrnorm in package MASS do what you want?

On 11/11/2015 08:38, leila zamani via R-help wrote:
> Hi every one,
> I'm new to R. I read about R and search all the packages but I couldn't find the package that I want. I want to generate 2D (matrices) random numbers that have correlation between them. One of my friends said that R has a function in geor like rand...(spherical (correlation coefficient=0.5)), but I read all packages with geo,like geor,geoRlgm,georob and etc, but I didn't find this! Can you help me? Thanks.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.CA.us  Wed Nov 11 18:02:09 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 11 Nov 2015 09:02:09 -0800
Subject: [R] Advice collating an R package
In-Reply-To: <b26943b4-5aca-484d-bfe0-bf539208f4cf@me.com>
References: <b26943b4-5aca-484d-bfe0-bf539208f4cf@me.com>
Message-ID: <CEA9C0F6-BF00-4E0D-9AA1-7A15F3CE3D87@dcn.davis.CA.us>

A) Do you have problem? Have you tried it?

B) There is a mailing list for this sort of question... read the Posting Guide.

C) What is a constant? In R, it is just another variable. The purpose of packages is to collect variables in namespaces in memory for easy access. Which means that "include" is not necessary. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 11, 2015 7:16:44 AM PST, Glenn Schultz <glennmschultz at me.com> wrote:
>Hi All,
>When collating a package - where does the file of constants go?
>
>I have an R package that defines 36 new classes and the AllClasses file
>is getting quite long. ?I would like to re-organize the files the
>following way - which is also easier for my personal mental map of what
>is going on.
>
>#' @includes foo1.R foo2.R
>setClass
>setGeneric
>setMethod(initialize)
>constructor function
>
>I also have a file fooC.R which defines the constants like
>days.in.month etc. ?So should every file be?
>#' @includes fooC. R foo1.R foo2.R
>setClass
>setGeneric
>setMethod(initialize)
>constructor function
>
>Thanks,
>Glenn
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From andrewcd at gmail.com  Wed Nov 11 18:25:13 2015
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Wed, 11 Nov 2015 12:25:13 -0500
Subject: [R] R packages/code for CART that is written entirely in R (not C)
Message-ID: <564379F9.5060804@gmail.com>

Dear List,

I'd like to make a few modifications to the typical CART algorithm, and 
I'd rather not code the whole thing from scratch.  Specifically I want 
to use different in-sample and out-of-sample fit criteria in the split 
choosing and cross-validation stages.

I see however that the code for CART in both the rpart and the tree 
packages is written in C.

Two questions:

  * Where is the C code?  It might be possible to get a C-fluent
    programmer to help me with this.
  * Is there any code for CART that is written entirely in R?

Thanks,
Andrew

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Nov 11 20:00:19 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Nov 2015 11:00:19 -0800
Subject: [R] R packages/code for CART that is written entirely in R (not
	C)
In-Reply-To: <564379F9.5060804@gmail.com>
References: <564379F9.5060804@gmail.com>
Message-ID: <477072FA-40B9-44A9-9547-E7CCCF095AF3@comcast.net>


> On Nov 11, 2015, at 9:25 AM, Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
> 
> Dear List,
> 
> I'd like to make a few modifications to the typical CART algorithm, and 
> I'd rather not code the whole thing from scratch.  Specifically I want 
> to use different in-sample and out-of-sample fit criteria in the split 
> choosing and cross-validation stages.
> 
> I see however that the code for CART in both the rpart and the tree 
> packages is written in C.
> 
> Two questions:
> 
>  * Where is the C code?  It might be possible to get a C-fluent
>    programmer to help me with this.
>  * Is there any code for CART that is written entirely in R?

Read: "R Help Desk: Accessing the Sources? by Uwe Ligges in:

https://www.r-project.org/doc/Rnews/Rnews_2006-4.pdf

The current sources are here:

https://svn.r-project.org/R/trunk/


> 
> Thanks,
> Andrew
> 
> 	[[alternative HTML version deleted]]

For future questions, this is a plain text mailing list.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

? 
David Winsemius
Alameda, CA, USA


From andrewcd at gmail.com  Wed Nov 11 20:26:32 2015
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Wed, 11 Nov 2015 14:26:32 -0500
Subject: [R] R packages/code for CART that is written entirely in R (not
 C)
In-Reply-To: <477072FA-40B9-44A9-9547-E7CCCF095AF3@comcast.net>
References: <564379F9.5060804@gmail.com>
	<477072FA-40B9-44A9-9547-E7CCCF095AF3@comcast.net>
Message-ID: <56439668.1000504@gmail.com>

Thanks for the reference!  I'd still be grateful for any pointers 
towards code for CART that has been written entirely in R, perhaps that 
hasn't made its way onto CRAN.

On 11/11/2015 02:00 PM, David Winsemius wrote:
>> On Nov 11, 2015, at 9:25 AM, Andrew Crane-Droesch <andrewcd at gmail.com> wrote:
>>
>> Dear List,
>>
>> I'd like to make a few modifications to the typical CART algorithm, and
>> I'd rather not code the whole thing from scratch.  Specifically I want
>> to use different in-sample and out-of-sample fit criteria in the split
>> choosing and cross-validation stages.
>>
>> I see however that the code for CART in both the rpart and the tree
>> packages is written in C.
>>
>> Two questions:
>>
>>   * Where is the C code?  It might be possible to get a C-fluent
>>     programmer to help me with this.
>>   * Is there any code for CART that is written entirely in R?
> Read: "R Help Desk: Accessing the Sources? by Uwe Ligges in:
>
> https://www.r-project.org/doc/Rnews/Rnews_2006-4.pdf
>
> The current sources are here:
>
> https://svn.r-project.org/R/trunk/
>
>
>> Thanks,
>> Andrew
>>
>> 	[[alternative HTML version deleted]]
> For future questions, this is a plain text mailing list.
>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ?
> David Winsemius
> Alameda, CA, USA
>


From ravi.varadhan at jhu.edu  Wed Nov 11 20:32:36 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 11 Nov 2015 19:32:36 +0000
Subject: [R] About error: L-BFGS-B needs finite values of 'fn'
Message-ID: <bb6c81cdbf624b6893d4459f5e65f4bf@ESGEBEX10.win.ad.jhu.edu>

With a small sample size, n=30, you will have realizations of data where you will run into difficulties with the MLE of generalized Gamma distribution.  This is mainly due to the `k' parameter.  Increase the sample size (e.g., n=50 or 100) and this problem is less likely to happen (but can still happen).

I would strongly suggest that when you are doing simulations, you should encapsulate the parameter estimation inside a `try' or `tryCatch' statement so that when there is an error, the simulation keeps going rather than crashing out.

See the attached code.

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


From ravi.varadhan at jhu.edu  Wed Nov 11 21:54:03 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 11 Nov 2015 20:54:03 +0000
Subject: [R] About error: L-BFGS-B needs finite values of 'fn'
Message-ID: <4d4ea2e9967d453ab0ce56569941a33b@ESGEBEX10.win.ad.jhu.edu>

It seems like there is substantial finite-sample bias in the MLEs.  Either that or there is some error in your procedure.  See attached code.

Ravi

From: Ravi Varadhan
Sent: Wednesday, November 11, 2015 2:33 PM
To: 'denizozonur at gazi.edu.tr' <denizozonur at gazi.edu.tr>; r-help at r-project.org
Cc: 'profjcnash at gmail.com' <profjcnash at gmail.com>
Subject: Re: [R] About error: L-BFGS-B needs finite values of 'fn'

With a small sample size, n=30, you will have realizations of data where you will run into difficulties with the MLE of generalized Gamma distribution.  This is mainly due to the `k' parameter.  Increase the sample size (e.g., n=50 or 100) and this problem is less likely to happen (but can still happen).

I would strongly suggest that when you are doing simulations, you should encapsulate the parameter estimation inside a `try' or `tryCatch' statement so that when there is an error, the simulation keeps going rather than crashing out.

See the attached code.

Best,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


From oma.gonzales at gmail.com  Thu Nov 12 00:15:17 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 11 Nov 2015 18:15:17 -0500
Subject: [R] seconds to h:m:s format
Message-ID: <CAM-xyZiTz6HNQUOEqgch=J9uOUE1XpR1JPpWjtfUwvCd5uo1Kw@mail.gmail.com>

Hi,

I've a data frame with 3 columns: "mes", "fuente", "avg.sessions.duration".

"avg.sessions.duration" is a column containing seconds.

I need you help with:

1.-  Help to put these values in "h:m:s" format.
.

=======================================================

I've found this german page:

http://forum.r-statistik.de/viewtopic.php?f=25&t=5284

So I've tried:

for (i in 1:nrow(session.duration.fuente)) {

  session.duration.fuente$avg.session.duration <-
format(as.POSIXct('0001-01-01 00:00:00') +
session.duration.fuente$avg.session.duration[i], "%H:%M:%S")

}

but got this error:

 Error in unclass(e1) + unclass(e2) :
  non-numeric argument to binary operator

=======================================================

After that I've tried: strptime:

session.duration.fuente$avg.session.duration <-
strptime(session.duration.fuente$avg.session.duration, "%H:%M:%OS")

But got NAs.

========================================================

Here is the data:


session.duration.fuente <- structure(list(mes = structure(c(1L, 1L, 1L, 1L,
1L, 2L, 2L,
2L, 2L, 2L), .Label = c("oct", "nov"), class = c("ordered", "factor"
)), fuente = c("adwords", "directo", "organico", "redes sociales",
"referral", "adwords", "directo", "organico", "redes sociales",
"referral"), avg.session.duration = c(970178, 1642455, 780485,
3170400, 179184, 352995, 833827, 260610, 2318928, 49836)), row.names =
c(NA,
-10L), class = c("grouped_df", "tbl_df", "tbl", "data.frame"), vars = list(
    mes), drop = TRUE, .Names = c("mes", "fuente", "avg.session.duration"
))

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Thu Nov 12 00:51:48 2015
From: sewashm at gmail.com (Ashta)
Date: Wed, 11 Nov 2015 17:51:48 -0600
Subject: [R] Cleaning
Message-ID: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>

Hi all,

I have a data frame with  huge rows and columns.

When I looked at the data,  it has several garbage values need to be

cleaned. For a sample I am showing you the frequency distribution
of one variables

    Var1 Freq
1    :    3
2    ]    6
3    MSN 1040
4    YYZ  300
5    \\    4
6    +     3
7.   ?>   15

and continues.

I want to keep those rows that contain only a valid variable value

In this  case MSN and YYZ. I tried the following

*test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*

but I am not getting the desired result.

 I have

Any help or idea?

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Nov 12 01:02:36 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Nov 2015 19:02:36 -0500
Subject: [R] Cleaning
In-Reply-To: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
Message-ID: <CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>

Hi,

On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
> Hi all,
>
> I have a data frame with  huge rows and columns.
>
> When I looked at the data,  it has several garbage values need to be
>
> cleaned. For a sample I am showing you the frequency distribution
> of one variables
>
>     Var1 Freq
> 1    :    3
> 2    ]    6
> 3    MSN 1040
> 4    YYZ  300
> 5    \\    4
> 6    +     3
> 7.   ?>   15

Please use dput() to provide your data. I made a guess at what you had
in R, but could be wrong.


> and continues.
>
> I want to keep those rows that contain only a valid variable value
>
> In this  case MSN and YYZ. I tried the following
>
> *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
>
> but I am not getting the desired result.

What are you getting? How does it differ from the desired result?

>  I have
>
> Any help or idea?

I get:

> dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ", "\\\\",
+ "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names = c("X",
+ "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
>
> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> test
  X Var1 Freq
3 3  MSN 1040
4 4  YYZ  300

Which seems reasonable to me.


>
>         [[alternative HTML version deleted]]

Please don't post in HTML either: it introduces all sorts of errors to
your message.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Thu Nov 12 01:38:30 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Nov 2015 19:38:30 -0500
Subject: [R] Cleaning
In-Reply-To: <CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
	<CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>
	<CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
Message-ID: <CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>

Please keep replies on the list so others may participate in the conversation.

If you have a character vector containing the potential values, you
might look at %in% for one approach to subsetting your data.

Var1 %in% myvalues

Sarah

On Wed, Nov 11, 2015 at 7:10 PM, Ashta <sewashm at gmail.com> wrote:
> Thank you Sarah for your prompt response!
>
> I have the list of values of the variable Var1 it is around 20.
> How can I modify this one to include all the 20 valid values?
>
> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>
> Is there a way (efficient )  of doing it?
>
> Thank you again
>
>
>
> On Wed, Nov 11, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Hi,
>>
>> On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
>> > Hi all,
>> >
>> > I have a data frame with  huge rows and columns.
>> >
>> > When I looked at the data,  it has several garbage values need to be
>> >
>> > cleaned. For a sample I am showing you the frequency distribution
>> > of one variables
>> >
>> >     Var1 Freq
>> > 1    :    3
>> > 2    ]    6
>> > 3    MSN 1040
>> > 4    YYZ  300
>> > 5    \\    4
>> > 6    +     3
>> > 7.   ?>   15
>>
>> Please use dput() to provide your data. I made a guess at what you had
>> in R, but could be wrong.
>>
>>
>> > and continues.
>> >
>> > I want to keep those rows that contain only a valid variable value
>> >
>> > In this  case MSN and YYZ. I tried the following
>> >
>> > *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
>> >
>> > but I am not getting the desired result.
>>
>> What are you getting? How does it differ from the desired result?
>>
>> >  I have
>> >
>> > Any help or idea?
>>
>> I get:
>>
>> > dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ", "\\\\",
>> + "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names = c("X",
>> + "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
>> >
>> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>> > test
>>   X Var1 Freq
>> 3 3  MSN 1040
>> 4 4  YYZ  300
>>
>> Which seems reasonable to me.
>>
>>
>> >
>> >         [[alternative HTML version deleted]]
>>
>> Please don't post in HTML either: it introduces all sorts of errors to
>> your message.
>>
>> Sarah
>>


From drjimlemon at gmail.com  Thu Nov 12 02:22:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 Nov 2015 12:22:43 +1100
Subject: [R] seconds to h:m:s format
In-Reply-To: <CAM-xyZiTz6HNQUOEqgch=J9uOUE1XpR1JPpWjtfUwvCd5uo1Kw@mail.gmail.com>
References: <CAM-xyZiTz6HNQUOEqgch=J9uOUE1XpR1JPpWjtfUwvCd5uo1Kw@mail.gmail.com>
Message-ID: <CA+8X3fU_ZHz2xt1O8eaa1R-ZyOeP8U3fgFvMTt5mS-1PZ9vUJw@mail.gmail.com>

Hi Omar,
There is some sort of error in your structure definition, but the following
works for me:

session.duration.fuente <-
 data.frame(mes=c(rep("oct",5),rep("nov",5)),
  fuente=c("adwords", "directo", "organico", "redes sociales",
   "referral", "adwords", "directo", "organico", "redes sociales",
   "referral"),
  avg.session.duration = c(970178, 1642455, 780485,
   3170400, 179184, 352995, 833827, 260610, 2318928, 49836))

base_dates<-strptime(rep("1970-01-01",10),"%Y-%m-%d")
format(base_dates+session.duration.fuente$avg.session.duration,"%H:%M:%S")
 [1] "05:29:38" "00:14:15" "00:48:05" "16:40:00" "01:46:24" "02:03:15"
 [7] "15:37:07" "00:23:30" "20:08:48" "13:50:36"

Jim

On Thu, Nov 12, 2015 at 10:15 AM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Hi,
>
> I've a data frame with 3 columns: "mes", "fuente", "avg.sessions.duration".
>
> "avg.sessions.duration" is a column containing seconds.
>
> I need you help with:
>
> 1.-  Help to put these values in "h:m:s" format.
> .
>
> =======================================================
>
> I've found this german page:
>
> http://forum.r-statistik.de/viewtopic.php?f=25&t=5284
>
> So I've tried:
>
> for (i in 1:nrow(session.duration.fuente)) {
>
>   session.duration.fuente$avg.session.duration <-
> format(as.POSIXct('0001-01-01 00:00:00') +
> session.duration.fuente$avg.session.duration[i], "%H:%M:%S")
>
> }
>
> but got this error:
>
>  Error in unclass(e1) + unclass(e2) :
>   non-numeric argument to binary operator
>
> =======================================================
>
> After that I've tried: strptime:
>
> session.duration.fuente$avg.session.duration <-
> strptime(session.duration.fuente$avg.session.duration, "%H:%M:%OS")
>
> But got NAs.
>
> ========================================================
>
> Here is the data:
>
>
> session.duration.fuente <- structure(list(mes = structure(c(1L, 1L, 1L, 1L,
> 1L, 2L, 2L,
> 2L, 2L, 2L), .Label = c("oct", "nov"), class = c("ordered", "factor"
> )), fuente = c("adwords", "directo", "organico", "redes sociales",
> "referral", "adwords", "directo", "organico", "redes sociales",
> "referral"), avg.session.duration = c(970178, 1642455, 780485,
> 3170400, 179184, 352995, 833827, 260610, 2318928, 49836)), row.names =
> c(NA,
> -10L), class = c("grouped_df", "tbl_df", "tbl", "data.frame"), vars = list(
>     mes), drop = TRUE, .Names = c("mes", "fuente", "avg.session.duration"
> ))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Thu Nov 12 02:44:33 2015
From: sewashm at gmail.com (Ashta)
Date: Wed, 11 Nov 2015 19:44:33 -0600
Subject: [R] Cleaning
In-Reply-To: <CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
	<CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>
	<CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
	<CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>
Message-ID: <CADDFq31d14s==wOqAYhN_xKMTBcBex2QBHAFuHJOCgaGrDE7Gg@mail.gmail.com>

Hi Sarah,

I used the following to clean my data, the program crushed several times.


*test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*



*What is the difference between these two**test <- dat[dat$Var1
**%in% "YYZ" | dat$Var1** %in% "MSN" ,]*




On Wed, Nov 11, 2015 at 6:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Please keep replies on the list so others may participate in the
> conversation.
>
> If you have a character vector containing the potential values, you
> might look at %in% for one approach to subsetting your data.
>
> Var1 %in% myvalues
>
> Sarah
>
> On Wed, Nov 11, 2015 at 7:10 PM, Ashta <sewashm at gmail.com> wrote:
> > Thank you Sarah for your prompt response!
> >
> > I have the list of values of the variable Var1 it is around 20.
> > How can I modify this one to include all the 20 valid values?
> >
> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> >
> > Is there a way (efficient )  of doing it?
> >
> > Thank you again
> >
> >
> >
> > On Wed, Nov 11, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Hi,
> >>
> >> On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
> >> > Hi all,
> >> >
> >> > I have a data frame with  huge rows and columns.
> >> >
> >> > When I looked at the data,  it has several garbage values need to be
> >> >
> >> > cleaned. For a sample I am showing you the frequency distribution
> >> > of one variables
> >> >
> >> >     Var1 Freq
> >> > 1    :    3
> >> > 2    ]    6
> >> > 3    MSN 1040
> >> > 4    YYZ  300
> >> > 5    \\    4
> >> > 6    +     3
> >> > 7.   ?>   15
> >>
> >> Please use dput() to provide your data. I made a guess at what you had
> >> in R, but could be wrong.
> >>
> >>
> >> > and continues.
> >> >
> >> > I want to keep those rows that contain only a valid variable value
> >> >
> >> > In this  case MSN and YYZ. I tried the following
> >> >
> >> > *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
> >> >
> >> > but I am not getting the desired result.
> >>
> >> What are you getting? How does it differ from the desired result?
> >>
> >> >  I have
> >> >
> >> > Any help or idea?
> >>
> >> I get:
> >>
> >> > dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ",
> "\\\\",
> >> + "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names =
> c("X",
> >> + "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
> >> >
> >> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> >> > test
> >>   X Var1 Freq
> >> 3 3  MSN 1040
> >> 4 4  YYZ  300
> >>
> >> Which seems reasonable to me.
> >>
> >>
> >> >
> >> >         [[alternative HTML version deleted]]
> >>
> >> Please don't post in HTML either: it introduces all sorts of errors to
> >> your message.
> >>
> >> Sarah
> >>
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Nov 12 02:54:59 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 11 Nov 2015 20:54:59 -0500
Subject: [R] Cleaning
In-Reply-To: <CADDFq31d14s==wOqAYhN_xKMTBcBex2QBHAFuHJOCgaGrDE7Gg@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
	<CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>
	<CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
	<CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>
	<CADDFq31d14s==wOqAYhN_xKMTBcBex2QBHAFuHJOCgaGrDE7Gg@mail.gmail.com>
Message-ID: <CAM_vjumhkp+WF6jDp9QiVP9oaKnm-YjO843R80k9PDtXN98U3w@mail.gmail.com>

On Wed, Nov 11, 2015 at 8:44 PM, Ashta <sewashm at gmail.com> wrote:
> Hi Sarah,
>
> I used the following to clean my data, the program crushed several times.
>
> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>
> What is the difference between these two
>
> test <- dat[dat$Var1  %in% "YYZ" | dat$Var1 %in% "MSN" ,]

Besides that you're using %in% wrong? I told you how to proceed.

myvalues <- c("YYZ", "MSN")

test <- subset(dat, Var1 %in% myvalues)


> subset(dat, Var1 %in% myvalues)
  X Var1 Freq
3 3  MSN 1040
4 4  YYZ  300

>
>
>
>
> On Wed, Nov 11, 2015 at 6:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Please keep replies on the list so others may participate in the
>> conversation.
>>
>> If you have a character vector containing the potential values, you
>> might look at %in% for one approach to subsetting your data.
>>
>> Var1 %in% myvalues
>>
>> Sarah
>>
>> On Wed, Nov 11, 2015 at 7:10 PM, Ashta <sewashm at gmail.com> wrote:
>> > Thank you Sarah for your prompt response!
>> >
>> > I have the list of values of the variable Var1 it is around 20.
>> > How can I modify this one to include all the 20 valid values?
>> >
>> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>> >
>> > Is there a way (efficient )  of doing it?
>> >
>> > Thank you again
>> >
>> >
>> >
>> > On Wed, Nov 11, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> > wrote:
>> >>
>> >> Hi,
>> >>
>> >> On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
>> >> > Hi all,
>> >> >
>> >> > I have a data frame with  huge rows and columns.
>> >> >
>> >> > When I looked at the data,  it has several garbage values need to be
>> >> >
>> >> > cleaned. For a sample I am showing you the frequency distribution
>> >> > of one variables
>> >> >
>> >> >     Var1 Freq
>> >> > 1    :    3
>> >> > 2    ]    6
>> >> > 3    MSN 1040
>> >> > 4    YYZ  300
>> >> > 5    \\    4
>> >> > 6    +     3
>> >> > 7.   ?>   15
>> >>
>> >> Please use dput() to provide your data. I made a guess at what you had
>> >> in R, but could be wrong.
>> >>
>> >>
>> >> > and continues.
>> >> >
>> >> > I want to keep those rows that contain only a valid variable value
>> >> >
>> >> > In this  case MSN and YYZ. I tried the following
>> >> >
>> >> > *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
>> >> >
>> >> > but I am not getting the desired result.
>> >>
>> >> What are you getting? How does it differ from the desired result?
>> >>
>> >> >  I have
>> >> >
>> >> > Any help or idea?
>> >>
>> >> I get:
>> >>
>> >> > dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ",
>> >> > "\\\\",
>> >> + "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names =
>> >> c("X",
>> >> + "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
>> >> >
>> >> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>> >> > test
>> >>   X Var1 Freq
>> >> 3 3  MSN 1040
>> >> 4 4  YYZ  300
>> >>
>> >> Which seems reasonable to me.
>> >>
>> >>
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >>
>> >> Please don't post in HTML either: it introduces all sorts of errors to
>> >> your message.
>> >>
>> >> Sarah
>> >>
>
>


From oma.gonzales at gmail.com  Thu Nov 12 03:25:01 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 11 Nov 2015 21:25:01 -0500
Subject: [R] seconds to h:m:s format
In-Reply-To: <CA+8X3fU_ZHz2xt1O8eaa1R-ZyOeP8U3fgFvMTt5mS-1PZ9vUJw@mail.gmail.com>
References: <CAM-xyZiTz6HNQUOEqgch=J9uOUE1XpR1JPpWjtfUwvCd5uo1Kw@mail.gmail.com>
	<CA+8X3fU_ZHz2xt1O8eaa1R-ZyOeP8U3fgFvMTt5mS-1PZ9vUJw@mail.gmail.com>
Message-ID: <CAM-xyZgxSXMpqaaccObMrvoD6zoEyiiByANTRVE6chPBFfs+Gw@mail.gmail.com>

Thank you, Jim.

Just to understand it:

You replicated 10 times: "1970-01-01". Why this specific date?





2015-11-11 20:22 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Omar,
> There is some sort of error in your structure definition, but the
> following works for me:
>
> session.duration.fuente <-
>  data.frame(mes=c(rep("oct",5),rep("nov",5)),
>   fuente=c("adwords", "directo", "organico", "redes sociales",
>    "referral", "adwords", "directo", "organico", "redes sociales",
>    "referral"),
>   avg.session.duration = c(970178, 1642455, 780485,
>    3170400, 179184, 352995, 833827, 260610, 2318928, 49836))
>
> base_dates<-strptime(rep("1970-01-01",10),"%Y-%m-%d")
> format(base_dates+session.duration.fuente$avg.session.duration,"%H:%M:%S")
>  [1] "05:29:38" "00:14:15" "00:48:05" "16:40:00" "01:46:24" "02:03:15"
>  [7] "15:37:07" "00:23:30" "20:08:48" "13:50:36"
>
> Jim
>
> On Thu, Nov 12, 2015 at 10:15 AM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
>
>> Hi,
>>
>> I've a data frame with 3 columns: "mes", "fuente",
>> "avg.sessions.duration".
>>
>> "avg.sessions.duration" is a column containing seconds.
>>
>> I need you help with:
>>
>> 1.-  Help to put these values in "h:m:s" format.
>> .
>>
>> =======================================================
>>
>> I've found this german page:
>>
>> http://forum.r-statistik.de/viewtopic.php?f=25&t=5284
>>
>> So I've tried:
>>
>> for (i in 1:nrow(session.duration.fuente)) {
>>
>>   session.duration.fuente$avg.session.duration <-
>> format(as.POSIXct('0001-01-01 00:00:00') +
>> session.duration.fuente$avg.session.duration[i], "%H:%M:%S")
>>
>> }
>>
>> but got this error:
>>
>>  Error in unclass(e1) + unclass(e2) :
>>   non-numeric argument to binary operator
>>
>> =======================================================
>>
>> After that I've tried: strptime:
>>
>> session.duration.fuente$avg.session.duration <-
>> strptime(session.duration.fuente$avg.session.duration, "%H:%M:%OS")
>>
>> But got NAs.
>>
>> ========================================================
>>
>> Here is the data:
>>
>>
>> session.duration.fuente <- structure(list(mes = structure(c(1L, 1L, 1L,
>> 1L,
>> 1L, 2L, 2L,
>> 2L, 2L, 2L), .Label = c("oct", "nov"), class = c("ordered", "factor"
>> )), fuente = c("adwords", "directo", "organico", "redes sociales",
>> "referral", "adwords", "directo", "organico", "redes sociales",
>> "referral"), avg.session.duration = c(970178, 1642455, 780485,
>> 3170400, 179184, 352995, 833827, 260610, 2318928, 49836)), row.names =
>> c(NA,
>> -10L), class = c("grouped_df", "tbl_df", "tbl", "data.frame"), vars =
>> list(
>>     mes), drop = TRUE, .Names = c("mes", "fuente", "avg.session.duration"
>> ))
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Thu Nov 12 04:03:12 2015
From: sewashm at gmail.com (Ashta)
Date: Wed, 11 Nov 2015 21:03:12 -0600
Subject: [R] Cleaning
In-Reply-To: <CAM_vjumhkp+WF6jDp9QiVP9oaKnm-YjO843R80k9PDtXN98U3w@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
	<CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>
	<CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
	<CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>
	<CADDFq31d14s==wOqAYhN_xKMTBcBex2QBHAFuHJOCgaGrDE7Gg@mail.gmail.com>
	<CAM_vjumhkp+WF6jDp9QiVP9oaKnm-YjO843R80k9PDtXN98U3w@mail.gmail.com>
Message-ID: <CADDFq30rGDEWcrQdbEDzoEKZh3YHrwLzYxNY5HGsCew9Hp=mNA@mail.gmail.com>

Sarah,

Thank you very much.   For the other variables
I was trying to do the same job in different way because it is easier to
list it

Example

test < which(dat$var1  !="BAA" | dat$var1 !="FAG" )
 {
    dat <- dat[-test,]}   and I did not get the  right result. What am I
missing here?





On Wed, Nov 11, 2015 at 7:54 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> On Wed, Nov 11, 2015 at 8:44 PM, Ashta <sewashm at gmail.com> wrote:
> > Hi Sarah,
> >
> > I used the following to clean my data, the program crushed several times.
> >
> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> >
> > What is the difference between these two
> >
> > test <- dat[dat$Var1  %in% "YYZ" | dat$Var1 %in% "MSN" ,]
>
> Besides that you're using %in% wrong? I told you how to proceed.
>
> myvalues <- c("YYZ", "MSN")
>
> test <- subset(dat, Var1 %in% myvalues)
>
>
> > subset(dat, Var1 %in% myvalues)
>   X Var1 Freq
> 3 3  MSN 1040
> 4 4  YYZ  300
>
> >
> >
> >
> >
> > On Wed, Nov 11, 2015 at 6:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
> > wrote:
> >>
> >> Please keep replies on the list so others may participate in the
> >> conversation.
> >>
> >> If you have a character vector containing the potential values, you
> >> might look at %in% for one approach to subsetting your data.
> >>
> >> Var1 %in% myvalues
> >>
> >> Sarah
> >>
> >> On Wed, Nov 11, 2015 at 7:10 PM, Ashta <sewashm at gmail.com> wrote:
> >> > Thank you Sarah for your prompt response!
> >> >
> >> > I have the list of values of the variable Var1 it is around 20.
> >> > How can I modify this one to include all the 20 valid values?
> >> >
> >> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> >> >
> >> > Is there a way (efficient )  of doing it?
> >> >
> >> > Thank you again
> >> >
> >> >
> >> >
> >> > On Wed, Nov 11, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com
> >
> >> > wrote:
> >> >>
> >> >> Hi,
> >> >>
> >> >> On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
> >> >> > Hi all,
> >> >> >
> >> >> > I have a data frame with  huge rows and columns.
> >> >> >
> >> >> > When I looked at the data,  it has several garbage values need to
> be
> >> >> >
> >> >> > cleaned. For a sample I am showing you the frequency distribution
> >> >> > of one variables
> >> >> >
> >> >> >     Var1 Freq
> >> >> > 1    :    3
> >> >> > 2    ]    6
> >> >> > 3    MSN 1040
> >> >> > 4    YYZ  300
> >> >> > 5    \\    4
> >> >> > 6    +     3
> >> >> > 7.   ?>   15
> >> >>
> >> >> Please use dput() to provide your data. I made a guess at what you
> had
> >> >> in R, but could be wrong.
> >> >>
> >> >>
> >> >> > and continues.
> >> >> >
> >> >> > I want to keep those rows that contain only a valid variable value
> >> >> >
> >> >> > In this  case MSN and YYZ. I tried the following
> >> >> >
> >> >> > *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
> >> >> >
> >> >> > but I am not getting the desired result.
> >> >>
> >> >> What are you getting? How does it differ from the desired result?
> >> >>
> >> >> >  I have
> >> >> >
> >> >> > Any help or idea?
> >> >>
> >> >> I get:
> >> >>
> >> >> > dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ",
> >> >> > "\\\\",
> >> >> + "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names =
> >> >> c("X",
> >> >> + "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
> >> >> >
> >> >> > test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
> >> >> > test
> >> >>   X Var1 Freq
> >> >> 3 3  MSN 1040
> >> >> 4 4  YYZ  300
> >> >>
> >> >> Which seems reasonable to me.
> >> >>
> >> >>
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >>
> >> >> Please don't post in HTML either: it introduces all sorts of errors
> to
> >> >> your message.
> >> >>
> >> >> Sarah
> >> >>
> >
> >
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Thu Nov 12 05:33:44 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 11 Nov 2015 23:33:44 -0500
Subject: [R] Cleaning
In-Reply-To: <CADDFq30rGDEWcrQdbEDzoEKZh3YHrwLzYxNY5HGsCew9Hp=mNA@mail.gmail.com>
References: <CADDFq31m55xzGNVTy8rG3JBkC=z6dfOpKoc28+YUq3-09uE1QA@mail.gmail.com>
	<CAM_vjukkBdt5NyoOQ=E92y6Wg9GZwk0Phb6+n1ZNLC8QSspfVQ@mail.gmail.com>
	<CADDFq33yRn1Ud7-BpGHSnXajtfvjYzGAoU7ucUn18O=hWni63Q@mail.gmail.com>
	<CAM_vjumfbUN0d8DGfd9uqO6pbjg5LaQeSfiC_KZoA+1udg6JPQ@mail.gmail.com>
	<CADDFq31d14s==wOqAYhN_xKMTBcBex2QBHAFuHJOCgaGrDE7Gg@mail.gmail.com>
	<CAM_vjumhkp+WF6jDp9QiVP9oaKnm-YjO843R80k9PDtXN98U3w@mail.gmail.com>
	<CADDFq30rGDEWcrQdbEDzoEKZh3YHrwLzYxNY5HGsCew9Hp=mNA@mail.gmail.com>
Message-ID: <647AFA5C-2F02-43F5-B346-BD5EC3C1357D@utoronto.ca>

If what you posted here is what you typed, your syntax is wrong.
I strongly advise you to consult the two links here:

http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide and don't post in HTML.


B.


On Nov 11, 2015, at 10:03 PM, Ashta <sewashm at gmail.com> wrote:

> Sarah,
> 
> Thank you very much.   For the other variables
> I was trying to do the same job in different way because it is easier to
> list it
> 
> Example
> 
> test < which(dat$var1  !="BAA" | dat$var1 !="FAG" )
> {
>    dat <- dat[-test,]}   and I did not get the  right result. What am I
> missing here?
> 
> 
> 
> 
> 
> On Wed, Nov 11, 2015 at 7:54 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> 
>> On Wed, Nov 11, 2015 at 8:44 PM, Ashta <sewashm at gmail.com> wrote:
>>> Hi Sarah,
>>> 
>>> I used the following to clean my data, the program crushed several times.
>>> 
>>> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>>> 
>>> What is the difference between these two
>>> 
>>> test <- dat[dat$Var1  %in% "YYZ" | dat$Var1 %in% "MSN" ,]
>> 
>> Besides that you're using %in% wrong? I told you how to proceed.
>> 
>> myvalues <- c("YYZ", "MSN")
>> 
>> test <- subset(dat, Var1 %in% myvalues)
>> 
>> 
>>> subset(dat, Var1 %in% myvalues)
>>  X Var1 Freq
>> 3 3  MSN 1040
>> 4 4  YYZ  300
>> 
>>> 
>>> 
>>> 
>>> 
>>> On Wed, Nov 11, 2015 at 6:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
>>> wrote:
>>>> 
>>>> Please keep replies on the list so others may participate in the
>>>> conversation.
>>>> 
>>>> If you have a character vector containing the potential values, you
>>>> might look at %in% for one approach to subsetting your data.
>>>> 
>>>> Var1 %in% myvalues
>>>> 
>>>> Sarah
>>>> 
>>>> On Wed, Nov 11, 2015 at 7:10 PM, Ashta <sewashm at gmail.com> wrote:
>>>>> Thank you Sarah for your prompt response!
>>>>> 
>>>>> I have the list of values of the variable Var1 it is around 20.
>>>>> How can I modify this one to include all the 20 valid values?
>>>>> 
>>>>> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>>>>> 
>>>>> Is there a way (efficient )  of doing it?
>>>>> 
>>>>> Thank you again
>>>>> 
>>>>> 
>>>>> 
>>>>> On Wed, Nov 11, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com
>>> 
>>>>> wrote:
>>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> On Wed, Nov 11, 2015 at 6:51 PM, Ashta <sewashm at gmail.com> wrote:
>>>>>>> Hi all,
>>>>>>> 
>>>>>>> I have a data frame with  huge rows and columns.
>>>>>>> 
>>>>>>> When I looked at the data,  it has several garbage values need to
>> be
>>>>>>> 
>>>>>>> cleaned. For a sample I am showing you the frequency distribution
>>>>>>> of one variables
>>>>>>> 
>>>>>>>    Var1 Freq
>>>>>>> 1    :    3
>>>>>>> 2    ]    6
>>>>>>> 3    MSN 1040
>>>>>>> 4    YYZ  300
>>>>>>> 5    \\    4
>>>>>>> 6    +     3
>>>>>>> 7.   ?>   15
>>>>>> 
>>>>>> Please use dput() to provide your data. I made a guess at what you
>> had
>>>>>> in R, but could be wrong.
>>>>>> 
>>>>>> 
>>>>>>> and continues.
>>>>>>> 
>>>>>>> I want to keep those rows that contain only a valid variable value
>>>>>>> 
>>>>>>> In this  case MSN and YYZ. I tried the following
>>>>>>> 
>>>>>>> *test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]*
>>>>>>> 
>>>>>>> but I am not getting the desired result.
>>>>>> 
>>>>>> What are you getting? How does it differ from the desired result?
>>>>>> 
>>>>>>> I have
>>>>>>> 
>>>>>>> Any help or idea?
>>>>>> 
>>>>>> I get:
>>>>>> 
>>>>>>> dat <- structure(list(X = 1:7, Var1 = c(":", "]", "MSN", "YYZ",
>>>>>>> "\\\\",
>>>>>> + "+", "?>"), Freq = c(3L, 6L, 1040L, 300L, 4L, 3L, 15L)), .Names =
>>>>>> c("X",
>>>>>> + "Var1", "Freq"), class = "data.frame", row.names = c(NA, -7L))
>>>>>>> 
>>>>>>> test <- dat[dat$Var1 == "YYZ" | dat$Var1 =="MSN" ,]
>>>>>>> test
>>>>>>  X Var1 Freq
>>>>>> 3 3  MSN 1040
>>>>>> 4 4  YYZ  300
>>>>>> 
>>>>>> Which seems reasonable to me.
>>>>>> 
>>>>>> 
>>>>>>> 
>>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> Please don't post in HTML either: it introduces all sorts of errors
>> to
>>>>>> your message.
>>>>>> 
>>>>>> Sarah
>>>>>> 
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Nov 11 23:02:43 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 Nov 2015 09:02:43 +1100
Subject: [R] Calculating distance between words in string
In-Reply-To: <1A8C1289955EF649A09086A153E2672403C7CA2E49@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CACs_9v9vR-YwXucTgR=kcaYwZSifEGZSnmMoPstCU0LhpAsjww@mail.gmail.com>
	<1A8C1289955EF649A09086A153E2672403C7CA2E49@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CA+8X3fWfY9+sDTMnO_39_YdQgy4A2UFUktPP8cUhL+Co4fT51Q@mail.gmail.com>

Perhaps what you are seeking is a sparse distance matrix.

"How far is each word from every other matching word"

sentence<-"How far is each word from every other matching word"
words<-tolower(unlist(strsplit(sentence," ")))
nwords<-length(words)
wdm<-matrix(NA,nrow=nwords,ncol=nwords)
for(word in 1:nwords) {
 wordmatch<-grep(words[word],words,fixed=TRUE)
 wdm[word,wordmatch]<-wordmatch-word
}
rownames(wdm)<-colnames(wdm)<-words
wdm

The result contains zeros for a self-match, relative positions for the
desired matches and NA for non-matches.

Jim



On Thu, Nov 12, 2015 at 12:15 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl
> > Subject: [R] Calculating distance between words in string
> >
> > .. given a specific keyword, I need to assign labels to the other words
> > based on the distance (number of words) to this keyword.
> >
> >...
> > If the sentence contains more than one instance of the keyword, I need
> values
> > for each instance.
>
> What would you like to happen when the sentence contains more than one
> instance of other words and more than one instance of both?
>
> e.g. what output do you want from
> " amet is not the only instance of 'amet', and there is more than one
> instance of 'instance', 'is', 'of' and 'and'."
>
>
> S Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From eliza_botto at outlook.com  Thu Nov 12 06:25:06 2015
From: eliza_botto at outlook.com (Eliza Botto)
Date: Thu, 12 Nov 2015 05:25:06 +0000
Subject: [R] Problem with Downloading TRMM
Message-ID: <SNT152-W662EB447C01322A688EE759A120@phx.gbl>

Dear Users of R,
I have this following confusion.
I want to download 3 hourly TRMM data from NASA website by using R, from the following website


##main Link
http://giovanni.gsfc.nasa.gov/giovanni/#service=ArAvTs&starttime=2008-12-31T00:00:00Z&endtime=2009-12-31T23:59:59Z&bbox=67,-50,67,-50&data=TRMM_3B42_007_precipitation
##the link allows to download data either in CSV format or png format. I prefer CSV format. The exact link to CSV file is
#Download link
http://giovanni.gsfc.nasa.gov/giovanni/daac-bin/serializer.pl?SESSION=BBF227CA-88F9-11E5-9F55-BE455C2ADB03:BBC3D554-88FA-11E5-BA70-60705B2ADB03:BBC8D64E-88FA-11E5-BA70-60705B2ADB03&FILE=g4.areaAvgTimeSeries.TRMM_3B42_007_precipitation.20081231-20091231.67E_50S_67E_50S.nc

In main link "bbox=67,-50,67,-50" shows the point where I want to download the data in the form of CSV file. The problem is that I have a vector of such points, a small part of which is below
structure(c(72, 71, 54, 67, 50, 53, 30, -50), .Dim = c(4L, 2L), .Dimnames = list(c("d", "e", "f", "g"), NULL))
How can I make a loop to download the data on given points automatically?

N.B.
It was fairly easy to download it, a few months ago. But ever since the outlook of website is changed. I cant use the previous codes that I use to use to download data.
The previous codes are
##############################################################################

setwd("C:\\Users\\Eliza\\Desktop\\hrly")

A few coordinates from the sample where I want to download data.

df2 <- data.frame(Longitude = c(45.75,46.25,46.75,), Latitude = c(34.75,34.25,33.75)) 

urlPattern1<-("http://disc2.nascom.nasa.gov/daac-bin/Giovanni/tovas/Giovanni_cgi.pl?west=%s&north=%s&east=%s&south=%s&params=1%%7C3B42_V7&plot_type=Time+Plot&byr=1998&bmo=01&bdy=1&bhr=00&eyr=1998&emo=12&edy=31&ehr=21&begin_date=1998%%2F01%%2F01%%2F00&end_date=2014%%2F02%%2F28%%2F21&cbar=cdyn&cmin=&cmax=&yaxis=ydyn&ymin=&ymax=&yint=&ascres=0.25x0.25&global_cfg=tovas.global.cfg.pl&instance_id=TRMM_V7&prod_id=3B42&action=ASCII+Output")


fileDestination <- c("C:\\Users\\Eliza\\Desktop\\hrly") 
fileNames <- paste("precip", df2[,1], df2[,2], sep = "_")
 fileNames <- paste(fileNames, "txt", sep = ".")
 files <- file.path(fileDestination, fileNames) for (i in 1:nrow(df2)){    queryUrl <- sprintf(urlPattern1, df2[i, 1], df2[i, 2], df2[i, 1], df2[i, 2])    download.file(queryUrl, files[i])}
 ## import data in first file 
precip <- read.table(files[1], skip = 4, header = TRUE, na.strings = "-9990000000000000649570314828644352.0000",                    sep = "", check.names = FALSE, stringsAsFactors = FALSE) 
head(precip,2) 
Kindly help me out on it.
Thankyou very much in advance.
 		 	   		  
	[[alternative HTML version deleted]]


From judsonblake at msn.com  Thu Nov 12 06:30:29 2015
From: judsonblake at msn.com (Judson)
Date: Thu, 12 Nov 2015 00:30:29 -0500
Subject: [R] Plot with pauses?
Message-ID: <COL130-W287B31682F3C91D9C25051AD120@phx.gbl>

I'm trying to create a 
series of demos for students.  

It would be helpful
if plotted data points
could appear one by one
with, say, half-second delays 
between points.  
 
For instance, 
code like this

v<-0:60
z<-3/5+4i/5
t<-z^(v/9)
plot(Re(t),Im(t))

would be better if I 
could invoke some 
pausing between points 
so the student could see
the progression of 
the process.  Many 
mathematical progressions 
might be more understandable
if the viewer could see
this happen over intervals
of time.   

Naturally I'd like to 
avoid for loops if that's 
possible.  

I really don't know
where to start my 
search.   Any suggestions?  

..... judson blake 		 	   		  
	[[alternative HTML version deleted]]


From dswiegert at gmail.com  Thu Nov 12 03:54:50 2015
From: dswiegert at gmail.com (Daniel Wiegert)
Date: Wed, 11 Nov 2015 21:54:50 -0500
Subject: [R] Quotes
Message-ID: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>

Hello, I am trying to use a code which requires quotes around each of about 1000 entries. When I did this in Microsoft programs, R rejected every quote. I converted the font to courier new size 10 true type (the R default). No luck. I had to find a sample code and copy the quotes from that 2000 times for R to accept them, or type them in manually in R. 

Is there anyway to make this easier? What font in Word/Excel etc. does R prefer and will function using quotes? Commas, letters, numbers, all work, just the full double quotes won't work. 

Thank you,

Daniel

From dwinsemius at comcast.net  Thu Nov 12 06:55:45 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Nov 2015 21:55:45 -0800
Subject: [R] Plot with pauses?
In-Reply-To: <COL130-W287B31682F3C91D9C25051AD120@phx.gbl>
References: <COL130-W287B31682F3C91D9C25051AD120@phx.gbl>
Message-ID: <D92FCAAB-F8D6-44C1-A7F7-6A82B63D74FE@comcast.net>


> On Nov 11, 2015, at 9:30 PM, Judson <judsonblake at msn.com> wrote:
> 
> I'm trying to create a 
> series of demos for students.  
> 
> It would be helpful
> if plotted data points
> could appear one by one
> with, say, half-second delays 
> between points.  
> 

?Sys.sleep


> For instance, 
> code like this
> 
> v<-0:60
> z<-3/5+4i/5
> t<-z^(v/9)
> plot(Re(t),Im(t))

If you want to plot points then use:

?points


> 
> would be better if I 
> could invoke some 
> pausing between points 
> so the student could see
> the progression of 
> the process.  Many 
> mathematical progressions 
> might be more understandable
> if the viewer could see
> this happen over intervals
> of time.   
> 
> Naturally I'd like to 
> avoid for loops if that's 
> possible.  
> 
> I really don't know
> where to start my 
> search.   Any suggestions?  
> 
> ..... judson blake 		 	   		  
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Nov 12 07:02:09 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 11 Nov 2015 22:02:09 -0800
Subject: [R] Quotes
In-Reply-To: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
References: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
Message-ID: <08E77FC6-98C9-40A3-922E-1ACEC807B4EF@comcast.net>


> On Nov 11, 2015, at 6:54 PM, Daniel Wiegert <dswiegert at gmail.com> wrote:
> 
> Hello, I am trying to use a code which requires quotes around each of about 1000 entries. When I did this

The use of pronouns in place of code is a major cause of ambiguity. What was ? ?this??


> in Microsoft programs, R rejected every quote.

Again. the phrase "R rejected? is completely ambiguous. Did you see an error message after you did <something>. If so, please offer up for examination both the <something> and the error message.


> I converted the font to courier new size 10 true type (the R default). No luck. I had to find a sample code and copy the quotes from that 2000 times for R to accept them, or type them in manually in R. 

Word typically uses smart quotes rather than either the single-quote or double-quotes. You can change this behavior in Word by changing the preferences. But you really should not be using Word for either data entry or for code.

> 
> Is there anyway to make this easier? What font in Word/Excel etc. does R prefer and will function using quotes? Commas, letters, numbers, all work, just the full double quotes won't work. 

As above. The ?quotes? that Word uses are not shared by most codign platforms.

> 
> Thank you,
> 
> Daniel
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Nov 12 07:07:38 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 Nov 2015 17:07:38 +1100
Subject: [R] seconds to h:m:s format
In-Reply-To: <CAM-xyZgxSXMpqaaccObMrvoD6zoEyiiByANTRVE6chPBFfs+Gw@mail.gmail.com>
References: <CAM-xyZiTz6HNQUOEqgch=J9uOUE1XpR1JPpWjtfUwvCd5uo1Kw@mail.gmail.com>
	<CA+8X3fU_ZHz2xt1O8eaa1R-ZyOeP8U3fgFvMTt5mS-1PZ9vUJw@mail.gmail.com>
	<CAM-xyZgxSXMpqaaccObMrvoD6zoEyiiByANTRVE6chPBFfs+Gw@mail.gmail.com>
Message-ID: <CA+8X3fUHbPtoHeMrPVnZUyhwJWs_G0YS=csWP87kv5-i4Mmwrg@mail.gmail.com>

Any date would do as you are only getting the H:M:S at the end. I just
chose the zero date.

Jim


On Thu, Nov 12, 2015 at 1:25 PM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Thank you, Jim.
>
> Just to understand it:
>
> You replicated 10 times: "1970-01-01". Why this specific date?
>
>
>
>
>
> 2015-11-11 20:22 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:
>
>> Hi Omar,
>> There is some sort of error in your structure definition, but the
>> following works for me:
>>
>> session.duration.fuente <-
>>  data.frame(mes=c(rep("oct",5),rep("nov",5)),
>>   fuente=c("adwords", "directo", "organico", "redes sociales",
>>    "referral", "adwords", "directo", "organico", "redes sociales",
>>    "referral"),
>>   avg.session.duration = c(970178, 1642455, 780485,
>>    3170400, 179184, 352995, 833827, 260610, 2318928, 49836))
>>
>> base_dates<-strptime(rep("1970-01-01",10),"%Y-%m-%d")
>> format(base_dates+session.duration.fuente$avg.session.duration,"%H:%M:%S")
>>  [1] "05:29:38" "00:14:15" "00:48:05" "16:40:00" "01:46:24" "02:03:15"
>>  [7] "15:37:07" "00:23:30" "20:08:48" "13:50:36"
>>
>> Jim
>>
>> On Thu, Nov 12, 2015 at 10:15 AM, Omar Andr? Gonz?les D?az <
>> oma.gonzales at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I've a data frame with 3 columns: "mes", "fuente",
>>> "avg.sessions.duration".
>>>
>>> "avg.sessions.duration" is a column containing seconds.
>>>
>>> I need you help with:
>>>
>>> 1.-  Help to put these values in "h:m:s" format.
>>> .
>>>
>>> =======================================================
>>>
>>> I've found this german page:
>>>
>>> http://forum.r-statistik.de/viewtopic.php?f=25&t=5284
>>>
>>> So I've tried:
>>>
>>> for (i in 1:nrow(session.duration.fuente)) {
>>>
>>>   session.duration.fuente$avg.session.duration <-
>>> format(as.POSIXct('0001-01-01 00:00:00') +
>>> session.duration.fuente$avg.session.duration[i], "%H:%M:%S")
>>>
>>> }
>>>
>>> but got this error:
>>>
>>>  Error in unclass(e1) + unclass(e2) :
>>>   non-numeric argument to binary operator
>>>
>>> =======================================================
>>>
>>> After that I've tried: strptime:
>>>
>>> session.duration.fuente$avg.session.duration <-
>>> strptime(session.duration.fuente$avg.session.duration, "%H:%M:%OS")
>>>
>>> But got NAs.
>>>
>>> ========================================================
>>>
>>> Here is the data:
>>>
>>>
>>> session.duration.fuente <- structure(list(mes = structure(c(1L, 1L, 1L,
>>> 1L,
>>> 1L, 2L, 2L,
>>> 2L, 2L, 2L), .Label = c("oct", "nov"), class = c("ordered", "factor"
>>> )), fuente = c("adwords", "directo", "organico", "redes sociales",
>>> "referral", "adwords", "directo", "organico", "redes sociales",
>>> "referral"), avg.session.duration = c(970178, 1642455, 780485,
>>> 3170400, 179184, 352995, 833827, 260610, 2318928, 49836)), row.names =
>>> c(NA,
>>> -10L), class = c("grouped_df", "tbl_df", "tbl", "data.frame"), vars =
>>> list(
>>>     mes), drop = TRUE, .Names = c("mes", "fuente", "avg.session.duration"
>>> ))
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov 12 07:15:13 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Nov 2015 06:15:13 +0000
Subject: [R] Quotes
In-Reply-To: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
References: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C500090B@SRVEXCHMBX.precheza.cz>

Hi

Can you explain little bit more about your intention?

Here is some explanation about quotes

https://stat.ethz.ch/R-manual/R-devel/library/base/html/Quotes.html

http://stackoverflow.com/questions/13449233/send-a-text-string-containing-double-quotes-to-function

You could find it yourself easily by internet search as I did.

If this is not what you want, you need to be more specific.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
> Wiegert
> Sent: Thursday, November 12, 2015 3:55 AM
> To: r-help at r-project.org
> Subject: [R] Quotes
>
> Hello, I am trying to use a code which requires quotes around each of
> about 1000 entries. When I did this in Microsoft programs, R rejected
> every quote. I converted the font to courier new size 10 true type (the
> R default). No luck. I had to find a sample code and copy the quotes
> from that 2000 times for R to accept them, or type them in manually in
> R.
>
> Is there anyway to make this easier? What font in Word/Excel etc. does
> R prefer and will function using quotes? Commas, letters, numbers, all
> work, just the full double quotes won't work.
>
> Thank you,
>
> Daniel
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Thu Nov 12 07:11:37 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 12 Nov 2015 17:11:37 +1100
Subject: [R] Quotes
In-Reply-To: <08E77FC6-98C9-40A3-922E-1ACEC807B4EF@comcast.net>
References: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
	<08E77FC6-98C9-40A3-922E-1ACEC807B4EF@comcast.net>
Message-ID: <CA+8X3fX2BN+cvf8_5hs-vtOHsnRo8wLKPteaBpDczJsci9C0eQ@mail.gmail.com>

Hi Daniel,
As David said, these problems are almost always due to fancy quotes. If you
want plain old ASCII 34 (double) or 39 (single) quotes, try using Notepad
for your editing rather than Word.

Jim


On Thu, Nov 12, 2015 at 5:02 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Nov 11, 2015, at 6:54 PM, Daniel Wiegert <dswiegert at gmail.com> wrote:
> >
> > Hello, I am trying to use a code which requires quotes around each of
> about 1000 entries. When I did this
>
> The use of pronouns in place of code is a major cause of ambiguity. What
> was ? ?this??
>
>
> > in Microsoft programs, R rejected every quote.
>
> Again. the phrase "R rejected? is completely ambiguous. Did you see an
> error message after you did <something>. If so, please offer up for
> examination both the <something> and the error message.
>
>
> > I converted the font to courier new size 10 true type (the R default).
> No luck. I had to find a sample code and copy the quotes from that 2000
> times for R to accept them, or type them in manually in R.
>
> Word typically uses smart quotes rather than either the single-quote or
> double-quotes. You can change this behavior in Word by changing the
> preferences. But you really should not be using Word for either data entry
> or for code.
>
> >
> > Is there anyway to make this easier? What font in Word/Excel etc. does R
> prefer and will function using quotes? Commas, letters, numbers, all work,
> just the full double quotes won't work.
>
> As above. The ?quotes? that Word uses are not shared by most codign
> platforms.
>
> >
> > Thank you,
> >
> > Daniel
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pmakananisa at sars.gov.za  Thu Nov 12 12:51:23 2015
From: pmakananisa at sars.gov.za (Mangalani Peter Makananisa)
Date: Thu, 12 Nov 2015 11:51:23 +0000
Subject: [R] *.rpt data
Message-ID: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>

Hi,

Could you please assist, how do I load the rpt data into R without converting it first to csv?

Kind regards
Peter

Please Note: This email and its contents are subject to our email legal notice which can be viewed at http://www.sars.gov.za/Pages/Email-disclaimer.aspx
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Thu Nov 12 13:44:37 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 12 Nov 2015 06:44:37 -0600
Subject: [R] recursive partitioning in R
Message-ID: <c10f8b$1rdele@ironport10.mayo.edu>

Look at the rpart vignette "User written split functions".  The code allows you to add 
your own splitting method to the code (in R, no C required).  This has proven to be very 
useful for trying out new ideas.

The second piece would be to do your own cross-validation.  That is, turn off the built in 
cross-validation using the xval=0 option, then explicitly do the cross-validation 
yourself.  Fit a new tree to some chosen subset of data, using your split rule of course, 
and then use predict() to get predicted values for the remaining observations. Again, this 
is all in R, and you can explicitly control your in or out of bag subsets.
The xpred.rpart function may be useful to automate some of the steps.

If you look up rpart on CRAN, you will see a link to the package source.  If you were to 
read the C source code you will discover that 95% is boring bookkeeping of what 
observations are in what part(s) of the tree, sorting the data, tracking missing values, 
etc.  If you ever do want to write your own code you are more than welcome to build off 
this --- I wouldn't want to write that part again.

Terry Therneau

On 11/12/2015 05:00 AM, r-help-request at r-project.org wrote:
> Dear List,
>
> I'd like to make a few modifications to the typical CART algorithm, and
> I'd rather not code the whole thing from scratch.  Specifically I want
> to use different in-sample and out-of-sample fit criteria in the split
> choosing and cross-validation stages.
>
> I see however that the code for CART in both the rpart and the tree
> packages is written in C.
>
> Two questions:
>
>    * Where is the C code?  It might be possible to get a C-fluent
>      programmer to help me with this.
>    * Is there any code for CART that is written entirely in R?
>
> Thanks,
> Andrew


From sarah.goslee at gmail.com  Thu Nov 12 14:16:52 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 Nov 2015 08:16:52 -0500
Subject: [R] *.rpt data
In-Reply-To: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
Message-ID: <CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>

What is "rpt data"? What source produced it? Where did you get it? Is it
associated with particular software? Is it ascii or binary?

Sarah

On Thursday, November 12, 2015, Mangalani Peter Makananisa <
pmakananisa at sars.gov.za> wrote:

> Hi,
>
> Could you please assist, how do I load the rpt data into R without
> converting it first to csv?
>
> Kind regards
> Peter
>
> Please Note: This email and its contents are subject to our email legal
> notice which can be viewed at
> http://www.sars.gov.za/Pages/Email-disclaimer.aspx
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Nov 12 14:40:42 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 12 Nov 2015 08:40:42 -0500
Subject: [R] *.rpt data
In-Reply-To: <BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
	<CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>
	<BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
Message-ID: <CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>

On Thursday, November 12, 2015, Mangalani Peter Makananisa <
pmakananisa at sars.gov.za> wrote:

> .rpt is one of the data extension like .csv, .txt , ?..
>
> All extensions are 'data extensions' in some sense.

Without knowing quite a bit more about YOUR rpt extension, it's impossible
to answer.


> *From:* Sarah Goslee [mailto:sarah.goslee at gmail.com
> <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>]
> *Sent:* 12 November 2015 03:17 PM
> *To:* Mangalani Peter Makananisa
> *Cc:* r-help at r-project.org
> <javascript:_e(%7B%7D,'cvml','r-help at r-project.org');>
> *Subject:* Re: [R] *.rpt data
>
>
>
> What is "rpt data"? What source produced it? Where did you get it? Is it
> associated with particular software? Is it ascii or binary?
>
> Sarah
>
> On Thursday, November 12, 2015, Mangalani Peter Makananisa <
> pmakananisa at sars.gov.za
> <javascript:_e(%7B%7D,'cvml','pmakananisa at sars.gov.za');>> wrote:
>
> Hi,
>
> Could you please assist, how do I load the rpt data into R without
> converting it first to csv?
>
> Kind regards
> Peter
>
> Please Note: This email and its contents are subject to our email legal
> notice which can be viewed at
> http://www.sars.gov.za/Pages/Email-disclaimer.aspx
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
> Please Note: This email and its contents are subject to our email legal
> notice which can be viewed at
> http://www.sars.gov.za/Pages/Email-disclaimer.aspx
>


-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Nov 12 14:52:48 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 12 Nov 2015 13:52:48 +0000
Subject: [R] *.rpt data
In-Reply-To: <CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
	<CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>
	<BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
	<CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000A7E@SRVEXCHMBX.precheza.cz>

Hi

If it is really "like" csv data you can import it by

read.csv...

or you can use any other read.* function.

Did you try it? If yes, what was the result?
If not, why not?

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> Goslee
> Sent: Thursday, November 12, 2015 2:41 PM
> To: Mangalani Peter Makananisa; r-help
> Subject: Re: [R] *.rpt data
>
> On Thursday, November 12, 2015, Mangalani Peter Makananisa <
> pmakananisa at sars.gov.za> wrote:
>
> > .rpt is one of the data extension like .csv, .txt , ?..
> >
> > All extensions are 'data extensions' in some sense.
>
> Without knowing quite a bit more about YOUR rpt extension, it's
> impossible to answer.
>
>
> > *From:* Sarah Goslee [mailto:sarah.goslee at gmail.com
> > <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>]
> > *Sent:* 12 November 2015 03:17 PM
> > *To:* Mangalani Peter Makananisa
> > *Cc:* r-help at r-project.org
> > <javascript:_e(%7B%7D,'cvml','r-help at r-project.org');>
> > *Subject:* Re: [R] *.rpt data
> >
> >
> >
> > What is "rpt data"? What source produced it? Where did you get it? Is
> > it associated with particular software? Is it ascii or binary?
> >
> > Sarah
> >
> > On Thursday, November 12, 2015, Mangalani Peter Makananisa <
> > pmakananisa at sars.gov.za
> > <javascript:_e(%7B%7D,'cvml','pmakananisa at sars.gov.za');>> wrote:
> >
> > Hi,
> >
> > Could you please assist, how do I load the rpt data into R without
> > converting it first to csv?
> >
> > Kind regards
> > Peter
> >
> > Please Note: This email and its contents are subject to our email
> > legal notice which can be viewed at
> > http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Sarah Goslee
> > http://www.stringpage.com
> > http://www.sarahgoslee.com
> > http://www.functionaldiversity.org
> >
> > Please Note: This email and its contents are subject to our email
> > legal notice which can be viewed at
> > http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> >
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marongiu.luigi at gmail.com  Thu Nov 12 15:19:58 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Thu, 12 Nov 2015 14:19:58 +0000
Subject: [R] How to calculate variance on multiple numbers at once?
In-Reply-To: <B0D502A6DB1.0000082Djrkrideau@inbox.com>
References: <a55a64c8f90.00000dcajrkrideau@inbox.com>
	<camk+s2svwmoxi76pg72_gb40ny1e-rqc5wzoh=njzxtxo=ka6w@mail.gmail.com>
	<CAMk+s2T08RrkZkVshrTU5KP0a2PuBu6dGfpONuR+TW+HF3w7ZQ@mail.gmail.com>
	<B0D502A6DB1.0000082Djrkrideau@inbox.com>
Message-ID: <CAMk+s2Q4-NMUB21+9CFdzFNppqvTVBR1hHskbK+Mp_maK-TzcQ@mail.gmail.com>

Essentially the problem is related to this problem. I am measuring the
fluorescence (flu) generated over time (clock) from 5 samples (samp)
which are grouped by two targets (targ).
I can calculate the variance of the fluorescence for each sample at a
given time (in this example, for sample 1); but if I consider a target
at the time there would be multiple readings at once to consider.
would the variance formula still be OK to use.
In this example:
>>>
samp <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
5, 5, 5, 5, 5)
clock <- rep(1:5,5)
targ <- c(rep("A", 5), rep("B", 5), rep("A", 5), rep("A", 5), rep("B", 5))
flu <- c(-0.012, -0.01, -0.008, -0.002, -0.001, -0.007, -0.008,
-0.009, -0.009, -0.012, -0.002, -0.003, -0.003, 0.001, 0.002, -0.006,
-0.001, 0.001, 0.002, 0.002, -0.002, -0.003, -0.003, -0.002, -0.001)
my.data <- data.frame(well, clock, targ, flu, stringsAsFactors = FALSE)

# variance with individual numbers
sub <- subset(my.data, samp == 1)
plot(sub$flu ~ sub$clock)
abline(lm(sub$flu ~ sub$clock))
for (i in 2:nrow(sub)) {
  X <- subset(sub, clock <= i)
  V <- var(X$flu)
  cat("variance at clock ", i, " = ", V, "\n", sep="")
}
# variance with multiple numbers
sub <- subset(my.data, targ == 'A')
plot(sub$flu ~ sub$clock)
abline(lm(sub$flu ~ sub$clock))
for (i in 2:max(sub$clock)) {
  X <- subset(sub, clock <= i)
  V <- var(X$flu)
  cat("variance at clock ", i, " = ", V, "\n", sep="")
}

the results for the individual numbers are:
variance at clock 2 = 2e-06
variance at clock 3 = 4e-06
variance at clock 4 = 1.866667e-05
variance at clock 5 = 2.38e-05

while the results for the multiple numbers are:
variance at clock 2 = 2.026667e-05
variance at clock 3 = 1.911111e-05
variance at clock 4 = 2.026515e-05
variance at clock 5 = 1.995238e-05

shall I accept these latter values?
Thanks

On Thu, Nov 12, 2015 at 10:59 AM, John Kane <jrkrideau at inbox.com> wrote:
> I still don't understand what you are doing. I think we need to see your actual data and the code your are using.  If S.Ellison's post has not shown up it is below my signature.
>
> Have a look at http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for suggestions on how to pose a question here. In particular data should be supplied in dput() format as it gives us a copy of exactly how the data is formatted on your machine.
>
>
> John Kane
> Kingston ON Canada
>
> ## ===========================================
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>> Marongiu
>> if I have a sample set of the following numbers x1=0.09, x2=0.94, x3=0.48,
>> x4=0.74, x5=0.04 I can calculate the variance easily.
> Not without concatenating them into a vector, you can't. You need them in a vector, as in
> var( c(x1, x2, x3, x4, x5) )
>
>> But if each x is actually a subset of multiple values, what would be the formula
>> to calculate the variance? and it is possible to implement such mathematical
>> function in R?
> This is what R wants anyway, so the function you are looking for is var()
>
>> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26, 0.89, 0.58),
>> x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and x5=(0.65, 0.16, 0.72) how can i
>> calculate the variance for each x?
> var(x1)
> var(x2)
> ....
>
> or, if you want to be a bit more slick about it and do it in one line
>
> lapply(list( x1, x2, x3, ...), var  )
>
> (or sapply() if you want a vector result)
>
> ## ===========================================
>
>
>> -----Original Message-----
>> From: marongiu.luigi at gmail.com
>> Sent: Wed, 11 Nov 2015 23:20:26 +0000
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] How to calculate variance on multiple numbers at once?
>>
>> Thank you for the reply. For clarification, let's say that I can
>> calculate the sum of variances of the individual x numbers in five
>> consecutive steps (although of course there are better
>> implementations) where each step the sum is incremented by (x -
>> mean)^2.
>> In the case I am handling, at each step i have to consider 3 values at
>> once and I don't know how to relate them neither with the mathematical
>> formula nor with the R implementation.
>> Besides I haven't seen Ellison's answer...
>> Best regards
>> L
>>
>> On Wed, Nov 11, 2015 at 1:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>>> I really don't understand what you are looking for but if S. Ellison's
>>> answer is not what you want what about this where your various x vectors
>>> are in a data frame
>>>
>>> ibrary(reshape2)
>>> library(plyr)
>>>
>>> dat1  <-  structure(list(x1 = c(0.77, 0.22, 0.44), x2 = c(0.26, 0.89,
>>> 0.58
>>> ), x3 = c(0.2, 0.25, 0.91), x4 = c(0.06, 0.13, 0.26), x5 = c(0.65,
>>> 0.16, 0.72)), .Names = c("x1", "x2", "x3", "x4", "x5"), row.names =
>>> c(NA,
>>> -3L), class = "data.frame")
>>>
>>> m1  <-   melt(dat1)
>>>
>>> ddply(m1, .(variable), summarize, variance = var(value))
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: marongiu.luigi at gmail.com
>>>> Sent: Wed, 11 Nov 2015 11:26:25 +0000
>>>> To: r-help at r-project.org
>>>> Subject: [R] How to calculate variance on multiple numbers at once?
>>>>
>>>> Dear all,
>>>>
>>>> if I have a sample set of the following numbers x1=0.09, x2=0.94,
>>>> x3=0.48, x4=0.74, x5=0.04 I can calculate the variance easily.
>>>> But if each x is actually a subset of multiple values, what would be
>>>> the formula to calculate the variance? and it is possible to implement
>>>> such mathematical function in R?
>>>>
>>>> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26,
>>>> 0.89, 0.58), x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and
>>>> x5=(0.65, 0.16, 0.72) how can i calculate the variance for each x?
>>>>
>>>> Thank you
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ____________________________________________________________
>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>>> your desktop!
>>> Check it out at http://www.inbox.com/marineaquarium
>>>
>>>
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>


From john.archie.mckown at gmail.com  Thu Nov 12 15:26:15 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 12 Nov 2015 08:26:15 -0600
Subject: [R] *.rpt data
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000A7E@SRVEXCHMBX.precheza.cz>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
	<CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>
	<BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
	<CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000A7E@SRVEXCHMBX.precheza.cz>
Message-ID: <CAAJSdjjR3YEuoLukpLOss9OUCquW9ki9DNHR6JAdy1v5bNv6+w@mail.gmail.com>

On Thu, Nov 12, 2015 at 7:52 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> If it is really "like" csv data you can import it by
>
> read.csv...
>
> or you can use any other read.* function.
>
> Did you try it? If yes, what was the result?
> If not, why not?
>
> Cheers
> Petr
>

?Purely as a guess, ".rpt" really seems to be short for "report". Which I
would guess indicates that this is some sort of file which was originally
physically printed to be read by a human. So I would _guess_ that perhaps
it is column oriented and might be readable using read.fwf() .Or course, it
if really is a "report" there are those irritating page headers & footers,
perhaps along with a summary at the end which would need to be ignored. The
OP really needs to cut'n'paste (NO HTML PLEASE!) about 10 lines for us to
all "eyeball".?


-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Nov 12 15:37:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 12 Nov 2015 14:37:57 +0000
Subject: [R] *.rpt data
In-Reply-To: <CAAJSdjjR3YEuoLukpLOss9OUCquW9ki9DNHR6JAdy1v5bNv6+w@mail.gmail.com>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
	<CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>
	<BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
	<CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000A7E@SRVEXCHMBX.precheza.cz>
	<CAAJSdjjR3YEuoLukpLOss9OUCquW9ki9DNHR6JAdy1v5bNv6+w@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DC381@mb02.ads.tamu.edu>

Another possibility for .rpt files from file-extensions.org:

"The rpt file extension is frequently used for various reports - output files of programs, often used for further analyze. Probably the most common type of RPT format is the one exported by Crystal Reports.

Crystal Reports is a business intelligence program for generating reports from a  wide range of data sources. Many applications (including Microsoft Visual Studio) bundled Crystal Reports as a general tool for reporting.

Other programs might also use rpt file extension for their reports, but it is mostly not always Crystal Reports format, unless the program is using the same reporting engine."

If it is a Crystal Reports file, the portion needed would likely have to be converted to .csv unless 


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
Sent: Thursday, November 12, 2015 8:26 AM
To: r-help
Subject: Re: [R] *.rpt data

On Thu, Nov 12, 2015 at 7:52 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> If it is really "like" csv data you can import it by
>
> read.csv...
>
> or you can use any other read.* function.
>
> Did you try it? If yes, what was the result?
> If not, why not?
>
> Cheers
> Petr
>

?Purely as a guess, ".rpt" really seems to be short for "report". Which I
would guess indicates that this is some sort of file which was originally
physically printed to be read by a human. So I would _guess_ that perhaps
it is column oriented and might be readable using read.fwf() .Or course, it
if really is a "report" there are those irritating page headers & footers,
perhaps along with a summary at the end which would need to be ignored. The
OP really needs to cut'n'paste (NO HTML PLEASE!) about 10 lines for us to
all "eyeball".?


-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From marco.prado.bs at gmail.com  Thu Nov 12 17:19:03 2015
From: marco.prado.bs at gmail.com (Marco)
Date: Thu, 12 Nov 2015 14:19:03 -0200
Subject: [R] replace NA's with row means for specific columns
In-Reply-To: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
References: <1446493741.77535.YahooMailBasic@web120802.mail.ne1.yahoo.com>
Message-ID: <1447345140-sup-7655@marco-HP-2000-Notebook-PC>

Excerpts from Zahra via R-help's message of 2015-11-02 17:49:01 -0200:
> Hi there,
> 
> I am looking for some help replacing missing values in R with the row mean. This is survey data and I am trying to impute values for missing variables in each set of questions separately using the mean of the scores for the other questions within that set. 
> 
> I have a dataset that looks like this
> 
> ID      A1    A2    A3          B1     B2     B3         C1   C2   C3    C4
> b        4       5      NA          2       NA      4          5      1        3      NA
> c        4       5      1            NA      3        4          5      1        3      2
> d       NA     5      1            1        NA      4          5      1        3      2
> e        4       5      4            5       NA      4           5      1        3      2
> 
> 
> I want to replace any NA's in columns A1:A3 with the row mean for those columns only. So for ID=b, I want the NA in A3[ID=b] to be (4+5)/2 which is the average of the values in A1 and A2 for that row. 
> Same thing for columns B1:B3 - I want the NA in B2[ID=b] to be the mean of the values of B1 and B3 in row ID=b so that B2[ID=b] becomes 3 which is (2+4)/2. And same in C1:C4, I want C4[ID=b] to become (5+1+3)/3 which is the mean of C1:C3. 
> 
> Then I want to go to row ID=c and do the same thing and so on.
> 
> Can anybody help me do this? I have tried using rowMeans and subsetting but can't figure out the right code to do it. 
> 
> Thanks so much.
> Zahra
> 
use 

is.na(df[ which(df$ID) == 'b']) <- fmean(...), where fmean:

Depends on column selection (Axx, Byy, etc..) and the row id itself (so consider pass
the left hand of assignment entirely). I would use:

fmean <- function(row, col_selection) { # homework for you here }

Best Regards,

-- 
Marco Arthur @ (M)arco Creatives


From marco.prado.bs at gmail.com  Thu Nov 12 17:19:36 2015
From: marco.prado.bs at gmail.com (Marco)
Date: Thu, 12 Nov 2015 14:19:36 -0200
Subject: [R] problem in R
In-Reply-To: <563C119E.4070109@auckland.ac.nz>
References: <CABLo8nG69euPzPe-fn=2-d9cWOT7UP3c6UZpv9xKhD0bbPVW4Q@mail.gmail.com>
	<CA+8X3fXRvfcMqMgsRTJjf5Ey8YZ3A6YvJ=g6AOyVKmNrSAao8g@mail.gmail.com>
	<563C119E.4070109@auckland.ac.nz>
Message-ID: <1447345175-sup-9937@marco-HP-2000-Notebook-PC>

Excerpts from Rolf Turner's message of 2015-11-06 00:34:06 -0200:
> 
> On 06/11/15 14:31, Jim Lemon wrote:
> 
> <SNIP>
> 
> > The fundamental problem that has emerged in this discussion is that
> > you seem to be applying the method of post-modernist deconstruction
> > to programming in R. I see no future in this enterprise.
> 
> <SNIP>
> 
> *Gotta* be a fortune!!!
> 
> cheers,
> 
> Rolf
> 

Jim++
Rolf++

must be.

-- 
Marco Arthur @ (M)arco Creatives


From dswiegert at gmail.com  Thu Nov 12 15:48:38 2015
From: dswiegert at gmail.com (Daniel Wiegert)
Date: Thu, 12 Nov 2015 09:48:38 -0500
Subject: [R] Quotes
In-Reply-To: <CA+8X3fX2BN+cvf8_5hs-vtOHsnRo8wLKPteaBpDczJsci9C0eQ@mail.gmail.com>
References: <E029114F-A524-4168-B751-88D798952CDC@gmail.com>
	<08E77FC6-98C9-40A3-922E-1ACEC807B4EF@comcast.net>
	<CA+8X3fX2BN+cvf8_5hs-vtOHsnRo8wLKPteaBpDczJsci9C0eQ@mail.gmail.com>
Message-ID: <7B1DA8B5-3927-4574-8805-CF5F7D660174@gmail.com>

Thank you. This was helpful. I'll try it. 

Daniel Wiegert 

> On Nov 12, 2015, at 1:11 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Daniel,
> As David said, these problems are almost always due to fancy quotes. If you want plain old ASCII 34 (double) or 39 (single) quotes, try using Notepad for your editing rather than Word.
> 
> Jim
> 
> 
>> On Thu, Nov 12, 2015 at 5:02 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> > On Nov 11, 2015, at 6:54 PM, Daniel Wiegert <dswiegert at gmail.com> wrote:
>> >
>> > Hello, I am trying to use a code which requires quotes around each of about 1000 entries. When I did this
>> 
>> The use of pronouns in place of code is a major cause of ambiguity. What was ? ?this??
>> 
>> 
>> > in Microsoft programs, R rejected every quote.
>> 
>> Again. the phrase "R rejected? is completely ambiguous. Did you see an error message after you did <something>. If so, please offer up for examination both the <something> and the error message.
>> 
>> 
>> > I converted the font to courier new size 10 true type (the R default). No luck. I had to find a sample code and copy the quotes from that 2000 times for R to accept them, or type them in manually in R.
>> 
>> Word typically uses smart quotes rather than either the single-quote or double-quotes. You can change this behavior in Word by changing the preferences. But you really should not be using Word for either data entry or for code.
>> 
>> >
>> > Is there anyway to make this easier? What font in Word/Excel etc. does R prefer and will function using quotes? Commas, letters, numbers, all work, just the full double quotes won't work.
>> 
>> As above. The ?quotes? that Word uses are not shared by most codign platforms.
>> 
>> >
>> > Thank you,
>> >
>> > Daniel
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From wornimatthias at gmail.com  Thu Nov 12 17:27:58 2015
From: wornimatthias at gmail.com (Matthias Worni)
Date: Thu, 12 Nov 2015 17:27:58 +0100
Subject: [R] Compute Regressions with R-Function
Message-ID: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>

Hello

I was trying to set up a function() that allows easely to calculate
regressions for severel dependent variables with the same independent
variables.

My function looked like this but was turned down by an error (Im quiet new
to R Studio). So here is my solution:

b
CO2
logTrop_Aerosol
lm(b ~ CO2  + logTrop_Aerosol  )

Trend <- function(x,CO2,logTrop_Aerosol) { lm x   CO2  + logTrop_Aerosol}

b is a vector containing 400 values of heat content
CO2 also contains 400 values as well as logTropAerosol

my idea would be that I simply can replace x (heat content) by other
vectors containing heat content.

The error I got was the following:

Error: unexpected symbol in "Trend <- function(x,y,z) { lm x"

Thanks a lot for the help!

Best Matthias

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Nov 12 17:56:12 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 12 Nov 2015 11:56:12 -0500
Subject: [R] "haven" - read_spss: How to avoid extracting value labels
 instead of long labels?
Message-ID: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>

Hello!

I don't have an example file, but I think my question should be clear
without it.
I have an SPSS file. I read it in using 'haven':

library(haven)
spss1 <- read_spss("SPSS_Example.sav")

I created a function that extracts the long labels (in SPSS - "Label"):

fix_labels <- function(x, TextIfMissing) {
      val <- attr(x, "label")
      if (is.null(val)) TextIfMissing else val
}
longlabels <- sapply(spss1, fix_labels, TextIfMissing = "NO LABLE IN SPSS")

This function is supposed to create a vector of long labels and
usually it does, e.g.:

str(longlabels)
 Named chr [1:64] "Serial number" ...
 - attr(*, "names")= chr [1:64] "Respondent_Serial" "weight" "r7_1" "r7_2" ...

However, I just got an SPSS file with 92 columns and ran exactly the
same function on it. Now, I am getting not a vector, but a list

str(longlabels)
List of 92
 $ VEHRATED      : chr "VEHICLE RATED"
 $ RESPID        : chr "RESPONDENT ID"
 $ RESPID8       : chr "8 DIGIT RESPONDENT NUMBER"

An observation about the structure of longlabels here: those columns
that do NOT have a long lable in SPSS but DO have Values (value
labels) - for them my function grabs their value labels, so that now
my long label is recorded as a numeric vector with names, e.g.:

 $ AWARE2        : Named num [1:2] 1 2
  ..- attr(*, "names")= chr [1:2] "VERY/SOMEWHAT FAMILIAR" "NOT AT ALL FAMILIAR"

Question: How could I avoid the extraction of the Value Labels for the
columns that have no long labels?

Thank you very much!
-- 
Dimitri Liakhovitski


From NordlDJ at dshs.wa.gov  Thu Nov 12 18:09:40 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 12 Nov 2015 17:09:40 +0000
Subject: [R] Compute Regressions with R-Function
In-Reply-To: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
References: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662EDB3C56@WAXMXOLYMB025.WAX.wa.lcl>

You may have additional scoping problems depending on where you various variables exist, but your Trend function syntax is incorrect. You need parentheses around your arguments to the lm call, and you left out the '~' in your formula.  In addition, don't fool yourself by your use of the names CO2 and logTrop_Aerosol as the function arguments.  Those arguments don't refer to variables in the global environment.  Function parameters have local scope in the function.   

Trend <- function(x,CO2,logTrop_Aerosol) { lm(x ~  CO2  + logTrop_Aerosol)}


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthias Worni
Sent: Thursday, November 12, 2015 8:28 AM
To: r-help at r-project.org
Subject: [R] Compute Regressions with R-Function

Hello

I was trying to set up a function() that allows easely to calculate regressions for severel dependent variables with the same independent variables.

My function looked like this but was turned down by an error (Im quiet new to R Studio). So here is my solution:

b
CO2
logTrop_Aerosol
lm(b ~ CO2  + logTrop_Aerosol  )

Trend <- function(x,CO2,logTrop_Aerosol) { lm x   CO2  + logTrop_Aerosol}

b is a vector containing 400 values of heat content
CO2 also contains 400 values as well as logTropAerosol

my idea would be that I simply can replace x (heat content) by other vectors containing heat content.

The error I got was the following:

Error: unexpected symbol in "Trend <- function(x,y,z) { lm x"

Thanks a lot for the help!

Best Matthias

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Thu Nov 12 18:11:33 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 12 Nov 2015 17:11:33 +0000
Subject: [R] Compute Regressions with R-Function
In-Reply-To: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
References: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
Message-ID: <5644C845.1000804@dewey.myzen.co.uk>

In-line

On 12/11/2015 16:27, Matthias Worni wrote:
> Hello
>
> I was trying to set up a function() that allows easely to calculate
> regressions for severel dependent variables with the same independent
> variables.
>
> My function looked like this but was turned down by an error (Im quiet new
> to R Studio). So here is my solution:
>
> b
> CO2
> logTrop_Aerosol
> lm(b ~ CO2  + logTrop_Aerosol  )
>
> Trend <- function(x,CO2,logTrop_Aerosol) { lm x   CO2  + logTrop_Aerosol}

Since you posted in HTML it is hard to be sure but I would have thought 
you have left out the parentheses and the ~ symbol.

>
> b is a vector containing 400 values of heat content
> CO2 also contains 400 values as well as logTropAerosol
>
> my idea would be that I simply can replace x (heat content) by other
> vectors containing heat content.
>
> The error I got was the following:
>
> Error: unexpected symbol in "Trend <- function(x,y,z) { lm x"
>
> Thanks a lot for the help!
>
> Best Matthias
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From 538280 at gmail.com  Thu Nov 12 18:12:53 2015
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 12 Nov 2015 10:12:53 -0700
Subject: [R] Plot with pauses?
In-Reply-To: <COL130-W287B31682F3C91D9C25051AD120@phx.gbl>
References: <COL130-W287B31682F3C91D9C25051AD120@phx.gbl>
Message-ID: <CAFEqCdwUP1TejRUwKcJ6JawHSLtX48qsq-QusVd0h7PiFiiQaQ@mail.gmail.com>

Here is one option if you don't want to write the explicit for loop
(there is still a loop):

library(TeachingDemos)
v<-0:60
z<-3/5+4i/5
t<-z^(v/9)
tmpfun <- function(npoints) {
  plot( Re(t)[seq_len(npoints)], Im(t)[seq_len(npoints)],
        xlab="Real", ylab="Imaginary", xlim=c(-1,1), ylim=c(-1,1),
        asp=1)
}
tkexamp(
  tmpfun,
  list(npoints=list('animate',from=0,to=length(t), resolution=1, delay=500))
)



On Wed, Nov 11, 2015 at 10:30 PM, Judson <judsonblake at msn.com> wrote:
> I'm trying to create a
> series of demos for students.
>
> It would be helpful
> if plotted data points
> could appear one by one
> with, say, half-second delays
> between points.
>
> For instance,
> code like this
>
> v<-0:60
> z<-3/5+4i/5
> t<-z^(v/9)
> plot(Re(t),Im(t))
>
> would be better if I
> could invoke some
> pausing between points
> so the student could see
> the progression of
> the process.  Many
> mathematical progressions
> might be more understandable
> if the viewer could see
> this happen over intervals
> of time.
>
> Naturally I'd like to
> avoid for loops if that's
> possible.
>
> I really don't know
> where to start my
> search.   Any suggestions?
>
> ..... judson blake
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jdnewmil at dcn.davis.CA.us  Thu Nov 12 18:37:01 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 12 Nov 2015 09:37:01 -0800
Subject: [R] Compute Regressions with R-Function
In-Reply-To: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
References: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
Message-ID: <A6F916B8-04EA-481A-88C7-48B2868DBA49@dcn.davis.CA.us>

Your email is severely damaged because you sent it using HTML format. Please adjust the settings in your email software to use only plain text when sending to this list so we can see what you see.

While you are at it you should read about making your examples reproducible [1]... it may seem like a pain but you are likely to get better assistance if you make the extra effort before pressing the send button.

(Also, RStudio is a fine way to use R, but many people here use the R interpreter just fine without it so ask all you like about R here but don't assume we are all looking at the same screen you are. If you find you need to refer to RStudio to ask your question then you may be going off-topic. Your current question seems on topic though.)

I don't see a problem with your approach such as I can guess where you are going with it, but your code is messed up and your error does not look like it goes with that code so I have no idea where your actual problem is.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 12, 2015 8:27:58 AM PST, Matthias Worni <wornimatthias at gmail.com> wrote:
>Hello
>
>I was trying to set up a function() that allows easely to calculate
>regressions for severel dependent variables with the same independent
>variables.
>
>My function looked like this but was turned down by an error (Im quiet
>new
>to R Studio). So here is my solution:
>
>b
>CO2
>logTrop_Aerosol
>lm(b ~ CO2  + logTrop_Aerosol  )
>
>Trend <- function(x,CO2,logTrop_Aerosol) { lm x   CO2  +
>logTrop_Aerosol}
>
>b is a vector containing 400 values of heat content
>CO2 also contains 400 values as well as logTropAerosol
>
>my idea would be that I simply can replace x (heat content) by other
>vectors containing heat content.
>
>The error I got was the following:
>
>Error: unexpected symbol in "Trend <- function(x,y,z) { lm x"
>
>Thanks a lot for the help!
>
>Best Matthias
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From andrewcd at gmail.com  Thu Nov 12 19:04:29 2015
From: andrewcd at gmail.com (ACD)
Date: Thu, 12 Nov 2015 13:04:29 -0500
Subject: [R] recursive partitioning in R
In-Reply-To: <c10f8b$1rdeld@ironport10.mayo.edu>
References: <c10f8b$1rdeld@ironport10.mayo.edu>
Message-ID: <5644D4AD.5020404@gmail.com>

Dear Terry,

Thanks for pointing me to your vignette.  I can't say that I fully 
understand it however.  I'd be grateful for your help with a couple of 
specific questions:

  * In my application, each potential split will be a function of the
    outcome (y), as well as two other variables (p1 and p2). These will
    need to be passed down the tree, as my data is the set of {y, p1,
    p2, X}.  How would p1 and p2 be passed to the three functions that
    you describe (init, eval, and split)?
  * What does the initialize function do exactly?  I see that it takes
    as arguments (y), along with offsets, weights, and "parms", and
    outputs y again, along with numresp, numy, and a string.  I guess
    I'd understand what this function was doing if I understood what
    contexts it was called in.  Why is it needed? What process needs
    "numresp" and "numy", and why does it need them?  And where is
    "sfun" getting its information from?  And what gets done with the
    string that gets outputted from it?
  * The evaluation function makes more sense to me at present.  It takes
    y, along with weights and parameters, and gives back the deviance,
    which is how different potential splits are evaluated.  The label is
    passed along to something (what is it passed to?) so that the mean
    of y in that partition can be known.
      o If it wanted to define a different evaluation function rss =
        f(y, p1,p2), using only data from within a particular node,
        would p1 and p2 be components of the "parms" object?  Is "parms"
        a list?
  * The splitting function makes the most sense of all to me -- the
    arguments are data (presumably only within-node data?), "parms"
    contains my p1 and p2 parameters (I still want to know if "parms" is
    a list or what), and outputs a goodness of fit measure, and a direction.
      o What  is the point of the direction?  Is not a split <x the same
        as a split >x?
      o If each splitting function evaluates goodness, what is the
        deviance in the eval function doing?

I appreciate your patience with my questions.  I'm sure that some of 
them will become painfully obvious once I'm able to share your perspective.

Best,
Andrew


On 11/12/2015 07:44 AM, Therneau, Terry M., Ph.D. wrote:
> Look at the rpart vignette "User written split functions".  The code 
> allows you to add your own splitting method to the code (in R, no C 
> required).  This has proven to be very useful for trying out new ideas.
>
> The second piece would be to do your own cross-validation.  That is, 
> turn off the built in cross-validation using the xval=0 option, then 
> explicitly do the cross-validation yourself.  Fit a new tree to some 
> chosen subset of data, using your split rule of course, and then use 
> predict() to get predicted values for the remaining observations. 
> Again, this is all in R, and you can explicitly control your in or out 
> of bag subsets.
> The xpred.rpart function may be useful to automate some of the steps.
>
> If you look up rpart on CRAN, you will see a link to the package 
> source.  If you were to read the C source code you will discover that 
> 95% is boring bookkeeping of what observations are in what part(s) of 
> the tree, sorting the data, tracking missing values, etc.  If you ever 
> do want to write your own code you are more than welcome to build off 
> this --- I wouldn't want to write that part again.
>
> Terry Therneau
>
> On 11/12/2015 05:00 AM, r-help-request at r-project.org wrote:
>> Dear List,
>>
>> I'd like to make a few modifications to the typical CART algorithm, and
>> I'd rather not code the whole thing from scratch.  Specifically I want
>> to use different in-sample and out-of-sample fit criteria in the split
>> choosing and cross-validation stages.
>>
>> I see however that the code for CART in both the rpart and the tree
>> packages is written in C.
>>
>> Two questions:
>>
>>    * Where is the C code?  It might be possible to get a C-fluent
>>      programmer to help me with this.
>>    * Is there any code for CART that is written entirely in R?
>>
>> Thanks,
>> Andrew


	[[alternative HTML version deleted]]


From alaasindi at gmail.com  Thu Nov 12 22:06:03 2015
From: alaasindi at gmail.com (Alaa Sindi)
Date: Thu, 12 Nov 2015 16:06:03 -0500
Subject: [R] mlogit.optim start values problem
Message-ID: <A0959BE3-4ACB-4C8D-88A3-4A057AA6F740@gmail.com>

Hello All,

I received the following message and I think it is regarding start values or the method.

semsem = mlogit.optim ( LL=LL*Prob[i,1] , start = c(1,1,1), method = c("bfgs"), iterlim = 2000, tol = 1E-05, ftol = 1e-08, steptol = 1e-10, print.level = 2)
+ 
+ }

Error in as.name(f[[2]]) : 
  'pairlist' object cannot be coerced to type ?symbol'

Do you have an idea how to fix this?

Thanks in advance


From dimitri.liakhovitski at gmail.com  Thu Nov 12 23:55:17 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 12 Nov 2015 17:55:17 -0500
Subject: [R] "haven" - read_spss: How to avoid extracting value labels
 instead of long labels?
In-Reply-To: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>
References: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>
Message-ID: <CAN2xGJZ4_tAEizGTzv3GydNPkuSbFSX8WWwdcGq0nM68d1SHVg@mail.gmail.com>

Looks like a little bug in 'haven':

When I actually look at the attributes of one variable that has no
long label in SPSS but has Value Labels, I am getting:
attr(spss1$WAVE, "label")
NULL

But when I sapply my function longlabels to my data frame and ask it
to print the long labels for each column, for the same column "WAVE" I
am getting - instead of NULL:
NULL
VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
                     1                      2

This is, of course, incorrect, because it grabs the next attribute
(which one? And replaces NULL with it).
Any suggestions?
Thanks!




On Thu, Nov 12, 2015 at 11:56 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Hello!
>
> I don't have an example file, but I think my question should be clear
> without it.
> I have an SPSS file. I read it in using 'haven':
>
> library(haven)
> spss1 <- read_spss("SPSS_Example.sav")
>
> I created a function that extracts the long labels (in SPSS - "Label"):
>
> fix_labels <- function(x, TextIfMissing) {
>       val <- attr(x, "label")
>       if (is.null(val)) TextIfMissing else val
> }
> longlabels <- sapply(spss1, fix_labels, TextIfMissing = "NO LABLE IN SPSS")
>
> This function is supposed to create a vector of long labels and
> usually it does, e.g.:
>
> str(longlabels)
>  Named chr [1:64] "Serial number" ...
>  - attr(*, "names")= chr [1:64] "Respondent_Serial" "weight" "r7_1" "r7_2" ...
>
> However, I just got an SPSS file with 92 columns and ran exactly the
> same function on it. Now, I am getting not a vector, but a list
>
> str(longlabels)
> List of 92
>  $ VEHRATED      : chr "VEHICLE RATED"
>  $ RESPID        : chr "RESPONDENT ID"
>  $ RESPID8       : chr "8 DIGIT RESPONDENT NUMBER"
>
> An observation about the structure of longlabels here: those columns
> that do NOT have a long lable in SPSS but DO have Values (value
> labels) - for them my function grabs their value labels, so that now
> my long label is recorded as a numeric vector with names, e.g.:
>
>  $ AWARE2        : Named num [1:2] 1 2
>   ..- attr(*, "names")= chr [1:2] "VERY/SOMEWHAT FAMILIAR" "NOT AT ALL FAMILIAR"
>
> Question: How could I avoid the extraction of the Value Labels for the
> columns that have no long labels?
>
> Thank you very much!
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Fri Nov 13 00:15:49 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 12 Nov 2015 18:15:49 -0500
Subject: [R] extraction of parameters for intercept from "lavaan" object
Message-ID: <CAN2xGJam5YvSVkmN4RNtiFRj-qVwdUkqGrAA-YKUUL=7-+aPEg@mail.gmail.com>

I am using 'lavaan' to estimate a single indicators model.
My model itself looks like this:

sem1model <- '
Imp ~ Ux
Mem ~ Ux + Imp
AE ~ Imp + Mem + Ux
UL ~ Ux + Imp + AE
'
sem1 <- sem(sem1model, data = mydata)

I am getting a decent fit and want to use this model.
My unstandardized coefficient for regressing Imp onto UX is 1.057,
taken from parameterEstimates(sem1, standardized = TRUE):

       lhs              op           rhs   est
1     Impression  ~            UX 1.057

Question: Can I know say: in order to predict Imp based on Ux it's Imp
= Ux * 1.057?
Or should there also be an intercept present in this formula?
I did not specify any intercepts anywhere in my model?

If there should be an intercept, then where can I find it in the object sem1?

Thanks a lot!

-- 
Dimitri Liakhovitski


From jrkrideau at inbox.com  Fri Nov 13 01:04:25 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 12 Nov 2015 16:04:25 -0800
Subject: [R] How to calculate variance on multiple numbers at once?
In-Reply-To: <CAMk+s2Q4-NMUB21+9CFdzFNppqvTVBR1hHskbK+Mp_maK-TzcQ@mail.gmail.com>
References: <b0d502a6db1.0000082djrkrideau@inbox.com>
	<camk+s2t08rrkzkvshrtu5kp0a2pubu6dgfponur+tw+hf3w7zq@mail.gmail.com>
	<a55a64c8f90.00000dcajrkrideau@inbox.com>
	<camk+s2svwmoxi76pg72_gb40ny1e-rqc5wzoh=njzxtxo=ka6w@mail.gmail.com>
Message-ID: <B7AEFC7F02F.000000B0jrkrideau@inbox.com>

I still don't understand what is happening, partly because the code has problems and partly because I don't understand why you are trying to take the variance of a single number.

The first problem, albeit a relatively minor one is that your data.frame has a variable that is not in the vectors you provide. 

my.data <- data.frame(well, clock, targ, flu, stringsAsFactors = FALSE)

There is no "well" in the vectors. Substituting "samp" results in a data.frame that corresponds to the rest of your code. This is one reason why we recommend using dput(). See ?dput for information.

I do not know what is happening with the loops : They run and output something but if you look at the code ?clock <= i? cannot be subsetting properly in either case.

Also if you look at ?sub? in the # variance with individual numbers, 

sub <- subset(my.data, samp == 1) 

it only has one instance for each value of clock and  var(X$flu) should be returning NA as one cannot take the variance of a single number.
So, as far as I can see you cannot trust any of the numbers in either set of calculations.

Your code 
# variance with individual numbers. 
sub <- subset(my.data, samp == 1)
for (i in 2:nrow(sub)) {
  X <- subset(sub, clock <= i)
  V <- var(X\$flu)
  cat("variance at clock ", i, " = ", V, "\n", sep="")
}

I tried :
library(plyr)
sub <- subset(my.data, samp == 1)
ddply(sub, .(clock), summarize, variance  = var(flu))
and got the expected 
clock variance
1     1       NA
2     2       NA
3     3       NA
4     4       NA
5     5       NA

Assuming I understand what the "# variance with multiple numbers" loop is doing (and I am by no means sure I do) I get

subtarg <- subset(my.data, targ == 'A')
 ddply(subtarg, .(clock), summarize, variance  = var(flu))
 clock     variance
1     1 2.533333e-05
2     2 2.233333e-05
3     3 2.033333e-05
4     4 4.333333e-06
5     5 3.000000e-06

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marongiu.luigi at gmail.com
> Sent: Thu, 12 Nov 2015 14:19:58 +0000
> To: jrkrideau at inbox.com, r-help at r-project.org
> Subject: Re: [R] How to calculate variance on multiple numbers at once?
> 
> Essentially the problem is related to this problem. I am measuring the
> fluorescence (flu) generated over time (clock) from 5 samples (samp)
> which are grouped by two targets (targ).
> I can calculate the variance of the fluorescence for each sample at a
> given time (in this example, for sample 1); but if I consider a target
> at the time there would be multiple readings at once to consider.
> would the variance formula still be OK to use.
> In this example:
>>>> 
> samp <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
> 5, 5, 5, 5, 5)
> clock <- rep(1:5,5)
> targ <- c(rep("A", 5), rep("B", 5), rep("A", 5), rep("A", 5), rep("B",
> 5))
> flu <- c(-0.012, -0.01, -0.008, -0.002, -0.001, -0.007, -0.008,
> -0.009, -0.009, -0.012, -0.002, -0.003, -0.003, 0.001, 0.002, -0.006,
> -0.001, 0.001, 0.002, 0.002, -0.002, -0.003, -0.003, -0.002, -0.001)
> my.data <- data.frame(well, clock, targ, flu, stringsAsFactors = FALSE)
> 
> # variance with individual numbers
> sub <- subset(my.data, samp == 1)
> plot(sub$flu ~ sub$clock)
> abline(lm(sub$flu ~ sub$clock))
> for (i in 2:nrow(sub)) {
>   X <- subset(sub, clock <= i)
>   V <- var(X$flu)
>   cat("variance at clock ", i, " = ", V, "\n", sep="")
> }
> # variance with multiple numbers
> sub <- subset(my.data, targ == 'A')
> plot(sub$flu ~ sub$clock)
> abline(lm(sub$flu ~ sub$clock))
> for (i in 2:max(sub$clock)) {
>   X <- subset(sub, clock <= i)
>   V <- var(X$flu)
>   cat("variance at clock ", i, " = ", V, "\n", sep="")
> }
> 
> the results for the individual numbers are:
> variance at clock 2 = 2e-06
> variance at clock 3 = 4e-06
> variance at clock 4 = 1.866667e-05
> variance at clock 5 = 2.38e-05
> 
> while the results for the multiple numbers are:
> variance at clock 2 = 2.026667e-05
> variance at clock 3 = 1.911111e-05
> variance at clock 4 = 2.026515e-05
> variance at clock 5 = 1.995238e-05
> 
> shall I accept these latter values?
> Thanks
> 
> On Thu, Nov 12, 2015 at 10:59 AM, John Kane <jrkrideau at inbox.com> wrote:
>> I still don't understand what you are doing. I think we need to see your
>> actual data and the code your are using.  If S.Ellison's post has not
>> shown up it is below my signature.
>> 
>> Have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and/or http://adv-r.had.co.nz/Reproducibility.html for suggestions on
>> how to pose a question here. In particular data should be supplied in
>> dput() format as it gives us a copy of exactly how the data is formatted
>> on your machine.
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> ## ===========================================
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>>> Marongiu
>>> if I have a sample set of the following numbers x1=0.09, x2=0.94,
>>> x3=0.48,
>>> x4=0.74, x5=0.04 I can calculate the variance easily.
>> Not without concatenating them into a vector, you can't. You need them
>> in a vector, as in
>> var( c(x1, x2, x3, x4, x5) )
>> 
>>> But if each x is actually a subset of multiple values, what would be
>>> the formula
>>> to calculate the variance? and it is possible to implement such
>>> mathematical
>>> function in R?
>> This is what R wants anyway, so the function you are looking for is
>> var()
>> 
>>> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26,
>>> 0.89, 0.58),
>>> x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and x5=(0.65, 0.16, 0.72)
>>> how can i
>>> calculate the variance for each x?
>> var(x1)
>> var(x2)
>> ....
>> 
>> or, if you want to be a bit more slick about it and do it in one line
>> 
>> lapply(list( x1, x2, x3, ...), var  )
>> 
>> (or sapply() if you want a vector result)
>> 
>> ## ===========================================
>> 
>> 
>>> -----Original Message-----
>>> From: marongiu.luigi at gmail.com
>>> Sent: Wed, 11 Nov 2015 23:20:26 +0000
>>> To: jrkrideau at inbox.com
>>> Subject: Re: [R] How to calculate variance on multiple numbers at once?
>>> 
>>> Thank you for the reply. For clarification, let's say that I can
>>> calculate the sum of variances of the individual x numbers in five
>>> consecutive steps (although of course there are better
>>> implementations) where each step the sum is incremented by (x -
>>> mean)^2.
>>> In the case I am handling, at each step i have to consider 3 values at
>>> once and I don't know how to relate them neither with the mathematical
>>> formula nor with the R implementation.
>>> Besides I haven't seen Ellison's answer...
>>> Best regards
>>> L
>>> 
>>> On Wed, Nov 11, 2015 at 1:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>>>> I really don't understand what you are looking for but if S. Ellison's
>>>> answer is not what you want what about this where your various x
>>>> vectors
>>>> are in a data frame
>>>> 
>>>> ibrary(reshape2)
>>>> library(plyr)
>>>> 
>>>> dat1  <-  structure(list(x1 = c(0.77, 0.22, 0.44), x2 = c(0.26, 0.89,
>>>> 0.58
>>>> ), x3 = c(0.2, 0.25, 0.91), x4 = c(0.06, 0.13, 0.26), x5 = c(0.65,
>>>> 0.16, 0.72)), .Names = c("x1", "x2", "x3", "x4", "x5"), row.names =
>>>> c(NA,
>>>> -3L), class = "data.frame")
>>>> 
>>>> m1  <-   melt(dat1)
>>>> 
>>>> ddply(m1, .(variable), summarize, variance = var(value))
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: marongiu.luigi at gmail.com
>>>>> Sent: Wed, 11 Nov 2015 11:26:25 +0000
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] How to calculate variance on multiple numbers at once?
>>>>> 
>>>>> Dear all,
>>>>> 
>>>>> if I have a sample set of the following numbers x1=0.09, x2=0.94,
>>>>> x3=0.48, x4=0.74, x5=0.04 I can calculate the variance easily.
>>>>> But if each x is actually a subset of multiple values, what would be
>>>>> the formula to calculate the variance? and it is possible to
>>>>> implement
>>>>> such mathematical function in R?
>>>>> 
>>>>> For instance if I have the following: x1=(0.77, 0.22, 0.44),
>>>>> x2=(0.26,
>>>>> 0.89, 0.58), x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and
>>>>> x5=(0.65, 0.16, 0.72) how can i calculate the variance for each x?
>>>>> 
>>>>> Thank you
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>>>> on
>>>> your desktop!
>>>> Check it out at http://www.inbox.com/marineaquarium
>>>> 
>>>> 
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> Check it out at http://www.inbox.com/marineaquarium
>> 
>>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From bgunter.4567 at gmail.com  Fri Nov 13 01:30:17 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 12 Nov 2015 16:30:17 -0800
Subject: [R] Compute Regressions with R-Function
In-Reply-To: <A6F916B8-04EA-481A-88C7-48B2868DBA49@dcn.davis.CA.us>
References: <CAM0cwgV-XyheSTOGKi7DT9eYGK=EutnSExyvO1iixWuOv5T-MA@mail.gmail.com>
	<A6F916B8-04EA-481A-88C7-48B2868DBA49@dcn.davis.CA.us>
Message-ID: <CAGxFJbTMgEZC0wUwUDgwJzjzBTJgSk63qpYWeeLy8aD=MPmc-Q@mail.gmail.com>

No function is necessary for multiple lhs's. lm() allows a matrix as
it's lhs and will fit a separate regression for each column of the
matrix. Please read ?lm carefully for details. For that matter, please
read the linked Help pages and/or spend some time with a tutorial
(there are many on the web) to learn proper linear models syntax.
There are subtleties involved (formulas have environments, use of ".",
use of I(), etc.) that require some effort to learn. It may help you
avoid further difficulties down the road.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Nov 12, 2015 at 9:37 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Your email is severely damaged because you sent it using HTML format. Please adjust the settings in your email software to use only plain text when sending to this list so we can see what you see.
>
> While you are at it you should read about making your examples reproducible [1]... it may seem like a pain but you are likely to get better assistance if you make the extra effort before pressing the send button.
>
> (Also, RStudio is a fine way to use R, but many people here use the R interpreter just fine without it so ask all you like about R here but don't assume we are all looking at the same screen you are. If you find you need to refer to RStudio to ask your question then you may be going off-topic. Your current question seems on topic though.)
>
> I don't see a problem with your approach such as I can guess where you are going with it, but your code is messed up and your error does not look like it goes with that code so I have no idea where your actual problem is.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On November 12, 2015 8:27:58 AM PST, Matthias Worni <wornimatthias at gmail.com> wrote:
>>Hello
>>
>>I was trying to set up a function() that allows easely to calculate
>>regressions for severel dependent variables with the same independent
>>variables.
>>
>>My function looked like this but was turned down by an error (Im quiet
>>new
>>to R Studio). So here is my solution:
>>
>>b
>>CO2
>>logTrop_Aerosol
>>lm(b ~ CO2  + logTrop_Aerosol  )
>>
>>Trend <- function(x,CO2,logTrop_Aerosol) { lm x   CO2  +
>>logTrop_Aerosol}
>>
>>b is a vector containing 400 values of heat content
>>CO2 also contains 400 values as well as logTropAerosol
>>
>>my idea would be that I simply can replace x (heat content) by other
>>vectors containing heat content.
>>
>>The error I got was the following:
>>
>>Error: unexpected symbol in "Trend <- function(x,y,z) { lm x"
>>
>>Thanks a lot for the help!
>>
>>Best Matthias
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Fri Nov 13 02:37:15 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 12 Nov 2015 20:37:15 -0500
Subject: [R] "haven" - read_spss: How to avoid extracting value labels
 instead of long labels?
In-Reply-To: <CAN2xGJZ4_tAEizGTzv3GydNPkuSbFSX8WWwdcGq0nM68d1SHVg@mail.gmail.com>
References: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>
	<CAN2xGJZ4_tAEizGTzv3GydNPkuSbFSX8WWwdcGq0nM68d1SHVg@mail.gmail.com>
Message-ID: <CAN2xGJZsZN7kd=x4GL7YPNnxth=6+2f9dsUf-jopQXfEWckByg@mail.gmail.com>

I have to rephrase my question again - it's clearly a small bug in
haven. Here is what it is about:

If I have a column in SPSS that has BOTH a long label and value
labels, then everything works fine - I access one with 'label' and
another with 'labels':

attr(spss1$MYVAR, "label")
[1] "LONG LABEL"
attr(spss1$MYVAR, "labels")
    DEFINITELY CONSIDER       PROBABLY CONSIDER   PROBABLY NOT
CONSIDER DEFINITELY NOT CONSIDER
                      1                       2
3                       4

However, if I have a column that has no long label and ONLY value
labels, then it's not working properly:

> attr(spss1$MYVAR, "label")
VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
                     1                      2
> attr(spss1$MYVAR, "labels")
VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
                     1                      2

And I actually need to be able to identify if label is empty.
Thank you for looking into it!

Dimitri


On Thu, Nov 12, 2015 at 5:55 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Looks like a little bug in 'haven':
>
> When I actually look at the attributes of one variable that has no
> long label in SPSS but has Value Labels, I am getting:
> attr(spss1$WAVE, "label")
> NULL
>
> But when I sapply my function longlabels to my data frame and ask it
> to print the long labels for each column, for the same column "WAVE" I
> am getting - instead of NULL:
> NULL
> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>                      1                      2
>
> This is, of course, incorrect, because it grabs the next attribute
> (which one? And replaces NULL with it).
> Any suggestions?
> Thanks!
>
>
>
>
> On Thu, Nov 12, 2015 at 11:56 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Hello!
>>
>> I don't have an example file, but I think my question should be clear
>> without it.
>> I have an SPSS file. I read it in using 'haven':
>>
>> library(haven)
>> spss1 <- read_spss("SPSS_Example.sav")
>>
>> I created a function that extracts the long labels (in SPSS - "Label"):
>>
>> fix_labels <- function(x, TextIfMissing) {
>>       val <- attr(x, "label")
>>       if (is.null(val)) TextIfMissing else val
>> }
>> longlabels <- sapply(spss1, fix_labels, TextIfMissing = "NO LABLE IN SPSS")
>>
>> This function is supposed to create a vector of long labels and
>> usually it does, e.g.:
>>
>> str(longlabels)
>>  Named chr [1:64] "Serial number" ...
>>  - attr(*, "names")= chr [1:64] "Respondent_Serial" "weight" "r7_1" "r7_2" ...
>>
>> However, I just got an SPSS file with 92 columns and ran exactly the
>> same function on it. Now, I am getting not a vector, but a list
>>
>> str(longlabels)
>> List of 92
>>  $ VEHRATED      : chr "VEHICLE RATED"
>>  $ RESPID        : chr "RESPONDENT ID"
>>  $ RESPID8       : chr "8 DIGIT RESPONDENT NUMBER"
>>
>> An observation about the structure of longlabels here: those columns
>> that do NOT have a long lable in SPSS but DO have Values (value
>> labels) - for them my function grabs their value labels, so that now
>> my long label is recorded as a numeric vector with names, e.g.:
>>
>>  $ AWARE2        : Named num [1:2] 1 2
>>   ..- attr(*, "names")= chr [1:2] "VERY/SOMEWHAT FAMILIAR" "NOT AT ALL FAMILIAR"
>>
>> Question: How could I avoid the extraction of the Value Labels for the
>> columns that have no long labels?
>>
>> Thank you very much!
>> --
>> Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From juliosergio at gmail.com  Fri Nov 13 03:41:03 2015
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Fri, 13 Nov 2015 02:41:03 +0000
Subject: [R] Problems using save to store NAMED R objects
Message-ID: <loom.20151113T032336-662@post.gmane.org>

I have to store (in a file) an R object that was created with is name as 
a string of characters, as follows:

   : nn <- "xxx"
   : assign(nn, 5)
   : xxx
   [1] 5

I don't want to store the object nn but the object xxx. I tried the 
following two expressions but none of them worked:

   : save(get(nn), file="f.RData")
   Error in save(get(nn), file = "f.RData") : object ?get(nn)? not found

   : save(eval(nn), file="f.RData")
   Error in save(eval(nn), file = "f.RData") : object ?eval(nn)? not 
found

I know that both save(xxx, ..), and save("xxx", ..) work, but the fact 
is that the string is going to be provided by an user:

   : nn <- readline("Your variable->")

and 
   : save(nn, file="f.RData")
stores the objet nn not xxx

Do you have any comments on this?

Thanks

  -Sergio.

From murdoch.duncan at gmail.com  Fri Nov 13 03:57:40 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 12 Nov 2015 18:57:40 -0800
Subject: [R] Problems using save to store NAMED R objects
In-Reply-To: <loom.20151113T032336-662@post.gmane.org>
References: <loom.20151113T032336-662@post.gmane.org>
Message-ID: <564551A4.7050508@gmail.com>

On 12/11/2015 6:41 PM, Julio Sergio Santana wrote:
> I have to store (in a file) an R object that was created with is name as
> a string of characters, as follows:
>
>     : nn <- "xxx"
>     : assign(nn, 5)
>     : xxx
>     [1] 5
>
> I don't want to store the object nn but the object xxx. I tried the
> following two expressions but none of them worked:
>
>     : save(get(nn), file="f.RData")
>     Error in save(get(nn), file = "f.RData") : object ?get(nn)? not found
>
>     : save(eval(nn), file="f.RData")
>     Error in save(eval(nn), file = "f.RData") : object ?eval(nn)? not
> found
>
> I know that both save(xxx, ..), and save("xxx", ..) work, but the fact
> is that the string is going to be provided by an user:
>
>     : nn <- readline("Your variable->")
>
> and
>     : save(nn, file="f.RData")
> stores the objet nn not xxx
>
> Do you have any comments on this?

I believe

do.call(save, list(as.name(nn), file = "f.RData"))

should do what you want.  There are probably other ways, maybe simpler 
ones.

If you're interested, the theory here is that do.call() constructs a 
call to the first argument, with arguments found by evaluating the 
second argument.

Duncan Murdoch


From juliosergio at gmail.com  Fri Nov 13 04:14:58 2015
From: juliosergio at gmail.com (Julio Sergio Santana)
Date: Thu, 12 Nov 2015 21:14:58 -0600
Subject: [R] Problems using save to store NAMED R objects
In-Reply-To: <564551A4.7050508@gmail.com>
References: <loom.20151113T032336-662@post.gmane.org>
	<564551A4.7050508@gmail.com>
Message-ID: <CAKa+SCUQj+kc-sNcT16sc4UZuNsE3FC259_vsdz9Zpdy7JgDZg@mail.gmail.com>

Thanks Duncan,

I just saw another, but similar, solution for this in
http://stackoverflow.com/questions/11084395/save-object-using-variable-with-object-name
,
and it is:

   : save(list=nn, file="f.RData")

Thanks again,

  -Sergio.

On Thu, Nov 12, 2015 at 8:57 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 12/11/2015 6:41 PM, Julio Sergio Santana wrote:
>
>> I have to store (in a file) an R object that was created with is name as
>> a string of characters, as follows:
>>
>>     : nn <- "xxx"
>>     : assign(nn, 5)
>>     : xxx
>>     [1] 5
>>
>> I don't want to store the object nn but the object xxx. I tried the
>> following two expressions but none of them worked:
>>
>>     : save(get(nn), file="f.RData")
>>     Error in save(get(nn), file = "f.RData") : object ?get(nn)? not found
>>
>>     : save(eval(nn), file="f.RData")
>>     Error in save(eval(nn), file = "f.RData") : object ?eval(nn)? not
>> found
>>
>> I know that both save(xxx, ..), and save("xxx", ..) work, but the fact
>> is that the string is going to be provided by an user:
>>
>>     : nn <- readline("Your variable->")
>>
>> and
>>     : save(nn, file="f.RData")
>> stores the objet nn not xxx
>>
>> Do you have any comments on this?
>>
>
> I believe
>
> do.call(save, list(as.name(nn), file = "f.RData"))
>
> should do what you want.  There are probably other ways, maybe simpler
> ones.
>
> If you're interested, the theory here is that do.call() constructs a call
> to the first argument, with arguments found by evaluating the second
> argument.
>
> Duncan Murdoch
>



-- 

[image: Julio Sergio Santana on about.me]

Julio Sergio Santana
about.me/juliosergio00
  <http://about.me/juliosergio00>

Julio Sergio Santana
Instituto Mexicano de Tecnolog?a del Agua
Tel       +52 777 3293600 x 826
Tel/Fax +52 777 3293683
-------------------------------------------

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Nov 13 05:09:11 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 13 Nov 2015 15:09:11 +1100
Subject: [R] mlogit.optim start values problem
In-Reply-To: <A0959BE3-4ACB-4C8D-88A3-4A057AA6F740@gmail.com>
References: <A0959BE3-4ACB-4C8D-88A3-4A057AA6F740@gmail.com>
Message-ID: <CA+8X3fWfKOhUnnTFucZwcvwEKjUGOMw50EhAC-NcDDdbwdg+7A@mail.gmail.com>

Hi Alaa,
>From the code you sent, I think that the error may be in one or more lines
preceding the call to mlogit.optim. The "+" prompt means that the R
interpreter thinks there is more to come, and when you added a right brace
("}"), it probably tried to interpret everything back to the last left
brace ("{"). Can you show us the preceding lines?

Jim


On Fri, Nov 13, 2015 at 8:06 AM, Alaa Sindi <alaasindi at gmail.com> wrote:

> Hello All,
>
> I received the following message and I think it is regarding start values
> or the method.
>
> semsem = mlogit.optim ( LL=LL*Prob[i,1] , start = c(1,1,1), method =
> c("bfgs"), iterlim = 2000, tol = 1E-05, ftol = 1e-08, steptol = 1e-10,
> print.level = 2)
> +
> + }
>
> Error in as.name(f[[2]]) :
>   'pairlist' object cannot be coerced to type ?symbol'
>
> Do you have an idea how to fix this?
>
> Thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Nov 13 08:36:48 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Nov 2015 07:36:48 +0000
Subject: [R] *.rpt data
In-Reply-To: <BBB169C177D06B4E8E650D24548404CEC0AF9827@PTABREXC12M2.sars.gov.za>
References: <BBB169C177D06B4E8E650D24548404CEC0AF9641@PTABREXC12M2.sars.gov.za>
	<CAM_vjuk-BGO+QiPtTWmkRfv48JQYXWrYwL=bS=rCHfQSqn8HmA@mail.gmail.com>
	<BBB169C177D06B4E8E650D24548404CEC0AF9763@PTABREXC12M2.sars.gov.za>
	<CAM_vjunRS-PEMN9rHrwZXSNJ1XhO6B2gX4w6VXdQ4bU0xfVwAQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000A7E@SRVEXCHMBX.precheza.cz>
	<BBB169C177D06B4E8E650D24548404CEC0AF9827@PTABREXC12M2.sars.gov.za>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000B95@SRVEXCHMBX.precheza.cz>

Hi

Please keep conversation on list, others may have better opinion than myself. The attachment is not welcomed when posting to R help list, you can post error message directly to your mail.

Anyway, you will hardly get any useful answer if you keep your cards hidden. You shall at least show some snippet of rpt file and its size.

Cheers
Petr


> -----Original Message-----
> From: Mangalani Peter Makananisa [mailto:pmakananisa at sars.gov.za]
> Sent: Thursday, November 12, 2015 3:58 PM
> To: PIKAL Petr
> Subject: RE: [R] *.rpt data
>
> I can see now it is working but R is now complaining about memory
> allocation, see the attached.
>
> Peter
>
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: 12 November 2015 03:53 PM
> To: Mangalani Peter Makananisa; r-help
> Subject: RE: [R] *.rpt data
>
> Hi
>
> If it is really "like" csv data you can import it by
>
> read.csv...
>
> or you can use any other read.* function.
>
> Did you try it? If yes, what was the result?
> If not, why not?
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> > Goslee
> > Sent: Thursday, November 12, 2015 2:41 PM
> > To: Mangalani Peter Makananisa; r-help
> > Subject: Re: [R] *.rpt data
> >
> > On Thursday, November 12, 2015, Mangalani Peter Makananisa <
> > pmakananisa at sars.gov.za> wrote:
> >
> > > .rpt is one of the data extension like .csv, .txt , ?..
> > >
> > > All extensions are 'data extensions' in some sense.
> >
> > Without knowing quite a bit more about YOUR rpt extension, it's
> > impossible to answer.
> >
> >
> > > *From:* Sarah Goslee [mailto:sarah.goslee at gmail.com
> > > <javascript:_e(%7B%7D,'cvml','sarah.goslee at gmail.com');>]
> > > *Sent:* 12 November 2015 03:17 PM
> > > *To:* Mangalani Peter Makananisa
> > > *Cc:* r-help at r-project.org
> > > <javascript:_e(%7B%7D,'cvml','r-help at r-project.org');>
> > > *Subject:* Re: [R] *.rpt data
> > >
> > >
> > >
> > > What is "rpt data"? What source produced it? Where did you get it?
> > > Is it associated with particular software? Is it ascii or binary?
> > >
> > > Sarah
> > >
> > > On Thursday, November 12, 2015, Mangalani Peter Makananisa <
> > > pmakananisa at sars.gov.za
> > > <javascript:_e(%7B%7D,'cvml','pmakananisa at sars.gov.za');>> wrote:
> > >
> > > Hi,
> > >
> > > Could you please assist, how do I load the rpt data into R without
> > > converting it first to csv?
> > >
> > > Kind regards
> > > Peter
> > >
> > > Please Note: This email and its contents are subject to our email
> > > legal notice which can be viewed at
> > > http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Sarah Goslee
> > > http://www.stringpage.com
> > > http://www.sarahgoslee.com
> > > http://www.functionaldiversity.org
> > >
> > > Please Note: This email and its contents are subject to our email
> > > legal notice which can be viewed at
> > > http://www.sars.gov.za/Pages/Email-disclaimer.aspx
> > >
> >
> >
> > --
> > Sarah Goslee
> > http://www.stringpage.com
> > http://www.sarahgoslee.com
> > http://www.functionaldiversity.org
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
>
> This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into
> a contract in any time, for any reason, and without stating any
> reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
>
> Please Note: This email and its contents are subject to our email legal
> notice which can be viewed at http://www.sars.gov.za/Pages/Email-
> disclaimer.aspx

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From christopher.clarkson15 at imperial.ac.uk  Fri Nov 13 00:06:34 2015
From: christopher.clarkson15 at imperial.ac.uk (Clarkson, Christopher)
Date: Thu, 12 Nov 2015 23:06:34 +0000
Subject: [R] student looking for help with assignment in R
Message-ID: <AM3PR06MB0773B6866FE4E33454C20CF7B9120@AM3PR06MB0773.eurprd06.prod.outlook.com>

Hello,

I am a student and I only have basic knowledge of R. I have been given the task of having to monitor cells' migration in 2 dimensions. I have been given 2 files one containing the the X-coordinates and the other contains the Y-coordinates of the cells. There are 50 cells and there movement both longitudinally and latitudinally has been documented 100 times- to determine their overall trajectories.

I have tried to get help on both Stackexchange Overflow and biostars.org but since it is not classic bioinformatics neither have yielded much success.

I was hoping someone could take a look at the R code I have tried thus far to see where I'm going wrong.

Attached are the files and the r-script that I have been trying to run.... any changes in strategy would be welcome especially if they are more practical and simpler than what I currently have.

Thanks.

If this is not the type of message that I should send to you can you recommend somewhere else that I can get help...

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dataContition01PosY.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151112/f04d297d/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dataCondition01PosX.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151112/f04d297d/attachment-0001.txt>

From petr.pikal at precheza.cz  Fri Nov 13 10:47:41 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 13 Nov 2015 09:47:41 +0000
Subject: [R] student looking for help with assignment in R
In-Reply-To: <AM3PR06MB0773B6866FE4E33454C20CF7B9120@AM3PR06MB0773.eurprd06.prod.outlook.com>
References: <AM3PR06MB0773B6866FE4E33454C20CF7B9120@AM3PR06MB0773.eurprd06.prod.outlook.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000C03@SRVEXCHMBX.precheza.cz>

Hi

What does it mean "to monitor". If you want to compute path length for each cell it seems to me that it is a simple problem of trigonometry

sqrt(a^2+b^2) = c

is a length of a segment between two points. a and b can be computed by differencing x and y coordinates.

If I read your data
tempx<-read.table("clipboard")
tempy<-read.table("clipboard")

I can make a plot
plot(tempx[,1], tempy[,1])
lines(tempx[,1], tempy[,1])

or

plot(tempx[,1], tempy[,1])
lines(tempx[1:3,1], tempy[1:3,1])

to see how one cell is moving

However it seems to me that your assignment is a homework and there is no-homework policy on this list, so it is enough from me for the time being. Sorry if it is not homework but anyway as a poor chemist I cannot help you further.

Besides, there was no r script attached.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Clarkson, Christopher
> Sent: Friday, November 13, 2015 12:07 AM
> To: r-help at R-project.org
> Subject: [R] student looking for help with assignment in R
>
> Hello,
>
> I am a student and I only have basic knowledge of R. I have been given
> the task of having to monitor cells' migration in 2 dimensions. I have
> been given 2 files one containing the the X-coordinates and the other
> contains the Y-coordinates of the cells. There are 50 cells and there
> movement both longitudinally and latitudinally has been documented 100
> times- to determine their overall trajectories.
>
> I have tried to get help on both Stackexchange Overflow and
> biostars.org but since it is not classic bioinformatics neither have
> yielded much success.
>
> I was hoping someone could take a look at the R code I have tried thus
> far to see where I'm going wrong.
>
> Attached are the files and the r-script that I have been trying to
> run.... any changes in strategy would be welcome especially if they are
> more practical and simpler than what I currently have.
>
> Thanks.
>
> If this is not the type of message that I should send to you can you
> recommend somewhere else that I can get help...


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Fri Nov 13 11:08:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 13 Nov 2015 21:08:04 +1100
Subject: [R] student looking for help with assignment in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000C03@SRVEXCHMBX.precheza.cz>
References: <AM3PR06MB0773B6866FE4E33454C20CF7B9120@AM3PR06MB0773.eurprd06.prod.outlook.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5000C03@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+8X3fWoB3p2ebZFTx+b6dbLKPA1cXQfeOv0wUmmxs+m=-O0_A@mail.gmail.com>

Hi Christopher,
If you want to plot the movements of cells, perhaps a look at the help page
for color.scale.lines (plotrix) will get you started.

Jim


On Fri, Nov 13, 2015 at 8:47 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> What does it mean "to monitor". If you want to compute path length for
> each cell it seems to me that it is a simple problem of trigonometry
>
> sqrt(a^2+b^2) = c
>
> is a length of a segment between two points. a and b can be computed by
> differencing x and y coordinates.
>
> If I read your data
> tempx<-read.table("clipboard")
> tempy<-read.table("clipboard")
>
> I can make a plot
> plot(tempx[,1], tempy[,1])
> lines(tempx[,1], tempy[,1])
>
> or
>
> plot(tempx[,1], tempy[,1])
> lines(tempx[1:3,1], tempy[1:3,1])
>
> to see how one cell is moving
>
> However it seems to me that your assignment is a homework and there is
> no-homework policy on this list, so it is enough from me for the time
> being. Sorry if it is not homework but anyway as a poor chemist I cannot
> help you further.
>
> Besides, there was no r script attached.
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Clarkson, Christopher
> > Sent: Friday, November 13, 2015 12:07 AM
> > To: r-help at R-project.org
> > Subject: [R] student looking for help with assignment in R
> >
> > Hello,
> >
> > I am a student and I only have basic knowledge of R. I have been given
> > the task of having to monitor cells' migration in 2 dimensions. I have
> > been given 2 files one containing the the X-coordinates and the other
> > contains the Y-coordinates of the cells. There are 50 cells and there
> > movement both longitudinally and latitudinally has been documented 100
> > times- to determine their overall trajectories.
> >
> > I have tried to get help on both Stackexchange Overflow and
> > biostars.org but since it is not classic bioinformatics neither have
> > yielded much success.
> >
> > I was hoping someone could take a look at the R code I have tried thus
> > far to see where I'm going wrong.
> >
> > Attached are the files and the r-script that I have been trying to
> > run.... any changes in strategy would be welcome especially if they are
> > more practical and simpler than what I currently have.
> >
> > Thanks.
> >
> > If this is not the type of message that I should send to you can you
> > recommend somewhere else that I can get help...
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Fri Nov 13 11:18:58 2015
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 13 Nov 2015 11:18:58 +0100
Subject: [R]  Release of R 3.2.3 scheduled for December 10
Message-ID: <46A477A2-1E2A-46ED-9BEE-CAF66B3F0345@cbs.dk>

We intend to have a patch release on December 10, nickname will be "Wooden Christmas-Tree". The detailed schedule will be made available via developer.r-project.org as usual (later today).

For the R Core Team,

Peter D.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From istazahn at gmail.com  Fri Nov 13 16:00:58 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 13 Nov 2015 10:00:58 -0500
Subject: [R] "haven" - read_spss: How to avoid extracting value labels
 instead of long labels?
In-Reply-To: <CAN2xGJZsZN7kd=x4GL7YPNnxth=6+2f9dsUf-jopQXfEWckByg@mail.gmail.com>
References: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>
	<CAN2xGJZ4_tAEizGTzv3GydNPkuSbFSX8WWwdcGq0nM68d1SHVg@mail.gmail.com>
	<CAN2xGJZsZN7kd=x4GL7YPNnxth=6+2f9dsUf-jopQXfEWckByg@mail.gmail.com>
Message-ID: <CA+vqiLE9U6gG0yRRPGWb4gLLRtVFtfU4Rko70FwNov1imZGeTQ@mail.gmail.com>

Why do you think this is a bug in have? To the contrary, I don't think
this has anything to do with haven at all. The problem seems to be
that attr does partial matching by default. Check it out:

> attr(x, "labels") <- c("foo", "bar", "baz")
> attr(x, "label")
[1] "foo" "bar" "baz"

and see ?attr for details.

The answer I think is

fix_labels <- function(x, TextIfMissing) {
      val <- attr(x, "label", exact = TRUE)
      if (is.null(val)) TextIfMissing else val
}

Finally, note that the development version of rio
(https://github.com/leeper/rio) has an (non-exported) function for
cleaning up meta data from haven imports. See
https://github.com/leeper/rio/blob/master/R/utils.R#L86

Best,
Ista

On Thu, Nov 12, 2015 at 8:37 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I have to rephrase my question again - it's clearly a small bug in
> haven. Here is what it is about:
>
> If I have a column in SPSS that has BOTH a long label and value
> labels, then everything works fine - I access one with 'label' and
> another with 'labels':
>
> attr(spss1$MYVAR, "label")
> [1] "LONG LABEL"
> attr(spss1$MYVAR, "labels")
>     DEFINITELY CONSIDER       PROBABLY CONSIDER   PROBABLY NOT
> CONSIDER DEFINITELY NOT CONSIDER
>                       1                       2
> 3                       4
>
> However, if I have a column that has no long label and ONLY value
> labels, then it's not working properly:
>
>> attr(spss1$MYVAR, "label")
> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>                      1                      2
>> attr(spss1$MYVAR, "labels")
> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>                      1                      2
>
> And I actually need to be able to identify if label is empty.
> Thank you for looking into it!
>
> Dimitri
>
>
> On Thu, Nov 12, 2015 at 5:55 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Looks like a little bug in 'haven':
>>
>> When I actually look at the attributes of one variable that has no
>> long label in SPSS but has Value Labels, I am getting:
>> attr(spss1$WAVE, "label")
>> NULL
>>
>> But when I sapply my function longlabels to my data frame and ask it
>> to print the long labels for each column, for the same column "WAVE" I
>> am getting - instead of NULL:
>> NULL
>> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>>                      1                      2
>>
>> This is, of course, incorrect, because it grabs the next attribute
>> (which one? And replaces NULL with it).
>> Any suggestions?
>> Thanks!
>>
>>
>>
>>
>> On Thu, Nov 12, 2015 at 11:56 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>> Hello!
>>>
>>> I don't have an example file, but I think my question should be clear
>>> without it.
>>> I have an SPSS file. I read it in using 'haven':
>>>
>>> library(haven)
>>> spss1 <- read_spss("SPSS_Example.sav")
>>>
>>> I created a function that extracts the long labels (in SPSS - "Label"):
>>>
>>> fix_labels <- function(x, TextIfMissing) {
>>>       val <- attr(x, "label")
>>>       if (is.null(val)) TextIfMissing else val
>>> }
>>> longlabels <- sapply(spss1, fix_labels, TextIfMissing = "NO LABLE IN SPSS")
>>>
>>> This function is supposed to create a vector of long labels and
>>> usually it does, e.g.:
>>>
>>> str(longlabels)
>>>  Named chr [1:64] "Serial number" ...
>>>  - attr(*, "names")= chr [1:64] "Respondent_Serial" "weight" "r7_1" "r7_2" ...
>>>
>>> However, I just got an SPSS file with 92 columns and ran exactly the
>>> same function on it. Now, I am getting not a vector, but a list
>>>
>>> str(longlabels)
>>> List of 92
>>>  $ VEHRATED      : chr "VEHICLE RATED"
>>>  $ RESPID        : chr "RESPONDENT ID"
>>>  $ RESPID8       : chr "8 DIGIT RESPONDENT NUMBER"
>>>
>>> An observation about the structure of longlabels here: those columns
>>> that do NOT have a long lable in SPSS but DO have Values (value
>>> labels) - for them my function grabs their value labels, so that now
>>> my long label is recorded as a numeric vector with names, e.g.:
>>>
>>>  $ AWARE2        : Named num [1:2] 1 2
>>>   ..- attr(*, "names")= chr [1:2] "VERY/SOMEWHAT FAMILIAR" "NOT AT ALL FAMILIAR"
>>>
>>> Question: How could I avoid the extraction of the Value Labels for the
>>> columns that have no long labels?
>>>
>>> Thank you very much!
>>> --
>>> Dimitri Liakhovitski
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Fri Nov 13 16:01:19 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 13 Nov 2015 07:01:19 -0800
Subject: [R] How to calculate variance on multiple numbers at once?
In-Reply-To: <CAMk+s2Q4-NMUB21+9CFdzFNppqvTVBR1hHskbK+Mp_maK-TzcQ@mail.gmail.com>
References: <b0d502a6db1.0000082djrkrideau@inbox.com>
	<camk+s2t08rrkzkvshrtu5kp0a2pubu6dgfponur+tw+hf3w7zq@mail.gmail.com>
	<a55a64c8f90.00000dcajrkrideau@inbox.com>
	<camk+s2svwmoxi76pg72_gb40ny1e-rqc5wzoh=njzxtxo=ka6w@mail.gmail.com>
Message-ID: <BF83B765744.00000686jrkrideau@inbox.com>

As a follow-up to my earlier post do you want to do something like the code below  does?

By the way, loops are used in R but usually when nothing else will work.  Things like ?argregate in R base or ?ddply in plyr will do the same thing with a lot less coding and usually code that is easier to read. 
##=============Data in dput() format=================
my.data  <-  structure(list(samp = c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 
3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5), clock = c(1L, 2L, 3L, 4L, 
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 
1L, 2L, 3L, 4L, 5L), targ = c("A", "A", "A", "A", "A", "B", "B", 
"B", "B", "B", "A", "A", "A", "A", "A", "A", "A", "A", "A", "A", 
"B", "B", "B", "B", "B"), flu = c(-0.012, -0.01, -0.008, -0.002, 
-0.001, -0.007, -0.008, -0.009, -0.009, -0.012, -0.002, -0.003, 
-0.003, 0.001, 0.002, -0.006, -0.001, 0.001, 0.002, 0.002, -0.002, 
-0.003, -0.003, -0.002, -0.001)), .Names = c("samp", "clock", 
"targ", "flu"), row.names = c(NA, -25L), class = "data.frame")

## variances of 'clock
library(plyr)
dd1 <-  ddply(my.data, .(clock), summarize, variance = var(flu))

## variance of "clock within targ
dd2 <-  ddply(my.data, .(targ, clock), summarize, variance = var(flu))
 arrange(dd2, targ, clock)


John Kane
Kingston ON Canada


> -----Original Message-----
> From: marongiu.luigi at gmail.com
> Sent: Thu, 12 Nov 2015 14:19:58 +0000
> To: jrkrideau at inbox.com, r-help at r-project.org
> Subject: Re: [R] How to calculate variance on multiple numbers at once?
> 
> Essentially the problem is related to this problem. I am measuring the
> fluorescence (flu) generated over time (clock) from 5 samples (samp)
> which are grouped by two targets (targ).
> I can calculate the variance of the fluorescence for each sample at a
> given time (in this example, for sample 1); but if I consider a target
> at the time there would be multiple readings at once to consider.
> would the variance formula still be OK to use.
> In this example:
>>>> 
> samp <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
> 5, 5, 5, 5, 5)
> clock <- rep(1:5,5)
> targ <- c(rep("A", 5), rep("B", 5), rep("A", 5), rep("A", 5), rep("B",
> 5))
> flu <- c(-0.012, -0.01, -0.008, -0.002, -0.001, -0.007, -0.008,
> -0.009, -0.009, -0.012, -0.002, -0.003, -0.003, 0.001, 0.002, -0.006,
> -0.001, 0.001, 0.002, 0.002, -0.002, -0.003, -0.003, -0.002, -0.001)
> my.data <- data.frame(well, clock, targ, flu, stringsAsFactors = FALSE)
> 
> # variance with individual numbers
> sub <- subset(my.data, samp == 1)
> plot(sub$flu ~ sub$clock)
> abline(lm(sub$flu ~ sub$clock))
> for (i in 2:nrow(sub)) {
>   X <- subset(sub, clock <= i)
>   V <- var(X$flu)
>   cat("variance at clock ", i, " = ", V, "\n", sep="")
> }
> # variance with multiple numbers
> sub <- subset(my.data, targ == 'A')
> plot(sub$flu ~ sub$clock)
> abline(lm(sub$flu ~ sub$clock))
> for (i in 2:max(sub$clock)) {
>   X <- subset(sub, clock <= i)
>   V <- var(X$flu)
>   cat("variance at clock ", i, " = ", V, "\n", sep="")
> }
> 
> the results for the individual numbers are:
> variance at clock 2 = 2e-06
> variance at clock 3 = 4e-06
> variance at clock 4 = 1.866667e-05
> variance at clock 5 = 2.38e-05
> 
> while the results for the multiple numbers are:
> variance at clock 2 = 2.026667e-05
> variance at clock 3 = 1.911111e-05
> variance at clock 4 = 2.026515e-05
> variance at clock 5 = 1.995238e-05
> 
> shall I accept these latter values?
> Thanks
> 
> On Thu, Nov 12, 2015 at 10:59 AM, John Kane <jrkrideau at inbox.com> wrote:
>> I still don't understand what you are doing. I think we need to see your
>> actual data and the code your are using.  If S.Ellison's post has not
>> shown up it is below my signature.
>> 
>> Have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>> and/or http://adv-r.had.co.nz/Reproducibility.html for suggestions on
>> how to pose a question here. In particular data should be supplied in
>> dput() format as it gives us a copy of exactly how the data is formatted
>> on your machine.
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> ## ===========================================
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
>>> Marongiu
>>> if I have a sample set of the following numbers x1=0.09, x2=0.94,
>>> x3=0.48,
>>> x4=0.74, x5=0.04 I can calculate the variance easily.
>> Not without concatenating them into a vector, you can't. You need them
>> in a vector, as in
>> var( c(x1, x2, x3, x4, x5) )
>> 
>>> But if each x is actually a subset of multiple values, what would be
>>> the formula
>>> to calculate the variance? and it is possible to implement such
>>> mathematical
>>> function in R?
>> This is what R wants anyway, so the function you are looking for is
>> var()
>> 
>>> For instance if I have the following: x1=(0.77, 0.22, 0.44), x2=(0.26,
>>> 0.89, 0.58),
>>> x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and x5=(0.65, 0.16, 0.72)
>>> how can i
>>> calculate the variance for each x?
>> var(x1)
>> var(x2)
>> ....
>> 
>> or, if you want to be a bit more slick about it and do it in one line
>> 
>> lapply(list( x1, x2, x3, ...), var  )
>> 
>> (or sapply() if you want a vector result)
>> 
>> ## ===========================================
>> 
>> 
>>> -----Original Message-----
>>> From: marongiu.luigi at gmail.com
>>> Sent: Wed, 11 Nov 2015 23:20:26 +0000
>>> To: jrkrideau at inbox.com
>>> Subject: Re: [R] How to calculate variance on multiple numbers at once?
>>> 
>>> Thank you for the reply. For clarification, let's say that I can
>>> calculate the sum of variances of the individual x numbers in five
>>> consecutive steps (although of course there are better
>>> implementations) where each step the sum is incremented by (x -
>>> mean)^2.
>>> In the case I am handling, at each step i have to consider 3 values at
>>> once and I don't know how to relate them neither with the mathematical
>>> formula nor with the R implementation.
>>> Besides I haven't seen Ellison's answer...
>>> Best regards
>>> L
>>> 
>>> On Wed, Nov 11, 2015 at 1:04 PM, John Kane <jrkrideau at inbox.com> wrote:
>>>> I really don't understand what you are looking for but if S. Ellison's
>>>> answer is not what you want what about this where your various x
>>>> vectors
>>>> are in a data frame
>>>> 
>>>> ibrary(reshape2)
>>>> library(plyr)
>>>> 
>>>> dat1  <-  structure(list(x1 = c(0.77, 0.22, 0.44), x2 = c(0.26, 0.89,
>>>> 0.58
>>>> ), x3 = c(0.2, 0.25, 0.91), x4 = c(0.06, 0.13, 0.26), x5 = c(0.65,
>>>> 0.16, 0.72)), .Names = c("x1", "x2", "x3", "x4", "x5"), row.names =
>>>> c(NA,
>>>> -3L), class = "data.frame")
>>>> 
>>>> m1  <-   melt(dat1)
>>>> 
>>>> ddply(m1, .(variable), summarize, variance = var(value))
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: marongiu.luigi at gmail.com
>>>>> Sent: Wed, 11 Nov 2015 11:26:25 +0000
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] How to calculate variance on multiple numbers at once?
>>>>> 
>>>>> Dear all,
>>>>> 
>>>>> if I have a sample set of the following numbers x1=0.09, x2=0.94,
>>>>> x3=0.48, x4=0.74, x5=0.04 I can calculate the variance easily.
>>>>> But if each x is actually a subset of multiple values, what would be
>>>>> the formula to calculate the variance? and it is possible to
>>>>> implement
>>>>> such mathematical function in R?
>>>>> 
>>>>> For instance if I have the following: x1=(0.77, 0.22, 0.44),
>>>>> x2=(0.26,
>>>>> 0.89, 0.58), x3=(0.20, 0.25, 0.91), x4=(0.06, 0.13, 0.26) and
>>>>> x5=(0.65, 0.16, 0.72) how can i calculate the variance for each x?
>>>>> 
>>>>> Thank you
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>>>> on
>>>> your desktop!
>>>> Check it out at http://www.inbox.com/marineaquarium
>>>> 
>>>> 
>> 
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
>> your desktop!
>> Check it out at http://www.inbox.com/marineaquarium
>> 
>>

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From isra4884 at gmail.com  Fri Nov 13 16:17:48 2015
From: isra4884 at gmail.com (Israel Ortiz)
Date: Fri, 13 Nov 2015 09:17:48 -0600
Subject: [R] Error survreg: Density function returned an an invalid
	matrix
In-Reply-To: <c10f8b$1pjtrd@ironport10.mayo.edu>
References: <mailman.5.1446548402.29982.r-help@r-project.org>
	<c10f8b$1pjtrd@ironport10.mayo.edu>
Message-ID: <CAMESY2hrtyBsjnxh-jJ+=ZGkWVEUvodxvcZ6v5qEoSPNDyJb0g@mail.gmail.com>

Thanks Terry but the error persists. See:

> library(foreign)> library(survival)> library(VGAM) > mypareto <- list(name='Pareto',+                  init= function(x, weights,parms){+                    alpha <- length(x)/(sum(log(x)))#this is a MLE for alpha+                    c(media <-(alpha*1/(alpha-1)),varianza <- ((1/alpha)^2)*(alpha/(alpha-2)))},+                  density= function(x,weights) {+                    alpha <- length(x)/(sum(log(x)))+                    cdf1 <- function(x, alpha) ifelse(x > 1 , 1 - (1/x)**alpha, 0 )+                    cdf2 <- function(x, alpha) ifelse(x > 1, (1/x)**alpha ,0)+                    distribution <- function(x, alpha) ifelse(x > 1 , alpha/(x**(alpha+1)), 0)+                    firstdev <- function(x, alpha) ifelse(x > 1, -(alpha+x)/x, 0)+                    seconddev <- function(x, alpha) ifelse(x > 1, (alpha+1)*(alpha+2)/x^2,0)+                    cbind(cdf1(x,alpha),cdf2(x, alpha), distribution(x,alpha),firstdev(x,alpha),seconddev(x,alpha))},+                  deviance=function(x) {stop('deviance residuals not defined')},+                  quantile= function(p, alpha) ifelse(p < 0 | p > 1, NaN, 1*(1-p)**(-1/alpha)))> > survregDtest(mypareto, TRUE)[1] TRUE> set.seed(1)> a <- rpareto(100, 1, 1) > b <- rnorm(100,5,1)> c <- rep(1,100)> base <- cbind.data.frame(a,b,c)> mod1<-survreg(Surv(a, c) ~ b, base, dist = mypareto)Error in survreg.fit(X, Y, weights, offset, init = init, controlvals = control,  :
  Density function returned an invalid matrix




2015-11-04 7:52 GMT-06:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu>:

> Hi, I want to perform a survival analysis using survreg procedure from
>> survival library in R for a pareto distribution for a time variable, so I
>> set the new distribution using the following sintax:
>>
>>      library(foreign)
>>      library(survival)
>>      library(VGAM)
>>
>>      mypareto <- list(name='Pareto',
>>                   init= function(x, weights,parms){
>>
> etc.
>
> The survreg routine fits location-scale distributions such that (t(y) -
> Xb)/s ~ F, where t is an optional transformation, F is some fixed
> distribution and X is a matrix of covariates.  For any distribution the
> questions to ask before trying to add the distribution to survreg are
>   - can it be written in a location-scale form?
>   - if so, how do the parameters of the distribution map to the location
> (Xb) and scale (s).
>
> In fitting data we normally have per-subject location (X b) but an
> intercept-only model is of course possible.
>
> If y is Weibull then log(y) fits into the framework, which is how survreg
> fits it.  The transformation of parameters location and scale parameters
> for log(y) back to the usual Weibull parameterization for y often trips
> people up (see comments in the Examples section of ?survreg).
>
> The log of a Pareto can be written in this form (I think?).  The two
> parameters are the scale a and lower limit b, with survival function of
> S(x)= (b/x)^a, for x >= b.  If y = log(x) the survival function for y is
> S(y) = (b/exp(y))^a = exp[-(y - log(b))/(1/a)], which has location log(b)
> and scale 1/a. But even if I am correct the discontinuity at b will cause
> the underlying Newton-Raphson method to fail.
>
>  Terry Therneau
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Fri Nov 13 18:42:12 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 13 Nov 2015 12:42:12 -0500
Subject: [R] "haven" - read_spss: How to avoid extracting value labels
 instead of long labels?
In-Reply-To: <CA+vqiLE9U6gG0yRRPGWb4gLLRtVFtfU4Rko70FwNov1imZGeTQ@mail.gmail.com>
References: <CAN2xGJZu6S_Q47QtgCmQDup3ZkF8cT8FgZqLBd_1BTWYfZZYzw@mail.gmail.com>
	<CAN2xGJZ4_tAEizGTzv3GydNPkuSbFSX8WWwdcGq0nM68d1SHVg@mail.gmail.com>
	<CAN2xGJZsZN7kd=x4GL7YPNnxth=6+2f9dsUf-jopQXfEWckByg@mail.gmail.com>
	<CA+vqiLE9U6gG0yRRPGWb4gLLRtVFtfU4Rko70FwNov1imZGeTQ@mail.gmail.com>
Message-ID: <CAN2xGJa_papi2YucVAo22ZV+di_=f02GKdoThm=KQ2ho_O5Amg@mail.gmail.com>

You are absolutely right, Ista - it's not haven's fault, my bad.
Of course, it's the attr function and exact = TRUE.
Thank you so much!
Dimitri

On Fri, Nov 13, 2015 at 10:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Why do you think this is a bug in have? To the contrary, I don't think
> this has anything to do with haven at all. The problem seems to be
> that attr does partial matching by default. Check it out:
>
>> attr(x, "labels") <- c("foo", "bar", "baz")
>> attr(x, "label")
> [1] "foo" "bar" "baz"
>
> and see ?attr for details.
>
> The answer I think is
>
> fix_labels <- function(x, TextIfMissing) {
>       val <- attr(x, "label", exact = TRUE)
>       if (is.null(val)) TextIfMissing else val
> }
>
> Finally, note that the development version of rio
> (https://github.com/leeper/rio) has an (non-exported) function for
> cleaning up meta data from haven imports. See
> https://github.com/leeper/rio/blob/master/R/utils.R#L86
>
> Best,
> Ista
>
> On Thu, Nov 12, 2015 at 8:37 PM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> I have to rephrase my question again - it's clearly a small bug in
>> haven. Here is what it is about:
>>
>> If I have a column in SPSS that has BOTH a long label and value
>> labels, then everything works fine - I access one with 'label' and
>> another with 'labels':
>>
>> attr(spss1$MYVAR, "label")
>> [1] "LONG LABEL"
>> attr(spss1$MYVAR, "labels")
>>     DEFINITELY CONSIDER       PROBABLY CONSIDER   PROBABLY NOT
>> CONSIDER DEFINITELY NOT CONSIDER
>>                       1                       2
>> 3                       4
>>
>> However, if I have a column that has no long label and ONLY value
>> labels, then it's not working properly:
>>
>>> attr(spss1$MYVAR, "label")
>> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>>                      1                      2
>>> attr(spss1$MYVAR, "labels")
>> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>>                      1                      2
>>
>> And I actually need to be able to identify if label is empty.
>> Thank you for looking into it!
>>
>> Dimitri
>>
>>
>> On Thu, Nov 12, 2015 at 5:55 PM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>> Looks like a little bug in 'haven':
>>>
>>> When I actually look at the attributes of one variable that has no
>>> long label in SPSS but has Value Labels, I am getting:
>>> attr(spss1$WAVE, "label")
>>> NULL
>>>
>>> But when I sapply my function longlabels to my data frame and ask it
>>> to print the long labels for each column, for the same column "WAVE" I
>>> am getting - instead of NULL:
>>> NULL
>>> VERY/SOMEWHAT FAMILIAR    NOT AT ALL FAMILIAR
>>>                      1                      2
>>>
>>> This is, of course, incorrect, because it grabs the next attribute
>>> (which one? And replaces NULL with it).
>>> Any suggestions?
>>> Thanks!
>>>
>>>
>>>
>>>
>>> On Thu, Nov 12, 2015 at 11:56 AM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>> Hello!
>>>>
>>>> I don't have an example file, but I think my question should be clear
>>>> without it.
>>>> I have an SPSS file. I read it in using 'haven':
>>>>
>>>> library(haven)
>>>> spss1 <- read_spss("SPSS_Example.sav")
>>>>
>>>> I created a function that extracts the long labels (in SPSS - "Label"):
>>>>
>>>> fix_labels <- function(x, TextIfMissing) {
>>>>       val <- attr(x, "label")
>>>>       if (is.null(val)) TextIfMissing else val
>>>> }
>>>> longlabels <- sapply(spss1, fix_labels, TextIfMissing = "NO LABLE IN SPSS")
>>>>
>>>> This function is supposed to create a vector of long labels and
>>>> usually it does, e.g.:
>>>>
>>>> str(longlabels)
>>>>  Named chr [1:64] "Serial number" ...
>>>>  - attr(*, "names")= chr [1:64] "Respondent_Serial" "weight" "r7_1" "r7_2" ...
>>>>
>>>> However, I just got an SPSS file with 92 columns and ran exactly the
>>>> same function on it. Now, I am getting not a vector, but a list
>>>>
>>>> str(longlabels)
>>>> List of 92
>>>>  $ VEHRATED      : chr "VEHICLE RATED"
>>>>  $ RESPID        : chr "RESPONDENT ID"
>>>>  $ RESPID8       : chr "8 DIGIT RESPONDENT NUMBER"
>>>>
>>>> An observation about the structure of longlabels here: those columns
>>>> that do NOT have a long lable in SPSS but DO have Values (value
>>>> labels) - for them my function grabs their value labels, so that now
>>>> my long label is recorded as a numeric vector with names, e.g.:
>>>>
>>>>  $ AWARE2        : Named num [1:2] 1 2
>>>>   ..- attr(*, "names")= chr [1:2] "VERY/SOMEWHAT FAMILIAR" "NOT AT ALL FAMILIAR"
>>>>
>>>> Question: How could I avoid the extraction of the Value Labels for the
>>>> columns that have no long labels?
>>>>
>>>> Thank you very much!
>>>> --
>>>> Dimitri Liakhovitski
>>>
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From albmont at centroin.com.br  Fri Nov 13 18:53:29 2015
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Fri, 13 Nov 2015 12:53:29 -0500
Subject: [R] Environment question
In-Reply-To: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
References: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
Message-ID: <2066696213.56186849.1447437209163.JavaMail.zimbra@centroin.com.br>

I have another environment question.

I understand why this works as expected:

f.factory <- function()
{
  y <- 2
  fname <- paste("plus", y, sep = ".")
  f <- function(x) x + y
  assign(fname, f, envir = globalenv())
}

f.factory()
plus.2(2) # 4

and I also understand why this does NOT work:

f.factory <- function()
{
  for (y in 2:3) {
    fname <- paste("plus", y, sep = ".")
    f <- function(x) x + y
    assign(fname, f, envir = globalenv())
  }
}

f.factory()
plus.2(2) # 5
  
(the reason is that both plus.2 and plus.3 have the
same environment as f.factory when f.factory terminates,
which assign 2 to variable y in the first case and 3 in
the second case)

However, I don't know an elegant way to adapt f.factory
so that it works as expected. Any suggestions?

Alberto Monteiro


From wdunlap at tibco.com  Fri Nov 13 19:53:11 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 13 Nov 2015 10:53:11 -0800
Subject: [R] Environment question
In-Reply-To: <2066696213.56186849.1447437209163.JavaMail.zimbra@centroin.com.br>
References: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
	<2066696213.56186849.1447437209163.JavaMail.zimbra@centroin.com.br>
Message-ID: <CAF8bMcZHRQbtviiqzZ8mvPFHnKSKPw4SJD-vePod8F=Rd77JiQ@mail.gmail.com>

Make a new environment for each function and populate it with
the variables that your functions require.  local() is a convenient
way to do this:

f.factory3 <- function(destinationEnvir = globalenv())
{
  for (y in 2:3) {
    fname <- paste("plus", y, sep = ".")
    f <- local(function(x) x + y, envir=list2env(list(y=y),
parent=destinationEnvir))
    assign(fname, f, envir = destinationEnvir)
  }
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Nov 13, 2015 at 9:53 AM, ALBERTO VIEIRA FERREIRA MONTEIRO
<albmont at centroin.com.br> wrote:
> I have another environment question.
>
> I understand why this works as expected:
>
> f.factory <- function()
> {
>   y <- 2
>   fname <- paste("plus", y, sep = ".")
>   f <- function(x) x + y
>   assign(fname, f, envir = globalenv())
> }
>
> f.factory()
> plus.2(2) # 4
>
> and I also understand why this does NOT work:
>
> f.factory <- function()
> {
>   for (y in 2:3) {
>     fname <- paste("plus", y, sep = ".")
>     f <- function(x) x + y
>     assign(fname, f, envir = globalenv())
>   }
> }
>
> f.factory()
> plus.2(2) # 5
>
> (the reason is that both plus.2 and plus.3 have the
> same environment as f.factory when f.factory terminates,
> which assign 2 to variable y in the first case and 3 in
> the second case)
>
> However, I don't know an elegant way to adapt f.factory
> so that it works as expected. Any suggestions?
>
> Alberto Monteiro
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alexierino at hotmail.com  Fri Nov 13 10:34:48 2015
From: alexierino at hotmail.com (Alex I)
Date: Fri, 13 Nov 2015 09:34:48 +0000
Subject: [R] =?utf-8?q?Options_for_running_Hausman-Taylor_with_robust_stan?=
	=?utf-8?q?dard_errors?=
Message-ID: <BLU406-EAS114A908921433206A796741C9110@phx.gbl>

This has been eating at me for a very long time. From everything I understand, the plm package does not yet allow robust standard errors to be calculated for the Hausman-Taylor using the coeftest command you would for other estimators (i.e. pooled, within, random). This is of course the error that plm shoots out when you try to run it in the package, which you can see below:


Error in vcovHC.plm(ht, type = "HC0") : 
  Model has to be either random, within or pooling model


It just seems like such a strange oversight given the popularity of HTM in econometrics and the almost granted necessity of robust standard errors.


What are my options, perhaps using other simple packages in R, to calculate a Hausman-Taylor using robust standard errors for my panel data regression? I?m not really sure if sharing data or much code will help in this case.


Alex
	[[alternative HTML version deleted]]


From ilgaz.somer at gmail.com  Fri Nov 13 14:11:35 2015
From: ilgaz.somer at gmail.com (Ilgaz S)
Date: Fri, 13 Nov 2015 15:11:35 +0200
Subject: [R] Suprising R behaviour
Message-ID: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>

Hello everybody, I am new to R and I discovered something that suprise me
and I have a question about it.
Today I wanted to return a bit array which represents this:

if( arbitrary point above the line)
     return TRUE
else
     return FALSE

First I tought I would use for loop and access every element of the data.
Then I tend to use lapply function.

At the end, I accidently done that without using any if/else statement. (
or for loop )  Here is the code:

data <- data.frame(x= c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))fin_hyp <-
list(slope=2,constant=1)outputs <- data['y'] > fin_hyp['slope'] *
data['x']  +fin_hyp['constant']outputs

What is R doing here? It is using loop somewhere inside? Is this code
more efficient than other methods I mentioned?

Thank you, I.S.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 13 20:13:20 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Nov 2015 14:13:20 -0500
Subject: [R] Environment question
In-Reply-To: <2066696213.56186849.1447437209163.JavaMail.zimbra@centroin.com.br>
References: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
	<2066696213.56186849.1447437209163.JavaMail.zimbra@centroin.com.br>
Message-ID: <56463650.4070004@gmail.com>

On 13/11/2015 12:53 PM, ALBERTO VIEIRA FERREIRA MONTEIRO wrote:
> I have another environment question.
>
> I understand why this works as expected:
>
> f.factory <- function()
> {
>    y <- 2
>    fname <- paste("plus", y, sep = ".")
>    f <- function(x) x + y
>    assign(fname, f, envir = globalenv())
> }
>
> f.factory()
> plus.2(2) # 4
>
> and I also understand why this does NOT work:
>
> f.factory <- function()
> {
>    for (y in 2:3) {
>      fname <- paste("plus", y, sep = ".")
>      f <- function(x) x + y
>      assign(fname, f, envir = globalenv())
>    }
> }
>
> f.factory()
> plus.2(2) # 5
>    
> (the reason is that both plus.2 and plus.3 have the
> same environment as f.factory when f.factory terminates,
> which assign 2 to variable y in the first case and 3 in
> the second case)
>
> However, I don't know an elegant way to adapt f.factory
> so that it works as expected. Any suggestions?

I think Bill answered your question.  I'd suggest that you should ask a 
different question.  It's generally a bad idea to use assign(), 
especially for assignments into the global environment. Your f.factory 
should return a value, it shouldn't modify globalenv().   It's often a 
bad idea to refer to the environment explicitly at all.  So my 
recommended solution might be this variation on Bill's:

f.factory4 <- function()
{
   result <- list()
   for (y in 2:3) {
     result[[y]] <- local({
       ylocal <- y
       function(x) x + ylocal
     })
     names(result)[y] <- paste("plus", y, sep = ".")
   }
   result
}

The "names" line is optional; with it, you can use

f <- f.factory4()
f$plus.2(2)

but with or without it you can use

f[[2]](2)

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Nov 13 20:15:35 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Nov 2015 14:15:35 -0500
Subject: [R] Suprising R behaviour
In-Reply-To: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>
References: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>
Message-ID: <564636D7.5070805@gmail.com>

On 13/11/2015 8:11 AM, Ilgaz S wrote:
> Hello everybody, I am new to R and I discovered something that suprise me
> and I have a question about it.
> Today I wanted to return a bit array which represents this:
>
> if( arbitrary point above the line)
>       return TRUE
> else
>       return FALSE
>
> First I tought I would use for loop and access every element of the data.
> Then I tend to use lapply function.
>
> At the end, I accidently done that without using any if/else statement. (
> or for loop )  Here is the code:

I can't read your code (you posted in HTML, don't do that), but it 
sounds as though you have discovered vectorized operations.  These are 
central to good R programming, and are well described in the 
Introduction to R manual.

Duncan Murdoch
>
> data <- data.frame(x= c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))fin_hyp <-
> list(slope=2,constant=1)outputs <- data['y'] > fin_hyp['slope'] *
> data['x']  +fin_hyp['constant']outputs
>
> What is R doing here? It is using loop somewhere inside? Is this code
> more efficient than other methods I mentioned?
>
> Thank you, I.S.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From writetohana at gmail.com  Fri Nov 13 20:34:28 2015
From: writetohana at gmail.com (writetohana at gmail.com)
Date: Fri, 13 Nov 2015 19:34:28 +0000
Subject: [R] =?utf-8?q?R_setting_number_of_knots_in_smoothing_splines?=
Message-ID: <56463d40.a323700a.645c9.ffffd8d8@mx.google.com>

Dear all,


I am solving a problem about setting a knots in function smooth. spline. I am not very sure how to set a knot points in this. I understand it accept only number of points, but not distances between them. Can you help me how to specify the distances?


Thanks a lot.

Regards!
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Nov 13 23:15:15 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 13 Nov 2015 14:15:15 -0800
Subject: [R] R setting number of knots in smoothing splines
In-Reply-To: <56463d40.a323700a.645c9.ffffd8d8@mx.google.com>
References: <56463d40.a323700a.645c9.ffffd8d8@mx.google.com>
Message-ID: <CAGxFJbTjAYPyP5jFMvFjqLwtSAd99BzQ-j-rV_UxCDAw8OgT5w@mail.gmail.com>

1. I am not an expert on smoothing splines, but what you are trying to
do seems unwise. See e.g. Chapter 5 of Hastie et. al. "The Elements of
Statistical Learning."

2. However, could you not do what you want by setting some of the
weights, w, to 0?

Cheers,
Bert

Bert Gunter
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Nov 13, 2015 at 11:34 AM,  <writetohana at gmail.com> wrote:
> Dear all,
>
>
> I am solving a problem about setting a knots in function smooth. spline. I am not very sure how to set a knot points in this. I understand it accept only number of points, but not distances between them. Can you help me how to specify the distances?
>
>
> Thanks a lot.
>
> Regards!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Nov 14 01:02:31 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 13 Nov 2015 19:02:31 -0500
Subject: [R] R setting number of knots in smoothing splines
In-Reply-To: <56463d40.a323700a.645c9.ffffd8d8@mx.google.com>
References: <56463d40.a323700a.645c9.ffffd8d8@mx.google.com>
Message-ID: <56467A17.3090001@gmail.com>

On 13/11/2015 2:34 PM, writetohana at gmail.com wrote:
> Dear all,
>
>
> I am solving a problem about setting a knots in function smooth. spline. I am not very sure how to set a knot points in this. I understand it accept only number of points, but not distances between them. Can you help me how to specify the distances?

smooth.spline (you really shouldn't be using HTML to post; then the 
function name wouldn't get messed up) chooses evenly spaced quantiles in 
x for the knots.  Normally the result if you choose every unique x won't 
be much different:  it's the "df" or "spar" parameter that controls the 
result much more than the knots.

So I'd say you should read more about smoothing splines before you 
continue with your approach.

Duncan Murdoch



>
>
> Thanks a lot.
>
> Regards!
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From valkremk at gmail.com  Sat Nov 14 02:34:37 2015
From: valkremk at gmail.com (Val)
Date: Fri, 13 Nov 2015 19:34:37 -0600
Subject: [R] Decast
Message-ID: <CAJOiR6Zrs7g41bDMCN-PrwjTB7A80WSLJLkK65LovPFhsR5GsQ@mail.gmail.com>

Hi all,
I have a data frame called "df"  it's dimension is

dim(df)
[1] 9540634       38

>From this data frame  the  variable *  df$X1 *has about 78, 000 unique
values and  *df$region *has two classes.  I am trying to do  the following
operation
The goal is reshaping the variable from  long to wide

#############################
library(reshape)
library(reshape2)
library(plyr)

sf1 <- ddply(df, df("df$X1","df$region"), summarise,
                           N    = length(df$region))
xr  <- dcast(sf1, df$x1 ~  df$region,  value.var= "N")


With this huge data set it is taking more than 6 hours and I don't know
when it is finishing.

I am sure the above syntax does not have any error because I tested with
small data set and worked fine except the following message
Aggregation function missing: defaulting to length

Is there an alternative way of doing this operation that may not take long
hours.
Thank you in advance

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Nov 14 03:58:30 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 13 Nov 2015 18:58:30 -0800
Subject: [R] Decast
In-Reply-To: <CAJOiR6Zrs7g41bDMCN-PrwjTB7A80WSLJLkK65LovPFhsR5GsQ@mail.gmail.com>
References: <CAJOiR6Zrs7g41bDMCN-PrwjTB7A80WSLJLkK65LovPFhsR5GsQ@mail.gmail.com>
Message-ID: <9643CAED-B458-4D9C-A03D-283EE7E2F3FA@comcast.net>


> On Nov 13, 2015, at 5:34 PM, Val <valkremk at gmail.com> wrote:
> 
> Hi all,
> I have a data frame called "df"  it's dimension is
> 
> dim(df)
> [1] 9540634       38
> 
>> From this data frame  the  variable *  df$X1 *has about 78, 000 unique
> values and  *df$region *has two classes.  I am trying to do  the following
> operation

It?s better to actually describe the operation so outside observers can advise whether the code is correct. My memory: dcast expects the row names to be on the LHS and the column names to be on the RHS:

> The goal is reshaping the variable from  long to wide
> 
> #############################
> library(reshape)
> library(reshape2)
> library(plyr)
> 
> sf1 <- ddply(df, df("df$X1","df$region"), summarise,
>                           N    = length(df$region))
> 

Generally R function that expect a formula do not expect the column names to be preceded by the dataframe name. You might try:

 xr  <- dcast(sf1, x1 ~  region,  value.var= "N?)


> 
> 
> With this huge data set it is taking more than 6 hours and I don't know
> when it is finishing.
> 
> I am sure the above syntax does not have any error because I tested with
> small data set and worked fine except the following message
> Aggregation function missing: defaulting to length
> 
> Is there an alternative way of doing this operation that may not take long
> hours.
> Thank you in advance
> 
> 	[[alternative HTML version deleted]]

Rhelp is a plain text mailing list.

? 
David.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From j.bayat194 at gmail.com  Sat Nov 14 06:45:58 2015
From: j.bayat194 at gmail.com (javad bayat)
Date: Sat, 14 Nov 2015 09:15:58 +0330
Subject: [R] prediction with neural network
Message-ID: <CANTxAmKbuErxCc+bAgY7m55-gVcAqJG9opm+XVV0Q-YB=_4J0A@mail.gmail.com>

Hi all;
I am working with a data set, pH of a lake water, and there is some gap in
my data. I it possible to predict these gaps by neural network? If so
please help to use the right code.
Many thanks.






-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat Nov 14 13:32:24 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 14 Nov 2015 07:32:24 -0500
Subject: [R] prediction with neural network
In-Reply-To: <CANTxAmKbuErxCc+bAgY7m55-gVcAqJG9opm+XVV0Q-YB=_4J0A@mail.gmail.com>
References: <CANTxAmKbuErxCc+bAgY7m55-gVcAqJG9opm+XVV0Q-YB=_4J0A@mail.gmail.com>
Message-ID: <D119C925-944C-4F6B-BDCA-1512815DEA17@utoronto.ca>

The process you are looking for is called "imputation" and the following link has the advice you need:
  http://rseek.org/?q=imputation

Other than that, please see here for some hints on how to ask questions productively:
http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide for this list.


B.


On Nov 14, 2015, at 12:45 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Hi all;
> I am working with a data set, pH of a lake water, and there is some gap in
> my data. I it possible to predict these gaps by neural network? If so
> please help to use the right code.
> Many thanks.
> 
> 
> 
> 
> 
> 
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lorenzo.isella at gmail.com  Sat Nov 14 16:15:18 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 14 Nov 2015 16:15:18 +0100
Subject: [R] Optim() and Instability
Message-ID: <20151114151518.GA7957@localhost.localdomain>

Dear All,
I am using optim() for a relatively simple task: a linear model where
instead of minimizing the sum of the squared errors, I minimize the sum
of the squared relative errors.
However, I notice that the default algorithm is very sensitive to the
choice of the initial fit parameters, whereas I get much more stable
(and therefore better?) results with the BFGS algorithm.
I would like to have some feedback on this (perhaps I made a mistake
somewhere).
I provide a small self-contained example.
You can download a tiny data set from the link

https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0

whereas I paste the script I am using at the end of the email.
Any feedback is really appreciated.
Many thanks

Lorenzo

################################################################

min.perc_error <- function(data, par) {
              with(data, sum(((par[1]*x1 + par[2]*x2+par[3]*x3 -
              y)/y)^2))
	                   }

par_ini1 <- c(.3,.1, 1e-3)

par_ini2 <- c(1,1, 1)


data <- read.csv("data-instability.csv")

mm_def1 <-optim(par = par_ini1
                    , min.perc_error, data = data)

mm_bfgs1 <-optim(par = par_ini1
                    , min.perc_error, data = data, method="BFGS")

print("fit parameters with the default algorithms and the first seed
")
print(mm_def1$par)

print("fit parameters with the BFGS algorithms and the first seed  ")
print(mm_bfgs1$par)



mm_def2 <-optim(par = par_ini2
                    , min.perc_error, data = data)

mm_bfgs2 <-optim(par = par_ini2
                    , min.perc_error, data = data, method="BFGS")




print("fit parameters with the default algorithms and the second seed
")
print(mm_def2$par)

print("fit parameters with the BFGS algorithms and the second seed  ")
print(mm_bfgs2$par)


From ggrothendieck at gmail.com  Sat Nov 14 16:30:22 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 14 Nov 2015 10:30:22 -0500
Subject: [R] Optim() and Instability
In-Reply-To: <20151114151518.GA7957@localhost.localdomain>
References: <20151114151518.GA7957@localhost.localdomain>
Message-ID: <CAP01uRnaJ13suDmkMVG0Tuw6T1hOL54nRsEOuQcchtVARq=BYA@mail.gmail.com>

Tyipcally the parameters being optimized should be the same order of
magnitude or else you can expect numerical problems.  That is what the
fnscale control parameter is for.

On Sat, Nov 14, 2015 at 10:15 AM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> I am using optim() for a relatively simple task: a linear model where
> instead of minimizing the sum of the squared errors, I minimize the sum
> of the squared relative errors.
> However, I notice that the default algorithm is very sensitive to the
> choice of the initial fit parameters, whereas I get much more stable
> (and therefore better?) results with the BFGS algorithm.
> I would like to have some feedback on this (perhaps I made a mistake
> somewhere).
> I provide a small self-contained example.
> You can download a tiny data set from the link
>
> https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0
>
> whereas I paste the script I am using at the end of the email.
> Any feedback is really appreciated.
> Many thanks
>
> Lorenzo
>
> ################################################################
>
> min.perc_error <- function(data, par) {
>              with(data, sum(((par[1]*x1 + par[2]*x2+par[3]*x3 -
>              y)/y)^2))
>                            }
>
> par_ini1 <- c(.3,.1, 1e-3)
>
> par_ini2 <- c(1,1, 1)
>
>
> data <- read.csv("data-instability.csv")
>
> mm_def1 <-optim(par = par_ini1
>                    , min.perc_error, data = data)
>
> mm_bfgs1 <-optim(par = par_ini1
>                    , min.perc_error, data = data, method="BFGS")
>
> print("fit parameters with the default algorithms and the first seed
> ")
> print(mm_def1$par)
>
> print("fit parameters with the BFGS algorithms and the first seed  ")
> print(mm_bfgs1$par)
>
>
>
> mm_def2 <-optim(par = par_ini2
>                    , min.perc_error, data = data)
>
> mm_bfgs2 <-optim(par = par_ini2
>                    , min.perc_error, data = data, method="BFGS")
>
>
>
>
> print("fit parameters with the default algorithms and the second seed
> ")
> print(mm_def2$par)
>
> print("fit parameters with the BFGS algorithms and the second seed  ")
> print(mm_bfgs2$par)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Sat Nov 14 16:32:26 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 14 Nov 2015 10:32:26 -0500
Subject: [R] Optim() and Instability
In-Reply-To: <CAP01uRnaJ13suDmkMVG0Tuw6T1hOL54nRsEOuQcchtVARq=BYA@mail.gmail.com>
References: <20151114151518.GA7957@localhost.localdomain>
	<CAP01uRnaJ13suDmkMVG0Tuw6T1hOL54nRsEOuQcchtVARq=BYA@mail.gmail.com>
Message-ID: <CAP01uRkLYF4mVPoxYEDM=0gD2745rpgjCOHO9KOdhOaBCvo4wg@mail.gmail.com>

I meant the parscale parameter.

On Sat, Nov 14, 2015 at 10:30 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> Tyipcally the parameters being optimized should be the same order of
> magnitude or else you can expect numerical problems.  That is what the
> fnscale control parameter is for.
>
> On Sat, Nov 14, 2015 at 10:15 AM, Lorenzo Isella
> <lorenzo.isella at gmail.com> wrote:
>> Dear All,
>> I am using optim() for a relatively simple task: a linear model where
>> instead of minimizing the sum of the squared errors, I minimize the sum
>> of the squared relative errors.
>> However, I notice that the default algorithm is very sensitive to the
>> choice of the initial fit parameters, whereas I get much more stable
>> (and therefore better?) results with the BFGS algorithm.
>> I would like to have some feedback on this (perhaps I made a mistake
>> somewhere).
>> I provide a small self-contained example.
>> You can download a tiny data set from the link
>>
>> https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0
>>
>> whereas I paste the script I am using at the end of the email.
>> Any feedback is really appreciated.
>> Many thanks
>>
>> Lorenzo
>>
>> ################################################################
>>
>> min.perc_error <- function(data, par) {
>>              with(data, sum(((par[1]*x1 + par[2]*x2+par[3]*x3 -
>>              y)/y)^2))
>>                            }
>>
>> par_ini1 <- c(.3,.1, 1e-3)
>>
>> par_ini2 <- c(1,1, 1)
>>
>>
>> data <- read.csv("data-instability.csv")
>>
>> mm_def1 <-optim(par = par_ini1
>>                    , min.perc_error, data = data)
>>
>> mm_bfgs1 <-optim(par = par_ini1
>>                    , min.perc_error, data = data, method="BFGS")
>>
>> print("fit parameters with the default algorithms and the first seed
>> ")
>> print(mm_def1$par)
>>
>> print("fit parameters with the BFGS algorithms and the first seed  ")
>> print(mm_bfgs1$par)
>>
>>
>>
>> mm_def2 <-optim(par = par_ini2
>>                    , min.perc_error, data = data)
>>
>> mm_bfgs2 <-optim(par = par_ini2
>>                    , min.perc_error, data = data, method="BFGS")
>>
>>
>>
>>
>> print("fit parameters with the default algorithms and the second seed
>> ")
>> print(mm_def2$par)
>>
>> print("fit parameters with the BFGS algorithms and the second seed  ")
>> print(mm_bfgs2$par)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From bhh at xs4all.nl  Sat Nov 14 17:02:57 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 14 Nov 2015 17:02:57 +0100
Subject: [R] Optim() and Instability
In-Reply-To: <20151114151518.GA7957@localhost.localdomain>
References: <20151114151518.GA7957@localhost.localdomain>
Message-ID: <66F555F6-9E10-47B5-A667-7DEE122F2EB2@xs4all.nl>


> On 14 Nov 2015, at 16:15, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Dear All,
> I am using optim() for a relatively simple task: a linear model where
> instead of minimizing the sum of the squared errors, I minimize the sum
> of the squared relative errors.
> However, I notice that the default algorithm is very sensitive to the
> choice of the initial fit parameters, whereas I get much more stable
> (and therefore better?) results with the BFGS algorithm.
> I would like to have some feedback on this (perhaps I made a mistake
> somewhere).
> I provide a small self-contained example.
> You can download a tiny data set from the link
> 
> https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0
> 
> whereas I paste the script I am using at the end of the email.
> Any feedback is really appreciated.
> Many thanks
> 

The initial parameter values for the percentage error variant are not very good.
If you print min.perc_error(data,par_ini2) you can see that.

Try

par_ini2 <- c(1e-4,1e-4,1e-4)

and you'll get results that are closer to each other.
The rest is up to you.

Berend

> Lorenzo
> 
> ################################################################
> 
> min.perc_error <- function(data, par) {
>             with(data, sum(((par[1]*x1 + par[2]*x2+par[3]*x3 -
>             y)/y)^2))
> 	                   }
> 
> par_ini1 <- c(.3,.1, 1e-3)
> 
> par_ini2 <- c(1,1, 1)
> 
> 
> data <- read.csv("data-instability.csv")
> 
> mm_def1 <-optim(par = par_ini1
>                   , min.perc_error, data = data)
> 
> mm_bfgs1 <-optim(par = par_ini1
>                   , min.perc_error, data = data, method="BFGS")
> 
> print("fit parameters with the default algorithms and the first seed
> ")
> print(mm_def1$par)
> 
> print("fit parameters with the BFGS algorithms and the first seed  ")
> print(mm_bfgs1$par)
> 
> 
> 
> mm_def2 <-optim(par = par_ini2
>                   , min.perc_error, data = data)
> 
> mm_bfgs2 <-optim(par = par_ini2
>                   , min.perc_error, data = data, method="BFGS")
> 
> 
> 
> 
> print("fit parameters with the default algorithms and the second seed
> ")
> print(mm_def2$par)
> 
> print("fit parameters with the BFGS algorithms and the second seed  ")
> print(mm_bfgs2$par)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sat Nov 14 17:04:06 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 14 Nov 2015 16:04:06 +0000
Subject: [R] Suprising R behaviour
In-Reply-To: <564636D7.5070805@gmail.com>
References: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>
	<564636D7.5070805@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD068@mb02.ads.tamu.edu>

You definitely need to learn about the differences between R and the other languages that you are familiar with. You've done some work since you mention the apply() family, but those are just another way of programming a loop. In many cases (including this one), a loop is not needed. Here's your code in a plain text message with some additions:

data <- data.frame(x = c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))
# fin_hyp could just as easily be a data frame or a matrix
fin_hyp <- list(slope = 2, constant = 1)
# R vectorizes the following command and automatically computes the
# result for each row in "data"
outputs <- data['y'] > fin_hyp['slope'] * data['x']  + fin_hyp['constant']
outputs
# Add a plot showing points above and below the line
# ifelse is vectorized so it creates a vector with
# 16 (symbol for solid circle) if above the line and 
# 1 (open circle) if below the line
sym <- ifelse(outputs, 16, 1)
plot(y~x, data, pch=sym)
abline(a=fin_hyp$constant, b=fin_hyp$slope)


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Friday, November 13, 2015 1:16 PM
To: Ilgaz S <ilgaz.somer at gmail.com>; r-help at r-project.org
Subject: Re: [R] Suprising R behaviour

On 13/11/2015 8:11 AM, Ilgaz S wrote:
> Hello everybody, I am new to R and I discovered something that suprise me
> and I have a question about it.
> Today I wanted to return a bit array which represents this:
>
> if( arbitrary point above the line)
>       return TRUE
> else
>       return FALSE
>
> First I tought I would use for loop and access every element of the data.
> Then I tend to use lapply function.
>
> At the end, I accidently done that without using any if/else statement. (
> or for loop )  Here is the code:

I can't read your code (you posted in HTML, don't do that), but it 
sounds as though you have discovered vectorized operations.  These are 
central to good R programming, and are well described in the 
Introduction to R manual.

Duncan Murdoch
>
> data <- data.frame(x= c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))fin_hyp <-
> list(slope=2,constant=1)outputs <- data['y'] > fin_hyp['slope'] *
> data['x']  +fin_hyp['constant']outputs
>
> What is R doing here? It is using loop somewhere inside? Is this code
> more efficient than other methods I mentioned?
>
> Thank you, I.S.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sat Nov 14 17:28:52 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 14 Nov 2015 16:28:52 +0000
Subject: [R] Suprising R behaviour
References: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>
	<564636D7.5070805@gmail.com> 
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD129@mb02.ads.tamu.edu>

My original answer works fine as long as fin_hyp contains only one definition for the line, but if it contains more than one, R will use a different line for each test which is probably not what you want (e.g. the first point will be tested against the first line and the second point against the second line, etc). In that case a loop or apply function would be needed:

> data <- data.frame(x = c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))
> fin_hyp <- data.frame(slope = c(2, 1, -2), constant = c(1, -1, 7))
> outputs <- apply(fin_hyp, 1, function(z) data$y > z[1] * data$x  + z[2])
> outputs
      [,1] [,2]  [,3]
[1,] FALSE TRUE FALSE
[2,] FALSE TRUE FALSE
[3,] FALSE TRUE  TRUE
[4,]  TRUE TRUE FALSE
[5,]  TRUE TRUE  TRUE
[6,]  TRUE TRUE  TRUE

The first column is the result for the first equation (row in fin_hyp) and so on.

David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: David L Carlson 
Sent: Saturday, November 14, 2015 9:57 AM
To: 'Duncan Murdoch' <murdoch.duncan at gmail.com>; Ilgaz S <ilgaz.somer at gmail.com>; r-help at r-project.org
Subject: RE: [R] Suprising R behaviour

You definitely need to learn about the differences between R and the other languages that you are familiar with. You've done some work since you mention the apply() family, but those are just another way of programming a loop. In many cases (including this one), a loop is not needed. Here's your code in a plain text message with some additions:

data <- data.frame(x = c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))
# fin_hyp could just as easily be a data frame or a matrix
fin_hyp <- list(slope = 2, constant = 1)
# R vectorizes the following command and automatically computes the
# result for each row in "data"
outputs <- data['y'] > fin_hyp['slope'] * data['x']  + fin_hyp['constant']
outputs
# Add a plot showing points above and below the line
# ifelse is vectorized so it creates a vector with
# 16 (symbol for solid circle) if above the line and 
# 1 (open circle) if below the line
sym <- ifelse(outputs, 16, 1)
plot(y~x, data, pch=sym)
abline(a=fin_hyp$constant, b=fin_hyp$slope)


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Friday, November 13, 2015 1:16 PM
To: Ilgaz S <ilgaz.somer at gmail.com>; r-help at r-project.org
Subject: Re: [R] Suprising R behaviour

On 13/11/2015 8:11 AM, Ilgaz S wrote:
> Hello everybody, I am new to R and I discovered something that suprise me
> and I have a question about it.
> Today I wanted to return a bit array which represents this:
>
> if( arbitrary point above the line)
>       return TRUE
> else
>       return FALSE
>
> First I tought I would use for loop and access every element of the data.
> Then I tend to use lapply function.
>
> At the end, I accidently done that without using any if/else statement. (
> or for loop )  Here is the code:

I can't read your code (you posted in HTML, don't do that), but it 
sounds as though you have discovered vectorized operations.  These are 
central to good R programming, and are well described in the 
Introduction to R manual.

Duncan Murdoch
>
> data <- data.frame(x= c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))fin_hyp <-
> list(slope=2,constant=1)outputs <- data['y'] > fin_hyp['slope'] *
> data['x']  +fin_hyp['constant']outputs
>
> What is R doing here? It is using loop somewhere inside? Is this code
> more efficient than other methods I mentioned?
>
> Thank you, I.S.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From waterfrogcdw at gmail.com  Sat Nov 14 04:43:20 2015
From: waterfrogcdw at gmail.com (Dawei Cheng)
Date: Sat, 14 Nov 2015 11:43:20 +0800
Subject: [R] How to inherit a base data type (e.g. list, vector)
Message-ID: <CAK=P2J8UjFkS+S2MNP6AzQJa3+FQaiyCwbDFAp5WiiaMOJZ7QA@mail.gmail.com>

Hi, there
I'm trying to extend customized type (for example mylist) from a base type
"list" in R, which contains all functions and prototype of R base "list".
It should support below operators as "list":

a <- list(column1=c(1:5), column2=c(6:10))
aa <- mylist(column1=c(1:5), column2=c(6:10))
a$column1
1 2 3 4 5
aa$column1
1 2 3 4 5

All other usages of "list" is expected to be supported my "mylist"

My questions is :
How could I create the "mylist" in R.
Thanks for help.

-- 

*Best RegardsDawei*

	[[alternative HTML version deleted]]


From pollyannaf at yahoo.com  Sat Nov 14 04:59:41 2015
From: pollyannaf at yahoo.com (Pollyanna Fisher)
Date: Sat, 14 Nov 2015 03:59:41 +0000 (UTC)
Subject: [R] plot.gam help
References: <66074682.3836926.1447473581080.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <66074682.3836926.1447473581080.JavaMail.yahoo@mail.yahoo.com>

 Hello, I've created a list of gams and for my last step I'd like to plot them but I keep getting an error method. Here is an example of one of themI appreciate your help

Gam1s=gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site, family=gaussian)
summary(Gam1s)

Family: gaussian 
Link function: identity 

Formula:
E1 ~ chlag + chla + waveMax + SST + IRR + site + day + chlag:site

Parametric coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)    1.059e+02  6.153e-01 172.154  < 2e-16 ***
chlag         -3.112e+01  4.356e+00  -7.144 1.25e-12 ***
chla          -1.380e+01  1.650e+00  -8.359  < 2e-16 ***
waveMax        6.718e-03  8.450e-04   7.950 3.02e-15 ***
SST            2.627e-02  9.210e-03   2.853  0.00438 ** 
IRR           -4.702e-02  6.665e-03  -7.055 2.33e-12 ***
siteJOH       -6.356e+00  7.508e-01  -8.465  < 2e-16 ***
siteKUR       -4.291e+00  4.497e-01  -9.540  < 2e-16 ***
day            1.208e-03  4.348e-04   2.777  0.00554 ** 
chlag:siteJOH  3.582e+01  7.436e+00   4.817 1.56e-06 ***
chlag:siteKUR  3.083e+01  4.602e+00   6.699 2.68e-11 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1


R-sq.(adj) =  0.294   Deviance explained = 29.8%
GCV = 3.9675  Scale est. = 3.9469    n = 2126

plot(Gam1s)
Error in plot.gam(Gam1s) : 
  No terms to plot - nothing for plot.gam() to do.
> plot.gam(Gam1s)
Error in plot.gam(Gam1s) : 
  No terms to plot - nothing for plot.gam() to do.
> plot.gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site, family=gaussian)
Error in if (se && x$Vp[1, 1] < 0) { : 
  missing value where TRUE/FALSE needed
	[[alternative HTML version deleted]]


From malcolm.mistry at unive.it  Sat Nov 14 14:51:09 2015
From: malcolm.mistry at unive.it (Malcolm MISTRY)
Date: Sat, 14 Nov 2015 19:21:09 +0530
Subject: [R] R: Package plm (pvcm) "within" and lm
Message-ID: <CADd=QgtificK9n1ayhBhnPzptQf5ub9KZhd_S7uizQDJhA6Fbw@mail.gmail.com>

Dear all,
I have a doubt on a fixed-effects specification I am trying to run on my
large "balanced" panel data with approx 15,000 IDs (n), 33 years (t).

I have used R packages lfe and plm and am aware of methods in both packages
for following specifications:

(a) Individual FE (ID)
(b) Twoways FE (ID + Year)

Now the third specification I am trying to run a specification of the form

y_it = a_i + b_i*t + e_it,

i.e. a model with an individual-specific intercept and an individual-
specific slope.

To illustrate, I show using Grunfeld data, where firm is the ID and year is
year. I did this using both plm(pvcm) and nlme (lmList) and get the desired
results.

e.g. in pvcm, below form

library(plm)

data(Grunfeld, package = "Ecdat")
head(Grunfeld)

pvcm_model <- pvcm(inv~value, data=Grunfeld, model="within",
effect="individual")  # gives individual coefficients and interecepts for
each firm

Plm documentation says that pvcm with method 'within' is equivalent of
estimating a separate model for each individual. So my doubt is this:

*(1) What is the equivalent form of the above pvcm_model if one would like
to repeat the same using 'lm'?*

I tried the below specifications in lm both am unable to replicate the
individual coefficients and the intercepts of pvcm

ols_model_1 <- lm(inv ~ value * factor(firm) -1, data = Grunfeld) # gives
the same individual intercepts as pvcm, but coefficients (slopes) are
incorrect

# Using time demeaned 'y' (inv) and 'x' (value)

ols_model_2 <- lm(demeaned_inv ~ factor(firm)/demeaned_value -1,
data=Grunfeld_final) # gives the same individual coefficients (slopes), but
intercepts are now incorrect

*(2) My second question is if there is any difference in the above pvcm
specification and a specification as below (notice the 'i' is dropped from
the intercept)*

y_it = a + b_i*t + e_it

In other words, if I would like to run a time series kind of specification
on each individual ID in my panel, to give me individual specific slopes
and intercepts,
does the above pvcm specification imply the same (I am confused with the
'i' subscript because in FEs we use 'i', but in pooling we don't and so
'a_i' should imply 'a'. Moreover, I am confused why the term "within" is
used in pvcm if we are talking of individual specific slopes and intercepts
anyways...).

Hoping someone can reply soon as I am really confused with the pvcm and (2)
specification

Note that my data is large N approx 500,000 observations and its at 0.5 x
0.5 deg resolution (global lat/lon). pvcm did run on a cluster althought it
took a few hours, where as nlme

(lmList) was quite fast.

Rgds
Malcolm

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Nov 14 18:48:35 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 14 Nov 2015 09:48:35 -0800
Subject: [R] How to inherit a base data type (e.g. list, vector)
In-Reply-To: <CAK=P2J8UjFkS+S2MNP6AzQJa3+FQaiyCwbDFAp5WiiaMOJZ7QA@mail.gmail.com>
References: <CAK=P2J8UjFkS+S2MNP6AzQJa3+FQaiyCwbDFAp5WiiaMOJZ7QA@mail.gmail.com>
Message-ID: <CAGxFJbS74rwaZ5M12vzrdW8BFsrFLY=fzSZOEv=StetWyYba5Q@mail.gmail.com>

??

R has 2 built-in OO "class" systems: S3 and S4. S3, which is less an
OO system than a way of customizing methods (see e.g. methods(plot) or
methods(print)), is simpler. S4 is a more full-fledged OO system,
although those coming from languages like C++ and Java might find it
somewhat idiosyncratic. You need to read up on these -- many web
tutorials discuss them, Hadley Wickham's "Advanced R" book is a good
resource also -- and then decide which, if either, suits your needs.
If you still need help **after** you have done your homework, then
post here.


Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Nov 13, 2015 at 7:43 PM, Dawei Cheng <waterfrogcdw at gmail.com> wrote:
> Hi, there
> I'm trying to extend customized type (for example mylist) from a base type
> "list" in R, which contains all functions and prototype of R base "list".
> It should support below operators as "list":
>
> a <- list(column1=c(1:5), column2=c(6:10))
> aa <- mylist(column1=c(1:5), column2=c(6:10))
> a$column1
> 1 2 3 4 5
> aa$column1
> 1 2 3 4 5
>
> All other usages of "list" is expected to be supported my "mylist"
>
> My questions is :
> How could I create the "mylist" in R.
> Thanks for help.
>
> --
>
> *Best RegardsDawei*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Sat Nov 14 19:18:43 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 14 Nov 2015 19:18:43 +0100
Subject: [R] Optim() and Instability
In-Reply-To: <66F555F6-9E10-47B5-A667-7DEE122F2EB2@xs4all.nl>
References: <20151114151518.GA7957@localhost.localdomain>
	<66F555F6-9E10-47B5-A667-7DEE122F2EB2@xs4all.nl>
Message-ID: <40083593-3328-4064-B6AA-3AB1B63D4B07@xs4all.nl>


> On 14 Nov 2015, at 17:02, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 14 Nov 2015, at 16:15, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>> 
>> Dear All,
>> I am using optim() for a relatively simple task: a linear model where
>> instead of minimizing the sum of the squared errors, I minimize the sum
>> of the squared relative errors.
>> However, I notice that the default algorithm is very sensitive to the
>> choice of the initial fit parameters, whereas I get much more stable
>> (and therefore better?) results with the BFGS algorithm.
>> I would like to have some feedback on this (perhaps I made a mistake
>> somewhere).
>> I provide a small self-contained example.
>> You can download a tiny data set from the link
>> 
>> https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0
>> 
>> whereas I paste the script I am using at the end of the email.
>> Any feedback is really appreciated.
>> Many thanks
>> 
> 
> The initial parameter values for the percentage error variant are not very good.
> If you print min.perc_error(data,par_ini2) you can see that.
> 
> Try
> 
> par_ini2 <- c(1e-4,1e-4,1e-4)
> 
> and you'll get results that are closer to each other.
> The rest is up to you.

Try this at the end of your script:

# Original
min.perc_error(data,par_ini2)

# Much better
par_ini3 <- c(1e-4,1e-4,1e-4)
min.perc_error(data,par_ini3)
mm_def3 <-optim(par = par_ini3
                  , min.perc_error, data = data)

mm_bfgs3 <-optim(par = par_ini3
                  , min.perc_error, data = data, method="BFGS")

print("fit parameters with the default algorithms and the second seed
")
print(mm_def3$par)
min.perc_error(data,mm_def3$par)
print("fit parameters with the BFGS algorithms and the second seed  ")
print(mm_bfgs3$par)
min.perc_error(data,mm_bfgs3$par)

and rejoice!

Berend


From pmaclean2011 at yahoo.com  Sat Nov 14 22:54:25 2015
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Sat, 14 Nov 2015 21:54:25 +0000 (UTC)
Subject: [R] Fixing Parameters in maxLik
In-Reply-To: <991554080.4241868.1446132085017.JavaMail.yahoo@mail.yahoo.com>
References: <991554080.4241868.1446132085017.JavaMail.yahoo@mail.yahoo.com>
	<991554080.4241868.1446132085017.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1525963344.4591110.1447538065641.JavaMail.yahoo@mail.yahoo.com>

Is there a way in maxLik to fix/constraint a parameter to fall within a certain range ? For example
I want sigma to be always between 1.98 and 2.02

library(maxLik)

 loglik <- function(param) {
  mu <- param[1]
  sigma <- param[2]
  ll <- -0.5*N*log(2*pi) - N*log(sigma) - sum(0.5*(x - mu)^2/sigma^2)
  ll
}
x <- rnorm(1000, 4.5, 2.1) 
N <- length(x)
res <- maxLik(loglik, start=c(0.5,0.5)) # use 'wrong' start values
print( res )
coef( res )


From andrewcd at gmail.com  Sat Nov 14 23:16:46 2015
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sat, 14 Nov 2015 17:16:46 -0500
Subject: [R] plot.gam help
In-Reply-To: <66074682.3836926.1447473581080.JavaMail.yahoo@mail.yahoo.com>
References: <66074682.3836926.1447473581080.JavaMail.yahoo.ref@mail.yahoo.com>
	<66074682.3836926.1447473581080.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <5647B2CE.8070506@gmail.com>

Your problem is that you've specified a parametric linear model. Your 
output is a set of parametric coefficients.  You can replace `gam` with 
`lm` in your example, and you'll get identical results. If you wish to 
specify one of the terms nonparametrically, you'd use s(chlag), for 
example (assuming you're using mgcv).



On 11/13/2015 10:59 PM, Pollyanna Fisher via R-help wrote:
>   Hello, I've created a list of gams and for my last step I'd like to plot them but I keep getting an error method. Here is an example of one of themI appreciate your help
>
> Gam1s=gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site, family=gaussian)
> summary(Gam1s)
>
> Family: gaussian
> Link function: identity
>
> Formula:
> E1 ~ chlag + chla + waveMax + SST + IRR + site + day + chlag:site
>
> Parametric coefficients:
>                  Estimate Std. Error t value Pr(>|t|)
> (Intercept)    1.059e+02  6.153e-01 172.154  < 2e-16 ***
> chlag         -3.112e+01  4.356e+00  -7.144 1.25e-12 ***
> chla          -1.380e+01  1.650e+00  -8.359  < 2e-16 ***
> waveMax        6.718e-03  8.450e-04   7.950 3.02e-15 ***
> SST            2.627e-02  9.210e-03   2.853  0.00438 **
> IRR           -4.702e-02  6.665e-03  -7.055 2.33e-12 ***
> siteJOH       -6.356e+00  7.508e-01  -8.465  < 2e-16 ***
> siteKUR       -4.291e+00  4.497e-01  -9.540  < 2e-16 ***
> day            1.208e-03  4.348e-04   2.777  0.00554 **
> chlag:siteJOH  3.582e+01  7.436e+00   4.817 1.56e-06 ***
> chlag:siteKUR  3.083e+01  4.602e+00   6.699 2.68e-11 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
>
> R-sq.(adj) =  0.294   Deviance explained = 29.8%
> GCV = 3.9675  Scale est. = 3.9469    n = 2126
>
> plot(Gam1s)
> Error in plot.gam(Gam1s) :
>    No terms to plot - nothing for plot.gam() to do.
>> plot.gam(Gam1s)
> Error in plot.gam(Gam1s) :
>    No terms to plot - nothing for plot.gam() to do.
>> plot.gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site, family=gaussian)
> Error in if (se && x$Vp[1, 1] < 0) { :
>    missing value where TRUE/FALSE needed
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Nov 14 23:22:09 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 14 Nov 2015 14:22:09 -0800
Subject: [R] plot.gam help
In-Reply-To: <5647B2CE.8070506@gmail.com>
References: <66074682.3836926.1447473581080.JavaMail.yahoo.ref@mail.yahoo.com>
	<66074682.3836926.1447473581080.JavaMail.yahoo@mail.yahoo.com>
	<5647B2CE.8070506@gmail.com>
Message-ID: <CAGxFJbRGrww2nHhJh0v7kWYtuqOjOyKB6o8biFkEynwmr4MdZA@mail.gmail.com>

Yes. And see the "all.terms" parameter of plot.gam(), which by default
is FALSE, yielding the error message reported.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 14, 2015 at 2:16 PM, Andrew Crane-Droesch
<andrewcd at gmail.com> wrote:
> Your problem is that you've specified a parametric linear model. Your output
> is a set of parametric coefficients.  You can replace `gam` with `lm` in
> your example, and you'll get identical results. If you wish to specify one
> of the terms nonparametrically, you'd use s(chlag), for example (assuming
> you're using mgcv).
>
>
>
> On 11/13/2015 10:59 PM, Pollyanna Fisher via R-help wrote:
>>
>>   Hello, I've created a list of gams and for my last step I'd like to plot
>> them but I keep getting an error method. Here is an example of one of themI
>> appreciate your help
>>
>> Gam1s=gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site,
>> family=gaussian)
>> summary(Gam1s)
>>
>> Family: gaussian
>> Link function: identity
>>
>> Formula:
>> E1 ~ chlag + chla + waveMax + SST + IRR + site + day + chlag:site
>>
>> Parametric coefficients:
>>                  Estimate Std. Error t value Pr(>|t|)
>> (Intercept)    1.059e+02  6.153e-01 172.154  < 2e-16 ***
>> chlag         -3.112e+01  4.356e+00  -7.144 1.25e-12 ***
>> chla          -1.380e+01  1.650e+00  -8.359  < 2e-16 ***
>> waveMax        6.718e-03  8.450e-04   7.950 3.02e-15 ***
>> SST            2.627e-02  9.210e-03   2.853  0.00438 **
>> IRR           -4.702e-02  6.665e-03  -7.055 2.33e-12 ***
>> siteJOH       -6.356e+00  7.508e-01  -8.465  < 2e-16 ***
>> siteKUR       -4.291e+00  4.497e-01  -9.540  < 2e-16 ***
>> day            1.208e-03  4.348e-04   2.777  0.00554 **
>> chlag:siteJOH  3.582e+01  7.436e+00   4.817 1.56e-06 ***
>> chlag:siteKUR  3.083e+01  4.602e+00   6.699 2.68e-11 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>>
>> R-sq.(adj) =  0.294   Deviance explained = 29.8%
>> GCV = 3.9675  Scale est. = 3.9469    n = 2126
>>
>> plot(Gam1s)
>> Error in plot.gam(Gam1s) :
>>    No terms to plot - nothing for plot.gam() to do.
>>>
>>> plot.gam(Gam1s)
>>
>> Error in plot.gam(Gam1s) :
>>    No terms to plot - nothing for plot.gam() to do.
>>>
>>> plot.gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site,
>>> family=gaussian)
>>
>> Error in if (se && x$Vp[1, 1] < 0) { :
>>    missing value where TRUE/FALSE needed
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Nov 14 23:28:28 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 14 Nov 2015 16:28:28 -0600
Subject: [R] Ranking
Message-ID: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>

Hi all,

I have the following raw data some records  don't have the second variable.

test <- read.table(textConnection(" Country  STATUS
USA
USA    W
USA    W
GER
GER    W
GER    w
GER    W
UNK    W
UNK
UNK    W
FRA
FRA
FRA    W
FRA    W
FRA    W
SPA
SPA    W
SPA          "),header = TRUE,  sep= "\t")
test

It is not reading it correctly.

Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 17 did not have 2 elements



After reading   I want change the status column  to numeric so that I
can use the table function

test$STATUS <- ifelse(is.na(test$STATUS), 0,  1)

at the end I want the following table (Country, Won, Lost , Number of
games played and % of score ) and pick the top 3 countries.

COUNTRY   Won   Lost   NG    %W
 USA             2        1         3      (2/3)*100
 GER             3        1         4      (3/4)*100
 UNK             2        1         3      (2/3)*100
 FRA             3         2        5      (3/5)*100
 SPA             1         2         3      (1/3)*100

Thank you in  advance


From milujisb at gmail.com  Sat Nov 14 23:18:23 2015
From: milujisb at gmail.com (Miluji Sb)
Date: Sat, 14 Nov 2015 23:18:23 +0100
Subject: [R] Two Time Fixed Effects - LFE package
Message-ID: <CAMLwc7MoW7TP2XhtsY9adDVzaquJY9MYvS_kj6zgueRtQaJqTQ@mail.gmail.com>

I have weekly panel data for more than a hundred cities. The independent
variables are temperature and precipitation. The time dimensions are year
and week and likely have time invariant characteristics and are all
important for proper estimation.

Could I use the LFE (or plm) package to estimate something like this by
including the location and two time fixed-effects?

felm(outcome ~ temperature + precipitation | city + year + week

Thanks!

MS

	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Sun Nov 15 00:13:43 2015
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sat, 14 Nov 2015 18:13:43 -0500
Subject: [R] Two Time Fixed Effects - LFE package
In-Reply-To: <CAMLwc7MoW7TP2XhtsY9adDVzaquJY9MYvS_kj6zgueRtQaJqTQ@mail.gmail.com>
References: <CAMLwc7MoW7TP2XhtsY9adDVzaquJY9MYvS_kj6zgueRtQaJqTQ@mail.gmail.com>
Message-ID: <5647C027.9080306@gmail.com>

Is this an R question or an econometrics question?  I'll assume that it 
is an R question.  If your weeks are coded sequentially (i.e.: weeks 
since a particular date), then they'll be strictly determined by year.  
If however you're interested in the effect of a particular week of the 
year (week 7, for example), then you'll need to recode your week 
variable as a factor with 52 levels.  For that you'd likely need the 
"%%" operator.  For example:

1> 1:10%%3
  [1] 1 2 0 1 2 0 1 2 0 1



On 11/14/2015 05:18 PM, Miluji Sb wrote:
> I have weekly panel data for more than a hundred cities. The independent
> variables are temperature and precipitation. The time dimensions are year
> and week and likely have time invariant characteristics and are all
> important for proper estimation.
>
> Could I use the LFE (or plm) package to estimate something like this by
> including the location and two time fixed-effects?
>
> felm(outcome ~ temperature + precipitation | city + year + week
>
> Thanks!
>
> MS
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Nov 15 01:10:54 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 15 Nov 2015 00:10:54 +0000
Subject: [R] Ranking
In-Reply-To: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>
References: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD380@mb02.ads.tamu.edu>

It is always good to read the manual page for a function, but especially when it is not working as you expected. In this case if you look at the arguments for read.table(), you will find one called fill=TRUE that is useful in this case.

Based on your ifelse(), you seem to be assuming that a blank is not missing data but a lost game. You may also discover that in your example wins are coded as w and W.  Since character variables get converted to factors by default, you could use something like:

> levels(test$STATUS) <- c("L", "W", "W")
> addmargins(xtabs(~Country+STATUS, test), 2)
       STATUS
Country L W Sum
    FRA 2 3   5
    GER 1 3   4
    SPA 2 1   3
    UNK 1 2   3
    USA 1 2   3

I'll let you figure out how to get the last column.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
Sent: Saturday, November 14, 2015 4:28 PM
To: R help <r-help at r-project.org>
Subject: [R] Ranking

Hi all,

I have the following raw data some records  don't have the second variable.

test <- read.table(textConnection(" Country  STATUS
USA
USA    W
USA    W
GER
GER    W
GER    w
GER    W
UNK    W
UNK
UNK    W
FRA
FRA
FRA    W
FRA    W
FRA    W
SPA
SPA    W
SPA          "),header = TRUE,  sep= "\t")
test

It is not reading it correctly.

Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
  line 17 did not have 2 elements



After reading   I want change the status column  to numeric so that I
can use the table function

test$STATUS <- ifelse(is.na(test$STATUS), 0,  1)

at the end I want the following table (Country, Won, Lost , Number of
games played and % of score ) and pick the top 3 countries.

COUNTRY   Won   Lost   NG    %W
 USA             2        1         3      (2/3)*100
 GER             3        1         4      (3/4)*100
 UNK             2        1         3      (2/3)*100
 FRA             3         2        5      (3/5)*100
 SPA             1         2         3      (1/3)*100

Thank you in  advance

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sun Nov 15 01:40:37 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 14 Nov 2015 18:40:37 -0600
Subject: [R] Ranking
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD380@mb02.ads.tamu.edu>
References: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD380@mb02.ads.tamu.edu>
Message-ID: <CADDFq31z_9b_HY5bMcXPpW+Cp2BpLxcCZmAg9yXpPMjMxu90uw@mail.gmail.com>

Thank you David,

My intention was if I change the status column  to numeric
0= Lost and 1 Won, then I can use this numeric variables  to calculate
the  Percent game Won by each country.
how did you read the data first?
That was my problem.   The actual data is in a file have to be read or laded.

Thank you !






On Sat, Nov 14, 2015 at 6:10 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> It is always good to read the manual page for a function, but especially when it is not working as you expected. In this case if you look at the arguments for read.table(), you will find one called fill=TRUE that is useful in this case.
>
> Based on your ifelse(), you seem to be assuming that a blank is not missing data but a lost game. You may also discover that in your example wins are coded as w and W.  Since character variables get converted to factors by default, you could use something like:
>
>> levels(test$STATUS) <- c("L", "W", "W")
>> addmargins(xtabs(~Country+STATUS, test), 2)
>        STATUS
> Country L W Sum
>     FRA 2 3   5
>     GER 1 3   4
>     SPA 2 1   3
>     UNK 1 2   3
>     USA 1 2   3
>
> I'll let you figure out how to get the last column.
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
> Sent: Saturday, November 14, 2015 4:28 PM
> To: R help <r-help at r-project.org>
> Subject: [R] Ranking
>
> Hi all,
>
> I have the following raw data some records  don't have the second variable.
>
> test <- read.table(textConnection(" Country  STATUS
> USA
> USA    W
> USA    W
> GER
> GER    W
> GER    w
> GER    W
> UNK    W
> UNK
> UNK    W
> FRA
> FRA
> FRA    W
> FRA    W
> FRA    W
> SPA
> SPA    W
> SPA          "),header = TRUE,  sep= "\t")
> test
>
> It is not reading it correctly.
>
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 17 did not have 2 elements
>
>
>
> After reading   I want change the status column  to numeric so that I
> can use the table function
>
> test$STATUS <- ifelse(is.na(test$STATUS), 0,  1)
>
> at the end I want the following table (Country, Won, Lost , Number of
> games played and % of score ) and pick the top 3 countries.
>
> COUNTRY   Won   Lost   NG    %W
>  USA             2        1         3      (2/3)*100
>  GER             3        1         4      (3/4)*100
>  UNK             2        1         3      (2/3)*100
>  FRA             3         2        5      (3/5)*100
>  SPA             1         2         3      (1/3)*100
>
> Thank you in  advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Nov 15 06:48:42 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 14 Nov 2015 21:48:42 -0800
Subject: [R] plot.gam help
In-Reply-To: <188460455.4096052.1447565487049.JavaMail.yahoo@mail.yahoo.com>
References: <CAGxFJbRGrww2nHhJh0v7kWYtuqOjOyKB6o8biFkEynwmr4MdZA@mail.gmail.com>
	<188460455.4096052.1447565487049.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbQMkgRSxu9N+CdHsgCD4Gi=KkEAyXGrT8BnrPtxK9THiA@mail.gmail.com>

Please always cc the list to assure a better chance of getting a good answer.

I dunno. I assume you could control scaling through xlim and/or ylim
arguments as "..." arguments. See ?plot.default and linked Help if you
don't know about graphical parameters. If you don't know what "..."
arguments are about, time to do some homework and read an R tutorial
or two (the Intro to R tutorial that ships with R is pretty good on
this). You may have to do some experimentation to get what you want,
which is rather obscure to me from your comment.

Note, however, that you should probably be using lm() and not gam() to
begin with, for which the associated plotting might be better.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 14, 2015 at 9:31 PM, Pollyanna Fisher <pollyannaf at yahoo.com> wrote:
> Thank you Bert,
> This fixed the issue and I can now see my plots,
> However, they appear to be in an very skewed scale where it is showing me
> the prediction line starting at 0 and the plotted values  way below it, in a
> way that is not quite understandable. Is there a way to scale the plot
> differently?
>
> ________________________________
> From: Bert Gunter <bgunter.4567 at gmail.com>
> To: Andrew Crane-Droesch <andrewcd at gmail.com>
> Cc: Pollyanna Fisher <pollyannaf at yahoo.com>; "r-help at r-project.org"
> <r-help at r-project.org>
> Sent: Saturday, November 14, 2015 12:22 PM
> Subject: Re: [R] plot.gam help
>
> Yes. And see the "all.terms" parameter of plot.gam(), which by default
> is FALSE, yielding the error message reported.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
>
>
> On Sat, Nov 14, 2015 at 2:16 PM, Andrew Crane-Droesch
> <andrewcd at gmail.com> wrote:
>> Your problem is that you've specified a parametric linear model. Your
>> output
>> is a set of parametric coefficients.  You can replace `gam` with `lm` in
>> your example, and you'll get identical results. If you wish to specify one
>> of the terms nonparametrically, you'd use s(chlag), for example (assuming
>> you're using mgcv).
>>
>>
>>
>> On 11/13/2015 10:59 PM, Pollyanna Fisher via R-help wrote:
>>>
>>>  Hello, I've created a list of gams and for my last step I'd like to plot
>>> them but I keep getting an error method. Here is an example of one of
>>> themI
>>> appreciate your help
>>>
>>> Gam1s=gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site,
>>> family=gaussian)
>>> summary(Gam1s)
>>>
>>> Family: gaussian
>>> Link function: identity
>>>
>>> Formula:
>>> E1 ~ chlag + chla + waveMax + SST + IRR + site + day + chlag:site
>>>
>>> Parametric coefficients:
>>>                  Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)    1.059e+02  6.153e-01 172.154  < 2e-16 ***
>>> chlag        -3.112e+01  4.356e+00  -7.144 1.25e-12 ***
>>> chla          -1.380e+01  1.650e+00  -8.359  < 2e-16 ***
>>> waveMax        6.718e-03  8.450e-04  7.950 3.02e-15 ***
>>> SST            2.627e-02  9.210e-03  2.853  0.00438 **
>>> IRR          -4.702e-02  6.665e-03  -7.055 2.33e-12 ***
>>> siteJOH      -6.356e+00  7.508e-01  -8.465  < 2e-16 ***
>>> siteKUR      -4.291e+00  4.497e-01  -9.540  < 2e-16 ***
>>> day            1.208e-03  4.348e-04  2.777  0.00554 **
>>> chlag:siteJOH  3.582e+01  7.436e+00  4.817 1.56e-06 ***
>>> chlag:siteKUR  3.083e+01  4.602e+00  6.699 2.68e-11 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>>
>>> R-sq.(adj) =  0.294  Deviance explained = 29.8%
>>> GCV = 3.9675  Scale est. = 3.9469    n = 2126
>>>
>>> plot(Gam1s)
>>> Error in plot.gam(Gam1s) :
>>>    No terms to plot - nothing for plot.gam() to do.
>>>>
>>>> plot.gam(Gam1s)
>>>
>>> Error in plot.gam(Gam1s) :
>>>    No terms to plot - nothing for plot.gam() to do.
>>>>
>>>> plot.gam(E1~chlag +chla + waveMax + SST + IRR + site + day +chlag:site,
>>>> family=gaussian)
>>>
>>> Error in if (se && x$Vp[1, 1] < 0) { :
>>>    missing value where TRUE/FALSE needed
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From ilgaz.somer at gmail.com  Sun Nov 15 08:24:55 2015
From: ilgaz.somer at gmail.com (Ilgaz S)
Date: Sun, 15 Nov 2015 09:24:55 +0200
Subject: [R] Suprising R behaviour
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD129@mb02.ads.tamu.edu>
References: <CANHKgcWT7F5xNmityay6nY0hct9A=2a85jk1J6i=vA2X1qbkTg@mail.gmail.com>
	<564636D7.5070805@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD129@mb02.ads.tamu.edu>
Message-ID: <CANHKgcXbgw_4SerL-joS4PTmDf-+6D1ykoYLjLbYf0TL4BQmgA@mail.gmail.com>

Thank you all for answering such a newbie question. :) David thank you for
your example too.
Best wishes, I.S
On Nov 14, 2015 18:28, "David L Carlson" <dcarlson at tamu.edu> wrote:

> My original answer works fine as long as fin_hyp contains only one
> definition for the line, but if it contains more than one, R will use a
> different line for each test which is probably not what you want (e.g. the
> first point will be tested against the first line and the second point
> against the second line, etc). In that case a loop or apply function would
> be needed:
>
> > data <- data.frame(x = c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))
> > fin_hyp <- data.frame(slope = c(2, 1, -2), constant = c(1, -1, 7))
> > outputs <- apply(fin_hyp, 1, function(z) data$y > z[1] * data$x  + z[2])
> > outputs
>       [,1] [,2]  [,3]
> [1,] FALSE TRUE FALSE
> [2,] FALSE TRUE FALSE
> [3,] FALSE TRUE  TRUE
> [4,]  TRUE TRUE FALSE
> [5,]  TRUE TRUE  TRUE
> [6,]  TRUE TRUE  TRUE
>
> The first column is the result for the first equation (row in fin_hyp) and
> so on.
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
> -----Original Message-----
> From: David L Carlson
> Sent: Saturday, November 14, 2015 9:57 AM
> To: 'Duncan Murdoch' <murdoch.duncan at gmail.com>; Ilgaz S <
> ilgaz.somer at gmail.com>; r-help at r-project.org
> Subject: RE: [R] Suprising R behaviour
>
> You definitely need to learn about the differences between R and the other
> languages that you are familiar with. You've done some work since you
> mention the apply() family, but those are just another way of programming a
> loop. In many cases (including this one), a loop is not needed. Here's your
> code in a plain text message with some additions:
>
> data <- data.frame(x = c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))
> # fin_hyp could just as easily be a data frame or a matrix
> fin_hyp <- list(slope = 2, constant = 1)
> # R vectorizes the following command and automatically computes the
> # result for each row in "data"
> outputs <- data['y'] > fin_hyp['slope'] * data['x']  + fin_hyp['constant']
> outputs
> # Add a plot showing points above and below the line
> # ifelse is vectorized so it creates a vector with
> # 16 (symbol for solid circle) if above the line and
> # 1 (open circle) if below the line
> sym <- ifelse(outputs, 16, 1)
> plot(y~x, data, pch=sym)
> abline(a=fin_hyp$constant, b=fin_hyp$slope)
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
> Murdoch
> Sent: Friday, November 13, 2015 1:16 PM
> To: Ilgaz S <ilgaz.somer at gmail.com>; r-help at r-project.org
> Subject: Re: [R] Suprising R behaviour
>
> On 13/11/2015 8:11 AM, Ilgaz S wrote:
> > Hello everybody, I am new to R and I discovered something that suprise me
> > and I have a question about it.
> > Today I wanted to return a bit array which represents this:
> >
> > if( arbitrary point above the line)
> >       return TRUE
> > else
> >       return FALSE
> >
> > First I tought I would use for loop and access every element of the data.
> > Then I tend to use lapply function.
> >
> > At the end, I accidently done that without using any if/else statement. (
> > or for loop )  Here is the code:
>
> I can't read your code (you posted in HTML, don't do that), but it
> sounds as though you have discovered vectorized operations.  These are
> central to good R programming, and are well described in the
> Introduction to R manual.
>
> Duncan Murdoch
> >
> > data <- data.frame(x= c(1,2,3,1,1,1), y = c(1,2,3,4,6,7))fin_hyp <-
> > list(slope=2,constant=1)outputs <- data['y'] > fin_hyp['slope'] *
> > data['x']  +fin_hyp['constant']outputs
> >
> > What is R doing here? It is using loop somewhere inside? Is this code
> > more efficient than other methods I mentioned?
> >
> > Thank you, I.S.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Sun Nov 15 15:24:27 2015
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Sun, 15 Nov 2015 09:24:27 -0500
Subject: [R] Two Time Fixed Effects - LFE package
In-Reply-To: <CAMLwc7MvFP6560-CYnFv0GQx18q8NJ6K4XePH_5Uo44zdfHEPg@mail.gmail.com>
References: <CAMLwc7MoW7TP2XhtsY9adDVzaquJY9MYvS_kj6zgueRtQaJqTQ@mail.gmail.com>
	<5647C027.9080306@gmail.com>
	<CAMLwc7MvFP6560-CYnFv0GQx18q8NJ6K4XePH_5Uo44zdfHEPg@mail.gmail.com>
Message-ID: <5648959B.40608@gmail.com>

I don't see why not, but I also don't see why you need to take my word 
for it when you can compare the output of felm against the output of lm, 
with dummy variables for all the factors.  If that many dummies is 
computationally tough, just work with a subset.

On 11/15/2015 08:37 AM, Miluji Sb wrote:
> Dear Andrew,
>
> Thank you for your reply. Its an R question. The weeks are coded as 
> 1-53 for each year and I would like to control weeks and years as time 
> fixed effects.
>
> Will this be an issue if I estimate this type of regression using the 
> LFE package?
>
> felm(outcome ~ temperature + precipitation | city + year + week
>
> Thanks again!
>
> Sincerely,
>
> MS
>
> On Sun, Nov 15, 2015 at 12:13 AM, Andrew Crane-Droesch 
> <andrewcd at gmail.com <mailto:andrewcd at gmail.com>> wrote:
>
>     Is this an R question or an econometrics question?  I'll assume
>     that it is an R question.  If your weeks are coded sequentially
>     (i.e.: weeks since a particular date), then they'll be strictly
>     determined by year.  If however you're interested in the effect of
>     a particular week of the year (week 7, for example), then you'll
>     need to recode your week variable as a factor with 52 levels.  For
>     that you'd likely need the "%%" operator.  For example:
>
>     1> 1:10%%3
>      [1] 1 2 0 1 2 0 1 2 0 1
>
>
>
>
>     On 11/14/2015 05:18 PM, Miluji Sb wrote:
>
>         I have weekly panel data for more than a hundred cities. The
>         independent
>         variables are temperature and precipitation. The time
>         dimensions are year
>         and week and likely have time invariant characteristics and
>         are all
>         important for proper estimation.
>
>         Could I use the LFE (or plm) package to estimate something
>         like this by
>         including the location and two time fixed-effects?
>
>         felm(outcome ~ temperature + precipitation | city + year + week
>
>         Thanks!
>
>         MS
>
>                 [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>         list -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Sun Nov 15 18:17:05 2015
From: lorenzo.isella at gmail.com (lorenzo.isella at gmail.com)
Date: Sun, 15 Nov 2015 18:17:05 +0100
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <1447606959006.93337@jhu.edu>
References: <1447606959006.93337@jhu.edu>
Message-ID: <20151115171705.GA1924@localhost.localdomain>

Thanks a lot, Ravi.
Indeed you best understood the point of my email.
I am perfectly aware that most of the optimization algorithms find
local rather than global minima and therefore the choice of the
initial parameters plays (at least in principle) a role.
Nevertheless, my optimization problem is rather trivial and I did not
bother to look for anything beyond the most basic tool in R for
optimization.
What surprised me is that an algorithm different from the default one
in optim() is extremely robust to a partially deliberate bad choice
ofthe initial parameters, whereas the standard one is not.
You perfectly answered my question.
Regards

Lorenzo


On Sun, Nov 15, 2015 at 05:02:52PM +0000, Ravi Varadhan wrote:
>Hi,
>
>
>
>While I agree with the comments about paying attention to parameter scaling, a major issue here is that the default optimization algorithm, Nelder-Mead, is not very good.  It is unfortunate that the optim implementation chose this as the "default" algorithm.  I have several instances where people have come to me with poor results from using optim(), because they did not realize that the default algorithm is bad.  We (John Nash and I) have pointed this out before, but the R core has not addressed this issue due to backward compatibility reasons.
>
>
>
>There is a better implementation of Nelder-Mead in the "dfoptim" package.
>
>
>
>?require(dfoptim)
>
>mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
>
>mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
>
>mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
>
>print(mm_def1$par)
>
>print(mm_def2$par)
>
>print(mm_def3$par)
>
>
>
>In general, better implementations of optimization algorithms are available in packages such as "optimx", "nloptr".  It is unfortunate that most na?ve users of optimization in R do not recognize this.  Perhaps, there should be a "message" in the optim help file that points this out to the users.
>
>
>
>Hope this is helpful,
>
>Ravi
>


From marammagdysalem at gmail.com  Sun Nov 15 18:18:40 2015
From: marammagdysalem at gmail.com (marammagdysalem at gmail.com)
Date: Sun, 15 Nov 2015 19:18:40 +0200
Subject: [R] Alternatives for explicit for() loops
In-Reply-To: <CAAxdm-5ha0iCfJdkeEkvdeVXTKkDifVnJBBO-Mw8JV7LA1EyYw@mail.gmail.com>
References: <CAPLSCn2NMu+5Tfpk8Qy6KOtWRydZk6_j0zwusJOi-E36Sd3KdA@mail.gmail.com>
	<CAAxdm-5HuBmaGuBN5uGz3wkjLD7H9BmUaGDQxuiRG8meqGGhZA@mail.gmail.com>
	<CAPLSCn0wmG5Hf5UKcZHVA75B=rSrwS6oUNvf+PiG5TnEacoC=A@mail.gmail.com>
	<CAAxdm-6rgLfqJpEB=y8TwoSagN6=zs08BgM6d7Cd-qgJ0B13Zw@mail.gmail.com>
	<CAPLSCn0WLK8uVQe5H=ZqKjwBBdFNENPxQ2HrzOcbX+w4fdp38Q@mail.gmail.com>
	<CAAxdm-5ha0iCfJdkeEkvdeVXTKkDifVnJBBO-Mw8JV7LA1EyYw@mail.gmail.com>
Message-ID: <3EF35269-A1CE-48FD-9BDF-C997913243DE@gmail.com>

Thanks a lot Jim and Boris for replying.

Sent from my iPhone

> On Nov 9, 2015, at 1:13 AM, jim holtman <jholtman at gmail.com> wrote:
> 
> You need to take a close look at the function incomb that you are creating.  I see what appears to be a constant value ("*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))") being computed that you might only have to compute once before the function.  You are also referencing many variables (m, LED, j, ...) that are not being passed in that are in the global environment; it is probably better to pass them in to the function.  I am not sure what 'pbapply' is doing for you since I see this is new to the code that you first sent out.
> 
> I would be good it you told us what the function is trying to do; you are showing us how you want to do it, not what you want to do.  Are there other ways of doing it?  If speed is your problem, then consider the "Rcpp" package and write the function is C++ which might be faster, but again, take a look at what you are doing to see if there are other ways.  I don't have time to dig into the code, since there is a lack of comments, to understand why you are using, e.g., 'choose', 'prod', etc.).  There are probably a lot of ways of speeding up the code, if could tell us what you want to accomplish.
> 
> 
> Jim Holtman
> Data Munger Guru
>  
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
>> On Sun, Nov 8, 2015 at 4:48 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>> Thanks all for replying.
>> 
>> In fact I've used the the Rprof() function and found out that the incomb() function (in my code above)  takes about 80% of the time, but I didn't figure out which part of the function is causing the delay. So I thought that this may be due to the for() loops. 
>> I MUST run this code for rather large values of n and m, so is there any way that can help me do that without having to wait for more than three days to reach an output. N.B. I'll have to repeat these runs for may be 70 or 80 times , and this means HUGE time
>> 
>> I'd appreciate any sort of help.
>> Thanks in advance.
>> 
>> Maram Salem
>> 
>>> On 6 November 2015 at 16:54, jim holtman <jholtman at gmail.com> wrote:
>>> If you have code that is running for a long time, then take a small case that only runs for 5-10 minutes and turn on the RProfiler so that you can see where you are spending your time.  In most cases, it is probably not the 'for' loops that are causing the problem, but some function/calculation you are doing within the loop that is consuming the time, and until you determine what section of code that is, is it hard to tell exactly what the problem is, much less the solution.
>>> 
>>> 
>>> Jim Holtman
>>> Data Munger Guru
>>>  
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>> 
>>>> On Wed, Nov 4, 2015 at 9:09 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>>>> Hi Jim,
>>>> 
>>>> Thanks a lot for replying.
>>>> 
>>>> In fact I'm trying to run a simulation study that enables me to calculate the Bayes risk of a sampling plan selected from progressively type-II censored Weibull model. One of the steps involves evaluating the expected test time, which is a rather complicated formula that involves nested multiple summations where the counters of the summation signs are dependent, that's why I thought of I should create the incomb() function inside the loop, or may be I didn't figure out how to relate its arguments to the ones inside the loop had I created it outside it.  I'm trying to create a matrix of all the possible combinations involved in the summations and then use the apply() function on each row of that matrix. The problem is that the code I wrote works perfectly well for rather small values of the sample size,n, and the censoring number, m (for example, n=8,m=4),but when n and m are increased (say, n=25,m=15) the code keeps on running for days with no output. That's why I thought I should try to avoid explicit loops as much as possible, so I did my best in this regard but still the code takes too long to execute,(more than three days), thus, i believe there must be something wrong.
>>>> 
>>>> Here's the full code:
>>>> 
>>>> library(pbapply)
>>>> f1 <- function(n, m) {
>>>>    stopifnot(n > m)
>>>>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>>>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1, len=n-m+1), m-2))
>>>>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
>>>> }
>>>> simpfun<- function (x,n,m,p,alpha,beta)
>>>>   {
>>>>   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>>>>   b <-  ((m-1):1)
>>>>   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))- sum(x%*%(as.matrix(b)))))
>>>> d <- n - cumsum(x) - (1:(m-1))
>>>>   e<- n*(prod(d))*c
>>>> LD<-list()
>>>>    for (i in 1:(m-1))  {
>>>>    LD[[i]]<-seq(0,x[i],1)
>>>>    }
>>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>    LED<-expand.grid (LD)
>>>>    LED<-as.matrix(LED)
>>>>    store1<-numeric(nrow(LED))
>>>> for (j in 1:length(store1) )
>>>>          {
>>>>             incomb<-function(x,alpha,beta) {
>>>>              g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>                     h <- choose(x, LED[j,-m])    
>>>>                    ik<-prod(h)*choose((n-m-sum(x)),LED[j,m]) 
>>>>                 lm<-cumsum(LED[j,-m]) + (1:(m-1))  
>>>>                 plm<-prod(lm)
>>>>                gil<-g*ik/(plm)
>>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>>              dsa<-length(hlm)
>>>>               for (i in 1:dsa)  
>>>>                 {
>>>>                  ppp<- sum(LED[j,])+(m-1)
>>>>                   hlm[i]<-  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))  
>>>>                  }
>>>>           shl<-gil*(sum(hlm)+1)         
>>>>           return (shl)
>>>>           }
>>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>       }
>>>> val1<- sum(store1)*e
>>>> return(val1)
>>>> }
>>>> 
>>>> va<-pbapply(s,1,simpfun,n=6,m=4,p=0.3,alpha=0.2,beta=2)
>>>> EXP<-sum(va)
>>>> 
>>>> 
>>>> 
>>>> Any help would be greatly appreciated.
>>>> Thanks a lot  for your time.
>>>> 
>>>> Best Regards, 
>>>> Maram Salem
>>>> 
>>>> 
>>>>> On 2 November 2015 at 00:27, jim holtman <jholtman at gmail.com> wrote:
>>>>> Why are you recreating the incomb function within the loop instead of defining it outside the loop?  Also you are referencing several variables that are global (e.g., m & j); you should be passing these in as parameters to the function.
>>>>> 
>>>>> 
>>>>> Jim Holtman
>>>>> Data Munger Guru
>>>>>  
>>>>> What is the problem that you are trying to solve?
>>>>> Tell me what you want to do, not how you want to do it.
>>>>> 
>>>>>> On Sun, Nov 1, 2015 at 7:31 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>>>>>> Hi All,
>>>>>> 
>>>>>> I'm writing a long code that takes long time to execute. So I used the
>>>>>> Rprof() function and found out that the function that takes about 80% of
>>>>>> the time is the incomb () fucntion (below), and this is most probably
>>>>>> because of the many explicit for() loops I'm using.
>>>>>> 
>>>>>> n=18;m=4;p=0.3;alpha=0.2;beta=2
>>>>>> x=c(3,0,0)
>>>>>> LD<-list()
>>>>>>    for (i in 1:(m-1))  {
>>>>>>    LD[[i]]<-seq(0,x[i],1)
>>>>>>    }
>>>>>>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>>>>>    LED<-expand.grid (LD)
>>>>>>    LED<-as.matrix(LED)
>>>>>>    store1<-numeric(nrow(LED))
>>>>>>     h<- numeric(m-1)
>>>>>>     lm<- numeric(m-1)
>>>>>>      for (j in 1:length(store1) )
>>>>>>          {
>>>>>>             incomb<-function(x,alpha,beta) {
>>>>>> 
>>>>>>  g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>>>>>>                   for (i in 1:(m-1))  {
>>>>>>                        h[i]<- choose(x[i],LED[j,i])
>>>>>>                        }
>>>>>>                  ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])
>>>>>>                 for (i in 1:(m-1)) {
>>>>>>                        lm[i]<-(sum(LED[j,1:i])) + i
>>>>>>                      }
>>>>>>                 plm<-prod(lm)
>>>>>>                gil<-g*ik/(plm)
>>>>>>              hlm<-numeric(sum(LED[j,])+(m-1))
>>>>>>              dsa<-length(hlm)
>>>>>>               for (i in 1:dsa)
>>>>>>                 {
>>>>>>                  ppp<- sum(LED[j,])+(m-1)
>>>>>>                   hlm[i]<-
>>>>>>  (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))
>>>>>>                  }
>>>>>>           shl<-gil*(sum(hlm)+1)
>>>>>>           return (shl)
>>>>>>           }
>>>>>>        store1[j]<-incomb(x,alpha=0.2,beta=2)
>>>>>>       }
>>>>>> 
>>>>>> 
>>>>>> I'm trying to use alternatives (for ex. to vectorize things) to the
>>>>>> explicit for() loops, but things don't work out.
>>>>>> 
>>>>>> Any suggestions that can help me to speed up the execution of the incomb()
>>>>>> function are much appreciated.
>>>>>> 
>>>>>> Thanks a lot in advance.
>>>>>> 
>>>>>> Maram Salem
>>>>>> 
>>>>>>         [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Sun Nov 15 18:21:21 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 15 Nov 2015 12:21:21 -0500
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <1447606959006.93337@jhu.edu>
References: <1447606959006.93337@jhu.edu>
Message-ID: <5648BF11.6060008@gmail.com>

Not contradicting Ravi's message, but I wouldn't say Nelder-Mead is
"bad" per se. It's issues are that it assumes the parameters are all on
the same scale, and the termination (not convergence) test can't use
gradients, so it tends to get "near" the optimum very quickly -- say
only 10% of the computational effort -- then spends an awful amount of
effort deciding it's got there. It often will do poorly when the
function has nearly "flat" zones e.g., long valley with very low slope.

So my message is still that Nelder-Mead is an unfortunate default -- it
has been chosen I believe because it is generally robust and doesn't
need gradients. BFGS really should use accurate gradients, preferably
computed analytically, so it would only be a good default in that case
or with very good approximate gradients (which are costly
computationally).

However, if you understand what NM is doing, and use it accordingly, it
is a valuable tool. I generally use it as a first try BUT turn on the
trace to watch what it is doing as a way to learn a bit about the
function I am minimizing. Rarely would I use it as a production minimizer.

Best, JN

On 15-11-15 12:02 PM, Ravi Varadhan wrote:
> Hi,
> 
>  
> 
> While I agree with the comments about paying attention to parameter
> scaling, a major issue here is that the default optimization algorithm,
> Nelder-Mead, is not very good.  It is unfortunate that the optim
> implementation chose this as the "default" algorithm.  I have several
> instances where people have come to me with poor results from using
> optim(), because they did not realize that the default algorithm is
> bad.  We (John Nash and I) have pointed this out before, but the R core
> has not addressed this issue due to backward compatibility reasons. 
> 
>  
> 
> There is a better implementation of Nelder-Mead in the "dfoptim" package.
> 
>  
> 
> ?require(dfoptim)
> 
> mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
> 
> mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
> 
> mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
> 
> print(mm_def1$par)
> 
> print(mm_def2$par)
> 
> print(mm_def3$par)
> 
>  
> 
> In general, better implementations of optimization algorithms are
> available in packages such as "optimx", "nloptr".  It is unfortunate
> that most na?ve users of optimization in R do not recognize this. 
> Perhaps, there should be a "message" in the optim help file that points
> this out to the users. 
> 
>  
> 
> Hope this is helpful,
> 
> Ravi
> 
>


From milujisb at gmail.com  Sun Nov 15 14:37:33 2015
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 15 Nov 2015 14:37:33 +0100
Subject: [R] Two Time Fixed Effects - LFE package
In-Reply-To: <5647C027.9080306@gmail.com>
References: <CAMLwc7MoW7TP2XhtsY9adDVzaquJY9MYvS_kj6zgueRtQaJqTQ@mail.gmail.com>
	<5647C027.9080306@gmail.com>
Message-ID: <CAMLwc7MvFP6560-CYnFv0GQx18q8NJ6K4XePH_5Uo44zdfHEPg@mail.gmail.com>

Dear Andrew,

Thank you for your reply. Its an R question. The weeks are coded as 1-53
for each year and I would like to control weeks and years as time fixed
effects.

Will this be an issue if I estimate this type of regression using the LFE
package?

felm(outcome ~ temperature + precipitation | city + year + week

Thanks again!

Sincerely,

MS

On Sun, Nov 15, 2015 at 12:13 AM, Andrew Crane-Droesch <andrewcd at gmail.com>
wrote:

> Is this an R question or an econometrics question?  I'll assume that it is
> an R question.  If your weeks are coded sequentially (i.e.: weeks since a
> particular date), then they'll be strictly determined by year.  If however
> you're interested in the effect of a particular week of the year (week 7,
> for example), then you'll need to recode your week variable as a factor
> with 52 levels.  For that you'd likely need the "%%" operator.  For example:
>
> 1> 1:10%%3
>  [1] 1 2 0 1 2 0 1 2 0 1
>
>
>
>
> On 11/14/2015 05:18 PM, Miluji Sb wrote:
>
>> I have weekly panel data for more than a hundred cities. The independent
>> variables are temperature and precipitation. The time dimensions are year
>> and week and likely have time invariant characteristics and are all
>> important for proper estimation.
>>
>> Could I use the LFE (or plm) package to estimate something like this by
>> including the location and two time fixed-effects?
>>
>> felm(outcome ~ temperature + precipitation | city + year + week
>>
>> Thanks!
>>
>> MS
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Sun Nov 15 18:02:52 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sun, 15 Nov 2015 17:02:52 +0000
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
Message-ID: <1447606959006.93337@jhu.edu>

Hi,



While I agree with the comments about paying attention to parameter scaling, a major issue here is that the default optimization algorithm, Nelder-Mead, is not very good.  It is unfortunate that the optim implementation chose this as the "default" algorithm.  I have several instances where people have come to me with poor results from using optim(), because they did not realize that the default algorithm is bad.  We (John Nash and I) have pointed this out before, but the R core has not addressed this issue due to backward compatibility reasons.



There is a better implementation of Nelder-Mead in the "dfoptim" package.



?require(dfoptim)

mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)

mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)

mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)

print(mm_def1$par)

print(mm_def2$par)

print(mm_def3$par)



In general, better implementations of optimization algorithms are available in packages such as "optimx", "nloptr".  It is unfortunate that most na?ve users of optimization in R do not recognize this.  Perhaps, there should be a "message" in the optim help file that points this out to the users.



Hope this is helpful,

Ravi


	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Sun Nov 15 18:46:22 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sun, 15 Nov 2015 17:46:22 +0000
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <5648BF11.6060008@gmail.com>
References: <1447606959006.93337@jhu.edu>,<5648BF11.6060008@gmail.com>
Message-ID: <1447609568414.71131@jhu.edu>

Hi John,
My main point is not about Nelder-Mead per se.  It is *primarily* about the Nelder-Mead implementation in optim().  

The users of optim() should be cautioned regarding the default algorithm and that they should consider alternatives such as "BFGS" in optim(), or other implementations of Nelder-Mead.

Best regards,
Ravi
________________________________________
From: ProfJCNash <profjcnash at gmail.com>
Sent: Sunday, November 15, 2015 12:21 PM
To: Ravi Varadhan; 'r-help at r-project.org'; lorenzo.isella at gmail.com
Cc: bhh at xs4all.nl; Gabor Grothendieck
Subject: Re: Cautioning optim() users about "Nelder-Mead" default - (originally) Optim instability

Not contradicting Ravi's message, but I wouldn't say Nelder-Mead is
"bad" per se. It's issues are that it assumes the parameters are all on
the same scale, and the termination (not convergence) test can't use
gradients, so it tends to get "near" the optimum very quickly -- say
only 10% of the computational effort -- then spends an awful amount of
effort deciding it's got there. It often will do poorly when the
function has nearly "flat" zones e.g., long valley with very low slope.

So my message is still that Nelder-Mead is an unfortunate default -- it
has been chosen I believe because it is generally robust and doesn't
need gradients. BFGS really should use accurate gradients, preferably
computed analytically, so it would only be a good default in that case
or with very good approximate gradients (which are costly
computationally).

However, if you understand what NM is doing, and use it accordingly, it
is a valuable tool. I generally use it as a first try BUT turn on the
trace to watch what it is doing as a way to learn a bit about the
function I am minimizing. Rarely would I use it as a production minimizer.

Best, JN

On 15-11-15 12:02 PM, Ravi Varadhan wrote:
> Hi,
>
>
>
> While I agree with the comments about paying attention to parameter
> scaling, a major issue here is that the default optimization algorithm,
> Nelder-Mead, is not very good.  It is unfortunate that the optim
> implementation chose this as the "default" algorithm.  I have several
> instances where people have come to me with poor results from using
> optim(), because they did not realize that the default algorithm is
> bad.  We (John Nash and I) have pointed this out before, but the R core
> has not addressed this issue due to backward compatibility reasons.
>
>
>
> There is a better implementation of Nelder-Mead in the "dfoptim" package.
>
>
>
> ?require(dfoptim)
>
> mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
>
> mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
>
> mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
>
> print(mm_def1$par)
>
> print(mm_def2$par)
>
> print(mm_def3$par)
>
>
>
> In general, better implementations of optimization algorithms are
> available in packages such as "optimx", "nloptr".  It is unfortunate
> that most na?ve users of optimization in R do not recognize this.
> Perhaps, there should be a "message" in the optim help file that points
> this out to the users.
>
>
>
> Hope this is helpful,
>
> Ravi
>
>


From profjcnash at gmail.com  Sun Nov 15 20:41:35 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Sun, 15 Nov 2015 14:41:35 -0500
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <1447609568414.71131@jhu.edu>
References: <1447606959006.93337@jhu.edu> <5648BF11.6060008@gmail.com>
	<1447609568414.71131@jhu.edu>
Message-ID: <5648DFEF.9000402@gmail.com>

Agreed on the default algorithm issue. That is important for users to
know, and I'm happy to underline it. Also that CG (which is based on one
of my codes) should be deprecated. BFGS (also based on one of my codes
from long ago) does much better than I would ever have expected.

Over the years I've tried different Nelder-Mead implementations. Cannot
say I've found any that is always better than that in optim() (also
based on an old code of mine), though nmkb() from dfoptim package seems
to do better a lot of the time, and it has a transformation method for
bounds, which may be useful, but does have the awkwardness that one
cannot start on a bound. For testing a function, I don't think it makes
a lot of difference which variant of NM one uses if the trace is on to
catch never-ending runs. For production use, it is a really good idea to
try different methods on a sample of likely cases and choose a method
that does well. That is the motivation for the optimx package or the
opm() function of the newer optimz (on R-forge) that I'm still
polishing. optimz has a function optimr() that has the same call as
optim() but incorporates over a dozen optimizers via method = "(selected
method)".

As a gradient-free choice, the Powell codes from minqa or other packages
(there are several implementations) can sometimes have spectacular
performance, but they also flub rather more regularly than Nelder-Mead
in my experience. That is, when they are good, they are very very good,
and when they are not they are horrid. (Plagiarism!)

JN

On 15-11-15 12:46 PM, Ravi Varadhan wrote:
> Hi John,
> My main point is not about Nelder-Mead per se.  It is *primarily* about the Nelder-Mead implementation in optim().  
> 
> The users of optim() should be cautioned regarding the default algorithm and that they should consider alternatives such as "BFGS" in optim(), or other implementations of Nelder-Mead.
> 
> Best regards,
> Ravi
> ________________________________________
> From: ProfJCNash <profjcnash at gmail.com>
> Sent: Sunday, November 15, 2015 12:21 PM
> To: Ravi Varadhan; 'r-help at r-project.org'; lorenzo.isella at gmail.com
> Cc: bhh at xs4all.nl; Gabor Grothendieck
> Subject: Re: Cautioning optim() users about "Nelder-Mead" default - (originally) Optim instability
> 
> Not contradicting Ravi's message, but I wouldn't say Nelder-Mead is
> "bad" per se. It's issues are that it assumes the parameters are all on
> the same scale, and the termination (not convergence) test can't use
> gradients, so it tends to get "near" the optimum very quickly -- say
> only 10% of the computational effort -- then spends an awful amount of
> effort deciding it's got there. It often will do poorly when the
> function has nearly "flat" zones e.g., long valley with very low slope.
> 
> So my message is still that Nelder-Mead is an unfortunate default -- it
> has been chosen I believe because it is generally robust and doesn't
> need gradients. BFGS really should use accurate gradients, preferably
> computed analytically, so it would only be a good default in that case
> or with very good approximate gradients (which are costly
> computationally).
> 
> However, if you understand what NM is doing, and use it accordingly, it
> is a valuable tool. I generally use it as a first try BUT turn on the
> trace to watch what it is doing as a way to learn a bit about the
> function I am minimizing. Rarely would I use it as a production minimizer.
> 
> Best, JN
> 
> On 15-11-15 12:02 PM, Ravi Varadhan wrote:
>> Hi,
>>
>>
>>
>> While I agree with the comments about paying attention to parameter
>> scaling, a major issue here is that the default optimization algorithm,
>> Nelder-Mead, is not very good.  It is unfortunate that the optim
>> implementation chose this as the "default" algorithm.  I have several
>> instances where people have come to me with poor results from using
>> optim(), because they did not realize that the default algorithm is
>> bad.  We (John Nash and I) have pointed this out before, but the R core
>> has not addressed this issue due to backward compatibility reasons.
>>
>>
>>
>> There is a better implementation of Nelder-Mead in the "dfoptim" package.
>>
>>
>>
>> ?require(dfoptim)
>>
>> mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
>>
>> mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
>>
>> mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
>>
>> print(mm_def1$par)
>>
>> print(mm_def2$par)
>>
>> print(mm_def3$par)
>>
>>
>>
>> In general, better implementations of optimization algorithms are
>> available in packages such as "optimx", "nloptr".  It is unfortunate
>> that most na?ve users of optimization in R do not recognize this.
>> Perhaps, there should be a "message" in the optim help file that points
>> this out to the users.
>>
>>
>>
>> Hope this is helpful,
>>
>> Ravi
>>
>>
>


From markleeds2 at gmail.com  Sun Nov 15 21:05:12 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Sun, 15 Nov 2015 15:05:12 -0500
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <5648DFEF.9000402@gmail.com>
References: <1447606959006.93337@jhu.edu> <5648BF11.6060008@gmail.com>
	<1447609568414.71131@jhu.edu> <5648DFEF.9000402@gmail.com>
Message-ID: <CAHz+bWZbZ9cw5kHOGMsEuNCYmXWAu_iMX-HAqx09927mJcX86w@mail.gmail.com>

and just to add to john's comments, since he's too modest, in my
experience,  the algorithm in the rvmmin  package ( written by john ) shows
great improvement compared to the L-BFGS-B  algorithm so I don't use
L-BFGS-B anymore.  L-BFGS-B often has a dangerous convergence issue  in
that it can claim to converge when it hasn't. which, to
me is worse than not converging.  Most likely it has to do with the link
below which was pointed out to me by john a while back.

http://www.ece.northwestern.edu/~morales/PSfiles/acm-remark.pdf


On Sun, Nov 15, 2015 at 2:41 PM, ProfJCNash <profjcnash at gmail.com> wrote:

> Agreed on the default algorithm issue. That is important for users to
> know, and I'm happy to underline it. Also that CG (which is based on one
> of my codes) should be deprecated. BFGS (also based on one of my codes
> from long ago) does much better than I would ever have expected.
>
> Over the years I've tried different Nelder-Mead implementations. Cannot
> say I've found any that is always better than that in optim() (also
> based on an old code of mine), though nmkb() from dfoptim package seems
> to do better a lot of the time, and it has a transformation method for
> bounds, which may be useful, but does have the awkwardness that one
> cannot start on a bound. For testing a function, I don't think it makes
> a lot of difference which variant of NM one uses if the trace is on to
> catch never-ending runs. For production use, it is a really good idea to
> try different methods on a sample of likely cases and choose a method
> that does well. That is the motivation for the optimx package or the
> opm() function of the newer optimz (on R-forge) that I'm still
> polishing. optimz has a function optimr() that has the same call as
> optim() but incorporates over a dozen optimizers via method = "(selected
> method)".
>
> As a gradient-free choice, the Powell codes from minqa or other packages
> (there are several implementations) can sometimes have spectacular
> performance, but they also flub rather more regularly than Nelder-Mead
> in my experience. That is, when they are good, they are very very good,
> and when they are not they are horrid. (Plagiarism!)
>
> JN
>
> On 15-11-15 12:46 PM, Ravi Varadhan wrote:
> > Hi John,
> > My main point is not about Nelder-Mead per se.  It is *primarily* about
> the Nelder-Mead implementation in optim().
> >
> > The users of optim() should be cautioned regarding the default algorithm
> and that they should consider alternatives such as "BFGS" in optim(), or
> other implementations of Nelder-Mead.
> >
> > Best regards,
> > Ravi
> > ________________________________________
> > From: ProfJCNash <profjcnash at gmail.com>
> > Sent: Sunday, November 15, 2015 12:21 PM
> > To: Ravi Varadhan; 'r-help at r-project.org'; lorenzo.isella at gmail.com
> > Cc: bhh at xs4all.nl; Gabor Grothendieck
> > Subject: Re: Cautioning optim() users about "Nelder-Mead" default -
> (originally) Optim instability
> >
> > Not contradicting Ravi's message, but I wouldn't say Nelder-Mead is
> > "bad" per se. It's issues are that it assumes the parameters are all on
> > the same scale, and the termination (not convergence) test can't use
> > gradients, so it tends to get "near" the optimum very quickly -- say
> > only 10% of the computational effort -- then spends an awful amount of
> > effort deciding it's got there. It often will do poorly when the
> > function has nearly "flat" zones e.g., long valley with very low slope.
> >
> > So my message is still that Nelder-Mead is an unfortunate default -- it
> > has been chosen I believe because it is generally robust and doesn't
> > need gradients. BFGS really should use accurate gradients, preferably
> > computed analytically, so it would only be a good default in that case
> > or with very good approximate gradients (which are costly
> > computationally).
> >
> > However, if you understand what NM is doing, and use it accordingly, it
> > is a valuable tool. I generally use it as a first try BUT turn on the
> > trace to watch what it is doing as a way to learn a bit about the
> > function I am minimizing. Rarely would I use it as a production
> minimizer.
> >
> > Best, JN
> >
> > On 15-11-15 12:02 PM, Ravi Varadhan wrote:
> >> Hi,
> >>
> >>
> >>
> >> While I agree with the comments about paying attention to parameter
> >> scaling, a major issue here is that the default optimization algorithm,
> >> Nelder-Mead, is not very good.  It is unfortunate that the optim
> >> implementation chose this as the "default" algorithm.  I have several
> >> instances where people have come to me with poor results from using
> >> optim(), because they did not realize that the default algorithm is
> >> bad.  We (John Nash and I) have pointed this out before, but the R core
> >> has not addressed this issue due to backward compatibility reasons.
> >>
> >>
> >>
> >> There is a better implementation of Nelder-Mead in the "dfoptim"
> package.
> >>
> >>
> >>
> >> ?require(dfoptim)
> >>
> >> mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
> >>
> >> mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
> >>
> >> mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
> >>
> >> print(mm_def1$par)
> >>
> >> print(mm_def2$par)
> >>
> >> print(mm_def3$par)
> >>
> >>
> >>
> >> In general, better implementations of optimization algorithms are
> >> available in packages such as "optimx", "nloptr".  It is unfortunate
> >> that most na?ve users of optimization in R do not recognize this.
> >> Perhaps, there should be a "message" in the optim help file that points
> >> this out to the users.
> >>
> >>
> >>
> >> Hope this is helpful,
> >>
> >> Ravi
> >>
> >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Nov 15 22:16:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 16 Nov 2015 10:16:20 +1300
Subject: [R] OT, apropos of nothing ....
Message-ID: <5648F624.6010803@auckland.ac.nz>


In respect of Bert Gunter's signature quote:

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."

The other day my wife saw a grocery truck with the following remark 
emblazoned on its side:

"Knowledge is being aware that a tomato is a fruit.  Wisdom is 
refraining from putting tomatoes in a fruit salad."

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From frainj at gmail.com  Sun Nov 15 22:31:33 2015
From: frainj at gmail.com (John C Frain)
Date: Sun, 15 Nov 2015 21:31:33 +0000
Subject: [R] Cautioning optim() users about "Nelder-Mead" default -
 (originally) Optim instability
In-Reply-To: <CAHz+bWZbZ9cw5kHOGMsEuNCYmXWAu_iMX-HAqx09927mJcX86w@mail.gmail.com>
References: <1447606959006.93337@jhu.edu> <5648BF11.6060008@gmail.com>
	<1447609568414.71131@jhu.edu> <5648DFEF.9000402@gmail.com>
	<CAHz+bWZbZ9cw5kHOGMsEuNCYmXWAu_iMX-HAqx09927mJcX86w@mail.gmail.com>
Message-ID: <CAHrK515O+5S1shutgPFQxnVnwSxNyzTTqfYiE3L+bro0h8CS1g@mail.gmail.com>

In econometrics it was common to start an optimization with Nelder-Mead and
then switch to one of the other algorithms to finish the optimization. As
John Nash states NM gets one close. switching then speeds the final
solution.

John

John C Frain
3 Aranleigh Park
Rathfarnham
Dublin 14
Ireland
www.tcd.ie/Economics/staff/frainj/home.html
mailto:frainj at tcd.ie
mailto:frainj at gmail.com

On 15 November 2015 at 20:05, Mark Leeds <markleeds2 at gmail.com> wrote:

> and just to add to john's comments, since he's too modest, in my
> experience,  the algorithm in the rvmmin  package ( written by john ) shows
> great improvement compared to the L-BFGS-B  algorithm so I don't use
> L-BFGS-B anymore.  L-BFGS-B often has a dangerous convergence issue  in
> that it can claim to converge when it hasn't. which, to
> me is worse than not converging.  Most likely it has to do with the link
> below which was pointed out to me by john a while back.
>
> http://www.ece.northwestern.edu/~morales/PSfiles/acm-remark.pdf
>
>
> On Sun, Nov 15, 2015 at 2:41 PM, ProfJCNash <profjcnash at gmail.com> wrote:
>
> > Agreed on the default algorithm issue. That is important for users to
> > know, and I'm happy to underline it. Also that CG (which is based on one
> > of my codes) should be deprecated. BFGS (also based on one of my codes
> > from long ago) does much better than I would ever have expected.
> >
> > Over the years I've tried different Nelder-Mead implementations. Cannot
> > say I've found any that is always better than that in optim() (also
> > based on an old code of mine), though nmkb() from dfoptim package seems
> > to do better a lot of the time, and it has a transformation method for
> > bounds, which may be useful, but does have the awkwardness that one
> > cannot start on a bound. For testing a function, I don't think it makes
> > a lot of difference which variant of NM one uses if the trace is on to
> > catch never-ending runs. For production use, it is a really good idea to
> > try different methods on a sample of likely cases and choose a method
> > that does well. That is the motivation for the optimx package or the
> > opm() function of the newer optimz (on R-forge) that I'm still
> > polishing. optimz has a function optimr() that has the same call as
> > optim() but incorporates over a dozen optimizers via method = "(selected
> > method)".
> >
> > As a gradient-free choice, the Powell codes from minqa or other packages
> > (there are several implementations) can sometimes have spectacular
> > performance, but they also flub rather more regularly than Nelder-Mead
> > in my experience. That is, when they are good, they are very very good,
> > and when they are not they are horrid. (Plagiarism!)
> >
> > JN
> >
> > On 15-11-15 12:46 PM, Ravi Varadhan wrote:
> > > Hi John,
> > > My main point is not about Nelder-Mead per se.  It is *primarily* about
> > the Nelder-Mead implementation in optim().
> > >
> > > The users of optim() should be cautioned regarding the default
> algorithm
> > and that they should consider alternatives such as "BFGS" in optim(), or
> > other implementations of Nelder-Mead.
> > >
> > > Best regards,
> > > Ravi
> > > ________________________________________
> > > From: ProfJCNash <profjcnash at gmail.com>
> > > Sent: Sunday, November 15, 2015 12:21 PM
> > > To: Ravi Varadhan; 'r-help at r-project.org'; lorenzo.isella at gmail.com
> > > Cc: bhh at xs4all.nl; Gabor Grothendieck
> > > Subject: Re: Cautioning optim() users about "Nelder-Mead" default -
> > (originally) Optim instability
> > >
> > > Not contradicting Ravi's message, but I wouldn't say Nelder-Mead is
> > > "bad" per se. It's issues are that it assumes the parameters are all on
> > > the same scale, and the termination (not convergence) test can't use
> > > gradients, so it tends to get "near" the optimum very quickly -- say
> > > only 10% of the computational effort -- then spends an awful amount of
> > > effort deciding it's got there. It often will do poorly when the
> > > function has nearly "flat" zones e.g., long valley with very low slope.
> > >
> > > So my message is still that Nelder-Mead is an unfortunate default -- it
> > > has been chosen I believe because it is generally robust and doesn't
> > > need gradients. BFGS really should use accurate gradients, preferably
> > > computed analytically, so it would only be a good default in that case
> > > or with very good approximate gradients (which are costly
> > > computationally).
> > >
> > > However, if you understand what NM is doing, and use it accordingly, it
> > > is a valuable tool. I generally use it as a first try BUT turn on the
> > > trace to watch what it is doing as a way to learn a bit about the
> > > function I am minimizing. Rarely would I use it as a production
> > minimizer.
> > >
> > > Best, JN
> > >
> > > On 15-11-15 12:02 PM, Ravi Varadhan wrote:
> > >> Hi,
> > >>
> > >>
> > >>
> > >> While I agree with the comments about paying attention to parameter
> > >> scaling, a major issue here is that the default optimization
> algorithm,
> > >> Nelder-Mead, is not very good.  It is unfortunate that the optim
> > >> implementation chose this as the "default" algorithm.  I have several
> > >> instances where people have come to me with poor results from using
> > >> optim(), because they did not realize that the default algorithm is
> > >> bad.  We (John Nash and I) have pointed this out before, but the R
> core
> > >> has not addressed this issue due to backward compatibility reasons.
> > >>
> > >>
> > >>
> > >> There is a better implementation of Nelder-Mead in the "dfoptim"
> > package.
> > >>
> > >>
> > >>
> > >> ?require(dfoptim)
> > >>
> > >> mm_def1 <- nmk(par = par_ini1, min.perc_error, data = data)
> > >>
> > >> mm_def2 <- nmk(par = par_ini2, min.perc_error, data = data)
> > >>
> > >> mm_def3 <- nmk(par = par_ini3, min.perc_error, data = data)
> > >>
> > >> print(mm_def1$par)
> > >>
> > >> print(mm_def2$par)
> > >>
> > >> print(mm_def3$par)
> > >>
> > >>
> > >>
> > >> In general, better implementations of optimization algorithms are
> > >> available in packages such as "optimx", "nloptr".  It is unfortunate
> > >> that most na?ve users of optimization in R do not recognize this.
> > >> Perhaps, there should be a "message" in the optim help file that
> points
> > >> this out to the users.
> > >>
> > >>
> > >>
> > >> Hope this is helpful,
> > >>
> > >> Ravi
> > >>
> > >>
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Mon Nov 16 03:22:42 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Sun, 15 Nov 2015 21:22:42 -0500
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
Message-ID: <56493DF2.8020404@cognigencorp.com>

Hi,

Pretty much everything is in the title of the post. An example is below.

library(lattice)
data <- 
data.frame(x=rep(1:10,8),y=rnorm(80),trt=factor(rep(1:4,each=20)),groups=rep(1:8,each=10))
xyplot <- xyplot(y~x|trt,data,groups=groups)

is.numeric.factor <- function(){
   print('hello world')
}

xyplot <- xyplot(y~x|trt,data,groups=groups)

Thanks for shedding some light on this.


From bgunter.4567 at gmail.com  Mon Nov 16 03:42:44 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 15 Nov 2015 18:42:44 -0800
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
In-Reply-To: <56493DF2.8020404@cognigencorp.com>
References: <56493DF2.8020404@cognigencorp.com>
Message-ID: <CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>

Think about it.

I shall assume that you are familiar with S3 methods.  What do you
think would happen when xyplot code calls is.numeric() on a factor
object expecting it to call the is.numeric primitive but, instead,
finding a factor method defined, calls that? Note that your factor
method has no arguments, but the is.numeric() primitive does. Hence
when the code calls the primitive on the factor object, the error you
saw is thrown.

I would say that this is a weakness of the informal S3 "class" system,
although you probably should not have been surprised that is.numeric
is called on factors as the "x" argument, so you were inviting trouble
by defining a factor method that overrides this behavior.
Nevertheless, I would argue that one cannot know in general when this
occurs for other S3 classes, and that therefore allowing methods for
is.numeric() is dangerous.

Of course, full qualification in the original xyplot code
(base::is.numeric() rather than is.numeric() ) would avoid such
things, but that's a drag.

Contrary opinions and corrections to any flawed understanding on my
part are welcome, of course.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sun, Nov 15, 2015 at 6:22 PM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Hi,
>
> Pretty much everything is in the title of the post. An example is below.
>
> library(lattice)
> data <-
> data.frame(x=rep(1:10,8),y=rnorm(80),trt=factor(rep(1:4,each=20)),groups=rep(1:8,each=10))
> xyplot <- xyplot(y~x|trt,data,groups=groups)
>
> is.numeric.factor <- function(){
>   print('hello world')
> }
>
> xyplot <- xyplot(y~x|trt,data,groups=groups)
>
> Thanks for shedding some light on this.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Nov 16 03:56:55 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 15 Nov 2015 18:56:55 -0800
Subject: [R] Why does a custom function called is.numeric.factor
	break	lattice?
In-Reply-To: <56493DF2.8020404@cognigencorp.com>
References: <56493DF2.8020404@cognigencorp.com>
Message-ID: <1A1D3CB9-6520-4BC6-A2D4-69FEA567EB2A@dcn.davis.CA.us>

You need to read about S3 classes, and either make your custom function behave the way that function needs to behave or use a different function name for your custom function.

I think this is an example of the old saying that if it hurts when you slam your head against the wall, then don't do that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 15, 2015 6:22:42 PM PST, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Hi,
>
>Pretty much everything is in the title of the post. An example is
>below.
>
>library(lattice)
>data <- 
>data.frame(x=rep(1:10,8),y=rnorm(80),trt=factor(rep(1:4,each=20)),groups=rep(1:8,each=10))
>xyplot <- xyplot(y~x|trt,data,groups=groups)
>
>is.numeric.factor <- function(){
>   print('hello world')
>}
>
>xyplot <- xyplot(y~x|trt,data,groups=groups)
>
>Thanks for shedding some light on this.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Nov 16 05:28:02 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Nov 2015 04:28:02 +0000
Subject: [R] Ranking
In-Reply-To: <CADDFq31z_9b_HY5bMcXPpW+Cp2BpLxcCZmAg9yXpPMjMxu90uw@mail.gmail.com>
References: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD380@mb02.ads.tamu.edu>,
	<CADDFq31z_9b_HY5bMcXPpW+Cp2BpLxcCZmAg9yXpPMjMxu90uw@mail.gmail.com>
Message-ID: <ura1gybsxv4gxsg9cvwmebfm.1447648076043@email.android.com>

I used your code but deleted sep="\t" since there were no tabs in your email and added the fill= argument I mentioned before.



David



-------- Original message --------
From: Ashta <sewashm at gmail.com>
Date: 11/14/2015 6:40 PM (GMT-06:00)
To: David L Carlson <dcarlson at tamu.edu>
Cc: R help <r-help at r-project.org>
Subject: Re: [R] Ranking

Thank you David,

My intention was if I change the status column  to numeric
0= Lost and 1 Won, then I can use this numeric variables  to calculate
the  Percent game Won by each country.
how did you read the data first?
That was my problem.   The actual data is in a file have to be read or laded.

Thank you !






On Sat, Nov 14, 2015 at 6:10 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> It is always good to read the manual page for a function, but especially when it is not working as you expected. In this case if you look at the arguments for read.table(), you will find one called fill=TRUE that is useful in this case.
>
> Based on your ifelse(), you seem to be assuming that a blank is not missing data but a lost game. You may also discover that in your example wins are coded as w and W.  Since character variables get converted to factors by default, you could use something like:
>
>> levels(test$STATUS) <- c("L", "W", "W")
>> addmargins(xtabs(~Country+STATUS, test), 2)
>        STATUS
> Country L W Sum
>     FRA 2 3   5
>     GER 1 3   4
>     SPA 2 1   3
>     UNK 1 2   3
>     USA 1 2   3
>
> I'll let you figure out how to get the last column.
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
> Sent: Saturday, November 14, 2015 4:28 PM
> To: R help <r-help at r-project.org>
> Subject: [R] Ranking
>
> Hi all,
>
> I have the following raw data some records  don't have the second variable.
>
> test <- read.table(textConnection(" Country  STATUS
> USA
> USA    W
> USA    W
> GER
> GER    W
> GER    w
> GER    W
> UNK    W
> UNK
> UNK    W
> FRA
> FRA
> FRA    W
> FRA    W
> FRA    W
> SPA
> SPA    W
> SPA          "),header = TRUE,  sep= "\t")
> test
>
> It is not reading it correctly.
>
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   line 17 did not have 2 elements
>
>
>
> After reading   I want change the status column  to numeric so that I
> can use the table function
>
> test$STATUS <- ifelse(is.na(test$STATUS), 0,  1)
>
> at the end I want the following table (Country, Won, Lost , Number of
> games played and % of score ) and pick the top 3 countries.
>
> COUNTRY   Won   Lost   NG    %W
>  USA             2        1         3      (2/3)*100
>  GER             3        1         4      (3/4)*100
>  UNK             2        1         3      (2/3)*100
>  FRA             3         2        5      (3/5)*100
>  SPA             1         2         3      (1/3)*100
>
> Thank you in  advance
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 16 06:17:58 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 15 Nov 2015 21:17:58 -0800
Subject: [R] Ranking
In-Reply-To: <ura1gybsxv4gxsg9cvwmebfm.1447648076043@email.android.com>
References: <CADDFq33HqGurwMstDJjiw4zr9shHVLA0AhpELv4oS2ADqjFMpw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6DD380@mb02.ads.tamu.edu>
	<CADDFq31z_9b_HY5bMcXPpW+Cp2BpLxcCZmAg9yXpPMjMxu90uw@mail.gmail.com>
	<ura1gybsxv4gxsg9cvwmebfm.1447648076043@email.android.com>
Message-ID: <CAGxFJbRBQ0fn_nZH=mG=ni=0n4sw3Ln=L+c=H0St4cgnS_Jgqg@mail.gmail.com>

It is perhaps worth mentioning that the OP's desire to do the
conversion to numeric to calculate won-lost percentages is completely
unnecessary and indicates that he/she could benefit by spending some
additional time learning R. See, e.g. ?tapply, ?table, ?prop.table,
and friends.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sun, Nov 15, 2015 at 8:28 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> I used your code but deleted sep="\t" since there were no tabs in your email and added the fill= argument I mentioned before.
>
>
>
> David
>
>
>
> -------- Original message --------
> From: Ashta <sewashm at gmail.com>
> Date: 11/14/2015 6:40 PM (GMT-06:00)
> To: David L Carlson <dcarlson at tamu.edu>
> Cc: R help <r-help at r-project.org>
> Subject: Re: [R] Ranking
>
> Thank you David,
>
> My intention was if I change the status column  to numeric
> 0= Lost and 1 Won, then I can use this numeric variables  to calculate
> the  Percent game Won by each country.
> how did you read the data first?
> That was my problem.   The actual data is in a file have to be read or laded.
>
> Thank you !
>
>
>
>
>
>
> On Sat, Nov 14, 2015 at 6:10 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> It is always good to read the manual page for a function, but especially when it is not working as you expected. In this case if you look at the arguments for read.table(), you will find one called fill=TRUE that is useful in this case.
>>
>> Based on your ifelse(), you seem to be assuming that a blank is not missing data but a lost game. You may also discover that in your example wins are coded as w and W.  Since character variables get converted to factors by default, you could use something like:
>>
>>> levels(test$STATUS) <- c("L", "W", "W")
>>> addmargins(xtabs(~Country+STATUS, test), 2)
>>        STATUS
>> Country L W Sum
>>     FRA 2 3   5
>>     GER 1 3   4
>>     SPA 2 1   3
>>     UNK 1 2   3
>>     USA 1 2   3
>>
>> I'll let you figure out how to get the last column.
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>> Sent: Saturday, November 14, 2015 4:28 PM
>> To: R help <r-help at r-project.org>
>> Subject: [R] Ranking
>>
>> Hi all,
>>
>> I have the following raw data some records  don't have the second variable.
>>
>> test <- read.table(textConnection(" Country  STATUS
>> USA
>> USA    W
>> USA    W
>> GER
>> GER    W
>> GER    w
>> GER    W
>> UNK    W
>> UNK
>> UNK    W
>> FRA
>> FRA
>> FRA    W
>> FRA    W
>> FRA    W
>> SPA
>> SPA    W
>> SPA          "),header = TRUE,  sep= "\t")
>> test
>>
>> It is not reading it correctly.
>>
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>>   line 17 did not have 2 elements
>>
>>
>>
>> After reading   I want change the status column  to numeric so that I
>> can use the table function
>>
>> test$STATUS <- ifelse(is.na(test$STATUS), 0,  1)
>>
>> at the end I want the following table (Country, Won, Lost , Number of
>> games played and % of score ) and pick the top 3 countries.
>>
>> COUNTRY   Won   Lost   NG    %W
>>  USA             2        1         3      (2/3)*100
>>  GER             3        1         4      (3/4)*100
>>  UNK             2        1         3      (2/3)*100
>>  FRA             3         2        5      (3/5)*100
>>  SPA             1         2         3      (1/3)*100
>>
>> Thank you in  advance
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Mon Nov 16 08:49:59 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 16 Nov 2015 09:49:59 +0200
Subject: [R] linear model solving
Message-ID: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>

Dear group
IF I had an objective function and some constrains formed in linear model form. is there a way,..library in R that helps me to solve such amodel and find the unknown variable in it?

thanks in advance
Ragia 		 	   		  

From r.turner at auckland.ac.nz  Mon Nov 16 09:55:18 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 16 Nov 2015 21:55:18 +1300
Subject: [R] linear model solving
In-Reply-To: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>
References: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>
Message-ID: <564999F6.2030003@auckland.ac.nz>

On 16/11/15 20:49, Ragia Ibrahim wrote:
> Dear group IF I had an objective function and some constrains formed
> in linear model form. is there a way,..library in R that helps me to
> solve such amodel and find the unknown variable in it?


This is a very ill-posed question and is unlikely to provoke any useful 
responses.  If you can't make the effort to ask a clear, precise 
question, why should anyone make the effort to try to answer you?  Even 
if they *could* answer you.  Which they can't.

(a) Frame a proper question, providing a minimal reproducible example.

(b) Do some googling; don't expect others to do your work for you.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From Sebastien.Bihorel at cognigencorp.com  Mon Nov 16 14:00:49 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Mon, 16 Nov 2015 08:00:49 -0500
Subject: [R] Why does a custom function called is.numeric.factor break
 lattice?
In-Reply-To: <CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
Message-ID: <5649D381.6070402@cognigencorp.com>

Hi,

Interesting, based upon my understanding of S3 methods, I would have 
assumed that my function would be applied to objects of class 
"numeric.factor". I was not aware of this multiple "dispatch".

Thanks for pointing this out.


On 11/15/2015 9:42 PM, Bert Gunter wrote:
> Think about it.
>
> I shall assume that you are familiar with S3 methods.  What do you
> think would happen when xyplot code calls is.numeric() on a factor
> object expecting it to call the is.numeric primitive but, instead,
> finding a factor method defined, calls that? Note that your factor
> method has no arguments, but the is.numeric() primitive does. Hence
> when the code calls the primitive on the factor object, the error you
> saw is thrown.
>
> I would say that this is a weakness of the informal S3 "class" system,
> although you probably should not have been surprised that is.numeric
> is called on factors as the "x" argument, so you were inviting trouble
> by defining a factor method that overrides this behavior.
> Nevertheless, I would argue that one cannot know in general when this
> occurs for other S3 classes, and that therefore allowing methods for
> is.numeric() is dangerous.
>
> Of course, full qualification in the original xyplot code
> (base::is.numeric() rather than is.numeric() ) would avoid such
> things, but that's a drag.
>
> Contrary opinions and corrections to any flawed understanding on my
> part are welcome, of course.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>     -- Clifford Stoll
>
>
> On Sun, Nov 15, 2015 at 6:22 PM, sbihorel
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>>
>> Pretty much everything is in the title of the post. An example is below.
>>
>> library(lattice)
>> data <-
>> data.frame(x=rep(1:10,8),y=rnorm(80),trt=factor(rep(1:4,each=20)),groups=rep(1:8,each=10))
>> xyplot <- xyplot(y~x|trt,data,groups=groups)
>>
>> is.numeric.factor <- function(){
>>    print('hello world')
>> }
>>
>> xyplot <- xyplot(y~x|trt,data,groups=groups)
>>
>> Thanks for shedding some light on this.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Nov 16 14:40:41 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 16 Nov 2015 07:40:41 -0600
Subject: [R] Error survreg: Density function returned an an invalid
	matrix
In-Reply-To: <mailman.7.1447498802.21143.r-help@r-project.org>
References: <mailman.7.1447498802.21143.r-help@r-project.org>
Message-ID: <c10f8b$1s3dc1@ironport10.mayo.edu>

The error message states that there is an invalid value for the density.  A long stretch 
of code is not very helpful in understanding this.  What we need are the definition of 
your density -- as it would be written in a textbook.  This formula needs to give a valid 
response for the range -infinity to +infinity.  Or more precisely, for any value that the 
maximizer might guess at some point during the iteration.

Terry T.


On 11/14/2015 05:00 AM, r-help-request at r-project.org wrote:
> Thanks Terry but the error persists. See:
>
>> >library(foreign)> library(survival)> library(VGAM) > mypareto <- list(name='Pareto',+                  init=

remainder of message trucated


From isra4884 at gmail.com  Mon Nov 16 15:56:43 2015
From: isra4884 at gmail.com (Israel Ortiz)
Date: Mon, 16 Nov 2015 08:56:43 -0600
Subject: [R] Error survreg: Density function returned an an invalid
	matrix
In-Reply-To: <c10f8b$1s3dc0@ironport10.mayo.edu>
References: <mailman.7.1447498802.21143.r-help@r-project.org>
	<c10f8b$1s3dc0@ironport10.mayo.edu>
Message-ID: <CAMESY2gkLx1VCceWON17cCRa1BGuqgsO4Vv+pr6zuaOtn07+4A@mail.gmail.com>

Thanks Terry, I use the following formula for density:

[image: f_X(x)= \begin{cases} \frac{\alpha
x_\mathrm{m}^\alpha}{x^{\alpha+1}} & x \ge x_\mathrm{m}, \\ 0 & x <
x_\mathrm{m}. \end{cases}]

Where *x*m is the minimum value for x. I get this f?rmula in
https://en.wikipedia.org/wiki/Pareto_distribution but there are a lot of
books and sites that use the same f?rmula. This part of the code use that
formula:

 distribution <- function(x, alpha) ifelse(x > min(x) ,
alpha*min(x)**alpha/(x**(alpha+1)), 0)

Also, I support my sintax in the following post:

http://stats.stackexchange.com/questions/78168/how-to-know-if-my-data-fits-pareto-distribution

Another option is transform my variable for time from pareto to exponential
(but this solution it's not very elegant):

If X is pareto distributed then
[image: Y = \log\left(\frac{X}{x_\mathrm{m}}\right)]

it's exponential distributed.

The syntax:

library(foreign)
library(survival)
library(VGAM)

set.seed(3)
X <- rpareto(n=100, scale = 5,shape =  1)

Y <- log(X/min(X))

hist(X,breaks=100)
hist(Y,breaks=100)
b <- rnorm(100,5,1)
c <- rep(1,100)
base <- cbind.data.frame(X,Y,b,c)
mod1<-survreg(Surv(Y+1, c) ~ b, base, dist = "exponential")# +1 it's
because time should be > 1

summary(mod1)

This solution works but I don?t like it.

Thanks.




2015-11-16 7:40 GMT-06:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu>:

> The error message states that there is an invalid value for the density.
> A long stretch of code is not very helpful in understanding this.  What we
> need are the definition of your density -- as it would be written in a
> textbook.  This formula needs to give a valid response for the range
> -infinity to +infinity.  Or more precisely, for any value that the
> maximizer might guess at some point during the iteration.
>
> Terry T.
>
>
> On 11/14/2015 05:00 AM, r-help-request at r-project.org wrote:
>
>> Thanks Terry but the error persists. See:
>>
>> >library(foreign)> library(survival)> library(VGAM) > mypareto <-
>>> list(name='Pareto',+                  init=
>>>
>>
> remainder of message trucated
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 16 16:22:30 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 Nov 2015 07:22:30 -0800
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
In-Reply-To: <5649D381.6070402@cognigencorp.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
Message-ID: <CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>

There is no multiple dispatch; just multiple misunderstanding.

The generic function is "is.numeric" . Your method for factors is
"is.numeric.factor".

You need to re-study.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 16, 2015 at 5:00 AM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Hi,
>
> Interesting, based upon my understanding of S3 methods, I would have assumed
> that my function would be applied to objects of class "numeric.factor". I
> was not aware of this multiple "dispatch".
>
> Thanks for pointing this out.
>
>
> On 11/15/2015 9:42 PM, Bert Gunter wrote:
>>
>> Think about it.
>>
>> I shall assume that you are familiar with S3 methods.  What do you
>> think would happen when xyplot code calls is.numeric() on a factor
>> object expecting it to call the is.numeric primitive but, instead,
>> finding a factor method defined, calls that? Note that your factor
>> method has no arguments, but the is.numeric() primitive does. Hence
>> when the code calls the primitive on the factor object, the error you
>> saw is thrown.
>>
>> I would say that this is a weakness of the informal S3 "class" system,
>> although you probably should not have been surprised that is.numeric
>> is called on factors as the "x" argument, so you were inviting trouble
>> by defining a factor method that overrides this behavior.
>> Nevertheless, I would argue that one cannot know in general when this
>> occurs for other S3 classes, and that therefore allowing methods for
>> is.numeric() is dangerous.
>>
>> Of course, full qualification in the original xyplot code
>> (base::is.numeric() rather than is.numeric() ) would avoid such
>> things, but that's a drag.
>>
>> Contrary opinions and corrections to any flawed understanding on my
>> part are welcome, of course.
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>     -- Clifford Stoll
>>
>>
>> On Sun, Nov 15, 2015 at 6:22 PM, sbihorel
>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>
>>> Hi,
>>>
>>> Pretty much everything is in the title of the post. An example is below.
>>>
>>> library(lattice)
>>> data <-
>>>
>>> data.frame(x=rep(1:10,8),y=rnorm(80),trt=factor(rep(1:4,each=20)),groups=rep(1:8,each=10))
>>> xyplot <- xyplot(y~x|trt,data,groups=groups)
>>>
>>> is.numeric.factor <- function(){
>>>    print('hello world')
>>> }
>>>
>>> xyplot <- xyplot(y~x|trt,data,groups=groups)
>>>
>>> Thanks for shedding some light on this.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From ignacio82 at gmail.com  Mon Nov 16 16:28:16 2015
From: ignacio82 at gmail.com (Ignacio Martinez)
Date: Mon, 16 Nov 2015 15:28:16 +0000
Subject: [R] Clustered Standard Errors?
Message-ID: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>

Hi,

I found this
<https://thetarzan.wordpress.com/2011/06/11/clustered-standard-errors-in-r/>
post
from 2011 for doing clustered standard errors in R.

Is there any update to the lm package that allows to do this without having
to write your own function? In STATA is as simple as adding cluster to the reg
command.

Thanks a lot for the help!

Ignacio

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Nov 16 16:42:58 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 16 Nov 2015 10:42:58 -0500
Subject: [R] Why does a custom function called is.numeric.factor break
 lattice?
In-Reply-To: <CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
Message-ID: <5649F982.50503@gmail.com>

On 16/11/2015 10:22 AM, Bert Gunter wrote:
> There is no multiple dispatch; just multiple misunderstanding.
>
> The generic function is "is.numeric" . Your method for factors is
> "is.numeric.factor".
>
> You need to re-study.


I think the problem is with S3.  "is.numeric.factor" could be a 
"numeric.factor" method for the "is" generic, or a "factor" method for 
the "is.numeric" generic.  Using names with dots is a bad idea. This 
would be all be simpler and less ambiguous if the class had been named 
"numeric_factor" or "numericFactor" or anything without a dot.

Duncan Murdoch


From dcarlson at tamu.edu  Mon Nov 16 16:47:50 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Nov 2015 15:47:50 +0000
Subject: [R] Clustered Standard Errors?
In-Reply-To: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>
References: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DDDD8@mb02.ads.tamu.edu>

Updates to lm() would be documented in the manual page for the function. Reading the link it appears that you do not have to write your own function, Mahmood Ara in Stockholm University has already done it for you. You just have to learn how to copy a function from a web site and paste it into an R script file. Given the cost of a single business license for STATA in the US for moderate-sized datasets of $1,195 (perpetual) versus the cost of R, $0 (perpetual), it would seem to be worth the bother.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ignacio Martinez
Sent: Monday, November 16, 2015 9:28 AM
To: r-help
Subject: [R] Clustered Standard Errors?

Hi,

I found this
<https://thetarzan.wordpress.com/2011/06/11/clustered-standard-errors-in-r/>
post
from 2011 for doing clustered standard errors in R.

Is there any update to the lm package that allows to do this without having
to write your own function? In STATA is as simple as adding cluster to the reg
command.

Thanks a lot for the help!

Ignacio

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Nov 16 17:21:09 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 Nov 2015 08:21:09 -0800
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
In-Reply-To: <5649F982.50503@gmail.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
	<5649F982.50503@gmail.com>
Message-ID: <CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>

Thanks Duncan. You are right; I missed this.

Namespaces and full qualification seems the only reliable solution to
the general issue though -- right?

Cheers,
Bert





Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 16/11/2015 10:22 AM, Bert Gunter wrote:
>>
>> There is no multiple dispatch; just multiple misunderstanding.
>>
>> The generic function is "is.numeric" . Your method for factors is
>> "is.numeric.factor".
>>
>> You need to re-study.
>
>
>
> I think the problem is with S3.  "is.numeric.factor" could be a
> "numeric.factor" method for the "is" generic, or a "factor" method for the
> "is.numeric" generic.  Using names with dots is a bad idea. This would be
> all be simpler and less ambiguous if the class had been named
> "numeric_factor" or "numericFactor" or anything without a dot.
>
> Duncan Murdoch


From maechler at stat.math.ethz.ch  Mon Nov 16 17:43:59 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 16 Nov 2015 17:43:59 +0100
Subject: [R] Why does a custom function called is.numeric.factor
	break	lattice?
In-Reply-To: <CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
	<5649F982.50503@gmail.com>
	<CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
Message-ID: <22090.1999.935528.696009@stat.math.ethz.ch>

>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>     on Mon, 16 Nov 2015 08:21:09 -0800 writes:

    > Thanks Duncan. You are right; I missed this.

    > Namespaces and full qualification seems the only reliable solution to
    > the general issue though -- right?

Not in this case;  full qualification is very very rarely needed
in package code (even some "schools" do use and propagate it
much more than I would recommend), and we are talking about the
lattice code, i.e., package code, not user code, here.

I.e., using  base::is.numeric()  would not help at all: It
will still find the bogous  is.numeric.factor because that is
taken before the internal default method.

Also, I'm almost sure S4 dispatch would suffer from the same
feature of S (and hence R) here:  You are allowed to define
methods for your new classes and they are used "dynamically".
(I also don't think that the problem is related to the fact that this
 a.b.c() case is S3-ambigous:  a() method for "b.c" or a.b() method for "c".)

Unfortunately, this can be misused to define methods for
existing ("base") classes in case they are handled by the default method.
OTOH, if base/stats/... already *had* a 'factor' method for
is.numeric(), be it S3 or S4, no harm would have been done by
the bad user defined is.numeric.factor definition, thanks to the
namespace technology.

To get full protection here, we would have to
store "the dispatch table for all base classes" (a pretty vague notion)
with the package at package build time or install time ("load time" is too late: 
the bad  is.numeric.factor() could already be present at package load time).

I'm not sure this would be is easily feasible.... but it may be
something to envisage for R 4.0.0 ..

Martin

    > Cheers,
    > Bert

    > Bert Gunter

    > "Data is not information. Information is not knowledge. And knowledge
    > is certainly not wisdom."
    > -- Clifford Stoll


    > On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
    > <murdoch.duncan at gmail.com> wrote:
    >> On 16/11/2015 10:22 AM, Bert Gunter wrote:
    >>> 
    >>> There is no multiple dispatch; just multiple misunderstanding.
    >>> 
    >>> The generic function is "is.numeric" . Your method for factors is
    >>> "is.numeric.factor".
    >>> 
    >>> You need to re-study.
    >> 
    >> 
    >> 
    >> I think the problem is with S3.  "is.numeric.factor" could be a
    >> "numeric.factor" method for the "is" generic, or a "factor" method for the
    >> "is.numeric" generic.  Using names with dots is a bad idea. This would be
    >> all be simpler and less ambiguous if the class had been named
    >> "numeric_factor" or "numericFactor" or anything without a dot.
    >> 
    >> Duncan Murdoch


From marongiu.luigi at gmail.com  Mon Nov 16 18:10:29 2015
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 16 Nov 2015 17:10:29 +0000
Subject: [R] variance of repeated measurements
Message-ID: <CAMk+s2QuRFYqC7zmKyDBHKQ+7vu6xBViJK7GHVJFt0f2rqS-rA@mail.gmail.com>

Dear all,
how can I calculate the global variance of repeated measurements? can
I simply use the var() function or shall i use more sophisticated
tools such as aov()? and in the latter case, how can i extract the
variance value?
I am providing an example.
Thank you.
best regards
luigi

>>>
samp <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
          5, 5, 5, 5, 5)
clock <- rep(1:5,5)
targ <- c(rep("A", 5), rep("B", 5), rep("A", 5), rep("A", 5), rep("B", 5))
fluo <- c(-0.012, -0.01, -0.008, -0.002, -0.001, -0.007, -0.008,
         -0.009, -0.009, -0.012, -0.002, -0.003, -0.003, 0.001, 0.002, -0.006,
         -0.001, 0.001, 0.002, 0.002, -0.002, -0.003, -0.003, -0.002, -0.001)
my.data <- data.frame(samp, clock, targ, fluo, stringsAsFactors = FALSE)

# variance individual measurement
sub <- subset(my.data, samp == 1)
plot(sub$flu ~ sub$clock)
abline(lm(sub$flu ~ sub$clock))
for (i in 2:nrow(sub)) {
  X <- subset(sub, clock <= i)
  V <- var(X$fluo)
  cat("variance at clock ", i, " = ", V, "\n", sep="")
}
# variance multiple measurements
sub <- subset(my.data, targ == 'A')
plot(sub$flu ~ sub$clock)
abline(lm(sub$flu ~ sub$clock))
for (i in 2:max(sub$clock)) {
  X <- subset(sub, clock <= i)
  V <- var(X$fluo)
  cat("variance at clock ", i, " = ", V, "\n", sep="")
}


From pollaktn at gmail.com  Sun Nov 15 22:58:24 2015
From: pollaktn at gmail.com (Tania Pollak)
Date: Sun, 15 Nov 2015 13:58:24 -0800
Subject: [R] Error in mkRespMod(fr,
	family = family) : response must be numeric
Message-ID: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>

Hi --

I am new to R, and not much more advanced in stats, but am trying to learn
my way through the program to finish my master's thesis.  I am trying to
run tests using glmer, and am getting the above error message.

My code is:

> test1=glmer(V12~V10+(1|V4),family=poisson)
Error in mkRespMod(fr, family = family) : response must be numeric

(The V's are the column numbers for the variable names -- the program
doesn't seem to recognize the actual variable names, although they are in
the table, but does recognize the column numbers.)

Any help is much appreciated.  I tried searching online for some guidance,
but came up empty.

Thank you --

Tania

	[[alternative HTML version deleted]]


From andrea.primo75 at gmail.com  Mon Nov 16 09:57:24 2015
From: andrea.primo75 at gmail.com (Andrea Primo)
Date: Mon, 16 Nov 2015 09:57:24 +0100
Subject: [R] kalman forecast with msm
Message-ID: <CACWNWmOExq_nDnJzP2Ap3Mk0v5gTBn+X6znQ0bRXTp-r7LiAQA@mail.gmail.com>

how can i implement the kalmanforecast code with R after fitted a Markov
Switching model ?
Can i have an exmple for the function:  Kalman.Forecst(n.ahead, mod, update)

thank you for your attention

Andrea Primo

	[[alternative HTML version deleted]]


From robertomarrone at hotmail.it  Mon Nov 16 15:19:11 2015
From: robertomarrone at hotmail.it (roberto marrone)
Date: Mon, 16 Nov 2015 14:19:11 +0000
Subject: [R] Problem with nls function
Message-ID: <DB4PR02MB035273112A91900DECFCA691A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>

Dear all,

I have a problem using the R finction nls. I am trying to perform an optimisation of the volatility parameter in the Black and Scholes formula. In the function nls I wrote as a formula the  call option price with the only unknown parameter the volatility that I called theta.  The code is the following and I have recevied some errors, one is that below. In my code I use as data a dataset of simuleted option price of length 99, and the same I did for subset.  I would like to have a code that compare my model with the volatility as an unknown parameter with a set of gien option data. Thanks in advance.



optim<- nls(call ~ S*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17))) - 14*exp(-0.015*0-17)*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17)) - theta * sqrt(0.17)), data=data, start= 0.01, control= nls.control(maxiter = 50, tol = 1e-05, minFactor = 1/1024,                        printEval = FALSE, warnOnly = FALSE),  subset= "data1")


Error in nls(call ~ S * pnorm((log(15/14) + (0.015 + theta^2/2) * 0.17)/(theta *  :
  parameters without starting value in 'data': theta


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 16 18:27:02 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 Nov 2015 09:27:02 -0800
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
In-Reply-To: <22090.1999.935528.696009@stat.math.ethz.ch>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
	<5649F982.50503@gmail.com>
	<CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
	<22090.1999.935528.696009@stat.math.ethz.ch>
Message-ID: <CAGxFJbQK9aSy5Wjj_kCWoEZAJ88aLfT0NDvMD87+VprRGsU2JA@mail.gmail.com>

Thanks, Martin.

You have clearly stated the issue that concerned me. I am sorry that
it cannot be (easily) resolved.


Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 16, 2015 at 8:43 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>     on Mon, 16 Nov 2015 08:21:09 -0800 writes:
>
>     > Thanks Duncan. You are right; I missed this.
>
>     > Namespaces and full qualification seems the only reliable solution to
>     > the general issue though -- right?
>
> Not in this case;  full qualification is very very rarely needed
> in package code (even some "schools" do use and propagate it
> much more than I would recommend), and we are talking about the
> lattice code, i.e., package code, not user code, here.
>
> I.e., using  base::is.numeric()  would not help at all: It
> will still find the bogous  is.numeric.factor because that is
> taken before the internal default method.
>
> Also, I'm almost sure S4 dispatch would suffer from the same
> feature of S (and hence R) here:  You are allowed to define
> methods for your new classes and they are used "dynamically".
> (I also don't think that the problem is related to the fact that this
>  a.b.c() case is S3-ambigous:  a() method for "b.c" or a.b() method for "c".)
>
> Unfortunately, this can be misused to define methods for
> existing ("base") classes in case they are handled by the default method.
> OTOH, if base/stats/... already *had* a 'factor' method for
> is.numeric(), be it S3 or S4, no harm would have been done by
> the bad user defined is.numeric.factor definition, thanks to the
> namespace technology.
>
> To get full protection here, we would have to
> store "the dispatch table for all base classes" (a pretty vague notion)
> with the package at package build time or install time ("load time" is too late:
> the bad  is.numeric.factor() could already be present at package load time).
>
> I'm not sure this would be is easily feasible.... but it may be
> something to envisage for R 4.0.0 ..
>
> Martin
>
>     > Cheers,
>     > Bert
>
>     > Bert Gunter
>
>     > "Data is not information. Information is not knowledge. And knowledge
>     > is certainly not wisdom."
>     > -- Clifford Stoll
>
>
>     > On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
>     > <murdoch.duncan at gmail.com> wrote:
>     >> On 16/11/2015 10:22 AM, Bert Gunter wrote:
>     >>>
>     >>> There is no multiple dispatch; just multiple misunderstanding.
>     >>>
>     >>> The generic function is "is.numeric" . Your method for factors is
>     >>> "is.numeric.factor".
>     >>>
>     >>> You need to re-study.
>     >>
>     >>
>     >>
>     >> I think the problem is with S3.  "is.numeric.factor" could be a
>     >> "numeric.factor" method for the "is" generic, or a "factor" method for the
>     >> "is.numeric" generic.  Using names with dots is a bad idea. This would be
>     >> all be simpler and less ambiguous if the class had been named
>     >> "numeric_factor" or "numericFactor" or anything without a dot.
>     >>
>     >> Duncan Murdoch


From Sebastien.Bihorel at cognigencorp.com  Mon Nov 16 18:35:11 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Mon, 16 Nov 2015 12:35:11 -0500
Subject: [R] Why does a custom function called is.numeric.factor break
 lattice?
In-Reply-To: <22090.1999.935528.696009@stat.math.ethz.ch>
References: <56493DF2.8020404@cognigencorp.com>	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>	<5649D381.6070402@cognigencorp.com>	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>	<5649F982.50503@gmail.com>	<CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
	<22090.1999.935528.696009@stat.math.ethz.ch>
Message-ID: <564A13CF.4060807@cognigencorp.com>

Hi,

Thanks everyone for all your insights...

I feel that the discussion is getting way deeper and more technical and 
it needs to be from the point of view of what I was trying to achieve 
with my little "is.numeric.factor" function (ie, checking if an object 
is a factor and if all levels of this factor can be coerced to numeric 
values).

I guess that, as Duncan pointed point, using dots in function names 
becomes bad practice for function starring "is". I'll rename my 
function, that's it.


On 11/16/2015 11:43 AM, Martin Maechler wrote:
>>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>      on Mon, 16 Nov 2015 08:21:09 -0800 writes:
>      > Thanks Duncan. You are right; I missed this.
>
>      > Namespaces and full qualification seems the only reliable solution to
>      > the general issue though -- right?
>
> Not in this case;  full qualification is very very rarely needed
> in package code (even some "schools" do use and propagate it
> much more than I would recommend), and we are talking about the
> lattice code, i.e., package code, not user code, here.
>
> I.e., using  base::is.numeric()  would not help at all: It
> will still find the bogous  is.numeric.factor because that is
> taken before the internal default method.
>
> Also, I'm almost sure S4 dispatch would suffer from the same
> feature of S (and hence R) here:  You are allowed to define
> methods for your new classes and they are used "dynamically".
> (I also don't think that the problem is related to the fact that this
>   a.b.c() case is S3-ambigous:  a() method for "b.c" or a.b() method for "c".)
>
> Unfortunately, this can be misused to define methods for
> existing ("base") classes in case they are handled by the default method.
> OTOH, if base/stats/... already *had* a 'factor' method for
> is.numeric(), be it S3 or S4, no harm would have been done by
> the bad user defined is.numeric.factor definition, thanks to the
> namespace technology.
>
> To get full protection here, we would have to
> store "the dispatch table for all base classes" (a pretty vague notion)
> with the package at package build time or install time ("load time" is too late:
> the bad  is.numeric.factor() could already be present at package load time).
>
> I'm not sure this would be is easily feasible.... but it may be
> something to envisage for R 4.0.0 ..
>
> Martin
>
>      > Cheers,
>      > Bert
>
>      > Bert Gunter
>
>      > "Data is not information. Information is not knowledge. And knowledge
>      > is certainly not wisdom."
>      > -- Clifford Stoll
>
>
>      > On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
>      > <murdoch.duncan at gmail.com> wrote:
>      >> On 16/11/2015 10:22 AM, Bert Gunter wrote:
>      >>>
>      >>> There is no multiple dispatch; just multiple misunderstanding.
>      >>>
>      >>> The generic function is "is.numeric" . Your method for factors is
>      >>> "is.numeric.factor".
>      >>>
>      >>> You need to re-study.
>      >>
>      >>
>      >>
>      >> I think the problem is with S3.  "is.numeric.factor" could be a
>      >> "numeric.factor" method for the "is" generic, or a "factor" method for the
>      >> "is.numeric" generic.  Using names with dots is a bad idea. This would be
>      >> all be simpler and less ambiguous if the class had been named
>      >> "numeric_factor" or "numericFactor" or anything without a dot.
>      >>
>      >> Duncan Murdoch

-- 
Sebastien Bihorel
Cognigen Corporation
(t) +1 716 633 3463 ext 323
Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.

From wdunlap at tibco.com  Mon Nov 16 18:44:33 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Nov 2015 09:44:33 -0800
Subject: [R] Problem with nls function
In-Reply-To: <DB4PR02MB035273112A91900DECFCA691A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>
References: <DB4PR02MB035273112A91900DECFCA691A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>
Message-ID: <CAF8bMcbBQZbmY=_uhS3UWshkhVb6hm3dMSDxOqUmmJpNWZbuvg@mail.gmail.com>

Instead of giving nls() start=0.01, give it a named vector of
parameters, start=c(theta=0.01).
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Nov 16, 2015 at 6:19 AM, roberto marrone
<robertomarrone at hotmail.it> wrote:
> Dear all,
>
> I have a problem using the R finction nls. I am trying to perform an optimisation of the volatility parameter in the Black and Scholes formula. In the function nls I wrote as a formula the  call option price with the only unknown parameter the volatility that I called theta.  The code is the following and I have recevied some errors, one is that below. In my code I use as data a dataset of simuleted option price of length 99, and the same I did for subset.  I would like to have a code that compare my model with the volatility as an unknown parameter with a set of gien option data. Thanks in advance.
>
>
>
> optim<- nls(call ~ S*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17))) - 14*exp(-0.015*0-17)*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17)) - theta * sqrt(0.17)), data=data, start= 0.01, control= nls.control(maxiter = 50, tol = 1e-05, minFactor = 1/1024,                        printEval = FALSE, warnOnly = FALSE),  subset= "data1")
>
>
> Error in nls(call ~ S * pnorm((log(15/14) + (0.015 + theta^2/2) * 0.17)/(theta *  :
>   parameters without starting value in 'data': theta
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Mon Nov 16 18:48:09 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Mon, 16 Nov 2015 18:48:09 +0100 (CET)
Subject: [R] Clustered Standard Errors?
In-Reply-To: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>
References: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1511161847070.15614@paninaro.uibk.ac.at>

On Mon, 16 Nov 2015, Ignacio Martinez wrote:

> Hi,
>
> I found this
> <https://thetarzan.wordpress.com/2011/06/11/clustered-standard-errors-in-r/>
> post
> from 2011 for doing clustered standard errors in R.
>
> Is there any update to the lm package that allows to do this without 
> having to write your own function? In STATA is as simple as adding 
> cluster to the reg command.

For "lm" objects, the easiest solution is to use the "multiwayvcov" 
package on CRAN.

Additionally, the "plm" package on CRAN offers further options beyond the 
simple clustered standard errors.

> Thanks a lot for the help!
>
> Ignacio
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Mon Nov 16 18:47:46 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 16 Nov 2015 12:47:46 -0500
Subject: [R] Optim() and Instability
In-Reply-To: <CAP01uRkLYF4mVPoxYEDM=0gD2745rpgjCOHO9KOdhOaBCvo4wg@mail.gmail.com>
References: <20151114151518.GA7957@localhost.localdomain>
	<CAP01uRnaJ13suDmkMVG0Tuw6T1hOL54nRsEOuQcchtVARq=BYA@mail.gmail.com>
	<CAP01uRkLYF4mVPoxYEDM=0gD2745rpgjCOHO9KOdhOaBCvo4wg@mail.gmail.com>
Message-ID: <CAP01uRmBPTLZ4s0Ls6k8_nf2n2CWKpzU1QqKQXuj2J-im+LijQ@mail.gmail.com>

Since some questioned the scaling idea, here are runs first with
scaling and then without scaling.  Note how much better the solution
is in the first run (see arrows).  It is also evident from the data

> head(data, 3)
      y x1   x2   x3
1 0.660 20  7.0 1680
2 0.165  5  1.7  350
3 0.660 20  7.0 1680

> # run 1 - scaling
> str(optim(par = c(1,1, 1), min.perc_error, data = data,
+   control = list(parscale = c(1, 1, 0.0001))))
List of 5
 $ par        : num [1:3] 0.030232 0.024411 -0.000113
 $ value      : num 0.653  <=====================================
 $ counts     : Named int [1:2] 180 NA
  ..- attr(*, "names")= chr [1:2] "function" "gradient"
 $ convergence: int 0
 $ message    : NULL

> # run 2 - no scaling
> str(optim(par = c(1,1, 1), min.perc_error, data = data))
List of 5
 $ par        : num [1:3] 0.6305 -0.1247 -0.0032
 $ value      : num 473  <=====================================
 $ counts     : Named int [1:2] 182 NA
  ..- attr(*, "names")= chr [1:2] "function" "gradient"
 $ convergence: int 0
 $ message    : NULL

On Sat, Nov 14, 2015 at 10:32 AM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> I meant the parscale parameter.
>
> On Sat, Nov 14, 2015 at 10:30 AM, Gabor Grothendieck
> <ggrothendieck at gmail.com> wrote:
>> Tyipcally the parameters being optimized should be the same order of
>> magnitude or else you can expect numerical problems.  That is what the
>> fnscale control parameter is for.
>>
>> On Sat, Nov 14, 2015 at 10:15 AM, Lorenzo Isella
>> <lorenzo.isella at gmail.com> wrote:
>>> Dear All,
>>> I am using optim() for a relatively simple task: a linear model where
>>> instead of minimizing the sum of the squared errors, I minimize the sum
>>> of the squared relative errors.
>>> However, I notice that the default algorithm is very sensitive to the
>>> choice of the initial fit parameters, whereas I get much more stable
>>> (and therefore better?) results with the BFGS algorithm.
>>> I would like to have some feedback on this (perhaps I made a mistake
>>> somewhere).
>>> I provide a small self-contained example.
>>> You can download a tiny data set from the link
>>>
>>> https://www.dropbox.com/s/tmbj3os4ev3d4y8/data-instability.csv?dl=0
>>>
>>> whereas I paste the script I am using at the end of the email.
>>> Any feedback is really appreciated.
>>> Many thanks
>>>
>>> Lorenzo
>>>
>>> ################################################################
>>>
>>> min.perc_error <- function(data, par) {
>>>              with(data, sum(((par[1]*x1 + par[2]*x2+par[3]*x3 -
>>>              y)/y)^2))
>>>                            }
>>>
>>> par_ini1 <- c(.3,.1, 1e-3)
>>>
>>> par_ini2 <- c(1,1, 1)
>>>
>>>
>>> data <- read.csv("data-instability.csv")
>>>
>>> mm_def1 <-optim(par = par_ini1
>>>                    , min.perc_error, data = data)
>>>
>>> mm_bfgs1 <-optim(par = par_ini1
>>>                    , min.perc_error, data = data, method="BFGS")
>>>
>>> print("fit parameters with the default algorithms and the first seed
>>> ")
>>> print(mm_def1$par)
>>>
>>> print("fit parameters with the BFGS algorithms and the first seed  ")
>>> print(mm_bfgs1$par)
>>>
>>>
>>>
>>> mm_def2 <-optim(par = par_ini2
>>>                    , min.perc_error, data = data)
>>>
>>> mm_bfgs2 <-optim(par = par_ini2
>>>                    , min.perc_error, data = data, method="BFGS")
>>>
>>>
>>>
>>>
>>> print("fit parameters with the default algorithms and the second seed
>>> ")
>>> print(mm_def2$par)
>>>
>>> print("fit parameters with the BFGS algorithms and the second seed  ")
>>> print(mm_bfgs2$par)
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Statistics & Software Consulting
>> GKX Group, GKX Associates Inc.
>> tel: 1-877-GKX-GROUP
>> email: ggrothendieck at gmail.com
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dcarlson at tamu.edu  Mon Nov 16 18:53:20 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 16 Nov 2015 17:53:20 +0000
Subject: [R] Error in mkRespMod(fr,
 family = family) : response must be numeric
In-Reply-To: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
References: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DDF7B@mb02.ads.tamu.edu>

The error message is straightforward. V12 is not a numeric variable and probably not a variable at all. Why would R assume that V12 is a column? A column in what? Read the manual page for glmer() and a basic tutorial on R. Don't assume that R can read your mind.

Without knowing something about your data, it is impossible to answer your question. How is your data stored? As a data frame? If so, you need to use the variable names in your formula and specify the data frame using the data= argument in glmer().

A good place to start would be to read one of these:

Using R by J H Maindonald - https://cran.r-project.org/doc/contrib/usingR.pdf
R for Beginners by E Paradis - https://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf
The R Guide by W J Owen - https://cran.r-project.org/doc/contrib/Owen-TheRGuide.pdf

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tania Pollak
Sent: Sunday, November 15, 2015 3:58 PM
To: r-help at r-project.org
Subject: [R] Error in mkRespMod(fr, family = family) : response must be numeric

Hi --

I am new to R, and not much more advanced in stats, but am trying to learn
my way through the program to finish my master's thesis.  I am trying to
run tests using glmer, and am getting the above error message.

My code is:

> test1=glmer(V12~V10+(1|V4),family=poisson)
Error in mkRespMod(fr, family = family) : response must be numeric

(The V's are the column numbers for the variable names -- the program
doesn't seem to recognize the actual variable names, although they are in
the table, but does recognize the column numbers.)

Any help is much appreciated.  I tried searching online for some guidance,
but came up empty.

Thank you --

Tania

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Nov 16 18:54:48 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 16 Nov 2015 09:54:48 -0800
Subject: [R] variance of repeated measurements
In-Reply-To: <CAMk+s2QuRFYqC7zmKyDBHKQ+7vu6xBViJK7GHVJFt0f2rqS-rA@mail.gmail.com>
References: <CAMk+s2QuRFYqC7zmKyDBHKQ+7vu6xBViJK7GHVJFt0f2rqS-rA@mail.gmail.com>
Message-ID: <5BDB221A-75B9-4760-97DC-29FDF7543A45@dcn.davis.CA.us>

I think your imprecise use of statistical methods is getting you into trouble. A literal interpretation of your question would lead to var(my.data$fluo), but whether that number would be meaningful would depend on what you did with it (I doubt much good would come from using it directly). Unfortunately such concerns are off-topic here (consider discussing at stats.stackexchange.com).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 16, 2015 9:10:29 AM PST, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Dear all,
>how can I calculate the global variance of repeated measurements? can
>I simply use the var() function or shall i use more sophisticated
>tools such as aov()? and in the latter case, how can i extract the
>variance value?
>I am providing an example.
>Thank you.
>best regards
>luigi
>
>>>>
>samp <- c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,
>          5, 5, 5, 5, 5)
>clock <- rep(1:5,5)
>targ <- c(rep("A", 5), rep("B", 5), rep("A", 5), rep("A", 5), rep("B",
>5))
>fluo <- c(-0.012, -0.01, -0.008, -0.002, -0.001, -0.007, -0.008,
>  -0.009, -0.009, -0.012, -0.002, -0.003, -0.003, 0.001, 0.002, -0.006,
>   -0.001, 0.001, 0.002, 0.002, -0.002, -0.003, -0.003, -0.002, -0.001)
>my.data <- data.frame(samp, clock, targ, fluo, stringsAsFactors =
>FALSE)
>
># variance individual measurement
>sub <- subset(my.data, samp == 1)
>plot(sub$flu ~ sub$clock)
>abline(lm(sub$flu ~ sub$clock))
>for (i in 2:nrow(sub)) {
>  X <- subset(sub, clock <= i)
>  V <- var(X$fluo)
>  cat("variance at clock ", i, " = ", V, "\n", sep="")
>}
># variance multiple measurements
>sub <- subset(my.data, targ == 'A')
>plot(sub$flu ~ sub$clock)
>abline(lm(sub$flu ~ sub$clock))
>for (i in 2:max(sub$clock)) {
>  X <- subset(sub, clock <= i)
>  V <- var(X$fluo)
>  cat("variance at clock ", i, " = ", V, "\n", sep="")
>}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Nov 16 18:59:24 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Nov 2015 09:59:24 -0800
Subject: [R] Why does a custom function called is.numeric.factor break
	lattice?
In-Reply-To: <564A13CF.4060807@cognigencorp.com>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
	<5649F982.50503@gmail.com>
	<CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
	<22090.1999.935528.696009@stat.math.ethz.ch>
	<564A13CF.4060807@cognigencorp.com>
Message-ID: <989973D1-7BFB-47B1-BBD6-C83E5D71B912@comcast.net>


> On Nov 16, 2015, at 9:35 AM, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
> 
> Hi,
> 
> Thanks everyone for all your insights...
> 
> I feel that the discussion is getting way deeper and more technical and it needs to be from the point of view of what I was trying to achieve with my little "is.numeric.factor" function (ie, checking if an object is a factor and if all levels of this factor can be coerced to numeric values).

You seem to be asking for a compound test: first with is.factor, then to see whether all the levels could be coerced to numeric properly. I would think that you would need something like:

 if( is.factor(varname) ) { !sum(is.na(as.numeric(as.character(varname)))) } else { FALSE }

? 
David.


> 
> I guess that, as Duncan pointed point, using dots in function names becomes bad practice for function starring "is". I'll rename my function, that's it.
> 
> 
> On 11/16/2015 11:43 AM, Martin Maechler wrote:
>>>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>>     on Mon, 16 Nov 2015 08:21:09 -0800 writes:
>>     > Thanks Duncan. You are right; I missed this.
>> 
>>     > Namespaces and full qualification seems the only reliable solution to
>>     > the general issue though -- right?
>> 
>> Not in this case;  full qualification is very very rarely needed
>> in package code (even some "schools" do use and propagate it
>> much more than I would recommend), and we are talking about the
>> lattice code, i.e., package code, not user code, here.
>> 
>> I.e., using  base::is.numeric()  would not help at all: It
>> will still find the bogous  is.numeric.factor because that is
>> taken before the internal default method.
>> 
>> Also, I'm almost sure S4 dispatch would suffer from the same
>> feature of S (and hence R) here:  You are allowed to define
>> methods for your new classes and they are used "dynamically".
>> (I also don't think that the problem is related to the fact that this
>>  a.b.c() case is S3-ambigous:  a() method for "b.c" or a.b() method for "c".)
>> 
>> Unfortunately, this can be misused to define methods for
>> existing ("base") classes in case they are handled by the default method.
>> OTOH, if base/stats/... already *had* a 'factor' method for
>> is.numeric(), be it S3 or S4, no harm would have been done by
>> the bad user defined is.numeric.factor definition, thanks to the
>> namespace technology.
>> 
>> To get full protection here, we would have to
>> store "the dispatch table for all base classes" (a pretty vague notion)
>> with the package at package build time or install time ("load time" is too late:
>> the bad  is.numeric.factor() could already be present at package load time).
>> 
>> I'm not sure this would be is easily feasible.... but it may be
>> something to envisage for R 4.0.0 ..
>> 
>> Martin
>> 
>>     > Cheers,
>>     > Bert
>> 
>>     > Bert Gunter
>> 
>>     > "Data is not information. Information is not knowledge. And knowledge
>>     > is certainly not wisdom."
>>     > -- Clifford Stoll
>> 
>> 
>>     > On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
>>     > <murdoch.duncan at gmail.com> wrote:
>>     >> On 16/11/2015 10:22 AM, Bert Gunter wrote:
>>     >>>
>>     >>> There is no multiple dispatch; just multiple misunderstanding.
>>     >>>
>>     >>> The generic function is "is.numeric" . Your method for factors is
>>     >>> "is.numeric.factor".
>>     >>>
>>     >>> You need to re-study.
>>     >>
>>     >>
>>     >>
>>     >> I think the problem is with S3.  "is.numeric.factor" could be a
>>     >> "numeric.factor" method for the "is" generic, or a "factor" method for the
>>     >> "is.numeric" generic.  Using names with dots is a bad idea. This would be
>>     >> all be simpler and less ambiguous if the class had been named
>>     >> "numeric_factor" or "numericFactor" or anything without a dot.
>>     >>
>>     >> Duncan Murdoch
> 
> -- 
> Sebastien Bihorel
> Cognigen Corporation
> (t) +1 716 633 3463 ext 323
> Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Nov 16 19:03:35 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Nov 2015 10:03:35 -0800
Subject: [R] Error in mkRespMod(fr,
	family = family) : response must be numeric
In-Reply-To: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
References: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
Message-ID: <0B77B635-2F23-400E-B9E4-7F987B8E0A70@comcast.net>


> On Nov 15, 2015, at 1:58 PM, Tania Pollak <pollaktn at gmail.com> wrote:
> 
> Hi --
> 
> I am new to R, and not much more advanced in stats, but am trying to learn
> my way through the program to finish my master's thesis.  I am trying to
> run tests using glmer, and am getting the above error message.
> 
> My code is:
> 
>> test1=glmer(V12~V10+(1|V4),family=poisson)
> Error in mkRespMod(fr, family = family) : response must be numeric
> 
> (The V's are the column numbers for the variable names -- the program
> doesn't seem to recognize the actual variable names, although they are in
> the table, but does recognize the column numbers.)

I do not understand what you are calling ?the table?. Did you use attach() on a dataframe that has those variable names as its column names? Using `attach` is very unwise, often leading to getting puzzling error messages. If my guess is correct, you should detach() the dataframe and post the output of summary( <whatever name it might have>). It appears you do not understand what is in the `V12` column.


> 
> Any help is much appreciated.  I tried searching online for some guidance,
> but came up empty.
> 
> Thank you --
> 
> Tania
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From robertomarrone at hotmail.it  Mon Nov 16 19:30:08 2015
From: robertomarrone at hotmail.it (roberto marrone)
Date: Mon, 16 Nov 2015 18:30:08 +0000
Subject: [R] Problem with the port algorithm in nls function
Message-ID: <DB4PR02MB035282F588E7FEC1AB44F8C0A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>

Dear all,

using the following code I have find a problem with the port algorithm. If I use the nls function without lower bound for my parameter it compute the parameter's value but I want the parameter positive. Running the following code I had this error. Thanks at all.


optim <- nls(Prezzo ~ S*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17))) - 14*exp(-0.015*0-17)*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17)) - theta * sqrt(0.17)),
+  start=c(theta=0.1),
+  data=data,
+  algorithm="port",
+  lower=0.01,
+  trace=TRUE,
+  control= nls.control(maxiter = 100, tol = 1e-05, minFactor = 1/1024, printEval = FALSE, warnOnly = FALSE))


Error in nls_port_fit(m, start, lower, upper, control, trace, give.v = TRUE) :
  INTEGER() can only be applied to a 'integer', not a 'NULL'


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 16 20:41:16 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 Nov 2015 11:41:16 -0800
Subject: [R] Problem with the port algorithm in nls function
In-Reply-To: <DB4PR02MB035282F588E7FEC1AB44F8C0A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>
References: <DB4PR02MB035282F588E7FEC1AB44F8C0A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>
Message-ID: <CAGxFJbR7hBhSf-XuOpC3LWSdd2X_+w0qt4rWTUKU82Sxcq+vuw@mail.gmail.com>

from ?nls ...

"The algorithm = "port" code appears unfinished, and does not even
check that the starting value is within the bounds. Use with caution,
especially where bounds are supplied."

So it appears that you may have gotten what you paid for.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 16, 2015 at 10:30 AM, roberto marrone
<robertomarrone at hotmail.it> wrote:
> Dear all,
>
> using the following code I have find a problem with the port algorithm. If I use the nls function without lower bound for my parameter it compute the parameter's value but I want the parameter positive. Running the following code I had this error. Thanks at all.
>
>
> optim <- nls(Prezzo ~ S*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17))) - 14*exp(-0.015*0-17)*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17)) - theta * sqrt(0.17)),
> +  start=c(theta=0.1),
> +  data=data,
> +  algorithm="port",
> +  lower=0.01,
> +  trace=TRUE,
> +  control= nls.control(maxiter = 100, tol = 1e-05, minFactor = 1/1024, printEval = FALSE, warnOnly = FALSE))
>
>
> Error in nls_port_fit(m, start, lower, upper, control, trace, give.v = TRUE) :
>   INTEGER() can only be applied to a 'integer', not a 'NULL'
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sch298 at g.uky.edu  Mon Nov 16 20:37:02 2015
From: sch298 at g.uky.edu (Chattopadhyay, Somsubhra)
Date: Mon, 16 Nov 2015 14:37:02 -0500
Subject: [R] Converting daily time series to monthly?
Message-ID: <CAEZ46x+NVAO-Mr7N0tALmCPFQEEpvfCR2rYMhZ7drL-RSo8FYQ@mail.gmail.com>

Hi all,

I have daily time series of rainfall for sufficiently long period of time
(70 years). I want to aggregate the data series into monthly, seasonal and
annual basis. I know excel can handle this with the pivot table
functionality. However, I have too many data points so, it's not a very
smart way of dealing with this that way. I am wondering a simple R code or
package may help me out here. I appreciate any feedback.

Thanks
Som

-- 
Somsubhra Chattopadhyay
Graduate Research Assistant
Biosystem and Agricultural Engineering Department
University of Kentucky, Lexington, KY 40546
Email: schattop14 at uky.edu
Cell: 9198026951

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Mon Nov 16 21:05:24 2015
From: profjcnash at gmail.com (ProfJCNash)
Date: Mon, 16 Nov 2015 15:05:24 -0500
Subject: [R] Problem with the port algorithm in nls function
In-Reply-To: <CAGxFJbR7hBhSf-XuOpC3LWSdd2X_+w0qt4rWTUKU82Sxcq+vuw@mail.gmail.com>
References: <DB4PR02MB035282F588E7FEC1AB44F8C0A81E0@DB4PR02MB0352.eurprd02.prod.outlook.com>
	<CAGxFJbR7hBhSf-XuOpC3LWSdd2X_+w0qt4rWTUKU82Sxcq+vuw@mail.gmail.com>
Message-ID: <564A3704.8090504@gmail.com>

You might try functions in the nlmrt package, but there are some
differences in the call -- you must have a well-defined dataframe for
example. And with only 1 parameter, I'm not sure of the behaviour.

JN

On 15-11-16 02:41 PM, Bert Gunter wrote:
> from ?nls ...
> 
> "The algorithm = "port" code appears unfinished, and does not even
> check that the starting value is within the bounds. Use with caution,
> especially where bounds are supplied."
> 
> So it appears that you may have gotten what you paid for.
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
> 
> 
> On Mon, Nov 16, 2015 at 10:30 AM, roberto marrone
> <robertomarrone at hotmail.it> wrote:
>> Dear all,
>>
>> using the following code I have find a problem with the port algorithm. If I use the nls function without lower bound for my parameter it compute the parameter's value but I want the parameter positive. Running the following code I had this error. Thanks at all.
>>
>>
>> optim <- nls(Prezzo ~ S*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17))) - 14*exp(-0.015*0-17)*pnorm((log(15/14)+(0.015+theta^2/2)*0.17)/(theta*sqrt(0.17)) - theta * sqrt(0.17)),
>> +  start=c(theta=0.1),
>> +  data=data,
>> +  algorithm="port",
>> +  lower=0.01,
>> +  trace=TRUE,
>> +  control= nls.control(maxiter = 100, tol = 1e-05, minFactor = 1/1024, printEval = FALSE, warnOnly = FALSE))
>>
>>
>> Error in nls_port_fit(m, start, lower, upper, control, trace, give.v = TRUE) :
>>   INTEGER() can only be applied to a 'integer', not a 'NULL'
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ckmsasi at gmail.com  Mon Nov 16 21:25:06 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Mon, 16 Nov 2015 12:25:06 -0800
Subject: [R] R runtime performance and memory usage
Message-ID: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>

Hi All,

I have couple of clarifications on R run-time performance. I have R-3.2.2
package compiled for MIPS64 and am running it on my linux machine with
mips64 processor (core speed 1.5GHz) and observing the following behaviors,

1. Applying "linear regression model" (lm) on 1MB of data (contains 1
column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
expected behavior or not? If not, can you please the suggestions or options
to improve if we have any?

2. Also, the R process runtime virtual memory is increased by 40MB after
applying the linear model on 1MB data. Is it also expected behavior? If it
is expected, can you please share the insight of memory usage?

Thanks in advance.

Regards
Sasi

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Nov 16 21:44:28 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 16 Nov 2015 12:44:28 -0800
Subject: [R] Converting daily time series to monthly?
In-Reply-To: <CAEZ46x+NVAO-Mr7N0tALmCPFQEEpvfCR2rYMhZ7drL-RSo8FYQ@mail.gmail.com>
References: <CAEZ46x+NVAO-Mr7N0tALmCPFQEEpvfCR2rYMhZ7drL-RSo8FYQ@mail.gmail.com>
Message-ID: <95C5B885-0BA3-4FE6-B8EF-1C57CFF7D782@dcn.davis.CA.us>

There are several ways to do this in R. You can get useful suggestions if you follow the recommendations in the Posting Guide, including:

Send your email using pain text format since HTML tends to mangle code samples.

Provide a sample of data that represents your actual data. See [1] for suggestions of how to do this... the dput function is particularly useful for generating some code that puts the some data into our R session.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 16, 2015 11:37:02 AM PST, "Chattopadhyay, Somsubhra" <sch298 at g.uky.edu> wrote:
>Hi all,
>
>I have daily time series of rainfall for sufficiently long period of
>time
>(70 years). I want to aggregate the data series into monthly, seasonal
>and
>annual basis. I know excel can handle this with the pivot table
>functionality. However, I have too many data points so, it's not a very
>smart way of dealing with this that way. I am wondering a simple R code
>or
>package may help me out here. I appreciate any feedback.
>
>Thanks
>Som


From bgunter.4567 at gmail.com  Mon Nov 16 21:44:43 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 16 Nov 2015 12:44:43 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
Message-ID: <CAGxFJbRr7rH-prAKKe-i+iVcmxkHcBaBWP7ohfNn2y0q2mYu6w@mail.gmail.com>

Do your own homework.
Google on "memory usage in R."  etc.
You should have no trouble finding what you need there.

Cheers,
Bert



Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
<ckmsasi at gmail.com> wrote:
> Hi All,
>
> I have couple of clarifications on R run-time performance. I have R-3.2.2
> package compiled for MIPS64 and am running it on my linux machine with
> mips64 processor (core speed 1.5GHz) and observing the following behaviors,
>
> 1. Applying "linear regression model" (lm) on 1MB of data (contains 1
> column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
> expected behavior or not? If not, can you please the suggestions or options
> to improve if we have any?
>
> 2. Also, the R process runtime virtual memory is increased by 40MB after
> applying the linear model on 1MB data. Is it also expected behavior? If it
> is expected, can you please share the insight of memory usage?
>
> Thanks in advance.
>
> Regards
> Sasi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Nov 16 23:04:53 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Nov 2015 14:04:53 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
Message-ID: <CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>

You cannot do a linear regression with one column of data - there must
be at least one response column and one predictor.  By default, lm
throws in a constant term which gives you a second predictor.  If your
predictor is categorical, you get a new column for all but the first
unique value in it.

lm() deals only with double precision data, at 8 bytes/number.  Thus
250k numbers occupies 2 million bytes.  Your three columns (in the
non-categorical-predictor case)  take up 6 million bytes,

lm()'s output contains several columns the size of the response
variable: residuals, effects, and fitted.values.  It also contains the
QR decomposition of the design matrix (the size of all the predictor
columns together).

There are also some temporary variables generated in the course of the
computation.

So your observed 40 MB memory usage seems reasonable.

Use the object.size() function to see how big objects are and str() to
look at their structure.

My laptop with  a 2.5 GHz Intel i7 processor takes a quarter second to
fit a simple linear model with one numeric predictor and a constant
term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
system.time() to see)?



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
<ckmsasi at gmail.com> wrote:
> Hi All,
>
> I have couple of clarifications on R run-time performance. I have R-3.2.2
> package compiled for MIPS64 and am running it on my linux machine with
> mips64 processor (core speed 1.5GHz) and observing the following behaviors,
>
> 1. Applying "linear regression model" (lm) on 1MB of data (contains 1
> column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
> expected behavior or not? If not, can you please the suggestions or options
> to improve if we have any?
>
> 2. Also, the R process runtime virtual memory is increased by 40MB after
> applying the linear model on 1MB data. Is it also expected behavior? If it
> is expected, can you please share the insight of memory usage?
>
> Thanks in advance.
>
> Regards
> Sasi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Tue Nov 17 00:04:02 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 16 Nov 2015 15:04:02 -0800
Subject: [R] how to eliminate ggplot warning frrom "knitted" document
Message-ID: <564A60E2.4010306@frontier.com>

I have the following data.

sumry <- structure(list(group = structure(c(1L, 1L, 1L, 2L, 2L, 2L), 
.Label = c("A",
"B"), class = "factor"), level = c(0.5, 1, 2, 0.5, 1, 2), n = c(10,
10, 10, 10, 10, 10), mean = c(13.23, 22.7, 26.06, 7.98, 16.77,
26.14), sd = c(4.45, 3.91, 2.65,
2.74, 2.51, 4.79), se = c(1.41,
1.23, 0.83, 0.86, 0.79,
1.51), lcl = c(10.03, 19.90,
24.16, 6.01, 14.972, 22.70
), ucl = c(16.42, 25.49, 27.95,
9.94, 18.56, 29.57)), .Names = c("group",
"level", "n", "mean", "sd", "se", "lcl", "ucl"), row.names = c(NA,
6L), class = "data.frame")

I want to plot the means with 95% confidence intervals for the means.  I 
can use the following ggplot code to get the plot.

ggplot(sumry, aes(x=level, y=mean, group=group, color=group)) +
   geom_line() +
   geom_point()+
   geom_errorbar(aes(ymin=lcl, ymax=ucl), width=.2)

I initially tried using position_dodge() to keep the error bars from 
plotting completely on top of each other.  However, I kept getting the 
following warning:

ymax not defined: adjusting position using y instead

I am using knitr to create a pdf document and the warning is cluttering 
up my pdf document. Is there anyway to alter the plot statement to avoid 
the warning?  If not, is there a way to get knitr not to print out the 
warning to the markdown document so that it doesn't end up in the pdf 
document?


Thanks,

Dan

-- 
Daniel Nordlund
Bothell, WA  USA


From jrkrideau at inbox.com  Tue Nov 17 00:12:13 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 16 Nov 2015 15:12:13 -0800
Subject: [R] Error in mkRespMod(fr,
 family = family) : response must be  numeric
In-Reply-To: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
Message-ID: <E984EDC8C3D.000009D8jrkrideau@inbox.com>

Welcome to R-help.

We probably need some more code and sample data.  Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for some suggestions.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pollaktn at gmail.com
> Sent: Sun, 15 Nov 2015 13:58:24 -0800
> To: r-help at r-project.org
> Subject: [R] Error in mkRespMod(fr, family = family) : response must be
> numeric
> 
> Hi --
> 
> I am new to R, and not much more advanced in stats, but am trying to
> learn
> my way through the program to finish my master's thesis.  I am trying to
> run tests using glmer, and am getting the above error message.
> 
> My code is:
> 
>> test1=glmer(V12~V10+(1|V4),family=poisson)
> Error in mkRespMod(fr, family = family) : response must be numeric
> 
> (The V's are the column numbers for the variable names -- the program
> doesn't seem to recognize the actual variable names, although they are in
> the table, but does recognize the column numbers.)
> 
> Any help is much appreciated.  I tried searching online for some
> guidance,
> but came up empty.
> 
> Thank you --
> 
> Tania
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Send any screenshot to your friends in seconds...
Works in all emails, instant messengers, blogs, forums and social networks.
TRY IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if2 for FREE


From thierry.onkelinx at inbo.be  Tue Nov 17 00:15:03 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 00:15:03 +0100
Subject: [R] how to eliminate ggplot warning frrom "knitted" document
In-Reply-To: <564A60E2.4010306@frontier.com>
References: <564A60E2.4010306@frontier.com>
Message-ID: <CAJuCY5zs2yw=6HSJuhSN4ZCz8DwznsZsxezyx3E19wD2cMN9ng@mail.gmail.com>

Add warning = FALSE to the chunk options
Op 17-nov.-2015 00:07 schreef "Daniel Nordlund" <djnordlund at frontier.com>:

> I have the following data.
>
> sumry <- structure(list(group = structure(c(1L, 1L, 1L, 2L, 2L, 2L),
> .Label = c("A",
> "B"), class = "factor"), level = c(0.5, 1, 2, 0.5, 1, 2), n = c(10,
> 10, 10, 10, 10, 10), mean = c(13.23, 22.7, 26.06, 7.98, 16.77,
> 26.14), sd = c(4.45, 3.91, 2.65,
> 2.74, 2.51, 4.79), se = c(1.41,
> 1.23, 0.83, 0.86, 0.79,
> 1.51), lcl = c(10.03, 19.90,
> 24.16, 6.01, 14.972, 22.70
> ), ucl = c(16.42, 25.49, 27.95,
> 9.94, 18.56, 29.57)), .Names = c("group",
> "level", "n", "mean", "sd", "se", "lcl", "ucl"), row.names = c(NA,
> 6L), class = "data.frame")
>
> I want to plot the means with 95% confidence intervals for the means.  I
> can use the following ggplot code to get the plot.
>
> ggplot(sumry, aes(x=level, y=mean, group=group, color=group)) +
>   geom_line() +
>   geom_point()+
>   geom_errorbar(aes(ymin=lcl, ymax=ucl), width=.2)
>
> I initially tried using position_dodge() to keep the error bars from
> plotting completely on top of each other.  However, I kept getting the
> following warning:
>
> ymax not defined: adjusting position using y instead
>
> I am using knitr to create a pdf document and the warning is cluttering up
> my pdf document. Is there anyway to alter the plot statement to avoid the
> warning?  If not, is there a way to get knitr not to print out the warning
> to the markdown document so that it doesn't end up in the pdf document?
>
>
> Thanks,
>
> Dan
>
> --
> Daniel Nordlund
> Bothell, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Tue Nov 17 01:01:06 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Tue, 17 Nov 2015 02:01:06 +0200
Subject: [R] {non} linear model solving
In-Reply-To: <564999F6.2030003@auckland.ac.nz>
References: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>,
	<564999F6.2030003@auckland.ac.nz>
Message-ID: <DUB125-W5E55364E615B4BB2379E4B31D0@phx.gbl>

thanks for replying.

the question about non linear model, I formed it incorrectly, I have a single objective multi constrain non linear model..I searched some R library to solve it, is there any tutorial step by step for such problem I can follow.

Best Regards

----------------------------------------
> Subject: Re: [R] linear model solving
> To: ragia11 at hotmail.com; r-help at r-project.org
> From: r.turner at auckland.ac.nz
> Date: Mon, 16 Nov 2015 21:55:18 +1300
>
> On 16/11/15 20:49, Ragia Ibrahim wrote:
>> Dear group IF I had an objective function and some constrains formed
>> in linear model form. is there a way,..library in R that helps me to
>> solve such amodel and find the unknown variable in it?
>
>
> This is a very ill-posed question and is unlikely to provoke any useful
> responses. If you can't make the effort to ask a clear, precise
> question, why should anyone make the effort to try to answer you? Even
> if they *could* answer you. Which they can't.
>
> (a) Frame a proper question, providing a minimal reproducible example.
>
> (b) Do some googling; don't expect others to do your work for you.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
 		 	   		  

From wdunlap at tibco.com  Tue Nov 17 01:01:42 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Nov 2015 16:01:42 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
	<CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
	<CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>
Message-ID: <CAF8bMcYOA1vBqVD+HYBN53zr57Y2sM2xnmKqxf_-eDvm8=orAQ@mail.gmail.com>

If a quick running time is important and your models involve only
numeric data with no missing values and you are willing to spend more
programming time setting things up, the lsfit() function may work
better for you.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Nov 16, 2015 at 3:25 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
> Thanks a lot Bill & Bert.
>
> Hi Bill,
>
> Sorry i was wrong on number of records, actually, i am using two dimensional
> data of 250K records each. And regarding CPU usage, it was the elapsed time.
> Infact, i have pined one core to run R.
>
> Thanks & Regards
> Sasi
>
> On Mon, Nov 16, 2015 at 2:04 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> You cannot do a linear regression with one column of data - there must
>> be at least one response column and one predictor.  By default, lm
>> throws in a constant term which gives you a second predictor.  If your
>> predictor is categorical, you get a new column for all but the first
>> unique value in it.
>>
>> lm() deals only with double precision data, at 8 bytes/number.  Thus
>> 250k numbers occupies 2 million bytes.  Your three columns (in the
>> non-categorical-predictor case)  take up 6 million bytes,
>>
>> lm()'s output contains several columns the size of the response
>> variable: residuals, effects, and fitted.values.  It also contains the
>> QR decomposition of the design matrix (the size of all the predictor
>> columns together).
>>
>> There are also some temporary variables generated in the course of the
>> computation.
>>
>> So your observed 40 MB memory usage seems reasonable.
>>
>> Use the object.size() function to see how big objects are and str() to
>> look at their structure.
>>
>> My laptop with  a 2.5 GHz Intel i7 processor takes a quarter second to
>> fit a simple linear model with one numeric predictor and a constant
>> term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
>> system.time() to see)?
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
>> <ckmsasi at gmail.com> wrote:
>> > Hi All,
>> >
>> > I have couple of clarifications on R run-time performance. I have
>> > R-3.2.2
>> > package compiled for MIPS64 and am running it on my linux machine with
>> > mips64 processor (core speed 1.5GHz) and observing the following
>> > behaviors,
>> >
>> > 1. Applying "linear regression model" (lm) on 1MB of data (contains 1
>> > column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
>> > expected behavior or not? If not, can you please the suggestions or
>> > options
>> > to improve if we have any?
>> >
>> > 2. Also, the R process runtime virtual memory is increased by 40MB after
>> > applying the linear model on 1MB data. Is it also expected behavior? If
>> > it
>> > is expected, can you please share the insight of memory usage?
>> >
>> > Thanks in advance.
>> >
>> > Regards
>> > Sasi
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From wdunlap at tibco.com  Tue Nov 17 01:10:52 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 16 Nov 2015 16:10:52 -0800
Subject: [R] Error in mkRespMod(fr,
	family = family) : response must be numeric
In-Reply-To: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
References: <CAJeBu8bEZO27KCvNAjGC8ZPCiKafvUsSE+VaoDZS65czamDBqw@mail.gmail.com>
Message-ID: <CAF8bMcZD3OrpfqRnf1jjkC-qFUjGkqC=zQujXy1PdeoJKTS9PA@mail.gmail.com>

You should look at the data that you imported to R from somewhere else
with the str() or summary() function.  Since you think the data should
have nice column names but seems to have the names V1, ..., Vn, I
think that you may may have read a file with column names at the top
into R with read.table without specifying header=TRUE.  With
header=FALSE, the names will cause read.table to think that the column
contains character data and header=FALSE also causes the column names
to be V1, ..., Vn.

 E.g.,

> dataText <- "ColA ColB\n1 100\n2 200\n"
> str(read.table(text=dataText))
'data.frame':   3 obs. of  2 variables:
 $ V1: Factor w/ 3 levels "1","2","ColA": 3 1 2
 $ V2: Factor w/ 3 levels "100","200","ColB": 3 1 2
> str(read.table(text=dataText, header=TRUE))
'data.frame':   2 obs. of  2 variables:
 $ ColA: int  1 2
 $ ColB: int  100 200

Again, use str() and summary() (or some of Hadley's tools) to make
sure what you read into R is what you think it is.  Also, make some
simple plots of the data, say with pairs().  Do this before fitting
any serious models to it.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Nov 15, 2015 at 1:58 PM, Tania Pollak <pollaktn at gmail.com> wrote:
> Hi --
>
> I am new to R, and not much more advanced in stats, but am trying to learn
> my way through the program to finish my master's thesis.  I am trying to
> run tests using glmer, and am getting the above error message.
>
> My code is:
>
>> test1=glmer(V12~V10+(1|V4),family=poisson)
> Error in mkRespMod(fr, family = family) : response must be numeric
>
> (The V's are the column numbers for the variable names -- the program
> doesn't seem to recognize the actual variable names, although they are in
> the table, but does recognize the column numbers.)
>
> Any help is much appreciated.  I tried searching online for some guidance,
> but came up empty.
>
> Thank you --
>
> Tania
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ckmsasi at gmail.com  Tue Nov 17 00:25:03 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Mon, 16 Nov 2015 15:25:03 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
	<CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
Message-ID: <CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>

Thanks a lot Bill & Bert.

Hi Bill,

Sorry i was wrong on number of records, actually, i am using two
dimensional data of 250K records each. And regarding CPU usage, it was the
elapsed time. Infact, i have pined one core to run R.

Thanks & Regards
Sasi

On Mon, Nov 16, 2015 at 2:04 PM, William Dunlap <wdunlap at tibco.com> wrote:

> You cannot do a linear regression with one column of data - there must
> be at least one response column and one predictor.  By default, lm
> throws in a constant term which gives you a second predictor.  If your
> predictor is categorical, you get a new column for all but the first
> unique value in it.
>
> lm() deals only with double precision data, at 8 bytes/number.  Thus
> 250k numbers occupies 2 million bytes.  Your three columns (in the
> non-categorical-predictor case)  take up 6 million bytes,
>
> lm()'s output contains several columns the size of the response
> variable: residuals, effects, and fitted.values.  It also contains the
> QR decomposition of the design matrix (the size of all the predictor
> columns together).
>
> There are also some temporary variables generated in the course of the
> computation.
>
> So your observed 40 MB memory usage seems reasonable.
>
> Use the object.size() function to see how big objects are and str() to
> look at their structure.
>
> My laptop with  a 2.5 GHz Intel i7 processor takes a quarter second to
> fit a simple linear model with one numeric predictor and a constant
> term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
> system.time() to see)?
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
> <ckmsasi at gmail.com> wrote:
> > Hi All,
> >
> > I have couple of clarifications on R run-time performance. I have R-3.2.2
> > package compiled for MIPS64 and am running it on my linux machine with
> > mips64 processor (core speed 1.5GHz) and observing the following
> behaviors,
> >
> > 1. Applying "linear regression model" (lm) on 1MB of data (contains 1
> > column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
> > expected behavior or not? If not, can you please the suggestions or
> options
> > to improve if we have any?
> >
> > 2. Also, the R process runtime virtual memory is increased by 40MB after
> > applying the linear model on 1MB data. Is it also expected behavior? If
> it
> > is expected, can you please share the insight of memory usage?
> >
> > Thanks in advance.
> >
> > Regards
> > Sasi
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Tue Nov 17 01:23:34 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Mon, 16 Nov 2015 19:23:34 -0500
Subject: [R] Why does a custom function called is.numeric.factor break
 lattice?
In-Reply-To: <989973D1-7BFB-47B1-BBD6-C83E5D71B912@comcast.net>
References: <56493DF2.8020404@cognigencorp.com>
	<CAGxFJbSZ5wZyp8za=8i-Nj6jcXBv9n-xC_H_rUpmsnZJtOStjw@mail.gmail.com>
	<5649D381.6070402@cognigencorp.com>
	<CAGxFJbQVnDqZP9gsPxY5abPNeU5QYpK4+cFiXFQXqQUHBavWoA@mail.gmail.com>
	<5649F982.50503@gmail.com>
	<CAGxFJbQjN31hB6rFWgSfhZmcwi2GSCGhn5CTh26wTXmhU1ZP5A@mail.gmail.com>
	<22090.1999.935528.696009@stat.math.ethz.ch>
	<564A13CF.4060807@cognigencorp.com>
	<989973D1-7BFB-47B1-BBD6-C83E5D71B912@comcast.net>
Message-ID: <564A7386.3080109@cognigencorp.com>

Thanks David,

I never seem to get my intention clear when I post to the R-help list... 
I am not sure why...

Anyways, my issue was not with the test (I came up with something 
similar). It was actually with the name of the function which I had to 
create, given that this test needed to be used dozens of times in the 
framework I work with.
My choice of function name was less than optimal and got me into all the 
troubles discussed in previous posts. My own debugging identified that 
the test was not the problem but the function name somehow interfered 
with lattice. So I already knew how to fix my problem before posting... 
just choose a different name.
My post was actually intended to clarify the reason why the function 
name itself was causing the issue... which I believe it now perfectly 
clear, thanks to all the previous posts.



On 11/16/2015 12:59 PM, David Winsemius wrote:
>> On Nov 16, 2015, at 9:35 AM, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>>
>> Hi,
>>
>> Thanks everyone for all your insights...
>>
>> I feel that the discussion is getting way deeper and more technical and it needs to be from the point of view of what I was trying to achieve with my little "is.numeric.factor" function (ie, checking if an object is a factor and if all levels of this factor can be coerced to numeric values).
> You seem to be asking for a compound test: first with is.factor, then to see whether all the levels could be coerced to numeric properly. I would think that you would need something like:
>
>   if( is.factor(varname) ) { !sum(is.na(as.numeric(as.character(varname)))) } else { FALSE }
>
> ?
> David.
>
>
>> I guess that, as Duncan pointed point, using dots in function names becomes bad practice for function starring "is". I'll rename my function, that's it.
>>
>>
>> On 11/16/2015 11:43 AM, Martin Maechler wrote:
>>>>>>>> Bert Gunter <bgunter.4567 at gmail.com>
>>>>>>>>      on Mon, 16 Nov 2015 08:21:09 -0800 writes:
>>>      > Thanks Duncan. You are right; I missed this.
>>>
>>>      > Namespaces and full qualification seems the only reliable solution to
>>>      > the general issue though -- right?
>>>
>>> Not in this case;  full qualification is very very rarely needed
>>> in package code (even some "schools" do use and propagate it
>>> much more than I would recommend), and we are talking about the
>>> lattice code, i.e., package code, not user code, here.
>>>
>>> I.e., using  base::is.numeric()  would not help at all: It
>>> will still find the bogous  is.numeric.factor because that is
>>> taken before the internal default method.
>>>
>>> Also, I'm almost sure S4 dispatch would suffer from the same
>>> feature of S (and hence R) here:  You are allowed to define
>>> methods for your new classes and they are used "dynamically".
>>> (I also don't think that the problem is related to the fact that this
>>>   a.b.c() case is S3-ambigous:  a() method for "b.c" or a.b() method for "c".)
>>>
>>> Unfortunately, this can be misused to define methods for
>>> existing ("base") classes in case they are handled by the default method.
>>> OTOH, if base/stats/... already *had* a 'factor' method for
>>> is.numeric(), be it S3 or S4, no harm would have been done by
>>> the bad user defined is.numeric.factor definition, thanks to the
>>> namespace technology.
>>>
>>> To get full protection here, we would have to
>>> store "the dispatch table for all base classes" (a pretty vague notion)
>>> with the package at package build time or install time ("load time" is too late:
>>> the bad  is.numeric.factor() could already be present at package load time).
>>>
>>> I'm not sure this would be is easily feasible.... but it may be
>>> something to envisage for R 4.0.0 ..
>>>
>>> Martin
>>>
>>>      > Cheers,
>>>      > Bert
>>>
>>>      > Bert Gunter
>>>
>>>      > "Data is not information. Information is not knowledge. And knowledge
>>>      > is certainly not wisdom."
>>>      > -- Clifford Stoll
>>>
>>>
>>>      > On Mon, Nov 16, 2015 at 7:42 AM, Duncan Murdoch
>>>      > <murdoch.duncan at gmail.com> wrote:
>>>      >> On 16/11/2015 10:22 AM, Bert Gunter wrote:
>>>      >>>
>>>      >>> There is no multiple dispatch; just multiple misunderstanding.
>>>      >>>
>>>      >>> The generic function is "is.numeric" . Your method for factors is
>>>      >>> "is.numeric.factor".
>>>      >>>
>>>      >>> You need to re-study.
>>>      >>
>>>      >>
>>>      >>
>>>      >> I think the problem is with S3.  "is.numeric.factor" could be a
>>>      >> "numeric.factor" method for the "is" generic, or a "factor" method for the
>>>      >> "is.numeric" generic.  Using names with dots is a bad idea. This would be
>>>      >> all be simpler and less ambiguous if the class had been named
>>>      >> "numeric_factor" or "numericFactor" or anything without a dot.
>>>      >>
>>>      >> Duncan Murdoch
>> -- 
>> Sebastien Bihorel
>> Cognigen Corporation
>> (t) +1 716 633 3463 ext 323
>> Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> David Winsemius
> Alameda, CA, USA
>

-- 
Sebastien Bihorel
Cognigen Corporation
(t) +1 716 633 3463 ext 323
Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.

From dwinsemius at comcast.net  Tue Nov 17 01:39:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 16 Nov 2015 16:39:31 -0800
Subject: [R] {non} linear model solving
In-Reply-To: <DUB125-W5E55364E615B4BB2379E4B31D0@phx.gbl>
References: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>
	<564999F6.2030003@auckland.ac.nz>
	<DUB125-W5E55364E615B4BB2379E4B31D0@phx.gbl>
Message-ID: <7A51C09F-AC40-4FE9-BF01-16A9EA461BF1@comcast.net>


> On Nov 16, 2015, at 4:01 PM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> 
> thanks for replying.
> 
> the question about non linear model, I formed it incorrectly, I have a single objective multi constrain non linear model..I searched some R library to solve it, is there any tutorial step by step for such problem I can follow.

I don?t see how this advances the discussion. It is hardly any more specific than the vague question you posted earlier. There has already been quite a bit of effort at building the CRAN Task Views and the Optimization Task View should have popped up with any sort of effort on your part:

https://cran.r-project.org/web/views/Optimization.html

Any sort of specific response will require that you provide ?? specifics.

? 
David.
> 
> Best Regards
> 
> ----------------------------------------
>> Subject: Re: [R] linear model solving
>> To: ragia11 at hotmail.com; r-help at r-project.org
>> From: r.turner at auckland.ac.nz
>> Date: Mon, 16 Nov 2015 21:55:18 +1300
>> 
>> On 16/11/15 20:49, Ragia Ibrahim wrote:
>>> Dear group IF I had an objective function and some constrains formed
>>> in linear model form. is there a way,..library in R that helps me to
>>> solve such amodel and find the unknown variable in it?
>> 
>> 
>> This is a very ill-posed question and is unlikely to provoke any useful
>> responses. If you can't make the effort to ask a clear, precise
>> question, why should anyone make the effort to try to answer you? Even
>> if they *could* answer you. Which they can't.
>> 
>> (a) Frame a proper question, providing a minimal reproducible example.
>> 
>> (b) Do some googling; don't expect others to do your work for you.
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ragia11 at hotmail.com  Tue Nov 17 01:57:19 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Tue, 17 Nov 2015 02:57:19 +0200
Subject: [R] {non} linear model solving
In-Reply-To: <7A51C09F-AC40-4FE9-BF01-16A9EA461BF1@comcast.net>
References: <DUB125-W39BD4E5200A493EBF0AE76B31E0@phx.gbl>
	<564999F6.2030003@auckland.ac.nz>
	<DUB125-W5E55364E615B4BB2379E4B31D0@phx.gbl>,
	<7A51C09F-AC40-4FE9-BF01-16A9EA461BF1@comcast.net>
Message-ID: <DUB125-W6009AF0694D3453274CF77B31D0@phx.gbl>

appreciate replying.. I'll go through these packages documentation.
Regards

----------------------------------------
> Subject: Re: [R] {non} linear model solving
> From: dwinsemius at comcast.net
> Date: Mon, 16 Nov 2015 16:39:31 -0800
> CC: r.turner at auckland.ac.nz; r-help at r-project.org
> To: ragia11 at hotmail.com
>
>
>> On Nov 16, 2015, at 4:01 PM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>>
>> thanks for replying.
>>
>> the question about non linear model, I formed it incorrectly, I have a single objective multi constrain non linear model..I searched some R library to solve it, is there any tutorial step by step for such problem I can follow.
>
> I don?t see how this advances the discussion. It is hardly any more specific than the vague question you posted earlier. There has already been quite a bit of effort at building the CRAN Task Views and the Optimization Task View should have popped up with any sort of effort on your part:
>
> https://cran.r-project.org/web/views/Optimization.html
>
> Any sort of specific response will require that you provide ?? specifics.
>
> ?
> David.
>>
>> Best Regards
>>
>> ----------------------------------------
>>> Subject: Re: [R] linear model solving
>>> To: ragia11 at hotmail.com; r-help at r-project.org
>>> From: r.turner at auckland.ac.nz
>>> Date: Mon, 16 Nov 2015 21:55:18 +1300
>>>
>>> On 16/11/15 20:49, Ragia Ibrahim wrote:
>>>> Dear group IF I had an objective function and some constrains formed
>>>> in linear model form. is there a way,..library in R that helps me to
>>>> solve such amodel and find the unknown variable in it?
>>>
>>>
>>> This is a very ill-posed question and is unlikely to provoke any useful
>>> responses. If you can't make the effort to ask a clear, precise
>>> question, why should anyone make the effort to try to answer you? Even
>>> if they *could* answer you. Which they can't.
>>>
>>> (a) Frame a proper question, providing a minimal reproducible example.
>>>
>>> (b) Do some googling; don't expect others to do your work for you.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
 		 	   		  

From isra4884 at gmail.com  Tue Nov 17 05:18:11 2015
From: isra4884 at gmail.com (Israel Ortiz)
Date: Mon, 16 Nov 2015 22:18:11 -0600
Subject: [R] Fwd: Error survreg: Density function returned an an invalid
	matrix
In-Reply-To: <CAMESY2hMc4a+JjVgeLneHCGC17DUzn-7B68a4ourk+WyjksnRg@mail.gmail.com>
References: <mailman.7.1447498802.21143.r-help@r-project.org>
	<c10f8b$1s3dc0@ironport10.mayo.edu>
	<CAMESY2gkLx1VCceWON17cCRa1BGuqgsO4Vv+pr6zuaOtn07+4A@mail.gmail.com>
	<c10f8b$1s71pk@ironport10.mayo.edu>
	<CAMESY2hMc4a+JjVgeLneHCGC17DUzn-7B68a4ourk+WyjksnRg@mail.gmail.com>
Message-ID: <CAMESY2j=_vuRm3Vx+NYojUqvD88W_EAUmgXsp-sMD=ktp5z2aQ@mail.gmail.com>

I don?t know how to write a pareto distribution in that form, I want a
pareto function for time because I have a time variable that fits that
distribution. For a weibull and lognormal it is very easy because they are
particular cases from a extreme value and gaussian distributions. I think
it is possible to write a pareto using an exponential distribution,but I?m
not sure, I tried this using :

# OPTION 1.
# Define one distribution in terms of another

library(foreign)
library(survival)
library(VGAM)


my.pareto <- survreg.distributions$exponential
my.pareto$name <- "Pareto"
my.pareto$scale <- NULL

#Using the following transformation:

my.pareto$dtrans <- function(y) min(y)*exp(y)


survregDtest(my.pareto, TRUE)
set.seed(1)
a <- rpareto(100, 1, 6)
b <- rnorm(100,5,1)
c <- rep(1,100)
base <- cbind.data.frame(a,b,c)
mod1 <- survreg(Surv(a, c) ~ b, base, dist = my.pareto)
summary(mod1)

# It works but I don?t know if it's correct

# OPTION 2.
# Using Density, distribution function, quantile function and random
generation for the Pareto(I) distribution
# from VGAM package.

my.pareto3 <- list(name='Pareto',
                 init= function(x, weights,alpha,k){
                   alpha <- length(x)/(sum(log(x))-length(x)*log(min(x)))
                   k <-min(x)
                   c(media <-(alpha*k/(alpha-1)),varianza <-
((k/alpha)^2)*(alpha/(alpha-2)))},
                 density= function (x, alpha,k)  {
                   alpha <- length(x)/(sum(log(x))-length(x)*log(min(x)))
                   k <-min(x)
                   pvec <- seq(0.1, 0.9, by = 0.1)
                   qvec <- qpareto(pvec, alpha, k)
                     cbind(ppareto(qvec, alpha, k),
                           1-ppareto(qvec, alpha,  k),
                           dpareto(x,  alpha,  k),
                           -(alpha+x)/x,
                           (alpha+1)*(alpha+2)/x^2)},
                 deviance=function(x) {stop('deviance residuals not
defined')},
                 quantile= function(alpha,k) qpareto(seq(0.1, 0.9, by =
0.1), alpha, k))

survregDtest(my.pareto3, TRUE)

mod3 <- survreg(Surv(a, c) ~ b, base, dist = my.pareto3)

# Did not work and I don't want a fixed value for alpha and k paremeters
but the function needs a default.
# I got this error:

Error in logdensity[xok] <- log(shape[xok]) + shape[xok] * log(scale[xok])
- : NAs are not allowed in subscripted assignments
6
dpareto(x, alpha, k)
5
cbind(ppareto(qvec, alpha, k), 1 - ppareto(qvec, alpha, k), dpareto(x,
alpha, k), -(alpha + x)/x, (alpha + 1) * (alpha + 2)/x^2)
4
density(z, parms)
3
derfun(y, yy, exp(vars), sd$density, parms)
2
survreg.fit(X, Y, weights, offset, init = init, controlvals = control, dist
= dlist, scale = scale, nstrat = nstrata, strata, parms = parms)
1
survreg(Surv(a, c) ~ b, base, dist = my.pareto3)



So, I don't know what else can I do.

Thanks.



2015-11-16 11:38 GMT-06:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu>:

> You are still missing the point.
> The survreg routine handles distribution of the form:
>
>   (t(y) - m)/s ~ f, where f is a distribution on the real line.
>
> Here t is an optional but fixed transform and m= X\beta.  Beta and s=scale
> are the parameters that the routine will fit.
>
> For a log-normal, t=log and f= the density of a Gaussian mean=0, sd=1.
> The distribution function is dnorm(x)
> For a Weibull,    t=log and f= the density of the least extreme value
> distribution: exp(-exp(x))
>
> How do you write a Pareto in this form?  I assume that you would like
> survreg to solve for some parameters -- how do you map them onto the beta
> and s values that survreg will attempt to optimize?  I have not yet grasped
> what it is that you want survreg to DO.
>
> Terry T.
>
>
>
>
>
>
>
>
> On 11/16/2015 08:56 AM, Israel Ortiz wrote:
>
> Thanks Terry, I use the following formula for density:
> [image: f_X(x)= \begin{cases} \frac{\alpha
> x_\mathrm{m}^\alpha}{x^{\alpha+1}} & x \ge x_\mathrm{m}, \\ 0 & x <
> x_\mathrm{m}. \end{cases}]
>
> Where *x*m is the minimum value for x. I get this f?rmula in
> https://en.wikipedia.org/wiki/Pareto_distribution but there are a lot of
> books and sites that use the same f?rmula. This part of the code use that
> formula:
>
>  distribution <- function(x, alpha) ifelse(x > min(x) ,
> alpha*min(x)**alpha/(x**(alpha+1)), 0)
>
> Also, I support my sintax in the following post:
>
>
> http://stats.stackexchange.com/questions/78168/how-to-know-if-my-data-fits-pareto-distribution
>
> Another option is transform my variable for time from pareto to
> exponential (but this solution it's not very elegant):
>
> If X is pareto distributed then
> [image: Y = \log\left(\frac{X}{x_\mathrm{m}}\right)]
>
> it's exponential distributed.
>
> The syntax:
>
> library(foreign)
> library(survival)
> library(VGAM)
>
> set.seed(3)
> X <- rpareto(n=100, scale = 5,shape =  1)
>
> Y <- log(X/min(X))
>
> hist(X,breaks=100)
> hist(Y,breaks=100)
> b <- rnorm(100,5,1)
> c <- rep(1,100)
> base <- cbind.data.frame(X,Y,b,c)
> mod1<-survreg(Surv(Y+1, c) ~ b, base, dist = "exponential")# +1 it's
> because time should be > 1
>
> summary(mod1)
>
> This solution works but I don?t like it.
>
> Thanks.
>
>
>
>
> 2015-11-16 7:40 GMT-06:00 Therneau, Terry M., Ph.D. <therneau at mayo.edu>:
>
>> The error message states that there is an invalid value for the density.
>> A long stretch of code is not very helpful in understanding this.  What we
>> need are the definition of your density -- as it would be written in a
>> textbook.  This formula needs to give a valid response for the range
>> -infinity to +infinity.  Or more precisely, for any value that the
>> maximizer might guess at some point during the iteration.
>>
>> Terry T.
>>
>>
>> On 11/14/2015 05:00 AM, r-help-request at r-project.org wrote:
>>
>>> Thanks Terry but the error persists. See:
>>>
>>> >library(foreign)> library(survival)> library(VGAM) > mypareto <-
>>>> list(name='Pareto',+                  init=
>>>>
>>>
>> remainder of message trucated
>>
>
>
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Tue Nov 17 16:21:15 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 17 Nov 2015 10:21:15 -0500
Subject: [R] SWEAVE - a gentle introduction
Message-ID: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>

I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations. 
I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
Thank you,
John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From marc_schwartz at me.com  Tue Nov 17 16:42:49 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 17 Nov 2015 09:42:49 -0600
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
Message-ID: <1167ED61-4F63-4713-B657-17ACCF9EDE02@me.com>


> On Nov 17, 2015, at 9:21 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations. 
> I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
> Thank you,
> John
> 


John,

A couple of initial comments.

First, you will likely get some recommendations to also consider using Knitr:

  http://yihui.name/knitr/

which I do not use myself (I use Sweave), but to be fair, is worth considering as an alternative.

Second, to create stand alone documents, as opposed to web based content, you will likely want the output to be in TeX/LaTeX via Sweave, which can then become PDF based documents via the post processing of the TeX/LaTeX source. That is what I do for all of my analytic deliverables. You can also use LaTeX classes like 'Beamer' to create Powerpoint-like slides for presentation.

Fritz' web site for Sweave is here:

  http://www.statistik.lmu.de/~leisch/Sweave/

and there are some links to supporting materials there with very basic examples.

Another resource is:

  https://beckmw.files.wordpress.com/2014/02/sweave_intro1.pdf

and if you Google for Sweave Introductions and Tutorials, there are a myriad of others.

In conjunction with Sweave itself, there are a variety of supporting packages on CRAN that have related functionality (e.g. formatted LaTeX output) that are worth knowing about and are included in the Reproducible Research task view:

  https://cran.r-project.org/web/views/ReproducibleResearch.html

Regards,

Marc Schwartz


From istazahn at gmail.com  Tue Nov 17 16:46:34 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 17 Nov 2015 10:46:34 -0500
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
Message-ID: <CA+vqiLGLVcwxRz62=_QTAHWJJgBW-R+UvgBOjZ+dfoze+xPDqw@mail.gmail.com>

I suggest using knitr instead of sweave. There are plenty of tutorials
online;
http://jeromyanglim.blogspot.co.nz/2012/05/getting-started-with-r-markdown-knitr.html?m=1
might be a good place to start. Links to a full length book and other
resources are available at
  http://yihui.name/knitr/

Best,
Ista
On Nov 17, 2015 10:23 AM, "John Sorkin" <jsorkin at grecc.umaryland.edu> wrote:

> I am looking for a gentle introduction to SWEAVE, and would appreciate
> recommendations.
> I have an R program that I want to run and have the output and plots in
> one document. I believe this can be accomplished with SWEAVE. Unfortunately
> I don't know HTML, but am willing to learn. . . as I said I need a gentle
> introduction to SWEAVE.
> Thank you,
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From jlorenz at uni-goettingen.de  Tue Nov 17 09:54:16 2015
From: jlorenz at uni-goettingen.de (Lorenz, Jennifer)
Date: Tue, 17 Nov 2015 08:54:16 +0000
Subject: [R] Clustered Standard Errors?
In-Reply-To: <alpine.DEB.2.11.1511161847070.15614@paninaro.uibk.ac.at>
References: <CAJA1VFze53HFWfmyNzexAm_-3n-Hr0pG_2hBM7FqbogZ-pEYSQ@mail.gmail.com>
	<alpine.DEB.2.11.1511161847070.15614@paninaro.uibk.ac.at>
Message-ID: <51661F79C9BE0341B082F375A44402FA5736A0FF@UM-EXCDAG-A04.um.gwdg.de>

Hi Ignacio, 

following this link: http://www.ne.su.se/polopoly_fs/1.216115.1426234213!/menu/standard/file/clustering1.pdf you can download a documentation for Arai's cl-function that is mentioned in the link in your email. I used it several times and it works quite well. Just copy the function into your script and call it after you calculated your regression using the following command: 
cl(data, regression-model, cluster-variable) 

Best 
Jen 



-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Achim Zeileis
Gesendet: Montag, 16. November 2015 18:48
An: Ignacio Martinez <ignacio82 at gmail.com>
Cc: r-help <r-help at r-project.org>
Betreff: Re: [R] Clustered Standard Errors?

On Mon, 16 Nov 2015, Ignacio Martinez wrote:

> Hi,
>
> I found this
> <https://thetarzan.wordpress.com/2011/06/11/clustered-standard-errors-
> in-r/>
> post
> from 2011 for doing clustered standard errors in R.
>
> Is there any update to the lm package that allows to do this without 
> having to write your own function? In STATA is as simple as adding 
> cluster to the reg command.

For "lm" objects, the easiest solution is to use the "multiwayvcov" 
package on CRAN.

Additionally, the "plm" package on CRAN offers further options beyond the simple clustered standard errors.

> Thanks a lot for the help!
>
> Ignacio
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Tue Nov 17 17:33:52 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 17:33:52 +0100
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
Message-ID: <CAJuCY5y0Tk3DvyWb5LUbamdx6b_T0c0UsvBX8KtWyXoC4HYuHQ@mail.gmail.com>

Given that you like a gentle introduction and don't know HTML, I would
recommend rmarkdown in combination with knitr. See
http://rmarkdown.rstudio.com/ for a lot of information.

I find knitr more flexible than sweave. Markdown syntax is much easier than
HTML or latex.

Best regards,

Thierry
Op 17-nov.-2015 16:25 schreef "John Sorkin" <jsorkin at grecc.umaryland.edu>:

> I am looking for a gentle introduction to SWEAVE, and would appreciate
> recommendations.
> I have an R program that I want to run and have the output and plots in
> one document. I believe this can be accomplished with SWEAVE. Unfortunately
> I don't know HTML, but am willing to learn. . . as I said I need a gentle
> introduction to SWEAVE.
> Thank you,
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From jrkrideau at inbox.com  Tue Nov 17 18:21:13 2015
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 17 Nov 2015 09:21:13 -0800
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
Message-ID: <F30705817E0.00000341jrkrideau@inbox.com>

I've been very pleased using knitr in combination with LyX for pdf production.  

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jsorkin at grecc.umaryland.edu
> Sent: Tue, 17 Nov 2015 10:21:15 -0500
> To: r-help at r-project.org
> Subject: [R] SWEAVE - a gentle introduction
> 
> I am looking for a gentle introduction to SWEAVE, and would appreciate
> recommendations.
> I have an R program that I want to run and have the output and plots in
> one document. I believe this can be accomplished with SWEAVE.
> Unfortunately I don't know HTML, but am willing to learn. . . as I said I
> need a gentle introduction to SWEAVE.
> Thank you,
> John
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:17}}


From maechler at stat.math.ethz.ch  Tue Nov 17 18:49:41 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 17 Nov 2015 18:49:41 +0100
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CAF8bMcYOA1vBqVD+HYBN53zr57Y2sM2xnmKqxf_-eDvm8=orAQ@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
	<CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
	<CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>
	<CAF8bMcYOA1vBqVD+HYBN53zr57Y2sM2xnmKqxf_-eDvm8=orAQ@mail.gmail.com>
Message-ID: <22091.26805.67927.847477@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Mon, 16 Nov 2015 16:01:42 -0800 writes:

    > If a quick running time is important and your models involve only
    > numeric data with no missing values and you are willing to spend more
    > programming time setting things up, the lsfit() function may work
    > better for you.

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

or even faster is the extra-simple but fast  .lm.fit() function
(in R >= 3.1.0).

I've written a small demo about it and published it here,
   http://rpubs.com/maechler/fast_lm

Martin Maechler, ETH Zurich (and R Core)


    > On Mon, Nov 16, 2015 at 3:25 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
    >> Thanks a lot Bill & Bert.
    >> 
    >> Hi Bill,
    >> 
    >> Sorry i was wrong on number of records, actually, i am using two dimensional
    >> data of 250K records each. And regarding CPU usage, it was the elapsed time.
    >> Infact, i have pined one core to run R.
    >> 
    >> Thanks & Regards
    >> Sasi
    >> 
    >> On Mon, Nov 16, 2015 at 2:04 PM, William Dunlap <wdunlap at tibco.com> wrote:
    >>> 
    >>> You cannot do a linear regression with one column of data - there must
    >>> be at least one response column and one predictor.  By default, lm
    >>> throws in a constant term which gives you a second predictor.  If your
    >>> predictor is categorical, you get a new column for all but the first
    >>> unique value in it.
    >>> 
    >>> lm() deals only with double precision data, at 8 bytes/number.  Thus
    >>> 250k numbers occupies 2 million bytes.  Your three columns (in the
    >>> non-categorical-predictor case)  take up 6 million bytes,
    >>> 
    >>> lm()'s output contains several columns the size of the response
    >>> variable: residuals, effects, and fitted.values.  It also contains the
    >>> QR decomposition of the design matrix (the size of all the predictor
    >>> columns together).
    >>> 
    >>> There are also some temporary variables generated in the course of the
    >>> computation.
    >>> 
    >>> So your observed 40 MB memory usage seems reasonable.
    >>> 
    >>> Use the object.size() function to see how big objects are and str() to
    >>> look at their structure.
    >>> 
    >>> My laptop with  a 2.5 GHz Intel i7 processor takes a quarter second to
    >>> fit a simple linear model with one numeric predictor and a constant
    >>> term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
    >>> system.time() to see)?
    >>> 
    >>> 
    >>> 
    >>> Bill Dunlap
    >>> TIBCO Software
    >>> wdunlap tibco.com
    >>> 
    >>> 
    >>> On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
    >>> <ckmsasi at gmail.com> wrote:
    >>> > Hi All,
    >>> >
    >>> > I have couple of clarifications on R run-time performance. I have
    >>> > R-3.2.2
    >>> > package compiled for MIPS64 and am running it on my linux machine with
    >>> > mips64 processor (core speed 1.5GHz) and observing the following
    >>> > behaviors,
    >>> >
    >>> > 1. Applying "linear regression model" (lm) on 1MB of data (contains 1
    >>> > column of 250K records) takes ~6 seconds to complete. Anyidea, is it an
    >>> > expected behavior or not? If not, can you please the suggestions or
    >>> > options
    >>> > to improve if we have any?
    >>> >
    >>> > 2. Also, the R process runtime virtual memory is increased by 40MB after
    >>> > applying the linear model on 1MB data. Is it also expected behavior? If
    >>> > it
    >>> > is expected, can you please share the insight of memory usage?
    >>> >
    >>> > Thanks in advance.
    >>> >
    >>> > Regards
    >>> > Sasi
    >>> >
    >>> >         [[alternative HTML version deleted]]
    >>> >
    >>> > ______________________________________________
    >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> > https://stat.ethz.ch/mailman/listinfo/r-help
    >>> > PLEASE do read the posting guide
    >>> > http://www.R-project.org/posting-guide.html
    >>> > and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> 

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Nov 17 20:09:34 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Nov 2015 14:09:34 -0500
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <1167ED61-4F63-4713-B657-17ACCF9EDE02@me.com>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
	<1167ED61-4F63-4713-B657-17ACCF9EDE02@me.com>
Message-ID: <564B7B6E.3080406@gmail.com>

On 17/11/2015 10:42 AM, Marc Schwartz wrote:
>
>> On Nov 17, 2015, at 9:21 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>>
>> I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations.
>> I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
>> Thank you,
>> John
>>
>
>
> John,
>
> A couple of initial comments.
>
> First, you will likely get some recommendations to also consider using Knitr:
>
>    http://yihui.name/knitr/
>
> which I do not use myself (I use Sweave), but to be fair, is worth considering as an alternative.

He did, and I'd agree with them.  I've switched to knitr for all new 
projects and some old ones.  knitr should be thought of as Sweave 
version 2.

Duncan Murdoch

>
> Second, to create stand alone documents, as opposed to web based content, you will likely want the output to be in TeX/LaTeX via Sweave, which can then become PDF based documents via the post processing of the TeX/LaTeX source. That is what I do for all of my analytic deliverables. You can also use LaTeX classes like 'Beamer' to create Powerpoint-like slides for presentation.
>
> Fritz' web site for Sweave is here:
>
>    http://www.statistik.lmu.de/~leisch/Sweave/
>
> and there are some links to supporting materials there with very basic examples.
>
> Another resource is:
>
>    https://beckmw.files.wordpress.com/2014/02/sweave_intro1.pdf
>
> and if you Google for Sweave Introductions and Tutorials, there are a myriad of others.
>
> In conjunction with Sweave itself, there are a variety of supporting packages on CRAN that have related functionality (e.g. formatted LaTeX output) that are worth knowing about and are included in the Reproducible Research task view:
>
>    https://cran.r-project.org/web/views/ReproducibleResearch.html
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From karl.schilling at uni-bonn.de  Tue Nov 17 20:14:15 2015
From: karl.schilling at uni-bonn.de (Karl Schilling)
Date: Tue, 17 Nov 2015 20:14:15 +0100
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
Message-ID: <564B7C87.6030808@uni-bonn.de>

Dear all,

I have one observation that I do not quite understand. Maybe someone
can clarify this issue for me.

I have a data frame which I want to subset based on a grouping variable, 
say "group". Actually, "group" is a numeric value, but it is saved as a 
character. I give some code to generate an exemplary data frame below.

Now, if I use

MySubset <- subset(Data, Data$group == "..")

everything works fine, as expected. ".." stands here for the value of 
group given as a character string.

Surprisingly, I also get a correct subsetting if I simply give the plain 
numeric value of group (like MySubset <- subset(Data, Data$group == ..), 
AS LONG AS this numeric value is less then 100000.

If the numeric value is 100000 or larger, I get an empty subset.

OK, I know how to avoid this situation, but I wonder what the 
explanation for this for me rather strange behavior might be.

Thank you so much for your suggestions.


Karl Schilling


#####
Exemplary code for reproducing the above described problem:

options(stringsAsFactors = F)

# set up some data frame
value <- c(1:6)
group <- rep(c("20000", "99999", "100000"), each = 2)
Data <- data.frame(value = value, group = group)
str(Data)

# subset data frame based on the value of the variable "group",
# treating this value once as a character, and once as a number:

Data20 <- subset(Data, Data$group =="20000")
str(Data20)
Data20N <- subset(Data, Data$group ==20000)
str(Data20N)


Data99 <- subset(Data, Data$group =="99999")
str(Data99)
Data99N <- subset(Data, Data$group ==99999)
str(Data99N)
Data100 <- subset(Data, Data$group =="100000")
str(Data100)
Data100N <- subset(Data, Data$group ==100000)
str(Data100N)

-- 
Karl Schilling


From Mike.Conklin at gfk.com  Tue Nov 17 20:22:19 2015
From: Mike.Conklin at gfk.com (Conklin, Mike (GfK))
Date: Tue, 17 Nov 2015 20:22:19 +0100
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B7C87.6030808@uni-bonn.de>
References: <564B7C87.6030808@uni-bonn.de>
Message-ID: <FB454C9C2759D64BA12708C3073C30BB83224996EA@NUEW-EXMBCRB1.gfk.com>

R silently converts the integer to a character for comparison in the subset operation.  But if we explicitly do the conversion we see that it does not work with the default R settings.

> as.character(100000)
[1] "1e+05"
> as.character(99999)
[1] "99999"


--
W. Michael Conklin
EVP Marketing & Data Sciences
GfK 
T +1 763 417 4545 | M +1 612 567 8287 


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Karl Schilling
Sent: Tuesday, November 17, 2015 1:14 PM
To: r-help at r-project.org
Subject: [R] Strange result when subsetting a data frame based on a character variable

Dear all,

I have one observation that I do not quite understand. Maybe someone can clarify this issue for me.

I have a data frame which I want to subset based on a grouping variable, say "group". Actually, "group" is a numeric value, but it is saved as a character. I give some code to generate an exemplary data frame below.

Now, if I use

MySubset <- subset(Data, Data$group == "..")

everything works fine, as expected. ".." stands here for the value of group given as a character string.

Surprisingly, I also get a correct subsetting if I simply give the plain numeric value of group (like MySubset <- subset(Data, Data$group == ..), AS LONG AS this numeric value is less then 100000.

If the numeric value is 100000 or larger, I get an empty subset.

OK, I know how to avoid this situation, but I wonder what the explanation for this for me rather strange behavior might be.

Thank you so much for your suggestions.


Karl Schilling


#####
Exemplary code for reproducing the above described problem:

options(stringsAsFactors = F)

# set up some data frame
value <- c(1:6)
group <- rep(c("20000", "99999", "100000"), each = 2) Data <- data.frame(value = value, group = group)
str(Data)

# subset data frame based on the value of the variable "group", # treating this value once as a character, and once as a number:

Data20 <- subset(Data, Data$group =="20000")
str(Data20)
Data20N <- subset(Data, Data$group ==20000)
str(Data20N)


Data99 <- subset(Data, Data$group =="99999")
str(Data99)
Data99N <- subset(Data, Data$group ==99999)
str(Data99N)
Data100 <- subset(Data, Data$group =="100000")
str(Data100)
Data100N <- subset(Data, Data$group ==100000)
str(Data100N)

--
Karl Schilling

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Nov 17 20:25:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Nov 2015 14:25:07 -0500
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B7C87.6030808@uni-bonn.de>
References: <564B7C87.6030808@uni-bonn.de>
Message-ID: <564B7F13.2080806@gmail.com>

On 17/11/2015 2:14 PM, Karl Schilling wrote:
> Dear all,
>
> I have one observation that I do not quite understand. Maybe someone
> can clarify this issue for me.
>
> I have a data frame which I want to subset based on a grouping variable,
> say "group". Actually, "group" is a numeric value, but it is saved as a
> character. I give some code to generate an exemplary data frame below.
>
> Now, if I use
>
> MySubset <- subset(Data, Data$group == "..")
>
> everything works fine, as expected. ".." stands here for the value of
> group given as a character string.
>
> Surprisingly, I also get a correct subsetting if I simply give the plain
> numeric value of group (like MySubset <- subset(Data, Data$group == ..),
> AS LONG AS this numeric value is less then 100000.
>
> If the numeric value is 100000 or larger, I get an empty subset.
>
> OK, I know how to avoid this situation, but I wonder what the
> explanation for this for me rather strange behavior might be.
>
> Thank you so much for your suggestions.

If you are comparing a character value to a numeric value, the numeric 
value is converted to character using as.character() for the 
comparison.  as.character(100000) or a larger number is likely not 
"100000"; try it.  (With the options I have on my
computer, I get "1e+05".)

If you want a numeric comparison, be explicit:

subset(Data, as.numeric(Data$group) == ..)


Duncan Murdoch

>
>
> Karl Schilling
>
>
> #####
> Exemplary code for reproducing the above described problem:
>
> options(stringsAsFactors = F)
>
> # set up some data frame
> value <- c(1:6)
> group <- rep(c("20000", "99999", "100000"), each = 2)
> Data <- data.frame(value = value, group = group)
> str(Data)
>
> # subset data frame based on the value of the variable "group",
> # treating this value once as a character, and once as a number:
>
> Data20 <- subset(Data, Data$group =="20000")
> str(Data20)
> Data20N <- subset(Data, Data$group ==20000)
> str(Data20N)
>
>
> Data99 <- subset(Data, Data$group =="99999")
> str(Data99)
> Data99N <- subset(Data, Data$group ==99999)
> str(Data99N)
> Data100 <- subset(Data, Data$group =="100000")
> str(Data100)
> Data100N <- subset(Data, Data$group ==100000)
> str(Data100N)
>


From thierry.onkelinx at inbo.be  Tue Nov 17 20:30:18 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 20:30:18 +0100
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B7C87.6030808@uni-bonn.de>
References: <564B7C87.6030808@uni-bonn.de>
Message-ID: <CAJuCY5yQz-tQ7u77kfdKu9iw-GdLqXuB1fmr-M1qMNrw-sCT4Q@mail.gmail.com>

Dear Karl,

Since you compare a character with a numeric, R converts the numeric
silently. And then you're into trouble.

as.character(99999) # "99999"
as.character(100000) # "1e+5"

Bottom line, use the same type on both sides of the binary operator.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 20:14 GMT+01:00 Karl Schilling <karl.schilling at uni-bonn.de>:

> Dear all,
>
> I have one observation that I do not quite understand. Maybe someone
> can clarify this issue for me.
>
> I have a data frame which I want to subset based on a grouping variable,
> say "group". Actually, "group" is a numeric value, but it is saved as a
> character. I give some code to generate an exemplary data frame below.
>
> Now, if I use
>
> MySubset <- subset(Data, Data$group == "..")
>
> everything works fine, as expected. ".." stands here for the value of
> group given as a character string.
>
> Surprisingly, I also get a correct subsetting if I simply give the plain
> numeric value of group (like MySubset <- subset(Data, Data$group == ..), AS
> LONG AS this numeric value is less then 100000.
>
> If the numeric value is 100000 or larger, I get an empty subset.
>
> OK, I know how to avoid this situation, but I wonder what the explanation
> for this for me rather strange behavior might be.
>
> Thank you so much for your suggestions.
>
>
> Karl Schilling
>
>
> #####
> Exemplary code for reproducing the above described problem:
>
> options(stringsAsFactors = F)
>
> # set up some data frame
> value <- c(1:6)
> group <- rep(c("20000", "99999", "100000"), each = 2)
> Data <- data.frame(value = value, group = group)
> str(Data)
>
> # subset data frame based on the value of the variable "group",
> # treating this value once as a character, and once as a number:
>
> Data20 <- subset(Data, Data$group =="20000")
> str(Data20)
> Data20N <- subset(Data, Data$group ==20000)
> str(Data20N)
>
>
> Data99 <- subset(Data, Data$group =="99999")
> str(Data99)
> Data99N <- subset(Data, Data$group ==99999)
> str(Data99N)
> Data100 <- subset(Data, Data$group =="100000")
> str(Data100)
> Data100N <- subset(Data, Data$group ==100000)
> str(Data100N)
>
> --
> Karl Schilling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov 17 20:37:21 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 17 Nov 2015 11:37:21 -0800
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B7C87.6030808@uni-bonn.de>
References: <564B7C87.6030808@uni-bonn.de>
Message-ID: <CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>

> 2 == "2"
[1] TRUE

?"=="  says:

"If the two arguments are atomic vectors of different types, one is
coerced to the type of the other, the (decreasing) order of precedence
being character, complex, numeric, integer, logical and raw."

> as.character(99999)
[1] "99999"
> as.character(100000)
[1] "1e+05"
> as.character(100000) == "100000"
[1] FALSE


Cheers,
Bert




Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 17, 2015 at 11:14 AM, Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
> Dear all,
>
> I have one observation that I do not quite understand. Maybe someone
> can clarify this issue for me.
>
> I have a data frame which I want to subset based on a grouping variable, say
> "group". Actually, "group" is a numeric value, but it is saved as a
> character. I give some code to generate an exemplary data frame below.
>
> Now, if I use
>
> MySubset <- subset(Data, Data$group == "..")
>
> everything works fine, as expected. ".." stands here for the value of group
> given as a character string.
>
> Surprisingly, I also get a correct subsetting if I simply give the plain
> numeric value of group (like MySubset <- subset(Data, Data$group == ..), AS
> LONG AS this numeric value is less then 100000.
>
> If the numeric value is 100000 or larger, I get an empty subset.
>
> OK, I know how to avoid this situation, but I wonder what the explanation
> for this for me rather strange behavior might be.
>
> Thank you so much for your suggestions.
>
>
> Karl Schilling
>
>
> #####
> Exemplary code for reproducing the above described problem:
>
> options(stringsAsFactors = F)
>
> # set up some data frame
> value <- c(1:6)
> group <- rep(c("20000", "99999", "100000"), each = 2)
> Data <- data.frame(value = value, group = group)
> str(Data)
>
> # subset data frame based on the value of the variable "group",
> # treating this value once as a character, and once as a number:
>
> Data20 <- subset(Data, Data$group =="20000")
> str(Data20)
> Data20N <- subset(Data, Data$group ==20000)
> str(Data20N)
>
>
> Data99 <- subset(Data, Data$group =="99999")
> str(Data99)
> Data99N <- subset(Data, Data$group ==99999)
> str(Data99N)
> Data100 <- subset(Data, Data$group =="100000")
> str(Data100)
> Data100N <- subset(Data, Data$group ==100000)
> str(Data100N)
>
> --
> Karl Schilling
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Nov 17 21:27:12 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Nov 2015 15:27:12 -0500
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B7F13.2080806@gmail.com>
References: <564B7C87.6030808@uni-bonn.de> <564B7F13.2080806@gmail.com>
Message-ID: <564B8DA0.9030006@gmail.com>

On 17/11/2015 2:25 PM, Duncan Murdoch wrote:
> On 17/11/2015 2:14 PM, Karl Schilling wrote:
> > Dear all,
> >
> > I have one observation that I do not quite understand. Maybe someone
> > can clarify this issue for me.
> >
> > I have a data frame which I want to subset based on a grouping variable,
> > say "group". Actually, "group" is a numeric value, but it is saved as a
> > character. I give some code to generate an exemplary data frame below.
> >
> > Now, if I use
> >
> > MySubset <- subset(Data, Data$group == "..")
> >
> > everything works fine, as expected. ".." stands here for the value of
> > group given as a character string.
> >
> > Surprisingly, I also get a correct subsetting if I simply give the plain
> > numeric value of group (like MySubset <- subset(Data, Data$group == ..),
> > AS LONG AS this numeric value is less then 100000.
> >
> > If the numeric value is 100000 or larger, I get an empty subset.
> >
> > OK, I know how to avoid this situation, but I wonder what the
> > explanation for this for me rather strange behavior might be.
> >
> > Thank you so much for your suggestions.
>
> If you are comparing a character value to a numeric value, the numeric
> value is converted to character using as.character() for the
> comparison.  as.character(100000) or a larger number is likely not
> "100000"; try it.  (With the options I have on my
> computer, I get "1e+05".)
>
> If you want a numeric comparison, be explicit:
>
> subset(Data, as.numeric(Data$group) == ..)

This might be bad advice.  If Data$group is a factor (as it tends to be 
when character data is put in a dataframe), this will use the underlying 
factor code, not the visible one.  You need to use

as.numeric(as.character(Data$group))

to do the conversion you probably want.

Duncan Murdoch
>
>
> Duncan Murdoch
>
> >
> >
> > Karl Schilling
> >
> >
> > #####
> > Exemplary code for reproducing the above described problem:
> >
> > options(stringsAsFactors = F)
> >
> > # set up some data frame
> > value <- c(1:6)
> > group <- rep(c("20000", "99999", "100000"), each = 2)
> > Data <- data.frame(value = value, group = group)
> > str(Data)
> >
> > # subset data frame based on the value of the variable "group",
> > # treating this value once as a character, and once as a number:
> >
> > Data20 <- subset(Data, Data$group =="20000")
> > str(Data20)
> > Data20N <- subset(Data, Data$group ==20000)
> > str(Data20N)
> >
> >
> > Data99 <- subset(Data, Data$group =="99999")
> > str(Data99)
> > Data99N <- subset(Data, Data$group ==99999)
> > str(Data99N)
> > Data100 <- subset(Data, Data$group =="100000")
> > str(Data100)
> > Data100N <- subset(Data, Data$group ==100000)
> > str(Data100N)
> >
>


From sheroukmoawad at yahoo.com  Tue Nov 17 21:37:38 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Tue, 17 Nov 2015 20:37:38 +0000 (UTC)
Subject: [R] finding root  of nonlinear equation
References: <1257387455.5192466.1447792658811.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1257387455.5192466.1447792658811.JavaMail.yahoo@mail.yahoo.com>

Dear R experts 
I'm trying to use R to solve for the root of one nonlinear function I 
tried to use the package "rootSolve" but it didn't give any value the 
value is (numeric(0)) although I tried on changing the interval of 
root. 

I tried also the package "nleqslv" but itdidn't iterate what ever the 
guess I'm giving to the root. 

please tell me what to do? should i have to use another package or search 
in another program rather than R (like matehmatica or matlab for 
example) 


Here's the r code I've used 

>>>>>>>>>>>>> 
alpha <- 40 
beta <- 10 
n <- 20 

to1 <- c(0.26308002, 0.09350968, 0.17371400, 
0.10310227,0.15631892,0.21255328,0.12333682,0.076527274) 
to2 <-(0.31238764,0.03546888,0.41671089,0.15223569,0.68194715,0.01491989,0.37137511,0.19945158,0.23525854,0.29444296) 

tc  <- c(0,0,0.06469491,0.20090405) 

to1 <- matrix(to1) 
to2 <- matrix(to2); 
tc <- matrix(tc) 
r1 <- nrow(to1) 
r2 <- nrow(to2) 
I <- ifelse((tc>0), 1, 0) 

fn <- function(a) sum(sapply(2:4, function(j1) { 
sum(sapply(2:(j1-1), 
function(j2){ 
factorial(n-r2-I[j1]-I[j2])*factorial(r2+I[j1]+I[j2])*(j1>j2)/(((beta+sum(to1)+sum(tc)-tc[j1]-tc[j2])^(r1+alpha))*((beta+sum(to2)+tc[j1]+tc[j2])^(r2+alpha)))}))}))-sum(sapply(2:4, 
function(j1) {sum(sapply(2:(j1-1), 
function(j2){factorial(n+1-r2-I[j1]-I[j2])*factorial(r2+I[j1]+I[j2])*(j1>j2)/((n+2)*((a+beta+sum(to1)+sum(tc)-tc[j1]-tc[j2])^(r1+alpha))*((beta+sum(to2)+tc[j1]+tc[j2])^(r2+alpha)))}))}))-sum(sapply(2:4, 
function(j1) {sum(sapply(2:(j1-1), 
function(j2){factorial(n-r2-I[j1]-I[j2])*factorial(1+r2+I[j1]+I[j2])*(j1>j2)/((n+2)*((beta+sum(to1)+sum(tc)-tc[j1]-tc[j2])^(r1+alpha))*((a+beta+sum(to2)+tc[j1]+tc[j2])^(r2+alpha)))}))})) 

library(rootSolve) 
a=uniroot.all(fn,c(0,3)) 

##"a" is : numeric(0) 

library(nleqslv) 

nleqslv(5, fn) 
>>>>>>>>>> 

what ever the value i put for the guess appears as the solution of the root 
and the message is "Function criterion near zero" 

Thank you


From thierry.onkelinx at inbo.be  Tue Nov 17 21:40:08 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 17 Nov 2015 21:40:08 +0100
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <564B8DA0.9030006@gmail.com>
References: <564B7C87.6030808@uni-bonn.de> <564B7F13.2080806@gmail.com>
	<564B8DA0.9030006@gmail.com>
Message-ID: <CAJuCY5xZv8DHrj=_j4KzrJK5u+SSt7JWnes+PSnbZjikwMZS3Q@mail.gmail.com>

Dear Duncan,

I'd rather convert the numeric to character. E.g. with sprintf() or
format() in case it is a numeric vector.

subset(Data, group == "100000")
subset(Data, group == sprintf("%.f", 100000))

sprintf("%.f", 100000) # "100000"

It requires the user to think about the format, which can reduce errors.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-11-17 21:27 GMT+01:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 17/11/2015 2:25 PM, Duncan Murdoch wrote:
>
>> On 17/11/2015 2:14 PM, Karl Schilling wrote:
>> > Dear all,
>> >
>> > I have one observation that I do not quite understand. Maybe someone
>> > can clarify this issue for me.
>> >
>> > I have a data frame which I want to subset based on a grouping variable,
>> > say "group". Actually, "group" is a numeric value, but it is saved as a
>> > character. I give some code to generate an exemplary data frame below.
>> >
>> > Now, if I use
>> >
>> > MySubset <- subset(Data, Data$group == "..")
>> >
>> > everything works fine, as expected. ".." stands here for the value of
>> > group given as a character string.
>> >
>> > Surprisingly, I also get a correct subsetting if I simply give the plain
>> > numeric value of group (like MySubset <- subset(Data, Data$group == ..),
>> > AS LONG AS this numeric value is less then 100000.
>> >
>> > If the numeric value is 100000 or larger, I get an empty subset.
>> >
>> > OK, I know how to avoid this situation, but I wonder what the
>> > explanation for this for me rather strange behavior might be.
>> >
>> > Thank you so much for your suggestions.
>>
>> If you are comparing a character value to a numeric value, the numeric
>> value is converted to character using as.character() for the
>> comparison.  as.character(100000) or a larger number is likely not
>> "100000"; try it.  (With the options I have on my
>> computer, I get "1e+05".)
>>
>> If you want a numeric comparison, be explicit:
>>
>> subset(Data, as.numeric(Data$group) == ..)
>>
>
> This might be bad advice.  If Data$group is a factor (as it tends to be
> when character data is put in a dataframe), this will use the underlying
> factor code, not the visible one.  You need to use
>
> as.numeric(as.character(Data$group))
>
> to do the conversion you probably want.
>
> Duncan Murdoch
>
>
>>
>> Duncan Murdoch
>>
>> >
>> >
>> > Karl Schilling
>> >
>> >
>> > #####
>> > Exemplary code for reproducing the above described problem:
>> >
>> > options(stringsAsFactors = F)
>> >
>> > # set up some data frame
>> > value <- c(1:6)
>> > group <- rep(c("20000", "99999", "100000"), each = 2)
>> > Data <- data.frame(value = value, group = group)
>> > str(Data)
>> >
>> > # subset data frame based on the value of the variable "group",
>> > # treating this value once as a character, and once as a number:
>> >
>> > Data20 <- subset(Data, Data$group =="20000")
>> > str(Data20)
>> > Data20N <- subset(Data, Data$group ==20000)
>> > str(Data20N)
>> >
>> >
>> > Data99 <- subset(Data, Data$group =="99999")
>> > str(Data99)
>> > Data99N <- subset(Data, Data$group ==99999)
>> > str(Data99N)
>> > Data100 <- subset(Data, Data$group =="100000")
>> > str(Data100)
>> > Data100N <- subset(Data, Data$group ==100000)
>> > str(Data100N)
>> >
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Nov 17 22:57:15 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 17 Nov 2015 22:57:15 +0100
Subject: [R] Strange result when subsetting a data frame based on a
	character variable
In-Reply-To: <CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
Message-ID: <11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>


> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> 2 == "2"
> [1] TRUE
> 
> ?"=="  says:
> 
> "If the two arguments are atomic vectors of different types, one is
> coerced to the type of the other, the (decreasing) order of precedence
> being character, complex, numeric, integer, logical and raw."
> 
>> as.character(99999)
> [1] "99999"
>> as.character(100000)
> [1] "1e+05"
>> as.character(100000) == "100000"
> [1] FALSE
> 

Also notice that, for similar reasons

> 10 > "2"
[1] FALSE

(At least in most collations. I recently discovered that OSX Finder sorted 2dnorm.R between 02-Probability.toc and 03-Combinatorics-2x2.pdf.)	



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Wed Nov 18 00:03:50 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 17 Nov 2015 23:03:50 +0000
Subject: [R] Strange result when subsetting a data frame based on
	a	character variable
In-Reply-To: <11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
	<11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DF188@mb02.ads.tamu.edu>

The conversion seems to be controlled by the scipen setting:

> options("scipen")
$scipen
[1] 0
> as.character(100000)
[1] "1e+05"
> options(scipen=5)
> as.character(100000)
[1] "100000"
> as.character(1000000)
[1] "1000000"
> as.character(10000000)
[1] "10000000"

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter dalgaard
Sent: Tuesday, November 17, 2015 3:57 PM
To: Bert Gunter
Cc: r-help
Subject: Re: [R] Strange result when subsetting a data frame based on a character variable


> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> 2 == "2"
> [1] TRUE
> 
> ?"=="  says:
> 
> "If the two arguments are atomic vectors of different types, one is
> coerced to the type of the other, the (decreasing) order of precedence
> being character, complex, numeric, integer, logical and raw."
> 
>> as.character(99999)
> [1] "99999"
>> as.character(100000)
> [1] "1e+05"
>> as.character(100000) == "100000"
> [1] FALSE
> 

Also notice that, for similar reasons

> 10 > "2"
[1] FALSE

(At least in most collations. I recently discovered that OSX Finder sorted 2dnorm.R between 02-Probability.toc and 03-Combinatorics-2x2.pdf.)	



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Wed Nov 18 00:56:22 2015
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 17 Nov 2015 15:56:22 -0800
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564B7B6E.3080406@gmail.com>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
	<1167ED61-4F63-4713-B657-17ACCF9EDE02@me.com>
	<564B7B6E.3080406@gmail.com>
Message-ID: <CAFDcVCRgQRP37i1j2QO3DWOgQHawNZfy=dnGowYSNxoX+Yemvw@mail.gmail.com>

When choosing source format, it's probably helpful to know that if you
work with a Markdown-based format (e.g. Rmarkdown) you'll be able to
generate either/both HTML or/and PDF documents, whereas if you work
with LaTeX-based formats (e.g. Sweave/knitr) you will only be able
output PDF documents (at least without great efforts).

One major advantage with HTML documents/reports is that they aren't
constrained by page breaks, e.g. you don't have to worry about
generating long tables that run across two or more pages. With LaTeX
that is often a great pain.  These days even mathematical equations
renders quite well in HTML.  I tend to use HTML output for everyday
analysis reports and PDF occasionally for more final artifacts such as
supplementary notes where I want to have full control of layout,
equations, figure sizes and bibliographies.

If you plan to write package vignettes using one of the above formats,
choice of vignette format does not matter these days.  They're all
equally easy to use and incorporate in packages.

Cheers,

Henrik

On Tue, Nov 17, 2015 at 11:09 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 17/11/2015 10:42 AM, Marc Schwartz wrote:
>>
>>
>>> On Nov 17, 2015, at 9:21 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>> wrote:
>>>
>>> I am looking for a gentle introduction to SWEAVE, and would appreciate
>>> recommendations.
>>> I have an R program that I want to run and have the output and plots in
>>> one document. I believe this can be accomplished with SWEAVE. Unfortunately
>>> I don't know HTML, but am willing to learn. . . as I said I need a gentle
>>> introduction to SWEAVE.
>>> Thank you,
>>> John
>>>
>>
>>
>> John,
>>
>> A couple of initial comments.
>>
>> First, you will likely get some recommendations to also consider using
>> Knitr:
>>
>>    http://yihui.name/knitr/
>>
>> which I do not use myself (I use Sweave), but to be fair, is worth
>> considering as an alternative.
>
>
> He did, and I'd agree with them.  I've switched to knitr for all new
> projects and some old ones.  knitr should be thought of as Sweave version 2.
>
> Duncan Murdoch
>
>
>>
>> Second, to create stand alone documents, as opposed to web based content,
>> you will likely want the output to be in TeX/LaTeX via Sweave, which can
>> then become PDF based documents via the post processing of the TeX/LaTeX
>> source. That is what I do for all of my analytic deliverables. You can also
>> use LaTeX classes like 'Beamer' to create Powerpoint-like slides for
>> presentation.
>>
>> Fritz' web site for Sweave is here:
>>
>>    http://www.statistik.lmu.de/~leisch/Sweave/
>>
>> and there are some links to supporting materials there with very basic
>> examples.
>>
>> Another resource is:
>>
>>    https://beckmw.files.wordpress.com/2014/02/sweave_intro1.pdf
>>
>> and if you Google for Sweave Introductions and Tutorials, there are a
>> myriad of others.
>>
>> In conjunction with Sweave itself, there are a variety of supporting
>> packages on CRAN that have related functionality (e.g. formatted LaTeX
>> output) that are worth knowing about and are included in the Reproducible
>> Research task view:
>>
>>    https://cran.r-project.org/web/views/ReproducibleResearch.html
>>
>> Regards,
>>
>> Marc Schwartz
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Nov 18 01:05:05 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 17 Nov 2015 19:05:05 -0500
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <CAFDcVCRgQRP37i1j2QO3DWOgQHawNZfy=dnGowYSNxoX+Yemvw@mail.gmail.com>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
	<1167ED61-4F63-4713-B657-17ACCF9EDE02@me.com>
	<564B7B6E.3080406@gmail.com>
	<CAFDcVCRgQRP37i1j2QO3DWOgQHawNZfy=dnGowYSNxoX+Yemvw@mail.gmail.com>
Message-ID: <564BC0B1.2070800@gmail.com>

On 17/11/2015 6:56 PM, Henrik Bengtsson wrote:
> When choosing source format, it's probably helpful to know that if you
> work with a Markdown-based format (e.g. Rmarkdown) you'll be able to
> generate either/both HTML or/and PDF documents, whereas if you work
> with LaTeX-based formats (e.g. Sweave/knitr) you will only be able
> output PDF documents (at least without great efforts).
>
> One major advantage with HTML documents/reports is that they aren't
> constrained by page breaks, e.g. you don't have to worry about
> generating long tables that run across two or more pages. With LaTeX
> that is often a great pain.  These days even mathematical equations
> renders quite well in HTML.  I tend to use HTML output for everyday
> analysis reports and PDF occasionally for more final artifacts such as
> supplementary notes where I want to have full control of layout,
> equations, figure sizes and bibliographies.
>
> If you plan to write package vignettes using one of the above formats,
> choice of vignette format does not matter these days.  They're all
> equally easy to use and incorporate in packages.

Yes, I agree with everything you say.  One additional thing:  I've been 
working on the rgl package lately (for movable 3D graphics); it is 
possible to embed those in a PDF document, but not portably (i.e. the 
PDF viewer will matter); it is much easier to embed rgl graphics in 
HTML.  So I tend to use Markdown input through knitr (which calls 
Rmarkdown).

Duncan Murdoch

>
> Cheers,
>
> Henrik
>
> On Tue, Nov 17, 2015 at 11:09 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 17/11/2015 10:42 AM, Marc Schwartz wrote:
>>>
>>>
>>>> On Nov 17, 2015, at 9:21 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>>> wrote:
>>>>
>>>> I am looking for a gentle introduction to SWEAVE, and would appreciate
>>>> recommendations.
>>>> I have an R program that I want to run and have the output and plots in
>>>> one document. I believe this can be accomplished with SWEAVE. Unfortunately
>>>> I don't know HTML, but am willing to learn. . . as I said I need a gentle
>>>> introduction to SWEAVE.
>>>> Thank you,
>>>> John
>>>>
>>>
>>>
>>> John,
>>>
>>> A couple of initial comments.
>>>
>>> First, you will likely get some recommendations to also consider using
>>> Knitr:
>>>
>>>     http://yihui.name/knitr/
>>>
>>> which I do not use myself (I use Sweave), but to be fair, is worth
>>> considering as an alternative.
>>
>>
>> He did, and I'd agree with them.  I've switched to knitr for all new
>> projects and some old ones.  knitr should be thought of as Sweave version 2.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> Second, to create stand alone documents, as opposed to web based content,
>>> you will likely want the output to be in TeX/LaTeX via Sweave, which can
>>> then become PDF based documents via the post processing of the TeX/LaTeX
>>> source. That is what I do for all of my analytic deliverables. You can also
>>> use LaTeX classes like 'Beamer' to create Powerpoint-like slides for
>>> presentation.
>>>
>>> Fritz' web site for Sweave is here:
>>>
>>>     http://www.statistik.lmu.de/~leisch/Sweave/
>>>
>>> and there are some links to supporting materials there with very basic
>>> examples.
>>>
>>> Another resource is:
>>>
>>>     https://beckmw.files.wordpress.com/2014/02/sweave_intro1.pdf
>>>
>>> and if you Google for Sweave Introductions and Tutorials, there are a
>>> myriad of others.
>>>
>>> In conjunction with Sweave itself, there are a variety of supporting
>>> packages on CRAN that have related functionality (e.g. formatted LaTeX
>>> output) that are worth knowing about and are included in the Reproducible
>>> Research task view:
>>>
>>>     https://cran.r-project.org/web/views/ReproducibleResearch.html
>>>
>>> Regards,
>>>
>>> Marc Schwartz
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Nov 18 01:11:43 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 17 Nov 2015 16:11:43 -0800
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6DF188@mb02.ads.tamu.edu>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
	<11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6DF188@mb02.ads.tamu.edu>
Message-ID: <CAGxFJbQpw-AJcFPFS3xD_m66mEDr4+oLO3PQF1Q+=evTmRQtwg@mail.gmail.com>

Thanks, David.

Probably as one should expect.

But reinforces what others said about first doing explicit conversions
so that comparisons are not made made between differing types.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 17, 2015 at 3:03 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> The conversion seems to be controlled by the scipen setting:
>
>> options("scipen")
> $scipen
> [1] 0
>> as.character(100000)
> [1] "1e+05"
>> options(scipen=5)
>> as.character(100000)
> [1] "100000"
>> as.character(1000000)
> [1] "1000000"
>> as.character(10000000)
> [1] "10000000"
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of peter dalgaard
> Sent: Tuesday, November 17, 2015 3:57 PM
> To: Bert Gunter
> Cc: r-help
> Subject: Re: [R] Strange result when subsetting a data frame based on a character variable
>
>
>> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>> 2 == "2"
>> [1] TRUE
>>
>> ?"=="  says:
>>
>> "If the two arguments are atomic vectors of different types, one is
>> coerced to the type of the other, the (decreasing) order of precedence
>> being character, complex, numeric, integer, logical and raw."
>>
>>> as.character(99999)
>> [1] "99999"
>>> as.character(100000)
>> [1] "1e+05"
>>> as.character(100000) == "100000"
>> [1] FALSE
>>
>
> Also notice that, for similar reasons
>
>> 10 > "2"
> [1] FALSE
>
> (At least in most collations. I recently discovered that OSX Finder sorted 2dnorm.R between 02-Probability.toc and 03-Combinatorics-2x2.pdf.)
>
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Nov 18 01:59:17 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 17 Nov 2015 16:59:17 -0800
Subject: [R] Strange result when subsetting a data frame based on
	a	character variable
In-Reply-To: <11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
	<11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
Message-ID: <13F20FF9-0625-41F9-94AB-CB9EE0CB1296@dcn.davis.CA.us>

Are you sure that wasn't oh-3 rather than 03?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 17, 2015 1:57:15 PM PST, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> 
>>> 2 == "2"
>> [1] TRUE
>> 
>> ?"=="  says:
>> 
>> "If the two arguments are atomic vectors of different types, one is
>> coerced to the type of the other, the (decreasing) order of
>precedence
>> being character, complex, numeric, integer, logical and raw."
>> 
>>> as.character(99999)
>> [1] "99999"
>>> as.character(100000)
>> [1] "1e+05"
>>> as.character(100000) == "100000"
>> [1] FALSE
>> 
>
>Also notice that, for similar reasons
>
>> 10 > "2"
>[1] FALSE
>
>(At least in most collations. I recently discovered that OSX Finder
>sorted 2dnorm.R between 02-Probability.toc and
>03-Combinatorics-2x2.pdf.)


From pdalgd at gmail.com  Wed Nov 18 02:11:44 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Nov 2015 02:11:44 +0100
Subject: [R] Strange result when subsetting a data frame based on a
	character variable
In-Reply-To: <13F20FF9-0625-41F9-94AB-CB9EE0CB1296@dcn.davis.CA.us>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
	<11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
	<13F20FF9-0625-41F9-94AB-CB9EE0CB1296@dcn.davis.CA.us>
Message-ID: <D94E70D6-FF4C-457D-8E4A-1EF4F9EC0A82@gmail.com>


> On 18 Nov 2015, at 01:59 , Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> Are you sure that wasn't oh-3 rather than 03?

Sure I'm sure. I even cut+pasted the filenames from the offending dir... It's all just Apple trying to be helpful (and failing, again).

O2 < 2d < O3 had been even stranger, no?

-p

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On November 17, 2015 1:57:15 PM PST, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>> 
>>>> 2 == "2"
>>> [1] TRUE
>>> 
>>> ?"=="  says:
>>> 
>>> "If the two arguments are atomic vectors of different types, one is
>>> coerced to the type of the other, the (decreasing) order of
>> precedence
>>> being character, complex, numeric, integer, logical and raw."
>>> 
>>>> as.character(99999)
>>> [1] "99999"
>>>> as.character(100000)
>>> [1] "1e+05"
>>>> as.character(100000) == "100000"
>>> [1] FALSE
>>> 
>> 
>> Also notice that, for similar reasons
>> 
>>> 10 > "2"
>> [1] FALSE
>> 
>> (At least in most collations. I recently discovered that OSX Finder
>> sorted 2dnorm.R between 02-Probability.toc and
>> 03-Combinatorics-2x2.pdf.)	
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Wed Nov 18 06:31:45 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 17 Nov 2015 21:31:45 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <CABbvK+GbWiCAPLDbzcEti0vstKUsPaj2Kk43c4bm9pQcaG4BcA@mail.gmail.com>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
	<CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
	<CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>
	<CAF8bMcYOA1vBqVD+HYBN53zr57Y2sM2xnmKqxf_-eDvm8=orAQ@mail.gmail.com>
	<22091.26805.67927.847477@stat.math.ethz.ch>
	<CABbvK+GbWiCAPLDbzcEti0vstKUsPaj2Kk43c4bm9pQcaG4BcA@mail.gmail.com>
Message-ID: <CAF8bMcbcWPWWfoPEtywgj00XrKd8p2e56a_4ROVuWgb+awTv4A@mail.gmail.com>

That is what I meant about saving compute time and increasing programming time.
You can do prediction by do the matrix multiplication explicitly.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Nov 17, 2015 at 9:01 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
> Thanks a lot, Martin and William. Looks like, we can't apply prediction on
> lsfit and lm.fit objects. Because, i am trying to use lm object to predict
> the values for new data frame.
>
> Thanks & Regards
> Sasi
>
> On Tue, Nov 17, 2015 at 9:49 AM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>
>> >>>>> William Dunlap <wdunlap at tibco.com>
>> >>>>>     on Mon, 16 Nov 2015 16:01:42 -0800 writes:
>>
>>     > If a quick running time is important and your models involve only
>>     > numeric data with no missing values and you are willing to spend
>> more
>>     > programming time setting things up, the lsfit() function may work
>>     > better for you.
>>
>>     > Bill Dunlap
>>     > TIBCO Software
>>     > wdunlap tibco.com
>>
>> or even faster is the extra-simple but fast  .lm.fit() function
>> (in R >= 3.1.0).
>>
>> I've written a small demo about it and published it here,
>>    http://rpubs.com/maechler/fast_lm
>>
>> Martin Maechler, ETH Zurich (and R Core)
>>
>>
>>     > On Mon, Nov 16, 2015 at 3:25 PM, Sasikumar Kandhasamy
>> <ckmsasi at gmail.com> wrote:
>>     >> Thanks a lot Bill & Bert.
>>     >>
>>     >> Hi Bill,
>>     >>
>>     >> Sorry i was wrong on number of records, actually, i am using two
>> dimensional
>>     >> data of 250K records each. And regarding CPU usage, it was the
>> elapsed time.
>>     >> Infact, i have pined one core to run R.
>>     >>
>>     >> Thanks & Regards
>>     >> Sasi
>>     >>
>>     >> On Mon, Nov 16, 2015 at 2:04 PM, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>     >>>
>>     >>> You cannot do a linear regression with one column of data - there
>> must
>>     >>> be at least one response column and one predictor.  By default, lm
>>     >>> throws in a constant term which gives you a second predictor.  If
>> your
>>     >>> predictor is categorical, you get a new column for all but the
>> first
>>     >>> unique value in it.
>>     >>>
>>     >>> lm() deals only with double precision data, at 8 bytes/number.
>> Thus
>>     >>> 250k numbers occupies 2 million bytes.  Your three columns (in the
>>     >>> non-categorical-predictor case)  take up 6 million bytes,
>>     >>>
>>     >>> lm()'s output contains several columns the size of the response
>>     >>> variable: residuals, effects, and fitted.values.  It also contains
>> the
>>     >>> QR decomposition of the design matrix (the size of all the
>> predictor
>>     >>> columns together).
>>     >>>
>>     >>> There are also some temporary variables generated in the course of
>> the
>>     >>> computation.
>>     >>>
>>     >>> So your observed 40 MB memory usage seems reasonable.
>>     >>>
>>     >>> Use the object.size() function to see how big objects are and
>> str() to
>>     >>> look at their structure.
>>     >>>
>>     >>> My laptop with  a 2.5 GHz Intel i7 processor takes a quarter
>> second to
>>     >>> fit a simple linear model with one numeric predictor and a
>> constant
>>     >>> term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
>>     >>> system.time() to see)?
>>     >>>
>>     >>>
>>     >>>
>>     >>> Bill Dunlap
>>     >>> TIBCO Software
>>     >>> wdunlap tibco.com
>>     >>>
>>     >>>
>>     >>> On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
>>     >>> <ckmsasi at gmail.com> wrote:
>>     >>> > Hi All,
>>     >>> >
>>     >>> > I have couple of clarifications on R run-time performance. I
>> have
>>     >>> > R-3.2.2
>>     >>> > package compiled for MIPS64 and am running it on my linux
>> machine with
>>     >>> > mips64 processor (core speed 1.5GHz) and observing the following
>>     >>> > behaviors,
>>     >>> >
>>     >>> > 1. Applying "linear regression model" (lm) on 1MB of data
>> (contains 1
>>     >>> > column of 250K records) takes ~6 seconds to complete. Anyidea,
>> is it an
>>     >>> > expected behavior or not? If not, can you please the suggestions
>> or
>>     >>> > options
>>     >>> > to improve if we have any?
>>     >>> >
>>     >>> > 2. Also, the R process runtime virtual memory is increased by
>> 40MB after
>>     >>> > applying the linear model on 1MB data. Is it also expected
>> behavior? If
>>     >>> > it
>>     >>> > is expected, can you please share the insight of memory usage?
>>     >>> >
>>     >>> > Thanks in advance.
>>     >>> >
>>     >>> > Regards
>>     >>> > Sasi
>>     >>> >
>>     >>> >         [[alternative HTML version deleted]]
>>     >>> >
>>     >>> > ______________________________________________
>>     >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>>     >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>     >>> > PLEASE do read the posting guide
>>     >>> > http://www.R-project.org/posting-guide.html
>>     >>> > and provide commented, minimal, self-contained, reproducible
>> code.
>>     >>
>>     >>
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>     > and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Wed Nov 18 02:41:05 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Nov 2015 12:41:05 +1100
Subject: [R] Strange result when subsetting a data frame based on a
 character variable
In-Reply-To: <D94E70D6-FF4C-457D-8E4A-1EF4F9EC0A82@gmail.com>
References: <564B7C87.6030808@uni-bonn.de>
	<CAGxFJbRLnVF-=zQbK8CRuBA5PfuXV2PX804VkAo2zcdFTiUqog@mail.gmail.com>
	<11E17FAE-9530-4A92-82C4-409F1BBEB08B@gmail.com>
	<13F20FF9-0625-41F9-94AB-CB9EE0CB1296@dcn.davis.CA.us>
	<D94E70D6-FF4C-457D-8E4A-1EF4F9EC0A82@gmail.com>
Message-ID: <CA+8X3fWjWnZXFoaNeiAB5j0fjbfDWrOmFk5W85ADpb0Y-Oxgvg@mail.gmail.com>

peter dalgaard wrote:

> O2 < 2d < O3 had been even stranger, no?

Don't give those dudes in Cupertino any more bright ideas, okay?

Jim

On Wed, Nov 18, 2015 at 12:11 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 18 Nov 2015, at 01:59 , Jeff Newmiller <jdnewmil at dcn.davis.CA.us>
> wrote:
> >
> > Are you sure that wasn't oh-3 rather than 03?
>
> Sure I'm sure. I even cut+pasted the filenames from the offending dir...
> It's all just Apple trying to be helpful (and failing, again).
>
> O2 < 2d < O3 had been even stranger, no?
>
> -p
>
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                      Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On November 17, 2015 1:57:15 PM PST, peter dalgaard <pdalgd at gmail.com>
> wrote:
> >>
> >>> On 17 Nov 2015, at 20:37 , Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >>>
> >>>> 2 == "2"
> >>> [1] TRUE
> >>>
> >>> ?"=="  says:
> >>>
> >>> "If the two arguments are atomic vectors of different types, one is
> >>> coerced to the type of the other, the (decreasing) order of
> >> precedence
> >>> being character, complex, numeric, integer, logical and raw."
> >>>
> >>>> as.character(99999)
> >>> [1] "99999"
> >>>> as.character(100000)
> >>> [1] "1e+05"
> >>>> as.character(100000) == "100000"
> >>> [1] FALSE
> >>>
> >>
> >> Also notice that, for similar reasons
> >>
> >>> 10 > "2"
> >> [1] FALSE
> >>
> >> (At least in most collations. I recently discovered that OSX Finder
> >> sorted 2dnorm.R between 02-Probability.toc and
> >> 03-Combinatorics-2x2.pdf.)
> >
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ckmsasi at gmail.com  Wed Nov 18 06:01:36 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Tue, 17 Nov 2015 21:01:36 -0800
Subject: [R] R runtime performance and memory usage
In-Reply-To: <22091.26805.67927.847477@stat.math.ethz.ch>
References: <CABbvK+HQ7K3GGaf_y6bgUd9BdLnoe8UdGOYmqytRb-isY_RyLQ@mail.gmail.com>
	<CAF8bMcZh1d5BXjjJy6q+sM7RC-pRr9zpvOk3SkV1zX4QVgOE+g@mail.gmail.com>
	<CABbvK+ETnQOC2p=9W84xNjWO0QeQHZMerTF1tmDn2O64KuQ68w@mail.gmail.com>
	<CAF8bMcYOA1vBqVD+HYBN53zr57Y2sM2xnmKqxf_-eDvm8=orAQ@mail.gmail.com>
	<22091.26805.67927.847477@stat.math.ethz.ch>
Message-ID: <CABbvK+GbWiCAPLDbzcEti0vstKUsPaj2Kk43c4bm9pQcaG4BcA@mail.gmail.com>

Thanks a lot, Martin and William. Looks like, we can't apply prediction on
lsfit and lm.fit objects. Because, i am trying to use lm object to predict
the values for new data frame.

Thanks & Regards
Sasi

On Tue, Nov 17, 2015 at 9:49 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> William Dunlap <wdunlap at tibco.com>
> >>>>>     on Mon, 16 Nov 2015 16:01:42 -0800 writes:
>
>     > If a quick running time is important and your models involve only
>     > numeric data with no missing values and you are willing to spend more
>     > programming time setting things up, the lsfit() function may work
>     > better for you.
>
>     > Bill Dunlap
>     > TIBCO Software
>     > wdunlap tibco.com
>
> or even faster is the extra-simple but fast  .lm.fit() function
> (in R >= 3.1.0).
>
> I've written a small demo about it and published it here,
>    http://rpubs.com/maechler/fast_lm
>
> Martin Maechler, ETH Zurich (and R Core)
>
>
>     > On Mon, Nov 16, 2015 at 3:25 PM, Sasikumar Kandhasamy <
> ckmsasi at gmail.com> wrote:
>     >> Thanks a lot Bill & Bert.
>     >>
>     >> Hi Bill,
>     >>
>     >> Sorry i was wrong on number of records, actually, i am using two
> dimensional
>     >> data of 250K records each. And regarding CPU usage, it was the
> elapsed time.
>     >> Infact, i have pined one core to run R.
>     >>
>     >> Thanks & Regards
>     >> Sasi
>     >>
>     >> On Mon, Nov 16, 2015 at 2:04 PM, William Dunlap <wdunlap at tibco.com>
> wrote:
>     >>>
>     >>> You cannot do a linear regression with one column of data - there
> must
>     >>> be at least one response column and one predictor.  By default, lm
>     >>> throws in a constant term which gives you a second predictor.  If
> your
>     >>> predictor is categorical, you get a new column for all but the
> first
>     >>> unique value in it.
>     >>>
>     >>> lm() deals only with double precision data, at 8 bytes/number.
> Thus
>     >>> 250k numbers occupies 2 million bytes.  Your three columns (in the
>     >>> non-categorical-predictor case)  take up 6 million bytes,
>     >>>
>     >>> lm()'s output contains several columns the size of the response
>     >>> variable: residuals, effects, and fitted.values.  It also contains
> the
>     >>> QR decomposition of the design matrix (the size of all the
> predictor
>     >>> columns together).
>     >>>
>     >>> There are also some temporary variables generated in the course of
> the
>     >>> computation.
>     >>>
>     >>> So your observed 40 MB memory usage seems reasonable.
>     >>>
>     >>> Use the object.size() function to see how big objects are and
> str() to
>     >>> look at their structure.
>     >>>
>     >>> My laptop with  a 2.5 GHz Intel i7 processor takes a quarter
> second to
>     >>> fit a simple linear model with one numeric predictor and a constant
>     >>> term.  6 seconds sounds slow.  Is that cpu or elapsed time (use
>     >>> system.time() to see)?
>     >>>
>     >>>
>     >>>
>     >>> Bill Dunlap
>     >>> TIBCO Software
>     >>> wdunlap tibco.com
>     >>>
>     >>>
>     >>> On Mon, Nov 16, 2015 at 12:25 PM, Sasikumar Kandhasamy
>     >>> <ckmsasi at gmail.com> wrote:
>     >>> > Hi All,
>     >>> >
>     >>> > I have couple of clarifications on R run-time performance. I have
>     >>> > R-3.2.2
>     >>> > package compiled for MIPS64 and am running it on my linux
> machine with
>     >>> > mips64 processor (core speed 1.5GHz) and observing the following
>     >>> > behaviors,
>     >>> >
>     >>> > 1. Applying "linear regression model" (lm) on 1MB of data
> (contains 1
>     >>> > column of 250K records) takes ~6 seconds to complete. Anyidea,
> is it an
>     >>> > expected behavior or not? If not, can you please the suggestions
> or
>     >>> > options
>     >>> > to improve if we have any?
>     >>> >
>     >>> > 2. Also, the R process runtime virtual memory is increased by
> 40MB after
>     >>> > applying the linear model on 1MB data. Is it also expected
> behavior? If
>     >>> > it
>     >>> > is expected, can you please share the insight of memory usage?
>     >>> >
>     >>> > Thanks in advance.
>     >>> >
>     >>> > Regards
>     >>> > Sasi
>     >>> >
>     >>> >         [[alternative HTML version deleted]]
>     >>> >
>     >>> > ______________________________________________
>     >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
>     >>> > https://stat.ethz.ch/mailman/listinfo/r-help
>     >>> > PLEASE do read the posting guide
>     >>> > http://www.R-project.org/posting-guide.html
>     >>> > and provide commented, minimal, self-contained, reproducible
> code.
>     >>
>     >>
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Nov 18 09:41:38 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 18 Nov 2015 08:41:38 +0000
Subject: [R] Converting daily time series to monthly?
In-Reply-To: <CAEZ46x+NVAO-Mr7N0tALmCPFQEEpvfCR2rYMhZ7drL-RSo8FYQ@mail.gmail.com>
References: <CAEZ46x+NVAO-Mr7N0tALmCPFQEEpvfCR2rYMhZ7drL-RSo8FYQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C50011ED@SRVEXCHMBX.precheza.cz>

Hi

You can use various ways. I would recommend to look at ?aggregate together with cut ?cut.POSIXt.

Your data shall be converted to POSIX type ?strptime before using them for cut and aggregate.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Chattopadhyay, Somsubhra
> Sent: Monday, November 16, 2015 8:37 PM
> To: r-help at r-project.org
> Subject: [R] Converting daily time series to monthly?
>
> Hi all,
>
> I have daily time series of rainfall for sufficiently long period of
> time (70 years). I want to aggregate the data series into monthly,
> seasonal and annual basis. I know excel can handle this with the pivot
> table functionality. However, I have too many data points so, it's not
> a very smart way of dealing with this that way. I am wondering a simple
> R code or package may help me out here. I appreciate any feedback.
>
> Thanks
> Som
>
> --
> Somsubhra Chattopadhyay
> Graduate Research Assistant
> Biosystem and Agricultural Engineering Department University of
> Kentucky, Lexington, KY 40546
> Email: schattop14 at uky.edu
> Cell: 9198026951
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From luca.cerone at gmail.com  Wed Nov 18 09:49:00 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 18 Nov 2015 09:49:00 +0100
Subject: [R] R hist density wrong?
Message-ID: <CAFnz2-8xJe5YJsvWE8s-SccZBvfq2BrT5BTU0VHG8a1eWx9Prw@mail.gmail.com>

Dear all,
this is probably a very naive question but I can't understand what
hist() means by density.

A very simple example:

h <- hist(c(1,1,2,3), plot=F)

h$counts
[1] 2 1 0 1

h$density
[1] 1.0 0.5 0.0 0.5

The counts are as I expect, but density is quite puzzling for me.

I would have expected to obtain the probability of that bin (i.e. 0.5,
0.25, 0, 0.25),
but I can't understand how those numbers come out.

Sometimes sum(h$density) is equal to 1 as I would expect, though.

What am I misunderstanding here?

Thanks a lot for the help!

Cheers,
Luca


From murdoch.duncan at gmail.com  Wed Nov 18 09:57:31 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 18 Nov 2015 03:57:31 -0500
Subject: [R] R hist density wrong?
In-Reply-To: <CAFnz2-8xJe5YJsvWE8s-SccZBvfq2BrT5BTU0VHG8a1eWx9Prw@mail.gmail.com>
References: <CAFnz2-8xJe5YJsvWE8s-SccZBvfq2BrT5BTU0VHG8a1eWx9Prw@mail.gmail.com>
Message-ID: <564C3D7B.2080007@gmail.com>

On 18/11/2015 3:49 AM, Luca Cerone wrote:
> Dear all,
> this is probably a very naive question but I can't understand what
> hist() means by density.
>
> A very simple example:
>
> h <- hist(c(1,1,2,3), plot=F)
>
> h$counts
> [1] 2 1 0 1
>
> h$density
> [1] 1.0 0.5 0.0 0.5
>
> The counts are as I expect, but density is quite puzzling for me.
>
> I would have expected to obtain the probability of that bin (i.e. 0.5,
> 0.25, 0, 0.25),
> but I can't understand how those numbers come out.

The bins are 0.5 wide (see h$breaks).  Density has the usual meaning for 
continuous distributions:  probability per unit.  So a density of 1 per 
unit over a distance of 0.5 gives a probability of 0.5.
>
> Sometimes sum(h$density) is equal to 1 as I would expect, though.

sum(h$density) would rarely make sense to calculate, any more than the 
sum of the normal density function at 4 points would.  You want to 
integrate a density.  The formula for that is 
sum(h$density*diff(h$breaks)).

Duncan Murdoch
>
> What am I misunderstanding here?
>
> Thanks a lot for the help!
>
> Cheers,
> Luca
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j.para.fernandez at hotmail.com  Wed Nov 18 11:19:49 2015
From: j.para.fernandez at hotmail.com (=?iso-8859-1?B?SmVz+nMgUGFyYSBGZXJu4W5kZXo=?=)
Date: Wed, 18 Nov 2015 11:19:49 +0100
Subject: [R] Get means of matrix
In-Reply-To: <DUB131-W61F32A8EFDB5BAB2D3E988CC1C0@phx.gbl>
References: <DUB131-W65334018DDB260B09E7C05CC1E0@phx.gbl>,
	<01E2FB25-7AF5-4B58-AF2F-2AEBA9C5BBDB@decsai.ugr.es>,
	<DUB131-W48ED7D7DE32EAA18D2194ECC1D0@phx.gbl>,
	<B7A741EA-2CE2-41DB-BE0A-BE63B72A2495@decsai.ugr.es>,
	<DUB131-W61F32A8EFDB5BAB2D3E988CC1C0@phx.gbl>
Message-ID: <DUB131-W698C30F7152106A992994CC1C0@phx.gbl>

Hi everyone

I have a dataframe "data" wich is the result of join multiple csv (400 rows and 600cols every csv). The "data" dataframe has n rows and m columns (200000 rows and 600 cols) , and I have add a new colum, "csvdata", in which I specify the number of csv at wich those data belong. 

So, the dataframe "data" looks like:

x1    x2     x3    ....    xn    csvdata
21   23    32    ....    12    1
27   21    39    ....    14    1
24   22    30    ....    11    1
..............................................
21   24    32    ....   19     2
27   21    39    ....    14    2
..............................................
27   22     30    ....    11    n

   

I want to store into a matrix the mean values of different substes of data of every csv, for example: 

region1,1 (rows 1:20,columns 1:20) for every "csvdata" value
region 2,1 (rows 21:40,columns 1:20) para every "csvdata" value
....

And so on for hole data.frame. 

I have tryed:

area1<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
area2<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)

But this error is the output I obtain:
 
Error in tapply(data[1:30, ], datos$nueva, mean, na.rm = T) : 
  arguments must have same length

I?m sure that it is not very complex to do it, but I have no idea of how to do it.

Thanks for all. 

 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Nov 18 11:40:18 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 18 Nov 2015 10:40:18 +0000
Subject: [R] Get means of matrix
In-Reply-To: <DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
References: <DUB131-W65334018DDB260B09E7C05CC1E0@phx.gbl>,
	<01E2FB25-7AF5-4B58-AF2F-2AEBA9C5BBDB@decsai.ugr.es>,
	<DUB131-W48ED7D7DE32EAA18D2194ECC1D0@phx.gbl>,
	<B7A741EA-2CE2-41DB-BE0A-BE63B72A2495@decsai.ugr.es>,
	<DUB131-W61F32A8EFDB5BAB2D3E988CC1C0@phx.gbl>
	<DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001347@SRVEXCHMBX.precheza.cz>

Hi

See in line

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jes?s
> Para Fern?ndez
> Sent: Wednesday, November 18, 2015 11:20 AM
> To: r-help at r-project.org
> Subject: [R] Get means of matrix
>
> Hi everyone
>
> I have a dataframe "data" wich is the result of join multiple csv (400
> rows and 600cols every csv). The "data" dataframe has n rows and m
> columns (200000 rows and 600 cols) , and I have add a new colum,
> "csvdata", in which I specify the number of csv at wich those data
> belong.
>
> So, the dataframe "data" looks like:
>
> x1    x2     x3    ....    xn    csvdata
> 21   23    32    ....    12    1
> 27   21    39    ....    14    1
> 24   22    30    ....    11    1
> ..............................................
> 21   24    32    ....   19     2
> 27   21    39    ....    14    2
> ..............................................
> 27   22     30    ....    11    n
>
>
>
> I want to store into a matrix the mean values of different substes of
> data of every csv, for example:
>
> region1,1 (rows 1:20,columns 1:20) for every "csvdata" value region 2,1
> (rows 21:40,columns 1:20) para every "csvdata" value ....
>
> And so on for hole data.frame.
>
> I have tryed:
>
> area1<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
> area2<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
>
> But this error is the output I obtain:
>
> Error in tapply(data[1:30, ], datos$nueva, mean, na.rm = T) :
>   arguments must have same length

Most probably length(datos$csvdata) is not 20 as you specified by data[1:20,1].

If you have already number of csv file in your data$csvdata you can do

area <- aggregate(data[,1:n], list(data$csvdata), mean, na.rm=TRUE)

If you want to aggregate each 20 rows you can elaborate index

ind <- rep(1:20, each=20)
area <- aggregate(data[,1:n], list(ind), mean, na.rm=TRUE)

Cheers
Petr

>
> I m sure that it is not very complex to do it, but I have no idea of
> how to do it.
>
> Thanks for all.
>
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From drjimlemon at gmail.com  Wed Nov 18 11:43:42 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 18 Nov 2015 21:43:42 +1100
Subject: [R] Get means of matrix
In-Reply-To: <DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
References: <DUB131-W65334018DDB260B09E7C05CC1E0@phx.gbl>
	<01E2FB25-7AF5-4B58-AF2F-2AEBA9C5BBDB@decsai.ugr.es>
	<DUB131-W48ED7D7DE32EAA18D2194ECC1D0@phx.gbl>
	<B7A741EA-2CE2-41DB-BE0A-BE63B72A2495@decsai.ugr.es>
	<DUB131-W61F32A8EFDB5BAB2D3E988CC1C0@phx.gbl>
	<DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
Message-ID: <CA+8X3fUV_3rHkWq5NSVZw7WPFjuQ+SeTXuwETUwNGf1-12K0vQ@mail.gmail.com>

Hi Jesus,
While I do not have your data and cannot test this, the problem may be that
you are using two different names for the data frame. Is this more or less
what you want?

datos<-data.frame(x1=sample(20:40,40,TRUE),x2=sample(20:40,40,TRUE),
 x3=sample(20:40,40,TRUE),csvdata=rep(1:2,each=20))
sapply(datos[datos$csvdata==1,],mean,na.rm=TRUE)
sapply(datos[datos$csvdata==2,],mean,na.rm=TRUE)

Jim


On Wed, Nov 18, 2015 at 9:19 PM, Jes?s Para Fern?ndez <
j.para.fernandez at hotmail.com> wrote:

> Hi everyone
>
> I have a dataframe "data" wich is the result of join multiple csv (400
> rows and 600cols every csv). The "data" dataframe has n rows and m columns
> (200000 rows and 600 cols) , and I have add a new colum, "csvdata", in
> which I specify the number of csv at wich those data belong.
>
> So, the dataframe "data" looks like:
>
> x1    x2     x3    ....    xn    csvdata
> 21   23    32    ....    12    1
> 27   21    39    ....    14    1
> 24   22    30    ....    11    1
> ..............................................
> 21   24    32    ....   19     2
> 27   21    39    ....    14    2
> ..............................................
> 27   22     30    ....    11    n
>
>
>
> I want to store into a matrix the mean values of different substes of data
> of every csv, for example:
>
> region1,1 (rows 1:20,columns 1:20) for every "csvdata" value
> region 2,1 (rows 21:40,columns 1:20) para every "csvdata" value
> ....
>
> And so on for hole data.frame.
>
> I have tryed:
>
> area1<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
> area2<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
>
> But this error is the output I obtain:
>
> Error in tapply(data[1:30, ], datos$nueva, mean, na.rm = T) :
>   arguments must have same length
>
> I?m sure that it is not very complex to do it, but I have no idea of how
> to do it.
>
> Thanks for all.
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Wed Nov 18 12:12:06 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Wed, 18 Nov 2015 11:12:06 +0000 (GMT)
Subject: [R] Getting rid of unwanted csv files
Message-ID: <1027888327.682893.1447845126622.JavaMail.open-xchange@oxbe20.tb.ukmail.iss.as9143.net>

Hi I have got a large folder with hundreds of csv files in it   The problem is
that some of them are junk, and I know which ones are junk because they were
created on certain days, that is before I had honed the programme generating
them to ultimate perfection

I'd like to get shot of the junk files, but I can't distinguish them by
names/label from the ones I want to keep -- the only criterion is the date of
making them, but I cannot see a way of telling R to look at the date rather than
the name/label   Obviously I could plough by hand, but there are loads and if
anyone has any ideas I'd be grateful

Thanks, Nick Wray

PS Just had a thought -- Going off R-piste now but of course is it poss to get
rid of them within Windows (which I'm using) rather than R itself?
	[[alternative HTML version deleted]]


From john.laing at gmail.com  Wed Nov 18 12:30:14 2015
From: john.laing at gmail.com (John Laing)
Date: Wed, 18 Nov 2015 06:30:14 -0500
Subject: [R] Getting rid of unwanted csv files
In-Reply-To: <1027888327.682893.1447845126622.JavaMail.open-xchange@oxbe20.tb.ukmail.iss.as9143.net>
References: <1027888327.682893.1447845126622.JavaMail.open-xchange@oxbe20.tb.ukmail.iss.as9143.net>
Message-ID: <CAA3Wa=s2UZuUuLCsdSP8K4Pcf=S6GchgsemJYYnue+C8Egom=A@mail.gmail.com>

?file.info

On Wed, Nov 18, 2015 at 6:12 AM, WRAY NICHOLAS <nicholas.wray at ntlworld.com>
wrote:

> Hi I have got a large folder with hundreds of csv files in it   The
> problem is
> that some of them are junk, and I know which ones are junk because they
> were
> created on certain days, that is before I had honed the programme
> generating
> them to ultimate perfection
>
> I'd like to get shot of the junk files, but I can't distinguish them by
> names/label from the ones I want to keep -- the only criterion is the date
> of
> making them, but I cannot see a way of telling R to look at the date
> rather than
> the name/label   Obviously I could plough by hand, but there are loads and
> if
> anyone has any ideas I'd be grateful
>
> Thanks, Nick Wray
>
> PS Just had a thought -- Going off R-piste now but of course is it poss to
> get
> rid of them within Windows (which I'm using) rather than R itself?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Nov 18 14:56:42 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 18 Nov 2015 07:56:42 -0600
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <mailman.5.1447844402.8473.r-help@r-project.org>
References: <mailman.5.1447844402.8473.r-help@r-project.org>
Message-ID: <c10f8b$1snnft@ironport10.mayo.edu>

As a digest reader I am late to the discussion, but let me toss in 2 further notes.

1. Three advantages of knitr over Sweave
   a. The book "Dynamic documents with R and knitr".  It is well written; sitting down for 
an evening with the first half (70 pages) is a pretty good way to learn the package.  The 
second half covers features you may or may not use over time.  My only complaint about the 
book is that it needs a longer index; I have had several cases of "I know I read about 
xxx, but where was it?".  But this is ameliorated by

   b. Good online resources: manuals, tutorials, and question/answer pairs on various lists.

   c. Ongoing support. Sweave is static.

2. Latex vs markdown  (knitr supports both)
   One can choose "latex style" or "markdown style" for writing your documents.  I know 
latex very well (I wrote my book using it) but recommend markdown to all others in my 
department.  The latter is about 1/3 the learning curve.  Markdown produces very nice 
output, latex goes the extra mile to produce true book quality.  But one rarely needs that 
extra polish, and even more rarely needs it enough to justify the extra learning cost.  I 
still use the latex form myself as it is not at all difficult to use --- once you learn it.

Terry Therneau

On 11/18/2015 05:00 AM, r-help-request at r-project.org wrote:
> I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations.
> I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
> Thank you,
> John


From par at leijonhufvud.org  Wed Nov 18 15:34:48 2015
From: par at leijonhufvud.org (Par Leijonhufvud)
Date: Wed, 18 Nov 2015 14:34:48 +0000
Subject: [R] Getting rid of unwanted csv files
In-Reply-To: <1027888327.682893.1447845126622.JavaMail.open-xchange@oxbe20.tb.ukmail.iss.as9143.net>
References: <1027888327.682893.1447845126622.JavaMail.open-xchange@oxbe20.tb.ukmail.iss.as9143.net>
Message-ID: <20151118143447.GB24941@onza.mythic-beasts.com>

WRAY NICHOLAS <nicholas.wray at ntlworld.com> [2015.11.18] wrote:
> 
> I'd like to get shot of the junk files, but I can't distinguish them by
> names/label from the ones I want to keep -- the only criterion is the date of
> making them, but I cannot see a way of telling R to look at the date rather than
> the name/label   Obviously I could plough by hand, but there are loads and if
> anyone has any ideas I'd be grateful

> PS Just had a thought -- Going off R-piste now but of course is it poss to get
> rid of them within Windows (which I'm using) rather than R itself?
> 	[[alternative HTML version deleted]]

You can list them by date, and them select all the ones with a certain
date range.

With other operating systems it would be even simplier... 

P?r

-- 
P?r Leijonhufvud			par at leijonhufvud.org


From peter.langfelder at gmail.com  Wed Nov 18 19:05:50 2015
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 18 Nov 2015 10:05:50 -0800
Subject: [R] WGCNA cluster
In-Reply-To: <60766BE34A0ACB44A137DBCF361980DE015D64D016BE@MBX.servizi.int>
References: <60766BE34A0ACB44A137DBCF361980DE015D64D016BE@MBX.servizi.int>
Message-ID: <CA+hbrhVN6jXwjqZTv+6UkCUtXi+2Y=gbu6zYUWHQQC7k7ZQ7gQ@mail.gmail.com>

Hi Giovanni,

please follow Tutorial I, section 3 (particularly 3d, "Summary output
of network analysis results") at
http://labs.genetics.ucla.edu/horvath/CoexpressionNetwork/Rpackages/WGCNA/Tutorials/index.html
. This will show you how to output module membership of each CpG into
a file. If you want to assign different colors, you will have to do it
yourself - first choose a set of colors (you will need at least 26),
then you will need to write a simple R code to change the colors.

Best,

Peter

On Wed, Nov 18, 2015 at 3:31 AM, Calice Giovanni
<giovanni.calice at crob.it> wrote:
> Hi all,
>
> I am using WGCNA for methylation level network construction e modules detection.
> In my network there are 26 modules with assigned colors and numeric labels, id.
>
> Which Is the best way to reassign different color to each module?
>
> How to know the elements associated to each colored module in the cluster?
>
>
> Thanks in advance, Regards
>
> Giovanni
>
>
> Laboratory of Preclinical and Translational Research
> IRCCS - CROB Oncology Referral Center of Basilicata - Italy
>
> Servizio di posta elettronica della Regione Basilicata "Powered By Microsoft Exchange 2007"
> Sito web istituzionale www.regione.basilicata.it


From giovcalice at gmail.com  Wed Nov 18 13:43:22 2015
From: giovcalice at gmail.com (Giovanni Calice)
Date: Wed, 18 Nov 2015 13:43:22 +0100
Subject: [R] WGCNA cluster
Message-ID: <CAAmhn2etu1joXX7f34JMmQ8Abyq1xpOSM+hFC-F3C17jtoESxA@mail.gmail.com>

Hi all,

I am using WGCNA for methylation level network construction e modules
detection.
In my network there are 26 modules with assigned colors and numeric labels,
id.

Which Is the best way to reassign different color to each module?

How to know the elements associated to each colored module in the cluster?


Thanks in advance, Regards

Giovanni


Laboratory of Preclinical and Translational Research
IRCCS - CROB Oncology Referral Center of Basilicata - Italy

	[[alternative HTML version deleted]]


From maria.vila at ciberehd.org  Wed Nov 18 16:35:10 2015
From: maria.vila at ciberehd.org (=?UTF-8?Q?Maria_Vila_Casades=C3=BAs?=)
Date: Wed, 18 Nov 2015 16:35:10 +0100
Subject: [R] Glmnet penalty.factor with multigaussian response
Message-ID: <CAK6bpOcbsJXWEUmrY_uvAP1RSTfL2OUQ5Qqdkdcfo9swMJXQ4w@mail.gmail.com>

Hi all,
I'm trying to use glmnet with penalty factors in a multigaussian response
model.

In case of the gaussian response the input for penalty factors is a vector,
but I haven't figured out how can I use penalty factors with a
multigaussian response, and even if it's possible. I've tried to use a
matrix of values, it doesn't give any error or warning but it seems to be
using only part of the data: the first column.

Do you know if it's possible to use penalty factors in this case? Or are
there any other alternatives?

So far, I've tried this:

cv<-cv.glmnet(x,y,alpha=.5,family = "mgaussian", penalty.factor=pen.matrix.tot)

Where:

> dim(x)[1]  40 723> dim(y)[1] 40  7

Penalty matrix looks like:

> pen.matrix.tot[1:5,1:5]
            NAT2 CYP1A2 CYP2A6 CYP2A7 CYP2A13
hsa-let-7a     1      0      1      1       1
hsa-let-7a*    1      1      1      1       1
hsa-let-7b     0      0      1      1       1
hsa-let-7b*    1      1      1      1       1
hsa-let-7c     0      0      1      1       1
> dim(pen.matrix.tot)[1] 723   7

The coefficients for lambda.min:

 > fullcoefs[1:5,1:5]
                    NAT2      CYP1A2       CYP2A6     CYP2A7     CYP2A13
 hsa-let-7a           NA          NA           NA         NA          NA
 hsa-let-7a*          NA          NA           NA         NA          NA
 hsa-let-7b   0.10222788  0.06621902  0.064668084  0.3887164  0.06369455
 hsa-let-7b*          NA          NA           NA         NA          NA
 hsa-let-7c  -0.06436899 -0.03362183 -0.007440406 -0.2581606
-0.01517728> dim(fullcoefs)[1] 723   7


More speciffically, in this case I would expect some value for
"hsa-let-7a":"CYP1A2", as the penalty for it is 0.

Many thanks!

Maria

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Wed Nov 18 19:48:04 2015
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 18 Nov 2015 11:48:04 -0700
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
References: <564AFF9B020000CB001401B3@smtp.medicine.umaryland.edu>
Message-ID: <CAFEqCdzSTnMfqLy=yUqrvPRYUkJc2DYFSiVaW1Gkeo8z8bN-Wg@mail.gmail.com>

John,

One additional point that I have not seen brought up yet.  If your
main goal is to have all the output from an existing R script put into
a single output file then you should look at the `stitch` function in
the knitr package.  This will take an existing R script and convert it
to one of the formats that knitr can process, then processes it for
you without you needing to modify the script or learn any of the
markdown (LaTeX or HTML or other).  You do not have a lot of control
over how the output looks, but it is quick and easy.

For the long run I would suggest learning to use the full power of
knitr, but stitch (and the related spin function which gives a few
more options) is a quick way to process an existing script.

On Tue, Nov 17, 2015 at 8:21 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations.
> I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
> Thank you,
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:18}}


From john.maindonald at anu.edu.au  Wed Nov 18 20:22:53 2015
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 18 Nov 2015 19:22:53 +0000
Subject: [R] SWEAVE - a gentle introduction
In-Reply-To: <mailman.4.1447844402.8473.r-help@r-project.org>
References: <mailman.4.1447844402.8473.r-help@r-project.org>
Message-ID: <836B38D4-FFB7-4FF8-97DA-97AA43FD9B17@anu.edu.au>

What?s more, for pdf output one can use R Markdown and judiciously
sneak in html and/or LaTeX (consider however what the processing
steps might do to such markup).


John Maindonald             email: john.maindonald at anu.edu.au<mailto:john.maindonald at anu.edu.au>


On 19/11/2015, at 00:00, r-help-request at r-project.org<mailto:r-help-request at r-project.org> wrote:

From: Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>>
Subject: Re: [R] SWEAVE - a gentle introduction
Date: 18 November 2015 08:09:34 NZDT
To: Marc Schwartz <marc_schwartz at me.com<mailto:marc_schwartz at me.com>>, John Sorkin <jsorkin at grecc.umaryland.edu<mailto:jsorkin at grecc.umaryland.edu>>
Cc: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>


On 17/11/2015 10:42 AM, Marc Schwartz wrote:

On Nov 17, 2015, at 9:21 AM, John Sorkin <jsorkin at grecc.umaryland.edu<mailto:jsorkin at grecc.umaryland.edu>> wrote:

I am looking for a gentle introduction to SWEAVE, and would appreciate recommendations.
I have an R program that I want to run and have the output and plots in one document. I believe this can be accomplished with SWEAVE. Unfortunately I don't know HTML, but am willing to learn. . . as I said I need a gentle introduction to SWEAVE.
Thank you,
John



John,

A couple of initial comments.

First, you will likely get some recommendations to also consider using Knitr:

  http://yihui.name/knitr/

which I do not use myself (I use Sweave), but to be fair, is worth considering as an alternative.

He did, and I'd agree with them.  I've switched to knitr for all new projects and some old ones.  knitr should be thought of as Sweave version 2.

Duncan Murdoch


	[[alternative HTML version deleted]]


From gangchen6 at gmail.com  Wed Nov 18 20:28:34 2015
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 18 Nov 2015 14:28:34 -0500
Subject: [R] Problem running mvrnorm
Message-ID: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>

 I?m running R 3.2.2 on a Linux server (Redhat 4.4.7-16), and having the
following problem.

It works fine with the following:

require('MASS?)
var(mvrnorm(n = 1000, rep(0, 2), Sigma=matrix(c(10,3,3,2),2,2)))

However, when running the following in a loop with simulated data (Sigma):

# Sigma defined somewhere else
mvrnorm(n=1000, rep(0, 190), Sigma)

I get this opaque message:

 *** caught illegal operation ***
address 0x7fe78f8693d2, cause 'illegal operand'

Traceback:
 1: eigen(Sigma, symmetric = TRUE)
 2: mvrnorm(n = nr, rep(0, NN), Sigma)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace

I tried to do core dump (option 1), but it didn?t go anywhere (hanging
there forever). I also ran the same code on a Mac, and there was no problem
at all. What is causing the problem on the Linux server? In case the
variance-covariance matrix ?Sigma? is needed, I can provide its definition
later.

Thanks,
Gang

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Wed Nov 18 21:56:35 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 19 Nov 2015 09:56:35 +1300
Subject: [R] [FORGED]  Problem running mvrnorm
In-Reply-To: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>
References: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>
Message-ID: <564CE603.2050808@auckland.ac.nz>


I cobbled together a 190 x 190 positive definite matrix Sigma and ran 
your example.  I got a result instantaneously, with no error message. 
(I'm running Linux; an ancient Fedora 17 system.)

So the problem is peculiar to your particular Sigma.

As the error message tells you, the problem comes from doing an 
eigendecomposition of Sigma.  So start your investigation by doing

     E <- eigen(Sigma,symmetric=TRUE)

Presumably that will lead to the same error.  How to get around this 
error is beyond the scope of my capabilities.

You *might* get somewhere by using the singular value decomposition
(equivalent for a positive definite matrix) rather than the 
eigendecomposition.  I have the vague notion that the svd is more 
numerically robust than eigendecomposition.  However I might well have 
that wrong.

Doing anything in 190 dimensions is bound to be fraught with numeric
peril.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 19/11/15 08:28, Gang Chen wrote:
>   I?m running R 3.2.2 on a Linux server (Redhat 4.4.7-16), and having the
> following problem.
>
> It works fine with the following:
>
> require('MASS?)
> var(mvrnorm(n = 1000, rep(0, 2), Sigma=matrix(c(10,3,3,2),2,2)))
>
> However, when running the following in a loop with simulated data (Sigma):
>
> # Sigma defined somewhere else
> mvrnorm(n=1000, rep(0, 190), Sigma)
>
> I get this opaque message:
>
>   *** caught illegal operation ***
> address 0x7fe78f8693d2, cause 'illegal operand'
>
> Traceback:
>   1: eigen(Sigma, symmetric = TRUE)
>   2: mvrnorm(n = nr, rep(0, NN), Sigma)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
>
> I tried to do core dump (option 1), but it didn?t go anywhere (hanging
> there forever). I also ran the same code on a Mac, and there was no problem
> at all. What is causing the problem on the Linux server? In case the
> variance-covariance matrix ?Sigma? is needed, I can provide its definition
> later.


From djmuser at gmail.com  Wed Nov 18 22:37:17 2015
From: djmuser at gmail.com (Dennis Murphy)
Date: Wed, 18 Nov 2015 13:37:17 -0800
Subject: [R] Get means of matrix
In-Reply-To: <DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
References: <DUB131-W65334018DDB260B09E7C05CC1E0@phx.gbl>
	<01E2FB25-7AF5-4B58-AF2F-2AEBA9C5BBDB@decsai.ugr.es>
	<DUB131-W48ED7D7DE32EAA18D2194ECC1D0@phx.gbl>
	<B7A741EA-2CE2-41DB-BE0A-BE63B72A2495@decsai.ugr.es>
	<DUB131-W61F32A8EFDB5BAB2D3E988CC1C0@phx.gbl>
	<DUB131-W698C30F7152106A992994CC1C0@phx.gbl>
Message-ID: <CADv2QyEqO7a4MYNhuuJhUvT9TponJtf+XyEC-=8BiUGafiw9yA@mail.gmail.com>

Hi:

Here's another way to look at the problem. Instead of manually adding
a new column after k datasets have been read in, read your individual
data files into a list, as long as they all have the same variable
names and the same class (in this case, data.frame). Then create a
vector of names for the list components and use 'apply family' logic
to get the column means, returning the combined results to a data
frame or matrix. Here's a toy example to illustrate the point.
Firstly, three data frames are created and saved to external files:

# Create some artificial data and ship to external files

d1 <- data.frame(x1 = rpois(10, 20), x2 = rpois(10, 23), x3 = rpois(10, 25))
d2 <- data.frame(x1 = rpois(10, 20), x2 = rpois(10, 23), x3 = rpois(10, 25))
d3 <- data.frame(x1 = rpois(10, 20), x2 = rpois(10, 23), x3 = rpois(10, 25))

write.csv(d1, file = "d1.csv", row.names = TRUE, quote = FALSE)
write.csv(d2, file = "d2.csv", row.names = TRUE, quote = FALSE)
write.csv(d3, file = "d3.csv", row.names = TRUE, quote = FALSE)

###
# Now, read them back in and store them in a list object

# Vector of file names to process
files <- paste0("d", 1:3, ".csv")

# Create the list of data frames and assign names to list components
L <- lapply(files, function(x) read.csv(x, header = TRUE))
names(L) <- paste0("d", 1:3)

# Compute column means from each list component and row bind them
# Method 1: base R
do.call(rbind, lapply(L, colMeans))


# Method 2: plyr package
library(plyr)
ldply(L, colMeans)


Dennis

On Wed, Nov 18, 2015 at 2:19 AM, Jes?s Para Fern?ndez
<j.para.fernandez at hotmail.com> wrote:
> Hi everyone
>
> I have a dataframe "data" wich is the result of join multiple csv (400 rows and 600cols every csv). The "data" dataframe has n rows and m columns (200000 rows and 600 cols) , and I have add a new colum, "csvdata", in which I specify the number of csv at wich those data belong.
>
> So, the dataframe "data" looks like:
>
> x1    x2     x3    ....    xn    csvdata
> 21   23    32    ....    12    1
> 27   21    39    ....    14    1
> 24   22    30    ....    11    1
> ..............................................
> 21   24    32    ....   19     2
> 27   21    39    ....    14    2
> ..............................................
> 27   22     30    ....    11    n
>
>
>
> I want to store into a matrix the mean values of different substes of data of every csv, for example:
>
> region1,1 (rows 1:20,columns 1:20) for every "csvdata" value
> region 2,1 (rows 21:40,columns 1:20) para every "csvdata" value
> ....
>
> And so on for hole data.frame.
>
> I have tryed:
>
> area1<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
> area2<-tapply(as.matrix(data[1:20,1]),datos$csvdata,mean,na.rm=T)
>
> But this error is the output I obtain:
>
> Error in tapply(data[1:30, ], datos$nueva, mean, na.rm = T) :
>   arguments must have same length
>
> I?m sure that it is not very complex to do it, but I have no idea of how to do it.
>
> Thanks for all.
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gangchen6 at gmail.com  Wed Nov 18 22:54:39 2015
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 18 Nov 2015 16:54:39 -0500
Subject: [R] [FORGED]  Problem running mvrnorm
In-Reply-To: <564CE603.2050808@auckland.ac.nz>
References: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>
	<564CE603.2050808@auckland.ac.nz>
Message-ID: <CAHmzXO5vGf1DvvssxwViXmJ+YtFvm9DoO-6OgDDMveTr7wwLkQ@mail.gmail.com>

Thanks a lot for the pointer, Rolf!

You're correct that

 E <- eigen(Sigma,symmetric=TRUE)

does lead to the same error on the RedHat machine. However, the same
computation on my Mac works fine:

E <- eigen(Sigma,symmetric=TRUE)

E$values

  [1] 4.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6 2.6
2.6
 [19] 2.6 2.6 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
 [37] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
 [55] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
 [73] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
 [91] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
[109] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
[127] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
[145] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
[163] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8
0.8
[181] 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8 0.8

As you can see, all the eigenvalues are truly positive. Is it possible that
some numerical library or package is required by eigen() but missing on the
Linux server? In case the real Sigma is useful, here is how the matrix
Sigma is defined:

constrSigma <- function(n, sig) {
   N <- n*(n-1)/2
   Sigma <- diag(N)
   bgn <- 1
   for(ii in (n-1):1) {
      end <- bgn+(ii-1)
      Sigma[bgn:end,bgn:end][lower.tri(Sigma[bgn:end,bgn:end])] <- rep(sig,
ii*(ii-1)/2)
      if(ii<(n-1)) {
         xx <- cbind(rep(sig,ii), diag(ii)*sig)
         yy <- xx
         for(jj in 1:(n-1-ii)) {
            if(jj>1) {
               xx <- cbind(rep(0, ii), xx)
               yy <- cbind(xx, yy)
            }
         }
         Sigma[bgn:end,1:(bgn-1)] <- yy
      }
      bgn <- end+1
   }
   Sigma[upper.tri(Sigma)] <- t(Sigma)[upper.tri(t(Sigma))]
   return(Sigma)
}

Sigma <- constrSigma(20, 0.1)
mvrnorm(n=1000, rep(0, 190), Sigma)






On Wed, Nov 18, 2015 at 3:56 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:
>
>
> I cobbled together a 190 x 190 positive definite matrix Sigma and ran
your example.  I got a result instantaneously, with no error message. (I'm
running Linux; an ancient Fedora 17 system.)
>
> So the problem is peculiar to your particular Sigma.
>
> As the error message tells you, the problem comes from doing an
eigendecomposition of Sigma.  So start your investigation by doing
>
>     E <- eigen(Sigma,symmetric=TRUE)
>
> Presumably that will lead to the same error.  How to get around this
error is beyond the scope of my capabilities.
>
> You *might* get somewhere by using the singular value decomposition
> (equivalent for a positive definite matrix) rather than the
eigendecomposition.  I have the vague notion that the svd is more
numerically robust than eigendecomposition.  However I might well have that
wrong.
>
> Doing anything in 190 dimensions is bound to be fraught with numeric
> peril.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> On 19/11/15 08:28, Gang Chen wrote:
>>
>>   I?m running R 3.2.2 on a Linux server (Redhat 4.4.7-16), and having the
>> following problem.
>>
>> It works fine with the following:
>>
>> require('MASS?)
>> var(mvrnorm(n = 1000, rep(0, 2), Sigma=matrix(c(10,3,3,2),2,2)))
>>
>> However, when running the following in a loop with simulated data
(Sigma):
>>
>> # Sigma defined somewhere else
>> mvrnorm(n=1000, rep(0, 190), Sigma)
>>
>> I get this opaque message:
>>
>>   *** caught illegal operation ***
>> address 0x7fe78f8693d2, cause 'illegal operand'
>>
>> Traceback:
>>   1: eigen(Sigma, symmetric = TRUE)
>>   2: mvrnorm(n = nr, rep(0, NN), Sigma)
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>>
>> I tried to do core dump (option 1), but it didn?t go anywhere (hanging
>> there forever). I also ran the same code on a Mac, and there was no
problem
>> at all. What is causing the problem on the Linux server? In case the
>> variance-covariance matrix ?Sigma? is needed, I can provide its
definition
>> later.
>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Nov 18 23:25:34 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 18 Nov 2015 23:25:34 +0100
Subject: [R] [FORGED]  Problem running mvrnorm
In-Reply-To: <564CE603.2050808@auckland.ac.nz>
References: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>
	<564CE603.2050808@auckland.ac.nz>
Message-ID: <8EA450AE-49F9-43D7-A4E4-5316A0689416@gmail.com>

I have a sense of a tiny bell ringing faintly from the distant past... There may be an issue with some versions of BLAS/LAPACK on some systems showing up in eigendecompositions. 

Checking... hmm, there have been several issues over time but I don't see anything that would be directly related to the present issue. There was a really stupid bug in R's reference BLAS, but that was found and fixed two years ago, and besides, it involved complex eigenvalues which I don't see creeping into mvrnorm. Also PR#15211 located an issue that could cause a hang (not segfault) which ended in a WONTFIX situation because it really needed to be fixed in LAPACK.

Anyways, some details about versions, hardware (you may be using a library optimized for the wrong CPU), would be needed. Even better if you can set up to run under Valgrind or a debugger to pinpoint the cause of the trouble. Also, check that you aren't simply running out of memory.

Pragmatically speaking, couldn't you get away with using a Choleski decomposition of Sigma? 

-pd 


> On 18 Nov 2015, at 21:56 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> I cobbled together a 190 x 190 positive definite matrix Sigma and ran your example.  I got a result instantaneously, with no error message. (I'm running Linux; an ancient Fedora 17 system.)
> 
> So the problem is peculiar to your particular Sigma.
> 
> As the error message tells you, the problem comes from doing an eigendecomposition of Sigma.  So start your investigation by doing
> 
>    E <- eigen(Sigma,symmetric=TRUE)
> 
> Presumably that will lead to the same error.  How to get around this error is beyond the scope of my capabilities.
> 
> You *might* get somewhere by using the singular value decomposition
> (equivalent for a positive definite matrix) rather than the eigendecomposition.  I have the vague notion that the svd is more numerically robust than eigendecomposition.  However I might well have that wrong.
> 
> Doing anything in 190 dimensions is bound to be fraught with numeric
> peril.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> On 19/11/15 08:28, Gang Chen wrote:
>>  I?m running R 3.2.2 on a Linux server (Redhat 4.4.7-16), and having the
>> following problem.
>> 
>> It works fine with the following:
>> 
>> require('MASS?)
>> var(mvrnorm(n = 1000, rep(0, 2), Sigma=matrix(c(10,3,3,2),2,2)))
>> 
>> However, when running the following in a loop with simulated data (Sigma):
>> 
>> # Sigma defined somewhere else
>> mvrnorm(n=1000, rep(0, 190), Sigma)
>> 
>> I get this opaque message:
>> 
>>  *** caught illegal operation ***
>> address 0x7fe78f8693d2, cause 'illegal operand'
>> 
>> Traceback:
>>  1: eigen(Sigma, symmetric = TRUE)
>>  2: mvrnorm(n = nr, rep(0, NN), Sigma)
>> 
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> 
>> I tried to do core dump (option 1), but it didn?t go anywhere (hanging
>> there forever). I also ran the same code on a Mac, and there was no problem
>> at all. What is causing the problem on the Linux server? In case the
>> variance-covariance matrix ?Sigma? is needed, I can provide its definition
>> later.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tmrsg11 at gmail.com  Wed Nov 18 23:31:07 2015
From: tmrsg11 at gmail.com (C W)
Date: Wed, 18 Nov 2015 17:31:07 -0500
Subject: [R] How to find the likelihood, MLE and plot it?
Message-ID: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>

Dear R list,

I am trying to find the MLE of the likelihood function.  I will plot the
log-likelihood to check my answer.

Here's my R code:

xvec <- c(2,5,3,7,-3,-2,0)

fn <- function(theta){

sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))

}

gn <- Vectorize(fn)

curve(gn, -5, 20)

optimize(gn, c(-5, 20))

$minimum

[1] 1.714286

$objective

[1] 39.71429


The MLE using optimize() is 1.71, but what curve() gives me is the absolute
minimum.

I think 1.71 is the right answer, but why does the graph showing it's the
minimum?  What is going on here?

Thank so much!

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Nov 19 00:14:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 19 Nov 2015 12:14:59 +1300
Subject: [R] [FORGED]  Problem running mvrnorm
In-Reply-To: <CAHmzXO5vGf1DvvssxwViXmJ+YtFvm9DoO-6OgDDMveTr7wwLkQ@mail.gmail.com>
References: <CAHmzXO5iUdxe3rvprntMgTgarqv2h1tVbUPyfXWPp1acnYxzZA@mail.gmail.com>
	<564CE603.2050808@auckland.ac.nz>
	<CAHmzXO5vGf1DvvssxwViXmJ+YtFvm9DoO-6OgDDMveTr7wwLkQ@mail.gmail.com>
Message-ID: <564D0673.6050606@auckland.ac.nz>

On 19/11/15 10:54, Gang Chen wrote:
> Thanks a lot for the pointer, Rolf!
>
> You're correct that
>
>   E <- eigen(Sigma,symmetric=TRUE)
>
> does lead to the same error on the RedHat machine. However, the same
> computation on my Mac works fine:
>
> E <- eigen(Sigma,symmetric=TRUE)
>
> E$values

<SNIP>

I used your constrSigma() function to create Sigma and did eigen() to 
it.  In a trice I got results which agree with those that you show.

So it's not *Linux* as such that is the problem.

(a) What happens if you do svd(Sigma)?  Or, in accordance with Peter 
Dalgaard's suggestion, chol(Sigma)?

(b) It would seem that you need to follow the lines of enquiry suggested 
by Peter.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Thu Nov 19 00:23:53 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 19 Nov 2015 12:23:53 +1300
Subject: [R] [FORGED]  How to find the likelihood, MLE and plot it?
In-Reply-To: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
Message-ID: <564D0889.2000407@auckland.ac.nz>

On 19/11/15 11:31, C W wrote:
> Dear R list,
>
> I am trying to find the MLE of the likelihood function.  I will plot the
> log-likelihood to check my answer.
>
> Here's my R code:
>
> xvec <- c(2,5,3,7,-3,-2,0)
>
> fn <- function(theta){
>
> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>
> }
>
> gn <- Vectorize(fn)
>
> curve(gn, -5, 20)
>
> optimize(gn, c(-5, 20))
>
> $minimum
>
> [1] 1.714286
>
> $objective
>
> [1] 39.71429
>
>
> The MLE using optimize() is 1.71, but what curve() gives me is the absolute
> minimum.
>
> I think 1.71 is the right answer, but why does the graph showing it's the
> minimum?  What is going on here?

Your graph shows that there is indeed a *minimum* at 1.71.  And 
optimise() is correctly finding that minimum.

If you want optimise() to find the maximum, set maximum=TRUE.  In which 
case it will return "20" (or something very close to 20).

Your function fn() appears not to be the log likelihood that you had in 
mind.  Perhaps you the negative of fn()???

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From rmh at temple.edu  Thu Nov 19 02:54:54 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Nov 2015 20:54:54 -0500
Subject: [R] is.na behavior
Message-ID: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>

What is the rationale for the following warning in R-3.2.2?

> is.na(expression(abcd))
[1] FALSE
Warning message:
In is.na(expression(abcd)) :
  is.na() applied to non-(list or vector) of type 'expression'

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Nov 19 03:36:22 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 18 Nov 2015 18:36:22 -0800
Subject: [R] is.na behavior
In-Reply-To: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
Message-ID: <5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>


> On Nov 18, 2015, at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
> What is the rationale for the following warning in R-3.2.2?
> 
>> is.na(expression(abcd))
> [1] FALSE
> Warning message:
> In is.na(expression(abcd)) :
>  is.na() applied to non-(list or vector) of type ?expression?

Well, the R interpreter does think that this is not a list:

> is.list(expression(abcd))
[1] FALSE


> methods(is.na)
 [1] is.na,abIndex-method       is.na,denseMatrix-method  
 [3] is.na,indMatrix-method     is.na,nsparseMatrix-method
 [5] is.na,nsparseVector-method is.na,sparseMatrix-method 
 [7] is.na,sparseVector-method  is.na.coxph.penalty*      
 [9] is.na.data.frame           is.na.numeric_version     
[11] is.na.POSIXlt              is.na.raster*             
[13] is.na.ratetable*           is.na.Surv 


So the rationale is probably the same as the rationale for this warning:

> is.na(call("mean", 1:4))
[1] FALSE FALSE
Warning message:
In is.na(call("mean", 1:4)) :
  is.na() applied to non-(list or vector) of type ?language'

> 	[[alternative HTML version deleted]]


I?m somewhat puzzled at your use of HTML for an Rhelp posting. I thought you were a longtime R user?

______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Thu Nov 19 04:03:21 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Nov 2015 22:03:21 -0500
Subject: [R] is.na behavior
In-Reply-To: <5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>
Message-ID: <CAGx1TMBDHaji4Lvu7HCXmDrjQPz74jr92cJdWtWR0dVkgbz1xA@mail.gmail.com>

David,

Your answer begs the question.
What is the problem with non-(list or vector) of type language.
To my eye both expression(abcd) and call("mean") look like they have
non-missing values, hence I anticipated that they are not NA, and therefore
that is.na() would return FALSE without a warning.

On the html email, I turned that off years ago.  It looks like gmail
(who handles
my university's email accounts) turned it back on.  I just turned it off again.
I too find it very annoying to have to revisit setting changes that I
didn't make.
Thank you for letting me know.

Rich


On Wed, Nov 18, 2015 at 9:36 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Nov 18, 2015, at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>
>> What is the rationale for the following warning in R-3.2.2?
>>
>>> is.na(expression(abcd))
>> [1] FALSE
>> Warning message:
>> In is.na(expression(abcd)) :
>>  is.na() applied to non-(list or vector) of type ?expression?
>
> Well, the R interpreter does think that this is not a list:
>
>> is.list(expression(abcd))
> [1] FALSE
>
>
>> methods(is.na)
>  [1] is.na,abIndex-method       is.na,denseMatrix-method
>  [3] is.na,indMatrix-method     is.na,nsparseMatrix-method
>  [5] is.na,nsparseVector-method is.na,sparseMatrix-method
>  [7] is.na,sparseVector-method  is.na.coxph.penalty*
>  [9] is.na.data.frame           is.na.numeric_version
> [11] is.na.POSIXlt              is.na.raster*
> [13] is.na.ratetable*           is.na.Surv
>
>
> So the rationale is probably the same as the rationale for this warning:
>
>> is.na(call("mean", 1:4))
> [1] FALSE FALSE
> Warning message:
> In is.na(call("mean", 1:4)) :
>   is.na() applied to non-(list or vector) of type ?language'
>
>>       [[alternative HTML version deleted]]
>
>
> I?m somewhat puzzled at your use of HTML for an Rhelp posting. I thought you were a longtime R user?
>
> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From wdunlap at tibco.com  Thu Nov 19 04:04:12 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 18 Nov 2015 19:04:12 -0800
Subject: [R] is.na behavior
In-Reply-To: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
Message-ID: <CAF8bMcZ0njiezQeuryXCL=OT6+jyC9x5TiAj64--80NgRkB_-Q@mail.gmail.com>

You can convert the expression to a list and use is.na on that:
   > e <- expression(1+NA, NA, 7, function(x)x+1)
   > is.na(as.list(e))
   [1] FALSE  TRUE FALSE FALSE
and you can do the same for a call object
   > is.na(as.list(quote(func(arg1, tag2=NA, tag3=log(NA)))))
                tag2  tag3
   FALSE FALSE  TRUE FALSE

However, what is your motivation for wanting to apply is.na to an expression?

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Nov 18, 2015 at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> What is the rationale for the following warning in R-3.2.2?
>
>> is.na(expression(abcd))
> [1] FALSE
> Warning message:
> In is.na(expression(abcd)) :
>   is.na() applied to non-(list or vector) of type 'expression'
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu Nov 19 04:22:45 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Nov 2015 22:22:45 -0500
Subject: [R] is.na behavior
In-Reply-To: <CAF8bMcZ0njiezQeuryXCL=OT6+jyC9x5TiAj64--80NgRkB_-Q@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<CAF8bMcZ0njiezQeuryXCL=OT6+jyC9x5TiAj64--80NgRkB_-Q@mail.gmail.com>
Message-ID: <CAGx1TMCP6QJUd2ZPv+T73K=aKKNRS6VJNmtXYWDFHJGk50D3mg@mail.gmail.com>

It is in context of determining if an input argument for a graph title
is missing or null or na.  In any of those cases the function defines
a main title.
If the incoming title is not one of those, then I use the incoming title.
When the incoming title is an expression I see the warning.

library(lattice)

simple <- function(x, y, main) {
  if (missing(main) || is.null(main) || is.na(main))
     main <-"abcd"
  xyplot(y ~ x, main=main)
}

simple(1, 2)
simple(1, 2, main=expression("defg"))

## In the real case the constructed title is not a simple character
## string, but the result of function call with several incoming
## arguments and several computed arguments.  It is of a complexity
## that making it the default in the calling sequence would
## unnecessarily complicate the calling sequence.

On Wed, Nov 18, 2015 at 10:04 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You can convert the expression to a list and use is.na on that:
>    > e <- expression(1+NA, NA, 7, function(x)x+1)
>    > is.na(as.list(e))
>    [1] FALSE  TRUE FALSE FALSE
> and you can do the same for a call object
>    > is.na(as.list(quote(func(arg1, tag2=NA, tag3=log(NA)))))
>                 tag2  tag3
>    FALSE FALSE  TRUE FALSE
>
> However, what is your motivation for wanting to apply is.na to an expression?
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Nov 18, 2015 at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> What is the rationale for the following warning in R-3.2.2?
>>
>>> is.na(expression(abcd))
>> [1] FALSE
>> Warning message:
>> In is.na(expression(abcd)) :
>>   is.na() applied to non-(list or vector) of type 'expression'
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu Nov 19 04:35:16 2015
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 18 Nov 2015 22:35:16 -0500
Subject: [R] is.na behavior
In-Reply-To: <CAGx1TMCP6QJUd2ZPv+T73K=aKKNRS6VJNmtXYWDFHJGk50D3mg@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<CAF8bMcZ0njiezQeuryXCL=OT6+jyC9x5TiAj64--80NgRkB_-Q@mail.gmail.com>
	<CAGx1TMCP6QJUd2ZPv+T73K=aKKNRS6VJNmtXYWDFHJGk50D3mg@mail.gmail.com>
Message-ID: <CAGx1TMAz_==85re0gR0VvT8RBWVY9zOyvc3BTDUOYV51-DyVsg@mail.gmail.com>

Maybe the way to rephrase my question is to ask why there is not
an is.na.expression method that does that task for me?

> is.na(as.list(expression("defg")))
[1] FALSE
> is.na(expression("defg"))
[1] FALSE
Warning message:
In is.na(expression("defg")) :
  is.na() applied to non-(list or vector) of type 'expression'
>

On Wed, Nov 18, 2015 at 10:22 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> It is in context of determining if an input argument for a graph title
> is missing or null or na.  In any of those cases the function defines
> a main title.
> If the incoming title is not one of those, then I use the incoming title.
> When the incoming title is an expression I see the warning.
>
> library(lattice)
>
> simple <- function(x, y, main) {
>   if (missing(main) || is.null(main) || is.na(main))
>      main <-"abcd"
>   xyplot(y ~ x, main=main)
> }
>
> simple(1, 2)
> simple(1, 2, main=expression("defg"))
>
> ## In the real case the constructed title is not a simple character
> ## string, but the result of function call with several incoming
> ## arguments and several computed arguments.  It is of a complexity
> ## that making it the default in the calling sequence would
> ## unnecessarily complicate the calling sequence.
>
> On Wed, Nov 18, 2015 at 10:04 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> You can convert the expression to a list and use is.na on that:
>>    > e <- expression(1+NA, NA, 7, function(x)x+1)
>>    > is.na(as.list(e))
>>    [1] FALSE  TRUE FALSE FALSE
>> and you can do the same for a call object
>>    > is.na(as.list(quote(func(arg1, tag2=NA, tag3=log(NA)))))
>>                 tag2  tag3
>>    FALSE FALSE  TRUE FALSE
>>
>> However, what is your motivation for wanting to apply is.na to an expression?
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Nov 18, 2015 at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>> What is the rationale for the following warning in R-3.2.2?
>>>
>>>> is.na(expression(abcd))
>>> [1] FALSE
>>> Warning message:
>>> In is.na(expression(abcd)) :
>>>   is.na() applied to non-(list or vector) of type 'expression'
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From j.bayat194 at gmail.com  Thu Nov 19 11:23:20 2015
From: j.bayat194 at gmail.com (javad bayat)
Date: Thu, 19 Nov 2015 13:53:20 +0330
Subject: [R] Prediction data gaps by "neuralnet" package
Message-ID: <CANTxAm+3DORVQoCobfPf9DhYLRxpaS8DFjNpUBGvJO-PEKdcVw@mail.gmail.com>

Dear R users;
I am trying to predict the gaps in my data set (colorofil.A) by using
"neuralnet" package. But when I run the following codes it gives me error.
Could anyone help me to fix the problem?
Bests.

> library("neuralnet")

> head(ss1,2)[,c(5,24)]
      Season      colorofil.A
1       Sp              NA
2       Sp              10

> net.sqrt <- neuralnet(colorofil.A~Season,ss1, hidden=10, threshold=0.01)
print(net.sqrt)











-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Thu Nov 19 14:09:47 2015
From: alaios at yahoo.com (Alaios)
Date: Thu, 19 Nov 2015 13:09:47 +0000 (UTC)
Subject: [R] improve my ggplot look
References: <1513794053.6024618.1447938587694.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1513794053.6024618.1447938587694.JavaMail.yahoo@mail.yahoo.com>

Dear all,the following line of code
print me a map of an area with the points I need. I only new two minor adjustments
??? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour =Error), data = PlotPoints, size = 6)+ scale_colour_gradient2(low=muted("red"),mid="green", high=muted("blue"),trans = "log")+geom_point(aes(Longitude,Latitude),data=stationaryPoint,colour="Red",shape="s",size=12) 

I want to specify my color ramp to have the specific scale 
0,000010,040,130,4

I also want to plot in a way where the fonts will be binger and the legends as well.Any ideas how I can do that?
I would like to thank you for your reply
RegardsAlex


	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Thu Nov 19 16:17:23 2015
From: tmrsg11 at gmail.com (C W)
Date: Thu, 19 Nov 2015 10:17:23 -0500
Subject: [R] [FORGED]  How to find the likelihood, MLE and plot it?
In-Reply-To: <564D0889.2000407@auckland.ac.nz>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
	<564D0889.2000407@auckland.ac.nz>
Message-ID: <CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>

Hi Rolf,

I think the MLE should be 1.71, no?  And yes, I am aware of the
maximum=TRUE argument.  I still feel something is wrong here.

Thanks!

On Wed, Nov 18, 2015 at 6:23 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 19/11/15 11:31, C W wrote:
>
>> Dear R list,
>>
>> I am trying to find the MLE of the likelihood function.  I will plot the
>> log-likelihood to check my answer.
>>
>> Here's my R code:
>>
>> xvec <- c(2,5,3,7,-3,-2,0)
>>
>> fn <- function(theta){
>>
>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>
>> }
>>
>> gn <- Vectorize(fn)
>>
>> curve(gn, -5, 20)
>>
>> optimize(gn, c(-5, 20))
>>
>> $minimum
>>
>> [1] 1.714286
>>
>> $objective
>>
>> [1] 39.71429
>>
>>
>> The MLE using optimize() is 1.71, but what curve() gives me is the
>> absolute
>> minimum.
>>
>> I think 1.71 is the right answer, but why does the graph showing it's the
>> minimum?  What is going on here?
>>
>
> Your graph shows that there is indeed a *minimum* at 1.71.  And optimise()
> is correctly finding that minimum.
>
> If you want optimise() to find the maximum, set maximum=TRUE.  In which
> case it will return "20" (or something very close to 20).
>
> Your function fn() appears not to be the log likelihood that you had in
> mind.  Perhaps you the negative of fn()???
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Nov 19 16:29:39 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 19 Nov 2015 16:29:39 +0100
Subject: [R] [FORGED]  How to find the likelihood, MLE and plot it?
In-Reply-To: <CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
	<564D0889.2000407@auckland.ac.nz>
	<CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>
Message-ID: <CD838941-835D-4937-9D8C-12553314C38F@gmail.com>


On 19 Nov 2015, at 16:17 , C W <tmrsg11 at gmail.com> wrote:

> Hi Rolf,
> 
> I think the MLE should be 1.71, no?  And yes, I am aware of the
> maximum=TRUE argument.  I still feel something is wrong here.
> 

Just read more carefully what Rolf said: Your fn is MINUS the log-likelihood. So the graph is upside-down.

-pd


> Thanks!
> 
> On Wed, Nov 18, 2015 at 6:23 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> 
>> On 19/11/15 11:31, C W wrote:
>> 
>>> Dear R list,
>>> 
>>> I am trying to find the MLE of the likelihood function.  I will plot the
>>> log-likelihood to check my answer.
>>> 
>>> Here's my R code:
>>> 
>>> xvec <- c(2,5,3,7,-3,-2,0)
>>> 
>>> fn <- function(theta){
>>> 
>>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>> 
>>> }
>>> 
>>> gn <- Vectorize(fn)
>>> 
>>> curve(gn, -5, 20)
>>> 
>>> optimize(gn, c(-5, 20))
>>> 
>>> $minimum
>>> 
>>> [1] 1.714286
>>> 
>>> $objective
>>> 
>>> [1] 39.71429
>>> 
>>> 
>>> The MLE using optimize() is 1.71, but what curve() gives me is the
>>> absolute
>>> minimum.
>>> 
>>> I think 1.71 is the right answer, but why does the graph showing it's the
>>> minimum?  What is going on here?
>>> 
>> 
>> Your graph shows that there is indeed a *minimum* at 1.71.  And optimise()
>> is correctly finding that minimum.
>> 
>> If you want optimise() to find the maximum, set maximum=TRUE.  In which
>> case it will return "20" (or something very close to 20).
>> 
>> Your function fn() appears not to be the log likelihood that you had in
>> mind.  Perhaps you the negative of fn()???
>> 
>> cheers,
>> 
>> Rolf Turner
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From itziar.irigoien at ehu.es  Thu Nov 19 14:09:46 2015
From: itziar.irigoien at ehu.es (itziar irigoien)
Date: Thu, 19 Nov 2015 14:09:46 +0100
Subject: [R] knn - random result although use.all=TRUE
Message-ID: <564DCA1A.4020101@ehu.es>

Dear all,

I have this toy example to work with k-nn classification approach. (My 
data, code and results are at the end of the message)
Working with knn function in library class and setting the parameter 
use.all=TRUE, I would not expect a random answer. Nevertheless I get a 
different answer each time I apply it. Could anyone help me finding out 
what is going on?

Thanks,

Itziar Irigoien

# Generate data
n <- 40
n1 <- 16
n2 <- n-n1
cl <- rep(1:2, c(n1, n2))
set.seed(37)
X1 <- sample(1:3, n, replace=TRUE, prob=rep(1/3, 3))
set.seed(36)
aux1 <- sample(1:2, n1, replace=TRUE, prob=c(0.9, 0.1))
set.seed(38)
aux2 <- sample(1:2, n2, replace=TRUE, prob=c(0.2, 0.8))
X2 <- c(aux1, aux2)
X2 <- X2+3
X2[3] <- 5

#Select training and testing sets
set.seed(36)
t <- sample(1:40, 30, replace=FALSE)
train <- cbind(X1[t], X2[t])
test <- cbind(X1[-t], X2[-t])
out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
table(out, clase[-t])
sum(diag(table(out, clase[-t])))/10

# Results I obtained
 > out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
 > table(out, clase[-t])

out 1 2
   1 1 2
   2 0 7
 > sum(diag(table(out, clase[-t])))/10
[1] 0.8


 > out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
 > table(out, clase[-t])

out 1 2
   1 1 4
   2 0 5
 > sum(diag(table(out, clase[-t])))/10
[1] 0.6


From costantino.zazza at uniroma1.it  Thu Nov 19 14:36:13 2015
From: costantino.zazza at uniroma1.it (Costantino Zazza)
Date: Thu, 19 Nov 2015 05:36:13 -0800 (PST)
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563B91C6.4080303@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
	<563B6BA0.6090608@gwdg.de> <563B91C6.4080303@gmail.com>
Message-ID: <b416f92d-8fa4-473c-b934-052d5394b824@googlegroups.com>

Hi R-users, 

talking about the compilation of rjags (gnu 4.4.7 - blas and lapack 
routines) package in R I have solved the issue in the thread as follows:

 Before compiling JAGS I need to recompile BLAS and LAPACK libraries with 
-fPIC instruction:

BLAS Makefile: 
[root at n14 library]# cat  /home/c.zazza/BLAS_pic/make.inc
####################################################################
#  BLAS make include file.                                         #
#  March 2007                                                      #
####################################################################
#
SHELL = /bin/sh
#
#  The machine (platform) identifier to append to the library names
#
PLAT = _LINUX
#
#  Modify the FORTRAN and OPTS definitions to refer to the
#  compiler and desired compiler options for your machine.  NOOPT
#  refers to the compiler options desired when NO OPTIMIZATION is
#  selected.  Define LOADER and LOADOPTS to refer to the loader and
#  desired load options for your machine.
#
FORTRAN  = gfortran
*OPTS     = -O3 -fPIC*
DRVOPTS  = $(OPTS)
*NOOPT    = -fPIC*
LOADER   = gfortran
*LOADOPTS = -fPIC*
#
#  The archiver and the flag(s) to use when building archive (library)
#  If you system has no ranlib, set RANLIB = echo.
#
ARCH     = ar
ARCHFLAGS= cr
RANLIB   = ranlib
#
#  The location and name of the Reference BLAS library.
#
BLASLIB      = blas$(PLAT).a

Also lapack makefile needs for -fPIC: 
[root at n14 library]# cat  /home/c.zazza/lapack-3.5.0_pic/make.inc
####################################################################
#  LAPACK make include file.                                       #
#  LAPACK, Version 3.5.0                                           #
#  November 2013                                                   #
####################################################################
#
SHELL = /bin/sh
#
#  Modify the FORTRAN and OPTS definitions to refer to the
#  compiler and desired compiler options for your machine.  NOOPT
#  refers to the compiler options desired when NO OPTIMIZATION is
#  selected.  Define LOADER and LOADOPTS to refer to the loader and
#  desired load options for your machine.
#
FORTRAN  = gfortran
OPTS     = -O2 -frecursive -fPIC
DRVOPTS  = $(OPTS)
NOOPT    = -O0 -frecursive -fPIC
LOADER   = gfortran
LOADOPTS = -fPIC
#
# Timer for the SECOND and DSECND routines
#
# Default : SECOND and DSECND will use a call to the EXTERNAL FUNCTION ETIME
#TIMER    = EXT_ETIME
# For RS6K : SECOND and DSECND will use a call to the EXTERNAL FUNCTION 
ETIME_
# TIMER    = EXT_ETIME_
# For gfortran compiler: SECOND and DSECND will use a call to the INTERNAL
FUNCTION ETIME
TIMER    = INT_ETIME
# If your Fortran compiler does not provide etime (like Nag Fortran 
Compiler, etc...)
# SECOND and DSECND will use a call to the INTERNAL FUNCTION CPU_TIME
# TIMER    = INT_CPU_TIME
# If neither of this works...you can use the NONE value... In that case, 
SECOND and DSECND will always return 0
# TIMER     = NONE
#
#  Configuration LAPACKE: Native C interface to LAPACK
#  To generate LAPACKE library: type 'make lapackelib'
#  Configuration file: turned off (default)
#  Complex types: C99 (default)
#  Name pattern: mixed case (default)
#  (64-bit) Data model: LP64 (default)
#
# CC is the C compiler, normally invoked with options CFLAGS.
#
CC = gcc
CFLAGS = -O3 -fPIC
#
#  The archiver and the flag(s) to use when building archive (library)
#  If you system has no ranlib, set RANLIB = echo.
#
ARCH     = ar
ARCHFLAGS= cr
RANLIB   = ranlib
#
#  Location of the extended-precision BLAS (XBLAS) Fortran library
#  used for building and testing extended-precision routines.  The
#  relevant routines will be compiled and XBLAS will be linked only if
#  USEXBLAS is defined.
#
# USEXBLAS    = Yes
XBLASLIB     =
# XBLASLIB    = -lxblas
#
#  The location of the libraries to which you will link.  (The
#  machine-specific, optimized BLAS library should be used whenever
#  possible.)
#
#BLASLIB      = ../../librefblas.a
BLASLIB      = /home/c.zazza/BLAS/blas_LINUX.a
LAPACKLIB    = liblapack.a
TMGLIB       = libtmglib.a
LAPACKELIB   = liblapacke.a

Next, we compile JAGS as follows: 

 *1032  wget 
http://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.0.0.tar.gz 
<http://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.0.0.tar.gz>*
* 1034  tar -zxvf JAGS-4.0.0.tar.gz*
* 1035  cd /share/apps/JAGS-4.0.0*
 *1038  ./configure F77="gfortran" 
--with-blas="/apps/BLAS_pic/blas_LINUX.a" --with-lapack="-ltmglib -llapack" 
LDFLAGS="-L/apps/lapack-3.5.0_pic"  --prefix="/apps/jags"  
--libdir="/apps/jags/lib64"*
 *1039  make -j4 >& make.log &*
* 1040  tail -f make.log*
* 1041  make install*

afterwards, before running R we need to set this:* (otherwise you obtain 
the error you posted like: libjargs.x.y.z etc etc):* 
*1027   export LD_LIBRARY_PATH=$RDIR/lib64/R/lib:${LD_LIBRARY_PATH}*

Finally, within the R-environment we install rjags as follows: 

*install.packages("rjags", configure.args = "--with-jags-prefix=/apps/jags 
--with-jags-include=/apps/jags/include/JAGS 
--with-jags-lib=/apps/jags/lib64 
--with-jags-modules=/apps/jags/lib/JAGS/modules-4")*


[root at n14 bin]# export 
LD_LIBRARY_PATH="/home/apps/jags/lib64:${LD_LIBRARY_PATH}"
[root at n14 bin]# echo $LD_LIBRARY_PATH
/home/apps/jags/lib64:/home/apps/R-3.2.1/lib64/R/lib:/opt/torque/lib:/home/apps/R/3.1.0/lib64:/opt/openmpi/gnu4.4.7/lib:/home/apps/gromacs-4.6.5/build_intel.13.1.1/lib:/usr/local/cuda/lib64:/opt/intel/composer_xe_2013.3.163/compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/mpirt/lib/intel64:/opt/intel/composer_xe_2013.3.163/ipp/../compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/intel/composer_xe_2013.3.163/compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/mkl/lib/intel64:/opt/intel/composer_xe_2013.3.163/tbb/lib/intel64/gcc4.4
[root at n14 bin]# R
R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
  Natural language support but running in an English locale
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
> install.packages("rjags", configure.args = 
"--with-jags-prefix=/home/apps/jags 
--with-jags-include=/home/apps/jags/include/JAGS 
--with-jags-lib=/home/apps/jags/lib64 
--with-jags-modules=/home/apps/jags/lib/JAGS/modules-4")
--- Please select a CRAN mirror for use in this session ---
CRAN mirror
  1: 0-Cloud [https]                 2: 0-Cloud
  3: Algeria                         4: Argentina (La Plata)
  5: Australia (Canberra)            6: Australia (Melbourne)
  7: Austria [https]                 8: Austria
  9: Belgium (Antwerp)              10: Belgium (Ghent)
 11: Brazil (BA)                    12: Brazil (PR)
 13: Brazil (RJ)                    14: Brazil (SP 1)
 15: Brazil (SP 2)                  16: Canada (BC)
 17: Canada (NS)                    18: Canada (ON)
 19: Chile [https]                  20: Chile
 21: China (Beijing 2)              22: China (Beijing 3)
 23: China (Beijing 4) [https]      24: China (Beijing 4)
 25: China (Xiamen)                 26: Colombia (Cali) [https]
 27: Colombia (Cali)                28: Czech Republic
 29: Denmark                        30: Ecuador
 31: El Salvador                    32: Estonia
 33: France (Lyon 1)                34: France (Lyon 2) [https]
 35: France (Lyon 2)                36: France (Marseille)
 37: France (Montpellier)           38: France (Paris 1)
 39: France (Paris 2) [https]       40: France (Paris 2)
 41: Germany (Berlin)               42: Germany (G?ttingen)
 43: Germany (M?nster) [https]      44: Germany (M?nster)
 45: Greece                         46: Hungary
 47: Iceland [https]                48: Iceland
 49: India                          50: Indonesia (Jakarta)
 51: Iran                           52: Ireland
 53: Italy (Milano)                 54: Italy (Padua) [https]
 55: Italy (Padua)                  56: Italy (Palermo)
 57: Japan (Tokyo)                  58: Japan (Yamagata)
 59: Korea (Seoul 1)                60: Korea (Seoul 2)
 61: Korea (Ulsan)                  62: Lebanon
 63: Mexico (Mexico City) [https]   64: Mexico (Mexico City)
 65: Mexico (Texcoco)               66: Mexico (Queretaro)
 67: Netherlands (Amsterdam)        68: Netherlands (Utrecht)
 69: New Zealand                    70: Norway
 71: Philippines                    72: Poland
 73: Portugal (Lisbon)              74: Russia (Moscow) [https]
 75: Russia (Moscow)                76: Singapore
 77: Slovakia                       78: South Africa (Cape Town)
 79: South Africa (Johannesburg)    80: Spain (A Coru?a) [https]
 81: Spain (A Coru?a)               82: Spain (Madrid)
 83: Sweden                         84: Switzerland [https]
 85: Switzerland                    86: Taiwan (Chungli)
 87: Taiwan (Taipei)                88: Thailand
 89: Turkey (Denizli)               90: Turkey (Mersin)
 91: UK (Bristol) [https]           92: UK (Bristol)
 93: UK (Cambridge) [https]         94: UK (Cambridge)
 95: UK (London 1)                  96: UK (London 2)
 97: UK (St Andrews)                98: USA (CA 1) [https]
 99: USA (CA 1)                    100: USA (CA 2)
101: USA (CO)                      102: USA (IA)
103: USA (IN)                      104: USA (KS) [https]
105: USA (KS)                      106: USA (MD) [https]
107: USA (MD)                      108: USA (MI 1) [https]
109: USA (MI 1)                    110: USA (MI 2)
111: USA (MO)                      112: USA (NC)
113: USA (OH 1)                    114: USA (OH 2)
115: USA (OR)                      116: USA (PA 1)
117: USA (PA 2)                    118: USA (TN) [https]
119: USA (TN)                      120: USA (TX) [https]
121: USA (TX)                      122: USA (WA) [https]
123: USA (WA)                      124: Venezuela

Selection: 53
trying URL 
'http://cran.mirror.garr.it/mirrors/CRAN/src/contrib/rjags_4-4.tar.gz'
Content type 'text/plain' length 72125 bytes (70 KB)
==================================================
downloaded 70 KB
* installing *source* package ?rjags? ...
** package ?rjags? successfully unpacked and MD5 sums checked
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
checking for pkg-config... /usr/bin/pkg-config
configure: WARNING: pkg-config file for jags 4 unavailable
configure: WARNING: Consider adding the directory containing `jags.pc`
configure: WARNING: to the PKG_CONFIG_PATH environment variable
configure: Attempting legacy configuration of rjags
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking Console.h usability... yes
checking Console.h presence... yes
checking for Console.h... yes
configure: Compile flags are -I/home/apps/jags/include/JAGS
configure: Link flags are -L/home/apps/jags/lib64 -ljags
checking for gcc... gcc -std=gnu99
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking for jags_version in -ljags... yes
checking version of JAGS library... OK
configure: creating ./config.status
config.status: creating src/Makevars
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
configure: creating ./config.status
config.status: creating src/Makevars
config.status: creating R/unix/zzz.R
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
** libs
g++ -I/home/apps/R-3.2.1/lib64/R/include -DNDEBUG 
-I/home/apps/jags/include/JAGS  -I/usr/local/include    -fpic  -g -O2  -c
jags.cc -o jags.o
g++ -I/home/apps/R-3.2.1/lib64/R/include -DNDEBUG 
-I/home/apps/jags/include/JAGS  -I/usr/local/include    -fpic  -g -O2  -c
parallel.cc -o parallel.o
g++ -shared -L/usr/local/lib64 -o rjags.so jags.o parallel.o 
-L/home/apps/jags/lib64 -ljags
installing to /home/apps/R-3.2.1/lib64/R/library/rjags/libs
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (rjags)
The downloaded source packages are in
        ?/tmp/Rtmpd2BSpp/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done

All the best,
Costantino

Il giorno gioved? 5 novembre 2015 18:32:18 UTC+1, Evan Cooch ha scritto:

> On 11/5/2015 9:45 AM, Rainer Hurling wrote:
> > Am 04.11.2015 um 21:36 schrieb Evan Cooch:
> >>
> >>
> >> On 11/4/2015 2:08 PM, Evan Cooch wrote:
> >>> Greetings --
> >>>
> >>> This has also been posted on the jags forum, but since I suspect the
> >>> problem is more 'R-related' than jags, will aos post here.
> >>>
> >>> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux
> >>> boxes (which run latest RHEL). Here are the basic details:
> >>>
> >>> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other
> >>> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
> >>>
> >>> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy,
> >>> ./configure & make & make install) -- no errors. Runs fine as a
> >>> standalone app from CLI.
> >>>
> >>>
> >>> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R --
> >>> usual R CMD INSTALL approach). Again, no errors reported.
> >>>
> >>>
> >>> However, when I fire up R, and try something simple like
> >>>
> >>> library(R2jags)
> >>>
> >>> I get a whole slew of error messages - following is reproducible on
> >>> all my machines:
> >>>
> >>> Loading required package: rjags
> >>> Loading required package: coda
> >>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
> >>> call: dyn.load(file, DLLpath = DLLpath, ...)
> >>> error: unable to load shared object
> >>> '/usr/lib64/R/library/rjags/libs/rjags.so':
> >>> libjags.so.3: cannot open shared object file: No such file or directory
> >>> Error: package ?rjags? could not be loaded
> >>>
> >>>
> >>
> >> Further puzzlement -- I uninstalled R2jags and rjags, with the idea that
> >> re-installing them (ostensibly with the 'latest and greatest') would do
> >> the trick. While the process went fine for R2jags, when I tried to
> >> re-install rjags, got the following error messages:
> >>
> >> checking for gcc -m64 -std=gnu99 option to accept ISO C89... none needed
> >> checking for jags_version in -ljags... yes
> >> checking version of JAGS library... wrong version
> >> configure: error: rjags requires JAGS version 4.x.y
> >> ERROR: configuration failed for package ?rjags?
> >> * removing ?/usr/lib64/R/library/rjags?
> >> * restoring previous ?/usr/lib64/R/library/rjags?
> >
> > Hmm, is it possible, that your JAGS 4.x.y installation is fine, but an
> > old libjags.so library is lying around from a not fully completed 
> > deinstallation? Could you have a look for older libjags.so versions, 
> > please?
> >
> > Just a thought.
> >
>
>
> I suppose thats possible -- I'll go through the sequence again at some 
> point, and report back.
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From costantino.zazza at uniroma1.it  Thu Nov 19 14:36:13 2015
From: costantino.zazza at uniroma1.it (Costantino Zazza)
Date: Thu, 19 Nov 2015 05:36:13 -0800 (PST)
Subject: [R] JAGS 4.x, rjags 4.x problems | Linux
In-Reply-To: <563B91C6.4080303@gmail.com>
References: <563A57BF.4090106@gmail.com> <563A6C31.3070704@gmail.com>
	<563B6BA0.6090608@gwdg.de> <563B91C6.4080303@gmail.com>
Message-ID: <b416f92d-8fa4-473c-b934-052d5394b824@googlegroups.com>

Hi R-users, 

talking about the compilation of rjags (gnu 4.4.7 - blas and lapack 
routines) package in R I have solved the issue in the thread as follows:

 Before compiling JAGS I need to recompile BLAS and LAPACK libraries with 
-fPIC instruction:

BLAS Makefile: 
[root at n14 library]# cat  /home/c.zazza/BLAS_pic/make.inc
####################################################################
#  BLAS make include file.                                         #
#  March 2007                                                      #
####################################################################
#
SHELL = /bin/sh
#
#  The machine (platform) identifier to append to the library names
#
PLAT = _LINUX
#
#  Modify the FORTRAN and OPTS definitions to refer to the
#  compiler and desired compiler options for your machine.  NOOPT
#  refers to the compiler options desired when NO OPTIMIZATION is
#  selected.  Define LOADER and LOADOPTS to refer to the loader and
#  desired load options for your machine.
#
FORTRAN  = gfortran
*OPTS     = -O3 -fPIC*
DRVOPTS  = $(OPTS)
*NOOPT    = -fPIC*
LOADER   = gfortran
*LOADOPTS = -fPIC*
#
#  The archiver and the flag(s) to use when building archive (library)
#  If you system has no ranlib, set RANLIB = echo.
#
ARCH     = ar
ARCHFLAGS= cr
RANLIB   = ranlib
#
#  The location and name of the Reference BLAS library.
#
BLASLIB      = blas$(PLAT).a

Also lapack makefile needs for -fPIC: 
[root at n14 library]# cat  /home/c.zazza/lapack-3.5.0_pic/make.inc
####################################################################
#  LAPACK make include file.                                       #
#  LAPACK, Version 3.5.0                                           #
#  November 2013                                                   #
####################################################################
#
SHELL = /bin/sh
#
#  Modify the FORTRAN and OPTS definitions to refer to the
#  compiler and desired compiler options for your machine.  NOOPT
#  refers to the compiler options desired when NO OPTIMIZATION is
#  selected.  Define LOADER and LOADOPTS to refer to the loader and
#  desired load options for your machine.
#
FORTRAN  = gfortran
OPTS     = -O2 -frecursive -fPIC
DRVOPTS  = $(OPTS)
NOOPT    = -O0 -frecursive -fPIC
LOADER   = gfortran
LOADOPTS = -fPIC
#
# Timer for the SECOND and DSECND routines
#
# Default : SECOND and DSECND will use a call to the EXTERNAL FUNCTION ETIME
#TIMER    = EXT_ETIME
# For RS6K : SECOND and DSECND will use a call to the EXTERNAL FUNCTION 
ETIME_
# TIMER    = EXT_ETIME_
# For gfortran compiler: SECOND and DSECND will use a call to the INTERNAL
FUNCTION ETIME
TIMER    = INT_ETIME
# If your Fortran compiler does not provide etime (like Nag Fortran 
Compiler, etc...)
# SECOND and DSECND will use a call to the INTERNAL FUNCTION CPU_TIME
# TIMER    = INT_CPU_TIME
# If neither of this works...you can use the NONE value... In that case, 
SECOND and DSECND will always return 0
# TIMER     = NONE
#
#  Configuration LAPACKE: Native C interface to LAPACK
#  To generate LAPACKE library: type 'make lapackelib'
#  Configuration file: turned off (default)
#  Complex types: C99 (default)
#  Name pattern: mixed case (default)
#  (64-bit) Data model: LP64 (default)
#
# CC is the C compiler, normally invoked with options CFLAGS.
#
CC = gcc
CFLAGS = -O3 -fPIC
#
#  The archiver and the flag(s) to use when building archive (library)
#  If you system has no ranlib, set RANLIB = echo.
#
ARCH     = ar
ARCHFLAGS= cr
RANLIB   = ranlib
#
#  Location of the extended-precision BLAS (XBLAS) Fortran library
#  used for building and testing extended-precision routines.  The
#  relevant routines will be compiled and XBLAS will be linked only if
#  USEXBLAS is defined.
#
# USEXBLAS    = Yes
XBLASLIB     =
# XBLASLIB    = -lxblas
#
#  The location of the libraries to which you will link.  (The
#  machine-specific, optimized BLAS library should be used whenever
#  possible.)
#
#BLASLIB      = ../../librefblas.a
BLASLIB      = /home/c.zazza/BLAS/blas_LINUX.a
LAPACKLIB    = liblapack.a
TMGLIB       = libtmglib.a
LAPACKELIB   = liblapacke.a

Next, we compile JAGS as follows: 

 *1032  wget 
http://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.0.0.tar.gz 
<http://sourceforge.net/projects/mcmc-jags/files/JAGS/4.x/Source/JAGS-4.0.0.tar.gz>*
* 1034  tar -zxvf JAGS-4.0.0.tar.gz*
* 1035  cd /share/apps/JAGS-4.0.0*
 *1038  ./configure F77="gfortran" 
--with-blas="/apps/BLAS_pic/blas_LINUX.a" --with-lapack="-ltmglib -llapack" 
LDFLAGS="-L/apps/lapack-3.5.0_pic"  --prefix="/apps/jags"  
--libdir="/apps/jags/lib64"*
 *1039  make -j4 >& make.log &*
* 1040  tail -f make.log*
* 1041  make install*

afterwards, before running R we need to set this:* (otherwise you obtain 
the error you posted like: libjargs.x.y.z etc etc):* 
*1027   export LD_LIBRARY_PATH=$RDIR/lib64/R/lib:${LD_LIBRARY_PATH}*

Finally, within the R-environment we install rjags as follows: 

*install.packages("rjags", configure.args = "--with-jags-prefix=/apps/jags 
--with-jags-include=/apps/jags/include/JAGS 
--with-jags-lib=/apps/jags/lib64 
--with-jags-modules=/apps/jags/lib/JAGS/modules-4")*


[root at n14 bin]# export 
LD_LIBRARY_PATH="/home/apps/jags/lib64:${LD_LIBRARY_PATH}"
[root at n14 bin]# echo $LD_LIBRARY_PATH
/home/apps/jags/lib64:/home/apps/R-3.2.1/lib64/R/lib:/opt/torque/lib:/home/apps/R/3.1.0/lib64:/opt/openmpi/gnu4.4.7/lib:/home/apps/gromacs-4.6.5/build_intel.13.1.1/lib:/usr/local/cuda/lib64:/opt/intel/composer_xe_2013.3.163/compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/mpirt/lib/intel64:/opt/intel/composer_xe_2013.3.163/ipp/../compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/ipp/lib/intel64:/opt/intel/mic/coi/host-linux-release/lib:/opt/intel/mic/myo/lib:/opt/intel/composer_xe_2013.3.163/compiler/lib/intel64:/opt/intel/composer_xe_2013.3.163/mkl/lib/intel64:/opt/intel/composer_xe_2013.3.163/tbb/lib/intel64/gcc4.4
[root at n14 bin]# R
R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)
R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.
  Natural language support but running in an English locale
R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.
Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
> install.packages("rjags", configure.args = 
"--with-jags-prefix=/home/apps/jags 
--with-jags-include=/home/apps/jags/include/JAGS 
--with-jags-lib=/home/apps/jags/lib64 
--with-jags-modules=/home/apps/jags/lib/JAGS/modules-4")
--- Please select a CRAN mirror for use in this session ---
CRAN mirror
  1: 0-Cloud [https]                 2: 0-Cloud
  3: Algeria                         4: Argentina (La Plata)
  5: Australia (Canberra)            6: Australia (Melbourne)
  7: Austria [https]                 8: Austria
  9: Belgium (Antwerp)              10: Belgium (Ghent)
 11: Brazil (BA)                    12: Brazil (PR)
 13: Brazil (RJ)                    14: Brazil (SP 1)
 15: Brazil (SP 2)                  16: Canada (BC)
 17: Canada (NS)                    18: Canada (ON)
 19: Chile [https]                  20: Chile
 21: China (Beijing 2)              22: China (Beijing 3)
 23: China (Beijing 4) [https]      24: China (Beijing 4)
 25: China (Xiamen)                 26: Colombia (Cali) [https]
 27: Colombia (Cali)                28: Czech Republic
 29: Denmark                        30: Ecuador
 31: El Salvador                    32: Estonia
 33: France (Lyon 1)                34: France (Lyon 2) [https]
 35: France (Lyon 2)                36: France (Marseille)
 37: France (Montpellier)           38: France (Paris 1)
 39: France (Paris 2) [https]       40: France (Paris 2)
 41: Germany (Berlin)               42: Germany (G?ttingen)
 43: Germany (M?nster) [https]      44: Germany (M?nster)
 45: Greece                         46: Hungary
 47: Iceland [https]                48: Iceland
 49: India                          50: Indonesia (Jakarta)
 51: Iran                           52: Ireland
 53: Italy (Milano)                 54: Italy (Padua) [https]
 55: Italy (Padua)                  56: Italy (Palermo)
 57: Japan (Tokyo)                  58: Japan (Yamagata)
 59: Korea (Seoul 1)                60: Korea (Seoul 2)
 61: Korea (Ulsan)                  62: Lebanon
 63: Mexico (Mexico City) [https]   64: Mexico (Mexico City)
 65: Mexico (Texcoco)               66: Mexico (Queretaro)
 67: Netherlands (Amsterdam)        68: Netherlands (Utrecht)
 69: New Zealand                    70: Norway
 71: Philippines                    72: Poland
 73: Portugal (Lisbon)              74: Russia (Moscow) [https]
 75: Russia (Moscow)                76: Singapore
 77: Slovakia                       78: South Africa (Cape Town)
 79: South Africa (Johannesburg)    80: Spain (A Coru?a) [https]
 81: Spain (A Coru?a)               82: Spain (Madrid)
 83: Sweden                         84: Switzerland [https]
 85: Switzerland                    86: Taiwan (Chungli)
 87: Taiwan (Taipei)                88: Thailand
 89: Turkey (Denizli)               90: Turkey (Mersin)
 91: UK (Bristol) [https]           92: UK (Bristol)
 93: UK (Cambridge) [https]         94: UK (Cambridge)
 95: UK (London 1)                  96: UK (London 2)
 97: UK (St Andrews)                98: USA (CA 1) [https]
 99: USA (CA 1)                    100: USA (CA 2)
101: USA (CO)                      102: USA (IA)
103: USA (IN)                      104: USA (KS) [https]
105: USA (KS)                      106: USA (MD) [https]
107: USA (MD)                      108: USA (MI 1) [https]
109: USA (MI 1)                    110: USA (MI 2)
111: USA (MO)                      112: USA (NC)
113: USA (OH 1)                    114: USA (OH 2)
115: USA (OR)                      116: USA (PA 1)
117: USA (PA 2)                    118: USA (TN) [https]
119: USA (TN)                      120: USA (TX) [https]
121: USA (TX)                      122: USA (WA) [https]
123: USA (WA)                      124: Venezuela

Selection: 53
trying URL 
'http://cran.mirror.garr.it/mirrors/CRAN/src/contrib/rjags_4-4.tar.gz'
Content type 'text/plain' length 72125 bytes (70 KB)
==================================================
downloaded 70 KB
* installing *source* package ?rjags? ...
** package ?rjags? successfully unpacked and MD5 sums checked
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
checking for pkg-config... /usr/bin/pkg-config
configure: WARNING: pkg-config file for jags 4 unavailable
configure: WARNING: Consider adding the directory containing `jags.pc`
configure: WARNING: to the PKG_CONFIG_PATH environment variable
configure: Attempting legacy configuration of rjags
checking whether the C++ compiler works... yes
checking for C++ compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking Console.h usability... yes
checking Console.h presence... yes
checking for Console.h... yes
configure: Compile flags are -I/home/apps/jags/include/JAGS
configure: Link flags are -L/home/apps/jags/lib64 -ljags
checking for gcc... gcc -std=gnu99
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking for jags_version in -ljags... yes
checking version of JAGS library... OK
configure: creating ./config.status
config.status: creating src/Makevars
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
configure: creating ./config.status
config.status: creating src/Makevars
config.status: creating R/unix/zzz.R
configure: WARNING: unrecognized options: --with-jags-include, 
--with-jags-lib, --with-jags-modules
** libs
g++ -I/home/apps/R-3.2.1/lib64/R/include -DNDEBUG 
-I/home/apps/jags/include/JAGS  -I/usr/local/include    -fpic  -g -O2  -c
jags.cc -o jags.o
g++ -I/home/apps/R-3.2.1/lib64/R/include -DNDEBUG 
-I/home/apps/jags/include/JAGS  -I/usr/local/include    -fpic  -g -O2  -c
parallel.cc -o parallel.o
g++ -shared -L/usr/local/lib64 -o rjags.so jags.o parallel.o 
-L/home/apps/jags/lib64 -ljags
installing to /home/apps/R-3.2.1/lib64/R/library/rjags/libs
** R
** data
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (rjags)
The downloaded source packages are in
        ?/tmp/Rtmpd2BSpp/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done

All the best,
Costantino

Il giorno gioved? 5 novembre 2015 18:32:18 UTC+1, Evan Cooch ha scritto:

> On 11/5/2015 9:45 AM, Rainer Hurling wrote:
> > Am 04.11.2015 um 21:36 schrieb Evan Cooch:
> >>
> >>
> >> On 11/4/2015 2:08 PM, Evan Cooch wrote:
> >>> Greetings --
> >>>
> >>> This has also been posted on the jags forum, but since I suspect the
> >>> problem is more 'R-related' than jags, will aos post here.
> >>>
> >>> Decided to 'upgrade' from jags 3.x.x to 4.x.x today, on my GNU/Linux
> >>> boxes (which run latest RHEL). Here are the basic details:
> >>>
> >>> 1\ used R 3.2.2 compiled from source. 64-bit -- nothing fancy, other
> >>> than the fact that I used OpenBLAS instead of 'generic'. Works fine.
> >>>
> >>> 2\ downloaded and compiled JAGS 4.0.1 from source (nothing fancy,
> >>> ./configure & make & make install) -- no errors. Runs fine as a
> >>> standalone app from CLI.
> >>>
> >>>
> >>> 3\ Downloaded rjags_4-3.tar.gz, and installed from R CLI (within R --
> >>> usual R CMD INSTALL approach). Again, no errors reported.
> >>>
> >>>
> >>> However, when I fire up R, and try something simple like
> >>>
> >>> library(R2jags)
> >>>
> >>> I get a whole slew of error messages - following is reproducible on
> >>> all my machines:
> >>>
> >>> Loading required package: rjags
> >>> Loading required package: coda
> >>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
> >>> call: dyn.load(file, DLLpath = DLLpath, ...)
> >>> error: unable to load shared object
> >>> '/usr/lib64/R/library/rjags/libs/rjags.so':
> >>> libjags.so.3: cannot open shared object file: No such file or directory
> >>> Error: package ?rjags? could not be loaded
> >>>
> >>>
> >>
> >> Further puzzlement -- I uninstalled R2jags and rjags, with the idea that
> >> re-installing them (ostensibly with the 'latest and greatest') would do
> >> the trick. While the process went fine for R2jags, when I tried to
> >> re-install rjags, got the following error messages:
> >>
> >> checking for gcc -m64 -std=gnu99 option to accept ISO C89... none needed
> >> checking for jags_version in -ljags... yes
> >> checking version of JAGS library... wrong version
> >> configure: error: rjags requires JAGS version 4.x.y
> >> ERROR: configuration failed for package ?rjags?
> >> * removing ?/usr/lib64/R/library/rjags?
> >> * restoring previous ?/usr/lib64/R/library/rjags?
> >
> > Hmm, is it possible, that your JAGS 4.x.y installation is fine, but an
> > old libjags.so library is lying around from a not fully completed 
> > deinstallation? Could you have a look for older libjags.so versions, 
> > please?
> >
> > Just a thought.
> >
>
>
> I suppose thats possible -- I'll go through the sequence again at some 
> point, and report back.
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From tmrsg11 at gmail.com  Thu Nov 19 16:35:46 2015
From: tmrsg11 at gmail.com (C W)
Date: Thu, 19 Nov 2015 10:35:46 -0500
Subject: [R] [FORGED] How to find the likelihood, MLE and plot it?
In-Reply-To: <CD838941-835D-4937-9D8C-12553314C38F@gmail.com>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
	<564D0889.2000407@auckland.ac.nz>
	<CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>
	<CD838941-835D-4937-9D8C-12553314C38F@gmail.com>
Message-ID: <CAE2FW2nQpjCoxn2Q=zOx+mG4fZW5CN8eet4e__o-oYBOOeLUtg@mail.gmail.com>

ah.  Let me fix that and get back to you.

On a side note, why can't I put fn inside curve(), why do I have to use
Vectorize()?

Here's the code and the message:

> curve(fn, -5, 20)
Error in curve(fn, -5, 20) :
  'expr' did not evaluate to an object of length 'n'


On Thu, Nov 19, 2015 at 10:29 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 19 Nov 2015, at 16:17 , C W <tmrsg11 at gmail.com> wrote:
>
> > Hi Rolf,
> >
> > I think the MLE should be 1.71, no?  And yes, I am aware of the
> > maximum=TRUE argument.  I still feel something is wrong here.
> >
>
> Just read more carefully what Rolf said: Your fn is MINUS the
> log-likelihood. So the graph is upside-down.
>
> -pd
>
>
> > Thanks!
> >
> > On Wed, Nov 18, 2015 at 6:23 PM, Rolf Turner <r.turner at auckland.ac.nz>
> > wrote:
> >
> >> On 19/11/15 11:31, C W wrote:
> >>
> >>> Dear R list,
> >>>
> >>> I am trying to find the MLE of the likelihood function.  I will plot
> the
> >>> log-likelihood to check my answer.
> >>>
> >>> Here's my R code:
> >>>
> >>> xvec <- c(2,5,3,7,-3,-2,0)
> >>>
> >>> fn <- function(theta){
> >>>
> >>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
> >>>
> >>> }
> >>>
> >>> gn <- Vectorize(fn)
> >>>
> >>> curve(gn, -5, 20)
> >>>
> >>> optimize(gn, c(-5, 20))
> >>>
> >>> $minimum
> >>>
> >>> [1] 1.714286
> >>>
> >>> $objective
> >>>
> >>> [1] 39.71429
> >>>
> >>>
> >>> The MLE using optimize() is 1.71, but what curve() gives me is the
> >>> absolute
> >>> minimum.
> >>>
> >>> I think 1.71 is the right answer, but why does the graph showing it's
> the
> >>> minimum?  What is going on here?
> >>>
> >>
> >> Your graph shows that there is indeed a *minimum* at 1.71.  And
> optimise()
> >> is correctly finding that minimum.
> >>
> >> If you want optimise() to find the maximum, set maximum=TRUE.  In which
> >> case it will return "20" (or something very close to 20).
> >>
> >> Your function fn() appears not to be the log likelihood that you had in
> >> mind.  Perhaps you the negative of fn()???
> >>
> >> cheers,
> >>
> >> Rolf Turner
> >>
> >> --
> >> Technical Editor ANZJS
> >> Department of Statistics
> >> University of Auckland
> >> Phone: +64-9-373-7599 ext. 88276
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Nov 19 16:56:55 2015
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 19 Nov 2015 08:56:55 -0700
Subject: [R] is.na behavior
In-Reply-To: <CAGx1TMBDHaji4Lvu7HCXmDrjQPz74jr92cJdWtWR0dVkgbz1xA@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>
	<CAGx1TMBDHaji4Lvu7HCXmDrjQPz74jr92cJdWtWR0dVkgbz1xA@mail.gmail.com>
Message-ID: <CAFEqCdy7N0Z6RY9KPmtbojQvnXivYX1FeAQvMq-Q=+X4coQ=ug@mail.gmail.com>

Richard,

I think the reason that this gives the warning is for the rest of us
who don't think about asking about missing values in non-data objects.

I could imagine someone choosing a poor name for a variable and doing
something like:

mean <- mean(x)
is.na(mean)

which would then tell them whether the mean of x was missing (due to
missing in x).  Later in a new session they may try something similar
but use a different variable name in the 1st line (e.g. Mean) but
accidentally still ask for is.na(mean).  So, is.na would find the mean
function and report that it is not missing, but the warning would let
the user know that what was checked for missingness was not what they
had intended.

I could also imagine meaning to write something like:

is.na(mean(x))

but accidentially writing

is.na(mean)

instead and I would appreciate the warning that would send me back to
review my code and find the mistake.

On Wed, Nov 18, 2015 at 8:03 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> David,
>
> Your answer begs the question.
> What is the problem with non-(list or vector) of type language.
> To my eye both expression(abcd) and call("mean") look like they have
> non-missing values, hence I anticipated that they are not NA, and therefore
> that is.na() would return FALSE without a warning.
>
> On the html email, I turned that off years ago.  It looks like gmail
> (who handles
> my university's email accounts) turned it back on.  I just turned it off again.
> I too find it very annoying to have to revisit setting changes that I
> didn't make.
> Thank you for letting me know.
>
> Rich
>
>
> On Wed, Nov 18, 2015 at 9:36 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>> On Nov 18, 2015, at 5:54 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>>
>>> What is the rationale for the following warning in R-3.2.2?
>>>
>>>> is.na(expression(abcd))
>>> [1] FALSE
>>> Warning message:
>>> In is.na(expression(abcd)) :
>>>  is.na() applied to non-(list or vector) of type ?expression?
>>
>> Well, the R interpreter does think that this is not a list:
>>
>>> is.list(expression(abcd))
>> [1] FALSE
>>
>>
>>> methods(is.na)
>>  [1] is.na,abIndex-method       is.na,denseMatrix-method
>>  [3] is.na,indMatrix-method     is.na,nsparseMatrix-method
>>  [5] is.na,nsparseVector-method is.na,sparseMatrix-method
>>  [7] is.na,sparseVector-method  is.na.coxph.penalty*
>>  [9] is.na.data.frame           is.na.numeric_version
>> [11] is.na.POSIXlt              is.na.raster*
>> [13] is.na.ratetable*           is.na.Surv
>>
>>
>> So the rationale is probably the same as the rationale for this warning:
>>
>>> is.na(call("mean", 1:4))
>> [1] FALSE FALSE
>> Warning message:
>> In is.na(call("mean", 1:4)) :
>>   is.na() applied to non-(list or vector) of type ?language'
>>
>>>       [[alternative HTML version deleted]]
>>
>>
>> I?m somewhat puzzled at your use of HTML for an Rhelp posting. I thought you were a longtime R user?
>>
>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dwinsemius at comcast.net  Thu Nov 19 18:12:43 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 19 Nov 2015 09:12:43 -0800
Subject: [R] [FORGED] How to find the likelihood, MLE and plot it?
In-Reply-To: <CAE2FW2nQpjCoxn2Q=zOx+mG4fZW5CN8eet4e__o-oYBOOeLUtg@mail.gmail.com>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
	<564D0889.2000407@auckland.ac.nz>
	<CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>
	<CD838941-835D-4937-9D8C-12553314C38F@gmail.com>
	<CAE2FW2nQpjCoxn2Q=zOx+mG4fZW5CN8eet4e__o-oYBOOeLUtg@mail.gmail.com>
Message-ID: <9344BB28-B9E5-4121-B6C6-050284EF0663@comcast.net>


> On Nov 19, 2015, at 7:35 AM, C W <tmrsg11 at gmail.com> wrote:
> 
> ah.  Let me fix that and get back to you.
> 
> On a side note, why can't I put fn inside curve(), why do I have to use
> Vectorize()?
> 
> Here's the code and the message:

>>>>> fn <- function(theta){
>>>>> 
>>>>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>>>> 
>>>>> }

> 
>> curve(fn, -5, 20)
> Error in curve(fn, -5, 20) :
>  'expr' did not evaluate to an object of length ?n?


The sum function is not vectorized. In oder for a function to be considered ?vectorized?, it needs to return a vector of the same length as its input.

? 
David.
> 
> 
> On Thu, Nov 19, 2015 at 10:29 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On 19 Nov 2015, at 16:17 , C W <tmrsg11 at gmail.com> wrote:
>> 
>>> Hi Rolf,
>>> 
>>> I think the MLE should be 1.71, no?  And yes, I am aware of the
>>> maximum=TRUE argument.  I still feel something is wrong here.
>>> 
>> 
>> Just read more carefully what Rolf said: Your fn is MINUS the
>> log-likelihood. So the graph is upside-down.
>> 
>> -pd
>> 
>> 
>>> Thanks!
>>> 
>>> On Wed, Nov 18, 2015 at 6:23 PM, Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>> 
>>>> On 19/11/15 11:31, C W wrote:
>>>> 
>>>>> Dear R list,
>>>>> 
>>>>> I am trying to find the MLE of the likelihood function.  I will plot
>> the
>>>>> log-likelihood to check my answer.
>>>>> 
>>>>> Here's my R code:
>>>>> 
>>>>> xvec <- c(2,5,3,7,-3,-2,0)
>>>>> 
>>>>> fn <- function(theta){
>>>>> 
>>>>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>>>> 
>>>>> }
>>>>> 
>>>>> gn <- Vectorize(fn)
>>>>> 
>>>>> curve(gn, -5, 20)
>>>>> 
>>>>> optimize(gn, c(-5, 20))
>>>>> 
>>>>> $minimum
>>>>> 
>>>>> [1] 1.714286
>>>>> 
>>>>> $objective
>>>>> 
>>>>> [1] 39.71429
>>>>> 
>>>>> 
>>>>> The MLE using optimize() is 1.71, but what curve() gives me is the
>>>>> absolute
>>>>> minimum.
>>>>> 
>>>>> I think 1.71 is the right answer, but why does the graph showing it's
>> the
>>>>> minimum?  What is going on here?
>>>>> 
>>>> 
>>>> Your graph shows that there is indeed a *minimum* at 1.71.  And
>> optimise()
>>>> is correctly finding that minimum.
>>>> 
>>>> If you want optimise() to find the maximum, set maximum=TRUE.  In which
>>>> case it will return "20" (or something very close to 20).
>>>> 
>>>> Your function fn() appears not to be the log likelihood that you had in
>>>> mind.  Perhaps you the negative of fn()???
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf Turner
>>>> 
>>>> --
>>>> Technical Editor ANZJS
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>> 
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Thu Nov 19 19:08:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 19 Nov 2015 19:08:14 +0100
Subject: [R] [FORGED] How to find the likelihood, MLE and plot it?
In-Reply-To: <9344BB28-B9E5-4121-B6C6-050284EF0663@comcast.net>
References: <CAE2FW2nuxzC7uH-Mk_4t_MzvEXgCP6pjQLiF5JaG82LhAt3XTQ@mail.gmail.com>
	<564D0889.2000407@auckland.ac.nz>
	<CAE2FW2n7qdWg_7M2JCrZVFsQHCkC_jQu+BNBtm--5KAJdwzi_A@mail.gmail.com>
	<CD838941-835D-4937-9D8C-12553314C38F@gmail.com>
	<CAE2FW2nQpjCoxn2Q=zOx+mG4fZW5CN8eet4e__o-oYBOOeLUtg@mail.gmail.com>
	<9344BB28-B9E5-4121-B6C6-050284EF0663@comcast.net>
Message-ID: <83BDB92C-9723-40C4-B168-CEEEA1446463@gmail.com>


> On 19 Nov 2015, at 18:12 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Nov 19, 2015, at 7:35 AM, C W <tmrsg11 at gmail.com> wrote:
>> 
>> ah.  Let me fix that and get back to you.
>> 
>> On a side note, why can't I put fn inside curve(), why do I have to use
>> Vectorize()?
>> 
>> Here's the code and the message:
> 
>>>>>> fn <- function(theta){
>>>>>> 
>>>>>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>>>>> 
>>>>>> }
> 
>> 
>>> curve(fn, -5, 20)
>> Error in curve(fn, -5, 20) :
>> 'expr' did not evaluate to an object of length ?n?
> 
> 
> The sum function is not vectorized. In oder for a function to be considered ?vectorized?, it needs to return a vector of the same length as its input.
> 

Even so, you would have to consider the implications of (xvec - rep(theta, 7)) if theta is a vector. You should have a fighting chance with something like

fn <- function(theta)
  colSums(outer(xvec, theta, dnorm, sd=1, log=TRUE))

or, if you are squeamish about relying on argument order:

fn <- function(theta)
colSums(outer(xvec, theta, function(x,th) dnorm(x=x, mean=th, sd=1, log=TRUE) ))

-pd

> ? 
> David.
>> 
>> 
>> On Thu, Nov 19, 2015 at 10:29 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> 
>>> On 19 Nov 2015, at 16:17 , C W <tmrsg11 at gmail.com> wrote:
>>> 
>>>> Hi Rolf,
>>>> 
>>>> I think the MLE should be 1.71, no?  And yes, I am aware of the
>>>> maximum=TRUE argument.  I still feel something is wrong here.
>>>> 
>>> 
>>> Just read more carefully what Rolf said: Your fn is MINUS the
>>> log-likelihood. So the graph is upside-down.
>>> 
>>> -pd
>>> 
>>> 
>>>> Thanks!
>>>> 
>>>> On Wed, Nov 18, 2015 at 6:23 PM, Rolf Turner <r.turner at auckland.ac.nz>
>>>> wrote:
>>>> 
>>>>> On 19/11/15 11:31, C W wrote:
>>>>> 
>>>>>> Dear R list,
>>>>>> 
>>>>>> I am trying to find the MLE of the likelihood function.  I will plot
>>> the
>>>>>> log-likelihood to check my answer.
>>>>>> 
>>>>>> Here's my R code:
>>>>>> 
>>>>>> xvec <- c(2,5,3,7,-3,-2,0)
>>>>>> 
>>>>>> fn <- function(theta){
>>>>>> 
>>>>>> sum(0.5 * (xvec - rep(theta, 7)) ^ 2 / 1 + 0.5 * log(1))
>>>>>> 
>>>>>> }
>>>>>> 
>>>>>> gn <- Vectorize(fn)
>>>>>> 
>>>>>> curve(gn, -5, 20)
>>>>>> 
>>>>>> optimize(gn, c(-5, 20))
>>>>>> 
>>>>>> $minimum
>>>>>> 
>>>>>> [1] 1.714286
>>>>>> 
>>>>>> $objective
>>>>>> 
>>>>>> [1] 39.71429
>>>>>> 
>>>>>> 
>>>>>> The MLE using optimize() is 1.71, but what curve() gives me is the
>>>>>> absolute
>>>>>> minimum.
>>>>>> 
>>>>>> I think 1.71 is the right answer, but why does the graph showing it's
>>> the
>>>>>> minimum?  What is going on here?
>>>>>> 
>>>>> 
>>>>> Your graph shows that there is indeed a *minimum* at 1.71.  And
>>> optimise()
>>>>> is correctly finding that minimum.
>>>>> 
>>>>> If you want optimise() to find the maximum, set maximum=TRUE.  In which
>>>>> case it will return "20" (or something very close to 20).
>>>>> 
>>>>> Your function fn() appears not to be the log likelihood that you had in
>>>>> mind.  Perhaps you the negative of fn()???
>>>>> 
>>>>> cheers,
>>>>> 
>>>>> Rolf Turner
>>>>> 
>>>>> --
>>>>> Technical Editor ANZJS
>>>>> Department of Statistics
>>>>> University of Auckland
>>>>> Phone: +64-9-373-7599 ext. 88276
>>>>> 
>>>> 
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luysgarcia at gmail.com  Thu Nov 19 20:18:16 2015
From: luysgarcia at gmail.com (=?UTF-8?Q?Luis_Fernando_Garc=C3=ADa?=)
Date: Thu, 19 Nov 2015 16:18:16 -0300
Subject: [R] Change breaks x axis in plot
Message-ID: <CANxP2S7iXVOmgXtOJoGr0xZDsC_W3LyBJ82t32yZPUkBcdecGQ@mail.gmail.com>

I have the following graph:
 my problem is the scale, I just need it to show the values for 1 and 2 and
remove the intermediate values (1.2,1.4,1.6,1.8). How could I do it? I'm,
attaching the script code for the plot.

Thanks in advance

###AV=mean values
##SD=Sd values


plot(D ~ ferre$Cantidad, type="n",ylim=range(0:1.5))
points(AV, pch = 16, cex = 1.5)
arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x + SD$x, angle
= 90)
arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x - SD$x, angle
= 90)

	[[alternative HTML version deleted]]


From erich.neuwirth at univie.ac.at  Thu Nov 19 21:59:33 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 19 Nov 2015 21:59:33 +0100
Subject: [R] is.na behavior
In-Reply-To: <CAFEqCdy7N0Z6RY9KPmtbojQvnXivYX1FeAQvMq-Q=+X4coQ=ug@mail.gmail.com>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>
	<CAGx1TMBDHaji4Lvu7HCXmDrjQPz74jr92cJdWtWR0dVkgbz1xA@mail.gmail.com>
	<CAFEqCdy7N0Z6RY9KPmtbojQvnXivYX1FeAQvMq-Q=+X4coQ=ug@mail.gmail.com>
Message-ID: <0660463A-2C21-4047-8FAD-1A4C21A18E9E@univie.ac.at>

I am not sure I undestand the issue.
But if the question is to decidedif an expression evaluates to NA,
using eval should solve the problem.
In fact, I do not really understand what an NA expression, and not an expression evaluating to NA,
means.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151119/f16ddc9d/attachment.bin>

From ruipbarradas at sapo.pt  Thu Nov 19 22:42:59 2015
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 19 Nov 2015 21:42:59 +0000
Subject: [R] Change breaks x axis in plot
In-Reply-To: <CANxP2S7iXVOmgXtOJoGr0xZDsC_W3LyBJ82t32yZPUkBcdecGQ@mail.gmail.com>
Message-ID: <20151119214259.Horde.kUuSQnW5hKNLD4IlsvDGfpw@mail.sapo.pt>

Hello,

Maybe something like this?

plot(1:2, xaxp = c(1,2,1))

See ?par.

Hope this helps,

Rui Barradas
?

Citando Luis Fernando Garc?a <luysgarcia at gmail.com>:

> I have the following graph:
> my problem is the scale, I just need it to show the values for 1 and 2 and
> remove the intermediate values (1.2,1.4,1.6,1.8). How could I do it? I'm,
> attaching the script code for the plot.
>
> Thanks in advance
>
> ###AV=mean values
> ##SD=Sd values
>
> plot(D ~ ferre$Cantidad, type="n",ylim=range(0:1.5))
> points(AV, pch = 16, cex = 1.5)
> arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x + SD$x, angle
> = 90)
> arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x - SD$x, angle
> = 90)
>
> ? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Nov 19 22:50:52 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 19 Nov 2015 13:50:52 -0800
Subject: [R] Change breaks x axis in plot
In-Reply-To: <CANxP2S7iXVOmgXtOJoGr0xZDsC_W3LyBJ82t32yZPUkBcdecGQ@mail.gmail.com>
Message-ID: <0E8708633B3.00001082jrkrideau@inbox.com>


xx <- seq(1, 2, by = 0.1)
yy <- sample(1:20, 11)
plot(xx, yy, xaxt="n")
axis(1, at=1: 2, labels=letters[1:2])

may be what you want.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: luysgarcia at gmail.com
> Sent: Thu, 19 Nov 2015 16:18:16 -0300
> To: r-help at r-project.org
> Subject: [R] Change breaks x axis in plot
> 
> I have the following graph:
>  my problem is the scale, I just need it to show the values for 1 and 2
> and
> remove the intermediate values (1.2,1.4,1.6,1.8). How could I do it? I'm,
> attaching the script code for the plot.
> 
> Thanks in advance
> 
> ###AV=mean values
> ##SD=Sd values
> 
> 
> plot(D ~ ferre$Cantidad, type="n",ylim=range(0:1.5))
> points(AV, pch = 16, cex = 1.5)
> arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x + SD$x,
> angle
> = 90)
> arrows(x0 = AV$Group.1, y0 = AV$x, x1 = AV$Group.1, y1 =AV$x - SD$x,
> angle
> = 90)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jdnewmil at dcn.davis.ca.us  Thu Nov 19 22:52:08 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 19 Nov 2015 13:52:08 -0800
Subject: [R] is.na behavior
In-Reply-To: <0660463A-2C21-4047-8FAD-1A4C21A18E9E@univie.ac.at>
References: <CAGx1TMBxw=5fE1sXqi3uPiOvkFFYHpcO-xM802o-p2OFxdMkKg@mail.gmail.com>
	<5CB69B3B-20C9-4D2A-9CB8-5B90FA238761@comcast.net>
	<CAGx1TMBDHaji4Lvu7HCXmDrjQPz74jr92cJdWtWR0dVkgbz1xA@mail.gmail.com>
	<CAFEqCdy7N0Z6RY9KPmtbojQvnXivYX1FeAQvMq-Q=+X4coQ=ug@mail.gmail.com>
	<0660463A-2C21-4047-8FAD-1A4C21A18E9E@univie.ac.at>
Message-ID: <967076C2-8AB6-443B-835C-8DE32558BAB8@dcn.davis.ca.us>

I don't think the question is about what an expression evaluates to,  but what it is.

I don't think it makes sense for an expression to be NA, but I am not a language designer.  The expression NA tells the compiler that a literal NA_logical_ value is to be returned from evaluating that expression,  but that is not what the expression itself is. Nor is it a no-operation... that has a different meaning than "unknown value".

I would construct a function that simply returns NA and use that as the default value for the function that the OP constructed, and always call the function rather than testing what it is. 

On November 19, 2015 12:59:33 PM PST, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
>I am not sure I undestand the issue.
>But if the question is to decidedif an expression evaluates to NA,
>using eval should solve the problem.
>In fact, I do not really understand what an NA expression, and not an
>expression evaluating to NA,
>means.
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent frommy phone. Please excuse my brevity.
	[[alternative HTML version deleted]]


From damir.cosic at gmail.com  Fri Nov 20 04:53:25 2015
From: damir.cosic at gmail.com (Damir Cosic)
Date: Thu, 19 Nov 2015 22:53:25 -0500
Subject: [R] predict() works with the design matrix but throws error with
 some rows of that matrix
Message-ID: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>

Hello,

I am having problems with predict() after a multinomial logit regression by
multinom(). I generate a design matrix with model.matrix() and use it to
estimate the model. Then, if I pass the entire design matrix to predict(),
it returns the same output as fitted(), which is expected. But if I pass
only a few rows of the design matrix, it throws this error:

Error in model.frame.default(Terms, newdata, na.action = na.omit, xlev
= object$xlevels) :    variable lengths differ (found for 'z') In addition:

Warning message: 'newdata' had 6 rows but variables found have 15 rows

This is a minimal example:

require(nnet)

y<-factor(rep(c(1,2,3),5), levels=1:3, labels=c("good","bad","ugly"))
x<-rnorm(15)+.2*rep(1:3,5)
z<-factor(rep(c(1,2,2),5), levels=1:2, labels=c("short","tall"))

df<-data.frame(y=y, x=x, z=z)
mm<-model.matrix(~x+z, data=df)[,2:3]
m<-multinom(y ~ x+z, data=df)

p1<-predict(m,mm,"probs")

p2<-predict(m,head(mm),"probs")

My actual goal is out-of-sample prediction, but I could not make it work
and, while debugging it, I reduced it to this problem.

Best,

Damir

	[[alternative HTML version deleted]]


From naomi.evans21 at gmail.com  Fri Nov 20 07:52:51 2015
From: naomi.evans21 at gmail.com (Naomi Evans)
Date: Fri, 20 Nov 2015 16:52:51 +1000
Subject: [R]  Non-conformable arrays - Error in var(betas)
Message-ID: <CAMu6Z51vT8B7kyqptp1PwYaHqO0D_i59XzLJHwx1HszLSMqS4w@mail.gmail.com>

Hello,



If there is anyone who can offer me some guidance on how to resolve the
error below, I would be very grateful.


I am attempting to conduct a 'Resource Utilization Function' analysis using
the 'ruf' package.  My code is below:


library(ruf)

d78423 <- read.csv("RUF/78423_RelUse.csv")

# Set initial estimates at the spatial range and smoothness

hval <- c(1040, 1.5)

# Estimate the maximum likelihood values with UNSTANDARDIZED COEFFICIENTS

d78423.fit.unstandardized <- ruf.fit(UD ~ factor(Asp_Cat) + Dist_Ck +
Dist_CV + Dist_Pl +

                                       factor(FI_BVG) + FPC + factor(LR5) +
b1_Sol,

                                     space = ~ X + Y,

                                     data = d78423, theta = hval,

                                     name = "Dingo 78423 unstandardized",

                                     fixsmoothness = FALSE,

                                     standardized = FALSE)


Running the 'd78423.fit.unstandardized' portion of the code produces the
following messages:


Error in var(betas) + asycovbeta/con$nresamples : non-conformable arrays

In addition: Warning message:

In ruf.fit(UD ~ factor(Asp_Cat) + Dist_Ck + Dist_CV + Dist_Pl +  :

 Estimating using a resampled MLE. The standard errors include the
variation due to the resampling.


I'm hoping someone here might be able to offer me some advice, as the error
is possibly not specific to the ruf package.


Thank you very much to anyone who can offer advice.


Kind regards,



Naomi

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Nov 20 10:07:09 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 20 Nov 2015 10:07:09 +0100
Subject: [R] predict() works with the design matrix but throws error
	with some rows of that matrix
In-Reply-To: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
References: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
Message-ID: <9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>


> On 20 Nov 2015, at 04:53 , Damir Cosic <damir.cosic at gmail.com> wrote:
> 
> Hello,
> 
> I am having problems with predict() after a multinomial logit regression by
> multinom(). I generate a design matrix with model.matrix() and use it to
> estimate the model. Then, if I pass the entire design matrix to predict(),
> it returns the same output as fitted(), which is expected. But if I pass
> only a few rows of the design matrix, it throws this error:
> 
> Error in model.frame.default(Terms, newdata, na.action = na.omit, xlev
> = object$xlevels) :    variable lengths differ (found for 'z') In addition:
> 
> Warning message: 'newdata' had 6 rows but variables found have 15 rows

Offhand (sorry, no time for testing things this morning) I suspect that you are mixing paradigms. You can _either_ multiply coefficients with a design matrix _or_ look up variables in a data frame, and I think you are trying to look up variables in a matrix. In particular, I don't expect mm to have a column called "z".

Accordingly, neither of your examples actually work, both cases find z (and x?) in the global environment, it is just only in the latter example that the inconsistency is discovered. I think you want either to use model.frame or an explicit mm %*% coef(model) (or thereabouts).


> 
> This is a minimal example:
> 
> require(nnet)
> 
> y<-factor(rep(c(1,2,3),5), levels=1:3, labels=c("good","bad","ugly"))
> x<-rnorm(15)+.2*rep(1:3,5)
> z<-factor(rep(c(1,2,2),5), levels=1:2, labels=c("short","tall"))
> 
> df<-data.frame(y=y, x=x, z=z)
> mm<-model.matrix(~x+z, data=df)[,2:3]
> m<-multinom(y ~ x+z, data=df)
> 
> p1<-predict(m,mm,"probs")
> 
> p2<-predict(m,head(mm),"probs")
> 
> My actual goal is out-of-sample prediction, but I could not make it work
> and, while debugging it, I reduced it to this problem.
> 
> Best,
> 
> Damir
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Fri Nov 20 10:57:15 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 20 Nov 2015 10:57:15 +0100
Subject: [R] predict() works with the design matrix but throws error
	with some rows of that matrix
In-Reply-To: <9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>
References: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
	<9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>
Message-ID: <6547A681-8821-49F6-88D0-EC3A0440FFBD@gmail.com>


On 20 Nov 2015, at 10:07 , peter dalgaard <pdalgd at gmail.com> wrote:

>> 
>> On 20 Nov 2015, at 04:53 , Damir Cosic <damir.cosic at gmail.com> wrote:
>> 
>> Hello,
>> 
>> I am having problems with predict() after a multinomial logit regression by
>> multinom(). I generate a design matrix with model.matrix() and use it to
>> estimate the model. Then, if I pass the entire design matrix to predict(),
>> it returns the same output as fitted(), which is expected. But if I pass
>> only a few rows of the design matrix, it throws this error:
>> 
>> Error in model.frame.default(Terms, newdata, na.action = na.omit, xlev
>> = object$xlevels) :    variable lengths differ (found for 'z') In addition:
>> 
>> Warning message: 'newdata' had 6 rows but variables found have 15 rows
> 
> Offhand (sorry, no time for testing things this morning) I suspect that you are mixing paradigms. You can _either_ multiply coefficients with a design matrix _or_ look up variables in a data frame, and I think you are trying to look up variables in a matrix. In particular, I don't expect mm to have a column called "z".

A little further thought later: The crux is that matrices will double as data frames in the newdata argument, but it will only work for numerical variables. Your model contains a numeric and a factor variable so it won't work, for two reasons:

> head(mm)
           x ztall
1 -2.4963581     0
2  0.9895450     1
3  1.8755237     1
4  0.8911458     0
5 -2.1458457     1
6  0.6294571     1

I.e., there is no "z" column, but even if there were, it would mismatch with the model

> colnames(mm)[2] <- "z"
> p2<-predict(m,head(mm),"probs")
Error: variable 'z' was fitted with type "factor" but type "numeric" was supplied
In addition: Warning message:
In model.frame.default(Terms, newdata, na.action = na.omit, xlev = object$xlevels) :
  variable 'z' is not a factor

At this point, newdata=mm will fail too, as I predicted. (Pun almost unintended.) 

Notice that this works fine:

> p2<-predict(m,head(df),"probs")
> p2
          good          bad         ugly
1 9.998923e-01 8.171733e-05 2.598999e-05
2 2.804424e-05 4.170214e-01 5.829506e-01
3 2.892377e-05 3.255878e-01 6.743832e-01
4 9.999315e-01 2.818836e-05 4.031584e-05
5 1.863116e-05 7.420142e-01 2.579672e-01
6 2.740359e-05 4.563101e-01 5.436625e-01
>

-pd

> 
> Accordingly, neither of your examples actually work, both cases find z (and x?) in the global environment, it is just only in the latter example that the inconsistency is discovered. I think you want either to use model.frame or an explicit mm %*% coef(model) (or thereabouts).
> 
> 
>> 
>> This is a minimal example:
>> 
>> require(nnet)
>> 
>> y<-factor(rep(c(1,2,3),5), levels=1:3, labels=c("good","bad","ugly"))
>> x<-rnorm(15)+.2*rep(1:3,5)
>> z<-factor(rep(c(1,2,2),5), levels=1:2, labels=c("short","tall"))
>> 
>> df<-data.frame(y=y, x=x, z=z)
>> mm<-model.matrix(~x+z, data=df)[,2:3]
>> m<-multinom(y ~ x+z, data=df)
>> 
>> p1<-predict(m,mm,"probs")
>> 
>> p2<-predict(m,head(mm),"probs")
>> 
>> My actual goal is out-of-sample prediction, but I could not make it work
>> and, while debugging it, I reduced it to this problem.
>> 
>> Best,
>> 
>> Damir
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pimlists at gmail.com  Fri Nov 20 09:24:24 2015
From: pimlists at gmail.com (pim schravendijk)
Date: Fri, 20 Nov 2015 09:24:24 +0100
Subject: [R] certificate error when downloading from cran.r-project.org
Message-ID: <CAEvVGNiJ2cCX3WvpXpumncSNchwuK=eViD4wG9hiUVV1O+F+ZA@mail.gmail.com>

Excuse me if this may be a superfluous question, but I was wondering if
maybe a change in the r-project server configuration broke the certificate.
Or are the certificates in my browser outdated?

Anyway, when downloading R source code from cran I get the following error:

ERROR: certificate common name ?r-project.org? doesn?t match requested host
name ?cran.r-project.org?.

I can of course use the workaround but I would rather make sure I am not
victim of some man-in-the-middle hack.

Any thoughts on this?

Greetings, Pim

Here's the whole message:

# wget https://cran.r-project.org/src/base/R-3/R-3.2.2.tar.gz
--2015-11-20 09:17:34--
https://cran.r-project.org/src/base/R-3/R-3.2.2.tar.gz
Resolving cran.r-project.org... 137.208.57.37
Connecting to cran.r-project.org|137.208.57.37|:443... connected.
ERROR: certificate common name ?r-project.org? doesn?t match requested host
name ?cran.r-project.org?.
To connect to cran.r-project.org insecurely, use ?--no-check-certificate?.

	[[alternative HTML version deleted]]


From bmihaljevic at fi.upm.es  Thu Nov 19 16:46:00 2015
From: bmihaljevic at fi.upm.es (Bojan Mihaljevic)
Date: Thu, 19 Nov 2015 16:46:00 +0100
Subject: [R] [R-pkgs] Version 0.3.2 of bnclassify on CRAN
Message-ID: <CAE4w2GWLqQP7Cg3YNAfVyVAQv7q0oOkjcU=E88aW9oHOiHPzkQ@mail.gmail.com>

Dear R users,

I am glad to announce that version 0.3.2 of bnclassify is on CRAN.
bnclassify implements algorithms for learning the structure and parameters
of discrete Bayesian network classifiers from data, fast prediction with
complete data, cross-validation and utility functions for inspecting the
models.

This version improves function documentation and the introductory vignette,
adds two vignettes, and implements the model averaged naive Bayes.

Best regards,
Bojan Mihaljevic

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dcarlson at tamu.edu  Fri Nov 20 16:40:29 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 20 Nov 2015 15:40:29 +0000
Subject: [R] knn - random result although use.all=TRUE
In-Reply-To: <564DCA1A.4020101@ehu.es>
References: <564DCA1A.4020101@ehu.es>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E157D@mb02.ads.tamu.edu>

Changing your definition of cl to clase let me replicate the problem. If you set a random seed just before running knn() the results are consistent so that indicates that the function is drawing a random number at some point. 

You should probably contact the package maintainer, but your toy data set is trivially simple. You have 40 total observations, but X1 has only 3 different values and X2 has only 2 different values so there are only 6 different combinations. The distance matrix on your training set has 435 distances, but only 5 different values! As a result there are many, many tied values so the algorithm probably uses a random method of selecting which 3 to use.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of itziar irigoien
Sent: Thursday, November 19, 2015 7:10 AM
To: r-help at r-project.org
Subject: [R] knn - random result although use.all=TRUE

Dear all,

I have this toy example to work with k-nn classification approach. (My 
data, code and results are at the end of the message)
Working with knn function in library class and setting the parameter 
use.all=TRUE, I would not expect a random answer. Nevertheless I get a 
different answer each time I apply it. Could anyone help me finding out 
what is going on?

Thanks,

Itziar Irigoien

# Generate data
n <- 40
n1 <- 16
n2 <- n-n1
cl <- rep(1:2, c(n1, n2))
set.seed(37)
X1 <- sample(1:3, n, replace=TRUE, prob=rep(1/3, 3))
set.seed(36)
aux1 <- sample(1:2, n1, replace=TRUE, prob=c(0.9, 0.1))
set.seed(38)
aux2 <- sample(1:2, n2, replace=TRUE, prob=c(0.2, 0.8))
X2 <- c(aux1, aux2)
X2 <- X2+3
X2[3] <- 5

#Select training and testing sets
set.seed(36)
t <- sample(1:40, 30, replace=FALSE)
train <- cbind(X1[t], X2[t])
test <- cbind(X1[-t], X2[-t])
out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
table(out, clase[-t])
sum(diag(table(out, clase[-t])))/10

# Results I obtained
 > out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
 > table(out, clase[-t])

out 1 2
   1 1 2
   2 0 7
 > sum(diag(table(out, clase[-t])))/10
[1] 0.8


 > out <- knn(train, test, clase[t], k=3, l=0, use.all=TRUE, prob=TRUE)
 > table(out, clase[-t])

out 1 2
   1 1 4
   2 0 5
 > sum(diag(table(out, clase[-t])))/10
[1] 0.6

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Nov 20 18:23:42 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 20 Nov 2015 18:23:42 +0100
Subject: [R] predict() works with the design matrix but throws error
	with some rows of that matrix
In-Reply-To: <CAFYOMUzB+pBeLoJcrRSMMmxKafH3955G4kwF9W1VtCy+wFCFfg@mail.gmail.com>
References: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
	<9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>
	<6547A681-8821-49F6-88D0-EC3A0440FFBD@gmail.com>
	<CAFYOMUzB+pBeLoJcrRSMMmxKafH3955G4kwF9W1VtCy+wFCFfg@mail.gmail.com>
Message-ID: <49DE1748-3645-4A38-B82E-F564C9ED4D38@gmail.com>


> On 20 Nov 2015, at 17:17 , Damir Cosic <damir.cosic at gmail.com> wrote:
> 
> 
> To do the same with matrix multiplication, I use the expression 1/(1+exp(-xb)):
> 
> head(1/(1+exp(-(cbind(c(1), mm) %*% coef(m)[2,]))))
> 
> which should produce the third column above, but it doesn't:
> 

I'm rusty on this, but I suspect that you need

e_i/sum(e_i)

with e_i = exp(x b_i)

(and b_1 == 0 by convention)

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From friendly at yorku.ca  Thu Nov 19 19:47:57 2015
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 19 Nov 2015 13:47:57 -0500
Subject: [R] [R-pkgs] matlib package for linear algebra and
	multivariate	statistics
Message-ID: <564E195D.8080807@yorku.ca>

Dear useRs

A new package, "matlib" has been under development and the latest 
version, 0.5.2,
will shortly be on CRAN.
http://cran.us.r-project.org/web/packages/matlib/

The package is designed to provide a collection of functions and vignettes
for teaching and learning linear algebra and multivariate statistics.

In some cases, convenience functions are provided for concepts available
elsewhere in R, but where the function call or name is not obvious. In other
cases, functions are provided to show or demonstrate an algorithm.

The topics covered in the package include:

* Vector geometry: vector diagrams, projection

* Determinants: minors, cofactors and expansion by cofactors

* Elementary row operations: functions for solving linear equations 
"manually" by the steps used in row echelon form and Gaussian elimination

* Linear equations: functions to illustrate and plot linear equations of 
the form $\mathbf{A x = b}$

* Gaussian elimination: functions for illustrating Gaussian elimination 
for solving systems of linear equations of the form
$\mathbf{A x = b}$.  These functions provide a `verbose=TRUE` argument 
to show the intermediate steps.

* Eigenvalues: functions to illustrate the algorithms for calculating 
eigenvalues and eigenvectors and the SVD

* browseVignettes("matlib") shows currently available vignettes.

The GitHub development page for the project is:
https://github.com/friendly/matlib

Comments, suggestions, issues, etc. are invited there.

best,
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From viveksutra at gmail.com  Fri Nov 20 18:38:14 2015
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Fri, 20 Nov 2015 18:38:14 +0100
Subject: [R] exporting tables from an access database using parallel foreach
Message-ID: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>

Hi
I want to extract data from a Microsoft access database having many tables
with more than 1e7 rows. I find that the following code works to export a
table to a rds file :
#####################
setwd('C:/sFolder')
library(RODBC);library(DBI)
ch<-odbcConnect("sample")

#No. of rows in the table not known
rowN<-1e6  # no. of rows defined
db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
file<-paste0('Table1',1,'.rds')
df1<-saveRDS(db,file1)

rm(db);gc()   # garbage collection to free up the memory

# To successively obtain more chunks from the access database
for (i in 2:10) {
  rm(df);gc()
  df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
  file<-paste0('Table1',i,'.rds')
  df1<-saveRDS(df,file)
  if (dim(df)[1]<rowN)
    break
}
rm(df);gc()
odbcCloseAll()
##############################

I would like to know the following :
1. Is there any way to extract data from a table by just specifying the row
number range. I have extracted data before. Instead of repeating the
operations, I would just like to obtain data from, let's say, 8e6 to 9e6
row range. I cannot do this now. I have to successively use the
sqlfetchMore command. I would like to know if it is possible to straight
away go to the 8e6 to 9e6 row range.
2. Is it possible to use the foreach package in the extraction step (in
place of the for loop above). I am planning to use the foreach command in
parallel later for processing the data in the multiple files. I just wonder
if it is possible to do parallel processing for the data extraction also.
Thanks,
Vivek Sutradhara

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri Nov 20 19:09:23 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 20 Nov 2015 12:09:23 -0600
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
Message-ID: <CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>

A possibility could be to not use ODBC, but the CRAN package openslsx (
https://cran.revolutionanalytics.com/web/packages/openxlsx/index.html ).
Then use the read.xlsx() function.
<quote>
Description Read data from an Excel file or Workbook object into a
data.frame

Usage read.xlsx(xlsxFile, sheet = 1, startRow = 1, colNames = TRUE,
rowNames = FALSE, detectDates = FALSE, skipEmptyRows = TRUE, rows = NULL,
cols = NULL, check.names = FALSE, namedRegion = NULL)

Arguments xlsxFile An xlsx file or Workbook object sheet The name or index
of the sheet to read data from.
startRow first row to begin looking for data. Empty rows at the top of a
file are always skipped, regardless of the value of startRow.
colNames If TRUE, the first row of data will be used as column names.
rowNames If TRUE, first column of data will be used as row names.
detectDates If TRUE, attempt to recognise dates and perform conversion.
skipEmptyRows If TRUE, empty rows are skipped else empty rows after the
first row containing data will return a row of NAs.
rows A numeric vector specifying which rows in the Excel file to read. If
NULL, all rows are read.
cols A numeric vector specifying which columns in the Excel file to read.
If NULL, all columns are read.
check.names logical. If TRUE then the names of the variables in the data
frame are checked to ensure that they are syntactically valid variable
names
namedRegion A named region in the Workbook. If not NULL startRow, rows and
cols paramters are ignored.
</quote>

On Fri, Nov 20, 2015 at 11:38 AM, Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi
> I want to extract data from a Microsoft access database having many tables
> with more than 1e7 rows. I find that the following code works to export a
> table to a rds file :
> #####################
> setwd('C:/sFolder')
> library(RODBC);library(DBI)
> ch<-odbcConnect("sample")
>
> #No. of rows in the table not known
> rowN<-1e6  # no. of rows defined
> db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
> file<-paste0('Table1',1,'.rds')
> df1<-saveRDS(db,file1)
>
> rm(db);gc()   # garbage collection to free up the memory
>
> # To successively obtain more chunks from the access database
> for (i in 2:10) {
>   rm(df);gc()
>   df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
>   file<-paste0('Table1',i,'.rds')
>   df1<-saveRDS(df,file)
>   if (dim(df)[1]<rowN)
>     break
> }
> rm(df);gc()
> odbcCloseAll()
> ##############################
>
> I would like to know the following :
> 1. Is there any way to extract data from a table by just specifying the row
> number range. I have extracted data before. Instead of repeating the
> operations, I would just like to obtain data from, let's say, 8e6 to 9e6
> row range. I cannot do this now. I have to successively use the
> sqlfetchMore command. I would like to know if it is possible to straight
> away go to the 8e6 to 9e6 row range.
> 2. Is it possible to use the foreach package in the extraction step (in
> place of the for loop above). I am planning to use the foreach command in
> parallel later for processing the data in the multiple files. I just wonder
> if it is possible to do parallel processing for the data extraction also.
> Thanks,
> Vivek Sutradhara
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From viveksutra at gmail.com  Fri Nov 20 19:32:31 2015
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Fri, 20 Nov 2015 19:32:31 +0100
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
Message-ID: <CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>

Hi John,
Thanks a lot for your quick reply. And thanks for drawing my attention to
the openslsx package. I will certainly look into it when I work with Excel.
But right now, my problems are with Microsoft Access.

There are huge tables there which I am not able to export to excel, csv or
text files with native access methods. The only solution that has worked so
far is to incrementally extract data with the the help of RODBC. This was a
huge leap in my attempts to export the tables. Once I have the data in form
of rds files (which are compressed as well), I have found that it is much
easier to work with them.

But my wishes have suddenly expanded and I want to find out if it is
possible to go beyond the normal capabilities of RODBC (the sqlFetch
command does not have a provision for specifying the row number range). I
am a newbie with parallel methods (using the 4 cores on my pc) but I am
hoping to progress with that for processing the data from the multiple
chunks of data (the first step will be just to filter and gather the data
of relevance).

I hope that I have explained what I am looking for.
Thanks,
Vivek

2015-11-20 19:09 GMT+01:00 John McKown <john.archie.mckown at gmail.com>:

> A possibility could be to not use ODBC, but the CRAN package openslsx (
> https://cran.revolutionanalytics.com/web/packages/openxlsx/index.html ).
> Then use the read.xlsx() function.
> <quote>
> Description Read data from an Excel file or Workbook object into a
> data.frame
>
> Usage read.xlsx(xlsxFile, sheet = 1, startRow = 1, colNames = TRUE,
> rowNames = FALSE, detectDates = FALSE, skipEmptyRows = TRUE, rows = NULL,
> cols = NULL, check.names = FALSE, namedRegion = NULL)
>
> Arguments xlsxFile An xlsx file or Workbook object sheet The name or index
> of the sheet to read data from.
> startRow first row to begin looking for data. Empty rows at the top of a
> file are always skipped, regardless of the value of startRow.
> colNames If TRUE, the first row of data will be used as column names.
> rowNames If TRUE, first column of data will be used as row names.
> detectDates If TRUE, attempt to recognise dates and perform conversion.
> skipEmptyRows If TRUE, empty rows are skipped else empty rows after the
> first row containing data will return a row of NAs.
> rows A numeric vector specifying which rows in the Excel file to read. If
> NULL, all rows are read.
> cols A numeric vector specifying which columns in the Excel file to read.
> If NULL, all columns are read.
> check.names logical. If TRUE then the names of the variables in the data
> frame are checked to ensure that they are syntactically valid variable
> names
> namedRegion A named region in the Workbook. If not NULL startRow, rows and
> cols paramters are ignored.
> </quote>
>
> On Fri, Nov 20, 2015 at 11:38 AM, Vivek Sutradhara <viveksutra at gmail.com>
> wrote:
>
>> Hi
>> I want to extract data from a Microsoft access database having many tables
>> with more than 1e7 rows. I find that the following code works to export a
>> table to a rds file :
>> #####################
>> setwd('C:/sFolder')
>> library(RODBC);library(DBI)
>> ch<-odbcConnect("sample")
>>
>> #No. of rows in the table not known
>> rowN<-1e6  # no. of rows defined
>> db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
>> file<-paste0('Table1',1,'.rds')
>> df1<-saveRDS(db,file1)
>>
>> rm(db);gc()   # garbage collection to free up the memory
>>
>> # To successively obtain more chunks from the access database
>> for (i in 2:10) {
>>   rm(df);gc()
>>   df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
>>   file<-paste0('Table1',i,'.rds')
>>   df1<-saveRDS(df,file)
>>   if (dim(df)[1]<rowN)
>>     break
>> }
>> rm(df);gc()
>> odbcCloseAll()
>> ##############################
>>
>> I would like to know the following :
>> 1. Is there any way to extract data from a table by just specifying the
>> row
>> number range. I have extracted data before. Instead of repeating the
>> operations, I would just like to obtain data from, let's say, 8e6 to 9e6
>> row range. I cannot do this now. I have to successively use the
>> sqlfetchMore command. I would like to know if it is possible to straight
>> away go to the 8e6 to 9e6 row range.
>> 2. Is it possible to use the foreach package in the extraction step (in
>> place of the for loop above). I am planning to use the foreach command in
>> parallel later for processing the data in the multiple files. I just
>> wonder
>> if it is possible to do parallel processing for the data extraction also.
>> Thanks,
>> Vivek Sutradhara
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
>
> Schrodinger's backup: The condition of any backup is unknown until a
> restore is attempted.
>
> Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.
>
> He's about as useful as a wax frying pan.
>
> 10 to the 12th power microphones = 1 Megaphone
>
> Maranatha! <><
> John McKown
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri Nov 20 19:33:11 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 20 Nov 2015 12:33:11 -0600
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
Message-ID: <CAAJSdjicFZfmF0b3aCN+dGewD60pBRAcrMMBYG5s6cNnR6WTYA@mail.gmail.com>

My apologies, you wrote "access" and I read "Excel". I really should not
play a game on my smartphone while speed reading emails.

On Fri, Nov 20, 2015 at 11:38 AM, Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi
> I want to extract data from a Microsoft access database having many tables
> with more than 1e7 rows. I find that the following code works to export a
> table to a rds file :
> #####################
> setwd('C:/sFolder')
> library(RODBC);library(DBI)
> ch<-odbcConnect("sample")
>
> #No. of rows in the table not known
> rowN<-1e6  # no. of rows defined
> db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
> file<-paste0('Table1',1,'.rds')
> df1<-saveRDS(db,file1)
>
> rm(db);gc()   # garbage collection to free up the memory
>
> # To successively obtain more chunks from the access database
> for (i in 2:10) {
>   rm(df);gc()
>   df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
>   file<-paste0('Table1',i,'.rds')
>   df1<-saveRDS(df,file)
>   if (dim(df)[1]<rowN)
>     break
> }
> rm(df);gc()
> odbcCloseAll()
> ##############################
>
> I would like to know the following :
> 1. Is there any way to extract data from a table by just specifying the row
> number range. I have extracted data before. Instead of repeating the
> operations, I would just like to obtain data from, let's say, 8e6 to 9e6
> row range. I cannot do this now. I have to successively use the
> sqlfetchMore command. I would like to know if it is possible to straight
> away go to the 8e6 to 9e6 row range.
> 2. Is it possible to use the foreach package in the extraction step (in
> place of the for loop above). I am planning to use the foreach command in
> parallel later for processing the data in the multiple files. I just wonder
> if it is possible to do parallel processing for the data extraction also.
> Thanks,
> Vivek Sutradhara
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Nov 20 20:25:13 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 20 Nov 2015 11:25:13 -0800
Subject: [R] exporting tables from an access database using
	parallel	foreach
In-Reply-To: <CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
	<CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
Message-ID: <39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>

Row numbers are not a standard feature in SQL, and as far as I know the Access Jet engine does not support them.   You are supposed to use the key columns to partition your data, but that may require knowing how many records fall within convenient bin sizes if the data are not uniformly distributed.  You can find that out using SQL group by queries. 

Note that you the resource you appear to be limited by is the database engine.  Parallel processing (more CPUs) is unlikely to yield any improvement,  and is in fact likely to slow you down. 

This looks like a good topic for the R-sig-db mailing list if you have further questions about R and databases,  or find a SQL support forum if you need to learn more about using SQL in general. 

On November 20, 2015 10:32:31 AM PST, Vivek Sutradhara <viveksutra at gmail.com> wrote:
>Hi John,
>Thanks a lot for your quick reply. And thanks for drawing my attention
>to
>the openslsx package. I will certainly look into it when I work with
>Excel.
>But right now, my problems are with Microsoft Access.
>
>There are huge tables there which I am not able to export to excel, csv
>or
>text files with native access methods. The only solution that has
>worked so
>far is to incrementally extract data with the the help of RODBC. This
>was a
>huge leap in my attempts to export the tables. Once I have the data in
>form
>of rds files (which are compressed as well), I have found that it is
>much
>easier to work with them.
>
>But my wishes have suddenly expanded and I want to find out if it is
>possible to go beyond the normal capabilities of RODBC (the sqlFetch
>command does not have a provision for specifying the row number range).
>I
>am a newbie with parallel methods (using the 4 cores on my pc) but I am
>hoping to progress with that for processing the data from the multiple
>chunks of data (the first step will be just to filter and gather the
>data
>of relevance).
>
>I hope that I have explained what I am looking for.
>Thanks,
>Vivek
>
>2015-11-20 19:09 GMT+01:00 John McKown <john.archie.mckown at gmail.com>:
>
>> A possibility could be to not use ODBC, but the CRAN package openslsx
>(
>> https://cran.revolutionanalytics.com/web/packages/openxlsx/index.html
>).
>> Then use the read.xlsx() function.
>> <quote>
>> Description Read data from an Excel file or Workbook object into a
>> data.frame
>>
>> Usage read.xlsx(xlsxFile, sheet = 1, startRow = 1, colNames = TRUE,
>> rowNames = FALSE, detectDates = FALSE, skipEmptyRows = TRUE, rows =
>NULL,
>> cols = NULL, check.names = FALSE, namedRegion = NULL)
>>
>> Arguments xlsxFile An xlsx file or Workbook object sheet The name or
>index
>> of the sheet to read data from.
>> startRow first row to begin looking for data. Empty rows at the top
>of a
>> file are always skipped, regardless of the value of startRow.
>> colNames If TRUE, the first row of data will be used as column names.
>> rowNames If TRUE, first column of data will be used as row names.
>> detectDates If TRUE, attempt to recognise dates and perform
>conversion.
>> skipEmptyRows If TRUE, empty rows are skipped else empty rows after
>the
>> first row containing data will return a row of NAs.
>> rows A numeric vector specifying which rows in the Excel file to
>read. If
>> NULL, all rows are read.
>> cols A numeric vector specifying which columns in the Excel file to
>read.
>> If NULL, all columns are read.
>> check.names logical. If TRUE then the names of the variables in the
>data
>> frame are checked to ensure that they are syntactically valid
>variable
>> names
>> namedRegion A named region in the Workbook. If not NULL startRow,
>rows and
>> cols paramters are ignored.
>> </quote>
>>
>> On Fri, Nov 20, 2015 at 11:38 AM, Vivek Sutradhara
><viveksutra at gmail.com>
>> wrote:
>>
>>> Hi
>>> I want to extract data from a Microsoft access database having many
>tables
>>> with more than 1e7 rows. I find that the following code works to
>export a
>>> table to a rds file :
>>> #####################
>>> setwd('C:/sFolder')
>>> library(RODBC);library(DBI)
>>> ch<-odbcConnect("sample")
>>>
>>> #No. of rows in the table not known
>>> rowN<-1e6  # no. of rows defined
>>> db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
>>> file<-paste0('Table1',1,'.rds')
>>> df1<-saveRDS(db,file1)
>>>
>>> rm(db);gc()   # garbage collection to free up the memory
>>>
>>> # To successively obtain more chunks from the access database
>>> for (i in 2:10) {
>>>   rm(df);gc()
>>>   df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
>>>   file<-paste0('Table1',i,'.rds')
>>>   df1<-saveRDS(df,file)
>>>   if (dim(df)[1]<rowN)
>>>     break
>>> }
>>> rm(df);gc()
>>> odbcCloseAll()
>>> ##############################
>>>
>>> I would like to know the following :
>>> 1. Is there any way to extract data from a table by just specifying
>the
>>> row
>>> number range. I have extracted data before. Instead of repeating the
>>> operations, I would just like to obtain data from, let's say, 8e6 to
>9e6
>>> row range. I cannot do this now. I have to successively use the
>>> sqlfetchMore command. I would like to know if it is possible to
>straight
>>> away go to the 8e6 to 9e6 row range.
>>> 2. Is it possible to use the foreach package in the extraction step
>(in
>>> place of the for loop above). I am planning to use the foreach
>command in
>>> parallel later for processing the data in the multiple files. I just
>>> wonder
>>> if it is possible to do parallel processing for the data extraction
>also.
>>> Thanks,
>>> Vivek Sutradhara
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>>
>> Schrodinger's backup: The condition of any backup is unknown until a
>> restore is attempted.
>>
>> Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you
>will be.
>>
>> He's about as useful as a wax frying pan.
>>
>> 10 to the 12th power microphones = 1 Megaphone
>>
>> Maranatha! <><
>> John McKown
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From damir.cosic at gmail.com  Fri Nov 20 17:17:01 2015
From: damir.cosic at gmail.com (Damir Cosic)
Date: Fri, 20 Nov 2015 11:17:01 -0500
Subject: [R] predict() works with the design matrix but throws error
 with some rows of that matrix
In-Reply-To: <6547A681-8821-49F6-88D0-EC3A0440FFBD@gmail.com>
References: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
	<9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>
	<6547A681-8821-49F6-88D0-EC3A0440FFBD@gmail.com>
Message-ID: <CAFYOMUzB+pBeLoJcrRSMMmxKafH3955G4kwF9W1VtCy+wFCFfg@mail.gmail.com>

Peter, this is extremely helpful. It is my first time using model.matrix()
and I was not very clear about it.Thank you for clarifying it!

It also helped me figure out how to do out-of-sample prediction. I add it
here in case someone else needs help with this.

oos.df<-data.frame(x=c(0,1), z=factor(c(1,2),levels=1:2,
labels=c("short","tall")))
p4<-predict(m, oos.df, "probs")

To follow up on your comment how design matrix can be used for multiplying
the coefficients and not for looking up variables, I tried to do just that,
but I am getting different results from those returned by predict().

For example,

head(predict(m, df, "probs"))

returns

          good          bad         ugly
1 9.999256e-01 3.419782e-05 4.018257e-05
2 1.064469e-05 5.163435e-01 4.836458e-01
3 8.623258e-06 4.523593e-01 5.476321e-01
4 9.999418e-01 3.116868e-05 2.702482e-05
5 1.289231e-05 5.789110e-01 4.210761e-01
6 9.213303e-06 4.718692e-01 5.281215e-01

To do the same with matrix multiplication, I use the expression
1/(1+exp(-xb)):

head(1/(1+exp(-(cbind(c(1), mm) %*% coef(m)[2,]))))

which should produce the third column above, but it doesn't:

          [,1]
1 4.018394e-05
2 9.999780e-01
3 9.999843e-01
4 2.702566e-05
5 9.999694e-01
6 9.999826e-01




On Fri, Nov 20, 2015 at 4:57 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 20 Nov 2015, at 10:07 , peter dalgaard <pdalgd at gmail.com> wrote:
>
> >>
> >> On 20 Nov 2015, at 04:53 , Damir Cosic <damir.cosic at gmail.com> wrote:
> >>
> >> Hello,
> >>
> >> I am having problems with predict() after a multinomial logit
> regression by
> >> multinom(). I generate a design matrix with model.matrix() and use it to
> >> estimate the model. Then, if I pass the entire design matrix to
> predict(),
> >> it returns the same output as fitted(), which is expected. But if I pass
> >> only a few rows of the design matrix, it throws this error:
> >>
> >> Error in model.frame.default(Terms, newdata, na.action = na.omit, xlev
> >> = object$xlevels) :    variable lengths differ (found for 'z') In
> addition:
> >>
> >> Warning message: 'newdata' had 6 rows but variables found have 15 rows
> >
> > Offhand (sorry, no time for testing things this morning) I suspect that
> you are mixing paradigms. You can _either_ multiply coefficients with a
> design matrix _or_ look up variables in a data frame, and I think you are
> trying to look up variables in a matrix. In particular, I don't expect mm
> to have a column called "z".
>
> A little further thought later: The crux is that matrices will double as
> data frames in the newdata argument, but it will only work for numerical
> variables. Your model contains a numeric and a factor variable so it won't
> work, for two reasons:
>
> > head(mm)
>            x ztall
> 1 -2.4963581     0
> 2  0.9895450     1
> 3  1.8755237     1
> 4  0.8911458     0
> 5 -2.1458457     1
> 6  0.6294571     1
>
> I.e., there is no "z" column, but even if there were, it would mismatch
> with the model
>
> > colnames(mm)[2] <- "z"
> > p2<-predict(m,head(mm),"probs")
> Error: variable 'z' was fitted with type "factor" but type "numeric" was
> supplied
> In addition: Warning message:
> In model.frame.default(Terms, newdata, na.action = na.omit, xlev =
> object$xlevels) :
>   variable 'z' is not a factor
>
> At this point, newdata=mm will fail too, as I predicted. (Pun almost
> unintended.)
>
> Notice that this works fine:
>
> > p2<-predict(m,head(df),"probs")
> > p2
>           good          bad         ugly
> 1 9.998923e-01 8.171733e-05 2.598999e-05
> 2 2.804424e-05 4.170214e-01 5.829506e-01
> 3 2.892377e-05 3.255878e-01 6.743832e-01
> 4 9.999315e-01 2.818836e-05 4.031584e-05
> 5 1.863116e-05 7.420142e-01 2.579672e-01
> 6 2.740359e-05 4.563101e-01 5.436625e-01
> >
>
> -pd
>
> >
> > Accordingly, neither of your examples actually work, both cases find z
> (and x?) in the global environment, it is just only in the latter example
> that the inconsistency is discovered. I think you want either to use
> model.frame or an explicit mm %*% coef(model) (or thereabouts).
> >
> >
> >>
> >> This is a minimal example:
> >>
> >> require(nnet)
> >>
> >> y<-factor(rep(c(1,2,3),5), levels=1:3, labels=c("good","bad","ugly"))
> >> x<-rnorm(15)+.2*rep(1:3,5)
> >> z<-factor(rep(c(1,2,2),5), levels=1:2, labels=c("short","tall"))
> >>
> >> df<-data.frame(y=y, x=x, z=z)
> >> mm<-model.matrix(~x+z, data=df)[,2:3]
> >> m<-multinom(y ~ x+z, data=df)
> >>
> >> p1<-predict(m,mm,"probs")
> >>
> >> p2<-predict(m,head(mm),"probs")
> >>
> >> My actual goal is out-of-sample prediction, but I could not make it work
> >> and, while debugging it, I reduced it to this problem.
> >>
> >> Best,
> >>
> >> Damir
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From damir.cosic at gmail.com  Fri Nov 20 18:37:26 2015
From: damir.cosic at gmail.com (Damir Cosic)
Date: Fri, 20 Nov 2015 12:37:26 -0500
Subject: [R] predict() works with the design matrix but throws error
 with some rows of that matrix
In-Reply-To: <49DE1748-3645-4A38-B82E-F564C9ED4D38@gmail.com>
References: <CAFYOMUw+rudSEDg_vDjmaJ0A9LegWAYSaDtOrAhUVROoRVp-iQ@mail.gmail.com>
	<9B889BE9-8C9C-4E20-AD82-A923FA74990B@gmail.com>
	<6547A681-8821-49F6-88D0-EC3A0440FFBD@gmail.com>
	<CAFYOMUzB+pBeLoJcrRSMMmxKafH3955G4kwF9W1VtCy+wFCFfg@mail.gmail.com>
	<49DE1748-3645-4A38-B82E-F564C9ED4D38@gmail.com>
Message-ID: <CAFYOMUwk+MjheDR4cupJr7bJvRnBeAdiS6X5aKcpk9eUHtXpvA@mail.gmail.com>

Right on! I was using the expression for binomial logit. Thank you so much!


On Fri, Nov 20, 2015 at 12:23 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 20 Nov 2015, at 17:17 , Damir Cosic <damir.cosic at gmail.com> wrote:
> >
> >
> > To do the same with matrix multiplication, I use the expression
> 1/(1+exp(-xb)):
> >
> > head(1/(1+exp(-(cbind(c(1), mm) %*% coef(m)[2,]))))
> >
> > which should produce the third column above, but it doesn't:
> >
>
> I'm rusty on this, but I suspect that you need
>
> e_i/sum(e_i)
>
> with e_i = exp(x b_i)
>
> (and b_1 == 0 by convention)
>
> -pd
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Sat Nov 21 13:44:13 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 21 Nov 2015 07:44:13 -0500
Subject: [R] rank/sort problem
Message-ID: <3692923E-2797-4588-B5DC-4595D8D65BC8@gmail.com>

Hello,

I would like to sort the df below, such that it sorts y1 in decreasing order for tt == 1 and in increasing order for 
tt == 0. My solution is below, but curious if there might be something better (meaning faster in this case). 

Actually, if instead if implicitly sorting, I could add a variable ?rank? as in my ?hope? data frame below, that would work too (as I just need the ranking of observations, not necessarily the data explicitly sorted in the results).

### Sample data
y1 <- c(50,100,200,20,400,100,500,1000,12,25)
tt <- factor(c(1,1,1,0,0,0,0,1,0,0))
df <- data.frame(y1, tt)
 
### My solution
library(dplyr)
sorted <- rbind(df[df$tt == 1, ] %>% arrange(desc(y1)),
                df[df$tt == 0, ] %>% arrange(y1))
 
### What I hope to get
hope <- data.frame(df,
                   rank = c(4, 3, 2, 6, 9, 8, 10, 1, 5, 7))
hope[order(hope$rank),]


Thanks for any help.

Best Axel.
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Nov 21 16:46:29 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 21 Nov 2015 07:46:29 -0800
Subject: [R] rank/sort problem
In-Reply-To: <3692923E-2797-4588-B5DC-4595D8D65BC8@gmail.com>
References: <3692923E-2797-4588-B5DC-4595D8D65BC8@gmail.com>
Message-ID: <CAGxFJbTkRjZTvVRGWy3817Nrb2fHE1=tLhPM6EAyjFzurhDf7Q@mail.gmail.com>

I did not read your post in detail but have you not looked at ?rank ?


Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 21, 2015 at 4:44 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> Hello,
>
> I would like to sort the df below, such that it sorts y1 in decreasing order for tt == 1 and in increasing order for
> tt == 0. My solution is below, but curious if there might be something better (meaning faster in this case).
>
> Actually, if instead if implicitly sorting, I could add a variable ?rank? as in my ?hope? data frame below, that would work too (as I just need the ranking of observations, not necessarily the data explicitly sorted in the results).
>
> ### Sample data
> y1 <- c(50,100,200,20,400,100,500,1000,12,25)
> tt <- factor(c(1,1,1,0,0,0,0,1,0,0))
> df <- data.frame(y1, tt)
>
> ### My solution
> library(dplyr)
> sorted <- rbind(df[df$tt == 1, ] %>% arrange(desc(y1)),
>                 df[df$tt == 0, ] %>% arrange(y1))
>
> ### What I hope to get
> hope <- data.frame(df,
>                    rank = c(4, 3, 2, 6, 9, 8, 10, 1, 5, 7))
> hope[order(hope$rank),]
>
>
> Thanks for any help.
>
> Best Axel.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Nov 21 18:52:39 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 11:52:39 -0600
Subject: [R] Conditional Random selection
Message-ID: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>

Hi all,

I have a data set that contains samples collected over time.   In
each time period the total number of samples are given (X2)   The goal
is to  select 500  random samples.    The selection should be based on
time  (select time periods until I reach 500 samples). Also the time
period should have greater than 0 for  X1 variable. X1 is an indicator
variable.

Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0

tab  <- read.table(textConnection(" time   X1 X2
1      0        251
2      5        230
3      1        300
4      0         25
5      2         10
6      3         101
7      1         300
 8     4         185   "),header = TRUE)

In the above example,  samples from time 1 and 4  will not be selected
( X1 is zero)
So I could reach my target by selecting time 6,7, and 8 or  time 2 and
3 and so on.

Can any one help to do that?


From viveksutra at gmail.com  Sat Nov 21 18:55:13 2015
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sat, 21 Nov 2015 18:55:13 +0100
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
	<CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
	<39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>
Message-ID: <CAHLp6SBAStHOzoBZcm=9KBx5y7Gq6hf9k5FPzXds6DG0H8XRpQ@mail.gmail.com>

Hi John and Jeff,
Thanks a lot for your help. I agree that row numbers are not a standard
feature in SQL. What I am looking for is some kind of a hack. After all,
the sqlFetch command is able to return a specific number of rows. And the
sqlFetchMore command is able to take up the baton from that row onwards to
futher return rows corresponding to the max parameter.

I wonder if it is possible to straight away hop to a certain row number
(without going through sqlfetch and sqlFetchMore and without loading any
data into memory) and then return the contents corresponding to a certain
number of rows. The question is : is there a "catch" for accessing a row
location, and what could be the "hook" for that? I am interested in the the
recent updated rows to a table after a certain date. Is it possible to
identify them in a quick way? Running sql queries on such large tables
appears to take too long a time.

 I understand that there is no provision to do this by available methods.
But, is it possible to get under the hood and find some hack?

Jeff, I will take your suggestion and try my luck at the R-sig-db mailing
list.
Thanks,
Vivek

2015-11-20 20:25 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> Row numbers are not a standard feature in SQL, and as far as I know the
> Access Jet engine does not support them. You are supposed to use the key
> columns to partition your data, but that may require knowing how many
> records fall within convenient bin sizes if the data are not uniformly
> distributed. You can find that out using SQL group by queries.
>
> Note that you the resource you appear to be limited by is the database
> engine. Parallel processing (more CPUs) is unlikely to yield any
> improvement, and is in fact likely to slow you down.
>
> This looks like a good topic for the R-sig-db mailing list if you have
> further questions about R and databases, or find a SQL support forum if you
> need to learn more about using SQL in general.
>
> On November 20, 2015 10:32:31 AM PST, Vivek Sutradhara <
> viveksutra at gmail.com> wrote:
>
>> Hi John,
>> Thanks a lot for your quick reply. And thanks for drawing my attention to
>> the openslsx package. I will certainly look into it when I work with Excel.
>> But right now, my problems are with Microsoft Access.
>>
>> There are huge tables there which I am not able to export to excel, csv or
>> text files with native access methods. The only solution that has worked so
>> far is to incrementally extract data with the the help of RODBC. This was a
>> huge leap in my attempts to export the tables. Once I have the data in form
>> of rds files (which are compressed as well), I have found that it is much
>> easier to work with them.
>>
>> But my wishes have suddenly expanded and I want to find out if it is
>> possible to go beyond the normal capabilities of RODBC (the sqlFetch
>> command does not have a provision for specifying the row number range). I
>> am a newbie with parallel methods (using the 4 cores on my pc) but I
>> am
>> hoping to progress with that for processing the data from the multiple
>> chunks of data (the first step will be just to filter and gather the data
>> of relevance).
>>
>> I hope that I have explained what I am looking for.
>> Thanks,
>> Vivek
>>
>> 2015-11-20 19:09 GMT+01:00 John McKown <john.archie.mckown at gmail.com>:
>>
>>  A possibility could be to not use ODBC, but the CRAN package openslsx (
>>>  https://cran.revolutionanalytics.com/web/packages/openxlsx/index.html ).
>>>  Then use the read.xlsx() function.
>>>  <quote>
>>>  Description Read data from an Excel file or Workbook object into a
>>>  data.frame
>>>
>>>  Usage read.xlsx(xlsxFile, sheet = 1, startRow = 1, colNames = TRUE,
>>>  rowNames = FALSE, detectDates = FALSE,
>>> skipEmptyRows = TRUE, rows = NULL,
>>>  cols = NULL, check.names = FALSE, namedRegion = NULL)
>>>
>>>  Arguments xlsxFile An xlsx file or Workbook object sheet The name or index
>>>  of the sheet to read data from.
>>>  startRow first row to begin looking for data. Empty rows at the top of a
>>>  file are always skipped, regardless of the value of startRow.
>>>  colNames If TRUE, the first row of data will be used as column names.
>>>  rowNames If TRUE, first column of data will be used as row names.
>>>  detectDates If TRUE, attempt to recognise dates and perform conversion.
>>>  skipEmptyRows If TRUE, empty rows are skipped else empty rows after the
>>>  first row containing data will return a row of NAs.
>>>  rows A numeric vector specifying which rows in the Excel file to read. If
>>>  NULL, all rows are read.
>>>  cols A numeric vector specifying which columns in the Excel file to read.
>>>  If NULL, all columns are read.
>>>  check.names logical. If TRUE then
>>> the names of the variables in the data
>>>  frame are checked to ensure that they are syntactically valid variable
>>>  names
>>>  namedRegion A named region in the Workbook. If not NULL startRow, rows and
>>>  cols paramters are ignored.
>>>  </quote>
>>>
>>>  On Fri, Nov 20, 2015 at 11:38 AM, Vivek Sutradhara <viveksutra at gmail.com>
>>>  wrote:
>>>
>>>  Hi
>>>>  I want to extract data from a Microsoft access database having many tables
>>>>  with more than 1e7 rows. I find that the following code works to export a
>>>>  table to a rds file :
>>>>  #####################
>>>>  setwd('C:/sFolder')
>>>>  library(RODBC);library(DBI)
>>>>  ch<-odbcConnect("sample")
>>>>
>>>>  #No. of rows in the table not known
>>>>  rowN<-1e6  # no. of rows defined
>>>>  db<-sqlFetch(ch,"Table1",max=rowN,as.is=TRUE)
>>>>
>>>> file<-paste0('Table1',1,'.rds')
>>>>  df1<-saveRDS(db,file1)
>>>>
>>>>  rm(db);gc()   # garbage collection to free up the memory
>>>>
>>>>  # To successively obtain more chunks from the access database
>>>>  for (i in 2:10) {
>>>>    rm(df);gc()
>>>>    df<-sqlFetchMore(ch,"Table1",max=rowN,as.is=TRUE)
>>>>    file<-paste0('Table1',i,'.rds')
>>>>    df1<-saveRDS(df,file)
>>>>    if (dim(df)[1]<rowN)
>>>>      break
>>>>  }
>>>>  rm(df);gc()
>>>>  odbcCloseAll()
>>>>  ##############################
>>>>
>>>>  I would like to know the following :
>>>>  1. Is there any way to extract data from a table by just specifying the
>>>>  row
>>>>  number range. I have extracted data before. Instead of repeating the
>>>>  operations, I would just like to obtain data from, let's say, 8e6 to 9e6
>>>>  row range. I cannot do this now. I have to successively use the
>>>>  sqlfetchMore command. I would like to know if it is possible to straight
>>>>
>>>> away go to the 8e6 to 9e6 row range.
>>>>  2. Is it possible to use the foreach package in the extraction step (in
>>>>  place of the for loop above). I am planning to use the foreach command in
>>>>  parallel later for processing the data in the multiple files. I just
>>>>  wonder
>>>>  if it is possible to do parallel processing for the data extraction also.
>>>>  Thanks,
>>>>  Vivek Sutradhara
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ------------------------------
>>>>
>>>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>>>  PLEASE do read the posting guide
>>>>  http://www.R-project.org/posting-guide.html
>>>>  and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>>
>>>  --
>>>
>>>  Schrodinger's backup: The condition of any backup is unknown until
>>> a
>>>  restore is attempted.
>>>
>>>  Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.
>>>
>>>  He's about as useful as a wax frying pan.
>>>
>>>  10 to the 12th power microphones = 1 Megaphone
>>>
>>>  Maranatha! <><
>>>  John McKown
>>
>>
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Nov 21 18:59:51 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Nov 2015 09:59:51 -0800
Subject: [R] rank/sort problem
In-Reply-To: <3692923E-2797-4588-B5DC-4595D8D65BC8@gmail.com>
References: <3692923E-2797-4588-B5DC-4595D8D65BC8@gmail.com>
Message-ID: <80C75530-2A6C-4E44-9B67-E078A3FF7180@comcast.net>


> On Nov 21, 2015, at 4:44 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
> 
> Hello,
> 
> I would like to sort the df below, such that it sorts y1 in decreasing order for tt == 1 and in increasing order for 
> tt == 0. My solution is below, but curious if there might be something better (meaning faster in this case). 
> 
> Actually, if instead if implicitly sorting, I could add a variable ?rank? as in my ?hope? data frame below, that would work too (as I just need the ranking of observations, not necessarily the data explicitly sorted in the results).
> 
> ### Sample data
> y1 <- c(50,100,200,20,400,100,500,1000,12,25)
> tt <- factor(c(1,1,1,0,0,0,0,1,0,0))
> df <- data.frame(y1, tt)
> 
> ### My solution
> library(dplyr)
> sorted <- rbind(df[df$tt == 1, ] %>% arrange(desc(y1)),
>                df[df$tt == 0, ] %>% arrange(y1))
> 
> ### What I hope to get
> hope <- data.frame(df,
>                   rank = c(4, 3, 2, 6, 9, 8, 10, 1, 5, 7))
> hope[order(hope$rank),]

Couldn?t this just be accomplished with a bit of Boolean arithmetic:

  df[ with(df,order( c(1,-1)[ 1+(tt==1) ]*y1 ) ), ] 


This inverts the y1-ordering of (tt==1) cases. If you need that third column, then cbind the ?rank" vector with seq(nrow(df)) but I would avoid using the name ?rank" for obvious reasons. (And note that `df` is also an R function name.) 


> 
> 
> Thanks for any help.
> 
> Best Axel.
> 	[[alternative HTML version deleted]]

Please. This is a plain-text list.  

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Sat Nov 21 19:20:40 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 21 Nov 2015 18:20:40 +0000
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>

Use dput() to send data to the list as it is more compact:

> dput(tab)
structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L, 
4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time", 
"X1", "X2"), class = "data.frame", row.names = c(NA, -8L))

You can just remove the lines with X1 = 0 since you don't want to use them.

> tab.sub <- tab[tab$X1>0, ]

Then the following gives you a sample:

> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]

Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
Sent: Saturday, November 21, 2015 11:53 AM
To: R help <r-help at r-project.org>
Subject: [R] Conditional Random selection

Hi all,

I have a data set that contains samples collected over time.   In
each time period the total number of samples are given (X2)   The goal
is to  select 500  random samples.    The selection should be based on
time  (select time periods until I reach 500 samples). Also the time
period should have greater than 0 for  X1 variable. X1 is an indicator
variable.

Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0

tab  <- read.table(textConnection(" time   X1 X2
1      0        251
2      5        230
3      1        300
4      0         25
5      2         10
6      3         101
7      1         300
 8     4         185   "),header = TRUE)

In the above example,  samples from time 1 and 4  will not be selected
( X1 is zero)
So I could reach my target by selecting time 6,7, and 8 or  time 2 and
3 and so on.

Can any one help to do that?

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Nov 21 19:56:05 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 12:56:05 -0600
Subject: [R] Conditional Random selection
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
Message-ID: <CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>

Thank you  David!

I rerun the your script and it is giving me the first three time periods
is it doing random sampling?

      tab.fan
  time X1  X2
2    2  5 230
3    3  1 300
5    5  2  10



On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Use dput() to send data to the list as it is more compact:
>
>> dput(tab)
> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time",
> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>
> You can just remove the lines with X1 = 0 since you don't want to use them.
>
>> tab.sub <- tab[tab$X1>0, ]
>
> Then the following gives you a sample:
>
>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>
> Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
> Sent: Saturday, November 21, 2015 11:53 AM
> To: R help <r-help at r-project.org>
> Subject: [R] Conditional Random selection
>
> Hi all,
>
> I have a data set that contains samples collected over time.   In
> each time period the total number of samples are given (X2)   The goal
> is to  select 500  random samples.    The selection should be based on
> time  (select time periods until I reach 500 samples). Also the time
> period should have greater than 0 for  X1 variable. X1 is an indicator
> variable.
>
> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>
> tab  <- read.table(textConnection(" time   X1 X2
> 1      0        251
> 2      5        230
> 3      1        300
> 4      0         25
> 5      2         10
> 6      3         101
> 7      1         300
>  8     4         185   "),header = TRUE)
>
> In the above example,  samples from time 1 and 4  will not be selected
> ( X1 is zero)
> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
> 3 and so on.
>
> Can any one help to do that?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Nov 21 20:15:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 21 Nov 2015 11:15:59 -0800
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
Message-ID: <CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>

David's "solution" is incorrect. It can also fail to give you times
with a total of 500 items to sample from in the time periods.

It is not entirely clear what you want. The solution below gives you a
random sample of time periods in which X1>0 and the total number of
samples among them is >= 500. It does not give you the fewest number
of periods that can do this. Is this what you want?

tab[with(tab,{
  rownums<- sample(seq_len(nrow(tab))[X1>0])
  sz <- cumsum(X2[rownums])
  rownums[c(TRUE,sz<500)]
}),]

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
> Thank you  David!
>
> I rerun the your script and it is giving me the first three time periods
> is it doing random sampling?
>
>       tab.fan
>   time X1  X2
> 2    2  5 230
> 3    3  1 300
> 5    5  2  10
>
>
>
> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Use dput() to send data to the list as it is more compact:
>>
>>> dput(tab)
>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time",
>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>
>> You can just remove the lines with X1 = 0 since you don't want to use them.
>>
>>> tab.sub <- tab[tab$X1>0, ]
>>
>> Then the following gives you a sample:
>>
>>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>
>> Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.
>>
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>> Sent: Saturday, November 21, 2015 11:53 AM
>> To: R help <r-help at r-project.org>
>> Subject: [R] Conditional Random selection
>>
>> Hi all,
>>
>> I have a data set that contains samples collected over time.   In
>> each time period the total number of samples are given (X2)   The goal
>> is to  select 500  random samples.    The selection should be based on
>> time  (select time periods until I reach 500 samples). Also the time
>> period should have greater than 0 for  X1 variable. X1 is an indicator
>> variable.
>>
>> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>>
>> tab  <- read.table(textConnection(" time   X1 X2
>> 1      0        251
>> 2      5        230
>> 3      1        300
>> 4      0         25
>> 5      2         10
>> 6      3         101
>> 7      1         300
>>  8     4         185   "),header = TRUE)
>>
>> In the above example,  samples from time 1 and 4  will not be selected
>> ( X1 is zero)
>> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
>> 3 and so on.
>>
>> Can any one help to do that?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Nov 21 20:30:10 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 13:30:10 -0600
Subject: [R] Conditional Random selection
In-Reply-To: <CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
Message-ID: <CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>

 Thank you Bert!

What I want is at least 500 samples based on random  sampling of time
period. This allows samples  collected at the same time period are
included together.

Your script is doing what I wanted to do!!

Many thanks




On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> David's "solution" is incorrect. It can also fail to give you times
> with a total of 500 items to sample from in the time periods.
>
> It is not entirely clear what you want. The solution below gives you a
> random sample of time periods in which X1>0 and the total number of
> samples among them is >= 500. It does not give you the fewest number
> of periods that can do this. Is this what you want?
>
> tab[with(tab,{
>   rownums<- sample(seq_len(nrow(tab))[X1>0])
>   sz <- cumsum(X2[rownums])
>   rownums[c(TRUE,sz<500)]
> }),]
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>> Thank you  David!
>>
>> I rerun the your script and it is giving me the first three time periods
>> is it doing random sampling?
>>
>>       tab.fan
>>   time X1  X2
>> 2    2  5 230
>> 3    3  1 300
>> 5    5  2  10
>>
>>
>>
>> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>> Use dput() to send data to the list as it is more compact:
>>>
>>>> dput(tab)
>>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time",
>>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>>
>>> You can just remove the lines with X1 = 0 since you don't want to use them.
>>>
>>>> tab.sub <- tab[tab$X1>0, ]
>>>
>>> Then the following gives you a sample:
>>>
>>>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>>
>>> Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.
>>>
>>>
>>> David L. Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>>> Sent: Saturday, November 21, 2015 11:53 AM
>>> To: R help <r-help at r-project.org>
>>> Subject: [R] Conditional Random selection
>>>
>>> Hi all,
>>>
>>> I have a data set that contains samples collected over time.   In
>>> each time period the total number of samples are given (X2)   The goal
>>> is to  select 500  random samples.    The selection should be based on
>>> time  (select time periods until I reach 500 samples). Also the time
>>> period should have greater than 0 for  X1 variable. X1 is an indicator
>>> variable.
>>>
>>> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>>>
>>> tab  <- read.table(textConnection(" time   X1 X2
>>> 1      0        251
>>> 2      5        230
>>> 3      1        300
>>> 4      0         25
>>> 5      2         10
>>> 6      3         101
>>> 7      1         300
>>>  8     4         185   "),header = TRUE)
>>>
>>> In the above example,  samples from time 1 and 4  will not be selected
>>> ( X1 is zero)
>>> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
>>> 3 and so on.
>>>
>>> Can any one help to do that?
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From sewashm at gmail.com  Sat Nov 21 20:52:53 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 13:52:53 -0600
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
Message-ID: <CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>

Hi  Bert  and all,
I have related question.  In each  time period there were different
locations where the samples were collected (S1).   I  want count  the
number of unique locations (S1)  for each unique time period . So in
time 1 the samples were collected from two locations and time 2 only
from one location and time 3  from  three locations..

tab  <- read.table(textConnection(" time   S1  rep
1      1       1
1      2       1
1      2       2
2      1       1
2      1       2
2      1       3
2      1       4
3      1       1
3      2       1
3      3       1   "),header = TRUE)

what I want is

time  S1
    1    2
    2    1
    3    3

Thank you again.



On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>  Thank you Bert!
>
> What I want is at least 500 samples based on random  sampling of time
> period. This allows samples  collected at the same time period are
> included together.
>
> Your script is doing what I wanted to do!!
>
> Many thanks
>
>
>
>
> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> David's "solution" is incorrect. It can also fail to give you times
>> with a total of 500 items to sample from in the time periods.
>>
>> It is not entirely clear what you want. The solution below gives you a
>> random sample of time periods in which X1>0 and the total number of
>> samples among them is >= 500. It does not give you the fewest number
>> of periods that can do this. Is this what you want?
>>
>> tab[with(tab,{
>>   rownums<- sample(seq_len(nrow(tab))[X1>0])
>>   sz <- cumsum(X2[rownums])
>>   rownums[c(TRUE,sz<500)]
>> }),]
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>    -- Clifford Stoll
>>
>>
>> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>>> Thank you  David!
>>>
>>> I rerun the your script and it is giving me the first three time periods
>>> is it doing random sampling?
>>>
>>>       tab.fan
>>>   time X1  X2
>>> 2    2  5 230
>>> 3    3  1 300
>>> 5    5  2  10
>>>
>>>
>>>
>>> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>> Use dput() to send data to the list as it is more compact:
>>>>
>>>>> dput(tab)
>>>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>>>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time",
>>>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>>>
>>>> You can just remove the lines with X1 = 0 since you don't want to use them.
>>>>
>>>>> tab.sub <- tab[tab$X1>0, ]
>>>>
>>>> Then the following gives you a sample:
>>>>
>>>>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>>>
>>>> Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.
>>>>
>>>>
>>>> David L. Carlson
>>>> Department of Anthropology
>>>> Texas A&M University
>>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>>>> Sent: Saturday, November 21, 2015 11:53 AM
>>>> To: R help <r-help at r-project.org>
>>>> Subject: [R] Conditional Random selection
>>>>
>>>> Hi all,
>>>>
>>>> I have a data set that contains samples collected over time.   In
>>>> each time period the total number of samples are given (X2)   The goal
>>>> is to  select 500  random samples.    The selection should be based on
>>>> time  (select time periods until I reach 500 samples). Also the time
>>>> period should have greater than 0 for  X1 variable. X1 is an indicator
>>>> variable.
>>>>
>>>> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>>>>
>>>> tab  <- read.table(textConnection(" time   X1 X2
>>>> 1      0        251
>>>> 2      5        230
>>>> 3      1        300
>>>> 4      0         25
>>>> 5      2         10
>>>> 6      3         101
>>>> 7      1         300
>>>>  8     4         185   "),header = TRUE)
>>>>
>>>> In the above example,  samples from time 1 and 4  will not be selected
>>>> ( X1 is zero)
>>>> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
>>>> 3 and so on.
>>>>
>>>> Can any one help to do that?
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Nov 21 20:58:04 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 21 Nov 2015 11:58:04 -0800
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
	<CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
Message-ID: <CAGxFJbTj2Fj=i=fJ+-zrNywaRPb+vhUmOPDSV83nbpgo_O2PPg@mail.gmail.com>

Time to do your own homework by working through an R tutorial or two.
There are many on the web -- or see the Intro to R tutorial that ships
with R.

?tapply
?unique

is one of many answers to your query.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Nov 21, 2015 at 11:52 AM, Ashta <sewashm at gmail.com> wrote:
> Hi  Bert  and all,
> I have related question.  In each  time period there were different
> locations where the samples were collected (S1).   I  want count  the
> number of unique locations (S1)  for each unique time period . So in
> time 1 the samples were collected from two locations and time 2 only
> from one location and time 3  from  three locations..
>
> tab  <- read.table(textConnection(" time   S1  rep
> 1      1       1
> 1      2       1
> 1      2       2
> 2      1       1
> 2      1       2
> 2      1       3
> 2      1       4
> 3      1       1
> 3      2       1
> 3      3       1   "),header = TRUE)
>
> what I want is
>
> time  S1
>     1    2
>     2    1
>     3    3
>
> Thank you again.
>
>
>
> On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>>  Thank you Bert!
>>
>> What I want is at least 500 samples based on random  sampling of time
>> period. This allows samples  collected at the same time period are
>> included together.
>>
>> Your script is doing what I wanted to do!!
>>
>> Many thanks
>>
>>
>>
>>
>> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> David's "solution" is incorrect. It can also fail to give you times
>>> with a total of 500 items to sample from in the time periods.
>>>
>>> It is not entirely clear what you want. The solution below gives you a
>>> random sample of time periods in which X1>0 and the total number of
>>> samples among them is >= 500. It does not give you the fewest number
>>> of periods that can do this. Is this what you want?
>>>
>>> tab[with(tab,{
>>>   rownums<- sample(seq_len(nrow(tab))[X1>0])
>>>   sz <- cumsum(X2[rownums])
>>>   rownums[c(TRUE,sz<500)]
>>> }),]
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>>    -- Clifford Stoll
>>>
>>>
>>> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>>>> Thank you  David!
>>>>
>>>> I rerun the your script and it is giving me the first three time periods
>>>> is it doing random sampling?
>>>>
>>>>       tab.fan
>>>>   time X1  X2
>>>> 2    2  5 230
>>>> 3    3  1 300
>>>> 5    5  2  10
>>>>
>>>>
>>>>
>>>> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>>>> Use dput() to send data to the list as it is more compact:
>>>>>
>>>>>> dput(tab)
>>>>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>>>>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names = c("time",
>>>>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>>>>
>>>>> You can just remove the lines with X1 = 0 since you don't want to use them.
>>>>>
>>>>>> tab.sub <- tab[tab$X1>0, ]
>>>>>
>>>>> Then the following gives you a sample:
>>>>>
>>>>>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>>>>
>>>>> Note, that your "solution" of times 6, 7, and 8 will never appear because the sum of the values is 586.
>>>>>
>>>>>
>>>>> David L. Carlson
>>>>> Department of Anthropology
>>>>> Texas A&M University
>>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>>>>> Sent: Saturday, November 21, 2015 11:53 AM
>>>>> To: R help <r-help at r-project.org>
>>>>> Subject: [R] Conditional Random selection
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I have a data set that contains samples collected over time.   In
>>>>> each time period the total number of samples are given (X2)   The goal
>>>>> is to  select 500  random samples.    The selection should be based on
>>>>> time  (select time periods until I reach 500 samples). Also the time
>>>>> period should have greater than 0 for  X1 variable. X1 is an indicator
>>>>> variable.
>>>>>
>>>>> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>>>>>
>>>>> tab  <- read.table(textConnection(" time   X1 X2
>>>>> 1      0        251
>>>>> 2      5        230
>>>>> 3      1        300
>>>>> 4      0         25
>>>>> 5      2         10
>>>>> 6      3         101
>>>>> 7      1         300
>>>>>  8     4         185   "),header = TRUE)
>>>>>
>>>>> In the above example,  samples from time 1 and 4  will not be selected
>>>>> ( X1 is zero)
>>>>> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
>>>>> 3 and so on.
>>>>>
>>>>> Can any one help to do that?
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Nov 21 21:38:11 2015
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 21 Nov 2015 20:38:11 +0000
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
	<CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
Message-ID: <20151121203811.Horde.AjZlJqlOV2DiINElGjridQb@mail.sapo.pt>

Hello,

Try

tapply(tab$S1, tab$time, function(x) length(unique(x)))

Hope this helps,

Rui Barradas
?

Citando Ashta <sewashm at gmail.com>:

> Hi? Bert? and all,
> I have related question.? In each? time period there were different
> locations where the samples were collected (S1).? ?I? want count? the
> number of unique locations (S1)? for each unique time period . So in
> time 1 the samples were collected from two locations and time 2 only
> from one location and time 3? from? three locations..
>
> tab? <- read.table(textConnection(" time? ?S1? rep
> 1? ? ? 1? ? ? ?1
> 1? ? ? 2? ? ? ?1
> 1? ? ? 2? ? ? ?2
> 2? ? ? 1? ? ? ?1
> 2? ? ? 1? ? ? ?2
> 2? ? ? 1? ? ? ?3
> 2? ? ? 1? ? ? ?4
> 3? ? ? 1? ? ? ?1
> 3? ? ? 2? ? ? ?1
> 3? ? ? 3? ? ? ?1? ?"),header = TRUE)
>
> what I want is
>
> time? S1
> ? ?1? ? 2
> ? ?2? ? 1
> ? ?3? ? 3
>
> Thank you again.
>
> On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>> Thank you Bert!
>>
>> What I want is at least 500 samples based on random? sampling of time
>> period. This allows samples? collected at the same time period are
>> included together.
>>
>> Your script is doing what I wanted to do!!
>>
>> Many thanks
>>
>> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> David's "solution" is incorrect. It can also fail to give you times
>>> with a total of 500 items to sample from in the time periods.
>>>
>>> It is not entirely clear what you want. The solution below gives you a
>>> random sample of time periods in which X1>0 and the total number of
>>> samples among them is >= 500. It does not give you the fewest number
>>> of periods that can do this. Is this what you want?
>>>
>>> tab[with(tab,{
>>> ? rownums<- sample(seq_len(nrow(tab))[X1>0])
>>> ? sz <- cumsum(X2[rownums])
>>> ? rownums[c(TRUE,sz<500)]
>>> }),]
>>>
>>> Cheers,
>>> Bert
>>>
>>> Bert Gunter
>>>
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> ? ?-- Clifford Stoll
>>>
>>> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>>>> Thank you? David!
>>>>
>>>> I rerun the your script and it is giving me the first three time periods
>>>> is it doing random sampling?
>>>>
>>>> ? ? ? tab.fan
>>>> ? time X1? X2
>>>> 2? ? 2? 5 230
>>>> 3? ? 3? 1 300
>>>> 5? ? 5? 2? 10
>>>>
>>>> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson  
>>>> <dcarlson at tamu.edu> wrote:
>>>>> Use dput() to send data to the list as it is more compact:
>>>>>> dput(tab)
>>>>>
>>>>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>>>>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)),  
>>>>> .Names = c("time",
>>>>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>>>>
>>>>> You can just remove the lines with X1 = 0 since you don't want  
>>>>> to use them.
>>>>>> tab.sub <- tab[tab$X1>0, ]
>>>>>
>>>>> Then the following gives you a sample:
>>>>>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>>>>
>>>>> Note, that your "solution" of times 6, 7, and 8 will never  
>>>>> appear because the sum of the values is 586.
>>>>>
>>>>> David L. Carlson
>>>>> Department of Anthropology
>>>>> Texas A&M University
>>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>>>>> Sent: Saturday, November 21, 2015 11:53 AM
>>>>> To: R help <r-help at r-project.org>
>>>>> Subject: [R] Conditional Random selection
>>>>>
>>>>> Hi all,
>>>>>
>>>>> I have a data set that contains samples collected over time.? ?In
>>>>> each time period the total number of samples are given (X2)? ?The goal
>>>>> is to? select 500? random samples.? ? The selection should be based on
>>>>> time? (select time periods until I reach 500 samples). Also the time
>>>>> period should have greater than 0 for? X1 variable. X1 is an indicator
>>>>> variable.
>>>>>
>>>>> Select "time" until reaching the? sum of X2? is > 500 and if?  
>>>>> ?X1 is? >? 0
>>>>>
>>>>> tab? <- read.table(textConnection(" time? ?X1 X2
>>>>> 1? ? ? 0? ? ? ? 251
>>>>> 2? ? ? 5? ? ? ? 230
>>>>> 3? ? ? 1? ? ? ? 300
>>>>> 4? ? ? 0? ? ? ? ?25
>>>>> 5? ? ? 2? ? ? ? ?10
>>>>> 6? ? ? 3? ? ? ? ?101
>>>>> 7? ? ? 1? ? ? ? ?300
>>>>> 8? ? ?4? ? ? ? ?185? ?"),header = TRUE)
>>>>>
>>>>> In the above example,? samples from time 1 and 4? will not be selected
>>>>> ( X1 is zero)
>>>>> So I could reach my target by selecting time 6,7, and 8 or? time 2 and
>>>>> 3 and so on.
>>>>>
>>>>> Can any one help to do that?
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide  
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide  
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide  
> http://www.R-project.org/posting-guide.htmland provide commented,  
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sat Nov 21 21:48:34 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 14:48:34 -0600
Subject: [R] Conditional Random selection
In-Reply-To: <20151121203811.Horde.AjZlJqlOV2DiINElGjridQb@mail.sapo.pt>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
	<CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
	<20151121203811.Horde.AjZlJqlOV2DiINElGjridQb@mail.sapo.pt>
Message-ID: <CADDFq31-fHz5+mwvuq55ax2VOpex6B_GoqEay+pk+xeA4K=frg@mail.gmail.com>

Hi  Rui ,

I tried that one  before I send out my original message.
it gave me only this,

tapply(tab$S1, tab$time, function(x) length(unique(x)))
1 2 3
2 1 3

I am expecting an output of like this

 time  S1
    1    2
    2    1
    3    3






On Sat, Nov 21, 2015 at 2:38 PM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Try
>
> tapply(tab$S1, tab$time, function(x) length(unique(x)))
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Ashta <sewashm at gmail.com>:
>
> Hi  Bert  and all,
> I have related question.  In each  time period there were different
> locations where the samples were collected (S1).   I  want count  the
> number of unique locations (S1)  for each unique time period . So in
> time 1 the samples were collected from two locations and time 2 only
> from one location and time 3  from  three locations..
>
> tab  <- read.table(textConnection(" time   S1  rep
> 1      1       1
> 1      2       1
> 1      2       2
> 2      1       1
> 2      1       2
> 2      1       3
> 2      1       4
> 3      1       1
> 3      2       1
> 3      3       1   "),header = TRUE)
>
> what I want is
>
> time  S1
>    1    2
>    2    1
>    3    3
>
> Thank you again.
>
>
>
> On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>
> Thank you Bert!
>
> What I want is at least 500 samples based on random  sampling of time
> period. This allows samples  collected at the same time period are
> included together.
>
> Your script is doing what I wanted to do!!
>
> Many thanks
>
>
>
>
> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> David's "solution" is incorrect. It can also fail to give you times
> with a total of 500 items to sample from in the time periods.
>
> It is not entirely clear what you want. The solution below gives you a
> random sample of time periods in which X1>0 and the total number of
> samples among them is >= 500. It does not give you the fewest number
> of periods that can do this. Is this what you want?
>
> tab[with(tab,{
>   rownums<- sample(seq_len(nrow(tab))[X1>0])
>   sz <- cumsum(X2[rownums])
>   rownums[c(TRUE,sz<500)]
> }),]
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>
> Thank you  David!
>
> I rerun the your script and it is giving me the first three time periods
> is it doing random sampling?
>
>       tab.fan
>   time X1  X2
> 2    2  5 230
> 3    3  1 300
> 5    5  2  10
>
>
>
> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
> Use dput() to send data to the list as it is more compact:
>
> dput(tab)
>
> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names =
> c("time",
> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>
> You can just remove the lines with X1 = 0 since you don't want to use them.
>
> tab.sub <- tab[tab$X1>0, ]
>
> Then the following gives you a sample:
>
> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>
> Note, that your "solution" of times 6, 7, and 8 will never appear because
> the sum of the values is 586.
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
> Sent: Saturday, November 21, 2015 11:53 AM
> To: R help <r-help at r-project.org>
> Subject: [R] Conditional Random selection
>
> Hi all,
>
> I have a data set that contains samples collected over time.   In
> each time period the total number of samples are given (X2)   The goal
> is to  select 500  random samples.    The selection should be based on
> time  (select time periods until I reach 500 samples). Also the time
> period should have greater than 0 for  X1 variable. X1 is an indicator
> variable.
>
> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>
> tab  <- read.table(textConnection(" time   X1 X2
> 1      0        251
> 2      5        230
> 3      1        300
> 4      0         25
> 5      2         10
> 6      3         101
> 7      1         300
> 8     4         185   "),header = TRUE)
>
> In the above example,  samples from time 1 and 4  will not be selected
> ( X1 is zero)
> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
> 3 and so on.
>
> Can any one help to do that?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.htmland provide commented, minimal,
> self-contained, reproducible code.
>
>
>


From ruipbarradas at sapo.pt  Sat Nov 21 22:40:55 2015
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sat, 21 Nov 2015 21:40:55 +0000
Subject: [R] Conditional Random selection
In-Reply-To: <CADDFq31-fHz5+mwvuq55ax2VOpex6B_GoqEay+pk+xeA4K=frg@mail.gmail.com>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
	<CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
	<20151121203811.Horde.AjZlJqlOV2DiINElGjridQb@mail.sapo.pt>
	<CADDFq31-fHz5+mwvuq55ax2VOpex6B_GoqEay+pk+xeA4K=frg@mail.gmail.com>
Message-ID: <20151121214055.Horde.fM3dILYFLYqKY_qbFBTnZd3@mail.sapo.pt>

Hello,

Is that a real doubt? Like Bert said, you should spend some time with  
an R tutorial. All you need is to know how to form a data.frame.

tmp <- tapply(tab1$S1, tab1$time, function(x) length(unique(x)))
data.frame(time = names(tmp), S1 = tmp)

Rui Barradas
?

Citando Ashta <sewashm at gmail.com>:

> Hi? Rui ,
>
> I tried that one? before I send out my original message.
> it gave me only this,
>
> tapply(tab$S1, tab$time, function(x) length(unique(x)))
> 1 2 3
> 2 1 3
>
> I am expecting an output of like this
>
> time? S1
> ? ?1? ? 2
> ? ?2? ? 1
> ? ?3? ? 3
>
> On Sat, Nov 21, 2015 at 2:38 PM,? <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Try
>>
>> tapply(tab$S1, tab$time, function(x) length(unique(x)))
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Citando Ashta <sewashm at gmail.com>:
>>
>> Hi? Bert? and all,
>> I have related question.? In each? time period there were different
>> locations where the samples were collected (S1).? ?I? want count? the
>> number of unique locations (S1)? for each unique time period . So in
>> time 1 the samples were collected from two locations and time 2 only
>> from one location and time 3? from? three locations..
>>
>> tab? <- read.table(textConnection(" time? ?S1? rep
>> 1? ? ? 1? ? ? ?1
>> 1? ? ? 2? ? ? ?1
>> 1? ? ? 2? ? ? ?2
>> 2? ? ? 1? ? ? ?1
>> 2? ? ? 1? ? ? ?2
>> 2? ? ? 1? ? ? ?3
>> 2? ? ? 1? ? ? ?4
>> 3? ? ? 1? ? ? ?1
>> 3? ? ? 2? ? ? ?1
>> 3? ? ? 3? ? ? ?1? ?"),header = TRUE)
>>
>> what I want is
>>
>> time? S1
>> ? ?1? ? 2
>> ? ?2? ? 1
>> ? ?3? ? 3
>>
>> Thank you again.
>>
>> On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>>
>> Thank you Bert!
>>
>> What I want is at least 500 samples based on random? sampling of time
>> period. This allows samples? collected at the same time period are
>> included together.
>>
>> Your script is doing what I wanted to do!!
>>
>> Many thanks
>>
>> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> David's "solution" is incorrect. It can also fail to give you times
>> with a total of 500 items to sample from in the time periods.
>>
>> It is not entirely clear what you want. The solution below gives you a
>> random sample of time periods in which X1>0 and the total number of
>> samples among them is >= 500. It does not give you the fewest number
>> of periods that can do this. Is this what you want?
>>
>> tab[with(tab,{
>> ? rownums<- sample(seq_len(nrow(tab))[X1>0])
>> ? sz <- cumsum(X2[rownums])
>> ? rownums[c(TRUE,sz<500)]
>> }),]
>>
>> Cheers,
>> Bert
>>
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> ? ?-- Clifford Stoll
>>
>> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>>
>> Thank you? David!
>>
>> I rerun the your script and it is giving me the first three time periods
>> is it doing random sampling?
>>
>> ? ? ? tab.fan
>> ? time X1? X2
>> 2? ? 2? 5 230
>> 3? ? 3? 1 300
>> 5? ? 5? 2? 10
>>
>> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> Use dput() to send data to the list as it is more compact:
>>
>> dput(tab)
>>
>> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
>> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names =
>> c("time",
>> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>>
>> You can just remove the lines with X1 = 0 since you don't want to use them.
>>
>> tab.sub <- tab[tab$X1>0, ]
>>
>> Then the following gives you a sample:
>>
>> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>>
>> Note, that your "solution" of times 6, 7, and 8 will never appear because
>> the sum of the values is 586.
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
>> Sent: Saturday, November 21, 2015 11:53 AM
>> To: R help <r-help at r-project.org>
>> Subject: [R] Conditional Random selection
>>
>> Hi all,
>>
>> I have a data set that contains samples collected over time.? ?In
>> each time period the total number of samples are given (X2)? ?The goal
>> is to? select 500? random samples.? ? The selection should be based on
>> time? (select time periods until I reach 500 samples). Also the time
>> period should have greater than 0 for? X1 variable. X1 is an indicator
>> variable.
>>
>> Select "time" until reaching the? sum of X2? is > 500 and if? ?X1 is? >? 0
>>
>> tab? <- read.table(textConnection(" time? ?X1 X2
>> 1? ? ? 0? ? ? ? 251
>> 2? ? ? 5? ? ? ? 230
>> 3? ? ? 1? ? ? ? 300
>> 4? ? ? 0? ? ? ? ?25
>> 5? ? ? 2? ? ? ? ?10
>> 6? ? ? 3? ? ? ? ?101
>> 7? ? ? 1? ? ? ? ?300
>> 8? ? ?4? ? ? ? ?185? ?"),header = TRUE)
>>
>> In the above example,? samples from time 1 and 4? will not be selected
>> ( X1 is zero)
>> So I could reach my target by selecting time 6,7, and 8 or? time 2 and
>> 3 and so on.
>>
>> Can any one help to do that?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.htmland provide commented, minimal,
>> self-contained, reproducible code.
>> ?
>
> ?

	[[alternative HTML version deleted]]


From sewashm at gmail.com  Sat Nov 21 23:59:02 2015
From: sewashm at gmail.com (Ashta)
Date: Sat, 21 Nov 2015 16:59:02 -0600
Subject: [R] Conditional Random selection
In-Reply-To: <20151121214055.Horde.fM3dILYFLYqKY_qbFBTnZd3@mail.sapo.pt>
References: <CADDFq309ATrOw9uJPAkjDYFCkLXWpa_xYD42kP9LDUXUkmqQGQ@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6E1D54@mb02.ads.tamu.edu>
	<CADDFq30QSAn=PuYU2u-GE_QhsncErGcwxBCP8DHY=cAE-DvtYQ@mail.gmail.com>
	<CAGxFJbQyqb_MGpAHFEEgBeCKgTNeAicQMc757Xsog9-S5n+XAw@mail.gmail.com>
	<CADDFq33F97qLZ05mM_Ba45kzB1YUJKXNuXXt91YyhYcHBJYmRQ@mail.gmail.com>
	<CADDFq32B=xtHRe_AK_nZcCbqrFhbUdU-01-MfcQWA9irX-vUxA@mail.gmail.com>
	<20151121203811.Horde.AjZlJqlOV2DiINElGjridQb@mail.sapo.pt>
	<CADDFq31-fHz5+mwvuq55ax2VOpex6B_GoqEay+pk+xeA4K=frg@mail.gmail.com>
	<20151121214055.Horde.fM3dILYFLYqKY_qbFBTnZd3@mail.sapo.pt>
Message-ID: <CADDFq30YvNc2SGcxGaCRfADC3NZ3sNz0P5kgkp5L90HXwOdtLQ@mail.gmail.com>

Thank you !

 I was also able to do it this way, too!

hc <- ddply(tab1, .(time), summarize, S1 = length(unique(S1)))


On Sat, Nov 21, 2015 at 3:40 PM,  <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Is that a real doubt? Like Bert said, you should spend some time with an R
> tutorial. All you need is to know how to form a data.frame.
>
>
> tmp <- tapply(tab1$S1, tab1$time, function(x) length(unique(x)))
> data.frame(time = names(tmp), S1 = tmp)
>
> Rui Barradas
>
>
> Citando Ashta <sewashm at gmail.com>:
>
> Hi  Rui ,
>
>
>
> I tried that one  before I send out my original message.
> it gave me only this,
>
> tapply(tab$S1, tab$time, function(x) length(unique(x)))
> 1 2 3
> 2 1 3
>
> I am expecting an output of like this
>
> time  S1
>    1    2
>    2    1
>    3    3
>
>
>
>
>
>
> On Sat, Nov 21, 2015 at 2:38 PM,  <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Try
>
> tapply(tab$S1, tab$time, function(x) length(unique(x)))
>
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Ashta <sewashm at gmail.com>:
>
> Hi  Bert  and all,
> I have related question.  In each  time period there were different
> locations where the samples were collected (S1).   I  want count  the
> number of unique locations (S1)  for each unique time period . So in
> time 1 the samples were collected from two locations and time 2 only
> from one location and time 3  from  three locations..
>
> tab  <- read.table(textConnection(" time   S1  rep
> 1      1       1
> 1      2       1
> 1      2       2
> 2      1       1
> 2      1       2
> 2      1       3
> 2      1       4
> 3      1       1
> 3      2       1
> 3      3       1   "),header = TRUE)
>
> what I want is
>
> time  S1
>    1    2
>    2    1
>    3    3
>
> Thank you again.
>
>
>
> On Sat, Nov 21, 2015 at 1:30 PM, Ashta <sewashm at gmail.com> wrote:
>
> Thank you Bert!
>
> What I want is at least 500 samples based on random  sampling of time
> period. This allows samples  collected at the same time period are
> included together.
>
> Your script is doing what I wanted to do!!
>
> Many thanks
>
>
>
>
> On Sat, Nov 21, 2015 at 1:15 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> David's "solution" is incorrect. It can also fail to give you times
> with a total of 500 items to sample from in the time periods.
>
> It is not entirely clear what you want. The solution below gives you a
> random sample of time periods in which X1>0 and the total number of
> samples among them is >= 500. It does not give you the fewest number
> of periods that can do this. Is this what you want?
>
> tab[with(tab,{
>   rownums<- sample(seq_len(nrow(tab))[X1>0])
>   sz <- cumsum(X2[rownums])
>   rownums[c(TRUE,sz<500)]
> }),]
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>    -- Clifford Stoll
>
>
> On Sat, Nov 21, 2015 at 10:56 AM, Ashta <sewashm at gmail.com> wrote:
>
> Thank you  David!
>
> I rerun the your script and it is giving me the first three time periods
> is it doing random sampling?
>
>       tab.fan
>   time X1  X2
> 2    2  5 230
> 3    3  1 300
> 5    5  2  10
>
>
>
> On Sat, Nov 21, 2015 at 12:20 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>
> Use dput() to send data to the list as it is more compact:
>
> dput(tab)
>
> structure(list(time = 1:8, X1 = c(0L, 5L, 1L, 0L, 2L, 3L, 1L,
> 4L), X2 = c(251L, 230L, 300L, 25L, 10L, 101L, 300L, 185L)), .Names =
> c("time",
> "X1", "X2"), class = "data.frame", row.names = c(NA, -8L))
>
> You can just remove the lines with X1 = 0 since you don't want to use them.
>
> tab.sub <- tab[tab$X1>0, ]
>
> Then the following gives you a sample:
>
> tab.sub[cumsum(sample(tab.sub$X2))<=500, ]
>
> Note, that your "solution" of times 6, 7, and 8 will never appear because
> the sum of the values is 586.
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashta
> Sent: Saturday, November 21, 2015 11:53 AM
> To: R help <r-help at r-project.org>
> Subject: [R] Conditional Random selection
>
> Hi all,
>
> I have a data set that contains samples collected over time.   In
> each time period the total number of samples are given (X2)   The goal
> is to  select 500  random samples.    The selection should be based on
> time  (select time periods until I reach 500 samples). Also the time
> period should have greater than 0 for  X1 variable. X1 is an indicator
> variable.
>
> Select "time" until reaching the  sum of X2  is > 500 and if   X1 is  >  0
>
> tab  <- read.table(textConnection(" time   X1 X2
> 1      0        251
> 2      5        230
> 3      1        300
> 4      0         25
> 5      2         10
> 6      3         101
> 7      1         300
> 8     4         185   "),header = TRUE)
>
> In the above example,  samples from time 1 and 4  will not be selected
> ( X1 is zero)
> So I could reach my target by selecting time 6,7, and 8 or  time 2 and
> 3 and so on.
>
> Can any one help to do that?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.htmland provide commented, minimal,
> self-contained, reproducible code.
>
>
>
>


From john.archie.mckown at gmail.com  Sun Nov 22 02:38:06 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 21 Nov 2015 19:38:06 -0600
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <CAHLp6SBAStHOzoBZcm=9KBx5y7Gq6hf9k5FPzXds6DG0H8XRpQ@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
	<CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
	<39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>
	<CAHLp6SBAStHOzoBZcm=9KBx5y7Gq6hf9k5FPzXds6DG0H8XRpQ@mail.gmail.com>
Message-ID: <CAAJSdjit6VTWyr5VPnSg_Ey69Dt6RO6prb9yxjbrVo7+PatwTw@mail.gmail.com>

On Sat, Nov 21, 2015 at 11:55 AM, Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi John and Jeff,
> Thanks a lot for your help. I agree that row numbers are not a standard
> feature in SQL. What I am looking for is some kind of a hack. After all,
> the sqlFetch command is able to return a specific number of rows. And the
> sqlFetchMore command is able to take up the baton from that row onwards to
> futher return rows corresponding to the max parameter.
>
> I wonder if it is possible to straight away hop to a certain row number
> (without going through sqlfetch and sqlFetchMore and without loading any
> data into memory) and then return the contents corresponding to a certain
> number of rows. The question is : is there a "catch" for accessing a row
> location, and what could be the "hook" for that? I am interested in the the
> recent updated rows to a table after a certain date. Is it possible to
> identify them in a quick way? Running sql queries on such large tables
> appears to take too long a time.
>
>  I understand that there is no provision to do this by available methods.
> But, is it possible to get under the hood and find some hack?
>

?Now you're talking about the internals of Microsoft Access. And you're
_way_ beyond my knowledge. Is there such knowledge? I sure there is. But,
unfortunately, once you get into that depth, you can get into real trouble
when (not if) MS decides to change the internals out from under you without
any warning at all. If you are really needing this, try looking the the
"MDB Tools" software at either https://github.com/brianb/mdbtools or
http://mdbtools.sourceforge.net/? I don't think this does exactly what you
want, but it may give you the information you need to read the MDB file
yourself directly in R code. <shudder/>

?What you would really want is something like the ROWID in SQLite. That is
a "system" maintained column in every table in SQLite. It is a 64-bit
unique number. Basically, it starts at 1 and increments every time you add
a new row.

What would be "best", IMO, would be if you could alter your Access database
to have a "serial" column which would be your "row number" You could then
get "directly" there by using a SELECT similar to:

SELECT * FROM table WHERE serial BETWEEN (first-row,last-row)



>
> Jeff, I will take your suggestion and try my luck at the R-sig-db mailing
> list.
> Thanks,
> Vivek
>
>
>
-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From tobias at byland.info  Sun Nov 22 00:33:16 2015
From: tobias at byland.info (Tobias Byland)
Date: Sun, 22 Nov 2015 00:33:16 +0100
Subject: [R] summarize_ (NSE) in combination with quantile not working
Message-ID: <5650FF3C.70902@byland.info>

Hi everyone,

I am stumbling over the following issue when using the NSE (non-standard 
evaluation) of the summarise function in dpylr (as described here: 
https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html):

mtcars  %>% summarise(min(mpg))      # summarize and min
mtcars  %>% summarise_("min(mpg)")   # summarize_ and min
mtcars  %>% summarise(quantile(mpg, 0.1))   # summarize and quantile
mtcars  %>% summarise_("quantile(mpg, 0.1)")   # summarize_ and 
quantile  -> ERROR

The last (and only the last) call results in the following error:

Error: could not find function "quantile"


It seems to me, that the combination of summarise_ and quantile() 
somehow doesn't work.

Does anyone have an idea what the issue here is?

Thanks a lot!

Regards
Tobi

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Nov 22 03:15:14 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 21 Nov 2015 18:15:14 -0800
Subject: [R] summarize_ (NSE) in combination with quantile not working
In-Reply-To: <5650FF3C.70902@byland.info>
References: <5650FF3C.70902@byland.info>
Message-ID: <8B21B306-853C-4039-85EB-23E936128616@dcn.davis.ca.us>

Please post using plain text. The following works. 

mutate %>% summarise_( ~quantile( mpg, 0.1 ) )

Read the vignette on nse that comes with dplyr,  or Google the error message. 

On November 21, 2015 3:33:16 PM PST, Tobias Byland <tobias at byland.info> wrote:
>Hi everyone,
>
>I am stumbling over the following issue when using the NSE
>(non-standard 
>evaluation) of the summarise function in dpylr (as described here: 
>https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html):
>
>mtcars  %>% summarise(min(mpg))      # summarize and min
>mtcars  %>% summarise_("min(mpg)")   # summarize_ and min
>mtcars  %>% summarise(quantile(mpg, 0.1))   # summarize and quantile
>mtcars  %>% summarise_("quantile(mpg, 0.1)")   # summarize_ and 
>quantile  -> ERROR
>
>The last (and only the last) call results in the following error:
>
>Error: could not find function "quantile"
>
>
>It seems to me, that the combination of summarise_ and quantile() 
>somehow doesn't work.
>
>Does anyone have an idea what the issue here is?
>
>Thanks a lot!
>
>Regards
>Tobi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Nov 22 04:08:23 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 21 Nov 2015 19:08:23 -0800
Subject: [R] summarize_ (NSE) in combination with quantile not working
In-Reply-To: <5650FF3C.70902@byland.info>
References: <5650FF3C.70902@byland.info>
Message-ID: <59E447AE-E00B-4616-8166-F488DED691CB@comcast.net>


> On Nov 21, 2015, at 3:33 PM, Tobias Byland <tobias at byland.info> wrote:
> 
> Hi everyone,
> 
> I am stumbling over the following issue when using the NSE (non-standard 
> evaluation) of the summarise function in dpylr (as described here: 
> https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html):
> 
> mtcars  %>% summarise(min(mpg))      # summarize and min
> mtcars  %>% summarise_("min(mpg)")   # summarize_ and min
> mtcars  %>% summarise(quantile(mpg, 0.1))   # summarize and quantile
> mtcars  %>% summarise_("quantile(mpg, 0.1)")   # summarize_ and 
> quantile  -> ERROR
> 
> The last (and only the last) call results in the following error:
> 
> Error: could not find function ?quantile"

You should have noticed that the error had double-quotes around the function name. That?s very un-Rlich. You should have been satisfied with the third variation.


> 
> 
> It seems to me, that the combination of summarise_ and quantile() 
> somehow doesn't work.
> 
If thine code offends thee, pluck it out.

? 
David.

> Does anyone have an idea what the issue here is?
> 
> Thanks a lot!
> 
> Regards
> Tobi
> 
> 	[[alternative HTML version deleted]]

And while you are at it can you pluck out the HTML???????

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rhurlin at gwdg.de  Sun Nov 22 07:43:01 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 22 Nov 2015 07:43:01 +0100
Subject: [R] exporting tables from an access database using parallel
 foreach
In-Reply-To: <CAAJSdjit6VTWyr5VPnSg_Ey69Dt6RO6prb9yxjbrVo7+PatwTw@mail.gmail.com>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
	<CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
	<39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>
	<CAHLp6SBAStHOzoBZcm=9KBx5y7Gq6hf9k5FPzXds6DG0H8XRpQ@mail.gmail.com>
	<CAAJSdjit6VTWyr5VPnSg_Ey69Dt6RO6prb9yxjbrVo7+PatwTw@mail.gmail.com>
Message-ID: <565163F5.5000401@gwdg.de>

Am 22.11.15 um 02:38 schrieb John McKown:
> On Sat, Nov 21, 2015 at 11:55 AM, Vivek Sutradhara <viveksutra at gmail.com>
> wrote:
> 
>> Hi John and Jeff,
>> Thanks a lot for your help. I agree that row numbers are not a standard
>> feature in SQL. What I am looking for is some kind of a hack. After all,
>> the sqlFetch command is able to return a specific number of rows. And the
>> sqlFetchMore command is able to take up the baton from that row onwards to
>> futher return rows corresponding to the max parameter.
>>
>> I wonder if it is possible to straight away hop to a certain row number
>> (without going through sqlfetch and sqlFetchMore and without loading any
>> data into memory) and then return the contents corresponding to a certain
>> number of rows. The question is : is there a "catch" for accessing a row
>> location, and what could be the "hook" for that? I am interested in the the
>> recent updated rows to a table after a certain date. Is it possible to
>> identify them in a quick way? Running sql queries on such large tables
>> appears to take too long a time.
>>
>>  I understand that there is no provision to do this by available methods.
>> But, is it possible to get under the hood and find some hack?
>>
> 
> ?Now you're talking about the internals of Microsoft Access. And you're
> _way_ beyond my knowledge. Is there such knowledge? I sure there is. But,
> unfortunately, once you get into that depth, you can get into real trouble
> when (not if) MS decides to change the internals out from under you without
> any warning at all. If you are really needing this, try looking the the
> "MDB Tools" software at either https://github.com/brianb/mdbtools or
> http://mdbtools.sourceforge.net/? I don't think this does exactly what you
> want, but it may give you the information you need to read the MDB file
> yourself directly in R code. <shudder/>

The mdb-tools give direct access to the physical mdb files, lying around
in a filesystem. A database file xxx.mdb has not to be 'active' within a
MS Access 'Server', to read in its contents via mdb-tools. The idea
behind is, that one should be able to read the contents of mdb files,
even when there is no MS Access you can connect to and/or when no
Windows installation is running.

In my knowledge, mdb-tools is not available for Windows platforms, only
for Unix alikes and Linux, maybe OSX.

The R package 'Hmisc' is able to use mdb-tools, if they are also present
on that system.

Unfortunately, it seems, that mdb-tools also has no direct way to select
rows by their number.

> 
> ?What you would really want is something like the ROWID in SQLite. That is
> a "system" maintained column in every table in SQLite. It is a 64-bit
> unique number. Basically, it starts at 1 and increments every time you add
> a new row.
> 
> What would be "best", IMO, would be if you could alter your Access database
> to have a "serial" column which would be your "row number" You could then
> get "directly" there by using a SELECT similar to:
> 
> SELECT * FROM table WHERE serial BETWEEN (first-row,last-row)
> 
> 
> 
>>
>> Jeff, I will take your suggestion and try my luck at the R-sig-db mailing
>> list.
>> Thanks,
>> Vivek
>>
>>
>>


From fw42746 at gmail.com  Sun Nov 22 08:04:08 2015
From: fw42746 at gmail.com (Frank Wang)
Date: Sat, 21 Nov 2015 23:04:08 -0800
Subject: [R] How to split 32 bits data into 16 bit or 8 bit data
Message-ID: <CA+0UNc9CDCxcLyyPXeW7xQnA5RhXe5ve=v=4qr_oAWdi5_ZHmw@mail.gmail.com>

Hi,

I am new user on R. I want to split a vector of hex data such as "00ff8020"
"02d00000" "001e0240" "00010096" "00010033"
into 16 bits such as:
"00ff", "8020", "02d0","0000","001e", "0240", "0001","0096", "0001", "0033"

Are there any way to do it?

Thanks

Frank

	[[alternative HTML version deleted]]


From kestrel1978 at gmail.com  Sun Nov 22 11:52:21 2015
From: kestrel1978 at gmail.com (Ronny Steen)
Date: Sun, 22 Nov 2015 11:52:21 +0100
Subject: [R] Converting time zones in R using metadata file information of
 video files, help needed.
Message-ID: <CABVupNZ307VZaiQsfZOXO8O28nNiPLO+7B-KO5GYH97gHpnonQ@mail.gmail.com>

Hi,

I have video files (FAT) that are taken in a different timezone than my
current location. The modification date/time in the metafila data of the
video file shows the time video was taken, although in the current timezone
of my computer, if I understand right.

I wish to convert the date/time to the origin. The video was taken in
London, Ontario Canada at 2015-06-21 07:53:28, when looking at the metadata
of the file on my computer (timezone "Europe/Berlin") it says modification
date "2015-06-22 01:53:28". Hence, there is a 6 hour difference between the
two time-zones

I use the script provided here:
http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html

pb.txt <- "2015-06-22 01:53:28" #modification date as shown on my
computer (timezone
"Europe/Berlin")

pb.date <- as.POSIXct(pb.txt, tz="Europe/London")

pb.date <- as.POSIXct(pb.txt, tz="America/Toronto")#timezone of origin
video camera location

format(pb.date, tz=local.time,usetz=TRUE) #formats the mtime to data and
time when the video was taken

[1] "2015-06-22 07:53:28 CEST" # the time is correct but the date is wrong
as it has added 6 hours rather than subtracting.

I find working with different time-zones to be difficult, I hope I managed
to formulate an understandable question.

Regards,

Kes

	[[alternative HTML version deleted]]


From tamsilap at yahoo.com  Sun Nov 22 16:08:37 2015
From: tamsilap at yahoo.com (Tamsila Parveen)
Date: Sun, 22 Nov 2015 15:08:37 +0000 (UTC)
Subject: [R] not allocate of vactor size
References: <1162706458.9270408.1448204917900.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>

Hello,?? ? ? ? ? Is there anyone to help me out how can I resolve memory issue of R, when I want to analyze data of 1Gb file, R returns me?Error: not allocate of vector size of 1.8 GB.I tried on linux as well as on windows with 64 bit system and using 64 bit R-3.2.2 version. So anyone who knows please guide me to resolve this issue
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Nov 22 17:30:46 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 22 Nov 2015 08:30:46 -0800
Subject: [R] not allocate of vactor size
In-Reply-To: <1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
References: <1162706458.9270408.1448204917900.JavaMail.yahoo.ref@mail.yahoo.com>
	<1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <655DD0CA-41FF-459B-AE94-EB71FB5428EF@dcn.davis.ca.us>

http://bfy.tw/2uv2

Please read and follow the guidance in the Posting Guide mentioned at the bottom of this message.  In particular,  be specific about the type of hardware and software environment you have and what R code you are having trouble with. 

On November 22, 2015 7:08:37 AM PST, Tamsila Parveen via R-help <r-help at r-project.org> wrote:
>Hello,?? ? ? ? ? Is there anyone to help me out how can I resolve
>memory issue of R, when I want to analyze data of 1Gb file, R returns
>me?Error: not allocate of vector size of 1.8 GB.I tried on linux as
>well as on windows with 64 bit system and using 64 bit R-3.2.2 version.
>So anyone who knows please guide me to resolve this issue
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Nov 22 17:38:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 22 Nov 2015 11:38:45 -0500
Subject: [R] How to split 32 bits data into 16 bit or 8 bit data
In-Reply-To: <CA+0UNc9CDCxcLyyPXeW7xQnA5RhXe5ve=v=4qr_oAWdi5_ZHmw@mail.gmail.com>
References: <CA+0UNc9CDCxcLyyPXeW7xQnA5RhXe5ve=v=4qr_oAWdi5_ZHmw@mail.gmail.com>
Message-ID: <5651EF95.2020909@gmail.com>

On 22/11/2015 2:04 AM, Frank Wang wrote:
> Hi,
>
> I am new user on R. I want to split a vector of hex data such as "00ff8020"
> "02d00000" "001e0240" "00010096" "00010033"
> into 16 bits such as:
> "00ff", "8020", "02d0","0000","001e", "0240", "0001","0096", "0001", "0033"
>
> Are there any way to do it?

If those are really strings, use substr().

If they are 32 bit integers, you could use x %% (2^16) for the low 16 
bits.  For the high 16 bits, you'll have to be careful about the sign. 
Or you could use the bitops package, bitShiftR(x, 16).  In either case 
the results will display by default in decimal; if you want a hex 
display, use as.hexmode().

Duncan Murdoch


From viveksutra at gmail.com  Sun Nov 22 19:55:01 2015
From: viveksutra at gmail.com (Vivek Sutradhara)
Date: Sun, 22 Nov 2015 19:55:01 +0100
Subject: [R] exporting tables from an access database using parallel
	foreach
In-Reply-To: <565163F5.5000401@gwdg.de>
References: <CAHLp6SADQd2VZ2rXj2Z-HML4taqOLdtkHZHye8N5qYTL-kv60w@mail.gmail.com>
	<CAAJSdjgEF2sXYd7sYcq7Bhuui1LzMGptChaRrpKjhZereYP8Ww@mail.gmail.com>
	<CAHLp6SCWfvVDZ2-kDa0AOBzKfougncH5sfY9hC44aNO0AcMzmQ@mail.gmail.com>
	<39763167-1395-407F-AE44-1444224DB873@dcn.davis.ca.us>
	<CAHLp6SBAStHOzoBZcm=9KBx5y7Gq6hf9k5FPzXds6DG0H8XRpQ@mail.gmail.com>
	<CAAJSdjit6VTWyr5VPnSg_Ey69Dt6RO6prb9yxjbrVo7+PatwTw@mail.gmail.com>
	<565163F5.5000401@gwdg.de>
Message-ID: <CAHLp6SDmMdsSf4=szZrG_cdGjTCs3gLVzyWi84+iUsNvoi1q7A@mail.gmail.com>

Hi Rainer and John,
Thanks once again for your continued help. I have actually tried out
mdbtools. I was able to get going on ubuntu. Unfortunately, to my
disappointment, it was not helpful in my specific case. Because the access
database is on a server which can be accessed only on windows and not from
ubuntu (for administrative reasons beyond my control).

When I copied the mdb file over to ubuntu, I saw only synonyms and no
tables (because I had no contact with the server).

Thanks for the suggestion of serial number. I will check and see if any
change is possible.

	[[alternative HTML version deleted]]


From khamenya at gmail.com  Sun Nov 22 19:23:34 2015
From: khamenya at gmail.com (Valery Khamenya)
Date: Sun, 22 Nov 2015 19:23:34 +0100
Subject: [R] Spectral density estimations for irregular time-series
Message-ID: <CABTXsnetcCoEYHM5i=t78dakbtJTUENSttejjPdnQ1f5OZQjyA@mail.gmail.com>

Hi,

I fail to find libraries to estimate the spectral density for irregular
time-series.

This entry from "CRAN Task View: Time Series Analysis":

  [...]Various packages implement irregular time series based on "POSIXct"
time stamps, intended especially for financial applications. These include
"its" from its, "irts" from tseries, and "fts" from fts.  [...]

is rather not that much helping.

best regards
--
Valery

	[[alternative HTML version deleted]]


From fw42746 at gmail.com  Sun Nov 22 20:12:56 2015
From: fw42746 at gmail.com (Frank Wang)
Date: Sun, 22 Nov 2015 11:12:56 -0800
Subject: [R] How to split 32 bits data into 16 bit or 8 bit data
In-Reply-To: <5651EF95.2020909@gmail.com>
References: <CA+0UNc9CDCxcLyyPXeW7xQnA5RhXe5ve=v=4qr_oAWdi5_ZHmw@mail.gmail.com>
	<5651EF95.2020909@gmail.com>
Message-ID: <CA+0UNc97jMGJaaK5OzZQKrAM8VgF4y7EB3c2a399xnTz=LR1Xg@mail.gmail.com>

Thank you very much that substr works great on my data. For future users, I
did in the following code.

z<-matrix(c(substr(tmp,5,8),substr(tmp,1,4)),5,2)
dataU16 <- c(t(z))



On Sun, Nov 22, 2015 at 8:38 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 22/11/2015 2:04 AM, Frank Wang wrote:
>
>> Hi,
>>
>> I am new user on R. I want to split a vector of hex data such as
>> "00ff8020"
>> "02d00000" "001e0240" "00010096" "00010033"
>> into 16 bits such as:
>> "00ff", "8020", "02d0","0000","001e", "0240", "0001","0096", "0001",
>> "0033"
>>
>> Are there any way to do it?
>>
>
> If those are really strings, use substr().
>
> If they are 32 bit integers, you could use x %% (2^16) for the low 16
> bits.  For the high 16 bits, you'll have to be careful about the sign. Or
> you could use the bitops package, bitShiftR(x, 16).  In either case the
> results will display by default in decimal; if you want a hex display, use
> as.hexmode().
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Nov 22 20:40:02 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 22 Nov 2015 11:40:02 -0800
Subject: [R] Spectral density estimations for irregular time-series
In-Reply-To: <CABTXsnetcCoEYHM5i=t78dakbtJTUENSttejjPdnQ1f5OZQjyA@mail.gmail.com>
References: <CABTXsnetcCoEYHM5i=t78dakbtJTUENSttejjPdnQ1f5OZQjyA@mail.gmail.com>
Message-ID: <9E98653F-F0ED-4E26-8203-5EF18C9403DF@dcn.davis.ca.us>

Since you seem to have trouble reading (the Posting Guide warns you to post here using plain text format emails.. doing so will be to your benefit when we can see what you posted clearly), perhaps it is not clear to you that the Task View is referring to contributed packages that have their own documentation. 

Also,  please be aware that a significant hurdle to applying spectral analysis in any calculation tool is familiarity with the underlying theory.  Doing so with irregular samples is going to be even more challenging,  and this is not an appropriate forum for learning such topics.

On November 22, 2015 10:23:34 AM PST, Valery Khamenya <khamenya at gmail.com> wrote:
>Hi,
>
>I fail to find libraries to estimate the spectral density for irregular
>time-series.
>
>This entry from "CRAN Task View: Time Series Analysis":
>
>[...]Various packages implement irregular time series based on
>"POSIXct"
>time stamps, intended especially for financial applications. These
>include
>"its" from its, "irts" from tseries, and "fts" from fts.  [...]
>
>is rather not that much helping.
>
>best regards
>--
>Valery
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Nov 22 21:54:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 22 Nov 2015 12:54:33 -0800
Subject: [R] Converting time zones in R using metadata file information
	of video files, help needed.
In-Reply-To: <CABVupNZ307VZaiQsfZOXO8O28nNiPLO+7B-KO5GYH97gHpnonQ@mail.gmail.com>
References: <CABVupNZ307VZaiQsfZOXO8O28nNiPLO+7B-KO5GYH97gHpnonQ@mail.gmail.com>
Message-ID: <F4DE8180-71FA-47CC-8AA2-B6D96CE19839@comcast.net>


> On Nov 22, 2015, at 2:52 AM, Ronny Steen <kestrel1978 at gmail.com> wrote:
> 
> Hi,
> 
> I have video files (FAT) that are taken in a different timezone than my
> current location. The modification date/time in the metafila data of the
> video file shows the time video was taken, although in the current timezone
> of my computer, if I understand right.
> 
> I wish to convert the date/time to the origin. The video was taken in
> London, Ontario Canada at 2015-06-21 07:53:28, when looking at the metadata
> of the file on my computer (timezone "Europe/Berlin") it says modification
> date "2015-06-22 01:53:28". Hence, there is a 6 hour difference between the
> two time-zones
> 
> I use the script provided here:
> http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html
> 
> pb.txt <- "2015-06-22 01:53:28" #modification date as shown on my
> computer (timezone
> "Europe/Berlin")
> 
> pb.date <- as.POSIXct(pb.txt, tz="Europe/London")
> 
> pb.date <- as.POSIXct(pb.txt, tz="America/Toronto")#timezone of origin
> video camera location
> 
> format(pb.date, tz=local.time,usetz=TRUE) #formats the mtime to data and
> time when the video was taken
> 
> [1] "2015-06-22 07:53:28 CEST" # the time is correct but the date is wrong
> as it has added 6 hours rather than subtracting.

I don?t understand why that is not the correct calculation, since the Sun rises in the East and so the local time is ?later? in Berlin than in Toronto. When it is later in the day in a more Westerly TZ the calculations on dates are correct>

> pb.txt <- "2015-06-22 21:53:28"

> pb.date <- as.POSIXct(pb.txt)
> pb.date
[1] "2015-06-22 21:53:28 PDT"

> format( pb.date, tz="Europe/Berlin")
[1] "2015-06-23 06:53:28"
> 
> I find working with different time-zones to be difficult, I hope I managed
> to formulate an understandable question.

With R the timezomes are mainly useful for output (including `print`-ing results in the current locale) and the options on input are limited. The numeric value is always in GMT/UCT.


> 
> Regards,
> 
> Kes
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rsherry8 at comcast.net  Sun Nov 22 23:10:31 2015
From: rsherry8 at comcast.net (Robert Sherry)
Date: Sun, 22 Nov 2015 17:10:31 -0500
Subject: [R] not allocate of vactor size
In-Reply-To: <1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
References: <1162706458.9270408.1448204917900.JavaMail.yahoo.ref@mail.yahoo.com>
	<1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56523D57.5060508@comcast.net>

I am thinking that R is running out of memory. Therefore, I would look 
to increase the size of my virtual memory. Here are two links
that might help you with that:
http://windows.microsoft.com/en-us/windows/change-virtual-memory-size#1TC=windows-7
http://www.ehow.com/how_5001512_increase-virtual-memory-linux.html
Bob
On 11/22/2015 10:08 AM, Tamsila Parveen via R-help wrote:
> Hello,           Is there anyone to help me out how can I resolve memory issue of R, when I want to analyze data of 1Gb file, R returns me Error: not allocate of vector size of 1.8 GB.I tried on linux as well as on windows with 64 bit system and using 64 bit R-3.2.2 version. So anyone who knows please guide me to resolve this issue
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From angelo.arcadi at virgilio.it  Sun Nov 22 23:44:26 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Sun, 22 Nov 2015 23:44:26 +0100 (CET)
Subject: [R] How to plot results from lme in presence of a significant
 interaction
Message-ID: <1335312516.470041448232266707.JavaMail.defaultUser@defaultHost>

Dear list members,
I wonder which is the best way to plot in r the 
results from the lme function, in presence of a significant interaction.
 My model has two interacting fixed effects and a random effect. The 
analysis is from an experiment where 19 participants had to adjust the 
Centroid parameter of some sounds stimuli, and I want to assess whether
 there is a relationship between their choices and their height and 
weight. There were 12 stimuli repeated twice for a total of 24 trials.
Here is the output of my analysis:

    > library(nlme)
    > lme_Centroid <- lme(Centroid ~ Weight*Height, data = scrd, random = ~1 | Subject)
    > 
    > summary(lme_Centroid)
    Linear mixed-effects model fit by REML
     Data: scrd 
           AIC      BIC    logLik
      25809.38 25840.69 -12898.69
    
    Random effects:
     Formula: ~1 | Subject
            (Intercept) Residual
    StdDev:    398.9658  3027.67
    
    Fixed effects: Centroid ~ Weight * Height 
                       Value Std.Error   DF   t-value p-value
    (Intercept)   -20232.203  9101.096 1349 -2.223051  0.0264
    Weight           478.854   152.184   15  3.146536  0.0067
    Height           140.440    52.194   15  2.690751  0.0168
    Weight:Height     -2.725     0.838   15 -3.253770  0.0053
     Correlation: 
                  (Intr) Weight Height
    Weight        -0.927              
    Height        -0.994  0.886       
    Weight:Height  0.951 -0.996 -0.919
    
    Standardized Within-Group Residuals:
           Min         Q1        Med         Q3        Max 
    -1.5059828 -0.8664208 -0.2111113  0.7098706  2.3620633 
    
    Number of Observations: 1368
    Number of Groups: 19 



I
 do not know how to represent in R these results. I tried 
xyplot(Centroid ~  Weight * Height, type = c("p","r"), data = scrd) but I
 guess it is wrong.

Thank you in advance

Best regards

Angelo
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Nov 23 00:45:08 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 22 Nov 2015 15:45:08 -0800
Subject: [R] How to plot results from lme in presence of a significant
	interaction
In-Reply-To: <1335312516.470041448232266707.JavaMail.defaultUser@defaultHost>
References: <1335312516.470041448232266707.JavaMail.defaultUser@defaultHost>
Message-ID: <CAGxFJbSo-8=n-oQr96j2B4uxs0DtNGsu8VAuPYyrmED7hNOp3A@mail.gmail.com>

I would have thought the first place to look would be ?interaction.plot

Cheers,

Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sun, Nov 22, 2015 at 2:44 PM, angelo.arcadi at virgilio.it
<angelo.arcadi at virgilio.it> wrote:
> Dear list members,
> I wonder which is the best way to plot in r the
> results from the lme function, in presence of a significant interaction.
>  My model has two interacting fixed effects and a random effect. The
> analysis is from an experiment where 19 participants had to adjust the
> Centroid parameter of some sounds stimuli, and I want to assess whether
>  there is a relationship between their choices and their height and
> weight. There were 12 stimuli repeated twice for a total of 24 trials.
> Here is the output of my analysis:
>
>     > library(nlme)
>     > lme_Centroid <- lme(Centroid ~ Weight*Height, data = scrd, random = ~1 | Subject)
>     >
>     > summary(lme_Centroid)
>     Linear mixed-effects model fit by REML
>      Data: scrd
>            AIC      BIC    logLik
>       25809.38 25840.69 -12898.69
>
>     Random effects:
>      Formula: ~1 | Subject
>             (Intercept) Residual
>     StdDev:    398.9658  3027.67
>
>     Fixed effects: Centroid ~ Weight * Height
>                        Value Std.Error   DF   t-value p-value
>     (Intercept)   -20232.203  9101.096 1349 -2.223051  0.0264
>     Weight           478.854   152.184   15  3.146536  0.0067
>     Height           140.440    52.194   15  2.690751  0.0168
>     Weight:Height     -2.725     0.838   15 -3.253770  0.0053
>      Correlation:
>                   (Intr) Weight Height
>     Weight        -0.927
>     Height        -0.994  0.886
>     Weight:Height  0.951 -0.996 -0.919
>
>     Standardized Within-Group Residuals:
>            Min         Q1        Med         Q3        Max
>     -1.5059828 -0.8664208 -0.2111113  0.7098706  2.3620633
>
>     Number of Observations: 1368
>     Number of Groups: 19
>
>
>
> I
>  do not know how to represent in R these results. I tried
> xyplot(Centroid ~  Weight * Height, type = c("p","r"), data = scrd) but I
>  guess it is wrong.
>
> Thank you in advance
>
> Best regards
>
> Angelo
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Nov 23 00:53:10 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 22 Nov 2015 18:53:10 -0500
Subject: [R] not allocate of vactor size
In-Reply-To: <1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
References: <1162706458.9270408.1448204917900.JavaMail.yahoo.ref@mail.yahoo.com>
	<1162706458.9270408.1448204917900.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-7XrRYi8p4J4HKpX0kgpSW70aYH71Syk-efrwQu=ZnLZw@mail.gmail.com>

My general rule of thumb is that I should have 3-4 times as much RAM as the
largest object that I am working with.  So hopefully you have at least 4 GB
of RAM on your system.  Also exactly what processing (packages, functions,
algorithms, etc.) are you using.  So functions may create multiple copies,
or they may create temporary objects bigger than the original.  So help us
out and provide more information.  You might be able to add virtual memory,
but this may slow down your process quite a bit with paging.  If you do go
this direction, then learn how to use the performance monitoring tools on
your system to see what is happening.?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Nov 22, 2015 at 10:08 AM, Tamsila Parveen via R-help <
r-help at r-project.org> wrote:

> Hello,           Is there anyone to help me out how can I resolve memory
> issue of R, when I want to analyze data of 1Gb file, R returns me Error:
> not allocate of vector size of 1.8 GB.I tried on linux as well as on
> windows with 64 bit system and using 64 bit R-3.2.2 version. So anyone who
> knows please guide me to resolve this issue
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From margarette.bayron at upr.edu  Mon Nov 23 05:56:46 2015
From: margarette.bayron at upr.edu (Margarette Bayron Arcelay)
Date: Mon, 23 Nov 2015 00:56:46 -0400
Subject: [R] RGL Problem
Message-ID: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>

Dear List,

Im using Rstudio on a macbook pro OS X Yosemite version 10.10.5 and im
trying to
open the package geomorph but a warning message related to rgl shows up.

> library(geomorph)
Loading required package: rgl
Warning messages:
1: In rgl.init(initValue, onlyNULL) : RGL: unable to open X11 display
2: In fun(libname, pkgname) : error in rgl_init

I have already installed X11 but this message keeps showing up.

Does somebody knows what to do?

-- 
*Margarette Bayr?n Arcelay*
*Master Student & Teaching Assistant in the Department of Biology *
*University of Puerto Rico at Mayaguez *
*BS Industrial Microbiology & **BS General Biology*
*Office: B-154;01A | Lab: B-282B: Ecolab*
*Linkedin <http://pr.linkedin.com/in/margarettebayron> | *
*margarette.bayron at upr.edu* <margarette.bayron at upr.edu>

*Office Hours (B-282B): *
*Tue- 11:00-11:50am & 2:00-4:30pm*
*Thurs- 10:30-11:30am*

*"Chance favors a prepared mind"*

	[[alternative HTML version deleted]]


From angelo.arcadi at virgilio.it  Mon Nov 23 10:45:20 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Mon, 23 Nov 2015 10:45:20 +0100 (CET)
Subject: [R] R: Re: How to plot results from lme in presence of a
 significant interaction
Message-ID: <240308828.507691448271920354.JavaMail.defaultUser@defaultHost>


Dear Bert and R list,
actually I had tried the interaction plot function, but I deduced that it was 
not the correct function since it gave me an empty plot (no lines). This should 
not be correct because as you can see from the results of the analysis I 
reported in the previous e-mail, there is a significant interaction.

The syntax for the function I used was interaction.plot(scrd$Weight,
scrd$Height,scrd$Centroid)

I want to plot my data and visualize the regression line showing the linear 
relationship between my dependent variable and the interaction between Weight 
and Height of the participants. 
How this is done in R?

Thank you

Best regards

Angelo



>----Messaggio originale----
>Da: bgunter.4567 at gmail.com
>Data: 22-nov-2015 23.45
>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>Cc: "r-help"<r-help at r-project.org>
>Ogg: Re: [R] How to plot results from lme in presence of a significant 
interaction
>
>I would have thought the first place to look would be ?interaction.plot
>
>Cheers,
>
>Bert
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Sun, Nov 22, 2015 at 2:44 PM, angelo.arcadi at virgilio.it
><angelo.arcadi at virgilio.it> wrote:
>> Dear list members,
>> I wonder which is the best way to plot in r the
>> results from the lme function, in presence of a significant interaction.
>>  My model has two interacting fixed effects and a random effect. The
>> analysis is from an experiment where 19 participants had to adjust the
>> Centroid parameter of some sounds stimuli, and I want to assess whether
>>  there is a relationship between their choices and their height and
>> weight. There were 12 stimuli repeated twice for a total of 24 trials.
>> Here is the output of my analysis:
>>
>>     > library(nlme)
>>     > lme_Centroid <- lme(Centroid ~ Weight*Height, data = scrd, random = 
~1 | Subject)
>>     >
>>     > summary(lme_Centroid)
>>     Linear mixed-effects model fit by REML
>>      Data: scrd
>>            AIC      BIC    logLik
>>       25809.38 25840.69 -12898.69
>>
>>     Random effects:
>>      Formula: ~1 | Subject
>>             (Intercept) Residual
>>     StdDev:    398.9658  3027.67
>>
>>     Fixed effects: Centroid ~ Weight * Height
>>                        Value Std.Error   DF   t-value p-value
>>     (Intercept)   -20232.203  9101.096 1349 -2.223051  0.0264
>>     Weight           478.854   152.184   15  3.146536  0.0067
>>     Height           140.440    52.194   15  2.690751  0.0168
>>     Weight:Height     -2.725     0.838   15 -3.253770  0.0053
>>      Correlation:
>>                   (Intr) Weight Height
>>     Weight        -0.927
>>     Height        -0.994  0.886
>>     Weight:Height  0.951 -0.996 -0.919
>>
>>     Standardized Within-Group Residuals:
>>            Min         Q1        Med         Q3        Max
>>     -1.5059828 -0.8664208 -0.2111113  0.7098706  2.3620633
>>
>>     Number of Observations: 1368
>>     Number of Groups: 19
>>
>>
>>
>> I
>>  do not know how to represent in R these results. I tried
>> xyplot(Centroid ~  Weight * Height, type = c("p","r"), data = scrd) but I
>>  guess it is wrong.
>>
>> Thank you in advance
>>
>> Best regards
>>
>> Angelo
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.
html
>> and provide commented, minimal, self-contained, reproducible code.
>


From angelo.arcadi at virgilio.it  Mon Nov 23 11:19:13 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Mon, 23 Nov 2015 11:19:13 +0100 (CET)
Subject: [R] Question about lme syntax
Message-ID: <302322655.518151448273953640.JavaMail.defaultUser@defaultHost>

Dear list,
I need an help to understand the syntax of lme to fit my model according to the analysis I want to perform.

My dependent variable resulted from a perceptual experiment in which responses of participants were measured twice for each provided stimulus. My goal is to verify whether the responses depend on two properties of the participants that I know to be related to each other (height and weight, so they need to be considered together as an interaction). More importantly, I need to understand how this relationship modulates according to the type of stimulus participants were presented to.

Based on my understanding of lme syntax, the formula I have to use should be the following (because I am only interested in the interaction factor of Weight and Height)

lme_dv <- lme(dv ~ Weight:Height:Stimulus_Type, data = scrd, random = ~ 1 | Subject)

Am I correct?


Thank you in advance

Best regards

Angelo



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Nov 23 11:49:00 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Nov 2015 05:49:00 -0500
Subject: [R] RGL Problem
In-Reply-To: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
Message-ID: <5652EF1C.1000402@gmail.com>

On 22/11/2015 11:56 PM, Margarette Bayron Arcelay via R-help wrote:
> Dear List,
>
> Im using Rstudio on a macbook pro OS X Yosemite version 10.10.5 and im
> trying to
> open the package geomorph but a warning message related to rgl shows up.
>
>> library(geomorph)
> Loading required package: rgl
> Warning messages:
> 1: In rgl.init(initValue, onlyNULL) : RGL: unable to open X11 display
> 2: In fun(libname, pkgname) : error in rgl_init
>
> I have already installed X11 but this message keeps showing up.
>
> Does somebody knows what to do?
>

It may be that you need to re-install XQuartz.  If that doesn't work, 
you can suppress its use.

If you run this before the library call:

options(rgl.useNULL = TRUE)

then rgl won't try to open your X11 display, and the error shouldn't 
happen.  (You won't be able to see output in X11 either.)

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Nov 23 11:50:13 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Nov 2015 05:50:13 -0500
Subject: [R] RGL Problem
In-Reply-To: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
Message-ID: <5652EF65.1050800@gmail.com>

On 22/11/2015 11:56 PM, Margarette Bayron Arcelay via R-help wrote:
> Dear List,
>
> Im using Rstudio on a macbook pro OS X Yosemite version 10.10.5 and im
> trying to
> open the package geomorph but a warning message related to rgl shows up.
>

Whoops, I forgot one thing.  The OSX binary version of rgl on CRAN is 
ancient.  You'll need to reinstall it from source for a current one.

Duncan Murdoch

>> library(geomorph)
> Loading required package: rgl
> Warning messages:
> 1: In rgl.init(initValue, onlyNULL) : RGL: unable to open X11 display
> 2: In fun(libname, pkgname) : error in rgl_init
>
> I have already installed X11 but this message keeps showing up.
>
> Does somebody knows what to do?
>


From knut.hansen at uit.no  Mon Nov 23 12:27:09 2015
From: knut.hansen at uit.no (Knut Hansen)
Date: Mon, 23 Nov 2015 12:27:09 +0100
Subject: [R] Problems installing biocLite on Fedora 23
Message-ID: <1708608.tF4uLfC62d@ws-ism-knuth.fm.uit.no>

I'm running Fedora 23 with KDE 5.16. I'm trying to install biocLite using the commands

source("https://bioconductor.org/biocLite.R")
biocLite()

as root.

During installation I get error messages like this:

gcc -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -
I"/usr/lib64/R/library/S4Vectors/include" -I"/usr/lib64/R/library/IRanges/include" -
I"/usr/lib64/R/library/XVector/include" -I"/usr/lib64/R/libr
*gcc:* *error: */usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory 

(Rsamtools is an example here, I get the same error message for all modules).

It did not help to reinstall gcc.

Any suggestions?


Knut Hansen
University of Troms?

	[[alternative HTML version deleted]]


From Martin.Morgan at roswellpark.org  Mon Nov 23 12:52:15 2015
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Mon, 23 Nov 2015 11:52:15 +0000
Subject: [R] Problems installing biocLite on Fedora 23
In-Reply-To: <1708608.tF4uLfC62d@ws-ism-knuth.fm.uit.no>
References: <1708608.tF4uLfC62d@ws-ism-knuth.fm.uit.no>
Message-ID: <DF23DAC5A53912408040FF04D8B780AAE33725@EXMB3RSC.roswellpark.org>

This is in reference to Bioconductor, and should be addressed to the Bioconductor support site

  https://support.bioconductor.org

The problem is not with biocLite per se, but with installation of Rsamtools.

My guess is that Rsamtools wraps a library 'samtools', and tries to re-map samtool's use of stderr and friends to R. The implementation requires use of -U_FORTIFY_SOURCE (undefine the _FORTIFY_SOURCE symbol when compiling), but unfortunately (or otherwise, depending on your level of paranoia) recent Fedora re-defines the symbol. A rough work-around might be to use the clang compiler, e.g., editing a file ~/.R/Makevars to contain something like the line

   CC=clang

When posting to the support site, please provide the full output of

  biocLite("Rsamtools")

as well as the output from the command line of

  gcc --version

Martin
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Knut Hansen [knut.hansen at uit.no]
Sent: Monday, November 23, 2015 6:27 AM
To: r-help at r-project.org
Subject: [R] Problems installing biocLite on Fedora 23

I'm running Fedora 23 with KDE 5.16. I'm trying to install biocLite using the commands

source("https://bioconductor.org/biocLite.R")
biocLite()

as root.

During installation I get error messages like this:

gcc -m64 -I/usr/include/R -DNDEBUG  -I/usr/local/include -
I"/usr/lib64/R/library/S4Vectors/include" -I"/usr/lib64/R/library/IRanges/include" -
I"/usr/lib64/R/library/XVector/include" -I"/usr/lib64/R/libr
*gcc:* *error: */usr/lib/rpm/redhat/redhat-hardened-cc1: No such file or directory

(Rsamtools is an example here, I get the same error message for all modules).

It did not help to reinstall gcc.

Any suggestions?


Knut Hansen
University of Troms?

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From stefanML at collocations.de  Mon Nov 23 13:45:49 2015
From: stefanML at collocations.de (Stefan Evert)
Date: Mon, 23 Nov 2015 13:45:49 +0100
Subject: [R] RGL Problem
In-Reply-To: <5652EF65.1050800@gmail.com>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
	<5652EF65.1050800@gmail.com>
Message-ID: <21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>


> On 23 Nov 2015, at 11:50, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>  The OSX binary version of rgl on CRAN is ancient.  You'll need to reinstall it from source for a current one.

Since you bring up this point: any chance of getting Mac binaries from CRAN again?  Rgl is a particularly nice tool because of its portability, and requiring users to install Xcode and Xquartz first makes life a lot harder for non-technical users.

This is compounded by the fact that the automatic configuration is easily broken. I have been unable to install rgl from source for some time on Mavericks, and have now discovered that this was due to a HomeBrew-installed imake in /usr/local.

Perhaps it would make sense always to use the well-known standard XQuartz paths on Mac and only consider other locations if explicitly asked for by the user?

Best,
Stefan

From jfox at mcmaster.ca  Mon Nov 23 13:50:54 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 23 Nov 2015 12:50:54 +0000
Subject: [R] How to plot results from lme in presence of a significant
 interaction
In-Reply-To: <1335312516.470041448232266707.JavaMail.defaultUser@defaultHost>
References: <1335312516.470041448232266707.JavaMail.defaultUser@defaultHost>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3C29C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Angelo,

You might try the Effect() function in the effects package: plot(Effect(c("Weight", "Height"), lme_Centroid)) .

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> angelo.arcadi at virgilio.it
> Sent: November 22, 2015 5:44 PM
> To: r-help at r-project.org
> Subject: [R] How to plot results from lme in presence of a significant interaction
> 
> Dear list members,
> I wonder which is the best way to plot in r the results from the lme function, in
> presence of a significant interaction.
>  My model has two interacting fixed effects and a random effect. The analysis is
> from an experiment where 19 participants had to adjust the Centroid
> parameter of some sounds stimuli, and I want to assess whether  there is a
> relationship between their choices and their height and weight. There were 12
> stimuli repeated twice for a total of 24 trials.
> Here is the output of my analysis:
> 
>     > library(nlme)
>     > lme_Centroid <- lme(Centroid ~ Weight*Height, data = scrd, random = ~1 |
> Subject)
>     >
>     > summary(lme_Centroid)
>     Linear mixed-effects model fit by REML
>      Data: scrd
>            AIC      BIC    logLik
>       25809.38 25840.69 -12898.69
> 
>     Random effects:
>      Formula: ~1 | Subject
>             (Intercept) Residual
>     StdDev:    398.9658  3027.67
> 
>     Fixed effects: Centroid ~ Weight * Height
>                        Value Std.Error   DF   t-value p-value
>     (Intercept)   -20232.203  9101.096 1349 -2.223051  0.0264
>     Weight           478.854   152.184   15  3.146536  0.0067
>     Height           140.440    52.194   15  2.690751  0.0168
>     Weight:Height     -2.725     0.838   15 -3.253770  0.0053
>      Correlation:
>                   (Intr) Weight Height
>     Weight        -0.927
>     Height        -0.994  0.886
>     Weight:Height  0.951 -0.996 -0.919
> 
>     Standardized Within-Group Residuals:
>            Min         Q1        Med         Q3        Max
>     -1.5059828 -0.8664208 -0.2111113  0.7098706  2.3620633
> 
>     Number of Observations: 1368
>     Number of Groups: 19
> 
> 
> 
> I
>  do not know how to represent in R these results. I tried xyplot(Centroid ~
> Weight * Height, type = c("p","r"), data = scrd) but I  guess it is wrong.
> 
> Thank you in advance
> 
> Best regards
> 
> Angelo
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Nov 23 14:48:11 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 23 Nov 2015 08:48:11 -0500
Subject: [R] RGL Problem
In-Reply-To: <21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
	<5652EF65.1050800@gmail.com>
	<21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>
Message-ID: <5653191B.2070405@gmail.com>

On 23/11/2015 7:45 AM, Stefan Evert wrote:
>
>> On 23 Nov 2015, at 11:50, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>>   The OSX binary version of rgl on CRAN is ancient.  You'll need to reinstall it from source for a current one.
>
> Since you bring up this point: any chance of getting Mac binaries from CRAN again?

You would have to ask them.  I don't know why they aren't building it.

Duncan Murdoch


  Rgl is a particularly nice tool because of its portability, and 
requiring users to install Xcode and Xquartz first makes life a lot 
harder for non-technical users.
>
> This is compounded by the fact that the automatic configuration is easily broken. I have been unable to install rgl from source for some time on Mavericks, and have now discovered that this was due to a HomeBrew-installed imake in /usr/local.
>
> Perhaps it would make sense always to use the well-known standard XQuartz paths on Mac and only consider other locations if explicitly asked for by the user?
>
> Best,
> Stefan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Mon Nov 23 15:59:32 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Nov 2015 14:59:32 +0000
Subject: [R] unique identifier for number sequence
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>

Dear all

I have a vector ones and zeroes like that
x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))

and I need to get result like that
x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))

It means I need an unique identifier for each sequence of ones.

It probably can be done by rle, cumsum and some fiddling with data but maybe there is some clever way which I overlooked.

Cheers
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jholtman at gmail.com  Mon Nov 23 16:14:10 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 23 Nov 2015 10:14:10 -0500
Subject: [R] unique identifier for number sequence
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
Message-ID: <CAAxdm-5QKZ6RvnOEPBbH4ZZ_16TAy=Hpq9k02eaHQcUsto4pKw@mail.gmail.com>

Here is one way of doing it:

> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
> x
 [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
>
> # mark changes from 0->1 and create increments
> indx <- cumsum(c(FALSE, diff(x) == 1))
>
> # keep just matches with '1'
> x.i <- ifelse(x == 1, indx, 0)
> x.i
 [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 23, 2015 at 9:59 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Dear all
>
> I have a vector ones and zeroes like that
> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
>
> and I need to get result like that
> x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))
>
> It means I need an unique identifier for each sequence of ones.
>
> It probably can be done by rle, cumsum and some fiddling with data but
> maybe there is some clever way which I overlooked.
>
> Cheers
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Nov 23 16:30:44 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 23 Nov 2015 15:30:44 +0000
Subject: [R] unique identifier for number sequence
In-Reply-To: <CAAxdm-5QKZ6RvnOEPBbH4ZZ_16TAy=Hpq9k02eaHQcUsto4pKw@mail.gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
	<CAAxdm-5QKZ6RvnOEPBbH4ZZ_16TAy=Hpq9k02eaHQcUsto4pKw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F7A@SRVEXCHMBX.precheza.cz>

Hi

Cool, thanks. I knew I am missing some obvious way.

Cheers
Petr

From: jim holtman [mailto:jholtman at gmail.com]
Sent: Monday, November 23, 2015 4:14 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] unique identifier for number sequence

Here is one way of doing it:

> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
> x
 [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
>
> # mark changes from 0->1 and create increments
> indx <- cumsum(c(FALSE, diff(x) == 1))
>
> # keep just matches with '1'
> x.i <- ifelse(x == 1, indx, 0)
> x.i
 [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 23, 2015 at 9:59 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Dear all

I have a vector ones and zeroes like that
x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))

and I need to get result like that
x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))

It means I need an unique identifier for each sequence of ones.

It probably can be done by rle, cumsum and some fiddling with data but maybe there is some clever way which I overlooked.

Cheers
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Nov 23 16:40:57 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 23 Nov 2015 10:40:57 -0500
Subject: [R] unique identifier for number sequence
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F7A@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
	<CAAxdm-5QKZ6RvnOEPBbH4ZZ_16TAy=Hpq9k02eaHQcUsto4pKw@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F7A@SRVEXCHMBX.precheza.cz>
Message-ID: <CAAxdm-7hU_a2nJWpiNANT9=iY8n4OXxKw7k0Ee05EEKUd2QCUA@mail.gmail.com>

Forgot to check if it starts with '1'; this should fix it.

> x<-c(rep(1,2), rep(0,5), rep(1,5), rep(0,10), rep(1,8))
> x
 [1] 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
>
> # mark changes from 0->1 and create increments
> # added a fix if it starts with '1'
> indx <- cumsum(c(x[1L] == 1, diff(x) == 1))
>
> # keep just matches with '1'
> x.i <- ifelse(x == 1, indx, 0)
> x.i
 [1] 1 1 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3 3 3 3
>
?


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 23, 2015 at 10:30 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> Cool, thanks. I knew I am missing some obvious way.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* jim holtman [mailto:jholtman at gmail.com]
> *Sent:* Monday, November 23, 2015 4:14 PM
> *To:* PIKAL Petr
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] unique identifier for number sequence
>
>
>
> Here is one way of doing it:
>
>
>
> > x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
> > x
>  [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1
> >
> > # mark changes from 0->1 and create increments
> > indx <- cumsum(c(FALSE, diff(x) == 1))
> >
> > # keep just matches with '1'
> > x.i <- ifelse(x == 1, indx, 0)
> > x.i
>  [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2
> >
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
>
> On Mon, Nov 23, 2015 at 9:59 AM, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
>
> Dear all
>
> I have a vector ones and zeroes like that
> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
>
> and I need to get result like that
> x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))
>
> It means I need an unique identifier for each sequence of ones.
>
> It probably can be done by rle, cumsum and some fiddling with data but
> maybe there is some clever way which I overlooked.
>
> Cheers
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From angelo.arcadi at virgilio.it  Mon Nov 23 16:59:47 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Mon, 23 Nov 2015 16:59:47 +0100 (CET)
Subject: [R] R: RE: How to plot results from lme in presence of a
 significant interaction
Message-ID: <1727674104.591281448294387198.JavaMail.defaultUser@defaultHost>


Dear prof. Fox,
thank you very much

Best regards

Angelo

>----Messaggio originale----
>Da: jfox at mcmaster.ca
>Data: 23-nov-2015 12.50
>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>Cc: "r-help at r-project.org"<r-help at r-project.org>
>Ogg: RE: [R] How to plot results from lme in presence of a significant 
interaction
>
>Dear Angelo,
>
>You might try the Effect() function in the effects package: plot(Effect(c
("Weight", "Height"), lme_Centroid)) .
>
>I hope this helps,
> John
>
>-----------------------------
>John Fox, Professor
>McMaster University
>Hamilton, Ontario
>Canada L8S 4M4
>Web: socserv.mcmaster.ca/jfox
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> angelo.arcadi at virgilio.it
>> Sent: November 22, 2015 5:44 PM
>> To: r-help at r-project.org
>> Subject: [R] How to plot results from lme in presence of a significant 
interaction
>> 
>> Dear list members,
>> I wonder which is the best way to plot in r the results from the lme 
function, in
>> presence of a significant interaction.
>>  My model has two interacting fixed effects and a random effect. The 
analysis is
>> from an experiment where 19 participants had to adjust the Centroid
>> parameter of some sounds stimuli, and I want to assess whether  there is a
>> relationship between their choices and their height and weight. There were 
12
>> stimuli repeated twice for a total of 24 trials.
>> Here is the output of my analysis:
>> 
>>     > library(nlme)
>>     > lme_Centroid <- lme(Centroid ~ Weight*Height, data = scrd, random = 
~1 |
>> Subject)
>>     >
>>     > summary(lme_Centroid)
>>     Linear mixed-effects model fit by REML
>>      Data: scrd
>>            AIC      BIC    logLik
>>       25809.38 25840.69 -12898.69
>> 
>>     Random effects:
>>      Formula: ~1 | Subject
>>             (Intercept) Residual
>>     StdDev:    398.9658  3027.67
>> 
>>     Fixed effects: Centroid ~ Weight * Height
>>                        Value Std.Error   DF   t-value p-value
>>     (Intercept)   -20232.203  9101.096 1349 -2.223051  0.0264
>>     Weight           478.854   152.184   15  3.146536  0.0067
>>     Height           140.440    52.194   15  2.690751  0.0168
>>     Weight:Height     -2.725     0.838   15 -3.253770  0.0053
>>      Correlation:
>>                   (Intr) Weight Height
>>     Weight        -0.927
>>     Height        -0.994  0.886
>>     Weight:Height  0.951 -0.996 -0.919
>> 
>>     Standardized Within-Group Residuals:
>>            Min         Q1        Med         Q3        Max
>>     -1.5059828 -0.8664208 -0.2111113  0.7098706  2.3620633
>> 
>>     Number of Observations: 1368
>>     Number of Groups: 19
>> 
>> 
>> 
>> I
>>  do not know how to represent in R these results. I tried xyplot(Centroid ~
>> Weight * Height, type = c("p","r"), data = scrd) but I  guess it is wrong.
>> 
>> Thank you in advance
>> 
>> Best regards
>> 
>> Angelo
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From nilesh.dighe at monsanto.com  Mon Nov 23 17:05:32 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Mon, 23 Nov 2015 16:05:32 +0000
Subject: [R] subset data using a vector
Message-ID: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>

Dear R users,
                I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.

I have created this function (fun1) but when I run it, I get the following error:

Error in m1[[i]] : subscript out of bounds

Any help will be highly appreciated!
Thanks, Nilesh

Dataset:
dput(mydata)
structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", "2", "3",
"4"), class = "factor"), cols = structure(c(1L, 10L, 11L, 12L,
13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L,
11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L,
8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L,
6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5", "6", "7",
"8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
    plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
    290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
    374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
    379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
    399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
    480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
    477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
    4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
    5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
    5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
    5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
    5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
    ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
    "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
    ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
    3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
    4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
    "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names = c("rows",
"cols", "plotid", "yield", "linecode", "ranges", "rangestouse"

), class = "data.frame", row.names = c(NA, -64L))

Function:

fun1<- function (dataset, plot.id, ranges2use, control)

{

    m1 <- strsplit(as.character(dataset$ranges2use), ",")

    dat1 <- data.frame()

    m2 <- c()

    row_check_mean <- c()

    row_check_adj_yield <- c()

    x <- length(plot.id)

    for (i in (1:x)) {

        m2[i] <- m1[[i]]

        dat1 <- dataset[dataset$ranges %in% m2[i], ]

        row_check_mean[i] <- tapply(dat1$trait, dat1$control,

            mean, na.rm = TRUE)[1]

        row_check_adj_yield[i] <- ifelse(control[i] == "variety",

            trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])

    }

    data.frame(dataset, row_check_adj_yield)

}

Apply function:
fun1(mydata, plot.id=mydata$plotid, ranges2use = mydata$rangestouse,control=mydata$linecode)

Error:

Error in m1[[i]] : subscript out of bounds

Session info:

R version 3.2.1 (2015-06-18)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



loaded via a namespace (and not attached):

 [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1

 [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31


Nilesh Dighe
(806)-252-7492 (Cell)
(806)-741-2019 (Office)


This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Nov 23 17:07:22 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Nov 2015 08:07:22 -0800
Subject: [R] unique identifier for number sequence
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF8bMcZ5UbcyYtbTat0OgV03gVdRV=PHygm2-ix4UjDXE=qhcQ@mail.gmail.com>

> f <- function(x)cumsum(c(x[1]==1, x[-length(x)]==0 & x[-1]==1)) * (x==1)
> f(x)
 [1] 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2
> f(rev(x))
 [1] 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Nov 23, 2015 at 6:59 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Dear all
>
> I have a vector ones and zeroes like that
> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
>
> and I need to get result like that
> x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))
>
> It means I need an unique identifier for each sequence of ones.
>
> It probably can be done by rle, cumsum and some fiddling with data but maybe there is some clever way which I overlooked.
>
> Cheers
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Nov 23 17:16:32 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 23 Nov 2015 16:16:32 +0000
Subject: [R] subset data using a vector
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <56533BE0.8010906@dewey.myzen.co.uk>

length(strsplit(as.character(mydata$ranges2use), ","))

was that what you expected? I think not.

On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
> Dear R users,
>                  I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.
>
> I have created this function (fun1) but when I run it, I get the following error:
>
> Error in m1[[i]] : subscript out of bounds
>
> Any help will be highly appreciated!
> Thanks, Nilesh
>
> Dataset:
> dput(mydata)
> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", "2", "3",
> "4"), class = "factor"), cols = structure(c(1L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L, 6L, 7L,
> 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5", "6", "7",
> "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
>      plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
>      290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
>      374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
>      379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
>      399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
>      480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
>      477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
>      4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
>      5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
>      5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
>      5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
>      5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
>      ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
>      "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
>      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>      4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>      ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>      4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
>      "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names = c("rows",
> "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
>
> ), class = "data.frame", row.names = c(NA, -64L))
>
> Function:
>
> fun1<- function (dataset, plot.id, ranges2use, control)
>
> {
>
>      m1 <- strsplit(as.character(dataset$ranges2use), ",")
>
>      dat1 <- data.frame()
>
>      m2 <- c()
>
>      row_check_mean <- c()
>
>      row_check_adj_yield <- c()
>
>      x <- length(plot.id)
>
>      for (i in (1:x)) {
>
>          m2[i] <- m1[[i]]
>
>          dat1 <- dataset[dataset$ranges %in% m2[i], ]
>
>          row_check_mean[i] <- tapply(dat1$trait, dat1$control,
>
>              mean, na.rm = TRUE)[1]
>
>          row_check_adj_yield[i] <- ifelse(control[i] == "variety",
>
>              trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
>
>      }
>
>      data.frame(dataset, row_check_adj_yield)
>
> }
>
> Apply function:
> fun1(mydata, plot.id=mydata$plotid, ranges2use = mydata$rangestouse,control=mydata$linecode)
>
> Error:
>
> Error in m1[[i]] : subscript out of bounds
>
> Session info:
>
> R version 3.2.1 (2015-06-18)
>
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
>
> locale:
>
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
>
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United States.1252
>
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> loaded via a namespace (and not attached):
>
>   [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1
>
>   [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
>
>
> Nilesh Dighe
> (806)-252-7492 (Cell)
> (806)-741-2019 (Office)
>
>
> This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
> all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
> this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
> including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
> applicable U.S. export laws and regulations.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Mon Nov 23 17:23:20 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Nov 2015 08:23:20 -0800
Subject: [R] Spectral density estimations for irregular time-series
In-Reply-To: <CABTXsncashU06Z6ikNBs25QQauDZFzPzLqBL6nB8F00RQ_tGpA@mail.gmail.com>
References: <CABTXsnetcCoEYHM5i=t78dakbtJTUENSttejjPdnQ1f5OZQjyA@mail.gmail.com>
	<9E98653F-F0ED-4E26-8203-5EF18C9403DF@dcn.davis.ca.us>
	<CABTXsncashU06Z6ikNBs25QQauDZFzPzLqBL6nB8F00RQ_tGpA@mail.gmail.com>
Message-ID: <992B64C9-7A19-4DA4-B826-50FF53E6E220@dcn.davis.ca.us>

Well,  that response was much more clear than your original email was.

1. The automatically-generated plain text component of an email is usually much less intelligible than a directly-generated text.  In particular,  line breaks and faux highlighting corrupt example code in the plain text version. Since the mailing list usually strips the html we don't even have the option to see it as you saw it in many cases, so don't even start there if you want reliable communication. As the Posting Guide says,  this is a plain-text mailing list. 

2. Looks like the Task View is out of date. .. perhaps those functions were moved or removed.  I Googled and found spec.ls in the cts package,  though. 

3. I think this is a perfectly reasonable place to ask about how to find appropriate packages, but it is less reasonable to ask for help when Google yields an answer immediately. You must be clear that that is what you are doing,  and you should indicate which search strategies failed you,  and how they failed, because such efforts are USUALLY successful. Note that I did not know about cts until I used Google to search for "irregular time series fourier transform r package", which doesn't seem so difficult to me, but if you had been more clear about attempts you had made I would have just shared that option.   Reporting that none of the mentioned packages even include a mention of spectral analysis also seems appropriate here, but you left that to our imagination. 

Thank you for your improved efforts to communicate clearly. 

On November 23, 2015 2:04:28 AM PST, Valery Khamenya <khamenya at gmail.com> wrote:
>Jeff, many thanks for your answer.
>
>On Sun, Nov 22, 2015 at 8:40 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>
>> Since you seem to have trouble reading (the Posting Guide warns you
>to post here using plain text format emails.. doing so will be to your
>benefit when we can see what you posted clearly),
>
>the body of the email sent by me has had both plain-text and html
>representations. I found no clear confrontation with the Posting Guide
>for this case.
>
>
>> perhaps it is not clear to you that the Task View is referring to
>contributed packages that have their own documentation.
>
>that's clear. To my understanding primary purpose of a Task View is
>giving a (over)view about the R-packages that one could use while
>addressing the respective task. The Task View this time was not enough
>to locate the needed package, so I had to admit I need a help. If the
>r-help mail-list isn't the right place to ask for a help to locate a
>relevant R-package then I'm a bit confused, but would kindly ask for
>redirecting me to a mail-list that is more relevant for my question.
>
>
>> Also, please be aware that a significant hurdle to applying spectral
>analysis in any calculation tool is familiarity with the underlying
>theory. Doing so with irregular samples is going to be even more
>challenging, and this is not an appropriate forum for learning such
>topics.
>
>I do confirm, that my focus was and is to locate an R-package that
>provides at least one function in its API to estimate power spectrum
>for the irregular time series.
>
>kind regards and thanks in advance for any help,
>Valery.
>
>> On November 22, 2015 10:23:34 AM PST, Valery Khamenya
><khamenya at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> I fail to find libraries to estimate the spectral density for
>irregular
>>> time-series.
>>>
>>> This entry from "CRAN Task View: Time Series Analysis":
>>>
>>>   [...]Various packages implement irregular time series based on
>"POSIXct"
>>> time stamps, intended especially for financial applications. These
>include
>>> "its" from its, "irts" from tseries, and "fts" from fts.  [...]
>>>
>>> is rather not that much helping.
>>>
>>> best regards
>>> --
>>> Valery
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ________________________________
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> --
>> Sent from my Android device with K-9 Mail. Please excuse my brevity.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From itziar.irigoien at ehu.es  Mon Nov 23 12:58:45 2015
From: itziar.irigoien at ehu.es (itziar irigoien)
Date: Mon, 23 Nov 2015 12:58:45 +0100
Subject: [R] Fwd: Re:  knn - random result although use.all=TRUE
In-Reply-To: <5652FED9.4040707@ehu.es>
References: <5652FED9.4040707@ehu.es>
Message-ID: <5652FF75.8000109@ehu.es>


Thank you very much for your prompt response. Now I see why the results
have a random part: although all units with tied distances are included
in the neighbourhood, the votes have to be broken at random.

Thank you!

Itziar Irigoien
On or., 2015.eko azaren 20a 16:40, David L Carlson wrote:
> Changing your definition of cl to clase let me replicate the problem. If you set a random seed just before running knn() the results are consistent so that indicates that the function is drawing a random number at some point.
>
> You should probably contact the package maintainer, but your toy data set is trivially simple. You have 40 total observations, but X1 has only 3 different values and X2 has only 2 different values so there are only 6 different combinations. The distance matrix on your training set has 435 distances, but only 5 different values! As a result there are many, many tied values so the algorithm probably uses a random method of selecting which 3 to use.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352


From khamenya at gmail.com  Mon Nov 23 11:04:28 2015
From: khamenya at gmail.com (Valery Khamenya)
Date: Mon, 23 Nov 2015 11:04:28 +0100
Subject: [R] Spectral density estimations for irregular time-series
In-Reply-To: <9E98653F-F0ED-4E26-8203-5EF18C9403DF@dcn.davis.ca.us>
References: <CABTXsnetcCoEYHM5i=t78dakbtJTUENSttejjPdnQ1f5OZQjyA@mail.gmail.com>
	<9E98653F-F0ED-4E26-8203-5EF18C9403DF@dcn.davis.ca.us>
Message-ID: <CABTXsncashU06Z6ikNBs25QQauDZFzPzLqBL6nB8F00RQ_tGpA@mail.gmail.com>

Jeff, many thanks for your answer.

On Sun, Nov 22, 2015 at 8:40 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:

> Since you seem to have trouble reading (the Posting Guide warns you to post here using plain text format emails.. doing so will be to your benefit when we can see what you posted clearly),

the body of the email sent by me has had both plain-text and html
representations. I found no clear confrontation with the Posting Guide
for this case.


> perhaps it is not clear to you that the Task View is referring to contributed packages that have their own documentation.

that's clear. To my understanding primary purpose of a Task View is
giving a (over)view about the R-packages that one could use while
addressing the respective task. The Task View this time was not enough
to locate the needed package, so I had to admit I need a help. If the
r-help mail-list isn't the right place to ask for a help to locate a
relevant R-package then I'm a bit confused, but would kindly ask for
redirecting me to a mail-list that is more relevant for my question.


> Also, please be aware that a significant hurdle to applying spectral analysis in any calculation tool is familiarity with the underlying theory. Doing so with irregular samples is going to be even more challenging, and this is not an appropriate forum for learning such topics.

I do confirm, that my focus was and is to locate an R-package that
provides at least one function in its API to estimate power spectrum
for the irregular time series.

kind regards and thanks in advance for any help,
Valery.

> On November 22, 2015 10:23:34 AM PST, Valery Khamenya <khamenya at gmail.com> wrote:
>>
>> Hi,
>>
>> I fail to find libraries to estimate the spectral density for irregular
>> time-series.
>>
>> This entry from "CRAN Task View: Time Series Analysis":
>>
>>   [...]Various packages implement irregular time series based on "POSIXct"
>> time stamps, intended especially for financial applications. These include
>> "its" from its, "irts" from tseries, and "fts" from fts.  [...]
>>
>> is rather not that much helping.
>>
>> best regards
>> --
>> Valery
>>
>>  [[alternative HTML version deleted]]
>>
>> ________________________________
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.


From nilesh.dighe at monsanto.com  Mon Nov 23 17:26:29 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Mon, 23 Nov 2015 16:26:29 +0000
Subject: [R] subset data using a vector
In-Reply-To: <56533BE0.8010906@dewey.myzen.co.uk>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56533BE0.8010906@dewey.myzen.co.uk>
Message-ID: <24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>

Michael:  I like to use the actual range id's listed in column "rangestouse" to subset my data and not the length of that vector.

Thanks.
Nilesh

-----Original Message-----
From: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Sent: Monday, November 23, 2015 10:17 AM
To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
Subject: Re: [R] subset data using a vector

length(strsplit(as.character(mydata$ranges2use), ","))

was that what you expected? I think not.

On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
> Dear R users,
>                  I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.
>
> I have created this function (fun1) but when I run it, I get the following error:
>
> Error in m1[[i]] : subscript out of bounds
>
> Any help will be highly appreciated!
> Thanks, Nilesh
>
> Dataset:
> dput(mydata)
> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
> 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor"), 
> cols = structure(c(1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 
> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 
> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 
> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 
> 5L, 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5", "6", "7", 
> "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
>      plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
>      290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
>      374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
>      379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
>      399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
>      480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
>      477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
>      4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
>      5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
>      5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
>      5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
>      5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
>      ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
>      "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
>      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>      4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>      ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>      1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>      2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>      3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>      4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
>      "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names = c("rows", 
> "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
>
> ), class = "data.frame", row.names = c(NA, -64L))
>
> Function:
>
> fun1<- function (dataset, plot.id, ranges2use, control)
>
> {
>
>      m1 <- strsplit(as.character(dataset$ranges2use), ",")
>
>      dat1 <- data.frame()
>
>      m2 <- c()
>
>      row_check_mean <- c()
>
>      row_check_adj_yield <- c()
>
>      x <- length(plot.id)
>
>      for (i in (1:x)) {
>
>          m2[i] <- m1[[i]]
>
>          dat1 <- dataset[dataset$ranges %in% m2[i], ]
>
>          row_check_mean[i] <- tapply(dat1$trait, dat1$control,
>
>              mean, na.rm = TRUE)[1]
>
>          row_check_adj_yield[i] <- ifelse(control[i] == "variety",
>
>              trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
>
>      }
>
>      data.frame(dataset, row_check_adj_yield)
>
> }
>
> Apply function:
> fun1(mydata, plot.id=mydata$plotid, ranges2use = 
> mydata$rangestouse,control=mydata$linecode)
>
> Error:
>
> Error in m1[[i]] : subscript out of bounds
>
> Session info:
>
> R version 3.2.1 (2015-06-18)
>
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
>
> locale:
>
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
> States.1252
>
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United States.1252
>
>
>
> attached base packages:
>
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
>
> loaded via a namespace (and not attached):
>
>   [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1
>
>   [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
>
>
> Nilesh Dighe
> (806)-252-7492 (Cell)
> (806)-741-2019 (Office)
>
>
> This e-mail message may contain privileged and/or confidential 
> information, and is intended to be received only by persons entitled 
> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to 
> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any 
> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export 
> control laws and regulations of the United States, potentially 
> including but not limited to the Export Administration Regulations 
> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html
This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.


From E.Vettorazzi at uke.de  Mon Nov 23 17:34:59 2015
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Mon, 23 Nov 2015 17:34:59 +0100
Subject: [R] unique identifier for number sequence
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5001F2B@SRVEXCHMBX.precheza.cz>
Message-ID: <56534033.7080205@uke.de>

cumsum(c(x[1],pmax(0,diff(x))))*x

Am 23.11.2015 um 15:59 schrieb PIKAL Petr:
> Dear all
> 
> I have a vector ones and zeroes like that
> x<-c(rep(0,5), rep(1,5), rep(0,10), rep(1,8))
> 
> and I need to get result like that
> x.i<-c(rep(0,5), rep(1,5), rep(0,10), rep(2,8))
> 
> It means I need an unique identifier for each sequence of ones.
> 
> It probably can be done by rle, cumsum and some fiddling with data but maybe there is some clever way which I overlooked.
> 
> Cheers
> Petr
> 
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Rainer Schoppik
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From wjhopper510 at gmail.com  Mon Nov 23 18:36:21 2015
From: wjhopper510 at gmail.com (Will Hopper)
Date: Mon, 23 Nov 2015 12:36:21 -0500
Subject: [R] diff-ing .rds files
Message-ID: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>

Hi all,

I'm posting to see if anyone knows of any existing resources that
auto-magically converts r objects in saved in .rds files to a plain text
representation, suitable for diffing?

I often save the results of long running calculation as .rds files, and
since I use git for source control, it would be nice if there were a way to
convert rds files to a plain text representation for diffing, so I could
avoid having large commits full of binary data. Git allows you specify a
programs for binary --> text conversion for any file type, effectively
teaching git how to diff binary files. If there was something out there
developed to do this with .rds files, it would really like to know about it!

I realize I could save the rds file with ascii=TRUE and compress=FALSE, but
that kind of defeats the point of saving as .rds in the first place.

If there is no tool out that there anyone knows of, I don't think it would
be too hard for me to write something with bash + Rscript to get the job
done, but I'd like to avoid re-inventing the wheel if possible.

Thanks for the help!

	[[alternative HTML version deleted]]


From Jason.Law at portlandoregon.gov  Mon Nov 23 18:51:13 2015
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Mon, 23 Nov 2015 17:51:13 +0000
Subject: [R] Converting time zones in R using metadata file information
 of video files, help needed.
In-Reply-To: <CABVupNZ307VZaiQsfZOXO8O28nNiPLO+7B-KO5GYH97gHpnonQ@mail.gmail.com>
References: <CABVupNZ307VZaiQsfZOXO8O28nNiPLO+7B-KO5GYH97gHpnonQ@mail.gmail.com>
Message-ID: <BY1PR09MB0821D45F079663E612838E7387070@BY1PR09MB0821.namprd09.prod.outlook.com>

The "lubridate" package will help simplify these time zone conversions. It provides two simple functions with_tz and force_tz that conceptually make things simpler.

library(lubridate)
> x <- as.POSIXct("2015-06-22 01:53:28", 'Europe/Berlin')
> with_tz(x, 'America/Toronto')
[1] "2015-06-21 19:53:28 EDT"

HTH,

J

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ronny Steen
Sent: Sunday, November 22, 2015 2:52 AM
To: r-help at r-project.org
Subject: [R] Converting time zones in R using metadata file information of video files, help needed.

Hi,

I have video files (FAT) that are taken in a different timezone than my current location. The modification date/time in the metafila data of the video file shows the time video was taken, although in the current timezone of my computer, if I understand right.

I wish to convert the date/time to the origin. The video was taken in London, Ontario Canada at 2015-06-21 07:53:28, when looking at the metadata of the file on my computer (timezone "Europe/Berlin") it says modification date "2015-06-22 01:53:28". Hence, there is a 6 hour difference between the two time-zones

I use the script provided here:
http://blog.revolutionanalytics.com/2009/06/converting-time-zones.html

pb.txt <- "2015-06-22 01:53:28" #modification date as shown on my computer (timezone
"Europe/Berlin")

pb.date <- as.POSIXct(pb.txt, tz="Europe/London")

pb.date <- as.POSIXct(pb.txt, tz="America/Toronto")#timezone of origin video camera location

format(pb.date, tz=local.time,usetz=TRUE) #formats the mtime to data and time when the video was taken

[1] "2015-06-22 07:53:28 CEST" # the time is correct but the date is wrong as it has added 6 hours rather than subtracting.

I find working with different time-zones to be difficult, I hope I managed to formulate an understandable question.

Regards,

Kes

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Nov 23 19:03:40 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 Nov 2015 10:03:40 -0800
Subject: [R] diff-ing .rds files
In-Reply-To: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
References: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
Message-ID: <CAGxFJbR8e=mQKD1aAVkV4WtrfyS703cCfeoun7oS9UMJgNTw-w@mail.gmail.com>

?dput  or ?dump perhaps.  (and dget() and source() )

I realize that these may not do what you want, but exactly what you
want is a bit unclear (to me, anyway) depending on exactly what your
saved results are.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 23, 2015 at 9:36 AM, Will Hopper <wjhopper510 at gmail.com> wrote:
> Hi all,
>
> I'm posting to see if anyone knows of any existing resources that
> auto-magically converts r objects in saved in .rds files to a plain text
> representation, suitable for diffing?
>
> I often save the results of long running calculation as .rds files, and
> since I use git for source control, it would be nice if there were a way to
> convert rds files to a plain text representation for diffing, so I could
> avoid having large commits full of binary data. Git allows you specify a
> programs for binary --> text conversion for any file type, effectively
> teaching git how to diff binary files. If there was something out there
> developed to do this with .rds files, it would really like to know about it!
>
> I realize I could save the rds file with ascii=TRUE and compress=FALSE, but
> that kind of defeats the point of saving as .rds in the first place.
>
> If there is no tool out that there anyone knows of, I don't think it would
> be too hard for me to write something with bash + Rscript to get the job
> done, but I'd like to avoid re-inventing the wheel if possible.
>
> Thanks for the help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Nov 23 19:10:33 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 23 Nov 2015 18:10:33 +0000
Subject: [R] subset data using a vector
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56533BE0.8010906@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <56535699.6030500@dewey.myzen.co.uk>

Try looking at your function and work through what happens if the length 
is what I suggested.

 >>       x <- length(plot.id)
 >>
 >>       for (i in (1:x)) {
 >>
 >>           m2[i] <- m1[[i]]

So unless m1 has length at least x you are doomed.

On 23/11/2015 16:26, DIGHE, NILESH [AG/2362] wrote:
> Michael:  I like to use the actual range id's listed in column "rangestouse" to subset my data and not the length of that vector.
>
> Thanks.
> Nilesh
>
> -----Original Message-----
> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Sent: Monday, November 23, 2015 10:17 AM
> To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
> Subject: Re: [R] subset data using a vector
>
> length(strsplit(as.character(mydata$ranges2use), ","))
>
> was that what you expected? I think not.
>
> On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
>> Dear R users,
>>                   I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.
>>
>> I have created this function (fun1) but when I run it, I get the following error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Any help will be highly appreciated!
>> Thanks, Nilesh
>>
>> Dataset:
>> dput(mydata)
>> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor"),
>> cols = structure(c(1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
>> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
>> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
>> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
>> 5L, 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5", "6", "7",
>> "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
>>       plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
>>       290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
>>       374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
>>       379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
>>       399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
>>       480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
>>       477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
>>       4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
>>       5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
>>       5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
>>       5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
>>       5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
>>       ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
>>       "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>>       ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
>>       "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names = c("rows",
>> "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
>>
>> ), class = "data.frame", row.names = c(NA, -64L))
>>
>> Function:
>>
>> fun1<- function (dataset, plot.id, ranges2use, control)
>>
>> {
>>
>>       m1 <- strsplit(as.character(dataset$ranges2use), ",")
>>
>>       dat1 <- data.frame()
>>
>>       m2 <- c()
>>
>>       row_check_mean <- c()
>>
>>       row_check_adj_yield <- c()
>>
>>       x <- length(plot.id)
>>
>>       for (i in (1:x)) {
>>
>>           m2[i] <- m1[[i]]
>>
>>           dat1 <- dataset[dataset$ranges %in% m2[i], ]
>>
>>           row_check_mean[i] <- tapply(dat1$trait, dat1$control,
>>
>>               mean, na.rm = TRUE)[1]
>>
>>           row_check_adj_yield[i] <- ifelse(control[i] == "variety",
>>
>>               trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
>>
>>       }
>>
>>       data.frame(dataset, row_check_adj_yield)
>>
>> }
>>
>> Apply function:
>> fun1(mydata, plot.id=mydata$plotid, ranges2use =
>> mydata$rangestouse,control=mydata$linecode)
>>
>> Error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Session info:
>>
>> R version 3.2.1 (2015-06-18)
>>
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>>
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United States.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>>    [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1
>>
>>    [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
>>
>>
>> Nilesh Dighe
>> (806)-252-7492 (Cell)
>> (806)-741-2019 (Office)
>>
>>
>> This e-mail message may contain privileged and/or confidential
>> information, and is intended to be received only by persons entitled
>> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>>
>> All e-mails and attachments sent and received are subject to
>> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
>> Monsanto, along with its subsidiaries, accepts no liability for any
>> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>>
>>
>> The information contained in this email may be subject to the export
>> control laws and regulations of the United States, potentially
>> including but not limited to the Export Administration Regulations
>> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
> all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
> this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
> including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
> applicable U.S. export laws and regulations.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Mon Nov 23 19:33:51 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Nov 2015 10:33:51 -0800
Subject: [R] diff-ing .rds files
In-Reply-To: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
References: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
Message-ID: <A12132CF-D295-45FF-B64F-3AFA5BB9BBD2@dcn.davis.ca.us>

You are sending contradictory signals... do you or do you not want plain text files?  You have not indicated what advantage you are getting from having binary files in your repository. By far the best answer I see to your dilemma is to save in ASCII format instead of the default binary format. 

On November 23, 2015 9:36:21 AM PST, Will Hopper <wjhopper510 at gmail.com> wrote:
>Hi all,
>
>I'm posting to see if anyone knows of any existing resources that
>auto-magically converts r objects in saved in .rds files to a plain
>text
>representation, suitable for diffing?
>
>I often save the results of long running calculation as .rds files, and
>since I use git for source control, it would be nice if there were a
>way to
>convert rds files to a plain text representation for diffing, so I
>could
>avoid having large commits full of binary data. Git allows you specify
>a
>programs for binary --> text conversion for any file type, effectively
>teaching git how to diff binary files. If there was something out there
>developed to do this with .rds files, it would really like to know
>about it!
>
>I realize I could save the rds file with ascii=TRUE and compress=FALSE,
>but
>that kind of defeats the point of saving as .rds in the first place.
>
>If there is no tool out that there anyone knows of, I don't think it
>would
>be too hard for me to write something with bash + Rscript to get the
>job
>done, but I'd like to avoid re-inventing the wheel if possible.
>
>Thanks for the help!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.
	[[alternative HTML version deleted]]


From wjhopper510 at gmail.com  Mon Nov 23 21:18:57 2015
From: wjhopper510 at gmail.com (Will Hopper)
Date: Mon, 23 Nov 2015 15:18:57 -0500
Subject: [R] diff-ing .rds files
In-Reply-To: <A12132CF-D295-45FF-B64F-3AFA5BB9BBD2@dcn.davis.ca.us>
References: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
	<A12132CF-D295-45FF-B64F-3AFA5BB9BBD2@dcn.davis.ca.us>
Message-ID: <CAGTXQPu=VvLcd+7j89-pVYhehiHSqrMvhzGbFOXbk6BL+Wwdtw@mail.gmail.com>

Thanks for the input Jeff and Burt, and I could have been more clear about
what I was looking for.

You are of course right that there is nothing preventing me from using
plain text files, I initially went with compressed binary files because
they were, of course, smaller.

What I was curious about is if there was any existing
program/script/function/tool that converted an rds to plain text, so that I
could point git at it when creating the change set for a commit. For
example, there are programs that convert pdf documents to plain text, and
you can configure git to use these programs to convert the PDF's to plain
text before comparing the current version with the version in the last
commit, and then only add the things that have changes to the new commit.
This allows you to the track changes to a pdf file the same way you would a
text file, and your delta's don't blow up by committing the entire PDF file
each time you change part of the file.

It would be simple enough to write something like this with some
combination of a shell script and an R script to do this same thing for
.rds files, but I wondered if there was something out there already I was
overlooking.

I do see the point that I may be trying to compensate for a flawed premise,
perhaps I should not use a .rds file here if I'm concerned about the repo
getting too big as time goes on. I was just hoping to have my cake and eat
it too.

- Will

On Mon, Nov 23, 2015 at 1:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You are sending contradictory signals... do you or do you not want plain
> text files? You have not indicated what advantage you are getting from
> having binary files in your repository. By far the best answer I see to
> your dilemma is to save in ASCII format instead of the default binary
> format.
>
> On November 23, 2015 9:36:21 AM PST, Will Hopper <wjhopper510 at gmail.com>
> wrote:
>
>> Hi all,
>>
>> I'm posting to see if anyone knows of any existing resources that
>> auto-magically converts r objects in saved in .rds files to a plain text
>> representation, suitable for diffing?
>>
>> I often save the results of long running calculation as .rds files, and
>> since I use git for source control, it would be nice if there were a way to
>> convert rds files to a plain text representation for diffing, so I could
>> avoid having large commits full of binary data. Git allows you specify a
>> programs for binary --> text conversion for any file type, effectively
>> teaching git how to diff binary files. If there was something out there
>> developed to do this with .rds files, it would really like to know about it!
>>
>> I realize I could save the rds file with ascii=TRUE and compress=FALSE, but
>> that kind of defeats the point of saving as .rds in the first place.
>>
>> If there is no tool out that there anyone
>> knows of, I don't think it would
>> be too hard for me to write something with bash + Rscript to get the job
>> done, but I'd like to avoid re-inventing the wheel if possible.
>>
>> Thanks for the help!
>>
>>  [[alternative HTML version deleted]]
>>
>> ------------------------------
>>
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From tonightsthenight at gmail.com  Mon Nov 23 21:20:53 2015
From: tonightsthenight at gmail.com (Sam Albers)
Date: Mon, 23 Nov 2015 12:20:53 -0800
Subject: [R] Extract an number from a character
Message-ID: <CADkXsV09Jnkhzmb0r_AGLu2-2EaiJTpKBEkOtRWokjB9vU+5sg@mail.gmail.com>

Hello,

I have a problem to which I am certain grep or gsub or that family of
functions are the solution. However, I just can't seem to wrap my mind
around exactly how. I have a dataframe below that has the dimensions
of a net. I am given the data is the "W X H" format. For calculations
I'll like to have each number as a separated column. I have been using
ifelse(). However that seems like a poor solution to this problem
especially once dataframes get larger and larger.

So my question is, can anyone describe a way to extract the number
from the variable y below is the example? I had also tried substr()
but that fall apart with the 2.5 x 2.5 net.


Thanks in advance!

Sam

Example:
##dataframe
df<-data.frame(x=rnorm(10),
               y=c("7 x 3","7 x 3","7 x 3","7 x 3","7 x 3","2.5 x
2.5","2.5 x 2.5","2.5 x 2.5","2.5 x 2.5","2.5 x 2.5"))


df$Width<-as.numeric(ifelse(df$y=="7 x 3","7","2.5"))
df$Height<-as.numeric(ifelse(df$y=="7 x 3","3","2.5"))


df$Width<-as.numeric(substr(df$y,5,5))
df$Width<-as.numeric(substr(df$y,5,5))


From r at catwhisker.org  Mon Nov 23 21:30:59 2015
From: r at catwhisker.org (David Wolfskill)
Date: Mon, 23 Nov 2015 12:30:59 -0800
Subject: [R] Extract an number from a character
In-Reply-To: <CADkXsV09Jnkhzmb0r_AGLu2-2EaiJTpKBEkOtRWokjB9vU+5sg@mail.gmail.com>
References: <CADkXsV09Jnkhzmb0r_AGLu2-2EaiJTpKBEkOtRWokjB9vU+5sg@mail.gmail.com>
Message-ID: <20151123203059.GR1119@albert.catwhisker.org>

On Mon, Nov 23, 2015 at 12:20:53PM -0800, Sam Albers wrote:
> Hello,
> 
> I have a problem to which I am certain grep or gsub or that family of
> functions are the solution. However, I just can't seem to wrap my mind
> around exactly how. I have a dataframe below that has the dimensions
> of a net. I am given the data is the "W X H" format. For calculations
> I'll like to have each number as a separated column. I have been using
> ifelse(). However that seems like a poor solution to this problem
> especially once dataframes get larger and larger.
> 
> So my question is, can anyone describe a way to extract the number
> from the variable y below is the example? I had also tried substr()
> but that fall apart with the 2.5 x 2.5 net.
> 
> 
> Thanks in advance!
> 
> Sam
> 
> Example:
> ##dataframe
> df<-data.frame(x=rnorm(10),
>                y=c("7 x 3","7 x 3","7 x 3","7 x 3","7 x 3","2.5 x
> 2.5","2.5 x 2.5","2.5 x 2.5","2.5 x 2.5","2.5 x 2.5"))
> 
> 
> df$Width<-as.numeric(ifelse(df$y=="7 x 3","7","2.5"))
> df$Height<-as.numeric(ifelse(df$y=="7 x 3","3","2.5"))
> 
> 
> df$Width<-as.numeric(substr(df$y,5,5))
> df$Width<-as.numeric(substr(df$y,5,5))
> ....

Something like:

> df$Height <- as.numeric(sub(' x .*$', '', df$y))
> df$Width <- as.numeric(sub('^.* x ', '', df$y))
> df
            x         y Height Width
1   1.2118958     7 x 3    7.0   3.0
2  -0.3911277     7 x 3    7.0   3.0
3  -0.8933737     7 x 3    7.0   3.0
4  -0.6537011     7 x 3    7.0   3.0
5   2.6182771     7 x 3    7.0   3.0
6   0.9622942 2.5 x 2.5    2.5   2.5
7   1.2858848 2.5 x 2.5    2.5   2.5
8   1.0431044 2.5 x 2.5    2.5   2.5
9  -1.4957406 2.5 x 2.5    2.5   2.5
10  2.1751108 2.5 x 2.5    2.5   2.5

seems promising.

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who would murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 949 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151123/b8b7047a/attachment.bin>

From wdunlap at tibco.com  Mon Nov 23 21:31:43 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 23 Nov 2015 12:31:43 -0800
Subject: [R] diff-ing .rds files
In-Reply-To: <CAGTXQPu=VvLcd+7j89-pVYhehiHSqrMvhzGbFOXbk6BL+Wwdtw@mail.gmail.com>
References: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
	<A12132CF-D295-45FF-B64F-3AFA5BB9BBD2@dcn.davis.ca.us>
	<CAGTXQPu=VvLcd+7j89-pVYhehiHSqrMvhzGbFOXbk6BL+Wwdtw@mail.gmail.com>
Message-ID: <CAF8bMcbBNa-eE7ZOHqqJiAgd7Ugr+kZtu-Wm+0e_9jm8RGxNnw@mail.gmail.com>

Your any-RDS-to-ASCII-converter could be the R function
   toASCIIRDS <- function (fromRDS, toRDS)
   {
      saveRDS(readRDS(fromRDS), file = toRDS, ascii = TRUE, compress = FALSE)
   }
which you  can call from Rscript with appropriate input and output file names.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Nov 23, 2015 at 12:18 PM, Will Hopper <wjhopper510 at gmail.com> wrote:
> Thanks for the input Jeff and Burt, and I could have been more clear about
> what I was looking for.
>
> You are of course right that there is nothing preventing me from using
> plain text files, I initially went with compressed binary files because
> they were, of course, smaller.
>
> What I was curious about is if there was any existing
> program/script/function/tool that converted an rds to plain text, so that I
> could point git at it when creating the change set for a commit. For
> example, there are programs that convert pdf documents to plain text, and
> you can configure git to use these programs to convert the PDF's to plain
> text before comparing the current version with the version in the last
> commit, and then only add the things that have changes to the new commit.
> This allows you to the track changes to a pdf file the same way you would a
> text file, and your delta's don't blow up by committing the entire PDF file
> each time you change part of the file.
>
> It would be simple enough to write something like this with some
> combination of a shell script and an R script to do this same thing for
> .rds files, but I wondered if there was something out there already I was
> overlooking.
>
> I do see the point that I may be trying to compensate for a flawed premise,
> perhaps I should not use a .rds file here if I'm concerned about the repo
> getting too big as time goes on. I was just hoping to have my cake and eat
> it too.
>
> - Will
>
> On Mon, Nov 23, 2015 at 1:33 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
>> You are sending contradictory signals... do you or do you not want plain
>> text files? You have not indicated what advantage you are getting from
>> having binary files in your repository. By far the best answer I see to
>> your dilemma is to save in ASCII format instead of the default binary
>> format.
>>
>> On November 23, 2015 9:36:21 AM PST, Will Hopper <wjhopper510 at gmail.com>
>> wrote:
>>
>>> Hi all,
>>>
>>> I'm posting to see if anyone knows of any existing resources that
>>> auto-magically converts r objects in saved in .rds files to a plain text
>>> representation, suitable for diffing?
>>>
>>> I often save the results of long running calculation as .rds files, and
>>> since I use git for source control, it would be nice if there were a way to
>>> convert rds files to a plain text representation for diffing, so I could
>>> avoid having large commits full of binary data. Git allows you specify a
>>> programs for binary --> text conversion for any file type, effectively
>>> teaching git how to diff binary files. If there was something out there
>>> developed to do this with .rds files, it would really like to know about it!
>>>
>>> I realize I could save the rds file with ascii=TRUE and compress=FALSE, but
>>> that kind of defeats the point of saving as .rds in the first place.
>>>
>>> If there is no tool out that there anyone
>>> knows of, I don't think it would
>>> be too hard for me to write something with bash + Rscript to get the job
>>> done, but I'd like to avoid re-inventing the wheel if possible.
>>>
>>> Thanks for the help!
>>>
>>>  [[alternative HTML version deleted]]
>>>
>>> ------------------------------
>>>
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjhopper510 at gmail.com  Mon Nov 23 21:40:40 2015
From: wjhopper510 at gmail.com (Will Hopper)
Date: Mon, 23 Nov 2015 15:40:40 -0500
Subject: [R] diff-ing .rds files
In-Reply-To: <CAF8bMcbBNa-eE7ZOHqqJiAgd7Ugr+kZtu-Wm+0e_9jm8RGxNnw@mail.gmail.com>
References: <CAGTXQPs8mmoUuCQPoLNaTEWFEtXXWuGz2D9O3MgVV69zArULog@mail.gmail.com>
	<A12132CF-D295-45FF-B64F-3AFA5BB9BBD2@dcn.davis.ca.us>
	<CAGTXQPu=VvLcd+7j89-pVYhehiHSqrMvhzGbFOXbk6BL+Wwdtw@mail.gmail.com>
	<CAF8bMcbBNa-eE7ZOHqqJiAgd7Ugr+kZtu-Wm+0e_9jm8RGxNnw@mail.gmail.com>
Message-ID: <CAGTXQPsb5xQpB8biHRTXBKu=axG-ncQn+BzgzP0L28myZai9Mg@mail.gmail.com>

I was envisioning something involving write.csv(), but this is a better
idea, thanks!

On Mon, Nov 23, 2015 at 3:31 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Your any-RDS-to-ASCII-converter could be the R function
>    toASCIIRDS <- function (fromRDS, toRDS)
>    {
>       saveRDS(readRDS(fromRDS), file = toRDS, ascii = TRUE, compress =
> FALSE)
>    }
> which you  can call from Rscript with appropriate input and output file
> names.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Nov 23, 2015 at 12:18 PM, Will Hopper <wjhopper510 at gmail.com>
> wrote:
> > Thanks for the input Jeff and Burt, and I could have been more clear
> about
> > what I was looking for.
> >
> > You are of course right that there is nothing preventing me from using
> > plain text files, I initially went with compressed binary files because
> > they were, of course, smaller.
> >
> > What I was curious about is if there was any existing
> > program/script/function/tool that converted an rds to plain text, so
> that I
> > could point git at it when creating the change set for a commit. For
> > example, there are programs that convert pdf documents to plain text, and
> > you can configure git to use these programs to convert the PDF's to plain
> > text before comparing the current version with the version in the last
> > commit, and then only add the things that have changes to the new commit.
> > This allows you to the track changes to a pdf file the same way you
> would a
> > text file, and your delta's don't blow up by committing the entire PDF
> file
> > each time you change part of the file.
> >
> > It would be simple enough to write something like this with some
> > combination of a shell script and an R script to do this same thing for
> > .rds files, but I wondered if there was something out there already I was
> > overlooking.
> >
> > I do see the point that I may be trying to compensate for a flawed
> premise,
> > perhaps I should not use a .rds file here if I'm concerned about the repo
> > getting too big as time goes on. I was just hoping to have my cake and
> eat
> > it too.
> >
> > - Will
> >
> > On Mon, Nov 23, 2015 at 1:33 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us>
> > wrote:
> >
> >> You are sending contradictory signals... do you or do you not want plain
> >> text files? You have not indicated what advantage you are getting from
> >> having binary files in your repository. By far the best answer I see to
> >> your dilemma is to save in ASCII format instead of the default binary
> >> format.
> >>
> >> On November 23, 2015 9:36:21 AM PST, Will Hopper <wjhopper510 at gmail.com
> >
> >> wrote:
> >>
> >>> Hi all,
> >>>
> >>> I'm posting to see if anyone knows of any existing resources that
> >>> auto-magically converts r objects in saved in .rds files to a plain
> text
> >>> representation, suitable for diffing?
> >>>
> >>> I often save the results of long running calculation as .rds files, and
> >>> since I use git for source control, it would be nice if there were a
> way to
> >>> convert rds files to a plain text representation for diffing, so I
> could
> >>> avoid having large commits full of binary data. Git allows you specify
> a
> >>> programs for binary --> text conversion for any file type, effectively
> >>> teaching git how to diff binary files. If there was something out there
> >>> developed to do this with .rds files, it would really like to know
> about it!
> >>>
> >>> I realize I could save the rds file with ascii=TRUE and
> compress=FALSE, but
> >>> that kind of defeats the point of saving as .rds in the first place.
> >>>
> >>> If there is no tool out that there anyone
> >>> knows of, I don't think it would
> >>> be too hard for me to write something with bash + Rscript to get the
> job
> >>> done, but I'd like to avoid re-inventing the wheel if possible.
> >>>
> >>> Thanks for the help!
> >>>
> >>>  [[alternative HTML version deleted]]
> >>>
> >>> ------------------------------
> >>>
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >> Sent from my Android device with K-9 Mail. Please excuse my brevity.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From A.Robinson at ms.unimelb.edu.au  Mon Nov 23 21:50:56 2015
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Tue, 24 Nov 2015 07:50:56 +1100
Subject: [R] Question about lme syntax
In-Reply-To: <302322655.518151448273953640.JavaMail.defaultUser@defaultHost>
References: <302322655.518151448273953640.JavaMail.defaultUser@defaultHost>
Message-ID: <CAHyGmd43HK66vxR0XhzrgydiVCQzSXgZEQKjWR=Q8FrxAzmLsQ@mail.gmail.com>

Hi Angelo,

it's dangerous to fit a model that includes interaction effects but omits
main effects.  Among other things, what can happen is that the statistical
tests become scale dependent, which is most unattractive.

I think that you should include the main effects in your model, even as
nuisance variables, and test the interaction using the model that includes
them.

BTW, your question might better be located with the mixed-effects models
special interest group.

https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Best wishes

Andrew

On Mon, Nov 23, 2015 at 9:19 PM, angelo.arcadi at virgilio.it <
angelo.arcadi at virgilio.it> wrote:

> Dear list,
> I need an help to understand the syntax of lme to fit my model according
> to the analysis I want to perform.
>
> My dependent variable resulted from a perceptual experiment in which
> responses of participants were measured twice for each provided stimulus.
> My goal is to verify whether the responses depend on two properties of the
> participants that I know to be related to each other (height and weight, so
> they need to be considered together as an interaction). More importantly, I
> need to understand how this relationship modulates according to the type of
> stimulus participants were presented to.
>
> Based on my understanding of lme syntax, the formula I have to use should
> be the following (because I am only interested in the interaction factor of
> Weight and Height)
>
> lme_dv <- lme(dv ~ Weight:Height:Stimulus_Type, data = scrd, random = ~ 1
> | Subject)
>
> Am I correct?
>
>
> Thank you in advance
>
> Best regards
>
> Angelo
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader & Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344
4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au
Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/

	[[alternative HTML version deleted]]


From sdurier.stat at gmail.com  Mon Nov 23 21:59:57 2015
From: sdurier.stat at gmail.com (=?UTF-8?Q?S=c3=a9bastien_Durier?=)
Date: Mon, 23 Nov 2015 21:59:57 +0100
Subject: [R] summarize_ (NSE) in combination with quantile not working
In-Reply-To: <8B21B306-853C-4039-85EB-23E936128616@dcn.davis.ca.us>
References: <5650FF3C.70902@byland.info>
	<8B21B306-853C-4039-85EB-23E936128616@dcn.davis.ca.us>
Message-ID: <56537E4D.80808@gmail.com>

Hello,

A more explicit response can be found in :
https://cran.r-project.org/web/packages/lazyeval/vignettes/lazyeval.html
where it is explained that :
"quoted called and strings don?t have environments associated with them, 
so as.lazy() defaults to using baseenv(). This will work if the 
expression is self-contained (i.e. doesn?t contain any references to 
variables in the local environment), and will otherwise fail quickly and 
robustly."
So summarise_ seems to work with "min" because this function is in the 
base package, but not with "quantile" which is in the stats package.
A solution using strings could be :
summarise_(mtcars, "stats::quantile(mpg, 0.1)")

SD

On 22/11/2015 03:15, Jeff Newmiller wrote:
> Please post using plain text. The following works.
>
> mutate %>% summarise_( ~quantile( mpg, 0.1 ) )
>
> Read the vignette on nse that comes with dplyr,  or Google the error message.
>
> On November 21, 2015 3:33:16 PM PST, Tobias Byland <tobias at byland.info> wrote:
>> Hi everyone,
>>
>> I am stumbling over the following issue when using the NSE
>> (non-standard
>> evaluation) of the summarise function in dpylr (as described here:
>> https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html):
>>
>> mtcars  %>% summarise(min(mpg))      # summarize and min
>> mtcars  %>% summarise_("min(mpg)")   # summarize_ and min
>> mtcars  %>% summarise(quantile(mpg, 0.1))   # summarize and quantile
>> mtcars  %>% summarise_("quantile(mpg, 0.1)")   # summarize_ and
>> quantile  -> ERROR
>>
>> The last (and only the last) call results in the following error:
>>
>> Error: could not find function "quantile"
>>
>>
>> It seems to me, that the combination of summarise_ and quantile()
>> somehow doesn't work.
>>
>> Does anyone have an idea what the issue here is?
>>
>> Thanks a lot!
>>
>> Regards
>> Tobi
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From angelo.arcadi at virgilio.it  Mon Nov 23 23:19:22 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Mon, 23 Nov 2015 23:19:22 +0100 (CET)
Subject: [R] R: Re:  Question about lme syntax
Message-ID: <902636199.657391448317162289.JavaMail.defaultUser@defaultHost>

Dear Prof. Andrew Robinson,
I am very grateful to you for your enlightening answer

All the best

Angelo





----Messaggio originale----

Da: A.Robinson at ms.unimelb.edu.au

Data: 23-nov-2015 20.50

A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>

Cc: "R help (r-help at r-project.org)"<r-help at r-project.org>

Ogg: Re: [R] Question about lme syntax



Hi Angelo,
it's dangerous to fit a model that includes interaction effects but omits main effects.  Among other things, what can happen is that the statistical tests become scale dependent, which is most unattractive.  
I think that you should include the main effects in your model, even as nuisance variables, and test the interaction using the model that includes them.
BTW, your question might better be located with the mixed-effects models special interest group. 
https://stat.ethz.ch/mailman/listinfo/r-sig-mixed-models

Best wishes
Andrew
On Mon, Nov 23, 2015 at 9:19 PM, angelo.arcadi at virgilio.it <angelo.arcadi at virgilio.it> wrote:
Dear list,

I need an help to understand the syntax of lme to fit my model according to the analysis I want to perform.



My dependent variable resulted from a perceptual experiment in which responses of participants were measured twice for each provided stimulus. My goal is to verify whether the responses depend on two properties of the participants that I know to be related to each other (height and weight, so they need to be considered together as an interaction). More importantly, I need to understand how this relationship modulates according to the type of stimulus participants were presented to.



Based on my understanding of lme syntax, the formula I have to use should be the following (because I am only interested in the interaction factor of Weight and Height)



lme_dv <- lme(dv ~ Weight:Height:Stimulus_Type, data = scrd, random = ~ 1 | Subject)



Am I correct?





Thank you in advance



Best regards



Angelo







        [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.



-- 
Andrew Robinson
Deputy Director, CEBRA, School of Biosciences
Reader &amp; Associate Professor in Applied Statistics  Tel: (+61) 0403 138 955
School of Mathematics and Statistics                        Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au/~andrewpr

MSME: http://www.crcpress.com/product/isbn/9781439858028
FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/






	[[alternative HTML version deleted]]


From tobias at byland.info  Mon Nov 23 23:15:08 2015
From: tobias at byland.info (Tobias Byland)
Date: Mon, 23 Nov 2015 23:15:08 +0100
Subject: [R] summarize_ (NSE) in combination with quantile not working
In-Reply-To: <56537E4D.80808@gmail.com>
References: <5650FF3C.70902@byland.info>
	<8B21B306-853C-4039-85EB-23E936128616@dcn.davis.ca.us>
	<56537E4D.80808@gmail.com>
Message-ID: <56538FEC.4040502@byland.info>


Hi SD,

thanks, that was exactly what I was looking for!
Much appreciated :)

Regards,
Tobi

On 11/23/2015 9:59 PM, S?bastien Durier wrote:
> Hello,
>
> A more explicit response can be found in :
> https://cran.r-project.org/web/packages/lazyeval/vignettes/lazyeval.html
> where it is explained that :
> "quoted called and strings don?t have environments associated with 
> them, so as.lazy() defaults to using baseenv(). This will work if the 
> expression is self-contained (i.e. doesn?t contain any references to 
> variables in the local environment), and will otherwise fail quickly 
> and robustly."
> So summarise_ seems to work with "min" because this function is in the 
> base package, but not with "quantile" which is in the stats package.
> A solution using strings could be :
> summarise_(mtcars, "stats::quantile(mpg, 0.1)")
>
> SD
>
> On 22/11/2015 03:15, Jeff Newmiller wrote:
>> Please post using plain text. The following works.
>>
>> mutate %>% summarise_( ~quantile( mpg, 0.1 ) )
>>
>> Read the vignette on nse that comes with dplyr,  or Google the error 
>> message.
>>
>> On November 21, 2015 3:33:16 PM PST, Tobias Byland 
>> <tobias at byland.info> wrote:
>>> Hi everyone,
>>>
>>> I am stumbling over the following issue when using the NSE
>>> (non-standard
>>> evaluation) of the summarise function in dpylr (as described here:
>>> https://cran.r-project.org/web/packages/dplyr/vignettes/nse.html):
>>>
>>> mtcars  %>% summarise(min(mpg))      # summarize and min
>>> mtcars  %>% summarise_("min(mpg)")   # summarize_ and min
>>> mtcars  %>% summarise(quantile(mpg, 0.1))   # summarize and quantile
>>> mtcars  %>% summarise_("quantile(mpg, 0.1)")   # summarize_ and
>>> quantile  -> ERROR
>>>
>>> The last (and only the last) call results in the following error:
>>>
>>> Error: could not find function "quantile"
>>>
>>>
>>> It seems to me, that the combination of summarise_ and quantile()
>>> somehow doesn't work.
>>>
>>> Does anyone have an idea what the issue here is?
>>>
>>> Thanks a lot!
>>>
>>> Regards
>>> Tobi
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From sheroukmoawad at yahoo.com  Tue Nov 24 00:05:44 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Mon, 23 Nov 2015 23:05:44 +0000 (UTC)
Subject: [R] how to write this summation n R
References: <1746463210.7780068.1448319944215.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1746463210.7780068.1448319944215.JavaMail.yahoo@mail.yahoo.com>

Dear R experts do you have any idea about how this equation can be written in R??

From nilesh.dighe at monsanto.com  Tue Nov 24 00:10:07 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Mon, 23 Nov 2015 23:10:07 +0000
Subject: [R] subset data using a vector
In-Reply-To: <56535699.6030500@dewey.myzen.co.uk>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56533BE0.8010906@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56535699.6030500@dewey.myzen.co.uk>
Message-ID: <24156952D190E841BF8E66CB59FAB94A486A2430@STLWEXMBXPRD14.na.ds.monsanto.com>

Michael:  I tried using your suggestion of using length and still get the same error:
Error in m1[[i]] : subscript out of bounds

I also checked the length of m1 and x and they both are of same length (64).

After trying several things, I was able to extract the list but this was done outside the function I am trying to create.
Code that worked is listed below:

for(i in (1:length(mydata$plotid))){
        v1<-as.numeric(strsplit(as.character(mydata$rangestouse), ",")[[i]])
        print(head(v1))}

However, when I try to get this code in a function (fun3) listed below, I get the following error:
Error in strsplit(as.character(dataset$ranges2use), ",")[[i]] : 
  subscript out of bounds

fun3<- function (dataset, plot.id, ranges2use, control) 
{
    m1 <- c()
    x <- length(plot.id)
    for (i in (1:x)) {
        m1 <- as.numeric(strsplit(as.character(dataset$ranges2use), 
            ",")[[i]])
    }
    m2
}

I am not sure where I am making a mistake.
Thanks.
Nilesh
 
-----Original Message-----
From: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Sent: Monday, November 23, 2015 12:11 PM
To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
Subject: Re: [R] subset data using a vector

Try looking at your function and work through what happens if the length is what I suggested.

 >>       x <- length(plot.id)
 >>
 >>       for (i in (1:x)) {
 >>
 >>           m2[i] <- m1[[i]]

So unless m1 has length at least x you are doomed.

On 23/11/2015 16:26, DIGHE, NILESH [AG/2362] wrote:
> Michael:  I like to use the actual range id's listed in column "rangestouse" to subset my data and not the length of that vector.
>
> Thanks.
> Nilesh
>
> -----Original Message-----
> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Sent: Monday, November 23, 2015 10:17 AM
> To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
> Subject: Re: [R] subset data using a vector
>
> length(strsplit(as.character(mydata$ranges2use), ","))
>
> was that what you expected? I think not.
>
> On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
>> Dear R users,
>>                   I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.
>>
>> I have created this function (fun1) but when I run it, I get the following error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Any help will be highly appreciated!
>> Thanks, Nilesh
>>
>> Dataset:
>> dput(mydata)
>> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
>> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
>> 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor"), 
>> cols = structure(c(1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L, 
>> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 
>> 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 
>> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
>> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5", 
>> "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
>>       plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
>>       290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
>>       374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
>>       379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
>>       399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
>>       480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
>>       477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
>>       4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
>>       5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
>>       5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
>>       5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
>>       5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
>>       ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
>>       "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>>       ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
>>       "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names = 
>> c("rows", "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
>>
>> ), class = "data.frame", row.names = c(NA, -64L))

>>
>> Function:
>>
>> fun1<- function (dataset, plot.id, ranges2use, control)
>>
>> {
>>
>>       m1 <- strsplit(as.character(dataset$ranges2use), ",")
>>
>>       dat1 <- data.frame()
>>
>>       m2 <- c()
>>
>>       row_check_mean <- c()
>>
>>       row_check_adj_yield <- c()
>>
>>       x <- length(plot.id)
>>
>>       for (i in (1:x)) {
>>
>>           m2[i] <- m1[[i]]
>>
>>           dat1 <- dataset[dataset$ranges %in% m2[i], ]
>>
>>           row_check_mean[i] <- tapply(dat1$trait, dat1$control,
>>
>>               mean, na.rm = TRUE)[1]
>>
>>           row_check_adj_yield[i] <- ifelse(control[i] == "variety",
>>
>>               trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
>>
>>       }
>>
>>       data.frame(dataset, row_check_adj_yield)
>>
>> }
>>
>> Apply function:
>> fun1(mydata, plot.id=mydata$plotid, ranges2use =
>> mydata$rangestouse,control=mydata$linecode)
>>
>> Error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Session info:
>>
>> R version 3.2.1 (2015-06-18)
>>
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>>
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United States.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>>    [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1
>>
>>    [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
>>
>>
>> Nilesh Dighe
>> (806)-252-7492 (Cell)
>> (806)-741-2019 (Office)
>>
>>
>> This e-mail message may contain privileged and/or confidential 
>> information, and is intended to be received only by persons entitled 
>> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>>
>> All e-mails and attachments sent and received are subject to 
>> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
>> Monsanto, along with its subsidiaries, accepts no liability for any 
>> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>>
>>
>> The information contained in this email may be subject to the export 
>> control laws and regulations of the United States, potentially 
>> including but not limited to the Export Administration Regulations
>> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> This e-mail message may contain privileged and/or confidential 
> information, and is intended to be received only by persons entitled 
> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to 
> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any 
> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export 
> control laws and regulations of the United States, potentially 
> including but not limited to the Export Administration Regulations 
> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html
This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.


From angelo.arcadi at virgilio.it  Tue Nov 24 00:58:59 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Tue, 24 Nov 2015 00:58:59 +0100 (CET)
Subject: [R] Is manova() correct for this analysis?
Message-ID: <365977731.661631448323139488.JavaMail.defaultUser@defaultHost>

Dear list members,
I have to perform the following analysis but I do not know which function in R 
must be used. My guess is to use manova().

During an experiment I presented participants with some sound stimuli and I asked them to 
modify two parameters of the sound (Centroid and Sound_Level_Peak) to reach a given 
experimental goal. The initial sounds (preset sounds) had a value for those two parameters. 
What I am interested in is whether participants' modifications of the two parameters of the 
sound stimuli resulted in values actually different from the initial values of the parameters
of the preset sounds.

To give an idea, some rows of my data set are the following:

> head(scrd) 
Stimulus_Type   Centroid        Sound_Level_Peak    Preset
Stimulus_A      1960.2          -20.963                           no
Stimulus_A      5317.2          -42.741                           no
.....
Stimulus_B      11256.0        -16.480                           no
Stimulus_B      9560.3          -19.682                           no
.....
.....
Stimulus_A      1900.2          -18.63                             yes
Stimulus_A      5617.6          -44.41                             yes
Stimulus_B      12056.0        -17.80                             yes
Stimulus_B      8960.5          -21.82                             yes


This is the analysis I performed with manova():

> fit <- manova(cbind(Centroid,Sound_Level_Peak)~ Stimulus_Type*Preset, data=scrd)
> summary(fit, test="Pillai")
                       Df  Pillai approx F num Df den Df  Pr(>F)    
Stimulus_Type          11 0.91888  106.629     22   2760 < 2e-16 ***
Preset                  1 0.00343    2.371      2   1379 0.09378 .  
Stimulus_Type:Preset   11 0.01155    0.729     22   2760 0.81348    
Residuals            1380                                           
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 

If I am not wrong, these results say that for each stimulus type there is no difference 
between the patterns of the two parameters in the preset and modified conditions.

Can anyone please tell me if I am correct or suggest how to perform in R such an analysis?

Thanks in advance

Best

Angelo

	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Tue Nov 24 01:04:50 2015
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Tue, 24 Nov 2015 08:04:50 +0800
Subject: [R] Ensure distribution of classes is the same as prior
 distribution in Cross Validation
Message-ID: <SNT152-W34E8076DF54DF72EC17F76DF060@phx.gbl>

In the caret train control function, is it possible to ensure Ensure distribution of classes is the same as prior distribution in the folds of cross
 validation? I know it can be done using create folds but was wondering if it is possible using train control?
 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Nov 24 01:09:20 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 23 Nov 2015 16:09:20 -0800
Subject: [R] how to write this summation n R
In-Reply-To: <1746463210.7780068.1448319944215.JavaMail.yahoo@mail.yahoo.com>
References: <1746463210.7780068.1448319944215.JavaMail.yahoo.ref@mail.yahoo.com>
	<1746463210.7780068.1448319944215.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <BFB61F40-A033-4361-905B-68CBA65ED00E@dcn.davis.ca.us>

You seem to have forgotten to show us any version of "this equation". You could link to a Web site that shows it,  or you could use LaTeX notation. 
-- 
Sent from my phone. Please excuse my brevity.

On November 23, 2015 3:05:44 PM PST, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
>Dear R experts do you have any idea about how this equation can be
>written in R??
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Nov 24 01:32:31 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 23 Nov 2015 16:32:31 -0800
Subject: [R] Is manova() correct for this analysis?
In-Reply-To: <365977731.661631448323139488.JavaMail.defaultUser@defaultHost>
References: <365977731.661631448323139488.JavaMail.defaultUser@defaultHost>
Message-ID: <CAGxFJbTLvYfGxURYKt8zh3UwiiqLJNQahdxooqBkFBxB4MkMRA@mail.gmail.com>

This list is about R programming. Yours is a statistical question.
Although there is certainly a nonempty intersection (and someone may
attempt a response), statistical questions are better directed to a
statistical list like stats.stackexchange.com.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Mon, Nov 23, 2015 at 3:58 PM, angelo.arcadi at virgilio.it
<angelo.arcadi at virgilio.it> wrote:
> Dear list members,
> I have to perform the following analysis but I do not know which function in R
> must be used. My guess is to use manova().
>
> During an experiment I presented participants with some sound stimuli and I asked them to
> modify two parameters of the sound (Centroid and Sound_Level_Peak) to reach a given
> experimental goal. The initial sounds (preset sounds) had a value for those two parameters.
> What I am interested in is whether participants' modifications of the two parameters of the
> sound stimuli resulted in values actually different from the initial values of the parameters
> of the preset sounds.
>
> To give an idea, some rows of my data set are the following:
>
>> head(scrd)
> Stimulus_Type   Centroid        Sound_Level_Peak    Preset
> Stimulus_A      1960.2          -20.963                           no
> Stimulus_A      5317.2          -42.741                           no
> .....
> Stimulus_B      11256.0        -16.480                           no
> Stimulus_B      9560.3          -19.682                           no
> .....
> .....
> Stimulus_A      1900.2          -18.63                             yes
> Stimulus_A      5617.6          -44.41                             yes
> Stimulus_B      12056.0        -17.80                             yes
> Stimulus_B      8960.5          -21.82                             yes
>
>
> This is the analysis I performed with manova():
>
>> fit <- manova(cbind(Centroid,Sound_Level_Peak)~ Stimulus_Type*Preset, data=scrd)
>> summary(fit, test="Pillai")
>                        Df  Pillai approx F num Df den Df  Pr(>F)
> Stimulus_Type          11 0.91888  106.629     22   2760 < 2e-16 ***
> Preset                  1 0.00343    2.371      2   1379 0.09378 .
> Stimulus_Type:Preset   11 0.01155    0.729     22   2760 0.81348
> Residuals            1380
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>
> If I am not wrong, these results say that for each stimulus type there is no difference
> between the patterns of the two parameters in the preset and modified conditions.
>
> Can anyone please tell me if I am correct or suggest how to perform in R such an analysis?
>
> Thanks in advance
>
> Best
>
> Angelo
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Nov 24 03:07:49 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 23 Nov 2015 21:07:49 -0500
Subject: [R] not allocate of vactor size
In-Reply-To: <414157001.9962368.1448306768037.JavaMail.yahoo@mail.yahoo.com>
References: <CAAxdm-7XrRYi8p4J4HKpX0kgpSW70aYH71Syk-efrwQu=ZnLZw@mail.gmail.com>
	<414157001.9962368.1448306768037.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAxdm-68MMhNx92oB+Zkx0Z3u6iXPJXqHNw5btFeHmKja5sj5g@mail.gmail.com>

?I am not sure how the 2GB file might expand when you read it into R.  I
would suggest that you take a portion, e.g., 500MB, and read it in and see
how large the resulting object is in R.  Continue and process this smaller
size to see how memory utilization changes.  This will provide information
as to how much memory you might need.

If you fail reading in a large file, start cutting it half to see what you
can get in and process.  Do you need all the columns that might be in the
data, or can you remove some?  Can you sample the data and perform the
calculation on that subset to get a rational answer.  Can you put the data
in a database (SQLite) and then pull in selected records more easily.
There are several other alternatives you might want to consider, but at
least find out what you can process on you available system and then you
might know what some of the options are.  Get access to a server with
32-64-128GB to see if you can process the data the way you want if you had
a larger system.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Nov 23, 2015 at 2:26 PM, Tamsila Parveen <tamsilap at yahoo.com> wrote:

> I already tried on windows to increase virtual memory, but it didn't work.
> Actually I want to analyze MD-Simulation trajectories through R and trying
> to generate cross correlation, PCA plotting graphs, but R didn't accept
> file of 2GB. Even though my system is of 4GB RAM.
>
>
>
> On Monday, 23 November 2015, 4:53, jim holtman <jholtman at gmail.com> wrote:
>
>
> My general rule of thumb is that I should have 3-4 times as much RAM as
> the largest object that I am working with.  So hopefully you have at least
> 4 GB of RAM on your system.  Also exactly what processing (packages,
> functions, algorithms, etc.) are you using.  So functions may create
> multiple copies, or they may create temporary objects bigger than the
> original.  So help us out and provide more information.  You might be able
> to add virtual memory, but this may slow down your process quite a bit with
> paging.  If you do go this direction, then learn how to use the performance
> monitoring tools on your system to see what is happening.?
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Nov 22, 2015 at 10:08 AM, Tamsila Parveen via R-help <
> r-help at r-project.org> wrote:
>
> Hello,           Is there anyone to help me out how can I resolve memory
> issue of R, when I want to analyze data of 1Gb file, R returns me Error:
> not allocate of vector size of 1.8 GB.I tried on linux as well as on
> windows with 64 bit system and using 64 bit R-3.2.2 version. So anyone who
> knows please guide me to resolve this issue
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Nov 24 09:53:23 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 24 Nov 2015 19:53:23 +1100
Subject: [R] subset data using a vector
In-Reply-To: <24156952D190E841BF8E66CB59FAB94A486A2430@STLWEXMBXPRD14.na.ds.monsanto.com>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56533BE0.8010906@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56535699.6030500@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A2430@STLWEXMBXPRD14.na.ds.monsanto.com>
Message-ID: <CA+8X3fWdJMdvpg182-vWonTmORcWDyBqdk92LNAYw29yAeuZJA@mail.gmail.com>

Hi Nilesh,
I simplified your code a bit:

fun1<-function (dataset, plot.id, ranges2use, control) {
 m1 <- strsplit(as.character(ranges2use), ",")
 dat1 <- data.frame()
 row_check_mean <- NA
 row_check_adj_yield <- NA
 x <- length(plot.id)
 for (i in 1:x) {
  cat(i,"\n")
  dat1 <- dataset[dataset$ranges %in% m1[[i]], ]
  row_check_mean[i] <- tapply(unlist(dat1$trait),unlist(dat1$control),
   mean, na.rm = TRUE)[1]
  row_check_adj_yield[i] <- ifelse(control[i] == "variety",
  trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
 }
 data.frame(dataset, row_check_adj_yield)
}

 and got it to run down to this line:

row_check_mean[i]<-tapply(dat1$trait,dat1$control,mean,na.rm=TRUE)[1]

which generates the error:

Error in split.default(X, group) : first argument must be a vector

As far as I can see, there is no element in "mydata" named "trait" and
"control" is not an element of the local variable "dat1". I can't get past
this, but perhaps it will help you to sort it out.

Jim


On Tue, Nov 24, 2015 at 10:10 AM, DIGHE, NILESH [AG/2362] <
nilesh.dighe at monsanto.com> wrote:

> Michael:  I tried using your suggestion of using length and still get the
> same error:
> Error in m1[[i]] : subscript out of bounds
>
> I also checked the length of m1 and x and they both are of same length
> (64).
>
> After trying several things, I was able to extract the list but this was
> done outside the function I am trying to create.
> Code that worked is listed below:
>
> for(i in (1:length(mydata$plotid))){
>         v1<-as.numeric(strsplit(as.character(mydata$rangestouse),
> ",")[[i]])
>         print(head(v1))}
>
> However, when I try to get this code in a function (fun3) listed below, I
> get the following error:
> Error in strsplit(as.character(dataset$ranges2use), ",")[[i]] :
>   subscript out of bounds
>
> fun3<- function (dataset, plot.id, ranges2use, control)
> {
>     m1 <- c()
>     x <- length(plot.id)
>     for (i in (1:x)) {
>         m1 <- as.numeric(strsplit(as.character(dataset$ranges2use),
>             ",")[[i]])
>     }
>     m2
> }
>
> I am not sure where I am making a mistake.
> Thanks.
> Nilesh
>
> -----Original Message-----
> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Sent: Monday, November 23, 2015 12:11 PM
> To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
> Subject: Re: [R] subset data using a vector
>
> Try looking at your function and work through what happens if the length
> is what I suggested.
>
>  >>       x <- length(plot.id)
>  >>
>  >>       for (i in (1:x)) {
>  >>
>  >>           m2[i] <- m1[[i]]
>
> So unless m1 has length at least x you are doomed.
>
> On 23/11/2015 16:26, DIGHE, NILESH [AG/2362] wrote:
> > Michael:  I like to use the actual range id's listed in column
> "rangestouse" to subset my data and not the length of that vector.
> >
> > Thanks.
> > Nilesh
> >
> > -----Original Message-----
> > From: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> > Sent: Monday, November 23, 2015 10:17 AM
> > To: DIGHE, NILESH [AG/2362]; r-help at r-project.org
> > Subject: Re: [R] subset data using a vector
> >
> > length(strsplit(as.character(mydata$ranges2use), ","))
> >
> > was that what you expected? I think not.
> >
> > On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
> >> Dear R users,
> >>                   I like to split my data by a vector created by using
> variable "ranges".  This vector will have the current range (ranges),
> preceding range (ranges - 1), and post range (ranges + 1) for a given
> plotid.  If the preceding or post ranges in this vector are outside the
> levels of ranges in the data set then I like to drop those ranges and only
> include the ranges that are available.  Variable "rangestouse" includes all
> the desired ranges I like to subset a given plotid.  After I subset these
> dataset using these desired ranges, then I like to extract the yield data
> for checks in those desired ranges and adjust yield of my data by dividing
> yield of a given plotid with the check average for the desired ranges.
> >>
> >> I have created this function (fun1) but when I run it, I get the
> following error:
> >>
> >> Error in m1[[i]] : subscript out of bounds
> >>
> >> Any help will be highly appreciated!
> >> Thanks, Nilesh
> >>
> >> Dataset:
> >> dput(mydata)
> >> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor"),
> >> cols = structure(c(1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
> >> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L,
> >> 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L,
> >> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> >> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5",
> >> "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16"), class =
> "factor"),
> >>       plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
> >>       290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
> >>       374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
> >>       379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
> >>       399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
> >>       480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
> >>       477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
> >>       4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
> >>       5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
> >>       5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
> >>       5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
> >>       5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
> >>       ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
> >>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>       1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>       2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
> >>       "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
> >>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
> >>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
> >>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
> >>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
> >>       ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
> >>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> >>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
> >>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
> >>       "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names =
> >> c("rows", "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
> >>
> >> ), class = "data.frame", row.names = c(NA, -64L))
>
> >>
> >> Function:
> >>
> >> fun1<- function (dataset, plot.id, ranges2use, control)
> >>
> >> {
> >>
> >>       m1 <- strsplit(as.character(dataset$ranges2use), ",")
> >>
> >>       dat1 <- data.frame()
> >>
> >>       m2 <- c()
> >>
> >>       row_check_mean <- c()
> >>
> >>       row_check_adj_yield <- c()
> >>
> >>       x <- length(plot.id)
> >>
> >>       for (i in (1:x)) {
> >>
> >>           m2[i] <- m1[[i]]
> >>
> >>           dat1 <- dataset[dataset$ranges %in% m2[i], ]
> >>
> >>           row_check_mean[i] <- tapply(dat1$trait, dat1$control,
> >>
> >>               mean, na.rm = TRUE)[1]
> >>
> >>           row_check_adj_yield[i] <- ifelse(control[i] == "variety",
> >>
> >>               trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
> >>
> >>       }
> >>
> >>       data.frame(dataset, row_check_adj_yield)
> >>
> >> }
> >>
> >> Apply function:
> >> fun1(mydata, plot.id=mydata$plotid, ranges2use =
> >> mydata$rangestouse,control=mydata$linecode)
> >>
> >> Error:
> >>
> >> Error in m1[[i]] : subscript out of bounds
> >>
> >> Session info:
> >>
> >> R version 3.2.1 (2015-06-18)
> >>
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> Running under: Windows 7 x64 (build 7601) Service Pack 1
> >>
> >>
> >>
> >> locale:
> >>
> >> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >> States.1252
> >>
> >> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> >>
> >> [5] LC_TIME=English_United States.1252
> >>
> >>
> >>
> >> attached base packages:
> >>
> >> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>
> >>
> >>
> >> loaded via a namespace (and not attached):
> >>
> >>    [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1
> Rcpp_0.12.1     stringi_1.0-1
> >>
> >>    [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
> >>
> >>
> >> Nilesh Dighe
> >> (806)-252-7492 (Cell)
> >> (806)-741-2019 (Office)
> >>
> >>
> >> This e-mail message may contain privileged and/or confidential
> >> information, and is intended to be received only by persons entitled
> >> to receive such information. If you have received this e-mail in error,
> please notify the sender immediately. Please delete it and all attachments
> from any servers, hard drives or any other media. Other use of this e-mail
> by you is strictly prohibited.
> >>
> >> All e-mails and attachments sent and received are subject to
> >> monitoring, reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for
> checking for the presence of "Viruses" or other "Malware".
> >> Monsanto, along with its subsidiaries, accepts no liability for any
> >> damage caused by any such code transmitted by or accompanying this
> e-mail or any attachment.
> >>
> >>
> >> The information contained in this email may be subject to the export
> >> control laws and regulations of the United States, potentially
> >> including but not limited to the Export Administration Regulations
> >> (EAR) and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this
> information you are obligated to comply with all applicable U.S. export
> laws and regulations.
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > --
> > Michael
> > http://www.dewey.myzen.co.uk/home.html
> > This e-mail message may contain privileged and/or confidential
> > information, and is intended to be received only by persons entitled
> > to receive such information. If you have received this e-mail in error,
> please notify the sender immediately. Please delete it and all attachments
> from any servers, hard drives or any other media. Other use of this e-mail
> by you is strictly prohibited.
> >
> > All e-mails and attachments sent and received are subject to
> > monitoring, reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for
> checking for the presence of "Viruses" or other "Malware".
> > Monsanto, along with its subsidiaries, accepts no liability for any
> > damage caused by any such code transmitted by or accompanying this
> e-mail or any attachment.
> >
> >
> > The information contained in this email may be subject to the export
> > control laws and regulations of the United States, potentially
> > including but not limited to the Export Administration Regulations
> > (EAR) and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this
> information you are obligated to comply with all applicable U.S. export
> laws and regulations.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> This e-mail message may contain privileged and/or confidential
> information, and is intended to be received only by persons entitled
> to receive such information. If you have received this e-mail in error,
> please notify the sender immediately. Please delete it and
> all attachments from any servers, hard drives or any other media. Other
> use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to monitoring,
> reading and archival by Monsanto, including its
> subsidiaries. The recipient of this e-mail is solely responsible for
> checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any damage
> caused by any such code transmitted by or accompanying
> this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export
> control laws and regulations of the United States, potentially
> including but not limited to the Export Administration Regulations (EAR)
> and sanctions regulations issued by the U.S. Department of
> Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this
> information you are obligated to comply with all
> applicable U.S. export laws and regulations.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From alaios at yahoo.com  Tue Nov 24 12:38:02 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 24 Nov 2015 11:38:02 +0000 (UTC)
Subject: [R] improve my ggplot look
In-Reply-To: <CADv2QyFFt=8WSvy3QyqLbS7FadNhvcHmaxfhO9KuhKY5UqvbJA@mail.gmail.com>
References: <CADv2QyFFt=8WSvy3QyqLbS7FadNhvcHmaxfhO9KuhKY5UqvbJA@mail.gmail.com>
Message-ID: <470477382.7991926.1448365082613.JavaMail.yahoo@mail.yahoo.com>

Dear Dennis, it would be better if not plotting the lon and lat. Keeping it blank is better for the aesthetics of my map.
I am not sure how I can give a reproducible example herebut I want to  
 ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour=Divergence), data = PlotPoints, size =10)+
?scale_colour_gradient2(low=muted("red"),mid="green", high=muted("blue"),trans ="log")+geom_point(aes(Longitude,Latitude),size=15,data=stationaryPoint,colour="Red",shape="X",size=15)?log10(seq(1,20,length.out=100))
to make the color scale with fixed colors (0.3 for green for example) and increase it in size so the numbers in the bar are still visible when the figure is getting smaller in size
RegardsAlex

    On Friday, November 20, 2015 11:02 PM, Dennis Murphy <djmuser at gmail.com> wrote:
 

 Hi Alex:

The documentation for ggmap tells you that its x-y coordinates are
lat-long. What did you want to plot instead?

There are several theme options for legends, as well as a few more in
the guide_legend() function. As far as the color scale, you should be
able to set it with hex codes in each map.

Since there is no reproducible example with which to work, I can't
really help/comment much further. If you come up with one, please post
it back to the group so that others can see it. Some of them have more
experience with mapping in ggplot2 than I do.

Dennis

On Thu, Nov 19, 2015 at 8:45 PM, Alaios <alaios at yahoo.com> wrote:
> dear Dennis,
> thanks for your answers.
> I have changed my code to look like
>
>? ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour
> =Divergence), data = PlotPoints, size =10)+
> scale_colour_gradient2(low=muted("red"),mid="green",
> high=muted("blue"),trans =
> "log")+geom_point(aes(Longitude,Latitude),size=15,data=stationaryPoint,colour="Red",shape="X",size=15)#
> log10(seq(1,20,length.out=100))
>
>
> current issues:
> -ggmap : plots the coordinates (longitudes and latitudes like x and y
> labels), which I do not want to do
> -Increase font size in the color bar
> -the color scale as it is now is totally fine, it is more that I want to
> make the colors there fixed, since different maps have slightly different
> numbers printed there (not much but that hinders comparisons between the
> maps).
>
> I would like to thank you for your support
> Regards
> Alex
>
>
>
> On Thursday, November 19, 2015 7:13 PM, Dennis Murphy <djmuser at gmail.com>
> wrote:
>
>
> Let's try this again....sorry for hitting Send inadvertently.
>
> On Thu, Nov 19, 2015 at 5:09 AM, Alaios via R-help <r-help at r-project.org>
> wrote:
>> Dear all,the following line of code
>> print me a map of an area with the points I need. I only new two minor
>> adjustments
>>? ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour
>> =Error), data = PlotPoints, size = 6)+
>> scale_colour_gradient2(low=muted("red"),mid="green",
>> high=muted("blue"),trans =
>> "log")+geom_point(aes(Longitude,Latitude),data=stationaryPoint,colour="Red",shape="s",size=12)
>>
>> I want to specify my color ramp to have the specific scale
>> 0,000010,040,130,4
>
> You can specify the hex codes for colors in any of the scale_colour*()
> functions.
>>
>> I also want to plot in a way where the fonts will be binger and the
>> legends as well.Any ideas how I can do that?
>
> See ?theme.
>
> Dennis
>
>
>
>> I would like to thank you for your reply
>> RegardsAlex
>>
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Nov 24 13:32:24 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 24 Nov 2015 07:32:24 -0500
Subject: [R] RGL Problem
In-Reply-To: <21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
	<5652EF65.1050800@gmail.com>
	<21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>
Message-ID: <565458D8.4070403@gmail.com>

Some comments on the second part of your message.

On 23/11/2015 7:45 AM, Stefan Evert wrote:
>
>> On 23 Nov 2015, at 11:50, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>>   The OSX binary version of rgl on CRAN is ancient.  You'll need to reinstall it from source for a current one.
>
> Since you bring up this point: any chance of getting Mac binaries from CRAN again?  Rgl is a particularly nice tool because of its portability, and requiring users to install Xcode and Xquartz first makes life a lot harder for non-technical users.
>
> This is compounded by the fact that the automatic configuration is easily broken. I have been unable to install rgl from source for some time on Mavericks, and have now discovered that this was due to a HomeBrew-installed imake in /usr/local.
>
> Perhaps it would make sense always to use the well-known standard XQuartz paths on Mac and only consider other locations if explicitly asked for by the user?

If rgl is using non-standard features in its makefiles, let me know what 
they are.  I use GNU make, so it's easy for GNUisms to slip into it.

We already have special handling for X11 on the Mac.  I don't know why 
yours isn't working, but it's pretty well-known that homebrew breaks the 
usual R build system, so I'd blame it on that.  If you are using 
homebrew, you should be prepared to manually configure rgl.  Or you can 
send me a patch to rgl's configure.ac that works around the differences, 
and I'll try it out.

Duncan Murdoch


From ragland.debra at yahoo.com  Tue Nov 24 18:04:21 2015
From: ragland.debra at yahoo.com (debra ragland)
Date: Tue, 24 Nov 2015 17:04:21 +0000 (UTC)
Subject: [R] Probing a protein sequence alignment in R
References: <1971834029.10587897.1448384661990.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>

I have 15 protein sequences of 99 amino acids each. After doing some looking around I have found that there are several ways you can read sequences into R and do pairwise or multiple alignments. I, however, do not know how to probe changes at specific positions. For instance, I would like to know the best way to align a standard sequence with one(1) or several mutant sequences and probe each amino acid position that does not match the standard sequence. In other words seq1 = "standard amino acid seq" and seq2 = "mutant seq", align these 2 and then have a way to ask R to report whether there is a change at position 10, or 11, or 12 and so on such that R reports(for example) TRUE or FALSE for this question. Where all the sequences that have a reported TRUE for a change at position X can be grouped against those that do not have a change at this position.I'm not even sure that R is the best way to do this, but it's the only language I'm somewhat familiar with.I hope this makes sense. Any help will be appreciated.
	[[alternative HTML version deleted]]


From stefanML at collocations.de  Tue Nov 24 18:09:29 2015
From: stefanML at collocations.de (Stefan Evert)
Date: Tue, 24 Nov 2015 18:09:29 +0100
Subject: [R] RGL Problem
In-Reply-To: <565458D8.4070403@gmail.com>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
	<5652EF65.1050800@gmail.com>
	<21272108-9426-4C2A-A2EE-BE48ADE02E45@collocations.de>
	<565458D8.4070403@gmail.com>
Message-ID: <4AAEC66E-28B9-4CC6-B841-3819B9768BFA@collocations.de>


> On 24 Nov 2015, at 13:32, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> Perhaps it would make sense always to use the well-known standard XQuartz paths on Mac and only consider other locations if explicitly asked for by the user?
> 
> If rgl is using non-standard features in its makefiles, let me know what they are.  I use GNU make, so it's easy for GNUisms to slip into it.

I didn't have any problems with GNUisms ? I only use GNU make anyway.

> We already have special handling for X11 on the Mac.  I don't know why yours isn't working, but it's pretty well-known that homebrew breaks the usual R build system, so I'd blame it on that.

Yes, it turned out that I had a bogus xmkmf in /usr/local/bin, which I had inadvertently installed through homebrew. My fault.

>  If you are using homebrew, you should be prepared to manually configure rgl.  Or you can send me a patch to rgl's configure.ac that works around the differences, and I'll try it out.

My thought was to prefer the known standard location of XQuartz to any automatically discovered X11 configuration on Darwin, i.e. run a test for X headers and libs in this location first, before trying xmkmf.  I guess that normally someone who has xmkmf would want to use this configuration rather than the standard one, so let's quietly forget about this idea.

In case anybody else encounters a similar problem ? no X11 found even they know they've installed XQuartz ? the first thing you should do is to check "which xmkmf".  If you find one, it is likely to be the cause of the failure.

Best,
Stefan

From boris.steipe at utoronto.ca  Tue Nov 24 18:39:32 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 24 Nov 2015 12:39:32 -0500
Subject: [R] Probing a protein sequence alignment in R
In-Reply-To: <1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>
References: <1971834029.10587897.1448384661990.JavaMail.yahoo.ref@mail.yahoo.com>
	<1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <09D7C0B6-05C2-4627-A1AF-5DFF9F2740F1@utoronto.ca>

One way would be to use the biostrings and msa packages from bioconductor.

Use AAStringSet() to collect your sequences, and (e.g.) msaMuscle() to align them. Then use BStringset() to extract the subrange you need, and e.g. table to look at the distributions...

table(BStringSet(<output-of-msaMuscle>, start=50, width=1))

Working with Bioconductor S4 objects can be a bit salty, so mail again if you need more explicit sample code.

Cheers,
Boris


On Nov 24, 2015, at 12:04 PM, debra ragland via R-help <r-help at r-project.org> wrote:

> I have 15 protein sequences of 99 amino acids each. After doing some looking around I have found that there are several ways you can read sequences into R and do pairwise or multiple alignments. I, however, do not know how to probe changes at specific positions. For instance, I would like to know the best way to align a standard sequence with one(1) or several mutant sequences and probe each amino acid position that does not match the standard sequence. In other words seq1 = "standard amino acid seq" and seq2 = "mutant seq", align these 2 and then have a way to ask R to report whether there is a change at position 10, or 11, or 12 and so on such that R reports(for example) TRUE or FALSE for this question. Where all the sequences that have a reported TRUE for a change at position X can be grouped against those that do not have a change at this position.I'm not even sure that R is the best way to do this, but it's the only language I'm somewhat familiar with.I hope this makes !
> sense. Any help will be appreciated.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Nov 24 18:43:14 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 24 Nov 2015 09:43:14 -0800
Subject: [R] Probing a protein sequence alignment in R
In-Reply-To: <1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>
References: <1971834029.10587897.1448384661990.JavaMail.yahoo.ref@mail.yahoo.com>
	<1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbTWz-ks5JGzfx8S_a639fCopPy2UVfBh_WOt_cjTNs_Pw@mail.gmail.com>

Wrong list (mostly). You would do much better at the Bioconductor
list, https://support.bioconductor.org/

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 24, 2015 at 9:04 AM, debra ragland via R-help
<r-help at r-project.org> wrote:
> I have 15 protein sequences of 99 amino acids each. After doing some looking around I have found that there are several ways you can read sequences into R and do pairwise or multiple alignments. I, however, do not know how to probe changes at specific positions. For instance, I would like to know the best way to align a standard sequence with one(1) or several mutant sequences and probe each amino acid position that does not match the standard sequence. In other words seq1 = "standard amino acid seq" and seq2 = "mutant seq", align these 2 and then have a way to ask R to report whether there is a change at position 10, or 11, or 12 and so on such that R reports(for example) TRUE or FALSE for this question. Where all the sequences that have a reported TRUE for a change at position X can be grouped against those that do not have a change at this position.I'm not even sure that R is the best way to do this, but it's the only language I'm somewhat familiar with.I hope this makes !
>  sense. Any help will be appreciated.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Nov 24 19:06:09 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 24 Nov 2015 13:06:09 -0500
Subject: [R] Probing a protein sequence alignment in R
In-Reply-To: <CAGxFJbTWz-ks5JGzfx8S_a639fCopPy2UVfBh_WOt_cjTNs_Pw@mail.gmail.com>
References: <1971834029.10587897.1448384661990.JavaMail.yahoo.ref@mail.yahoo.com>
	<1971834029.10587897.1448384661990.JavaMail.yahoo@mail.yahoo.com>
	<CAGxFJbTWz-ks5JGzfx8S_a639fCopPy2UVfBh_WOt_cjTNs_Pw@mail.gmail.com>
Message-ID: <6679492C-C94F-46E2-BEC4-7B58AD97E87A@utoronto.ca>

Well ... that depends on what the best solution will turn out to be.

filling a matrix with the characters, or even substr() would be alternative "lightweight" appraoches.


B.


On Nov 24, 2015, at 12:43 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Wrong list (mostly). You would do much better at the Bioconductor
> list, https://support.bioconductor.org/
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Tue, Nov 24, 2015 at 9:04 AM, debra ragland via R-help
> <r-help at r-project.org> wrote:
>> I have 15 protein sequences of 99 amino acids each. After doing some looking around I have found that there are several ways you can read sequences into R and do pairwise or multiple alignments. I, however, do not know how to probe changes at specific positions. For instance, I would like to know the best way to align a standard sequence with one(1) or several mutant sequences and probe each amino acid position that does not match the standard sequence. In other words seq1 = "standard amino acid seq" and seq2 = "mutant seq", align these 2 and then have a way to ask R to report whether there is a change at position 10, or 11, or 12 and so on such that R reports(for example) TRUE or FALSE for this question. Where all the sequences that have a reported TRUE for a change at position X can be grouped against those that do not have a change at this position.I'm not even sure that R is the best way to do this, but it's the only language I'm somewhat familiar with.I hope this make!
> s !
>> sense. Any help will be appreciated.
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Tue Nov 24 18:39:01 2015
From: alaios at yahoo.com (Alaios)
Date: Tue, 24 Nov 2015 17:39:01 +0000 (UTC)
Subject: [R] improve my ggplot look
In-Reply-To: <470477382.7991926.1448365082613.JavaMail.yahoo@mail.yahoo.com>
References: <470477382.7991926.1448365082613.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1778856038.8140760.1448386741574.JavaMail.yahoo@mail.yahoo.com>

I am giving to the community two examples
My code currently look like:
breaks<-c(0,0.01,0.05,0.08,0.1,0.15,0.2,0.3,0.5,0.7,0.9,1)
ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour =Divergence), data = PlotPoints, size =10)+ 
scale_colour_gradientn(colours=rainbow(9),breaks=breaks)+
geom_point(aes(Longitude,Latitude),size=15,data=stationaryPoint,colour="Red",shape="X",size=15)
where I added the gradientn in attempt to specify specific limits with a specific color for a a given range.
I am attaching two examples where you would seethat the values on the colorramp are not the same. In the first case is the 0.20 that gets the purple number and in the second case the 1 (the latter is not printed in the color ramp....)
Can someone explain me in what small change Ineed here?
I would like to thank you for your replyRegardsAlex
 


    On Tuesday, November 24, 2015 12:43 PM, Alaios via R-help <r-help at r-project.org> wrote:
 

 Dear Dennis, it would be better if not plotting the lon and lat. Keeping it blank is better for the aesthetics of my map.
I am not sure how I can give a reproducible example herebut I want to? 
 ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour=Divergence), data = PlotPoints, size =10)+
?scale_colour_gradient2(low=muted("red"),mid="green", high=muted("blue"),trans ="log")+geom_point(aes(Longitude,Latitude),size=15,data=stationaryPoint,colour="Red",shape="X",size=15)?log10(seq(1,20,length.out=100))
to make the color scale with fixed colors (0.3 for green for example) and increase it in size so the numbers in the bar are still visible when the figure is getting smaller in size
RegardsAlex

? ? On Friday, November 20, 2015 11:02 PM, Dennis Murphy <djmuser at gmail.com> wrote:
 

 Hi Alex:

The documentation for ggmap tells you that its x-y coordinates are
lat-long. What did you want to plot instead?

There are several theme options for legends, as well as a few more in
the guide_legend() function. As far as the color scale, you should be
able to set it with hex codes in each map.

Since there is no reproducible example with which to work, I can't
really help/comment much further. If you come up with one, please post
it back to the group so that others can see it. Some of them have more
experience with mapping in ggplot2 than I do.

Dennis

On Thu, Nov 19, 2015 at 8:45 PM, Alaios <alaios at yahoo.com> wrote:
> dear Dennis,
> thanks for your answers.
> I have changed my code to look like
>
>? ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour
> =Divergence), data = PlotPoints, size =10)+
> scale_colour_gradient2(low=muted("red"),mid="green",
> high=muted("blue"),trans =
> "log")+geom_point(aes(Longitude,Latitude),size=15,data=stationaryPoint,colour="Red",shape="X",size=15)#
> log10(seq(1,20,length.out=100))
>
>
> current issues:
> -ggmap : plots the coordinates (longitudes and latitudes like x and y
> labels), which I do not want to do
> -Increase font size in the color bar
> -the color scale as it is now is totally fine, it is more that I want to
> make the colors there fixed, since different maps have slightly different
> numbers printed there (not much but that hinders comparisons between the
> maps).
>
> I would like to thank you for your support
> Regards
> Alex
>
>
>
> On Thursday, November 19, 2015 7:13 PM, Dennis Murphy <djmuser at gmail.com>
> wrote:
>
>
> Let's try this again....sorry for hitting Send inadvertently.
>
> On Thu, Nov 19, 2015 at 5:09 AM, Alaios via R-help <r-help at r-project.org>
> wrote:
>> Dear all,the following line of code
>> print me a map of an area with the points I need. I only new two minor
>> adjustments
>>? ? ggmap(mp, darken = 0) + geom_point(aes(Longitude, Latitude, colour
>> =Error), data = PlotPoints, size = 6)+
>> scale_colour_gradient2(low=muted("red"),mid="green",
>> high=muted("blue"),trans =
>> "log")+geom_point(aes(Longitude,Latitude),data=stationaryPoint,colour="Red",shape="s",size=12)
>>
>> I want to specify my color ramp to have the specific scale
>> 0,000010,040,130,4
>
> You can specify the hex codes for colors in any of the scale_colour*()
> functions.
>>
>> I also want to plot in a way where the fonts will be binger and the
>> legends as well.Any ideas how I can do that?
>
> See ?theme.
>
> Dennis
>
>
>
>> I would like to thank you for your reply
>> RegardsAlex
>>
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  

From r at timothylegg.com  Tue Nov 24 20:47:16 2015
From: r at timothylegg.com (Timothy D. Legg)
Date: Tue, 24 Nov 2015 14:47:16 -0500
Subject: [R] Plotting Example Fail
Message-ID: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>

Hello,

I am quite new to R and have high expectations for my future with it.

R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

I have stepped back to an earlier tutorial and found an odd inconsistency
with one of the examples:

plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
"rpois(100, lambda = 5)")

I read the local documentation on the plot command and it's arguments. 
>From that, I learned that 'main' defines the title from a text string.  I
decide to modify some values to see how the resulting behavior changes. 
What I didn't expect was that modifying the text string caused the chart
to change greatly.

plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
"rpois(100, lambda = 4)")

With the previous line, the columns change values.

plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main = "hello")

This line even adds a 12th column.

I return to plot the original and the output has changed again.   Here are
some screenshots

http://timothylegg.com/R/lambda5_.png
http://timothylegg.com/R/lambda5.png
http://timothylegg.com/R/lambda4.png
http://timothylegg.com/R/hello.png

What am I doing wrong to get inconsistent results like this?  I'm very new
to R and really hoping that this is a misunderstanding on my part.


From wdunlap at tibco.com  Tue Nov 24 20:58:29 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 24 Nov 2015 11:58:29 -0800
Subject: [R] Plotting Example Fail
In-Reply-To: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
References: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
Message-ID: <CAF8bMcZaLGBYVhK=bXZwE1gA3TR7=H27WFPpYiLWO7ebeaxULQ@mail.gmail.com>

rpois(100, 5) gives a different set of random numbers each time it is
called, so if you want repeatable results compute it once and use its
value in the calls to plot.  E.g.,
   r <- rpois(100, 5)
   plot(table(r), type="h", col="red", lwd=10, main="hello")
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Nov 24, 2015 at 11:47 AM, Timothy D. Legg <r at timothylegg.com> wrote:
> Hello,
>
> I am quite new to R and have high expectations for my future with it.
>
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> I have stepped back to an earlier tutorial and found an odd inconsistency
> with one of the examples:
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
> "rpois(100, lambda = 5)")
>
> I read the local documentation on the plot command and it's arguments.
> >From that, I learned that 'main' defines the title from a text string.  I
> decide to modify some values to see how the resulting behavior changes.
> What I didn't expect was that modifying the text string caused the chart
> to change greatly.
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
> "rpois(100, lambda = 4)")
>
> With the previous line, the columns change values.
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main = "hello")
>
> This line even adds a 12th column.
>
> I return to plot the original and the output has changed again.   Here are
> some screenshots
>
> http://timothylegg.com/R/lambda5_.png
> http://timothylegg.com/R/lambda5.png
> http://timothylegg.com/R/lambda4.png
> http://timothylegg.com/R/hello.png
>
> What am I doing wrong to get inconsistent results like this?  I'm very new
> to R and really hoping that this is a misunderstanding on my part.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Tue Nov 24 21:01:58 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 24 Nov 2015 15:01:58 -0500
Subject: [R] Plotting Example Fail
In-Reply-To: <CAF8bMcZaLGBYVhK=bXZwE1gA3TR7=H27WFPpYiLWO7ebeaxULQ@mail.gmail.com>
References: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
	<CAF8bMcZaLGBYVhK=bXZwE1gA3TR7=H27WFPpYiLWO7ebeaxULQ@mail.gmail.com>
Message-ID: <2F6F3981-1EB6-4F89-8E7D-A1E2E09A59AE@utoronto.ca>

... or read about set.seed() and use it.

B.


On Nov 24, 2015, at 2:58 PM, William Dunlap <wdunlap at tibco.com> wrote:

> rpois(100, 5) gives a different set of random numbers each time it is
> called, so if you want repeatable results compute it once and use its
> value in the calls to plot.  E.g.,
>   r <- rpois(100, 5)
>   plot(table(r), type="h", col="red", lwd=10, main="hello")
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Tue, Nov 24, 2015 at 11:47 AM, Timothy D. Legg <r at timothylegg.com> wrote:
>> Hello,
>> 
>> I am quite new to R and have high expectations for my future with it.
>> 
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> 
>> I have stepped back to an earlier tutorial and found an odd inconsistency
>> with one of the examples:
>> 
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
>> "rpois(100, lambda = 5)")
>> 
>> I read the local documentation on the plot command and it's arguments.
>>> From that, I learned that 'main' defines the title from a text string.  I
>> decide to modify some values to see how the resulting behavior changes.
>> What I didn't expect was that modifying the text string caused the chart
>> to change greatly.
>> 
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
>> "rpois(100, lambda = 4)")
>> 
>> With the previous line, the columns change values.
>> 
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main = "hello")
>> 
>> This line even adds a 12th column.
>> 
>> I return to plot the original and the output has changed again.   Here are
>> some screenshots
>> 
>> http://timothylegg.com/R/lambda5_.png
>> http://timothylegg.com/R/lambda5.png
>> http://timothylegg.com/R/lambda4.png
>> http://timothylegg.com/R/hello.png
>> 
>> What am I doing wrong to get inconsistent results like this?  I'm very new
>> to R and really hoping that this is a misunderstanding on my part.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mxkuhn at gmail.com  Tue Nov 24 21:51:48 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Tue, 24 Nov 2015 15:51:48 -0500
Subject: [R] Ensure distribution of classes is the same as prior
 distribution in Cross Validation
In-Reply-To: <SNT152-W34E8076DF54DF72EC17F76DF060@phx.gbl>
References: <SNT152-W34E8076DF54DF72EC17F76DF060@phx.gbl>
Message-ID: <CAJ9CoWkk5=WpZLL9QyS9G1PpnejgWFPv=GWcqWK4894=OFjyMg@mail.gmail.com>

Right now, using `method = "cv"` or `method = "repeatedcv"` does stratified
sampling. Depending on what you mean by "ensure" and the nature of your
outcome (categorical?), it probably already does.

On Mon, Nov 23, 2015 at 7:04 PM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:

> In the caret train control function, is it possible to ensure Ensure
> distribution of classes is the same as prior distribution in the folds of
> cross
>  validation? I know it can be done using create folds but was wondering if
> it is possible using train control?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r at timothylegg.com  Tue Nov 24 21:43:42 2015
From: r at timothylegg.com (Timothy D. Legg)
Date: Tue, 24 Nov 2015 15:43:42 -0500
Subject: [R] Plotting Example Fail
In-Reply-To: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
References: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
Message-ID: <826ee05b8553e9a6b87d7cb8257a09c5.squirrel@www.timothylegg.com>

Thank you for your suggestions.  I am quite grateful to understand that
plotting is reliable and consistent in R.  I had believed that this was
based on a built-in dataset within the R programming language, just as the
New Zealand volcano is.

I look forward to further participation in R as I continue to develop
skills in this arena.

Timothy D. Legg

> Hello,
>
> I am quite new to R and have high expectations for my future with it.
>
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> I have stepped back to an earlier tutorial and found an odd inconsistency
> with one of the examples:
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
> "rpois(100, lambda = 5)")
>
> I read the local documentation on the plot command and it's arguments.
>>From that, I learned that 'main' defines the title from a text string.  I
> decide to modify some values to see how the resulting behavior changes.
> What I didn't expect was that modifying the text string caused the chart
> to change greatly.
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
> "rpois(100, lambda = 4)")
>
> With the previous line, the columns change values.
>
> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
> "hello")
>
> This line even adds a 12th column.
>
> I return to plot the original and the output has changed again.   Here are
> some screenshots
>
> http://timothylegg.com/R/lambda5_.png
> http://timothylegg.com/R/lambda5.png
> http://timothylegg.com/R/lambda4.png
> http://timothylegg.com/R/hello.png
>
> What am I doing wrong to get inconsistent results like this?  I'm very new
> to R and really hoping that this is a misunderstanding on my part.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Tue Nov 24 22:12:17 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 24 Nov 2015 13:12:17 -0800
Subject: [R] Plotting Example Fail
In-Reply-To: <826ee05b8553e9a6b87d7cb8257a09c5.squirrel@www.timothylegg.com>
References: <508da8df1770eeb4bd18ad4f70897a81.squirrel@www.timothylegg.com>
	<826ee05b8553e9a6b87d7cb8257a09c5.squirrel@www.timothylegg.com>
Message-ID: <CAGxFJbSXS3cBb6cKZ0d9U8bo8GGPDE9BgAYTX=WdkogoWd72Kw@mail.gmail.com>

But please spend some time with an R tutorial or two (An Intro to R
ships with R; there are many more on the Web) before you post further
here. Many such elementary confusions and time wasted -- both yours
and ours -- will be avoided if you do so.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Nov 24, 2015 at 12:43 PM, Timothy D. Legg <r at timothylegg.com> wrote:
> Thank you for your suggestions.  I am quite grateful to understand that
> plotting is reliable and consistent in R.  I had believed that this was
> based on a built-in dataset within the R programming language, just as the
> New Zealand volcano is.
>
> I look forward to further participation in R as I continue to develop
> skills in this arena.
>
> Timothy D. Legg
>
>> Hello,
>>
>> I am quite new to R and have high expectations for my future with it.
>>
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> I have stepped back to an earlier tutorial and found an odd inconsistency
>> with one of the examples:
>>
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
>> "rpois(100, lambda = 5)")
>>
>> I read the local documentation on the plot command and it's arguments.
>>>From that, I learned that 'main' defines the title from a text string.  I
>> decide to modify some values to see how the resulting behavior changes.
>> What I didn't expect was that modifying the text string caused the chart
>> to change greatly.
>>
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
>> "rpois(100, lambda = 4)")
>>
>> With the previous line, the columns change values.
>>
>> plot(table(rpois(100, 5)), type = "h", col = "red", lwd = 10, main =
>> "hello")
>>
>> This line even adds a 12th column.
>>
>> I return to plot the original and the output has changed again.   Here are
>> some screenshots
>>
>> http://timothylegg.com/R/lambda5_.png
>> http://timothylegg.com/R/lambda5.png
>> http://timothylegg.com/R/lambda4.png
>> http://timothylegg.com/R/hello.png
>>
>> What am I doing wrong to get inconsistent results like this?  I'm very new
>> to R and really hoping that this is a misunderstanding on my part.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nilesh.dighe at monsanto.com  Tue Nov 24 23:13:58 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Tue, 24 Nov 2015 22:13:58 +0000
Subject: [R] subset data using a vector
In-Reply-To: <CA+8X3fWdJMdvpg182-vWonTmORcWDyBqdk92LNAYw29yAeuZJA@mail.gmail.com>
References: <24156952D190E841BF8E66CB59FAB94A486A1AE1@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56533BE0.8010906@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A1C0A@STLWEXMBXPRD14.na.ds.monsanto.com>
	<56535699.6030500@dewey.myzen.co.uk>
	<24156952D190E841BF8E66CB59FAB94A486A2430@STLWEXMBXPRD14.na.ds.monsanto.com>
	<CA+8X3fWdJMdvpg182-vWonTmORcWDyBqdk92LNAYw29yAeuZJA@mail.gmail.com>
Message-ID: <24156952D190E841BF8E66CB59FAB94A486A38B1@STLWEXMBXPRD14.na.ds.monsanto.com>

Jim & Michael:  I really appreciate your guidance in creating the function I wanted.  I took suggestions from both of you and was able to complete this function.  I had to split the process into two functions as listed below.
I just thought to send the results to the list in case someone might be interested in doing similar task in the future.
Thanks.
Nilesh

getcheckmeans<- function (dataset)
{
    row_check_mean <- c()
    dat1 <- data.frame()
    check_mean <- c()
    x <- length(dataset$plotid)
    for (i in (1:x)) {
        r1 <- dataset[i, 1]
        r2 <- r1 - 1
        r3 <- r1 + 1
        r4 <- c(r1, r2, r3)
        dat1 <- split(dataset, dataset$rows %in% r4)[[2]]
        row_check_mean[i] <- tapply(dat1$yield, dat1$linecode,
            mean, na.rm = TRUE)[1]
        check_mean <- round(unlist(row_check_mean)[1:x], digits = 2)
    }
    check_mean
}


adjustdata<- function (dataset, trait, control)

{

    check_mean <- getcheckmeans(dataset)

    dat_check_mean <- as.data.frame(check_mean)

    dataset <- cbind(dataset, dat_check_mean)

    adj_yield <- c()

    x <- length(trait)

    for (i in 1:x) {

        adj_yield[i] <- ifelse(control[i] == "variety", round(trait[i]/dataset$check_mean[i],

            digits = 3), round(trait[i]/trait[i], digits = 3))

    }

    data.frame(dataset, adj_yield)

}


dat<- structure(list(rows = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,

1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,

3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,

4L, 4L, 4L, 4L, 4L, 4L), cols = c(1L, 2L, 3L, 4L, 5L, 6L, 7L,

8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 16L, 15L, 14L, 13L,

12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L, 1L, 2L, 3L,

4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 16L,

15L, 14L, 13L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L,

1L), plotid = c(289L, 290L, 291L, 292L, 293L, 294L, 295L, 296L,

297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 369L, 370L, 371L,

372L, 373L, 374L, 375L, 376L, 377L, 378L, 379L, 380L, 381L, 382L,

383L, 384L, 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,

394L, 395L, 396L, 397L, 398L, 399L, 400L, 465L, 466L, 467L, 468L,

469L, 470L, 471L, 472L, 473L, 474L, 475L, 476L, 477L, 478L, 479L,

480L), yield = c(5.1, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5, 5,

3.9, 4.6, 5, 4.4, 5.1, 4.3, 4.4, 4.2, 3.9, 4.6, 4.8, 5.4, 4.7,

5.5, 5.3, 4.8, 5.8, 4.6, 5.8, 5.5, 5.3, 5.6, 5.6, 5, 4.8, 4.9,

5.2, 5.3, 4.6, 4.8, 5.3, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5, 5.4,

4.8, 4.6, 5.2, 4.9, 5.1, 4.5, 5.8, 5.2, 4.7, 4.8, 5.3, 5.8, 4.9,

5.9, 4.5), line = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,

9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,

1L, 21L, 22L, 1L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,

32L, 33L, 1L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 1L,

43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 1L, 51L, 52L, 53L, 54L,

1L, 55L, 56L, 57L), .Label = c("CHK", "V002", "V003", "V004",

"V005", "V006", "V007", "V008", "V009", "V010", "V011", "V012",

"V013", "V014", "V015", "V016", "V017", "V018", "V019", "V020",

"V021", "V022", "V023", "V024", "V025", "V026", "V027", "V028",

"V029", "V030", "V031", "V032", "V033", "V034", "V035", "V036",

"V037", "V038", "V039", "V040", "V041", "V042", "V043", "V044",

"V045", "V046", "V047", "V048", "V049", "V050", "V051", "V052",

"V053", "V054", "V055", "V056", "V057"), class = "factor"), linecode = structure(c(1L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label = c("check",

"variety"), class = "factor")), .Names = c("rows", "cols", "plotid",

"yield", "line", "linecode"), class = "data.frame", row.names = c(NA,

-64L))

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Tuesday, November 24, 2015 2:53 AM
To: DIGHE, NILESH [AG/2362]
Cc: r-help at r-project.org
Subject: Re: [R] subset data using a vector

Hi Nilesh,
I simplified your code a bit:

fun1<-function (dataset, plot.id<http://plot.id>, ranges2use, control) {
 m1 <- strsplit(as.character(ranges2use), ",")
 dat1 <- data.frame()
 row_check_mean <- NA
 row_check_adj_yield <- NA
 x <- length(plot.id<http://plot.id>)
 for (i in 1:x) {
  cat(i,"\n")
  dat1 <- dataset[dataset$ranges %in% m1[[i]], ]
  row_check_mean[i] <- tapply(unlist(dat1$trait),unlist(dat1$control),
   mean, na.rm = TRUE)[1]
  row_check_adj_yield[i] <- ifelse(control[i] == "variety",
  trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
 }
 data.frame(dataset, row_check_adj_yield)
}

 and got it to run down to this line:

row_check_mean[i]<-tapply(dat1$trait,dat1$control,mean,na.rm=TRUE)[1]

which generates the error:

Error in split.default(X, group) : first argument must be a vector

As far as I can see, there is no element in "mydata" named "trait" and "control" is not an element of the local variable "dat1". I can't get past this, but perhaps it will help you to sort it out.

Jim


On Tue, Nov 24, 2015 at 10:10 AM, DIGHE, NILESH [AG/2362] <nilesh.dighe at monsanto.com<mailto:nilesh.dighe at monsanto.com>> wrote:
Michael:  I tried using your suggestion of using length and still get the same error:
Error in m1[[i]] : subscript out of bounds

I also checked the length of m1 and x and they both are of same length (64).

After trying several things, I was able to extract the list but this was done outside the function I am trying to create.
Code that worked is listed below:

for(i in (1:length(mydata$plotid))){
        v1<-as.numeric(strsplit(as.character(mydata$rangestouse), ",")[[i]])
        print(head(v1))}

However, when I try to get this code in a function (fun3) listed below, I get the following error:
Error in strsplit(as.character(dataset$ranges2use), ",")[[i]] :
  subscript out of bounds

fun3<- function (dataset, plot.id<http://plot.id>, ranges2use, control)
{
    m1 <- c()
    x <- length(plot.id<http://plot.id>)
    for (i in (1:x)) {
        m1 <- as.numeric(strsplit(as.character(dataset$ranges2use),
            ",")[[i]])
    }
    m2
}

I am not sure where I am making a mistake.
Thanks.
Nilesh

-----Original Message-----
From: Michael Dewey [mailto:lists at dewey.myzen.co.uk<mailto:lists at dewey.myzen.co.uk>]
Sent: Monday, November 23, 2015 12:11 PM
To: DIGHE, NILESH [AG/2362]; r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] subset data using a vector

Try looking at your function and work through what happens if the length is what I suggested.

 >>       x <- length(plot.id<http://plot.id>)
 >>
 >>       for (i in (1:x)) {
 >>
 >>           m2[i] <- m1[[i]]

So unless m1 has length at least x you are doomed.

On 23/11/2015 16:26, DIGHE, NILESH [AG/2362] wrote:
> Michael:  I like to use the actual range id's listed in column "rangestouse" to subset my data and not the length of that vector.
>
> Thanks.
> Nilesh
>
> -----Original Message-----
> From: Michael Dewey [mailto:lists at dewey.myzen.co.uk<mailto:lists at dewey.myzen.co.uk>]
> Sent: Monday, November 23, 2015 10:17 AM
> To: DIGHE, NILESH [AG/2362]; r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] subset data using a vector
>
> length(strsplit(as.character(mydata$ranges2use), ","))
>
> was that what you expected? I think not.
>
> On 23/11/2015 16:05, DIGHE, NILESH [AG/2362] wrote:
>> Dear R users,
>>                   I like to split my data by a vector created by using variable "ranges".  This vector will have the current range (ranges), preceding range (ranges - 1), and post range (ranges + 1) for a given plotid.  If the preceding or post ranges in this vector are outside the levels of ranges in the data set then I like to drop those ranges and only include the ranges that are available.  Variable "rangestouse" includes all the desired ranges I like to subset a given plotid.  After I subset these dataset using these desired ranges, then I like to extract the yield data for checks in those desired ranges and adjust yield of my data by dividing yield of a given plotid with the check average for the desired ranges.
>>
>> I have created this function (fun1) but when I run it, I get the following error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Any help will be highly appreciated!
>> Thanks, Nilesh
>>
>> Dataset:
>> dput(mydata)
>> structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class = "factor"),
>> cols = structure(c(1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L, 4L,
>> 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L, 3L,
>> 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 2L,
>> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
>> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L), .Label = c("1", "2", "3", "4", "5",
>> "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),
>>       plotid = c(289L, 298L, 299L, 300L, 301L, 302L, 303L, 304L,
>>       290L, 291L, 292L, 293L, 294L, 295L, 296L, 297L, 384L, 375L,
>>       374L, 373L, 372L, 371L, 370L, 369L, 383L, 382L, 381L, 380L,
>>       379L, 378L, 377L, 376L, 385L, 394L, 395L, 396L, 397L, 398L,
>>       399L, 400L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L,
>>       480L, 471L, 470L, 469L, 468L, 467L, 466L, 465L, 479L, 478L,
>>       477L, 476L, 475L, 474L, 473L, 472L), yield = c(5.1, 5, 3.9,
>>       4.6, 5, 4.4, 5.1, 4.3, 5.5, 5, 5.5, 6.2, 5.1, 5.5, 5.2, 5,
>>       5.6, 4.7, 5.4, 4.8, 4.6, 3.9, 4.2, 4.4, 5.3, 5.5, 5.8, 4.6,
>>       5.8, 4.8, 5.3, 5.5, 5.6, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5,
>>       5, 4.8, 4.9, 5.2, 5.3, 4.6, 4.8, 5.3, 4.5, 4.5, 5.1, 4.9,
>>       5.2, 4.6, 4.8, 5.4, 5.9, 4.9, 5.8, 5.3, 4.8, 4.7, 5.2, 5.8
>>       ), linecode = structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L), .Label = c("check",
>>       "variety"), class = "factor"), ranges = c(1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
>>       ), rangestouse = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>       1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>       2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>>       3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>>       4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1,2",
>>       "1,2,3", "2,3,4", "3,4"), class = "factor")), .Names =
>> c("rows", "cols", "plotid", "yield", "linecode", "ranges", "rangestouse"
>>
>> ), class = "data.frame", row.names = c(NA, -64L))

>>
>> Function:
>>
>> fun1<- function (dataset, plot.id<http://plot.id>, ranges2use, control)
>>
>> {
>>
>>       m1 <- strsplit(as.character(dataset$ranges2use), ",")
>>
>>       dat1 <- data.frame()
>>
>>       m2 <- c()
>>
>>       row_check_mean <- c()
>>
>>       row_check_adj_yield <- c()
>>
>>       x <- length(plot.id<http://plot.id>)
>>
>>       for (i in (1:x)) {
>>
>>           m2[i] <- m1[[i]]
>>
>>           dat1 <- dataset[dataset$ranges %in% m2[i], ]
>>
>>           row_check_mean[i] <- tapply(dat1$trait, dat1$control,
>>
>>               mean, na.rm = TRUE)[1]
>>
>>           row_check_adj_yield[i] <- ifelse(control[i] == "variety",
>>
>>               trait[i]/dataset$row_check_mean[i], trait[i]/trait[i])
>>
>>       }
>>
>>       data.frame(dataset, row_check_adj_yield)
>>
>> }
>>
>> Apply function:
>> fun1(mydata, plot.id<http://plot.id>=mydata$plotid, ranges2use =
>> mydata$rangestouse,control=mydata$linecode)
>>
>> Error:
>>
>> Error in m1[[i]] : subscript out of bounds
>>
>> Session info:
>>
>> R version 3.2.1 (2015-06-18)
>>
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252
>>
>> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_United States.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>>    [1] magrittr_1.5    plyr_1.8.3      tools_3.2.1     reshape2_1.4.1  Rcpp_0.12.1     stringi_1.0-1
>>
>>    [7] grid_3.2.1      agridat_1.12    stringr_1.0.0   lattice_0.20-31
>>
>>
>> Nilesh Dighe
>> (806)-252-7492 (Cell)
>> (806)-741-2019 (Office)
>>
>>
>> This e-mail message may contain privileged and/or confidential
>> information, and is intended to be received only by persons entitled
>> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>>
>> All e-mails and attachments sent and received are subject to
>> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
>> Monsanto, along with its subsidiaries, accepts no liability for any
>> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>>
>>
>> The information contained in this email may be subject to the export
>> control laws and regulations of the United States, potentially
>> including but not limited to the Export Administration Regulations
>> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> This e-mail message may contain privileged and/or confidential
> information, and is intended to be received only by persons entitled
> to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
> All e-mails and attachments sent and received are subject to
> monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
> Monsanto, along with its subsidiaries, accepts no liability for any
> damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>
>
> The information contained in this email may be subject to the export
> control laws and regulations of the United States, potentially
> including but not limited to the Export Administration Regulations
> (EAR) and sanctions regulations issued by the U.S. Department of Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all applicable U.S. export laws and regulations.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html
This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.

	[[alternative HTML version deleted]]


From judsonblake at msn.com  Wed Nov 25 04:32:34 2015
From: judsonblake at msn.com (Judson)
Date: Tue, 24 Nov 2015 22:32:34 -0500
Subject: [R] Non-linear fit?
Message-ID: <COL130-W81B713AFD971448205FC32AD050@phx.gbl>

I need to fit a sinusoidal curve to 
x-y data that exhibits a sinusoidal 
pattern.   The curve will be: 
 y = a*sin(w*x +p) ; 
where I need to get the best 
fit choice for the parameters 
a, w, and p.   Could anyone 
suggest which package and 
routine I should use?   I have 
less than 1000 data points. 
Can this problem be somehow 
coerced into a linear fit?     
....... judson blake 		 	   		  
	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Nov 25 09:01:59 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 25 Nov 2015 08:01:59 +0000
Subject: [R] could not load r package in mac
Message-ID: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi R user,

I was wondering why I could not load R packages such as reshape2 in mac. I tried different ways but could not success.


here I what I got


Warning: unable to access index for repository http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2


> install.packages(reshape2)

Error in install.packages(reshape2) : object 'reshape2' not found

>

 Any hints?



	[[alternative HTML version deleted]]


From phgrosjean at sciviews.org  Wed Nov 25 09:07:55 2015
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Wed, 25 Nov 2015 09:07:55 +0100
Subject: [R] could not load r package in mac
In-Reply-To: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <DA246082-DAF3-41AE-884D-AFD12A61EA5A@sciviews.org>

Have you tried a different mirror? If they all fail, also check your internet connection.

PhG


> On 25 Nov 2015, at 09:01, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> Hi R user,
> 
> I was wondering why I could not load R packages such as reshape2 in mac. I tried different ways but could not success.
> 
> 
> here I what I got
> 
> 
> Warning: unable to access index for repository http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2
> 
> 
>> install.packages(reshape2)
> 
> Error in install.packages(reshape2) : object 'reshape2' not found
> 
>> 
> 
> Any hints?
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Wed Nov 25 09:09:24 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 25 Nov 2015 09:09:24 +0100
Subject: [R] could not load r package in mac
In-Reply-To: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
	(Kristi Glover's message of "Wed, 25 Nov 2015 08:01:59 +0000")
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <m2wpt6qz4b.fsf@krugs.de>

Kristi Glover <kristi.glover at hotmail.com> writes:

> Hi R user,
>
> I was wondering why I could not load R packages such as reshape2 in mac. I tried different ways but could not success.
>
>
> here I what I got
>
>
> Warning: unable to access index for repository http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2

Directly clicking on the link reveals: the mirror is down. Choose a
different mirror and it should work.

Cheers,

Rainer

>
>
>> install.packages(reshape2)
>
> Error in install.packages(reshape2) : object 'reshape2' not found
>
>>
>
>  Any hints?
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151125/86c0c910/attachment.bin>

From kristi.glover at hotmail.com  Wed Nov 25 09:17:25 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 25 Nov 2015 08:17:25 +0000
Subject: [R] could not load r package in mac
In-Reply-To: <m2wpt6qz4b.fsf@krugs.de>
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>,
	<m2wpt6qz4b.fsf@krugs.de>
Message-ID: <BY2PR13MB0454B51BB9D61E7B38D6D54CFA050@BY2PR13MB0454.namprd13.prod.outlook.com>

I don't know how i can chose different mirror. I am new in mac. Would you mind to give a little bit more information?

I have installed R 3.2.2 binary for Mac OS X 10.9

I tried following one

Warning: unable to access index for repository http://cran.parentingamerica.com/src/contrib
Warning: unable to access index for repository http://R.research.att.com/

thanks

________________________________________
From: Rainer M Krug <Rainer at krugs.de>
Sent: November 25, 2015 1:09 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] could not load r package in mac

Kristi Glover <kristi.glover at hotmail.com> writes:

> Hi R user,
>
> I was wondering why I could not load R packages such as reshape2 in mac. I tried different ways but could not success.
>
>
> here I what I got
>
>
> Warning: unable to access index for repository http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2

Directly clicking on the link reveals: the mirror is down. Choose a
different mirror and it should work.

Cheers,

Rainer

>
>
>> install.packages(reshape2)
>
> Error in install.packages(reshape2) : object 'reshape2' not found
>
>>
>
>  Any hints?
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982

From jdnewmil at dcn.davis.ca.us  Wed Nov 25 09:20:27 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 Nov 2015 00:20:27 -0800
Subject: [R] could not load r package in mac
In-Reply-To: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <FEA09FF6-F83B-4916-A478-27C99E31F2EA@dcn.davis.ca.us>

The usual issue is that the mirror is unavailable and you need to choose a different one.  Another complication is the recent switch to preferring secure repositories, which only a minority of mirrors are currently supporting. To address that be sure to pick a mirror that has https protocol. 
-- 
Sent from my phone. Please excuse my brevity.

On November 25, 2015 12:01:59 AM PST, Kristi Glover <kristi.glover at hotmail.com> wrote:
>Hi R user,
>
>I was wondering why I could not load R packages such as reshape2 in
>mac. I tried different ways but could not success.
>
>
>here I what I got
>
>
>Warning: unable to access index for repository
>http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2
>
>
>> install.packages(reshape2)
>
>Error in install.packages(reshape2) : object 'reshape2' not found
>
>>
>
> Any hints?
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Nov 25 09:23:27 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 25 Nov 2015 08:23:27 +0000
Subject: [R] could not load r package in mac
In-Reply-To: <FEA09FF6-F83B-4916-A478-27C99E31F2EA@dcn.davis.ca.us>
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>,
	<FEA09FF6-F83B-4916-A478-27C99E31F2EA@dcn.davis.ca.us>
Message-ID: <BY2PR13MB04541631C65FE1121820BD39FA050@BY2PR13MB0454.namprd13.prod.outlook.com>

Got it. Thanks for your kind help.



________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: November 25, 2015 1:20 AM
To: Kristi Glover; R-help
Subject: Re: [R] could not load r package in mac

The usual issue is that the mirror is unavailable and you need to choose a different one. Another complication is the recent switch to preferring secure repositories, which only a minority of mirrors are currently supporting. To address that be sure to pick a mirror that has https protocol.
--
Sent from my phone. Please excuse my brevity.

On November 25, 2015 12:01:59 AM PST, Kristi Glover <kristi.glover at hotmail.com> wrote:

Hi R user,

I was wondering why I could not load R packages such as reshape2 in mac. I tried different ways but could not success.


here I what I got


Warning: unable to access index for repository http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2


 install.packages(reshape2)

Error in install.packages(reshape2) : object 'reshape2' not found



 Any hints?



 [[alternative HTML version deleted]]

________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Wed Nov 25 12:49:24 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Wed, 25 Nov 2015 06:49:24 -0500
Subject: [R] Returning a factor from vapply
Message-ID: <2E9A0C60-DD60-46FE-AC7A-42DDEF47595A@gmail.com>

Hello, 

I would like to return a factor from vapply, which looks it cannot be done directly since a factor is typeof() numeric. So I?m not sure if the solution below is the standard approach to handle this. My concern is that the factor levels are mixed up in the results (as shown in the last line of code), which is undesirable. 

set.seed(1)
df <- data.frame(x1 = runif(100), x2 = runif(100))


mycuts <- function(x) {
  
  xc <- cut(x, breaks = unique(quantile(x, seq(0, 1, 1/4), na.rm = TRUE)),
            include.lowest = TRUE)
  as.character(xc)
  
}

head(df_out <- data.frame(vapply(df, mycuts, character(nrow(df)))))

identical(levels(df_out$x1), levels(cut(df$x1, breaks = unique(quantile(df$x1, 
                                        seq(0, 1, 1/4), na.rm = TRUE)),
                                        include.lowest = TRUE)))


Thanks for any pointers. 

Axel.

From jfox at mcmaster.ca  Wed Nov 25 14:27:52 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 25 Nov 2015 13:27:52 +0000
Subject: [R] could not load r package in mac
In-Reply-To: <BY2PR13MB0454B51BB9D61E7B38D6D54CFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB045424BE0C74EACBBAE2168EFA050@BY2PR13MB0454.namprd13.prod.outlook.com>,
	<m2wpt6qz4b.fsf@krugs.de>
	<BY2PR13MB0454B51BB9D61E7B38D6D54CFA050@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3CE9A@FHSDB2D11-2.csu.mcmaster.ca>

Dear Kristi,

>From a subsequent message, you appear to have solved your problem, but whether or not the mirror you're using is available, the command you posted won't work. You need to put the package name in quotes: install.packages("reshape2"), as you may have discovered. 

It's the object reshape2, which doesn't exist in your workspace, that triggers the error, not the presence or absence of the package reshape2 on the CRAN mirror you're using.

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kristi Glover
> Sent: November 25, 2015 3:17 AM
> To: Rainer M Krug <Rainer at krugs.de>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] could not load r package in mac
> 
> I don't know how i can chose different mirror. I am new in mac. Would you
> mind to give a little bit more information?
> 
> I have installed R 3.2.2 binary for Mac OS X 10.9
> 
> I tried following one
> 
> Warning: unable to access index for repository
> http://cran.parentingamerica.com/src/contrib
> Warning: unable to access index for repository http://R.research.att.com/
> 
> thanks
> 
> ________________________________________
> From: Rainer M Krug <Rainer at krugs.de>
> Sent: November 25, 2015 1:09 AM
> To: Kristi Glover
> Cc: R-help
> Subject: Re: [R] could not load r package in mac
> 
> Kristi Glover <kristi.glover at hotmail.com> writes:
> 
> > Hi R user,
> >
> > I was wondering why I could not load R packages such as reshape2 in mac. I
> tried different ways but could not success.
> >
> >
> > here I what I got
> >
> >
> > Warning: unable to access index for repository
> > http://cran.parentingamerica.com/bin/macosx/mavericks/contrib/3.2
> 
> Directly clicking on the link reveals: the mirror is down. Choose a different
> mirror and it should work.
> 
> Cheers,
> 
> Rainer
> 
> >
> >
> >> install.packages(reshape2)
> >
> > Error in install.packages(reshape2) : object 'reshape2' not found
> >
> >>
> >
> >  Any hints?
> >
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology,
> UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology Stellenbosch University South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bodenhofer at bioinf.jku.at  Wed Nov 25 14:45:13 2015
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Wed, 25 Nov 2015 14:45:13 +0100
Subject: [R] Probing a protein sequence alignment in R
Message-ID: <5655BB69.4050807@bioinf.jku.at>

Hi Debra,

As already noted by Boris, the right packages can be found in Bioconductor, namely Biostrings (for handling sets of sequences and pairwise alignments) and msa (for multiple alignments; a package I am maintaining). Your question does not yet clearly indicate to me whether pairwise or multiple sequence alignments are the right choice. If I understand you correctly, this is not the point anyway, since you want a solution how to find out in which positions two aligned sequences differ, right? The following code snippet demonstrates by means of a simple example with two DNA strings how to check where two strings in a pairwise alignment differ:

    library(Biostrings)
    seq1 <- DNAString("AGCGAGCGA")
    seq2 <- DNAString("AGGATCGA")
    aln <- pairwiseAlignment(seq1, seq2, type="global",
    substitutionMatrix=nucleotideSubstitutionMatrix(4, -1))
    which(strsplit(as.character(pattern(aln)), split="")[[1]] !=
    strsplit(as.character(subject(aln)), split="")[[1]])

Maybe there are more elegant solutions than this one. This is just a 
quick approach using basic R. Note that the positions are relative to 
the positions in the alignment, which need not be the same as the 
positions in your original "non-mutant" sequence if the alignment 
algorithm has inserted some gaps in this sequence. If you use multiple 
alignments, the approach is basically the same:

    library(msa)
    seqs <- DNAStringSet(c(seq1="AGCGAGCGA", seq2="AGGATCGA",
    seq3="AGCGAGC"))
    aln <- msaMuscle(seqs, order="input")
    ## seq1 against seq2:
    which(strsplit(as.character(aln)[1], split="")[[1]] !=
    strsplit(as.character(aln)[2], split="")[[1]])
    ## seq1 against seq3:
    which(strsplit(as.character(aln)[1], split="")[[1]] !=
    strsplit(as.character(aln)[3], split="")[[1]])

I hope this helps.

Best regards,
Ulrich

P.S.: I fully agree with Bert that the Bioconductor support forum would 
be a good place to discuss this.


On Nov 24, 2015, at 12:04 PM, debra ragland via R-help<r-help at r-project.org>  wrote:

> I have 15 protein sequences of 99 amino acids each. After doing some looking around I have found that there are several ways you can read sequences into R and do pairwise or multiple alignments. I, however, do not know how to probe changes at specific positions. For instance, I would like to know the best way to align a standard sequence with one(1) or several mutant sequences and probe each amino acid position that does not match the standard sequence. In other words seq1 = "standard amino acid seq" and seq2 = "mutant seq", align these 2 and then have a way to ask R to report whether there is a change at position 10, or 11, or 12 and so on such that R reports(for example) TRUE or FALSE for this question. Where all the sequences that have a reported TRUE for a change at position X can be grouped against those that do not have a change at this position.I'm not even sure that R is the best way to do this, but it's the only language I'm somewhat familiar with.I hope this makes sense.


From jdnewmil at dcn.davis.ca.us  Wed Nov 25 15:15:39 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 25 Nov 2015 06:15:39 -0800
Subject: [R] Returning a factor from vapply
In-Reply-To: <2E9A0C60-DD60-46FE-AC7A-42DDEF47595A@gmail.com>
References: <2E9A0C60-DD60-46FE-AC7A-42DDEF47595A@gmail.com>
Message-ID: <7EFEF022-1131-4A9B-A0D1-0F9FDBAD9801@dcn.davis.ca.us>

Such manipulations are usually better performed in character data.  Convert to factor only after the vector is complete. 
-- 
Sent from my phone. Please excuse my brevity.

On November 25, 2015 3:49:24 AM PST, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>Hello, 
>
>I would like to return a factor from vapply, which looks it cannot be
>done directly since a factor is typeof() numeric. So I?m not sure if
>the solution below is the standard approach to handle this. My concern
>is that the factor levels are mixed up in the results (as shown in the
>last line of code), which is undesirable. 
>
>set.seed(1)
>df <- data.frame(x1 = runif(100), x2 = runif(100))
>
>
>mycuts <- function(x) {
>  
>xc <- cut(x, breaks = unique(quantile(x, seq(0, 1, 1/4), na.rm =
>TRUE)),
>            include.lowest = TRUE)
>  as.character(xc)
>  
>}
>
>head(df_out <- data.frame(vapply(df, mycuts, character(nrow(df)))))
>
>identical(levels(df_out$x1), levels(cut(df$x1, breaks =
>unique(quantile(df$x1, 
>                                        seq(0, 1, 1/4), na.rm = TRUE)),
>                                        include.lowest = TRUE)))
>
>
>Thanks for any pointers. 
>
>Axel.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From uma at sophie.unam.mx  Wed Nov 25 16:52:04 2015
From: uma at sophie.unam.mx (Ulises M. Alvarez)
Date: Wed, 25 Nov 2015 09:52:04 -0600
Subject: [R] Non-linear fit?
In-Reply-To: <COL130-W81B713AFD971448205FC32AD050@phx.gbl>
References: <COL130-W81B713AFD971448205FC32AD050@phx.gbl>
Message-ID: <5655D924.9020905@sophie.unam.mx>

On 11/24/2015 09:32 PM, Judson wrote:
> I need to fit a sinusoidal curve to
> x-y data that exhibits a sinusoidal
> pattern.   The curve will be:
>   y = a*sin(w*x +p) ;
> where I need to get the best
> fit choice for the parameters
> a, w, and p.   Could anyone
> suggest which package and
> routine I should use?   I have
> less than 1000 data points.
> Can this problem be somehow
> coerced into a linear fit?
> ....... judson blake 		 	   		

You may take a look at the nlme library.
-- 
Ulises M. Alvarez
http://sophie.unam.mx/


From S.Ellison at LGCGroup.com  Wed Nov 25 17:11:43 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 25 Nov 2015 16:11:43 +0000
Subject: [R] Non-linear fit?
In-Reply-To: <5655D924.9020905@sophie.unam.mx>
References: <COL130-W81B713AFD971448205FC32AD050@phx.gbl>
	<5655D924.9020905@sophie.unam.mx>
Message-ID: <1A8C1289955EF649A09086A153E2672403C9423FE7@GBTEDVPEXCMB04.corp.lgc-group.com>



> -----Original Message-----
> On 11/24/2015 09:32 PM, Judson wrote:
> > I need to fit a sinusoidal curve to
> > x-y data that exhibits a sinusoidal
> > pattern.   The curve will be:
> >   y = a*sin(w*x +p) ;
> > where I need to get the best
> > fit choice for the parameters
> > a, w, and p.   Could anyone
> > suggest which package and
> > routine I should use?   I have
> > less than 1000 data points.
> > Can this problem be somehow
> > coerced into a linear fit?
> > ....... judson blake
> 
> You may take a look at the nlme library.
> --
> Ulises M. Alvarez

nlme includes a nonlinear _mixed effects_ model, but non-linear least squares fitting is well catered for already. nlm, nls and optim in the core distribution all cover non-linear fitting.

But you'll need good starting values.

Life could be easier with a reformulation expanding sin(w*x + p) to 
y = alpha sin(w*x) + beta * cos(w*x) 

where alpha=a*cos(p) and beta = a * sin(p)
(if my mental trig is working)

Given a good starting value for w (eg from an FFT) that would allow an initial linear (ie lm() )  fit to cos(w*x) + sin(w*x) to get alpha and beta, and hence a and p. Those values could then be used as starting values for optim or similar.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From angelo.arcadi at virgilio.it  Wed Nov 25 17:30:06 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Wed, 25 Nov 2015 17:30:06 +0100 (CET)
Subject: [R] Syntax error in using Anova (car package)
Message-ID: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>

Dear list members,
I am getting an error while performing a repeated measures MANOVA using the Anova function 
of the "car" package. I want to apply it on the results of an experiment involving 19 participants, 
who were subjected to 36 stimuli, each stimulus was repeated twice for a total of 72 trials 
per subject. Participants had to adjust two parameters of sounds, Centroid and Sound_Level_Peak, 
for each stimulus. This is the head of my dataset (dependent variables: Centroid and 
Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2 levels)). 

> head(scrd)
    Subject         Mat   Sh      Centroid            Sound_Level_Peak
1     Subject1      C     DS        1960.2               -20.963
2     Subject1      C     SN        5317.2               -42.741
3     Subject1      G     DS       11256.0               -16.480
4     Subject1      G     SN        9560.3               -19.682
5     Subject1      M     DS        4414.1               -33.723
6     Subject1      M     SN        4946.1               -23.648


Based on my understanding of the online material I found, this is the procedure I used:

idata <- data.frame(scrd$Subject)
mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)


I get the following error

Error in check.imatrix(X.design) : 
  Terms in the intra-subject model matrix are not orthogonal.


Can anyone please tell me what is wrong in my formulas?

Thanks in advance

Best regards

Angelo





	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Nov 25 18:23:23 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 25 Nov 2015 17:23:23 +0000
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
References: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3D05C@FHSDB2D11-2.csu.mcmaster.ca>

Dear Angelo,

I'm afraid that this is badly confused. To use Anova() for repeated measures, the data must be in "wide" format, with one row per subject. To see how this works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or for more detail, the R Journal paper at <{http://journal.r-project.org/archive/2013-1/RJournal_2013-1_fox-friendly-weisberg.pdf>.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
> Sent: Wednesday, November 25, 2015 11:30 AM
> To: r-help at r-project.org
> Cc: Fox, John
> Subject: Syntax error in using Anova (car package)
> 
> Dear list members,
> I am getting an error while performing a repeated measures MANOVA using
> the Anova function
> of the "car" package. I want to apply it on the results of an experiment
> involving 19 participants,
> who were subjected to 36 stimuli, each stimulus was repeated twice for a
> total of 72 trials
> per subject. Participants had to adjust two parameters of sounds,
> Centroid and Sound_Level_Peak,
> for each stimulus. This is the head of my dataset (dependent variables:
> Centroid and
> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
> levels)).
> 
> > head(scrd)
>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
> 1     Subject1      C     DS        1960.2               -20.963
> 2     Subject1      C     SN        5317.2               -42.741
> 3     Subject1      G     DS       11256.0               -16.480
> 4     Subject1      G     SN        9560.3               -19.682
> 5     Subject1      M     DS        4414.1               -33.723
> 6     Subject1      M     SN        4946.1               -23.648
> 
> 
> Based on my understanding of the online material I found, this is the
> procedure I used:
> 
> idata <- data.frame(scrd$Subject)
> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
> 
> 
> I get the following error
> 
> Error in check.imatrix(X.design) :
>   Terms in the intra-subject model matrix are not orthogonal.
> 
> 
> Can anyone please tell me what is wrong in my formulas?
> 
> Thanks in advance
> 
> Best regards
> 
> Angelo
> 
> 
> 
> 


From dwinsemius at comcast.net  Wed Nov 25 18:25:21 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Nov 2015 09:25:21 -0800
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
References: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
Message-ID: <8A78A259-9796-4AB7-8698-3A81E6DC5580@comcast.net>


> On Nov 25, 2015, at 8:30 AM, angelo.arcadi at virgilio.it wrote:
> 
> Dear list members,
> I am getting an error while performing a repeated measures MANOVA using the Anova function 
> of the "car" package. I want to apply it on the results of an experiment involving 19 participants, 
> who were subjected to 36 stimuli, each stimulus was repeated twice for a total of 72 trials 
> per subject. Participants had to adjust two parameters of sounds, Centroid and Sound_Level_Peak, 
> for each stimulus. This is the head of my dataset (dependent variables: Centroid and 
> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2 levels)). 
> 
>> head(scrd)
>    Subject         Mat   Sh      Centroid            Sound_Level_Peak
> 1     Subject1      C     DS        1960.2               -20.963
> 2     Subject1      C     SN        5317.2               -42.741
> 3     Subject1      G     DS       11256.0               -16.480
> 4     Subject1      G     SN        9560.3               -19.682
> 5     Subject1      M     DS        4414.1               -33.723
> 6     Subject1      M     SN        4946.1               -23.648
> 
> 
> Based on my understanding of the online material I found, this is the procedure I used:
> 
> idata <- data.frame(scrd$Subject)
> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
> 
> 
> I get the following error
> 
> Error in check.imatrix(X.design) : 
>  Terms in the intra-subject model matrix are not orthogonal.
> 
> 
> Can anyone please tell me what is wrong in my formulas?

I suspect that instead of `idesign=~scrd$Subject` that you may want `idesign=~scrd|Subject` or after experimenting with an example in ?Anova, more probably `idesign=~scrd*Subject`

The `$` operator is generally not correctly used in formulas, since it would violate the scoping expectations of the package authors. It would be pulling in a vector of length nrow(scrd) from the object outside the function evaluation frame.

I also question whether the repeated measures within trial might also be needed to be accounted for in the ?idata' object and ?idesign' formula. I?m not a real statistician, so this is based more on syntactical reasoning rather than considered statistical advice. You probably do need to be consulting a real statistician.

> 
> Thanks in advance
> 
> Best regards
> 
> Angelo
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list, although your current posting seems to have survived intact.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Nov 25 18:51:38 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 25 Nov 2015 09:51:38 -0800
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F3D05C@FHSDB2D11-2.csu.mcmaster.ca>
References: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
	<ACD1644AA6C67E4FBD0C350625508EC810F3D05C@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <6CFBB4C0-F6EA-493E-AAC1-0628924ED5DC@comcast.net>


> On Nov 25, 2015, at 9:23 AM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Angelo,
> 
> I'm afraid that this is badly confused. To use Anova() for repeated measures, the data must be in "wide" format, with one row per subject. To see how this works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or for more detail, the R Journal paper at <{http://journal.r-project.org/archive/2013-1/RJournal_2013-1_fox-friendly-weisberg.pdf>.

I got an error with that link, but this link succeeded:

https://journal.r-project.org/archive/2013-1/fox-friendly-weisberg.pdf


> 
> I hope this helps,
> John
> 
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
> 
> 
> 
>> -----Original Message-----
>> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
>> Sent: Wednesday, November 25, 2015 11:30 AM
>> To: r-help at r-project.org
>> Cc: Fox, John
>> Subject: Syntax error in using Anova (car package)
>> 
>> Dear list members,
>> I am getting an error while performing a repeated measures MANOVA using
>> the Anova function
>> of the "car" package. I want to apply it on the results of an experiment
>> involving 19 participants,
>> who were subjected to 36 stimuli, each stimulus was repeated twice for a
>> total of 72 trials
>> per subject. Participants had to adjust two parameters of sounds,
>> Centroid and Sound_Level_Peak,
>> for each stimulus. This is the head of my dataset (dependent variables:
>> Centroid and
>> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
>> levels)).
>> 
>>> head(scrd)
>>    Subject         Mat   Sh      Centroid            Sound_Level_Peak
>> 1     Subject1      C     DS        1960.2               -20.963
>> 2     Subject1      C     SN        5317.2               -42.741
>> 3     Subject1      G     DS       11256.0               -16.480
>> 4     Subject1      G     SN        9560.3               -19.682
>> 5     Subject1      M     DS        4414.1               -33.723
>> 6     Subject1      M     SN        4946.1               -23.648
>> 
>> 
>> Based on my understanding of the online material I found, this is the
>> procedure I used:
>> 
>> idata <- data.frame(scrd$Subject)
>> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
>> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
>> 
>> 
>> I get the following error
>> 
>> Error in check.imatrix(X.design) :
>>  Terms in the intra-subject model matrix are not orthogonal.
>> 
>> 
>> Can anyone please tell me what is wrong in my formulas?
>> 
>> Thanks in advance
>> 
>> Best regards
>> 
>> Angelo
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From margarette.bayron at upr.edu  Wed Nov 25 18:09:22 2015
From: margarette.bayron at upr.edu (Margarette Bayron Arcelay)
Date: Wed, 25 Nov 2015 13:09:22 -0400
Subject: [R] Digitize2d Error
Message-ID: <CAEY_6RtyO7Daro5i4pXRCsVyqrnqdVAS2ntJ8zpK_b50PN-Qdw@mail.gmail.com>

Dear List,

I have been trying to use the package geomorph...but every time i load the
function digitized2d i get this error:

> digitize2d("Bolivina_lowmani.jpg", nlandmarks=6, scale=NULL,
"Bolivina_Practice.TPS", verbose=TRUE)
Error in coords[1:nland, , ] : subscript out of bounds

does somebody knows how to resolve it?

I am using a Mac OSX Yosemite version10.10.5

Thanks.

-- 
*Margarette Bayr?n Arcelay*
*Master Student & Teaching Assistant in the Department of Biology *
*University of Puerto Rico at Mayaguez *
*BS Industrial Microbiology & **BS General Biology*
*Office: B-154;01A | Lab: B-282B: Ecolab*
*Linkedin <http://pr.linkedin.com/in/margarettebayron> | *
*margarette.bayron at upr.edu* <margarette.bayron at upr.edu>

*Office Hours (B-282B): *
*Tue- 11:00-11:50am & 2:00-4:30pm*
*Thurs- 10:30-11:30am*

*"Chance favors a prepared mind"*

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Wed Nov 25 19:42:14 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Wed, 25 Nov 2015 18:42:14 +0000
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <6CFBB4C0-F6EA-493E-AAC1-0628924ED5DC@comcast.net>
References: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
	<ACD1644AA6C67E4FBD0C350625508EC810F3D05C@FHSDB2D11-2.csu.mcmaster.ca>
	<6CFBB4C0-F6EA-493E-AAC1-0628924ED5DC@comcast.net>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3D0EA@FHSDB2D11-2.csu.mcmaster.ca>

Dear David,

Thanks for the correction.

I copied the link from the R Journal website at <https://journal.r-project.org/archive/RJournal.bib>, so I guess they need to fix their .bib file.

I'm cc'ing the R Journal editor.

Best,
 John



> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Wednesday, November 25, 2015 12:52 PM
> To: Fox, John
> Cc: angelo.arcadi at virgilio.it; r-help at r-project.org
> Subject: Re: [R] Syntax error in using Anova (car package)
> 
> 
> > On Nov 25, 2015, at 9:23 AM, Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Angelo,
> >
> > I'm afraid that this is badly confused. To use Anova() for repeated
> measures, the data must be in "wide" format, with one row per subject.
> To see how this works, check out the OBrienKaiser example in ?Anova and
> ?OBrienKaiser, or for more detail, the R Journal paper at
> <{http://journal.r-project.org/archive/2013-1/RJournal_2013-1_fox-
> friendly-weisberg.pdf>.
> 
> I got an error with that link, but this link succeeded:
> 
> https://journal.r-project.org/archive/2013-1/fox-friendly-weisberg.pdf
> 
> 
> >
> > I hope this helps,
> > John
> >
> > -----------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
> >> Sent: Wednesday, November 25, 2015 11:30 AM
> >> To: r-help at r-project.org
> >> Cc: Fox, John
> >> Subject: Syntax error in using Anova (car package)
> >>
> >> Dear list members,
> >> I am getting an error while performing a repeated measures MANOVA
> using
> >> the Anova function
> >> of the "car" package. I want to apply it on the results of an
> experiment
> >> involving 19 participants,
> >> who were subjected to 36 stimuli, each stimulus was repeated twice
> for a
> >> total of 72 trials
> >> per subject. Participants had to adjust two parameters of sounds,
> >> Centroid and Sound_Level_Peak,
> >> for each stimulus. This is the head of my dataset (dependent
> variables:
> >> Centroid and
> >> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
> >> levels)).
> >>
> >>> head(scrd)
> >>    Subject         Mat   Sh      Centroid            Sound_Level_Peak
> >> 1     Subject1      C     DS        1960.2               -20.963
> >> 2     Subject1      C     SN        5317.2               -42.741
> >> 3     Subject1      G     DS       11256.0               -16.480
> >> 4     Subject1      G     SN        9560.3               -19.682
> >> 5     Subject1      M     DS        4414.1               -33.723
> >> 6     Subject1      M     SN        4946.1               -23.648
> >>
> >>
> >> Based on my understanding of the online material I found, this is the
> >> procedure I used:
> >>
> >> idata <- data.frame(scrd$Subject)
> >> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
> >> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
> >>
> >>
> >> I get the following error
> >>
> >> Error in check.imatrix(X.design) :
> >>  Terms in the intra-subject model matrix are not orthogonal.
> >>
> >>
> >> Can anyone please tell me what is wrong in my formulas?
> >>
> >> Thanks in advance
> >>
> >> Best regards
> >>
> >> Angelo
> >>
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA


From angelo.arcadi at virgilio.it  Thu Nov 26 04:04:01 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Thu, 26 Nov 2015 04:04:01 +0100 (CET)
Subject: [R] R: RE: Syntax error in using Anova (car package)
Message-ID: <828729051.1022791448507041842.JavaMail.defaultUser@defaultHost>



Dear Prof. John Fox, 
thanks a lot for your answer. Do you mean that my data set should have 19 rows 
(one for each of the 19 subjects)
and 144 columns (that is 72 trials * 2 dependent variables)? So should the 
dataframe look like this?

Subject     Stimulus_1.Centroid.repetition1  Stimulus_1.Centroid.repetition2 
Stimulus_1.Peak.repetition1  Stimulus_1.Peak.repetition2 
Subject1    1000                             2000                              
10                           20                
Subject2    500                              
600                                5                           6    
......
SubjectN


However, differently from the example reported in the document you kindly 
provided, my experiment
has two dependent variables. 
My guess is that the analysis should be the following (considering 12 types of 
stimuli and 6 repetitions 
for each of them, and 2 dependent variables)



stimulus_type <- factor(rep(c("Stimulus_1", "Stimulus_2", "Stimulus_3", 
"Stimulus_4", "Stimulus_5", "Stimulus_6", 
 "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11", 
"Stimulus_12"), c(6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)), 
levels=c("Stimulus_1", "Stimulus_2", "Stimulus_3", "Stimulus_4", "Stimulus_5", 
"Stimulus_6", 
 "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11", 
"Stimulus_12"))
 
repetitions <- ordered(rep(1:6, 12))

idata <- data.frame(stimulus_type, repetitions)

Notably, now idata has 72 rows (should it have 144 rows instead?). Then I 
continue with:


mod.ok <- lm(cbind(Stimulus_1.Centroid.repetition1, ....., Stimulus_12.Peak.
repetition2) ~  Subject, data=scrd)

av.ok <- Anova(mod.ok, idata=idata, idesign=~stimulus_type*repetitions)


Am I correct?

Thanks in advance

Best regards

Angelo




>----Messaggio originale----
>Da: jfox at mcmaster.ca
>Data: 25-nov-2015 17.23
>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>Cc: "r-help at r-project.org"<r-help at r-project.org>
>Ogg: RE: Syntax error in using Anova (car package)
>
>Dear Angelo,
>
>I'm afraid that this is badly confused. To use Anova() for repeated measures, 
the data must be in "wide" format, with one row per subject. To see how this 
works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or for 
more detail, the R Journal paper at <{http://journal.r-project.org/archive/2013-
1/RJournal_2013-1_fox-friendly-weisberg.pdf>.
>
>I hope this helps,
> John
>
>-----------------------------------------------
>John Fox, Professor
>McMaster University
>Hamilton, Ontario, Canada
>http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>> -----Original Message-----
>> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
>> Sent: Wednesday, November 25, 2015 11:30 AM
>> To: r-help at r-project.org
>> Cc: Fox, John
>> Subject: Syntax error in using Anova (car package)
>> 
>> Dear list members,
>> I am getting an error while performing a repeated measures MANOVA using
>> the Anova function
>> of the "car" package. I want to apply it on the results of an experiment
>> involving 19 participants,
>> who were subjected to 36 stimuli, each stimulus was repeated twice for a
>> total of 72 trials
>> per subject. Participants had to adjust two parameters of sounds,
>> Centroid and Sound_Level_Peak,
>> for each stimulus. This is the head of my dataset (dependent variables:
>> Centroid and
>> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
>> levels)).
>> 
>> > head(scrd)
>>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
>> 1     Subject1      C     DS        1960.2               -20.963
>> 2     Subject1      C     SN        5317.2               -42.741
>> 3     Subject1      G     DS       11256.0               -16.480
>> 4     Subject1      G     SN        9560.3               -19.682
>> 5     Subject1      M     DS        4414.1               -33.723
>> 6     Subject1      M     SN        4946.1               -23.648
>> 
>> 
>> Based on my understanding of the online material I found, this is the
>> procedure I used:
>> 
>> idata <- data.frame(scrd$Subject)
>> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
>> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
>> 
>> 
>> I get the following error
>> 
>> Error in check.imatrix(X.design) :
>>   Terms in the intra-subject model matrix are not orthogonal.
>> 
>> 
>> Can anyone please tell me what is wrong in my formulas?
>> 
>> Thanks in advance
>> 
>> Best regards
>> 
>> Angelo
>> 
>> 
>> 
>> 
>
>


From bgunter.4567 at gmail.com  Thu Nov 26 04:24:20 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 25 Nov 2015 19:24:20 -0800
Subject: [R] R: RE: Syntax error in using Anova (car package)
In-Reply-To: <828729051.1022791448507041842.JavaMail.defaultUser@defaultHost>
References: <828729051.1022791448507041842.JavaMail.defaultUser@defaultHost>
Message-ID: <CAGxFJbSUtvH4fac8JS1sLFaUqO3jrkZJMqbtXO67pwKHFQmqwQ@mail.gmail.com>

At this point, it seem obvious to me that you would benefit by local
statistical consulting, rather than further badgering on this list, as
you seem confused by both the underlying statistical concepts and how
they need to be handled in R/car. Pursuing your current course seems
destined to lead to folly.

Of course, both you and John (and others) are free to disagree ...

Cheers,
Bert



Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Nov 25, 2015 at 7:04 PM, angelo.arcadi at virgilio.it
<angelo.arcadi at virgilio.it> wrote:
>
>
> Dear Prof. John Fox,
> thanks a lot for your answer. Do you mean that my data set should have 19 rows
> (one for each of the 19 subjects)
> and 144 columns (that is 72 trials * 2 dependent variables)? So should the
> dataframe look like this?
>
> Subject     Stimulus_1.Centroid.repetition1  Stimulus_1.Centroid.repetition2
> Stimulus_1.Peak.repetition1  Stimulus_1.Peak.repetition2
> Subject1    1000                             2000
> 10                           20
> Subject2    500
> 600                                5                           6
> ......
> SubjectN
>
>
> However, differently from the example reported in the document you kindly
> provided, my experiment
> has two dependent variables.
> My guess is that the analysis should be the following (considering 12 types of
> stimuli and 6 repetitions
> for each of them, and 2 dependent variables)
>
>
>
> stimulus_type <- factor(rep(c("Stimulus_1", "Stimulus_2", "Stimulus_3",
> "Stimulus_4", "Stimulus_5", "Stimulus_6",
>  "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11",
> "Stimulus_12"), c(6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)),
> levels=c("Stimulus_1", "Stimulus_2", "Stimulus_3", "Stimulus_4", "Stimulus_5",
> "Stimulus_6",
>  "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11",
> "Stimulus_12"))
>
> repetitions <- ordered(rep(1:6, 12))
>
> idata <- data.frame(stimulus_type, repetitions)
>
> Notably, now idata has 72 rows (should it have 144 rows instead?). Then I
> continue with:
>
>
> mod.ok <- lm(cbind(Stimulus_1.Centroid.repetition1, ....., Stimulus_12.Peak.
> repetition2) ~  Subject, data=scrd)
>
> av.ok <- Anova(mod.ok, idata=idata, idesign=~stimulus_type*repetitions)
>
>
> Am I correct?
>
> Thanks in advance
>
> Best regards
>
> Angelo
>
>
>
>
>>----Messaggio originale----
>>Da: jfox at mcmaster.ca
>>Data: 25-nov-2015 17.23
>>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>>Cc: "r-help at r-project.org"<r-help at r-project.org>
>>Ogg: RE: Syntax error in using Anova (car package)
>>
>>Dear Angelo,
>>
>>I'm afraid that this is badly confused. To use Anova() for repeated measures,
> the data must be in "wide" format, with one row per subject. To see how this
> works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or for
> more detail, the R Journal paper at <{http://journal.r-project.org/archive/2013-
> 1/RJournal_2013-1_fox-friendly-weisberg.pdf>.
>>
>>I hope this helps,
>> John
>>
>>-----------------------------------------------
>>John Fox, Professor
>>McMaster University
>>Hamilton, Ontario, Canada
>>http://socserv.socsci.mcmaster.ca/jfox/
>>
>>
>>
>>> -----Original Message-----
>>> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
>>> Sent: Wednesday, November 25, 2015 11:30 AM
>>> To: r-help at r-project.org
>>> Cc: Fox, John
>>> Subject: Syntax error in using Anova (car package)
>>>
>>> Dear list members,
>>> I am getting an error while performing a repeated measures MANOVA using
>>> the Anova function
>>> of the "car" package. I want to apply it on the results of an experiment
>>> involving 19 participants,
>>> who were subjected to 36 stimuli, each stimulus was repeated twice for a
>>> total of 72 trials
>>> per subject. Participants had to adjust two parameters of sounds,
>>> Centroid and Sound_Level_Peak,
>>> for each stimulus. This is the head of my dataset (dependent variables:
>>> Centroid and
>>> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
>>> levels)).
>>>
>>> > head(scrd)
>>>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
>>> 1     Subject1      C     DS        1960.2               -20.963
>>> 2     Subject1      C     SN        5317.2               -42.741
>>> 3     Subject1      G     DS       11256.0               -16.480
>>> 4     Subject1      G     SN        9560.3               -19.682
>>> 5     Subject1      M     DS        4414.1               -33.723
>>> 6     Subject1      M     SN        4946.1               -23.648
>>>
>>>
>>> Based on my understanding of the online material I found, this is the
>>> procedure I used:
>>>
>>> idata <- data.frame(scrd$Subject)
>>> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
>>> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
>>>
>>>
>>> I get the following error
>>>
>>> Error in check.imatrix(X.design) :
>>>   Terms in the intra-subject model matrix are not orthogonal.
>>>
>>>
>>> Can anyone please tell me what is wrong in my formulas?
>>>
>>> Thanks in advance
>>>
>>> Best regards
>>>
>>> Angelo
>>>
>>>
>>>
>>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Bettina.Gruen at jku.at  Thu Nov 26 08:34:36 2015
From: Bettina.Gruen at jku.at (Bettina Gruen)
Date: Thu, 26 Nov 2015 08:34:36 +0100
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F3D0EA@FHSDB2D11-2.csu.mcmaster.ca>
References: <1978215458.966481448469006918.JavaMail.defaultUser@defaultHost>
	<ACD1644AA6C67E4FBD0C350625508EC810F3D05C@FHSDB2D11-2.csu.mcmaster.ca>
	<6CFBB4C0-F6EA-493E-AAC1-0628924ED5DC@comcast.net>
	<ACD1644AA6C67E4FBD0C350625508EC810F3D0EA@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <5656B60C.50009@jku.at>

Dear John,

thanks for the hint. This issue should be corrected now.

Best,
Bettina

On 11/25/2015 07:42 PM, Fox, John wrote:
> Dear David,
>
> Thanks for the correction.
>
> I copied the link from the R Journal website at <https://journal.r-project.org/archive/RJournal.bib>, so I guess they need to fix their .bib file.
>
> I'm cc'ing the R Journal editor.
>
> Best,
>   John
>
>
>
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net]
>> Sent: Wednesday, November 25, 2015 12:52 PM
>> To: Fox, John
>> Cc: angelo.arcadi at virgilio.it; r-help at r-project.org
>> Subject: Re: [R] Syntax error in using Anova (car package)
>>
>>
>>> On Nov 25, 2015, at 9:23 AM, Fox, John <jfox at mcmaster.ca> wrote:
>>>
>>> Dear Angelo,
>>>
>>> I'm afraid that this is badly confused. To use Anova() for repeated
>> measures, the data must be in "wide" format, with one row per subject.
>> To see how this works, check out the OBrienKaiser example in ?Anova and
>> ?OBrienKaiser, or for more detail, the R Journal paper at
>> <{http://journal.r-project.org/archive/2013-1/RJournal_2013-1_fox-
>> friendly-weisberg.pdf>.
>>
>> I got an error with that link, but this link succeeded:
>>
>> https://journal.r-project.org/archive/2013-1/fox-friendly-weisberg.pdf
>>
>>
>>>
>>> I hope this helps,
>>> John
>>>
>>> -----------------------------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> http://socserv.socsci.mcmaster.ca/jfox/
>>>
>>>
>>>
>>>> -----Original Message-----
>>>> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
>>>> Sent: Wednesday, November 25, 2015 11:30 AM
>>>> To: r-help at r-project.org
>>>> Cc: Fox, John
>>>> Subject: Syntax error in using Anova (car package)
>>>>
>>>> Dear list members,
>>>> I am getting an error while performing a repeated measures MANOVA
>> using
>>>> the Anova function
>>>> of the "car" package. I want to apply it on the results of an
>> experiment
>>>> involving 19 participants,
>>>> who were subjected to 36 stimuli, each stimulus was repeated twice
>> for a
>>>> total of 72 trials
>>>> per subject. Participants had to adjust two parameters of sounds,
>>>> Centroid and Sound_Level_Peak,
>>>> for each stimulus. This is the head of my dataset (dependent
>> variables:
>>>> Centroid and
>>>> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
>>>> levels)).
>>>>
>>>>> head(scrd)
>>>>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
>>>> 1     Subject1      C     DS        1960.2               -20.963
>>>> 2     Subject1      C     SN        5317.2               -42.741
>>>> 3     Subject1      G     DS       11256.0               -16.480
>>>> 4     Subject1      G     SN        9560.3               -19.682
>>>> 5     Subject1      M     DS        4414.1               -33.723
>>>> 6     Subject1      M     SN        4946.1               -23.648
>>>>
>>>>
>>>> Based on my understanding of the online material I found, this is the
>>>> procedure I used:
>>>>
>>>> idata <- data.frame(scrd$Subject)
>>>> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
>>>> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
>>>>
>>>>
>>>> I get the following error
>>>>
>>>> Error in check.imatrix(X.design) :
>>>>   Terms in the intra-subject model matrix are not orthogonal.
>>>>
>>>>
>>>> Can anyone please tell me what is wrong in my formulas?
>>>>
>>>> Thanks in advance
>>>>
>>>> Best regards
>>>>
>>>> Angelo
>>>>
>>>>
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>
>
>


From angelo.arcadi at virgilio.it  Thu Nov 26 10:33:00 2015
From: angelo.arcadi at virgilio.it (angelo.arcadi at virgilio.it)
Date: Thu, 26 Nov 2015 10:33:00 +0100 (CET)
Subject: [R] R: Re:  R: RE: Syntax error in using Anova (car package)
Message-ID: <703900996.1054571448530380752.JavaMail.defaultUser@defaultHost>

Dear Bert,
I do not have any statistical consultant that I can find near me or pay. Yes, 
I was confused by some statistical
concept, but I remember you, with humility, that human beings have the 
possibility to learn. Some even 
learn fast! Don't under estimate the will of a person of learning.

However, it is my hope that you are the only one that feels so much pissed off 
by my HELP requests!

The point of a forum is to provide help, don't you think? And there might be 
people in future that reading
my posts over internet can find solutions to the same problem. Do you know 
that there are many
people around that do not have a statistical consultant available and try to 
learn by themselves?

I do hope that some one could provide an answer to my last question, since it 
is just a syntactical question
and this is the most appropriate forum in the world that can help me (and 
maybe others in future) in 
understanding and solving the problem.

Thank you 

Best regards

Angelo


>----Messaggio originale----
>Da: bgunter.4567 at gmail.com
>Data: 26-nov-2015 3.24
>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>Cc: <jfox at mcmaster.ca>, "r-help at r-project.org"<r-help at r-project.org>
>Ogg: Re: [R] R: RE: Syntax error in using Anova (car package)
>
>At this point, it seem obvious to me that you would benefit by local
>statistical consulting, rather than further badgering on this list, as
>you seem confused by both the underlying statistical concepts and how
>they need to be handled in R/car. Pursuing your current course seems
>destined to lead to folly.
>
>Of course, both you and John (and others) are free to disagree ...
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>   -- Clifford Stoll
>
>
>On Wed, Nov 25, 2015 at 7:04 PM, angelo.arcadi at virgilio.it
><angelo.arcadi at virgilio.it> wrote:
>>
>>
>> Dear Prof. John Fox,
>> thanks a lot for your answer. Do you mean that my data set should have 19 
rows
>> (one for each of the 19 subjects)
>> and 144 columns (that is 72 trials * 2 dependent variables)? So should the
>> dataframe look like this?
>>
>> Subject     Stimulus_1.Centroid.repetition1  Stimulus_1.Centroid.
repetition2
>> Stimulus_1.Peak.repetition1  Stimulus_1.Peak.repetition2
>> Subject1    1000                             2000
>> 10                           20
>> Subject2    500
>> 600                                5                           6
>> ......
>> SubjectN
>>
>>
>> However, differently from the example reported in the document you kindly
>> provided, my experiment
>> has two dependent variables.
>> My guess is that the analysis should be the following (considering 12 types 
of
>> stimuli and 6 repetitions
>> for each of them, and 2 dependent variables)
>>
>>
>>
>> stimulus_type <- factor(rep(c("Stimulus_1", "Stimulus_2", "Stimulus_3",
>> "Stimulus_4", "Stimulus_5", "Stimulus_6",
>>  "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11",
>> "Stimulus_12"), c(6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6)),
>> levels=c("Stimulus_1", "Stimulus_2", "Stimulus_3", "Stimulus_4", 
"Stimulus_5",
>> "Stimulus_6",
>>  "Stimulus_7", "Stimulus_8", "Stimulus_9", "Stimulus_10", "Stimulus_11",
>> "Stimulus_12"))
>>
>> repetitions <- ordered(rep(1:6, 12))
>>
>> idata <- data.frame(stimulus_type, repetitions)
>>
>> Notably, now idata has 72 rows (should it have 144 rows instead?). Then I
>> continue with:
>>
>>
>> mod.ok <- lm(cbind(Stimulus_1.Centroid.repetition1, ....., Stimulus_12.
Peak.
>> repetition2) ~  Subject, data=scrd)
>>
>> av.ok <- Anova(mod.ok, idata=idata, idesign=~stimulus_type*repetitions)
>>
>>
>> Am I correct?
>>
>> Thanks in advance
>>
>> Best regards
>>
>> Angelo
>>
>>
>>
>>
>>>----Messaggio originale----
>>>Da: jfox at mcmaster.ca
>>>Data: 25-nov-2015 17.23
>>>A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
>>>Cc: "r-help at r-project.org"<r-help at r-project.org>
>>>Ogg: RE: Syntax error in using Anova (car package)
>>>
>>>Dear Angelo,
>>>
>>>I'm afraid that this is badly confused. To use Anova() for repeated 
measures,
>> the data must be in "wide" format, with one row per subject. To see how 
this
>> works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or 
for
>> more detail, the R Journal paper at <{http://journal.r-project.
org/archive/2013-
>> 1/RJournal_2013-1_fox-friendly-weisberg.pdf>.
>>>
>>>I hope this helps,
>>> John
>>>
>>>-----------------------------------------------
>>>John Fox, Professor
>>>McMaster University
>>>Hamilton, Ontario, Canada
>>>http://socserv.socsci.mcmaster.ca/jfox/
>>>
>>>
>>>
>>>> -----Original Message-----
>>>> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
>>>> Sent: Wednesday, November 25, 2015 11:30 AM
>>>> To: r-help at r-project.org
>>>> Cc: Fox, John
>>>> Subject: Syntax error in using Anova (car package)
>>>>
>>>> Dear list members,
>>>> I am getting an error while performing a repeated measures MANOVA using
>>>> the Anova function
>>>> of the "car" package. I want to apply it on the results of an experiment
>>>> involving 19 participants,
>>>> who were subjected to 36 stimuli, each stimulus was repeated twice for a
>>>> total of 72 trials
>>>> per subject. Participants had to adjust two parameters of sounds,
>>>> Centroid and Sound_Level_Peak,
>>>> for each stimulus. This is the head of my dataset (dependent variables:
>>>> Centroid and
>>>> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
>>>> levels)).
>>>>
>>>> > head(scrd)
>>>>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
>>>> 1     Subject1      C     DS        1960.2               -20.963
>>>> 2     Subject1      C     SN        5317.2               -42.741
>>>> 3     Subject1      G     DS       11256.0               -16.480
>>>> 4     Subject1      G     SN        9560.3               -19.682
>>>> 5     Subject1      M     DS        4414.1               -33.723
>>>> 6     Subject1      M     SN        4946.1               -23.648
>>>>
>>>>
>>>> Based on my understanding of the online material I found, this is the
>>>> procedure I used:
>>>>
>>>> idata <- data.frame(scrd$Subject)
>>>> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
>>>> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
>>>>
>>>>
>>>> I get the following error
>>>>
>>>> Error in check.imatrix(X.design) :
>>>>   Terms in the intra-subject model matrix are not orthogonal.
>>>>
>>>>
>>>> Can anyone please tell me what is wrong in my formulas?
>>>>
>>>> Thanks in advance
>>>>
>>>> Best regards
>>>>
>>>> Angelo
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.
html
>> and provide commented, minimal, self-contained, reproducible code.
>


From Markus.Koesters at uni-ulm.de  Thu Nov 26 14:39:34 2015
From: Markus.Koesters at uni-ulm.de (=?iso-8859-1?Q?Markus_K=F6sters?=)
Date: Thu, 26 Nov 2015 14:39:34 +0100
Subject: [R] metafor - Meta-Analysis of rare events / beta-binomial
	regression
Message-ID: <002901d1284f$e4f45400$aedcfc00$@uni-ulm.de>

Dear all,

 

I am currently writing a protocol for a meta-analysis which will analyze
suicidal events. Recently, O. Kuss has (DOI 10.1002/sim.6383) published a
paper that suggest using beta-binomial regression methods to incorporate
double-zero studies. He states that ?Methods that ignore information from
double-zero studies or use continuity corrections should no longer be used.?
It seems obvious to me that excluding studies with zero events will bias the
results and I am willing to follow his advice. However, I am not a a
biometrician, I have to admit that I am at a loss if and how it is possible
to fit such model within the metafor package. Can someone help me or should
I use the Yusuf?Peto odds ratio method as suggested in the Cochrane
handbook?

Many thanks in advance,

 

Markus

 

 


	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Thu Nov 26 16:25:04 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Thu, 26 Nov 2015 15:25:04 +0000
Subject: [R] Syntax error in using Anova (car package)
In-Reply-To: <828729051.1022791448507041842.JavaMail.defaultUser@defaultHost>
References: <828729051.1022791448507041842.JavaMail.defaultUser@defaultHost>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F3D483@FHSDB2D11-2.csu.mcmaster.ca>

Dear Angelo,

I'll answer the question that you posed but also try to explain why the analysis that you want to perform probably doesn't make sense.

Yes, if you want to take the MANOVA approach to repeated measures, you have 144 "dependent variables." The purpose if the idata and idesign arguments are to define the structure of the repeated measures and of the model to be fit to them. In your case, idata would have 144 rows and 3 columns for the combinations of levels of stimulus, repetition, and dependent variable. 

You can't, however, perform a MANOVA because with only 19 subjects the SSP matrices will be singular. Although you could perform a univariate repeated-measures ANOVA (if the two dependent variables are on the same scale), that's likely inadvisable. With only 19 subjects, the within-subjects design is probably too complex.

Is it possible to simplify? Is anything lost by averaging over repetitions, for example, or are you interested in how the responses develop over repetitions? If the latter, maybe you don't have enough data. Is there a compelling reason not to do separate analyses for the two dependent variables, particularly if they're on different scales?

Burt Gunter suggested that you'd do well to get some help, and I think that's good advice. You're representing this as a software-syntax problem but I think that there are serious issues about how best to perform the statistical analysis. There's a limit to how far you can get in an email discussion.

Best,
 John

> -----Original Message-----
> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
> Sent: November 25, 2015 10:04 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: R: RE: Syntax error in using Anova (car package)
> 
> 
> 
> Dear Prof. John Fox,
> thanks a lot for your answer. Do you mean that my data set should have 19
> rows (one for each of the 19 subjects) and 144 columns (that is 72 trials * 2
> dependent variables)? So should the dataframe look like this?
> 
> Subject     Stimulus_1.Centroid.repetition1  Stimulus_1.Centroid.repetition2
> Stimulus_1.Peak.repetition1  Stimulus_1.Peak.repetition2
> Subject1    1000                             2000
> 10                           20
> Subject2    500
> 600                                5                           6
> ......
> SubjectN
> 
> 
> However, differently from the example reported in the document you kindly
> provided, my experiment has two dependent variables.
> My guess is that the analysis should be the following (considering 12 types of
> stimuli and 6 repetitions for each of them, and 2 dependent variables)
> 
> 
> 
> stimulus_type <- factor(rep(c("Stimulus_1", "Stimulus_2", "Stimulus_3",
> "Stimulus_4", "Stimulus_5", "Stimulus_6",  "Stimulus_7", "Stimulus_8",
> "Stimulus_9", "Stimulus_10", "Stimulus_11", "Stimulus_12"), c(6, 6, 6, 6, 6, 6, 6,
> 6, 6, 6, 6, 6)), levels=c("Stimulus_1", "Stimulus_2", "Stimulus_3", "Stimulus_4",
> "Stimulus_5", "Stimulus_6",  "Stimulus_7", "Stimulus_8", "Stimulus_9",
> "Stimulus_10", "Stimulus_11",
> "Stimulus_12"))
> 
> repetitions <- ordered(rep(1:6, 12))
> 
> idata <- data.frame(stimulus_type, repetitions)
> 
> Notably, now idata has 72 rows (should it have 144 rows instead?). Then I
> continue with:
> 
> 
> mod.ok <- lm(cbind(Stimulus_1.Centroid.repetition1, ....., Stimulus_12.Peak.
> repetition2) ~  Subject, data=scrd)
> 
> av.ok <- Anova(mod.ok, idata=idata, idesign=~stimulus_type*repetitions)
> 
> 
> Am I correct?
> 
> Thanks in advance
> 
> Best regards
> 
> Angelo
> 
> 
> 
> 
> >----Messaggio originale----
> >Da: jfox at mcmaster.ca
> >Data: 25-nov-2015 17.23
> >A: "angelo.arcadi at virgilio.it"<angelo.arcadi at virgilio.it>
> >Cc: "r-help at r-project.org"<r-help at r-project.org>
> >Ogg: RE: Syntax error in using Anova (car package)
> >
> >Dear Angelo,
> >
> >I'm afraid that this is badly confused. To use Anova() for repeated measures,
> the data must be in "wide" format, with one row per subject. To see how this
> works, check out the OBrienKaiser example in ?Anova and ?OBrienKaiser, or
> for
> more detail, the R Journal paper at <{http://journal.r-
> project.org/archive/2013-
> 1/RJournal_2013-1_fox-friendly-weisberg.pdf>.
> >
> >I hope this helps,
> > John
> >
> >-----------------------------------------------
> >John Fox, Professor
> >McMaster University
> >Hamilton, Ontario, Canada
> >http://socserv.socsci.mcmaster.ca/jfox/
> >
> >
> >
> >> -----Original Message-----
> >> From: angelo.arcadi at virgilio.it [mailto:angelo.arcadi at virgilio.it]
> >> Sent: Wednesday, November 25, 2015 11:30 AM
> >> To: r-help at r-project.org
> >> Cc: Fox, John
> >> Subject: Syntax error in using Anova (car package)
> >>
> >> Dear list members,
> >> I am getting an error while performing a repeated measures MANOVA using
> >> the Anova function
> >> of the "car" package. I want to apply it on the results of an experiment
> >> involving 19 participants,
> >> who were subjected to 36 stimuli, each stimulus was repeated twice for a
> >> total of 72 trials
> >> per subject. Participants had to adjust two parameters of sounds,
> >> Centroid and Sound_Level_Peak,
> >> for each stimulus. This is the head of my dataset (dependent variables:
> >> Centroid and
> >> Sound_Level_Peak; independent variables: Mat (6 levels) and Sh (2
> >> levels)).
> >>
> >> > head(scrd)
> >>     Subject         Mat   Sh      Centroid            Sound_Level_Peak
> >> 1     Subject1      C     DS        1960.2               -20.963
> >> 2     Subject1      C     SN        5317.2               -42.741
> >> 3     Subject1      G     DS       11256.0               -16.480
> >> 4     Subject1      G     SN        9560.3               -19.682
> >> 5     Subject1      M     DS        4414.1               -33.723
> >> 6     Subject1      M     SN        4946.1               -23.648
> >>
> >>
> >> Based on my understanding of the online material I found, this is the
> >> procedure I used:
> >>
> >> idata <- data.frame(scrd$Subject)
> >> mod.ok <- lm(cbind(Centroid,Sound_Level_Peak) ~  Mat*Sh,data=scrd)
> >> av.ok <- Anova(mod.ok, idata=idata, idesign=~scrd$Subject)
> >>
> >>
> >> I get the following error
> >>
> >> Error in check.imatrix(X.design) :
> >>   Terms in the intra-subject model matrix are not orthogonal.
> >>
> >>
> >> Can anyone please tell me what is wrong in my formulas?
> >>
> >> Thanks in advance
> >>
> >> Best regards
> >>
> >> Angelo
> >>
> >>
> >>
> >>
> >
> >
> 


From marwa.syam at feps.edu.eg  Thu Nov 26 20:57:12 2015
From: marwa.syam at feps.edu.eg (Marwah Sabry Siam)
Date: Thu, 26 Nov 2015 21:57:12 +0200
Subject: [R] Memory problem when changing a function
Message-ID: <CAOGgF3-e4VX0dYpcGAVcEKg6Zo5e14CFZz8mJjeCUbME9WwUjw@mail.gmail.com>

I changed a function in a package and I want to run this new function.
It always gives the error of "Error in memory: couldn't allocate a
vector of 15.3 Gb" altough  the built in function doesn't give this
error.

My system is window 10, 8 Ram, AMD Quad-Core processor.
I've read about memory problems but I couldn't solve it. I tried the
code on another system with 16 RAM but it didn't work also. How can I
solve this problem given that i can't change the code?Thank you.
Regards,
Marwah Sabry Siam,
Teaching Assistant at Faculty of Economics and Political Science,
Statistics Department,
01225875205


From murdoch.duncan at gmail.com  Thu Nov 26 21:36:39 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 26 Nov 2015 15:36:39 -0500
Subject: [R] RGL Problem
In-Reply-To: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
References: <CAEY_6Ruk5E-fSBTRsUP+y4Uue8JRP0ShfK7iUhTYD2f7k-tykw@mail.gmail.com>
Message-ID: <56576D57.4040109@gmail.com>

On 22/11/2015 11:56 PM, Margarette Bayron Arcelay via R-help wrote:
> Dear List,
>
> Im using Rstudio on a macbook pro OS X Yosemite version 10.10.5 and im
> trying to
> open the package geomorph but a warning message related to rgl shows up.
>
>> library(geomorph)
> Loading required package: rgl
> Warning messages:
> 1: In rgl.init(initValue, onlyNULL) : RGL: unable to open X11 display
> 2: In fun(libname, pkgname) : error in rgl_init
>
> I have already installed X11 but this message keeps showing up.
>
> Does somebody knows what to do?
>

I think other messages in this thread may have helped you to get X11 
going.  If not, and the latest version doesn't work for you, please ask 
again.

If you get the very latest version 0.95.1415 of rgl from R-forge, it 
will continue on after this, using the "NULL" device.  This can't 
display from within R, but can still output WebGL code for display on a 
web page, so it may be useful for some systems.  (It can sort of display 
in RStudio; you need to load the rglwidget package, and call rglwidget() 
each time you want to see output.  This behaviour is still in flux.)

Duncan Murdoch


From jrkrideau at inbox.com  Thu Nov 26 21:38:40 2015
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 26 Nov 2015 12:38:40 -0800
Subject: [R] Memory problem when changing a function
In-Reply-To: <CAOGgF3-e4VX0dYpcGAVcEKg6Zo5e14CFZz8mJjeCUbME9WwUjw@mail.gmail.com>
Message-ID: <65E83548829.00000CAEjrkrideau@inbox.com>

Perhaps you should tell us what package you were using, what the function was, and how you changed it. 

Please have a look at
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example and/or http://adv-r.had.co.nz/Reproducibility.html for some suggestions on how to ask a question here.

Note that sample data, preferably in dput() format as described in the links above, is likely to be very important.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: marwa.syam at feps.edu.eg
> Sent: Thu, 26 Nov 2015 21:57:12 +0200
> To: r-help at r-project.org
> Subject: [R] Memory problem when changing a function
> 
> I changed a function in a package and I want to run this new function.
> It always gives the error of "Error in memory: couldn't allocate a
> vector of 15.3 Gb" altough  the built in function doesn't give this
> error.
> 
> My system is window 10, 8 Ram, AMD Quad-Core processor.
> I've read about memory problems but I couldn't solve it. I tried the
> code on another system with 16 RAM but it didn't work also. How can I
> solve this problem given that i can't change the code?Thank you.
> Regards,
> Marwah Sabry Siam,
> Teaching Assistant at Faculty of Economics and Political Science,
> Statistics Department,
> 01225875205
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From merricks.merricks at gmail.com  Fri Nov 27 01:59:53 2015
From: merricks.merricks at gmail.com (Margaret Donald)
Date: Fri, 27 Nov 2015 11:59:53 +1100
Subject: [R] rjags cannot find JAGS-4.0.0
Message-ID: <CAM=LvPw3tT5KwKwgo3eAPno4LsJspbpLM3mOHqS3BxjpUJhnWA@mail.gmail.com>

1. Despite being in R with administrative rights  the library "rjags" loads
in a temporary location.

> install.packages("rjags", dependencies=TRUE,
+       lib= "C:/Users/Margaret Donald/Documents/R/win-library/3.2")
trying URL 'https://cran.r-project.org/bin/windows/contrib/3.2/rjags_4-4.zip
'
Content type 'application/zip' length 525871 bytes (513 KB)
downloaded 513 KB

package ?rjags? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\Margaret
Donald\AppData\Local\Temp\RtmpMzv76s\downloaded_packages
#-----------------------------------------------------------------------------------------------------------------

2. Cannot find JAGS-4.0.0 which is in C;\programs\JAGS\JAGS-4.0.0.  How do
I get R to see JAGS-4.0.0
> library(rjags)
Error : .onLoad failed in loadNamespace() for 'rjags', details:
  call: fun(libname, pkgname)
  error: Failed to locate any version of JAGS version 4

The rjags package is just an interface to the JAGS library
Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
http://www.sourceforge.net/projects/mcmc-jags/files

Error: package or namespace load failed for ?rjags?
> library(R2jags)
Loading required package: rjags
Error : .onLoad failed in loadNamespace() for 'rjags', details:
  call: fun(libname, pkgname)
  error: Failed to locate any version of JAGS version 4

The rjags package is just an interface to the JAGS library
Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
http://www.sourceforge.net/projects/mcmc-jags/files

Error: package ?rjags? could not be loaded
>

Regards,
Margaret Donald
-- 
Margaret Donald
Post Doctoral researcher
University of New South Wales
margaret.donald at unsw.edu.au
0405 834 550

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Fri Nov 27 13:32:25 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Fri, 27 Nov 2015 12:32:25 +0000
Subject: [R] metafor - Meta-Analysis of rare events / beta-binomial
 regression
In-Reply-To: <002901d1284f$e4f45400$aedcfc00$@uni-ulm.de>
References: <002901d1284f$e4f45400$aedcfc00$@uni-ulm.de>
Message-ID: <56584D59.6070106@dewey.myzen.co.uk>

Dear Markus

This is not a direct answer to your question, I will leave that to 
Wolfgang but two thoughts:

1 - if all the studies have very sparse data
@article{bradburn07,
    author = {Bradburn, M J and Deeks, J J and Berlin, J A and Localio, 
A R},
    title = {Much ado about nothing: a comparison of the performance of
       meta--analytical methods with rare events},
    journal = {Statistics in Medicine},
    year = {2007},
    volume = {26},
    pages = {53--77},
    keywords = {meta-analysis, fixed effects, random effects}
}
suggests, surprisingly, that just collapsing the tables may be adequate

2 - there is a CRAN package mmeta which uses beta-binomial in a Bayesian 
perspective. I did not find the documentation very explicit but there is 
a paper in JSS.

On 26/11/2015 13:39, Markus K?sters wrote:
> Dear all,
>
>
>
> I am currently writing a protocol for a meta-analysis which will analyze
> suicidal events. Recently, O. Kuss has (DOI 10.1002/sim.6383) published a
> paper that suggest using beta-binomial regression methods to incorporate
> double-zero studies. He states that ?Methods that ignore information from
> double-zero studies or use continuity corrections should no longer be used.?
> It seems obvious to me that excluding studies with zero events will bias the
> results and I am willing to follow his advice. However, I am not a a
> biometrician, I have to admit that I am at a loss if and how it is possible
> to fit such model within the metafor package. Can someone help me or should
> I use the Yusuf?Peto odds ratio method as suggested in the Cochrane
> handbook?
>
> Many thanks in advance,
>
>
>
> Markus
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From sstoline at gmail.com  Fri Nov 27 13:52:31 2015
From: sstoline at gmail.com (Steven Stoline)
Date: Fri, 27 Nov 2015 07:52:31 -0500
Subject: [R] Graphing the Area of Definite Integral
Message-ID: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>

Dear All:

I am trying to explain to my students how to calculate the definite
integral using the Riemann sum. Can someone help me to graph the area under
the curve of the function, showing the curve as well as the rectangles
between 0 and 4..

*f(x) = x^3 - 2*x *

over the interval [0 , 4]



with many thanks
steve

-- 
Steven M. Stoline
1123 Forest Avenue
Portland, ME 04112
sstoline at gmail.com

	[[alternative HTML version deleted]]


From attenka at utu.fi  Fri Nov 27 13:24:09 2015
From: attenka at utu.fi (Atte Tenkanen)
Date: Fri, 27 Nov 2015 14:24:09 +0200
Subject: [R] From KDE-surfaces to 3d-printing format?
Message-ID: <56584B69.6060601@utu.fi>

Hi,

Is it somehow possible to produce 3D-printing data from the kernel 
density map produced by the
"DrawDensity3D"-function of "VecStatGraphs3D"-package?

I'm not an expert of KDE-technics, just can use that function to produce 
surfaces...

Best ,

Atte Tenkanen


From ajay_ramaseshan at hotmail.com  Fri Nov 27 12:03:05 2015
From: ajay_ramaseshan at hotmail.com (Ajay Ramaseshan)
Date: Fri, 27 Nov 2015 11:03:05 +0000
Subject: [R] Handling huge data of 17GB in R
Message-ID: <MA1PR01MB0504D818F82AC411900B467F9E030@MA1PR01MB0504.INDPRD01.PROD.OUTLOOK.COM>

Hello,


I am trying the DBSCAN clustering algorithm on a huge data matrix (26000 x 26000). I dont have the datapoints, just the distance matrix. It comes to 17 GB in the hard disk, and needs to be loaded into R to use the DBSCAN implementation (under package fpc). So I tried using read.csv but R crashed.


I am getting the message 'Killed after it runs for 10 minutes'


 dist<-read.csv('dist.csv',header=FALSE)
Killed

So I chceked is there any R package that handles big data like this, and came across bigmemory package in R. So I installed it and ran this command, but even this does not work, R exits.

> dist<-read.big.matrix('dist.csv',sep=',',header=FALSE)

 *** caught bus error ***
address 0x7fbc4faba000, cause 'non-existent physical address'

Traceback:
 1: .Call("bigmemory_CreateSharedMatrix", PACKAGE = "bigmemory",     row, col, colnames, rownames, typeLength, ini, separated)
 2: CreateSharedMatrix(as.double(nrow), as.double(ncol), as.character(colnames),     as.character(rownames), as.integer(typeVal), as.double(init),     as.logical(separated))
 3: big.matrix(nrow = numRows, ncol = createCols, type = type, dimnames = list(rowNames,     colNames), init = NULL, separated = separated, backingfile = backingfile,     backingpath = backingpath, descriptorfile = descriptorfile,     binarydescriptor = binarydescriptor, shared = TRUE)
 4: read.big.matrix("dist.csv", sep = ",", header = FALSE)
 5: read.big.matrix("dist.csv", sep = ",", header = FALSE)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection: 2
Save workspace image? [y/n/c]: n
Warning message:
In read.big.matrix("dist.csv", sep = ",", header = FALSE) :
  Because type was not specified, we chose double based on the first line of data.


So how do I handle such huge data in R for DBSCAN? Or is there any other implementation of DBSCAN in other programming language which can handle such a huge distance matrix of 17 GB ?



Regards,

Ajay

	[[alternative HTML version deleted]]


From Markus.Koesters at uni-ulm.de  Fri Nov 27 14:37:33 2015
From: Markus.Koesters at uni-ulm.de (=?utf-8?Q?Markus_K=C3=B6sters?=)
Date: Fri, 27 Nov 2015 14:37:33 +0100
Subject: [R] metafor - Meta-Analysis of rare events / beta-binomial
	regression
In-Reply-To: <56584D59.6070106@dewey.myzen.co.uk>
References: <002901d1284f$e4f45400$aedcfc00$@uni-ulm.de>
	<56584D59.6070106@dewey.myzen.co.uk>
Message-ID: <004501d12918$c5866c10$50934430$@uni-ulm.de>

Dear Michael,

Thank you very much for your input, that is very much appreciated. I have not considered that method, because it's rather outlawed in general. But it is also included in Kuss and if I understood correctly, the collapsing method (and the Cochrane method) both performed not too bad under FEM assumption and had weaknesses in REM. I usually prefer a REM approach, but in this case that may not be that important.
I will also read the mmeta paper and documentation.

Thanks a lot!

Markus


-----Urspr?ngliche Nachricht-----
Von: Michael Dewey [mailto:lists at dewey.myzen.co.uk] 
Gesendet: Freitag, 27. November 2015 13:32
An: Markus K?sters; r-help at r-project.org
Betreff: Re: [R] metafor - Meta-Analysis of rare events / beta-binomial regression

Dear Markus

This is not a direct answer to your question, I will leave that to Wolfgang but two thoughts:

1 - if all the studies have very sparse data @article{bradburn07,
    author = {Bradburn, M J and Deeks, J J and Berlin, J A and Localio, A R},
    title = {Much ado about nothing: a comparison of the performance of
       meta--analytical methods with rare events},
    journal = {Statistics in Medicine},
    year = {2007},
    volume = {26},
    pages = {53--77},
    keywords = {meta-analysis, fixed effects, random effects} } suggests, surprisingly, that just collapsing the tables may be adequate

2 - there is a CRAN package mmeta which uses beta-binomial in a Bayesian perspective. I did not find the documentation very explicit but there is a paper in JSS.

On 26/11/2015 13:39, Markus K?sters wrote:
> Dear all,
>
>
>
> I am currently writing a protocol for a meta-analysis which will 
> analyze suicidal events. Recently, O. Kuss has (DOI 10.1002/sim.6383) 
> published a paper that suggest using beta-binomial regression methods 
> to incorporate double-zero studies. He states that  Methods that 
> ignore information from double-zero studies or use continuity 
> corrections should no longer be used.  It seems obvious to me that 
> excluding studies with zero events will bias the results and I am 
> willing to follow his advice. However, I am not a a biometrician, I 
> have to admit that I am at a loss if and how it is possible to fit 
> such model within the metafor package. Can someone help me or should I 
> use the Yusuf Peto odds ratio method as suggested in the Cochrane handbook?
>
> Many thanks in advance,
>
>
>
> Markus
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html


From dusa.adrian at unibuc.ro  Fri Nov 27 14:43:14 2015
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Fri, 27 Nov 2015 15:43:14 +0200
Subject: [R] detect computer drives
Message-ID: <CAJ=0CtCASoapV1C+A7siVMa4OBDrq-_LRimS8xzObx1jUV7q8Q@mail.gmail.com>

Dear All,

Is there a method to detect the computer's drives?
That would include USB sticks, when they are recognised by the operating
system.

I believe to have read somewhere it's possible, but I am unable to find
that message.

Thank you for any hint,
Adrian


-- 
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr.90
050663 Bucharest sector 5
Romania

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Fri Nov 27 14:48:03 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 27 Nov 2015 08:48:03 -0500
Subject: [R] Graphing the Area of Definite Integral
In-Reply-To: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
References: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
Message-ID: <F2417F01-2010-4532-802C-210E6B91E3BC@bigelow.org>

Hi Steve,

Give RSeek.org a try ...

http://rseek.org/?q=show+area+under+curve

There a loads of examples and blogs on this topic at RSeek.org.  Under the 'Support' tab there is an exchange between two USM folk on this very topic.

Cheers,
Ben


On Nov 27, 2015, at 7:52 AM, Steven Stoline <sstoline at gmail.com> wrote:

> Dear All:
> 
> I am trying to explain to my students how to calculate the definite
> integral using the Riemann sum. Can someone help me to graph the area under
> the curve of the function, showing the curve as well as the rectangles
> between 0 and 4..
> 
> *f(x) = x^3 - 2*x *
> 
> over the interval [0 , 4]
> 
> 
> 
> with many thanks
> steve
> 
> -- 
> Steven M. Stoline
> 1123 Forest Avenue
> Portland, ME 04112
> sstoline at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From istazahn at gmail.com  Fri Nov 27 14:59:19 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 27 Nov 2015 08:59:19 -0500
Subject: [R] Handling huge data of 17GB in R
In-Reply-To: <MA1PR01MB0504D818F82AC411900B467F9E030@MA1PR01MB0504.INDPRD01.PROD.OUTLOOK.COM>
References: <MA1PR01MB0504D818F82AC411900B467F9E030@MA1PR01MB0504.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <CA+vqiLHsaO-4CaF1OZVMBwOaJUDmV-aMqX8LbQ+mKqnrWW4D0A@mail.gmail.com>

The easy way is to use a machine with say 32 Gb of ram. You can rent them
by the hour from AWS or google cloud at very reasonable prices.

Best,
Ista
On Nov 27, 2015 8:39 AM, "Ajay Ramaseshan" <ajay_ramaseshan at hotmail.com>
wrote:

> Hello,
>
>
> I am trying the DBSCAN clustering algorithm on a huge data matrix (26000 x
> 26000). I dont have the datapoints, just the distance matrix. It comes to
> 17 GB in the hard disk, and needs to be loaded into R to use the DBSCAN
> implementation (under package fpc). So I tried using read.csv but R crashed.
>
>
> I am getting the message 'Killed after it runs for 10 minutes'
>
>
>  dist<-read.csv('dist.csv',header=FALSE)
> Killed
>
> So I chceked is there any R package that handles big data like this, and
> came across bigmemory package in R. So I installed it and ran this command,
> but even this does not work, R exits.
>
> > dist<-read.big.matrix('dist.csv',sep=',',header=FALSE)
>
>  *** caught bus error ***
> address 0x7fbc4faba000, cause 'non-existent physical address'
>
> Traceback:
>  1: .Call("bigmemory_CreateSharedMatrix", PACKAGE = "bigmemory",     row,
> col, colnames, rownames, typeLength, ini, separated)
>  2: CreateSharedMatrix(as.double(nrow), as.double(ncol),
> as.character(colnames),     as.character(rownames), as.integer(typeVal),
> as.double(init),     as.logical(separated))
>  3: big.matrix(nrow = numRows, ncol = createCols, type = type, dimnames =
> list(rowNames,     colNames), init = NULL, separated = separated,
> backingfile = backingfile,     backingpath = backingpath, descriptorfile =
> descriptorfile,     binarydescriptor = binarydescriptor, shared = TRUE)
>  4: read.big.matrix("dist.csv", sep = ",", header = FALSE)
>  5: read.big.matrix("dist.csv", sep = ",", header = FALSE)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 2
> Save workspace image? [y/n/c]: n
> Warning message:
> In read.big.matrix("dist.csv", sep = ",", header = FALSE) :
>   Because type was not specified, we chose double based on the first line
> of data.
>
>
> So how do I handle such huge data in R for DBSCAN? Or is there any other
> implementation of DBSCAN in other programming language which can handle
> such a huge distance matrix of 17 GB ?
>
>
>
> Regards,
>
> Ajay
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Nov 27 15:02:46 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 27 Nov 2015 09:02:46 -0500
Subject: [R] Handling huge data of 17GB in R
In-Reply-To: <MA1PR01MB0504D818F82AC411900B467F9E030@MA1PR01MB0504.INDPRD01.PROD.OUTLOOK.COM>
References: <MA1PR01MB0504D818F82AC411900B467F9E030@MA1PR01MB0504.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <56586286.7000401@gmail.com>

On 27/11/2015 6:03 AM, Ajay Ramaseshan wrote:
> Hello,
>
>
> I am trying the DBSCAN clustering algorithm on a huge data matrix (26000 x 26000). I dont have the datapoints, just the distance matrix. It comes to 17 GB in the hard disk, and needs to be loaded into R to use the DBSCAN implementation (under package fpc). So I tried using read.csv but R crashed.
>
>
> I am getting the message 'Killed after it runs for 10 minutes'

This is coming from your OS, not from R.

>
>
>   dist<-read.csv('dist.csv',header=FALSE)

This would be much faster if you specified the column types and number 
of rows.  Try

read.csv('dist.csv', header=FALSE, colClasses = "numeric", nrows = 26000)

(assuming all entries are numeric).  And once you've read it in, convert 
it to a matrix; dataframe operations tend to be slow.

> Killed
>
> So I chceked is there any R package that handles big data like this, and came across bigmemory package in R. So I installed it and ran this command, but even this does not work, R exits.

Plain base R can handle a dataframe or matrix of that size, you don't 
need a special package. To see this, try

m <- matrix(0, 26000, 26000)

However, it takes a lot of memory. Make sure you are trying this on a 
machine with 10 or 20 GB of free memory. (Each copy of your data takes 
about 5 GB; operations may result in duplication.)

Duncan Murdoch

>> dist<-read.big.matrix('dist.csv',sep=',',header=FALSE)
>
>   *** caught bus error ***
> address 0x7fbc4faba000, cause 'non-existent physical address'
>
> Traceback:
>   1: .Call("bigmemory_CreateSharedMatrix", PACKAGE = "bigmemory",     row, col, colnames, rownames, typeLength, ini, separated)
>   2: CreateSharedMatrix(as.double(nrow), as.double(ncol), as.character(colnames),     as.character(rownames), as.integer(typeVal), as.double(init),     as.logical(separated))
>   3: big.matrix(nrow = numRows, ncol = createCols, type = type, dimnames = list(rowNames,     colNames), init = NULL, separated = separated, backingfile = backingfile,     backingpath = backingpath, descriptorfile = descriptorfile,     binarydescriptor = binarydescriptor, shared = TRUE)
>   4: read.big.matrix("dist.csv", sep = ",", header = FALSE)
>   5: read.big.matrix("dist.csv", sep = ",", header = FALSE)
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection: 2
> Save workspace image? [y/n/c]: n
> Warning message:
> In read.big.matrix("dist.csv", sep = ",", header = FALSE) :
>    Because type was not specified, we chose double based on the first line of data.
>
>
> So how do I handle such huge data in R for DBSCAN? Or is there any other implementation of DBSCAN in other programming language which can handle such a huge distance matrix of 17 GB ?
>
>
>
> Regards,
>
> Ajay
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From edd at debian.org  Fri Nov 27 15:03:43 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 27 Nov 2015 08:03:43 -0600
Subject: [R] detect computer drives
In-Reply-To: <CAJ=0CtCASoapV1C+A7siVMa4OBDrq-_LRimS8xzObx1jUV7q8Q@mail.gmail.com>
References: <CAJ=0CtCASoapV1C+A7siVMa4OBDrq-_LRimS8xzObx1jUV7q8Q@mail.gmail.com>
Message-ID: <22104.25279.511691.337056@max.nulle.part>


On 27 November 2015 at 15:43, Adrian Du?a wrote:
| Is there a method to detect the computer's drives?
| That would include USB sticks, when they are recognised by the operating
| system.

That is very obviously OS-dependent amd would need to be wrapped conditional
on the OS.  In R you can test for _explicitly named_ directories and files,
but not more.

As such, the question is not appropriate for this forum.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From dusa.adrian at unibuc.ro  Fri Nov 27 15:18:43 2015
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Fri, 27 Nov 2015 16:18:43 +0200
Subject: [R] detect computer drives
In-Reply-To: <22104.25279.511691.337056@max.nulle.part>
References: <CAJ=0CtCASoapV1C+A7siVMa4OBDrq-_LRimS8xzObx1jUV7q8Q@mail.gmail.com>
	<22104.25279.511691.337056@max.nulle.part>
Message-ID: <CAJ=0CtAp76FKUhP=ePVWQYKRSoA6Ogqu0AAxvFJYOpmzOJitQA@mail.gmail.com>

On Fri, Nov 27, 2015 at 4:03 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> On 27 November 2015 at 15:43, Adrian Du?a wrote:
> | Is there a method to detect the computer's drives?
> | That would include USB sticks, when they are recognised by the operating
> | system.
>
> That is very obviously OS-dependent amd would need to be wrapped
> conditional
> on the OS.  In R you can test for _explicitly named_ directories and files,
> but not more.


OK, thanks very much, it helps.
Adrian

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Nov 27 15:20:16 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 27 Nov 2015 15:20:16 +0100
Subject: [R] Graphing the Area of Definite Integral
In-Reply-To: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
References: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
Message-ID: <2D194A57-7B09-4F3C-95BD-5C7866D65C35@gmail.com>

Something like this?

f <- function(x) x^3-2*x
curve(f(x), from=0, to=4)
abline(h=0)
n <- 16
dx <- 4/n
right <- (1:n)*dx
left <- right - dx
mid <- right - dx/2
fm <- f(mid)
points(mid, fm)
rect(left,0,right,fm)

sum(fm*dx)

1/4 * 4^4 - 4^2


-pd


On 27 Nov 2015, at 13:52 , Steven Stoline <sstoline at gmail.com> wrote:

> Dear All:
> 
> I am trying to explain to my students how to calculate the definite
> integral using the Riemann sum. Can someone help me to graph the area under
> the curve of the function, showing the curve as well as the rectangles
> between 0 and 4..
> 
> *f(x) = x^3 - 2*x *
> 
> over the interval [0 , 4]
> 
> 
> 
> with many thanks
> steve
> 
> -- 
> Steven M. Stoline
> 1123 Forest Avenue
> Portland, ME 04112
> sstoline at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Nov 27 16:01:09 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 27 Nov 2015 16:01:09 +0100
Subject: [R] metafor - Meta-Analysis of rare events / beta-binomial
 regression
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F248F1D2B@UM-MAIL4112.unimaas.nl>

I would say the issue of how to deal with 'double-zero' studies is far from settled. For example, under the (non-central) hypergeometric model, studies with no events have a flat likelihood, so they are automatically excluded. That may go against our intuition (for various reasons, some of them are aptly described on page 1098 in Kuss, 2015), but from a likelhood perspective, it is correct. And since the Mantel-Haenszel and Peto's method are also based on the hypergeometric model, they should also exclude double-zero studies. Now I am not so sure if we are ready to completely scrap these methods altogether simply because they exclude double-zero studies.

However, for 2x2 table data, I am all in favor of using methods that make more realistic distributional assumptions than the 'standard' approach that assumes that the sampling distribution of the log(odds ratio) is normal and has a known sampling variance. That's why metafor includes rma.glmm() for fitting appropriate unconditional mixed-effects logistic and the conditional mixed-effects logistic (i.e., hypergeometric) model to such data. And for fixed-effects models, there are also rma.mh() and rma.peto() for the Mantel-Haenszel and Peto's method.

I may also eventually include the beta-binomial model, but I need to give this some more thought. If you already want to start using this model, you will find implementions thereof in VGAM, aods3, and gamlss.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Markus
> K?sters
> Sent: Friday, November 27, 2015 14:38
> To: 'Michael Dewey'; r-help at r-project.org
> Subject: Re: [R] metafor - Meta-Analysis of rare events / beta-binomial
> regression
> 
> Dear Michael,
> 
> Thank you very much for your input, that is very much appreciated. I have
> not considered that method, because it's rather outlawed in general. But
> it is also included in Kuss and if I understood correctly, the collapsing
> method (and the Cochrane method) both performed not too bad under FEM
> assumption and had weaknesses in REM. I usually prefer a REM approach,
> but in this case that may not be that important.
> I will also read the mmeta paper and documentation.
> 
> Thanks a lot!
> 
> Markus
> 
> -----Urspr?ngliche Nachricht-----
> Von: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Gesendet: Freitag, 27. November 2015 13:32
> An: Markus K?sters; r-help at r-project.org
> Betreff: Re: [R] metafor - Meta-Analysis of rare events / beta-binomial
> regression
> 
> Dear Markus
> 
> This is not a direct answer to your question, I will leave that to
> Wolfgang but two thoughts:
> 
> 1 - if all the studies have very sparse data @article{bradburn07,
>     author = {Bradburn, M J and Deeks, J J and Berlin, J A and Localio, A
> R},
>     title = {Much ado about nothing: a comparison of the performance of
>        meta--analytical methods with rare events},
>     journal = {Statistics in Medicine},
>     year = {2007},
>     volume = {26},
>     pages = {53--77},
>     keywords = {meta-analysis, fixed effects, random effects} } suggests,
> surprisingly, that just collapsing the tables may be adequate
> 
> 2 - there is a CRAN package mmeta which uses beta-binomial in a Bayesian
> perspective. I did not find the documentation very explicit but there is
> a paper in JSS.
> 
> On 26/11/2015 13:39, Markus K?sters wrote:
> > Dear all,
> >
> > I am currently writing a protocol for a meta-analysis which will
> > analyze suicidal events. Recently, O. Kuss has (DOI 10.1002/sim.6383)
> > published a paper that suggest using beta-binomial regression methods
> > to incorporate double-zero studies. He states that  Methods that
> > ignore information from double-zero studies or use continuity
> > corrections should no longer be used.  It seems obvious to me that
> > excluding studies with zero events will bias the results and I am
> > willing to follow his advice. However, I am not a a biometrician, I
> > have to admit that I am at a loss if and how it is possible to fit
> > such model within the metafor package. Can someone help me or should I
> > use the Yusuf Peto odds ratio method as suggested in the Cochrane
> handbook?
> >
> > Many thanks in advance,
> >
> > Markus

From marwa.syam at feps.edu.eg  Fri Nov 27 17:26:30 2015
From: marwa.syam at feps.edu.eg (Marwah Sabry Siam)
Date: Fri, 27 Nov 2015 18:26:30 +0200
Subject: [R] Memory problem when changing a function
In-Reply-To: <65E83548829.00000CAEjrkrideau@inbox.com>
References: <CAOGgF3-e4VX0dYpcGAVcEKg6Zo5e14CFZz8mJjeCUbME9WwUjw@mail.gmail.com>
	<65E83548829.00000CAEjrkrideau@inbox.com>
Message-ID: <CAOGgF391cgH79quZUaHOx4Xy4QpbjGCRgho9WgP5NKbyXK9Grw@mail.gmail.com>

i didn't write them because I thought it would be long. I am using
HPbayes package. I changed mp8.mle function. Two functions depend on
this one; loop.optim and prior.likewts, so I changed them and rename
them. The memory problem arises when applying the new loop.optim
function named loop.optim_m. The data is
> dput(AUS)
structure(list(Year = c(2011L, 2011L, 2011L, 2011L, 2011L, 2011L,
2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L,
2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L, 2011L
), Age = structure(c(1L, 2L, 3L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 4L, 5L,
6L), .Label = c("0", "04-Jan", "09-May", "100-104", "105-109",
"110+", "14-Oct", "15-19", "20-24", "25-29", "30-34", "35-39",
"40-44", "45-49", "50-54", "55-59", "60-64", "65-69", "70-74",
"75-79", "80-84", "85-89", "90-94", "95-99"), class = "factor"),
    mx = c(0.00381, 0.00018, 1e-04, 9e-05, 0.00033, 0.00046,
    0.00051, 0.00067, 0.00088, 0.00122, 0.00184, 0.00277, 0.00418,
    0.00645, 0.01005, 0.01725, 0.02955, 0.05478, 0.10292, 0.18274,
    0.30093, 0.45866, 0.62819, 0.75716), qx = c(0.0038, 0.00071,
    5e-04, 0.00047, 0.00163, 0.00229, 0.00256, 0.00337, 0.00437,
    0.00609, 0.00916, 0.01374, 0.02068, 0.03177, 0.04912, 0.08298,
    0.13827, 0.24257, 0.41114, 0.61482, 0.80056, 0.91837, 0.9686,
    1), ax = c(0.06, 1.56, 2.36, 2.79, 2.81, 2.47, 2.55, 2.59,
    2.6, 2.62, 2.7, 2.67, 2.65, 2.64, 2.67, 2.7, 2.67, 2.64,
    2.55, 2.34, 2.08, 1.74, 1.43, 1.32), lx = c(100000L, 99620L,
    99550L, 99500L, 99453L, 99291L, 99064L, 98811L, 98478L, 98048L,
    97450L, 96558L, 95231L, 93262L, 90299L, 85864L, 78739L, 67852L,
    51393L, 30263L, 11657L, 2325L, 190L, 6L), dx = c(380L, 70L,
    50L, 47L, 162L, 227L, 253L, 333L, 430L, 598L, 893L, 1327L,
    1969L, 2963L, 4436L, 7125L, 10887L, 16459L, 21130L, 18606L,
    9332L, 2135L, 184L, 6L), Lx = c(99643L, 398308L, 497617L,
    497397L, 496912L, 495882L, 494700L, 493254L, 491358L, 488818L,
    485200L, 479691L, 471529L, 459313L, 441161L, 412941L, 368377L,
    300433L, 205300L, 101820L, 31011L, 4655L, 293L, 8L), Tx = c(8215623L,
    8115980L, 7717672L, 7220055L, 6722657L, 6225746L, 5729864L,
    5235163L, 4741909L, 4250551L, 3761733L, 3276532L, 2796841L,
    2325312L, 1865999L, 1424838L, 1011897L, 643520L, 343087L,
    137787L, 35967L, 4956L, 301L, 8L), ex = c(82.16, 81.47, 77.53,
    72.56, 67.6, 62.7, 57.84, 52.98, 48.15, 43.35, 38.6, 33.93,
    29.37, 24.93, 20.66, 16.59, 12.85, 9.48, 6.68, 4.55, 3.09,
    2.13, 1.58, 1.32)), .Names = c("Year", "Age", "mx", "qx",
"ax", "lx", "dx", "Lx", "Tx", "ex"), class = "data.frame", row.names = c(NA,
-24L))

loop.optim_m function is

function (prior, nrisk, ndeath, d = 10, theta.dim = 8, age = c(1e-05,
    1, seq(5, 110, 5)))
{
    lx <- nrisk
    dx <- ndeath
    H.k <- prior
    pllwts <- prior.likewts_m(prior = prior, nrisk = lx, ndeath = dx)
    log.like.0 <- pllwts$log.like.0
    wts.0 <- pllwts$wts.0
    B0 <- 1000 * theta.dim
    q0 <- H.k
    d.keep <- 0
    theta.new <- H.k[wts.0 == max(wts.0), ]
    keep <- H.k
    ll.keep <- log.like.0
    opt.mu.d <- matrix(NA, nrow = d, ncol = theta.dim)
    opt.cov.d <- array(NA, dim = c(theta.dim, theta.dim, d))
    prior.cov <- cov(q0)
    opt.low <- apply(q0, 2, min)
    opt.hi <- apply(q0, 2, max)
    imp.keep <- theta.dim * 100
    max.log.like.0 <- max(log.like.0)
    mp8.mle <- function(theta, x.fit = age) {
        p.hat <- mod8p(theta = q0, x = age)
        ll = dmultinom(x = dx, size = NULL, prob = p.hat, log = FALSE)
        return(ll)
    }
    for (i in 1:d) {
        out <- optim(par = theta.new, fn = mp8.mle, method = "L-BFGS-B",
            lower = opt.low, upper = opt.hi, control = list(fnscale = -1,
                maxit = 1e+05))
        out.mu <- out$par
        if (out$value > max.log.like.0) {
            d.keep <- d.keep + 1
            opt.mu.d[i, ] <- out.mu
            out.hess <- hessian(func = mp8.mle, x = out$par)
            if (is.positive.definite(-out.hess)) {
                out.cov <- try(solve(-out.hess))
                opt.cov.d[, , i] <- out.cov
            }
            if (!is.positive.definite(-out.hess)) {
                out.grad <- grad(func = mp8.mle, x = out.mu)
                A <- out.grad %*% t(out.grad)
                out.prec <- try(solve(prior.cov)) + A
                if (!is.positive.definite(out.prec)) {
                  out.prec <- solve(prior.cov)
                }
                out.cov <- try(solve(out.prec))
                opt.cov.d[, , i] <- out.cov
            }
        }
        if (i == 1 & out$value <= max.log.like.0) {
            out.hess <- hessian(func = mp8.mle, x = out$par)
            if (is.positive.definite(-out.hess)) {
                out.cov <- solve(-out.hess)
            }
            if (!is.positive.definite(-out.hess)) {
                out.grad <- grad(func = mp8.mle, x = out.mu)
                A <- out.grad %*% t(out.grad)
                out.prec <- solve(prior.cov) + A
                if (!is.positive.definite(out.prec)) {
                  out.prec <- solve(prior.cov)
                }
                out.cov <- solve(out.prec)
            }
            warning("likelihood of first local maximum does not exceed
maximum \t\t\tlikelihood from the prior")
        }
        if (i < d) {
            keep <- keep[ll.keep != max(ll.keep), ]
            ll.keep <- ll.keep[ll.keep != max(ll.keep)]
            dist.to.mu <- mahalanobis(x = keep, center = out.mu,
                cov = out.cov)
            keep <- keep[rank(1/dist.to.mu) <= (d - i) * B0/d,
                ]
            ll.keep <- ll.keep[rank(1/dist.to.mu) <= (d - i) *
                B0/d]
            theta.new <- keep[ll.keep == max(ll.keep), ]
        }
    }
    return(list(opt.mu.d = opt.mu.d, opt.cov.d = opt.cov.d, theta.new
= theta.new,
        d.keep = d.keep, log.like.0 = log.like.0, wts.0 = wts.0))
}

Thank you for your reply.


From dwinsemius at comcast.net  Fri Nov 27 20:27:29 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Nov 2015 11:27:29 -0800
Subject: [R] rjags cannot find JAGS-4.0.0
In-Reply-To: <CAM=LvPw3tT5KwKwgo3eAPno4LsJspbpLM3mOHqS3BxjpUJhnWA@mail.gmail.com>
References: <CAM=LvPw3tT5KwKwgo3eAPno4LsJspbpLM3mOHqS3BxjpUJhnWA@mail.gmail.com>
Message-ID: <C4B61F15-B8BC-4F41-8F6C-5CBF0F981F6B@comcast.net>


> On Nov 26, 2015, at 4:59 PM, Margaret Donald <merricks.merricks at gmail.com> wrote:
> 
> 1. Despite being in R with administrative rights  the library "rjags" loads
> in a temporary location.
> 
>> install.packages("rjags", dependencies=TRUE,
> +       lib= "C:/Users/Margaret Donald/Documents/R/win-library/3.2")
> trying URL 'https://cran.r-project.org/bin/windows/contrib/3.2/rjags_4-4.zip
> '
> Content type 'application/zip' length 525871 bytes (513 KB)
> downloaded 513 KB
> 
> package ?rjags? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
>        C:\Users\Margaret
> Donald\AppData\Local\Temp\RtmpMzv76s\downloaded_packages

That?s not an indication of an error. The installation process always does that.


> #-----------------------------------------------------------------------------------------------------------------
> 
> 2. Cannot find JAGS-4.0.0 which is in C;\programs\JAGS\JAGS-4.0.0.  How do
> I get R to see JAGS-4.0.0

You might try to use Sys.setenv to create a properly directed JAGS_HOME

Sys.setenv(JAGS_HOME=?C:\programs\JAGS\JAGS-4.0.0?)

(I corrected the semi-colon.) 
>> library(rjags)
> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>  call: fun(libname, pkgname)
>  error: Failed to locate any version of JAGS version 4
> 
> The rjags package is just an interface to the JAGS library
> Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
> http://www.sourceforge.net/projects/mcmc-jags/files

I?m was having a perhaps similar problem on a Mac. The binary version 3-15 of rjags installed today from CRAN was trying to access /usr/local/lib/libjags.3.dylib, but since I have installed JAGS version 4.0.1 installed from the SourceForge repository, there is no ligjags.3.dylib, but instead there was only a /usr/local/lib/libjags.4.dylib


Going back to SourceForge and tracking down the older version of JAGS and installing version 3.4.0 was successful in getting rjags to load correctly. I suspect that with the release of JAGS v4 that there is some mismatch among the various editions of rjags and JAGS.

? 
David
> 
> Error: package or namespace load failed for ?rjags?
>> library(R2jags)
> Loading required package: rjags
> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>  call: fun(libname, pkgname)
>  error: Failed to locate any version of JAGS version 4
> 
> The rjags package is just an interface to the JAGS library
> Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
> http://www.sourceforge.net/projects/mcmc-jags/files
> 
> Error: package ?rjags? could not be loaded
>> 
> 
> Regards,
> Margaret Donald
> -- 
> Margaret Donald
> Post Doctoral researcher
> University of New South Wales
> margaret.donald at unsw.edu.au
> 0405 834 550
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bakiunal at yahoo.com  Fri Nov 27 20:30:25 2015
From: bakiunal at yahoo.com (Baki UNAL)
Date: Fri, 27 Nov 2015 19:30:25 +0000 (UTC)
Subject: [R] An error using frbs package
References: <199354402.9356228.1448652625299.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <199354402.9356228.1448652625299.JavaMail.yahoo@mail.yahoo.com>

Hello
I'm trying to run code below with frbs package. But I get an error saying: 

"Error in MF[k, temp[j + 2]] : subscript out of bounds" 
I couldn't spot the source of the error. What may be the problem?



##-----------------------------------------
varinp.mf <- matrix(c(4, 0, 0, 10, 50, 4, 10, 50, 70, 110, 4, 70, 110, 200, 200),
??????????????????? nrow = 5, byrow = FALSE)

rule <- matrix(c("d1","->","e1",
???????????????? "d2","->","e2",
???????????????? "d3","->","e3"),
?????????????? nrow=3, byrow=TRUE)

num.fvalinput <- matrix(c(3), nrow=1)

varinput.1 <- c("d1", "d2", "d3")

names.varinput <- c(varinput.1)

range.data <- matrix(c(0, 200, 0, 1), nrow=2)

type.defuz <- "COG"

type.tnorm <- "MIN"
type.snorm <- "MAX"
type.implication.func <- "ZADEH"

name <- "Sim-1"

newdata<- matrix(c(150), nrow= 1, byrow = TRUE)

colnames.var <- c("AralikD","Cikti")

num.fvaloutput <- matrix(c(3), nrow=1)

varoutput.1 <- c("e1", "e2", "e3")

names.varoutput <- c(varoutput.1)

varout.mf <- matrix(c(4, 0, 0, 0.1, 0.4, 4, 0.1, 0.4, 0.6, 0.9, 4, 0.6, 0.9, 1.0, 1.0),
??????????????????? nrow = 5, byrow = FALSE)

type.model <- "MAMDANI"

object <- frbs.gen(range.data, num.fvalinput, names.varinput, num.fvaloutput, varout.mf, 
?????????????????? names.varoutput, rule, varinp.mf, type.model, type.defuz, type.tnorm, 
?????????????????? type.snorm, func.tsk = NULL, colnames.var, type.implication.func, name)

plotMF(object)

res <- predict(object, newdata)$predicted.val
##-----------------------------------------

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Nov 27 21:06:50 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 27 Nov 2015 12:06:50 -0800
Subject: [R] rjags cannot find JAGS-4.0.0
In-Reply-To: <C4B61F15-B8BC-4F41-8F6C-5CBF0F981F6B@comcast.net>
References: <CAM=LvPw3tT5KwKwgo3eAPno4LsJspbpLM3mOHqS3BxjpUJhnWA@mail.gmail.com>
	<C4B61F15-B8BC-4F41-8F6C-5CBF0F981F6B@comcast.net>
Message-ID: <0DC4F550-A1C0-427D-BC5F-D3F3B0BEB702@comcast.net>


> On Nov 27, 2015, at 11:27 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Nov 26, 2015, at 4:59 PM, Margaret Donald <merricks.merricks at gmail.com> wrote:
>> 
>> 1. Despite being in R with administrative rights  the library "rjags" loads
>> in a temporary location.
>> 
>>> install.packages("rjags", dependencies=TRUE,
>> +       lib= "C:/Users/Margaret Donald/Documents/R/win-library/3.2")
>> trying URL 'https://cran.r-project.org/bin/windows/contrib/3.2/rjags_4-4.zip
>> '
>> Content type 'application/zip' length 525871 bytes (513 KB)
>> downloaded 513 KB
>> 
>> package ?rjags? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>>       C:\Users\Margaret
>> Donald\AppData\Local\Temp\RtmpMzv76s\downloaded_packages
> 
> That?s not an indication of an error. The installation process always does that.
> 
> 
>> #-----------------------------------------------------------------------------------------------------------------
>> 
>> 2. Cannot find JAGS-4.0.0 which is in C;\programs\JAGS\JAGS-4.0.0.  How do
>> I get R to see JAGS-4.0.0
> 
> You might try to use Sys.setenv to create a properly directed JAGS_HOME
> 
> Sys.setenv(JAGS_HOME=?C:\programs\JAGS\JAGS-4.0.0?)

Er ,,,, being a Mac user I forgot that this should have been (but I don?t really know whether `rjags` checks this environment variable, so am unsure if it was the correct notion in the first place)::

Sys.setenv(JAGS_HOME=?C:\\programs\\JAGS\\JAGS-4.0.0?)

Or:

Sys.setenv(JAGS_HOME=?C:/programs/JAGS/JAGS-4.0.0?)

? 
David.

> 
> (I corrected the semi-colon.) 
>>> library(rjags)
>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>> call: fun(libname, pkgname)
>> error: Failed to locate any version of JAGS version 4
>> 
>> The rjags package is just an interface to the JAGS library
>> Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
>> http://www.sourceforge.net/projects/mcmc-jags/files
> 
> I?m was having a perhaps similar problem on a Mac. The binary version 3-15 of rjags installed today from CRAN was trying to access /usr/local/lib/libjags.3.dylib, but since I have installed JAGS version 4.0.1 installed from the SourceForge repository, there is no ligjags.3.dylib, but instead there was only a /usr/local/lib/libjags.4.dylib
> 
> 
> Going back to SourceForge and tracking down the older version of JAGS and installing version 3.4.0 was successful in getting rjags to load correctly. I suspect that with the release of JAGS v4 that there is some mismatch among the various editions of rjags and JAGS.
> 
> ? 
> David
>> 
>> Error: package or namespace load failed for ?rjags?
>>> library(R2jags)
>> Loading required package: rjags
>> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>> call: fun(libname, pkgname)
>> error: Failed to locate any version of JAGS version 4
>> 
>> The rjags package is just an interface to the JAGS library
>> Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
>> http://www.sourceforge.net/projects/mcmc-jags/files
>> 
>> Error: package ?rjags? could not be loaded
>>> 
>> 
>> Regards,
>> Margaret Donald
>> -- 
>> Margaret Donald
>> Post Doctoral researcher
>> University of New South Wales
>> margaret.donald at unsw.edu.au
>> 0405 834 550
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sstoline at gmail.com  Fri Nov 27 21:36:33 2015
From: sstoline at gmail.com (Steven Stoline)
Date: Fri, 27 Nov 2015 15:36:33 -0500
Subject: [R] Graphing the Area of Definite Integral
In-Reply-To: <2D194A57-7B09-4F3C-95BD-5C7866D65C35@gmail.com>
References: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
	<2D194A57-7B09-4F3C-95BD-5C7866D65C35@gmail.com>
Message-ID: <CAHDp66D3y+uDSv1sNhQH4JGPippqx4tPHT3H8W2nN2z5-o0o5w@mail.gmail.com>

many thanks

steve

On Fri, Nov 27, 2015 at 9:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> Something like this?
>
> f <- function(x) x^3-2*x
> curve(f(x), from=0, to=4)
> abline(h=0)
> n <- 16
> dx <- 4/n
> right <- (1:n)*dx
> left <- right - dx
> mid <- right - dx/2
> fm <- f(mid)
> points(mid, fm)
> rect(left,0,right,fm)
>
> sum(fm*dx)
>
> 1/4 * 4^4 - 4^2
>
>
> -pd
>
>
> On 27 Nov 2015, at 13:52 , Steven Stoline <sstoline at gmail.com> wrote:
>
> > Dear All:
> >
> > I am trying to explain to my students how to calculate the definite
> > integral using the Riemann sum. Can someone help me to graph the area
> under
> > the curve of the function, showing the curve as well as the rectangles
> > between 0 and 4..
> >
> > *f(x) = x^3 - 2*x *
> >
> > over the interval [0 , 4]
> >
> >
> >
> > with many thanks
> > steve
> >
> > --
> > Steven M. Stoline
> > 1123 Forest Avenue
> > Portland, ME 04112
> > sstoline at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>


-- 
Steven M. Stoline
1123 Forest Avenue
Portland, ME 04112
sstoline at gmail.com

	[[alternative HTML version deleted]]


From attenka at utu.fi  Fri Nov 27 23:13:18 2015
From: attenka at utu.fi (Atte Tenkanen)
Date: Sat, 28 Nov 2015 00:13:18 +0200
Subject: [R] From KDE-surfaces to 3d-printing format?
In-Reply-To: <565862F1.2000000@gmail.com>
References: <56584B69.6060601@utu.fi> <565862F1.2000000@gmail.com>
Message-ID: <5658D57E.1080606@utu.fi>

Dear Duncan,

Thank you! I think, I got conversion working by putting just writeSTL() 
after the contour3d-function (inside DrawDensity3D()).

contour3d(....)
writeSTL("Data3D.stl")

At least, the stl-file seems to open in Pleasant3D and ply-file in MeshLab.

:-)

Best,

Atte

27.11.2015, 16.04, Duncan Murdoch kirjoitti:
> On 27/11/2015 7:24 AM, Atte Tenkanen wrote:
>> Hi,
>>
>> Is it somehow possible to produce 3D-printing data from the kernel
>> density map produced by the
>> "DrawDensity3D"-function of "VecStatGraphs3D"-package?
>>
>> I'm not an expert of KDE-technics, just can use that function to produce
>> surfaces...
>
> I don't know about that package, but you can certainly do so using 
> rgl.  See ?writeSTL (and the See Also links for other formats).
>
> Duncan Murdoch
>


From mviljamaa at kapsi.fi  Sat Nov 28 01:08:36 2015
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sat, 28 Nov 2015 02:08:36 +0200
Subject: [R] Using uniroot on c(0,
 1) when the function does not change sign in this interval?
Message-ID: <29dcca7011486d0aff963405a8cf8f64@kapsi.fi>

How can I use uniroot to find a root in the interval (0,1) when my 
function does not change sign in this interval.

I've tried plugging in some values and seems like e.g. f(50) < 0 and 
then I can pick c(0,50). But this sounds really weird, given that I need 
to find a root in (0,1).

So what are my options? Perhaps another function?


From sstoline at gmail.com  Sat Nov 28 06:50:46 2015
From: sstoline at gmail.com (Steven Stoline)
Date: Sat, 28 Nov 2015 00:50:46 -0500
Subject: [R] Graphing the Area of Definite Integral
In-Reply-To: <CAHDp66D3y+uDSv1sNhQH4JGPippqx4tPHT3H8W2nN2z5-o0o5w@mail.gmail.com>
References: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
	<2D194A57-7B09-4F3C-95BD-5C7866D65C35@gmail.com>
	<CAHDp66D3y+uDSv1sNhQH4JGPippqx4tPHT3H8W2nN2z5-o0o5w@mail.gmail.com>
Message-ID: <CAHDp66AM5vLRJzvfXEDfkz+M-zPuNoxZNhPm11Bq666B6YXafw@mail.gmail.com>

Dear Peter: in my previous email I forgot to reply to the list too

I used your code for more than one examples, and it works nicely. But when
I tried to use for the the function: f(x) = x^2, it looks like I am missing
something, but I could not figured it out.

This what I used:



f <- function(x) x^2

curve(f(x), from=-4, to=4, lwd=2, col="blue")
abline(h=0)
n <- 16
dx <- 8/n
right <- (1:n)*dx
left <- right - dx
mid <- right - dx/2
fm <- f(mid)
rect(left,0,right,fm, density = 20, border = "red")
points(mid, fm, col = "red", cex = 1.25, pch=19)
sum(fm*dx)



1/3 * (64+64)



with many thanks
steve

On Fri, Nov 27, 2015 at 3:36 PM, Steven Stoline <sstoline at gmail.com> wrote:

> many thanks
>
> steve
>
> On Fri, Nov 27, 2015 at 9:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> Something like this?
>>
>> f <- function(x) x^3-2*x
>> curve(f(x), from=0, to=4)
>> abline(h=0)
>> n <- 16
>> dx <- 4/n
>> right <- (1:n)*dx
>> left <- right - dx
>> mid <- right - dx/2
>> fm <- f(mid)
>> points(mid, fm)
>> rect(left,0,right,fm)
>>
>> sum(fm*dx)
>>
>> 1/4 * 4^4 - 4^2
>>
>>
>> -pd
>>
>>
>> On 27 Nov 2015, at 13:52 , Steven Stoline <sstoline at gmail.com> wrote:
>>
>> > Dear All:
>> >
>> > I am trying to explain to my students how to calculate the definite
>> > integral using the Riemann sum. Can someone help me to graph the area
>> under
>> > the curve of the function, showing the curve as well as the rectangles
>> > between 0 and 4..
>> >
>> > *f(x) = x^3 - 2*x *
>> >
>> > over the interval [0 , 4]
>> >
>> >
>> >
>> > with many thanks
>> > steve
>> >
>> > --
>> > Steven M. Stoline
>> > 1123 Forest Avenue
>> > Portland, ME 04112
>> > sstoline at gmail.com
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>
>
> --
> Steven M. Stoline
> 1123 Forest Avenue
> Portland, ME 04112
> sstoline at gmail.com
>



-- 
Steven M. Stoline
1123 Forest Avenue
Portland, ME 04112
sstoline at gmail.com

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Nov 28 17:12:27 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 28 Nov 2015 08:12:27 -0800
Subject: [R] Using uniroot on c(0,
 1) when the function does not change sign in this interval?
In-Reply-To: <29dcca7011486d0aff963405a8cf8f64@kapsi.fi>
References: <29dcca7011486d0aff963405a8cf8f64@kapsi.fi>
Message-ID: <CAGxFJbR2Z3FBHBo7sBQPoWQyuVV6wKk-pFhYb0xzeMak+QodxA@mail.gmail.com>

Is this a homework problem? This list has a no homework policy.

Cheers,
Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Nov 27, 2015 at 4:08 PM, mviljamaa <mviljamaa at kapsi.fi> wrote:
> How can I use uniroot to find a root in the interval (0,1) when my function
> does not change sign in this interval.
>
> I've tried plugging in some values and seems like e.g. f(50) < 0 and then I
> can pick c(0,50). But this sounds really weird, given that I need to find a
> root in (0,1).
>
> So what are my options? Perhaps another function?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Nov 28 19:11:45 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 28 Nov 2015 10:11:45 -0800
Subject: [R] Graphing the Area of Definite Integral
In-Reply-To: <CAHDp66AM5vLRJzvfXEDfkz+M-zPuNoxZNhPm11Bq666B6YXafw@mail.gmail.com>
References: <CAHDp66CP-bv+ojUD_39V7ZdduYNJYCRMDbJg-zSr_coRx4BipA@mail.gmail.com>
	<2D194A57-7B09-4F3C-95BD-5C7866D65C35@gmail.com>
	<CAHDp66D3y+uDSv1sNhQH4JGPippqx4tPHT3H8W2nN2z5-o0o5w@mail.gmail.com>
	<CAHDp66AM5vLRJzvfXEDfkz+M-zPuNoxZNhPm11Bq666B6YXafw@mail.gmail.com>
Message-ID: <CAF8bMcY1SH9pufuP7ujymNLrR18BF_xvdAuRTKDN1syM0ZedfQ@mail.gmail.com>

Your right <- (1:n)*dx mean that your leftmost rectangle's left edge
is at 0, but you want it to be at -4.  You should turn this into a function
so you don't have to remember how the variables in your code depend
on one another.   E.g.,

showIntegral <- function (f, xmin, xmax, n = 16)
{
    curve(f(x), from = xmin, to = xmax, lwd = 2, col = "blue")
    abline(h = 0)
    dx <- (xmax - xmin)/n
    right <- xmin + (1:n) * dx
    left <- right - dx
    mid <- right - dx/2
    fm <- f(mid)
    rect(left, 0, right, fm, density = 20, border = "red")
    points(mid, fm, col = "red", cex = 1.25, pch = 19)
    sum(fm * dx)
}
> showIntegral(f=function(x)x^2, xmin=-4, xmax=4, n=16)
[1] 42.5
> showIntegral(f=function(x)x^2, xmin=-4, xmax=4, n=256)
[1] 42.66602
> showIntegral(f=function(x)x^2, xmin=-4, xmax=4, n=1024)
[1] 42.66663

> 2*4^3/3
[1] 42.66667
> showIntegral
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Nov 27, 2015 at 9:50 PM, Steven Stoline <sstoline at gmail.com> wrote:
> Dear Peter: in my previous email I forgot to reply to the list too
>
> I used your code for more than one examples, and it works nicely. But when
> I tried to use for the the function: f(x) = x^2, it looks like I am missing
> something, but I could not figured it out.
>
> This what I used:
>
>
>
> f <- function(x) x^2
>
> curve(f(x), from=-4, to=4, lwd=2, col="blue")
> abline(h=0)
> n <- 16
> dx <- 8/n
> right <- (1:n)*dx
> left <- right - dx
> mid <- right - dx/2
> fm <- f(mid)
> rect(left,0,right,fm, density = 20, border = "red")
> points(mid, fm, col = "red", cex = 1.25, pch=19)
> sum(fm*dx)
>
>
>
> 1/3 * (64+64)
>
>
>
> with many thanks
> steve
>
> On Fri, Nov 27, 2015 at 3:36 PM, Steven Stoline <sstoline at gmail.com> wrote:
>
>> many thanks
>>
>> steve
>>
>> On Fri, Nov 27, 2015 at 9:20 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>> Something like this?
>>>
>>> f <- function(x) x^3-2*x
>>> curve(f(x), from=0, to=4)
>>> abline(h=0)
>>> n <- 16
>>> dx <- 4/n
>>> right <- (1:n)*dx
>>> left <- right - dx
>>> mid <- right - dx/2
>>> fm <- f(mid)
>>> points(mid, fm)
>>> rect(left,0,right,fm)
>>>
>>> sum(fm*dx)
>>>
>>> 1/4 * 4^4 - 4^2
>>>
>>>
>>> -pd
>>>
>>>
>>> On 27 Nov 2015, at 13:52 , Steven Stoline <sstoline at gmail.com> wrote:
>>>
>>> > Dear All:
>>> >
>>> > I am trying to explain to my students how to calculate the definite
>>> > integral using the Riemann sum. Can someone help me to graph the area
>>> under
>>> > the curve of the function, showing the curve as well as the rectangles
>>> > between 0 and 4..
>>> >
>>> > *f(x) = x^3 - 2*x *
>>> >
>>> > over the interval [0 , 4]
>>> >
>>> >
>>> >
>>> > with many thanks
>>> > steve
>>> >
>>> > --
>>> > Steven M. Stoline
>>> > 1123 Forest Avenue
>>> > Portland, ME 04112
>>> > sstoline at gmail.com
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> --
>>> Peter Dalgaard, Professor,
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Office: A 4.23
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>> --
>> Steven M. Stoline
>> 1123 Forest Avenue
>> Portland, ME 04112
>> sstoline at gmail.com
>>
>
>
>
> --
> Steven M. Stoline
> 1123 Forest Avenue
> Portland, ME 04112
> sstoline at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hamednofal85 at gmail.com  Sat Nov 28 19:04:16 2015
From: hamednofal85 at gmail.com (Hamed Nofal)
Date: Sat, 28 Nov 2015 20:04:16 +0200
Subject: [R] Isotonic Regression
Message-ID: <CAP7c-TYp-My8UPFSE8mh0s+a2MFoyeBScYTTg1B0fw5r7yu4vg@mail.gmail.com>

Dear Sir
I am new to R.statistics. I am an Anaesthetist using the version Ri 386
3.2.2
I have tested the patients' response sequence for a dose sequence, and I
need to calculate an estimate of the minimum dose that gives a certain
effect on a certain percentage of the patients' number.
 I am using the Canty Bootstrap package and the  functions:
preparePava.R  (last updated 16-Dec.2012)
bootIsotonicResample.R (last updated 17-Dec.2012)
bootIsotonicReggresion.R (last updated 17-Dec.2012)
bootBC.ci.R                   (last updated 28-Dec.2011)

Unfortunately, I always get the error messages
Error in is.data.frame(x) : argument "x" is missing, with no default
Error: object 'test.boot' not found

after using the boot package:

test.boot <- boot(data=test.df,statistic=bootIsotonicRegression,
R=9999,sim='parametric',ran.gen=bootIsotonicResample,
mle = list(baselinePava=testPava.df,firstDose=10,PROBABILITY.GAMMA=0.5),
baselinePava=testPava.df,PROBABILITY.GAMMA=0.5)

Searching all the program for "is.data.frame(x)", returns with nothing

May you kindly help me
thank you and best regards

Hamed

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Sat Nov 28 21:34:47 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Sat, 28 Nov 2015 20:34:47 +0000 (GMT)
Subject: [R] Some help understanding ggplot2
Message-ID: <9a82c48d-1e22-4157-bcaa-27e3f14403c9@me.com>

All,

I am trying to format a graph using scales and percent format but I am missing something and all my graphics books on ggplot2 are now quite far behind where ggplot2 is today. ? ?I seem to be missing a trick but the documentation implies that percent_format() will multiply by 100 and add %. ?I think the problem has to do with normalizing the data.

Glenn


Here is my data
structure(list(Rate = c(0.004975, 0.0126625, 0.0180375, 0.0136, 
0.016, 0.0196, 0.023, 0.0256, 0.0293, 0.0324, 0.0338), Maturity = c(0.0833, 
0.25, 0.5, 1, 2, 3, 4, 5, 7, 10, 30)), .Names = c("Rate", "Maturity"
), row.names = c("ED1M", "ED3M", "ED6M", "USSW1", "USSW2", "USSW3", 
"USSW4", "USSW5", "USSW7", "USSW10", "USSW30"), class = "data.frame")

data <- data.frame(Rates[1:2,2:12])
data <- data.frame(t(data))
Note: if I do not normalize the data by dividing by 100 percent_format() works but then 2.25% is 225%
data[,1] <- data[,1]/100
colnames(data) <- c("Rate", "Maturity")


Here is the color palette
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", 
"#000000","#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#000000")


This code does not work and returns an error
ggplot(data, aes(x=Maturity, y = Rate, colour = 'Rate')) +
geom_line(size = 1.5) +
theme_minimal()+
theme(panel.grid.major = element_line(size = .25, color = "grey")) +
scale_y_continuous(breaks = c(seq(0, 0.05, .0025)), percent_format()) +
scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5, 7, 10, 30)) +
ylab("Swap Rate (%)") +
xlab("Maturity") +
theme(axis.text.y = element_text(size = 15)) +
theme(axis.text.x = element_text(angle = 0, size = 15)) +
theme(axis.title = element_text(size = 20)) +
scale_colour_manual(values = cbbPalette, guide = FALSE)

This code works but no percent
ggplot(data, aes(x=Maturity, y = Rate, colour = 'Rate')) +
geom_line(size = 1.5) +
theme_minimal()+
theme(panel.grid.major = element_line(size = .25, color = "grey")) +
scale_y_continuous(breaks = c(seq(0, 0.05, .0025))) +
scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5, 7, 10, 30)) +
ylab("Swap Rate (%)") +
xlab("Maturity") +
theme(axis.text.y = element_text(size = 15)) +
theme(axis.text.x = element_text(angle = 0, size = 15)) +
theme(axis.title = element_text(size = 20)) +
scale_colour_manual(values = cbbPalette, guide = FALSE)

From btyner at gmail.com  Sun Nov 29 04:01:22 2015
From: btyner at gmail.com (Benjamin Tyner)
Date: Sat, 28 Nov 2015 22:01:22 -0500
Subject: [R] efficiently multiply each column of a sparse Matrix by a sparse
 vector
Message-ID: <565A6A82.9000501@gmail.com>

Hi,

Say I have a sparse Matrix X, and a sparse vector (stored as a 1-column 
sparse Matrix A), with X and A having the same number of rows, and I 
wish to multiply each column of X by A, but would like the operation to 
take full advantage of the sparseness of both X and A. In other words I 
want the result to be another sparse Matrix but not having any zeros 
calculated or stored unnecessarily. For concreteness,

    library(Matrix)
    set.seed(6860)
    X <- sparseMatrix(i = sample(1:10, 5L),
                      j = sample(1:10, 5L),
                      x = rep(1, 5),
                      dims = c(10L, 10L)
                      )
    A <- sparseMatrix(i = sample(1:10, 5L),
                      j = rep(1L, 5L),
                      x = rep(1, 5),
                      dims = c(10L, 1L)
                      )

and observe that

    print(X * A[, 1L, drop=TRUE])

gives the following, in which three 0s are not represented sparsely,

    10 x 10 sparse Matrix of class "dgCMatrix"

     [1,] . . . . . . . . . .
     [2,] . . 1 . . . . . . .
     [3,] . . . . . . . . . .
     [4,] . . . . . 0 . . . .
     [5,] . . . . . . 0 . . .
     [6,] . 1 . . . . . . . .
     [7,] . . . . . . . . . .
     [8,] . . . . . . . . . .
     [9,] . . . . . . . . . .
    [10,] 0 . . . . . . . . .

in other words I am wondering if there is a more efficient way to arrive 
at the same result as,

    print(X * A[, rep(1L, ncol(X)), drop=FALSE])

    10 x 10 sparse Matrix of class "dgCMatrix"

     [1,] . . . . . . . . . .
     [2,] . . 1 . . . . . . .
     [3,] . . . . . . . . . .
     [4,] . . . . . . . . . .
     [5,] . . . . . . . . . .
     [6,] . 1 . . . . . . . .
     [7,] . . . . . . . . . .
     [8,] . . . . . . . . . .
     [9,] . . . . . . . . . .
    [10,] . . . . . . . . . .

without the additional overhead of duplicating A for ncol(X) times.

This seems like such a simple thing, but has me stumped. Any ideas?

Regards,
Ben


From kb1304 at rit.edu  Sun Nov 29 03:47:19 2015
From: kb1304 at rit.edu (kb1304 at rit.edu)
Date: Sat, 28 Nov 2015 21:47:19 -0500
Subject: [R] Error in Contrast
Message-ID: <565a6737.4a568c0a.41fe5.ffffd24f@mx.google.com>

Hey,
I was trying to implement Stochastic Gradient Boosting in R. Following is my code in rstudio:

library(caret);
library(gbm);
library(plyr);
library(survival);
library(splines);
library(mlbench);
set.seed(35);
stack = read.csv("E:/Semester 3/BDA/PROJECT/Sample_SO.csv", head =TRUE,sep=",");
dim(stack); #displaying dimensions of the dataset

#SPLITTING TRAINING AND TESTING SET
totraining <- createDataPartition(stack$ID, p = .6, list = FALSE);
training <- stack[ totraining,]
test <- stack[-totraining,]

#PARAMETER SETTING
t_control <- trainControl(method = "cv", number = 10);


# GLM
start <- proc.time();

glm = train(ID ~ ., data = training,
             method = "gbm",
             metric = "ROC",
             trControl = t_control,
             verbose = FALSE)

When I am compiling last line, I am getting following error:

Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : 
  contrasts can be applied only to factors with 2 or more levels


Can anyone tell me where I am going wrong and How to rectify it. It?ll be greatful.

Thank you. Looking forward to it.

Regards,
Karteek Pradyumna Bulusu.

	[[alternative HTML version deleted]]


From kartikpradyumna92 at gmail.com  Sun Nov 29 04:04:46 2015
From: kartikpradyumna92 at gmail.com (Karteek Pradyumna Bulusu)
Date: Sat, 28 Nov 2015 22:04:46 -0500
Subject: [R] Error in 'Contrasts<-' while using GBM.
Message-ID: <CAKaJDkSOxxgHwYo1LS0+WKVCUoVqyhe--Xymw2TtNJ3VtN+t9w@mail.gmail.com>

Hey,

I was trying to implement Stochastic Gradient Boosting in R. Following is
my code in rstudio:



library(caret);

library(gbm);

library(plyr);

library(survival);

library(splines);

library(mlbench);

set.seed(35);

stack = read.csv("E:/Semester 3/BDA/PROJECT/Sample_SO.csv", head
=TRUE,sep=",");

dim(stack); #displaying dimensions of the dataset



#SPLITTING TRAINING AND TESTING SET

totraining <- createDataPartition(stack$ID, p = .6, list = FALSE);

training <- stack[ totraining,]

test <- stack[-totraining,]



#PARAMETER SETTING

t_control <- trainControl(method = "cv", number = 10);





# GLM

start <- proc.time();



glm = train(ID ~ ., data = training,

             method = "gbm",

             metric = "ROC",

             trControl = t_control,

             verbose = FALSE)



When I am compiling last line, I am getting following error:



Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :

  contrasts can be applied only to factors with 2 or more levels





Can anyone tell me where I am going wrong and How to rectify it. It?ll be
greatful.



Thank you. Looking forward to it.



Regards,
Karteek Pradyumna Bulusu.

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Nov 29 04:42:27 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 29 Nov 2015 14:42:27 +1100
Subject: [R] Isotonic Regression
In-Reply-To: <CAP7c-TYp-My8UPFSE8mh0s+a2MFoyeBScYTTg1B0fw5r7yu4vg@mail.gmail.com>
References: <CAP7c-TYp-My8UPFSE8mh0s+a2MFoyeBScYTTg1B0fw5r7yu4vg@mail.gmail.com>
Message-ID: <CA+8X3fWMP7y5krqTbFQKGZz9uzkaMHP5mj2FF0Djq5NAVtYmNQ@mail.gmail.com>

Hi Hamed,
I guess the first thing to do is to find out what "test.df" is:

is.data.frame(test.df)
dim(test.df)

If these come up FALSE or NULL respectively, you are not passing the
correct data argument to the boot function.

Jim


On Sun, Nov 29, 2015 at 5:04 AM, Hamed Nofal <hamednofal85 at gmail.com> wrote:

> Dear Sir
> I am new to R.statistics. I am an Anaesthetist using the version Ri 386
> 3.2.2
> I have tested the patients' response sequence for a dose sequence, and I
> need to calculate an estimate of the minimum dose that gives a certain
> effect on a certain percentage of the patients' number.
>  I am using the Canty Bootstrap package and the  functions:
> preparePava.R  (last updated 16-Dec.2012)
> bootIsotonicResample.R (last updated 17-Dec.2012)
> bootIsotonicReggresion.R (last updated 17-Dec.2012)
> bootBC.ci.R                   (last updated 28-Dec.2011)
>
> Unfortunately, I always get the error messages
> Error in is.data.frame(x) : argument "x" is missing, with no default
> Error: object 'test.boot' not found
>
> after using the boot package:
>
> test.boot <- boot(data=test.df,statistic=bootIsotonicRegression,
> R=9999,sim='parametric',ran.gen=bootIsotonicResample,
> mle = list(baselinePava=testPava.df,firstDose=10,PROBABILITY.GAMMA=0.5),
> baselinePava=testPava.df,PROBABILITY.GAMMA=0.5)
>
> Searching all the program for "is.data.frame(x)", returns with nothing
>
> May you kindly help me
> thank you and best regards
>
> Hamed
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From 13351275265 at 163.com  Sun Nov 29 11:00:18 2015
From: 13351275265 at 163.com (13351275265)
Date: Sun, 29 Nov 2015 18:00:18 +0800
Subject: [R] Frank Wang <fw42746@gmail.com>
In-Reply-To: <mailman.5.1448276402.6491.r-help@r-project.org>
References: <mailman.5.1448276402.6491.r-help@r-project.org>
Message-ID: <1811d91e.1784fe.15152b2caef.Coremail.13351275265@163.com>

Frank Wang <fw42746 at gmail.com>
you  can  use   function   substr()  to  split  the  number.

x<-c(substr("02d00000",1,4),substr("02d00000",5,8))
> x
[1] "02d0" "0000"
	[[alternative HTML version deleted]]


From mviljamaa at kapsi.fi  Sun Nov 29 19:22:07 2015
From: mviljamaa at kapsi.fi (mviljamaa)
Date: Sun, 29 Nov 2015 20:22:07 +0200
Subject: [R] Separating lines in ts.plot()?
Message-ID: <40f141f4a6cdac89c2ff50c8b94eee5f@kapsi.fi>

I'm using ts.plot() to plot a matrix of time series (each column is a 
ts).

What I noticed is that ts.plot() creates a lot of overlapping lines 
which makes it difficult to distinguish different series.

What options exist for making the series more easily read?


From drjimlemon at gmail.com  Sun Nov 29 21:29:04 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 30 Nov 2015 07:29:04 +1100
Subject: [R] Separating lines in ts.plot()?
In-Reply-To: <40f141f4a6cdac89c2ff50c8b94eee5f@kapsi.fi>
References: <40f141f4a6cdac89c2ff50c8b94eee5f@kapsi.fi>
Message-ID: <CA+8X3fVZA3z4MXMkLC4_+HboLuNnQHC_UGA_xuFKJxPrGouzLg@mail.gmail.com>

Hi mviljamaa,
Line color, line style, line width... An example or an image of the output
would help.

Jim

On Mon, Nov 30, 2015 at 5:22 AM, mviljamaa <mviljamaa at kapsi.fi> wrote:

> I'm using ts.plot() to plot a matrix of time series (each column is a ts).
>
> What I noticed is that ts.plot() creates a lot of overlapping lines which
> makes it difficult to distinguish different series.
>
> What options exist for making the series more easily read?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From merricks.merricks at gmail.com  Sun Nov 29 23:44:31 2015
From: merricks.merricks at gmail.com (Margaret Donald)
Date: Mon, 30 Nov 2015 09:44:31 +1100
Subject: [R] Converting a matrix to an mcmc object
Message-ID: <CAM=LvPycXRM=r=WFSSqA82ToQjfKmVd6aeEB8EPbxmUVt73mdA@mail.gmail.com>

Dear List,

I am using R2jags and post process some mcmc objects to produce a new
object, which is currently a matrix, which replicates the shape of the
objects from which it is derived.

I want to produce a Gelman-Rubin graph from its (implied) three chains, but
I need to coerce the matrix into an mcmc object if I am to use gelman.plot
or gelman.diag from the R-package "coda".

(The various mcmc functions in "coda" seem to work in the other
direction.....)

Regards,
Margaret Donald



-- 
Margaret Donald
Post Doctoral researcher
University of New South Wales
margaret.donald at unsw.edu.au
0405 834 550

	[[alternative HTML version deleted]]


From mxkuhn at gmail.com  Mon Nov 30 02:59:52 2015
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sun, 29 Nov 2015 20:59:52 -0500
Subject: [R] Error in 'Contrasts<-' while using GBM.
In-Reply-To: <CAKaJDkSOxxgHwYo1LS0+WKVCUoVqyhe--Xymw2TtNJ3VtN+t9w@mail.gmail.com>
References: <CAKaJDkSOxxgHwYo1LS0+WKVCUoVqyhe--Xymw2TtNJ3VtN+t9w@mail.gmail.com>
Message-ID: <CAJ9CoWnqOAZWz95kRjBiPOqJ28dB3Eg6pWvbcr8bsxHfAy70wg@mail.gmail.com>

Providing a reproducible example and the results of `sessionInfo` will help
get your question answered.

My only guess is that one or more of your predictors are factors and that
the in-sample data (used to build the model during resampling) have
different levels than the holdout samples.

Max

On Sat, Nov 28, 2015 at 10:04 PM, Karteek Pradyumna Bulusu <
kartikpradyumna92 at gmail.com> wrote:

> Hey,
>
> I was trying to implement Stochastic Gradient Boosting in R. Following is
> my code in rstudio:
>
>
>
> library(caret);
>
> library(gbm);
>
> library(plyr);
>
> library(survival);
>
> library(splines);
>
> library(mlbench);
>
> set.seed(35);
>
> stack = read.csv("E:/Semester 3/BDA/PROJECT/Sample_SO.csv", head
> =TRUE,sep=",");
>
> dim(stack); #displaying dimensions of the dataset
>
>
>
> #SPLITTING TRAINING AND TESTING SET
>
> totraining <- createDataPartition(stack$ID, p = .6, list = FALSE);
>
> training <- stack[ totraining,]
>
> test <- stack[-totraining,]
>
>
>
> #PARAMETER SETTING
>
> t_control <- trainControl(method = "cv", number = 10);
>
>
>
>
>
> # GLM
>
> start <- proc.time();
>
>
>
> glm = train(ID ~ ., data = training,
>
>              method = "gbm",
>
>              metric = "ROC",
>
>              trControl = t_control,
>
>              verbose = FALSE)
>
>
>
> When I am compiling last line, I am getting following error:
>
>
>
> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>
>   contrasts can be applied only to factors with 2 or more levels
>
>
>
>
>
> Can anyone tell me where I am going wrong and How to rectify it. It?ll be
> greatful.
>
>
>
> Thank you. Looking forward to it.
>
>
>
> Regards,
> Karteek Pradyumna Bulusu.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Mon Nov 30 04:55:08 2015
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 30 Nov 2015 05:55:08 +0200
Subject: [R] Extracing Unique Rows based on 2 Column
Message-ID: <DUB125-W50517870DB586FFACA4D62B3000@phx.gbl>

Dear group,
kindly, ?I have a data frame, as follows:


?Measure_id i j value ? ? ?rank
1 ? ? ? ? ? 1 2 3 ? 2.0 1.0000000
2 ? ? ? ? ? 1 5 1 ? 2.0 1.0000000
3 ? ? ? ? ? 1 2 1 ? 1.5 0.7500000
4 ? ? ? ? ? 1 5 2 ? 1.5 0.7500000
5 ? ? ? ? ? 1 7 3 ? 1.5 1.0000000
6 ? ? ? ? ? 1 2 4 ? 1.0 0.5000000
7 ? ? ? ? ? 1 7 5 ? 1.0 0.6666667
8 ? ? ? ? ? 2 5 2 ? 2.5 1.0000000
9 ? ? ? ? ? 2 2 1 ? 2.0 1.0000000
10 ? ? ? ? ?2 2 4 ? 2.0 1.0000000
.. ? ? ? ?... . . ? ... ? ? ? ...

I want to select distinct rows based on two coulmn (?Measure_id? and i )

for example for?Measure_id? = 1,2 ?the result would be....
1 ? ? ? ? ? 1 2 3 ? 2.0 1.0000000
2 ? ? ? ? ? 1 5 1 ? 2.0 1.0000000
5 ? ? ? ? ? 1 7 3 ? 1.5 1.0000000
8 ? ? ? ? ? 2 5 2 ? 2.5 1.0000000
9 ? ? ? ? ?2 2 1 ? 2.0 1.0000000


kindly how I could do this?

example of the data frame are followed using dput.

dput(orderlist)

structure(list(Measure_id = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,?
2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,?
5, 5, 5), i = c(2, 5, 2, 5, 7, 2, 7, 5, 2, 2, 7, 2, 5, 7, 2,?
2, 2, 5, 5, 7, 7, 2, 5, 2, 2, 5, 7, 7, 2, 2, 5, 2, 5, 7, 7),?
? ? j = c(3, 1, 1, 2, 3, 4, 5, 2, 1, 4, 5, 3, 1, 3, 1, 3, 4,?
? ? 1, 2, 3, 5, 4, 2, 1, 3, 1, 3, 5, 1, 4, 2, 3, 1, 3, 5), value = c(2,?
? ? 2, 1.5, 1.5, 1.5, 1, 1, 2.5, 2, 2, 2, 1.5, 1.5, 1, 1, 0,?
? ? 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1),?
? ? rank = c(1, 1, 0.75, 0.75, 1, 0.5, 0.666666666666667, 1,?
? ? 1, 1, 1, 0.75, 0.6, 0.5, 1, 0, 0, NaN, NaN, NaN, NaN, 1,?
? ? 1, 0, 0, 0, NaN, NaN, 1, 1, 1, 0.5, 0.5, 1, 1)), class = c("grouped_df",?
"tbl_df", "tbl", "data.frame"), row.names = c(NA, -35L), .Names = c("Measure_id",?
"i", "j", "value", "rank"), vars = list(Measure_id), indices = list(
? ? 0:6, 7:13, 14:20, 21:27, 28:34), group_sizes = c(7L, 7L,?
7L, 7L, 7L), biggest_group_size = 7L, labels = structure(list(
? ? Measure_id = c(1, 2, 3, 4, 5)), class = "data.frame", row.names = c(NA,?
-5L), .Names = "Measure_id", vars = list(Measure_id)))




thanks in advance
Ragia 		 	   		  

From boris.steipe at utoronto.ca  Mon Nov 30 05:36:19 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 29 Nov 2015 23:36:19 -0500
Subject: [R] Extracing Unique Rows based on 2 Column
In-Reply-To: <DUB125-W50517870DB586FFACA4D62B3000@phx.gbl>
References: <DUB125-W50517870DB586FFACA4D62B3000@phx.gbl>
Message-ID: <DD8678B0-D321-412D-A0A9-253D513E07F1@utoronto.ca>

A logical expression applied to a vector (such as a dataframe column) gives you a logical vector that you can use for selection. You can combine several of these with the & (AND) and | (OR) operator. In your case, you apparently want a range of possible values. Use the %in% operator.

Consider eg.

orderlist$i == 2
orderlist$i == 2 & orderlist$j < 3
orderlist$i %in% c(5, 7)

Cheers,
B.


On Nov 29, 2015, at 10:55 PM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:

> Dear group,
> kindly,  I have a data frame, as follows:
> 
> 
>  Measure_id i j value      rank
> 1           1 2 3   2.0 1.0000000
> 2           1 5 1   2.0 1.0000000
> 3           1 2 1   1.5 0.7500000
> 4           1 5 2   1.5 0.7500000
> 5           1 7 3   1.5 1.0000000
> 6           1 2 4   1.0 0.5000000
> 7           1 7 5   1.0 0.6666667
> 8           2 5 2   2.5 1.0000000
> 9           2 2 1   2.0 1.0000000
> 10          2 2 4   2.0 1.0000000
> ..        ... . .   ...       ...
> 
> I want to select distinct rows based on two coulmn ( Measure_id  and i )
> 
> for example for Measure_id  = 1,2  the result would be....
> 1           1 2 3   2.0 1.0000000
> 2           1 5 1   2.0 1.0000000
> 5           1 7 3   1.5 1.0000000
> 8           2 5 2   2.5 1.0000000
> 9          2 2 1   2.0 1.0000000
> 
> 
> kindly how I could do this?
> 
> example of the data frame are followed using dput.
> 
> dput(orderlist)
> 
> structure(list(Measure_id = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 
> 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 
> 5, 5, 5), i = c(2, 5, 2, 5, 7, 2, 7, 5, 2, 2, 7, 2, 5, 7, 2, 
> 2, 2, 5, 5, 7, 7, 2, 5, 2, 2, 5, 7, 7, 2, 2, 5, 2, 5, 7, 7), 
>     j = c(3, 1, 1, 2, 3, 4, 5, 2, 1, 4, 5, 3, 1, 3, 1, 3, 4, 
>     1, 2, 3, 5, 4, 2, 1, 3, 1, 3, 5, 1, 4, 2, 3, 1, 3, 5), value = c(2, 
>     2, 1.5, 1.5, 1.5, 1, 1, 2.5, 2, 2, 2, 1.5, 1.5, 1, 1, 0, 
>     0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1), 
>     rank = c(1, 1, 0.75, 0.75, 1, 0.5, 0.666666666666667, 1, 
>     1, 1, 1, 0.75, 0.6, 0.5, 1, 0, 0, NaN, NaN, NaN, NaN, 1, 
>     1, 0, 0, 0, NaN, NaN, 1, 1, 1, 0.5, 0.5, 1, 1)), class = c("grouped_df", 
> "tbl_df", "tbl", "data.frame"), row.names = c(NA, -35L), .Names = c("Measure_id", 
> "i", "j", "value", "rank"), vars = list(Measure_id), indices = list(
>     0:6, 7:13, 14:20, 21:27, 28:34), group_sizes = c(7L, 7L, 
> 7L, 7L, 7L), biggest_group_size = 7L, labels = structure(list(
>     Measure_id = c(1, 2, 3, 4, 5)), class = "data.frame", row.names = c(NA, 
> -5L), .Names = "Measure_id", vars = list(Measure_id)))
> 
> 
> 
> 
> thanks in advance
> Ragia 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Nov 30 07:31:01 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 30 Nov 2015 17:31:01 +1100
Subject: [R] Converting a matrix to an mcmc object
In-Reply-To: <CAM=LvPycXRM=r=WFSSqA82ToQjfKmVd6aeEB8EPbxmUVt73mdA@mail.gmail.com>
References: <CAM=LvPycXRM=r=WFSSqA82ToQjfKmVd6aeEB8EPbxmUVt73mdA@mail.gmail.com>
Message-ID: <CA+8X3fVH-zjkzfmyxkN19NTgbX0Fg_aX6uOmpJo21xqtM4HR_A@mail.gmail.com>

Hi Margaret,
Doesn't the "mcmc" function in the "coda" package create an mcmc object
from a matrix?

Jim


On Mon, Nov 30, 2015 at 9:44 AM, Margaret Donald <
merricks.merricks at gmail.com> wrote:

> Dear List,
>
> I am using R2jags and post process some mcmc objects to produce a new
> object, which is currently a matrix, which replicates the shape of the
> objects from which it is derived.
>
> I want to produce a Gelman-Rubin graph from its (implied) three chains, but
> I need to coerce the matrix into an mcmc object if I am to use gelman.plot
> or gelman.diag from the R-package "coda".
>
> (The various mcmc functions in "coda" seem to work in the other
> direction.....)
>
> Regards,
> Margaret Donald
>
>
>
> --
> Margaret Donald
> Post Doctoral researcher
> University of New South Wales
> margaret.donald at unsw.edu.au
> 0405 834 550
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From johannes at huesing.name  Mon Nov 30 08:14:47 2015
From: johannes at huesing.name (Johannes Huesing)
Date: Mon, 30 Nov 2015 08:14:47 +0100
Subject: [R] Extracing Unique Rows based on 2 Column
In-Reply-To: <DUB125-W50517870DB586FFACA4D62B3000@phx.gbl>
References: <DUB125-W50517870DB586FFACA4D62B3000@phx.gbl>
Message-ID: <20151130071446.GA7716@volois>

Ragia Ibrahim <ragia11 at hotmail.com> [Mon, Nov 30, 2015 at 04:55:08AM CET]:
>Dear group,
>kindly, ?I have a data frame, as follows:
>
>
>?Measure_id i j value ? ? ?rank
>
>I want to select distinct rows based on two coulmn (?Measure_id? and i )
>

I didn't get your example code to run but the following works for me:

dfr <- data.frame(Measure_id = c(1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,
2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5,
5, 5, 5), i = c(2, 5, 2, 5, 7, 2, 7, 5, 2, 2, 7, 2, 5, 7, 2,
2, 2, 5, 5, 7, 7, 2, 5, 2, 2, 5, 7, 7, 2, 2, 5, 2, 5, 7, 7),
   j = c(3, 1, 1, 2, 3, 4, 5, 2, 1, 4, 5, 3, 1, 3, 1, 3, 4,
   1, 2, 3, 5, 4, 2, 1, 3, 1, 3, 5, 1, 4, 2, 3, 1, 3, 5), value = c(2,
   2, 1.5, 1.5, 1.5, 1, 1, 2.5, 2, 2, 2, 1.5, 1.5, 1, 1, 0,
   0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 1, 1, 1, 1))

dfr[!duplicated(dfr[, c("Measure_id", "i")]), ]

This returns

    Measure_id i j value
1           1 2 3   2.0
2           1 5 1   2.0
5           1 7 3   1.5
8           2 5 2   2.5
9           2 2 1   2.0
11          2 7 5   2.0
15          3 2 1   1.0
18          3 5 1   0.0
20          3 7 3   0.0
22          4 2 4   1.0
23          4 5 2   1.0
27          4 7 3   0.0
29          5 2 1   2.0
31          5 5 2   2.0
34          5 7 3   1.0

Is that what you were aiming at?

Note that I had to find the solution myself, which I did, 
thanks to the documentation I got by ?unique, which pointed
me to duplicated().

-- 
Johannes H?sing               
http://derwisch.wikidot.com
Threema-ID: VHVJYH3H


From cdetermanjr at gmail.com  Mon Nov 23 14:10:09 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Mon, 23 Nov 2015 07:10:09 -0600
Subject: [R] [R-pkgs] New package: gpuR
Message-ID: <CAKxd1KNuX5LYPBhCpf8GKbeJBYpf82Vcrwv6GUK35kVNh6Bg-A@mail.gmail.com>

R Users,

I am happy to inform you that my 'gpuR' package has just been accepted to
CRAN.

https://cran.r-project.org/web/packages/gpuR/index.html

The gpuR package is designed to provide simple to use functions for
leveraging GPU's for computing.  Although there are a couple existing
packages for GPU's in R most are specific to NVIDIA GPU's and have very
limited and specific functions.  The packaged is based on an OpenCL backend
in conjunction with the ViennaCL library (which is packaged within the
RViennaCL package).  This allows the user to use almost any GPU (Intel,
AMD, or NVIDIA).  It is my hope that these functions can be used to more
rapidly develop algorithms within R that can leverage GPUs.

The package is structured to use a few new S4 classes that retain the
object either on the host CPU or in GPU memory (thereby avoiding transfer
time).  I have included a minimal introductory vignette describing the
package further, providing a simple use case, and listing currently
available functions.

https://cran.r-project.org/web/packages/gpuR/vignettes/gpuR.pdf

You can view the github page here:

https://github.com/cdeterman/gpuR

which also contains a wiki to help with installation.  Although it must be
compiled, it is able to be installed on Linux, Mac OSX, and Windows
platforms.

I welcome any comments, issues (please submit on the github), and of course
additional contributions.

Regards,
Charles Determan

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From Markus.Koesters at uni-ulm.de  Mon Nov 30 09:44:55 2015
From: Markus.Koesters at uni-ulm.de (=?UTF-8?Q?Markus_K=C3=B6sters?=)
Date: Mon, 30 Nov 2015 09:44:55 +0100
Subject: [R] metafor - Meta-Analysis of rare events / beta-binomial
	regression
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F248F1D2B@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730F248F1D2B@UM-MAIL4112.unimaas.nl>
Message-ID: <008301d12b4b$631f1ce0$295d56a0$@uni-ulm.de>

Dear Wolfgang,

Thanks a lot. I am sure that debate will continue. Kuss has apparently the advantage to be rather universal, which from an users perspective is always a big advantage. 

I'll check other options and think it over.

Many thanks,

Markus



-----Urspr?ngliche Nachricht-----
Von: Viechtbauer Wolfgang (STAT) [mailto:wolfgang.viechtbauer at maastrichtuniversity.nl] 
Gesendet: Freitag, 27. November 2015 16:01
An: Markus K?sters; 'Michael Dewey'; r-help at r-project.org
Betreff: RE: [R] metafor - Meta-Analysis of rare events / beta-binomial regression

I would say the issue of how to deal with 'double-zero' studies is far from settled. For example, under the (non-central) hypergeometric model, studies with no events have a flat likelihood, so they are automatically excluded. That may go against our intuition (for various reasons, some of them are aptly described on page 1098 in Kuss, 2015), but from a likelhood perspective, it is correct. And since the Mantel-Haenszel and Peto's method are also based on the hypergeometric model, they should also exclude double-zero studies. Now I am not so sure if we are ready to completely scrap these methods altogether simply because they exclude double-zero studies.

However, for 2x2 table data, I am all in favor of using methods that make more realistic distributional assumptions than the 'standard' approach that assumes that the sampling distribution of the log(odds ratio) is normal and has a known sampling variance. That's why metafor includes rma.glmm() for fitting appropriate unconditional mixed-effects logistic and the conditional mixed-effects logistic (i.e., hypergeometric) model to such data. And for fixed-effects models, there are also rma.mh() and rma.peto() for the Mantel-Haenszel and Peto's method.

I may also eventually include the beta-binomial model, but I need to give this some more thought. If you already want to start using this model, you will find implementions thereof in VGAM, aods3, and gamlss.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Markus 
> K?sters
> Sent: Friday, November 27, 2015 14:38
> To: 'Michael Dewey'; r-help at r-project.org
> Subject: Re: [R] metafor - Meta-Analysis of rare events / 
> beta-binomial regression
> 
> Dear Michael,
> 
> Thank you very much for your input, that is very much appreciated. I 
> have not considered that method, because it's rather outlawed in 
> general. But it is also included in Kuss and if I understood 
> correctly, the collapsing method (and the Cochrane method) both 
> performed not too bad under FEM assumption and had weaknesses in REM. 
> I usually prefer a REM approach, but in this case that may not be that important.
> I will also read the mmeta paper and documentation.
> 
> Thanks a lot!
> 
> Markus
> 
> -----Urspr?ngliche Nachricht-----
> Von: Michael Dewey [mailto:lists at dewey.myzen.co.uk]
> Gesendet: Freitag, 27. November 2015 13:32
> An: Markus K?sters; r-help at r-project.org
> Betreff: Re: [R] metafor - Meta-Analysis of rare events / 
> beta-binomial regression
> 
> Dear Markus
> 
> This is not a direct answer to your question, I will leave that to 
> Wolfgang but two thoughts:
> 
> 1 - if all the studies have very sparse data @article{bradburn07,
>     author = {Bradburn, M J and Deeks, J J and Berlin, J A and 
> Localio, A R},
>     title = {Much ado about nothing: a comparison of the performance of
>        meta--analytical methods with rare events},
>     journal = {Statistics in Medicine},
>     year = {2007},
>     volume = {26},
>     pages = {53--77},
>     keywords = {meta-analysis, fixed effects, random effects} } 
> suggests, surprisingly, that just collapsing the tables may be 
> adequate
> 
> 2 - there is a CRAN package mmeta which uses beta-binomial in a 
> Bayesian perspective. I did not find the documentation very explicit 
> but there is a paper in JSS.
> 
> On 26/11/2015 13:39, Markus K?sters wrote:
> > Dear all,
> >
> > I am currently writing a protocol for a meta-analysis which will 
> > analyze suicidal events. Recently, O. Kuss has (DOI 
> > 10.1002/sim.6383) published a paper that suggest using beta-binomial 
> > regression methods to incorporate double-zero studies. He states 
> > that  Methods that ignore information from double-zero studies or 
> > use continuity corrections should no longer be used.  It seems 
> > obvious to me that excluding studies with zero events will bias the 
> > results and I am willing to follow his advice. However, I am not a a 
> > biometrician, I have to admit that I am at a loss if and how it is 
> > possible to fit such model within the metafor package. Can someone 
> > help me or should I use the Yusuf Peto odds ratio method as 
> > suggested in the Cochrane
> handbook?
> >
> > Many thanks in advance,
> >
> > Markus


From abhinabaroy09 at gmail.com  Mon Nov 30 11:39:20 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Mon, 30 Nov 2015 16:09:20 +0530
Subject: [R] Extracting part of alpha numeric string
Message-ID: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>

Hi,

I have a field with alpha numeric codes like,

2154333b-3208-4519-8b76-acaef5b5a479 980958a0-103b-4ba9-afaf-27b2f5c24e69
00966654-0dea-4899-b8cf-26e8300b262d
I want a derived field which will contain ONLY the numeric part before the
first alphabet and the first '-',

for example the derived field from the sample above will give me

2154333
980958
00966654

How can this be achieved in R?

P.S. I do not have much knowledge on regex. It would be of great help if
you could suggest some reading for beginners.

Thanks,
Abhinaba

	[[alternative HTML version deleted]]


From phgrosjean at sciviews.org  Mon Nov 30 12:17:52 2015
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Mon, 30 Nov 2015 12:17:52 +0100
Subject: [R] Extracting part of alpha numeric string
In-Reply-To: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
References: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
Message-ID: <524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>

fields <- c("2154333b-3208-4519-8b76-acaef5b5a479", "980958a0-103b-4ba9-afaf-27b2f5c24e69",
            "00966654-0dea-4899-b8cf-26e8300b262d")
sub("^([0-9]*).*$", "\\1", fields)

Best,

Philippe Grosjean

> On 30 Nov 2015, at 11:39, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> 
> Hi,
> 
> I have a field with alpha numeric codes like,
> 
> 2154333b-3208-4519-8b76-acaef5b5a479 980958a0-103b-4ba9-afaf-27b2f5c24e69
> 00966654-0dea-4899-b8cf-26e8300b262d
> I want a derived field which will contain ONLY the numeric part before the
> first alphabet and the first '-',
> 
> for example the derived field from the sample above will give me
> 
> 2154333
> 980958
> 00966654
> 
> How can this be achieved in R?
> 
> P.S. I do not have much knowledge on regex. It would be of great help if
> you could suggest some reading for beginners.
> 
> Thanks,
> Abhinaba
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abhinabaroy09 at gmail.com  Mon Nov 30 13:09:00 2015
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Mon, 30 Nov 2015 17:39:00 +0530
Subject: [R] Extracting part of alpha numeric string
In-Reply-To: <524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>
References: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
	<524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>
Message-ID: <CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>

Hey,

worked like a charm! :)

Could you please explain about

sub("^([0-9]*).*$", "\\1", fields)

Thanks,
Abhinaba

On Mon, Nov 30, 2015 at 4:47 PM, <phgrosjean at sciviews.org> wrote:

> fields <- c("2154333b-3208-4519-8b76-acaef5b5a479",
> "980958a0-103b-4ba9-afaf-27b2f5c24e69",
>             "00966654-0dea-4899-b8cf-26e8300b262d")
> sub("^([0-9]*).*$", "\\1", fields)
>
> Best,
>
> Philippe Grosjean
>
> > On 30 Nov 2015, at 11:39, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> >
> > Hi,
> >
> > I have a field with alpha numeric codes like,
> >
> > 2154333b-3208-4519-8b76-acaef5b5a479 980958a0-103b-4ba9-afaf-27b2f5c24e69
> > 00966654-0dea-4899-b8cf-26e8300b262d
> > I want a derived field which will contain ONLY the numeric part before
> the
> > first alphabet and the first '-',
> >
> > for example the derived field from the sample above will give me
> >
> > 2154333
> > 980958
> > 00966654
> >
> > How can this be achieved in R?
> >
> > P.S. I do not have much knowledge on regex. It would be of great help if
> > you could suggest some reading for beginners.
> >
> > Thanks,
> > Abhinaba
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Nov 30 14:20:17 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 30 Nov 2015 14:20:17 +0100
Subject: [R] Error in 'Contrasts<-' while using GBM.
In-Reply-To: <CAJ9CoWnqOAZWz95kRjBiPOqJ28dB3Eg6pWvbcr8bsxHfAy70wg@mail.gmail.com>
References: <CAKaJDkSOxxgHwYo1LS0+WKVCUoVqyhe--Xymw2TtNJ3VtN+t9w@mail.gmail.com>
	<CAJ9CoWnqOAZWz95kRjBiPOqJ28dB3Eg6pWvbcr8bsxHfAy70wg@mail.gmail.com>
Message-ID: <AB946621-4F94-4353-BECC-30038BE7104B@gmail.com>


On 30 Nov 2015, at 02:59 , Max Kuhn <mxkuhn at gmail.com> wrote:

> Providing a reproducible example and the results of `sessionInfo` will help
> get your question answered.
> 
> My only guess is that one or more of your predictors are factors and that
> the in-sample data (used to build the model during resampling) have
> different levels than the holdout samples.

Another guess is that there's a factor in your (Karteek's) data that has only one level and that "ID ~ ." is pullling more variables into the model than you actually want. 

-pf

> 
> Max
> 
> On Sat, Nov 28, 2015 at 10:04 PM, Karteek Pradyumna Bulusu <
> kartikpradyumna92 at gmail.com> wrote:
> 
>> Hey,
>> 
>> I was trying to implement Stochastic Gradient Boosting in R. Following is
>> my code in rstudio:
>> 
>> 
>> 
>> library(caret);
>> 
>> library(gbm);
>> 
>> library(plyr);
>> 
>> library(survival);
>> 
>> library(splines);
>> 
>> library(mlbench);
>> 
>> set.seed(35);
>> 
>> stack = read.csv("E:/Semester 3/BDA/PROJECT/Sample_SO.csv", head
>> =TRUE,sep=",");
>> 
>> dim(stack); #displaying dimensions of the dataset
>> 
>> 
>> 
>> #SPLITTING TRAINING AND TESTING SET
>> 
>> totraining <- createDataPartition(stack$ID, p = .6, list = FALSE);
>> 
>> training <- stack[ totraining,]
>> 
>> test <- stack[-totraining,]
>> 
>> 
>> 
>> #PARAMETER SETTING
>> 
>> t_control <- trainControl(method = "cv", number = 10);
>> 
>> 
>> 
>> 
>> 
>> # GLM
>> 
>> start <- proc.time();
>> 
>> 
>> 
>> glm = train(ID ~ ., data = training,
>> 
>>             method = "gbm",
>> 
>>             metric = "ROC",
>> 
>>             trControl = t_control,
>> 
>>             verbose = FALSE)
>> 
>> 
>> 
>> When I am compiling last line, I am getting following error:
>> 
>> 
>> 
>> Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :
>> 
>>  contrasts can be applied only to factors with 2 or more levels
>> 
>> 
>> 
>> 
>> 
>> Can anyone tell me where I am going wrong and How to rectify it. It?ll be
>> greatful.
>> 
>> 
>> 
>> Thank you. Looking forward to it.
>> 
>> 
>> 
>> Regards,
>> Karteek Pradyumna Bulusu.
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From S.Ellison at LGCGroup.com  Mon Nov 30 14:28:46 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 30 Nov 2015 13:28:46 +0000
Subject: [R] Extracting part of alpha numeric string
In-Reply-To: <CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>
References: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
	<524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>
	<CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C942461B@GBTEDVPEXCMB04.corp.lgc-group.com>

> Could you please explain about
> 
> sub("^([0-9]*).*$", "\\1", fields)

See ?regex and the extensive online literature on regular expressions.

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From phgrosjean at sciviews.org  Mon Nov 30 14:57:58 2015
From: phgrosjean at sciviews.org (phgrosjean at sciviews.org)
Date: Mon, 30 Nov 2015 14:57:58 +0100
Subject: [R] Extracting part of alpha numeric string
In-Reply-To: <CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>
References: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
	<524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>
	<CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>
Message-ID: <CDA2C92B-B32E-4BEA-AAAA-96342F70B0BC@sciviews.org>


> On 30 Nov 2015, at 13:09, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> 
> Hey,
> 
> worked like a charm! :)
> 
> Could you please explain about
> 
> sub("^([0-9]*).*$", "\\1", fields)
> 

Yes.

sub() replaces substrings. The first argument captures the interesting part of the string:

^ = start of the string,

([0-9]*) = capture of the interesting part of the string. [0-9] means any figure from 0 to 9. * means 1 or more of these characters, and () is used to capture the substring, 

.* = all the rest. Dot (.) means any character, and * means again one or more of these characters,

$ = the end of the string.

The whole regular expression matches the whole string and captures the interesting part inside the ().

The second argument is the replacement. //1 means the first captured substring.

Thus, globally, we replace the whole string by the captured substring.

Best,

Philippe Grosjean


> Thanks,
> Abhinaba
> 
> On Mon, Nov 30, 2015 at 4:47 PM, <phgrosjean at sciviews.org <mailto:phgrosjean at sciviews.org>> wrote:
> fields <- c("2154333b-3208-4519-8b76-acaef5b5a479", "980958a0-103b-4ba9-afaf-27b2f5c24e69",
>             "00966654-0dea-4899-b8cf-26e8300b262d")
> sub("^([0-9]*).*$", "\\1", fields)
> 
> Best,
> 
> Philippe Grosjean
> 
> > On 30 Nov 2015, at 11:39, Abhinaba Roy <abhinabaroy09 at gmail.com <mailto:abhinabaroy09 at gmail.com>> wrote:
> >
> > Hi,
> >
> > I have a field with alpha numeric codes like,
> >
> > 2154333b-3208-4519-8b76-acaef5b5a479 980958a0-103b-4ba9-afaf-27b2f5c24e69
> > 00966654-0dea-4899-b8cf-26e8300b262d
> > I want a derived field which will contain ONLY the numeric part before the
> > first alphabet and the first '-',
> >
> > for example the derived field from the sample above will give me
> >
> > 2154333
> > 980958
> > 00966654
> >
> > How can this be achieved in R?
> >
> > P.S. I do not have much knowledge on regex. It would be of great help if
> > you could suggest some reading for beginners.
> >
> > Thanks,
> > Abhinaba
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


	[[alternative HTML version deleted]]


From ragland.debra at yahoo.com  Mon Nov 30 14:56:40 2015
From: ragland.debra at yahoo.com (debra ragland)
Date: Mon, 30 Nov 2015 13:56:40 +0000 (UTC)
Subject: [R] PCA plot of variable names only
References: <1464521238.12631664.1448891800674.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1464521238.12631664.1448891800674.JavaMail.yahoo@mail.yahoo.com>

Hello,?

A colleague of mine prepared a PCA plot of my data and I have no clue how he did it. My original data set contains 15 variables and 64 observations. I have been trying to figure out how he did it on my own, and I have asked but he's swamped so his response is taking longer than usual. Anywho, the plot is simply of PC1 vs. PC2 and in the area of the plot there are just the variable names aligned with values I'm guessing are the loadings (?) I have been searching around and I do not think that this was done via biplot. I am also not sure what is normally plotted on a PCA plot of this type (e.g. loadings, scores, sdevs -- no clue). ?Again, the 15 variable names (var1, var2, var3 etc) are all that is contained in this plot, aligned with their respective values projected onto the first 2 PCs.?

Any idea on how to generate such a plot based on this description?

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Nov 30 15:25:28 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 30 Nov 2015 09:25:28 -0500
Subject: [R] PCA plot of variable names only
In-Reply-To: <1464521238.12631664.1448891800674.JavaMail.yahoo@mail.yahoo.com>
References: <1464521238.12631664.1448891800674.JavaMail.yahoo.ref@mail.yahoo.com>
	<1464521238.12631664.1448891800674.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <E9AD124D-758C-457A-BA56-D69EB8442028@utoronto.ca>

Your description is obscure but the following may get you started. The function prcomp() returns a list in which the matrix x contains the rotated values of your input. Assuming that your "variable names" are the rownames of your input, you can plot them with text().  

Something like (untested):

myPCA <- prcomp(someData)
plot(myPCA$x[,1], myPCA$x[,2], type = "n")
text(myPCA$x[,1], myPCA$x[,2], rownames(someData))

B.



On Nov 30, 2015, at 8:56 AM, debra ragland via R-help <r-help at r-project.org> wrote:

> Hello, 
> 
> A colleague of mine prepared a PCA plot of my data and I have no clue how he did it. My original data set contains 15 variables and 64 observations. I have been trying to figure out how he did it on my own, and I have asked but he's swamped so his response is taking longer than usual. Anywho, the plot is simply of PC1 vs. PC2 and in the area of the plot there are just the variable names aligned with values I'm guessing are the loadings (?) I have been searching around and I do not think that this was done via biplot. I am also not sure what is normally plotted on a PCA plot of this type (e.g. loadings, scores, sdevs -- no clue).  Again, the 15 variable names (var1, var2, var3 etc) are all that is contained in this plot, aligned with their respective values projected onto the first 2 PCs. 
> 
> Any idea on how to generate such a plot based on this description?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Nov 30 15:26:13 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 30 Nov 2015 14:26:13 +0000
Subject: [R] PCA plot of variable names only
In-Reply-To: <1464521238.12631664.1448891800674.JavaMail.yahoo@mail.yahoo.com>
References: <1464521238.12631664.1448891800674.JavaMail.yahoo.ref@mail.yahoo.com>
	<1464521238.12631664.1448891800674.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C9424662@GBTEDVPEXCMB04.corp.lgc-group.com>

> Any idea on how to generate such a plot based on this description?

One simple way of suppressing the individual points in biplot() is to give the labels a colour of 0. 
Adapting the biplot.princomp example:

     biplot(princomp(USArrests), col=c(0,1))

But that retains the point plot axes. If it's not what you meant, you'll need to provide the picture.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From boris.steipe at utoronto.ca  Mon Nov 30 16:00:32 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 30 Nov 2015 10:00:32 -0500
Subject: [R] PCA plot of variable names only
In-Reply-To: <1175215247.13304251.1448894952216.JavaMail.yahoo@mail.yahoo.com>
References: <E9AD124D-758C-457A-BA56-D69EB8442028@utoronto.ca>
	<1175215247.13304251.1448894952216.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D60958F9-CF69-4B53-AFFE-FE14A552D7CB@utoronto.ca>

Please keep communications on list.
This is too confused to continue productively.

See here: http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide and don't post in HTML.





On Nov 30, 2015, at 9:49 AM, debra ragland <ragland.debra at yahoo.com> wrote:

> Hi,
> 
> I've tried this -- before your suggestion -- R throws an error at the plot argument stating that the figure margins are too large and the text argument staring that there is an invalid graphics state.
> 
> The figure that I am referring to is similar to figure 4 here;
> Computing and visualizing PCA in R
> 
>  
>  
> 
>  
>  
>  
>  
>  
> Computing and visualizing PCA in R
> Following my introduction to PCA, I will demonstrate how to apply and visualize PCA in R. There are many packages and functions that can apply PCA in R. In this po...
> View on www.r-bloggers.com
> Preview by Yahoo
>  
> Without the circle (or gray background, but this is minor) enclosing the variables. I am currently trying to figure out how to the adapt the code to my needs but I am struggling. 
> 
> 
> 
> On Monday, November 30, 2015 9:25 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> Your description is obscure but the following may get you started. The function prcomp() returns a list in which the matrix x contains the rotated values of your input. Assuming that your "variable names" are the rownames of your input, you can plot them with text().  
> 
> Something like (untested):
> 
> myPCA <- prcomp(someData)
> plot(myPCA$x[,1], myPCA$x[,2], type = "n")
> text(myPCA$x[,1], myPCA$x[,2], rownames(someData))
> 
> B.
> 
> 
> 
> On Nov 30, 2015, at 8:56 AM, debra ragland via R-help <r-help at r-project.org> wrote:
> 
> > Hello, 
> > 
> > A colleague of mine prepared a PCA plot of my data and I have no clue how he did it. My original data set contains 15 variables and 64 observations. I have been trying to figure out how he did it on my own, and I have asked but he's swamped so his response is taking longer than usual. Anywho, the plot is simply of PC1 vs. PC2 and in the area of the plot there are just the variable names aligned with values I'm guessing are the loadings (?) I have been searching around and I do not think that this was done via biplot. I am also not sure what is normally plotted on a PCA plot of this type (e.g. loadings, scores, sdevs -- no clue).  Again, the 15 variable names (var1, var2, var3 etc) are all that is contained in this plot, aligned with their respective values projected onto the first 2 PCs. 
> > 
> > Any idea on how to generate such a plot based on this description?
> 
> > 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 


From bhh at xs4all.nl  Mon Nov 30 16:34:35 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 30 Nov 2015 16:34:35 +0100
Subject: [R] Extracting part of alpha numeric string
In-Reply-To: <CDA2C92B-B32E-4BEA-AAAA-96342F70B0BC@sciviews.org>
References: <CANtKHPU1WfTPvNPmBfpfQBe9BYsNqK2GxSzwYEbtWry9+Q4jkQ@mail.gmail.com>
	<524A0581-C4DE-4C41-A8C9-D4F7C40906C0@sciviews.org>
	<CANtKHPX+SK20N48O_u53DOQhZsDZ1rWpvCK3H=Uh-QHF6XFa-Q@mail.gmail.com>
	<CDA2C92B-B32E-4BEA-AAAA-96342F70B0BC@sciviews.org>
Message-ID: <7E3147A0-1296-4440-95C9-24EAEBC73297@xs4all.nl>


> On 30 Nov 2015, at 14:57, phgrosjean at sciviews.org wrote:
> 
> 
>> On 30 Nov 2015, at 13:09, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
>> 
>> Hey,
>> 
>> worked like a charm! :)
>> 
>> Could you please explain about
>> 
>> sub("^([0-9]*).*$", "\\1", fields)
>> 
> 
> Yes.
> 
> sub() replaces substrings. The first argument captures the interesting part of the string:
> 
> ^ = start of the string,
> 
> ([0-9]*) = capture of the interesting part of the string. [0-9] means any figure from 0 to 9. * means 1 or more of these characters, and () is used to capture the substring, 
> 
> .* = all the rest. Dot (.) means any character, and * means again one or more of these characters,
> 
> $ = the end of the string.

Small correction:

* means zero or more characters

according to ?regex.

Berend


From dcarlson at tamu.edu  Mon Nov 30 16:48:09 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 30 Nov 2015 15:48:09 +0000
Subject: [R] PCA plot of variable names only
In-Reply-To: <D60958F9-CF69-4B53-AFFE-FE14A552D7CB@utoronto.ca>
References: <E9AD124D-758C-457A-BA56-D69EB8442028@utoronto.ca>
	<1175215247.13304251.1448894952216.JavaMail.yahoo@mail.yahoo.com>
	<D60958F9-CF69-4B53-AFFE-FE14A552D7CB@utoronto.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E54EE@mb02.ads.tamu.edu>

If it is just a plot of the variables by their loadings on the first two components, this should do it:

> dat <- data.frame(matrix(rnorm(100), 10, 5))
> dat.pca <- prcomp(dat)
> plot(dat.pca$rotation[, 1:2])
> text(dat.pca$rotation[, 1:2], colnames(dat), pos=3)

Or if you don't want the symbols just the names, change the last two lines:

> plot(dat.pca$rotation[, 1:2], type="n")
> text(dat.pca$rotation[, 1:2], colnames(dat))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris Steipe
Sent: Monday, November 30, 2015 9:01 AM
To: debra ragland
Cc: r-help
Subject: Re: [R] PCA plot of variable names only

Please keep communications on list.
This is too confused to continue productively.

See here: http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide and don't post in HTML.





On Nov 30, 2015, at 9:49 AM, debra ragland <ragland.debra at yahoo.com> wrote:

> Hi,
> 
> I've tried this -- before your suggestion -- R throws an error at the plot argument stating that the figure margins are too large and the text argument staring that there is an invalid graphics state.
> 
> The figure that I am referring to is similar to figure 4 here;
> Computing and visualizing PCA in R
> 
>  
>  
> 
>  
>  
>  
>  
>  
> Computing and visualizing PCA in R
> Following my introduction to PCA, I will demonstrate how to apply and visualize PCA in R. There are many packages and functions that can apply PCA in R. In this po...
> View on www.r-bloggers.com
> Preview by Yahoo
>  
> Without the circle (or gray background, but this is minor) enclosing the variables. I am currently trying to figure out how to the adapt the code to my needs but I am struggling. 
> 
> 
> 
> On Monday, November 30, 2015 9:25 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> Your description is obscure but the following may get you started. The function prcomp() returns a list in which the matrix x contains the rotated values of your input. Assuming that your "variable names" are the rownames of your input, you can plot them with text().  
> 
> Something like (untested):
> 
> myPCA <- prcomp(someData)
> plot(myPCA$x[,1], myPCA$x[,2], type = "n")
> text(myPCA$x[,1], myPCA$x[,2], rownames(someData))
> 
> B.
> 
> 
> 
> On Nov 30, 2015, at 8:56 AM, debra ragland via R-help <r-help at r-project.org> wrote:
> 
> > Hello, 
> > 
> > A colleague of mine prepared a PCA plot of my data and I have no clue how he did it. My original data set contains 15 variables and 64 observations. I have been trying to figure out how he did it on my own, and I have asked but he's swamped so his response is taking longer than usual. Anywho, the plot is simply of PC1 vs. PC2 and in the area of the plot there are just the variable names aligned with values I'm guessing are the loadings (?) I have been searching around and I do not think that this was done via biplot. I am also not sure what is normally plotted on a PCA plot of this type (e.g. loadings, scores, sdevs -- no clue).  Again, the 15 variable names (var1, var2, var3 etc) are all that is contained in this plot, aligned with their respective values projected onto the first 2 PCs. 
> > 
> > Any idea on how to generate such a plot based on this description?
> 
> > 
> >     [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ragland.debra at yahoo.com  Mon Nov 30 16:59:18 2015
From: ragland.debra at yahoo.com (debra ragland)
Date: Mon, 30 Nov 2015 15:59:18 +0000 (UTC)
Subject: [R] PCA plot of variable names only
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E54EE@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6E54EE@mb02.ads.tamu.edu>
Message-ID: <818125085.12595190.1448899158984.JavaMail.yahoo@mail.yahoo.com>

Thanks David!!! You have helped me tremendously! Thanks to all others for their input. I'll get out of your hair now :) 


    On Monday, November 30, 2015 10:48 AM, David L Carlson <dcarlson at tamu.edu> wrote:
 

 If it is just a plot of the variables by their loadings on the first two components, this should do it:

> dat <- data.frame(matrix(rnorm(100), 10, 5))
> dat.pca <- prcomp(dat)
> plot(dat.pca$rotation[, 1:2])
> text(dat.pca$rotation[, 1:2], colnames(dat), pos=3)

Or if you don't want the symbols just the names, change the last two lines:

> plot(dat.pca$rotation[, 1:2], type="n")
> text(dat.pca$rotation[, 1:2], colnames(dat))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris Steipe
Sent: Monday, November 30, 2015 9:01 AM
To: debra ragland
Cc: r-help
Subject: Re: [R] PCA plot of variable names only

Please keep communications on list.
This is too confused to continue productively.

See here: http://adv-r.had.co.nz/Reproducibility.html
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
... and please read the posting guide and don't post in HTML.







> Hi,
> 
> I've tried this -- before your suggestion -- R throws an error at the plot argument stating that the figure margins are too large and the text argument staring that there is an invalid graphics state.
> 
> The figure that I am referring to is similar to figure 4 here;
> Computing and visualizing PCA in R
> 
>? 
>? 
> 
>? 
>? 
>? 
>? 
>? 
> Computing and visualizing PCA in R
> Following my introduction to PCA, I will demonstrate how to apply and visualize PCA in R. There are many packages and functions that can apply PCA in R. In this po...
> View on www.r-bloggers.com
> Preview by Yahoo
>? 
> Without the circle (or gray background, but this is minor) enclosing the variables. I am currently trying to figure out how to the adapt the code to my needs but I am struggling. 
> 
> 
> 
> On Monday, November 30, 2015 9:25 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> 
> Your description is obscure but the following may get you started. The function prcomp() returns a list in which the matrix x contains the rotated values of your input. Assuming that your "variable names" are the rownames of your input, you can plot them with text().? 
> 
> Something like (untested):
> 
> myPCA <- prcomp(someData)
> plot(myPCA$x[,1], myPCA$x[,2], type = "n")
> text(myPCA$x[,1], myPCA$x[,2], rownames(someData))
> 
> B.
> 
> 
> 
> On Nov 30, 2015, at 8:56 AM, debra ragland via R-help <r-help at r-project.org> wrote:
> 
> > Hello, 
> > 
> > A colleague of mine prepared a PCA plot of my data and I have no clue how he did it. My original data set contains 15 variables and 64 observations. I have been trying to figure out how he did it on my own, and I have asked but he's swamped so his response is taking longer than usual. Anywho, the plot is simply of PC1 vs. PC2 and in the area of the plot there are just the variable names aligned with values I'm guessing are the loadings (?) I have been searching around and I do not think that this was done via biplot. I am also not sure what is normally plotted on a PCA plot of this type (e.g. loadings, scores, sdevs -- no clue).? Again, the 15 variable names (var1, var2, var3 etc) are all that is contained in this plot, aligned with their respective values projected onto the first 2 PCs. 
> > 
> > Any idea on how to generate such a plot based on this description?
> 
> > 
> >? ? [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From justin.balthrop at rice.edu  Mon Nov 30 16:19:59 2015
From: justin.balthrop at rice.edu (Justin Balthrop)
Date: Mon, 30 Nov 2015 09:19:59 -0600
Subject: [R] General copula model with heterogeneous marginals
Message-ID: <20151130091959.Horde.etl0ALdkrzuzZzZI4khTIg1@webmail.rice.edu>


	I am looking to model the sum of a number of random variables with  
arbitrary gamma distributions and an empirical dependence structure  
that I obtain from data. Basically I observe all of the individual  
pieces but I want to model their sum, as opposed to many copula  
questions which observe a single outcome of a multivariate process and  
seek to fit possible marginal and covariance structure.
It has been years since I coded in R, but this is what I have thus far:

library(copula)
library(scatterplot3d)
library(psych)
set.seed(1)
myCop<-  
normalCopula(param=c(.1,.1,.1,.1,.1,.2,.2,.2,.2,.2,.2,.2,.4,.4,.4,.4,.4,.5,.5,.5,.5), dim=7,  
dispstr="un")
myMvd<-mvdc(copula=myCop, margins=rep("gamma",7),  
paramMargins=list(list(shape=3,scale=4),
   list(shape=2, scale=5),
   list(shape=2, scale=5),
   list(shape=2, scale=5),
   list(shape=2, scale=5),
   list(shape=3, scale=5),
   list(shape=3, scale=5)))

simulation<- rMvdc(20000,myMvd)

colnames(simulation)<-c("P1","P2","P3","P4","P5","P6","P7")

total =  
simulation[,1]+simulation[,2]+simulation[,3]+simulation[,4]+simulation[,5]+simulation[,6]+simulation[,7]

As you can see, I have forced 7 gamma distributions with a placeholder  
covariance matrix input. The problem is that I am looking to  
generalize this to the order of ~150 different marginals with  
potentially differing distributions and parameters.
Ultimately I will have the following input:
?	matrix of 150 marginal distributions with family and parameters
?	150x150 covariance matrix
And what I need to produce is the following:
An empirical CDF/PDF of the sum of realizations from 5-10 of the  
underlying marginal distributions. To be more clear, assume each  
marginal distribution is a person's response to a treatment, and I  
need to calculate the cumulative treatment effect for a sub-group of  
the population of 150. So, I will have a vector of 0s and 1s to  
identify which members of the population are grouped together for a  
trial. Then I will have a separate vector for the next group. Each  
group vector will have dim=150 but have between 5 and 10 1s with the  
rest 0s. I need a different empirical CDF for each vector.
Any help?


From plummerm at iarc.fr  Mon Nov 30 19:09:16 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Mon, 30 Nov 2015 18:09:16 +0000
Subject: [R] rjags cannot find JAGS-4.0.0
In-Reply-To: <C4B61F15-B8BC-4F41-8F6C-5CBF0F981F6B@comcast.net>
References: <CAM=LvPw3tT5KwKwgo3eAPno4LsJspbpLM3mOHqS3BxjpUJhnWA@mail.gmail.com>
	<C4B61F15-B8BC-4F41-8F6C-5CBF0F981F6B@comcast.net>
Message-ID: <1448906956.4643.259.camel@iarc.fr>

On Fri, 2015-11-27 at 11:27 -0800, David Winsemius wrote:
> > On Nov 26, 2015, at 4:59 PM, Margaret Donald <merricks.merricks at gmail.com> wrote:
> > 
> > 1. Despite being in R with administrative rights  the library "rjags" loads
> > in a temporary location.
> > 
> >> install.packages("rjags", dependencies=TRUE,
> > +       lib= "C:/Users/Margaret Donald/Documents/R/win-library/3.2")
> > trying URL 'https://cran.r-project.org/bin/windows/contrib/3.2/rjags_4-4.zip
> > '
> > Content type 'application/zip' length 525871 bytes (513 KB)
> > downloaded 513 KB
> > 
> > package ?rjags? successfully unpacked and MD5 sums checked
> > 
> > The downloaded binary packages are in
> >        C:\Users\Margaret
> > Donald\AppData\Local\Temp\RtmpMzv76s\downloaded_packages
> 
> That?s not an indication of an error. The installation process always does that.
> 
> 
> > #-----------------------------------------------------------------------------------------------------------------
> > 
> > 2. Cannot find JAGS-4.0.0 which is in C;\programs\JAGS\JAGS-4.0.0.  How do
> > I get R to see JAGS-4.0.0

The Windows installer writes some keys in the Windows registry. These
keys are then read by the rjags package when it is loaded to locate the
JAGS DLL.

I don't know why this is not working in your case. You might try
uninstalling and reinstalling JAGS (and by this I mean that the user who
installed it should uninstall it from the Control Panel).

Otherwise, as David says, you can set the environment variable
JAGS_HOME. Note that if you previously set JAGS_HOME in .Rprofile and
have upgraded to a new version of JAGS, then JAGS_HOME will be pointing
to the wrong place. This might explain why rjags cannot find JAGS and
this is why I do not recommend this solution except as a last resort.

> You might try to use Sys.setenv to create a properly directed JAGS_HOME
> 
> Sys.setenv(JAGS_HOME=?C:\programs\JAGS\JAGS-4.0.0?)
> 
> (I corrected the semi-colon.) 
> >> library(rjags)
> > Error : .onLoad failed in loadNamespace() for 'rjags', details:
> >  call: fun(libname, pkgname)
> >  error: Failed to locate any version of JAGS version 4
> > 
> > The rjags package is just an interface to the JAGS library
> > Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
> > http://www.sourceforge.net/projects/mcmc-jags/files
> 
> I?m was having a perhaps similar problem on a Mac. The binary version
> 3-15 of rjags installed today from CRAN was trying to
> access /usr/local/lib/libjags.3.dylib, but since I have installed JAGS
> version 4.0.1 installed from the SourceForge repository, there is no
> ligjags.3.dylib, but instead there was only
> a /usr/local/lib/libjags.4.dylib

rjags_4-4 requires JAGS 4.x.y and the previous version rjags_3-15 is not
compatible with JAGS 4.0.0. Unfortunately the Mac OS X binaries on CRAN
are not up to date. I have no control over this but Matt Denwood has
made a binary for Mavericks or later available on Sourceforge:

http://sourceforge.net/projects/mcmc-jags/files/rjags/4/rjags_4-4.tgz

Martyn

> Going back to SourceForge and tracking down the older version of JAGS
> and installing version 3.4.0 was successful in getting rjags to load
> correctly. I suspect that with the release of JAGS v4 that there is
> some mismatch among the various editions of rjags and JAGS.
> 
> ? 
> David
> > 
> > Error: package or namespace load failed for ?rjags?
> >> library(R2jags)
> > Loading required package: rjags
> > Error : .onLoad failed in loadNamespace() for 'rjags', details:
> >  call: fun(libname, pkgname)
> >  error: Failed to locate any version of JAGS version 4
> > 
> > The rjags package is just an interface to the JAGS library
> > Make sure you have installed JAGS-4.x.y.exe (for any x >=0, y>=0) from
> > http://www.sourceforge.net/projects/mcmc-jags/files
> > 
> > Error: package ?rjags? could not be loaded
> >> 
> > 
> > Regards,
> > Margaret Donald
> > -- 
> > Margaret Donald
> > Post Doctoral researcher
> > University of New South Wales
> > margaret.donald at unsw.edu.au
> > 0405 834 550
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 


From sheroukmoawad at yahoo.com  Mon Nov 30 22:20:34 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Mon, 30 Nov 2015 21:20:34 +0000 (UTC)
Subject: [R] summation equation whose numerator has subscript
References: <944655747.7652698.1448918434492.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <944655747.7652698.1448918434492.JavaMail.yahoo@mail.yahoo.com>

Dear R experts 
Please do you have any idea about how this summation can be written in R(the equation can be viewed in the following link): 
http://s16.postimg.org/or2km30ph/equation.jpg 

I've tried out out this code but it gave me error for writing brackets in function of summation:

>>> 
x=matrix(c(6,2,1),3,1) 

for (l in 1:3){ 
sum(sapply(1:3, function(j[l]){if(l>1){sum(sapply(1:j[l-1], function(j[l]){x[j[l]]*(j[l]<j[l-1])}))}}))}>>>Thank you


From jdnewmil at dcn.davis.ca.us  Mon Nov 30 23:17:55 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 30 Nov 2015 14:17:55 -0800
Subject: [R] summation equation whose numerator has subscript
In-Reply-To: <944655747.7652698.1448918434492.JavaMail.yahoo@mail.yahoo.com>
References: <944655747.7652698.1448918434492.JavaMail.yahoo.ref@mail.yahoo.com>
	<944655747.7652698.1448918434492.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <731B7B27-F965-44B2-8892-771D3D7A57EA@dcn.davis.ca.us>

I cannot understand that summation at all,  much less translate it to R. Do you have an original citation for this thing? 

As for putting subscripts in parameter lists,  that is not going to happen. You have to accept that the code that calls your function needs to do any necessary subscripting before it gives that piece to your function. Keep in mind that apply functions do this by their nature without the mess of specifying it yourself. If you know that the automatic subscripting that sapply does is not going to get the result you want then don't use that function. 
-- 
Sent from my phone. Please excuse my brevity.

On November 30, 2015 1:20:34 PM PST, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
>Dear R experts 
>Please do you have any idea about how this summation can be written in
>R(the equation can be viewed in the following link): 
>http://s16.postimg.org/or2km30ph/equation.jpg 
>
>I've tried out out this code but it gave me error for writing brackets
>in function of summation:
>
>>>> 
>x=matrix(c(6,2,1),3,1) 
>
>for (l in 1:3){ 
>sum(sapply(1:3, function(j[l]){if(l>1){sum(sapply(1:j[l-1],
>function(j[l]){x[j[l]]*(j[l]<j[l-1])}))}}))}>>>Thank you
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Nov 30 23:27:46 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 30 Nov 2015 14:27:46 -0800
Subject: [R] summation equation whose numerator has subscript
In-Reply-To: <944655747.7652698.1448918434492.JavaMail.yahoo@mail.yahoo.com>
References: <944655747.7652698.1448918434492.JavaMail.yahoo.ref@mail.yahoo.com>
	<944655747.7652698.1448918434492.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <954081E4-C3D2-4029-A90F-044C636395A2@comcast.net>


> On Nov 30, 2015, at 1:20 PM, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
> 
> Dear R experts 
> Please do you have any idea about how this summation can be written in R(the equation can be viewed in the following link): 
> http://s16.postimg.org/or2km30ph/equation.jpg 

Can you explain in natural language the goals of this expression. It makes little sense to me to start with an index of j_sub_l = 0 and to then iterate to up to j_sub_(l-1) -1 . How can there be a value for j_sub(l-1) with a starting point of zero. The notation saying to do something for l = 2:n is not helpful since values of ?l? doesn?t really appear in the looped expression (noting that j_sub_l starts at 0, so it's not being determined by ?l".

I believe the confused notation was the cause of this question being closed after it appeared last week on SO:

http://stackoverflow.com/questions/33882285/summation-equation-whose-numerator-has-subscript

And what intent is meant for the indices of the outer summation? The expression j_sub_1 = 0 seems to have no corresponding reference point inside the looped expression. So you would simply be summing the same value N times, but since N is not defined we cannot write any code.

> 
> I've tried out out this code but it gave me error for writing brackets in function of summation:

You should _always_, _always_, _always_ post the entire results of an error. We have no way of seeing your console. Error messages are usually informative.

> 
>>>> 
> x=matrix(c(6,2,1),3,1) 
> 
> for (l in 1:3){ 
> sum(sapply(1:3, function(j[l]){if(l>1){sum(sapply(1:j[l-1], function(j[l]){x[j[l]]*(j[l]<j[l-1])}))}}))}


You have three nested loops in the code above, but at least it appears you do understand that R is a 1-based language. But since the image-expression goes from 0 to some cryptic value (minus one) then the R version ought to go from one to "one more? than that expression.


> >>>Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


